<doc id="53982" url="http://en.wikipedia.org/wiki?curid=53982" title="Euchromatin">
Euchromatin

Euchromatin is a lightly packed form of chromatin (DNA, RNA and protein) that is rich in gene concentration, and is often (but not always) under active transcription. Euchromatin comprises the most active portion of the genome within the cell nucleus. 92% of the human genome is euchromatic. The remainder is called heterochromatin.
Structure.
The structure of euchromatin is reminiscent of an unfolded set of beads along a string, wherein those beads represent nucleosomes. Nucleosomes consist of eight proteins known as histones, with approximately 147 base pairs of DNA wound around them; in euchromatin, this wrapping is loose so that the raw DNA may be accessed. Each core histone possesses a `tail' structure, which can vary in several ways; it is thought that these variations act as "master control switches," which determine the overall arrangement of the chromatin. In particular, it is believed that the presence of methylated lysine 4 on the histone tails acts as a general marker for euchromatin.
Appearance.
In general, euchromatin appears as light-colored bands when stained in G banding and observed under an optical microscope, in contrast to heterochromatin, which stains darkly. This lighter staining is due to the less compact structure of euchromatin. The basic structure of euchromatin is an elongated, open, 10 nm microfibril, as noted by electron microscopy. In prokaryotes, euchromatin is the "only" form of chromatin present; this indicates that the heterochromatin structure evolved later along with the nucleus, possibly as a mechanism to handle increasing genome size.
Function.
Euchromatin participates in the active transcription of DNA to mRNA products. The unfolded structure allows gene regulatory proteins and RNA polymerase complexes to bind to the DNA sequence, which can then initiate the transcription process. Not all euchromatin is necessarily transcribed, but in general that which is not is transformed into heterochromatin to protect the genes while they are not in use. There is therefore a direct link to how actively productive a cell is and the amount of euchromatin that can be found in its nucleus. It is thought that the cell uses transformation from euchromatin into heterochromatin as a method of controlling gene expression and replication, since such processes behave differently on densely compacted chromatin, known as the `accessibility hypothesis'. One example of constitutive euchromatin that is 'always turned on' is housekeeping genes, which code for the proteins needed for basic functions of cell survival.

</doc>
<doc id="53983" url="http://en.wikipedia.org/wiki?curid=53983" title="Heterochromatin">
Heterochromatin

Heterochromatin is a tightly packed form of DNA, which comes in multiple varieties. These varieties lie on a continuum between the two extremes of constitutive and facultative heterochromatin. Both play a role in the expression of genes.
 Constitutive heterochromatin can affect the genes near them (position-effect variegation). It is usually repetitive and forms structural functions such as centromeres or telomeres, in addition to acting as an attractor for other gene-expression or repression signals. 
Facultative heterochromatin is the result of genes that are silenced through a mechanism such as histone deacetylation or piRNA through RNAi. It is not repetitive and shares the compact structure of constitutive heterochromatin. However, under specific developmental or environmental signaling cues, it can lose its condensed structure and become transcriptionally active.
 Heterochromatin has been associated with the di and tri-methylation of H3K9 in certain portions of the genome.
Structure.
Chromatin is found in two varieties: euchromatin and heterochromatin. Originally, the two forms were distinguished cytologically by how intensely they stained - the euchromatin is less intense, while heterochromatin stains intensely, indicating tighter packing. Heterochromatin is usually localized to the periphery of the nucleus.
Despite this early dichotomy, recent evidence in both animals and plants has suggested that there are more than two distinct heterochromatin states, and it may in fact exist in four or five 'states', each marked by different combinations of epigenetic marks.
Heterochromatin mainly consists of genetically inactive satellite sequences, and many genes are repressed to various extents, although some cannot be expressed in euchromatin at all. Both centromeres and telomeres are heterochromatic, as is the Barr body of the second, inactivated X-chromosome in a female.
Function.
Heterochromatin has been associated with several functions, from gene regulation to the protection of chromosome integrity; some of these roles can be attributed to the dense packing of DNA, which makes it less accessible to protein factors that usually bind DNA or its associated factors. For example, naked double-stranded DNA ends would usually be interpreted by the cell as damaged or viral DNA, triggering cell cycle arrest, DNA repair or destruction of the fragment, such as by endonucleases in bacteria.
Some regions of chromatin are very densely packed with fibers that display a condition comparable to that of the chromosome at mitosis. Heterochromatin is generally clonally inherited; when a cell divides the two daughter cells typically contain heterochromatin within the same regions of DNA, resulting in epigenetic inheritance. Variations cause heterochromatin to encroach on adjacent genes or recede from genes at the extremes of domains. Transcribable material may be repressed by being positioned (in "cis") at these boundary domains. This gives rise to expression levels that vary from cell to cell, which may be demonstrated by position-effect variegation. Insulator sequences may act as a barrier in rare cases where constitutive heterochromatin and highly active genes are juxtaposed (e.g. the 5'HS4 insulator upstream of the chicken β-globin locus, and loci in two "Saccharomyces" spp.).
Constitutive heterochromatin.
All cells of a given species that package the same regions of DNA in constitutive heterochromatin, and thus in all cells any genes contained within the constitutive heterochromatin will be poorly expressed. For example, all human chromosomes 1, 9, 16, and the Y-chromosome contain large regions of constitutive heterochromatin. In most organisms, constitutive heterochromatin occurs around the chromosome centromere and near telomeres.
Facultative heterochromatin.
The regions of DNA packaged in facultative heterochromatin will not be consistent between the cell types within a species, and thus a sequence in one cell that is packaged in facultative heterochromatin (and the genes within are poorly expressed) may be packaged in euchromatin in another cell (and the genes within are no longer silenced). However, the formation of facultative heterochromatin is regulated, and is often associated with morphogenesis or differentiation. An example of facultative heterochromatin is X-chromosome inactivation in female mammals: one X chromosome is packaged as facultative heterochromatin and silenced, while the other X chromosome is packaged as euchromatin and expressed.
Among the molecular components that appear to regulate the spreading of heterochromatin include the Polycomb-group proteins and non-coding genes such as Xist. The mechanism for such spreading is still a matter of controversy.
Yeast heterochromatin.
"Saccharomyces cerevisiae", or budding yeast, is a model eukaryote and its heterochromatin has been defined thoroughly. Although most of its genome can be characterized as euchromatin, "S. cerevisiae" has regions of DNA that are transcribed very poorly. These loci are the so-called silent mating type loci (HML and HMR), the rDNA (encoding ribosomal RNA), and the sub-telomeric regions.
Fission yeast ("Schizosaccharomyces pombe") uses another mechanism for heterochromatin formation at its centromeres. Gene silencing at this location depends on components of the RNAi pathway. Double-stranded RNA is believed to result in silencing of the region through a series of steps.
In the fission yeast "Schizosaccharomyces pombe" two RNAi complexes, the RNAi-induced transcriptional gene silencing (RITS) complex and the RNA-directed RNA polymerase complex (RDRC), are part of an RNAi machinery involved in the initiation, propagation and maintenance of heterochromatin assembly. These two complexes localize in a siRNA-dependent manner on chromosomes, at the site of heterochromatin assembly. RNA polymerase II synthesizes a transcript that serves as a platform to recruit RITS, RDRC and possibly other complexes required for heterochromatin assembly. Both RNAi and an exosome-dependent RNA degradation process contribute to heterochromatic gene silencing. These mechanisms of "Schizosaccharomyces pombe" may occur in other eukaryotes. A large RNA structure called RevCen has also been implicated in the production of siRNAs to mediate heterochromatin formation in some fission yeast.

</doc>
<doc id="53986" url="http://en.wikipedia.org/wiki?curid=53986" title="Fallacy">
Fallacy

A fallacy is the use of poor, or invalid, reasoning for the construction of an argument. It is also used to refer to "an argument which appears to be correct but is not." If an argument is fallacious, it does not necessarily mean the conclusion is false.
Fallacies are commonly divided into those that are formal and those that are informal. A formal fallacy can neatly be expressed in standard system of logic; for example, propositional logic. Conversely, an informal fallacy originates in an other error in reasoning than an improper logical form. Arguments committing informal fallacies may be formally valid but still be fallacious.
Fallacies of presumption fail to prove the conclusion by assuming the conclusion in the proof. Fallacies of weak inference fail to prove the conclusion due to insufficient evidence. Fallacies of distraction fail to prove the conclusion due to irrelevant evidence, like emotion. Fallacies of ambiguity fail to prove the conclusion due to vagueness in words, phrases, or grammar.
Some fallacies are committed intentionally (to manipulate or persuade by deception), others unintentionally due to carelessness or ignorance.
Formal fallacy.
A formal fallacy is a common error of thinking that can neatly be expressed in standard system of logic. An argument that is formally fallacious is rendered invalid due to a flaw in its logical structure. Such an argument is always considered to be wrong.
The presence of a formal fallacy in a deductive argument does not imply anything about the argument's premises or its conclusion. Both may actually be true, or may even be more probable as a result of the argument; but the deductive argument is still invalid because the conclusion does not follow from the premises in the manner described. By extension, an argument can contain a formal fallacy even if the argument is not a deductive one: for instance, an inductive argument that incorrectly applies principles of probability or causality can be said to commit a formal fallacy.
Aristotle's Fallacies.
Aristotle was the first to systematize logical errors into a list. Aristotle's "Sophistical Refutations" ("De Sophisticis Elenchis") identifies thirteen fallacies. He divided them up into two major types, those depending on language and those not depending on language. These fallacies are called verbal fallacies and material fallacies, respectively. A material fallacy is an error in what the arguer is talking about, while a verbal fallacy is an error in how the arguer is talking. Verbal fallacies are those in which a conclusion is obtained by improper or ambiguous use of words.
Whately's grouping of fallacies.
Richard Whately defines a fallacy broadly as, "any argument, or apparent argument, which professes to be decisive of the matter at hand, while in reality it is not.
Whately divided fallacies into two groups: "logical" and "material". According to Whately, logical fallacies are arguments where the conclusion does not follow from the premises. Material fallacies are not logical errors because the conclusion does follow from the premises. He then divided the logical group into two groups: purely logical and semi-logical. The semi-logical group included all of Aristotle's sophisms except:"ignoratio elenchi", "petitio principii", and "non causa pro causa", which are in the material group.
Intentional fallacies.
Sometimes a speaker or writer uses a fallacy intentionally. In any context, including academic debate, a conversation among friends, political discourse, advertising, or for comedic purposes, the arguer may use fallacious reasoning to try to persuade the listener or reader, by means other than offering relevant evidence, that the conclusion is true.
Examples of this include the speaker or writer: diverting the argument to unrelated issues with a red herring (Ignoratio elenchi); insulting someone's character (argumentum ad hominem), assuming they are right by "begging the question" (petitio principi); making jumps in logic (non-sequitur); identifying a false cause and effect (post hoc ergo propter hoc); asserting that everyone agrees (bandwagoning); creating a "false dilemma" ("either-or fallacy") in which the situation is oversimplified; selectively using facts (card-stacking); making false or misleading comparisons (false equivalence and "false analogy); generalizing quickly and sloppily (hasty generalization).
In humor, errors of reasoning are used for comical purposes. Groucho Marx used fallacies of amphiboly, for instance, to make ironic statements; Gary Larson employs fallacious reasoning in many of his cartoons. Wes Boyer and Samuel Stoddard have written a humorous essay teaching students how to be persuasive by means of a whole host of informal and formal fallacies.
Deductive fallacy.
In philosophy, the term formal fallacy for logical fallacies and defined formally as: a flaw in the structure of a deductive argument which renders the argument invalid. The term is preferred as logic is the use of valid reasoning and a fallacy is an argument that uses poor reasoning therefore the term logical fallacy is an oxymoron. However, the same terms are used in informal discourse to mean an argument which is problematic for any reason. 
A logical form such as ""A" and "B"" is independent of any particular conjunction of meaningful propositions. Logical form alone can guarantee that given true premises, a true conclusion must follow. However, formal logic makes no such guarantee if any premise is false; the conclusion can be either true or false. Any formal error or logical fallacy similarly invalidates the deductive guarantee. Both the argument and all its premises must be true for a statement to be true.
Paul Meehl's Fallacies.
In "Why I Do Not Attend Case Conferences" (1973), psychologist Paul Meehl discusses several fallacies that can arise in medical case conferences that are primarily held to diagnose patients. These fallacies can also be considered more general errors of thinking that all individuals (not just psychologists) are prone to making.
Fallacies of Measurement.
Increasing availability and circulation of big data are driving proliferation of new metrics for scholarly authority, and there is lively discussion regarding the relative usefulness of such metrics for measuring the value of knowledge production in the context of an "information tsunami." Where mathematical fallacies are subtle mistakes in reasoning leading to invalid mathematical proofs, measurement fallacies are unwarranted inferential leaps involved in the extrapolation of raw data to a measurement-based value claim. The ancient Greek Sophist Protagoras was one of the first thinkers to propose that humans can generate reliable measurements through his "human-measure" principle and the practice of "dissoi logoi" (arguing multiple sides of an issue). This history helps explain why measurement fallacies are informed by informal logic and argumentation theory.
Other systems of classification.
Of other classifications of fallacies in general the most famous are those of Francis Bacon and J. S. Mill. Bacon ("Novum Organum", Aph. 33, 38 sqq.) divided fallacies into four Idola (Idols, i.e. False Appearances), which summarize the various kinds of mistakes to which the human intellect is prone. With these should be compared the Offendicula of Roger Bacon, contained in the Opus maius, pt. i. J. S. Mill discussed the subject in book v. of his Logic, and Jeremy Bentham's Book of Fallacies (1824) contains valuable remarks. See Rd. Whateley's Logic, bk. v.; A. de Morgan, Formal Logic (1847) ; A. Sidgwick, Fallacies (1883) and other textbooks.
See also.
Lists
Concepts
Works
References.
</dl>
Further reading.
Historical texts

</doc>
<doc id="53990" url="http://en.wikipedia.org/wiki?curid=53990" title="Cornales">
Cornales

Cornales is an order of flowering plants, basal among the asterids, containing about 600 species. Plants within Cornales usually have four-parted flowers, drupaceous fruits, and inferior gynoecia topped with disc-shaped nectaries. Under the APG system, Cornales includes the following families:
Phylogeny.
Cornales is sister to the remainder of the large and diverse asterid clade. 
Members of Cornales are highly geographically disjunct and morphologically diverse, which has led to considerable confusion regarding the proper circumscription of the groups within the order and the relationships between them. Under the Cronquist system the order comprised the families Cornaceae, Nyssaceae, Garryaceae, and Alangiaceae, and was placed among the Rosidae, but this interpretation is no longer followed. Many families and genera previously associated with Cornales have been removed, including Garryaceae, "Griselinia", "Corokia", and "Kaliphora", among others. 
Molecular data suggest that there are four clades within the Cornales: "Cornus-Alangium", nyssoids-mastixioids, Hydrangeaceae-Loasaceae, and "Grubbia-Curtisia", with Hydrostachyaceae in an uncertain position, possibly basal. However, the relationship between these clades is unclear, and as a result of many historical taxonomic interpretations and differing opinions regarding the significance of morphological variations, rankings of taxa within the order are inconsistent. These difficulties in interpreting the systematics of Cornales may represent an early and rapid diversification of the groups within the order.
External links.
http://www.britannica.com/EBchecked/topic/137865/Cornales

</doc>
<doc id="53991" url="http://en.wikipedia.org/wiki?curid=53991" title="Adjoint functors">
Adjoint functors

In mathematics, specifically category theory, adjunction is a possible relationship between two functors.
Adjunction is ubiquitous in mathematics, as it specifies intuitive notions of optimization and efficiency.
In the most concise symmetric definition, an adjunction between categories "C" and "D" is a pair of functors,
and a family of bijections
which is natural in the variables "X" and "Y". The functor "F" is called a left adjoint functor, while "G" is called a right adjoint functor. The relationship “"F" is left adjoint to "G"” (or equivalently, “"G" is right adjoint to "F"”) is sometimes written
This definition and others are made precise below.
Introduction.
“The slogan is ‘Adjoint functors arise everywhere’.” (Saunders Mac Lane, "Categories for the working mathematician")
The long list of examples in this article is only a partial indication of how often an interesting mathematical construction is an adjoint functor. As a result, general theorems about left/right adjoint functors, such as the equivalence of their various definitions or the fact that they respectively preserve colimits/limits (which are also found in every area of mathematics), can encode the details of many useful and otherwise non-trivial results.
Spelling (or morphology).
One can observe (e.g. in this article), two different roots are used: "adjunct" and "adjoint". From Oxford shorter English dictionary, "adjunct" is from Latin, "adjoint" is from French.
In Mac Lane, "Categories for the working mathematician," chap. 4, "Adjoints", one can verify the following usage.
formula_5
The hom-set bijection formula_6 is an "adjunction".
If formula_7 an arrow in formula_8, formula_9 is the right "adjunct" of formula_7 (p. 81).
The functor formula_11 is left "adjoint" for formula_12.
Motivation.
Solutions to optimization problems.
It can be said that an adjoint functor is a way of giving the "most efficient" solution to some problem via a method which is "formulaic". For example, an elementary problem in ring theory is how to turn a rng (which is like a ring that might not have a multiplicative identity) into a ring. The "most efficient" way is to adjoin an element '1' to the rng, adjoin all (and only) the elements which are necessary for satisfying the ring axioms (e.g. "r"+1 for each "r" in the ring), and impose no relations in the newly formed ring that are not forced by axioms. Moreover, this construction is "formulaic" in the sense that it works in essentially the same way for any rng.
This is rather vague, though suggestive, and can be made precise in the language of category theory: a construction is "most efficient" if it satisfies a universal property, and is "formulaic" if it defines a functor. Universal properties come in two types: initial properties and terminal properties. Since these are dual (opposite) notions, it is only necessary to discuss one of them.
The idea of using an initial property is to set up the problem in terms of some auxiliary category "E", and then identify that what we want is to find an initial object of "E". This has an advantage that the "optimization" — the sense that we are finding the "most efficient" solution — means something rigorous and is recognisable, rather like the attainment of a supremum. The category "E" is also formulaic in this construction, since it is always the category of elements of the functor to which one is constructing an adjoint. In fact, this latter category is precisely the comma category over the functor in question.
As an example, take the given rng "R", and make a category "E" whose "objects" are rng homomorphisms "R" → "S", with "S" a ring having a multiplicative identity. The "morphisms" in "E" between "R" → "S1" and "R" → "S2" are commutative triangles of the form ("R" → "S1","R" → "S2", "S1" → "S2") where S1 → S2 is a ring map (which preserves the identity). Note that this is precisely the definition of the comma category of "R" over the inclusion of unitary rings into rng. The existence of a morphism between "R" → "S1" and "R" → "S2" implies that "S1" is at least as efficient a solution as "S2" to our problem: "S2" can have more adjoined elements and/or more relations not imposed by axioms than "S1".
Therefore, the assertion that an object "R" → "R*" is initial in "E", that is, that there is a morphism from it to any other element of "E", means that the ring "R"* is a "most efficient" solution to our problem.
The two facts that this method of turning rngs into rings is "most efficient" and "formulaic" can be expressed simultaneously by saying that it defines an "adjoint functor".
Symmetry of optimization problems.
Continuing this discussion, suppose we "started" with the functor "F", and posed the following (vague) question: is there a problem to which "F" is the most efficient solution?
The notion that "F" is the "most efficient solution" to the problem posed by "G" is, in a certain rigorous sense, equivalent to the notion that "G" poses the "most difficult problem" that "F" solves. 
This has the intuitive meaning that adjoint functors should occur in pairs, and in fact they do, but this is not trivial from the universal morphism definitions. The equivalent symmetric definitions involving adjunctions and the symmetric language of adjoint functors (we can say either "F" is left adjoint to "G" or "G" is right adjoint to "F") have the advantage of making this fact explicit.
Formal definitions.
There are various definitions for adjoint functors. Their equivalence is elementary but not at all trivial and in fact highly useful. This article provides several such definitions:
Adjoint functors arise everywhere, in all areas of mathematics. Their full usefulness lies in that the structure in any of these definitions gives rise to the structures in the others via a long but trivial series of deductions. Thus, switching between them makes implicit use of a great deal of tedious details that would otherwise have to be repeated separately in every subject area. For example, naturality and terminality of the counit can be used to prove that any right adjoint functor preserves limits.
Conventions.
The theory of adjoints has the terms "left" and "right" at its foundation, and there are many components which live in one of two categories "C" and "D" which are under consideration. It can therefore be extremely helpful to choose letters in alphabetical order according to whether they live in the "lefthand" category "C" or the "righthand" category "D", and also to write them down in this order whenever possible.
In this article for example, the letters "X", "F", "f", ε will consistently denote things which live in the category "C", the letters "Y", "G", "g", η will consistently denote things which live in the category "D", and whenever possible such things will be referred to in order from left to right (a functor "F":"C"←"D" can be thought of as "living" where its outputs are, in "C").
Universal morphisms.
A functor "F" : "C" ← "D" is a left adjoint functor if for each object "X" in "C", there exists a terminal morphism from "F" to "X". If, for each object "X" in "C", we choose an object "G"0"X" of "D" for which there is a terminal morphism ε"X" : "F"("G"0"X") → "X" from "F" to "X", then there is a unique functor "G" : "C" → "D" such that "GX" = "G"0"X" and ε"Xʹ" ∘ "FG"("f") = "f" ∘ ε"X" for "f" : "X" → "Xʹ" a morphism in "C"; "F" is then called a left adjoint to "G".
A functor "G" : "C" → "D" is a right adjoint functor if for each object "Y" in "D", there exists an initial morphism from "Y" to "G". If, for each object "Y" in "D", we choose an object "F"0"Y" of "C" and an initial morphism η"Y" : "Y" → "G"("F"0"Y") from "Y" to "G", then there is a unique functor "F" : "C" ← "D" such that "FY" = "F"0"Y" and "GF"("g") ∘ η"Y" = η"Yʹ" ∘ "g" for "g" : "Y" → "Yʹ" a morphism in "D"; "G" is then called a right adjoint to "F".
 "Remarks: " 
It is true, as the terminology implies, that "F" is "left adjoint to G" if and only if "G" is "right adjoint to F". This is apparent from the symmetric definitions given below. The definitions via universal morphisms are often useful for establishing that a given functor is left or right adjoint, because they are minimalistic in their requirements. They are also intuitively meaningful in that finding a universal morphism is like solving an optimization problem.
Counit-unit adjunction.
A counit-unit adjunction between two categories "C" and "D" consists of two functors "F" : "C" ← "D" and "G" : "C" → "D" and two natural transformations
respectively called the counit and the unit of the adjunction (terminology from universal algebra), such that the compositions
are the identity transformations 1"F" and 1"G" on "F" and "G" respectively.
In this situation we say that "F" is left adjoint to "G" and "G" is right adjoint to "F" , and may indicate this relationship by writing  formula_16 , or simply  formula_17 .
In equation form, the above conditions on (ε,η) are the counit-unit equations
which mean that for each "X" in "C" and each "Y" in "D",
Note that here formula_20 denotes identity functors, while above the same symbol was used for identity natural transformations.
These equations are useful in reducing proofs about adjoint functors to algebraic manipulations. They are sometimes called the "zig-zag equations" because of the appearance of the corresponding string diagrams. A way to remember them is to first write down the nonsensical equation formula_21 and then fill in either "F" or "G" in one of the two simple ways which make the compositions defined.
Note: The use of the prefix "co" in counit here is not consistent with the terminology of limits and colimits, because a colimit satisfies an "initial" property whereas the counit morphisms will satisfy "terminal" properties, and dually. The term "unit" here is borrowed from the theory of monads where it looks like the insertion of the identity 1 into a monoid.
Hom-set adjunction.
A hom-set adjunction between two categories "C" and "D" consists of two functors "F" : "C" ← "D" and "G" : "C" → "D" and a natural isomorphism
This specifies a family of bijections
for all objects "X" in "C" and "Y" in "D".
In this situation we say that "F" is left adjoint to "G" and "G" is right adjoint to "F" , and may indicate this relationship by writing  formula_24 , or simply  formula_17 .
This definition is a logical compromise in that it is somewhat more difficult to satisfy than the universal morphism definitions, and has fewer immediate implications than the counit-unit definition. It is useful because of its obvious symmetry, and as a stepping-stone between the other definitions.
In order to interpret Φ as a "natural isomorphism", one must recognize hom"C"("F"–, –) and hom"D"(–, "G"–) as functors. In fact, they are both bifunctors from "D"op × "C" to Set (the category of sets). For details, see the article on hom functors. Explicitly, the naturality of Φ means that for all morphisms "f" : "X" → "X′" in "C" and all morphisms "g" : "Y′ " → "Y" in "D" the following diagram commutes:
The vertical arrows in this diagram are those induced by composition with "f" and "g". Formally, Hom("Fg", "f") : HomC("FY", "X") → HomC("FY′", "X′") is given by "h" → "f h Fg" for each "h" in HomC("FY", "X"). Hom("g", "Gf") is similar.
Adjunctions in full.
There are hence numerous functors and natural transformations associated with every adjunction, and only a small portion is sufficient to determine the rest.
An "adjunction" between categories "C" and "D" consists of
An equivalent formulation, where "X" denotes any object of "C" and "Y" denotes any object of "D":
"For every "C"-morphism "f" : "FY" → "X", there is a unique "D"-morphism Φ"Y", "X"("f") = "g" : "Y" → "GX" such that the diagrams below commute, and for every "D"-morphism "g" : "Y" → "GX", there is a unique "C"-morphism Φ−1"Y", "X"("g") = "f" : "FY" → "X" in "C" such that the diagrams below commute:"
From this assertion, one can recover that:
In particular, the equations above allow one to define Φ, ε, and η in terms of any one of the three. However, the adjoint functors "F" and "G" alone are in general not sufficient to determine the adjunction. We will demonstrate the equivalence of these situations below.
Universal morphisms induce hom-set adjunction.
Given a right adjoint functor "G" : "C" → "D"; in the sense of initial morphisms, one may construct the induced hom-set adjunction by doing the following steps.
A similar argument allows one to construct a hom-set adjunction from the terminal morphisms to a left adjoint functor. (The construction that starts with a right adjoint is slightly more common, since the right adjoint in many adjoint pairs is a trivially defined inclusion or forgetful functor.)
Counit-unit adjunction induces hom-set adjunction.
Given functors "F" : "C" ← "D", "G" : "C" → "D", and a counit-unit adjunction (ε, η) : "F" formula_28 "G", we can construct a hom-set adjunction by finding the natural transformation Φ : hom"C"("F"-,-) → hom"D"(-,"G"-) in the following steps:
Hom-set adjunction induces all of the above.
Given functors "F" : "C" ← "D", "G" : "C" → "D", and a hom-set adjunction Φ : hom"C"("F"-,-) → hom"D"(-,"G"-), we can construct a counit-unit adjunction
which defines families of initial and terminal morphisms, in the following steps:
History.
Ubiquity.
The idea of an adjoint functor was formulated by Daniel Kan in 1958. Like many of the concepts in category theory, it was suggested by the needs of homological algebra, which was at the time devoted to computations. Those faced with giving tidy, systematic presentations of the subject would have noticed relations such as
in the category of abelian groups, where "F" was the functor formula_40 (i.e. take the tensor product with "A"), and "G" was the functor hom("A",–).
The use of the "equals" sign is an abuse of notation; those two groups are not really identical but there is a way of identifying them that is "natural". It can be seen to be natural on the basis, firstly, that these are two alternative descriptions of the bilinear mappings from "X" × "A" to "Y". That is, however, something particular to the case of tensor product. In category theory the 'naturality' of the bijection is subsumed in the concept of a natural isomorphism.
The terminology comes from the Hilbert space idea of adjoint operators "T", "U" with formula_41, which is formally similar to the above relation between hom-sets. We say that "F" is "left adjoint" to "G", and "G" is "right adjoint" to "F". Note that "G" may have itself a right adjoint that is quite different from "F" (see below for an example). The analogy to adjoint maps of Hilbert spaces can be made precise in certain contexts.
If one starts looking for these adjoint pairs of functors, they turn out to be very common in abstract algebra, and elsewhere as well. The example section below provides evidence of this; furthermore, universal constructions, which may be more familiar to some, give rise to numerous adjoint pairs of functors.
In accordance with the thinking of Saunders Mac Lane, any idea such as adjoint functors that occurs widely enough in mathematics should be studied for its own sake.
Problems formulations.
Mathematicians do not generally need the full adjoint functor concept. Concepts can be judged according to their use in solving problems, as well as for their use in building theories. The tension between these two motivations was especially great during the 1950s when category theory was initially developed. Enter Alexander Grothendieck, who used category theory to take compass bearings in other work — in functional analysis, homological algebra and finally algebraic geometry.
It is probably wrong to say that he promoted the adjoint functor concept in isolation: but recognition of the role of adjunction was inherent in Grothendieck's approach. For example, one of his major achievements was the formulation of Serre duality in relative form — loosely, in a continuous family of algebraic varieties. The entire proof turned on the existence of a right adjoint to a certain functor. This is something undeniably abstract, and non-constructive, but also powerful in its own way.
Posets.
Every partially ordered set can be viewed as a category (with a single morphism between "x" and "y" if and only if "x" ≤ "y"). A pair of adjoint functors between two partially ordered sets is called a Galois connection (or, if it is contravariant, an "antitone" Galois connection). See that article for a number of examples: the case of Galois theory of course is a leading one. Any Galois connection gives rise to closure operators and to inverse order-preserving bijections between the corresponding closed elements.
As is the case for Galois groups, the real interest lies often in refining a correspondence to a duality (i.e. "antitone" order isomorphism). A treatment of Galois theory along these lines by Kaplansky was influential in the recognition of the general structure here.
The partial order case collapses the adjunction definitions quite noticeably, but can provide several themes:
Together these observations provide explanatory value all over mathematics.
Examples.
Free groups.
The construction of free groups is a common and illuminating example.
Suppose that "F" : Grp ← Set is the functor assigning to each set "Y" the free group generated by the elements of "Y", and that "G" : Grp → Set is the forgetful functor, which assigns to each group "X" its underlying set. Then "F" is left adjoint to "G":
Terminal morphisms. For each group "X", the group "FGX" is the free group generated freely by "GX", the elements of "X". Let  formula_42  be the group homomorphism which sends the generators of "FGX" to the elements of "X" they correspond to, which exists by the universal property of free groups. Then each  formula_43  is a terminal morphism from "F" to "X", because any group homomorphism from a free group "FZ" to "X" will factor through  formula_42  via a unique set map from "Z" to "GX". This means that ("F","G") is an adjoint pair.
Initial morphisms. For each set "Y", the set "GFY" is just the underlying set of the free group "FY" generated by "Y". Let  formula_45  be the set map given by "inclusion of generators". Then each  formula_46  is an initial morphism from "Y" to "G", because any set map from "Y" to the underlying set "GW" of a group will factor through  formula_45  via a unique group homomorphism from "FY" to "W". This also means that ("F","G") is an adjoint pair.
Hom-set adjunction. Maps from the free group "FY" to a group "X" correspond precisely to maps from the set "Y" to the set "GX": each homomorphism from "FY" to "X" is fully determined by its action on generators. One can verify directly that this correspondence is a natural transformation, which means it is a hom-set adjunction for the pair ("F","G").
Counit-unit adjunction. One can also verify directly that ε and η are natural. Then, a direct verification that they form a counit-unit adjunction  formula_16  is as follows:
The first counit-unit equation  formula_49  says that for each set "Y" the composition
should be the identity. The intermediate group "FGFY" is the free group generated freely by the words of the free group "FY". (Think of these words as placed in parentheses to indicate that they are independent generators.) The arrow  formula_51  is the group homomorphism from "FY" into "FGFY" sending each generator "y" of "FY" to the corresponding word of length one ("y") as a generator of "FGFY". The arrow  formula_52  is the group homomorphism from "FGFY" to "FY" sending each generator to the word of "FY" it corresponds to (so this map is "dropping parentheses"). The composition of these maps is indeed the identity on "FY".
The second counit-unit equation  formula_53  says that for each group "X" the composition
should be the identity. The intermediate set "GFGX" is just the underlying set of "FGX". The arrow  formula_55  is the "inclusion of generators" set map from the set "GX" to the set "GFGX". The arrow  formula_56  is the set map from "GFGX" to "GX" which underlies the group homomorphism sending each generator of "FGX" to the element of "X" it corresponds to ("dropping parentheses"). The composition of these maps is indeed the identity on "GX".
Free constructions and forgetful functors.
Free objects are all examples of a left adjoint to a forgetful functor which assigns to an algebraic object its underlying set. These algebraic free functors have generally the same description as in the detailed description of the free group situation above.
Diagonal functors and limits.
Products, fibred products, equalizers, and kernels are all examples of the categorical notion of a limit. Any limit functor is right adjoint to a corresponding diagonal functor (provided the category has the type of limits in question), and the counit of the adjunction provides the defining maps from the limit object (i.e. from the diagonal functor on the limit, in the functor category). Below are some specific examples.
Colimits and diagonal functors.
Coproducts, fibred coproducts, coequalizers, and cokernels are all examples of the categorical notion of a colimit. Any colimit functor is left adjoint to a corresponding diagonal functor (provided the category has the type of colimits in question), and the unit of the adjunction provides the defining maps into the colimit object. Below are some specific examples.
Properties.
Existence.
Not every functor "G" : "C" → "D" admits a left adjoint. If "C" is a complete category, then the functors with left adjoints can be characterized by the adjoint functor theorem of Peter J. Freyd: "G" has a left adjoint if and only if it is continuous and a certain smallness condition is satisfied: for every object "Y" of "D" there exists a family of morphisms
where the indices "i" come from a "set" "I", not a "proper class", such that every morphism
can be written as
for some "i" in "I" and some morphism
An analogous statement characterizes those functors with a right adjoint.
Uniqueness.
If the functor "F" : "C" ← "D" has two right adjoints "G" and "G"′, then "G" and "G"′ are naturally isomorphic. The same is true for left adjoints.
Conversely, if "F" is left adjoint to "G", and "G" is naturally isomorphic to "G"′ then "F" is also left adjoint to "G"′. More generally, if 〈"F", "G", ε, η〉 is an adjunction (with counit-unit (ε,η)) and
are natural isomorphisms then 〈"F"′, "G"′, ε′, η′〉 is an adjunction where
Here formula_130 denotes vertical composition of natural transformations, and formula_131 denotes horizontal composition.
Composition.
Adjunctions can be composed in a natural fashion. Specifically, if 〈"F", "G", ε, η〉 is an adjunction between "C" and "D" and 〈"F"′, "G"′, ε′, η′〉 is an adjunction between "D" and "E" then the functor
is left adjoint to
More precisely, there is an adjunction between "F"′ "F" and "G" "G"′ with unit and counit given by the compositions:
This new adjunction is called the composition of the two given adjunctions.
One can then form a category whose objects are all small categories and whose morphisms are adjunctions.
Limit preservation.
The most important property of adjoints is their continuity: every functor that has a left adjoint (and therefore "is" a right adjoint) is "continuous" (i.e. commutes with limits in the category theoretical sense); every functor that has a right adjoint (and therefore "is" a left adjoint) is "cocontinuous" (i.e. commutes with colimits).
Since many common constructions in mathematics are limits or colimits, this provides a wealth of information. For example:
Additivity.
If "C" and "D" are preadditive categories and "F" : "C" ← "D" is an additive functor with a right adjoint "G" : "C" → "D", then "G" is also an additive functor and the hom-set bijections
are, in fact, isomorphisms of abelian groups. Dually, if "G" is additive with a left adjoint "F", then "F" is also additive.
Moreover, if both "C" and "D" are additive categories (i.e. preadditive categories with all finite biproducts), then any pair of adjoint functors between them are automatically additive.
Relationships.
Universal constructions.
As stated earlier, an adjunction between categories "C" and "D" gives rise to a family of universal morphisms, one for each object in "C" and one for each object in "D". Conversely, if there exists a universal morphism to a functor "G" : "C" → "D" from every object of "D", then "G" has a left adjoint.
However, universal constructions are more general than adjoint functors: a universal construction is like an optimization problem; it gives rise to an adjoint pair if and only if this problem has a solution for every object of "D" (equivalently, every object of "C").
Equivalences of categories.
If a functor "F": "C"→"D" is one half of an equivalence of categories then it is the left adjoint in an adjoint equivalence of categories, i.e. an adjunction whose unit and counit are isomorphisms.
Every adjunction 〈"F", "G", ε, η〉 extends an equivalence of certain subcategories. Define "C"1 as the full subcategory of "C" consisting of those objects "X" of "C" for which ε"X" is an isomorphism, and define "D"1 as the full subcategory of "D" consisting of those objects "Y" of "D" for which η"Y" is an isomorphism. Then "F" and "G" can be restricted to "D"1 and "C"1 and yield inverse equivalences of these subcategories.
In a sense, then, adjoints are "generalized" inverses. Note however that a right inverse of "F" (i.e. a functor "G" such that "FG" is naturally isomorphic to 1"D") need not be a right (or left) adjoint of "F". Adjoints generalize "two-sided" inverses.
Monads.
Every adjunction 〈"F", "G", ε, η〉 gives rise to an associated monad 〈"T", η, μ〉 in the category "D". The functor
is given by "T" = "GF". The unit of the monad
is just the unit η of the adjunction and the multiplication transformation
is given by μ = "G"ε"F". Dually, the triple 〈"FG", ε, "F"η"G"〉 defines a comonad in "C".
Every monad arises from some adjunction—in fact, typically from many adjunctions—in the above fashion. Two constructions, called the category of Eilenberg–Moore algebras and the Kleisli category are two extremal solutions to the problem of constructing an adjunction that gives rise to a given monad.

</doc>
<doc id="53993" url="http://en.wikipedia.org/wiki?curid=53993" title="Sylow theorems">
Sylow theorems

In mathematics, specifically in the field of finite group theory, the Sylow theorems are a collection of theorems named after the Norwegian mathematician Ludwig Sylow (1872) that give detailed information about the number of subgroups of fixed order that a given finite group contains. The Sylow theorems form a fundamental part of finite group theory and have very important applications in the classification of finite simple groups.
For a prime number "p", a Sylow "p"-subgroup (sometimes "p"-Sylow subgroup) of a group "G" is a maximal "p"-subgroup of "G", i.e., a subgroup of "G" that is a "p"-group (so that the order of any group element is a power of "p"), and that is not a proper subgroup of any other "p"-subgroup of "G". The set of all Sylow "p"-subgroups for a given prime "p" is sometimes written Syl"p"("G").
The Sylow theorems assert a partial converse to Lagrange's theorem. While Lagrange's theorem states that for any finite group "G" the order (number of elements) of every subgroup of "G" divides the order of "G", the Sylow theorems state that for any prime factor "p" of the order of a finite group "G", there exists a Sylow "p"-subgroup of "G". The order of a Sylow "p"-subgroup of a finite group "G" is "pn", where "n" is the multiplicity of "p" in the order of "G", and any subgroup of order "pn" is a Sylow "p"-subgroup of "G". The Sylow "p"-subgroups of a group (for a given prime "p") are conjugate to each other. The number of Sylow "p"-subgroups of a group for a given prime "p" is congruent to 1 mod "p".
Theorems.
Collections of subgroups that are each maximal in one sense or another are common in group theory. The surprising result here is that in the case of Syl"p"("G"), all members are actually isomorphic to each other and have the largest possible order: if |"G"| = "pnm" with "n" > 0 where "p" does not divide "m", then any Sylow "p"-subgroup "P" has order |"P"| = "pn". That is, "P" is a "p"-group and gcd(|"G" : "P"|, "p") = 1. These properties can be exploited to further analyze the structure of "G".
The following theorems were first proposed and proven by Ludwig Sylow in 1872, and published in "Mathematische Annalen".
Theorem 1: For any prime factor "p" with multiplicity "n" of the order of a finite group "G", there exists a Sylow "p"-subgroup of "G", of order "pn".
The following weaker version of theorem 1 was first proved by Cauchy, and is known as Cauchy's theorem.
Corollary: Given a finite group "G" and a prime number "p" dividing the order of "G", then there exists an element (and hence a subgroup) of order "p" in "G".
Theorem 2: Given a finite group "G" and a prime number "p", all Sylow "p"-subgroups of "G" are conjugate to each other, i.e. if "H" and "K" are Sylow "p"-subgroups of "G", then there exists an element "g" in "G" with "g"−1"Hg" = "K".
Theorem 3: Let "p" be a prime factor with multiplicity "n" of the order of a finite group "G", so that the order of "G" can be written as "pnm", where "n" > 0 and "p" does not divide "m". Let "np" be the number of Sylow "p"-subgroups of "G". Then the following hold:
Consequences.
The Sylow theorems imply that for a prime number "p" every Sylow "p"-subgroup is of the same order, "pn". Conversely, if a subgroup has order "pn", then it is a Sylow "p"-subgroup, and so is isomorphic to every other Sylow "p"-subgroup. Due to the maximality condition, if "H" is any "p"-subgroup of "G", then "H" is a subgroup of a "p"-subgroup of order "pn".
A very important consequence of Theorem 3 is that the condition "np" = 1 is equivalent to saying that the Sylow "p"-subgroup of "G" is a normal subgroup
(there are groups that have normal subgroups but no normal Sylow subgroups, such as "S"4).
Sylow theorems for infinite groups.
There is an analogue of the Sylow theorems for infinite groups. We define a Sylow "p"-subgroup in an infinite group to be a "p"-subgroup (that is, every element in it has "p"-power order) that is maximal for inclusion among all "p"-subgroups in the group. Such subgroups exist by Zorn's lemma.
Theorem: If "K" is a Sylow "p"-subgroup of "G", and "np" = |Cl("K")| is finite, then every Sylow "p"-subgroup is conjugate to "K", and "np" ≡ 1 mod "p", where Cl("K") denotes the conjugacy class of "K".
Examples.
A simple illustration of Sylow subgroups and the Sylow theorems are the dihedral group of the "n"-gon, "D"2"n". For "n" odd, 2 = 21 is the highest power of 2 dividing the order, and thus subgroups of order 2 are Sylow subgroups. These are the groups generated by a reflection, of which there are "n," and they are all conjugate under rotations; geometrically the axes of symmetry pass through a vertex and a side. 
By contrast, if "n" is even, then 4 divides the order of the group, and the subgroups of order 2 are no longer Sylow subgroups, and in fact they fall into two conjugacy classes, geometrically according to whether they pass through two vertices or two faces. These are related by an outer automorphism, which can be represented by rotation through π/"n", half the minimal rotation in the dihedral group.
Example applications.
Since Sylow's theorem ensures the existence of p-subgroups of a finite group, its worthwhile to study groups of prime power order more closely. Most of the examples use Sylow's theorem to prove that a group of a particular order is not simple. For groups of small order, the congruence condition of Sylow's theorem is often sufficient to force the existence of a normal subgroup. 
Example-1: Groups of order pq, p and q primes with p<q. 
Example-2: Group of order 30, groups of order 20, groups of order p2q, p and q distinct primes are some of the applications. 
Example-3: (Groups of order 60): If o(G)=60 and G has more than one Sylow 5-subgroups, then G is simple.
Cyclic group orders.
Some numbers "n" are such that every group of order "n" is cyclic. One can show that "n" = 15 is such a number using the Sylow theorems: Let "G" be a group of order 15 = 3 · 5 and "n"3 be the number of Sylow 3-subgroups. Then "n"3 | 5 and "n"3 ≡ 1 (mod 3). The only value satisfying these constraints is 1; therefore, there is only one subgroup of order 3, and it must be normal (since it has no distinct conjugates). Similarly, "n"5 must divide 3, and "n"5 must equal 1 (mod 5); thus it must also have a single normal subgroup of order 5. Since 3 and 5 are coprime, the intersection of these two subgroups is trivial, and so "G" must be the internal direct product of groups of order "3" and "5", that is the cyclic group of order 15. Thus, there is only one group of order 15 (up to isomorphism).
Small groups are not simple.
A more complex example involves the order of the smallest simple group that is not cyclic. Burnside's "pa qb" theorem states that if the order of a group is the product of one or two prime powers, then it is solvable, and so the group is not simple, or is of prime order and is cyclic. This rules out every group up to order 30 .
If "G" is simple, and |"G"| = 30, then "n"3 must divide 10 ( = 2 · 5), and "n"3 must equal 1 (mod 3). Therefore "n"3 = 10, since neither 4 nor 7 divides 10, and if "n"3 = 1 then, as above, "G" would have a normal subgroup of order 3, and could not be simple. "G" then has 10 distinct cyclic subgroups of order 3, each of which has 2 elements of order 3 (plus the identity). This means "G" has at least 20 distinct elements of order 3. 
As well, "n"5 = 6, since "n"5 must divide 6 ( = 2 · 3), and "n"5 must equal 1 (mod 5). So "G" also has 24 distinct elements of order 5. But the order of "G" is only 30, so a simple group of order 30 cannot exist.
Next, suppose |"G"| = 42 = 2 · 3 · 7. Here "n"7 must divide 6 ( = 2 · 3) and "n"7 must equal 1 (mod 7), so "n"7 = 1. So, as before, "G" can not be simple.
On the other hand for |"G"| = 60 = 22 · 3 · 5, then "n"3 = 10 and "n"5 = 6 is perfectly possible. And in fact, the smallest simple non-cyclic group is A5, the alternating group over 5 elements. It has order 60, and has 24 cyclic permutations of order 5, and 20 of order 3.
Wilson's theorem.
Part of Wilson's theorem states that
for every prime "p". One may easily prove this theorem by Sylow's third theorem. Indeed, 
observe that the number "np" of Sylow's "p"-subgroups 
in the symmetric group "Sp" is (p-2)!. On the other hand, 
np ≡ 1 mod p. Hence, (p-2)! ≡ 1 mod p. So, (p-1)! ≡ -1 mod p.
Fusion results.
Frattini's argument shows that a Sylow subgroup of a normal subgroup provides a factorization of a finite group. A slight generalization known as Burnside's fusion theorem states that if "G" is a finite group with Sylow "p"-subgroup "P" and two subsets "A" and "B" normalized by "P", then "A" and "B" are "G"-conjugate if and only if they are "NG"("P")-conjugate. The proof is a simple application of Sylow's theorem: If "B"="Ag", then the normalizer of "B" contains not only "P" but also "Pg" (since "Pg" is contained in the normalizer of "Ag"). By Sylow's theorem "P" and "Pg" are conjugate not only in "G", but in the normalizer of "B". Hence "gh"−1 normalizes "P" for some "h" that normalizes "B", and then "A""gh"−1 = "B"h−1 = "B", so that "A" and "B" are "NG"("P")-conjugate. Burnside's fusion theorem can be used to give a more powerful factorization called a semidirect product: if "G" is a finite group whose Sylow "p"-subgroup "P" is contained in the center of its normalizer, then "G" has a normal subgroup "K" of order coprime to "P", "G" = "PK" and "P"∩"K" = 1, that is, "G" is "p"-nilpotent.
Less trivial applications of the Sylow theorems include the focal subgroup theorem, which studies the control a Sylow "p"-subgroup of the derived subgroup has on the structure of the entire group. This control is exploited at several stages of the classification of finite simple groups, and for instance defines the case divisions used in the Alperin–Brauer–Gorenstein theorem classifying finite simple groups whose Sylow 2-subgroup is a quasi-dihedral group. These rely on J. L. Alperin's strengthening of the conjugacy portion of Sylow's theorem to control what sorts of elements are used in the conjugation.
Proof of the Sylow theorems.
The Sylow theorems have been proved in a number of ways, and the history of the proofs themselves are the subject of many papers including , , , , and to some extent .
One proof of the Sylow theorems exploits the notion of group action in various creative ways. The group "G" acts on itself or on the set of its "p"-subgroups in various ways, and each such action can be exploited to prove one of the Sylow theorems. The following proofs are based on combinatorial arguments of . In the following, we use "a" | "b" as notation for "a divides b" and "a" formula_2 "b" for the negation of this statement.
 Theorem 1: A finite group "G" whose order |"G"| is divisible by a prime power "pk" has a subgroup of order "pk".
Proof: Let |"G"| = "pkm = pk+ru" such that "p" does not divide "u", and let Ω denote the set of subsets of "G" of size "pk". "G" acts on Ω by left multiplication. The orbits "G"ω = {"g"ω | "g" ∈ "G"} of the ω ∈ Ω are the equivalence classes under the action of "G".
For any ω ∈ Ω consider its stabilizer subgroup "G"ω = {"g" ∈ "G" | "g"ω = ω}. For any fixed element α ∈ ω the function ["g" ↦ "g"α] maps "G"ω to ω injectively: for any two "g", "h" ∈ "G"ω we have that "g"α = "h"α implies "g" = "h", because α ∈ ω ⊆ "G" means that one may cancel on the right. Therefore " pk" = |ω| ≥ |"G"ω|.
On the other hand
and no power of "p" remains in any of the factors inside the product on the right. Hence "νp"(|Ω|) = "νp"("m") = "r".
Let "R" ⊆ Ω be a complete representation of all the equivalence classes under the action of "G". Then,
Thus, there exists an element ω ∈ "R" such that "s" := "νp"(|"G"ω|) ≤ "νp"(|Ω|) = "r". Hence |"G"ω| = "psv" where "p" does not divide "v". By the stabilizer-orbit-theorem we have |"G"ω| = |"G"| / |"G"ω| = "pk+r-su/v". Therefore "pk" | |"G"ω|, so "pk" ≤ |"G"ω| and "G"ω" is the desired subgroup.
 Lemma: Let "G" be a finite "p"-group, let "G" act on a finite set Ω, and let Ω0 denote the set of points of Ω that are fixed under the action of "G". Then |Ω| ≡ |Ω0| mod "p". 
Proof: Write Ω as a disjoint sum of its orbits under "G". Any element "x" ∈ Ω not fixed by "G" will lie in an orbit of order |"G"|/|"Gx"| (where "Gx" denotes the stabilizer), which is a multiple of "p" by assumption. The result follows immediately.
Theorem 2: If "H" is a "p"-subgroup of "G" and "P" is a Sylow "p"-subgroup of "G", then there exists an element "g" in "G" such that "g"−1"Hg" ≤ "P". In particular, all Sylow "p"-subgroups of "G" are conjugate to each other (and therefore isomorphic), i.e. if "H" and "K" are Sylow "p"-subgroups of "G", then there exists an element "g" in "G" with "g"−1"Hg" = "K".
Proof: Let Ω be the set of left cosets of "P" in "G" and let "H" act on Ω by left multiplication. Applying the Lemma to "H" on Ω, we see that |Ω0| ≡ |Ω| = ["G" : "P"] mod "p". Now "p" formula_2 ["G" : "P"] by definition so "p" formula_2 |Ω0|, hence in particular |Ω0| ≠ 0 so there exists some "gP" ∈ Ω0. It follows that for some "g" ∈ "G" and ∀ "h" ∈ "H" we have "hgP" = "gP" so "g"−1"HgP" = "P" and therefore "g"−1"Hg" ≤ "P". Now if "H" is a Sylow "p"-subgroup, |"H"| = |"P"| = |"gPg"−1| so that "H" = "gPg"−1 for some "g" ∈ "G".
Theorem 3: Let "q" denote the order of any Sylow "p"-subgroup of a finite group "G". Then "np" | |"G"|/"q" and "np" ≡ 1 mod "p".
Proof: By Theorem 2, "np" = ["G" : "NG"("P")], where "P" is any such subgroup, and "NG"("P") denotes the normalizer of "P" in "G", so this number is a divisor of |"G"|/"q". Let Ω be the set of all Sylow "p"-subgroups of "G", and let "P" act on Ω by conjugation. Let "Q" ∈ Ω0 and observe that then "Q" = "xQx"−1 for all "x" ∈ "P" so that "P" ≤ "NG"("Q"). By Theorem 2, "P" and "Q" are conjugate in "NG"("Q") in particular, and "Q" is normal in "NG"("Q"), so then "P" = "Q". It follows that Ω0 = {"P"} so that, by the Lemma, |Ω| ≡ |Ω0| = 1 mod "p".
Algorithms.
The problem of finding a Sylow subgroup of a given group is an important problem in computational group theory.
One proof of the existence of Sylow "p"-subgroups is constructive: if "H" is a "p"-subgroup of "G" and the index ["G":"H"] is divisible by "p", then the normalizer "N" = "NG"("H") of "H" in "G" is also such that ["N" : "H"] is divisible by "p". In other words, a polycyclic generating system of a Sylow "p"-subgroup can be found by starting from any "p"-subgroup "H" (including the identity) and taking elements of "p"-power order contained in the normalizer of "H" but not in "H" itself. The algorithmic version of this (and many improvements) is described in textbook form in , including the algorithm described in . These versions are still used in the GAP computer algebra system.
In permutation groups, it has been proven in (Kantor 1985a, 1985b, 1990; ) that a Sylow "p"-subgroup and its normalizer can be found in polynomial time of the input (the degree of the group times the number of generators). These algorithms are described in textbook form in , and are now becoming practical as the constructive recognition of finite simple groups becomes a reality. In particular, versions of this algorithm are used in the Magma computer algebra system.

</doc>
<doc id="54000" url="http://en.wikipedia.org/wiki?curid=54000" title="Biophysics">
Biophysics

Biophysics is an interdisciplinary science using methods of, and theories from, physics to study biological systems. Biophysics spans all scales of biological organization, from the molecular scale to whole organisms and ecosystems. Biophysical research shares significant overlap with biochemistry, nanotechnology, bioengineering, computational biology and (complex) systems biology. It has been suggested as a bridge between biology and physics.
The term "biophysics" was originally introduced by Karl Pearson in 1892.
Overview.
Molecular biophysics typically addresses biological questions similar to those in biochemistry and molecular biology, but more quantitatively. Scientists in this field conduct research concerned with understanding the interactions between the various systems of a cell, including the interactions between DNA, RNA and protein biosynthesis, as well as how these interactions are regulated. A great variety of techniques are used to answer these questions.
Fluorescent imaging techniques, as well as electron microscopy, x-ray crystallography, NMR spectroscopy, atomic force microscopy (AFM) and small-angle scattering (SAS) both with X-rays and neutrons (SAXS/SANS) are often used to visualize structures of biological significance. Protein dynamics can be observed by neutron spin echo spectroscopy. Conformational change in structure can be measured using techniques such as dual polarisation interferometry, circular dichroism, SAXS and SANS. Direct manipulation of molecules using optical tweezers or AFM, can also be used to monitor biological events where forces and distances are at the nanoscale. Molecular biophysicists often consider complex biological events as systems of interacting entities which can be understood e.g. through statistical mechanics, thermodynamics and chemical kinetics. By drawing knowledge and experimental techniques from a wide variety of disciplines, biophysicists are often able to directly observe, model or even manipulate the structures and interactions of individual molecules or complexes of molecules.
In addition to traditional (i.e. molecular and cellular) biophysical topics like structural biology or enzyme kinetics, modern biophysics encompasses an extraordinarily broad range of research, from bioelectronics to quantum biology involving both experimental and theoretical tools. It is becoming increasingly common for biophysicists to apply the models and experimental techniques derived from physics, as well as mathematics and statistics (see biomathematics), to larger systems such as tissues, organs, populations and ecosystems. Biophysical models are used extensively in the study of electrical conduction in single neurons, as well as neural circuit analysis in both tissue and whole brain.
History.
Some of the earlier studies in biophysics were conducted in the 1840s by a group known as the Berlin school of physiologists. Among its members 
were pioneers such as Hermann von Helmholtz, Ernst Heinrich Weber, Carl F. W. Ludwig, and Johannes Peter Müller. Biophysics might even be seen as dating back to the studies of Luigi Galvani.
The popularity of the field rose when the book “What is life?” by Erwin Schrödinger was published. Since 1957 biophysicists have organized themselves into the Biophysical Society which now has about 7,000 members over the world.
Focus as a subfield.
Generally, biophysics does not have university-level departments of its own, but has presence as groups across departments within the fields of molecular biology, biochemistry, chemistry, computer science, mathematics, medicine, pharmacology, physiology, physics, and neuroscience. What follows is a list of examples of how each department applies its efforts toward the study of biophysics. This list is hardly all inclusive. Nor does each subject of study belong exclusively to any particular department. Each academic institution makes its own rules and there is much overlap between departments.
decohered isomers to yield time-dependent base substitutions. These studies imply applications in quantum computing.
Many biophysical techniques are unique to this field. Research efforts in biophysics are often initiated by scientists who were traditional physicists, chemists, and biologists by training.
Notes.
</dl>

</doc>
<doc id="54001" url="http://en.wikipedia.org/wiki?curid=54001" title="Comanche">
Comanche

The Comanche (Comanche: "Nʉmʉnʉʉ") are a Plains Indian tribe whose historic territory, known as Comancheria, consisted of present day eastern New Mexico, southeastern Colorado, southwestern Kansas, western Oklahoma, and most of northwest Texas. The Comanche people are federally recognized as the Comanche Nation, headquartered in Lawton, Oklahoma.
Post-contact, the Comanches were hunter-gatherers with a horse culture. There may have been as many as 45,000 Comanches in the late 18th century. They were the dominant tribe on the Southern Plains and often took captives from weaker tribes during warfare, selling them as slaves to the Spanish and later Mexican settlers. They also took thousands of captives from the Spanish, Mexican, and American settlers.
Today, the Comanche Nation has 15,191 members, approximately 7,763 of whom reside in tribal jurisdictional area around the Lawton, Fort Sill, and surrounding areas of southwest Oklahoma. The Comanche Nation Homecoming Powwow is held annually in Walters, Oklahoma in mid-July.
The Comanche language is a Numic language of the Uto-Aztecan family, sometimes classified as a Shoshone dialect. Only about 1% of Comanches speak their language today.
The name "Comanche" is from the Ute name for them, "kɨmantsi" (enemy).
Government.
The Comanche Nation is headquartered in Lawton, Oklahoma. Their tribal jurisdictional area is located in Caddo, Comanche, Cotton, Grady, Jefferson, Kiowa, Stephens, and Tillman Counties. Membership of the tribe requires a 1/8 blood quantum (equivalent to one great-grandparent).
As of June 1, 2012, Wallace Coffey is the Tribal Chairman, and Robert Komahcheet, Tribal Administrator. CBC members recalled in April 2012 have been reinstated per an emergency interim order by Judge Phil Lujan, CFR Court of Indian Offenses. Ed Eschiti, Vice Chairman; Robert Tippeconnie, Secretary/Treasurer; Ron Red Elk, Seat No. 1; Yonevea Terry, Seat No. 2; and Darrell Kosechequetah. Seats No. 3 and No. 4 were vacant pending outcome of the Primary Election and Run Off slated for June 30, 2012.
Economic development.
The tribe operates its own housing authority and issues tribal vehicle tags. They have their own Department of Higher Education, primarily awarding scholarships and financial aid for members' college educations. Additionally, they operate the Comanche Nation College in Lawton, Oklahoma. They own ten tribal smoke shops and four casinos. The casinos are Comanche Nation Games in Lawton; Comanche Red River Casino in Devol; Comanche Spur Casino, in Elgin; and Comanche Star Casino in Walters, Oklahoma.
Cultural institutions.
In 2002, the tribe founded the Comanche Nation College, a two-year tribal college in Lawton.
Each July Comanches from across the United States gather to celebrate their heritage and culture in Walters, Oklahoma at the annual Comanche Homecoming powwow. The Comanche Nation Fair is held every September. The Comanche Little Ponies host two annual dances—one over New Year's and one in May.
History.
Formation.
The Comanche emerged as a distinct group shortly before 1700, when they broke off from the Shoshone people living along the upper Platte River in Wyoming. In 1680, the Comanche acquired horses from the Pueblo Indians after the Pueblo Revolt. They separated from the Shoshone after this, as the horses allowed them greater mobility in their search for better hunting grounds.
The horse was a key element in the emergence of a distinctive Comanche culture. It was of such strategic importance that some scholars suggested that the Comanche broke away from the Shoshone and moved southward to search for additional sources of horses among the settlers of New Spain to the south (rather than search for new herds of buffalo.) The Comanche may have been the first group of Plains natives to fully incorporate the horse into their culture and to have introduced the animal to the other Plains peoples.
Their original migration took them to the southern Great Plains, into a sweep of territory extending from the Arkansas River to central Texas. They reached present-day New Mexico and the Texas Panhandle by 1700, forcing the Lipan Apache people ever southward, defeating them in a nine-day battle along the Rio del Fierro (Wichita River) in 1723. The River of Iron may be the location written about by Athanase De Mezieres in 1772, containing "a mass of metal which the Indians say is hard, thick, heavy, and composed of iron", which they "venerate...as an extraordinary manifestation of nature", the Comanche's calling it "Ta-pic-ta-carre" [standing rock], "Po-i-wisht-carre" [standing metal], or "Po-a-cat-le-pi-le-carre" [medicine rock], the general area containing a "large number of meteoric masses". By 1777, the Lipan Apache had retreated to the Rio Grande and the Mescalero Apache to Coahuila.
During that time, their population increased dramatically because of the abundance of buffalo, an influx of Shoshone migrants, and their adoption of significant numbers of women and children taken captive from rival groups. The Comanche never formed a single cohesive tribal unit, but were divided into almost a dozen autonomous groups, called bands. These groups shared the same language and culture, and rarely fought each other. They were estimated to have taken captive thousands of people from the Spanish, Mexican and American settlers in their lands. Curtis Marez suggests that this contributed to the development of "mestizaje" in the borderlands, as the descendants of such captives were mixed-race.
By the mid-19th century, the Comanche were supplying horses to French and American traders and settlers, and later to migrants passing through their territory on the way to the California Gold Rush, along the California Road. The Comanche had stolen many of the horses from other tribes and settlers; they earned their reputation as formidable horse thieves, later extending their rustling to cattle. Their stealing of livestock from Spanish and American settlers, as well as the other Plains tribes, often led to war.
The Comanche also had access to vast numbers of feral horses, which numbered approximately 2,000,000 in and around Comancheria, and which the tribe was particularly skilled at breaking to saddle. In the late 18th and early 19th centuries, the Comanche lifestyle required about one horse per person (though warriors each possessed many more). With a population of about 30,000 to 40,000 and in possession of herds many times that number, the Comanche had a surplus of about 90,000 to 120,000 horses.
They were formidable opponents who developed strategies for using traditional weapons for fighting on horseback. Warfare was a major part of Comanche life. Comanche raids into Mexico traditionally took place during the full moon, when the Comanche could see to ride at night. This led to the term "Comanche Moon", during which the Comanche raided for horses, captives, and weapons. The majority of Comanche raids into Mexico were in the state of Chihuahua and neighboring northern states. 
Divisions.
In Comanche society there were four levels of social-political integration:
As an example of such political and kinship-based division, the "Yaparʉhka" identified as a separate division. Because of cultural and linguistic differences from other Comanche bands, they became the “(Yap)Root-Eaters”, in contrast to the "Kʉhtsʉtʉhka" (“Buffalo-Eaters”). The Yaparʉhka division was composed of several residential local groups, such as the "Ketahtoh Tʉ", "Motso Tʉ" and "Pibianigwai".
In contrast to the neighboring Cheyenne and Arapaho to the north, the Comanche never developed a political idea of forming a nation or tribe. The Comanche recognized each other as Nʉmʉnʉ and bands seldom fought against each other; but the "Kwaarʉ Nʉʉ" pursued policies against the Spanish and Indian settlements in New Mexico independently of the "Kʉhtsʉtʉhka". As a consequence, at the time when Comanche society was breaking down, the once respected and feared "Penatʉka Nʉʉ" provided U.S. Army Indian Scouts for the Americans and Texans against their still fighting and free-roaming Comanche kin.
The band was the primary social unit of the Comanche. A typical band might number about one hundred people. Bands were part of larger divisions, or tribes. Before the 1750s, there were three Comanche divisions: "Yamparikas", "Jupes", and "Kotsotekas". In the 1750s and 1760s, a number of Kotsoteka bands split off and moved to the southeast. This resulted in a large division between the original group, the western Comanches, and the break-away Kotsotekas, the eastern Comanches. The western Comanche lived in the region of the upper Arkansas, Canadian, and Red rivers, and the Llano Estacado. The eastern Comanches lived on the Edwards Plateau and the Texas plains of the upper Brazos and Colorado rivers, and east to the Cross Timbers.
Over time, these divisions were altered in various ways. In the early 19th century, the Jupes vanished from history, probably merging into the other divisions. Many Yamparikas moved southeast, joining the eastern Comanche and becoming known as the "Tenewa". Many Kiowa and Plains Apache (or "Naishan") moved to northern Comancheria and became closely associated with the Yamparika. A group of Arapaho, known as the "Charitica", moved into Comancheria and joined Comanche society. New divisions arose, such as the "Nokonis", closely linked with the Tenewa; and the "Kwahadi", who emerged as a new faction on the southern "Llano Estacado". The western-eastern distinction changed in the 19th century. Observers began to call them Northern, Middle and Southern Comanche.
One of the largest groups, as well as the southernmost, lived on the edge of the Edwards Plateau and east across to the Cross Timbers, and became known as the "Penateka", ("Penatʉka Nʉʉ") "Southern Comanches".
In the eastern part of the Comancheria, between the Colorado and Red rivers, roamed the "Nokoni" ("Nokoni Nʉʉ" — ‘Movers’, ‘Returners’). South of them were the strong, associated smaller bands or residential groups of the "Tenawa" ("Tahnahwah" or "Tenahwit" — ‘Those Who Live Downstream’) and "Tanima" ("Tanimʉʉ", "Dahaʉi" or "Tevawish" — ‘Liver-Eaters’). Together, the Nokoni, Tenawa and Tanima were called the "Middle Comanche". Just north of the Nokonis in the Red River Valley, between the Red and Canadian rivers, lived the numerous residential local groups of the powerful "Kotsotekas" ("Kʉhtsʉtʉʉka" — ‘Buffalo-Eaters’); they took their name from the large buffalo herds that were always in their territory.
The northernmost Comanche band was the "Yamparikas" ("Yaparʉhka" or "Yapai Nʉʉ" — ‘(Yap)Root-Eaters’). As the last band to move onto the Plains, they retained much of their Shoshone tradition. Because the Kotsoteka and Yamparika lived in the northern part of the Comancheria, they were called the "Northern Comanche". The last large group was known as "Kwahadis" ("Quohada" or "Kwaarʉ Nʉʉ/Kwahare" — ‘Antelope-Eaters’), originally "Kotsoteka"-residential local groups that moved south out of the Cimarron Valley onto the desert plains of the Llano Estacado. They emerged as a new division in the 19th century. Even though the western-eastern distinction had changed in the 19th century, these people were classified as "Western Comanche" because of their relative isolation on the westernmost edge of the Comancheria.
All these division names were spelled in many different ways by Spanish and English writers, and spelling differences continue today. Large-scale groupings became unstable and unclear during the 19th century. The Comanche society was slowly overwhelmed and ultimately subjugated to the United States.
Various bands of the Comanche (Nʉmʉnʉ).
Naming practices of the Comanche were flexible, so some of these names are probably synonyms of others on the list. Joking and insulting synonyms were also commonly found in use among rival or allied bands.
In addition, there are several smaller bands:
Relationship with settlers.
The Comanche maintained an ambiguous relationship with Europeans and later settlers attempting to colonize their territory. The Comanche were valued as trading partners since 1786 via the Comancheros out of New Mexico, but were feared for their raids against settlers in Texas. and similarly, they were, at one time or another, at war with virtually every other Native American group living on the South Plains leaving opportunities for political maneuvering by European colonial powers and the United States. At one point, Sam Houston, president of the newly created Republic of Texas, almost succeeded in reaching a peace treaty with the Comanche in the 1844 Treaty of Tehuacana Creek. His efforts were thwarted in 1845 when the Texas legislature refused to create an official boundary between Texas and the "Comancheria."
While the Comanche managed to maintain their independence and increase their territory, by the mid-19th century they faced annihilation because of a wave of epidemics due to Eurasian diseases to which they had no immunity, such as smallpox and measles. Outbreaks of smallpox (1817, 1848) and cholera (1849) took a major toll on the Comanche, whose population dropped from an estimated 20,000 in mid-century to just a few thousand by the 1870s.
The US began efforts in the late 1860s to move the Comanche into reservations, with the Treaty of Medicine Lodge (1867), which offered churches, schools, and annuities in return for a vast tract of land totaling over 60,000 sqmi. The government promised to stop the buffalo hunters, who were decimating the great herds of the Plains, provided that the Comanche, along with the Apaches, Kiowas, Cheyenne, and Arapahos, move to a reservation totaling less than 5,000 sqmi of land. However, the government did not prevent the slaughtering of the herds. The Comanche under "Isa-tai" (Coyote's Vagina) retaliated by attacking a group of hunters in the Texas Panhandle in the Second Battle of Adobe Walls (1874). The attack was a disaster for the Comanche, and the US army was called in during the Red River War to drive the remaining Comanche in the area into the reservation, culminating in the Battle of Palo Duro Canyon. Within just ten years, the buffalo were on the verge of extinction, effectively ending the Comanche way of life as hunters. In 1875, the last free band of Comanches, led by the Quahada warrior Quanah Parker, surrendered and moved to the Fort Sill reservation in Oklahoma. The last independent Kiowa and Kiowa Apache had also surrendered.
Unhappy with life on the reservation, 170 warriors and their families, led by Black Horse, left the reservation in late 1876 for the Llano Estacado. Attacks on buffalo hunters' camps led to the Buffalo Hunters' War of 1877.
Some of the Lipan Apache and Mescalero Apache bands with some Comanche in their company held out in northern Mexico until the early 1880s, when Mexican and U.S. Army forces drove them onto reservations or into extinction.
The 1890 Census showed 1,598 Comanche at the Fort Sill reservation, which they shared with 1,140 Kiowa and 326 Kiowa Apache.
Cherokee Commission.
The signed with the Cherokee Commission October 6–21, 1892, further reduced their reservation to 480,000 acre at a cost of $1.25 per acre ($308.88/km²), with an allotment of 160 acre per person per tribe to be held in trust. New allotments were made in 1906 to all children born after the agreement, and the remaining land was opened to white settlement. With this new arrangement, the era of the Comanche reservation came to an abrupt end.
Meusebach–Comanche treaty.
The Peneteka band agreed to a peace treaty with the German Immigration Company under John O. Meusebach. This treaty was not affiliated with any level of government. Meusebach brokered the treaty in order to settle the lands on the Fisher-Miller Land Grant, from which were formed the ten counties of Concho, Kimble, Llano, Mason, McCulloch, Menard, Schleicher, San Saba, Sutton and Tom Green. In contrast to many treaties of its day, this treaty was very brief and simple, with all parties agreeing to a mutual cooperation and a sharing of the land. The treaty was agreed to at a meeting in San Saba County, Texas, and signed by all parties on May 9, 1847 in Fredericksburg, Texas. The treaty was never broken. A popular and misleading myth is that the treaty "is unbroken to this day". The treaty was very specifically between the Peneteka band and the German Immigration Company. No other band or tribe was involved. The German Immigration Company was dissolved by Meusebach himself shortly after it had served its purpose. By 1875, the Comanches had been relocated to reservations. Five years later, artist Friedrich Richard Petri and his family moved to the settlement of Pedernales, near Fredericksburg. Petri's sketches and watercolors gave witness to the friendly relationships between the Germans and various local Native American tribes.
Fort Martin Scott treaty.
In 1850, another treaty was signed in San Saba, between the United States government and a number of local tribes, among which were the Comanches. This treaty was named for the nearest military fort, which was Fort Martin Scott. The treaty was never officially ratified by any level of government and was binding only on the part of the Native Americans.
Captive Herman Lehmann.
One of the most famous captives in Texas was a German lad named Herman Lehmann. He had been kidnapped by the Apaches, only to escape and be rescued by the Comanches. Lehmann became the adoptive son of Quanah Parker. On August 26, 1901, Quanah Parker provided a legal affidavit verifying Lehman's life as his adopted son 1877–1878. On May 29, 1908, the United States Congress authorized the United States Secretary of the Interior to allot Lehmann, as an adopted member of the Comanche nation, one hundred and sixty acres of Oklahoma land, near Grandfield.
Recent history.
Entering the Western economy was a challenge for the Comanche in the late 19th and early 20th centuries. Many tribal members were defrauded of whatever remained of their land and possessions. Appointed paramount chief by the United States government, Chief Quanah Parker campaigned vigorously for better deals for his people, meeting with Washington politicians frequently; and helped manage land for the tribe. Parker became wealthy as a cattleman. Parker also campaigned for the Comanches' permission to practice the Native American Church religious rites, such as the usage of peyote, which was condemned by European Americans.
Before the first Oklahoma legislature, Quanah testified:
"I do not think this legislature should interfere with a man's religion, also these people should be allowed to retain this health restorer. These healthy gentleman before you use peoti and those that do not use it are not so healthy." ["sic"]
During World War II, many Comanche left the traditional tribal lands in Oklahoma to seek jobs and more opportunities in the cities of California and the Southwest. About half of the Comanche population still lives in Oklahoma, centered around the town of Lawton.
Recently, an 80-minute 1920 silent film was "rediscovered", titled "The Daughter of Dawn." It features a cast of more than 300 Comanche and Kiowa.
Culture.
Social order.
Comanche groups did not have a single acknowledged leader. Instead, a small number of generally recognized leaders acted as counsel and advisors to the group as a whole. These included the "peace chief", the members of the council, and the "war chief". The peace chief was usually an older individual, who could bring his experience to the task of advising. There was no formal inauguration or election to the position, it was one of general consensus. The council made decisions about where the band should hunt, whether they should war against their enemies, and whether to ally themselves with other bands. Any member could speak at council meetings, but the older men usually did most of the talking. In times of war, the band selected a war chief. To be chosen for this position, a man had to prove he was a brave fighter. He also had to have the respect of all the other warriors in the band. While the band was at war, the war chief was in charge, and all the warriors had to obey him. After the conflict was over, however, the war chief's authority ended. The Comanche men did most of the hunting and all of the fighting in the wars. They learned how to ride horses when they were young and were eager to prove themselves in battle. On the plains, Comanche women carried out the demanding tasks of cooking, skinning animals, setting up camp, rearing children, and transporting household goods.
Childbirth.
If a woman started labor while the band was on the move, she simply paused along the trail and gave birth to her child. After a few hours of rest, she would take the baby and catch up with the group.
If a woman went into labor while the band was in camp, she was moved to a tipi, or a brush lodge if it was summer. One or more of the older women assisted as midwives. Men were not allowed inside the tipi during or immediately after the delivery.
First, the midwives softened the earthen floor of the tipi and dug two holes. One of the holes was for heating water and the other for the afterbirth. One or two stakes were driven into the ground near the expectant mother's bedding for her to grip during the pain of labor. After the birth, the midwives hung the umbilical cord on a hackberry tree. The people believed that if the umbilical cord was not disturbed before it rotted, the baby would live a long and prosperous life.
The newborn was swaddled and remained with its mother in the tipi for a few days. The baby was placed in a cradleboard, and the mother went back to work. She could easily carry the cradleboard on her back, or prop it against a tree where the baby could watch her while she collected seeds or roots. Cradleboards consisted of a flat board to which a basket was attached. The latter was made from rawhide straps, or a leather sheath that laced up the front. With soft, dry moss as a diaper, the young one was safely tucked into the leather pocket. During cold weather, the baby was wrapped in blankets, and then placed in the cradleboard. The baby remained in the cradleboard for about ten months; then it was allowed to crawl around.
Both girls and boys were welcomed into the band, but boys were favored. If the baby was a boy, one of the midwives informed the father or grandfather, "It's your close friend". Families might paint a flap on the tipi to tell the rest of the tribe that they had been strengthened with another warrior. Sometimes a man named his child, but mostly the father asked a medicine man (or another man of distinction) to do so. He did this in the hope of his child living a long and productive life. During the public naming ceremony, the medicine man lit his pipe and offered smoke to the heavens, earth, and each of the four directions. He prayed that the child would remain happy and healthy. He then lifted the child to symbolize its growing up and announced the child's name four times. He held the child a little higher each time he said the name. It was believed that the child's name foretold its future; even a weak or sick child could grow up to be a great warrior, hunter, and raider if given a name suggesting courage and strength. Boys were often named after their grandfather, uncle, or other relative. Girls were usually named after one of their father's relatives, but the name was selected by the mother. As children grew up they also acquired nicknames at different points in their lives, to express some aspect of their lives.
Children.
The Comanche looked on their children as their most precious gift. Children were rarely punished. Sometimes, though, an older sister or other relative was called upon to discipline a child, or the parents arranged for a boogey man to scare the child. Occasionally, old people donned sheets and frightened disobedient boys and girls. Children were also told about Big Cannibal Owl ("Pia Mupitsi"), who lived in a cave on the south side of the Wichita Mountains and ate bad children at night.
Children learned from example, by observing and listening to their parents and others in the band. As soon as she was old enough to walk, a girl followed her mother about the camp and played at the daily tasks of cooking and making clothing. She was also very close to her mother's sisters, who were called not aunt but "pia", meaning mother. She was given a little deerskin doll, which she took with her everywhere. She learned to make all the clothing for the doll.
A boy identified not only with his father but with his father's family, as well as with the bravest warriors in the band. He learned to ride a horse before he could walk. By the time he was four or five, he was expected to be able to skillfully handle a horse. When he was five or six, he was given a small bow and arrows. Often, a boy was taught to ride and shoot by his grandfather, since his father and other warriors were on raids and hunts. His grandfather also taught him about his own boyhood and the history and legends of the Comanche.
As the boy grew older, he joined the other boys to hunt birds. He eventually ranged farther from camp looking for better game to kill. Encouraged to be skillful hunters, boys learned the signs of the prairie as they learned to patiently and quietly stalk game. They became more self-reliant, yet, by playing together as a group, also formed the strong bonds and cooperative spirit that they would need when they hunted and raided.
Boys were highly respected because they would become warriors and might die young in battle. As he approached manhood, a boy went on his first buffalo hunt. If he made a kill, his father honored him with a feast. Only after he had proven himself on a buffalo hunt was a young man allowed to go to war.
When he was ready to become a warrior, at about age fifteen or sixteen, a young man first "made his medicine" by going on a vision quest (a rite of passage). Following this quest, his father gave the young man a good horse to ride into battle and another mount for the trail. If he had proved himself as a warrior, a Give Away Dance might be held in his honor. As drummers faced east, the honored boy and other young men danced. His parents, along with his other relatives and the people in the band, threw presents at his feet – especially blankets and horses symbolized by sticks. Anyone might snatch one of the gifts for themselves, although those with many possessions refrained; they did not want to appear greedy. People often gave away all their belongings during these dances, providing for others in the band, but leaving themselves with nothing.
Girls learned to gather healthy berries, nuts, and roots. They carried water and collected wood, and when about twelve years old learned to cook meals, make tipis, sew clothing, prepare hides, and perform other tasks essential to becoming a wife and mother. They were then considered ready to be married.
Death.
During the 19th century, the traditional Comanche burial custom was to wrap the deceased's body in a blanket and place it on a horse, behind a rider, who would then ride in search an appropriate burial place, such as a secure cave. After entombment, the rider covered the body with stones and returned to camp, where the mourners burned all the deceased's possessions. The primary mourner slashed his arms to express his grief. The Quahada band following this custom longer than other bands and buried their relatives in the Wichita Mountains. Christian missionaries convinced Comanche people to bury their dead in coffins in graveyards, which is the practice today.
Transportation and habitation.
When they lived with the Shoshone, the Comanche mainly used dog-drawn travois for transportation. Later, they acquired horses from other tribes, such as the Pueblo, and from the Spaniards. Since horses are faster, easier to control and able to carry more, this helped with their hunting and warfare and made moving camp easier. Larger dwellings were made due to the ability to pull and carry more belongings. Being herbivores, horses were also easier to feed than dogs, since meat was a valuable resource. The horse was of the utmost value to the Comanche. A Comanche man's wealth was measured by the size of his horse herd. Horses were prime targets to steal during raids; often raids were conducted specifically to capture horses. Often horse herds numbering in the hundreds were stolen by Comanche during raids against other Indian nations, Spanish, Mexicans, and later from the ranches of Texans. Horses were used for warfare with the Comanche being considered to be among the finest light cavalry and mounted warriors in history.
Much of the area inhabited by the Comanches was flat and dry, with the exception of major rivers like the Cimarron River, the Pecos River, the Brazos River, and the Red River. The water of these rivers was often too dirty to drink, so the Comanches usually lived along the smaller, clear streams that flowed into them. These streams supported trees that the Comanche used to build shelters.
The Comanche sheathed their tipis with a covering made of buffalo hides sewn together. To prepare the buffalo hides, women first spread them on the ground, then scraped away the fat and flesh with blades made from bones or antlers, and left them in the sun. When the hides were dry, they scraped off the thick hair, and then soaked them in water. After several days, they vigorously rubbed the hides in a mixture of animal fat, brains, and liver to soften the hides. The hides were made even more supple by further rinsing and working back and forth over a rawhide thong. Finally, they were smoked over a fire, which gave the hides a light tan color. To finish the tipi covering, women laid the tanned hides side by side and stitched them together. As many as 22 hides could be used, but 14 was the average. When finished, the hide covering was tied to a pole and raised, wrapped around the cone-shaped frame, and pinned together with pencil-sized wooden skewers. Two wing-shaped flaps at the top of the tipi were turned back to make an opening, which could be adjusted to keep out the moisture and held pockets of insulating air. With a fire pit in the center of the earthen floor, the tipis stayed warm in the winter. In the summer, the bottom edges of the tipis could be rolled up to let cool breezes in. Cooking was done outside during the hot weather. Tipis were very practical homes for itinerant people. Working together, women could quickly set them up or take them down. An entire Comanche band could be packed and chasing a buffalo herd within about 20 minutes. The Comanche women were the ones who did the most work with food processing and preparation.
Food.
The Comanche were initially hunter-gatherers. When they lived in the Rocky Mountains, during their migration to the Great Plains, both men and women shared the responsibility of gathering and providing food. When the Comanche reached the plains, hunting came to predominate. Hunting was considered a male activity and was a principal source of prestige. For meat, the Comanche hunted buffalo, elk, black bear, pronghorn, and deer. When game was scarce, the men hunted wild mustangs, sometimes eating their own ponies. In later years the Comanche raided Texas ranches and stole longhorn cattle. They did not eat fish or fowl, unless starving, when they would eat virtually any creature they could catch, including armadillos, skunks, rats, lizards, frogs, and grasshoppers. Buffalo meat and other game was prepared and cooked by the women. The women also gathered wild fruits, seeds, nuts, berries, roots, and tubers — including plums, grapes, juniper berries, persimmons, mulberries, acorns, pecans, wild onions, radishes, and the fruit of the prickly pear cactus. The Comanche also acquired maize, dried pumpkin, and tobacco through trade and raids. Most meats were roasted over a fire or boiled. To boil fresh or dried meat and vegetables, women dug a pit in the ground, which they lined with animal skins or buffalo stomach and filled with water to make a kind of cooking pot. They placed heated stones in the water until it boiled and had cooked their stew. After they came into contact with the Spanish, the Comanche traded for copper pots and iron kettles, which made cooking easier.
Women used berries and nuts, as well as honey and tallow, to flavor buffalo meat. They stored the tallow in intestine casings or rawhide pouches called "parfleches". They especially liked to make a sweet mush of buffalo marrow mixed with crushed mesquite beans.
The Comanches sometimes ate raw meat, especially raw liver flavored with gall. They also drank the milk from the slashed udders of buffalo, deer, and elk . Among their delicacies was the curdled milk from the stomachs of suckling buffalo calves. They also enjoyed buffalo tripe, or stomachs.
Comanche people generally had a light meal in the morning and a large evening meal. During the day they ate whenever they were hungry or when it was convenient. Like other Plains Indians, the Comanche were very hospitable people. They prepared meals whenever a visitor arrived in camp, which led to outsiders' belief that the Comanches ate at all hours of the day or night. Before calling a public event, the chief took a morsel of food, held it to the sky, and then buried it as a peace offering to the Great Spirit. Many families offered thanks as they sat down to eat their meals in their tipis.
Comanche children ate pemmican, but this was primarily a tasty, high-energy food reserved for war parties. Carried in a parfleche pouch, pemmican was eaten only when the men did not have time to hunt. Similarly, in camp, people ate pemmican only when other food was scarce. Traders ate pemmican sliced and dipped in honey, which they called Indian bread.
Clothing.
Comanche clothing was simple and easy to wear. Men wore a leather belt with a breechcloth — a long piece of buckskin that was brought up between the legs and looped over and under the belt at the front and back, and loose-fitting deerskin leggings. Moccasins had soles made from thick, tough buffalo hide with soft deerskin uppers. The Comanche men wore nothing on the upper body except in the winter, when they wore warm, heavy robes made from buffalo hides (or occasionally, bear, wolf, or coyote skins) with knee-length buffalo-hide boots. Young boys usually went without clothes except in cold weather. When they reached the age of eight or nine, they began to wear the clothing of a Comanche adult. In the 19th century, men used woven cloth to replace the buckskin breechcloths, and the men began wearing loose-fitting buckskin shirts. The women decorated their shirts, leggings and moccasins with fringes made of deer-skin, animal fur, and human hair. They also decorated their shirts and leggings with patterns and shapes formed with beads and scraps of material. Comanche women wore long deerskin dresses. The dresses had a flared skirt and wide, long sleeves, and were trimmed with buckskin fringes along the sleeves and hem. Beads and pieces of metal were attached in geometric patterns. Comanche women wore buckskin moccasins with buffalo soles. In the winter they, too, wore warm buffalo robes and tall, fur-lined buffalo-hide boots.
Unlike the boys, young girls did not go without clothes. As soon as they were able to walk, they were dressed in breechcloths. By the age of twelve or thirteen, they adopted the clothes of Comanche women.
Hair and headgear.
Comanche people took pride in their hair, which was worn long and rarely cut. They arranged their hair with porcupine quill brushes, greased it and parted it in the center from the forehead to the back of the neck. They painted the scalp along the parting with yellow, red, or white clay (or other colors). They wore their hair in two long braids tied with leather thongs or colored cloth, and sometimes wrapped with beaver fur. They also braided a strand of hair from the top of their head. This slender braid, called a scalp lock, was decorated with colored scraps of cloth and beads, and a single feather. Comanche men rarely wore anything on their heads. Only after they moved onto a reservation late in the 19th century did Comanche men begin to wear the typical Plains headdress. If the winter was severely cold, they might wear a brimless, woolly buffalo hide hat. When they went to war, some warriors wore a headdress made from a buffalo's scalp. Warriors cut away most of the hide and flesh from a buffalo head, leaving only a portion of the woolly hair and the horns. This type of woolly, horned buffalo hat was worn only by the Comanche. Comanche women did not let their hair grow as long as the men did. Young women might wear their hair long and braided, but women parted their hair in the middle and kept it short. Like the men, they painted their scalp along the parting with bright paint.
Body decoration.
Comanche men usually had pierced ears with hanging earrings made from pieces of shell or loops of brass or silver wire. A female relative would pierce the outer edge of the ear with six or eight holes. The men also tattooed their face, arms, and chest with geometric designs, and painted their face and body. Traditionally they used paints made from berry juice and the colored clays of the Comancheria. Later, traders supplied them with vermilion (red pigment) and bright grease paints. Comanche men also wore bands of leather and strips of metal on their arms. Except for black, which was the color for war, there was no standard color or pattern for face and body painting: it was a matter of individual preference. For example, one Comanche might paint one side of his face white and the other side red; another might paint one side of his body green and the other side with green and black stripes. One Comanche might always paint himself in a particular way, while another might change the colors and designs when so inclined. Some designs had special meaning to the individual, and special colors and designs might have been revealed in a dream. Comanche women might also tattoo their face or arms. They were fond of painting their bodies and were free to paint themselves however they pleased. A popular pattern among the women was to paint the insides of their ears a bright red and paint great orange and red circles on their cheeks. They usually painted red and yellow around their lips. 
Visual arts.
Because of their frequent traveling, Comanche Indians had to make sure that their household goods and other possessions were unbreakable. They did not use pottery that could easily be broken on long journeys. Basketry, weaving, wood carving, and metal working were also unknown among the Comanches. Instead, they depended upon the buffalo for most of their tools, household goods, and weapons. They made nearly 200 different articles from the horns, hide, and bones of the buffalo.
Removing the lining of the inner stomach, women made the paunch into a water bag. The lining was stretched over four sticks and then filled with water to make a pot for cooking soups and stews. With wood scarce on the plains, women relied on buffalo chips (dried dung) to fuel the fires that cooked meals and warmed the people through long winters.
Stiff rawhide was fashioned into saddles, stirrups and cinches, knife cases, buckets, and moccasin soles. Rawhide was also made into rattles and drums. Strips of rawhide were twisted into sturdy ropes. Scraped to resemble white parchment, rawhide skins were folded to make parfleches in which food, clothing, and other personal belongings were kept. Women also tanned hides to make soft and supple buckskin, which was used for tipi covers, warm robes, blankets, cloths, and moccasins. They also relied upon buckskin for bedding, cradles, dolls, bags, pouches, quivers, and gun cases.
Sinew was used for bowstrings and sewing thread. Hooves were turned into glue and rattles. The horns were shaped into cups, spoons, and ladles, while the tail made a good whip, a fly-swatter, or a decoration for the tipi. Men made tools, scrapers, and needles from the bones, as well as a kind of pipe, and fashioned toys for their children. As warriors, however, men concentrated on making bows and arrows, lances, and shields. The thick neck skin of an old bull was ideal for war shields that deflected arrows as well as bullets. Since they spent most of each day on horseback, they also fashioned leather into saddles, stirrups, and other equipment for their mounts. Buffalo hair was used to fill saddle pads and was also used in rope and halters.
Language.
The language spoken by the Comanche people, "Comanche" ("Numu tekwapu"), is a Numic language of the Uto-Aztecan language group. It is closely related to the language of the Shoshone, from which the Comanche diverged around 1700. The two languages remain closely related, but a few low-level sound changes inhibit mutual intelligibility. The earliest records of Comanche from 1786 clearly show a dialect of Shoshone, but by the beginning of the 20th century, these sound changes had modified the way Comanche sounded in subtle, but profound, ways. Although efforts are now being made to ensure survival of the language, most of its speakers are elderly, and less than one percent of the Comanches can speak it.
In the late 19th century, many Comanche children were placed in boarding schools with children from different tribes. The children were taught English and discouraged from speaking their native language. Anecdotally, enforcement of speaking English was severe. The objectives were to ensure safety (in an emergency, it would have been impossible to relay information to the children quickly in every known language and dialect) and to establish a common language between the teachers and administration of the boarding schools, as well as among the children from different tribes.
Quanah Parker learned and spoke English and was adamant that his own children do the same. The second generation then grew up speaking English, because it was believed that it was better for them not to know Comanche.
During World War II, a group of 17 young men, referred to as "The Comanche Code Talkers", were trained and used by the U.S. Army to send messages conveying sensitive information that could not be deciphered by the Germans.

</doc>
<doc id="54002" url="http://en.wikipedia.org/wiki?curid=54002" title="Sauk">
Sauk

Sauk may refer to:

</doc>
<doc id="54004" url="http://en.wikipedia.org/wiki?curid=54004" title="Le Havre">
Le Havre

Le Havre (; ]) is an urban French commune and city in the Seine-Maritime department in the Haute-Normandie region of north-western France. It is situated on the right bank of the estuary of the river Seine on the Channel south-west of the Pays de Caux.
Modern Le Havre remains deeply influenced by its work and maritime traditions. Its port is the second largest in France, after that of Marseille, for total traffic, and the largest French container port. The name "Le Havre" means "the harbour" or "the port". Its inhabitants are known as "Havrais" or "Havraises".
Administratively the commune is located in the Haute-Normandie region and, with Dieppe, is one of the two sub-prefectures of the Seine-Maritime department. Le Havre is the capital of the canton and since 1974 has been the see of the diocese of Le Havre.
Le Havre is the most populous commune in the Haute-Normandie region, although the total population of the greater Le Havre conurbation is smaller than that of Rouen. It is also the second largest subprefecture in France (after Reims).
The city and port were officially founded by King François I in 1517. Economic development in the Early modern period was hampered by religious wars, conflicts with the English, epidemics, and storms. It was from the end of the 18th century that Le Havre started growing and the port took off first with the slave trade then other international trade. After the 1944 bombings the firm of Auguste Perret began to rebuild the city in concrete. The oil, chemical, and automotive industries were dynamic during the Trente Glorieuses (postwar boom) but the 1970s marked the end of the golden age of ocean liners and the beginning of the economic crisis: the population declined, unemployment increased and remains at a high level today. Changes in years 1990–2000 were numerous. The right won the municipal elections and committed the city to the path of reconversion, seeking to develop the service sector and new industries (Aeronautics, Wind turbines). The Port 2000 project increased the container capacity to compete with ports of northern Europe, transformed the southern districts of the city, and ocean liners returned. In 2005 UNESCO inscribed the central city of Le Havre as a World Heritage Site. The André Malraux Modern Art Museum is the second of France for the number of impressionist paintings.
The city has been awarded two flowers by the "National Council of Towns and Villages in Bloom" in the "Competition of cities and villages in Bloom".
Geography.
Location.
Le Havre is a major French city located some 50 km west of Rouen on the shore of the English Channel and at the mouth of the Seine. Numerous roads link to Le Havre with the main access roads being the A29 autoroute from Amiens and the A13 autoroute from Paris linking to the A131 autoroute.
Administratively, Le Havre is a commune in the Haute-Normandie region in the west of the department of Seine-Maritime. The urban area of Le Havre corresponds roughly to the territory of the Agglomeration community of Le Havre (CODAH) which includes 17 communes and 250,000 people. It occupies the south-western tip of the natural region of Pays de Caux where it is the largest city. Le Havre is sandwiched between the coast of the Channel from south-west to north-west and the estuary of the Seine to the south.
Geology and terrain.
Le Havre belongs to the Paris basin which was formed in the Mesozoic period. The Paris basin consists of sedimentary rocks. The commune of Le Havre consists of two areas separated by a natural cliff edge: one part in the lower part of the town to the south including the harbour, the city centre and the suburbs. It was built on former marshland and mudflats that were drained in the 16th century. The soil consists of several metres of Alluvium or silt deposited by the Seine. The city centre was rebuilt after the Second World War using a metre of flattened rubble as a foundation.
The upper town to the north, is part of the cauchois plateau: the neighbourhood of Dollemard is its highest point (between 90 to above sea level). The plateau is covered with a layer of flinty clay and a fertile silt. The bedrock consists of a large thickness of chalk measuring up to 200 m deep. Because of the slope the coast is affected by the risk of landslides.
Climate.
Due to its location on the coast of the Channel, the climate of Le Havre is temperate oceanic. Days without wind are rare. There are maritime influences throughout the year. According to the records of the meteorological station of the Cap de la Heve (from 1961 to 1990), the temperature drops below 0 C on 24.9 days per year and it rises above 25 °C on 11.3 days per year. The average annual sunshine duration is 1,785.8 hours per year.
Precipitation is distributed throughout the year, with a maximum in autumn and winter. The months of June and July are marked by some thunderstorms on average 2 days per month. One of the characteristics of the region is the high variability of the temperature, even during the day. The prevailing winds are from the southwest sector for strong winds and north-north-east for breezes, snowstorms occur in winter, especially in January and February.
The absolute speed record for wind at Le Havre – Cap de la Heve was recorded on 16 October 1987 at 180 km/h.
The main natural hazards are floods, storms, and tidal waves. The lower town is subject to a rising Water table. The lack of watercourses within the commune prevents flooding from overflows. Le Havre's beach may rarely experience flooding known as "flooding from storms". These are caused by the combination of strong winds, high waves and a large tidal range.
Weather Data for Le Havre
Environment.
A study by "Aphekom" comparing ten large French cities showed that Le Havre is the least polluted urban commune of France. Le Havre is also the third best city in France with more than 100,000 inhabitants for air quality. A Carbon accounting showed in 2009 that the municipality ejected some 32,500 tonnes of CO₂ per year. In 2011 the average annual emissions of sulfur dioxide by industry was between three micrograms per cubic metre in the centre of Le Havre to twelve micrograms per cubic metre in the district of Caucriauville.
The municipality has set a target to reduce emissions of CO2 by 3% per year. To achieve this solar panels have been installed on several municipal buildings (city hall, hanging gardens). Since 2008, Le Havre has been part of the network of Energy Cities and, in this context, it applies the steps of Agenda 21 and an Environmental Approach to Urban Planning. The city has received many awards of eco-labels several times (Energy of the Future label in 2009–2011, sustainable Earth label in 2009). Since 1998, Le Havre's beach has received the Blue Flag yearly thanks to its range of facilities, which extend over 30,000 Sq. M.
Le Havre has kept extensive green areas (750 hectares or 41 Sq. M per inhabitant): the two largest areas are the Montgeon Forest and Rouelles Park which are both located in the upper town. The gardens of the Priory of Graville and the hanging gardens offer views of the lower city. In the city centre, Saint-Roch Square and the City Hall Gardens provide the people with urban recreation areas. Various ecosystems are represented in the Beach Gardens and the Hauser Park (caves). Finally, the Plateau of Dollemard was classified as a "Sensitive Natural Area" of the department in 2001 to protect its landscape and ecosystems on the cliff. The streets are lined with 13,000 trees of 150 different varieties.
Transport.
For a long time Le Havre has exploited the strengths of its coastal location but also suffered from its relative isolation. This is why the accessibility of the city has been improved with the harbour highway A131 (E05) which links Le Havre to the A13 autoroute over Tancarville Bridge. The city is one hour from Rouen and one and a half-hour from Île-de-France. More recently the A29 autoroute (E44) has connected Le Havre to the north of France and passes over the Normandy Bridge which makes Amiens (in the north-east) two hours away and Caen (in the south-west) one hour.
The TER network was modernized with the creation of the LER line in 2001 and direct services to Fécamp in 2005. Thirteen Corail trains of the Paris-Le Havre line link stations at Bréauté-Beuzeville, Yvetot, and Rouen, with Paris Saint-Lazare station. In addition there is a TGV daily service to Le Havre: it has connected the city to Marseille since December 2004 serving Rouen, Mantes-la-Jolie, Versailles, Massy, Lyon, Avignon, Aix-en-Provence, and Saint Charles station in Marseilles.
No direct rail link connects Le Havre and Caen yet many projects – known as the "Southwest Line" – to link Le Havre to the left bank of the Seine downstream from Rouen, near the estuary of the river, were studied in the second half of the 19th century and the beginning of the 20th century but none have been realized due to lack of political will and strong opposition from Rouen port authorities. By public transport it is necessary to go to Rouen by train or bus (using No. 20 Green Bus). There is a Gray Coach to Etretat and Fécamp and there is VTNI for destinations in the Seine valley and Rouen who provide inter-urban services on behalf of the Department of Seine-Maritime. Finally, the company AirPlus provides a shuttle service to the train stations and airports of Paris.
For air transport, there is Le Havre Octeville Airport which is located 5 km north of Le Havre at the town of Octeville-sur-Mer and managed by CODAH.
The main destination is the Transport hub of Lyon. Many holiday destinations are offered each year (Tunisia, Balearic Islands, Portugal, Greece, Bulgaria, etc.) through local travel agencies that charter aircraft. There is also the Flying club Jean Maridor at the airport.
The Channel maritime links with Portsmouth in southern England with P&O Ferries ended on 30 September 2005 to be taken over by LD Lines who have changed the configuration. Two services to Portsmouth are provided daily from the Terminal de la Citadelle. The link to Ireland was moved to the port of Cherbourg.
Crossing times to Portsmouth vary from five hours and thirty minutes to eight hours. Popular alternative routes going to areas close to Le Havre include Newhaven to Dieppe, and Poole to Cherbourg.
Urban transport.
The city and the metropolitan area has a dense transport network. This solves the problem of a break between the lower town and the upper town and the two parts of the city are connected by long boulevards, winding roads, many stairs, a funicular, and finally the Jenner tunnel.
The CODAH transport network is called "Lia" and is operated by the "Ocean Port Transport company" (CTPO), a subsidiary of Veolia Transport. The overhaul of the bus network in 2008 helped to ensure a better service for all the towns in the metropolitan area. The CTPO operates a bus network consisting of 19 regular urban routes and six evening routes called the "Midnight Bus". The Le Havre urban area is served by 165 vehicles and 41 regular bus routes with an average of 100,000 passengers per day. From January 2011 there has been a regular shuttle service specific to the Industrial Zone and Port of Le Havre, thus adding to the cross-estuary service of VTNI. Since 1890 the funicular has provided a link between the upper town and the lower town in four minutes with a cable car.
Le Havre had a tramway system from 1894 until it closed in 1957. More recently a new tramway system, with 23 stations and 13 km of route, was built, and opened on 12 December 2012. The first part of the line connects the beach to the station climbing to the upper town through a new tunnel near the Jenner tunnel then it splits into two: one link going to Mont-Gaillard, the other to Caucriauville.
Finally, since 2001 Le Havre agglomeration has operated the LER, a TER line connecting the Le Havre station to Rolleville passing through five other SNCF railway stations of the urban area.
From 2005, development work for Segregated cycle facilities have increased including a connection to the Greenway which promises to be an important network of quality. Between 2007 and 2011, the total length of cycle paths has doubled to 46 km in total length. It is possible to rent bicycles through agencies of the Océane bus or from the town hall (Vel-H) which has them on hand. Finally, 140 taxis work in Le Havre and serve 25 stations.
Urbanism.
The Lower City.
City rebuilt after 1945.
Largely destroyed during the Second World War, the city was rebuilt according to the plans of the architect Auguste Perret between 1945 and 1964. Only the town hall and the Church of Saint Joseph (107m high) were personally designed by Auguste Perret. In commending the reconstruction work UNESCO listed the city of Le Havre on 15 July 2005 as a World Heritage Site. This area of 133 hectares is one of the few inscribed contemporary sites in Europe. The architecture of the area is characterized by the use of precast concrete using a system of a modular frame of 6.24 metres and straight lines.
Another notable architectural work of the central city is that of the "House of Culture" built in 1982 by the Brazilian architect Oscar Niemeyer and nicknamed "the Volcano" because of the shape of the building. In 2012, this place was being refurbished both inside and outside with fairly significant changes approved by the architect including greater openness to the outside of the plaza.
The Notre Dame and Perrey neighbourhoods are mainly residential. Les Halles is one of the commercial hubs of the city. The Saint Francis neighborhood was also rebuilt after 1945 but in a radically different architectural style: the buildings are brick and have pitched slate roofs. This is the restaurant district and the fish market.
Neighbourhoods in the old centre of town.
To the east and north of the rebuilt central city are a stretch of old neighbourhoods (Danton, Saint-Vincent, Graville, Massillon, etc.) which were spared the bombings of World War II. The buildings, usually in brick, dated to the 19th and the first half of the 20th centuries. The shops are concentrated along several major roads in the Rond-Point neighbourhood. During the 1990s and 2000s, these neighborhoods have seen major redevelopments, particularly in the context of an OPAH: improvement of habitat by rehabilitation or reconstruction, creation of public facilities, and revitalization of business.
At the end of the 20th century and beginning of the 21st century, the area around the railway station has undergone a major transformation. As the station is the gateway to the city with the main avenues intersecting here. New buildings have sprung up (University of Le Havre, the conservatory, headquarters of the SPB (Provident Society Bank), and of CMA CGM, Novotel, Matmut, new CCI) some of which were designed by renowned architects. The bus station, certified "NF" since 2005, has been refurbished. North of the station, another construction project in place of the dilapidated island of Turgot-Magellan will be opened in 2013, including 12500 m2 of office space and an eight-storey hotel, complete with shops on the ground-floor.
The southern districts.
The southern districts of Le Havre are mainly used for industrial and port activities. There are buildings in brick from the 19th century, large developments (Chicago, Les Neiges), worker estates, SMEs, warehouses, dock and port facilities, and transport infrastructure. 
The southern districts have for some years experienced profound change due to European funding. It is revitalizing areas neglected by industrial and port activities by developing tertiary activities. Thus, the docks have been completely transformed into sports and entertainment complexes (Dock Océane), a mall (Docks Vauban), and an exhibition hall (Docks Café). Les Bains Des Docks was designed by the architect Jean Nouvel. At the end of 2012 students from Sciences-Po Europe Asia and from INSA integrated new buildings next to the ISEL (Higher Institute of logistics studies) and the future ENSM (Ecole Nationale Supérieure Maritime). The new medical axis around the new "Clinic des Ormeaux" was built in the neighbourhoods where many homes are planned with the aim of promoting social mix. The "City of the Sea and of Sustainable Development" (Odyssey 21) will be organized around a metal tower one hundred metres high designed by Jean Nouvel: the project was suspended in 2007 but the work should finally begin in 2013. The municipality has to attract some 300,000 visitors per year.
The Upper Town.
The upper town is composed of three parts: the "coast", the suburban districts of the plateau, and large peripheral housing estates.
The neighbourhoods on the "coast" (the Dead Cliff) are residential – more prosperous in the western part (Les Ormeaux, Rue Felix Faure) and more modest to the east (St. Cecilia, Aplemont). The Jenner tunnel passes under the "coast" and connects the upper town to the lower town. It is also on the coast that there are two fortifications of the city, Forts Sainte-Adresse and Tourneville, and the main cemetery (Sainte-Marie cenetery). With the demise of the military functions of the city, the forts are gradually being converted: Fort Sainte-Adresse houses the "Hanging Gardens" and Fort Tourneville hosted the Tetris project in 2013 – an axis of contemporary music with concert halls and rehearsal studios.
To the north of the "coast" suburban districts such as Rouelles, Sainte-Cecile, la Mare au Clerc, Sanvic, Bleville, and Dollemard were developed during the first half of the 19th century. In their extension North-west between Bleville and Octeville airport a new area is being developed: "Les Hauts de Bleville". This eco-district made up of housing units to HQE standards, a Joint Development Area (ZAC), and a school should have a total of 1,000 housing units.
The peripheral suburbs of the commune grew in the postwar period. These are large housing estates in Caucriauville, Bois de Bleville, Mont-Gaillard, and Mare-rouge where a disadvantaged population is concentrated. In October 2004 the National Agency for Urban Renewal (ANRU) signed with the municipality of Havre the first agreement to finance the rehabilitation of these areas. This finance agreement provides more than 340 million euros for the housing estates in the northern districts, where about 41,000 people reside. This development extends the budget for the "Grand Projet de Ville" (GPV). It allows the demolition and rebuilding of more than 1,700 homes.
Toponymy.
The name of the town was attested in 1489, even before it was founded by François I in the form "le Hable de Grace" then "Ville de Grace" in 1516, two years before its official founding. The learned and transient name of "Franciscopolis" in tribute to the same king, is encountered in some documents then that of "Havre Marat", referring to Jean-Paul Marat during the French Revolution but was not imposed. However it explains why the complementary determinant "-de-Grace" was not restored. This qualifier undoubtedly referred to the Chapel of Notre Dame located at the site of the cathedral of the same name. It should be noted that the chapel faced the Chapel Notre Dame de Grace of Honfleur across the estuary. The commune name of "havre" meaning "port" was out of use at the end of the 18th or beginning of the 19th centuries but is still preserved in the phrase "havre de paix" meaning "safe haven". It is generally considered a loan from Middle Dutch from the 12th century. A Germanic origin can explain the "aspiration" of the initial "h".
New research however focuses on the fact that the term was attested very early (12th century) and in Norman texts in the forms "Hable", "hafne", "havene", "havne", and "haule" makes a Dutch origin unlikely. By contrast, a Scandinavian etymology is relevant given the old Scandinavian "höfn" (genitive "hafnar") or "hafn" meaning "natural harbour" or "haven" and the phonetic evolution of the term "étrave" which is assuredly of Scandinavian origin is also attested in similar forms such as "estable" and probably dates back to the ancient Scandinavian "stafn".
History.
Le Havre was founded on 8 October 1517 as a new port by royal command of François I partly to replace the historic harbours of Harfleur and Honfleur which had become increasingly impractical due to silting-up. The city was originally named "Franciscopolis" after the king then subsequently became Le Havre-de-Grâce ("Harbour of Grace") after an existing chapel of "Notre-Dame-de-Grâce" ("our Lady of Grace").
Before François I.
Human presence on the territory of Le Havre dates back to Prehistory around 400,000 BC.
Many remains from the Neolithic period have been excavated in the lower city and the Montgeon Forest: it is at this time that the population increased and settled down in the first hamlets. During the Iron Age Celtic people from Caletes settled in the region. From ancient times river traffic on the Seine supported Gallo-Roman cities of the estuary. A Roman road linked Lillebonne (Juliobona) at the mouth of the Seine through the current territory of the commune of Le Havre. 
The first mention of Graville Abbey was in the 9th century, about Sanvic on the plateau. The village of Leure and its commercial port appear in the 11th century. It served as a shelter for ships awaiting the tide to enter the port of Harfleur upstream. It was at this time that Guillaume Mallet, companion of William the Conqueror built himself a castle at Graville and a Motte-and-bailey castle in Aplemont. Several hamlets of fishermen and farmers, the first parishes emerged in the High Middle Ages. During the Hundred Years War the fortified ports Leurre and Harfleur were destroyed. At the beginning of the 16th century the growth of trade, the silting-up of the port of Harfleur, and the fear of an English landing pushed the king François I to found the port of Le Havre and the town. 
The foundation of Le Havre.
On 8 October 1517, François I signed the founding charter of the port the plans of which are first assigned to Vice Admiral Guyon le Roy. The "big tower" defended the entrance. Despite difficulties associated with marshland and storms, the port of Le Havre welcomed its first ship in October 1518. The king himself travelled there in 1520 and granted in perpetuity the privileges of Le Havre and gave them his own arms consisting of a salamander. The military function was also encouraged: Le Havre was an assembly point for the French fleet during the wars. Ships also went fishing for cod in Newfoundland.
In 1525, a storm caused the death a hundred people, destroyed 28 fishing boats and the Chapel of Notre Dame. In 1536 the chapel was rebuilt in wood with stone pillars under the direction of Guillaume de Marceilles. A gothic tower with a large octagonal spire was added in 1540. The same year Francis I entrusted the planning and fortification project with Italian architect Girolamo Bellarmato. He had full power and organized the neighbourhood of Saint-François according to specific standards (grid plan, limiting the height of the houses, etc.). The first school and the granary were erected. The 1550s saw the creation of several municipal institutions: the town hall, the "Amirauté" (court of Justice), the hospital, the seat of the Viscounty and of the bailiwick.
The New World attracted adventurers and some left from Le Havre such as Villegagnon who founded a colony in Brazil (Fort Coligny) in 1555. At the end of the 16th century trade expanded quickly and Le Havre saw the arrival of American products like leather, sugar, and tobacco. One of the main players in the traffic was an explorer and cartographer Guillaume Le Testu (1509–1573): a dock in Le Havre still bears his name.
On 20 April 1564 Le Havre became the port of departure for the French expedition of René Goulaine de Laudonnière to the New World where he created the first French colony at Fort Caroline near present-day Jacksonville, Florida. Famed artist Jacques le Moyne de Morgues joined Laudonnière on this colonizing effort and created the first known artistic depictions by a European of Native Americans in the New World, specifically the Timucua tribes in the modern-day areas of northeast Florida and southeast Georgia.
The wars of religion.
The Protestant Reformation experienced relative success in Normandy. From 1557, John Venable, library colporteur from Dieppe disseminated in Pays de Caux and Lower Normandy the writings of Martin Luther and John Calvin. The first Protestant church was built in Le Havre in 1600 in the district of Sanvic at 85 rue Romain Rolland. It was destroyed in 1685 on the revocation of the Edict of Nantes by Louis XIV. It was not until 1787 and the Edict of Toleration of King Louis XVI that Le Havre reopened a Protestant place of worship in the district of Saint-François.
Le Havre was affected by the Wars of Religion: On 8 May 1562 the reformers took the city, looted churches, and expelled Catholics. Fearing a counter-attack by the royal armies, they turned to the English who sent their troops. The occupants of the city built fortifications under the Treaty of Hampton Court. The troops of Charles IX, commanded by Anne de Montmorency, attacked Le Havre and the English were finally expelled on 29 July 1563. The fort built by the English was destroyed and the tower of the Cathedral of Notre-Dame was lowered on the orders of the King. He then ordered the construction of a new citadel which was completed in 1574. New fortifications were established between 1594 and 1610. In 1581 the construction began of a canal between Harfleur and the estuary of the Seine.
The 17th and 18th centuries.
The defense function of Le Havre was reaffirmed and modernization of the port began in the 16th century on the orders of Cardinal Richelieu, governor of the city: the arsenal and the Roy Basin were developed, the walls were reinforced and a fortress built. It was in the latter that Cardinal Mazarin imprisoned the Fronde princes, Longueville, Conti, and Condé. At the beginning of the reign of Louis XIV, Colbert decided to renovate the port infrastructure and military: the work lasted 14 years. In 1669, the Minister inaugurated the Havre to Harfleur canal which is also called the "canal Vauban".
Le Havre affirmed its maritime and international calling during the 17th century: the Company of the Orient settled there in 1643. There were imports of exotic products from America (sugar, cotton, tobacco, coffee, and various spices). The slave trade enriched local traders especially in the 18th century. With 399 slave trade expeditions in the 17th and 18th centuries, Le Havre was the third largest French slave trade port after Nantes and La Rochelle. Maritime trade however is subject to international relations and a European context: the wars of Louis XIV and Louis XV momentarily interrupted the development of Le Havre. The Anglo-Dutch bombarded the city several times, notably in 1694 and in 1696.
In 1707 Michel Dubocage, a Captain from Le Havre, explored the Pacific Ocean aboard the "Discovery" and reached the Clipperton Island. Upon his return to Le Havre, he made his fortune by setting up a trading house and bought a mansion (now a Museum) in the heart of the Saint-François district and the lordship of Bléville. Another Captain from Le Havre Jean-Baptiste d'Après de Mannevillette (1707–1780) worked for the East India Company and mapped the coasts of India and China.
From the middle of the 18th century wealthy traders were building homes on the coast. In 1749 Madame de Pompadour wanted to see the sea and Louis XV chose Le Havre to satisfy her desire. The visit was ruinous to the city's finances.
In 1759, the city was the staging point for a planned French invasion of Britain – thousands of troops, horses and ships being assembled there – only for many of the barges to be destroyed in the Raid on Le Havre and the invasion to be abandoned following the naval defeat at the Battle of Quiberon Bay.
The economic boom of Le Havre resulted in an increase of its population (18,000 inhabitants in 1787) but also resulted in changes to the port and the city: the installation of a Tobacco Factory in the Saint-François district, the expansion of the shipyards, a new arsenal, and a commodity exchange. During a visit in 1786 Louis XVI approved the project to extend the city and it was François Laurent Lamandé he chose to take on the task of quadrupling the size of the city.
The French Revolutionary Period (1789–1815).
Between 1789 and 1793 the port of Le Havre was the second largest in France after that of Nantes. The Triangular trade continued until the war and its abolition. The port remained strategic because of the grain trade (supply of Paris) and its closeness to the British enemy.
The national events of the French Revolution were echoed in Le Havre: delegates for the "List of Grievances" were elected in March 1789. Popular riots occurred in July and the National Guard was formed some time later. A mayor was elected in 1790, the year of celebration of the "Fête de la Fédération". The year 1793 was difficult for France and for Le Havre because of the war, federalist insurrections, and economic stagnation. The religious Terror transformed Notre Dame Cathedral into a "Temple of Reason". The city acquired the status of sub-prefecture in the administrative reform of the "Year VIII" (1799–1800). Under the Empire Napoleon I came to Le Havre and ordered the construction of forts A Chamber of Commerce was founded in 1800 but, because of the war against Britain and the continental blockade, port activity was reduced and activity of pirates increased. The population of Le Havre decreased to 16,231 inhabitants in 1815.
The Prosperity of the 19th century.
The end of the Revolutionary and Napoleonic Wars allowed trade to recover normally as the British threat receded. The context of new-found peace and economic growth led to a large influx of population. Le Havre quickly outgrew its walls and new neighbourhoods appeared. Many poor were still crammed into the slum of Saint Francis. Epidemics of cholera, typhoid fever, and "fevers" caused hundreds of deaths in the years 1830–1850. Alcoholism and infant mortality wreaked havoc in the poorest classes. Throughout the 19th century, the cosmopolitan aspect of the city only strengthened: in times of maritime prosperity, the workers of the Pays de Caux were driven to Le Havre because of the crisis in the weaving industry. The implantation of a large Breton community (10% of the population Le Havre at the end of the 19th century) modified the cultural life of Le Havre. On the docks and in the factories there were Italians, Poles and North Africans. The economic success of the city attracted Anglo-Saxon, Nordic, and Alsatian entrepreneurs
The city and its port were transformed through major development work, partly funded by the state, which were spread throughout the 19th century – sometimes interrupted by political and economic crises. Several projects were completed such as construction of a new stock exchange and commercial basin in the first half of the century. There was progressive installation of gas lighting in 1835, rubbish collection (1844), and sewerage works showed a concern for urban modernization. By mid-century the old ramparts had been razed and the surrounding communities annexed to the city so the population increased sharply. The period 1850–1914 was a golden age for Le Havre. Apart from a few years of depression (the American Civil War, the Franco-Prussian War), trade exploded and the city was embellished with elegant new constructions (boulevards, city hall, courthouse, new stock exchange).
The effects of the industrial revolution were increasingly visible in Le Havre: the first steam dredge was used in 1831. The shipyards developed with Augustin Normand. Frederic Sauvage developed his first propeller in Le Havre in 1833. The railway arrived in 1848 which allowed the opening up of Le Havre. The docks were built in the same period as well as general warehouses. The industrial sector, however, remained in a minority in the 19th century: the plants were related to port traffic (shipyards, sugar refineries, rope factories, etc.). The banking sector developed but was still largely dependent on the outside. The city had few professionals and officials. The number of schools was inadequate even in the 1870s.
On the eve of the First World War Le Havre was the primary European port for coffee, it imported some 250,000 tonnes of cotton and 100,000 tons of oil. European cabotage brought wood, coal, Northern Europe wheat, and Mediterranean wine and oil. The abolition of the slave trade gradually caused a change in traffic. Le Havre was not only an entry for American goods but also a transit point for migrants to the USA. Transatlantic steamer travel grew in the 1830s.
Under the July Monarchy Le Havre was a Seaside resort popular with Parisians. The creation of marine baths went back to this time. It was in 1889 that the maritime boulevard was built, dominated by the "Villa Maritime". The casino Marie-Christine (1910) and the Palace of Regattas (1906) brought the Bourgeoisie and the first Beach huts were installed on the beach. The end of the 19th century and of the Belle Époque, however, arrived with social tensions exacerbated by inflation and unemployment. From 1886, worker unrest, causing the Socialists to become increasingly influential, shook the city. The case of Jules Durand (a case in 1910 where Durand, secretary of a union of striking workers, was found guilty of complicity in murder) was symptomatic of this context.
Times of War (1914–1945).
The human toll from the First World War was heavy for the city: Le Havre suffered about 6,000 dead, mostly soldiers who left to fight. The city was spared massive destruction as the front was much further north. Several ships were nevertheless torpedoed by German submarines in the Roadstead. One of the notable facts of the war was the installation of the Belgian government at Sainte-Adresse on the outskirts of Le Havre as they had been forced to flee the German occupation. The city served as a base for the Triple Entente especially for British warships: 1.9 million British soldiers passed through the port of Le Havre.
The Interwar period was marked by the cessation of population growth, social unrest, and economic crisis. At the end of the conflict inflation ruined many pensioners. The city became largely a workers city. Shortages and high prices caused the great strike of 1922 in which a state of emergency was declared. In 1936 the Breguet factory at Le Havre was occupied by strikers: this was the beginning of the labour movement under the Popular Front. On the economic front the strong growth seen in the second half of the 19th century seemed to be over. The ports of northern Europe seriously competed with Le Havre and major port development work slowed. Oil imports, however, continued to grow and refineries emerged east of Le Havre. The global crisis of 1929 and protectionist measures hindered the development of trade. Only the travel industry was doing relatively well, with 500,000 passengers carried in 1930. The liner "Normandie" began sailing to New York in 1935.
In the Second World War, German forces occupied Le Havre from the spring of 1940 causing an exodus of its population. They made a naval base in preparation for the invasion of the United Kingdom (Operation Sealion) and set up the "Festung Le Havre", lined with bunkers, pillboxes and artillery batteries integrated into the Atlantic Wall. For the people of Le Havre, daily life was difficult because of shortages, censorship, bombings and political anti-Semitism: Mayor Leon Meyer was forced to leave his post because of his Jewish origins. The Le Havre resistance was built around several nodes such as the group of the high school of Le Havre or the "Vagabond Bien-Aimé" (beloved vagabond). These groups were involved with British intelligence and with acts of sabotage preceding the landings of 6 June.
Much of the population opted to evacuate at dusk by foot, bicycle or wagon, only to return during daylight hours after the Allied Forces air bombardments were over.
Le Havre suffered 132 bombings by the Allies during the war. The Nazis also destroyed the port infrastructure and sank ships before leaving the city. The greatest destruction, however, occurred on 5 and 6 September 1944 when the British Royal Air Force bombed the city centre and the port to weaken the occupier under Operation Astonia – often described as the "storm of iron and fire".
The results of the bombing campaign were appalling: 5,000 deaths (including 1,770 in 1944), 75,000 to 80,000 injured, 150 hectares of land razed, 12,500 buildings destroyed. The port was also devastated and some 350 wrecks lie at the bottom of the sea. Le Havre was liberated by Allied troops on 12 September 1944.
Despite the extensive damage, Le Havre became the location of one of the biggest Replacement Depots, or "Repple Depples" in the European Theatre of Operations in WWII. Thousands of American replacement troops poured through the city before being deployed to combat operations.
Le Havre after 1945.
General de Gaulle visited Le Havre on 7 October 1944. The city received the Legion of Honour on 18 July 1949 for the "heroism with which it has faced its destruction".
In spring 1945, Raoul Dautry of the Ministry of Reconstruction and Urban Development entrusted the project to rebuild the city of Le Havre to Auguste Perret. The city council requested Brunau form part of the planning team, but subsequently he left a short time later due to creative conflicts with Perret. Perret wanted to make a clean sweep of the old structures and apply the theories of structural classicism. The material to be used for the building construction was concrete and the general plan was an orthogonal frame. Officially, the reconstruction was completed in the mid-1960s.
The triangular axis of the Boulevard François I, the Avenue Foch and Rue de Paris led the traveller north, south, east and west of the town centre. The pre-war shopping precinct of Rue de Paris was redesigned with wide footpaths. A surrounding gridiron street system allowed for opened shopping areas, far from the dense and overcrowded crannies of the old. The Place de l’Hotel de Ville, the central square, was lined with 330 apartments around the edge in varying sizes and permitted a 1000-person occupancy. State funds also allowed for the building of high-rise apartments over six blocks leading into the residential areas. These new apartments possessed the latest innovations including central heating. The Avenue Foch stretched 80 metres wide, a little more than the Champs-Élysées in Paris. The finest apartments were built here facing the northern sunlight. Beyond the concrete formations of the inner township stretched the Saint-Francois neighbourhood, made up of red-brick residences and slate rooflines. Aplemont’s three-square-kilometre rebuild consisted of detached housing, double storey terraces and small apartment blocks. A church, community centre and shops also defined the new features. The inclusion of 7.7 km² of green spaces with parks, gardens and woodlands added to the port’s urban renewal. This equates to an average of 41 square metres of green space per inhabitant, exceptional for any European city of its time. The "Museum of Modern Art" and the first "House of Culture" in the region were inaugurated in 1961 by André Malraux. The commune was enlarged through the annexation of "Bleville", "Sanvic", and "Rouelles".
In the 1970s economic difficulties due to de-industrialization saw, for example, the closure of "Ateliers et chantiers du Havre" (ACH) in 1999 and transformed the trade of the port. 1974 also saw the end of the ocean liner service to New York by the "France". The Energy crisis precipitated an industry slump. Since then the city has embarked on a process of restructuring mainly oriented towards the tertiary sector: opening of the University of Le Havre in the 1980s, tourism development, and modernization of the port (Port 2000 project).
UNESCO declared the city centre of Le Havre a World Heritage Site on 15 July 2005 honouring the "innovative utilisation of concrete's potential". The 133-hectare space that represented, according to UNESCO, "an exceptional example of architecture and town planning of the post-war era," is one of the rare contemporary World Heritage Sites in Europe.
Politics and Administration.
Le Havre is one of two sub-prefectures of Seine-Maritime and the second largest subprefecture in France after Reims. It is also the capital of the Arrondissement of Le Havre which includes 20 Cantons and 176 communes. It is also the largest member of the Agglomeration community of Le Havre (CODAH).
The city of Le Havre is divided into nine Cantons as shown in the following table with the councillors in 2011:
For the parliamentary elections, Le Havre spans two constituencies: the seventh (cantons I, V, VI, and VII) and the eighth (cantons II, III, IV, VIII, IX).
Political trends and results.
Several politicians have spent part of their lives in the city: Jules Lecesne (1818–1878), Jules Siegfried (1837–1922), and Félix Faure (1841–1899) who was elected municipal councilor and MP. A pool, a shopping centre and a street have been named after René Coty from Le Havre who served as President of the French Republic from 1954 to 1959. Christine Lagarde (born 1956) did part of her studies in Le Havre before becoming Minister of the Economy and Director-General of the International Monetary Fund in 2011.
Since 23 October 2010 the mayor has been Édouard Philippe (UMP). He also holds the presidency of the CODAH and has held a seat in the National Assembly for the 7th district of Seine-Maritime since 2012. He succeeded Antoine Rufenacht (UMP) as the head of the municipality who was mayor of Le Havre for fifteen years before resigning. The city of Le Havre has long been the largest bastion of the Communist Party of France, who directed it from 1956 to 1995. Overall, the inhabitants of Le Havre in the 7th electoral district (city centre and west) vote right while those of the 8th electoral district (neighbourhoods) choose the candidate of the left. So, in the presidential election of 2007, the 7th electoral district elected Nicolas Sarkozy (UMP) by 55.05% against 44.95% for Ségolène Royal (PS) while the 8th electoral district preferred the Socialist candidate by 55.02%. In revenge however, the results of the 2012 presidential elections gave the PS wins in both districts with a small difference in the 7th (Hollande: 51.71% / Sarkozy: 48.29%) than in the 8th (Hollande 64.21% / Sarkozy: 35.79%).
Municipal Administration.
The number of inhabitants in Le Havre is between 150,000 and 199,999 so the number of councilors is 59 members. The mayor, 41 aldermen and 17 deputies form the council of Le Havre elected in 2008. It meets on average once a month at the town hall. The debates are generally public except for certain proceedings.
Le Havre has experienced many territorial extensions by annexing neighbouring communes:
Mayors of Le Havre.
List of Successive Mayors of Le Havre from the French Revolution to 1940
Public institutions and services.
The Le Havre Palace of Justice is located on the Boulevard de Strasbourg. With its annex, it includes a high court, a juvenile court, and a commercial court. The city also has a Labour Court and District Court. Among the legal services offered there are legal aid services and the application of penalties. Le Havre depends on the Court of Appeal of Rouen. The prison, which dates from the Second Empire, was completely destroyed in 2012. The new prison for Le Havre was completed in 2010 at Saint-Aubin-Routot east of the Le Havre agglomeration. It has an area of 32,000 m2 on a site of 15 hectares and can accommodate 690 people.
The "Hospital Group of Havre" is a public health facility managed by a Supervisory Board chaired by the Mayor of Le Havre. Its main structures are Flaubert Hospital (the oldest, located downtown), the Monod Hospital (in Montivilliers), the Pierre Janet Hospital (psychiatry), the house for adolescents, day hospitals, and seniors' residences. It is the largest employer in the CODAH. Built in 1987, the Jacques Monod Hospital offers a full range of care in medicine, surgery, gynecology, obstetrics, pediatrics, geriatrics, mental health follow-up care, rehabilitation, reintegration, and public health.
Finally, there are several private clinics that offer complete care: the private clinic of the Estuary groups together the old clinics of "Petit Colmoulins" and François I. The private clinic of Ormeaux is located in the neighbourhood of Eure.
During the first half of the 20th century, the 129th regiment of infantry of the line was stationed at Le Havre and left an important mark on the city so a street was named after them. The 74th Infantry Regiment of commandos was present from 1963 to 1976. Finally, Le Havre is the godmother city for BPC Mistral. The ceremony was held at the City Hall on 15 November 2009, during a stopover at the Building.
Twinning.
Le Havre has twinning associations with:
Demographics.
Le Havre experienced a population boom in the second half of the 19th century. Subsequently, the population drain of the First World War was offset by the annexation of the town of Graville (the city gained 27,215 people between 1911 and 1921). During the Second World War the population decreased significantly (a loss of 57,149 people between 1936 and 1946) because of the exodus and bombings. After the war the commune saw its population increase until 1975. Since then population has decreased again, especially between 1975 and 1982: during these years of industrial crisis the population fell by 18,494 people. The trend continued in the 1980s although at a slower pace. The current policy of the municipality is to build new housing to attract new residents with the goal of exceeding 200,000 inhabitants, a level that was reached in the 1960s. The population of the commune of Le Havre was 191,000 inhabitants in 1999 which placed the city at 12th place among the most populated cities in France and in the first place in Normandy. In 2009 INSEE counted 177,259 people lived in the commune of Le Havre while the urban area of Le Havre had 242,474 people (25th place nationally) and the Metropolitan area of Havre ahd 293,361 inhabitants.
In 2009, the commune had 177,259 inhabitants. The evolution of the number of inhabitants is known through the population censuses conducted in the commune since 1793. From the 21st century, a census of communes with fewer than 10,000 inhabitants is held every five years, unlike larger towns that have a sample survey every year.
Evolution of the Population 
Sources : , (population without double counting and municipal population from 2006)
In 2009, the birth rate was 14.2 per thousand and the mortality rate was 9.4 per thousand: even though the Rate of natural increase is positive it does not compensate for the clearly negative Net migration rate. In 2009 19% of Le Havre's population was under 15 years old and 40% were under 29 years old which was above the average for metropolitan France. 18.4% of men and 25.6% of women were over 60 years old. The population is mainly concentrated in the city centre and Côte-Ormeaux. The foreign population is estimated at 8,525 persons or 4.8% of the population. 12,148 immigrants live in Havre, or 6.8% of the urban population. Most have North African (5060) or African (3114) origins.
With the economic changes that have affected the city, the "Professions and Socio-professional categories" (PCS) have changed dramatically since the 1980s: between 1982 and 1999, the number of workers has declined by about a third (−10,593), their share of the active labour force was 16% in 1982 and 12.5% in 1999. The population of workers is concentrated in the southern suburbs close to the port and the industrial zone. At the same time the numbers of executives and intellectual professions increased by 24.5%, which is explained in part by the creation and development of the University of Le Havre. In 2009 the city had a lower proportion of managers and intellectual occupations than the national average (4.2% against 6.7%). The proportion of workers (15.9%) was one point higher than the national average. Going from 13.5% to 11.7% of the labour force, the rate of unemployment has decreased between 1999 and 2009. However, it remains higher than in the rest of the country. The proportion Le Havre people in short-term employment (CDD and interim work) is higher than the national average. Finally, the proportion of Le Havre people with a degree from higher education dramatically increased from about 21% in 1999 to 32.1% in 2009 against 24.5% for metropolitan France. However, this proportion has increased since 2009.
Education.
Schools.
Le Havre is located in the Academy of Rouen. The city operates 55 kindergartens (254 classes) and 49 communal primary schools (402 classes). The department manages 16 colleges and the region of Haute-Normandie manages 9 schools. The Jules Valles collage in Caucriauville is classified as a "sensitive institution" and eleven colleges are in a priority education zone (ZEP). A "boarding school of excellence", the Claude Bernard college, opened in 2011. The first college in Le Havre dates to the 16th century, the high school François I was founded during the Second Empire and is the oldest in Le Havre. The philosopher Jean-Paul Sartre (1905–1980) and Raymond Aron (1905–1983) taught there. The writer Armand Salacrou (1899–1989) studied in this institution.
List of Public Colleges in Le Havre
Private Colleges
List of Public Grammar Schools in Le Havre
Private Grammar Schools
Public Vocational Schools
Private Vocational Schools
Special schools and higher education.
In 2011 there were approximately 12,000 students in all disciplines in Le Havre. Opened in 1986, the University of Le Havre is recent, medium-sized and well located: the largest campus is virtually in the centre of the city near railway and tram stations. The campus includes a University Library (2006), a gym, several dining halls with student housing, a structure incorporating a theatre, an orientation service, and student associations. In 2010–2011, 6,914 students were enrolled including 5,071 undergraduates, 1,651 Masters students, and 192 postgraduate students. The university also trains 317 engineering students including the Logistical Studies Higher Education Institute (ISEL). It offers 120 Diplomas of State prepared by the Faculty of Science and Technology, Faculty of International Affairs, and the Faculty of Arts and Humanities. Many courses are offered are related to the port operations, logistics, industry, and sustainable development. Twelve languages are taught and 17% of students are foreigners. The University of Le Havre is also a research centre with nine laboratories. It works in partnership with other higher education institutions (INSA Rouen, IEP, IUFM, and Normandy University). The University Institutes of Technology of Le Havre occupies two main sites: one in the upper town in the Caucriauville-Rouelles district which was opened in 1967 and another in the Eure district since 2011. The IUT has a total of 1,881 students divided into ten departments preparing for the DUT. There is also a branch of the teacher training institute of Rouen (IUFM) for two courses (CAPET of technology and CRPE school teacher).
In addition there is a large number of specialized higher education institutions covering a wide range of different areas. Founded in 1871, the "Ecole Superieure de Commerce du Havre", one of the oldest in France, has merged with "Sup Europe" and "l'IPER" to create the "Normandy Management School" in 2006. This School had over 2,000 students on its three campuses (Le Havre, Caen and Deauville) in 2011. Since the 2007 school year, the Institute of Political Studies of Paris opened a Euro-Asia cycle in Le Havre. The "National School of The Merchant Marine" trains Officers of the First Class for the Merchant Marine: currently located at Sainte-Adresse, it will move to the "Bassin Vauban" in 2015 in a building that will house 1,000 students. The National Higher School of Petrol and Motors (ENSPM) is a school for specialist petroleum engineers, petrochemists, and engine makers. The ITIP (National Institute for International Transportation and Ports) prepares students for careers in the multimodal transport and port business. The (Institut national des sciences appliquées|National Institute of Applied Sciences of Rouen) (INSA) opened a branch in Le Havre in 2008 with a civil engineering and sustainable construction department. The SPI (Axis of Science for the Engineer) is expected to reopen in 2012 in a new building in the Eure district.
In the arts, the Conservatory of Departmental Radiance Arthur Honegger is attended by 1,680 students (music, dance and drama). The "Graduate School of Art of Le Havre" (ESAH) offers several degrees and preparation for competition. Finally 800 people study in paramedical and social schools mostly in the IFSI (Institute of Training in Nursing) which has approximately 600 students.
Sports.
The city of Le Havre has some of the oldest sports clubs in France: the "Le Havre Rowing Society" (1838), the "Regatta Society of Le Havre" (1838), and "Le Havre Athletic Club" (1872), doyen of French football and rugby clubs.
The city also hosted the sailing events for the 1900 and 1924 Summer Olympics, respectively.
Le Havre is dominated by three professional sports teams: the first is the Le Havre AC football team who played in Ligue 1 for the last time in 2008–2009 and is currently in Ligue 2. Its training centre, which is well-reputed for having trained international French players Vikash Dhorasoo, Julien Faubert, Jean-Alain Boumsong, Lassana Diarra, and also Steve Mandanda who is consistently ranked in the top ten in France. The second major sports team is Saint Thomas Basketball who represent the city in LNB Pro A. Thirdly the HAC women's team who play in the first division with many international players in its ranks. The team won their first major national title, the Coupe de France for women's handball in 2006. "Le Havre Rugby athletic club" plays in Fédérale 3 (equivalent to 5th division). The Hockey Club of Le Havre played at the fourth level nationally (Division 3) for the 2008–2009 season. The team is nicknamed the "Dock's du Havre".
The maritime side of the city is found in many sports: for example, the tradition of sailing is old. On 29 July 1840 the first French pleasure boat regatta was held. Today, Le Havre is known as a water sports and Seaside resort. The marina can host deepwater vessels around the clock in any weather. Built in the Interwar period, it is now the largest in Seine-Maritime with about 1,300 moorings additional moorings were installed in the Vauban basin in 2011–2012. The "Havraise Rowing Society" has trained many rowers to a high level as Thierry Renault. The "Club Nautique Le Havrais" (CNH) is the centre of mixed swimming, synchronized swimming, and men's water polo. The "Centre Nautique Paul Vatine" is the fifth largest club in the country for the number of sports licenses it holds; it ranks second in the Division 1 of the Championship France for Catamaran Clubs.
Several major local sportsmen began their career at Le Havre: the swimmer Hugues Duboscq was an Olympic medallist several times. In judo the French team has two members from Le Havre: Dimitri Dragin and Baptiste Leroy. Jerome Le Banner is a professional kick-boxer at world level who participates in the K-1 championship. Finally the navigator Paul Vatine, who was lost at sea in 1999, won the Transat Jacques Vabre several times.
Sports facilities.
The city has 99 sports facilities including 46 gymnasiums, 23 sports fields, and 5 swimming pools. The Stade Océane (Ocean Stadium), inaugurated in July 2012, replaced the Stade Jules Deschaseaux. With 25,000 seats, it can host football matches as well as other sporting and cultural events. Basketball and Handball matches are playued in the Dock Océane hall (3600 seats) while ice hockey is played at the ice hockey rink (900 seats). Of the five swimming pools in the city, two are operated by the municipality: the CNH (which has an Olympic pool for competitions) and Les Bains Des Docks (which was designed by the architect Jean Nouvel). Le Havre has the largest free outdoor skatepark in France with approximately 7,000 m2 allocated to the urban Boardsport. The port infrastructure allows for many water activities such as sailing, fishing, canoeing, and rowing. Finally, the beach is a place for kitesurfing, windsurfing and surfing.
Sporting Events.
Le Havre has been and is still the venue of major sports events: the Tour de France has passed a dozen times by the Ocean Gate, the last stage took place here in 1995. Sailing events are often held and the Transat Jacques Vabre transatlantic race has been held every two years since 1993 linking Le Havre to Latin America. The course of the Solitaire du Figaro was partly in Le Havre in 2010. Since 2006, weekends of freestyle board sports have been popular (skateboarding, rollerblading, funboard, kiteboarding, skydiving etc.). Every summer roller blade events are organized in the city on Friday evening every fortnight and have great success. The first International Triathlon was held in 2012. Finally, there are several opportunities for runners with ten kilometres (10 km) in Le Havre or the strides of Montgeon.
Media.
Five newspapers cover the Le Havre agglomeration: the dailies "Le Havre libre", "Le Havre Presse", "Paris Normandie" in its Le Havre edition in collaboration with "Le Havre Presse" and "Liberté-Dimanche" (communal Sunday edition of the previous three) are part of the Hersant group which is currently in serious financial trouble and looking for a buyer. A free weekly of information, "Le Havre Infos" (PubliHebdo group) has been published since 2010 every Wednesday and is available in many places in the city.
Several magazines provide local information: "LH Océanes" (Municipal magazine) and "Terres d'Agglo" (Agglomeration Area magazine) to which must be added several free magazines: "Aux Arts" (cultural information more focused on the Basse-Normandie region) "Bazart" (cultural events in Le Havre but now with circulation across all of Normandy), and "HAC Magazine" (news about HAC). Several newspapers are also available on the Internet: Infocéane, Le Havre on the Internet.
A local televised edition on France 3, "France 3 Baie de Seine", is broadcast every evening then again on "France 3 Haute Normandie". "Radio Albatros" is a local station installed in the Sanvic du Havre district transmitting on FM frequency 88.2. "Radio Vallée de la Lézarde", based in Épouville, "RESONANCE" on 98.9, and "RCF Le Havre" are other radio stations. It was in Le Havre radio stations that the journalist and television host Laurent Ruquier, who was born in Le Havre in 1963, began his career. Several national and regional radio stations are relays for Le Havre: local information on "France Bleu Haute Normandie", local relay from 12 noon to 4pm on "Virgin radio Normandie 101.8 FM", local relay for Information from 6am to 9am and from 4pm to 8pm on "NRJ Le Havre 92.5 FM". Associations like "LHnouslanuit" and "Only-Hit" have tried to develop alternative and cultural local radio by featuring local community associations (Papa's Production, Ben Salad Prod, Asso6Sons, Agend'Havre, Pied Nu, I Love LH).
Religion.
At the request of Monsigneur André Mulch, Archbishop of Rouen, Pope Paul VI decided on 6 July 1974 through the papal bull "Quae Sacrosanctum" on the creation of the diocese of Le Havre ("Portus Gratiae" in Latin meaning "Port of Grace"). The diocese was created from part of the parishes of the Archdiocese of Rouen to the west of a line joining Norville to Sassetot-le-Mauconduit. Monseigneur Michel Saudreau, its first bishop, was ordained on 22 September 1974. The church of Notre Dame was promoted to Cathedral Notre Dame du Havre. Today, the commune of Le Havre is divided into eight parishes and 24 places of worship (churches and chapels). The oldest chapel is Saint-Michel d'Ingouville which dates back to the 11th century. The Church of Saint Joseph du Havre, built by Auguste Perret, dominates the city with its spire 107m high. There are several monastic establishments (Carmel of the Transfiguration, Franciscan Monastery, Little Sisters of the Poor, etc.).
The Protestant Church of Le Havre was built in the city centre in 1862. Bombed in 1941, it lost its pediment, its bell tower, and roof. Rebuilt in 1953 by the architects Jacques Lamy and Gérard Dupasquier, who worked in the Auguste Perret office, is the only building in Le Havre uniting the original architecture of the 19th century with the architecture of the Perret school. Le Havre also has seven evangelical Protestant churches: "Salvation Army", "Seventh Day Adventist", "Apostolic Church", "Assembly of God", "Baptist Church", "Good News Church", et "Church of Le Havre" as well as several Protestant churches of African origin.
The city also has seven Muslim places of worship: the socio-cultural association of Muslims in Upper Normandy, En-Nour Mosque on Rue Paul Claudel, El Fath Mosque on rue Victor Hugo, Bellevue mosque on rue Gustavus Brindeau, and three prayer rooms located on rue Audran, Boulevard Jules Durant, and rue Lodi. The synagogue, located in the rebuilt central city, was visited by President Jacques Chirac in April 2002. It is the seat of the "association consistoriale israélite du Havre" whose president is Victor Elgressy.
Economy.
General.
In 2006 the median household income tax was 14,667 euros, which put Le Havre at 22,251th place among the 30,687 communes of more than 50 households in France. Although well developed and diversified, the local economy relies heavily on industrial sites, international groups, and subcontracted SMEs. The Le Havre economy is far from decision centres which are located mainly in Paris and major European economic cities. There is therefore a low representation of head offices in the city with the exception of some local economic successes such as the Sidel Group (now a subsidiary of Tetra Pak) – a distributor of interior furniture, and the ship-owner Delmas which was recently acquired by the CMA-CGM group.
Port.
With 68.6 million tons of cargo in 2011, the port of Le Havre is the second largest French seaport in trade volume behind that of Marseille and 50th largest port in the world. It represents 60% of total French container traffic with nearly 2.2 million Twenty-foot equivalent unit|EVP]s in 2011. At the European level, it is 8th largest for container traffic and 6th largest for total traffic. The Port receives a large number of oil tankers that transported 27.5 million tonnes of crude oil and 11.7 million tonnes of refined product in 2011. Finally, 340,500 vehicles passed through the Roll-on/roll-off terminal in 2010. 75 regular shipping lines serve 500 ports around the world. The largest trading partner of the port of Le Havre is the Asian continent which alone accounts for 58% of imports by container and 39.6% of exports. The rest of the traffic is distributed mainly to Europe and America.
Le Havre occupies the north bank of the estuary of the Seine on the Channel. Its location is favourable for several reasons: it is on the most frequented waterway in the world; it is the first and last port in the "North Range" of European ports – the largest in Europe which handles a quarter of all global maritime trade. As a deepwater port, it is accessible to all types of ships whatever their size around the clock. At the national level, Le Havre is 200 km west of the most populous and richest region in France: Île-de-France. Since its founding in 1517 on the orders of François I, Le Havre has continued to grow: today it measures 27 km from east to west, about 5 km from north to south with an area of 10000 ha. The last big project called Port 2000 increased the handling capacity for containers.
The port provides 16,000 direct jobs to the Le Havre region, to which must be added indirect jobs in industry and transport. With approximately 3,000 employees in 2006, the activities of distribution and warehousing provide more jobs, followed by road transport (2,420 jobs) and handling (2,319 jobs).
In 2011, 715,279 passengers passed through the port of Le Havre and there were 95 visits by cruise ships carrying 185,000 passengers. The port expects 110 cuise ship calls in 2012. Created in 1934, the leisure boat harbour of Le Havre is located to the west and is the largest French boat harbour in the Channel with a capacity of 1,160 moorings. Finally, there is a small fishing port in the Saint-François district and a Hawker centre.
Industry.
Most industries are located in the industrial-port area north of the estuary and east of the city of Le Havre. The largest industrial employer (2,400 employees) of the Le Havre region is the Renault public company in the commune of Sandouville. The second important sector for the industrial zone is petrochemicals. The Le Havre region has more than a third of French refining capacity. It provides about 50% of the production of basic plastics and 80% of additives and oils with more than 3,500 researchers working in private and public laboratories. Large firms in the chemical industry are mainly in the communes of Le Havre (Millenium Chemicals Le Havre), Montivilliers (Total S.A., Yara, Chevron Oronite SA, Lanxess, etc.) and Sandouville (Goodyear Chemicals Europe). A total of 28 industrial establishments manufacture plastics in the Le Havre area many of which are classed as SECESO. 
There are several firms in the aerospace industry: the Aircelle-Safran Group, a sub-contractor of Airbus making with thrust reversers, is located in Harfleur and employs 1,200 people from the Le Havre area. Finally, Dresser-Rand SA manufactures equipment for the oil and gas industry and employs about 700 people. In the energy field, the "EDF thermal power plant" of Le Havre has an installed capacity of 1,450MW and operates using coal with 357 employees. The AREVA group announced the opening of a factory for building wind turbines: installed in the port of Le Havre, it should create some 1,800 jobs. The machines are designed for Offshore wind power in Brittany, the UK, and Normandy.
Other industries are dispersed throughout the Le Havre agglomeration: the "Brûlerie du Havre", which belongs to Legal-Legoût, located in the district of Dollemard that roasts coffee, Sidel located both in the industrial area of Port of Le Havre and Octeville-sur-Mer designs and manufactures blow moulding machines and complete filling line machines for plastic bottles.
Services sector.
The two largest employers in the service sector are the "Groupe Hospitalier du Havre" with 4,384 staff and the "City of Le Havre" with 3,467 permanent employees. The city has long been home to many service companies whose activity is related to port operations: primarily the ship-owning companies and also the marine insurance companies. The headquarters of Delmas (transport and communications, 1,200 employees) and SPB (Provident Society Banking, insurance, 500 employees) have settled recently at the entrance to the city. The head office of Groupama Transport (300 employees) is also present.
The transport sector is the largest economic sector in Le Havre with 15.5% of employment. Logistics occupies a large part of the population and the ISEL trains engineers in this field. Since September 2007 the ICC has welcomed local students in their first year in the relocated Europe-Asia campus of the Institute of Political Studies of Paris. Higher Education is represented by the University of Le Havre which employs 399 permanent professors and 850 lecturers as well as by engineering companies like Auxitec and SERO.
There are many growth factors in the tourist industry: blue flag rating, World Heritage status from UNESCO, the label "French Towns and Lands of Art and History", cruise ship development, a policy of value-creation from heritage, and the "City of the Sea" project. In early 2010 the city had 22 hotels with a total of 1,064 rooms.
Le Havre is the seat of the Chamber of Commerce and Industry of Le Havre. It manages the Le Havre Octeville Airport.
Culture.
Cultural events and festivals.
Le Havre's festival calendar is punctuated by a wide range of events.
In spring a "Children's Book Festival" was recently created. In May there is the "Fest Yves", a Breton festival in the Saint-François district. On the beach of Le Havre and Sainte-Adresse there is a jazz festival called "Dixie Days" in June. In July, detective novels are featured in the Polar room at the Beach hosted by "The Black Anchors". Between the latter also in the context of "Z'Estivales" is an event offering many shows of street art throughout the summer supplemented by the festival of world music "MoZaïques" at the fort of Sainte-Adresse in August since 2010. In mid-August there is a Flower parade which passes through the streets of the central city.
In the first weekend of September the marine element is highlighted in the "Festival of the Sea". This is a race between Le Havre and Bahia in Brazil. Also every November there is a fair held in the Docks Café. The Autumn Festival in Normandy, organized by the departments of Seine-Maritime and Eure, and the Region of Haute-Normandie, runs from September to November and offers numerous concerts throughout the region as well as theatre performances and dance. In late October, since 2009, there is rock music festival which has been at the fort of Tourneville since the moving of the "Papa's Production" association site there. The West Park Festival, after its inauguration in 2004, has been held in the park of the town hall of Harfleur.
Since 1 June 2006 a "Biennale of contemporary Art" has been organized by the group "Partouche".
Cultural heritage and architecture.
Many buildings in the city are classified as "historical monuments", but the 2000s marked the real recognition of Le Havre's architectural heritage. The city received the label "City of Art and History" in 2001, then in 2005 UNESCO inscribed the city of Le Havre as a World Heritage Site.
The oldest building still standing in Le Havre is the Graville Abbey. The other medieval building in the city is the Chapel of Saint-Michel of Ingouville. Because of the bombing in 1944, heritage from the modern era is rare: "Le Havre Cathedral", the "Church of Saint Francis", the "Museum of the Hotel Dubocage of Bleville", the "House of the ship-owner" and the old palace of justice (now the "Natural History Museum") are concentrated in the Notre-Dame and Saint-François areas. The buildings of the 19th century testify to the maritime and military vocations of the city: the "Hanging Gardens", the "Fort of Tourneville", "Vauban docks", and the "Maritime Villa". The heritage of the 1950s and 1960s which were the work of the Auguste Perret workshop forms the most coherent architecture: the "Church of Saint Francis" and the Town Hall are the centrepieces. The all curved architecture of the "Volcano", designed by Oscar Niemeyer, contrasts with that of the rebuilt centre. Finally, the reconstruction of many districts is a showcase for the architecture of the 21st century. Among the achievements by renowned architects are the Chamber of Commerce and Industry (René and Phine Weeke Dottelond), Les Bains Des Docks (Jean Nouvel).
Museums.
Five Museums in Le Havre have the distinction of being classified as "Musées de France" (Museums of France) an official label granted only to museums of a high status. The five museums are:
The most important of the five, Museum Malraux was built in 1955 by the Atelier LWD and was opened in 1961 by André Malraux. This museum houses a collection of art from the late Middle Ages until the 20th century. The impressionist paintings collections are the second most extensive in France after those of the Orsay Museum in Paris. The museum houses some paintings of Claude Monet, Auguste Renoir, Raoul Dufy, Edgar Degas... I.
A Museum dedicated to the history of Le Havre with many objects from the Ancien Régime and the 19th century: furniture, old maps, statues, and paintings.
Founded in 1881 but heavily damaged during World War II, the Museum of Natural History is housed in Le Havre’s former law courts, built in the mid-18th century; the façade and monumental staircase are listed as historical monuments. The museum houses mineralogy, zoology, ornithology, palaeontology and prehistory departments as well as 8,000 early 19th-century paintings from the collection of local naturalist and traveller Charles-Alexandre Lesueur (1778–1846). The museum was destroyed during Allied bombings on 5 September 1944. The library was lost, along with its collections of photographs, scientific instruments and archives. The mineral and geological collections were all destroyed, including a rare collection of local mineral specimens of Normandy. The destruction of the museum was so intense, that all the catalogues, lists of donations, lists of purchases and other archives prevented even a precise inventory of all that was lost."
From the 18th century; like the Museum of Old Havre it is dedicated to the History of Le Havre and contains many relics from the Ancien Régime as well as furniture, old maps, statues, and paintings.
The Museum at the Priory of Graville displays many items of religious art including statues, madonnas, and other religious objects many of which are classified by the Ministry of Culture. It also houses the Gosselin collection of 206 model houses created by Jules Gosselin in the 19th century.
Other less important museums reflect the history of Le Havre and its maritime vocation. The "apartment-control" (Apartement-Temoine) was a standard apartment designed by in 1947–1950 and shows a place of daily life in the 1950s. The maritime museum displays objects related to the sea and the port. Finally, there are numerous exhibitions in the city such as the "SPOT", a centre for contemporary art, art galleries, and "Le Portique" – a contemporary art space opened in 2008; the municipal library of Le Havre regularly organizes exhibitions.
Other attractions include:
Theatres, auditoriums and concerts.
There are two main cultural axes in Le Havre: the central city and the Eure district. The "Espace Oscar Niemeyer" consists of a part of the "Great Volcano", a national theatre seating 1,093 (which houses the "National Choreographic Centre" of Le Havre Haute-Normandie directed by Hervé Robbe) and secondly the "Little Volcano" with a 250-seat multi-purpose hall for live performances. The whole "Espace Oscar Niemeyer" has been worked on since 2011: the "little volcano" will be transformed into a multimedia library. As for the performances at the "Great Volcano", they are now taking place in the old ferry terminal until the end of construction. Other cultural institutions of the city centre are being transformed: the cinema of art and a trial of "Le Sirius" facing the University will reopen in 2013. "Le Tetris" at the fort of Tourneville will, in 2013, be a place devoted to contemporary music. Other cultural venues are scattered in the city centre: the cinema "Le Studio", the theatre of the City Hall (700 seats), the "Little Theatre" (450 seats), the "Théâtre des Bains Douches" (94 seats), "Akté theatre" (60 seats), and the "Poulailler" (Henhouse)) (associative theatre with 50 seats) host numerous shows each year. The National Choreographic Centre of Le Havre Haute-Normandie specialises in the creation and production of dance shows. Other shows and performances are given in other places and at the Conservatory Arthur Honegger.
The second cultural centre of the city is in the Eure district near the Basin Vauban. Docks Océane is a multi-purpose hall (concerts, shows, and sporting events) which can accommodate up to 4,700 spectators in 1800 m2. The largest cinema in Le Havre is located on the Docks Vauban (2,430 seats). The Docks Café is an exhibition centre of 17500 m2 used for shows, fairs, and exhibitions. The "Magic Mirrors" offers many concerts managed by the city and leased to private organizers.
Following the closure of "Cabaret Electric" which was located in the "Espace Oscar Niemeyer" in 2011 a new auditorium, "Le Tetris", is under construction at the Fort of Tourneville. It will open in September 2013 with a large festival free-of-charge. It will consist of two halls with 800 and 200 seats, exhibition space, housing for artists in residence, a restaurant etc. "Le Tetris" will be a venue for contemporary music as well as theatre, dance, and visual arts. An "expectation" outside the walls was held on the site of the fort during 2012 and early 2013. 
Libraries and Archives.
The main library is located in the city centre, named after the writer Armand Salacrou. It has branches in all districts. A new multimedia library at the "Volcano" is being refurbished for 2014. Thousands of references are available in specialized libraries in the Higher School of Art, the Museum of André Malraux, and the Natural History Museum. Of medieval manuscripts and Incunables are conserved at the public library. The archives of the city, at the Fort of Tourneville, possesses documents from the 16th to the 20th centuries.
Le Havre in Visual Arts.
The Port of Le Havre and the light on the estuary of the Seine inspired many painters: Louis-Philippe Crepin (1772–1851), Jean-Baptiste Corot (1796–1875), Eugène Isabey (1803–1886), Theodore Gudin (1802–1880), Adolphe-Felix Cals (1810–1880), Jean-François Millet (1814–1875) in 1845, Gustave Courbet (1819–1877) etc.. It is to Eugène Boudin (1824–1898) who created many representations of Le Havre in the 19th century. The artist lived for a time in the city. Thanks to its proximity to Honfleur, Le Havre was also represented by foreign artists such as William Turner, Johan Barthold Jongkind, Alfred Stevens, and Richard Parkes Bonington.
Claude Monet (1840–1926), a resident of Le Havre from the age of five, in 1872 painted "Impression soleil levant" (Impression, Sunrise), a painting that gave its name to the impressionist movement. In 1867–1868, he painted many seascapes in the of Le Havre region ("Terrasse a Sainte-Adresse" (Garden at Sainte-Adresse), 1867 "Bateaux quittant le port" (Boats Leaving the Port), 1874). The Musée Malraux houses some of his paintings : Waterlilies, London Parliament et Winter Sun at Lavacourt. Two other Impressionists, Camille Pissarro (1830–1903) and Maxime Maufra (1861–1918) also represented the port of Le Havre which also inspired Paul Signac (1863–1935), Albert Marquet (1875–1947), and Maurice de Vlaminck (1876–1958).
Then came the school of Fauvism in which many artists did their training at Le Havre: Othon Friesz (1879–1949), Henri de Saint-Delis (1876–1958), Raoul Dufy (1877–1953), Georges Braque (1882–1963), Raymond Lecourt (1882–1946), Albert Copieux (1885–1956), who followed the course of the "School of Fine Arts of Le Havre" in the time of Charles Lhuillier. They left a number of paintings on the theme of the city and the port. In 1899, Henri de Toulouse-Lautrec (1864–1901) painted "La serveuse anglaise du Star" (The English waitress of Star) (Museum Toulouse-Lautrec, Albi) of a girl he met in a bar in the city.
Other painters who painted Le Havre and/or its surroundings such as Sainte-Adresse can be cited in particular: Frédéric Bazille, John Gendall, Thomas Couture, Ambroise Louis Garneray, Pablo Picasso ("Souvenir du Havre"). Jean Dubuffet studied at the School of Art in Le Havre.
Cinema.
With nearly 70 films, Le Havre is one of the provincial cities most represented in the cinema. Several directors have chosen the port facilities as part of their movie:
The city has also hosted the filming of several comedies such as:
The film by Sophie Marceau, "La Disparue de Deauville", made in 2007, contains many scenes around the port of Le Havre, in the Coty shopping centre of Coty and in the streets of the central city.
The film "Le Havre" by Aki Kaurismaki received two prizes at the 2011 Cannes Film Festival and also the Louis Delluc Prize. It was nominated three times for the 37th César Awards.
Literature.
Le Havre appears in several literary works as a point of departure to America: in the 18th century, Father Prevost embarked "Manon Lescaut" and "Des Grieux" for French Louisiana. Fanny Loviot departed from Le Havre in 1852, as an emigrant to San Francisco and points further west, and recounted her adventures in "Les pirates chinois" ("A Lady's Captivity among Chinese Pirates in the Chinese Seas", 1858).
In the 19th century, Le Havre was the setting for several French novels: Honoré de Balzac described the failure of a Le Havre merchant family in "Modeste Mignon". Later, the Norman writer Guy de Maupassant located several of his works at Le Havre such as "Au muséum d'histoire naturelle" (At the Museum of Natural History) a text published in "Le Gaulois" on 23 March 1881 and again in "Pierre et Jean". Alphonse Allais located his intrigues at Le Havre too. "La Bête humaine" (The Human Beast) by Émile Zola evokes the world of the railway and runs along the Paris-Le Havre railway. Streets, buildings, and public places in Le Havre pay tribute to other famous Le Havre people from this period: the writer Casimir Delavigne (1793–1843) has a street named after him and a statue in front of the palace of justice alongside another man of letters, Bernardin de Saint-Pierre (1737–1814).
In the 20th century, Henry Miller located part of the action in Le Havre in his masterpiece "Tropic of Cancer", published in 1934. Bouville was the commune where the writer lived who wrote his diary in "La Nausée" (The Nausea) (1938) by Jean-Paul Sartre who was inspired by Le Havre city where he wrote his first novel. There are also the testimonies of Raymond Queneau (1903–1976), born in Le Havre, the city served as a framework for his novel "Un rude hiver" (A harsh winter) (1939). The plot of "Une maison soufflée aux vents" (A house blown to the winds) by Emile Danoën, winner of the Popular Novel Prize in 1951, and its sequel "Idylle dans un quartier muré" (Idyll in a walled neighbourhood) were located in Le Havre during the Second World War. Under the name "Port de Brume" Le Havre is the setting for three other novels by this author: "Cerfs-volants" (Kites), "L'Aventure de Noël" (The Adventure at Christmas), and "La Queue à la pègre" (Queue to the underworld). Michel Leiris wrote "De la littérature considérée comme une tauromachie" (Of literature considered like a bullfight) in December 1945.
Two mystery novels take place in Le Havre: "Le Bilan Maletras" (The Maletras Balance) by Georges Simenon and "Le Crime de Rouletabille" (Crime at the Roulette table) by Gaston Leroux. In "Rouge Brésil" (Red Brazil), winner of the Goncourt Prize in 2001, Jean-Christophe Rufin describes Le Havre in the 16th century as the port of departure of French expeditions to the New World: the hero Villegagnon leaves of the port to conquer new lands for the French crown which become Brazil. Martine–Marie Muller tells the saga of a clan of Stevedores from Le Havre in the 1950s to the 1970s in "Quai des Amériques" (Quay of the Americas).
Benoît Duteurtre published in 2001, "Le Voyage en France" (Travel in France), for which he received the Prix Médicis: the main character, a young American impassioned by France, lands at Le Havre which he describes in the first part of the novel. In 2008, Benoît Duteurtre publishes "Les pieds dans l'eau" (Feet in the water), a highly autobiographical book in which he describes his youth spent between Le Havre and Etretat. The city hosted writers such as Emile Danoën (1920–1999) who grew up in the district of Saint-François, Yoland Simon (born 1941), and Philippe Huet (born 1955). Canadian poet Octave Crémazie (1827–1879) died at Le Havre and was buried in Saint Marie Cemetery. The playwright Jacques-François Ancelot (1794–1854) was also a native of Le Havre. Two famous historians, Gabriel Monod (1844–1912) and André Siegfried (1875–1959) were from the city.
Le Havre also appears in comic books: for example, in "L'Oreille cassée" (The Broken Ear) (1937), Tintin embarks on the vessel "City of Lyon" sailing to South America. The meeting between Tintin and General Alcazar in "Les Sept Boules de cristal" (The Seven Crystal Balls) (1948) is in Le Havre, according to notes by Hergé in the margins of Le Soir, the first publisher of this adventure. The first adventure of Ric Hochet (1963), the designer Tibet and André-Paul Duchâteau, "Traquenard au Havre" (Trap at Le Havre) shows the seaside and the port. Similarly, in 1967, for the album "Rapt sur le France" (Rapt on France), the hero passes by the ocean port. Frank Le Gall, in "Novembre toute l'année" (November all year) (2000) embarks Theodore Poussin at Le Havre on the "Cap Padaran".
Music.
Le Havre is the birthplace of many musicians and composers such as Henri Woollett (1864–1936), André Caplet (1878–1925) and Arthur Honegger (1892–1955). There was also Victor Mustel (1815–1890) who was famous for having perfected the harmonium.
Le Havre has long been regarded as one of the cradles of French rock and blues. In the 1980s many groups have emerged after a first dynamic development in the 1960s and 1970s. The most famous personality of Le Havre rock is "Little Bob" who began his career in the 1970s. The port tradition in many of the groups was repeated in the unused sheds of the port, such as Bovis hall which could hold 20,000 spectators. A blues festival, driven by Jean-François Skrobek, Blues a Gogo existed for eight years from 1995 to 2002. Several artists have been produced such as: Youssou N'Dour, Popa Chubby, Amadou & Mariam, Patrick Verbeke etc. It was organized by the Coup de Bleu association whose former president was head of music Café "L'Agora" in the Niemeyer Centre which produced the new Le Havre scene. During these same years, the "Festival of the Future", the local version of the "Fête de l'Humanité" (Festival of Humanity), attracted a large audience while at the same time the municipality organized "June in the street" which attracted artists such as Michel Fugain, Jimmy Cliff, Gilberto Gil, Johnny Clegg, Eddy Mitchell, etc.
Le Havre has a musical history closely linked to rock, Little Bob is a local rock star with his band. Like all cities of this size, Le Havre sees many groups with styles ranging from punk to rock and through to heavy metal such as a group simply called "Les Havrais". Made up of young musicians, they are often short-lived. However, they have the opportunity to express themselves on stage in small parts of the city such as la Cafet, the Music Bar, or McDaid's pub. All one scene "hard" rock continues to evolve and learn with some success and evolving to a new hard rock linking with national and international groups who are invited to share the stage at Le Havre.
Currently, the musical tradition continues in the Symphony Orchestra of the city of Le Havre, the orchestra of Concerts André Caplet, the conservatory, and music schools such as the Centre for Vocal and Musical Expression (rock) or the JUPO (mainly jazz), associations or labels like Papa's Production (la Folie Ordinaire, Mob's et Travaux, Dominique Comont, Souinq, Your Happy End etc.). The organization by the association of West Park Festival since the 2000s in Harfleur and since 2004 at the Fort of Tourneville is a demonstration. Moreover, since 2008, the association "I Love LH" was started and promotes Le Havre culture and especially its music scene by organizing original cultural events as well as the free distribution of compilation music by local artists.
Rap is also relatively developed by Le Havre artists. After the success of Ness&Cité – first discovered of the Printemps de Bourges 2000, other groups were formed: "Bouchées Doubles", "Médine", and "La Boussole" comprised members of these groups. The majority of the rap scene in Le Havre is grouped on the Din Records label. Recently the group from the Mare Rouge "Original Section" consisting of Madsy and Alivor and is currently practicing with the participation of "Black List" compiled by beatmaker Havrais Dicé. Their first album was released in January 2012. In another rap record more middle working class on productions of soul, funk and reggae artists such as Def and Acoosmik and begin to talk about them outside the territory of the city.
The Norman language.
Main articles: Norman language and Cauchois dialect.
The legacy of the Norman language is present in the language used by the people of Le Havre, part of which is identified as speaking cauchois. Among the Norman words most used in Le Havre there are: "boujou" (hello, goodbye), "clenche" (door handle), "morveux (veuse)" (child), and bezot (te) (last born).
Notable People linked to Le Havre.
Le Havre was the birthplace of:
Further reading.
English
French

</doc>
<doc id="54006" url="http://en.wikipedia.org/wiki?curid=54006" title="Seine">
Seine

The Seine (; French: "La Seine", ]) is a 776 km long river and an important commercial waterway within the Paris Basin in the north of France. It rises at Source-Seine, 30 km northwest of Dijon in northeastern France in the Langres plateau, flowing through Paris and into the English Channel at Le Havre (and Honfleur on the left bank). It is navigable by ocean-going vessels as far as Rouen, 120 km from the sea. Over 60 percent of its length, as far as Burgundy, is negotiable by commercial riverboats and nearly its whole length is available for recreational boating; excursion boats offer sightseeing tours of the "Rive Droite" and "Rive Gauche" within the city of Paris.
There are 37 bridges within Paris and dozens more spanning the river outside the city. Examples in Paris include the Pont Louis-Philippe and Pont Neuf, the latter of which dates back to 1607. Outside the city, examples include the Pont de Normandie, one of the longest cable-stayed bridges in the world, which links Le Havre to Honfleur.
Origin of the name.
The name "Seine" comes from the Latin "Sequana". Some have argued that "Sicauna" is cognate to the name of Saône River. However, a suggested relationship to the River Shannon in Ireland is unlikely, given the very different forms of the two. (Gaelic "an tSiona", dative "Sionainn", is from Prehistoric Irish *Sinona. Another proposal has it that "Sequana" is the Latin version of the Gaulish "Issicauna" "Lower-Icauna", which would be the diminutive of "Icauna", which was the Gaulish name of the Yonne River.) Some believe the ancient Gauls considered the Seine to be a tributary of the Yonne, which indeed presents a greater average discharge than the Seine. (The river flowing through Paris would be called Yonne if the standard rules of geography were applied.)
Some identify the river Sikanos, origin (according to Thucydides) of the Sicanoi of Sikelia (Sicily), with the river Sequana (Seine).
According to Pierre-Yves Lambert, a specialist of the Gaulish language, "Sequana" retains QV [kʷ], that is unusual in Gaulish, which is normally a P-Celtic language, but he compares with the month name EQVOS, read on the Coligny Calendar. The name of the Gaulish tribe "Sequani" derives from it.
The digram QV of Sequana could recover a whole syllable, that is to say [se-ku-wa-na], like "ucuetis" [u-ku-we-tis], but its meaning remains unknown.
Source.
The Seine Source.
The source where the Seine rises, in the commune of Source-Seine, has been owned by the city of Paris since 1864. A number of closely associated small ditches/depressions provide the source waters, with an artificial grotta laid out to highlight and contain a deemed main source. The grotto includes a statue of a nymph. On the same site there still are the buried remains of a . Small statues of the "dea Sequana" "Seine goddess" and other "ex voti" found at the same place are now exhibited in the Dijon archeological museum.
The Seine course.
The Seine can artificially be divided into five parts :
Navigation.
The Seine is dredged and oceangoing vessels can dock at Rouen, 120 km from the sea. Commercial riverboats can use the river from Bar-sur-Seine, 560 km to its mouth. At Paris, there are 37 bridges. The river is only 24 m above sea level 446 km from its mouth, making it slow flowing and thus easily navigable.
The Seine Maritime, 105.7 km from the English Channel at Le Havre to Rouen, is the only portion of the Seine used by ocean-going craft. The tidal section of the Seine Maritime is followed by a canalized section with four large multiple locks until the mouth of the Oise River at Conflans-Sainte-Honorine. Multiple locks at Bougival / Chatou and at Suresnes lift the vessels to the level of the river in Paris, where the mouth of the Marne River is located. Upstream from Paris seven locks ensure navigation to Saint Mammès, where the Loing mouth is situated. Through an eighth lock the river Yonne is reached at Montereau-Fault-Yonne. From the mouth of the Yonne, larger ships can continue upstream to Nogent-sur-Seine. From there on, the river is navigable only by small craft. All navigation ends abruptly at Marcilly-sur-Seine, where the ancient Canal de la Haute-Seine used to allow vessels to continue all the way to Troyes. This canal has been abandoned for many years.
The average depth of the Seine today at Paris is about 9.5 m. Until locks were installed to raise the level in the 1800s, the river was much shallower within the city most of the time, and consisted of a small channel of continuous flow bordered by sandy banks (depicted in many illustrations of the period). Today the depth is tightly controlled and the entire width of the river between the built-up banks on either side is normally filled with water. The average flow of the river is very low, only a few cubic metres per second, but much higher flows are possible during periods of heavy runoff. Special reservoirs upstream help to maintain a constant level for the river through the city, but during periods of extreme runoff significant increases in river level may occur.
Flooding.
A very severe period of high water in January 1910 produced extensive flooding throughout the city. The Seine again rose to threatening levels in 1924, 1955, 1982 and 1999–2000. After a first-level flood alert in 2003, about 100,000 works of art were moved out of Paris, the largest relocation of art since World War II. Much of the art in Paris is kept in underground storage rooms that would have been flooded. A 2002 report by the French government stated the worst-case Seine flood scenario would cost 10 billion euros and cut telephone service for a million Parisians, leaving 200,000 without electricity and 100,000 without gas.
Watershed.
The basin area is 78910 km2, 2 percent of which is forest and 78 percent cultivated land. In addition to Paris, three other cities with a population over 100,000 are in the Seine watershed: Le Havre at the estuary, Rouen in the Seine valley and Rheims at the northern limit—with an annual urban growth rate of 0.2 percent. The population density is 201 per square kilometer.
Water quality.
Periodically the sewerage systems of Paris experience a failure known as sanitary sewer overflow, often in periods of high rainfall. Under these conditions untreated sewage has been discharged into the Seine. The resulting oxygen deficit is principally caused by allochthonous bacteria larger than one micrometre in size. The specific activity of these sewage bacteria is typically three to four times greater than that of the autochthonous (background) bacterial population. Heavy metal concentrations in the Seine are relatively high. The pH level of the Seine at Pont Neuf has been measured to be 8.46. Despite this, the water quality has improved significantly over what several historians at various times in the past called an "open sewer".
In 2009, it was announced that Atlantic salmon had returned to the Seine.
History.
After the burning at the stake of Joan of Arc in 1431, her ashes were thrown into the Seine from the medieval stone Mathilde Bridge at Rouen, though unserious counter-claims persist.
According to his will, Napoleon, who died in 1821, wished to be buried on the banks of the Seine. His request was not granted.
At the 1900 Summer Olympics, the river hosted the rowing, swimming, and water polo events. Twenty-four years later, it hosted the rowing events again at Bassin d'Argenteuil, along the Seine north of Paris.
Until the 1930s, a towing system using a chain on the bed of the river existed to facilitate movement of barges upriver.World Canals by Charles Hadfield, David and Charles 1986
The Seine River was one of the original objectives of Operation Overlord in 1944. The Allies' intention was to reach the Seine by 90 days after D-Day. That objective was met. An anticipated assault crossing of the river never materialized as German resistance in France crumbled by early September 1944. However, the First Canadian Army did encounter resistance immediately west of the Seine and fighting occurred in the Forêt de la Londe as Allied troops attempted to cut off the escape across the river of parts of the German 7th Army in the closing phases of the Battle of Normandy.
Some of the Algerian victims of the Paris massacre of 1961 drowned in the Seine after being thrown by French policemen from the Pont Saint-Michel and other locations in Paris.
Dredging in the 1960s mostly eliminated tidal bores on the lower river, known in French as "“le mascaret.”"
In 1991 UNESCO added the banks of the Seine in Paris—the "Rive Gauche" and "Rive Droite"—to its list of World Heritage Sites in Europe.
Since 2002 Paris-Plages has been held every summer on the Paris banks of the Seine: a transformation of the paved banks into a beach with sand and facilities for sunbathing and entertainment.
The river is a popular site for both suicides and the disposal of bodies of murder victims. In 2007, 55 bodies were retrieved from its waters; in February 2008, the body of supermodel-turned-activist Katoucha Niane was found there.
In art.
During the 19th and the 20th centuries in particular the Seine inspired many artists, including:
A song 'La seine' by Vanessa Paradis feat. Matthieu Chedid was originally written as a soundtrack for the movie 'A monster in Paris'

</doc>
<doc id="54009" url="http://en.wikipedia.org/wiki?curid=54009" title="Shill">
Shill

A shill, also called a plant or a stooge, is a person who publicly helps a person or organization without disclosing that they have a close relationship with the person or organization.
Shill typically refers to someone who purposely gives onlookers the impression that they are an enthusiastic independent customer of a seller (or marketer of ideas) for whom they are secretly working. The person or group who hires the shill is using crowd psychology to encourage other onlookers or audience members to purchase the goods or services (or accept the ideas being marketed). Shills are often employed by professional marketing campaigns. "Plant" and "stooge" more commonly refer to any person who is secretly in league with another person or organization while pretending to be neutral or actually a part of the organization he is planted in, such as a magician's audience, a political party, or an intelligence organization (see double agent).
Shilling is illegal in many circumstances and in many jurisdictions because of the potential for fraud and damage; however if a shill does not place uninformed parties at a risk of loss, but merely generates "buzz," the shill's actions may be legal. For example, a person planted in an audience to laugh and applaud when desired (see claque), or to participate in on-stage activities as a "random member of the audience," is a type of legal shill.
Shill can also be used pejoratively to describe a critic who appears either all-too-eager to heap glowing praise upon mediocre offerings, or who acts as an apologist for glaring flaws. In this sense, such a critic would be an indirect shill for the industry at large, because said critic's income is tied to the prosperity of the industry.
Etymology.
The origin of the term "shill" is uncertain; it may be an abbreviation of "shillaber." The word originally denoted a carnival worker who pretended to be a member of the audience in an attempt to elicit interest in an attraction. Some sources trace the usage back to 1914.
Internet.
In online discussion media, satisfied consumers or "innocent" parties may express specific opinions in order to further the interests of an organization in which they have an interest, such as a commercial vendor or special interest group. In academia, this is called "opinion spamming". Web sites can also be set up for the same purpose. For example, an employee of a company that produces a specific product might praise the product anonymously in a discussion forum or group in order to generate interest in that product, service, or group. In addition, some shills use "sock puppetry", where they sign on as one user soliciting recommendations for a specific product or service. They then sign on as a different user pretending to be a satisfied customer of a specific company.
In some jurisdictions and circumstances, this type of activity may be illegal. In addition, reputable organizations may prohibit their employees and other interested parties (contractors, agents, etc.) from participating in public forums or discussion groups in which a conflict of interest might arise, or will at least insist that their employees and agents refrain from participating in any way that might create a conflict of interest. For example, the plastic surgery company Lifestyle Lift ordered their employees to post fake positive reviews on websites. As a result, they were sued, and ordered to pay $300,000 in damages by the New York Attorney General's office. Said Attorney General Andrew Cuomo: "This company’s attempt to generate business by duping consumers was cynical, manipulative, and illegal. My office has [been] and will continue to be on the forefront in protecting consumers against emerging fraud and deception, including 'astroturfing,' on the Internet."
Gambling.
Both the illegal and legal gambling industries often use shills to make winning at games appear more likely than it actually is. For example, illegal three-card monte and shell-game peddlers are notorious employers of shills. These shills also often aid in cheating, disrupting the game if the "mark" is likely to win. In a legal casino, however, a shill is sometimes a gambler who plays using the casino's money in order to keep games (especially poker) going when there are not enough players. The title of one of Erle Stanley Gardner's mystery novels, "Shills Can't Cash Chips", is derived from this type of shill. This is different from "proposition players" who are paid a salary by the casino for the same purpose, but bet with their own money.
Marketing.
In marketing, shills are often employed to assume the air of satisfied customers and give testimonials to the merits of a given product. This type of shilling is illegal in some jurisdictions but almost impossible to detect. It may be considered a form of unjust enrichment or unfair competition, as in California's Business & Professions Code § 17200, which prohibits any "unfair or fraudulent business act or practice and unfair, deceptive, untrue or misleading advertising."
Radio stations will often have shills (usually front office employees or relative) in the crowd at remote appearances and it is they who will "win" the big prizes (concert tickets, expensive jewelry) while the listeners who show up win nothing.
Auctions.
Shills, or "potted plants", are sometimes employed in auctions. Driving prices up with phony bids, they seek to provoke a bidding war among other participants. Often they are told by the seller precisely how high to bid, as the seller actually pays the price (to himself, of course) if the item does not sell, losing only the auction fees. Shilling has a substantially higher rate of occurrence in online auctions, where any user with multiple accounts can bid on their own items. One detailed example of this has been documented in online auctions for used cars. Many online auction sites employ sophisticated (and usually secret) methods to detect collusion. The online auction site eBay forbids shilling; its rules do not allow friends or employees of a person selling an item to bid on the item.
In his book "Fake: Forgery, Lies, & eBay", Kenneth Walton describes how he and his cohorts placed shill bids on hundreds of eBay auctions over the course of a year. Walton and his associates were charged and convicted of fraud by the United States Attorney for their eBay shill bidding.
With the proliferation of live online auctions in recent years shill bidding has become commonplace. Some websites allow shill bidding by participating auctioneers. These auctioneers are able to see bids placed in real time and can then place counter bids to increase the amount. One proxibid auctioneers' website states, "At the request of the auction company, this auction permits bids to be placed by the seller or on the seller's behalf, even if such bids are placed solely for the purpose of increasing the bid."
Journalism.
The term is applied metaphorically to journalists or commentators who have vested interests in or associations with parties in a controversial issue. Corporate-owned media outlets of radio and television are often accused of being shills for establishment political candidates. By limiting the dialogue and discourse between specific candidates and political parties, the media can psychologically limit choices in the public mind and thus assure that only politicians acceptable to the ruling class and corporate structure are elected to public office. By highlighting the disparities among each candidate, the media appears as an honest broker and fair-minded third party to the public, but is acting as a shill for the wealthy investment class. This methodology was one of Edward Bernays's favorite techniques for manipulating public opinion by the indirect use of "third-party authorities" to influence the public, without their conscious cooperation.
More specifically, there are historical cases of journalists in private media organizations being covert representatives of government and/or businesses. In these roles the journalists will present positive stories about their respective interests at key moments in order to influence public opinion. This is often achieved by claiming to have access to anonymous government or business sources. At other times, the links may actually appear overt to some, but not to the intended audience such as with Radio Free Europe, a broadcaster which targeted Eastern European audiences on behalf of the Central Intelligence Agency.
An extension of these tactics is the practice of monitoring news outlets prior to or during publication. Often when a negative story is discovered attempts are made first to stop it. However as this can, in some societies, draw attention to what could otherwise be a minor story, shills are used to put out alternative views, either to confuse the public about the legitimacy of the story or to outright convince them that it is a lie.
Research and experiments.
A shill in a psychology experiment, or the like, is called a '"confederate". In Stanley Milgram's experiment in which the subjects witnessed people getting electric shocks, a confederate would pretend to be one of the experimental subjects who would receive the fake shocks, so that the real experimental subject would think that a draw of names from a hat was random. The confederate would always play the role of the learner, and the subject would be the teacher, and the subject would think that this was a random draw from a hat containing papers that say "learner" and "teacher."
In performance art, such as DECONference (Decontamination Conference), the confederates were called "deconfederates". When a large group of DECONference attendees were asked to remove all clothing prior to entry to the event, the deconfederates, planted among the attendees, would comply immediately with the request, causing all of the others to follow the orders and disrobe as well.
Interrogations.
Police or military interrogators sometimes use undercover agents (called "plants") to assist with the interrogation of an individual or suspect. The plant can pose as a fellow inmate or internee, build a rapport and earn the confidence of the interviewee. The plant may subtly suggest that telling the interrogators what they want to know is the sensible or right thing to do. Even if no outright confessions are obtained, minor details and discrepancies that come out in supposedly innocent conversation can be used to chip away at the interviewee. Some plants are in reality inmates or prisoners of war who have been promised better treatment and conditions in return for helping with the interrogation; the character played by William Hurt in the film "Kiss of the Spider Woman "is an example of this. One notorious UK case is that of Colin Stagg, a man who was falsely accused of the murder of Rachel Nickell, in which a female police officer posed as a potential love interest to try to tempt Stagg to implicate himself.
Related concepts.
Puppet government.
Puppet, vassal, quisling, or satellite states have been routinely used in exercises of foreign policy to give weight to the arguments of the country that controls them. Examples of this include the USSR's use of its satellites in the United Nations during the Cold War. These states are also used to give the impression of legitimacy to domestic policies that are ultimately harmful to the population they control, while beneficial to the government that controls them.
Even outside the spectrum of sovereign powers many multiparty democratic systems give foreign powers the capacity to influence political discourse through shills and pseudo sock-puppets. Thanks to the reliance of many political parties on external sources of revenue for campaigns it can be easy for a government or business to either choose which party it funds or to outright create one. This way they can either choose to support existing minority voices that echo their views or form their own, using their funds and usually semi-covert influence to make them a more prominent voice.
Another concept in foreign policy is seen in sovereign alliances. In these instances, an allied country acts on behalf of another's interests so that it appears that the original power does not want to get involved. This is useful in situations where there is little public support in the original country for the actions. This type of collusion is typically practiced between countries that share common goals and are capable of returning favours. An example of this may be Cuba's role during the Cold War, in sending active combat troops to wars in Africa when it was unpalatable for the USSR to do so.
Undercover operations.
During covert operations or police investigations agents may routinely claim to be of political views or a part of an organisation in order to gain the confidence of the people they wish to surveil. Sometimes this goes further with the agents participating in acts on behalf of the organisations they infiltrate or falsely represent as was the case during the Operations like Gladio and Chaos. Often the end goal is not just to gain information about the organisation but to discredit them in the eyes of the public. However, these kinds of actions are more similar to False Flag Operations than typical Undercover Operations. In other examples, operatives may act in a manner they deem positive to assist an organisation to which they cannot have overt ties.
External links.
</dl>

</doc>
<doc id="54010" url="http://en.wikipedia.org/wiki?curid=54010" title="Sophus Lie">
Sophus Lie

Marius Sophus Lie ( ; ]; 17 December 1842 – 18 February 1899) was a Norwegian mathematician. He largely created the theory of continuous symmetry and applied it to the study of geometry and differential equations.
Biography.
His first mathematical work, "Repräsentation der Imaginären der Plangeometrie", was published, in 1869, by the Academy of Sciences in Christiania and also by "Crelle's Journal". That same year he received a scholarship and traveled to Berlin, where he stayed from September to February 1870. There, he met Felix Klein and they became close friends. When he left Berlin, Lie traveled to Paris, where he was joined by Klein two months later. There, they met Camille Jordan and Gaston Darboux. But on 19 July 1870 the Franco-Prussian War began and Klein (who was Prussian) had to leave France very quickly. Lie decided then to visit Luigi Cremona in Milan but he was arrested at Fontainebleau under suspicion of being a German spy, an event which made him famous in Norway. He was released from prison after a month, thanks to the intervention of Darboux.
Lie obtained his PhD at the University of Christiania (present day Oslo) in 1871 with a thesis entitled "On a class of geometric transformations". It would be described by Darboux as “one of the most handsome discoveries of modern Geometry”. The next year, the Norwegian Parliament established an extraordinary professorship for him. That same year, Lie visited Klein, who was then at Erlangen and working on the Erlangen program.
At the end of 1872, Sophus Lie proposed to Anna Birch, then eighteen years old, and they were married in 1874. The couple had three children: Marie (b. 1877), Dagny (b. 1880) and Herman (b. 1884).
In 1884, Friedrich Engel arrived at Christiania to help him, with the support of Klein and Adolph Mayer (who were both professors at Leipzig, by then). Engel would help Lie to write his most important treatise, "Theorie der Transformationsgruppen", published in Leipzig in three volumes from 1888 to 1893. Decades later, Engel would also be one of the two editors of Lie's collected works.
In 1886 Lie became professor at Leipzig, replacing Klein, who had moved to Göttingen. In November 1889, Lie suffered a mental breakdown and had to be hospitalized until June 1890. After that, he returned to his post, but over the years his anaemia progressed to the point where he decided to return to his homeland. Consequently, in 1898 he tendered his resignation in May, and left for home (for good) in September the same year. (He died in 1899.)
He was made Honorary Member of the London Mathematical Society in 1878, Member of the French Academy of Sciences in 1892, Foreign Member of the Royal Society of London in 1895 and foreign associate of the National Academy of Sciences of the United States of America in 1895.
Sophus Lie died at the age of 56, due to pernicious anemia, a disease caused by impaired absorption of vitamin B12.
Legacy.
Lie's principal tool, and one of his greatest achievements, was the discovery that continuous transformation groups (now called, after him, Lie groups) could be better understood by "linearizing" them, and studying the corresponding generating vector fields (the so-called infinitesimal generators). The generators are subject to a linearized version of the group law, now called the commutator bracket, and have the structure of what is today called a Lie algebra.
Hermann Weyl used Lie's work on group theory in his papers from 1922 and 1923, and Lie groups today play a role in quantum mechanics.
However, the subject of Lie groups as it is studied today is vastly different from what the research by Sophus Lie was about and “among the 19th century masters, Lie's work is "in detail" certainly the least known today”.

</doc>
<doc id="54012" url="http://en.wikipedia.org/wiki?curid=54012" title="1924 Winter Olympics">
1924 Winter Olympics

The 1924 Winter Olympics, officially known as the I Olympic Winter Games (French: Les "Iers Jeux olympiques d'hiver"), were a winter multi-sport event which was held in 1924 in Chamonix, France. Originally called "Semaine Internationale des Sports d'Hiver" ("International Winter Sports Week") and held in association with the 1924 Summer Olympics, the sports competitions were held at the foot of Mont Blanc in Chamonix, and Haute-Savoie, France between January 25 and February 5, 1924. The Games were organized by the French Olympic Committee, and were in retrospect designated by the International Olympic Committee (IOC) as the I Olympic Winter Games.
The tradition of holding the Winter Olympics in the same year as the Summer Olympics would continue until 1992, after which the current practice of holding a Winter Olympics in the second year after each Summer Olympics began.
Although Figure Skating had been an Olympic event in both London and Antwerp, and Ice Hockey had been an event in Antwerp, the winter sports had always been limited by the season. In 1921, at the convention of the IOC in Lausanne, there was a call for equality for winter sports, and after much discussion it was decided to organize an "international week of winter sport" in 1924 in Chamonix.
Highlights.
Day 2.
The first gold medal awarded in the Olympic Winter games was won by Charles Jewtraw of the United States in
the 500-meter speed skate.
Day 4.
Sonja Henie, at just eleven years old, skates in the ladies' figure skating competition. Although she finishes last, she becomes popular with fans, and will take the gold at the next three Winter Olympics.
Day 6.
Finding himself in a unique situation, the figure skater Gillis Grafström is the first one ever to successfully defend his Summer Olympics title at the Winter Olympics.
Day 8.
The Canadian ice-hockey team finished their qualifying round with 3 wins, scoring a total of 85 goals against Switzerland, Czechoslovakia, and Sweden without surrendering even a single goal against.
Day 10.
Finding themselves in the same situation as Gillis Grafström, the Canadian ice-hockey team is the last ever to successfully defend its Summer Olympics title at the Winter Olympics. Canada would dominate ice hockey in early Olympic competition, winning six of the first seven gold medals awarded.
Epilogue.
At the closing of the games a prize was awarded for a sport that did not lend itself very well for tournaments: Pierre de Coubertin presented a prize for 'alpinisme' (mountaineering) to Charles Granville Bruce, the leader of the expedition that tried to climb Mount Everest in 1922. 
For the first time in the history of the modern Olympics, the host country, in this case, France, failed to win any gold medals, finishing with three bronze medals. This feat would later occur at the next Winter Olympics in St. Moritz where Switzerland won only a single bronze medal, the lowest ever output by a host nation at an Olympics. Later host nations to finish without gold medals included Canada at the 1976 Summer Olympics in Montreal and 1988 Winter Olympics in Calgary and Yugoslavia at the 1984 Winter Olympics in Sarajevo.
In 1925, the IOC decided to organize Olympic Winter Games every four years, independent of the Olympic Games proper, and recognized the International Winter Sports Week as the first Olympic Winter games in retrospect.
In 1974 the final individual medal of Chamonix 1924 was presented. Anders Haugen, who until then had been recorded as finishing fourth in the ski jumping event, received a bronze medal. After fifty years an error had been discovered in the score of Thorleif Haug.
In 2006, the IOC retroactively awarded medals to the 1924 curling teams. The IOC decided that curling was officially part of the program, after the "Glasgow Herald" newspaper filed a claim on behalf of the families of the team.
Events.
Medals were awarded in 16 events contested in 5 sports (9 disciplines). Many sources do not list curling and the military patrol, or list them as demonstration events. However, no such designation was made in 1924. In February 2006 the International Olympic Committee (IOC) ruled that curling was a full part of the Olympic program, and have included the medals awarded in the official count.
Participating nations.
Athletes from 16 nations competed in the first Winter Olympic Games. Germany was banned from competing in the games, and instead hosted a series of games called Deutsche Kampfspiele.
See also.
Other Olympic Games celebrated in France

</doc>
<doc id="54017" url="http://en.wikipedia.org/wiki?curid=54017" title="Ngo Dinh Diem">
Ngo Dinh Diem

Ngô Đình Diệm ( ;    ;3 January 1901 – 2 November 1963) was the first president of South Vietnam (1955–1963). In the wake of the French withdrawal from Indochina as a result of the 1954 Geneva Accords, Diệm led the effort to create the Republic of Vietnam. Accruing considerable U.S. support due to his staunch anti-communism, he announced victory after a fraudulent 1955 plebiscite in which he won 600,000 votes from an electorate of 450,000 and began building a right-wing dictatorship in South Vietnam.
A Roman Catholic, Diệm's discriminatory policies toward the Republic's Montagnard natives and the nation's Buddhist majority were met with protests and non-violent resistance, culminating in the self-immolation of Buddhist monk Thích Quảng Đức in 1963. Amid religious protests, Diệm lost the backing of his US patrons and was assassinated, along with his brother, Ngô Đình Nhu by Nguyễn Văn Nhung, the aide of ARVN General Dương Văn Minh on 2 November 1963, during a coup d'état that deposed his government.
Family and childhood.
Diệm was born in Quảng Bình province, 110 km north from the Vietnamese Nguyễn dynasty-era capital of Huế, in central Vietnam. His family originated from Phú Cam district, a (formerly) Catholic district in Huế, (after the 1975 North Vietnamese invasion of South Vietnam, most homes and businesses in the district were confiscated by communist cadres, and Phú Cam's Catholic residents forcibly relocated, many to New Economic Zones in the jungle interior of Thừa Thiên–Huế Province). Portuguese missionaries had converted his family to Roman Catholicism in the 17th century, so Diệm was given a saint's name at birth, following the custom of the Catholic Church. The Ngô-Đình family, along with other Vietnamese Catholics, suffered from anti-Catholic persecutions from Emperors Minh Mạng and Tự Đức. In 1880, while Diệm's father, Ngô Đình Khả, was studying in Malaya for government service for the Nguyễn dynasty, an anti-Catholic riot led by Buddhist monks almost wiped out the entire Ngô-Đình family. Over 100 Ngôs, including Khả's parents, brothers and sisters, were buried alive.
Ngô Đình Khả scrapped plans to become a Roman Catholic priest and became the highest-ranked mandarin and a counselor to Emperor Thành Thái during French colonisation. He also rose to become the minister of the rites and chamberlain, and keeper of the eunuchs. Khả had nine children - six sons and three daughters by his second wife, whom he married after his first died childless. Past discriminatory oppression against Catholics further strengthened Khả's devotion to Catholicism. Devoutly Roman Catholic, Khả took his entire family to Mass every morning. Diệm rose every morning before dawn to pray. The Ngô-Đình family was firmly Confucianist and Catholic. In 1907, the French deposed Emperor Thành Thái on the pretext of insanity, because of his complaints about the colonisation. Khả retired in protest and became a farmer. Diệm laboured in the family's rice fields while studying at a French Catholic school, and later entered a private school started by his father. At age fifteen he followed his elder brother, Ngô Đình Thục, who would later become Vietnam's highest ranking Catholic bishop, into a monastery. After a few months he left, finding monastic life too rigorous.
At the end of his secondary schooling, his very high examination results at the French "lycée" in Huế saw him offered a scholarship to Paris, but he declined and enrolled to study at the School of Public Administration and Law in Hanoi, a French school that educated Vietnamese bureaucrats. It was there that he had the only romantic relationship of his life, when he fell in love with one of his teacher's daughters. After she persisted with her vocation, entering a convent, he remained celibate for the rest of his life.
Early career.
After graduating at the top of his class in 1921, Ngô Đình Diệm followed in the footsteps of his eldest brother, Ngô Đình Khôi, joining the civil service. Starting from the lowest rank of mandarin, Ngô Đình Diệm steadily rose. He first served at the royal library in Huế, and within one year was the district chief, presiding over seventy villages. Ngô Đình Diệm was promoted to be a provincial chief at the age of 25, overseeing 300 villages. Ngô Đình Diệm's rise was helped by Khôi's marriage to the daughter of Nguyễn Hữu Bài, the Catholic head of the Council of Ministers. Nguyễn Hữu Bài was highly regarded among the French, and Ngô Đình Diệm's religious and family ties impressed him. The French were impressed by his work ethic but were irritated by his frequent calls to grant more autonomy to Vietnam. Ngô Đình Diệm replied that he contemplated resigning but encouragement from the populace convinced him to persist. He first encountered communists distributing propaganda while riding horseback through the region near Quảng Trị. Revolted by calls for violent socialist revolution contained in the propaganda leaflets, Ngô Đình Diệm involved himself in anti-communist activities for the first time, printing his own pamphlets.
In 1929, he helped to round up Viet Minh communist agitators in his administrative area. He was rewarded with the promotion to the governorship of Bình Thuận Province, and in 1930 and 1931 suppressed the first peasant revolts organised by the communists, in collaboration with French forces. During the violent events, many villagers were raped and murdered. In 1933, with the return of Bảo Đại to ascend the throne, Ngô Đình Diệm was appointed by the French to be his interior minister following lobbying by Nguyễn Hữu Bài. Soon after his appointment, Diệm headed a commission to advise for potential administration reforms. After calling for the French to introduce a Vietnamese legislature and many other political reforms, he resigned after three months in office when this and other proposals were rejected. Diệm denounced Emperor Bảo Đại as "nothing but an instrument in the hands of the French", and renounced his decorations and titles from Bảo Đại. The French then threatened him with arrest and exile.
For the next decade, Ngô Đình Diệm lived as a private citizen with his family in Huế, although he was kept under surveillance. He was to have no formal job for 21 years. He spent his time on reading, meditating, attending church, gardening, hunting and amateur photography. A conservative by nature, Ngô Đình Diệm extensively conducted his nationalist activities during those 21 years, with meetings and correspondence with various leading Vietnamese revolutionaries, such as trips to Saigon to meet with Phan Bội Châu. With the start of the Second World War in the Pacific, seeing an opportunity for Vietnam to free itself from French colonization, he attempted to persuade the invading Japanese forces to declare independence for Vietnam in 1942 but was ignored. He founded a secret political party, the Association for the Restoration of Great Vietnam. When its existence was discovered in the summer of 1944, the French declared Ngô Đình Diệm to be a subversive and ordered his arrest. He fled to Saigon disguised as a Japanese officer, hiding there until the end of WWII.
In 1945, the Japanese offered him the post of prime ministers under Bảo Đại which they organised upon leaving the country. He declined initially, but regretted his decision and attempted to reclaim the offer. Bảo Đại had already given the post to another candidate and Ngô Đình Diệm avoided the stigma of being a collaborationist. In September 1945, after the Japanese withdrawal, Hồ Chí Minh proclaimed the Democratic Republic of Vietnam in the Northern half of Vietnam, his Việt Minh began fighting the French. Ngô Đình Diệm attempted to travel to Huế to dissuade Bảo Đại from joining Hồ, but was arrested by the Việt Minh along the way and exiled to a highland village near the border. He might have died of malaria, dysentery and influenza had the local tribesmen not nursed him back to health. Six months later, he was taken to meet Hồ in Hanoi, but refused to join the Việt Minh, assailing Hồ for the murder of his brother, , who was buried alive by Việt Minh cadres.
Ngô Đình Diệm continued to attempt to gather support for himself on an anti-Việt Minh platform. Despite having little success, Hồ was sufficiently irritated to order Ngô Đình Diệm's arrest, which Ngô Đình Diệm narrowly evaded. Ngô Đình Diệm was given a respite in November 1946 when clashes between the French and the Việt Minh escalated into full-scale war, forcing the Việt Minh to divert their resources. Ngô Đình Diệm then moved south to the Saigon region to live with Thục. Ngô Đình Diệm co-founded the Vietnam National Alliance, which called for France to grant Vietnam dominion status similar to the Commonwealth of Nations. The alliance was sufficient to generate support to fund newspapers in Hanoi and Saigon respectively. Both were shut down; the editor in Hanoi was arrested and hit men were hired to kill his Saigon counterpart. 
Ngô Đình Diệm's activities garnered substantial publicity and when France decided to make concessions to placate nationalist agitators, they asked him to lobby Bảo Đại to join them. Ngô Đình Diệm gave up when Bảo Đại made a deal which he felt to be soft, and returned to Huế. In the meantime, the French had started the State of Vietnam and Ngô Đình Diệm refused Bảo Đại's offer to become the Prime Minister. He then published a new manifesto in newspapers proclaiming a third force different from communism and French colonialism, but raised little interest. In 1950, the Việt Minh lost patience and sentenced him to death in absentia, and the French refused to protect him. Ho's cadres tried to kill him while he was traveling to visit his elder brother Thục, bishop of the Vĩnh Long diocese in the Mekong Delta. Ngô Đình Diệm left Vietnam in 1950.
Exile.
Diệm applied for permission to travel to Rome for the Holy Year celebrations at the Vatican. After gaining French permission he left in August with Thục, apparently destined to become a politically irrelevant figure. Before going to Europe, Diệm went to Japan, where he intended to meet Cường Để to enlist his support to seize power. Neither this nor an attempt to woo help from General Douglas MacArthur, the American supreme commander in occupied Japan, yielded meetings. A friend managed to organize a meeting with Wesley Fishel, an American academic who had done consultancy work for the United States government. Fishel was a proponent of the anti-colonial, anti-communist third force doctrine in Asia and was impressed with Diệm and helped him organize contacts and meetings in the United States to enlist support. It was an opportune time for Diệm, with the outbreak of the Korean War and McCarthyism helping to make Vietnamese anti-communists a sought after commodity in America. Diệm was given a reception at the State Department with the Acting Secretary of State James E. Webb. He reportedly gave a weak performance, in which Thục did most of the talking. As a result, no further audiences with notable officials were afforded to him. However, he did meet Francis Cardinal Spellman, who was regarded as the most politically powerful cleric of his time. Spellman had studied with Thục in Rome in the 1930s and was to become one of Diệm's most powerful advocates.
Diệm obtained an audience with Pope Pius XII in Rome before further lobbying across Europe. He attempted to convince Bảo Đại to make him the Prime Minister of the State of Vietnam but was turned down. Diệm returned to the United States to continue lobbying. In 1951 he secured an audience with Secretary of State Dean Acheson. During the next three years he lived at Spellman's Maryknoll seminary in Lakewood Township, New Jersey and occasionally at another seminary in Ossining, New York.
Spellman helped Diệm to garner support among right-wing and Catholic circles. Diệm toured the East Coast, speaking at universities, arguing that Vietnam could only be saved for the "free world" if the United States sponsored a government of nationalists who were opposed to both the Việt Minh and the French. He was appointed as a consultant to Michigan State University's Government Research Bureau, where Fishel worked. MSU was administering government-sponsored assistance programs for cold war allies, and Diệm helped Fishel to lay the foundation for a program later implemented in South Vietnam, the Michigan State University Vietnam Advisory Group. As French power in Vietnam declined, Diệm's support in the United States increased.
With the fall of Điện Biên Phủ in 1954 to the Viet Minh, French control of Vietnam collapsed and Bảo Đại needed foreign help to sustain his State of Vietnam. Realising Diệm's popularity among American policymakers, Bảo Đại chose Diệm's youngest brother Ngô Đình Luyện, who was studying in Europe at the time, to be part of his delegation at the 1954 Geneva Conference to determine the future of Indochina. Luyen represented Bảo Đại in his dealings with the Americans, who understood this to be an expression of interest in Diệm. With the backing of the Eisenhower administration, Bảo Đại named Diệm as the Prime Minister. The appointment was widely condemned by French officials, who felt that Diệm was incompetent, with Prime Minister Pierre Mendès France declaring Diệm to be a "fanatic". 
The Geneva accords resulted in Vietnam being partitioned temporarily at the 17th parallel, pending elections in 1956 to reunify the country. The Viet Minh controlled the north, while the French backed State of Vietnam controlled the south with Diệm as the Prime Minister. French Indochina was to be dissolved at the start of 1955. Diệm's South Vietnamese delegation chose not to sign the accords, refusing to have half the country under communist rule, but the agreement went into effect regardless. Diệm arrived at Tân Sơn Nhất airport in Saigon on 26 June where only a few hundred people turned out to greet him, mainly Catholics. He managed only one wave after getting into his vehicle and did not smile.
In the words of one historian, "Diem's attractiveness to his first American patrons derived from three qualities: he was a certified anti-communist nationalist, he was a Roman Catholic, and he understood English." English language ability was rare among Vietnamese at the time.
Consolidation of power.
The accords allowed for freedom of movement between the two zones until October 1954; this was to put a large strain on the south. Diệm had only expected 10,000 refugees, but by August, there were over 200,000 waiting in Hanoi and Haiphong to be evacuated; the migration helped to strengthen Diệm's political base of support. Before the partition, the majority of Vietnam's Catholic population lived in the north. After the borders were sealed, this majority was now under Diệm's rule. The U.S. Navy program Operation Passage to Freedom saw up to one million North Vietnamese move south, most of them Catholics. The CIA's Edward Lansdale, who had been posted to help Diệm strengthen his rule, led a propaganda campaign to encourage as many refugees to move south as possible. Diệm also used slogans such as "Christ has gone south" and "the Virgin Mary had departed from the North", alleging anti-Catholic persecution under Hồ Chí Minh. Over 60% of northern Catholics moved to Diệm's South Vietnam, providing him with a source of loyal support. 
Diệm's position at the time was weak; Bảo Đại disliked Diệm and appointed him mainly to political imperatives. The French saw him as hostile and hoped that his rule would collapse. At the time, the French Expeditionary Corps was the most powerful military force in the south; Diệm's Vietnamese National Army was essentially organized and trained by the French. Its officers were installed by the French and the chief of staff General Nguyễn Văn Hinh was a French citizen; Hinh loathed Diệm and frequently disobeyed him. Diệm also contended with two religious sects, the Cao Đài and Hòa Hảo, who wielded private armies in the Mekong Delta, with the Cao Đài estimated to have 25,000 men. The Việt Minh was also estimated to have control over a third of the country. The situation was worse in the capital, where the Bình Xuyên organized crime syndicate boasted an army of 40,000 and controlled a vice empire of brothels, casinos, extortion rackets, and opium factories unparalleled in Asia. Bảo Đại had given the Bình Xuyên control of the national police for US$1,250,000, creating a situation that the Americans likened to Chicago under Al Capone in the 1920s. In effect, Diệm's control did not extend beyond his palace. In August, Hinh launched a series of public attacks on Diệm, proclaiming that South Vietnam needed a "strong and popular" leader; Hinh bragged that he was preparing a coup. This was thwarted when Lansdale arranged overseas holiday invitations for Hinh's officers. Fearing Diệm's collapse, nine members of his government resigned during Hinh's abortive bid for power. Despite its failure, the French continued to encourage Diệm's enemies in an attempt to destabilize him.
Establishment of the Republic of Vietnam.
Diệm's appointment came after the French had been defeated at the Battle of Dien Bien Phu and were ready to withdraw from Indochina. At the start of 1955, French Indochina was dissolved, leaving Diệm in temporary control of the south. A referendum was scheduled for 23 October 1955 to determine the future direction of the south. It was contested by Bảo Đại, the Emperor, advocating the restoration of the monarchy, while Diệm ran on a republican platform. The elections were held, with Diệm's brother and confidant Ngô Đình Nhu, the leader of the family's Cần Lao Party, which supplied Diệm's electoral base, organising and supervising the elections. Campaigning for Bảo Đại was prohibited, and Đại supporters were attacked by Nhu's workers. Diệm recorded 98.2 percent of the vote—an implausibly high result that could have only been obtained through fraud. The total announced number of votes for a republic exceeded the number of registered voters by over 380,000—further evidence that the referendum was heavily rigged. For example, only 450,000 voters were registered in Saigon, but 605,025 were said to have voted for a republic. Three days later, Diệm proclaimed the formation of the Republic of Vietnam, naming himself President. Under the 1954 Geneva Accords, Vietnam was to undergo elections in 1956 to reunify the country. Diệm, noting that South Vietnam was not a party to the convention, canceled these. Criticising the Communists, he justified the electoral cancellation by claiming that the 1956 elections would be "meaningful only on the condition that they are absolutely free." With respect to the question of reunification, the non-communist Vietnamese delegation objected strenuously to any division of Vietnam, but lost out when the French accepted the proposal of Viet Minh delegate Phạm Văn Đồng, who proposed that Vietnam eventually be united by elections under the supervision of "local commissions". The United States countered with what became known as the "American Plan", with the support of South Vietnam and the United Kingdom. It provided for unification elections under the supervision of the United Nations, but was rejected by the Soviet delegation and North Vietnamese.
After coming under pressure from within the country and the United States, Diệm agreed to hold legislative elections in August 1959 for South Vietnam. Newspapers were not allowed to publish names of independent candidates or their policies, and political meetings exceeding five people were prohibited. Candidates were disqualified for petty reasons such as acts of vandalism against campaign posters. In the rural areas, candidates who ran were threatened using charges of conspiracy with the Việt Cộng, which carried the death penalty. Phan Quang Đán, the government's most prominent critic, was allowed to run. Despite the deployment of 8,000 ARVN plainclothes troops into his district to vote, Đán still won by a ratio of 6–1. The busing of soldiers occurred across the country, and when the new assembly convened, Đán was arrested.
Presidency.
Madame Nhu, the wife of Diệm's younger brother Nhu, was South Vietnam's de facto First Lady, and a Catholic convert herself. She led the way in Diệm's programs to reform Saigon society in accordance with Catholic values. Brothels and opium dens were closed, divorce and abortion made illegal, and adultery laws strengthened. Diệm won a street war with the private army of the Bình Xuyên organised crime syndicate of the Cholon brothels and gambling houses who had enjoyed special favors under the French and Bảo Đại. He further dismantled the private armies of the Cao Đài and Hòa Hảo religious sects, which controlled parts of the Mekong Delta. Diệm was passionately anti-Communist. According to Gabriel Kolko about 12,000 suspected opponents of Diệm were killed between 1955 and 1957 and by the end of 1958 an estimated 40,000 political prisoners had been jailed. However, Guenter Lewy argues that such figures were exaggerated and that there were never more than 35,000 prisoners of all kinds in the whole country. Diệm's repression extended beyond communists to anti-communist dissidents and anti-corruption whistleblowers.
As opposition to Diệm's rule in South Vietnam grew, a low-level insurgency began to take shape there in 1957. Finally, in January 1959, under pressure from southern Viet Cong cadres who were being successfully targeted by Diệm's secret police, Hanoi's Central Committee issued a secret resolution authorizing the use of armed insurgency in the South with supplies and troops from the North. On 20 December 1960, under instructions from Hanoi, southern communists established the Viet Cong (NLF) in order to overthrow the government of the south. The NLF was made up of two distinct groups: South Vietnamese intellectuals who opposed the government and were nationalists; and communists who had remained in the south after the partition and regrouping of 1954 as well as those who had since come from the north, together with local peasants. While there were many non-communist members of the NLF, they were subject to the control of the party cadres and increasingly side-lined as the conflict continued; they did, however, enable the NLF to portray itself as a primarily nationalist, rather than communist, movement, despite being in almost direct control by the Northern regime. The cornerstone of Diệm's counterinsurgency effort was the Strategic Hamlet Program, which called for the consolidation of 14,000 villages of South Vietnam into 11,000 secure hamlets, each with its own houses, schools, wells, and watchtowers. The hamlets were intended to isolate the NLF from the villages, their source of recruiting soldiers, supplies and information.
Assassination attempts.
The communists in southern Vietnam resolved that "if we are able to kill Ngô Đình Diệm, the leader of the current fascists dictatorial puppet government, the situation would develop along lines more favourable to our side." On 22 February 1957, when Diệm made a visit to an economic fair in Buôn Ma Thuột, a communist cadre named Ha Minh Tri carried out a directive to assassinate the president. He approached Diệm and fired a pistol from close range, but missed, hitting the Secretary for Agrarian Reform's left arm. The weapon jammed and security overpowered Tri before he was able to fire another shot. Diệm was unmoved by the incident. There was a further attempt to assassinate Diệm and his family in 1962 when two air force officers—acting in unison—bombed the presidential palace. 
Land policy.
During the 1946–54 war against the French Union forces, the Việt Minh, having gained control of parts of southern Vietnam, initiated land reform. During the period of war, rent collection, which hovered at around 50–70%, was impossible in some parts of the country, or the Việt Minh had compelled landlords to seek safety in the city and confiscated their land, distributing it to the peasants. When Diệm came to power, he reversed these re-allocations as upper-class landowners were part of his ideological support base. In the Mekong Delta, 0.025% of landowners owned 40% of the land; most of the land was owned by absentee landlords and worked by tenant farmers. This generated resentment among the populace, as land ownership was highly valued by Vietnamese society. Diệm declared that landlords could collect no more than 25%, but this was not enforced and in some cases the rent levels were higher than those under French colonisation. Under U.S. pressure, in 1956, he limited individual land holdings to 1.15 km², and reimbursed the landlords for the excess, which he sold to peasants. Many landlords evaded the redistribution by transferring the property to the name of family members. Additionally, the ceiling limit was more than 30 times that allowed in South Korea and Taiwan, and the 370000 acre of the Catholic Church's landownings in Vietnam were exempted. As a result, only 13% of the South Vietnam's land was redistributed, and by the end of his regime, only 10% of the tenants had received any land, at a high cost. This policy failure generated anger, and in turn sympathy to the Việt Minh who had given the peasants free land. At the end of Diệm's rule, 10% of the population owned 55% of the land.
Believing the central highlands were of strategic importance to the Việt Cộng or subject to a potential invasion by North Vietnam, Diệm decided to construct a Maginot Line of settlements. The area, inhabited by Montagnard indigenous people, had been largely allowed local autonomy in previous times, and the locals distrusted ethnic Vietnamese. Diệm initiated a program of internal migration where 210,000 Vietnamese, mainly Catholics, were moved to Montagnard land in fortified settlements. When the Montagnards protested, Diệm's forces confiscated their spears and bows, which they used to hunt for daily sustenance. Since then Vietnam has faced Montagnard insurgent separatist movements.
Government policy towards Buddhists.
In a country where surveys of the religious composition estimated the Buddhist majority to be between 70 and 90 percent, Diệm's policies generated claims of religious bias. As a member of the Vietnamese Catholic minority, he is widely regarded by historians as having pursued pro-Catholic policies that antagonized many Buddhists, since the Catholic community is anti-Communist. Specifically, the government was regarded as being biased towards Catholics in public service and military promotions, as well as the allocation of land, business favors and tax concessions. Diệm once told a high-ranking officer, forgetting that the man was from a Buddhist background, "Put your Catholic officers in sensitive places. They can be trusted." Many officers in the Army of the Republic of Vietnam converted to Catholicism in the belief that their military prospects depended on it.
The distribution of weapons to village self-defense militias intended to repel Việt Cộng guerrillas saw weapons only given to Catholics. Buddhists in the army were often denied promotion if they refused to convert to Catholicism. Some Buddhist villages converted en masse in order to receive aid or avoid being forcibly resettled by Diệm's regime. The Catholic Church was the largest landowner in the country, and the "private" status that was imposed on Buddhism by the French, which required official permission to conduct public Buddhist activities, was never repealed by Diệm.
Catholics were also "de facto" exempt from the "corvée" labor that the government obliged all citizens to perform; U.S. aid was disproportionately distributed to Catholic majority villages. Under Diệm, the Catholic Church enjoyed special exemptions in property acquisition, and in 1959, Diệm dedicated his country to the Virgin Mary. The white and gold Vatican flag was regularly flown at all major public events in South Vietnam. U.S. Aid supplies tended to go to Catholics, and the newly constructed Huế and Dalat universities were placed under Roman Catholic authority to foster a Catholic-skewed academic environment.
Buddhist crisis.
The regime's relations with the United States worsened during 1963, as discontent among South Vietnam's Buddhist majority was simultaneously heightened. In May, in the heavily Buddhist central city of Huế, where Diệm's elder brother was the Catholic Archbishop, the Buddhist majority was prohibited from displaying Buddhist flags during Vesak celebrations commemorating the birth of Gautama Buddha when the government cited a regulation prohibiting the display of non-government flags. A few days earlier, however, Catholics had been encouraged to fly religious flags at another celebration. This led to a protest led by Thích Trí Quang against the government, which was suppressed by Diệm's forces, killing nine unarmed civilians. Diệm and his supporters blamed the Việt Cộng for the deaths and claimed the protesters were responsible for the violence. Although the provincial chief expressed sorrow for the killings and offered to compensate the victims’ families, they resolutely denied that government forces were responsible for the killings and blamed the Viet Cong.
The Buddhists pushed for a five point agreement: freedom to fly religious flags, an end to arbitrary arrests, compensation for the Huế victims, punishment for the officials responsible and religious equality. Diệm labeled the Buddhists as "damn fools" for demanding something that, according to him, they already enjoyed. He banned demonstrations, and ordered his forces to arrest those who engaged in civil disobedience. On 3 June 1963, protesters attempted to march towards the Từ Đàm pagoda. Six waves of ARVN tear gas and attack dogs failed to disperse the crowds, and finally brownish-red liquid chemicals were doused on praying protesters, resulting in 67 being hospitalised for chemical injuries. A curfew was subsequently enacted. 
The turning point came in June when a Buddhist monk, Thích Quảng Đức, set himself on fire in the middle of a busy Saigon intersection in protest of Diệm's policies; photos of this event were disseminated around the world, and for many people these pictures came to represent the failure of Diệm's government. A number of other monks publicly self-immolated, and the U.S. grew increasingly frustrated with the unpopular leader's public image in both Vietnam and the United States. Diệm used his conventional anti-communist argument, identifying the dissenters as communists. As demonstrations against his government continued throughout the summer, the special forces loyal to Diệm's brother, Nhu, conducted a brutal August raid of the Xá Lợi pagoda in Saigon. Pagodas were vandalised, monks beaten, the cremated remains of Quảng Đức, which included his heart, a religious relic, were confiscated.
Simultaneous raids were carried out across the country, with the Từ Đàm pagoda in Huế looted, the statue of Gautama Buddha demolished and a body of a deceased monk confiscated. When the populace came to the defense of the monks, the resulting clashes saw 30 civilians killed and 200 wounded. In all 1,400 monks were arrested, and some thirty were injured across the country. The United States indicated its disapproval of Diệm's administration when ambassador Henry Cabot Lodge Jr. visited the pagoda "ex post facto". No further mass Buddhist protests occurred during the remainder of Diệm's rule (which would amount to less than five months).
Diệm's sister-in-law Madame Nhu, who was the nation's "de facto" first lady because of Diệm's unmarried status, inflamed the situation by mockingly applauding the suicides. A Catholic convert from Buddhism, she referred to the suicides as "barbecues", stating, "If the Buddhists want to have another barbecue, I will be glad to supply the gasoline." The pagoda raids stoked widespread public disquiet in Saigon. Students at Saigon University boycotted classes and rioted, which led to arrests, imprisonments and the closure of the university; this was repeated at Huế University. When high school students demonstrated, Diệm arrested them as well; over 1,000 students from Saigon's leading high school, most of them children of Saigon civil servants, were sent to re-education camps, including, reportedly, children as young as five, on charges of anti-government graffiti. Diệm's foreign minister Vũ Văn Mẫu resigned, shaving his head like a Buddhist monk in protest. When he attempted to leave the country on a religious pilgrimage to India, he was detained and kept under house arrest.
Coup and assassination.
As the Buddhist crisis deepened in July 1963, noncommunist Vietnamese nationalists and the military began preparations for a coup. Bùi Diễm, later South Vietnam's Ambassador to the United States, reported in his memoirs that General Lê Văn Kim requested his aid in learning what the United States might do about Diệm's government. Diễm had contacts in both the embassy and with the high-profile American journalists then in South Vietnam, David Halberstam ("New York Times"), Neil Sheehan (United Press International) and Malcolm Browne (Associated Press). On 20 August 1963, Nhu's security forces raided the Xá Lợi Pagoda in Saigon. They chose to wear Army uniforms during the raid to make it appear as if the Army were behind the crackdown. Nhu's forces arrested more than 400 monks who had been sitting cross-legged in front of a statue of the Buddha. Thousands of other Buddhists were arrested throughout the country. 
Henry Cabot Lodge Jr., the American ambassador to South Vietnam, refused to meet with Diệm. Upon hearing that a coup d'état was being designed by ARVN generals led by General Dương Văn Minh, and supported by the CIA, Lodge gave secret assurances to the generals that the United States would not interfere. Lucien Conein, a CIA operative, had become a liaison between the U.S. Embassy and the generals, who were led by Trần Văn Đôn. Conein provided a group of South Vietnamese generals with US $42,000 to carry out the coup with the promise that U.S. forces would make no attempt to protect Diệm.
The orders that ended in the deaths of Diệm and his brother originated with W. Averell Harriman and were carried out by Henry Cabot Lodge's own military assistant.
Having served as ambassador to Moscow and governor of New York, W. Averell Harriman was in the middle of a long public career. In 1960, President-elect Kennedy appointed him ambassador-at-large, to operate "with the full confidence of the president and an intimate knowledge of all aspects of United States policy." By 1963, according to Corson, Harriman was running "Vietnam without consulting the president or the attorney general".
The president had begun to suspect that not everyone on his national security team was loyal. As Corson put it, "Kenny O’Donnell (JFK's appointments secretary) was convinced that McGeorge Bundy, the national security advisor, was taking orders from Ambassador Averell Harriman and not the president. He was especially worried about Michael Forrestal, a young man on the White House staff who handled liaison on Vietnam with Harriman".
At the heart of the murders was the sudden recall of Saigon Station Chief Jocko Richardson, and his replacement by a hitherto unfamiliar group. Special Operations Army officer, John Michael Dunn was key to the operation. Dunn took his orders, not from the normal CIA hierarchy but from Harriman and Forrestal.
According to Corson, "John Michael Dunn was known to be in touch with the coup plotters", although Dunn's role has never been made public. Corson believes that Richardson was removed so that Dunn, assigned to Ambassador Lodge for "special operations", could act without hindrance.
Minh and his co-conspirators overthrew the government on 1 November 1963 in a swift coup. On 1 November, with only the palace guard remaining to defend Diệm and his younger brother, Nhu, the generals called the palace offering Diệm exile if he surrendered. That evening, however, Diệm and his entourage escaped via an underground passage to Cholon, where they were captured the following morning, 2 November. The brothers were assassinated together in the back of an M113 armoured personnel carrier with a bayonet and revolver by Captain Nguyễn Văn Nhung, under orders from Dương Văn Minh, while en route to the Vietnamese Joint General Staff headquarters. Diệm was buried in an unmarked grave in a cemetery next to the house of the U.S. Ambassador.
Aftermath.
Upon learning of Diệm's ouster and assassination, Hồ Chí Minh reportedly stated: "I can scarcely believe the Americans would be so stupid." The North Vietnamese Politburo was more explicit:"The consequences of the 1 November coup d'état will be contrary to the calculations of the U.S. imperialists ... Diệm was one of the strongest individuals resisting the people and Communism. Everything that could be done in an attempt to crush the revolution was carried out by Diệm. Diệm was one of the most competent lackeys of the U.S. imperialists  ... Among the anti-Communists in South Vietnam or exiled in other countries, no one has sufficient political assets and abilities to cause others to obey. Therefore, the lackey administration cannot be stabilized. The coup d'état on 1 November 1963 will not be the last."
After Diệm's assassination, South Vietnam was unable to establish a stable government and several coups took place after his death. While the United States continued to influence South Vietnam's government, the assassination bolstered North Vietnamese attempts to characterize the South Vietnamese as "supporters of colonialism".

</doc>
<doc id="54019" url="http://en.wikipedia.org/wiki?curid=54019" title="Cuscuta">
Cuscuta

Cuscuta (dodder) is a genus of about 100–170 species of yellow, orange, or red (rarely green) parasitic plants. Formerly treated as the only genus in the family Cuscutaceae, it now is accepted as belonging in the morning glory family, Convolvulaceae, on the basis of the work of the Angiosperm Phylogeny Group. The genus is found throughout the temperate and tropical regions of the world, with the greatest species diversity in subtropical and tropical regions; the genus becomes rare in cool temperate climates, with only four species native to northern Europe.
Folk names include devil's guts, devil's hair, devil's ringlet, goldthread, hailweed, hairweed, hellbine, love vine, pull-down, strangleweed, angel hair, and witch's hair.
Appearance.
Dodder can be identified by its thin stems appearing leafless, with the leaves reduced to minute scales. In these respects it closely resembles the similarly parasitic, but unrelated genus "Cassytha". From mid-summer to early autumn, the vines can produce small fruit that take the same color as the vine, and are approximately the size of a common pea. It has very low levels of chlorophyll; some species such as "Cuscuta reflexa" can photosynthesize slightly, while others such as "C. europaea" are entirely dependent on the host plants for nutrition.
Dodder flowers range in color from white to pink to yellow to cream. Some flower in the early summer, others later, depending on the species. The seeds are minute and produced in large quantities. They have a hard coating, and typically can survive in the soil for 5–10 years, sometimes longer.
Dodder seeds sprout at or near the surface of the soil. Although dodder germination can occur without a host, it has to reach a green plant quickly and is adapted to grow towards the nearby plants by following chemosensory clues. If a plant is not reached within 5 to 10 days of germination, the dodder seedling will die. Before a host plant is reached, the dodder, as other plants, relies on food reserves in the embryo; the cotyledons, though present, are vestigial.
Parasitism.
After a dodder attaches itself to a plant, it wraps itself around it. If the host contains food beneficial to dodder, the dodder produces haustoria that insert themselves into the vascular system of the host. The original root of the dodder in the soil then dies. The dodder can grow and attach itself to multiple plants. In tropical areas it can grow more or less continuously, and may reach high into the canopy of shrubs and trees; in temperate regions it is an annual plant and is restricted to relatively low vegetation that can be reached by new seedlings each spring.
Dodder is parasitic on a very wide variety of plants, including a number of agricultural and horticultural crop species, such as alfalfa, lespedeza, flax, clover, potatoes, chrysanthemum, dahlia, helenium, trumpet vine, ivy and petunias, among others.
Dodder ranges in severity based on its species and the species of the host, the time of attack, and whether any viruses are also present in the host plant. By debilitating the host plant, dodder decreases the ability of plants to resist viral diseases, and dodder can also spread plant diseases from one host to another if it is attached to more than one plant. This is of economical concern in agricultural systems, where an annual drop of 10% yield can be devastating. There has been an emphasis on dodder vine control in order to manage plant diseases in the field. 
Host location.
A report published in "Science" in 2006 demonstrated that dodder use airborne volatile organic compound cues to locate their host plants. Seedlings of "Cuscuta pentagona" exhibit positive growth responses to volatiles released by tomato and other species of host plants. When given a choice between volatiles released by the preferred host tomato and the non-host wheat, the parasite grew toward the former. Further experiments demonstrated attraction to a number of individual compounds released by host plants and repellance by one compound released by wheat. These results do not rule out the possibility that other cues, such as light, may also play a role in host location.
Host defenses.
Less is known about host defenses against dodder and other parasitic plants than is known about plant defenses against herbivores and pathogens. In one study, tomato plants were found to employ complex mechanisms to defend against dodder. Two pathways, using jasmonic acid and salicylic acid, were activated in response to attack by Cuscuta pentagona. Dodder attack was also found to induce production of volatiles, including 2-carene, α-pinene, limonene, and β-phellandrene. It is not known if or how these volatiles defend the host, but they could potentially interfere with the dodder's ability to locate and select hosts. Also, the presence of trichomes on the tomato stem effectively blocks the dodder from attaching to the stem.
Prevention and treatment.
Many countries have laws prohibiting import of dodder seed, requiring crop seeds to be free of dodder seed contamination. Before planting, all clothes should be inspected for dodder seed when moving from an infested area to a non-infested crop. When dealing with an infested area, swift action is necessary. Recommendations include planting a non-host crop for several years after the infestation, pulling up host crops immediately, particularly before the dodder produces seed, and use of preemergent herbicides such as Dacthal in the spring. Examples of non-host crops include grasses and many other monocotyledons. If dodder is found before it chokes a host plant, it may be simply removed from the soil. If choking has begun, the host plant must be pruned significantly lower than the dodder, as dodder is versatile and can grow back if present from haustoria.
Use in traditional medicine.
"C. chinensis" seeds (simplified Chinese: 菟丝子，"tusizi") have long been used for osteoporosis in China and some other Asian countries. "C. chinensis" is a commonly used traditional Chinese medicine which is believed to strengthen the liver and kidneys.
Further reading.
Cudney, D.W., S.B. Orloff, and J.S. Reints. 1992. An integrated weed management procedure for the control of dodder (Cuscuta indecora) in alfalfa (Medicago sativa). Weed Technology, 6, 603-606.

</doc>
<doc id="54020" url="http://en.wikipedia.org/wiki?curid=54020" title="EAPC">
EAPC

EAPC may refer to:

</doc>
<doc id="54022" url="http://en.wikipedia.org/wiki?curid=54022" title="Euro-Atlantic Partnership Council">
Euro-Atlantic Partnership Council

The Euro-Atlantic Partnership Council (EAPC), a post-Cold War NATO institution, is a multilateral forum created to improve relations between NATO and non-NATO countries in Europe and those parts of Asia on the European periphery. States meet to cooperate and go to the range of political and security issues. It was formed on May 29, 1997 in the ministers meeting of Sintra, Portugal, as the successor to the North Atlantic Cooperation Council (NACC), which was created in 1991. It works alongside the Partnership for Peace (PfP), created in 1994.
Members.
There are 50 members, the 28 NATO member countries and 22 partner countries. The partner countries are:

</doc>
<doc id="54023" url="http://en.wikipedia.org/wiki?curid=54023" title="Peter Bonetti">
Peter Bonetti

Peter Phillip Bonetti (born 27 September 1941 in Putney, London) is a former football goalkeeper for Chelsea, the St. Louis Stars, Dundee United and England. Bonetti was known for his safe handling, lightning reflexes and his graceful style, for which he was given the nickname, "The Cat". He was one of several goalkeepers (Gordon West of Everton was another) who specialised in a one-armed throw which could achieve a similar distance to a drop kick.
Early life.
In 1948 Bonetti's family moved from London to Worthing on the Sussex coast. His parents ran a cafe on the seafront next to the Worthing Dome. Bonetti shone at an early age, playing for Worthing.
Career.
Chelsea.
Chelsea signed him from the Reading youth team after his mother had written to then manager Ted Drake, requesting that he give her son a trial. Whilst a Chelsea junior, Bonetti made several appearances on loan to Croydon Amateurs in the Surrey Senior League. He made his first team debut in 1960 and a few weeks later helped the Chelsea youth side win the FA Youth Cup. From the 1960–61 season onwards, he was Chelsea's first choice goalkeeper, a position he held more or less constantly for the next nineteen years. Chelsea were relegated in Bonetti's second full season, which saw the appointment of Tommy Docherty as manager. Bonetti emerged as a key figure in a talented young side which included Bobby Tambling, Terry Venables, John Hollins and Barry Bridges. The team went into the penultimate match of the season needing to beat promotion rivals Sunderland to have a chance of going up. Chelsea won 1–0, with Bonetti making a brilliant last minute save to deny George Mulhall and maintain his side's promotion chances; a 7–0 win over Portsmouth secured instant promotion back to the First Division.
The new Chelsea side challenged for honours during the 1960s, with Bonetti a key figure throughout, although more often than not the team narrowly missed out. Chelsea won the League Cup in 1965 with a 3–2 aggregate victory over Leicester City. Leicester put Chelsea under heavy pressure in the second leg at Filbert Street, but an inspired performance from Bonetti helped secure a 0–0 draw for his side and thus the trophy. For most of the same season, Chelsea were on course to add both the league title and the FA Cup but ultimately missed out. They were beaten by Liverpool in the FA Cup while the title challenge was ended with a few games left after a bust-up between Docherty and several of his first-team players – though not Bonetti – meaning that a much-weakened team was fielded in a key match against Burnley, in which Bonetti conceded six goals.
Bonetti played in every game of Chelsea's Fairs Cup run the following season, putting in a series of impressive displays against the likes of AS Roma, AC Milan and FC Barcelona, though the side were eventually knocked out in the semi-finals, as they were in the FA Cup for the second consecutive year. The signing of Alex Stepney at the end of that season briefly threatened his position as Chelsea's first choice goalkeeper and he considered putting in a transfer request, but Stepney ultimately played only one game for the club and was sold to Manchester United a few months later. Chelsea eventually reached an FA Cup final in 1967, where they faced Tottenham Hotspur, but the team got outplayed on the day and Bonetti could do little to stop Spurs winning 2–1.
That was the closest he came to winning another trophy with Chelsea until 1970, by which time Docherty had been succeeded by Dave Sexton. In 1970, Chelsea again reached the FA Cup final and this time faced reigning league champions Leeds United. Over the two fiercely contested games, Bonetti had what was perhaps the finest moment of his playing career. Chelsea were outplayed for large spells in the first final at Wembley and he made a series of crucial saves to help them emerge with a 2–2 draw. Shortly into the replay at Old Trafford, his left knee was badly injured after a challenge from Leeds' Mick Jones. He returned to the field after treatment, but was effectively playing on one leg for the rest of the match and was powerless to stop Jones scoring the opener a few minutes later. In spite of the injury, and being targeted by the Leeds forwards, he made crucial saves throughout the match, denying both Peter Lorimer and Terry Cooper, and resisted more pressure from Leeds after Chelsea had taken the lead in extra time to help secure a 2–1 win. Such were Bonetti's performances that season, he was voted runner-up in the FWA Footballer of the Year awards.
A year later, the team added the UEFA Cup Winners' Cup after another replayed win in the final, this time over Spanish giants Real Madrid in Athens. Chelsea took a 2–0 lead in the replay, but Real dominated for much of the second half and it was another inspired performance from Bonetti, who had missed a large part of that season through injury, which helped them hold on for a 2–1 win.
That was his last trophy with the club, although they narrowly missed out on more in the following years, losing in the 1972 League Cup final to Stoke City and in the semi-finals of the same competition to Norwich City a year later. Financial and disciplinary problems within the club prevented them from building on their success.
St Louis Stars.
Bonetti left on a free transfer in 1975, joining the St. Louis Stars of the North American Soccer League (NASL). That year, he played 21 games for the side and helped them top the Central Division that summer and reach the play-off semi-finals.
Return to Chelsea.
He then returned to Chelsea, where his experience proved invaluable in helping new manager Eddie McCreadie's young side gain promotion in 1976–77. Two years later, in May 1979, he played his final game for Chelsea, a 1–1 draw with Arsenal, having made a total of 729 appearances for the club in nineteen years – only Ron Harris has made more – and kept over 200 clean sheets. He conceded one goal or less in two-thirds of his games for Chelsea.
England.
Bonetti's international career was somewhat unfortunate. He emerged in an era of talented English goalkeepers and thus faced stiff competition for a place in the side, particularly from Ron Springett and Gordon Banks, and later on Peter Shilton, which limited him to just seven caps. He was a member of England's successful 1966 World Cup squad, but didn't make an appearance. His career with the England national side is also largely remembered for one match – the 1970 FIFA World Cup quarter-final against West Germany in Mexico, when he was thrust into the starting line-up as a late replacement for Banks, who was suffering from food poisoning. During the match England let slip a 2–0 lead and lost 3–2 after extra time, with Bonetti one of the scapegoats, although he could be reasonably faulted for only one of the three goals conceded. That game was his only ever World Cup appearance. He conceded one goal in his other six international matches.
In the 1966 World Cup final only the 11 players on the pitch at the end of the 4–2 win over West Germany received medals. Following a Football Association led campaign to persuade FIFA to award medals to all the winners’ squad members, Bonetti was presented with his medal by Gordon Brown at a ceremony at 10 Downing Street on 10 June 2009.
Retirement.
After leaving Chelsea, Bonetti moved to the Isle of Mull where he became a postman. While living in Scotland, he briefly came out of retirement to play several games for Dundee United as understudy to Hamish McAlpine. Following his retirement from playing, Bonetti moved into coaching and had spells with Chelsea, Manchester City and the England national side. During his time as a Chelsea coach, he was persuaded to play 2 games for Isthmian League Division 2 side, Woking, including an FA Cup debut in a 1–0 win over Football Conference side Weymouth. At one time he held the record for the most appearances for a single club by a goalkeeper, but was overtaken in the 1990s by Portsmouth's Alan Knight.
Since 2005, Bonetti has made several appearances for an Old England XI in various charity games, notably against celebrity sides, usually coming on for the last 10 minutes of each game.
Statistics.
"Totals include one Charity Shield appearance in 1970–71."

</doc>
<doc id="54024" url="http://en.wikipedia.org/wiki?curid=54024" title="Equity (law)">
Equity (law)

In jurisdictions following the English common law, equity is the set of maxims that "reign over all the law" and "from which flow all civil laws". The Chancery, the office of equity, was the "office that issued the writs that were the foundation of the common law system". Equity is wholly "unaffected by any state laws” (Pomeroy) and is "everything, even without law".
Equity is commonly said to "mitigate the rigor of common law", allowing courts to use their discretion and apply justice in accordance with natural law. In practice, modern equity is limited by substantive and procedural rules, and English and Australian legal writers tend to focus on technical aspects of equity. Twelve "vague ethical statements", known as the maxims of equity, guide the application of equity, and an additional five can be added.
A historical criticism of equity while it developed was that it lacked fixed rules, with the Lord Chancellor occasionally judging in the main according to his conscience. The rules of equity later lost much of their flexibility, and from the 17th century onwards, equity was rapidly consolidated into a system of precedents much like its common-law cousin.
History.
Equity was developed two or three hundred years after the birth of the common law system to resolve disputes where damages were an unsuitable remedy and to introduce fairness into the legal system. The distinction between "law" and "equity" is an accident of history. The law courts or "courts of law" were the courts in England that enforced the king's laws in medieval times. There the King's Judges, educated in law rather than theology, administered the universal law of the realm. This body of law evolved on the basis of previously set precedent into what is recognized as the Common law of England. However, if changes were not quick enough, or if decisions by the judges were regarded as unfair, then litigants could still appeal directly to the King, who, as the sovereign, was seen as the 'fount of justice' and responsible for the just treatment of his subjects. Such filings were usually phrased in terms of throwing oneself upon the king's mercy or conscience. Eventually, the king began to regularly delegate the function of resolving such petitions to the Chancellor, an important member of the King's Council. The early Chancellors were often clergymen, acting as the King's confessor and thereby sacerdotally as keeper of the King's conscience. As a result of their theological and clerical training, Chancellors were well versed in Latin and French, as well as in classical Roman civil and canon law, which heavily influenced the development of equity. Soon the Chancery, the Crown's secretarial department, began to resemble a judicial body and became known as the "Court of Chancery".
By the 15th century, the judicial power of Chancery was recognized. Equity, as a body of rules, varied from Chancellor to Chancellor, until the end of the 16th century. After the end of the 17th century, only lawyers were appointed to the office of Chancellor.
One area in which the Court of Chancery assumed a vital role was the enforcement of uses, a role that the rigid framework of land law could not accommodate. This role gave rise to the basic distinction between legal and equitable interests.
Development of equity in England.
It was early provided that, in seeking to remove one who wrongfully entered another's land with force and arms, a person could allege disseisin (dispossession) and demand (and pay for) a writ of entry. That writ gave him the written right to re-enter his own land and established this right under the protection of the Crown if need be, whence its value. In 1253, to prevent judges from inventing new writs, Parliament provided that the power to issue writs would thereafter be transferred to judges only one writ at a time, in a "writ for right" package known as a form of action. However, because it was limited to enumerated writs for enumerated rights and wrongs, the writ system sometimes produced unjust results. Thus, even though the King's Bench might have jurisdiction over a case and might have the power to issue the perfect writ, the plaintiff might still not have a case if there was not a single form of action combining them. Therefore, lacking a legal remedy, the plaintiff's only option would be petitioning the King.
People started petitioning the King for relief against unfair judgments, and as the number of petitioners rapidly grew, so the King delegated the task of hearing petitions to the Lord Chancellor. As the early Chancellors lacked formal legal training and showed little regard for precedent, their decisions were often widely diverse. In 1529, a lawyer, Sir Thomas More, was appointed as Chancellor, marking the beginning of a new era. After this time, all future Chancellors were lawyers. Beginning around 1557, records of proceedings in the Courts of Chancery were kept and several equitable doctrines developed. Criticisms continued, the most famous being 17th century jurist John Selden's aphorism:Equity is a roguish thing: for law we have a measure, know what to trust to; equity is according to the conscience of him that is Chancellor, and as that is larger or narrower, so is equity. 'Tis all one as if they should make the standard for the measure we call a foot, a Chancellor’s foot; what an uncertain measure would this be? One Chancellor has a long foot, another a short foot, a third an indifferent foot: 'tis the same thing in a Chancellor’s conscience.
As the law of equity developed, it began to rival and conflict with the common law. Litigants would go ‘jurisdiction shopping’ and often would seek an equitable injunction prohibiting the enforcement of a common law court order. The penalty for disobeying an equitable ‘common injunction’ and enforcing a common law judgment was imprisonment.
The Chief Justice of the King’s Bench, Sir Edward Coke, began the practice of issuing writs of "habeas corpus" that required the release of people imprisoned for contempt of chancery orders.
This tension climaxed in the Earl of Oxford’s case (1615) where a judgment of Chief Justice Coke was allegedly obtained by fraud. The Lord Chancellor, Lord Ellesmere, issued a common injunction from the Chancery prohibiting the enforcement of the common law order. The two courts became locked in a stalemate, and the matter was eventually referred to the Attorney-General, Sir Francis Bacon. Sir Francis, by authority of King James I, upheld the use of the common injunction and concluded that in the event of any conflict between the common law and equity, equity would prevail. Equity's primacy in England was later enshrined in the Judicature Acts of the 1870s, which also served to fuse the courts of equity and the common law (although emphatically not the systems themselves) into one unified court system.
Statute of Uses 1535.
In order to avoid paying land taxes and other feudal dues, lawyers developed a primitive form of trust called ‘the use’ that enabled one person (who was not required to pay tax) to hold the legal title of the land for the use of another person. The effect of this trust was that the first person owned the land under the common law, but the second person had a right to use the land under the law of equity.
Henry VIII enacted the Statute of Uses in 1535 (which became effective in 1536) in an attempt to outlaw this practice and recover lost revenue. The Act effectively made the beneficial owner of the land the legal owner and therefore liable for feudal dues.
The response of the lawyers to this Statute was to create the 'use upon a use'. The Statute recognized only the first use, and so land owners were again able to separate the legal and beneficial interests in their land.
For an example, see Godwyne v. Profyt (after 1393): a petition to the Chancellor
See generally treatises on equity and trusts.
Comparison of equity traditions in common law countries.
As with the geographical transmission of any cultural artifact, direct English influence over equity weakened with time and distance, although the widespread import of printed opinions provided a corrective force, however long delayed. As the colonies gained political independence, each of their legal systems began drifting from the original in an irreversible departure from the English way of making laws and deciding cases. Nonetheless, each former colony acknowledged the reception of the common law and equity of England as a vital source of their jurisprudence.
The comparative question is an easy one to pose. Did English equity develop maturity early enough that all of its derivative systems necessarily tended toward the same doctrines, based on exactly the same set of general principles? Or did the split-offs of any of the colonies occur somewhere in the middle of its development so that substantial permanent differences resulted? One equity, or many?
The answer generally accepted in America, the earliest of the English colonies to gain independence, is the former, that the outcome of a case to be decided today upon principles of equity should be expected to be substantially the same whether decided in the UK or the US. The reasonableness of the belief enjoys strong historical support.
The perfection of modern equity as a system has been authoritatively credited to Lord Hardwicke who served as (Lord) Chancellor 1737–1756 and was rewarded with his peerage.
United States.
In modern practice, perhaps the most important distinction between law and equity is the set of remedies each offers. The most common civil remedy a court of law can award is monetary damages. Equity, however, enters injunctions or decrees directing someone either to act or to forbear from acting. Often, this form of relief is in practical terms more valuable to a litigant; for example, a plaintiff whose neighbor will not return his only milk cow, which had wandered onto the neighbor's property, may want that particular cow back, not just its monetary value. However, in general, a litigant cannot obtain equitable relief unless there is "no adequate remedy at law"; that is, a court will not grant an injunction unless monetary damages are an insufficient remedy for the injury in question. Law courts can also enter certain types of immediately enforceable orders, called "writs" (such as a writ of habeas corpus), but they are less flexible and less easily obtained than an injunction.
Another distinction is the unavailability of a jury in equity: the judge is the trier of fact. In the American legal system, the right of jury trial in civil cases tried in federal court is guaranteed by the Seventh Amendment "in Suits at common law", cases that traditionally would have been handled by the law courts. The question of whether a case should be determined by a jury depends largely on the type of relief the plaintiff requests. If a plaintiff requests damages in the form of money or certain other forms of relief, such as the return of a specific item of property, the remedy is considered legal, and a jury is available as the fact-finder. On the other hand, if the plaintiff requests an injunction, declaratory judgment, specific performance, modification of contract, or some other non-monetary relief, the claim would usually be one in equity.
Thomas Jefferson explained in 1785 that there are three main limitations on the power of a court of equity: "If the legislature means to enact an injustice, however palpable, the court of Chancery is not the body with whom a correcting power is lodged. That it shall not interpose in any case which does not come within a general description and admit of redress by a general and practicable rule." The US Supreme Court, however, has concluded that courts have wide discretion to fashion relief in cases of equity. The first major statement of this power came in "Willard v. Tayloe", 75 U.S. 557 (1869). The Court concluded that "relief is not a matter of absolute right to either party; it is a matter resting in the discretion of the court, to be exercised upon a consideration of all the circumstances of each particular case." "Willard v. Tayloe" was for many years the leading case in contract law regarding intent and enforcement. as well as equity.
In the United States today, the federal courts and most state courts have merged law and equity in the courts of general jurisdiction, such as county courts. However, the substantive distinction between law and equity has retained its old vitality. This difference is not a mere technicality, because the successful handling of certain law cases is difficult or impossible unless a temporary restraining order (TRO) or preliminary injunction is issued at the outset, to restrain someone from fleeing the jurisdiction taking the only property available to satisfy a judgment, for instance. Furthermore, certain statutes like Employee Retirement Income Security Act specifically authorize "only" equitable relief, which forces US courts to analyze in lengthy detail whether the relief demanded in particular cases brought under those statutes would have been available in equity.
Equity courts were widely distrusted in the northeastern US following the American Revolution. A serious movement for merger of law and equity began in the states in the mid-19th century, when David Dudley Field II convinced New York State to adopt what became known as the Field Code of 1848. The federal courts did not abandon the old law/equity separation until the promulgation of the Federal Rules of Civil Procedure in 1938.
Today three states still have separate courts for law and equity; the most notable is Delaware, whose Court of Chancery is where most cases involving Delaware corporations are decided. However, merger in some states is less than complete; some other states (such as Illinois and New Jersey) have separate divisions for legal and equitable matters in a single court. Besides corporate law, which developed out of the law of trusts, areas traditionally handled by chancery courts included wills and probate, adoptions and guardianships, and marriage and divorce.
After US courts merged law and equity, American law courts adopted many of the procedures of equity courts. The procedures in a court of equity were much more flexible than the courts at common law. In American practice, certain devices such as joinder, counterclaim, cross-claim and interpleader originated in the courts of equity. Also, the modern class action evolved out of the equitable doctrine of virtual representation, which enabled a court of equity to fully dispose of an estate even though it might contain contingent interests held by persons over which the court did not have direct jurisdiction.
India.
In India the common law doctrine of equity had traditionally been followed even after it became independent in 1947. However in 1963 the "Specific Relief Act" was passed by the Parliament of India following the recommendation of the Law Commission of India and repealing the earlier "Specific Relief Act" of 1877. Under the 1963 Act, most equitable concepts were codified and made statutory rights, thereby ending the discretionary role of the courts to grant equitable reliefs. The rights codified under the 1963 Act were as under:
With this codification, the nature and tenure of the equitable reliefs available earlier have been modified to make them statutory rights and are also required to be pleaded specifically to be enforced. Further to the extent that these equitable reliefs have been codified into rights, they are no longer discretionary upon the courts or as the English law has it, "Chancellor's foot" but instead are enforceable rights subject to the conditions under the 1963 Act being satisfied. Nonetheless, in the event of situations not covered under the 1963 Act, the courts in India continue to exercise their inherent powers in terms of Section 151 of the Code of Civil Procedure, 1908, which applies to all civil courts in India.
There is no such inherent powers with the criminal courts in India except with the High Courts in terms of Section 482 of the Code of Criminal Procedure, 1973. Further, such inherent powers are vested in the Supreme Court of India in terms of Article 142 of the Constitution of India which confers wide powers on the Supreme Court to pass orders "as is necessary for doing complete justice in any cause of matter pending before it".
References.
For a history of equity in England, including the Statute of Uses 1535:
For a general treatise on Equity, including a historical analysis:
For a brief outline of the maxims, doctrines and remedies developed under equity:

</doc>
<doc id="54025" url="http://en.wikipedia.org/wiki?curid=54025" title="Rubiaceae">
Rubiaceae

Rubiaceae is a family of flowering plants, commonly known as the coffee, madder, or bedstraw family. It consists of terrestrial trees, shrubs, lianas, or herbs that are recognizable by simple, opposite leaves with interpetiolar stipules. The family contains about 13,000 species in 611 genera, which makes it the fourth-largest angiosperm family. Rubiaceae has a cosmopolitan distribution, however, the largest species diversity is concentrated in the (sub)tropics. Economic importance includes "Coffea", the source of coffee, "Cinchona", the source of quinine used to treat malaria, some dye plants (e.g. "Rubia"), and ornamental cultivars (e.g. "Gardenia", "Ixora", "Pentas").
Description.
Rubiaceae is morphologically easily recognizable as a coherent group by a combination of characters: opposite leaves that are simple and entire, interpetiolar stipules, tubular sympetalous actinomorphic corollas and an inferior ovary.
A wide variety of growth forms are present: shrubs are most common, but members of the family can also be trees, lianas or herbs. Some epiphytes are also present (e.g. "Myrmecodia"). The leaves are simple, undivided and entire; leaf blades are usually elliptic, with a cuneate base and an acute tip. In three genera ("Pavetta", "Psychotria", "Sericanthe"), bacterial leaf nodules can be observed as dark spots or lines on the leaves. The phyllotaxis is usually decussate; rarely whorled (e.g. "Fadogia"); or rarely alternate resulting from the suppression of one leaf at each node (e.g. "Sabicea sthenula"). Characteristic for Rubiaceae is the presence of stipules that are mostly fused to an interpetiolar structure on either side of the stem between the opposite leaves. Their inside surface often bears glands called "colleters", which produce mucilaginous compounds protecting the young shoot. The "whorled" leaves of the herbaceous Rubieae tribe have classically been interpreted as true leaves plus interpetiolar leaf-like stipules. The inflorescence is a cyme, rarely of solitary flowers (e.g. "Rothmannia"), and is either terminal or axillary and paired at the nodes. The flowers are usually bisexual and usually epigynous. The perianth is usually biseriate, although the calyx is absent in some taxa (e.g. "Theligonum"). The calyx is 4-5-merous with basally fused lobes. The corolla is sympetalous with 4-5 lobes, mostly actinomorphic, usually tubular, often white but also yellow, blue, and (rarely) red. The stamens are 4-5, alternipetalous and epipetalous. Anthers are longitudinal in dehiscence, but some genera are poricidal (e.g. "Rustia"). The gynoecium is syncarpous with an inferior ovary (rarely secondarily superior, e.g. "Gaertnera", "Pagamea") and 2(3-5+) carpels. Placentation is axial, rarely parietal (e.g. "Gardenia"); ovules are anatropous to hemitropous, unitegmic, with a funicular obturator, 1-many per carpel. Nectaries are often present as a nectariferous disk atop the ovary. The fruit is a berry, capsule, drupe, or schizocarp. Red fruits are fairly dominant; yellow, orange or blackish fruits are equally common; blue fruits are rather exceptional save in Psychotrieae and associated tribes. Most fruits are about one cm in diameter; very small fruits are relatively rare and occur in herbaceous tribes; very large fruits are rare and confined to Gardenieae. The seeds are endospermous.
Distribution and habitat.
Rubiaceae has a cosmopolitan distribution and is found in nearly every region of the world, except for extreme environments such as the polar regions and deserts. The distribution pattern of the family is very similar to the global distribution of plant diversity overall. However, the largest diversity is distinctly concentrated in the humid tropics and subtropics. An exception is the Rubieae tribe, which is cosmopolitan but centered in temperate regions. Only a few genera are pantropical (e.g. "Ixora", "Psychotria"), many are paleotropical, while Afro-American distributions are rare (e.g. "Sabicea"). Endemic rubiaceous genera are found in most tropical and subtropical floristic regions of the world. The highest number of species is found in Colombia, Venezuela and New Guinea. When adjusted for area, Venezuela is the most diverse, followed by Colombia and Cuba.
Rubiaceae consists of terrestrial and predominantly woody plants. Woody rubiaceous shrubs constitute an important part of the understorey of low- and mid-altitude rainforests. Rubiaceae are tolerant of a broad array of environmental conditions (soil types, altitudes, community structures, etc.) and do not specialize in one specific habitat type (although genera within the family often specialize).
Ecology.
Flower biology.
Most Rubiaceae are zoophilous. Entomophilous species produce nectar from an epigynous disk at the base of the corolla tube to attract insects. Ornithophily is rare and is found in red-flowered species of "Alberta", "Bouvardia", and "Burchellia". Anemophylous species are found in the tribes Anthospermeae and Theligoneae and are characterized by hermaphroditic and/or unisexual flowers that exhibit a set of specialized features, such as striking sexual dimorphism, increased receptive surface of the stigmas and pendulous anthers.
Although most Rubiaceae species are hermaphroditic, outbreeding is promoted through proterandry and spacial isolation of the reproductive organs. More complex reproductive strategies include secondary pollen presentation, heterodistyly, and unisexual flowers.Secondary pollen presentation (also known as stylar pollen presentation or ixoroid pollen mechanism) is especially known from the Gardenieae and related tribes. The flowers are proterandrous and the pollen is shed early onto the outside of the stigmas and/or the upper part of the style, which serve as a 'receptaculum pollinis'. Increased surface area and irregularity of the pollen receptacle, caused by swellings, hairs, grooves or ridges often ensure a more efficient pollen deposition. After elongation of the style, animals transport the pollen to flowers in the female or receptive stage with exposed stigmatic surfaces. A pollen catapult mechanism is present in the genera "Molopanthera" and "Posoqueria" (tribe Posoquerieae) that projects a spherical pollen mass onto visiting sphingidae.Heterodistyly is another mechanism to avoid inbreeding and is widely present in the Rubiaceae family. The tribes containing the largest number of heterostylous species are Spermacoceae and Psychotrieae. Heterostyly is absent in groups that have secondary pollen presentation (e.g. Vanguerieae).Unisexual flowers also occur in Rubiaceae and most taxa that have this characteristic are dioecious. The two flower morphs are however difficult to observe as they are rather morphologically similar; male flowers have a pistillode with the ovaries empty and female flowers have empty, smaller anthers (staminodes). Flowers that are morphologically hermaphrodite, but functionally dioecious are for example found in "Pyrostria".
Fruit biology.
The dispersal units in Rubiaceae can be entire fruits, syncarps, mericarps, pyrenes or seeds. Fleshy fruit taxa are probably all (endo)zoochorous (e.g. tribes Pavetteae, Psychotrieae), while the dispersal of dry fruits is often unspecialized (e.g. tribes Knoxieae, Spermacoceae). When seeds function as diaspores, the dispersal is either anemochorous or hydrochorous. There are three types of wind-dispersed diaspores in Rubiaceae: dust seeds (rare, e.g. "Lerchea"), plumed seeds (e.g. "Hillia") and winged seeds (e.g. "Coutarea"). Long distance dispersal by ocean currents is very rare (e.g. the seashore tree "Guettarda speciosa"). Other dispersal mechanisms are absent or at least very rare. Some Spermacoceae having seeds with elaiosomes are probably myrmecochorous (e.g. "Spermacoce hepperiana"). Epizoochorous taxa are limited to herbaceous Rubiaceae (e.g. "Galium aparine" fruits are densely covered with hooked bristly hairs).
Associations with other organisms.
The genera "Anthorrhiza", "Hydnophytum", "Myrmecodia", "Myrmephytum", and "Squamellaria" are succulent epiphytes that have evolved a mutualistic relationship with ants. Their hypocotyl grows out into an ant-inhabited tuber. Some shrubs or trees have ant holes in their stems (e.g. "Globulostylis").Some Rubiaceae species have domatia that are inhabited by mites (viz. acarodomatia; e.g. "Plectroniella armata").An intimate association between bacteria and plants is found in three rubiaceous genera (viz. "Pavetta", "Psychotria", and "Sericanthe"). The presence of endophytic bacteria is visible by eye because of the formation of dark spots or nodules in the leaf blades. The endophytes have been identified as "Burkholderia" bacteria. Their function, however, remains enigmatic. A different type of plant-bacteria association is found in the genera "Fadogia", "Fadogiella", "Globulostylis", "Rytigynia", "Vangueria" (all belonging to the Vanguerieae tribe), where bacteria are found freely distributed among the mesophyll cells and no leaf nodules are formed.
Systematics.
The Rubiaceae family is named after "Rubia", a name used by Pliny the Elder in his Naturalis Historia for madder ("Rubia tinctorum"). The roots of this plant have been used since ancient times to extract alizarin and purpurin, two red dyes used for coloring clothes. The name "rubia" is therefore derived from the Latin word "ruber", meaning "red". The well-known genus "Rubus" (blackberries and raspberries) is unrelated and belongs to Rosaceae, the rose family.
Taxonomy.
The family was described in 1789 by Antoine Laurent de Jussieu.
Several historically accepted families are since long included in Rubiaceae: Aparinaceae, Asperulaceae, Catesbaeaceae, Cephalanthaceae, Cinchonaceae, Coffeaceae, Coutariaceae, Galiaceae, Gardeniaceae, Guettardaceae, Hameliaceae, Hedyotidaceae, Houstoniaceae, Hydrophylacaceae, Lippayaceae, Lygodisodeaceae, Naucleaceae, Nonateliaceae, Operculariaceae, Pagamaeaceae, Psychotriaceae, Randiaceae, Sabiceaceae, Spermacoceaceae.More recently, the morphologically quite different families Dialypetalanthaceae, Henriqueziaceae, and Theligonaceae were reduced to synonymy of Rubiaceae.
Subfamilies and tribes.
The classical classification system of Rubiaceae distinguished only two subfamilies: Cinchonoideae, characterized by more than one ovule in each locule, and Coffeoideae, having one ovule in each locule. This distinction, however, was criticized because of the distant position of two obviously related tribes, viz. Gardenieae with many ovules in Cinchonoideae and Ixoreae with one ovule in Coffeoideae, and because in species of "Tarenna" the number of ovules varies from one to several in each locule. During the twentieth century other characters were used to delineate subfamilies, e.g. stylar pollen presentation, raphides, endosperm, heterostyly, etc. On this basis, three or eight subfamilies were recognised. The last subfamilial classification solely based on morphological characters divided Rubiaceae into four subfamilies: Cinchonoideae, Ixoroideae, Antirheoideae, and Rubioideae. In general, problems of subfamilies delimitation in Rubiaceae based on morphological characters are linked with the extreme naturalness of the family, hence a relatively low divergence of its members.
The introduction of molecular phylogenetics in Rubiaceae research has corroborated or rejected several of the conclusions made in the pre-molecular era. There is support for the subfamilies Cinchonoideae, Ixoroideae, and Rubioideae, although differently circumscribed, and Antirheoideae is shown to be polyphyletic. The tribe Coptosapelteae including the genera "Acranthera" and "Coptosapelta", and the monogeneric tribe Luculieae have not been placed within a subfamily and are sister to the rest of Rubiaceae. Currently, in most molecular research concerning the Rubiaceae family, the classification with three subfamilies (Cinchonoideae, Ixoroideae, and Rubioideae) is followed. However, an alternative view is proposed where only two subfamilies are recognized, an expanded Cinchonoideae (that includes Ixoroideae, Coptosapeltaeae and Luculieae) and Rubioideae. The adoption of the Melbourne Code for botanical nomenclature had an unexpected impact on many names that have been long in use and are well-established in literature. According to the Melbourne Code, the subfamilial name Ixoroideae should be replaced by Dialypetalanthoideae. However, "Dialypetalanthus" is morphologically quite aberrant in Rubiaceae and if it should be excluded from Rubiaceae, the subfamilial name remains Ixoroideae. Molecular studies also have substantial impact on tribal delimitations and taxonomic changes are still being made. Also here, according to the Melbourne Code, the tribe Condamineeae should be renamed to Dialypetalantheae. The following list contains all validly published tribe names, however, some tribes might be disputed.
Genera.
Rubiaceae contains approximately 13,000 species in 611 genera. This makes it the fourth-largest family of flowering plants by number of species and fifth-largest by number of genera. Although taxonomic adjustments are still being made, the total number of accepted genera remains stable. In total, around 1300 genus names have been published, indicating that more than half of the published names are synonyms. "Psychotria", with around 1850 species, is the largest genus within the family and the third-largest genus of the angiosperms, after the legume "Astragalus" and the orchid "Bulbophyllum". However, the delimitation of "Psychotria" remains problematic and its adjustment might reduce the number of species. Twenty-nine other genera also have more than 100 species. On the other hand, 211 genera are monotypic, which account for more than 30% of all genera, but only 1.6% of all species.
Phylogeny.
Molecular studies have demonstrated the phylogenetic placement of Rubiaceae within the order Gentianales and the monophyly of the family is confirmed. The relationships of the three subfamilies of Rubiaceae together with the tribes Coptosapelteae and Luculieae are shown in the phylogenetic tree below. The placement of these two groups relative to the three subfamilies has not been fully resolved.
Evolution.
The fossil history of Rubiaceae goes back at least as far as the Eocene. The geographic distribution of these fossils, coupled with the fact that they represent all three subfamilies, is indicative of an earlier origin for the family, probably in the Late Cretaceous or Paleocene. Although fossils dating back to the Cretaceous and Palaeocene have been referred to the family by various authors, none of these fossils have been confirmed as belonging to Rubiaceae.
The oldest confirmed fossils, which are fruits that strongly resemble those of the genus "Emmenopterys", were found in the Washington State and are 48–49 million years old. A fossil infructescence and fruit found in 44-million-year-old strata in Oregon was assigned to "Emmenopterys dilcheri", an extinct species. The next oldest fossils date to the Late Eocene and include "Canthium" from Australia, "Faramea" from Panama, "Guettarda" from New Caledonia, and "Paleorubiaceophyllum", an extinct genus from the southeastern United States.
Fossil Rubiaceae are known from three regions in the Eocene (North America north of Mexico, Mexico-Central America-Caribbean, and Southeast Pacific-Asia). In the Oligocene they are found in these three regions plus Africa. In the Miocene they are found in these four regions plus South America and Europe.
Uses.
Food.
Staple foods are not found in Rubiaceae, instead some species are consumed locally and fruits may be used as famine food. Examples are African medlar fruits (e.g. "V. infausta", "V. madagascariensis"), African peach ("Nauclea latifolia"), and noni ("Morinda citrifolia").
Beverage.
The most economically important member of the family and the world's second most important commodity (after petroleum) is the genus "Coffea" used in the production of coffee. "Coffea" includes 124 species, but only three species are cultivated for coffee production: "C. arabica", "C. canephora", and "C. liberica".
Medicinal.
The bark of trees in the genus "Cinchona" is the source of a variety of alkaloids, the most familiar of which is quinine, one of the first agents effective in treating malaria. Woodruff ("Galium odoratum") is a small herbaceous perennial that contains coumarin—a natural precursor of warfarin—and the South American plant "Carapichea ipecacuanha" is the source of the emetic ipecac. "Psychotria viridis" is frequently used as a source of dimethyltryptamine in the preparation of ayahuasca, a psychoactive decoction.
Ornamentals.
Originally from China, the common gardenia ("Gardenia jasminoides") is a widely grown garden plant and flower in frost-free climates worldwide. Several other species from the genus are also seen in horticulture. The genus "Ixora" contains plants cultivated in warmer climate gardens; the most commonly grown species, "Ixora coccinea", is frequently used for pretty red-flowering hedges. "Mussaenda" cultivars with enlarged colored calyx lobes are shrubs with the aspect of "Hydrangea"; they are mainly cultivated in tropical Asia. The New Zealand native "Coprosma repens" is a commonly used plant for hedges. The South African "Rothmannia globosa" is seen as a specimen tree in horticulture. "Nertera granadensis" is a well-known house plant cultivated for its conspicuous orange berries. Other ornamental plants include "Mitchella", "Morinda", "Pentas", and "Rubia".
Dyes.
Rose madder, the crushed root of "Rubia tinctorum", yields a red dye, and the tropical "Morinda citrifolia" yields a yellow dye.

</doc>
<doc id="54026" url="http://en.wikipedia.org/wiki?curid=54026" title="Gambier">
Gambier

Gambier may refer to:

</doc>
<doc id="54028" url="http://en.wikipedia.org/wiki?curid=54028" title="Uncaria">
Uncaria

Uncaria is a genus of flowering plants in the family Rubiaceae. It has about 40 species. Their distribution is pantropical, with most species native to tropical Asia, three from Africa and the Mediterranean and two from the neotropics. They are known colloquially as Gambier, Cat's Claw or Uña de Gato. The latter two names are shared with several other plants. The type species for the genus is "Uncaria guianensis.
Indonesian Gambier ("U. gambir") is a large tropical vine with leaves typical of the genus, being opposite and about 10 cm long. The South American "U. tomentosa" is called Uña de Gato. "Uncaria sinensis" is common in China.
"Uncaria" was named in 1789 by Johann von Schreber in his "Genera Plantarum" edition 8[a] (not to be confused with books of the same title by Linnaeus, Jussieu, and others). The genus name is derived from the Latin word "uncus", meaning "a hook". It refers to the hooks, formed from reduced branches, that "Uncaria" vines use to cling to other vegetation.
"Uncaria" is a member of the tribe Nauclea, but its position within that tribe remains unresolved.
Description.
Woody lianas; climbing by hooks formed from reduced, modified branches. Stipules entire or bifid. Inflorescence a compact head, terminal, at the ends of plagiotropic branches and their very reduced branches. Corolla lobes without appendages. Seeds with a long wing at each end, the lower wing deeply bifid.
Species.
The following species list may be incomplete or contain synonyms.
Uses.
Cat's claw ("U. tomentosa") and the Chinese species are used medicinally. The glycosidic compounds have recognized anti-inflammatory properties, while the alkaloids increase the reactivity of lymphocytes, granting higher response to viral infection. Cat's claw has two varieties depending on whether the alkaloids have four rings or five. The five-ring alkaloid variety is medicinal and is called "savéntaro" by the Asháninka. Diplomat Edmund Roberts noted that upon his visit to China in the 1830s, Chinese were using it for tanning, and noted that the "uncaria gambir" made "leather porous and rotten." He also noted that Chinese would chew it with areca nut.
Gambier ("U. gambir"), is chewed in Indonesia with areca and betel as well as used for tanning and dyeing. It contains many flavan-3-ols ("catechins") which are known to have many medicinal properties and are components of Chinese herbal remedies and certain modern medicines. To make gambier, the leaves are first boiled in water. They absorb it and turn brownish in color. The leaves are then pressed mechanically to squeeze and extract liquid. This liquid is then dried into a semi-solid paste and molded into cubes, which are dried in the sun. Gambier is generally packed in 50 kg multi-layered packing (polypropylene bags inside and gunny bags outside).
"U. rhynchophylla" has also been shown to be a powerful MAO-B inhibitor.
Research has shown that rhamnose, a chemical extracted from uncaria plants, can actively regenerate skin, making it feel plumper and more elastic.

</doc>
<doc id="54029" url="http://en.wikipedia.org/wiki?curid=54029" title="Cubomania">
Cubomania

Cubomania is a surrealist method of making collages in which a picture or image is cut into squares and the squares are then reassembled without regard for the image, automatically "or at random," or a collage made using this method, a "rearrangement... suffic[ing] to create an entirely new work." It has been described as a "statistical method". Robert Hirsch has seemed to imply that this process can be done with digital photography.
Although seemingly a contradiction in terms, at least one cubomania has been made with triangular shapes.
Cubomania is done by cutting up an image into squares or rectangles (normally the same size) and reassembling randomly, the outcome is a new image with little resemblance to the starting image.
Penelope Rosemont and Joseph Jablonski have suggested that cubomania, with other surrealist methods, can "subvert the enslaving 'message' of advertising and to free images from repressive contexts." 
Cubomania was invented by the Romanian surrealist Gherasim Luca.
Using cubomania as a method for arranging soundscapes has been suggested.
See also Cut-up technique, surautomatism
This definition of cubomania is to be distinguished from the use of the word to mean "love of cubes" (or, perhaps, Rubik's Cube), or the joke about the possibility of its relating to compulsive dice playing in Shomit Dutta's translation of Aristophanes' "The Wasps", and other related uses.

</doc>
<doc id="54030" url="http://en.wikipedia.org/wiki?curid=54030" title="Vanilla Sky">
Vanilla Sky

Vanilla Sky is a 2001 American psychological thriller film directed, written, and co-produced by Cameron Crowe. It is an English-language remake of Alejandro Amenábar's 1997 Spanish film "Open Your Eyes", which was written by Amenábar and Mateo Gil, with Penélope Cruz reprising her role from the original movie. The movie is described as "an odd mixture of science fiction, romance and reality warp",
"Vanilla Sky" stars Tom Cruise, Penélope Cruz, and Cameron Diaz, with Jason Lee and Kurt Russell appearing in supporting roles. It received mixed reviews, with critics comparing it unfavorably to the original film and criticizing the screenplay for being confusing. It was a box office success, and received an Academy Award nomination for Best Original Song, as well as Screen Actors Guild and Golden Globe Award nominations for Cameron Diaz's performance. The soundtrack was also critically acclaimed. "Vanilla Sky" will be released on Blu-ray Disc on June 30, 2015 in North America.
Plot.
From a prison cell where he has been charged for murder, David Aames (Tom Cruise), in a prosthetic mask, tells his life story to court psychologist Dr. Curtis McCabe (Kurt Russell).
In flashback, David is shown to be the wealthy owner of a large publishing firm in New York City which he inherited from his father, leaving its regular duties to his father's trusted associates. As David enjoys the bachelor lifestyle, he is introduced to Sofia Serrano (Penélope Cruz) by his best friend and author Brian Shelby (Jason Lee) at a party. David and Sofia spend a night together talking, and fall in love. When David's former lover, Julianna "Julie" Gianni (Cameron Diaz), hears of Sofia, she attempts to kill herself and David in a car crash. Julie dies but David survives, his face grotesquely disfigured, leading him to wear a mask to hide the injuries. With no hope to use plastic surgery to repair the damage, David cannot come to grips with the idea of wearing the mask for the rest of his life. One night on a night out with Sofia and Brian, David gets hopelessly drunk, and Sofia and Brian leave David to wallow in the street outside.
David is awakened the next day in the street by Sofia, who apologises for deserting him the night before, and takes him home. The two continue to see each other, and David has his face surgically repaired despite being told it was impossible before. Though his life seems perfectly content, David finds oddities, such as brief visions of his distorted face, and a man (Noah Taylor) at a bar that tells him David can control the world and everyone in it, if he wanted to. One day, when he goes to Sofia's apartment, he finds Julie there instead; all of the previous mementos of Sofia now showing Julie's face. Angry and confused, David suffocates Julie, and is later arrested and placed in a mental institution, finding his face has reverted to its previously disfigured state.
David completes telling his story to Curtis, who proceeds to then visit David further for more sessions to try to help him recuperate. During one interview, David sees a nearby TV advertisement for "Life Extension", a company that specializes in cryonic suspension, finding the name familiar. Under Curtis' and a police officer's guard, David is taken to the Life Extension offices, where the salesclerk (Tilda Swinton) explains they freeze people just after the point of death, until a cure for their ailment is available in the future, keeping their brain active by placing them in a lucid dream state. David becomes anxious and breaks free of Curtis, realizing he is in his own lucid dream that has gone wrong, and calls for tech support.
David finds himself in the empty lobby of the offices, and the man whom he saw earlier at the bar appears, claiming to be David's tech support from Life Extension, which is now known as the Oasis Project. They ride up in an elevator to the top of an impossibly tall building, the height triggering David's severe acrophobia. The man explains that David has been in cryonic sleep for 150 years. David had opted for Life Extension's services after struggling with his breakup of Sofia and his disfigurement, and after securing the publishing company to its associates, proceeded to kill himself with a drug overdose; Life Extension preserved his body and, as David directed, put him into his lucid dream starting from the drunken night when Sofia left him, under the "vanilla sky" from a Monet painting. However, during his sleep, the dream went horribly wrong and attempted to incorporate elements from his subconscious, such as substituting Julie for Sofia and creating a father-figure like Curtis. As they arrive at the top of the building, the man offers David a choice: either to be reinserted into the corrected lucid dream, or to wake up by taking a literal leap of faith off the roof, which forces him to challenge his own fears. David decides to wake up, ignoring the vision of Curtis that his subconscious has brought to life to talk him out of it. David envisions Sofia and Brian to say his goodbyes. Conquering his final fear, David jumps off the building, his life flashing before his eyes, and whites out immediately before hitting the ground. A female voice commands him to "open your eyes" (a recurring theme in the movie), and the film ends with David opening his eyes.
Production.
Development.
"In the days after completing "Almost Famous", the opportunity to keep our film-making team together was too attractive to pass up. I'd always written my own original screenplays, but "Open Your Eyes", with its open-ended and impressionistic themes, felt like a great song for our 'band' to cover."
—Cameron Crowe, explaining his reason for directing "Vanilla Sky".
After the American debut of Alejandro Amenábar's 1997 Spanish film "Abre los ojos (Open Your Eyes)" at the 1998 Sundance Film Festival, Tom Cruise and his producing partner Paula Wagner optioned the remake rights. Hoping to entice director Cameron Crowe, who previously collaborated with Cruise on "Jerry Maguire", Cruise invited Crowe over to his house to view the film. Cruise has stated: 
I've been offered a lot of films to buy and remake, and I never have because I felt it was too connected with the culture of that place, whatever country it was from. But this was a universal story that was still open-ended, that still felt like it needed another chapter to be told.
The title of the film is a reference to depictions of skies in certain paintings by Claude Monet. In addition to Monet's impressionistic artwork, the film's tone was derived from the acoustic ballad "By Way of Sorrow" by Julie Miller and a line from an early interview of Elvis Presley in which he said, "I feel lonely, even in a crowded room."
Filming.
Principal photography for "Vanilla Sky" began in late 2000 and concluded in March 2001. On November 12, 2000, shooting for the scene of the deserted Times Square in New York took place in the early hours of the day. A large section of traffic was blocked off around Times Square while the scene was shot. "There was a limit on how long the city would let us lock everything up even on an early Sunday morning when much of NYC would be slow getting up," said Steadicam operator, Larry McConkey. "Several times we rehearsed with Steadicam and Crane including a mockup of an unmovable guardrail that we had to work the crane arm around. [Cruise] participated in these rehearsals as well so we shared a clear understanding of what my limitations and requirements would be."
Filming lasted for six weeks around the New York City-area, which included scenes shot in Central Park, Upper West Side, SoHo, and Brooklyn. One prominent location in the area was the Condé Nast Building that served as Aames Publishing and David’s office. After filming finished in New York, production moved to Los Angeles, where the remainder of interior shots were completed at Paramount Studios.
Despite the film's distorted aspects of reality, the style of cinematography remains grounded for much of the film. "I didn't do anything that was overtly obvious, because the story revolves around the main character not knowing whether he's in a state of reality, a dream or a nightmare, so we want it to feel a little ambiguous," said cinematographer, John Toll. "We want the audience to make discoveries as [Cruise]'s character does, rather than ahead of him." "American Cinematographer" magazine wrote a feature story on the lighting designer Lee Rose's work on the film.
Music.
Aside from selected works by Icelandic group Sigur Rós, the musical score for "Vanilla Sky" was composed by Crowe's then wife, Nancy Wilson, who previously scored "Almost Famous". Wilson spent nine months working on the film's music, which was done through experimentation of sound collages. "We were trying to balance out the heaviness of the story with sugary pop-culture music," said Wilson. "We made sound collages of all kinds. We were channeling Brian Wilson to a large extent. I was recording things through hoses, around corners, playing guitars with cello bows, and with [music editor] Carl Kaller, we tried all kinds of wacky stuff. In the murder–sex scene sound collage, Cameron even used Brian Wilson’s speaking voice from a "Pet Sounds" mix session."
Interpretations.
According to Cameron Crowe's commentary, there are five different interpretations of the ending:
Crowe has noted that the presence of "Vanilla Sky" marks the first lucid dream scene (the morning reunion after the club scene)—all that follows is a dream.
Release.
Box office.
"Vanilla Sky" opened at #1 at the box office in the United States when it was first presented on December 14, 2001. The opening weekend took in a gross income of $25,015,518 (24.9%). The final domestic gross income was $100.61 million while the foreign gross income was slightly higher at $102.76m for a worldwide gross income of $203,388,341.
Critical reception.
Critical reaction for "Vanilla Sky" was highly mixed. It holds a "rotten" rating of 40% on Rotten Tomatoes, based on 162 reviews (65 positive, 97 negative). Metacritic reported, based on 33 reviews, a "Mixed" rating of 45 out of 100.
Roger Ebert's printed review of "Vanilla Sky" awarded the film three out of four stars:
Think it all the way through, and Cameron Crowe's "Vanilla Sky" is a scrupulously moral picture. It tells the story of a man who has just about everything, thinks he can have it all, is given a means to have whatever he wants, and loses it because — well, maybe because he has a conscience. Or maybe not. Maybe just because life sucks. Or maybe he only thinks it does. This is the kind of movie you don't want to analyse until you've seen it two times.
Ebert interpreted the ending as an explanation for "the mechanism of our confusion", rather than a device that tells "us for sure what actually happened."
Film critic Richard Roeper identified the film as the second best of 2001.
A more mixed review from "The New York Times" early on calls "Vanilla Sky" a "highly entertaining, erotic science-fiction thriller that takes Mr. Crowe into Steven Spielberg territory", but then it notes:
As it leaves behind the real world and begins exploring life as a waking dream (this year's most popular theme in Hollywood movies with lofty ideas), "Vanilla Sky" loosens its emotional grip and becomes a disorganised and abstract if still-intriguing meditation on parallel themes. One is the quest for eternal life and eternal youth; another is guilt and the ungovernable power of the unconscious mind to undermine science's utopian discoveries. David's redemption ultimately consists of his coming to grips with his own mortality, but that redemption lacks conviction.
A negative review was published by Salon.com, which called "Vanilla Sky" an "aggressively plotted puzzle picture, which clutches many allegedly deep themes to its heaving bosom without uncovering even an onion-skin layer of insight into any of them." The review rhetorically asks:
Who would have thought that Cameron Crowe had a movie as bad as "Vanilla Sky" in him? It's a punishing picture, a betrayal of everything that Crowe has proved he knows how to do right...But the disheartening truth is that we can see Crowe taking all the right steps, the most Crowe-like steps, as he mounts a spectacle that overshoots boldness and ambition and idiosyncrasy and heads right for arrogance and pretension — and those last two are traits I never would have thought we'd have to ascribe to Crowe.
Peter Bradshaw of "The Guardian" and Gareth Von Kallenbach of the publication "Film Threat" compared "Vanilla Sky" unfavorably to "Open Your Eyes". Bradshaw says "Open Your Eyes" is "certainly more distinctive than" "Vanilla Sky", which he describes as an "extraordinarily narcissistic high-concept vanity project for producer-star Tom Cruise." Other reviewers extrapolate from the knowledge that Cruise had bought the rights to do a version of Amenábar's film. A "Village Voice" reviewer characterized "Vanilla Sky" as "hauntingly frank about being a manifestation of its star's cosmic narcissism".
Despite the negative reviews, Cameron Diaz's performance was critically acclaimed, with the "Los Angeles Times"‍ '​ film critic calling her "compelling as the embodiment of crazed sensuality" and "The New York Times" reviewer saying she gives a "ferociously emotional" performance. Edward Guthmann of The San Francisco Chronicle similarly says of the film, "most impressive is Cameron Diaz, whose fatal-attraction stalker is both heartbreaking and terrifying." For her performance Diaz won multiple critic's group awards, as well as earning nominations for the Golden Globe Award, Screen Actors Guild Award, Critics' Choice Movie Award, Saturn Award, and AFI Award. Penélope Cruz's performance, however, earned her a Razzie Award nomination for Worst Actress (in addition to her roles in "Blow" and "Captain Corelli's Mandolin").

</doc>
<doc id="54032" url="http://en.wikipedia.org/wiki?curid=54032" title="Brocard (law)">
Brocard (law)

A brocard is a legal principle expressed in Latin (and often derived from past legal authorities or Roman Law), which is traditionally used to express concisely a wider legal concept or rule. The name comes from the Latinized name of Burchard (died 1025), bishop of Worms, Germany, who compiled 20 volumes of "Ecclesiastical Rules".
History.
Begun in 1008, the materials took Burchard four years to compile. He wrote it while living in a small structure on top of a hill in the forest outside Worms, after his defeat of Duke Otto and while raising his adopted child. The collection, which he called the "Collectarium canonum" or "Decretum", became the primary source for canon law.
Along with numerous documents from a variety of sources, including the Old Testament and Augustine of Hippo, Burchard included the Canon Episcopi in this collection, under the belief that it dated from a bishop's "Council of Anquira" in 314, but no other evidence of this council exists. Because of this inclusion, Burchard has been described as something of a rationalist. As the source of canon law, Burchard's Decretum was supplanted around 1150 by the Decretum Gratiani, a much larger collection that further attempted to reconcile contradictory canon law.
Burchard spent the years 1023 to 1025 promulgating "Leges et Statuta familiae S. Petri Wormatiensis", a collection of religious laws he endorsed as fair and hoped to see adopted with official approval.
Weblink.
 The dictionary definition of brocard at Wiktionary

</doc>
<doc id="54033" url="http://en.wikipedia.org/wiki?curid=54033" title="List of horse breeds">
List of horse breeds

 This page is a list of horse and pony breeds, and also includes terms for types of horse that are not breeds but are commonly mistaken for breeds. While there is no scientifically accepted definition of the term "breed," a breed is defined generally as having distinct true-breeding characteristics over a number of generations; its members may be called "purebred". In most cases, bloodlines of horse breeds are recorded with a breed registry. However, in horses, the concept is somewhat flexible, as open stud books are created for developing horse breeds that are not yet fully true-breeding. Registries also are considered the authority as to whether a given breed is listed as a "horse" or a "pony". There are also a number of "color breed", sport horse, and gaited horse registries for horses with various phenotypes or other traits, which admit any animal fitting a given set of physical characteristics, even if there is little or no evidence of the trait being a true-breeding characteristic. Other recording entities or specialty organizations may recognize horses from multiple breeds, thus, for the purposes of this article, such animals are classified as a "type" rather than a "breed". 
The breeds and types listed here are those that already have a Wikipedia article. For a more extensive list, see the List of all horse breeds in DAD-IS.
For additional information, see horse breed, horse breeding and the individual articles listed below. Additional articles may be listed under and .
Horse breeds.
Horses are members of "Equus ferus caballus" that generally mature to be 14.2 hands (58 in) or taller, but many breed registries do accept animals under this height and classify them as "horses," as horse characteristics include factors other than height. For the purposes of this page, if a breed registry or stud book classifies the breed as a horse, it is listed here as a horse, even if some representatives are pony-sized or have some pony characteristics. Pony breeds are listed in the next section, "below."
Pony breeds.
Ponies are usually classified as members of "Equus caballus" that mature at less than 14.2 hands. However, some pony breeds may occasionally have individuals who mature over 14.2 but retain all other breed characteristics. There are also some breeds that now frequently mature over 14.2 hands due to modern nutrition and management, yet retain the historic classification "pony." For the purposes of this list, if a breed registry classifies the breed as a "pony," it is listed here as such, even if some individuals have horse characteristics.
Color "breeds".
There are some registries that accept horses (and sometimes ponies and mules) of almost any breed or type for registration. Color is either the only criterion for registration or the primary criterion. These are called "color breeds," because unlike "true" horse breeds, there are few other physical requirements, nor is the stud book limited in any fashion. As a general rule, the color also does not always breed on (in some cases due to genetic impossibility), and offspring without the stated color are usually not eligible for recording with the color breed registry. There are breeds that have color that usually breeds "true" as well as distinctive physical characteristics and a limited stud book. These horses are true breeds that have a preferred color, not color breeds, and include the Friesian horse, the Cleveland Bay, the Appaloosa, and the American Paint Horse.
The best-known "color breed" registries that accept horses from many different breeds are for the following colors:
Types of horse.
"See also" 
<br>
A "type" of horse is not a breed but is used here to categorize groups of horses or horse breeds that are similar in appearance (phenotype) or use. A type usually has no breed registry, and often encompasses several breeds. However, in some nations, particularly in Europe, there is a recording method or means of studbook selection for certain types to allow them to be licensed for breeding. Horses of a given type may be registered as one of several different recognized breeds, or a grouping may include horses that are of no particular pedigree but meet a certain standard of appearance or use. 
Archaic types.
Prior to approximately the 13th century, few pedigrees were written down, and horses were classified by physical type or use. Thus, many terms for Horses in the Middle Ages did not refer to breeds as we know them today, but rather described appearance or purpose. These terms included:
Extinct subspecies and breeds.
These members of "equus ferus" either were a recognized, distinct breed of horse that no longer exists as such, or subspecies that have become extinct at some point since domestication of the horse. This section does not include any species within evolution of the horse prior to modern "Equus ferus caballus". 
Early prototypes.
Before the availability of DNA techniques to resolve the questions related to the domestication of the horse, various hypothesis were proposed. One classification was based on body types and conformation, suggesting the presence of four basic prototypes, labeled the "Tarpan", "Forest horse", Draft and "Oriental", each of which was hypothesized to have adapted to their environment prior to domestication. However, more recent studies suggest that all domesticated horses originated from a single wild species and that the different body types of horses were entirely a result of selective breeding after domestication, or possibly landrace adaptation.
Extinct breeds.
These were human-developed breeds which no longer exist

</doc>
<doc id="54034" url="http://en.wikipedia.org/wiki?curid=54034" title="Misznay–Schardin effect">
Misznay–Schardin effect

The Misznay–Schardin effect (alternative spelling Misnay-Schardin), or platter effect, is a characteristic of the detonation of a broad sheet of explosive. The explosive blast expands directly away from (perpendicular to) the surface of an explosive. Unlike the blast from a rounded explosive charge, which expands in all directions, the blast produced by an explosive sheet expands primarily perpendicular to its plane, in both directions. If one side is backed by a heavy or fixed object, however, the majority of the blast (that is, most of the rapidly expanding gas and its kinetic energy) will be sent in the direction away from it. 
This effect was studied and experimented with by explosive experts József Misznay (alternative spelling Misnay), a Hungarian, and Hubert Schardin, a German, who initially sought to develop a more effective anti-tank (AT) mine for Nazi Germany. Some sources claim World War II ended before their design became usable, but they and others continued their work. Actually, Misznay designed two weapons. The 43 M was an AT mine, the LŐTAK was a side-attack mine. The Hungarian army used these weapons in 1944-1945.
The AT2 mine relies on this effect.

</doc>
<doc id="54035" url="http://en.wikipedia.org/wiki?curid=54035" title="Jus soli">
Jus soli

Jus soli (English pronunciation: ) (Latin: "right of the soil") is the right of anyone born in the territory of a state to nationality or citizenship. As an unconditional basis for citizenship, it is the predominant rule in the Americas, but is rare elsewhere. Since the Twenty-seventh Amendment of the Constitution of Ireland was enacted in 2004, no European country grants citizenship based on unconditional "jus soli". A study in 2010 found that only 30 of the world's 194 countries grant citizenship at birth to the children of undocumented foreign residents, although definitive information was not available from 19 countries.
Almost all states in Europe, Asia, Africa, and Oceania grant citizenship at birth based upon the principle of "jus sanguinis" (right of blood), in which citizenship is inherited through parents not by birthplace, or a restricted version of "jus soli" in which citizenship by birthplace is not automatic for the children of certain immigrants. Countries that have acceded to the 1961 Convention on the Reduction of Statelessness will grant nationality to otherwise stateless persons who were born on their territory, or on a ship or plane flagged by that country.
"Jus soli" is associated with permissive citizenship rights. Most countries with unconditional "jus soli" laws tend to give birthright citizenship (and nationality) based on "jus sanguinis" rules as well, although these stipulations tend to be more restrictive than in countries that use "jus sanguinis" as the primary basis for nationality.
History.
At one time, "jus sanguinis" (right of blood) was the sole means of determining nationality in Europe (where it is still widespread in Central and Eastern Europe) and Asia. An individual belonged to a family, a tribe or a people, not to a territory. It was a basic tenet of Roman law.
An early form of partial "jus soli" dates from Cleisthenes' reforms of ancient Athenian law. It developed further in the Roman world, where citizenship was extended to all free inhabitants of the Roman Empire, especially with the Constitutio Antoniniana (Edict of Caracalla).
Much later, the independence of the English colonies in America and the French Revolution laid the foundations for "jus soli". With the social and economic development of the 19th and 20th centuries, and the massive migrations to the Americas and Western Europe, "jus soli" was established in a greater and greater number of countries.
Geographer Jared Diamond has calculated that if the application of "jus soli" since 1850 were abolished, 60% of Americans and 80% of Argentinians would lose their citizenship, and 25% of the British and French.
At the turn of the 19th century, nation-states commonly divided themselves between those granting nationality on the grounds of "jus soli" (France, for example) and those granting it on the grounds of "jus sanguinis" (Germany, for example, before 1990). However, most European countries chose the German concept of an "objective nationality", based on race or language (as in Fichte's classical definition of a nation), opposing themselves to republican Ernest Renan's "subjective nationality", based on a daily plebiscite of one's belonging to one's Fatherland. This non-essentialist concept of nationality allowed the implementation of "jus soli", against the essentialist "jus sanguinis". However, today's increase of migrants has somewhat blurred the lines between these two antagonistic sources of right.
National laws.
"Lex soli" is a law used in practice to regulate who and under what circumstances an individual can assert the right of "jus soli". Most states provide a specific "lex soli", in application of the respective "jus soli", and it is the most common means of acquiring nationality. A frequent exception to "lex soli" is imposed when a child was born to a parent in the diplomatic or consular service of another state, on a mission to the state in question.
Restricted "jus soli".
There is a trend in some countries toward restricting "lex soli" by requiring that at least one of the child's parents be a citizen, national, or legal permanent resident of the state in question at time of the child's birth, or requiring that at least one parent have resided in the country for a specific period of time. Modification of "jus soli" has been criticized as contributing to economic inequality, the perpetuation of unfree labour from a helot underclass, and statelessness. "Jus soli" has been restricted in the following countries:
Abolition of "jus soli".
Some countries which formerly observed "jus soli" have moved to abolish it entirely, conferring citizenship on children born in the country only if one of the parents is a citizen of that country.

</doc>
<doc id="54036" url="http://en.wikipedia.org/wiki?curid=54036" title="Jus sanguinis">
Jus sanguinis

Jus sanguinis (Latin: "right of blood") is a principle of nationality law by which citizenship is not determined by place of birth but by having one or both parents who are citizens of the state. Children at birth may automatically be citizens if their parents have state citizenship or national identities of ethnic, cultural or other origins. Citizenship can also apply to children whose parents belong to a diaspora and were not themselves citizens of the state conferring citizenship. This principle contrasts with "jus soli" (Latin: "right of soil").
At the end of the 19th century, the French-German debate on nationality saw the French, such as Ernest Renan, oppose the German conception, exemplified by Johann Fichte, who believed in an "objective nationality", based on blood, race or language. Renan's republican conception, but perhaps also the presence of a German-speaking population in Alsace-Lorraine, explains France's early adoption of "jus soli". Many nations have a mixture of "jus sanguinis" and "jus soli", including the United States, Canada, Israel, Greece, Ireland, and recently Germany.
Today France only narrowly applies "jus sanguinis," but" "it is still the most common means of passing on citizenship in many continental European countries. Some countries provide almost the same rights as a citizen to people born in the country, without actually giving them citizenship. An example is "Indfødsret" in Denmark, which provides that upon reaching 18, non-citizen residents can decide to take a test to gain citizenship.
Some modern European states which arose out of dissolved empires, like the Austro-Hungarian or Ottoman, have huge numbers of ethnic populations outside of their new 'national' boundaries, as do most of the former Soviet states. Such long-standing diasporas do not conform to codified 20th-century European rules of citizenship.
In many cases, "jus sanguinis" rights are mandated by international treaty, with citizenship definitions imposed by the international community. In other cases, minorities are subject to legal and extra-legal persecution and choose to immigrate to their ancestral home country. States offering "jus sanguinis" rights to ethnic citizens and their descendants include Italy, Greece, Turkey, Bulgaria, Lebanon, Armenia and Romania. Each is required by international treaty to extend those rights.
In recent years, the Gulf Cooperation Council states have ensured that nationality is not easily awarded to residents and expatriates, unless they have some ethnic connection. This is mainly because they fear that a larger population could be a threat to the existing political systems in these countries. In the workplace, preferential treatment is given to full citizens. State benefits are also generally available for citizens only and not residents.
Lex sanguinis.
Many countries provide immigration privileges to individuals with ethnic ties to these countries (so-called "leges sanguinis"):

</doc>
<doc id="54039" url="http://en.wikipedia.org/wiki?curid=54039" title="Colosseum (disambiguation)">
Colosseum (disambiguation)

The Colosseum is an elliptical amphitheater in Rome, Italy.
Colosseum or coliseum may also refer to:

</doc>
<doc id="54041" url="http://en.wikipedia.org/wiki?curid=54041" title="Talcott Parsons">
Talcott Parsons

Talcott Parsons (December 13, 1902 – May 8, 1979) was an American sociologist who served on the faculty of Harvard University from 1927 to 1973.
Parsons developed a general theory for the study of society called action theory, based on the methodological principle of voluntarism and the epistemological principle of analytical realism. The theory attempted to establish a balance between two major methodological traditions: the utilitarian-positivist and hermeneutic-idealistic traditions. For Parsons, voluntarism established a third alternative between these two. More than a theory of society, Parsons presented a theory of social evolution and a concrete interpretation of the "drives" and directions of world history.
Parsons analyzed the work of Émile Durkheim and Vilfredo Pareto and evaluated their contributions through the paradigm of voluntaristic action. Parsons was also largely responsible for introducing and interpreting Max Weber's work to American audiences. Although he was generally considered a major structuralist functionalist scholar, in an article late in life, Parsons explicitly wrote that the term "functional" or "structural functionalist" were inappropriate ways to describe the character of his theory. For Parsons, "structural functionalism" was a particular stage in the methodological development of the social science, and "functionalism" was a universal method; neither term was a name for any specific school. In the same way, the concept "grand theory" is a derogatory term, which Parsons himself never used.
Biography.
Talcott Parsons was born 13 December 1902 in Colorado Springs. He was the son of Edward Smith Parsons (1863–1943) and Mary Augusta Ingersoll (1863–1949). His father had attended Yale Divinity School and was ordained as a Congregationalist minister, serving first as a minister for a pioneer community in Greeley, Colorado. At the time of Parsons' birth Edward S. Parsons was a professor in English at Colorado College and vice-president of the college.
During his Congregational ministry in Greeley, Edward S. Parsons had become sympathetic to the social gospel movement; yet, at the same time, he tended to view this question from a higher theological position and he was hostile to socialism as a sheer ideology. Also both Edward S. Parsons and his son Talcott would be familiar with the theology of Jonathan Edwards. The father would later become the president of Marietta College in Ohio. Parsons' family is one of the oldest families in American history; his ancestors were some of the first to arrive from England in the first half of the 17th century. The family's heritage consisted of two separate and independently developed Parsons lines, which both went back to the early days of America and indeed deeper into British history. On the father's side the family could be traced back to the Parsons of York, Maine. On the mother's side, the Ingersoll line was connected with Jonathan Edwards and from Edwards on there would be a new independent Parsons line because his eldest daughter Sarah married Elihu Parsons on June 11, 1750.
Studies: Amherst College.
As an undergraduate, Parsons studied biology, sociology and philosophy at Amherst College and received his B.A. in 1924. Amherst College had become the Parsons' family college by tradition; his father and his uncle Frank had attended it, as had his older brother. Initially Parsons was attracted to a career in medicine, inspired in this direction by his older brother Charles Edward Parsons, so he studied a great deal of biology and spent a summer working at the Oceanographic Institution at Woods Hole, Massachusetts.
Parsons' biology teachers while at Amherst were Otto C. Glaser and Henry Plough. Gently mocked as "Little Talcott, the gilded cherub", Parsons became one of the student leaders at Amherst. Parsons also took courses with Walton Hamilton and the philosopher Clarence Edwin Ayres, both known as "institutional economists". They exposed him to literature by Thorstein Veblen, John Dewey, and William Graham Sumner, among others. Parsons also took a course with George Brown in the philosophy of Immanuel Kant, and a course in modern German philosophy with Otto Manthey-Zorn, who was a great Kant interpreter. Parsons showed from early on a great interest in the topic of philosophy, which most likely was an echo of his father's great interest in theology in the tradition of which he had been profoundly socialized, a position that contrasted with his teachers' view.
Two term papers Parsons wrote as a student for Clarence E. Ayres' class in Philosophy III at Amherst have survived. These are referred to as the Amherst Papers and have been of strong interest to Parsons scholars. The first is written on December 19, 1922 and is called "The Theory of Human Behavior in its Individual and Social Aspects." The second term paper is written on March 27, 1923 and is called "A Behavioristic Conception of the Nature of Morals." The papers reveal in part Parsons' early interest in social evolutionary questions. The Amherst Papers also reveal that Parsons did not agree with his institutionalist teachers, since he writes in the Amherst papers that technological development and moral progress are two structurally independent empirical processes.
Studies: London School of Economics.
After Amherst, he studied at the London School of Economics for a year, where he was exposed to the work of R. H. Tawney, Bronisław Malinowski, and Leonard Trelawny Hobhouse. During his days at LSE he made friends with E.E. Evans-Pritchard, Meyer Fortes and Raymonth Firth, who all participated in the Malinowski seminar and in addition, he made a close personal friendship with Arthur and Eveline Burns.
While studying at LSE he met a young American girl in the students common room by the name of Helen Bancroft Walker whom he married on April 30, 1927. The couple had three children, Anne, Charles and Susan and eventually four grandchildren. Walker's father was born in Canada but had moved to the Boston area and had become a naturalized American citizen.
Studies: University of Heidelberg.
Parsons went on to the University of Heidelberg, where he received his Ph.D. in sociology and economics. During his time in Heidelberg, he worked with Alfred Weber (Max Weber's brother), Edgar Salin (who was his dissertation adviser) Emil Lederer, and Karl Mannheim and in addition he was examined in Immanuel Kant's "Critique of pure Reason" by the philosopher Karl Jaspers. At Heidelberg Parsons was also examed by Willy Andreas in the French Revolution. Parsons wrote his Dr. phil. thesis on "The Concept of Capitalism in the Recent German Literature" with his main focus on the work of Werner Sombart and Max Weber. It was clear from his discussion that he rejected Sombart's quasi-idealistic views and was in favor of Weber's attempt to strike a balance between "historicism", "idealism" and a Neo-Kantian approach.
The most crucial encounter for Parsons at Heidelberg was his encounter with the work of Max Weber, who he never had heard about before he arrived. Weber became tremendously important for Parsons because given his upbringing with a liberal yet strongly religious father, the question of the role of culture and religion in the basic processes of world history had been a persistent puzzle in his mind. Weber was the first scholar who truly provided Parsons with a compelling theoretical "answer" to this question and Parsons became absorbed in the reading of Weber to the utmost extent.
Parsons decided among other things that he would like to translate Weber's work into English and approached Marianne Weber, Max Weber's wife in this regard and he would eventually translate several of Weber's works into English. During his time in Heidelberg Parsons was invited by Marianne Weber to "sociological teas," which were study group meetings Marianne held in the library room of her and Max Weber's old apartment. One scholar Parsons met at Heidelberg who shared his enthusiasm for Weber was Alexander von Schelting. Parsons later wrote a review article on von Schelting's book on Weber. Generally, Parsons read extensively in religious literature, especially works focusing on the sociology of religion. One scholar who became especially important for Parsons in this regard was Ernst D. Troeltsch (1865–1923). Parsons also read widely on the topic of Calvinism. His reading included the work of Emile Doumerque, Eugéne Choisy and Henri Hauser.
Instructor at Harvard Department of Economics, 1927.
In 1927, after a year teaching at Amherst (1926–27), Parsons entered Harvard as an instructor in the Department of Economics, where he followed F.W. Taussig's lectures on Alfred Marshall and became friend with the economist historian Edwin Gay, who was the founder of Harvard Business School. Parsons also became a close associate of Joseph Schumpeter and followed his course on "General Economics". Parsons was generally at odds with some of the trends in Harvard's Economics department which in those days went in a highly technical, mathematical direction, and Parsons looked for other options at Harvard and gave courses in "Social Ethics" and in the "Sociology of Religion." Although Parsons entered Harvard through the Economics Department, he never aimed at becoming an economist; all his activities and his basic intellectual interest propelled him toward Sociology, although no Sociology Department existed in the first years at the time at Harvard. However, Harvard was in these years working toward establishing a Sociology Department and Parsons positioned himself in various ways through writing and teaching obligations so he was ready to join a Sociology Department, when it finally was established. In contrast to legend Parsons was never "forced" out of the Economics Department, his exit was voluntary and a deliberate decision.
Harvard's first Sociology Department, 1931.
The chance for a shift to sociology came in 1931, when Harvard's first Sociology Department was created under the Russian scholar Pitirim Sorokin. Sorokin, who had fled the Russian Revolution and had emigrated from Russia to the United States in 1923, was given the opportunity to establish the department. Parsons became one of the new department's two instructors, along with Carl Joslyn. During this period Parsons established close ties with biochemist and sociologist Lawrence Joseph Henderson, who took personal interest in Parsons' career at Harvard. Parsons became part of L.J. Henderson's famous Vilfredo Pareto study group in which some of the most important intellectuals at Harvard participated, including Crane Brinton, George C. Homans, and Charles P. Curtis. Parsons wrote an article on Pareto's theory and later explained that he had adopted the concept of "social system" from his reading of Pareto. Parsons also made strong connections with two other influential intellectuals with whom he corresponded for years; one was economist Frank H. Knight and the other was Chester I. Barnard, one of US's most dynamic business-men at the time. The relationship between Parsons and Sorokin quickly ran sour. A pattern of personal tensions was aggravated by Sorokin's deep dislike for American civilization, which he regarded as a sensate culture in decline. Sorokin's writings became increasingly anti-scientistic in his later years, widening the gulf between his work and Parsons', and turning the increasingly positivisitic American sociology community against him. Sorokin also tended to belittle all other sociology tendencies than his own writings and by 1934 the perception of Sorokin at Harvard had already turned quite negative.
Some of Parsons' students in the first years of the new department of Sociology were people like Robin Williams Jr., Robert K. Merton, Kingsley Davis, Wilbert Moore, Edward C. Devereux, Logan Wilson, Nicholas Demereth, John Riley, Jr. and Mathilda White Riley. Later cohorts of students, included among others Harry Johnson, Bernard Barber, Marion Levy and Jesse R. Pitts. Parsons established, at the students' request, a little informal study group which met year after year in Adams house. Toward the end of Parsons' career, the German systems theorist Niklas Luhmann also attended his lectures.
In 1932 Parsons bought his famous farmhouse in New Hampshire for $2.500. The farmhouse was located in a wooden area near the small town of Acworth, although Parsons often in his writing referred to it as "the farmhouse in Alstead." The farmhouse was not big and impressive; indeed, it was a very humble structure with almost no modern utilities. The farmhouse became central to Parsons' life, and many of his most important works were written in the peace and quiet at the farmhouse.
In the spring of 1933, Susan Kingsbury, a pioneer of women's rights in America, wrote to Parsons and offered him a position at Bryn Mawr; however, Parsons declined the offer because, as he wrote to Kingsbury, "neither salary nor rank is really definitely above what I enjoy here."
In the academic year of 1939-40 Talcott Parsons and Joseph Schumpeter conducted an informal faculty seminar at Harvard, which met in Emerson Hall and discussed the concept of rationality. Among the participants in the seminary were D.V. McGranahan, Abram Bergson, Wassily Leontief, Gottfried Haberler, and Paul Sweezy. Schumpeter contributed with the essay "Rationality in Economics" to the seminar, while Parsons submitted the paper "The Role of Rationality in Social Action" for a general discussion. Schumpeter suggested that he and Parsons write or edit a book together on the topic of rationality but the project never materialized.
Neoclassical economics versus institutionalists.
In the prevailing discussion between neoclassical economics and the institutionalists, which was one of the conflicts that prevailed within the field of economics in the 1920s and early 1930s, Parsons attempted to walk a very fine line. Put briefly, he was very critical about neo-classical theory and this was an attitude that prevailed all the way through his life and is reflected in his critique of Milton Friedman and Gary Becker. He was opposed to the utilitarian bias within the neo-classical approach, not in the sense that he discredited everything the neoclassical economists said, but to the effect that he could not embrace them fully. However, he agreed generally (or at least up to a point) on their theoretical and methodological style of approach (which should be discriminated from its substance). For the same reasons (and for several other reasons in addition) he was unable to accept the institutionalist solution. In an interview late in life Parsons recalled his conversation with Joseph Schumpeter about the institutionalist methodological position, the following way: "An economist like Schumpeter, by contrast, would absolutely have none of that. I remember talking to him about the problem and ... I think Schumpeter was right. If economics had gone that way [like the institutionalists] it would have had to become a primarily empirical discipline, largely descriptive, and without theoretical focus. That's the way the 'institutionalists' went, and of course Mitchell (Wesley Mitchell) was affiliated with that movement."
Second period in Germany and the fight against Nazism.
Parsons revisited Germany in the summer of 1930 and became a direct eye-witness to the feverish atmosphere in Weimar Germany during which the Nazi Party rose to power. In the following period Parsons received constant reports about the rise of Nazism through his friend Edward Y. Hartshorne who was travelling in Germany. Parsons began in the late 1930s to warn the American public about the Nazi threat; this was not an easy task since US in those days was predominantly isolationist.
One of the first articles Parsons wrote in this regard was entitled: "New Dark Age Seen If Nazis Should Win." Parsons became one of the key initiators of the Harvard Defense Committee, an organization aimed at rallying the American public against the Nazis. Parsons' voice would sound again and again over Boston's local radio-stations as a part of this campaign. Parsons also spoke against Nazism during a dramatic meeting at Harvard campus which was disturbed by isolationist activists. To fight isolationism early in World War II was a very difficult task since polls showed that 91 percent of the population was unwilling to go to war for the allied cause. Together with graduate student Charles O. Porter, Parsons would rally graduate students at Harvard for the war effort. (Porter would later become a US Congressman for Oregon elected on a Democratic ticket.) During the War Parsons conducted a special study group at Harvard, which analyzed what its members considered the causes of Nazism and where leading experts on the topic participated.
1940s: The Second World War and the Harvard School of Overseas Administration.
In the spring of 1941 a discussion group on Japan began to meet at Harvard. The group's five core members were Talcott Parsons, John K. Fairbank, Edwin O. Reischauer, William M. McGovern and Marion Levy, Jr.. A few others would also occasionally join the group including Ai-Li Sung (Ai-Li Sung Chin) and Edward Y. Hartshorne. The group rose out of a strong desire to understand Japan whose power in the East had grown tremendously (while at the same time allied with Nazi Germany since November 1936) but as Levy frankly admit "Reischauer was the only one who knew anything about Japan." Parsons, however, was eager to learn more about Japan and was "concerned with general implications." Shortly after the Japanese attack on Pearl Harbor, Parsons wrote in a letter to Arthur Upham Pope (1881–1969) that the importance of studies of Japan certainly had intensified. During 1942 Parsons worked on arranging a major study of occupied countries together with Bartholomew Landheer of the Netherland Information Office (located in New York). Parsons had mobilized Georges Gurvitch, Conrad Arnsberg, Dr. Safranek and Theodore Abel to participate in these studies but this initiative never materialized because of lack of funding. In early 1942 Parsons approached Hartshorne, who had joined the Psychology Division of the Office of the Coordinator of Information (COI) in Washington, DC to interest his agency in the research project but without result. In February 1943, Parsons became the deputy director of Harvard School of Overseas administration, a school which educated administrators to "run" the occupied territories in Germany and the Pacific. The task of finding relevant literature on both Europe and Asia for the Harvard School of Oversea administration (ASOA) was mind-boggling and occupied a fair amount of Parsons' time. One scholar Parsons came to know in his period was Karl August Wittfogel with whom he discussed Max Weber and whom he asked to lecture at the ASOA. On the issue of China, which also was taught at the school, Parsons received fundamental information from Chinese scholar Ai-Li Sung Chin and her husband Robert Chin. Another Chinese scholar Parsons worked closely with during the ASOA period was Hsiao-Tung Fei (also written: Fei Xiaotong) (1910–2005) who had studied at the London School of Economics and who was an expert on the social structure of the Chinese village.
1940s: Intellectual exchange with Schutz, Voegelin, Dodd and other debates.
Parsons met Alfred Schutz (Schütz) during the rationality seminar, which he conducted jointly together with Joseph Schumpeter at Harvard in the spring of 1940. Schutz has been close to Edmund Husserl and was deeply embedded in his phenomenological philosophy. Schutz who had been born in Vienna and had moved to the US in 1939, had for years worked on the project of developing a phenomenological sociology primarily based on an attempt to find some fixpoint between Husserl's method and Weber's sociology. Parsons had asked Schutz to give a presentation at the rationality seminar, which he did on April 13, 1940 and Parsons and Schutz had lunched together afterward. Schutz was fascinated with Parsons' theory, which he regarded as the state of the art of social theory and he had written an evaluation of Parsons' theory which he kindly asked Parsons to comment on. This led to a short but intensive correspondence, which generally revealed that the gap between Schutz's sociologized phenomenology and Parsons concept of voluntaristic action was far too great. From Parsons' point of view Schutz's position was too speculative and subjectivist of nature and he felt that Schutz was essentially a philosopher, who tended to reduce social processes to the articulation of a Lebenswelt consciousness, while for Parsons the defining edge of human life was action as a catalyst for historical change. For Parsons it was essential that sociology as a science should pay strong attention to the subjective element of action but it should never become completely absorbed in it, since the purpose of a science was to explain causal relationships, whether by covering laws or by other types of explanatory devices. Schutz's basic argument was that sociology cannot ground itself and that epistemology was not a luxury but a necessity for the social scientist. Parsons agreed but stressed the pragmatic need to demarcate science and philosophy and insisted moreover that the grounding of a conceptual scheme for empirical theory construction cannot aim at absolute solutions but need to take a sensible stock-taking of the epistemological balance at each point in time. However, there is no doubt that the two men shared many basic assumptions about the nature of social theory, which have made the debate simmering ever since. By request from Mrs. Ilse Schutz, after her husband's death, Parsons gave on July 23, 1971 permission to the publication of the correspondence between him and Schutz. Parsons also wrote "A 1974 Retrospective Perspective" to the correspondence, where he characterized his own position as a "Kantian point of view" and still found that Schutz strong dependence of Husserl's "phenomenological reduction" would make it very difficult to reach the kind of "conceptual scheme," which Parsons found essential for theory building in the social sciences.
Between 1940 and 1944, Parsons and Eric Voegelin (Vögelin) (1901–1985) exchanged their intellectual views through correspondence. Parsons had probably met Voegelin during 1938-39 when Voegelin held a temporary instructor appointment at Harvard. The bouncing point for their conversation was Parsons´' manuscript on anti-Semitism and other materials Parsons had sent to Voegelin. The discussion touched on the nature of capitalism, the rise of the West and the origin of Nazism. The key to this discussion was the implication of Max Weber's interpretation of the Protestant ethics and the impact of Calvinism on modern history. Although the two scholars agree on many fundamental characteristics about Calvinism, their understanding of its historical impact was quite different. Generally, Voegelin regarded Calvinism as essentially a dangerous totalitarian ideology; Parsons argued that these features of Calvinism was temporary and that the functional implications of its long-term, emerging value-system had revolutionary and by no means simply "negative" impact on the general rise of the institutions of modernity. The two scholars also discussed Parsons' debate with Alfred Schutz (Schütz) and especially why Parsons had ended his encounter with Schutz. Parsons found that Schutz rather than attempting to build social science theory tended to get consumed in philosophical detours. In this regard Parsons wrote to Voegelin: "Possibly one of my troubles in my discussion with Schuetz lies in the fact that by cultural heritage I am a Calvinist. I do not want to be a philosopher – I shy away from the philosophical problems underlying my scientific work. By the same token I don't think he wants to be a scientist as I understand the term until he has settled all the underlying philosophical difficulties. If the physicists of the 17th century had been Schuetzes there might well have been no Newtonian system."
In 1942, Stuart C. Dodd published a major work called "Dimensions of society", which attempted to build a general theory of society on the foundation of a mathematical and quantitative systematization of the Social Sciences. Especially, Dodd advanced a particular approach known as a "S-theory." Parsons discussed Dodd's theoretical outline in a review article the same year. Parsons acknowledge Dodd's contribution to be an exceedingly formidable work but at the same time he argued against its premises as a general paradigm for the social sciences. Parsons generally argued that Dodd's "S-theory," which included the so-called "social distance" scheme of Bogardus, was unable to construct a sufficiently sensitive and systematized theoretical matrix, compared with the "traditional" approach, which has developed around the lines of Max Weber, Vilfredo Pareto, Émile Durkheim, Sigmund Freud, William Isaac Thomas, and other important agents of an action-system approach with a more clear dialogue with the cultural and motivational dimensions of human interaction.
In April 1944, Parsons participated in the conference "On Germany after the war," which was a conference of psychoanalytical oriented psychiatrists and a few social scientists with the aim of analyzing the causes of Nazism and to discuss the principles for the coming occupation. During the conference Parsons opposed what he found to be Lawrence S. Kubie's reductionism. Lawrence S. Kubie was a psychoanalyst who strongly argued that the German national character was completely "destructive" and that it would be necessary for a special agency of the United Nation to control the German educational system directly. Parsons and many others at the conference were strongly opposed to Kubie's idea. Parsons argued that such an enterprise certainly would fail and he suggested that Kubie was viewing the question of German's reorientation "too exclusively in psychiatric terms." Parsons was also against the Morgenthau plan, which was aired in September 1944. After the conference Parsons wrote an article called, "The Problem of Controlled Institutional Change," which essential was designed as an argument against the Morgenthau plan. Parsons participated as part-time adviser to the Foreign Economic Administration Agency between March and October 1945, where he participated in discussions about reparations and deindustrialization practices after the war. He was elected a Fellow of the American Academy of Arts and Sciences in 1945.
Parsons takes charge at Harvard.
Parsons' situation at Harvard University changed significantly in early 1944 when he received a good offer from Northwestern University. Harvard reacted to the offer from Northwestern by appointing Parsons as the chairman of the department, promoting him to the rank of full professor and accepting the process of reorganization, which could lead to the establishment of the new department of Social Relations. Parsons' letter to Dean Paul Buck of April 3, 1944 reveals the high point of this moment. Because of the new development at Harvard, Parsons chose to decline an offer from William Langer to join the O.S.S. (Office of Strategic Services). The assignment Langer proposed for Parsons was that Parsons should follow the American army in its march into Germany and function as a political adviser to the administration of the occupied territories. Late in 1944, under the auspices of the Cambridge Community Council, Parsons directed a project together with Elizabeth Schlesinger. They investigated ethnic and racial tensions in the Boston area between students from Radcliffe College and Wellesley College. This study was a reaction to the upsurge of antisemitism in the Boston area, which began in late 1943 and continued into 1944. At the end of November 1946, the Social Research Council (SSRC) asked Parsons to write a comprehensive report of the topic of how the social sciences could contribute to the understanding of the modern world. The background was a controversy over whether the social sciences should be incorporated into the National Science Foundation. Parsons' report in form of a large memorandum called "Social Science: A Basic National Resource" became available in July 1948 and remains a powerful historical statement about how Talcott Parsons saw the role of the modern Social Sciences.
The Russian Research Center at Harvard.
Parsons became a member of the Executive Committee of the newly established Russian Research Center at Harvard in 1948, which had Parsons' close friend and colleague, Clyde Kluckhohn, as its director. Parsons went to Allied-occupied Germany in the summer of 1948 where he functioned as a contact person on behalf of RRC who was interested in the Russian refugees who had been stranded in Germany. Among the people Parsons happened to interview while in Germany were a few members of the Vlasov Army, which was an anti-Sovietic Russian Liberation Army who had collaborated with the Germans during the war. The movement was named after Andrey Vlasov who was a Soviet general captured by the Germans in June 1942. The Vlasov movement's ideology was a hybrid of elements but has been called "communism without Stalin" although in the Prague Manifesto (1944) the Vlasovs moved toward the framework of a constitutional liberal state. While in Germany that summer of 1948 Parsons wrote several letters to Kluckhohn reporting on his intelligence-investigations.
Against Communism.
Parsons' fight against Communism was a natural extension of his fight against fascism in the 1930s and 1940s. For Parsons, communism and fascism were two aspects of the same problem; they both represented what Parsons in his discussion in his article "A Tentative Outline of American Values" (posthum, 1989) called collectivistic types of "empirical finalism," which he believed was a secular "mirror" of religious types of "salvationalism." In contrast, Parsons highlighted that American values generally were based on the principle of "instrumental activism," which he believed was the outcome of Puritanism as a historical process. It representing what Parsons called "worldly asceticism" and in that capacity, it represented the absolute opposite principle of empirical finalism. It is also in this light one shall understand Parsons' statement late in life that the greatest threat to Mankind was that of "fundamentalism" in whatever form. By the term "empirical finalism" Parsons implied the type of claim assessed by cultural and ideological actors about the correct or "final" ends of particular patterns of value-orientation in the actual historical world (such as the notion of "a truly just society") which was absolutist and "indisputable" in its manner of declaration and in its function as a belief system. For example, the Jacobins behavior during the French Revolution would be a typical example of "empirical finalism." Parsons' rejection of communist and fascist totalitarianism was both theoretically and intellectually an integral part of his theory of world history, where Parsons tended to regard the European Reformation as the most crucial event in "modern" world history and where he like Max Weber tended to highlight the crucial impact of Calvinist religiosity in the socio-political and socio-economic processes, which followed; this development Parsons maintained reached its most radical form in England during the 17th century and gave in effect birth to the special cultural mode, which has characterized the American (United States) value-system and history ever since. Although it was not intended, the Calvinist faith-system, though authoritarian in the beginning, released in its long-term institutional effects a fundamental democratic revolution in the world; a revolution Parsons maintained was steadily unfolding as a part of the interpenetration of Puritan values in the world at large.
American exceptionalism.
Parsons defended the notion of American exceptionalism, and argued that because of a variety of historical circumstances, the impact of the Reformation had reached a certain intensity in the history of Great Britain. Puritan, essentially Calvinist, value-patterns had become institutionalized within the internal situation there. The outcome was that Puritan radicalism was reflected in the religious radicalism of the Puritan sects, in the poetry of John Milton, in the English Civil War and in the process coming to a head in the Glorious Revolution of 1688. It was the radical fling of Puritan revolution which provided settlers in early seventeenth century colonial America, and the Puritans who settled in America represented the radical wing with regard to ideals of individuality, egalitarianism, skepticism toward state power and the zeal of the religious calling. These settlers established something unique in the world, under the religious zeal of Calvinist values.
Therefore a new kind of nation was born, the character of which became clear by the time of the American Revolution and in the American constitution of 1787, and the dynamics of which later was studied by Alexis de Tocqueville. The French Revolution was an attempt to copy the American model, but it was essentially a process that failed. Although America has changed in its social composition since 1787, it preserves, Parsons maintained, the basic revolutionary Calvinist value-pattern. This development has been further revealed in the pluralist and highly individualized America with its thick, network-oriented civil society, which is of crucial importance to America's success, and these factors have provided the United States with its historical lead in the industrialized process.
This momentum, Parsons maintained, has continued to place the United States in the leading position in the world, but as a historical process and not in "the nature of things". Parsons viewed the "highly special feature of the modern Western social world" as "dependent on the peculiar circumstances of its history, and not the necessary universal result of social development as a whole."
Defender of modernity.
In contrast to some "radicals," Parsons was a defender of modernity. He believed that modern civilization with its technology and its constantly evolving institutions was ultimately strong, vibrant and essentially progressive. He acknowledged that the future of Mankind had no inherent guarantees. Yet at the same time, as Robert J. Holton and Bryan S. Turner have said, Parsons was not nostalgic: he did not believe in the past as a lost "golden age," but rather maintained that modernity generally had improved the conditions of Man, admittedly often in troublesome and painful ways, yet in sum mankind's condition has generally progressed. In this way he had faith in Man, not naively but still believing in human beings' potentials. When asked at the Brown seminary in 1973, whether he was optimistic about the future, he answered, "Oh, I think I'm basically optimistic about the human prospects in the long run." Parsons pointed out that he was student at Heidelberg at the height of the vogue of Oswald Spengler, the author of "Der Untergang des Abenlandes" "and he didn't give the West more than 50 years of continuing vitality after the time he wrote ... Well, its more than 50 years later now, and I don't think the West has just simply declined. He was wrong in thinking it was the end."
Harvard Department of Social Relations, 1946.
At Harvard, Parsons was instrumental in forming the Department of Social Relations, an interdisciplinary venture among sociology, anthropology, and psychology. The new department was officially created in January 1946 with Talcott Parsons as the chairman and with prominent figures at the faculty such as Samuel Stouffer, Clyde Kluckhohn, Henry Murray and Gordon Allport. An appointment for Hartshorne was considered but came to a bloody end, when Hartshorne was killed in Germany by an unknown gunman while driving on the highway. His position went instead to George C. Homans. The new department was galvanized by Parsons' idea of creating a theoretical and institutional base for a unified social science. During this period Parsons also became strongly interested in systems theory and cybernetics and began to adopt their basic ideas and concepts to the realm of social science, especially the work of Norbert Wiener (1894–1964) had his attention.
Some of the students who arrived at the Department of Social Relations in the years after the Second World War were: David Aberle, Gardner Lindzey, Harold Garfinkel, David G. Hays, Benton Johnson, Marian Johnson, Kaspar Naegele, James Olds, Albert Cohen, Norman Birnbaum, Jackson Toby, Robert Bellah, Joseph Kahl, Joseph Berger, Morris Zelditch, Renee Fox, Tom O'Dea, Ezra Vogel, Clifford Geertz, Joseph Elder, Theodore Mills, Mark Field and Francis Sutton. Renee Fox, who arrived at Harvard in 1949, would become a very close, personal friend of the Parsons family. Joseph Berger, who also arrived at Harvard in 1949, after finishing his B.A. from Brooklyn College, would become Parsons' research assistant in the year 1952-53 and would get involved in Parsons' research projects with Robert F. Bales.
According to Parsons' own account, it was during his conversations with Elton Mayo (1880–1949) that he realized it was necessary for him to take a serious look at the work of Freud. In the fall of 1938 Parsons began to offer a series of non-credit evening courses on Sigmund Freud. As time passed, Parsons developed a strong interest in psychoanalysis. He volunteered to participate in non-therapeutic training at the Boston Psychoanalytic Institute, where he began a didactic analysis with Dr. Grete Bibring in September 1946. Insight into psychoanalysis is significantly reflected in his later work, especially reflected in "The Social System" and in his general writing on psychological issues and on the theory of socialization. This influence was also to some extent apparent in his empirical analysis of fascism during the war. Beside the work of Freud, also Wolfgang Köhler's study of the mentality of apes and Kurt Koffka's ideas of Gestalt Psychology had Parsons attention.
"The Social System" and "Toward a General Theory of Action".
During the late 1940s and early 1950s Parsons worked very hard on producing some major theoretical statements. In 1951 Parsons published two major theoretical works, "The Social System" and "Toward a General Theory of Action." The latter work which was coauthored with Edward Tolman, Edward Shils and several others, was the outcome of the so-called Carnegie Seminar, which had taken place in the period of September 1949 and January 1950. "The Social System" represented Parsons first major attempt to present his basic outline of a general theory of society, since "The Structure of Social Action" (1937) can be regarded as the work, where he discussed the basic methodological and meta-theoretical principles for such a theory. The Social system attempted to present a general social system theory build systematically from it most basic premises and hence, it featured the idea of an interaction situation based on need-dispositions and facilitated through the basic concepts of cognitive, cathectic and evaluative orientation. By the same token the work also became known for the place, where Parsons introduced his famous pattern variables, which in reality represented choices distributed along a Gemeinschaft versus Gesellschaft axis. However, the way Parsons' thought about the outline of the social system went through a rapid series of re-editing processes in the following years although the basic core remained. During the early 1950s the idea of the AGIL model took stepwise place in Parsons mind. According to Parsons the key idea to the AGIL scheme was sparked during Parsons' work with Robert F. Bales on the study of motivational processes in small groups. Parsons carried this idea into the major work he coauthored with his student Neil Smelser, which was published in 1956 with the title "Economy and Society," where the first rudimentary model of the AGIL scheme was presented. The AGIL scheme reorganized the basic concepts of the pattern variables in a new way and presented the solution within a system-theoretical approach using the idea of a cybernetic hierarchy as an organizing principle. The real innovation in the AGIL model was the concept of the "latent function" or the pattern maintenance function, which became the crucial key to the whole cybernetic hierarchy.
During this theoretical development Parsons showed a persistent interest in symbolism. An important statement in this regard was Parsons' article "The theory of symbolism in relation to action." This article was stimulated by a series of informal discussion group meetings, which Parsons and several other colleagues in the spring of 1951 had conducted with philosopher and semiotician Charles W. Morris. Parsons interest in symbolism went hand in hand with his interest in Freud's theory and the paper "The Superego and the Theory of Social Systems," written in May 1951, for the meeting of the American Psychiatric Association can be regarded as a main statement of his own Freud interpretation but also as a statement how Parsons tried to use Freud's pattern of symbolization as a way to structure the theory of social system and eventually a way in which to codify the cybernetic hierarchy of the AGIL system within the parameter of a system of symbolic differentiation. His discussion of Sigmund Freud also contains several layers of criticism, which reveal that Parsons use of Freud is selective rather than orthodox. Especially he highlights in his critique of Freud that "Freud introduced an unreal separation between the superego and the ego."
Subscriber to system-theory, early 1950s.
Parsons was an early subscriber to system-theory. Parsons had from early on been fascinated by the writing of Walter B. Cannon and his concept of homeostasis, as well as of the writings of French physiologist Claude Bernard. His interest in system-theory had been further stimulated through his contract with L.J. Henderson. Parsons called the concept of "system" for an indispensable master concept in the work of building theoretical paradigms for the social sciences. From 1952 to 1957 Parsons participated in an ongoing Conference on System Theory under the chairmanship of Dr. Roy Grinker in Chicago. During these conferences Parsons came into contact with several prominent intellectuals of the time and he was particularly impressed by the ideas of social insect biologist Alfred Emerson. Parsons was especially compelled by Emerson's idea that in the sociocultural world, the functional equivalent of the gene was that of the "symbol." Parsons also participated in two of the meetings of the famous Macy conferences on system theory (and on issues which today is classified as cognitive science), which took place in New York in the period from 1946–1953 and include scientists like John von Neumann. Parsons read widely in system theory at the time and read especially some of the works by Norbert Wiener and William Ross Ashby who also were part of the core participants in the Macy Conferences. Around the same time Parsons also benefited from conversations with political scientist Karl Deutsch over the concept of system theory. In one conference, the Fourth Conference of the problems of consciousness, taking place in March 1953 at Princeton and sponsored by the Macy Foundation, Parsons would give a presentation on "Conscious and Symbolic Processes" and embark in an intensive group discussion which included exchange with child psychologist Jean Piaget. Among the other participants in the Conference were Mary A.B. Brazier, Frieda Fromm-Reichmann, Nathaniel Kleitman, Margaret Mead and Gregory Zilboorg. During the Conference Parsons would defend the thesis that consciousness was essentially a social action phenomenon and not primarily a "biological" one. During the conference Parsons criticized Jean Piaget for not sufficiently separating cultural factors from a physiologistic concept of "energy."
The McCarthy era, 1952.
During the McCarthy era, on April 1, 1952, J. Edgar Hoover received a personal letter from an informant who reported on Communist activities at Harvard. During a later interview the informant claimed that "Professor Talcott Parsons ... was probably the leader of an inner group" of Communist sympathizers at Harvard. The informant reported that the old department under Sorokin had been conservative and consisted of "loyal Americans of good character," but that the new department of Social Relation had turned into a decisive left wing place as a result of "Parsons' manipulations and machinations." Based on this evidence Hoover granted on October 27, 1952, Boston FBI authorization to initiate a security-type investigation on Parsons. In February 1954, Parsons' colleague Samuel Stouffer wrote to Parsons, who was located in England and informed him that he, Stouffer, had been denied access to classified documents and a part of the stated reason was that Stouffer knew Communists, including Talcott Parsons "who was a member of the Communist Party." Parsons immediately wrote an affidavit in defense of Stouffer, where he also defended himself against the charges. In the affidavit Parsons wrote, "This allegation is so preposterous that I cannot understand how any reasonable person could come to the conclusion that I was a member of the Communist Party or ever had been." In a personal letter to Stouffer, Parsons wrote, "I will fight for you against this evil with everything there is in me: I am in it with you to the death." The charges against Parsons resulted in Parsons being unable to participate in a UNESCO conference and it was not until January 1955 that he was acquitted of the charges.
Since the late 1930s Parsons had continued to show great interest in psychology and in psychoanalysis. In the academic year of 1955-56, he taught a seminar at Boston Psychoanalytic Society and Institute entitled "Sociology and Psychoanalysis." In 1956, he published a major work entitled "Family, Socialization and Interaction Process" which explored the way in which psychology (and psychoanalysis) bounce into the theories of motivation and socialization, as well into the question of kinship, which for Parsons established the fundamental axis for that subsystem he later would call "the social community." This work contained articles written by Parsons alone as well as articles written in collaboration with Robert F. Bales, James Olds, Morris Zelditch, Jr., and Philip E. Slater. The work included a theory of personality as well as studies of role-differentiation. The strongest intellectual stimuli in this period, Parsons most likely got from brain-researcher James Olds, who was one of the founders of neuroscience and Olds' book from 1955 on the question of learning and motivation is strongly influenced from his conversations with Parsons. Some of the ideas in the book Parsons had submitted in an intellectual brain-storm in an informal "work group," which he had organized which consisted in part of Joseph Berger, William Caudill, Frank E. Jones, Kaspar D. Naegele, Theodore M. Mills and Bengt G. Rundblad. In addition professor Albert J. Reiss from the Vanderbilt University had submitted his critical commentary. During the mid-1950s, Parsons also had extensive discussions with Olds about the motivational structure of psychosomatic problems and Parsons' concept of psychosomatic problems at the time was strongly influence by readings and direct conversations with Franz Alexander (a psychoanalyst (originally associated with Berlin Psychoanalytic Institute) who was a pioneer of psychosomatic medicine), Roy Grinker and John Spiegel.
In 1955, Francois Bourricaud was preparing a reader of some of Parsons work for a French audience and Parsons who wrote a preface for the book called "Au lecteur francais", also went over Bourricaud's introduction very carefully. In his correspondence with Bourricaud, Parsons insisted that he did not necessarily treat values as the only let alone "the primary empirical reference point" of the action system, since so many other factors was involved in the actual historical pattern of an action situation.
Center of Advanced Study in the Behavioral Sciences, 1957-58.
Parsons spent the year 1957-58 at the center of Advanced Study in the Behavioral Sciences in Palo Alto, California where he, for the first time in his life, met Kenneth Burke whose flamboyant, explosive temperament made a great impression on Parsons. The two men became close friends. Parsons explained in a letter the impression Burke had left on him: "The big thing to me is that Burke more than anyone else has helped me to fill a major gap in my own theoretical interests, in the field of the analysis of expressive symbolism."
Another scholar Parsons met while at the Center for Advanced Studies in the Behavioral Sciences at Palo Alto was Alfred L. Kroeber who at the time was the "dean of American anthropologists." Kroeber who had received his Ph.D. at Columbia and who had worked with the Arapaho Indians, was about 81 years old when he met Parsons. Parsons had the greatest admiration of Kroeber and called him "my favorite elder statesman." While in Palo Alto, Kroeber suggested to Parsons that they wrote a joint statement together, which purpose it was to clarify the distinction between cultural and social systems, which in those day was the subject of endless debates. In October 1958, Parsons and Kroeber published their joint statement in a small article, which became highly influential. Parsons and Kroeber declared in the article that it was important to keep a clear distinction between the two concepts and to avoid a methodology by which the one would be reduced to the other.
Discussion of Parsons' writings, late 1950s.
During the academic year of 1955-56, a group of faculty members at Cornell University met regularly and discussed Parsons' writings. In the next academic year a series of seven widely attended public seminars followed culminating in a session at which Parsons himself answered his critics. The discussions in these seminars was summed up in a joined publication edited by Max Black entitled "The Social Theories of Talcott Parsons: A Critical Examination" and included an essay by Parsons called "The point of view of the author." The scholars included in the volume were Edward C. Devereux, Jr., Robin M. Williams, Jr., Chandler Morse, Alfred L. Baldwin, Urie Bronfenbrenner, Henry A. Landsberger, William Foote Whyte, Max Black and Andrew Hacker. The contributions converted many angles including personality theory, organizational theory and various methodological discussions. Parsons' essay is particularly notable because it, together with another essay published in 1960 and called "Pattern Variables Revisited," represents one of the most full-scale account of the basic elements of his theoretical strategy and the general principles behind his approach to theory building. The essay also included although in meta-theoretical terms a criticism of the theoretical foundations for the so-called "conflict theory".
Starting from the late 1950s and culminating during the student rebellion in the 1960s and its aftermath, Parsons' theory was criticized by some scholars and intellectuals of the left, claiming that Parsons' theory was:
The first manifestations of this branch of criticism would be intellectuals like Lewis Coser, Ralf Dahrendorf, David Lockwood, John Rex, C.W. Mills, Tom Bottomore and Alvin Gouldner among other.
Early 1960s.
Parsons voted for John F. Kennedy on November 8, 1960; since 1923 with one exception Parsons would vote for Democrats all his life. He discussed the Kennedy election widely in his correspondence at the time. Parsons was especially interested in the symbolic implications involved in the fact of Kennedy's Catholic background for the implications for United States as an integral community. (It was the first and so far only time a Catholic became President of the United States.) In a letter to Robert Bellah, he wrote: "I am sure you have been greatly intrigued by the involvement of the religious issue in our election." Parsons who described himself as a "Stevenson Democrat," was especially enthusiastic about that his favored politician Adlai Stevenson had been appointed United States Ambassador to the United Nations. Parsons had persistently voted for Stevenson in both of the years he had run for election and was greatly disappointed that Stevenson twice was rejected by the American voters.
In the early 1960s it became obvious that Parsons' ideas had a great impact on much of the theories of modernization at the time. His influence was very extensive yet at the same time the concrete adoption of his theory was often quite selective, half-hearted, superficial and at times utterly confused. In this way, many of the modernization theorists never used the full power of Parsons theory but concentrated on some formalist formula, which often was taken out of context with the deeper meaning by which Parsons originally had introduced them. Nonetheless, works such as Gabriel A. Almond and James S. Coleman, "The Politics of the Developing Areas," as well as works by Karl W. Deutsch, S.N. Eisenstadt, Seymour Martin Lipset, Samuel P. Huntington, David E. Apter, Lucian W. Pye, Sidney Verba and Chalmers Johnson among others were importantly influenced by Talcott Parsons in some way or another. Indeed, it was the intensive influence of Parsons ideas in Political sociology, which originally made a scholar like William Buxton interested in Parsons work. In addition, a scholar like David Easton would claim that in the history of Political Science, the two scholars who had made any serious attempt to construct a general theory for Political Science on the issue of political support were himself and Talcott Parsons.
One of the scholars Parsons corresponded extensively with during his lifetime and whose opinion he highly valued was Robert N. Bellah. Parsons' discussion with Bellah would cover a wide range of topics including the theology of Paul Tillich. The correspondence would continue when Bellah in the early fall of 1960 went to Japan in order to study Japanese religion and ideology. In August 1960, Parsons sent Bellah a draft of his paper on "The Religious Background of the American Value System" and ask for his commentary. In a letter to Bellah of September 30, 1960, Parsons discussed his reading of Perry Miller's "An Errand into the Wilderness." Parsons wrote that Miller's discussion of the role of Calvinism "in the early New England theology ... is a first rate and fit beautifully with the broad position I have taken." Perry Miller (1905–1963) was a literary Harvard historian whose books such as "The New England Mind" established new standards for the writing of American cultural and religious history. Miller remain one of Parsons most favoured historians throughout his life. Indeed, religion had always a special place in Parsons heart, although his son in an interview maintained that he didn't really think that his father was "religious." Throughout his life Parsons interacted with a broad range of intellectuals and others who took a deep interest in religious belief systems, doctrines and institutions. One notable person among these people whom Parsons interacted with in this regard was Maria Augusta Neal who was a Catholic sister of Notre Dame de Namur, who would send Parsons countless of her manuscripts and invite him to Conferences and intellectual events in the Catholic Church. Maria Augusta Neal received her Ph.D. from Harvard under Parsons supervision in 1963 and would eventually became professor (then Chair) of sociology at Emmanuel College in Boston. Maria Augusta Neal was very enthusiastic about the Second Vatican Council and became known for the National Sisters Survey, which aimed at improving women's position in the Catholic Church.
Parsons and Winston White wrote together an article called "The Link Between Character and Society," which was published in 1961. Parsons and White's article was a critical discussion of David Riesman's "The Lonely Crowd," which had been published a decade earlier and which had turned into an unexpected bestseller reaching 1 million sold copies in 1977. Riesman was a prominent member of the American academic left influenced by Erich Fromm and the Frankfurt School. In reality, Riesman's book was an academic attempt to give credit to the concept of "mass society" and especially to the idea of an America suffocated in social conformity. Riesman had essentially argued that at the emerging of highly advanced capitalism, the America basic value-system and its socializing roles had change from an "inner-directed" toward an "other-directed" pattern of value-orientation. Parsons and White challenged Riesman's idea and argued that there had been no change away from an inner-directed personality structure. While noticing that Riesman's "other-directness" look like a caricature of Cooley's looking-glass self, they argued that the framework of "institutional individualism" as the basic code-structure of America's normative system had essentially not changed. What had happen, however, was that the industrialized process and its increased pattern of societal differentiation had changed the family's generalized symbolic function in society and had allowed for a greater permissiveness in the way the child related to his parents. This, however, Parsons and White argued, was not the prelude to greater "otherdirectness" but a more complicated way by which inner-directed pattern situated itself in the social environment.
Political power and the concept of Influence, 1963.
1963 became a notable year in Parsons's theoretical development because it was the year when he published two important articles; one on political power and one on the concept of influence. The two articles represented Parsons's first published attempt to work out the idea of Generalized Symbolic Media as an integral part of the exchange processes within the AGIL system. This was a theoretical development, which Parsons had worked on ever since the publication of "Economy and Society" (1956). The prime model for the generalized symbolic media was money and Parsons was reflecting on the question whether the functional characteristics of money represented an exclusive uniqueness of the economic system or whether it was possible to identify other generalized symbolic media in other subsystems as well. Although each medium had unique characteristics, Parsons claimed that power (for the political system) and influence (for the societal community) had institutional functions, which essentially was structurally similar to the general systemic function of money. Utilizing Roman Jakobson's idea of "code" and "message," Parsons divided the components of the media into a question of value-principle versus coordination standards for the "code-structure" and the question of factor versus product control within those social process which carried the "message" components. In this way, while "utility" could be regarded as the value-principle for the economy (medium: money), "effectiveness" was the value-principle for the political system (medium: political power) and solidarity for the societal community (medium: influence). Parsons would eventually chose the concept of value-commitment as the generalized symbolic medium for the fiduciary system with integrity as the value-principle.
In August 1963 Parsons got a new research assistant, Victor Lidz, who would become an important collaborator and colleague. In 1964 Parsons flew to Heidelberg in Germany in order to celebrate the 100th birthday of Max Weber and discuss Weber's work with Jürgen Habermas, Herbert Marcuse and others. Parsons delivered his paper "Evaluation and Objectivity in Social Science: An Interpretation of Max Weber's Contribution." The meeting became in reality a clash between pro-Weberian scholars and the representatives for the Frankfurther School. Before leaving for Germany Parsons discussed the upcoming meeting with Reinhard Bendix and commented that "I am afraid I will be something of a Daniel in the Lion's den." Bendix wrote back and told Parsons that Marcuse in his ears sounded very much like Christoph Steding (who was a Nazi philosopher).
Parsons conducted a persistent correspondence with noted scholar Benjamin Nelson, with whom he shared a common interest in the rise and destiny of civilizations, a correspondence which only ceased with Nelson's death in 1977. The two scholars also shared a common enthusiasm for the work of Max Weber and the two scholars would generally agree on the main interpretative approach to the study of Weber. Benjamin Nelson had participated in the Weber Centennial in Heidelberg and during the conference Nelson had got into a violent argument with Herbert Marcuse, whom he accused to tarnish Weber's name. In reading the written version of Nelson' s contribution to the Weber Centennial, Parsons wrote, "I cannot let the occasion pass without a word of congratulations which is strong enough so that if it were concert I should shout bravo." In several letters Nelson would keep Parsons informed of the often turbulent leftist environment of Herbert Marcuse. In the letter of September 1967, Nelson would tell Parsons how much he enjoyed reading Parsons' essay on "Kinship and the associational Aspect of Social Structure." Also, among the scholars on whom Parsons and Nelson would share internal commentaries was the work of Jürgen Habermas.
Mark Gould was educated at Reed College in Portland, Oregon, at the time a center for political radicalism. At Reed, Gould's theoretical interest was sparked by Professor Howard Jolly's exegesis of Parsons. Gould decided that he wanted to study with Parsons and arrived at Harvard in the fall of 1967 and entered Parsons' office, at their first meeting, with hair down to his shoulders, with a wild beard and dressed in the colorful manners of the late sixties. Gould would become Parsons' research assistant by the summer of 1968. Parsons was opposed to the Vietnam War, yet he was disturbed by what he considered the anti-intellectual tendency in the student rebellion, where serious debate often was substituted by handy slogans by Marx, Mao and Fidel Castro. Gould, who was thrown out by the state police from University Hall (at Harvard) early in the morning on April 10, 1969, often had heated discussions with Parsons about politics and society in Parsons' office, yet as Gould insisted these dialogues were always theoretically fruitful.
1960s: Toward a concept of the societal community: Ethnicity, kinship and diffuse solidarity.
Talcott Parsons had for years corresponded with his former graduate student David M. Schneider who had taught at the University of California Berkeley before he in 1960 accepted a position as professor in Anthropology at the University of Chicago. Schneider had received his Ph.D. at Harvard in Social Anthropology in 1949 and had become a leading expert in the American kinship system. Schneider had in 1968 published "American Kinship: A cultural account," which became a classic within the field and he had sent Parsons a copy of the copy-edited manuscript before publication. Parsons was highly appreciative of Schneider's work and Schneider became in many ways a crucial bouncing-point for Parsons' own attempt to understand the fundamental elements of the American kinship system, which for him was a key to understand the factor of ethnicity and especially to build up the theoretical foundation of his concept of the societal community, which by the beginning of the early 1970s had begun to become a strong priority in the number of theoretical projects, which occupied his intellectual life. Among other things Parsons borrowed the term "diffuse enduring solidarity" from Schneider as a major concept for his own considerations regarding the theoretical construction of the concept of the societal community. In the spring of 1968 Parsons and Schneider discussed Clifford Geertz's article on religion as a cultural system in regard to which Parsons wrote a review article. Parsons, who was a close friend of Geertz, was puzzled over Geertz's article. In a letter to David Schneider, Parsons spoke about "the rather sharp strictures on what he (Geertz) calls the extremely narrow intellectual tradition with special reference to Weber, but also to Durkheim. My basic point is in this respect, he greatly overstated his case seeming to argue that this intellectual tradition was by now irrelevant." David Schneider wrote back to Parsons, "So much, so often, as I read Cliff's stuff I cannot get a clear consistent picture of just what the religious system consist in instead only how it is said to work."
In a letter of July 1968 to Gene Tanke of the University of California Press, Parsons offers a critical note on the state of psychoanalytical theory and writes: "The use of psychoanalytical theory in interpretation of social and historical subject matter is somewhat hazardous enterprise, and a good deal of nonsense has been written in the name of such attempts." Around 1969, Parsons was approached by the prestigious "Encyclopedia of the History of Idea" about writing an entrance in the encyclopedia on the topic of the "Sociology of Knowledge." Parsons accepted and wrote one of his most powerful essays entitled "The Sociology of Knowledge and the History of Ideas" during the period of 1969-1970. In this essay Parsons discussed how the Sociology of knowledge as a modern intellectual discipline had emerged from the dynamics of European intellectual history reaching a kind of cutting point in the philosophy of Immanuel Kant and further explored by Hegel yet reaching its first "classical" formulation in the writing of Karl Mannheim, whose brilliance Parsons acknowledged yet also found himself in opposition to, since Mannheim never betrayed German historicism, whose antipositivistic epistemology was largely rejected in the more positivistic world of American social science. For various reasons the editors of the encyclopedia turned down Parsons essay since it didn't fit the general format of their volume, so Parsons essay was not published before 2006. Parsons had several conversations with Daniel Bell on a "Post-industrial society", some of which were conducted over lunch at William James Hall. After reading an early version of Bell's magnum opus, "The Coming of the Post-Industrial Society", Parsons wrote a letter to Daniel Bell dated November 30, 1971, where he offered his criticism. Among his many critical points, Parsons stressed especially that Bell's discussion of technology tended to "separate off culture" and treat these two categories "as what I would call culture minus the cognitive component."
Parsons's interest in the role of ethnicity and religion in the genesis of social solidarity within the local community heavily influenced another of his early 1960s graduate students, Edward Laumann. As a student, Laumann was interested in the role of social network structure in shaping community-level solidarity. Combining Parsons's interest in the role of ethnicity in shaping local community solidarity with W. Lloyd Warner's structural approach to social class, Laumann argued that ethnicity, religion, and perceived social class together play a large role in structuring community social networks. Laumann's work found that community networks are highly partitioned along lines of ethnicity, religion, and occupational social status. It also highlighted the tension individuals experience between their preference to associate with people who are like them (homophily) and the simultaneous desire to affiliate with higher-status others. Later, at the beginning of his career at the University of Chicago, Laumann would argue that how these impulses are resolved by individuals forms the basis of corporate or competitive class consciousness within a given community. In addition to demonstrating how community solidarity can be conceptualized as a social network, and the role of ethnicity, religion, and class in shaping such networks, Laumann's dissertation became one of the first examples of the use of population-based surveys in the collection of social network data, and thus a precursor to decades of egocentric social network analysis. Parsons thus played an important role in shaping social network analysis's early interest in homophily, and the use of egocentric network data to assess group- and community-level social network structures.
Early 1970s: System-theoretical considerations about biological and social systems.
In his later years Parsons became increasingly interested in working out the higher conceptual parameters of the human condition, which in part led him toward rethinking questions of cultural and social evolution and the "nature" of telic systems, the latter which he especially discussed with Robert Bellah, Victor Lidz, Reene Fox, Willy de Craemer and others. As a part of this pattern, Parsons became increasingly interested in clarifying the relationship between biological and social theory. Parsons was the initiator of the first Daedalus conference on "Some Relations between biological and social theory" sponsored by the American Academy of Arts and Science. Parsons wrote a memorandum dated September 16, 1971, where he spelled out the intellectual framework for the conference. As Parsons explained in the memo, the basic goal of the conference was to establish a conceptual fundament for a theory of living systems. The first conference was held on January 7, 1972. Among the participants beside Parsons and Victor Lidz were Ernst Mayr, Seymour Kety, Gerald Holton, A. Hunter Dupree, and William Wimsatt. A second Daedalus Conference on Living Systems was held on March 1–2, 1974 and included Edward O. Wilson, who at the time was about to publish his famous work on sociobiology. Other new participants were John T. Bonner, Karl H. Pribram, Eric Lennenberg and Stephen J. Gould.
Early 1970s.
Parsons began in the fall of 1972 to conduct a seminar on "Law and Sociology" with Lon L. Fuller who was well known for his work "The Morality of Law" (1964). The seminar and his conversations with Fuller stimulated Parsons to write one of this most influential articles "Law as an Intellectual Stepchild." In this article Parsons discusses among other things Roberto Mangabeira Unger's "Law in Modern Society" (1976). Another indication of Parsons interest in law is reflected in his students, hence Parsons' student John Akula writes his dissertation in Sociology on the topic "Law and the Development of Citizenship" (1973). In September 1972 Parsons participates in a Conference in Salzburg on "The Social Consequences of Modernization in Socialist Countries." Among the other participants in this conference is Alex Inkeles, Ezra Vogel, and Ralf Dahrendorf.
In 1972 Parsons wrote two review articles, where he discussed the work of Reinhard Bendix, which provides a clear statement on Parsons' approach to the study of Max Weber. Bendix was an emigrant scholar who had become well known for his Weber-interpretations. In the first review article, Parsons analyzed Bendix's work entitled "Embattled Reason." Parsons basically praised the work's attempt to defend the basic values of cognitive rationality, a defense Parsons unconditionally shared and he agree with Bendix that the question of cognitive rationality was primarily a cultural issue and not a category, which could be reduced from biologial, economic and social factors. However, Parsons did have problems with the way Bendix had proceed with his task and he especially felt that Bendix had misrepresented the work of Freud and Durkheim. Parsons found that the real reason behind this case of misrepresentation lied in the way Bendix tended to conceive the question of systematic theorizing under the concept of "reductionism." Parsons further found that Bendix approach suffered from a "conspicuous hostility" toward the idea of evolution. It was true Parsons assessed that Max Weber rejected the one-linear evolutionary approaches of Karl Marx and Herbert Spencer but it didn't follow that Weber rejected the question of evolution as a generalized question. In his second review article, which was a commentary of Reinhard Bendix and Guenther Roth, "Scholarship and Partisanship: Essays on Max Weber," Parsons continued his line of criticism. Parsons was especially concerned with a statement by Bendix, where Bendix claimed that Weber was a subscriber to Karl Marx's notion that ideas were "the epiphenomena of the organization of production." Parsons strongly rejected this assessment. As he said: "I should contend that certainly the intellectual "mature" Weber never was an "hypothetical" Marxist." Somewhere behind these attitudes of Bendix, Parsons detected a discomport on Bendix behalf to move out of an "idiographic" mode of theorizing.
In 1973 Parsons published "The American University," which he had coauthored together with Gerald M. Platt. The idea had originally emerged then Martin Meyerson and Stephen Graubard of the American Academy of the Art and Sciences in 1969 asked Parsons to undertake a monographic study of the American University System. The work on the book went on for years and was first finished in June 1972. From the theoretical point of view the book had several functions, one important one was to substantiate Parsons' concept of the educational revolution, which was a crucial component in his theory of the rise of the modern world. What was equally intellectually compelling, however, was undoubtedly Parsons' discussion of "the cognitive complex", which aimed at explaining how cognitive rationality and learning operated as an interpenetrative zone on the level of the general action-system in society. In retrospect the categories of "the cognitive complex" serve as a theoretical foundation for an understanding of what has been called the modern knowledge-based society.
Retired from Harvard, 1973.
He retired from Harvard in 1973, but continued his writing, teaching and other activities in the same rapid pace as before. Parsons also continued his extensive correspondence with a wide group of colleagues and intellectuals. He taught at the University of Pennsylvania, Brown University, Rutgers University, the University of Chicago and the University of California at Berkeley. At Parsons' retirement banquet held on May 18, 1973, Robert K. Merton was asked to preside, while John Riley, Bernard Barber, Jesse Pitts, Neil J. Smelser and John Akula were asked to share their experiences of the man with the audience.
One scholar who became important in Parsons' later years was professor Martin U. Martel of Brown University. Martel and Parsons made contact in the early 1970s, the occasion was a discussion of an article, which Martel had written about Talcott Parsons' work. Martel arranged a series of seminars at Brown University in 1973-74, where Parsons spoke about his life and work and answered question from students and faculty. Among the participants at the seminars were Martin U. Martel, Robert M. Marsh, Dietrich Rueschemeyer, C. Parker Wolf, Albert F. Wessen, A. Hunter Dupree, Philip L. Quinn, Adrian Hayes and Mark A. Shields. In February–May 1974, Parsons also gave the Culver lectures at Brown and spoke on the issue "The Evolution of Society." These lectures as well as the seminars were videotaped.
Late in life Parsons began to work out a new level of the AGIL model, which he called "A Paradigm of the Human Condition." This new level of the AGIL model crystallized in the summer of 1974 and the ideas of the new paradigm he worked out with a variety of people but especially with Victor Lidz, Renee Fox and Harold Bershady. The new meta-paradigm featured the environment of the general action system, which include the physical system, the biological system and what Parsons called the telic system; the latter system represented the sphere of ultimate values in a sheer metaphysical sense. Parsons also worked toward a more comprehensive understanding of the code-structure of social systems and on the logic of the cybernetic pattern of control facilitating the AGIL model, where he among many things worked out a bulk of notes, he called "Thoughts on the linking of systems" and another memo he called "money and time." He had also extensive discussions with Larry Brownstein and Adrian Hayes concerning the possibility of a mathematical formalization of Parsons' theory.
Parsons had during his lifetime worked intensively with questions of medical sociology, the medical profession, psychiatry, psychosomatic problems and related issues with the questions of health and illness. Most of all Parsons had become known for his concept of "the Sick role." This field of social research was an issue, which Parsons constantly developed through elaboration and self-criticism. Parsons participated at the World Congress of Sociology in Toronto in August 1974, where he presented a paper called "The sick role revisited: a response to critics and an updating in terms of the theory of action," which was published under a slightly different title in 1975. In his essay Parsons highlighted that his concept of "sick role" never was meant to confine this category to "deviant behavior," although as he stated it: "its negative valuation should not be forgotten." It was also important to keep a certain focus on the "motivatedness" of illness, since there always is a factor of unconscious motivation in the therapeutic aspects of the sick role.
In 1975 Robert N. Bellah published his book called "The Broken Covenant." "The Covenant" Bellah refers to the sermon delivered by John Winthrop (1587–1649) to this flock on board his ship 'Arbella' on the evening of the landing in Massachusetts Bay in the year 1630. In his sermon Winthrop declared that the Puritan colonists emigrating to the New World was part of a special pact (Covenant) with God to create a holy community. Winthrop used the phrases: "For we must consider that we shall be a city on the hill. The eyes of all people are upon us." Parsons disagreed strongly with Bellah's analysis in "The Broken Covenant" and insisted that "the covenant" was not broken. Parsons later used a major part of his influential article, "Law as an Intellectual Stepchild" to discuss Bellah's position in "The Broken Covenant." Parsons found that Bellah unduly trivialized the discussion of the tension and problems involved in questions of individual interests and collective interests on the level of total society by reducing them to the concept of "capitalism." Parsons find that Bellah in his characterization of the negative aspects of American society is compelled by a charismatic based optimalism and he declared that Bellah's position in "The Broken Covenant" is that of moral absolutism.
In 1975 Parsons responded to an article by Jonathan H. Turner called "Parsons as a symbolic interactionist." In his response Parsons acknowledged that action theory and symbolic interactionism should not be regarded as two separate, antagonistic positions; in contrast they have overlapping structures of conceptualization. Parsons regarded symbolic interactionism and the theory of George Herbert Mead as valuable contributions to action theory specifying certain aspects of the theory of the personality of the individual. Parsons, however, criticized the symbolic interactionism of Herbert Blumer, since in Blumer's theory there is no end to the openness of action. Parsons regarded Blumer as the mirror image of Claude Lévi-Strauss who tended to stress the quasi-determined nature of macro-structural systems. Action theory, Parsons maintained, represented a middle ground between these two extremes.
In 1976 Parsons was asked to contribute to a volume celebrating the eightieth years birthday of Jean Piaget. Parsons contributed with an essay called "A few considerations on the place of rationality in Modern Culture and Society." Parsons characterized Piaget as the most eminent contributor to cognitive theory in the 20th century. However, in his article, he also argued that the future study of cognition had to go beyond its narrow encounter with psychology and aim at a higher understanding of how cognition as a human intellectual force was entangled in the processes of social and cultural institutionalization.
In 1978, when James Grier Miller published his famous work "Living Systems", Parsons was approached by "Contemporary Sociology" who asked him to write a review article on Miller's work. Parsons had already complained in a letter to A. Hunter Dupree that American intellectual life suffered from a deep-seated tradition of empiricism and he saw Miller's book the latest confirmation of that tradition. In his review article called "Concrete and "Abstracted" systems, he generally praised the herculean task behind Miller's work but he criticized Miller for getting caught in the effort of hierarchize concrete systems while underplaying the importance of structural categories in theory building. Parsons was also concerned about Miller's lack of any clear-cut discrimination between cultural and non-cultural systems.
In Japan, 1978.
Japan was a country where from early on there was a keen interest in Talcott Parsons' work. As early as 1958 a Japanese translation of "Economy and Society" appeared. Also "The Structure of Social Action" was translated into Japanese. In the same way, "The Social System" was translated into Japanese by Tsutomu Sato in 1974. Indeed, already Ryozo Takeda had in 1952 in his "Shakaigaku no Kozo (The Framework of Sociology)" introduced Japanese scholars to some of Parsons' ideas. Parsons visited Japan for the first time in 1972, where he gave a lecture on November 25 to the Japanese Sociological Association entitled "Some Reflections on Post-Industrial Society." The lecture was published in "The Japanese Sociological Review." At the same time Parsons participated in an international symposium on "New Problems of Advanced Societies," that was held in Tokyo and two short articles written by Parsons appeared in the proceedings of the symposium in 1973. Ken'ichi Tominaga (born, 1931), a leading figure in Japanese Sociology and professor at the University of Tokyo was asked by Victor Lidz to contribute to a two-volume collection of Essays in honor of Talcott Parsons. Ken'ichi Tominaga wrote an essays on the industrial growth model of Japan using Parsons' AGIL Model.
In 1977, professor Washio Kurata, who just had been elected Dean of the Faculty of Sociology of Kwansei Gakuin University wrote to Parsons and invited him to visit Japan during the 1978-79 academic year. In the early spring Parsons accepted Kurata's invitation and on October 20, 1978 Parsons arrived in airport of Osaka, accompanied by his wife and was greeted royally by a large entourage.
Parsons began weekly lectures at Kwansei Gakuin's sociology department from October 23 to December 15. Parsons gave his first public lecture to a huge mass of undergraduates speaking on the issue of "The Development of Contemporary Sociology," while professor Hideichiro Nakano served as an interpreter. On November 17–18, when the Sengari Seminar House was opened, Parsons was invited as the key speaker at the event and gave two lectures, one entitled "On the Crisis of Modern Society" and the other on "Modern Society and Religion." Among those present at this event were Ken'ichi Tominaga, Mutsundo Atarashi, Kazuo Muto and Hideichiro Nakano.
On November 25 Parsons lectured at Kobe University. This lecture was organized by Hiroshi Mannari and Parsons lectured on the topic of organization theory to faculty and graduate students from the department of economics, management and sociology. Also faculty members from Kyoto and Osaka Universities were present. The lecture was published the following year. On November 30-December 1, Parsons participated in the Tsukuba (University) Conference in Tokyo, where Parsons spoke on "Enter the New Society: The Problem of the Relationship of Work and Leisure in Relation to Economic and Cultural Values." On December 5, Parsons gave a lecture at Kyoto University on the topic "A Sociologist Looks at Contemporary U.S. Society."
At a special lecture at Osaka on December 12, Parsons spoke at the suggestion of Tominaga on the topic "Social System Theory and Organization Theory" to the Japanese Sociological Association. Earlier the same day Parsons had a discussion with Professor Ken'ichi Tominaga at Iwanami Shoten, which was published in the journal SHISO.
On December 14, Kwansei Gakuin University granted Parsons an honorary doctor degree. A number of his lectures was collected into a volume by Dean Kurata and published in 1983. The Parsons` flew back to the US in mid-December 1978. As a sign of friendship Hideichiro Nakano sent Parsons a Buddha mask. Parsons had especially been captivated by certain aspects of Zen Buddhism. He told his friends that after his experience in Japan he was going to reconsider certain aspects of his interpretation of the origins of modern civilizations.
The end, 1979.
Parsons died of a stroke on May 8, 1979 in Munich while on a trip to Germany, where he was celebrating the 50th anniversary of his Heidelberg degree. The day before he died he gave a lecture on the declining significance of social class for an audience of German intellectuals, including Jürgen Habermas, Niklas Luhmann, Richard Münch and Wolfgang Schluchter.
Parsons was a strong advocate for the professionalization of sociology and its expansion within American academia. He was elected president of the American Sociological Association in 1949 and served as secretary from 1960–1965.
His son Charles Parsons is a distinguished figure in philosophy of mathematics and an expert in Immanuel Kant. His daughter Anne Parsons committed suicide in June 1964 at the age of 33.
Work.
Parsons produced a general theoretical system for the analysis of society, which he called 'theory of action' based on the methodological and epistemological principle of "analytical realism" and on the ontological assumption of "voluntaristic action." Parsons concept of analytical realism can be regarded as a kind of compromise between nominalist and realist views on the nature of reality and human knowledge. Parsons assesses that we (as scientists and humans) relate to objective reality but only through a particular encounter of such reality, and that our general intellectual understanding is only feasible through conceptual schemes and theories. Our interaction with objective reality on an intellectual level should always be understood as an approach. Parsons often explicated the meaning of analytical realism by quoting a statement by L.J. Henderson: "A fact is a statement about experience in terms of a conceptual scheme."
Generally, Parsons maintained that his inspiration regarding analytical realism had been Lawrence Joseph Henderson and A.N. Whitehead although it is possible the idea originated much earlier. It is important in this regard that Parsons' "analytical realism" insist on the reference to an objective reality since Parsons at several occasions highlighted that his concept of "analytical realism" was importantly different from the "fictionalism" of Hans Vaihiger (Hans Vaihinger). As Parsons specify this: "We must start with the assertion that all knowledge which purports to be valid in anything like the scientific sense presumes both the reality of object known and of a knower. I think we can go beyond that and say that there must be a community of knowers who are able to communicate with each other. Without such a presupposition it would seem difficult to avoid the pitfall of solipsism. The so-called natural sciences do not, however, impute the "status of knowing subjects" to the objects with which they deal."
The Structure of Social Action.
"The Structure of Social Action" (SSA), Parsons' most famous work, took form piece by piece. Its central figure was Weber and the other key figures in the discussion were added little by little as the central idea took form. One important work that helped Parsons' central argument in SSA was when in 1932 he unexpectedly found Élie Halévy, "La Formation du Radicalisme Philosophique," (1901–1904) a 3 volume work, which he read in French. About Halévy work Parsons explained, "Well, Halévy was just a different world ... and helped me to really get in to many clarifications of the assumptions distinctive to the main line of British utilitarian thought; assumptions about the 'natural identity of interest', and so on. I still think it is one of the true masterpieces in intellectual history." Parsons first achieved significant recognition with the publication of "The Structure of Social Action" (1937), his first grand synthesis, combining the ideas of Durkheim, Max Weber, and Pareto, among others.
Parsons' action theory.
Parsons' action theory can be characterized as an attempt to maintain the scientific rigour of positivism, while acknowledging the necessity of the "subjective dimension" of human action incorporated in hermeneutic types of sociological theories. It is cardinal in Parsons' general theoretical and methodological view that human action must be understood in conjunction with the motivational component of the human act. In this way social science must consider the question of ends, purpose and ideals in its analysis of human action. Parsons' strong reaction to behavioristic theory as well as to sheer materialistic approaches derives from the attempt of these theoretical positions to eliminate ends, purpose and ideals as factors of analysis. Parsons already in his college student term-papers at Amherst criticized attempts to reduce human life to psychological, biological or materialist forces. What was essential in human life, Parsons maintained, was how the factor of culture was codified. Culture, however, was to Parsons an independent variable in that it could not be "deducted" from any other factor of the social system. This methodological intention is given the most elaborate presentation in "The Structure of Social Action," which was Parsons' first basic discussion of the methodological foundation of the social sciences. Some of the themes reaching a high point in "The Structure of Social Action" were presented in a compelling essay published two years earlier with the title: "The Place of Ultimate Values in Sociological Theory."
Relations to cybernetics and system theory.
Parsons developed his ideas during a period when systems theory and cybernetics were very much on the front burner of social and behavioral science. In using systems thinking, he postulated that the relevant systems treated in social and behavioral science were "open," meaning that they were embedded in an environment consisting of other systems. For social and behavioral science, the largest system is "the action system," consisting of interrelated behaviors of human beings, embedded in a physical-organic environment.
As Parsons developed his theory it became increasingly bound to the fields of cybernetics and system theory, but also to Alfred E. Emerson's concept of "homeostasis" and Ernst Mayr's concept of "teleonomic processes." On the meta-theoretical level Parson attempted to balance psychologist phenomenology and idealism on the one hand and pure types of what Parsons called the utilitarian-positivistic complex, on the other hand. The theory includes a general theory of social evolution and a concrete interpretation of the major drives of world-history. In Parsons' theory of history and evolution, the constitutive-cognitive symbolization of the cybernetic hierarchy of action-systemic levels has in principle the same function as genetic information in DNA's control of biological evolution, except this factor of meta-systemic control does not "determine" any outcome, but rather defines the orientational boundaries of the real pathfinder, which is action itself. Parsons compares also the constitutive level of society with Noam Chomsky's concept of "deep structure." As Parsons writes, "The deep structures do not as such articulate any sentences which could convey coherent meaning. The surface structures constitute the level at which this occurs. The connecting link between them is a set of rules of transformation, to use Chomsky's own phase." These transformative processes and entities are generally (at least on one level of empirical analysis) performed or actualized by myths and religions but also philosophies, art-systems, or even semiotic consumer behavior might in principle perform this function.
A unified concept of social science.
Parsons' theory reflects a vision of a unified concept of social science and indeed, of living systems in general. Parsons' approach differs in essence from Niklas Luhmann's theory because Parsons rejects the idea that systems can be autopoietic short of the actual action-system of individual actors. Systems have immanent capacities but only as an outcome of the institutionalized processes of action-systems, which in the final analysis consists of the historical effort of individual actors. While Niklas Luhmann became caught up in sheer systemic immanence, Parsons insisted that the question of autocatalytic and homeostatic processes on the one hand, and the question about the actor as the ultimate "first mover" on the other, was not mutually exclusive. Homeostatic processes might be "necessary" if and when they occur but action is "necessitating."
It is only within this perspective of the ultimate reference in action that Parsons' dictum that higher order cybernetic systems during the course of history will tend to control social forms organized on the lower levels of the cybernetic hierarchy, should be understood. For Parsons the highest levels of the cybernetic hierarchy as far as the general action level is concerned is what Parsons calls the constitutive part of the Cultural system (the L of the L). However, within the interactional processes of the system specially attention should be made to the cultural-expressivistic axis (the L-G line in the AGIL). By the term "constitutive," Parsons generally referred to very highly codified cultural values especially religious elements (but other interpretation of the term "constitutive" is possible). Cultural systems Parsons maintained had an independent status from that of the normative and orientational pattern of the social system; the one system cannot be reduced to the other. For example, the question of the "cultural capital" of a social system as a sheer historical entity (that is, in its function as a "fiduciary system"), is not identical with the higher cultural values of that system; that is, the cultural system is embodied with a meta-structural logic there cannot be reduced to any given social system or cannot be viewed as a materialist (or behavioralist) deduction from the "necessities" of the social system (or from the "necessities" of its economy). Within this context, culture would have an independent power of transition, not only as factors of actual socio-cultural units (like Western civilization or China) but also in the way original cultural bases would tend to "universalize" through interpenetration and spread over large numbers of social systems as with classical Greece and Israel, where the original social bases had died but where the cultural system survived as an independently "working" cultural pattern, as in the case of Greek philosophy or in the case of Christianity as a modified derivation from its original seed-bed in ancient Israel.
Parsons and Habermas.
The difference between Parsons and Jürgen Habermas lies essentially in how Habermas uses Parsons' theory to establish the basic propositions of his own. Habermas takes the division between Parsons' separation between the "outer" and the "inner" dimensions of the social system and labels them "system" (outer dimension (A-G)) and "lifeworld" (inner dimension (I-L)). The problem with this model from Parsons' point of view is a) that conflict within the social system can in reality emerge from any relational point and not simply from the system-lifeworld dichotomy, and b) by relating the system-lifeworld model to some kind of "liberation"-epic, Habermas produces the Utopian notion that the potentiality of conflict within the social system has some kind of "final solution," which produces a misleading concept of the nature of systemic conflict.
General theory.
It is important to highlight that Parsons discriminates between two "meanings" or modes of the term "general theory." For some purposes he speaks about general theory as those aspects of theoretical concerns for the field of the social sciences, where the focus is on the most "constitutive" elements of cognitive concern for the basic theoretical systematization of a given field. Within these concerns Parsons would include the basic conceptual scheme for the given field, including its highest order of theoretical relations and naturally also the necessary specification of this system's axiomatic, epistemological and methodological foundations from the point of view of logical implications. All these elements would signify the quest for a general theory on the highest level of theoretical concern. However, the term general theory also referred to a more fully operational system, which was a system, where the implications of the conceptual scheme was "spelled out" on lower levels of cognitive structuralization, that is, levels standing closer to a perceived "empirical object." In his speech to the American Sociological Society in 1947, he spoke of five of such levels. These levels were the following:
During his life Parsons would work on developing all five fields of theoretical concerns but he would pay special attention to the development on the highest "constitutive" level, since the rest of the building would stand or fall on the solidity of the highest level.
Contrary to prevailing myths Parsons never thought that modern societies exist in some kind of perfect harmony with their norms or that most modern societies necessary were characterized by some high level of consensus or a "happy" institutional integration. Parsons highlighted two things in this regard. a) It is almost logically impossible that there can be any "perfect fit" or perfect consensus situation in the basic normative structure of complex modern societies because the basic value-pattern of modern societies are generally differentiated in such a way so some of the basic normative categories will exist in inherent conflict with each other if not actually, then at least potentially. For example, both freedom and equality is generally viewed as fundamental and in a sense non-negotiable values of modern societies. Each represents a kind of ultimate imperative about what the higher values of humanity is all about. However, as Parsons emphasizes there does not exist any simple answer to the priority of freedom versus equality or any simple solution to how they possibly can be mediated if at all. Therefore all modern societies are faced with the inherent conflict prevailing between these two values of which there is no "eternal solution" as such. For this reason alone, there cannot exist any perfect match between motivational pattern, normative solutions and the prevailing value-pattern in any modern society. Parsons would also maintain that the never-ending "dispute" between "left" and "right" had something to do with the fact that they both defend ultimately "justified" human values (or ideals), which each on their own terms are indispensable as values but these fundamental values will always exist in an endless conflictual position to each other. b) As a general token Parsons always maintained that the integration of normative pattern in society always is problematic and the level of integration reached are in principle always far from harmonious and perfect. If some "harmonious pattern" does emerge, then it is related to specific historical circumstances, it is not a general law of the social systems.
AGIL paradigm.
The heuristic scheme Parsons used to analyze systems and subsystems is called the "AGIL Paradigm", "AGIL scheme". To survive or maintain equilibrium with respect to its environment, any system must to some degree adapt to that environment (Adaptation), attain its goals (Goal Attainment), integrate its components (Integration), and maintain its latent pattern (Latency Pattern Maintenance), a sort of cultural template. These concepts can be abbreviated as AGIL. These are called the system's functional imperatives. It is important to understand that Parsons AGIL model is an analytical scheme for the sake of theoretical "production," it is not any simple "copy" or any direct historical "summary" of empirical reality. Also the scheme itself doesn't explain "anything" as little as the periodical table in the natural sciences explains anything in and by itself. The AGIL scheme is a tool for explanations and no better than the quality of those theories and explanation by which it is processed.
In the case of the analysis of a social action system, the AGIL Paradigm, according to Parsons, yields four interrelated and interpenetrating subsystems: the behavioral systems of its members (A), the personality systems of those members (G), the social system (as such) (I) and the cultural system of that society (L). To analyze a society as a social system (the I subsystem of action), people are posited to enact roles associated with positions. These positions and roles become differentiated to some extent and in a modern society are associated with things such as occupational, political, judicial and educational roles.
Considering the interrelation of these specialized roles, as well as functionally differentiated collectivities (e.g., firms, political parties), the society can be analyzed as a complex system of interrelated functional subsystems, namely:
The pure AGIL model for all living systems:
The Social system level:
The General Action Level:
The cultural level:
The Generalized Symbolic media:
Social System level:
Parsons elaborated upon the idea that each of these systems also developed some specialized symbolic mechanisms of interaction analogous to money in the economy, e.g.., influence in the social community. Various processes of "interchange" among the subsystems of the social system were postulated.
Parsons' use of social systems analysis based on the AGIL scheme was established in his work "Economy and Society" (with N. Smelser, 1956) and has prevailed in all his work ever since. However, the AGIL system does only exist in a "rudimentary" form in the beginning and is then gradually elaborated and expanded in the decades which followed. A brief introduction to Parsons' AGIL scheme can be found in chapter 2 of "The American University" (with G. Platt, 1973). There is, however, no single place in Parsons writing where the total AGIL system is visually displayed or explained—the complete system have to be reconstructed from multiple places in his writing. The system displayed in "The American University" is only the most basic elements and should not be mistaken for the whole system.
Social evolutionism.
Parsons contributed to the field of social evolutionism and neoevolutionism. He divided evolution into four sub-processes:
Furthermore, Parsons explored these sub-processes within three stages of evolution:
Parsons viewed Western civilisation as the pinnacle of modern societies, and out of all western cultures he declared the United States as the most dynamically developed.
Parsons' late work focused on a new theoretical synthesis around four functions common (he claimed) to all systems of action—from the behavioral to the cultural, and a set of symbolic media that enable communication across them. His attempt to structure the world of action according to a scheme that focused on order was unacceptable for American sociologists, who were at that time retreating from the grand pretensions of the 1960s to a more empirical, grounded approach.
Pattern variables.
Parsons asserted that there were not two dimensions to societies: instrumental and expressive. By this he meant that there are qualitative differences between kinds of social interaction.
He observed that people can have personalized and formally detached relationships based on the roles that they play. The characteristics that were associated with each kind of interaction he called the "pattern variables".
An interaction can be characterized by one identifier of each contrastive pair:
Influences.
For many years Parsons was the best-known sociologist in the United States, and indeed one of the most influential and most controversial sociologists in the world. His work was very influential well into the 1960s, particularly in the United States, until it met with extensive criticism and was generally dismissed by the 1970s. Currently, interest in Parsons is increasing worldwide. Despite the traditional view that Parsons' theories are unsatisfactory if not inaccessible, prominent attempts to revive Parsonian thinking have been made by Parsonsian sociologists and social scientists like Jeffrey Alexander, Bryan S. Turner, Victor Lidz, Giuseppe Sciortino, Helmut Staubmann, David Sciulli, Richard Münch, Roland Robertson, A. Javier Trevino, Mark Gould, Thomas J. Fararo, Harold J. Bershady, Reneé Fox, Leon Mayhew, Jens Beckert, Harald Wenzel, Bernard Barber, Robert Holton, Frank J. Lechner, Rudolf Stichweh, Mathieu Deflem, Wolfgang Schluchter, Riccardo Prandini, Akira Tokuyasu, Kiyomitsu Yui, Kazuyoshi Takagi and Ken'chi Tominaga, the latter a towering figure in Japanese sociology. On the issue of studying Parsons' biographical and historical data scholars such as William Buxton, Uta Gerhardt, Charles Camic, Lawrence T. Nichols, and Jens Kaalhauge Nielsen have been most prominent. The key centers of Parsons interest today beside the US are Germany, Japan, Italy, and the United Kingdom.
Parsons had a seminal influence and early mentorship of many American and international scholars among them Ralf Dahrendorf, Alain Touraine, Niklas Luhmann and Jürgen Habermas.

</doc>
<doc id="54044" url="http://en.wikipedia.org/wiki?curid=54044" title="Gothic architecture">
Gothic architecture

Gothic architecture is a style of architecture that flourished during the high and late medieval period. It evolved from Romanesque architecture and was succeeded by Renaissance architecture. Originating in 12th-century France and lasting into the 16th century, Gothic architecture was known during the period as "Opus Francigenum" ("French work") with the term "Gothic" first appearing during the later part of the Renaissance. Its characteristics include the pointed arch, the ribbed vault and the flying buttress. Gothic architecture is most familiar as the architecture of many of the great cathedrals, abbeys and churches of Europe. It is also the architecture of many castles, palaces, town halls, guild halls, universities and to a less prominent extent, private dwellings.
It is in the great churches and cathedrals and in a number of civic buildings that the Gothic style was expressed most powerfully, its characteristics lending themselves to appeals to the emotions, whether springing from faith or from civic pride. A great number of ecclesiastical buildings remain from this period, of which even the smallest are often structures of architectural distinction while many of the larger churches are considered priceless works of art and are listed with UNESCO as World Heritage Sites. For this reason a study of Gothic architecture is largely a study of cathedrals and churches.
A series of Gothic revivals began in mid-18th-century England, spread through 19th-century Europe and continued, largely for ecclesiastical and university structures, into the 20th century.
The term "Gothic".
The term "Gothic architecture" originated as a pejorative description. Giorgio Vasari used the term "barbarous German style" in his Lives of the Most Excellent Painters, Sculptors, and Architects to describe what is now considered the Gothic style, and in the introduction to the "Lives" he attributes various architectural features to "the Goths" whom he holds responsible for destroying the ancient buildings after they conquered Rome, and erecting new ones in this style. At the time in which Vasari was writing, Italy had experienced a century of building in the Classical architectural vocabulary revived in the Renaissance and seen as evidence of a new Golden Age of learning and refinement.
The Renaissance had then overtaken Europe, overturning a system of culture that, prior to the advent of printing, was almost entirely focused on the Church and was perceived, in retrospect, as a period of ignorance and superstition. Hence, François Rabelais, also of the 16th century, imagines an inscription over the door of his utopian Abbey of Thélème, "Here enter no hypocrites, bigots..." slipping in a slighting reference to "Gotz" and "Ostrogotz."
In English 17th-century usage, "Goth" was an equivalent of "vandal", a savage despoiler with a Germanic heritage, and so came to be applied to the architectural styles of northern Europe from before the revival of classical types of architecture.
According to a 19th-century correspondent in the London Journal "Notes and Queries":
There can be no doubt that the term 'Gothic' as applied to pointed styles of ecclesiastical architecture was used at first contemptuously, and in derision, by those who were ambitious to imitate and revive the Grecian orders of architecture, after the revival of classical literature. Authorities such as Christopher Wren lent their aid in deprecating the old medieval style, which they termed Gothic, as synonymous with everything that was barbarous and rude.
On 21 July 1710, the Académie d'Architecture met in Paris, and among the subjects they discussed, the assembled company noted the new fashions of bowed and cusped arches on chimneypieces being employed "to finish the top of their openings. The Company disapproved of several of these new manners, which are defective and which belong for the most part to the Gothic."
Definition and scope.
Gothic architecture is the architecture of the late medieval period, characterised by use of the pointed arch. Other features common to Gothic architecture are the rib vault, buttresses, including flying buttresses; large windows which are often grouped, or have tracery; rose windows, towers, spires and pinnacles; and ornate façades.
As an architectural style, Gothic developed primarily in ecclesiastical architecture, and its principles and characteristic forms were applied to other types of buildings. Buildings of every type were constructed in the Gothic style, with evidence remaining of simple domestic buildings, elegant town houses, grand palaces, commercial premises, civic buildings, castles, city walls, bridges, village churches, abbey churches, abbey complexes and large cathedrals.
The greatest number of surviving Gothic buildings are churches. These range from tiny chapels to large cathedrals, and although many have been extended and altered in different styles, a large number remain either substantially intact or sympathetically restored, demonstrating the form, character and decoration of Gothic architecture. The Gothic style is most particularly associated with the great cathedrals of Northern France, England and Spain, with other fine examples occurring across Europe. 
Influences.
Political.
At the end of the 12th century, Europe was divided into a multitude of city states and kingdoms. The area encompassing modern Germany, southern Denmark, the Netherlands, Belgium, Luxembourg, Switzerland, Austria, Slovakia, Czech Republic and much of northern Italy (excluding Venice and Papal State) was nominally part of the Holy Roman Empire, but local rulers exercised considerable autonomy. France, Denmark, Poland, Hungary, Portugal, Scotland, Castile, Aragon, Navarre, Sicily and Cyprus were independent kingdoms, as was the Angevin Empire, whose Plantagenet kings ruled England and large domains in what was to become modern France. Norway came under the influence of England, while the other Scandinavian countries and Poland were influenced by trading contacts with the Hanseatic League. Angevin kings brought the Gothic tradition from France to Southern Italy, while Lusignan kings introduced French Gothic architecture to Cyprus.
Throughout Europe at this time there was a rapid growth in trade and an associated growth in towns. Germany and the Lowlands had large flourishing towns that grew in comparative peace, in trade and competition with each other, or united for mutual weal, as in the Hanseatic League. Civic building was of great importance to these towns as a sign of wealth and pride. England and France remained largely feudal and produced grand domestic architecture for their kings, dukes and bishops, rather than grand town halls for their burghers.
Religious.
The Catholic Church prevailed across Europe at this time, influencing not only faith but also wealth and power. Bishops were appointed by the Church and often ruled as virtual princes over large estates. The early Medieval periods had seen a rapid growth in monasticism, with several different orders being prevalent and spreading their influence widely. Foremost were the Benedictines whose great abbey churches vastly outnumbered any others in England. A part of their influence was that they tended to build within towns, unlike the Cistercians whose ruined abbeys are seen in the remote countryside. The Cluniac and Cistercian Orders were prevalent in France, the great monastery at Cluny having established a formula for a well planned monastic site which was then to influence all subsequent monastic building for many centuries.
In the 13th century St. Francis of Assisi established the Franciscans, or so-called "Grey Friars", a mendicant order. The Dominicans, another mendicant order founded during the same period but by St. Dominic in Toulouse and Bologna, were particularly influential in the building of Italy's Gothic churches.
Geographic.
From the 10th to the 13th century, Romanesque architecture had become a pan-European style and manner of construction, affecting buildings in countries as far apart as Ireland, Croatia, Sweden and Sicily. The same wide geographic area was then affected by the development of Gothic architecture, but the acceptance of the Gothic style and methods of construction differed from place to place, as did the expressions of Gothic taste. The proximity of some regions meant that modern country borders do not define divisions of style. On the other hand, some regions such as England and Spain produced defining characteristics rarely seen elsewhere, except where they have been carried by itinerant craftsmen, or the transfer of bishops. Regional differences that are apparent in the great abbey churches and cathedrals of the Romanesque period often become even more apparent in the Gothic.
The local availability of materials affected both construction and style. In France, limestone was readily available in several grades, the very fine white limestone of Caen being favoured for sculptural decoration. England had coarse limestone and red sandstone as well as dark green Purbeck marble which was often used for architectural features.
In Northern Germany, Netherlands, northern Poland, Denmark, and the Baltic countries local building stone was unavailable but there was a strong tradition of building in brick. The resultant style, Brick Gothic, is called "Backsteingotik" in Germany and Scandinavia and is associated with the Hanseatic League. In Italy, stone was used for fortifications, but brick was preferred for other buildings. Because of the extensive and varied deposits of marble, many buildings were faced in marble, or were left with undecorated façade so that this might be achieved at a later date.
The availability of timber also influenced the style of architecture, with timber buildings prevailing in Scandinavia. Availability of timber affected methods of roof construction across Europe. It is thought that the magnificent hammer-beam roofs of England were devised as a direct response to the lack of long straight seasoned timber by the end of the Medieval period, when forests had been decimated not only for the construction of vast roofs but also for ship building.
Architectural background.
Gothic architecture grew out of the previous architectural genre, Romanesque. For the most part, there was not a clean break, as there was to be later in Renaissance Florence with the revival of the Classical style by Filippo Brunelleschi in the early 15th century, and the sudden abandonment in Renaissance Italy of both the style and the structural characteristics of Gothic.
Romanesque tradition.
By the 12th century, Romanesque architecture (termed Norman architecture in England because of its association with the Norman invasion), was established throughout Europe and provided the basic architectural forms and units that were to remain in evolution throughout the Medieval period. The important categories of building: the cathedral church, the parish church, the monastery, the castle, the palace, the great hall, the gatehouse, the civic building, had been established in the Romanesque period.
Many architectural features that are associated with Gothic architecture had been developed and used by the architects of Romanesque buildings. These include ribbed vaults, buttresses, clustered columns, ambulatories, wheel windows, spires and richly carved door tympana. These were already features of ecclesiastical architecture before the development of the Gothic style, and all were to develop in increasingly elaborate ways.
It was principally the widespread introduction of a single feature, the pointed arch, which was to bring about the change that separates Gothic from Romanesque. The technological change permitted a stylistic change which broke the tradition of massive masonry and solid walls penetrated by small openings, replacing it with a style where light appears to triumph over substance. With its use came the development of many other architectural devices, previously put to the test in scattered buildings and then called into service to meet the structural, aesthetic and ideological needs of the new style. These include the flying buttresses, pinnacles and traceried windows which typify Gothic ecclesiastical architecture. But while pointed arch is so strongly associated with the Gothic style, it was first used in Western architecture in buildings that were in other ways clearly Romanesque, notably Durham Cathedral in the north of England, Monreale Cathedral and Cathedral of Cefalù in Sicily, Autun Cathedral in France.
Possible Islamic influence.
The pointed arch, one of the defining attributes of Gothic, was earlier incorporated into Islamic architecture following the Islamic conquests of Roman Syria and the Sassanid Empire in the Seventh Century. The pointed arch and its precursors had been employed in Late Roman and Sassanian architecture; within the Roman context, evidenced in early church building in Syria and occasional secular structures, like the Roman Karamagara Bridge; in Sassanid architecture, in the parabolic and pointed arches employed in palace and sacred construction.
Increasing military and cultural contacts with the Muslim world, including the Norman conquest of Islamic Sicily in 1090, the Crusades, beginning 1096, and the Islamic presence in Spain, may have influenced Medieval Europe's adoption of the pointed arch, although this hypothesis remains controversial. Certainly, in those parts of the Western Mediterranean subject to Islamic control or influence, rich regional variants arose, fusing Romanesque and later Gothic traditions with Islamic decorative forms, as seen, for example, in Monreale and Cefalù Cathedrals, the Alcázar of Seville, and Teruel Cathedral.
Architectural development.
Transition from Romanesque to Gothic architecture.
The characteristic forms that were to define Gothic architecture grew out of Romanesque architecture and developed at several different geographic locations, as the result of different influences and structural requirements.
While barrel vaults and groin vaults are typical of Romanesque architecture, ribbed vaults were used in the naves of two Romanesque churches in Caen, Abbey of Saint-Étienne and Abbaye aux Dames in 1120. Another early example is the nave and apse area of the Cathedral of Cefalù in 1131. The ribbed vault over the north transept at Durham Cathedral in England, built from 1128 to 1133, is probably earlier still and was the first time pointed arches were used in a high vault.
Other characteristics of early Gothic architecture, such as vertical shafts, clustered columns, compound piers, plate tracery and groups of narrow openings had evolved during the Romanesque period. The west front of Ely Cathedral exemplifies this development. Internally the three tiered arrangement of arcade, gallery and clerestory was established. Interiors had become lighter with the insertion of more and larger windows.
The Basilica of Saint Denis is generally cited as the first truly Gothic building, however the distinction is best reserved for the choir, of which the ambulatory remains intact. Noyon Cathedral, also in France, saw the earliest completion of a rebuilding of an entire cathedral in the new style from 1150 to 1231. While using all those features that came to be known as Gothic, including pointed arches, flying buttresses and ribbed vaulting, the builders continued to employ many of the features and much of the character of Romanesque architecture including round-headed arch throughout the building, varying the shape to pointed where it was functionally practical to do so.
At the Abbey Saint-Denis, Noyon Cathedral, Notre Dame de Paris and at the eastern end of Canterbury Cathedral in England, simple cylindrical columns predominate over the Gothic forms of clustered columns and shafted piers. Wells Cathedral in England, commenced at the eastern end in 1175, was the first building in which the designer broke free from Romanesque forms. The architect entirely dispensed with the round arch in favour of the pointed arch and with cylindrical columns in favour of piers composed of clusters of shafts which lead into the mouldings of the arches. The transepts and nave were continued by Adam Locke in the same style and completed in about 1230. The character of the building is entirely Gothic. Wells Cathedral is thus considered the first truly Gothic cathedral.
Abbot Suger.
The eastern end of the Basilica Church of Saint-Denis, built by Abbot Suger and completed in 1144, is often cited as the first truly Gothic building, as it draws together many of architectural forms which had evolved from Romanesque and typify the Gothic style.
Suger, friend and confidant of the French Kings, Louis VI and Louis VII, decided in about 1137, to rebuild the great Church of Saint-Denis, attached to an abbey which was also a royal residence. He began with the West Front, reconstructing the original Carolingian façade with its single door. He designed the façade of Saint-Denis to be an echo of the Roman Arch of Constantine with its three-part division and three large portals to ease the problem of congestion. The rose window is the earliest-known example above the West portal in France. The façade combines both round arches and pointed arches of the Gothic style.
At the completion of the west front in 1140, Abbot Suger moved on to the reconstruction of the eastern end, leaving the Carolingian nave in use. He designed a choir that would be suffused with light. To achieve his aims, his masons drew on the several new features which evolved or had been introduced to Romanesque architecture, the pointed arch, the ribbed vault, the ambulatory with radiating chapels, the clustered columns supporting ribs springing in different directions and the flying buttresses which enabled the insertion of large "clerestory" windows.
The new structure was finished and dedicated on 11 June 1144, in the presence of the King. The choir and west front of the Abbey of Saint-Denis both became the prototypes for further building in the royal domain of northern France and in the Duchy of Normandy. Through the rule of the Angevin dynasty, the new style was introduced to England and spread throughout France, the Low Countries, Germany, Spain, northern Italy and Sicily.
Characteristics of Gothic cathedrals and great churches.
While many secular buildings exist from the Late Middle Ages, it is in the buildings of cathedrals and great churches that Gothic architecture displays its pertinent structures and characteristics to the fullest advantage. A Gothic cathedral or abbey was, prior to the 20th century, generally the landmark building in its town, rising high above all the domestic structures and often surmounted by one or more towers and pinnacles and perhaps tall spires. These cathedrals were the skyscrapers of that day and would have been the largest buildings by far that Europeans would ever have seen. It is in the architecture of these Gothic churches that a unique combination of existing technologies established the emergence of a new building style. Those technologies were the ogival or pointed arch, the ribbed vault, and the buttress.
The Gothic style, when applied to an ecclesiastical building, emphasizes verticality and light. This appearance was achieved by the development of certain architectural features, which together provided an engineering solution. The structural parts of the building ceased to be its solid walls, and became a stone skeleton comprising clustered columns, pointed ribbed vaults and flying buttresses.
Plan.
Most large Gothic churches and many smaller parish churches are of the Latin cross (or "cruciform") plan, with a long nave making the body of the church, a transverse arm called the transept and, beyond it, an extension which may be called the choir, chancel or presbytery. There are several regional variations on this plan.
The nave is generally flanked on either side by aisles, usually single, but sometimes double. The nave is generally considerably taller than the aisles, having clerestory windows which light the central space. Gothic churches of the Germanic tradition, like St. Stephen of Vienna, often have nave and aisles of similar height and are called "Hallenkirche". In the South of France there is often a single wide nave and no aisles, as at Sainte-Marie in Saint-Bertrand-de-Comminges.
In some churches with double aisles, like Notre Dame, Paris, the transept does not project beyond the aisles. In English cathedrals transepts tend to project boldly and there may be two of them, as at Salisbury Cathedral, though this is not the case with lesser churches.
The eastern arm shows considerable diversity. In England it is generally long and may have two distinct sections, both choir and presbytery. It is often square ended or has a projecting "Lady Chapel", dedicated to the Virgin Mary. In France the eastern end is often polygonal and surrounded by a walkway called an ambulatory and sometimes a ring of chapels called a "chevet". While German churches are often similar to those of France, in Italy, the eastern projection beyond the transept is usually just a shallow apsidal chapel containing the sanctuary, as at Florence Cathedral.
Structure: the pointed arch.
History.
One of the defining characteristics of Gothic architecture is the pointed or ogival arch. Arches of a similar type were used in the Near East in pre-Islamic as well as Islamic architecture before they were structurally employed in medieval architecture. It is thought by some architectural historians that this was the inspiration for the use of the pointed arch in France, in otherwise Romanesque buildings, as at Autun Cathedral.
Contrary to the diffusionist theory, it appears that there was simultaneously a structural evolution towards the pointed arch, for the purpose of vaulting spaces of irregular plan, or to bring transverse vaults to the same height as diagonal vaults. This latter occurs at Durham Cathedral in the nave aisles in 1093. Pointed arches also occur extensively in Romanesque decorative blind arcading, where semi-circular arches overlap each other in a simple decorative pattern, and the points are accidental to the design.
Functions.
The Gothic vault, unlike the semi-circular vault of Roman and Romanesque buildings, can be used to roof rectangular and irregularly shaped plans such as trapezoids. The other structural advantage is that the pointed arch channels the weight onto the bearing piers or columns at a steep angle. This enabled architects to raise vaults much higher than was possible in Romanesque architecture. While, structurally, use of the pointed arch gave a greater flexibility to architectural form, it also gave Gothic architecture a very different and more vertical visual character than Romanesque.
In Gothic architecture the pointed arch is used in every location where a vaulted shape is called for, both structural and decorative. Gothic openings such as doorways, windows, arcades and galleries have pointed arches. Gothic vaulting above spaces both large and small is usually supported by richly moulded ribs.
Rows of pointed arches upon delicate shafts form a typical wall decoration known as blind arcading. Niches with pointed arches and containing statuary are a major external feature. The pointed arch lent itself to elaborate intersecting shapes which developed within window spaces into complex Gothic tracery forming the structural support of the large windows that are characteristic of the style.
Height.
A characteristic of Gothic church architecture is its height, both absolute and in proportion to its width, the verticality suggesting an aspiration to Heaven. A section of the main body of a Gothic church usually shows the nave as considerably taller than it is wide. In England the proportion is sometimes greater than 2:1, while the greatest proportional difference achieved is at Cologne Cathedral with a ratio of 3.6:1. The highest internal vault is at Beauvais Cathedral at 48 m.
Externally, towers and spires are characteristic of Gothic churches both great and small, the number and positioning being one of the greatest variables in Gothic architecture. In Italy, the tower, if present, is almost always detached from the building, as at Florence Cathedral, and is often from an earlier structure. In France and Spain, two towers on the front is the norm. In England, Germany and Scandinavia this is often the arrangement, but an English cathedral may also be surmounted by an enormous tower at the crossing. Smaller churches usually have just one tower, but this may also be the case at larger buildings, such as Salisbury Cathedral or Ulm Minster, which has the tallest spire in the world, slightly exceeding that of Lincoln Cathedral, the tallest which was actually completed during the medieval period, at 160 m.
Vertical emphasis.
The pointed arch lends itself to a suggestion of height. This appearance is characteristically further enhanced by both the architectural features and the decoration of the building.
On the exterior, the verticality is emphasised in a major way by the towers and spires and in a lesser way by strongly projecting vertical buttresses, by narrow half-columns called "attached shafts" which often pass through several storeys of the building, by long narrow windows, vertical mouldings around doors and figurative sculpture which emphasises the vertical and is often attenuated. The roofline, gable ends, buttresses and other parts of the building are often terminated by small pinnacles, Milan Cathedral being an extreme example in the use of this form of decoration.
On the interior of the building attached shafts often sweep unbroken from floor to ceiling and meet the ribs of the vault, like a tall tree spreading into branches. The verticals are generally repeated in the treatment of the windows and wall surfaces. In many Gothic churches, particularly in France, and in the "Perpendicular period" of English Gothic architecture, the treatment of vertical elements in gallery and window tracery creates a strongly unifying feature that counteracts the horizontal divisions of the interior structure.
Light.
Expansive interior light has been a feature of Gothic cathedrals since the first structure was opened. The metaphysics of light in the Middle Ages led to clerical belief in its divinity and the importance of its display in holy settings. Much of this belief was based on the writings of Pseudo-Dionysius, a sixth century mystic whose book, The Celestial Hierarchy, was popular among monks in France. Pseudo-Dionysius held that all light, even light reflected from metals or streamed through windows, was divine. To promote such faith, the abbot in charge of the Saint-Denis church on the north edge of Paris, the Abbot Suger, encouraged architects remodeling the building to make the interior as bright as possible.
Ever since the remodeled Basilica of Saint-Denis opened in 1144, Gothic architecture has featured expansive windows, such as at Sainte Chapelle, York Minster, Gloucester Cathedral and in the Milan Cathedral. The increase in size between windows of the Romanesque and Gothic periods is related to the use of the ribbed vault, and in particular, the pointed ribbed vault which channeled the weight to a supporting shaft with less outward thrust than a semicircular vault. Walls did not need to be so weighty.
A further development was the flying buttress which arched externally from the springing of the vault across the roof of the aisle to a large buttress pier projecting well beyond the line of the external wall. These piers were often surmounted by a pinnacle or statue, further adding to the downward weight, and counteracting the outward thrust of the vault and buttress arch as well as stress from wind loading.
The internal columns of the arcade with their attached shafts, the ribs of the vault and the flying buttresses, with their associated vertical buttresses jutting at right-angles to the building, created a stone skeleton. Between these parts, the walls and the infill of the vaults could be of lighter construction. Between the narrow buttresses, the walls could be opened up into large windows.
Through the Gothic period, thanks to the versatility of the pointed arch, the structure of Gothic windows developed from simple openings to immensely rich and decorative sculptural designs. The windows were very often filled with stained glass which added a dimension of colour to the light within the building, as well as providing a medium for figurative and narrative art.
Majesty.
The façade of a large church or cathedral, often referred to as the "West Front", is generally designed to create a powerful impression on the approaching worshipper, demonstrating both the might of God and the might of the institution that it represents. One of the best known and most typical of such façades is that of Notre Dame de Paris.
Central to the façade is the main portal, often flanked by additional doors. In the arch of the door, the tympanum, is often a significant piece of sculpture, most frequently "Christ in Majesty" and "Judgment Day". If there is a central doorjamb or a trumeau, then it frequently bears a statue of the "Madonna and Child". There may be much other carving, often of figures in niches set into the mouldings around the portals, or in sculptural screens extending across the façade.
Above the main portal there is generally a large window, like that at York Minster, or a group of windows such as those at Ripon Cathedral. In France there is generally a rose window like that at Reims Cathedral. Rose windows are also often found in the façades of churches of Spain and Italy, but are rarer elsewhere and are not found on the façades of any English Cathedrals. The gable is usually richly decorated with arcading or sculpture or, in the case of Italy, may be decorated with the rest of the façade, with polychrome marble and mosaic, as at Orvieto Cathedral.
The West Front of a French cathedral and many English, Spanish and German cathedrals generally have two towers, which, particularly in France, express an enormous diversity of form and decoration. However some German cathedrals have only one tower located in the middle of the façade (such as Freiburg Münster).
Basic shapes of Gothic arches and stylistic character.
The way in which the pointed arch was drafted and utilised developed throughout the Gothic period. There were fairly clear stages of development, which did not, however, progress at the same rate, or in the same way in every country. Moreover, the names used to define various periods or styles within Gothic architecture differs from country to country.
Lancet arch.
The simplest shape is the long opening with a pointed arch known in England as the lancet. Lancet openings are often grouped, usually as a cluster of three or five. Lancet openings may be very narrow and steeply pointed. Lancet arches are typically defined as two-centered arches whose radii are larger than the arch's span.
Salisbury Cathedral is famous for the beauty and simplicity of its Lancet Gothic, known in England as the Early English Style. York Minster has a group of lancet windows each fifty feet high and still containing ancient glass. They are known as the Five Sisters. These simple undecorated grouped windows are found at Chartres and Laon Cathedrals and are used extensively in Italy.
Equilateral arch.
Many Gothic openings are based upon the equilateral form. In other words, when the arch is drafted, the radius is exactly the width of the opening and the centre of each arch coincides with the point from which the opposite arch springs. This makes the arch higher in relation to its width than a semi-circular arch which is exactly half as high as it is wide.
The Equilateral Arch gives a wide opening of satisfying proportion useful for doorways, decorative arcades and large windows.
The structural beauty of the Gothic arch means, however, that no set proportion had to be rigidly maintained. The Equilateral Arch was employed as a useful tool, not as a Principle of Design. This meant that narrower or wider arches were introduced into a building plan wherever necessity dictated. In the architecture of some Italian cities, notably Venice, semi-circular arches are interspersed with pointed ones.
The Equilateral Arch lends itself to filling with tracery of simple equilateral, circular and semi-circular forms. The type of tracery that evolved to fill these spaces is known in England as Geometric Decorated Gothic and can be seen to splendid effect at many English and French Cathedrals, notably Lincoln and Notre Dame in Paris. Windows of complex design and of three or more "lights" or vertical sections, are often designed by overlapping two or more equilateral arches.
Flamboyant arch.
The Flamboyant Arch is one that is drafted from four points, the upper part of each main arc turning upwards into a smaller arc and meeting at a sharp, flame-like point. These arches create a rich and lively effect when used for window tracery and surface decoration. The form is structurally weak and has very rarely been used for large openings except when contained within a larger and more stable arch. It is not employed at all for vaulting.
Some of the most beautiful and famous traceried windows of Europe employ this type of tracery. It can be seen at St Stephen's Vienna, Sainte Chapelle in Paris, at the Cathedrals of Limoges and Rouen in France, and at Milan Cathedral in Italy. In England the most famous examples are the West Window of York Minster with its design based on the Sacred Heart, the extraordinarily rich nine-light East Window at Carlisle Cathedral and the exquisite East window of Selby Abbey.
Doorways surmounted by Flamboyant mouldings are very common in both ecclesiastical and domestic architecture in France. They are much rarer in England. A notable example is the doorway to the Chapter Room at Rochester Cathedral.
The style was much used in England for wall arcading and niches. Prime examples in are in the Lady Chapel at Ely, the Screen at Lincoln and externally on the façade of Exeter Cathedral. In German and Spanish Gothic architecture it often appears as openwork screens on the exterior of buildings. The style was used to rich and sometimes extraordinary effect in both these countries, notably on the famous pulpit in Vienna Cathedral.
Depressed arch.
The Depressed or four-centred arch is much wider than its height and gives the visual effect of having been flattened under pressure. Its structure is achieved by drafting two arcs which rise steeply from each springing point on a small radius and then turn into two arches with a wide radius and much lower springing point.
This type of arch, when employed as a window opening, lends itself to very wide spaces, provided it is adequately supported by many narrow vertical shafts. These are often further braced by horizontal transoms. The overall effect produces a grid-like appearance of regular, delicate, rectangular forms with an emphasis on the perpendicular. It is also employed as a wall decoration in which arcade and window openings form part of the whole decorative surface.
The style, known as Perpendicular, that evolved from this treatment is specific to England, although very similar to contemporary Spanish style in particular, and was employed to great effect through the 15th century and first half of the 16th as Renaissance styles were much slower to arrive in England than in Italy and France.
It can be seen notably at the East End of Gloucester Cathedral where the East Window is said to be as large as a tennis court. There are three very famous royal chapels and one chapel-like Abbey which show the style at its most elaborate: King's College Chapel, Cambridge; St George's Chapel, Windsor; Henry VII's Chapel at Westminster Abbey and Bath Abbey. However very many simpler buildings, especially churches built during the wool boom in East Anglia, are fine examples of the style.
Symbolism and ornamentation.
The Gothic cathedral represented the universe in microcosm and each architectural concept, including the loftiness and huge dimensions of the structure, were intended to convey a theological message: the great glory of God.
The building becomes a microcosm in two ways. Firstly, the mathematical and geometrical nature of the construction is an image of the orderly universe, in which an underlying rationality and logic can be perceived.
Secondly, the statues, sculptural decoration, stained glass and murals incorporate the essence of creation in depictions of the Labours of the Months and the Zodiac and sacred history from the Old and New Testaments and Lives of the Saints, as well as reference to the eternal in the Last Judgment and "Coronation of the Virgin".
The decorative schemes usually incorporated Biblical stories, emphasizing visual typological allegories between Old Testament prophecy and the New Testament.
Many churches were very richly decorated, both inside and out. Sculpture and architectural details were often bright with coloured paint of which traces remain at the Cathedral of Chartres. Wooden ceilings and panelling were usually brightly coloured. Sometimes the stone columns of the nave were painted, and the panels in decorative wall arcading contained narratives or figures of saints. These have rarely remained intact, but may be seen at the Chapterhouse of Westminster Abbey.
Some important Gothic churches could be severely simple such as the Basilica of Mary Magdalene in Saint-Maximin, Provence where the local traditions of the sober, massive, Romanesque architecture were still strong.
Regional differences.
Wherever Gothic architecture is found, it is subject to local influences, and frequently the influence of itinerant stonemasons and artisans, carrying ideas between cities and sometimes between countries. Certain characteristics are typical of particular regions and often override the style itself, appearing in buildings hundreds of years apart.
France.
The distinctive characteristic of French cathedrals, and those in Germany and Belgium that were strongly influenced by them, is their height and their impression of verticality. Each French cathedral tends to be stylistically unified in appearance when compared with an English cathedral where there is great diversity in almost every building. They are compact, with slight or no projection of the transepts and subsidiary chapels. The west fronts are highly consistent, having three portals surmounted by a rose window, and two large towers. Sometimes there are additional towers on the transept ends. The east end is polygonal with ambulatory and sometimes a chevette of radiating chapels. In the south of France, many of the major churches are without transepts and some are without aisles.
England.
The distinctive characteristic of English cathedrals is their extreme length, and their internal emphasis upon the horizontal, which may be emphasised visually as much or more than the vertical lines. Each English cathedral (with the exception of Salisbury) has an extraordinary degree of stylistic diversity, when compared with most French, German and Italian cathedrals. It is not unusual for every part of the building to have been built in a different century and in a different style, with no attempt at creating a stylistic unity. Unlike French cathedrals, English cathedrals sprawl across their sites, with double transepts projecting strongly and "Lady Chapels" tacked on at a later date, such as at Westminster Abbey. In the west front, the doors are not as significant as in France, the usual congregational entrance being through a side porch. The West window is very large and never a rose, which are reserved for the transept gables. The west front may have two towers like a French Cathedral, or none. There is nearly always a tower at the crossing and it may be very large and surmounted by a spire. The distinctive English east end is square, but it may take a completely different form. Both internally and externally, the stonework is often richly decorated with carvings, particularly the capitals.
Germany and Central Europe.
Romanesque architecture in Germany, Poland, the Czech Lands and Austria is characterised by its massive and modular nature. This is expressed in the Gothic architecture of Central Europe in the huge size of the towers and spires, often projected, but not always completed. The west front generally follows the French formula, but the towers are very much taller and, if complete, are surmounted by enormous openwork spires that are a regional feature. Because of the size of the towers, the section of the façade between them may appear narrow and compressed. The eastern end follows the French form. The distinctive character of the interior of German Gothic cathedrals is their breadth and openness. This is the case even when, as at Cologne, they have been modelled upon a French cathedral. German cathedrals, like the French, tend not to have strongly projecting transepts. There are also many hall churches ("Hallenkirchen") without clerestory windows.
Spain and Portugal.
The distinctive characteristic of Gothic cathedrals of the Iberian Peninsula is their spatial complexity, with many areas of different shapes leading from each other. They are comparatively wide, and often have very tall arcades surmounted by low clerestories, giving a similar spacious appearance to the "'Hallenkirche" of Germany, as at the Church of the Batalha Monastery in Portugal. Many of the cathedrals are completely surrounded by chapels. Like English cathedrals, each is often stylistically diverse. This expresses itself both in the addition of chapels and in the application of decorative details drawn from different sources. Among the influences on both decoration and form are Islamic architecture and, towards the end of the period, Renaissance details combined with the Gothic in a distinctive manner. The West front, as at Leon Cathedral, typically resembles a French west front, but wider in proportion to height and often with greater diversity of detail and a combination of intricate ornament with broad plain surfaces. At Burgos Cathedral there are spires of German style. The roofline often has pierced parapets with comparatively few pinnacles. There are often towers and domes of a great variety of shapes and structural invention rising above the roof.
Italy.
The distinctive characteristic of Italian Gothic is the use of polychrome decoration, both externally as marble veneer on the brick façade and also internally where the arches are often made of alternating black and white segments, and where the columns may be painted red, the walls decorated with frescoes and the apse with mosaic. The plan is usually regular and symmetrical. With the exception of Milan Cathedral which is Germanic in style, Italian cathedrals have few and widely spaced columns. The proportions are generally mathematically equilibrated, based on the square and the concept of "armonìa", and except in Venice where they loved flamboyant arches, the arches are almost always equilateral. Colours and moldings define the architectural units rather than blending them. Italian cathedral façades are often polychrome and may include mosaics in the lunettes over the doors. The façades have projecting open porches and occular or wheel windows rather than roses, and do not usually have a tower. The crossing is usually surmounted by a dome. There is often a free-standing tower and baptistry. The eastern end usually has an apse of comparatively low projection. The windows are not as large as in northern Europe and, although stained glass windows are often found, the favourite narrative medium for the interior is the fresco.
Other Gothic buildings.
Synagogues, commonly built in the prevailing architectural style of the period and country where they are constructed, were built in the Gothic style in Europe during the Medieval period. A surviving example is the Old New Synagogue in Prague, built in the 13th century.
Many examples of secular, non-military structures in Gothic style survive in fairly original condition.
The Palais des Papes in Avignon is the best complete large royal palace, alongside the Royal palace of Olite, built during the 13th and 14th centuries for the kings of Navarre, and Malbork Castle, a remarkable example of Brick Gothic built for the master of the Teutonic order in what nowadays is northern Poland. Partial survivals of former royal residences include the Doge's Palace of Venice, the Palau de la Generalitat in Barcelona, built in the 15th century for the kings of Aragon, or the famous Conciergerie, former palace of the kings of France, in Paris.
Secular gothic architecture can also be found in a number of public buildings such as town halls, universities, markets or hospitals. The Gdańsk and Wrocław town halls are remarkable examples of northern brick gothic built in the 15th centuries. The Belfry of Bruges or Brussels Town Hall, built during the 15th century, are associated to the increasing wealth and power of the bourgeoisie in the late Middle Ages; by the 15th century, the traders of the trade cities of Burgundy had acquired such wealth and influence that they could afford to express their power by funding lavishly decorated buildings of vast proportions. This kind of expressions of secular and economic power are also found in other late mediaeval commercial cities, including the Llotja de la Seda of Valencia, Spain, a purpose built silk exchange dating from the 15th century, in the partial remains of Westminster Hall in the Houses of Parliament in London, or the Palazzo Pubblico in Siena, Italy, a 13th-century town hall built to host the offices of the then prosperous republic of Siena. Other Italian cities such as Florence (Palazzo Vecchio), Mantua or Venice also host remarkable examples of secular public architecture.
By the late Middle Ages university towns had grown in wealth and importance as well, and this was reflected in the buildings of some of Europe's ancient universities. Particularly remarkable examples still standing nowadays include the Collegio di Spagna in the University of Bologna, built during the 14th and 15th centuries; the Escuelas mayores of the University of Salamanca in Spain; the chapel of King's College, Cambridge; or the Collegium Maius of the Jagiellonian University in Kraków, Poland.
In addition to monumental secular architecture, examples of the Gothic style in private buildings can be seen in surviving medieval portions of cities across Europe, above all the distinctive Venetian Gothic such as the Ca' d'Oro. The house of the wealthy early 15th-century merchant Jacques Coeur in Bourges, is the classic Gothic bourgeois mansion, full of the asymmetry and complicated detail beloved of the Gothic Revival.
Other cities with a concentration of secular Gothic include Bruges and Siena. Most surviving small secular buildings are relatively plain and straightforward; most windows are flat-topped with mullions, with pointed arches and vaulted ceilings often only found at a few focal points. The country-houses of the nobility were slow to abandon the appearance of being a castle, even in parts of Europe, like England, where defence had ceased to be a real concern. The living and working parts of many monastic buildings survive, for example at Mont Saint-Michel.
Exceptional works of Gothic architecture can also be found in Sicily, Cyprus, especially in the walled cities of Nicosia and Famagusta. Also, the roof of the Znojmo Town Hall Tower in the Czech Republic is an excellent example of late Gothic craftsmanship.
Gothic survival and revival.
In 1663 at the Archbishop of Canterbury's residence, Lambeth Palace, a Gothic hammerbeam roof was built to replace that destroyed when the building was sacked during the English Civil War. Also in the late 17th century, some discrete Gothic details appeared on new construction at Oxford University and Cambridge University, notably on Tom Tower at Christ Church, Oxford, by Christopher Wren. It is not easy to decide whether these instances were "Gothic survival" or early appearances of "Gothic revival".
In England in the mid-18th century, the Gothic style was more widely revived, first as a decorative, whimsical alternative to Rococo that is still conventionally termed 'Gothick', of which Horace Walpole's Twickenham villa "Strawberry Hill" is the familiar example.
19th- and 20th-century Gothic Revival.
In England, partly in response to a philosophy propounded by the Oxford Movement and others associated with the emerging revival of 'high church' or Anglo-Catholic ideas during the second quarter of the 19th century, neo-Gothic began to become promoted by influential establishment figures as the preferred style for ecclesiastical, civic and institutional architecture. The appeal of this Gothic revival (which after 1837, in Britain, is sometimes termed Victorian Gothic), gradually widened to encompass "low church" as well as "high church" clients. This period of more universal appeal, spanning 1855–1885, is known in Britain as High Victorian Gothic.
The Houses of Parliament in London by Sir Charles Barry with interiors by a major exponent of the early Gothic Revival, Augustus Welby Pugin, is an example of the Gothic revival style from its earlier period in the second quarter of the 19th century. Examples from the "High Victorian Gothic" period include George Gilbert Scott's design for the Albert Memorial in London, and William Butterfield's chapel at Keble College, Oxford. From the second half of the 19th century onwards it became more common in Britain for neo-Gothic to be used in the design of non-ecclesiastical and non-governmental buildings types. Gothic details even began to appear in working-class housing schemes subsidised by philanthropy, though given the expense, less frequently than in the design of upper and middle-class housing.
In France, simultaneously, the towering figure of the Gothic Revival was Eugène Viollet-le-Duc, who outdid historical Gothic constructions to create a Gothic as it ought to have been, notably at the fortified city of Carcassonne in the south of France and in some richly fortified keeps for industrial magnates. Viollet-le-Duc compiled and coordinated an "Encyclopédie médiévale" that was a rich repertory his contemporaries mined for architectural details. He effected vigorous restoration of crumbling detail of French cathedrals, including the Abbey of Saint-Denis and famously at Notre Dame de Paris, where many of whose most "Gothic" gargoyles are Viollet-le-Duc's. He taught a generation of reform-Gothic designers and showed how to apply Gothic style to modern structural materials, especially cast iron.
In Germany, the great cathedral of Cologne and the Ulm Minster, left unfinished for 600 years, were brought to completion, while in Italy, Florence Cathedral finally received its polychrome Gothic façade. New churches in the Gothic style were created all over the world, including Mexico, Argentina, Japan, Thailand, India, Australia, New Zealand, Hawaii and South Africa.
As in Europe, the United States, Canada, Australia and New Zealand utilised Neo-Gothic for the building of universities, a fine example being the University of Sydney by Edmund Blacket. In Canada, the Canadian Parliament Buildings in Ottawa designed by Thomas Fuller and Chilion Jones with its huge centrally placed tower draws influence from Flemish Gothic buildings.
Although falling out of favour for domestic and civic use, Gothic for churches and universities continued into the 20th century with buildings such as Liverpool Cathedral, the Cathedral of Saint John the Divine, New York and São Paulo Cathedral, Brazil. The Gothic style was also applied to iron-framed city skyscrapers such as Cass Gilbert's Woolworth Building and Raymond Hood's Tribune Tower.
Post-Modernism in the late 20th and early 21st centuries has seen some revival of Gothic forms in individual buildings, such as the Gare do Oriente in Lisbon, Portugal and a finishing of the Cathedral of Our Lady of Guadalupe in Mexico.

</doc>
<doc id="54045" url="http://en.wikipedia.org/wiki?curid=54045" title="Old Italic script">
Old Italic script

Old Italic refers to any of several now extinct alphabet systems used on the Italian Peninsula in ancient times for various Indo-European languages (predominantly Italic) and non-Indo-European (e.g. Etruscan) languages. The alphabets derive from the Euboean Greek Cumaean alphabet, used at Ischia and Cumae in the Bay of Naples in the eighth century BC.
Various Indo-European languages belonging to the Italic branch (Faliscan and members of the Sabellian group, including Oscan, Umbrian, and South Picene, and other Indo-European branches such as Celtic, Venetic and Messapic) originally used the alphabet. Faliscan, Oscan, Umbrian, North Picene, and South Picene all derive from an Etruscan form of the alphabet.
The Germanic runic alphabet was derived from one of these alphabets by the 2nd century.
Etruscan alphabet.
It is not clear whether the process of adaptation from the Greek alphabet took place in Italy from the first colony of Greeks, the city of Cumae, or in Greece/Asia Minor. It was in any case a Western Greek alphabet. In the alphabets of the West, X had the [ks], Ψ stood for [kʰ]; in Etruscan: X = [s], Ψ = [kʰ] or [kχ] (Rix 202–209).
The earliest Etruscan "abecedarium," the Marsiliana (near Grosseto) tablet which dates to c. 700 BC, lists 26 letters corresponding to contemporary forms of the Greek alphabet which retained san and qoppa but which had not yet developed omega.
Until about 600 BC, the archaic form of the Etruscan alphabet remained practically unchanged, and the direction of writing was free. From the 6th century, however, evolutions of the alphabet took place, guided by the phonology of the Etruscan language, and letters representing phonemes nonexistent in Etruscan were dropped. By 400 BC, it appears that all of Etruria was using the classical Etruscan alphabet of 20 letters, mostly written from left to right:
An additional sign 𐌚, in shape similar to the numeral 8, transcribed as F, was present in both Lydian and Etruscan (Jensen 513). Its origin is disputed; it may have been an altered B or H or an ex novo creation (Rix 202). Its sound value was /f/ and it replaced the Etruscan FH. Some letters were, on the other hand, falling out of use: B and D were apparently considered superfluous over P and T. K was dropped in favour of G (also transcribed as C). O disappeared and was replaced by U. In the course of its simplification, the redundant letters showed some tendency towards a syllabary: C, K and Q were predominantly used in the contexts CE, KA, QU.
This classical alphabet remained in use until the 2nd century BC when it began to be influenced by the rise of the Latin alphabet. Soon after, the Etruscan language itself became extinct.
Oscan alphabet.
The Osci probably adopted the archaic Etruscan alphabet during the 7th century BC, but a recognizably Oscan variant of the alphabet is attested only from the 5th century BC; its sign inventory extended over the classical Etruscan alphabet by the introduction of long vowel variants of I and U, transcribed as Í and Ú. U came to be used to represent Oscan "o", while Ú was used for actual Oscan "u".
Alphabet of Nuceria.
The "Nucerian alphabet" is based on inscriptions found in southern Italy (Nocera Superiore, Sorrento, Vico Equense and others places). It is attested only between the 6th and the 5th century BC.
The most important sign is the /S/, shaped like a fir tree, and possibly a derivation from the Phoenician alphabet.
Alphabet of Lugano.
The Alphabet of Lugano, based on inscriptions found in northern Italy and Canton Ticino, was used to record Lepontic inscriptions, among the oldest testimonies of any Celtic language, in use from the 7th to the 5th centuries BC. The alphabet has 17 letters, derived from the archaic Etruscan alphabet:
The alphabet does not distinguish voiced and unvoiced occlusives, i.e. P represents /b/ or /p/, T is for /t/ or /d/, K for /g/ or /k/.
Z is probably for /ts/. U /u/ and V /w/ are distinguished. Θ is probably for /t/ and X for /g/. There are claims of a related script discovered in Glozel.
Raetic alphabets.
The alphabet of Sanzeno (also, of Bolzano), about 100 Raetic inscriptions. 
The alphabet of Magrè (near Schio), east Raetian inscriptions.
Venetic alphabet.
Alphabet of Este: Similar but not identical to that of Magrè, Venetic inscriptions.
Camunic alphabet.
Inscripted abecedarium on rock engraves in Valle Camonica.
Latin alphabet.
21 of the 26 archaic Etruscan letters were adopted for Old Latin from the 7th century BC, either directly from the Cumae alphabet, or via archaic Etruscan forms, compared to the classical Etruscan alphabet retaining B, D, K, O, Q, X but dropping Θ, Ś, Φ, Ψ, and F. (Etruscan U is Latin V; Etruscan V is Latin F.)
Unicode.
The Old Italic alphabets were unified and added to the Unicode Standard in March, 2001 with the release of version 3.1.
Block.
The Unicode block for Old Italic is U+10300–U+1032F without specification of a particular alphabet (i.e. the Old Italic alphabets are considered equivalent, and the font used will determine the variant).
Writing direction (right-to-left, left-to-right, or boustrophedon) varies based on the language and even the time period. For simplicity most scholars use left-to-right and this is the Unicode default direction for the Old Italic block. For this reason, the glyphs in the code chart are shown with left-to-right orientation.

</doc>
<doc id="54047" url="http://en.wikipedia.org/wiki?curid=54047" title="Rubus">
Rubus

Rubus is a large genus of flowering plants in the rose family, Rosaceae, subfamily Rosoideae. Raspberries, blackberries, and dewberries are common, widely distributed members of the genus. Most of these plants have woody stems with prickles like roses; spines, bristles, and gland-tipped hairs are also common in the genus. The "Rubus" fruit, sometimes called a bramble fruit, is an aggregate of drupelets. The term "cane fruit" (or "cane-fruit") applies to any "Rubus" species or hybrid which is commonly grown with supports such as wires or canes, including raspberries, blackberries, and hybrids such as loganberry, boysenberry and tayberry.
Overview.
Most species are hermaphrodites, "Rubus chamaemorus" being an exception.
The blackberries, as well as various other "Rubus" species with mounding or rambling growth habits, are often called brambles. However, this name is not used for those like the raspberry that grow as upright canes, or for trailing or prostrate species, such as most dewberries, or various low-growing boreal, arctic, or alpine species.
The generic name means blackberry in Latin and was derived from the word "ruber", meaning "red".
The scientific study of brambles is known as "".
Examples of the hundreds, if not thousands, of species of "Rubus" include:
The British National Collection of "Rubus" is held by Barry Clark at Houghton, Hampshire. His collection stands at over 200 species and, although not within the scope of the National Collection, he also grows many cultivars.
Hybrid berries.
The term "hybrid berry" is often used collectively for those fruits in the genus "Rubus" which have been developed mainly in the USA and UK in the last 130 years. As "Rubus" species readily interbreed and are apomicts (able to set seed without fertilisation), the parentage of these plants is often highly complex, but is generally agreed to include cultivars of blackberries, ("Rubus ursinus", "R. fruticosus") and raspberries ("R. idaeus").
The hybrid berries include:- 
Scientific classification.
The genus "Rubus" is a very complex one, particularly the blackberry/dewberry subgenus ("Rubus"), with polyploidy, hybridization, and facultative apomixis apparently all frequently occurring, making species classification of the great variation in the subgenus one of the grand challenges of systematic botany.
"Rubus" species have a basic chromosome number of seven. Polyploidy from the diploid (14 chromosomes) to the tetradecaploid (98 chromosomes) is exhibited.
Some treatments have recognized dozens of species each for what other, comparably qualified botanists have considered single, more variable species. On the other hand, species in the other "Rubus" subgenera (such as the raspberries) are generally distinct, or else involved in more routine one-or-a-few taxonomic debates, such as whether the European and American red raspberries are better treated as one species or two. (In this case, the two-species view is followed here, with "Rubus idaeus" and "R. strigosus" both recognized; if these species are combined, then the older name "R. idaeus" has priority for the broader species.)
Molecular data have backed up classifications based on geography and chromosome number, but following morphological data, such as the structure of the leaves and stems, do not appear to produce a phylogenetic classification.
The classification presented below recognizes 13 subgenera within "Rubus", with the largest subgenus ("Rubus") in turn divided into 12 sections. Representative examples are presented, but many more species are not mentioned here.
See also.
List of Lepidoptera that feed on "Rubus"

</doc>
<doc id="54048" url="http://en.wikipedia.org/wiki?curid=54048" title="Steppe">
Steppe

In physical geography, a steppe (Ukrainian: степ Russian: степь, "step'"; ]) is an ecoregion, in the montane grasslands and shrublands and temperate grasslands, savannas, and shrublands biomes, characterized by grassland plains without trees apart from those near rivers and lakes. The prairie (especially the shortgrass and mixed prairie) is an example of a steppe, though it is not usually called such. It may be semi-desert, or covered with grass or shrubs or both, depending on the season and latitude. The term is also used to denote the climate encountered in regions too dry to support a forest, but not dry enough to be a desert. The soil is typically of chernozem type.
Steppes are usually characterized by a semi-arid and continental climate. Extremes can be recorded in the summer of up to 40 °C (104 °F) and in winter, –40 °C (–40 °F). Besides this huge difference between summer and winter, the differences between day and night are also very great. In the highlands of Mongolia, 30 °C (86 °F) can be reached during the day with sub-zero °C (sub 32 °F) readings at night.
The mid-latitude steppes can be summarised by hot summers and cold winters, averaging 250–500 mm (10-20 inches) of precipitation per year. Precipitation level alone is not what defines a steppe climate; potential evapotranspiration must also be taken into account.
Two types.
Two types of steppe can be recorded: 
Peculiar types of steppe include shrub-steppe and alpine-steppe.
The Eurasian Grass-Steppe of the temperate grasslands, savannas, and shrublands had a role in the spread of the horse, the wheel, and the Indo-European languages. The Indo-European expansion and diverse invasions of horse archer civilizations of the steppe eventually led to, e.g., the rise of Mycenaean Greece by amalgamation of Indo-Europeans with the autochthonous pre-Greek population and also its destruction during the Dorian invasion in the Late Bronze Age collapse, followed by the demise of the Achaeans, the spread of the Sea Peoples, and eventually the rise of Archaic and ultimately Classical Greece.
Locations.
Cold steppe.
The world's largest steppe region, often referred to as "the Great Steppe", is found in Eastern Europe and Central Asia, and neighbouring countries stretching from Ukraine in the west through Russia, Kazakhstan, Turkmenistan and Uzbekistan to the Altai, Koppet Dag and Tian Shan ranges.
The inner parts of Anatolia in Turkey, Central Anatolia and East Anatolia in particular and also some parts of Southeast Anatolia, as well as much of Armenia and Iran are largely dominated by cold steppe.
The Pannonian Plain is another steppe region in eastern Europe, primarily Hungary.
Another large steppe area (prairie) is located in the central United States, western Canada and northern part of Mexico. The shortgrass prairie steppe is the westernmost part of the Great Plains region. The Channeled Scablands in Southern British Columbia and Washington State is an example of a steppe region in North America outside of the Great Plains.
In South America, cold steppe can be found in Patagonia and much of the high elevation regions east of the southern Andes.
Relatively small steppe areas can be found in the interior of the South Island of New Zealand.
Subtropical steppe.
In Europe, some Mediterranean areas have a steppe-like vegetation, such as central Sicily, southern Portugal, parts of Greece in the southern Athens area, and central-eastern Spain, especially the southeastern coast (around Murcia), and places cut off from adequate moisture due to rain shadow effects such as Zaragoza.
In Asia, a subtropical steppe can be found in semi-arid lands that fringe the Thar Desert of the Indian subcontinent.
In Australia, "subtropical steppe" can be found in a belt surrounding the most severe deserts of the continent and around the Musgrave Ranges.
In North America this environment is typical of transition areas between zones with a Mediterranean climate and true deserts, such as Reno, Nevada, the inner part of California, and much of West Texas and adjacent areas in Mexico.

</doc>
<doc id="54050" url="http://en.wikipedia.org/wiki?curid=54050" title="Typographic unit">
Typographic unit

Typographic units are the units of measurement used in typography or typesetting. The traditional units are different from common metric units, as they were established earlier. Even though these units are all very small, across a line of print they add up quickly. Confusions such as resetting text originally in type of one unit in type of another will result in words moving from one line to the next, resulting in all sorts of typesetting errors (viz. rivers of white, widows and orphans, disrupted tables, and misplaced captions).
Development.
In Europe, the Didot point system was created by François-Ambroise Didot (1730–1804) in c. 1783. Didot's system was based on Pierre Simon Fournier's (1712–1768), but Didot modified Fournier's by adjusting the base unit precisely to a French Royal inch ("pouce"), as Fournier's unit was based on a less common foot.
However, the basic idea of the point system – to generate different type sizes by multiplying a single minimum unit calculated by dividing a base measurement unit such as one French Royal inch – was not Didot's invention, but Fournier's. In Fournier's system, an approximate French Royal inch ("pouce") is divided by 12 to calculate 1 "ligne", which is then divided by 6 to get 1 point. Didot just made the base unit (one French Royal inch) identical to the standard value defined by the government.
"In Didot's point system:"
Both in Didot's and Fournier's systems, some point sizes have traditional names such as "Cicero" (before introduction of point systems, type sizes were called by names such as "Cicero", Pica, Ruby, Long Primer, etc.).
The Didot point system has been widely used in European countries. An abbreviation for it that these countries use is "dd", employing an old method for indicating plurals. Hence "12 dd" means twelve didot points. 
In Britain and the U.S.A., many proposals for type size standardization had been made by the end of 19th century (such as Bruce Typefoundry's mathematical system that was based on a precise geometric progression). However, no nationwide standard was created until the American Point System was decided in 1886.
The American Point System was proposed by Nelson C. Hawks of Marder Luse & Company in Chicago in the 1870s, and his point system used the same method of size division as Fournier's; viz. dividing 1 inch by 6 to get 1 pica, and dividing it again by 12 to get 1 point. However, the American Point System standardized finally in 1886 is different from Hawks' original idea in that 1 pica is not precisely equal to 1⁄6 inch (neither the Imperial inch nor the U.S. inch), as the United States Type Founders' Association defined the standard pica to be the Johnson Pica, which had been adopted and used by Mackellar, Smiths and Jordan type foundry (MS&J), Philadelphia. As MS&J was very influential in those days, many other type foundries were using the Johnson Pica. Also, MS&J defined that 83 Picas are equal to 35 centimeters. The choice of the metric unit for the prototype was because at the time the Imperial and US inches differed in size slightly, and neither country could legally specify a unit of the other.
The Johnson Pica was named after Lawrence Johnson who had succeeded Binny & Ronaldson in 1833. Binny & Ronaldson was one of the oldest type foundries in the United States, established in Philadelphia in 1796. Binny & Ronaldson had bought the type founding equipment of Benjamin Franklin's (1706–1790) type foundry established in 1786 and run by his grandson Benjamin Franklin Bache (1769–1798). The equipment is thought to be that which Benjamin Franklin purchased from Pierre Simon Fournier when he visited France for diplomatic purposes (1776–1785).
The official standard approved by the Fifteenth Meeting of the Type Founders Association of the United States in 1886 was this Johnson pica, equal to exactly 0.166 inch. Therefore the two other – very close – definitions, 1200 / 7227 inch and 350 / 83 mm, are both unofficial.
"In the American point system:"
The American point system has been used in the USA, Britain, Japan, and many other countries.
Today, digital printing and display devices and page layout software use a unit that is different from these traditional typographic units. On many digital printing systems (desktop publishing systems in particular), the following equations are applicable (with exceptions, most notably the popular TeX typesetting system and its derivatives).
You can see that Fournier's original method of division is restored in today's digital typography. 
Comparing a piece of type in didots for Continental European countries – 12 dd, say – to a piece of type for an English-speaking country – 12 pt – shows that the main body of a character is actually about the same size. The difference is that the languages of the former often need extra space atop the capital letters for accent marks (e.g. Ñ, Â, Ö, É), but English rarely needs this.
Metric units.
The traditional typographic units are based either on non-metric units, or on odd multiples (such as 35⁄83) of a metric unit. There are no specifically metric units for this particular purpose, although there is a DIN standard sometimes used in German publishing, which measures type sizes in multiples of 0.25 mm, and proponents of the metrication of typography generally recommend the use of the millimetre for typographical measurements, rather than the development of new specifically typographical metric units. The Japanese already do this for their own characters (using the "kyu", which is "q" in romanized Japanese and is also 0.25 mm), and have metric-sized type for European languages as well. One advantage of the q is that it reintroduces the proportional integer division of 3 mm (12 q) by 6 & 4.
During the age of the French Revolution or Napoleonic Empire, the French established a typographic unit of 0.4 mm, but except for the government's print shops, this did not catch on. 
In 1973, the "didot" was restandardized in the EU as 0.375 (= 3⁄8) mm. Care must be taken because the name of the unit is often left unmodified. The Germans, however, use the terms Fournier-Punkt and Didot-Punkt for the earlier ones, and Typografischer Punkt for this metric one.

</doc>
<doc id="54053" url="http://en.wikipedia.org/wiki?curid=54053" title="Wank (mountain)">
Wank (mountain)

Wank (]) is a mountain in southern Germany, situated in the Loisach valley close to the Austrian border in the southwestern Ester Mountains range near Garmisch-Partenkirchen. It rises from about 700 m above mean sea level up to 1780 m at the summit. The mountain is crowned by a grassy summit which offers spectacular views over Garmisch-Partenkirchen and the surrounding region. The summit can be reached via the eponymous Wankbahn, a cable car system that runs during the summer months, or by an extensive network of footpaths that criss-cross the area. It is possible to both eat and sleep on the Wank at the Wank-Haus, a mountain hut on the summit, and a nearby scientific observatory plays an important role in monitoring atmospheric and climatic conditions. The Wank is a popular destination for hikers, day-trippers from Garmisch-Partenkirchen and paragliders, who are able to take advantage of its strong thermals to make exceptionally long flights.
Physical characteristics.
The mountain's geology, which is dominated by calcareous rocks, is typical of the Bavarian Alps. Its climate is also typical of the region. Precipitation is high, ranging from about 1300 mm at valley level to 1800 mm at the summit. It peaks in the summer and is lowest in winter. Wank's mean annual air temperature ranges from 7 C in the valley to 3 C at the summit. The prevailing wind comes from a westerly direction but for about 30 to 40 days a year the mountain experiences a warm, dry föhn wind. A local wind system also operates in the area giving a daily uphill/downhill circulation. Inversion layers occur for about 30 days per year, predominately in the autumn and winter.
Wank was originally covered by a forest consisting of a mix of spruce, fir and beech trees. A process of man-made deforestation that began in the Roman period, when the trees were cut down and the mountain's slopes were grazed by horses, sheep, goats and cattle, resulted in much of the forest being destroyed by the 15th century. Forestry in the area was taken over by the Bavarian government in 1803 but the former forest cover did not regenerate due in part to the continued use of forest lands as pasture, storms and browsing by game animals. As a result, the current Wank forest is predominately spruce (about 75%) and pine (15%). Forestry programmes are currently underway to improve the arboreal diversity of the mountain.
Wankbahn.
Wank is linked to Garmisch-Partenkirchen by a cable car system called the Wankbahn, which usually operates between May and September during daylight hours. Construction began in 1928 under the auspices of the Wank-Bahn AG and the cable car entered service in 1929.<Ref>"". Bayerische Zugspitzbahn Bergbahn AG. Accessed 15 December 2010</ref> It is 3 km long and rises from 740 m to 1750 m above sea level. The system has been upgraded several times since its opening. In 1960 its passenger capacity was increased from 125 to 210 persons per hour. A new Wankbahn was built in 1982, opening on 18 December, which increased the system's capacity to 1,000 persons per hour. Two 300 kW DC motors were installed to drive the cable.
The current Wankbahn is built in two sections, measuring 1670 m and 1330 m long respectively, with a maximum height of 45 m above the ground. The Wankbahn's 135 cabins each have a capacity of four people. They take approximately 18 minutes at a speed of 4 m per second to reach the summit station. A "Wankpass" permits year-round access to the cable car.
Summit.
The grassy summit of the Wank is topped by a cross, set up in July 1904 by the Werdenfelser Heimat Partenkirchen society. Nearby is an observatory and the Wank-Haus, also known as the Alois Huber Haus, a mountain hut that provides food and accommodation to visitors. The Wank-Haus was built by the local branch of the German Alpine Association (DAV) in 1911. Its construction was originally proposed in 1894 and was approved by the Bavarian Forest Service in 1903. It was designed by the Partenkirchen DAV's Treasurer, Alois Huber, and work began in July 1910. It was opened on 28 May 1911 and was renamed after Huber following his death in 1922. It has since been renovated and upgraded on several occasions, most recently in 2006.
The summit is popular for its spectacular views across the region, which provide the best view of Garmisch-Partenkirchen and a complete panorama of the Zugspitze and the Wetterstein mountain range. Patrons of Garmisch's spas can often be seen enjoying the sunshine at the summit as part of their "Liegekur" ("deckchair cure").
Panorama taken from the summit of the Wank
Summit observatory.
The summit observatory, which is located at an altitude of 1782 m, is an important scientific measuring station operated by the Institute for Meteorology and Climate Research of Karlsruhe Institute of Technology. Since 1972 it has measured a variety of atmospheric and climatic phenomena, including the levels of ozone, nitric oxide, sulphur dioxide and various hydrocarbons in the atmosphere as well as meteorological data such as the levels of temperature, dew point, relative humidity, pressure, wind, global and direct irradiance. It became part of the World Meteorological Organization's Background Air Pollution Monitoring Network in 1982. Supplementary meteorological stations have also been established at middle elevation (1175 m above sea level) and in the valley at 735 m. This has enabled scientists to measure a range of natural phenomena including the transport of air pollutants in the region and a marked decline since 1990 in the amount of atmospheric mercury pollution, an effect which has been attributed to the post-1989 closure of polluting factories in the former Eastern Bloc states.
Paragliding.
The mountain is a popular destination for enthusiasts of paragliding who take off from the summit plateau to fly south into the Garmisch-Partenkirchen valley or to peaks in the Wettersteingebirge. The mountain's thermals make it especially popular, as they enable paragliders to make exceptionally long flights when the weather conditions are right.

</doc>
<doc id="54056" url="http://en.wikipedia.org/wiki?curid=54056" title="Rolemaster">
Rolemaster

Rolemaster is a role-playing game published by Iron Crown Enterprises. Rolemaster has come in four separate editions. The third edition, first published in 1995, is also known as the "Rolemaster Standard System" (or RMSS for short). There are two editions currently in production. "Rolemaster Fantasy Roleplaying" (or RMFRP) was first published in 1999 as a reorganized edition of RMSS, and is largely compatible with that edition. The most recent publication of the Rolemaster rule set is "Rolemaster Classic" (RMC), a republished set of the second edition rules.
Basic game mechanics.
Rolemaster uses a percentile dice system and employs both classes (called "Professions" in Rolemaster) and levels to describe character capabilities and advancement.
Task resolution is done by rolling percentile dice, applying relevant modifiers, and looking the result up on the appropriate chart to determine the result. There are various charts to increase the realism of the results, but most of these are optional, and many rolls can be made on a relatively small number of tables.
Combat.
For combat each character has an Offensive Bonus (OB), which takes into account one's natural physical adeptness, weapon skill, and other factors, and a Defensive Bonus (DB), which takes into account natural agility, the use of shields and "Adrenal Defense", the ability of martial artists to avoid blows seemingly without effort. In addition various modifiers for position, wounds, and other factors are present.
An attacking combatant rolls percentile dice, adds his or her OB to the total, adds modifiers, and subtracts the defender's DB. The total is then applied to a table for the attacker's weapon. The attack total is cross-indexed with the type of armor (if any) worn by the defender and the result will be a number of concussion hits dealt, which are then subtracted from the defender's running total. If sufficient hits are dealt, the defender may go unconscious, but death seldom results purely from concussion hit damage.
In addition to concussion hits, however, a critical hit can be dealt by the result on the weapon table. These are described by type (slash, crush, puncture, etc.) and by severity (generally A through E, with E being the most severe). Critical Hits (or simply "crits"), can inflict additional concussion hits, bleeding (subtracted from concussion hits at the start of each new round), broken bones, loss of limbs or extremities, internal organ damage and outright death. If a crit is inflicted, a second roll is made on the appropriate critical table.
Thus, unlike, for example, Dungeons and Dragons, Rolemaster describes wounds not only in the number of points of damage dealt (which are then subtracted from an abstract pool of 'Hit Points'), but with specific details of the injury inflicted. Death occurs, for both player characters and Gamemaster-controlled adversaries, primarily through this critical damage, and not through loss of hit points. In addition, specific injuries carry with them injury penalties, which inhibit further actions on the part of the wounded part, and loss of concussion hits (which represent overall health), can bring about similar penalties.
Almost all die rolls in Rolemaster are 'open-ended', meaning that if a result is high enough (or low enough), you roll again and add (or subtract) the new roll to the original result - and this can happen multiple times, so in theory, there is no upper limit to how well (or poorly) one can roll. This means that a halfling does have a chance, albeit slight, to put down a troll with one well-placed (and lucky) dagger strike.
However, the fact that one's opponents also fight using these same rules can make Rolemaster a very deadly game for both PCs and NPCs; a lucky shot may let an inexperienced fighter slay a war-hardened veteran.
Fans of the system maintain that this adds a great deal of realism not present in many other fantasy games, and reflects the true deadliness of a well-placed strike from a weapon, even a small one such as a dagger. Death from natural weapons (such as a fist or an animal's teeth and claws) can happen but is very rare against armored combatants. Unarmored characters may very well suffer serious wounds when mauled by animals, but again this allows for more credible confrontations than in other fantasy games, where the threat posed by an "unfantastic" beast such as a wolf, grizzly bear, or tiger is considered minimal.
Because Rolemaster's approach to combat favors a warrior that is properly armed and armored, a character that is poorly equipped (as is typically the case with newly generated characters) is decidedly vulnerable. Such characters can have a tough time prevailing against even fairly mundane opponents. This can prove frustrating for new players, and has given rise to hyperbolic tales of housecats cutting down promising young heroes in their prime.
Rolemaster is sometimes derisively called 'Chartmaster' or 'Rulemonster' for depending upon numerous tables and charts for character generation and resolving game actions, and for its perceived vast array of rules covering every possible situation. Supporters of the game argue that many of these rules and charts are entirely optional.
Character creation and development.
Rolemaster is a skill-based system in which very few absolute restrictions on skill selection are employed. All character abilities (fighting, stealth, spell use, etc.) are ultimately handled through the skill system. A character's profession represents not a rigid set of abilities available to the character, but rather a set of natural proficiencies in numerous areas. These proficiencies are reflected in the cost to purchase the skills themselves.
Rolemaster characters have ten attributes, called "stats", which represent their natural abilities in such areas as physical strength, memory, self-discipline, agility. Both random and points-based methods for determining stat totals exist, but the final result will be a number on a percentile scale (1-100), which is then used to determine the character's skill bonus at actions which employ that stat. A self-governing system is in place also such that each skill closer to 100 is more costly than the last. Moving a skill from 50 to 51 is almost trivial; from 98 to 99 nigh impossible.
In character creation, and as characters advance in levels, Development Points are assigned, and can be used to purchase skills. In RMSS and RFRP, they can also be spent on Training Packages, which represent a specific bundle of skills, equipment and contacts gained through training. These are optional, and can be ignored if the player prefers to design his or her character entirely from the ground up.
Skills are purchased in Ranks; the more ranks a character has in a skill, the more able he is at actions covered by that skill. The number of ranks is multiplied by a set number dependent on the total number of ranks the character has, then added to the bonus for the relevant stats. The final number is the character's skill bonus, which is the number actually added to the dice when actions are attempted.
History of Rolemaster.
Over the years, a large number of products have been brought out for Rolemaster and it can be rather confusing to figure out which of these were put out for which version of the game and what books are needed to actually play.
There have been four versions of the game produced, which fall into two major groups with a fifth currently in the beta testing phase. First Edition and Second Edition Rolemaster belong to the first group, usually just referred to as RM2. There was then a fairly major revision to the game when the third version, Rolemaster Standard System was released (RMSS). This was then reorganized and very lightly revised into the fourth version, Rolemaster Fantasy Roleplaying (RMFRP). RMSS and RMFRP comprise the second group. The latest release of Rolemaster which was released for playtesting in September 2012 is an attempt to unify all previous versions of the game. 
Products within one group tend to be almost 100% compatible with other products in the same group. Compatibility between the groups is also high, but problematic, especially in the case of RM2's vast array of optional rules, some of which will simply not work in RMSS or RMFRP without modification. Many of RM2's options were added as part of the RMSS/RMFRP core in different forms.
Rolemaster first and second editions.
The term Rolemaster First Edition (RM1) is generally used to refer to the products released between 1980 and 1982, including the original versions of Arms Law, Claw Law, Spell Law, Character Law and Campaign Law. These were available initially as individual books, and later as combined volumes (Character Law & Campaign Law and Arms Law & Claw Law were combined virtually unaltered into single books), and in boxed sets.
The original concept was to produce a series of modular supplements which could be used to replace portions of existing roleplaying games (in particular Advanced Dungeons & Dragons, but also including other contemporary games such as RuneQuest, which was closer to Rolemaster in many respects than AD&D was). However, with the publication of Character Law, the full Rolemaster system became able to stand on its own as a distinct game system.
In 1984 the information in the books was expanded and revised and some of the books were combined and the material in them rearranged. An initial boxed set was brought out in 1984 which resembled the previous Spell Law and Arms Law/Claw Law boxed set but contained a new Spell Law, a combined Arms Law/Claw and the existing Character Law, as well as the Vog Mur campaign setting module.
A new boxed set was released shortly thereafter containing the combined Arms Law/Claw Law, the updated Spell Law and the combined Character Law/Campaign Law book, as well as The Cloudlords of Tanara, a detailed setting and adventure supplement which introduced ICE's original Loremaster setting, which would later develop into the more sophisticated Shadow World.
Several additional books were published from 1985 to 1988, including Rolemaster Companions 1, 2, and 3 and the first Creatures and Treasures book. The official start of the Second Edition Rolemaster series came with a Boxed Set (the so-called "Red Spine" set) containing redesigned editions of Arms Law & Claw Law, Spell Law, and Character Law & Campaign Law, all with red-bordered covers.
Technically, the products released between 1984 and 1988 are also First Edition Rolemaster products, but actual differences between RM1 and RM2 were slight (limited to a minor modification to the combat sequence, some rearranging of material, and a major graphical overhaul), and few (if any) compatibility issues ever arose.
This means that, in common parlance, the term "Rolemaster Second Edition" (RM2) is often used to refer everything published from 1984 to 1994. In particular, Rolemaster Companion II included the complete Skill list and descriptions section and Master Development Point Cost Tables as well as several Professions that are often considered the distinguishing features of Rolemaster Second Edition.
Numerous additional supplements were produced for the Second Edition, including "numbered" Companions 4-7, the Alchemy, Oriental, Elemental Spell Users' and Arms Companions, and two additional Creatures and Treasures volumes.
Much of this material, and the material that was published under the aegis of the first edition, took the form of optional and variant rules (some of which, like the greatly expanded skill system of Rolemaster Companion II, were widely adopted), and new professions and spell lists. Given this, many regarded RM2 as a toolkit for outfitting and developing one's own game. Some variants even replaced whole sections of distinctively "Rolemaster" rules, such as the combat system, with more traditional systems closer to the line established by Advanced Dungeons and Dragons.
Debate still persists over whether this toolkit approach was RM2's greatest asset or a terrible weakness. Ultimately it made for a very flexible system with a vast array of options, but could easily suffer from play balance problems if particular sets of rules were used together, since little effort was made to balance different variants against each other, and power creep in the later professions and spell lists was very much in evidence.
Rolemaster Standard System.
In 1995 the game was revamped and re-released as Rolemaster Standard System (RMSS). The biggest changes were to Character Generation, particularly in the number of skills available and the way bonuses for the skills were calculated. Skills were now grouped into Categories of similar skills and one could buy ranks separately in the Category and the actual Skill. Also the combat sequence was revised again, and some of the details of spellcasting were changed. The way Spell Lists were learned was completely overhauled and most of the Spell lists were adjusted and rebalanced. The actual method of attacking and adjudicating damage did not change much, and there weren't much more than cosmetic changes to the stats for Creatures and Monsters.
Like most changes, opinions on whether the changes were for the better or not vary widely; some fans really liked the changes, while others were unimpressed and elected to stick with the more familiar RM2. For the most part the objections from RM2 players had more to do with feeling that Rolemaster did not need such a radical overhaul, and disappointment over the fact that RM2 was no longer going to be supported as such.
Rolemaster Fantasy Roleplaying.
In 1999 the game underwent a slight restructuring when Rolemaster Fantasy Roleplaying (RMFRP) was released, but this was mostly a rearranging of material with very few changes to the rules themselves. A detailed comparison of the RMSS and RMFRP systems may be found on the .
Rolemaster Fantasy Roleplaying is the current edition of the Rolemaster rules, and is thus well-supported and easier for interested new players to pick up and try out. One positive change made in RMFRP was a single core book ("Rolemaster Fantasy Roleplaying"), containing a stripped-down version of the complete game, so that only one book was necessary for play. "Arms Law" adds additional Attack and Critical tables, while "Character Law" adds additional races, professions, skills and the full talent and flaw system.
RMFRP has broken the older single-volume Spell Law into three separate books, "Of Essence", "Of Channelling" and "Of Mentalism", each of which expands that realm of power with additional professions and spell lists, and expanding each spell list to 50th level spells. All of this material was previously available under RMSS as part of the single-volume Spell Law and the Rolemaster Standard Rules.
There are other supplements as well, but most of them build upon the material presented in the books listed. Such as the Channeling Companion, which introduces a new profession called the Priest and adds a passel of new rules. Another supplement is "Fire and Ice: The Elemental Companion". This book contains all you need to know to add elementalism to Rolemaster.
Rolemaster Classic.
The problems that drove Iron Crown Enterprises into voluntary receivership also created problems with the intellectual property that was the RM1 and RM2 systems. Multiple parties owned the content of those original publications, so Iron Crown wasn't able to republish the originals. As a result, Iron Crown cleaned up and republished the RM2 rules with new typesetting and illustrations in 2007 as Rolemaster Classic (RMC). The core books of Rolemaster Classic are "Character Law", "Arms Law", and "Spell Law".
Rolemaster Express.
Iron Crown also published the core of the Rolemaster Classic rules, with most of the options removed, as Rolemaster Express. The company describes RMX as an experimental publication, designed to address the persistent criticism of Rolemaster as being too complex. Rolemaster Express is a single, 88-page book that contains everything necessary to play.
Unified Rolemaster.
In September 2012 Iron Crown Enterprises announced the release of a new version of Rolemaster for playtesting. Known as "Rolemaster Unified", the game is an attempt to combine the previous versions of the game into one system.

</doc>
<doc id="54057" url="http://en.wikipedia.org/wiki?curid=54057" title="IS–LM model">
IS–LM model

The IS–LM model, or Hicks–Hansen model, is a macroeconomic tool that demonstrates the relationship between interest rates and real output, in the goods and services market and the money market (also known as the assets market). The intersection of the "investment–saving" (IS) and "liquidity preference–money supply" (LM) curves is the "general equilibrium" where there is simultaneous equilibrium in both markets. Two equivalent interpretations are possible: first, the IS–LM model explains changes in national income when the price level is fixed in the short-run; second, the IS–LM model shows why the aggregate demand curve shifts.
Hence, this tool is sometimes used not only to analyse the fluctuations of the economy but also to find appropriate stabilisation policies.
The model was developed by John Hicks in 1937, and later extended by Alvin Hansen, as a mathematical representation of Keynesian macroeconomic theory. Between the 1940s and mid-1970s, it was the leading framework of macroeconomic analysis. While it has been largely absent from macroeconomic research ever since, it is still the backbone of many introductory macroeconomics textbooks.
History.
The IS/LM model was born at the econometric conference held in Oxford during September, 1936. Roy Harrod, John R. Hicks, and James Meade all presented papers
describing mathematical models attempting to summarize John Maynard Keynes' "General Theory of Employment, Interest, and Money". Hicks, who had seen a draft of Harrod's paper, invented the IS/LM model (originally using the abbreviation "LL", not "LM"). He later presented it in
"Mr. Keynes and the Classics: A Suggested Interpretation".
Hicks later agreed that the model missed important points of Keynesian theory, criticizing it as having very limited use beyond "a classroom gadget", and criticizing equilibrium methods generally: "When one turns to questions of policy, looking towards the future instead of the past, the use of equilibrium methods is still more suspect." The first problem was that it presents the real and monetary sectors as separate, something Keynes attempted to transcend. In addition, an equilibrium model ignores uncertainty—and that liquidity preference only makes sense in the presence of uncertainty "For there is no sense in liquidity, unless expectations are uncertain." A shift in one of the IS or LM curves will cause a change in expectations, which shifts the other curve. Most modern macroeconomists see the IS/LM model as being—at best—a starting approximation for understanding the real world.
Although generally accepted as being imperfect, the model is seen as a useful pedagogical tool for imparting an understanding of the questions that macroeconomists today attempt to answer through more nuanced approaches. As such, it is included in most undergraduate macroeconomics textbooks, but omitted from most graduate texts due to the current dominance of real business cycle and new Keynesian theories.
Formation.
The model is presented as a graph of two intersecting lines in the first quadrant.
The horizontal axis represents national income or real gross domestic product and is labelled "Y." The vertical axis represents the real interest rate, "r." Since this is a non-dynamic model, there is a fixed relationship between the nominal interest rate and the real interest rate (the former equals the latter plus the expected inflation rate which is exogenous in the short run); therefore variables such as money demand which actually depend on the nominal interest rate can equivalently be expressed as depending on the real interest rate.
The point where these schedules intersect represents a short-run equilibrium in the real and monetary sectors (though not necessarily in other sectors, such as labor markets): both the product market and the money market are in equilibrium. This equilibrium yields a unique combination of the interest rate and real GDP.
IS curve.
For the investment—saving curve, the independent variable is the interest rate and the dependent variable is the level of income. (Note that economics graphs like this one typically place the independent variable—interest rate,in this example—on the vertical axis rather than the horizontal axis.) The IS curve is drawn as downward-sloping with the interest rate (i) on the vertical axis and GDP (gross domestic product: Y) on the horizontal axis. The initials IS stand for "Investment and Saving equilibrium" but since 1937 have been used to represent the locus of all equilibria where total spending (consumer spending + planned private investment + government purchases + net exports) equals an economy's total output (equivalent to real income, Y, or GDP). To keep the link with the historical meaning, the IS curve can be said to represent the equilibria where total private investment equals total saving, where the latter equals consumer saving "plus" government saving (the budget surplus) "plus" foreign saving (the trade surplus). In equilibrium, all spending is desired or planned; there is no unplanned inventory accumulation. The level of real GDP (Y) is determined along this line for each interest rate.
Thus the IS curve is a locus of points of equilibrium in the "real" (non-financial) economy. Each point on the curve represents the equilibrium between the Savings and Investment (S=I).
Given expectations about returns on fixed investment, every level of the real interest rate (i) will generate a certain level of planned fixed investment and other interest-sensitive spending: lower interest rates encourage higher fixed investment and the like. Income is at the equilibrium level for a given interest rate when the saving that consumers and other economic participants choose to do out of this income equals investment (or, equivalently, when "leakages" from the circular flow equal "injections"). The multiplier effect of an increase in fixed investment resulting from a lower interest rate raises real GDP. This explains the downward slope of the IS curve. In summary, this line represents the causation from falling interest rates to rising planned fixed investment (etc.) to rising national income and output.
The IS curve is defined by the equation
where Y represents income, formula_2 represents consumer spending as an increasing function of disposable income (income, Y, minus taxes, T(Y), which themselves depend positively on income), formula_3 represents investment as a decreasing function of the real interest rate, G represents government spending, and NX(Y) represents net exports (exports minus imports) as an increasing function of income (increasing because exports are an increasing function of income).
In this model, the level of C (consumption), G (government spending), EX (exports), IM (imports), and Rt (real interest rate) are considered to be exogenous, meaning that they are taken as a given, because they are determined by factors outside of this model. Their equations are as follows: Ct = āt Ȳt , Gt = āg Ỹt , EXt = āex Ȳt , and IMt = āim Ȳt. I (investment) is endogenous, meaning that it is explained by our model, and has the equation It = (āi Ȳt) − b (Rt − ṝ) Ȳt , where ṝ is the marginal product of capital, Rt is the real interest rate, āi is the share of potential output that goes toward investment, and b is a constant. A few equations are necessary in order to derive the IS curve: ā = āc + āi + āg + āex - āim - 1, and Ỹt = (Yt - Ȳt) / Ȳt = (Yt / Ȳt) - (Ȳt / Ȳt) = (Yt / Ȳt) - 1. When you plug in all the equations into the original Yt = Ct + It + Gt + EXt - IMt and solve, you will get the short run output, which is Ỹt = ā - b (Rt - ṝ).
LM curve.
For the liquidity preference and money supply curve, the independent variable is "income" and the dependent variable is "the interest rate." The LM curve shows the combinations of interest rates and levels of real income for which the money market is in equilibrium. It is an upward-sloping curve representing the role of finance and money.
The LM function is the set of equilibrium points between the liquidity preference (or demand for money) function and the money supply function (as determined by banks and central banks).
Each point on the LM curve reflects a particular equilibrium situation in the money market equilibrium diagram, based on a particular level of income. In the money market equilibrium diagram, the liquidity preference function is simply the willingness to hold cash balances instead of securities. For this function, the nominal interest rate (on the vertical axis) is plotted against the quantity of cash balances (or liquidity), on the horizontal. The liquidity preference function is downward sloping. Two basic elements determine the quantity of cash balances demanded (liquidity preference) and therefore the position and slope of the function:
The money supply function for this situation is plotted on the same graph as the liquidity preference function. The money supply is determined by the central bank decisions and willingness of commercial banks to loan money. Though the money supply is related indirectly to interest rates in the very short run, the money supply in effect is perfectly inelastic with respect to nominal interest rates (assuming the central bank chooses to control the money supply rather than focusing directly on the interest rate). Thus the money supply function is represented as a vertical line – money supply is a constant, independent of the interest rate, GDP, and other factors. Mathematically, the LM curve is defined by the equation formula_4, where the supply of money is represented as the real amount M/P (as opposed to the nominal amount M), with P representing the price level, and L being the real demand for money, which is some function of the interest rate i and the level Y of real income. The LM curve shows the combinations of interest rates and levels of real income for which money supply equals money demand—that is, for which the money market is in equilibrium.
For a given level of income, the intersection point between the liquidity preference and money supply functions implies a single point on the LM curve: specifically, the point giving the level of the interest rate which equilibrate the money market at the given level of income. Recalling that for the LM curve, the interest rate is plotted against real GDP (whereas the liquidity preference and money supply functions plot interest rates against the quantity of cash balances), an increase in GDP shifts the liquidity preference function rightward and hence increases the interest rate. Thus the LM function is positively sloped.
Shifts.
One hypothesis is that a government's deficit spending ("fiscal policy") has an effect similar to that of a lower saving rate or increased private fixed investment, increasing the amount of demand for goods at each individual interest rate. An increased deficit by the national government shifts the IS curve to the right. This raises the equilibrium interest rate (from i1 to i2) and national income (from Y1 to Y2), as shown in the graph above. The equilibrium level of national income in the IS-LM diagram is referred to as aggregate demand.
By the above hypothesis, the graph indicates one of the major criticisms of deficit spending as a way to stimulate the economy: rising interest rates lead to crowding out – i.e., discouragement – of private fixed investment, which in turn may hurt long-term growth of the supply side (potential output).
Keynesians respond that deficit spending may actually "crowd in" (encourage) private fixed investment via the accelerator effect, which helps long-term growth. Further, if government deficits are spent on productive public investment (e.g., infrastructure or public health) that spending directly and eventually raises potential output, although not necessarily more (or less) than the lost private investment might have. The extent of any crowding out depends on the shape of the LM curve. A shift in the IS curve along a relatively flat LM curve can increase output substantially with little change in the interest rate. On the other hand, an upward shift in the IS curve along a vertical LM curve will lead to higher interest rates, but no change in output (this case represents the treasury view).
Rightward shifts of the IS curve also result from exogenous increases in investment spending (i.e., for reasons other than interest rates or income), in consumer spending, and in export spending by people outside the economy being modelled, as well as by exogenous decreases in spending on imports. Thus these too raise both equilibrium income and the equilibrium interest rate. Of course, changes in these variables in the opposite direction shift the IS curve in the opposite direction.
The IS–LM model also allows for the role of monetary policy. If the money supply is increased, that shifts the LM curve downward and to the right, lowering interest rates and raising equilibrium national income. Further, exogenous decreases in liquidity preference, perhaps due to improved transactions technologies, lead to downward shifts of the LM curve and thus increases in income and decreases in interest rates. Changes in these variables in the opposite direction shift the LM curve in the opposite direction.
Incorporation into larger models.
By itself, the IS–LM model is used to study the short run when prices are fixed or sticky and no inflation is taken into consideration. But in practice the main role of the model is as a sub-model of larger models (especially the Aggregate Demand-Aggregate Supply model – the AD–AS model) which allow for a flexible price level. In the aggregate demand-aggregate supply model, each point on the aggregate demand curve is an outcome of the IS–LM model for aggregate demand Y based on a particular price level. Starting from one point on the aggregate demand curve, at a particular price level and a quantity of aggregate demand implied by the IS–LM model for that price level, if one considers a higher potential price level, in the IS–LM model the real money supply M/P will be lower and hence the LM curve will be shifted higher, leading to lower aggregate demand; hence at the higher price level the level of aggregate demand is lower, so the aggregate demand curve is negatively sloped.

</doc>
<doc id="54058" url="http://en.wikipedia.org/wiki?curid=54058" title="Hypanthium">
Hypanthium

In angiosperms, a hypanthium or floral cup is a structure where basal portions of the calyx, the corolla, and the stamens form a cup-shaped tube. It is sometimes called a floral tube, a term that is also used for corolla tube and calyx tube. It can often contain the nectaries of the plant. It is present in most flowering species, although varies in structural dimensions and appearance. This differentiation between the hypanthium in particular species is useful with identification. Some geometric forms are obconic shapes as in toyon, whereas some are saucer-shaped as in "Mitella caulescens".
Its presence is diagnostic of many families, including the Rosaceae, Grossulariaceae, and Fabaceae. In some cases, it can be so deep, with such a narrow top, that the flower can appear to have an inferior ovary - the ovary is below the other attached floral parts. The hypanthium is known by different common names in differing species. In the eucalypts, it is referred to as the "gum nut"; in roses it is called the hip.
Variations in plant species.
In myrtles the hypanthium can either surround the ovary loosely or tightly; in some cases it can be fused to the walls of the ovary. It can vary in length. The rims around the outside of the hypanthium contain the calyx lobes or free sepals, petals and either the stamen or multiple stamen that are attached at one or two points. 
The flowers of the Rosaceae family always have some type of hypanthium or at least a floral cup from which the sepals, petals and stamens all arise. In the Rosaceae family, or the rose family, the hypanthium is lined with nectar-producing tissue known as nectaries. The nectar is a sugary substance that attracts birds and bees to the flower, who then take the pollen from the lining of the hypanthium and transfer it to the next flower they visit, usually a neighbouring plant.
The stamens borne on the rim of the hypanthium are the pollen-producing reproductive organs of the flower. The androecious or male organ usually consists of a filament which is a structure that supports the anther, which release the pollen. The anthers are typically two-lobed and attach to the filament either at the base or middle. The hypanthium helps in many ways with the reproduction and cross pollination pathways of most plants. It provides weather protection and a medium to sustain the lost pollen, increasing the probability of fertility and cross-pollination. The retained pollen can then attach to pollinators such as birds, bees, moths, beetles, bats, butterflies and other animals. Wind can act as an instigator for fertilisation. The hypanthium is also an adaptive feature for structural support. It helps the stem fuse together with the flower, in turn strengthening the bond and overall stability and integrity.
Bibliography.
Books.
</dl>

</doc>
<doc id="54060" url="http://en.wikipedia.org/wiki?curid=54060" title="City of Westminster">
City of Westminster

The City of Westminster () is an Inner London borough which occupies much of the central area of Greater London including most of the West End. It is to the west of and adjoining the ancient City of London, directly to the east of the Royal Borough of Kensington and Chelsea, and its southern boundary is the River Thames. It was created with the 1965 establishment of Greater London. Upon creation, Westminster was awarded city status, which had been previously held by the smaller Metropolitan Borough of Westminster.
Aside from a number of large parks and open spaces, the population density of the district is high. Many sites commonly associated with London are in the borough, including St. James's Palace, Buckingham Palace, the Houses of Parliament, and 10 Downing Street. The borough is divided into a number of localities including the ancient political district of Westminster around the Palace of Westminster; the shopping areas around Oxford Street, Regent Street, Piccadilly and Bond Street; and the night time entertainment district of Soho. Much of the borough is residential, and in 2008 it was estimated to have a population of 236,000. The local authority is Westminster City Council.
History.
The origins of the City of Westminster pre-date the Norman Conquest of England. In the mid-11th Century king Edward the Confessor began the construction of an abbey at Westminster, only the foundations of which survive today. Between the abbey and the river he built a palace, thereby guaranteeing that the seat of Government would be fixed at Westminster, and inevitably drawing power and wealth west out of the old City of London.
For centuries Westminster and the City of London were geographically quite distinct. It was not until the sixteenth century that houses began to be built over the adjoining fields, eventually absorbing nearby villages such as Marylebone and Kensington, and gradually creating the vast Greater London that exists today. Westminster briefly became a city (in the sense of the seat of a bishop) in 1540 when Henry VIII created the short-lived Diocese of Westminster.
The present-day City of Westminster as an administrative entity with its present boundaries dates from 1965, when the City of Westminster was created from the former area of three metropolitan boroughs: St Marylebone, Paddington, and the smaller Metropolitan Borough of Westminster, which included Soho, Mayfair, St. James's, Strand, Westminster, Pimlico, Belgravia, and Hyde Park. This re-structuring took place under the London Government Act 1963, which significantly reduced the number of local government districts in London, resulting in local authorities responsible for larger geographical areas and greater populations.
The Westminster Metropolitan Borough was itself the result of an administrative amalgamation which took place in 1900. Sir John Hunt O.B.E was the First Town Clerk of the City of Westminster, 1900–1928. 
Prior to 1900, the area occupied by what would become the Metropolitan Borough of Westminster had been administered by five separate local bodies: the Vestry of St George Hanover Square, the Vestry of St Martin in the Fields, Strand District Board of Works, Westminster District Board of Works and the Vestry of Westminster St James.
The boundaries of the City of Westminster today, as well as those of the other London boroughs, have remained more or less unchanged since the Act of 1963.
Demography.
According to the 2011 census, the city had a population of 219,396. Approximately 61.6% of the population are White (British: 35.2%, Irish: 2.3%, and Other White: 24.1%). 14.6% are of any Asian ethnicity (Including Chinese), 7.5% Black,7.2% Arab, 5.2% Mixed, and 3.9% belong to other racial groups.
Governance.
Local government.
The city is divided into 20 wards, each electing three councillors. Westminster City Council is currently composed of 48 Conservative Party members and 12 Labour Party members.
A Lord Mayor is elected annually to serve as the official representative of the city for one year. See List of Lord Mayors of Westminster for a list of former Mayors (1900–1965) and Lord Mayors (1965 to date).
Districts.
The City of Westminster covers all or part of the following areas of London:
Economy.
The City of Westminster is home to a large number of companies. Many leading global corporations have chosen to establish their global or European headquarters in the City of Westminster. Mayfair and St. James's within the City of Westminster also have a large concentration of hedge fund and private equity funds. The West End is known as the Theatre District and is home to many of the leading performing arts businesses. Soho and its adjoining areas house a concentration of media and creative companies. Oxford Street is one of the leading shopping destinations in the world. The list of companies includes
The Hong Kong Economic and Trade Office, London is in Westminster.
Companies that previously had their head offices in the City of Westminster include Imperial Chemical Industries (ICI), British Aircraft Corporation, British Midland (Portland House), British United Airways, British Mediterranean Airways, Cadbury, Diageo, BAA Limited, Lloyd International Airways, and P&O Princess Cruises. In addition, Iran Air previously had its Piccadilly main sales office in the city.
Landmarks.
The City of Westminster contains many of the most famous sites in London. Some of the popular tourist sites are Buckingham Palace, Palace of Westminster (Houses of Parliament) and Big Ben and nearby Westminster Abbey.
Parks and open spaces.
These include Green Park, Hyde Park, Kensington Gardens, Regent's Park and St. James's Park. In addition to parks and open spaces within the borough, the City owns and maintains East Finchley Cemetery and crematorium in the London Borough of Barnet.
Transport.
Bridges.
These include Chelsea Bridge, Grosvenor Bridge, Vauxhall Bridge, Lambeth Bridge, Westminster Bridge, Hungerford Bridge and Waterloo Bridge, listed west to east (downstream).
National Rail stations.
Stations include: London Charing Cross; serving the South Eastern Main Line via South East London and Kent. London Marylebone; serving the Chiltern Main Line via North East London, the West Midlands and Birmingham. London Paddington; serving the Great Western Main Line via South West England, Wales and Heathrow Airport and London Victoria; serving the Brighton Main Line and the Chatham Main Line. These are all main London termini stations.
London Underground.
The City of Westminster is served by 27 tube stations, and 10 of the 11 Underground lines (the Waterloo and City line is the exception).
Electric charging points.
Westminster City Council now has electric vehicle charging points in 15 locations through the city (13 car parks and two on-street points). Users pay an annual fee to cover administration costs to register and use the points.
Travel to work.
In March 2011, the main forms of transport that residents used to travel to work were: underground, metro, light rail, tram, 21.0% of all residents aged 16–74; on foot, 9.3%; bus, minibus or coach, 9.3%; driving a car or van, 6.0%; work mainly at or from home, 5.5%; bicycle, 3.1%; train, 3.0%.
Education.
Westminster Children's Services administers many primary and secondary schools. In addition, there are several state-funded faith schools, primarily Church of England (CE), and Roman Catholic (RC), but Christian non-denominational (ND) schools are also in the borough, and there are several non-profit-making junior and senior independent schools.
Public libraries.
The London Library, an independent lending library, is at 14 St. James Square.
The city operates one reference library, the Westminster Reference Library. City-operated public lending libraries in Westminster include:
In addition the city has two specialist libraries, the Westminster Music Library, the largest music library in the United Kingdom, and the Westminster Chinese Library in the Charing Cross Library.
Home ownership.
In terms of tenure, the borough ranks highest on one standard criteria in analysing housing supply and demand, the proportion of private rented accommodation relative to other types of housing in England. This is indicative of a high density of development and higher investment demand relative to other districts in England and most of the 15 highest-ranking local authorities are boroughs of Greater London. Tourism also increases the proportion of willing third-party landlords, as the two authorities which are outside of London in the list are England's largest south coast holiday resorts.

</doc>
<doc id="54061" url="http://en.wikipedia.org/wiki?curid=54061" title="Amphitheatre">
Amphitheatre

An amphitheatre or amphitheater is an open-air venue used for entertainment, performances, and sports. The term derives from the ancient Greek ἀμφιθέατρον ("amphitheatron"), from ἀμφί ("amphi"), meaning "on both sides" or "around" and θέατρον ("théātron"), meaning "place for viewing". 
Ancient Roman amphitheatres were oval or circular in plan, with seating tiers that surrounded the central performance area, like a modern open-air stadium. In contrast both ancient Greek and ancient Roman theatres were built in a semicircle, with tiered seating rising on one side of the performance area. Modern usage for "amphitheater" is lax, and does not always respect the ancient usage. As a result the word can be found describing theatre-style stages with the audience only on one side, theatres in the round, and stadiums. Natural formations shaped like man-made theatres are sometimes known as natural amphitheatres. The three largest Roman amphitheatres (in the original sense) in the world in order of size are the Colosseum, the Amphitheatre Campania and the Amphitheatre of El Djem.
Ancient Roman amphitheatres were major public venues, circular or oval in shape, and used for events such as gladiator combats, chariot races, "venationes" (animal slayings) and executions. About 230 Roman amphitheatres have been found across the area of the Roman Empire. Their typical shape, functions and name distinguish them from Roman theatres, which are more or less semicircular in shape; from the circuses (akin to hippodromes) whose much longer circuits were designed mainly for horse or chariot racing events; and from the smaller stadia, which were primarily designed for athletics and footraces.
The earliest Roman amphitheatres date from the middle of the first century BC, but most were built under Imperial rule, from the Augustan period (27 BC–14 AD) onwards. Imperial amphitheatres were built throughout the Roman empire; the largest could accommodate 40,000–60,000 spectators, and the most elaborate featured multi-storeyed, arcaded façades and were elaborately decorated with marble, stucco and statuary. After the end of gladiatorial games in the 5th century and of animal killings in the sixth, most amphitheatres fell into disrepair, and their materials were mined or recycled. Some were razed, and others converted into fortifications. A few continued as convenient open meeting places; in some of these, churches were sited.
Modern amphitheatres.
In the sense in which the word has come to be popularly used now, an amphitheatre is a curved, acoustically vibrant performance space, particularly one located outdoors. Contemporary amphitheatres often include standing structures, called bandshells, sometimes curved or bowl-shaped, both behind the stage and behind the audience, creating an area which echoes or amplifies sound, making the amphitheatre ideal for musical or theatrical performances. Most are semicircular in shape, so they should not properly be called amphitheatres, but nevertheless this usage has become common. 
Notable modern amphitheatres include the Shoreline Amphitheatre and the Hollywood Bowl. The term "amphitheatre" is also used (completely incorrectly in this case) for some indoor venues such as the Gibson Amphitheatre.
Natural amphitheatres.
A natural amphitheatre is a performance space located in a spot where a steep mountain or a particular rock formation naturally amplifies or echoes sound, making it ideal for musical and theatrical performances. The term amphitheatre can also be used to describe naturally occurring formations which would be ideal for this purpose, even if no theatre has been constructed there. 
Notable natural amphitheatres include the Drakensberg amphitheatre in Drakensberg, South Africa, Slane Castle in Ireland, the Supernatural Amphitheatre in Victoria, Australia, and Echo amphitheatre, Red Rocks Amphitheatre in Morrison, Colorado and The Gorge Amphitheatre in Washington State, United States.

</doc>
<doc id="54062" url="http://en.wikipedia.org/wiki?curid=54062" title="Southwark">
Southwark

Southwark ( ) is a district of Central London and part of the London Borough of Southwark. Situated 1.5 mi east of Charing Cross, it forms one of the oldest parts of London and fronts the River Thames to the north. It historically formed an ancient borough in the county of Surrey, made up of a number of parishes, which increasingly came under the influence and jurisdiction of the City of London. As an inner district of London, Southwark experienced rapid depopulation during the late 19th and early-20th centuries. It is now at an advanced stage of regeneration and is the location of the City Hall offices of the Greater London Authority.
History.
Toponymy.
The name "Suthriganaweorc" or "Suthringa geweorche" is recorded for the area in the 10th century Anglo-Saxon document known as the "Burghal Hidage" and means "fort of the men of Surrey" or "the defensive work of the men of Surrey". Southwark is recorded in the 1086 Domesday Book as "Sudweca". The name means "southern defensive work" and is formed from the Old English "sūth" and "weorc". The southern location is in reference to the City of London to the north, Southwark being at the southern end of London Bridge. Until 1889, the county of Surrey included the present-day London borough of Southwark, yet the name has been used for various areas of civil administration, including the ancient Borough of Southwark, the Metropolitan Borough of Southwark and the current London Borough of Southwark. The ancient borough of Southwark was also known simply as The Borough—or Borough—and this name, in distinction from 'The City', has persisted as an alternative name for the area. Southwark was also simultaneously referred to as the Ward of Bridge Without when administered by the City (from 1550 to 1900) and as an Aldermanry until 1978.
Early history.
Southwark is on a previously marshy area south of the River Thames. Recent excavation has revealed prehistoric activity including evidence of early ploughing, burial mounds and ritual activity. The area was originally a series of islands in the River Thames. This formed the best place to bridge the Thames and the area became an important part of Londinium owing its importance to its position as the endpoint of the Roman London Bridge. Two Roman roads, Stane Street and Watling Street, met at Southwark in what is now Borough High Street. Archaeological work at Tabard Street in 2004 discovered a plaque with the earliest reference to 'London' from the Roman period on it. Londinium was abandoned at the end of the Roman occupation in the early fifth century and both the city and its bridge collapsed in decay. Archaeologically, evidence of settlement is replaced by a largely featureless soil called the Dark Earth which probably (although this is contested) represents an urban area abandoned.
Southwark appears to recover only during the time of King Alfred and his successors. Sometime about 886 AD, the 'burh' of Southwark was created and the Roman City area reoccupied. It was probably fortified to defend the bridge and hence the re-emerging City of London to the north. This defensive role is highlighted by the use of the bridge in 1016 as a defence against King Sweyn and his son King Cnut by Ethelred the Unready and again, in 1066, against King William the Conqueror. He failed to force the bridge during the Norman conquest of England, but Southwark was devastated.
Southwark appears in the "Domesday Book" of 1086 as held by several Surrey manors. Its assets were: The Bishop Odo of Bayeux held the monastery (the site of the Cathedral), the 'tide-way' - which still exists as St Mary Overy dock; the King owned the 'church' (probably St Olave's) and its 'tidal stream' (St Olave's Dock); the dues of the 'waterway' or mooring place were shared between the 'King' and Earl Godwin; the King also had the 'toll' of the strand; and the 'men of Southwark' had the right to a 'haw and its toll'. Southwark's value to the King was £16. Much of Southwark was originally owned by the church—the greatest reminder of monastic London is Southwark Cathedral, originally the priory of St Mary Overy.
During the early Middle Ages, Southwark developed and was one of the four Surrey towns which returned Members of Parliament for the first commons assembly in 1295. An important market occupied the High Street from some time in the 13th century, which was controlled by the City's officers—it was later removed in order to improve traffic to the Bridge, under a separate Trust by Act of Parliament of 1756 as the Borough Market on the present site. The area was renowned for its inns, especially The Tabard, from which Chaucer's pilgrims set off on their journey in "The Canterbury Tales".
Just west of the Bridge was the 'Clink Liberty' manor, which was never controlled by the City, technically held under the Bishopric of Winchester's nominal authority. This area therefore became the entertainment district for London, and it was also the red-light area. In 1587, Southwark was given its first playhouse theatre, "The Rose". The Rose was set up by Philip Henslowe, and soon became a popular place of entertainment for all classes of Londoners. Both Christopher Marlowe and William Shakespeare, two of the finest writers of the Elizabethan age, worked at the Rose.
In 1599 the Globe Theatre, in which Shakespeare was a shareholder, was erected on the Bankside in the Liberty of the Clink. It burned down in 1613, and was rebuilt in 1614, only to be closed by the Puritans in 1642 and subsequently pulled down not long thereafter. A modern replica called Shakespeare's Globe, has been built near the original site. Southwark was also a favourite area for entertainment such as bull and bear-baiting. The impresario in the later Elizabethan period for these entertainments was Shakespeare's colleague Edward Alleyn, who left many local charitable endowments, most notably Dulwich College.
On 26 May 1676, ten years after the Great Fire of London, a great fire broke out, which continued for 17 hours before houses were blown up to create fire breaks. King Charles II and his brother the Duke of York were involved in the effort.
There was also a famous fair in Southwark which took place near the Church of St George the Martyr. William Hogarth depicted this fair in his engraving of "Southwark Fair" (1733).
Southwark was also the location of several prisons, including those of the Crown or 'Prerogative Courts', the Marshalsea and King's Bench prisons, that of the local manors courts e.g. Borough Compter, The Clink, and the Surrey county gaol originally housed at the 'White Lion Inn' (also called informally the 'Borough Gaol') and eventually at Horsemonger Lane Gaol.
One other local family is of note, the Harvards. John Harvard went to the local parish free school of St Saviour's and on to Cambridge University. He migrated to the Massachusetts Colony and left his library and the residue of his will to the new college there, named after him as its first benefactor. Harvard University maintains a link, having paid for a memorial chapel within Southwark Cathedral (his family's parish church), and where its UK-based alumni hold services. John Harvard's mother's house is in Stratford upon Avon.
Urbanisation.
In 1836 the first railway for the London area was created, the London and Greenwich Railway originally terminating at Spa Road Station and later extended west to London Bridge Station.
In 1861, another Great Fire of Southwark destroyed a large number of buildings between Tooley Street and the Thames, including those around Hays Wharf (later replaced by Hays Galleria) and blocks to the west almost as far as St Olave's Church.
The first deep-level London 'tube' underground line was the City and South London Railway, now the Bank branch of the Northern line, opened in 1890, running from King William Street south through Borough to Stockwell. Southwark, since 1999, is also now served by Southwark, Bermondsey and London Bridge stations on the Jubilee line.
Local governance.
The ancient borough of Southwark initially consisted of the Surrey parishes of St George the Martyr, St Olave, St Margaret and St Mary. St Margaret and St Mary were abolished in 1541 and their former area combined to create Southwark St Saviour. Around 1555 Southwark St Thomas was split off from St Olave, and in 1733 Southwark St John Horsleydown was also split off.
In 1855 the parishes came into the area of responsibility of the Metropolitan Board of Works. The St George the Martyr parish was large enough to be governed by a vestry. St John Horsleydown, St Olave and St Thomas were grouped to form the St Olave District. St Savour was combined with Southwark Christchurch (the former liberty of Paris Garden) to form the St Saviour's District. In 1889 the area became part of the County of London. St Olave and St Thomas were combined as a single parish in 1896.
The local government arrangements were reorganised in 1900 with a Metropolitan Borough of Southwark created comprising the parishes of Southwark Christchurch, Southwark St Saviours, Southwark St George the Martyr and Newington. The eastern parishes that had formed the St Olave District instead became part of the Metropolitan Borough of Bermondsey. In 1965 the two boroughs were combined with the Metropolitan Borough of Camberwell to form the current London Borough of Southwark.
Relationship with the City of London.
Southwark was outside of the control of the City of London and was a haven for criminals and free traders, who would sell goods and conduct trades outside the regulation of the City Livery Companies. In 1327 the City obtained control from Edward III, of the manor next to the south-side of London Bridge ' the town of Southwark' (called latterly 'Guildable Manor'—i.e., the place of taxes and tolls). The Livery Companies also ensured that they had jurisdiction over the area.
From the Norman period manorial organisation obtained through major lay and ecclesiastic magnates. Southwark still has vestiges of this because of the connection with the City of London. In 1327 the City acquired from Edward III the original 'vill of Southwark' and this was also described as "the borough". In 1536 Henry VIII acquired the Bermondsey Priory properties and in 1538 that of the Archbishop. In 1550 these were sold to the City.
After many decades of petitioning, in 1550 Southwark was incorporated into the City of London as 'The Ward of Bridge Without'. However, the Alderman was appointed by the Court of Aldermen and no Common Councilmen were ever elected. This 'Ward' was constituted of the original 'Guildable Manor' and the properties previously held by the church, under a charter of Edward VI, latterly called the 'King's Manor' and 'Great Liberty' manor. These manors are still constituted by the City under a Bailiff and Steward with their Courts Leet and View of Frankpledge Juries and Officers which still meet—their annual assembly being held in November under the present High Steward (the Recorder of London). The Ward and Aldermanry were effectively abolished in 1978, by merging it with the Ward of Bridge (Within). These manorial courts were preserved under the Administration of Justice Act 1977. Therefore, between 1750 and 1978 Southwark had two persons (the Alderman and the Recorder) who were members of the City's Court of Aldermen and Common Council who were elected neither by the City freemen or by the Southwark electorate but appointed by the Court of Aldermen.
Governance.
The Borough and Bankside Community Council corresponds to the Southwark electoral wards of Cathedrals and Chaucer. They are part of the Bermondsey and Old Southwark Parliament constituency and the Member of Parliament is Neil Coyle. It is within the Lambeth and Southwark London Assembly constituency and the London European Parliament constituency. Southwark is the location of City Hall, the administrative headquarters of the Greater London Authority and the meeting place of the London Assembly and Mayor of London. Since 2009, Southwark London Borough Council has its main offices at 160 Tooley Street, having moved administrative staff from the town hall in Camberwell.
Geography.
In common with much of the south bank of the Thames, The Borough has seen extensive regeneration in the last decade. Declining wharfage trade, light industry and factories have given way to residential development, shops, restaurants, galleries, bars and most notably major office developments housing international headquarters of accountancy, legal and other professional services consultances, most notably along London Bridge City and More London between Tooley Street and the riverside. The area is in easy walking distance of the City and the West End. As such it has become a major business centre with many national and international corporations, professional practices and publishers locating to the area.
The massive supertall skyscraper, London Bridge Tower, nicknamed 'The Shard' is next to London Bridge Station.
To the north is the River Thames, London Bridge station and Southwark Cathedral. Borough Market is a well-developed visitor attraction and has grown in size. The adjacent units have been converted and form a gastronomic focus for London. Borough High Street runs roughly north to south from London Bridge towards Elephant and Castle. The Borough runs further to the south than realised; both St George's Cathedral and the Imperial War Museum are within the ancient boundaries, which border nearby Lambeth.
The Borough is generally an area of mixed development, with council estates, major office developments, social housing and high value residential gated communities side by side with each other.

</doc>
<doc id="54069" url="http://en.wikipedia.org/wiki?curid=54069" title="Inductive logic programming">
Inductive logic programming

Inductive logic programming (ILP) is a subfield of machine learning which uses logic programming as a uniform representation for examples, background knowledge and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesised logic program which entails all the positive and none of the negative examples.
Schema: "positive examples" + "negative examples" + "background knowledge" => "hypothesis".
Inductive logic programming is particularly useful in bioinformatics and natural language processing. Ehud Shapiro laid the theoretical foundation for inductive logic programming and built its first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples. The term "Inductive Logic Programming" was first introduced in a paper by Stephen Muggleton in 1991. The term ""inductive" here refers to philosophical (i.e. suggesting a theory to explain observed facts) rather than mathematical (i.e. proving a property for all members of a well-ordered set) induction.
Formal definition.
The "background knowledge" is given as a logic theory formula_1, commonly in the form of Horn clauses used in logic programming.
The "positive" and "negative" examples are given as a conjunction formula_2 and formula_3 of unnegated and negated ground literals, respectively.
A "correct hypothesis" formula_4 is a logic proposition satisfying the following requirements.
"Necessity" does not impose a restriction on formula_4, but forbids any generation of a hypothesis as long as the positive facts are explainable without it.
"Sufficiency" requires any generated hypothesis formula_4 to explain all positive examples formula_2.
"Weak consistency" forbids generation of any hypothesis formula_4 that contradicts the background knowledge formula_1.
"Strong consistency" also forbids generation of any hypothesis formula_4 that is inconsistent with the negative examples formula_3, given the background knowledge formula_1; it implies "Weak consistency"; if no negative examples are given, both requirements coincide. Džeroski requires only "Sufficiency"" (called "Completeness" there) and ""Strong consistency".
Example.
The following well-known example about learning definitions of family relations uses the abbreviations formula_13, formula_14, formula_15, formula_16, formula_17, formula_18, formula_19, formula_20, and formula_21. It starts from the background knowledge (cf. picture)
the positive examples
and the trivial proposition
formula_24
to denote the absence of negative examples.
Plotkin's "relative least general generalization (rlgg)" approach to "inductive logic programming" shall be used to obtain a suggestion about how to formally define the daughter relation formula_25.
This approach uses the following steps.
The resulting Horn clause is the hypothesis formula_4 obtained by the rlgg approach. Ignoring the background knowledge facts, the clause informally reads "formula_49 is called a daughter of formula_50 if formula_50 is the parent of formula_49 and formula_49 is female", which is a commonly accepted definition.
Concerning the above requirements, "Necessity" was satisfied because the predicate formula_25 doesn't appear in the background knowledge, which hence cannot imply any property containing this predicate, such as the positive examples are.
"Sufficiency" is satisfied by the computed hypothesis formula_4, since it, together with formula_56 from the background knowledge, implies the first positive example formula_31, and similarly formula_4 and formula_59 from the background knowledge implies the second positive example formula_32. "Weak consistency" is satisfied by formula_4, since formula_4 holds in the (finite) Herbrand structure described by the background knowledge; similar for "Strong consistency"".
The common definition of the grandmother relation, viz. formula_63, cannot be learned using the above approach, since the variable formula_64 occurs in the clause body only; the corresponding literals would have been deleted in the 4th step of the approach. To overcome this flaw, that step has to be modified such that it can be parametrized with different "literal post-selection heuristics". Historically, the GOLEM implementation is based on the rlgg approach.
Inductive Logic Programming system.
Inductive Logic Programming system is a program that takes as an input logic theories formula_65 and outputs a correct hypothesis formula_66 wrt theories formula_65 An algorithm of an ILP system consists of two parts: hypothesis search and hypothesis selection. First a hypothesis is searched with an inductive logic programming procedure, then a subset of the found hypotheses (in most systems one hypothesis) is chosen by a selection algorithm. A selection algorithm scores each of the found hypotheses and returns the ones with the highest score. An example of score function include minimal compression length where a hypothesis with a lowest Kolmogorov complexity has the highest score and is returned. An ILP system is complete iff for any input logic theories formula_65 any correct hypothesis formula_66 wrt to these input theories can be found with its hypothesis search procedure.
Hypothesis search.
Modern ILP systems like Progol, Hail and Imparo find a hypothesis formula_66 using the principle of the inverse entailment for theories formula_1, formula_72, formula_66: formula_74. First they construct an intermediate theory formula_75 called a bridge theory satisfying the conditions formula_76 and formula_77. Then as formula_78, they generalize the negation of the bridge theory formula_75 with the anti-entailment. However, the operation of the anti-entailment since being highly non-deterministic is computationally more expensive. Therefore an alternative hypothesis search can be conducted using the operation of the inverse subsumption (anti-subsumption) instead which is less non-deterministic than anti-entailment.
Questions of completeness of a hypothesis search procedure of specific ILP system arise. For example, Progol's hypothesis search procedure based on the inverse entailment inference rule is not complete by Yamamoto's example. On the other hand, Imparo is complete by both anti-entailment procedure and its extended inverse subsumption procedure.
Further reading.
</dl>

</doc>
<doc id="54073" url="http://en.wikipedia.org/wiki?curid=54073" title="Circus (disambiguation)">
Circus (disambiguation)

A circus is a traveling company of performers that may include acrobats, clowns, trained animals, and other novelty acts.
Circus may also refer to:

</doc>
<doc id="54077" url="http://en.wikipedia.org/wiki?curid=54077" title="Perpetual motion">
Perpetual motion

Perpetual motion is motion that continues indefinitely without any external source of energy. This is impossible to ever achieve because of friction and other sources of energy loss. A perpetual motion machine is a hypothetical machine that can do work indefinitely without an energy source. This kind of machine is impossible, as it would violate the first or second law of thermodynamics.
These laws of thermodynamics apply even at the grandest scale: for example, the motion or rotation of celestial bodies such as planets may appear perpetual, but are actually subjected to many forces such as solar winds, interstellar medium resistance, gravitation, thermal radiation and electro-magnetic radiation, and will eventually end.
Thus, machines which extract energy from seemingly perpetual sources will not operate indefinitely, because they are driven by the energy stored in the source, which will eventually be exhausted. A common example is devices powered by ocean currents, whose energy is ultimately derived from the Sun, which itself will eventually burn out. Machines powered by more obscure sources have been proposed, but are subject to the same inescapable laws, and will eventually wind down.
Basic principles.
 Oh ye seekers after perpetual motion, how many vain chimeras have you pursued? Go and take your place with the alchemists.
 — Leonardo da Vinci, 1494
There is a scientific consensus that perpetual motion in an isolated system violates either the first law of thermodynamics, the second law of thermodynamics, or both. The first law of thermodynamics is essentially a statement of conservation of energy. The second law can be phrased in several different ways, the most intuitive of which is that heat flows spontaneously from hotter to colder places; the most well known statement is that entropy tends to increase (see entropy production), or at the least stay the same; another statement is that no heat engine (an engine which produces work while moving heat from a high temperature to a low temperature) can be more efficient than a Carnot heat engine.
In other words:
The statements 2 and 3 only apply to heat engines. Other types of engines, which convert e.g. mechanical into electromagnetic energy, can, in principle, operate with 100% efficiency.
Machines which comply with both laws of thermodynamics by accessing energy from unconventional sources are sometimes referred to as perpetual motion machines, although they do not meet the standard criteria for the name. By way of example, clocks and other low-power machines, such as Cox's timepiece, have been designed to run on the differences in barometric pressure or temperature between night and day. These machines have a source of energy, albeit one which is not readily apparent so that they only seem to violate the laws of thermodynamics.
Machines which extract energy from seemingly perpetual sources - such as ocean currents - are indeed capable of moving "perpetually" until that energy source runs down. They are not considered to be perpetual motion machines because they are consuming energy from an external source and are not isolated systems. 
Classification.
One classification of perpetual motion machines refers to the particular law of thermodynamics the machines purport to violate:
Impossibility.
"Epistemic impossibility" describes things which absolutely cannot occur within our "current" formulation of the physical laws. This interpretation of the word "impossible" is what is intended in discussions of the impossibility of perpetual motion in a closed system.
The conservation laws are particularly robust from a mathematical perspective. Noether's theorem, which was proven mathematically in 1915, states that any conservation law can be derived from a corresponding continuous symmetry of the action of a physical system. For example, if the true laws of physics remain invariant over time then the conservation of energy follows. On the other hand, if the conservation laws are invalid, then the foundations of physics would need to change.
Scientific investigations as to whether the laws of physics are invariant over time use telescopes to examine the universe in the distant past to discover, to the limits of our measurements, whether ancient stars were identical to stars today. Combining different measurements such as spectroscopy, direct measurement of the speed of light in the past and similar measurements demonstrates that physics has remained substantially the same, if not identical, for all of observable history spanning billions of years.
The principles of thermodynamics are so well established, both theoretically and experimentally, that proposals for perpetual motion machines are universally met with disbelief on the part of physicists. Any proposed perpetual motion design offers a potentially instructive challenge to physicists: one is certain that it cannot work, so one must explain "how" it fails to work. The difficulty (and the value) of such an exercise depends on the subtlety of the proposal; the best ones tend to arise from physicists' own thought experiments and often shed light upon certain aspects of physics. So, for example, the thought experiment of a Brownian ratchet as a perpetual motion machine was first discussed by Gabriel Lippmann in 1900 but it was not until 1912 that Marian Smoluchowski gave an adequate explanation for why it cannot work. However, during that twelve-year period scientists did not believe that the machine was possible. They were merely unaware of the exact mechanism by which it would inevitably fail.
The law that entropy always increases, holds, I think, the supreme position among the laws of Nature. If someone points out to you that your pet theory of the universe is in disagreement with Maxwell's equations — then so much the worse for Maxwell's equations. If it is found to be contradicted by observation — well, these experimentalists do bungle things sometimes. But if your theory is found to be against the second law of thermodynamics I can give you no hope; there is nothing for it but to collapse in deepest humiliation.—Sir Arthur Stanley Eddington, "The Nature of the Physical World" (1927)
In the mid 19th-century Henry Dircks investigated the history of perpetual motion experiments, writing a vitriolic attack on those who continued to attempt what he believed to be impossible:
"There is something lamentable, degrading, and almost insane in pursuing the visionary schemes of past ages with dogged determination, in paths of learning which have been investigated by superior minds, and with which such adventurous persons are totally unacquainted. The history of Perpetual Motion is a history of the fool-hardiness of either half-learned, or totally ignorant persons."—Henry Dircks, "Perpetuum Mobile: Or, A History of the Search for Self-motive" (1861)
Techniques.
Some common ideas recur repeatedly in perpetual motion machine designs. Many ideas that continue to appear today were stated as early as 1670 by John Wilkins, Bishop of Chester and an official of the Royal Society. He outlined three potential sources of power for a perpetual motion machine, "Chymical Extractions", "Magnetical Virtues" and "the Natural Affection of Gravity".
The seemingly mysterious ability of magnets to influence motion at a distance without any apparent energy source has long appealed to inventors. One of the earliest examples of a magnetic motor was proposed by Wilkins and has been widely copied since: it consists of a ramp with a magnet at the top, which pulled a metal ball up the ramp. Near the magnet was a small hole that was supposed to allow the ball to drop under the ramp and return to the bottom, where a flap allowed it to return to the top again. The device simply could not work: any magnet strong enough to pull the ball up the ramp would necessarily be too powerful to allow it to drop through the hole. Faced with this problem, more modern versions typically use a series of ramps and magnets, positioned so the ball is to be handed off from one magnet to another as it moves. The problem remains the same.
Gravity also acts at a distance, without an apparent energy source, but to get energy out of a gravitational field (for instance, by dropping a heavy object, producing kinetic energy as it falls) one has to put energy in (for instance, by lifting the object up), and some energy is always dissipated in the process. A typical application of gravity in a perpetual motion machine is Bhaskara's wheel in the 12th century, whose key idea is itself a recurring theme, often called the overbalanced wheel: moving weights are attached to a wheel in such a way that they fall to a position further from the wheel's center for one half of the wheel's rotation, and closer to the center for the other half. Since weights further from the center apply a greater torque, it was thought that the wheel would rotate forever. However, since the side with weights further from the center has fewer weights than the other side, at that moment, the torque is balanced and perpetual movement is not achieved. The moving weights may be hammers on pivoted arms, or rolling balls, or mercury in tubes; the principle is the same.
Another theoretical machine involves a frictionless environment for motion. This involves the use of diamagnetic or electromagnetic levitation to float an object. This is done in a vacuum to eliminate air friction and friction from an axle. The levitated object is then free to rotate around its center of gravity without interference. However, this machine has no practical purpose because the rotated object cannot do any work as work requires the levitated object to cause motion in other objects, bringing friction into the problem. Furthermore, a "perfect" vacuum is an unattainable goal since both the container and the object itself would slowly vaporize, thereby degrading the vacuum.
To extract work from heat, thus producing a perpetual motion machine of the second kind, the most common approach (dating back at least to Maxwell's demon) is "unidirectionality". Only molecules moving fast enough and in the right direction are allowed through the demon's trap door. In a Brownian ratchet, forces tending to turn the ratchet one way are able to do so while forces in the other direction are not. A diode in a heat bath allows through currents in one direction and not the other. These schemes typically fail in two ways: either maintaining the unidirectionality costs energy (requiring Maxwell's demon to perform more thermodynamic work to gauge the speed of the molecules than the amount of energy gained by the difference of temperature caused) or the unidirectionality is an illusion and occasional big violations make up for the frequent small non-violations (the Brownian ratchet will be subject to internal Brownian forces and therefore will sometimes turn the wrong way).
Buoyancy is another frequently-misunderstood phenomenon. Some proposed perpetual-motion machines miss the fact that to push a volume of air down in a fluid takes the same work as to raise a corresponding volume of fluid up against gravity. These types of machines may involve two chambers with pistons, and a mechanism to squeeze the air out of the top chamber into the bottom one, which then becomes buoyant and floats to the top. The squeezing mechanism in these designs would not be able to do enough work to move the air down, or would leave no excess work available to be extracted.
Patents.
Proposals for such inoperable machines have become so common that the United States Patent and Trademark Office (USPTO) has made an official policy of refusing to grant patents for perpetual motion machines without a working model. The USPTO Manual of Patent Examining Practice states:
With the exception of cases involving perpetual motion, a model is not ordinarily required by the Office to demonstrate the operability of a device. If operability of a device is questioned, the applicant must establish it to the satisfaction of the examiner, but he or she may choose his or her own way of so doing.
And, further, that:
A rejection [of a patent application] on the ground of lack of utility includes the more specific grounds of inoperativeness, involving perpetual motion. A rejection under 35 U.S.C. 101 for lack of utility should not be based on grounds that the invention is frivolous, fraudulent or against public policy.
The filing of a patent application is a clerical task, and the USPTO will not refuse filings for perpetual motion machines; the application will be filed and then most probably rejected by the patent examiner, after he has done a formal examination. Even if a patent is granted, it does not mean that the invention actually works, it just means that the examiner believes that it works, or was unable to figure out why it would not work.
The USPTO maintains a collection of .
The United Kingdom Patent Office has a specific practice on perpetual motion; Section 4.05 of the UKPO Manual of Patent Practice states:
Processes or articles alleged to operate in a manner which is clearly contrary to well-established physical laws, such as perpetual motion machines, are regarded as not having industrial application.
Examples of decisions by the UK Patent Office to refuse patent applications for perpetual motion machines include:
The European Patent Classification (ECLA) has classes including patent applications on perpetual motion systems: ECLA classes "F03B17/04: Alleged perpetua mobilia ..." and "F03B17/00B: [... machines or engines] (with closed loop circulation or similar : ... Installations wherein the liquid circulates in a closed loop; Alleged perpetua mobilia of this or similar kind ...".
Apparent perpetual motion machines.
While "perpetual motion" can only exist in isolated systems, and true isolated systems do not exist, there are not any real "perpetual motion" devices. However there are concepts and technical drafts that propose "perpetual motion", but on closer analysis it is revealed that they actually "consume" some sort of natural resource or latent energy, such as the phase changes of water or other fluids or small natural temperature gradients, or simply cannot sustain indefinite operation. In general, extracting work from these devices is impossible.
Resource consuming.
Some examples of such devices include:
Thought experiments.
In some cases a thought (or "gedanken") experiment appears to suggest that perpetual motion may be possible through accepted and understood physical processes. However, in all cases, a flaw has been found when all of the relevant physics is considered. Examples include:

</doc>
<doc id="54078" url="http://en.wikipedia.org/wiki?curid=54078" title="Robert Ludlum">
Robert Ludlum

Robert Ludlum (May 25, 1927 – March 12, 2001) was an American author of 27 thriller novels. The number of copies of his books in print is estimated between 290 million and 500 million. They have been published in 33 languages and 40 countries. Ludlum also published books under the pseudonyms Jonathan Ryder and Michael Shepherd.
Life and career.
Early life and education.
Ludlum was born in New York City, the son of Margaret (née Wadsworth) and George Hartford Ludlum. His maternal grandparents were English. He was educated at The Rectory School then Cheshire Academy and Wesleyan University in Middletown, Connecticut were he earned a B.A. in Drama. While at Wesleyan, Ludlum joined the Alpha Delta Phi fraternity. After becoming an author later in life, Ludlum would set his mystery novel "Matlock Paper" at the fictitious Carlyle University in Connecticut, a thinly-disguised Wesleyan.
Career.
Prior to becoming an author, he had been a United States Marine, a theatrical actor and producer. In the 1950's, he produced shows at the Grant Lee theater in Fort Lee, NJ. From 1960 to 1970, he managed and produced shows at the Playhouse on the Mall in Paramus, NJ. His theatrical experience may have contributed to his understanding of the energy, escapism and action that the public wanted in a novel. He once remarked: "I equate suspense and good theater in a very similar way. I think it's all suspense and what-happens-next. From that point of view, yes, I guess, I am theatrical."
Many of Ludlum's novels have been made into films and mini-series, including "The Osterman Weekend", "The Holcroft Covenant", "The Apocalypse Watch", "The Bourne Identity", "The Bourne Supremacy" and "The Bourne Ultimatum". "", a book co-written with Gayle Lynds, was originally conceived as a mini-series; the book evolved from a short treatment Ludlum wrote for NBC. The Bourne movies, starring Matt Damon in the title role, have been commercially and critically successful ("The Bourne Ultimatum" won three Academy Awards in 2008), although the story lines depart significantly from the source material.
During the 1970s, Ludlum lived in Leonia, New Jersey, where he spent hours each day writing in his home.
Death.
Ludlum died on March 12, 2001, at his home in Naples, Florida, while recovering from severe burns caused by a mysterious fire which occurred on February 10.
Writing analysis and criticism.
Ludlum's novels typically feature one heroic man, or a small group of crusading individuals, in a struggle against powerful adversaries whose intentions and motivations are evil and who are capable of using political and economic mechanisms in frightening ways. The world in his writings is one where global corporations, shadowy military forces and government organizations all conspire to preserve (if it is good) or undermine (if it is evil) the status quo.
Ludlum's novels were often inspired by conspiracy theories, both historical and contemporary. He wrote that "The Matarese Circle" was inspired by rumors about the Trilateral Commission, and it was published only a few years after the commission was founded. His depictions of terrorism in books such as "The Holcroft Covenant" and "The Matarese Circle" reflected the theory that terrorists, rather than being merely isolated bands of ideologically motivated extremists, are actually pawns of governments or private organizations who are using them to facilitate the establishment of authoritarian rule.
Selected bibliography.
Covert-One series.
Written by other authors.
Filmography.
Some of Ludlum's novels have been made into films and mini-series, although the story lines might depart significantly from the source material. In general, a miniseries is more faithful to the original novel on which it is based.
1 announced/in development

</doc>
<doc id="54080" url="http://en.wikipedia.org/wiki?curid=54080" title="Gentianales">
Gentianales

Gentianales is an order of flowering plants, included within the asterid clade of eudicots. It comprises more than 16,000 species in about 1,138 genera in 5 families. More than 80% of the species belong to the Rubiaceae family.
Etymology.
It takes its name from the Gentianaceae family, which in turn is based on the name of the type genus "Gentiana". The genus name is a tribute to Gentius, an Illyrian king.
Uses.
Well-known members of Gentianales are coffee, frangipani, "Gardenia", gentian, oleander, and periwinkle.
Taxonomy.
The following families are included according to the APG III system:
Phylogeny.
The following phylogenetic tree is based on molecular phylogenetic studies of DNA sequences.

</doc>
<doc id="54081" url="http://en.wikipedia.org/wiki?curid=54081" title="Maloideae">
Maloideae

The Maloideae C.Weber was the apple subfamily, a grouping used by some taxonomists within the rose family, Rosaceae. Recent molecular phylogenetic evidence has shown that the traditional Spiraeoideae and Amygdaloideae form part of the same clade as the traditional Maloideae, and the correct name for this group is Amygdaloideae. Earlier circumscriptions of Maloideae are more-or-less equivalent to subtribe Malinae or to tribe Maleae. The group includes a number of plants bearing commercially important fruits, such as apples and pears, while others are cultivated as ornamentals.
In its traditional circumscription this subfamily consisted exclusively of shrubs and small trees characterised by a pome, a type of accessory fruit that does not occur in other Rosaceae, and by a basal haploid chromosome count of 17 (instead of 7, 8, or 9 as in the other Rosaceae), involving approximately 28 genera with approximately 1100 species worldwide, with most species occurring in the temperate Northern Hemisphere.
Taxonomy.
The subfamily was given the name Pomoideae Juss. in 1789, but this name is no longer accepted under the nomenclature codes because it is not based on a genus name. It has also been separated into its own family the Malaceae Small (formerly Pomaceae Lindl.).
Recent molecular data have shown that the traditional subfamily Spiraeoideae is paraphyletic, and to best reflect relationships subfamily Amygdaloideae has been expanded to include the former Spiraeoideae and Maloideae.
An earlier intermediate classification expanded Maloideae to include four genera with dry non-pome fruit. These are "Kageneckia", "Lindleya", and "Vauquelinia", which have a haploid chromosome count of 15 or 17, and "Gillenia", which is herbaceous and has a haploid chromosome count of 9.
A traditional circumscription of Maloideae includes the following genera:<br>
"Amelanchier" - serviceberry, juneberry<br>
"Aria" (see "Sorbus")<br>
"Aronia" - chokeberry<br>
"Chaenomeles" - Japanese quince<br>
"Chamaemeles"
"Chamaemespilus" (see "Sorbus chamaemespilus")<br>
"Cormus" (see "Sorbus")<br>
"Cotoneaster" - cotoneaster<br>
"Crataegus" - hawthorn<br>
"Cydonia" - quince<br>
"Dichotomanthes"<br>
"Docynia" <br>
"Docyniopsis" <br>
"Eriobotrya" - loquat<br>
"Eriolobus"<br>
"Hesperomeles"<br>
"Heteromeles" - toyon<br>
"Malacomeles"<br>
"Malus" - apple, crabapple<br>
"Mespilus" - medlar<br>
"Osteomeles"<br>
"Peraphyllum"<br>
"Photinia"<br>
"Pseudocydonia" - Chinese quince<br>
"Pyracantha" - firethorn<br>
"Pyrus" - pear<br>
"Rhaphiolepis" - hawthorn<br>
"Sorbus" - rowan, whitebeam, service tree<br>
"Stranvaesia" = "Photinia" pro parte<br>
"Torminalis" (see "Sorbus torminalis")
intergeneric hybrids:<br>
"×Amelasorbus"<br>
"×Crataegosorbus"<br>
"×Crataemespilus"<br>
"×Malosorbus"<br>
"×Sorbocotoneaster"<br>
"×Sorbopyrus"
and graft hybrids:<br>
"+Crataegomespilus"<br>
"+Pyrocydonia" ("Pirocydonia")

</doc>
<doc id="54083" url="http://en.wikipedia.org/wiki?curid=54083" title="Amygdaloideae">
Amygdaloideae

Amygdaloideae is a subfamily within the flowering plant family Rosaceae. It was formerly considered by some authors to be separate from Rosaceae, and the family names Prunaceae and Amygdalaceae have been used. Reanalysis from 2007 has shown that the previous definition of subfamily Spiraeoideae was paraphyletic. To solve this problem, a larger subfamily was defined that includes the former Amygdaloideae, Spiraeoideae, and Maloideae. This subfamily, however, is to be called Amygdaloideae rather than Spiraeoideae under the International Code of Nomenclature for algae, fungi, and plants as updated in 2011.
As traditionally defined, the Amygdaloideae includes such commercially important crops as plum, cherry, apricot, peach, and almond. The fruit of these plants are known as stone fruit (drupes), as each fruit contains a hard shell (the endocarp) called a "stone" or "pit", which contains the single seed.
The expanded definition of the Amygdaloideae adds to these commercially important crops such as apples and pears that have pome fruit, and also important ornamental plants such as "Spiraea" and "Aruncus" that have hard dry fruits.
Taxonomic history.
The name Prunoideae is sometimes used, but is incorrect. The 1835 publication of that name by Gilbert Thomas Burnett (Burnett) is invalid because it lacks a description (or diagnosis or reference to an earlier description or diagnosis). Paul Fedorowitsch Horaninow (Horan.) published the name in 1847, but Amygdaloideae, published in 1832 by George Arnott Walker Arnott, has priority and is therefore the correct name.
The taxonomy of this group of plants within the Rosaceae has recently been unclear. In 2001 it was reported that Amygdaloideae "sensu stricto" consists of two distinct genetic groups or "clades", "Prunus"–"Maddenia" and "Exochorda"–"Oemleria"–"Prinsepia". Further refinement shows that "Exochorda"–"Oemleria"–"Prinsepia" is somewhat separate from "Prunus"–"Maddenia"–"Pygeum", and that the traditional subfamilies Maloideae and Spiraeoideae must be included in Amygdaloideae if a paraphyletic group is to be avoided. With this classification, the genus "Prunus" is considered to include "Armeniaca", "Cerasus", "Amygdalus", "Padus", "Laurocerasus", "Pygeum", and "Maddenia".
Robert Frost alluded to the merging of Amygdalaceae into Rosaceae in his poem "The Rose Family", when he wrote "The rose is a rose and was always a rose / But the theory now goes that the apple's a rose, / and the pear is, and "so's the plum, I suppose"." In the next line he wrote, "The dear [i.e., "the dear Lord", euphemized] only knows what will next prove a rose." This referred to shifting botanical opinion which had recently reunited Amygdalaceae, Spiraeaceae, and Malaceae into Rosaceae (which matches de Jussieu's 1789 classification).
Classification.
A recent classification places the following genera in the subfamily:

</doc>
<doc id="54084" url="http://en.wikipedia.org/wiki?curid=54084" title="Rosoideae">
Rosoideae

The rose subfamily Rosoideae consists of more than 850 species, including many shrubs, perennial herbs, and fruit plants such as strawberries and brambles. Only a few are annual herbs.
The circumscription of the Rosoideae is still not wholly certain; recent genetic research has resulted in several changes at the genus level and the removal from Rosoideae of some genera (notably "Cercocarpus", "Cowania", "Dryas" and "Purshia") previously included in the subfamily.

</doc>
<doc id="54085" url="http://en.wikipedia.org/wiki?curid=54085" title="Len Deighton">
Len Deighton

Leonard Cyril Deighton (; born 18 February 1929), known as Len Deighton, is a British military historian, cookery writer, graphic artist, and novelist. He is perhaps most famous for his spy novel "The IPCRESS File", which was made into a film starring Michael Caine as Harry Palmer.
Early years.
Deighton was born in Marylebone, London, in 1929. His father was a chauffeur and mechanic, and his mother was a part-time cook. At the time they lived in Gloucester Place Mews near Baker Street.
Deighton's interest in spy stories may have been partially inspired by the arrest of Anna Wolkoff, which he witnessed as an 11-year-old boy. Wolkoff, a British subject of Russian descent, was a Nazi spy. She was detained on 20 May 1940 and subsequently convicted of violating the Official Secrets Act for attempting to pass secret documents to the Nazis.
Career.
After leaving school, Deighton worked as a railway clerk before performing his National Service, which he spent as a photographer for the Royal Air Force's Special Investigation Branch. After discharge from the RAF, he studied at Saint Martin's School of Art in London in 1949, and in 1952 won a scholarship to the Royal College of Art, graduating in 1955. While he was at the RCA he became a "lifelong friend" of fellow designer Raymond Hawkey, who later designed covers for his early books. Deighton then worked as an airline steward with BOAC. Before he began his writing career he worked as an illustrator in New York and, in 1960, as an art director in a now defunct London advertising agency, Sharps Advertising. He is credited with creating the first British cover for Kerouac's "On the Road". He has since used his drawing skills to illustrate a number of his own military history books.
Following the success of his first novels, Deighton became "The Observer"'s cookery writer and produced illustrated cookbooks. In September 1967 he wrote an article in the "Sunday Times Magazine" about Operation Snowdrop - an SAS attack on Benghazi during World War II. The following year David Stirling would be awarded substantial damages in libel from the article.
He also wrote travel guides and became travel editor of "Playboy", before becoming a film producer. After producing a film adaption of his 1968 novel "Only When I Larf", Deighton and photographer Brian Duffy bought the film rights to Joan Littlewood and Theatre Workshop's stage musical "Oh, What a Lovely War!". Deighton wrote the screenplay and was an uncredited producer
 of the film but he had his name removed from the credits, however, a move that he later described as "stupid and infantile". That was his last involvement with the cinema.
Deighton left England in 1969. He briefly resided in Blackrock, County Louth, in Ireland. He has not returned to England apart from some personal visits and very few media appearances, his last one since 1985 being a 2006 interview that formed part of a "Len Deighton Night" on BBC Four. He and his wife Ysabele divide their time between homes in Portugal and Guernsey.
Works.
Novels.
Several of Deighton's novels have been adapted as films. His first five novels featured an anonymous and cynical anti-hero, named "Harry Palmer" in the films and portrayed by Michael Caine. The atmosphere was considered quite realistic, not the least because many of the characters were openly venal, cowardly, or stupid; equally because the bureaucratic complications (and inter-departmental rivalries) of the British civil service (even the secret civil service) made for frequent black-comic relief; and the portrayal of the technical aspects of espionage and related criminal enterprises was quite detailed. The novels were dotted with footnotes explaining various slang terms and abbreviations in the dialogue; there were even appendices. The first trilogy of his "Bernard Samson" novel series was made into a twelve-part television series by Granada Television in 1988, shown only once, then withdrawn on instructions from Deighton. Quentin Tarantino has expressed interest in filming the trilogy.
Deighton's 1970 World War II historical novel "Bomber" about an RAF Bomber Command raid over Germany often is considered his masterpiece. It was the first novel to be written on a word processor, the IBM MT/ST. He reportedly began an unfinished Vietnam War novel, a portion of which appeared as the story "First Base" in his short story collection "Declarations of War".
Cookery books.
Deighton also published a series of cookery books and wrote and drew a weekly strip cartoon-style illustrated cooking guide in London's "The Observer" newspaper – "Len Deighton's Cookstrip". At least one of the strips is pinned up in Deighton's spy hero's kitchen in the 1965 film of his novel "The IPCRESS File".
To exploit the success of Deighton's first four "Unnamed Hero" novels, he wrote "Len Deighton's London Dossier" (1967), a guide book to Swinging Sixties London with a "secret agent" theme – contributions from other writers are described as "surveillance reports".
History books.
Deighton's 1977 "" was said by Albert Speer (once Hitler's Minister of Armaments) to be "an excellent, most thorough examination. I read page after page with fascination." The piece was furnished with a comment by A. J. P. Taylor simply saying: "Brilliant analysis."

</doc>
<doc id="54086" url="http://en.wikipedia.org/wiki?curid=54086" title="Reciprocal">
Reciprocal

Reciprocal may refer to:

</doc>
<doc id="54087" url="http://en.wikipedia.org/wiki?curid=54087" title="Spiraeoideae">
Spiraeoideae

The subfamily Spiraeoideae was traditionally a subfamily of flowering plants within family Rosaceae. The taxonomy of this subfamily has changed several times in the last century as more detailed studies have been carried out. Spiraeoideae as defined before 2007 is paraphyletic, leading some authors to define a broader subfamily which includes the Spiraeoideae as well as the Maleae (plants such as pears and apples whose fruits are pomes), and the Amygdaloideae (including almonds and plums, whose fruits are drupes). Such an expanded subfamily is to be called Amygdaloideae under the International Code of Nomenclature for algae, fungi, and plants.
The traditional Spiraeoideae are shrubs. Most have simple leaves, but the genera "Aruncus" and "Sorbaria" have pinnately compound leaves. Carpels are usually 2-5. Most genera traditionally placed in the Spiraeoideae produce flowers with distinct follicles that, upon seed-set, mature to form fruits that are aggregates of follicles.
A traditional classification places the following genera in the subfamily:

</doc>
<doc id="54088" url="http://en.wikipedia.org/wiki?curid=54088" title="Harry Palmer">
Harry Palmer

Harry Palmer is the protagonist of a number of films based on the unnamed main character from the spy novels written by Len Deighton. Michael Caine played Harry Palmer in three films based on the four published novels featuring this character, and also later in two films not based on Len Deighton's novels.
Origin of the 'Harry Palmer' name.
When developing the movie, The Ipcress File, based on Len Deighton's novel of the same name, the production team needed a name for the previously anonymous secret agent protagonist, they chose "Harry Palmer", because they wanted a dull, unglamorous name to distance him from Ian Fleming's James Bond, the stereotypical flamboyant, swashbuckling spy. In his memoirs, Michael Caine says producer Harry Saltzman thought up the surname "Palmer", and Caine innocently remarked that "Harry" was a dull name, not realising his gaffe until seeing Saltzman's stare. In a Len Feldman interview, Caine recalled "I made a rather bad social blunder, because, he said, 'What's the dullest name you can think of ?', and I said, 'Harry', and he said, 'Thanks very much.' And then he said, 'What's a dull surname ?', and the most boring boy in our school was called: 'Palmer', 'Tommy Palmer'. So, he said, 'All right, we'll call him Harry Palmer.'" 
This coincidentally meshed with the protagonist in the books being referred to as "Harry" by another character, although he clearly states this is not his real name. However, the ambiguity this creates between the two versions, while coincidental, is in keeping with the nature of the character and Deighton's theme of agents losing sight of their original lives. It is never made clear if the book protagonist had ever used the name and forgotten his old alias (or former life), or if the film protagonist is using an assumed name to distance himself from his former illegal activities. Either, or both, are possible.
Novels.
Early novels.
Len Deighton introduced the lead character in "The IPCRESS File", his first novel, published in November 1962. In that first-person novel, the secret agent is anonymous, although at one point in he is greeted by someone saying "Hello, Harry"; he later says, "Now my name isn't Harry, but in this business it's hard to remember whether it ever had been." Deighton's spy is described as working class, living in a back street flat and seedy hotels, and shopping in supermarkets. He wears glasses, is hindered by bureaucracy, and craves a pay raise.
Further novels featuring this character followed: "Horse Under Water" (1963), "Funeral in Berlin" (1964), and "Billion-Dollar Brain" (1966). Again however the lead protagonist is never named, although they are clearly the same character in all of the books.
Later novels and discrepancies.
In 1974, the novel "Spy Story" was published, followed in 1976 by "Twinkle, Twinkle, Little Spy" (also known as "Catch A Falling Spy" in North America). As the protagonist also remains anonymous in both of these novels, it is open to debate whether or not 'Harry Palmer' is the same narrator of these last two novels as in the earlier books. There is conflicting evidence for either view. Despite this, and despite the lead protagonist being unnamed, all six books have been unofficially called the Harry Palmer novels, based on the protagonist's name given in the subsequent film adaptations of "The IPCRESS File" and its sequels.
Evidence for this narrator being different from the earlier novels comes from Deighton himself, who is quoted as saying that the narrator of "Spy Story" is not the same character as the narrator of "The IPCRESS File"; in fact, for most of "Spy Story", the narrator is named and addressed as "Patrick Armstrong" - although, as another character says, "We have so many different names." Additionally, he is reported to be in his late 30s, whereas the narrator of "The IPCRESS File" was born in 1922 or 1923 (making him in his 40s), and thus implying that this protagonist is different from that of the earlier novels.
Encouraging the unitary concept - that the later novels feature 'Harry Palmer' - is the 1974 dust jacket to the Harcourt, Brace & Jovanovich American edition of "Spy Story", in which the cover blurb states, "He is back, after five long-years' absence, the insubordinate, decent, bespectacled English spy who fought, fumbled, and survived his outrageous way through the best-selling "Horse Under Water", "Funeral in Berlin", and the rest of those marvellous, celebrated Len Deighton spy thrillers." Likewise, on the 1976 edition dust jacket to "Catch a Falling Spy", the novel features "Deighton's familiar hero, our bespectacled Englishman". A number of minor characters from the earlier novels also appear in "Spy Story", further connecting the books.
Related novels.
A related novel by Deighton, "Yesterday's Spy" (1975), also features some of the same characters that appeared in "Spy Story", although 'Harry Palmer' is not apparently amongst them. It has been theorised that the protagonist in another of Deighton's spy novels, "An Expensive Place to Die" (1967), also written in the first-person-anonymous narrative, is also 'Harry Palmer'; however, differences in characterisation and plotting indicate this is someone else other than Palmer.
Film adaptations.
"The IPCRESS File".
"The IPCRESS File" novel came out just after the release of the first James Bond film "Dr. No" (1962). When the novel sold well, Eon producers Harry Saltzman and Albert Broccoli approached Deighton to write the script for the next 007 film, "From Russia With Love" (1963); despite Deighton's efforts, little of his screenplay was filmed. Saltzman instead decided to use "The IPCRESS File" and its sequels as the beginning of a new secret agent movie series. Unlike the Bond films, "The IPCRESS File" was designed to have a different, more down-beat style, although Saltzman employed many Bond movie staff, including production designer Ken Adam, editor Peter Hunt, and composer John Barry. Michael Caine was chosen to play the lead.
In the film version, Harry Palmer is a British army sergeant forcibly drafted into the security services to work away a prison sentence for black marketeering. He worked first for Army Intelligence, then the Foreign Office. He works for the brilliant but slightly duplicitous Colonel Ross. Harry Palmer has much in common with Deighton, including passions for military history (Harvey Newbegin complains about his bookshelf contents in "Billion Dollar Brain"), cooking, and classical music.
Sequels.
After the release of "The IPCRESS File" in 1965, Saltzman's production company made "Funeral in Berlin" (1966) and "Billion Dollar Brain" (1967), both starring Michael Caine. The second Harry Palmer novel "Horse Under Water" was not used. In 1976, Deighton's novel "Spy Story" was filmed with Michael Petrovitch as 'Patrick Armstrong'; it is unrelated to Saltzman's Harry Palmer films.
In the mid-1990s there appeared two Harry Palmer films with original screenplays and starring Michael Caine: "Bullet to Beijing" (1995) and "Midnight in Saint Petersburg" (1996). Despite sometimes being titled "Len Deighton's Bullet to Beijing" and "Len Deighton's Midnight in St Petersburg", Len Deighton did not participate in these films.
Allusions.
Evidence of Michael Caine's popular identification as Harry Palmer can be seen in movies such as "Blue Ice" (1992), where he plays an ex-spy named 'Harry', and who has many similarities to Harry Palmer. 
In "Austin Powers in Goldmember" (2002), Caine's portrayal of Nigel Powers, father of secret agent Austin Powers, spoofs Harry Palmer.
In "" (2014), Caine portrays the bespectacled head of a secret espionage unit.

</doc>
<doc id="54089" url="http://en.wikipedia.org/wiki?curid=54089" title="List of tram and light rail transit systems">
List of tram and light rail transit systems

The following is a list of cities that have current tram/streetcar, heritage tram/heritage streetcar, or light rail systems as part of their regular public transit systems. In other words, this list only includes systems which operate year-round and provide actual transit service, not ones that are primarily tourist services, are seasonal-only, or are excursion-type tram operations.
Only "currently operational" LRT systems are included in this listing – LRT systems that have "suspended operation" or are presently under construction are "excluded".
Asia.
Note: All systems in Russia, including those in Asia, are listed together, for convenience, in the Europe section of this article.
Europe.
Note: All systems in Turkey, including those in Europe, are listed together, for convenience, in the Asia section of this article.
North America.
The following systems provide regular transit service daily and year-round in North America. The bottom of the table lists those specific systems or lines using vintage or faux-vintage streetcars. For other heritage streetcar lines, ones with more limited service, see Streetcars in North America.

</doc>
<doc id="54098" url="http://en.wikipedia.org/wiki?curid=54098" title="Vitamin P">
Vitamin P

Vitamin P may refer to:

</doc>
<doc id="54099" url="http://en.wikipedia.org/wiki?curid=54099" title="Pantothenic acid">
Pantothenic acid

Pantothenic acid, also called pantothenate or vitamin B5 (a B vitamin), is a water-soluble vitamin. For many animals, pantothenic acid is an essential nutrient. Animals require pantothenic acid to synthesize coenzyme-A (CoA), as well as to synthesize and metabolize proteins, carbohydrates, and fats.
Pantothenic acid is the amide between pantoic acid and β-alanine. Its name derives from the Greek "pantothen" (πάντοθεν), meaning "from everywhere", and small quantities of pantothenic acid are found in nearly every food, with high amounts in avocado, whole-grain cereals, legumes, eggs, meat, royal jelly, and yogurt. It is commonly found as its alcohol analog, the provitamin panthenol (pantothenol), and as calcium pantothenate. Pantothenic acid is an ingredient in some hair and skin care products.
Pantothenic acid was discovered by Roger J. Williams in 1933.
Biological role.
Only the dextrorotatory (D) isomer of pantothenic acid possesses biologic activity. The levorotatory (L) form may antagonize the effects of the dextrorotatory isomer.
Pantothenic acid is used in the synthesis of coenzyme A (CoA). Coenzyme A may act as an acyl group carrier to form acetyl-CoA and other related compounds; this is a way to transport carbon atoms within the cell. CoA is important in energy metabolism for pyruvate to enter the tricarboxylic acid cycle (TCA cycle) as acetyl-CoA, and for α-ketoglutarate to be transformed to succinyl-CoA in the cycle. CoA is also important in the biosynthesis of many important compounds such as fatty acids, cholesterol, and acetylcholine. CoA is incidentally also required in the formation of ACP, which is also required for fatty acid synthesis in addition to CoA.
Pantothenic acid in the form of CoA is also required for acylation and acetylation, which, for example, are involved in signal transduction and enzyme activation and deactivation, respectively.
Since pantothenic acid participates in a wide array of key biological roles, it is essential to all forms of life. As such, deficiencies in pantothenic acid may have numerous wide-ranging effects, as discussed below.
Sources.
Dietary.
Small quantities of pantothenic acid are found in most foods. The major food source of pantothenic acid is meat. The concentration found in human muscle is about double that in other animals' muscle. Whole grains are another good source of the vitamin, but milling removes much of the pantothenic acid, as it is found in the outer layers of whole grains. Vegetables, such as avocados and broccoli, also have an abundance. In animal feeds, the most important sources are alfalfa, cereal, condensed fish solutions, peanut meal, molasses, mushrooms, rice, wheat bran, and yeasts. The most significant sources of pantothenic acid in nature are coldwater fish ovaries and royal jelly.:346
Supplementation.
The derivative of pantothenic acid, pantothenol (panthenol), is a more stable form of the vitamin and is often used as a source of the vitamin in multivitamin supplements.:347 Another common supplemental form of the vitamin is calcium pantothenate. Calcium pantothenate is often used in dietary supplements because, as a salt, it is more stable than pantothenic acid in the digestive mentation may improve oxygen utilization efficiency and reduce lactic acid accumulation in athletes.
Daily requirement.
Pantothenate in the form of 4'phosphopantetheine is considered to be the more active form of the vitamin in the body; however, any derivative must be broken down to pantothenic acid before absorption. 10 mg of calcium pantothenate is equivalent to 9.2 mg of pantothenic acid.
Absorption.
When found in foods, most pantothenic acid is in the form of CoA or acyl carrier protein (ACP). For the intestinal cells to absorb this vitamin, it must be converted into free pantothenic acid. Within the lumen of the intestine, CoA and ACP are hydrolyzed into 4'-phosphopantetheine. The 4'-phosphopantetheine is then dephosphorylated into pantetheine. Pantetheinase, an intestinal enzyme, then hydrolyzes pantetheine into free pantothenic acid.
Free pantothenic acid is absorbed into intestinal cells via a saturable, sodium-dependent active transport system. At high levels of intake, when this mechanism is saturated, some pantothenic acid may also be absorbed via passive diffusion. As intake increases 10-fold, however, absorption rate decreases to 10%.
Deficiency.
Pantothenic acid deficiency is exceptionally rare and has not been thoroughly studied. In the few cases where deficiency has been seen (victims of starvation and limited volunteer trials), nearly all symptoms can be reversed with the return of pantothenic acid.
Symptoms of deficiency are similar to other vitamin B deficiencies. There is impaired energy production, due to low CoA levels, which could cause symptoms of irritability, fatigue, and apathy. Acetylcholine synthesis is also impaired; therefore, neurological symptoms can also appear in deficiency; they include numbness, paresthesia, and muscle cramps. Deficiency in pantothenic acid can also cause hypoglycemia, or an increased sensitivity to insulin. Insulin receptors are acylated with palmitic acid when they do not want to bind with insulin. Therefore, more insulin will bind to receptors when acylation decreases, causing hypoglycemia. Additional symptoms could include restlessness, malaise, sleep disturbances, nausea, vomiting, and abdominal cramps. In a few rare circumstances, more serious (but reversible) conditions have been seen, such as adrenal insufficiency and hepatic encephalopathy.
One study noted reports of painful burning sensations of the feet in tests conducted on volunteers. Deficiency of pantothenic acid may explain similar sensations reported in malnourished prisoners of war.
Deficiency symptoms in other nonruminant animals include disorders of the nervous, gastrointestinal, and immune systems, reduced growth rate, decreased food intake, skin lesions and changes in hair coat, and alterations in lipid and carbohydrate metabolism.
Toxicity.
Toxicity of pantothenic acid is unlikely. In fact, no Tolerable Upper Level Intake (UL) has been established for the vitamin. Large doses of the vitamin, when ingested, have no reported side effects and massive doses (e.g., 10 g/day) may only yield mild intestinal distress, and diarrhea at worst. It has been suggested, however, that high doses of pantothenic acid might worsen panic attacks in those with panic disorder by prolonging the duration until adrenal exhaustion.
There are also no adverse reactions known following parenteral or topical application of the vitamin.
Research.
Given pantothenic acid's prevalence among living things and the limited body of studies in deficiency, many uses of pantothenic acid have been the subject of research.
Diabetic ulceration.
Foot ulceration is a problem commonly associated with diabetes, which often leads to amputation. A preliminary study completed by Abdelatif, Yakoot and Etmaan indicated that perhaps a royal jelly and panthenol ointment can help cure the ulceration. People with foot ulceration or deep tissue infection in the study had a 96% and 92% success rate of recovery. While these results appear promising, they need to be validated, as this was a pilot study; it was not a randomized, placebo-controlled, double-blind study.
Hypolipidemic effects.
Pantothenic acid derivatives, panthenol, phosphopantethine and pantethine, have also been seen to improve the lipid profile in the blood and liver. In this mouse model, they injected 150 mg of the derivative/kg body weight. All three derivatives were able to effectively lower low-density lipoprotein (LDL), as well as triglyceride (TG) levels; panthenol was able to lower total cholesterol, and pantethine was able to lower LDL-cholesterol in the serum. The decrease in LDL is significant, as it is related to a decrease the risk of myocardial infarction and stroke. In the liver, panthenol was the most effective, as it lowered TG, total cholesterol, free cholesterol and cholesterol-ester levels.
Wound healing.
A study in 1999 showed pantothenic acid has an effect on wound healing "in vitro". Wiemann and Hermann found cell cultures with a concentration of 100 μg/mL calcium D-pantothenate increased migration, and the fibers ran directionally with several layers, whereas the cell cultures without pantothenic acid healed in no orderly motion, and with fewer layers. Cell proliferation or cell multiplication was found to increase with pantothenic acid supplementation. Finally, increased concentrations of two proteins, both of which have yet to be identified, were found in the supplemented culture, but not in the control. Further studies are needed to determine whether these effects will stand "in vivo".
Hair care.
Mouse models identified skin irritation and loss of hair color as possible results of severe pantothenic acid deficiency. As a result, the cosmetic industry began adding pantothenic acid to various cosmetic products, including shampoo. These products, however, showed no benefits in human trials. Despite this, many cosmetic products still advertise pantothenic acid additives.
Diabetic peripheral polyneuropathy.
Twenty-eight out of 33 patients (84.8%) previously treated with alpha-lipoic acid for peripheral polyneuropathy reported further improvement after combination with pantothenic acid. The theoretical basis for this is that both substances intervene at different sites in pyruvate metabolism and are, thus, more effective than one substance alone. Additional clinical findings indicated diabetic neuropathy may occur in association with a latent prediabetic metabolic disturbance, and that the symptoms of neuropathy can be favorably influenced by the described combination therapy, even in poorly controlled diabetes.
Ruminant nutrition.
No dietary requirement for pantothenic acid has been established as synthesis of pantothenic acid by ruminal microorganisms appears to be 20 to 30 times more than dietary amounts. Net microbial synthesis of pantothenic acid in the rumen of steer calves has been estimated to be 2.2 mg/kg of digestible organic matter consumed per day. The degradation of dietary intake of pantothenic acid is considered to be 78 percent. Supplementation of pantothenic acid at 5 to 10 times theoretic requirements did not improve performance of feedlot cattle

</doc>
<doc id="54104" url="http://en.wikipedia.org/wiki?curid=54104" title="Vitamin E">
Vitamin E

Vitamin E refers to a group of compounds that include both tocopherols and tocotrienols. Of the many different forms of vitamin E, γ-tocopherol is the most common in the North American diet. γ-Tocopherol can be found in corn oil, soybean oil, margarine, and dressings. α-tocopherol, the most biologically active form of vitamin E, is the second-most common form of vitamin E in the diet. This variant can be found most abundantly in wheat germ oil, sunflower, and safflower oils. As a fat-soluble antioxidant, it stops the production of reactive oxygen species formed when fat undergoes oxidation. Regular consumption of more than 1,000 mg (1,500 IU) of tocopherols per day may be expected to cause hypervitaminosis E, with an associated risk of vitamin K deficiency and consequently of bleeding problems.
Forms.
The nutritional content of vitamin E is defined by α-tocopherol activity. The molecules that contribute α-tocopherol activity are four tocopherols and four tocotrienols, identified by the prefixes alpha- (α-), beta- (β-), gamma- (γ-), and delta- (δ-). Natural tocopherols occur in the RRR-configuration only. The synthetic form contains eight different stereoisomers and is called 'all-rac'-α-tocopherol. Water soluble forms such as d-alpha-tocopheryl succinate are used as food additive.
α-Tocopherol.
α-Tocopherol is an important lipid-soluble antioxidant. It performs its functions as antioxidant in the glutathione peroxidase pathway, and it protects cell membranes from oxidation by reacting with lipid radicals produced in the lipid peroxidation chain reaction. This would remove the free radical intermediates and prevent the oxidation reaction from continuing. The oxidized α-tocopheroxyl radicals produced in this process may be recycled back to the active reduced form through reduction by other antioxidants, such as ascorbate, retinol or ubiquinol. However, the importance of the antioxidant properties of this molecule at the concentrations present in the body are not clear and the reason vitamin E is required in the diet is possibly unrelated to its ability to act as an antioxidant. Other forms of vitamin E have their own unique properties; for example, γ-tocopherol is a nucleophile that can react with electrophilic mutagens.
Tocotrienols.
Compared with tocopherols, tocotrienols are sparsely studied. Less than 1% of PubMed papers on vitamin E relate to tocotrienols. The current research direction is starting to give more prominence to the tocotrienols, the lesser known but more potent antioxidants in the vitamin E family. Some studies have suggested that tocotrienols have specialized roles in protecting neurons from damage and cholesterol reduction by inhibiting the activity of HMG-CoA reductase; δ-tocotrienol blocks processing of sterol regulatory element‐binding proteins (SREBPs).
Oral consumption of tocotrienols is also thought to protect against stroke-associated brain damage "in vivo". Until further research has been carried out on the other forms of vitamin E, conclusions relating to the other forms of vitamin E, based on trials studying only the efficacy of α-tocopherol, may be premature.
Functions.
Vitamin E has many biological functions, the antioxidant function being the most important and best known. Other functions include enzymatic activities, gene expression, and neurological function(s). The most important function of vitamin E has been suggested to be in cell signaling (and it may not have a significant role in antioxidant metabolism).
So far, most human supplementation studies about vitamin E have used only α-tocopherol. This can affect levels of other forms of vitamin E, e.g. reducing serum γ- and δ-tocopherol concentrations. Moreover, a 2007 clinical study involving α-tocopherol concluded supplementation did not reduce the risk of major cardiovascular events in middle-aged and older men.
Deficiency.
Vitamin E deficiency can cause:
Supplementation.
While vitamin E supplementation was initially hoped to have a positive effect on health, research has not supported this hope. Vitamin E does not decrease mortality in adults, even at large doses, and high-dosage supplementation may slightly increase it. It does not improve blood sugar control in an unselected group of people with diabetes mellitus or decrease the risk of stroke. Daily supplementation of vitamin E does not decrease the risk of prostate cancer and may increase it. Studies on its role in age-related macular degeneration are ongoing as, though it is of a combination of dietary antioxidants used to treat the condition, it may increase the risk.
A 2012 Cochrane Review examined the potential effectiveness of antioxidant vitamin supplementation in preventing and slowing the progression of age-related cataract. The included studies involved supplementation of vitamin E, along with β-carotene and vitamin C, either dosed independently or in combination, and compared to the placebo. The systematic review showed that vitamin E supplementation had no protective effect on reducing the risk of cataract, cataract extraction, progression of cataract, and slowing the loss of visual acuity.
Overdose.
Vitamin E can act as an anticoagulant, increasing the risk of bleeding problems. As a result, many agencies have set a tolerable upper intake levels (UL) at 1,000 mg (1,500 IU) per day. In combination with certain other drugs such as aspirin, hypervitaminosis E can be life-threatening. Hypervitaminosis E may also counteract vitamin K, leading to a vitamin K deficiency.
Dietary sources.
Butter and egg yolk are the only food containing vitamin E and free from phytate
Recommended daily intake.
The Food and Nutrition Board at the Institute of Medicine (IOM) of the US National Academy of Sciences reported the following dietary reference intakes for vitamin E:
One IU of vitamin E is defined as equivalent to either: 0.67 mg of the natural form, RRR-α-tocopherol, also known as d-α-tocopherol; or 0.45 mg of the synthetic form, all-rac-α-tocopherol, also known as dl-α-tocopherol.
History.
Vitamin E was discovered in 1922 by Herbert McLean Evans and Katharine Scott Bishop and first isolated in a pure form by Gladys Anderson Emerson in 1935 at the University of California, Berkeley. Erhard Fernholz elucidated its structure in 1938 and shortly afterwards the same year, Paul Karrer and his team first synthesized it.
The first use for vitamin E as a therapeutic agent was conducted in 1938 by Widenbauer, who used wheat germ oil supplement on 17 premature newborn infants suffering from growth failure. Eleven of the original 17 patients recovered and were able to resume normal growth rates.
In 1945, Drs. Evan V. Shute and Wilfred E. Shute, siblings from Ontario, Canada, published the first monograph arguing that megadoses of vitamin E can slow down and even reverse the development of atherosclerosis. Peer-reviewed publications soon followed. The same research team also demonstrated, in 1946, that α-tocopherol improved impaired capillary permeability and low platelet counts in experimental and clinical thrombocytopenic purpura.
Later, in 1948, while conducting experiments on alloxan effects on rats, Gyorge and Rose noted rats receiving tocopherol supplements suffered from less hemolysis than those that did not receive tocopherol. In 1949, Gerloczy administered all-rac-α-tocopheryl acetate to prevent and cure edema. Methods of administration used were both oral, that showed positive response, and intramuscular, which did not show a response. This early investigative work on the benefits of vitamin E supplementation was the gateway to curing the vitamin E deficiency-caused hemolytic anemia described during the 1960s. Since then, supplementation of infant formulas with vitamin E has eradicated this vitamin’s deficiency as a cause for hemolytic anemia.
Vitamin E supplementation and cardiovascular disease.
Vitamin E and atherosclerosis.
Atherosclerosis is a disease condition refer to the build up of plaque, which is a substance containing lipid and cholesterol (mainly the low-density lipoprotein or LDL cholesterol) on the inner layer of the arterial lumen. With the existing plaque, instead of being smooth and elastic, the layers become thickened and irregular and the lumen of the artery become narrower. This vessel-narrowing effect lead to a reduction of blood circulation and can lead to or worsen the condition of hypertension.
There are currently multiple theories explaining factors causing and affecting the cholesterol plaque build up within arteries with the most popular theory indicating that the rate of build up is affected by the oxidation of the LDL cholesterol. LDL cholesterol is one of the five major groups of lipoproteins with one of the physiological roles being lipid transportation. A typical LDL particle contain 2,700 fatty acid molecules and half of them are poly-unsaturated fatty acids, which are very oxidation sensitive. Once the oxidation of LDL occur, it will start a series of undesirable effects starting from the increase production of inflammatory cytokines by stimulating the endothelial cells and monocytes, followed by increased production of tissue factors, production of macrophages and monocytes, which eventually lead to the formation of foam cells and accelerated development of atherosclerosis. With the presence of adequate concentration of vitamin E, which is a very potent fat-soluble antioxidant, it can inhibit the oxidation of LDL, and this inhibition contributes protection against the development of atherosclerosis and can stabilize the existing plaque.
Critical evaluation of current related literature.
Many observational and interventional studies have been conducted to clarify the association between vitamin E and CVD and it’s risk factors. The many observational studies supported a protective role for dietary and supplementary vitamin E intake on the risk of CVD. For randomized controlled trials (RCTs), however, the results are more controversial.
According to Asplund (2002)’s meta-analysis, nine cohort studies showed that high intake of tocopherol was associated with a lower risk of CVD events compared with lower intake. The odds ratio (OR) was 0.74 (95% confidential interval (CI): 0.66-0.83). In this study, higher dietary, supplementation and combined vitamin E intake was also associated with lower CHD incidents, as presented in Appendix II. A large cohort study conducted by Rimm et al in 1993 included 39,919 male health professionals aged between 40 to 75 showed that consumption of more than 60IU of vitamin E (any form) per day was associated with a lower incidence of CHD compared with less than 7.5 IU/day intake. This study also showed an inverse association between vitamin E supplementation and the incidence of CHD. The relative risk (RR) of at least 100 IU/day for at least two years was 0.63 (95% CI: 0.74-0.84). A European cohort study was conducted by Knekt et al in 1994. This study also found an inverse relationship between higher vitamin E (any form) intake and lower CHD risk in men and women. In addition, Kushi et al (1996) discovered an inverse relationship between vitamin E intake and CHD mortality among 34,486 postmenopausal women (RR=0.38, 95% CI: 0.18-0.8; trend: P=0.014).
For the result of RCTs, as mentioned previously, it was controversy. A meta-analysis of 6 RCTs showed no significant association between vitamin E supplementation and CVD mortality; the pooled OR (95% CI) was 1.0 (0.94-1.06) (Vivekananthan et al, 2003). Another meta-analysis of 7 RCTs also snowed similar results, with the pooled Ors (95% CI) of cardiovascular events, non-fatal MI, non-fatal stroke, and CVD deaths being 0.98 (0.94-1.03), 1.00 (0.92-1.09), 1.03 (0.93-1.14), and 1.00 (0.94-1.05), respectively 

</doc>
<doc id="54105" url="http://en.wikipedia.org/wiki?curid=54105" title="Tocopherol">
Tocopherol

Tocopherols (or TCP) are a class of organic chemical compounds (more precisely, various methylated phenols), many of which have vitamin E activity. Because the vitamin activity was first identified in 1936 from a dietary fertility factor in rats, it was given the name "tocopherol" from the Greek words "τόκος" ["tókos", birth], and "φέρειν", ["phérein", to bear or carry] meaning in sum "to carry a pregnancy," with the ending "-ol" signifying its status as a chemical alcohol.
α-Tocopherol is the main source found in supplements and in the European diet, where the main dietary sources are olive and sunflower oils, while γ-tocopherol is the most common form in the American diet due to a higher intake of soybean and corn oil.
Tocotrienols, which are related compounds, also have vitamin E activity. All of these various derivatives with vitamin activity may correctly be referred to as "vitamin E". Tocopherols and tocotrienols are fat-soluble antioxidants but also seem to have many other functions in the body.
Forms.
Vitamin E exists in eight different forms, four tocopherols and four tocotrienols. All feature a chromane ring, with a hydroxyl group that can donate a hydrogen atom to reduce free radicals and a hydrophobic side chain which allows for penetration into biological membranes.
Both the tocopherols and tocotrienols occur in α (alpha), β (beta), γ (gamma) and δ (delta) forms, determined by the number and position of methyl groups on the chromanol ring. 
The tocotrienols have the same methyl structure at the ring and the same Greek letter-methyl-notation, but differ from the analogous tocopherols by the presence of three double bonds in the hydrophobic side chain. The unsaturation of the tails gives tocotrienols only a single stereoisomeric carbon (and thus two possible isomers per structural formula, one of which occurs naturally), whereas tocopherols have 3 centers (and eight possible stereoisomers per structural formula, again, only one of which occurs naturally).
Each form has a different biological activity.
In general, the unnatural l-isomers of tocotrienols lack almost all vitamin activity, and half of the possible 8 isomers of the tocopherols (those with 2S chirality at the ring-tail junction) also lack vitamin activity. Of the stereoisomers which retain activity, increasing methylation, especially full methylation to the alpha-form, increases vitamin activity. In tocopherols, this is due to the preference of the tocophrol binding protein for the alpha-tocopherol form of the vitamin.
As a food additive, tocopherol is labeled with these E numbers: E306 (tocopherol), E307 (α-tocopherol), E308 (γ-tocopherol), and E309 (δ-tocopherol). These are all approved in the USA, EU and Australia and New Zealand for use as antioxidants.
α-Tocopherol.
Alpha-tocopherol is the form of vitamin E that is preferentially absorbed and accumulated in humans. The measurement of "vitamin E" activity in international units (IU) was based on fertility enhancement by the prevention of miscarriages in pregnant rats relative to alpha-tocopherol.
Although the mono-methylated form ddd-gamma-tocopherol is the most prevalent form of vitamin E in oils, there is evidence that rats can methylate this form to the preferred alpha-tocopherol, since several generations of rats retained alpha-tocopherol tissue levels, even when fed only gamma-tocopherol through their lives.
There are three stereocenters in alpha-tocopherol, so this is a chiral molecule. The eight stereoisomers of alpha-tocopherol differ in the arrangement of groups around these stereocenters. In the image of "RRR"-alpha-tocopherol below, all three stereocenters are in the "R" form. However, if the middle of the three stereocenters were changed (so the hydrogen was now pointing down and the methyl group pointing up), this would become the structure of "RSR"-alpha-tocopherol. These stereoisomers can also be named in an alternative older nomenclature, where the stereocenters are either in the "d" or "l" form.
1 IU of tocopherol is defined as ⅔ milligrams of "RRR"-alpha-tocopherol (formerly named d-alpha-tocopherol or sometimes ddd-alpha-tocopherol). 1 IU is also defined as 1 milligram of an equal mix of the eight stereoisomers, which is a racemic mixture called "all-rac"-alpha-tocopheryl acetate. This mix of stereoisomers is often called dl-alpha-tocopheryl acetate, even though it is more precisely dl,dl,dl-alpha-tocopheryl acetate). However, 1 IU of this racemic mixture is not now considered equivalent to 1 IU of natural (RRR) α-tocopherol, and the Institute of Medicine and the USDA now convert IU's of the racemic mixture to milligrams of equivalent RRR using 1 IU racemic mixture = 0.45 "milligrams α-tocopherol".
Tocotrienols.
Tocotrienols, although less commonly known, also belong to the vitamin E family. Tocotrienols have four natural 2' d-isomers (they have a stereoisomeric carbon only at the 2' ring-tail position). The four tocotrienols (in order of decreasing methylation: d-alpha, d-beta, d-gamma, and d-delta-tocotrienol) have structures corresponding to the four tocopherols, except with an unsaturated bond in each of the three isoprene units that form the hydrocarbon tail, whereas tocopherols have a saturated phytyl tail (the phytyl tail of tocopherols gives the possibility for 2 more stereoisomeric sites in these molecules that tocotrienols do not have). Tocotrienol has been subject to fewer clinical studies and seen less research as compared to tocopherol. However, there is growing interest in the health effects of these compounds.
History.
During feeding experiments with rats Herbert McLean Evans concluded in 1922 that besides vitamins B and C, an unknown vitamin existed. Although every other nutrition was present, the rats were not fertile. This condition could be changed by additional feeding with wheat germ. It took several years until 1936 when the substance was isolated from wheat germ and the formula C29H50O2 was determined. Evans also found that the compound reacted like an alcohol and concluded that one of the oxygen atoms was part of an OH (hydroxyl) group. As noted in the introduction, the vitamin was given its name by Evans from Greek words meaning "to bear young" with the addition of the -ol as an alcohol.
The structure was determined shortly thereafter in 1938.
Recommended amounts.
The U.S. Dietary Reference Intake (DRI) Recommended Daily Amount (RDA) for a 25-year-old male for Vitamin E is 15 mg/day. The DRI for vitamin E is based on the alpha-tocopherol form because it is the most active form as originally tested. Results of two national surveys, the National Health and Nutrition Examination Survey (NHANES III 1988-91) and the Continuing Survey of Food Intakes of Individuals (1994 CSFII) indicated that the dietary intakes of most Americans do not provide the recommended amounts of vitamin E. However, a 2000 Institute of Medicine (IOM) report on vitamin E states that intake estimates of vitamin E may be low because energy and fat intake is often underreported in national surveys and because the kind and amount of fat added during cooking is often not known. The IOM states that most North American adults get enough vitamin E from their normal diets to meet current recommendations. However, they do caution individuals who consume low fat diets because vegetable oils are such a good dietary source of vitamin E. "Low-fat diets can substantially decrease vitamin E intakes if food choices are not carefully made to enhance alpha-tocopherol intakes". Vitamin E supplements are absorbed best when taken with meals.
Because vitamin E can act as an anticoagulant and may increase the risk of bleeding problems, many agencies have set an upper tolerable intake level (UL) for vitamin E at 1,000 mg (1,500 IU) per day.
The European Food Safety Authority by its Scientific Committee on Food (SCF) has set a tolerable upper intake level (UL) of vitamin E for adults of 300 mg alpha-tocopherol equivalents /day.
α-Tocopherol equivalents.
For dietary purposes, vitamin E activity of vitamin E isomers is expressed as α-tocopherol equivalents (a-TEs). One a-TE is defined by the biological activity of 1 mg (natural) d-alpha-Tocopherol in the resorption-gestation test. According to listings by FAO and others beta-tocopherol should be multiplied by 0.5, gamma-tocopherol by 0.1, and a-tocotrienol by 0.3. 
The IU is converted to aTE by multiplying it with 0.67.
These factors do not correlate with the antioxidant activity of Vitamin E Isomers, where Tocotrienols show even much higher activity in vivo.
Sources.
In general, food sources with the highest concentrations of vitamin E are vegetable oils, followed by nuts and seeds including whole grains. Adjusting for typical portion sizes, however, for many people in the United States the most important sources of vitamin E include commercial breakfast cereal and tomato sauce. Although originally extracted from wheat germ oil, most natural vitamin E supplements are now derived from vegetable oils, usually soybean oil.
Vitamin E content per 100 g of source include:
A 100 g serving of certain fortified breakfast cereals may contain 24 mg (or more) vitamin E.
The proportion of vitamin E to other tocopherols in a nutrient source varies greatly. For example, the tocopherol content is 96% vitamin E in almonds and 9% vitamin E in poppy seeds.
Deficiency.
Vitamin E deficiency causes neurological problems due to poor nerve conduction. These include neuromuscular problems such as spinocerebellar ataxia and myopathies. Deficiency can also cause anemia, due to oxidative damage to red blood cells.
Supplements.
Commercial vitamin E supplements can be classified into several distinct categories:
Synthetic all-racemic.
Synthetic vitamin E derived from petroleum products is manufactured as all-racemic alpha tocopheryl acetate with a mixture of eight stereoisomers. In this mixture, one alpha-tocopherol molecule in eight molecules are in the form of "RRR"-alpha-tocopherol (12.5% of the total).
The 8-isomer "all-rac" vitamin E is always marked on labels simply as dl-tocopherol or dl-tocopheryl acetate, even though it is (if fully written out) actually dl,dl,dl-tocopherol. The present largest manufacturers of this type are DSM and BASF.
Natural alpha-tocopherol is the RRR-alpha (or ddd-alpha) form. The synthetic dl,dl,dl-alpha ("dl-alpha") form is not as active as the natural ddd-alpha ("d-alpha") tocopherol form. This is mainly due to reduced vitamin activity of the 4 possible stereoisomers which are represented by the "l" or "S" enantiomer at the first stereocenter (an S or l configuration between the chromanol ring and the tail, i.e., the SRR, SRS, SSR, and SSS stereoisomers). The 3 unnatural "2R" stereoisomers with natural R configuration at this 2' stereocenter, but S at one of the other centers in the tail (i.e., RSR, RRS, RSS), appear to retain substantial RRR vitamin activity, because they are recognized by the alpha-tocopherol transport protein, and thus maintained in the plasma, where the other four stereoisomers (SRR, SRS, SSR, and SSS) are not. Thus, the synthetic all-rac-α-tocopherol in theory would have approximately half the vitamin activity of RRR-alpha-tocopherol in humans. Experimentally, the ratio of activities of the 8 stereoisomer racemic mixture to the natural vitamin, is 1 to 1.36 in the rat pregnancy model (suggesting a measured activity ratio of 1/1.36 = 74% of natural, for the 8-isomer racemic mix).
Although it is clear that mixtures of stereoisomers are not as active as the natural "RRR"-alpha-tocopherol form, in the ratios discussed above, specific information on any side effects of the seven synthetic vitamin E stereoisomers is not readily available.
Esters.
Manufacturers also commonly convert the phenol form of the vitamins (with a free hydroxyl group) to esters, using acetic or succinic acid. These tocopheryl esters are more stable and are easy to use in vitamin supplements. Alpha tocopheryl esters are de-esterified in the gut and then absorbed as the free tocopherol. Tocopheryl nicotinate and tocopheryl linolate esters are also used in cosmetics and some pharmaceuticals.
Mixed tocopherols.
"Mixed tocopherols" in the US contain at least 20% w/w other natural R, R,R- tocopherols, i.e. R, R,R-alpha-tocopherol content plus at least 25% R, R,R-beta-, R, R,R-gamma-, R, R,R-delta-tocopherols.
Some brands may contain 200% w/w or more of the other tocopherols and measurable tocotrienols. Some mixed tocopherols with higher gamma-tocopherol content are marketed as "High Gamma-Tocopherol." The label should report each component in milligrams, except R, R,R-alpha-tocopherol may still be reported in IU. Mixed tocopherols can also be found in other nutritional supplements.
Pharmacology.
Age-related macular degeneration (AMD).
Age-related macular degeneration (AMD) is the leading cause of visual impairment and blindness in the United States and the developed world among people 65 years and older. It has been shown that vitamin E alone does not attenuate the development or progression of AMD.
However, studies focusing on efficacy of Vitamin E combined with other antioxidants, like zinc and vitamin C, indicate a protective effect against the onset and progression of AMD.
Alternative medicine.
Excessive intake of vitamin E may increase risk of bleeding, and a 2005 meta-analysis found that high-dosage vitamin E supplements may increase all-cause mortality. A Cochrane review of 2007 also found an increase in mortality, of 4% (Relative Risk 1.04, 95% confidence interval 1.01-1.07).
Proponents of megavitamin, orthomolecular, and naturally based therapies have for the last two thirds of a century advocated and used the "natural tocopherols", often mixed tocopherols with an additional 25%-200% w/w d-beta-, d-gamma-, and d-delta-tocopherol. Studies on vitamin E have largely concentrated on use of either a synthetic all-racemic ("d, l-") alpha tocopheryl ester (acetate or succinate) or a semi-synthetic d-alpha tocopheryl ester (acetate or succinate).
Alzheimer's disease.
Alzheimer's disease is a wasting disease of the brain. As oxidative stress may be involved in the pathogenesis of Alzheimer's, tocopherols have been tested as both a means of prevention and treatment. The results of these studies have been mixed, with some research suggesting that high levels of vitamin E in the diet may reduce the risk of Alzheimer's, while other studies found no such link. Studies on progression have also been contradictory, with the Alzheimer's Disease Cooperative Study suggesting that vitamin E supplementation might be beneficial, but a later trial finding no clinical benefit. Due to this contradictory and confusing evidence, vitamin E or tocopherol supplements are not currently recommended for treating or preventing Alzheimer's disease.
Cancer.
s of 2009[ [update]], human trials and surveys that have investigated potential association of vitamin E intake with incidence of cancer remain generally inconclusive.
Some evidence associates higher intake of vitamin E with a decreased incidence of prostate cancer (see ATBC study) and breast cancer. Some studies correlate additional cofactors, such as specific vitamin E isomers, "e.g." gamma-tocopherol, and other nutrients, "e.g." selenium, with dramatic risk reductions in prostate cancer. However, an examination of the effect of dietary factors, including vitamin E, on incidence of postmenopausal breast cancer in over 18,000 women from New York State did not associate a greater vitamin E intake with a reduced risk of developing breast cancer. A study of the effect on lung cancer in smokers also showed no benefit.
Recent studies have found that increased intake of vitamin E, especially among smokers may be responsible for an increase in the incidence of lung cancer, with one study finding an increase in the incidence of lung cancer by 7% for each 100 IU of vitamin E taken daily.
A potential confounding factor is the form of Vitamin E used in these studies. As explained earlier, synthetic, racemic mixtures of Vitamin E isomers are not bioequivalent to natural, non-racemic mixtures, yet are widely used academically and commercially. The SELECT study for prostate cancer used racemic alpha-tocopherol, for instance, and has shown no benefit. The study, cited above, showing a modest increase in cancer risk with Vitamin E supplementation, reported that over 90% of its respondents used a racemic form of Vitamin E (d,l-alpha-tocopherol). A meta-analysis of studies using Vitamin E, sorting results by the form (racemic vs non-racemic) used, is necessary.
Cataracts.
Antioxidants are being studied to determine whether they can help prevent or delay age-related growth of cataracts, a clouding of the tissue of the lens of the eye. A controlled trial of high doses of vitamins C and E and beta carotene found no effect on the risk of developing cataracts. Similarly, a trial using vitamin E alone found that vitamin E supplementation produced no change in the risk of developing cataracts or the rate of progression of existing cataracts.
Glaucoma.
A 2007 study published in the "European Journal of Ophthalmology" found that, along with other treatments for glaucoma, adding alpha-tocopherol appeared to help protect the retina from glaucomatous damage. Groups receiving 300 mg and 600 mg per day of alpha-tocopherol, delivered orally, showed statistically significant decreases in the resistivity index in the posterior ciliary arteries and in the pulsatility index in the ophthalmic arteries, after six and twelve months of therapy. Alpha-tocopherol-treated patients also had significantly lower differences in mean visual field deviations."
Heart disease.
Preliminary research has led to a widely held belief that vitamin E may help prevent or delay coronary heart disease, but larger controlled studies have not shown any benefit. Many researchers advance the belief that oxidative modification of LDL-cholesterol (sometimes called "bad" cholesterol) promotes blockages in coronary arteries that may lead to atherosclerosis and heart attacks. Vitamin E may help prevent or delay coronary heart disease by limiting the oxidation of LDL-cholesterol. Vitamin E also may help prevent the formation of blood clots, which could lead to a heart attack. Observational studies have associated lower rates of heart disease with higher vitamin E intake. A study of approximately 90,000 nurses suggested that the incidence of heart disease was 30% to 40% lower among nurses with the highest intake of vitamin E from diet and supplements. The range of intakes from both diet and supplements in this group was 21.6 to 1,000 IU (32 to 1,500 mg), with the median intake being 208 IU (139 mg). A 1994 review of 5,133 Finnish men and women aged 30 – 69 years suggested that increased dietary intake of vitamin E was associated with decreased mortality (death) from heart disease.
Despite these promising observations, randomized clinical trials have consistently shown lack of benefit to the role of vitamin E supplements in heart disease. The Heart Outcomes Prevention Evaluation (HOPE) Study followed almost 10,000 patients for 4.5 years who were at high risk for heart attack or stroke. In this intervention study the subjects who received 265 mg (400) IU of vitamin E daily did not experience significantly fewer cardiovascular events or hospitalizations for heart failure or chest pain when compared to those who received a sugar pill. The researchers suggested that it is unlikely that the vitamin E supplement provided any protection against cardiovascular disease in the HOPE study. This study is continuing, to determine whether a longer duration of intervention with vitamin E supplements will provide any protection against cardiovascular disease.
Furthermore, meta analysis of several trials of antioxidants, including vitamin E, have not shown any benefit to vitamin E supplementation for preventing coronary heart disease. One study suggested that Vitamin E (as alpha-tocopherol only) supplementation may increase the risk for heart failure. Supplementing alpha-tocopherol without gamma-tocopherol is known to lead to reduced serum gamma- and delta-tocopherol concentrations.
A large-scale 10-year study published in 2007 examined the rates of venous thromboembolism (VTE) and pulmonary embolism in women taking 600 IU of vitamin E on alternate days. The study found a significant reduction in VTE especially in women who had a history of thrombtic events or a genetic predispostion.
Parkinson's disease.
In May 2005, "The Lancet Neurology" published a study suggesting that vitamin E may help protect against Parkinson's disease. Individuals with moderate to high intakes of dietary vitamin E were found to have a lower risk of Parkinson's. No conclusion could be made whether supplemental vitamin E has the same effect. Other trials have tested whether giving vitamin E supplements reduces the risk of Parkinson's disease, or if they can slow the progression of the disease. In a 1998 study, vitamin E supplements had no effect on the rate of progression.
Pregnancy.
Recent studies into the use of both vitamin C and the single isomer vitamin E esters as possible aids in preventing oxidative stress leading to pre-eclampsia has failed to show significant benefits, but did increase the rate of babies born with a low birthweight in one study.
Preservative.
Tocopherols are sometimes used as a food preservative to prevent oils from going rancid, and in liquid castile soap made from coconut, olive, jojoba or hemp oil.
Topical use.
Vitamin E is widely used as an inexpensive antioxidant in cosmetics and foods. Vitamin E containing products are commonly used in the belief that vitamin E is good for the skin; many cosmetics include it, often labeled as tocopherol acetate, tocopheryl linoleate or tocopheryl nicotinate. Some individuals experience allergic reactions to some tocopheryl esters or develop a rash and hives that may spread over the entire body from the use of topical products with alpha tocopheryl esters.
Vitamin E is often claimed by manufacturers of skin creams and lotions to play a role in encouraging skin healing and reducing scarring after injuries such as burns on the basis of limited research, but the weak evidence of a benefit of silicon gel sheeting with or without added Vitamin E is limited by the poor quality of the research. One study found that it did not improve or worsen the cosmetic appearance in 90% of patients, with a third developing contact dermatitis.

</doc>
<doc id="54110" url="http://en.wikipedia.org/wiki?curid=54110" title="Vitamin B6">
Vitamin B6

Vitamin B6 refers to a group of chemically very similar compounds which can be interconverted in biological systems. Vitamin B6 is part of the vitamin B complex group, and its active form, Pyridoxal 5'-phosphate (PLP) serves as a cofactor in many enzyme reactions in amino acid, glucose, and lipid metabolism.
Forms.
Seven forms (vitamers) of vitamin B6 are known:
All forms except PA can be interconverted. Absorbed pyridoxamine is converted to PMP by pyridoxal kinase, which is further converted to PLP by pyridoxamine-phosphate transaminase or pyridoxine 5’-phosphate oxidase which also catalyzes the conversion of PNP to PLP. Pyridoxine 5’-phosphate oxidase is dependent on flavin mononucleotide (FMN) as a cofactor which is produced from riboflavin (vitamin B2) i.e. in this biochemical pathway, dietary vitamin B6 cannot be used without vitamin B2.
Functions.
PLP, the metabolically active form of vitamin B6, is involved in many aspects of macronutrient metabolism, neurotransmitter synthesis, histamine synthesis, hemoglobin synthesis and function, and gene expression. PLP generally serves as a coenzyme (cofactor) for many reactions including decarboxylation, transamination, racemization, elimination, replacement, and beta-group interconversion. The liver is the site for vitamin B6 metabolism.
Glucose metabolism.
PLP is a required coenzyme of glycogen phosphorylase, the enzyme necessary for glycogenolysis to occur. PLP can catalyze transamination reactions that are essential for providing amino acids as a substrate for gluconeogenesis.
Lipid metabolism.
PLP is an essential component of enzymes that facilitate the biosynthesis of sphingolipids. Particularly, the synthesis of ceramide requires PLP. In this reaction, serine is decarboxylated and combined with palmitoyl-CoA to form sphinganine, which is combined with a fatty acyl-CoA to form dihydroceramide. Dihydroceramide is then further desaturated to form ceramide. In addition, the breakdown of sphingolipids is also dependent on vitamin B6 because S1P lyase, the enzyme responsible for breaking down sphingosine-1-phosphate, is also PLP-dependent.
Hemoglobin synthesis and function.
PLP aids in the synthesis of hemoglobin, by serving as a coenzyme for the enzyme ALA synthase. It also binds to two sites on hemoglobin to enhance the oxygen binding of hemoglobin.
Gene expression.
PLP has been implicated in increasing or decreasing the expression of certain genes. Increased intracellular levels of the vitamin lead to a decrease in the transcription of glucocorticoids. Also, vitamin B6 deficiency leads to the increased gene expression of albumin mRNA. Also, PLP influences expression of glycoprotein IIb by interacting with various transcription factors. The result is inhibition of platelet aggregation.
Nutrition.
Food sources.
Vitamin B6 is widely distributed in foods in both its free and bound forms. Good sources include meats, whole-grain products (including cereals), vegetables, nuts, and bananas. Cooking, storage, and processing losses of vitamin B6 vary and in some foods may be more than 50%, depending on the form of vitamin present in the food. Plant foods lose the least during processing, as they contain mostly pyridoxine, which is far more stable than the pyridoxal or pyridoxamine found in animal foods. For example, milk can lose 30 to 70% of its vitamin B6 content when dried. Vitamin B6 is found in the germ and aleurone layer of grains, and milling results in the reduction of this vitamin in white flour. Freezing and canning are other food processing methods that result in the loss of vitamin B6 in foods.
The best natural sources include avocado, brewer's yeast, wheat bran, wheat germ, liver, kidney, heart, blackstrap molasses, milk, eggs, and beef.
Dietary reference intakes.
The Recommended Daily Allowance of the Institute of Medicine is 1.3 mg/d for a 19- to 50-year-old adult.
Absorption and excretion.
Vitamin B6 is absorbed in the jejunum and ileum by passive diffusion. With the capacity for absorption being so great, animals are able to absorb quantities much greater than necessary for physiological demands. The absorption of pyridoxal phosphate and pyridoxamine phosphate involves their dephosphorylation catalyzed by a membrane-bound alkaline phosphatase. Those products and nonphosphorylated forms in the digestive tract are absorbed by diffusion, which is driven by trapping of the vitamin as 5'-phosphates through the action of phosphorylation (by a pyridoxal kinase) in the jejunal mucosa. The trapped pyridoxine and pyridoxamine are oxidized to pyridoxal phosphate in the tissue.
The products of vitamin B6 metabolism are excreted in the urine, the major product of which is 4-pyridoxic acid. An estimated 40–60% of ingested vitamin B6 is oxidized to 4-pyridoxic acid. Several studies have shown that 4-pyridoxic acid is undetectable in the urine of vitamin B6-deficient subjects, making it a useful clinical marker to assess the vitamin B6 status of an individual. Other products of vitamin B6 metabolism excreted in the urine when high doses of the vitamin have been given include pyridoxal, pyridoxamine, and pyridoxine and their phosphates. A small amount of vitamin B6 is also excreted in the feces.
Deficiency.
Signs and symptoms.
The classic clinical syndrome for vitamin B6 deficiency is a seborrhoeic dermatitis-like eruption, atrophic glossitis with ulceration, angular cheilitis, conjunctivitis, intertrigo, and neurologic symptoms of somnolence, confusion, and neuropathy (due to impaired sphingosin synthesis) and sideroblastic anemia (due to impaired heme synthesis).
Less severe cases present with metabolic lesions associated with insufficient activities of the coenzyme PLP. The most prominent of the lesions is due to impaired tryptophan-niacin conversion. This can be detected based on urinary excretion of xanthurenic acid after an oral tryptophan load. Vitamin B6 deficiency can also result in impaired transsulfuration of methionine to cysteine. The PLP-dependent transaminases and glycogen phosphorylase provide the vitamin with its role in gluconeogenesis, so deprivation of vitamin B6 results in impaired glucose tolerance.
Diagnosis.
The assessment of vitamin B6 status is essential, as the clinical signs and symptoms in less severe cases are not specific. The three biochemical tests most widely used are the activation coefficient for the erythrocyte enzyme aspartate aminotransferase, plasma PLP concentrations, and the urinary excretion of vitamin B6 degradation products, specifically urinary PA. Of these, plasma PLP is probably the best single measure, because it reflects tissue stores. Plasma PLP less than 10nmol/l is indicative of vitamin B6 deficiency. A PLP concentration greater than 20nmol/l has been chosen as a level of adequacy for establishing Estimated Average Requirements and Recommended Daily Allowances in the USA. Urinary PA is also an indicator of vitamin B6 deficiency; levels of less than 3.0 mmol/day is suggestive of vitamin B6 deficiency.
Also liver test AST ALT can be low due to pyridoxine (B6) deficiency
The classic syndrome for vitamin B6 deficiency is rare, even in developing countries. A handful of cases were seen between 1952 and 1953, particularly in the United States, and occurred in a small percentage of infants who were fed a formula lacking in pyridoxine.
Causes.
A deficiency of vitamin B6 alone is relatively uncommon and often occurs in association with other vitamins of the B complex. The elderly and alcoholics have an increased risk of vitamin B6 deficiency, as well as other micronutrient deficiencies. Evidence exists for decreased levels of vitamin B6 in women with type 1 diabetes and in patients with systemic inflammation, liver disease, rheumatoid arthritis, and those infected with HIV. Use of oral contraceptives and treatment with certain anticonvulsants, isoniazid, cycloserine, penicillamine, and hydrocortisone negatively impact vitamin B6 status. Hemodialysis reduces vitamin B6 plasma levels.
There are indications that B6 deficiency can be influenced by Theophylline in medication or (mal)nutrition
Treatment.
Treatment of vitamin B6 deficiency lies with replacement, usually in the form of pyridoxine hydrochloride, orally, as a nasal spray, or for injection when in its solution form.
Toxicity.
Adverse effects have been documented from vitamin B6 supplements, but never from food sources. Toxicologic animal studies identify specific destruction of the dorsal root ganglia which is documented in human cases of overdose of pyridoxine. Although it is a water-soluble vitamin and is excreted in the urine, doses of pyridoxine in excess of the RDI over long periods of time result in painful and ultimately irreversible neurological problems.
The primary symptoms are pain and numbness of the extremities. In severe cases, motor neuropathy may occur with "slowing of motor conduction velocities, prolonged F wave latencies, and prolonged sensory latencies in both lower extremities", causing difficulty in walking. Sensory neuropathy typically develops at doses of pyridoxine in excess of 1,000 mg per day, but adverse effects can occur with much less, so doses over 200 mg are not considered safe. Symptoms among women taking lower doses have been reported. Two reported cases of neuropathy with pyridoxine treatment of 24 and 40 mg/day may have been coincidental.
Existing authorisations and valuations vary considerably worldwide. In 1993, the European Community Scientific Committee on Food defined intakes of 50 mg of vitamin B6 per day as harmful and established a tolerable upper intake level of 25 mg/day for adults in 2000. The Expert Group on Vitamins and Minerals of the Food Standard Agency UK (UK EVM) derived a safe upper level (SUL) of 10 mg/day for a 60-kg adult in 2003. The tolerable upper limit has been set by the US FDA at 100 mg/day in 2000.
The nutrient reference values in Australia and New Zealand recommend an upper limit of 50 mg a day in adults. "The same figure was set for pregnancy and lactation as there is no evidence of teratogenicity at this level. The UL was set based on metabolic body size and growth considerations for all other ages and life stages except infancy. It was not possible to set a UL for infants, so intake is recommended in the form of food, milk or formula." "The ULs were set using results of studies involving long-term oral administration of pyridoxine at doses of less than 1g/day (Berger & Schaumburg 1984, Bernstein & Lobitz 1988, Dalton 1985, Dalton & Dalton 1987, Del Tredici et al 1985, FNB:IOM 1998, Parry & Bredesen 1985). A NOAEL (No-observed-adverse-effect level) of 200 mg/day was identified from the studies of Bernstein & Lobitz (1988) and Del Tredici et al (1985). These studies involved subjects who had generally been on the supplements for five to six months or less. The study of Dalton and Dalton (1987), however, suggested the symptoms might take substantially longer than this to appear. In this latter retrospective survey, subjects who reported symptoms had been on supplements for 2.9 years, on average. Those reporting no symptoms had taken supplements for 1.9 years."
Because no placebo-controlled studies show therapeutic benefits of high doses of pyridoxine, and the well-documented occurrence of significant toxic effects, little reason exists to exceed the RDI using supplements unless under medical supervision e.g. in treatment of primary hyperoxaluria.
Medical uses.
Vitamin B6 has been used to treat nausea and vomiting in early pregnancy for decades, commonly in conjunction with other medications such as metoclopramide or doxylamine. Alone, it has been found safe and effective, though any woman's prenatal caregiver must help guide treatment for these symptoms.
At least one preliminary study has found this vitamin may increase dream vividness or the ability to recall dreams. This effect is possibly due to the role this vitamin plays in the conversion of tryptophan to serotonin. Anecdotal evidence suggests supplemental vitamin B6 may be associated with lucid dreaming.
The intake of vitamin B6, from either diet or supplements, could cut the risk of Parkinson's disease in smokers by half, according to a prospective study from the Netherlands.
Nutritional supplementation with high dose vitamin B6 and magnesium is one of the most popular alternative medicine choices for autism, but randomised control trials have had mixed results and small sample sizes mean no conclusions can be drawn as to the efficacy of this treatment.
Some studies suggest the vitamin B6-magnesium combination can also help attention deficit disorder, citing improvements in hyperactivity, hyperemotivity/aggressiveness, and improved school attention.
Vitamin B6 has been shown in at least two small-scale clinical studies to have a beneficial effect on the carpal tunnel syndrome, particularly in cases where no trauma or overuse etiology is known.
Pyridoxine may help balance hormonal changes in women and aid the immune system.
The effectiveness as treatment for PMS, PMDD, and clinical depression is debatable.
Although a recent study has pointed to the increase in efficacy of citalopram when given with magnesium and Vitamin B6 in adults with severe depression. See Reference:
B vitamins to enhance treatment response to antidepressants in middle-aged and older adults: results from the B-VITAGE randomised, double-blind, placebo-controlled trial. Br J Psychiatry 2014;205:450-457.
Ingestion of vitamin B6 possibly can alleviate some of the many symptoms of an alcoholic hangover and morning sickness from pregnancy. This might result from its mild diuretic effect. Though the mechanism is not known, results show pyridoxamine has therapeutic effects in clinical trials for diabetic nephropathy.
Vitamin B6 intake and PLP levels are inversely related to the risk of colon cancer. While the correlation with B6 intake is moderate, it was quite dramatic with PLP levels, where the risk of colon cancer was decreased by nearly half.
Vitamin B6 is also known to increase the metabolism of Parkinson's medications, such as levodopa, and should be used cautiously.
Pyridoxine-dependent epilepsy is an extremely rare genetic disorder characterized by intractable seizures in the prenatal and neonatal period that can be treated with pharmacological doses of vitamin B6.
Pyridoxine is given to patients taking isoniazid (INH) to combat the toxic side effects of the drug.
In one form of homocystinuria, activity of the deficient enzyme can be enhanced by the administration of large doses of pyridoxine (100–1000 mg/day).
History.
In 1934, the Hungarian physician Paul Gyorgy discovered a substance that was able to cure a skin disease in rats (dermititis acrodynia). He named this substance vitamin B6. In 1938, Samuel Lepkovsky isolated vitamin B6 from rice bran. Harris and Folkers in 1939 determined the structure of pyridoxine, and, in 1945, Snell was able to show the two forms of vitamin B6, pyridoxal and pyridoxamine. Vitamin B6 was named pyridoxine to indicate its structural homology to pyridine.

</doc>
<doc id="54114" url="http://en.wikipedia.org/wiki?curid=54114" title="Vitamin A">
Vitamin A

Vitamin A is a group of unsaturated nutritional organic compounds, that includes retinol, retinal, retinoic acid, and several provitamin A carotenoids, among which beta-carotene is the most important. Vitamin A has multiple functions: it is important for growth and development, for the maintenance of the immune system and good vision. Vitamin A is needed by the retina of the eye in the form of retinal, which combines with protein opsin to form rhodopsin, the light-absorbing molecule necessary for both low-light (scotopic vision) and color vision. Vitamin A also functions in a very different role as retinoic acid (an irreversibly oxidized form of retinol), which is an important hormone-like growth factor for epithelial and other cells.
In foods of animal origin, the major form of vitamin A is an ester, primarily retinyl palmitate, which is converted to retinol (chemically an alcohol) in the small intestine. The retinol form functions as a storage form of the vitamin, and can be converted to and from its visually active aldehyde form, retinal.
All forms of vitamin A have a beta-ionone ring to which an isoprenoid chain is attached, called a "retinyl group". Both structural features are essential for vitamin activity. The orange pigment of carrots (beta-carotene) can be represented as two connected retinyl groups, which are used in the body to contribute to vitamin A levels. Alpha-carotene and gamma-carotene also have a single retinyl group, which give them some vitamin activity. None of the other carotenes have vitamin activity. The carotenoid beta-cryptoxanthin possesses an ionone group and has vitamin activity in humans.
Vitamin A can be found in two principal forms in foods:
History.
The discovery of vitamin A may have stemmed from research dating back to 1816, when physiologist François Magendie observed that dogs deprived of nutrition developed corneal ulcers and had a high mortality rate. In 1912, Frederick Gowland Hopkins demonstrated that unknown accessory factors found in milk, other than carbohydrates, proteins, and fats were necessary for growth in rats. Hopkins received a Nobel Prize for this discovery in 1929. By 1917, one of these substances was independently discovered by Elmer McCollum at the University of Wisconsin–Madison, and Lafayette Mendel and Thomas Burr Osborne at Yale University who studied the role of fats in the diet. The "accessory factors" were termed "fat soluble" in 1918 and later "vitamin A" in 1920. In 1919, Harry Steenbock (University of Wisconsin) proposed a relationship between yellow plant pigments (beta-carotene) and vitamin A. In 1931, Swiss chemist Paul Karrer described the chemical structure of vitamin A. Vitamin A was first synthesized in 1947 by two Dutch chemists, David Adriaan van Dorp and Jozef Ferdinand Arens.
Equivalencies of retinoids and carotenoids (IU).
As some carotenoids can be converted into vitamin A, attempts have been made to determine how much of them in the diet is equivalent to a particular amount of retinol, so that comparisons can be made of the benefit of different foods. The situation can be confusing because the accepted equivalences have changed. For many years, a system of equivalencies in which an international unit (IU) was equal to 0.3 μg of retinol, 0.6 μg of β-carotene, or 1.2 μg of other provitamin-A carotenoids was used. Later, a unit called retinol equivalent (RE) was introduced. Prior to 2001, one RE corresponded to 1 μg retinol, 2 μg β-carotene dissolved in oil (it is only partly dissolved in most supplement pills, due to very poor solubility in any medium), 6 μg β-carotene in normal food (because it is not absorbed as well as when in oils), and 12 μg of either α-carotene, γ-carotene, or β-cryptoxanthin in food.
Newer research has shown that the absorption of provitamin-A carotenoids is only half as much as previously thought. As a result, in 2001 the US Institute of Medicine recommended a new unit, the retinol activity equivalent (RAE). Each μg RAE corresponds to 1 μg retinol, 2 μg of β-carotene in oil, 12 μg of "dietary" beta-carotene, or 24 μg of the three other dietary provitamin-A carotenoids.
Because the conversion of retinol from provitamin carotenoids by the human body is actively regulated by the amount of retinol available to the body, the conversions apply strictly only for vitamin A-deficient humans. The absorption of provitamins depends greatly on the amount of lipids ingested with the provitamin; lipids increase the uptake of the provitamin.
The conclusion that can be drawn from the newer research is that fruits and vegetables are not as useful for obtaining vitamin A as was thought; in other words, the IUs that these foods were reported to contain were worth much less than the same number of IUs of fat-dissolved oils and (to some extent) supplements. This is important for vegetarians, as night blindness is prevalent in countries where little meat or vitamin A-fortified foods are available.
A sample vegan diet for one day that provides sufficient vitamin A has been published by the Food and Nutrition Board (page 120). On the other hand, reference values for retinol or its equivalents, provided by the National Academy of Sciences, have decreased. The RDA (for men) of 1968 was 5000 IU (1500 μg retinol). In 1974, the RDA was set to 1000 RE (1000 μg retinol), whereas now the Dietary Reference Intake is 900 RAE (900 μg or 3000 IU retinol). This is equivalent to 1800 μg of β-carotene supplement (3000 IU) or 10800 μg of β-carotene in food (18000 IU).
Recommended daily allowance.
Vitamin A Dietary Reference Intake:
According to the Institute of Medicine of the National Academies, "RDAs are set to meet the needs of almost all (97 to 98%) individuals in a group. For healthy breastfed infants, the AI is the mean intake. The AI for other life stage and gender groups is believed to cover the needs of all individuals in the group, but lack of data prevents being able to specify with confidence the percentage of individuals covered by this intake."
Sources.
Vitamin A is found naturally in many foods:
Note: Data taken from USDA database. Bracketed values are retinol activity equivalences (RAEs) and percentage of the adult male RDA, per 100 grams of the foodstuff (average).
Conversion of carotene to retinol varies from person to person and bioavailability of carotene in food varies.
Metabolic functions.
Vitamin A plays a role in a variety of functions throughout the body, such as:
Vision.
The role of vitamin A in the visual cycle is specifically related to the retinal form. Within the eye, 11-"cis"-retinal is bound to protein "opsin" to form rhodopsin in rods and iodopsin (cones) at conserved lysine residues. As light enters the eye, the 11-"cis"-retinal is isomerized to the all-"trans" form. The all-"trans" retinal dissociates from the opsin in a series of steps called photo-bleaching. This isomerization induces a nervous signal along the optic nerve to the visual center of the brain. After separating from opsin, the all-"trans"-retinal is recycled and converted back to the 11-"cis"-retinal form by a series of enzymatic reactions. In addition, some of the all-"trans" retinal may be converted to all-"trans" retinol form and then transported with an interphotoreceptor retinol-binding protein (IRBP) to the pigment epithelial cells. Further esterification into all-"trans" retinyl esters allow for storage of all-trans-retinol within the pigment epithelial cells to be reused when needed. The final stage is conversion of 11-"cis"-retinal will rebind to opsin to reform rhodopsin (visual purple) in the retina. Rhodopsin is needed to see in low light (contrast) as well as for night vision. Kühne showed that the regeneration of rhodopsin only occurs when retina is attached to retinal pigmented epithelial (RPE). It is for this reason that a deficiency in vitamin A will inhibit the reformation of rhodopsin and lead to one of the first symptoms, night blindness.
Gene transcription.
Vitamin A, in the retinoic acid form, plays an important role in gene transcription. Once retinol has been taken up by a cell, it can be oxidized to retinal (retinaldehyde) by retinol dehydrogenases and then retinaldehyde can be oxidized to retinoic acid by retinaldehyde dehydrogenases. The conversion of retinaldehyde to retinoic acid is an irreversible step, meaning that the production of retinoic acid is tightly regulated, due to its activity as a ligand for nuclear receptors. The physiological form of retinoic acid (all-trans-retinoic acid) regulates gene transcription by binding to nuclear receptors known as retinoic acid receptors (RARs) which are bound to DNA as heterodimers with retinoid "X" receptors (RXRs). RAR and RXR must dimerize before they can bind to the DNA. RAR will form a heterodimer with RXR (RAR-RXR), but it does not readily form a homodimer (RAR-RAR). RXR, on the other hand, may form a homodimer (RXR-RXR) and will form heterodimers with many other nuclear receptors as well, including the thyroid hormone receptor (RXR-TR), the Vitamin D3 receptor (RXR-VDR), the peroxisome proliferator-activated receptor (RXR-PPAR) and the liver "X" receptor (RXR-LXR). The RAR-RXR heterodimer recognizes retinoic acid response elements (RAREs) on the DNA whereas the RXR-RXR homodimer recognizes retinoid "X" response elements (RXREs) on the DNA; although several RAREs near target genes have been shown to control physiological processes, this has not been demonstrated for RXREs. The heterodimers of RXR with nuclear receptors other than RAR (i.e. TR, VDR, PPAR, LXR) bind to various distinct response elements on the DNA to control processes not regulated by vitamin A. Upon binding of retinoic acid to the RAR component of the RAR-RXR heterodimer, the receptors undergo a conformational change that causes co-repressors to dissociate from the receptors. Coactivators can then bind to the receptor complex, which may help to loosen the chromatin structure from the histones or may interact with the transcriptional machinery. This response can upregulate (or downregulate) the expression of target genes, including Hox genes as well as the genes that encode for the receptors themselves (i.e. RAR-beta in mammals).
Dermatology.
Vitamin A, and more specifically, retinoic acid, appears to maintain normal skin health by switching on genes and differentiating keratinocytes (immature skin cells) into mature epidermal cells. Exact mechanisms behind pharmacological retinoid therapy agents in the treatment of dermatological diseases are being researched.
For the treatment of acne, the most prescribed retinoid drug is 13-cis retinoic acid (isotretinoin). It reduces the size and secretion of the sebaceous glands. Although it is known that 40 mg of isotretinoin will break down to an equivalent of 10 mg of ATRA — the mechanism of action of the drug (original brand name Accutane) remains unknown and is a matter of some controversy. Isotretinoin reduces bacterial numbers in both the ducts and skin surface. This is thought to be a result of the reduction in sebum, a nutrient source for the bacteria. Isotretinoin reduces inflammation via inhibition of chemotactic responses of monocytes and neutrophils. Isotretinoin also has been shown to initiate remodeling of the sebaceous glands; triggering changes in gene expression that selectively induce apoptosis. Isotretinoin is a teratogen with a number of potential side-effects. Consequently, its use requires medical supervision.
Retinal/retinol versus retinoic acid.
Vitamin A deprived rats can be kept in good general health with supplementation of retinoic acid. This reverses the growth-stunting effects of vitamin A deficiency, as well as early stages of xerophthalmia. However, such rats show infertility (in both male and females) and continued degeneration of the retina, showing that these functions require retinal or retinol, which are interconvertible but which cannot be recovered from the oxidized retinoic acid. The requirement of retinol to rescue reproduction in vitamin A deficient rats is now known to be due to a requirement for local synthesis of retinoic acid from retinol in testis and embryos.
Deficiency.
Vitamin A deficiency is estimated to affect approximately one third of children under the age of five around the world. It is estimated to claim the lives of 670,000 children under five annually. Approximately 250,000–500,000 children in developing countries become blind each year owing to vitamin A deficiency, with the highest prevalence in Southeast Asia and Africa.
Vitamin A deficiency can occur as either a primary or a secondary deficiency. A primary vitamin A deficiency occurs among children and adults who do not consume an adequate intake of provitamin A carotenoids from fruits and vegetables or preformed vitamin A from animal and dairy products. Early weaning from breastmilk can also increase the risk of vitamin A deficiency.
Secondary vitamin A deficiency is associated with chronic malabsorption of lipids, impaired bile production and release, and chronic exposure to oxidants, such as cigarette smoke, and chronic alcoholism. Vitamin A is a fat soluble vitamin and depends on micellar solubilization for dispersion into the small intestine, which results in poor use of vitamin A from low-fat diets. Zinc deficiency can also impair absorption, transport, and metabolism of vitamin A because it is essential for the synthesis of the vitamin A transport proteins and as the cofactor in conversion of retinol to retinal. In malnourished populations, common low intakes of vitamin A and zinc increase the severity of vitamin A deficiency and lead physiological signs and symptoms of deficiency. A study in Burkina Faso showed major reduction of malaria morbidity with combined vitamin A and zinc supplementation in young children.
Due to the unique function of retinal as a visual chromophore, one of the earliest and specific manifestations of vitamin A deficiency is impaired vision, particularly in reduced light – night blindness. Persistent deficiency gives rise to a series of changes, the most devastating of which occur in the eyes. Some other ocular changes are referred to as xerophthalmia. First there is dryness of the conjunctiva (xerosis) as the normal lacrimal and mucus-secreting epithelium is replaced by a keratinized epithelium. This is followed by the build-up of keratin debris in small opaque plaques (Bitot's spots) and, eventually, erosion of the roughened corneal surface with softening and destruction of the cornea (keratomalacia) and leading to total blindness. Other changes include impaired immunity (increased risk of ear infections, urinary tract infections, Meningococcal disease), hyperkeratosis (white lumps at hair follicles), keratosis pilaris and squamous metaplasia of the epithelium lining the upper respiratory passages and urinary bladder to a keratinized epithelium. With relations to dentistry, a deficiency in Vitamin A leads to enamel hypoplasia.
Adequate supply, but not excess vitamin A, is especially important for pregnant and breastfeeding women for normal fetal development and in breastmilk. Deficiencies cannot be compensated by postnatal supplementation. Excess vitamin A, which is most common with high dose vitamin supplements, can cause birth defects and therefore should not exceed recommended daily values.
Vitamin A metabolic inhibition as a result of alcohol consumption during pregnancy is the elucidated mechanism for fetal alcohol syndrome and is characterized by teratogenicity closely matching maternal vitamin A deficiency.
Vitamin A supplementation.
Global efforts to support national governments in addressing vitamin A deficiency are led by the Global Alliance for Vitamin A (GAVA), which is an informal partnership between A2Z, the Canadian International Development Agency, Helen Keller International, the Micronutrient Initiative, UNICEF, USAID, and the World Bank. Joint GAVA activity is coordinated by the Micronutrient Initiative.
While strategies include intake of vitamin A through a combination of breast feeding and dietary intake, delivery of oral high-dose supplements remain the principal strategy for minimizing deficiency. A meta-analysis of 43 studies showed that vitamin A supplementation of children under five who are at risk of deficiency reduces mortality by up to 24%. About 75% of the vitamin A required for supplementation activity by developing countries is supplied by the Micronutrient Initiative with support from the Canadian International Development Agency. Food fortification approaches are becoming increasingly feasible but cannot yet ensure coverage levels.
The World Health Organization estimates that Vitamin A supplementation has averted 1.25 million deaths due to vitamin A deficiency in 40 countries since 1998. In 2008 it was estimated that an annual investment of US$60 million in vitamin A and zinc supplementation combined would yield benefits of more than US$1 billion per year, with every dollar spent generating benefits of more than US$17. These combined interventions were ranked by the Copenhagen Consensus 2008 as the world’s best development investment.
Observational studies of pregnant women in sub-Saharan Africa have shown that low serum vitamin A levels are associated with an increased risk of mother-to-child transmission (MTCT) of HIV. Vitamin A is cheap and easily provided through existing health services in low-income settings. It is thus important to determine the effect of routine supplementation of H levels, and because low blood vitamin A levels have been associated with rapid HIV infection and deaths, To identify randomised controlled trials comparing vitamin A supplementation with placebo in known HIV-infected pregnant women, authors searched the Cochrane Library, PubMed, EMBASE, AIDSearch and GATEWAY; checked reference lis. Authoritative reviews of more recent and better-designed studies have found no relationship between the level of serum maternal and/or infant vitamin A and the likelihood of vertical (MTCT) HIV transmission. of HIV, our trials which enrolled 3033 HIV-infected pregnant women met inclusion criteria. Authors found significant statistical heterogeneity between the three trials with information on MTCT of HIV. Overall, there was no evidence of an effect of antenatal vitamin A supplementation on the risk of MTCT of HIV. However, antenatal vitamin A supplementation significantly improved birth weight, but there was no evidence of an effect on preterm births, stillbirths, deaths by 24 months.
Toxicity.
Since vitamin A is fat-soluble, disposing of any excesses taken in through diet takes much longer than with water-soluble B vitamins and vitamin C. This allows for toxic levels of vitamin A to accumulate.
In general, acute toxicity occurs at doses of 25,000 IU/kg of body weight, with chronic toxicity occurring at 4,000 IU/kg of body weight daily for 6–15 months. However, liver toxicities can occur at levels as low as 15,000 IU (4500 micrograms) per day to 1.4 million IU per day, with an average daily toxic dose of 120,000 IU, particularly with excessive consumption of alcohol . In people with renal failure, 4000 IU can cause substantial damage. Children can reach toxic levels at 1,500 IU/kg of body weight.
Excessive vitamin A consumption can lead to nausea, irritability, anorexia (reduced appetite), vomiting, blurry vision, headaches, hair loss, muscle and abdominal pain and weakness, drowsiness, and altered mental status. In chronic cases, hair loss, dry skin, drying of the mucous membranes, fever, insomnia, fatigue, weight loss, bone fractures, anemia, and diarrhea can all be evident on top of the symptoms associated with less serious toxicity. Some of these symptoms are also common to acne treatment with Isotretinoin. Chronically high doses of vitamin A, and also pharmaceutical retinoids such as 13-cis retinoic acid, can produce the syndrome of pseudotumor cerebri. This syndrome includes headache, blurring of vision and confusion, associated with increased intracerebral pressure. Symptoms begin to resolve when intake of the offending substance is stopped.
Chronic intake of 1500 RAE of preformed vitamin A may be associated with osteoporosis and hip fractures because it suppresses bone building while simultaneously stimulating bone breakdown.
High vitamin A intake has been associated with spontaneous bone fractures in animals. Cell culture studies have linked increased bone resorption and decreased bone formation with high intakes. This interaction may occur because vitamins A and D may compete for the same receptor and then interact with parathyroid hormone, which regulates calcium. Indeed, a study by Forsmo "et al." shows a correlation between low bone mineral density and too high intake of vitamin A. Sufficiently high levels of vitamin D may be protective against the bone density lowering effects of high vitamin A, while inadequate levels of vitamin D may exacerbate those effects.
Toxic effects of vitamin A have been shown to significantly affect developing fetuses. Therapeutic doses used for acne treatment have been shown to disrupt cephalic neural cell activity. The fetus is particularly sensitive to vitamin A toxicity during the period of organogenesis. These toxicities only occur with preformed (retinoid) vitamin A (such as from liver). The carotenoid forms (such as beta-carotene as found in carrots), give no such symptoms, except with supplements and chronic alcoholism, but excessive dietary intake of beta-carotene can lead to carotenodermia, which causes orange-yellow discoloration of the skin.
Hepatic (liver) injury has been found in human and animal studies where consumption of alcohol is paired with high dose vitamin A and beta-carotene supplementation.
Researchers have succeeded in creating water-soluble forms of vitamin A, which they believed could reduce the potential for toxicity. However, a 2003 study found water-soluble vitamin A was approximately 10 times as toxic as fat-soluble vitamin. A 2006 study found children given water-soluble vitamin A and D, which are typically fat-soluble, suffer from asthma twice as much as a control group supplemented with the fat-soluble vitamins.
In some studies, the use of Vitamin A supplements has been linked to an increased rate of mortality, but there is minimal evidence to show this.
Vitamin A and derivatives in medical use.
Retinyl palmitate has been used in skin creams, where it is broken down to retinol and ostensibly metabolised to retinoic acid, which has potent biological activity, as described above.
The retinoids (for example, 13-cis-retinoic acid) constitute a class of chemical compounds chemically related to retinoic acid, and are used in medicine to modulate gene functions in place of this compound. Like retinoic acid, the related compounds do not have full vitamin A activity, but do have powerful effects on gene expression and epithelial cell differentiation.
Pharmaceutics utilizing mega doses of naturally occurring retinoic acid derivatives are currently in use for cancer, HIV, and dermatological purposes. At high doses, side-effects are similar to vitamin A toxicity.

</doc>
<doc id="54115" url="http://en.wikipedia.org/wiki?curid=54115" title="Retinol">
Retinol

Retinol is one of the animal forms of vitamin A. It is a diterpenoid and an alcohol. It is convertible to other forms of vitamin A, and the retinyl ester derivative of the alcohol serves as the storage form of the vitamin in animals.
When converted to the retinal (retinaldehyde) form, vitamin A is essential for vision, and when converted to retinoic acid is essential for skin health, teeth remineralization and bone growth. These chemical compounds are collectively known as retinoids, and possess the structural motif of all-"trans" retinol as a common feature in their structure. Structurally, all retinoids also possess a β-ionone ring and a polyunsaturated side chain, with either an alcohol, aldehyde, a carboxylic acid group or an ester group. The side chain is composed of four isoprenoid units, with a series of conjugated double bonds which may exist in "trans"- or "cis"-configuration.
Retinol is produced in the body from the hydrolysis of retinyl esters, and from the reduction of retinal. Retinol in turn is ingested in a precursor form; animal sources (liver and eggs) contain retinyl esters, whereas plants (carrots, spinach) contain provitamin A carotenoids (these may also be considered simply vitamin A). Hydrolysis of retinyl esters results in retinol, while provitamin A carotenoids can be cleaved to produce retinal by carotene dioxygenase in the intestinal mucosa. Retinal, also known as retinaldehyde, can be reversibly reduced to produce retinol or it can be "irreversibly" oxidized to produce retinoic acid, which then cannot function as the vitamin in the eye.
Commercial production of retinol typically requires retinal synthesis through reduction of a pentadiene derivative and subsequent acidification/hydrolysis of the resulting isomer to produce retinol. Pure retinol is extremely sensitive to oxidization and is prepared and transported at low temperatures and oxygen free atmospheres. When prepared as a dietary supplement, retinol is stabilized as the ester derivatives retinyl acetate or retinyl palmitate.
Discovery.
In 1913, Elmer McCollum, a biochemist at the University of Wisconsin–Madison, and colleague Marguerite Davis identified a fat-soluble nutrient in butterfat and cod liver oil. Their work confirmed that of Thomas Osborne and Lafayette Mendel, at Yale, which suggested a fat-soluble nutrient in butterfat, also in 1913. Vitamin A was first synthesized in 1947 by two Dutch chemists, David Adriaan van Dorp and Jozef Ferdinand Arens.
Although the vitamin A was not identified until the 20th century, written observations of conditions created by deficiency of this nutrient appeared much earlier in history. Sommer (2008) classified historical accounts related to vitamin A and/or manifestations of deficiency as follows: "Ancient" accounts; 18th- to 19th-century clinical descriptions (and their purported etiologic associations); early 20th-century laboratory animal experiments, and clinical and epidiomologic observations that identified the existence of this unique nutrient and manifestations of its deficiency.
Chemical structure and function.
Many different geometric isomers of retinol, retinal and retinoic acid are possible as a result of either a "trans" or "cis" configuration of four of the five double bonds found in the polyene chain. The "cis" isomers are less stable and can readily convert to the all-"trans" configuration (as seen in the structure of all-"trans"-retinol shown here). Nevertheless, some "cis" isomers are found naturally and carry out essential functions. For example, the 11-"cis"-retinal isomer is the chromophore of rhodopsin, the vertebrate photoreceptor molecule. Rhodopsin is composed of the 11-cis-retinal covalently linked via a Schiff base to the opsin protein (either rod opsin or blue, red or green cone opsins). The process of vision relies on the light-induced isomerisation of the chromophore from 11-"cis" to all-"trans" resulting in a change of the conformation and activation of the photoreceptor molecule. One of the earliest signs of vitamin A deficiency is night-blindness followed by decreased visual acuity.
George Wald won the 1967 Nobel Prize in Physiology or Medicine for his work with retina pigments (also called visual pigments), which led to the understanding of the role of vitamin A in vision.
Many of the non-visual functions of vitamin A are mediated by retinoic acid, which regulates gene expression by activating nuclear retinoic acid receptors. The non-visual functions of vitamin A are essential in the immunological function, reproduction and embryonic development of vertebrates as evidenced by the impaired growth, susceptibility to infection and birth defects observed in populations receiving suboptimal vitamin A in their diet.
Biosynthesis of retinol.
Retinol is synthesized from the breakdown of β-carotene. First the β-carotene 15-15’-monooxygenase cleaves β-carotene at the central double bond, creating an epoxide. This epoxide is then attacked by water creating two hydroxyl groups in the center of the structure. The cleavage occurs when these alcohols are reduced to the aldehydes using NADH. This compound is called retinal. Retinal is then reduced to retinol by the enzyme retinol dehydrogenase. Retinol dehydrogenase is an enzyme that is dependent on NADH.
Biological role.
Role in embryology.
Retinoic acid via the retinoic acid receptor influences the process of cell differentiation, hence, the growth and development of embryos. During development there is a concentration gradient of retinoic acid along the anterior-posterior (head-tail) axis. Cells in the embryo respond to retinoic acid differently depending on the amount present. For example, in vertebrates the hindbrain transiently forms eight rhombomers and each rhombomere has a specific pattern of genes being expressed. If retinoic acid is not present the last four rhombomeres do not develop. Instead rhombomeres 1–4 grow to cover the same amount of space as all eight would normally occupy. Retinoic acid has its effects by turning on a differential pattern of Hox genes which encode different homeodomain transcription factors which in turn can turn on cell type specific genes. Deletion of the Hox-1 gene from rhombomere 4 makes the neurons growing in that region behave like neurons from rhombomere 2. Retinoic acid is not required for patterning of the retina as originally proposed, but retinoic acid synthesized in the retina is secreted into surrounding mesenchyme where it is required to prevent overgrowth of perioptic mesenchyme which can cause microphthalmia, defects in the cornea and eyelid, and rotation of the optic cup.
Stem cell biology.
Retinoic acid is an influential factor used in differentiation of stem cells to more committed fates, echoing retinoic acid's importance in natural embryonic developmental pathways. It is thought to initiate differentiation into a number of different cell lineages by unsequestering certain sequences in the genome.
It has numerous applications in the experimental induction of stem cell differentiation; amongst these are the differentiation of human embryonic stem cells to posterior foregut lineages and also to functional motor neurons.
Vision.
Vitamin A is converted by the protein RPE65 within the retinal pigment epithelium into 11-cis-retinal. This molecule is then transported into the photoreceptor cells of the retina, where it acts as a light-activated molecular switch within opsin proteins that activates a complex cascade called the visual cycle. This cycle begins with 11-cis retinal absorbing light and isomerizing into all-trans retinal. The change in shape of the molecule after absorbing light in turn changes the configuration of the complex protein rhodopsin, the visual pigment used in low light levels. This represents the first step of the visual cycle. This is why eating foods rich in vitamin A is often said to allow an individual to see in the dark, although the effect they have on one's vision is negligible. In fact, excess vitamin A intake can cause toxicity to the optic nerve and permanent vision loss. 
Epithelial cells.
Vitamin A is essential for the correct functioning of epithelial cells. In vitamin A deficiency, mucus-secreting cells are replaced by keratin producing cells, leading to xerosis. 
Glycoprotein synthesis.
Glycoprotein synthesis requires adequate vitamin A status. In severe vitamin A deficiency, lack of glycoproteins may lead to corneal ulcers or liquefaction. 
Immune system.
Vitamin A is essential to maintain intact epithelial tissues as a physical barrier to infection; it is also involved in maintaining a number of immune cell types from both the innate and acquired immune systems. These include the lymphocytes (B-cells, T-cells, and natural killer cells), as well as many myelocytes (neutrophils, macrophages, and myeloid dendritic cells).
Formation of red blood cells (haematopoiesis).
Vitamin A may be needed for normal haematopoiesis; deficiency causes abnormalities in iron metabolism.
Growth.
Vitamin A affects the production of human growth hormone.
Clinical use.
All retinoid forms of vitamin A are used in cosmetic and medical applications applied to the skin. Retinoic acid, termed Tretinoin in clinical usage, is used in the treatment of acne and keratosis pilaris in a topical cream. An isomer of tretinoin, isotretinoin is also used orally (under the trade names "Accutane" and "Roaccutane"), generally for severe or recalcitrant acne.
Tretinoin, under the alternative name of all-trans retinoic acid (ATRA), is used as chemotherapy for acute promyelocytic leukemia, a subtype of acute myelogenous leukemia. This is because cells of this subtype of leukemia are sensitive to agonists of the retinoic acid receptors (RARs).
Units of measurement.
When referring to dietary allowances or nutritional science, retinol is usually measured in international units (IU). IU refers to biological activity and therefore is unique to each individual compound, however 1 IU of retinol is equivalent to approximately 0.3 micrograms (300 nanograms).
Nutrition.
This vitamin plays an essential role in vision, particularly night vision, normal bone and tooth development, reproduction, and the health of skin and mucous membranes (the mucus-secreting layer that lines body regions such as the respiratory tract). Vitamin A also acts in the body as an antioxidant, a protective chemical that may reduce the risk of certain cancers.
There are two sources of dietary vitamin A. Active forms, which are immediately available to the body are obtained from animal products. These are known as retinoids and include retinaldehyde and retinol. Precursors, also known as provitamins, which must be converted to active forms by the body, are obtained from fruits and vegetables containing yellow, orange and dark green pigments, known as carotenoids, the most well-known being β-carotene. For this reason, amounts of vitamin A are measured in Retinol Equivalents (RE). One RE is equivalent to 0.001 mg of retinol, or 0.006 mg of β-carotene, or 3.3 International Units of vitamin A.
In the intestine, vitamin A is protected from being chemically changed by vitamin E. Vitamin A is fat-soluble and can be stored in the body. Most of the vitamin A consumed is stored in the liver. When required by a particular part of the body, the liver releases some vitamin A, which is carried by the blood and delivered to the target cells and tissues.
Dietary intake.
The Dietary Reference Intake (DRI) Recommended Daily Amount (RDA) for vitamin A for a 25-year-old male is 900 micrograms/day, or 3000 IU. NHS daily recommended values are slightly lower at 700 micrograms for men and 600 micrograms.
Estimates have changed over time of the rate at which β-carotene is converted to vitamin A in the human body. An early estimate of 6:1 was revised to 12:1 and from recent studies and experimental trials carried out in developing nations it was revised again to 21:1. The implication of the reduced estimate is that larger quantities of β-carotene are needed to yield the necessary dietary requirement of vitamin A. This means that more continents are affected by the deficiency of vitamin A than was previously thought. Changing dietary choices in Africa, Asia, and South America will not be sufficient, and agricultural practices on those continents will need to change.
The Food Standards Agency states that an average adult should not consume more than 1500 micrograms (5000 IU) per day, because this increases the chance of osteoporosis.
During the absorption process in the intestines, retinol is incorporated into chylomicrons as the ester form, and it is these particles that mediate transport to the liver. Liver cells (hepatocytes) store vitamin A as the ester, and when retinol is needed in other tissues, it is de-esterifed and released into the blood as the alcohol. Retinol then attaches to a serum carrier, retinol binding protein, for transport to target tissues. A binding protein inside cells, cellular retinoic acid binding protein, serves to store and move retinoic acid intracellularly. Carotenoid bioavailability ranges between 1/5 to 1/10 of retinol's. Carotenoids are better absorbed when ingested as part of a fatty meal. Also, the carotenoids in vegetables, especially those with tough cell walls (e.g. carrots), are better absorbed when these cell walls are broken up by cooking or mincing.
Deficiency.
Vitamin A deficiency is common in developing countries but rarely seen in developed countries. Approximately 250,000 to 500,000 malnourished children in the developing world go blind each year from a deficiency of vitamin A. Night blindness is one of the first signs of vitamin A deficiency. Vitamin A deficiency contributes to blindness by making the cornea very dry and damaging the retina and cornea.
Interventions/remedies.
Interventions or remedies in vitamin A deficiency in a deficient population may be enforced using three approaches:(A) through dietary modification involving the adjustment of menu choices of affected persons from available food sources to optimize vitamin A content, (B) enriching commonly eaten and affordable foods with vitamin A, a process called fortification. It involves addition of synthetic vitamin A to staple foods like margarine, bread, flours, cereals and other infant formulae during processing and (C) giving high-doses of vitamin A to the targeted deficient population, a method known as supplementation. Caution should however be exercised when using supplementation as a method of replenishing vitamin A in the body so that upper harmful limits are not attained.
Retinoid overdose (toxicity).
The Tolerable Upper Intake Level (UL) for vitamin A, for a 25-year-old male, is 3,000 micrograms/day, or about 10,000 IU.
Too much vitamin A in retinoid form can be harmful or fatal, resulting in what is known as hypervitaminosis A. The body converts the dimerized form, carotene, into vitamin A as it is needed, therefore high levels of carotene are not toxic compared to the ester (animal) forms. The livers of certain animals, especially those adapted to polar environments, often contain amounts of vitamin A that would be toxic to humans. Thus, vitamin A toxicity is typically reported in Arctic explorers and people taking large doses of synthetic vitamin A. The first documented death due to vitamin A poisoning was Xavier Mertz, a Swiss scientist who died in January 1913 on an Antarctic expedition that had lost its food supplies and fell to eating its sled dogs. Mertz consumed lethal amounts of vitamin A by eating the dogs' livers.
Vitamin A toxicity occurs when an individual ingests vitamin A in large amounts more than the daily recommended value in the threshold of 25,000 IU/Kg or more. Often, the individual consumes about 3–4 times the RDA's specification. Toxicity of vitamin A is believed to be associated with the intervention methods used to upgrade vitamin A levels in the body such as food modification, fortification and supplementation, all of which are employed to combat vitamin A deficiency Toxicity is classified into two categories: acute and chronic toxicities. The former occurs few hours or days after ingestion of large amounts of vitamin A accidentally or via inappropriate therapy. The later toxicity (Chronic) takes place when about 25,000 IU/Kg or more of vitamin A is consumed for a prolonged period of time. Symptoms associated with both toxicities include, but not limited to nausea, blurred vision, fatigue, weight-loss, menstrual abnormalities etc.
Excess vitamin A has also been suspected to be a contributor to osteoporosis. This seems to happen at much lower doses than those required to induce acute intoxication. Only preformed vitamin A can cause these problems, because the conversion of carotenoids into vitamin A is downregulated when physiological requirements are met. An excessive uptake of carotenoids can, however, cause carotenosis.
Dietary supplementation with β-carotene was interestingly associated with an increase in lung cancer when it was studied in a lung cancer prevention trial in male smokers. In non-smokers, the opposite effect has been noted.
Excess preformed vitamin A during early pregnancy has also been associated with a significant increase in birth defects. These defects may be severe, even life-threatening. Even twice the daily recommended amount can cause severe birth defects. The FDA currently recommends that pregnant women get their vitamin A from foods containing β-carotene and that they should ensure that they consume no more than 5,000 IU of preformed vitamin A (if any) per day. Although vitamin A is necessary for fetal development, most women carry stores of vitamin A in their fat cells, so oversupplementation should be strictly avoided.
A review of all randomized controlled trials in the scientific literature by the Cochrane Collaboration published in JAMA in 2007 found that supplementation with β-carotene or vitamin A "increased" mortality by 5% and 16%, respectively.
Contrary to earlier observations, recent studies emerging from some developing countries (India, Bangladesh and Indonesia) have strongly suggested that dosing expectant mothers in the population in which vitamin A deficiency is common and maternal mortality is high can greatly reduce the maternal mortality rate. Similarly, dosing newborn infants with 50,000 IU (15 mg) of vitamin A within 2 days of birth, can significantly reduce neonatal mortality.
Sources.
All sources of vitamin A can provide retinol, but retinoids are found naturally in some foods of animal origin. Each of the following contains at least 0.15 mg of retinoids per 1.75 -:
Synthetic sources.
Synthetic retinol is marketed under the following trade names: Acon, Afaxin, Agiolan, Alphalin, Anatola, Aoral, Apexol, Apostavit, Atav, Avibon, Avita, Avitol, Axerol, Dohyfral A, Epiteliol, Nio-A-Let, Prepalin, Testavol, Vaflol, Vi-Alpha, Vitpex, Vogan, and Vogan-Neu.
There are three known routes to retinol that are used industrially, all of which start with β-ionone.
Night vision.
Night blindness—the inability to see well in dim light—is associated with a deficiency of vitamin A. At first, the most light sensitive (containing more retinal) protein rhodopsin is influenced. Less pigmented retinal iodopsins (three forms/colors in humans), responsible for color vision and sensing relatively high light intensities (day vision), are less impaired at early stages of the vitamin A deficiency. All these protein-pigment complexes are located in the light-sensing cells in eye's retina.
When stimulated by light, rhodopsin splits into a protein and a cofactor: opsin and all-"trans"-retinal (a form of vitamin A). The regeneration of active rhodopsin requires opsin and 11-"cis"-retinal. The regeneration of 11-"cis"-retinal occurs in vertebrates via a sequence of chemical transformations that constitute "the visual cycle" and which occurs primarily in the retinal pigmented epithelial cells.
Without adequate amounts of retinal, regeneration of rhodopsin is incomplete and night blindness occurs.
Genetically engineered vitamin A enriched rice.
Because of the high prevalence of vitamin A deficiency in developing countries, there are efforts to produce genetically modified rice rich in β-carotene. The idea is that this would help poor people, who can not afford a varied diet containing sufficient natural sources of vitamin A, meet their dietary needs. The golden rice project is one such effort, and is already undergoing trials.

</doc>
<doc id="54116" url="http://en.wikipedia.org/wiki?curid=54116" title="Fortune-telling">
Fortune-telling

Fortune-telling is the practice of predicting information about a person's life. The scope of fortune-telling is in principle identical with the practice of divination. The difference is that divination is the term used for predictions considered part of a religious ritual, invoking deities or spirits, while the term fortune-telling implies a less serious or formal setting, even one of popular culture, where belief in occult workings behind the prediction is less prominent than the concept of suggestion, spiritual or practical advisory or affirmation.
Historically, fortune-telling grows out of folkloristic reception of Renaissance magic, specifically associated with Romani people. During the 19th and 20th century, methods of divination from non-Western cultures, such as the I Ching, were also adopted as methods of fortune-telling in western popular culture.
An example of divination or fortune-telling as purely an item of pop culture, with little or no vestiges of belief in the occult, would be the "Magic 8-Ball" sold as a toy by Mattel, or Paul II, an octopus at the Sea Life Aquarium at Oberhausen used to predict the outcome of matches played by the German national football team.
There is opposition against fortune-telling in Christianity, Islam and Judaism based on biblical prohibitions against divination. This sometimes causes discord in the Jewish community due to their views on mysticism.
Methods.
Common methods used for fortune telling in Europe and the Americas include astromancy, horary astrology, pendulum reading, spirit board reading, tasseography (reading tea leaves in a cup), cartomancy (fortune telling with cards), tarot reading, crystallomancy (reading of a crystal sphere), and chiromancy (palmistry, reading of the palms). The last three have traditional associations in the popular mind with the Roma and Sinti people (often called "gypsies").
Another form of fortune-telling, sometimes called "reading" or "spiritual consultation", does not rely on specific devices or methods, but rather the practitioner gives the client advice and predictions which are said to have come from spirits or in visions.
Sociology.
Western fortune-tellers typically attempt predictions on matters such as future romantic, financial, and childbearing prospects. 
Many fortune-tellers will also give "character readings". These may use numerology, graphology, palmistry (if the subject is present), and astrology.
In contemporary Western culture, it appears that women consult fortune-tellers more than men. Some women maintain decades-long relationships with their personal readers. Telephone consultations with psychics (at very high rates) grew in popularity through the 1990s but they have not replaced traditional methods.
As a business in North America.
Discussing the role of fortune-telling in society, Ronald H. Isaacs, an American rabbi and author, opined, "Since time immemorial humans have longed to learn that which the future holds for them. Thus, in ancient civilization, and even today with fortune telling as a true profession, humankind continues to be curious about its future, both out of sheer curiosity as well as out of desire to better prepare for it."
Popular media outlets like the New York Times have explained to their American readers that although 5000 years ago, soothsayers were prized advisers to the Assyrians, they lost respect and reverence during the rise of Reason in the 17th and 18th centuries.
With the rise of commercialism, "the sale of occult practices [adapted to survive] in the larger society," according to sociologists Danny L. and Lin Jorgensen. Ken Feingold, writer of "Interactive Art as Divination as a Vending Machine," stated that with the invention of money, fortune-telling became "a private service, a commodity within the marketplace".
As J. Peder Zane wrote in the New York Times in 1994, "Whether it’s 3 P.M. or 3 A.M., there’s Dionne Warwick and her psychic friends selling advice on love, money and success. In a nation where the power of crystals and the likelihood that angels hover nearby prompt more contemplation than ridicule, it may not be surprising that one million people a year call Ms. Warwick’s friends." 
Clientele.
In 1994, the psychic counsellor Rosanna Rogers of Cleveland, Ohio explained to J. Peder Zane that a wide variety of people consulted her: "Couch potatoes aren’t the only people seeking the counsel of psychics and astrologers. Clairvoyants have a booming business advising Philadelphia bankers, Hollywood lawyers and CEO’s of Fortune 500 companies... If people knew how many people, especially the very rich and powerful ones, went to psychics, their jaws would drop through the floor." Ms. Rogers "claims to have 4,000 names in her rolodex."
Typical clients.
In 1982, Danny Jorgensen, a professor of Religious Studies at the University of South Florida offered a spiritual explanation for the popularity of fortune-telling. He said that people visit psychics or fortune-tellers to gain self-understanding. and knowledge which will lead to personal power or success in some aspect of life
In 1995, Ken Feingold offered a different explanation for why people seek out fortune-tellers: "We desire to know other people’s actions and to resolve our own conflicts regarding decisions to be made and our participation in social groups and economies. … Divination seems to have emerged from our knowing the inevitability of death. The idea is clear—we know that our time is limited and that we want things in our lives to happen in accord with our wishes. Realizing that our wishes have little power, we have sought technologies for gaining knowledge of the future...gain power over our own [lives]."
Ultimately, the reasons a person consults a diviner or fortune teller are mediated by cultural expectations and by personal desires, and until a statistically rigorous study of the phenomenon have been conducted, the question of why people consult fortune-tellers is wide open for opinion-making.
Services.
Traditional fortune-tellers vary in methodology, generally using techniques long established in their cultures and thus meeting the cultural expectations of their clientele.
In the United States and Canada, among clients of European ancestry, palmistry is popular and, as with astrology and tarot card reading, advice is generally given about specific problems besetting the client.
Non-religious spiritual guidance may also be offered. An American clairvoyant by the name of Catherine Adams has written, "My philosophy is to teach and practice spiritual freedom, which means you have your own spiritual guidance, which I can help you get in touch with."
In the African American community, where many people practice a form of folk magic called hoodoo or rootworking, a fortune telling session or "reading" for a client may be followed by practical guidance in spell-casting and Christian prayer, through a process called "magical coaching".
In addition to sharing and explaining their visions, fortune-tellers can also act like counselors by discussing and offering advice about their clients’ problems. They want their clients to exercise their own willpower.
Full-time careers.
Some fortune-tellers support themselves entirely on their divination business; others hold down one or more jobs, and their second jobs may or may not relate to the occupation of divining. In 1982, Danny L., and Lin Jorgensen found that "while there is considerable variation among [these secondary] occupations, [part-time fortune-tellers] are over-represented in human service fields: counseling, social work, teaching, health care." The same authors, making a limited survey of North American diviners, found that the majority of fortune-tellers are married with children, and a few claim graduate degrees. "They attend movies, watch television, work at regular jobs, shop at K-Mart, sometimes eat at McDonald’s, and go to the hospital when they are seriously ill."
Legality.
In 1982, the sociologists Danny L., and Lin Jorgensen found that, “when it is reasonable, [fortune -tellers] comply with local laws and purchase a business license.” However, in the United States, a variety of local and state laws restrict fortune-telling, require the licensing or bonding of fortune-tellers, or make necessary the use of terminology that avoids the term "fortune-teller" in favour of terms such as "spiritual advisor" or "psychic consultant." There are also laws that forbid the practice outright in certain districts.
For instance, fortune telling is a class B misdemeanor in the state of New York. Under New York State law, S 165.35:
A person is guilty of fortune telling when, for a fee or compensation which he directly or indirectly solicits or receives, he claims or pretends to tell fortunes, or holds himself out as being able, by claimed or pretended use of occult powers, to answer questions or give advice on personal matters or to exercise, influence or affect evil spirits or curses; except that this section does not apply to a person who engages in the aforedescribed conduct as part of a show or exhibition solely for the purpose of entertainment or amusement.
Law-makers who wrote this statute acknowledged that fortune-tellers do not restrict themselves to "a show or exhibition solely for the purpose of entertainment or amusement" and that people will continue to seek out fortune-tellers even though fortune-tellers operate in violation of the law.
Similarly, in New Zealand, Section 16 of the Summary Offences Act 1981 provides a one thousand dollar penalty for anyone who sets out to "deceive or pretend" for financial recompense that they possess telepathy or clairvoyance or acts as a medium for money through use of "fraudulent devices." As with the New York legislation cited above, however, it is not a criminal offence if it is solely intended for purposes of entertainment.
The Kingdom of Saudi Arabia also bans the practice outright, considering fortune-telling to be sorcery and thus contrary to Islamic teaching and jurisprudence. It has been punishable by death.
External links.
 Media related to at Wikimedia Commons

</doc>
<doc id="54117" url="http://en.wikipedia.org/wiki?curid=54117" title="Folic acid">
Folic acid

IUPACName_hidden= IUPACNames_hidden= IUPACNames= IUPACName= ImageAlt1= ImageAlt2= ImageAlt3= ImageAlt4= ImageAltL1= ImageAltL2= ImageAltL3= ImageAltL4= ImageAltR1= ImageAltR2= ImageAltR3= ImageAltR4= ImageAlt= ImageCaption1= ImageCaption2= ImageCaption3= ImageCaption4= ImageCaptionL1= ImageCaptionL2= ImageCaptionL3= ImageCaptionL4= ImageCaptionR1= ImageCaptionR2= ImageCaptionR3= ImageCaptionR4= ImageCaption= ImageFile1_Ref= ImageFile1= ImageFile2_Ref= ImageFile2= ImageFile3_Ref= ImageFile3= ImageFile4_Ref= ImageFile4= ImageFileL1_Ref= ImageFileL1= ImageFileL2_Ref= ImageFileL2= ImageFileL3_Ref= ImageFileL3= ImageFileL4_Ref= ImageFileL4= ImageFileR1_Ref= ImageFileR1= ImageFileR2_Ref= ImageFileR2= ImageFileR3_Ref= ImageFileR3= ImageFileR4_Ref= ImageFileR4= ImageFile_Ref= ImageFile= ImageName1= ImageName2= ImageName3= ImageName4= ImageNameL1= ImageNameL2= ImageNameL3= ImageNameL4= ImageNameR1= ImageNameR2= ImageNameR3= ImageNameR4= ImageName= ImageSize1= ImageSize2= ImageSize3= ImageSize4= ImageSizeL1= ImageSizeL2= ImageSizeL3= ImageSizeL4= ImageSizeR1= ImageSizeR2= ImageSizeR3= ImageSizeR4= ImageSize= Name= OtherNames= PIN= Reference= Section1= Section2= Section3= Section4= Section5= Section6= Section7= Section8= Section9= SystematicName= Verifiedfields= Watchedfields= general_note= show_infobox_ref= show_ss_note= style-left-column-width= style= verifiedrevid= width= 
Folic acid or folate is a B vitamin. It is also referred to as vitamin M, vitamin B9, vitamin Bc (or folacin), pteroyl-L-glutamic acid, and pteroyl-L-glutamate.
Food supplement manufacturers often use the term "folate" for something different than "pure" folic acid: in chemistry, "folate" refers to the deprotonated ion, and "folic acid" to the neutral molecule—which both co-exist in water. (The International Union of Pure and Applied Chemistry and the International Union of Biochemistry and Molecular Biology state that folate and folic acid are the preferred synonyms for pteroylglutamate and pteroylglutamic acid, respectively.) 
"Folate" indicates a collection of "folates" that is not chemically well-characterized, including other members of the family of pteroylglutamates, or mixtures of them, having various levels of reduction of the pteridine ring, one-carbon substitutions and different numbers of glutamate residues.
Folic acid is synthetically produced, and used in fortified foods and supplements. Folate is converted by humans to dihydrofolate (dihydrofolic acid), tetrahydrofolate (tetrahydrofolic acid), and other derivatives, which have various biological activities.
Vitamin B9 is essential for numerous bodily functions. Humans cannot synthesize folates "de novo"; therefore, folic acid has to be supplied through the diet to meet their daily requirements. The human body needs folate to synthesize DNA, repair DNA, and methylate DNA as well as to act as a cofactor in certain biological reactions. It is especially important in aiding rapid cell division and growth, such as in infancy and pregnancy. Children and adults both require folate to produce healthy red blood cells and prevent anemia.
Folate and folic acid derive their names from the Latin word "", which means "leaf". Folates occur naturally in many foods and, among plants, are especially plentiful in dark green leafy vegetables.
A lack of dietary folates can lead to folate deficiency. A complete lack of dietary folate takes months before deficiency develops as normal individuals have about 500–20,000 µg of folate in body stores. This deficiency can result in many health problems, the most notable one being neural tube defects in developing embryos—a relatively rare birth defect affecting only 300,000 (0.002%) of births globally each year. Common symptoms of folate deficiency include diarrhea, macrocytic anemia with weakness or shortness of breath, nerve damage with weakness and limb numbness (peripheral neuropathy), pregnancy complications, mental confusion, forgetfulness or other cognitive deficits, mental depression, sore or swollen tongue, peptic or mouth ulcers, headaches, heart palpitations, irritability, and behavioral disorders. Low levels of folate can also lead to homocysteine accumulation. Low levels of folate have been associated with specific cancers. However, it is not clear whether consuming recommended (or higher) amounts of folic acid—from foods or in supplements—can lower cancer risk in some people.
Health benefits and risks.
Pregnancy.
Adequate folate intake during the preconception period (which is the time right before and just after a woman becomes pregnant) helps protect against a number of congenital malformations, including neural tube defects (which are the most notable birth defects that occur from folate deficiency). Neural tube defects are severe abnormalities of the central nervous system that develop in embryos during the first few weeks of pregnancy resulting in malformations of the spine, skull, and brain; the most common neural tube defects are spina bifida and anencephaly. The risk of neural tube defects is significantly reduced when supplemental folic acid is consumed in addition to a healthy diet before conception and during the first month after conception. Supplementation with folic acid has also been shown to reduce the risk of congenital heart defects, cleft lips, limb defects, and urinary tract anomalies. Folate deficiency during pregnancy may also increase the risk of preterm delivery, infant low birth weight and fetal growth retardation, as well as increasing homocysteine level in the blood, which may lead to spontaneous abortion and pregnancy complications, such as placental abruption and pre-eclampsia. Women who could become pregnant are advised to eat foods fortified with folic acid or take supplements in addition to eating folate-rich foods to reduce the risk of serious birth defects. Some have suggested that all non-pregnant women take 400 micrograms of synthetic folic acid daily from fortified foods or supplements to ensure they have adequate folic acid intake, even in case of unplanned pregnancies. The RDA for folate equivalents for pregnant women is set at 600 micrograms, although a range of 400 micrograms up to 4 milligrams (4000 micrograms) reported in an old U.S. Public Health Service guideline is still followed by many health care providers.
The mechanisms and reasons why folic acid prevents birth defects is unknown. It is hypothesized that the insulin-like growth factor 2 gene is differentially methylated and these changes in IGF2 result in improved intrauterine growth and development. Failure of post-translational methylation of the cytoskeleton, required for differentiation has been implicated in neural tube defects.<Approximately 85% of women in an urban Irish study reported using folic acid supplements before they become pregnant, but only 18% used enough folic acid supplements to meet the current folic acid requirements due, it is reported, to socio-economic challenges. Folic acid supplements may also protect the fetus against disease when the mother is battling a disease or taking medications or smoking during pregnancy.
It also contributes to oocyte maturation, implantation, placentation, in addition to the general effects of folic acid and pregnancy. Therefore, it is necessary to receive sufficient amounts through the diet to avoid subfertility.
There is growing concern worldwide that prenatal high folic acid in the presence of low vitamin B12 causes epigenetic changes in the unborn predisposing them to metabolic syndromes, central adiposity and adult diseases such as Type 2 diabetes. Another active area of research and concern is that either too much or too little folic acid in utero causes epigenetic changes to the brain leading to autism spectrum disorders. Epidemiologic studies have been demonstrating a correlation between maternal folic supplementation with folic acid and increased risk for asthma and respiratory diseases in children. However, a systematic review and meta-analysis did not confirm such findings and recommends additional studies to verify the hypothesis. 
Fertility.
Folate is necessary for fertility in both men and women. It contributes to spermatogenesis. Therefore, it is necessary to receive sufficient amounts through the diet to avoid subfertility. Also, polymorphisms in genes of enzymes involved in folate metabolism could be one reason for fertility complications in some women with unexplained infertility.
Heart disease.
Taking folic acid does not reduce cardiovascular disease even though it reduces homocysteine levels.
Folic acid supplements consumed before and during pregnancy may reduce the risk of heart defects in infants.
Stroke.
Folic acid appears to reduce the risk of stroke, which may be due to the role folate plays in regulating homocysteine concentration. The reviews indicate the risk of stroke appears to be reduced only in some individuals, but a definite recommendation regarding supplementation beyond the current RDA has not been established for stroke prevention. Observed stroke reduction is consistent with the reduction in pulse pressure produced by folate supplementation of 5 mg per day, since hypertension is a key risk factor for stroke. Folic supplements are inexpensive and relatively safe to use, which is why stroke or hyperhomocysteinemia patients are encouraged to consume daily B vitamins including folic acid.
Cancer.
Folic acid supplementation does not appear to affect the rate of cancer.
Diets high in folate are associated with decreased risk of colorectal cancer; some studies show the association is stronger for folate from foods alone than for folate from foods and supplements, One broad cancer screening trial reported a potential harmful effect of too much folate intake on breast cancer risk, suggesting routine folate supplementation should not be recommended as a breast cancer preventive. Most research studies indicate that dietary folate intake does not significantly increase or decrease the risk of prostate cancer.
Antifolate chemotherapy.
Folate is important for cells and tissues that rapidly divide. Cancer cells divide rapidly, and drugs that interfere with folate metabolism are used to treat cancer. The antifolate methotrexate is a drug often used to treat cancer because it inhibits the production of the active form of THF from the inactive dihydrofolate (DHF). However, methotrexate can be toxic,
producing side effects, such as inflammation in the digestive tract that make it difficult to eat normally. Also, bone marrow depression (inducing leukopenia and thrombocytopenia), and acute kidney and liver failure have been reported.
Folinic acid, under the drug name leucovorin, a form of folate (formyl-THF), can help "rescue" or reverse the toxic effects of methotrexate.
Folinic acid is "not" the same as folic acid. Folic acid supplements have little established role in cancer chemotherapy.
There have been cases of severe adverse effects of accidental substitution of folic acid for folinic acid in patients receiving methotrexate cancer chemotherapy. It is important for anyone receiving methotrexate to follow medical advice on the use of folic or folinic acid supplements. The supplement of folinic acid in patients undergoing methotrexate treatment is to give cells dividing less rapidly enough folate to maintain normal cell functions. The amount of folate given is depleted by rapidly dividing cells (cancer) quickly, and so does not negate the effects of methotrexate.
Psychological.
Some evidence links a shortage of folate with depression.
Limited evidence from randomised controlled trials showed using folic acid in addition to SSRIs may have benefits. Research at the University of York and Hull York Medical School has found a link between depression and low levels of folate. One study by the same team involved 15,315 subjects. However, the evidence is probably too limited at present for this to be a routine treatment recommendation.
Folic acid supplementation affects noradrenaline and serotonin receptors within the brain, which could be the cause of folic acid's possible ability to act as an antidepressant. The exact mechanisms involved in the development of schizophrenia and depression are not entirely clear, but the bioactive folate, methyltetrahydrofolate (5-MTHF), a direct target of methyl donors like S-adenosyl methionine (SAMe), recycles the inactive dihydrobiopterin (BH2) into tetrahydrobiopterin (BH4), the necessary cofactor in various steps of monoamine synthesis, including that of dopamine. BH4 serves a regulatory role in monoamine neurotransmission and is required to mediate the actions of most antidepressants. 5-MTHF also plays both direct & indirect roles in DNA methylation, NO2 synthesis, and one-carbon metabolism.
Macular degeneration.
A substudy of the Women's Antioxidant and Folic Acid Cardiovascular Study published in 2009 reported use of a nutritional supplement containing folic acid, pyridoxine, and cyanocobalamin decreased the risk of developing age-related macular degeneration by 34.7%.
Folic Acid, B12 and Iron.
There is a complex interaction between folic acid, vitamin B12 and iron. A deficiency of one may be "masked" by excess of another so the three must always be in balance.
Toxicity.
The risk of toxicity from folic acid is low, because folate is a water-soluble vitamin and is regularly removed from the body through urine. One potential issue associated with high dosages of folic acid is that it has a masking effect on the diagnosis of pernicious anaemia (vitamin B12 deficiency), and a variety of concerns of potential negative impacts on health.
Folate deficiency.
Folate deficiency may lead to glossitis, diarrhea, depression, confusion, anemia, and fetal neural tube defects and brain defects (during pregnancy). Folate deficiency is accelerated by alcohol consumption. Folate deficiency is diagnosed by analyzing CBC and plasma vitamin B12 and folate levels. CBC may indicate megaloblastic anemia but this could also be a sign of vitamin B12 deficiency. A serum folate of 3 μg/L or lower indicates deficiency. Serum folate level reflects folate status but erythrocyte folate level better reflects tissue stores after intake. Serum folate reacts
more rapidly to folate intake than erythrocyte folate An erythrocyte folate level of 140 μg/L or lower indicates inadequate folate status. Increased homocysteine level suggests tissue folate deficiency but homocysteine is also affected by vitamin B12 and vitamin B6, renal function, and genetics.
One way to differentiate between folate deficiency from vitamin B12 deficiency is by testing for methylmalonic acid levels. Normal MMA levels indicate folate deficiency and elevated MMA levels indicate vitamin B12 deficiency. Folate deficiency is treated with supplemental oral folate of 400 to 1000 μg per day. This treatment is very successful in replenishing tissues, even if deficiency was caused by malabsorption. Patients with megaloblastic anemia need to be tested for vitamin B12 deficiency before folate treatment, because if the patient has vitamin B12 deficiency, folate supplementation can remove the anemia, but can also worsen neurologic problems. Morbidly obese patients with BMIs of greater than 50 are more likely to develop folate deficiency.
Patients with celiac disease have a higher chance of developing folate deficiency.
Cobalamin deficiency may lead to folate deficiency, which, in turn, increases homocysteine levels and may result in the development of cardiovascular disease or birth defects.
Malaria.
Some studies show iron-folic acid supplementation in children under 5 may result in increased mortality due to malaria; this has prompted the World Health Organization to alter their iron-folic acid supplementation policies for children in malaria-prone areas, such as India.
Dietary reference intake.
Because of the difference in bioavailability between supplemented folic acid and the different forms of folate found in food, the dietary folate equivalent (DFE) system was established. One DFE is defined as 1 μg (microgram) of dietary folate, or 0.6 μg of folic acid supplement.
The Dietary Reference Intake (DRIs) were developed by the United States National Academy of Sciences to set reference values for planning and assessing nutrient intake for healthy people. DRIs incorporate two reference values, the Reference Daily Intake (RDI, the daily intake level that is adequate for 97–98% of the population in the United States where the standards were set) and tolerable upper intake levels (UL, the highest level of intake that is known to avoid toxicity). The UL for folate refers to only synthetic folate, as no health risks have been associated with high intake of folate from food sources.
Sources.
Folate naturally occurs in a wide variety of foods, including vegetables (particularly dark green leafy vegetables), fruits and fruit juices, nuts, beans, peas, dairy products, poultry and meat, eggs, seafood, grains, and some beers. Avocado, spinach, liver, yeast, asparagus, and Brussels sprouts are among the foods with the highest levels of folate.
Folic acid is added to grain products in many countries, and in these countries, fortified products make up a significant source of the population's folic acid intake. Because of the difference in bioavailability between supplemented folic acid and the different forms of folate found in food, the dietary folate equivalent (DFE) system was established. 1 DFE is defined as 1 μg of dietary folate, or 0.6 μg of folic acid supplement. This is reduced to 0.5 μg of folic acid if the supplement is taken on an empty stomach.
Folate naturally found in food is susceptible to high heat and ultraviolet light, and is soluble in water. It is heat-labile in acidic environments and may also be subject to oxidation.
Some meal replacement products do not meet the folate requirements as specified by the RDAs.
Folate (B9) can also be processed from the pro-vitamin Pteroylmonoglutamic acid (Vitamin B10).
History.
In the 1920s, scientists believed folate deficiency and anemia were the same condition. In 1931, researcher Lucy Wills made a key observation that led to the identification of folate as the nutrient required to prevent anemia during pregnancy. Dr. Wills demonstrated that anemia could be reversed with brewer's yeast. In the late 1930s, folate was identified as the corrective substance in brewer's yeast. 
It was first isolated in and extracted from spinach leaves by Mitchell and others in 1941. Bob Stokstad isolated the pure crystalline form in 1943, and was able to determine its chemical structure while working at the Lederle Laboratories of the American Cyanamid Company. This historical research project, of obtaining folic acid in a pure crystalline form in 1945, was done by the team called the "folic acid boys," under the supervision and guidance of Director of Research Dr. Yellapragada Subbarow, at the Lederle Lab, Pearl River, NY. 
This research subsequently led to the synthesis of the antifolate aminopterin, the first-ever anticancer drug, the clinical efficacy was proven by Sidney Farber in 1948. In the 1950s and 1960s, scientists began to discover the biochemical mechanisms of action for folate. In 1960, experts first linked folate deficiency to neural tube defects. In the late 1990s, US scientists realized, despite the availability of folate in foods and in supplements, there was still a challenge for people to meet their daily folate requirements, which is when the US implemented the folate fortification program.
Biological roles.
DNA and cell division.
Folate is necessary for the production and maintenance of new cells, for DNA synthesis and RNA synthesis, and for preventing changes to DNA, and, thus, for preventing cancer. It is especially important during periods of frequent cell division and growth, such as infancy and pregnancy. Folate is needed to carry one-carbon groups for methylation reactions and nucleic acid synthesis (the most notable one being thymine, but also purine bases). Thus, folate deficiency hinders DNA synthesis and cell division, affecting hematopoietic cells and neoplasms the most because of their greater frequency of cell division. RNA transcription, and subsequent protein synthesis, are less affected by folate deficiency, as the mRNA can be recycled and used again (as opposed to DNA synthesis, where a new genomic copy must be created). Since folate deficiency limits cell division, erythropoiesis, production of red blood cells, is hindered and leads to megaloblastic anemia, which is characterized by large immature red blood cells. This pathology results from persistently thwarted attempts at normal DNA replication, DNA repair, and cell division, and produces abnormally large red cells called megaloblasts (and hypersegmented neutrophils) with abundant cytoplasm capable of RNA and protein synthesis, but with clumping and fragmentation of nuclear chromatin. Some of these large cells, although immature (reticulocytes), are released early from the marrow in an attempt to compensate for the anemia. Both adults and children need folate to make normal red and white blood cells and prevent anemia. Deficiency of folate in pregnant women has been implicated in neural tube defects (NTD); therefore, many developed countries have implemented mandatory folic acid fortification in cereals, etc. NTDs occur early in pregnancy (first month), therefore women must have abundant folate upon conception. Folate is required to make red blood cells and white blood cells and folate deficiency may lead to anemia, which causes fatigue, weakness and inability to concentrate.
Biochemistry of DNA base and amino acid production.
In the form of a series of tetrahydrofolate (THF) compounds, folate derivatives are substrates in a number of single-carbon-transfer reactions, and also are involved in the synthesis of dTMP (2′-deoxythymidine-5′-phosphate) from dUMP (2′-deoxyuridine-5′-phosphate). It is a substrate for an important reaction that involves vitamin B12 and it is necessary for the synthesis of DNA, and so required for all dividing cells.
The pathway leading to the formation of tetrahydrofolate (FH4) begins when folic acid (F) is reduced to dihydrofolate (DHF) (FH2), which is then reduced to THF. Dihydrofolate reductase catalyses the last step. Vitamin B3 in the form of NADPH is a necessary cofactor for both steps of the synthesis. Thus, hydride molecules are transferred from NADPH to the C6 position of the pteridine ring to reduce folic acid to THF.
Methylene-THF (CH2FH4) is formed from THF by the addition of a methylene bridge from one of three carbon donors: formate, serine, or glycine. Methyl tetrahydrofolate (CH3-THF, or methyl-THF) can be made from methylene-THF by reduction of the methylene group with NADPH.
Another form of THF, 10-formyl-THF, results from oxidation of methylene-THF or is formed from formate donating formyl group to THF. Also, histidine can donate a single carbon to THF to form methenyl-THF.
Vitamin B12 is the only acceptor of methyl-THF, and this reaction produces methyl-B12 (methylcobalamin). There is also only one acceptor for methyl-B12, homocysteine, in a reaction catalyzed by homocysteine methyltransferase. These reactions are important because a defect in homocysteine methyltransferase or a deficiency of B12 may lead to a so-called "methyl-trap" of THF, in which THF converts to a reservoir of methyl-THF. Thereafter, this THE has no way of being metabolized, and serves as a sink of THF that causes a subsequent deficiency in folate. Thus, a deficiency in B12 can generate a large pool of methyl-THF that is unable to undergo reactions and mimics folate deficiency.
The reactions that lead to the methyl-THF reservoir can be shown in chain form:
Conversion to biologically active derivatives.
All the biological functions of folic acid are performed by tetrahydrofolate and other derivatives. Their biological availability to the body depends upon dihydrofolate reductase action in the liver. This action is unusually slow in humans, being less than 2% of that in rats. Moreover, in contrast to rats, an almost-5-fold variation in the activity of this enzyme exists between humans. Due to this low activity, it has been suggested this limits the conversion of folic acid into its biologically active forms "when folic acid is consumed at levels higher than the Tolerable Upper Intake Level (1 mg/d for adults)."
Overview of drugs that interfere with folate reactions.
A number of drugs interfere with the biosynthesis of folic acid and THF. Among them are the such as trimethoprim, pyrimethamine, and methotrexate; the sulfonamides (competitive inhibitors of 4-aminobenzoic acid in the reactions of dihydropteroate synthetase).
Valproic acid, one of the most commonly prescribed anticonvulsants that is also used to treat certain psychological conditions, is a known inhibitor of folic acid, and as such, has been shown to cause neural tube defects and cases of spina bifida and cognitive impairment in the newborn. Because of this considerable risk, those mothers who must continue to use valproic acid or its derivatives during pregnancy to control their condition (as opposed to stopping the drug or switching to another drug or to a lesser dose) should take folic acid supplements under the direction and guidance of their health care providers.
The National Health and Nutrition Examination Survey (NHANES III 1988–91) and the Continuing Survey of Food Intakes by Individuals (1994–96 CSFII) indicated most adults did not consume adequate folate.
However, the folic acid fortification program in the United States has increased folic acid content of commonly eaten foods such as cereals and grains, and as a result, diets of most adults now provide recommended amounts of folate equivalents.
Dietary fortification.
"Folic acid fortification" is a process where folic acid is added to flour with the intention of promoting public health through increasing blood folate levels in the populace. In the USA, food is fortified with folic acid, only one of the many naturally-occurring forms of folate, and a substance contributing only a minor amount to the folates in natural foods.
Since the discovery of the link between insufficient folic acid and neural tube defects, governments and health organizations worldwide have made recommendations concerning folic acid "supplementation" for women intending to become pregnant.
Fortification is controversial, with issues having been raised concerning individual liberty, as well as the health concerns described in the Toxicity section above. In the USA, there is concern that the federal government mandates fortification, but does not provide monitoring of potential undesirable effects of fortification.
76 countries worldwide require mandatory folic acid fortification of at least one major cereal grain, with nearly all fortifying at least wheat flour, according to November 2013 data from the Flour Fortification Initiative. These countries are:
As of November 2013, no EU country has mandated folic acid fortification.
Australia.
There has been previous debate in Australia regarding the inclusion of folic acid in products such as bread and flour.
Australia and New Zealand have jointly agreed to fortification though the Food Standards Australia New Zealand. Australia will fortify all flour from 18 September 2009. Although the food standard covers both Australia and New Zealand, an Australian government official has stated it is up to New Zealand to decide whether to implement it there, and they will watch with interest.
The requirement is 0.135 mg of folate per 100g of bread.
Canada.
In 2003, a Hospital for Sick Children, University of Toronto research group published findings showing the fortification of flour with folic acid in Canada has resulted in a dramatic decrease in neuroblastoma, an early and very dangerous cancer in young children. In 2009, further evidence from McGill University showed a 6.2% decrease per year in the birth prevalence of severe congenital heart defects.
Folic acid used in fortified foods is a synthetic form called pteroylmonoglutamate. It is in its oxidized state and contains only one conjugated glutamate residue. Folic acid therefore enters via a different carrier system from naturally occurring folate, and this may have different effects on folate binding proteins and its transporters. Folic acid has a higher bioavailability than natural folates and are rapidly absorbed across the intestine, therefore it is important to consider the Dietary Folate Equivalent (DFE) when calculating one's intake. Natural occurring folate is equal to 1 DFE, however 0.6 µg of folic acid is equal to 1 DFE.
Folic acid food fortification became mandatory in Canada in 1998, with the fortification of 150 µg of folic acid per 100 grams of enriched flour and uncooked cereal grains. The purpose of fortification was to decrease the risk of neural tube defects in newborns. It is important to fortify grains because it is a widely eaten food and the neural tube closes in the first four weeks of gestation, often before many women even know they are pregnant.
Canada's fortification program has been successful with a decrease of neural tube defects by 19% since its introduction. A seven-province study from 1993 to 2002 showed a reduction of 46% in the overall rate of neural tube defects after folic acid fortification was introduced in Canada.
The fortification program was estimated to raise a person’s folic acid intake level by 70–130 µg/day, however an increase of almost double that amount was actually observed. This could be from the fact that many foods are over fortified by 160–175% the predicted value. In addition, much of the elder population take supplements that adds 400 µg to their daily folic acid intake. This is a concern because 70–80% of the population have detectable levels of unmetabolized folic acid in their blood and high intakes can accelerate the growth of preneoplasmic lesions. It is still unknown the amount of folic acid supplementation that might cause harm.
Supplementation promotion.
According to a Canadian survey, 58% of women said they took a folic acid containing multivitamin or a folic acid supplement as early as three months before becoming pregnant. Women in higher income households and with more years of school education are using more folic acid supplements before pregnancy. Women with planned pregnancies and who are over the age of 25 are more likely to use folic acid supplement. Canadian public health efforts are focused on promoting awareness of the importance of folic acid supplementation for all women of childbearing age and decreasing socio-economic inequalities by providing practical folic acid support to vulnerable groups of women.
New Zealand.
New Zealand was planning to fortify bread (excluding organic and unleavened varieties) from 18 September 2009, but has opted to wait until more research is done.
The Association of Bakers and the Green Party have opposed mandatory fortification, describing it as "mass medication". Food Safety Minister Kate Wilkinson reviewed the decision to fortify in July 2009, citing links between overconsumption of folate with cancer . The New Zealand Government is reviewing whether it will continue with the mandatory introduction of folic acid to bread.
United Kingdom.
There has been previous debate in the United Kingdom regarding the inclusion of folic acid in products such as bread and flour. While the Food Standards Agency has recommended folic acid fortification, and wheat flour is fortified with iron, folic acid fortification of wheat flour is allowed voluntarily rather than required.
United States.
The United States Public Health Service recommends an extra 0.4 mg/day for newly pregnant women, which they can take as a pill. However, many researchers believe this supplementation can never work effectively enough, since about half of all pregnancies in the U.S. are unplanned, and not all women comply with the recommendation. Approximately 53% of the US population uses dietary supplements and 35% uses dietary supplements that contain folic acid. 
Men consume more folate (in dietary folate equivalents) than women, and non-Hispanic whites have higher folate intakes than Mexican Americans and non-Hispanic blacks. Twenty-nine percent of black women have inadequate intakes of folate. The age group consuming the most folate and folic acid is the >50 group. 5% of the population exceeds the Tolerable Upper Intake Level.
In 1996, the United States Food and Drug Administration (FDA) published regulations requiring the addition of folic acid to enriched breads, cereals, flours, corn meals, pastas, rice, and other grain products.
This ruling took effect on January 1, 1998, and was specifically targeted to reduce the risk of neural tube birth defects in newborns. There are concerns that the amount of folate added is insufficient . In October 2006, the Australian press claimed that U.S. regulations requiring fortification of grain products were being interpreted as disallowing fortification in non-grain products, specifically Vegemite (an Australian yeast extract containing folate). The FDA later said the report was inaccurate, and no ban or other action was being taken against Vegemite.
As a result of the folic acid fortification program, fortified foods have become a major source of folic acid in the American diet. The Centers for Disease Control and Prevention in Atlanta, Georgia used data from 23 birth defect registries covering about half of United States births, and extrapolated their findings to the rest of the country. These data indicate that, since the addition of folic acid in grain-based foods as mandated by the FDA, the rate of neural tube defects dropped by 25% in the United States. The results of folic acid fortification on the rate of neural tube defects in Canada have also been positive, showing a 46% reduction in prevalence of NTDs; the magnitude of reduction was proportional to the prefortification rate of NTDs, essentially removing geographical variations in rates of NTDs seen in Canada before fortification.
When the U.S. Food and Drug Administration set the folic acid fortification regulation in 1996, the projected increase in folic acid intake was 100 µg/d. Data from a study with 1480 subjects showed that folic acid intake increased by 190 µg/d and total folate intake increased by 323 µg dietary folate equivalents (DFE)/d. Folic acid intake above the upper tolerable intake level (1000 µg folic acid/d) increased only among those individuals consuming folic acid supplements as well as folic acid found in fortified grain products. Taken together, folic acid fortification has led to a bigger increase in folic acid intake than first projected.

</doc>
<doc id="54118" url="http://en.wikipedia.org/wiki?curid=54118" title="Biotin">
Biotin

Biotin, also known as vitamin H or coenzyme R, is a water-soluble B-vitamin (vitamin B7).
It is composed of a ureido (tetrahydroimidizalone) ring fused with a tetrahydrothiophene ring. A valeric acid substituent is attached to one of the carbon atoms of the tetrahydrothiophene ring. Biotin is a coenzyme for carboxylase enzymes, involved in the synthesis of fatty acids, isoleucine, and valine, and in gluconeogenesis.
The only human health condition for which there is strong evidence of biotin's potential benefit as a treatment is biotin deficiency.
General overview.
Biotin is necessary for cell growth, the production of fatty acids, and the metabolism of fats and amino acids. Biotin assists in various metabolic reactions involving the transfer of carbon dioxide. It may also be helpful in maintaining a steady blood sugar level. Biotin is often recommended as a dietary supplement for strengthening hair and nails, though scientific data supporting this outcome are weak. In addition to being taken as a supplement, many health & beauty products include biotin as an alternative supplement method. Nevertheless, biotin is found in many cosmetics and health products for the hair and skin.
Biotin deficiency is rare because, in general, intestinal bacteria produce biotin in excess of the body's daily requirements. For that reason, statutory agencies in many countries, for example the USA and Australia, do not prescribe a recommended daily intake of biotin. However, a number of metabolic disorders exist in which an individual's metabolism of biotin is abnormal, such as deficiency in the holocarboxylase synthetase enzyme which covalently links biotin onto the carboxylase, where the biotin acts as a cofactor.
High doses of biotin may play a role in stopping and reversing progression in progressive multiple sclerosis, as shown in a small pilot study of 23 patients in France. 91% of these patients were judged to have improved clinically. There was a 2 to 8 month lag in improvements. 
There are few treatment options for progressive MS. 
Biosynthesis.
Biotin has an unusual structure (see above figure), with two rings fused together via one of their sides. The two rings are ureido and thiophene moieties. Biotin is a heterocyclic, S-containing monocarboxylic acid. It is made from two precursors, alanine and pimeloyl-CoA via three enzymes. 8-Amino-7-oxopelargonic acid synthase is a pyridoxal 5'-phosphate enzyme. The pimeloyl-CoA, could be produced by a modified fatty acid pathway involving a malonyl thioester as the starter. 7,8Diaminopelargonic acid (DAPA) aminotransferase is unusual in using S-adenosyl methionine (SAM) as the NH2 donor. Dethiobiotin synthethase catalyzes the formation of the ureido ring via a DAPA carbamate activated with ATP. Biotin synthase reductively cleaves SAM into a deoxyadenosyl radical—a first radical formed on dethiobiotin is trapped by the sulfur donor, which was found to be the iron-sulfur (Fe-S) center contained in the enzyme.
Cofactor biochemistry.
-(+)-Biotin is a cofactor responsible for carbon dioxide transfer in several carboxylase enzymes:
Biotin is important in fatty acid synthesis, branched-chain amino acid catabolism, and gluconeogenesis. It covalently attaches to the epsilon-amino group of specific lysine residues in these carboxylases. This biotinylation reaction requires ATP and is catalyzed by holocarboxylase synthetase. In bacteria, biotin is attached to biotin carboxyl carrier protein (BCCP) by biotin protein ligase (BirA in "E. coli"). The attachment of biotin to various chemical sites, biotinylation, is used as an important laboratory technique to study various processes, including protein localization, protein interactions, DNA transcription, and replication. Biotinidase itself is known to be able to biotinylate histone proteins, but little biotin is found naturally attached to chromatin.
Biotin binds very tightly to the tetrameric protein avidin (also streptavidin and neutravidin), with a dissociation constant "K"d on the order of 10−15 M, which is one of the strongest known protein-ligand interactions. This is often used in different biotechnological applications. Until 2005, very harsh conditions were thought to be required to break the biotin-streptavidin bond.
Sources of biotin.
Biotin is consumed from a wide range of food sources in the diet, but few are particularly rich sources. Foods with a relatively high biotin content include peanuts, Swiss chard and other leafy green vegetables, raw egg yolk (however, the consumption of avidin-containing egg whites with egg yolks minimizes the effectiveness of egg yolk's biotin in one's body), liver, and Saskatoon berries. The dietary biotin intake in Western populations has been estimated to be 35 to 70 μg/d (143–287 nmol/d).
Biotin is also available in supplement form and can be found in most pharmacies. The synthetic process developed by Leo Sternbach and Moses Wolf Goldberg in the 1940s uses fumaric acid as a starting material.
Bioavailability.
Biotin is also called vitamin H (the H represents "Haar und Haut", German words for "hair and skin") or vitamin B7. Studies on its bioavailability have been conducted in rats and in chicks. Based on these studies, biotin bioavailability may be low or variable, depending on the type of food being consumed. In general, biotin exists in food as protein-bound form or biocytin. Proteolysis by protease is required prior to absorption. This process assists free biotin release from biocytin and protein-bound biotin. The biotin present in corn is readily available; however, most grains have about a 20-40% bioavailability of biotin.
The wide variability in biotin bioavailability may be due to the ability of an organism to break various biotin-protein bonds from food. Whether an organism has an enzyme with that ability will determine the bioavailability of biotin from the foodstuff.
Factors that affect biotin requirements.
The frequency of marginal biotin status is not known, but the incidence of low circulating biotin levels in alcoholics has been found to be much greater than in the general population. Also, relatively low levels of biotin have been reported in the urine or plasma of patients who have had a partial gastrectomy or have other causes of achlorhydria, burn patients, epileptics, elderly individuals, and athletes. Pregnancy and lactation may be associated with an increased demand for biotin. In pregnancy, this may be due to a possible acceleration of biotin catabolism, whereas, in lactation, the higher demand has yet to be elucidated. Recent studies have shown marginal biotin deficiency can be present in human gestation, as evidenced by increased urinary excretion of 3-hydroxyisovaleric acid, decreased urinary excretion of biotin and bisnorbiotin, and decreased plasma concentration of biotin. Additionally, smoking may further accelerate biotin catabolism in women.
Deficiency.
Biotin deficiency can arise due to various inborn genetic errors that affect the activity of biotin-related enzymes. Since endogenous biotin production occurs in the gut, dysbiosis could also upset the metabolic processes that allow the body to generate biotin on its own.
The first demonstration of biotin deficiency in animals was observed in animals fed raw egg white. Rats fed egg white protein were found to develop dermatitis, alopecia and neuromuscular dysfunction. This syndrome, called egg white injury, was discovered to be caused by a glycoprotein found in egg white, avidin. Avidin denatures upon heating (cooking). This protein binds extremely well with biotin, making it unavailable for use in enzymatic reactions.
Regardless of the root cause, the deficiency can usually be addressed directly with nutritional supplementation.
Deficiency symptoms include:
The neurological and psychological symptoms can occur with only mild deficiencies. Dermatitis, conjunctivitis, and hair loss will generally occur only when deficiency becomes more severe. In severe cases of deficiency, a characteristic facial rash, together with an unusual facial fat distribution, may also be present (this has been termed the "biotin-deficient face" by some experts) (no citation provided).
Individuals with hereditary disorders of biotin deficiency have evidence of impaired immune system function, including increased susceptibility to bacterial and fungal infections.
Pregnant women tend to have a high risk of biotin deficiency. Nearly half of pregnant women have abnormal increases of 3-hydroxyisovaleric acid, which reflects reduced status of biotin. Several studies have reported this possible biotin deficiency during the pregnancy may cause infants' congenital malformations, such as cleft palate. Mice fed with dried raw egg to induce biotin deficiency during the gestation resulted in up to 100% incidence of the infants' malnourishment. Infants and embryos are more sensitive to the biotin deficiency. Therefore, even a mild level of the mother's biotin deficiency that does not reach the appearance of physiological deficiency signs may cause a serious consequence in the infants.
Metabolic disorders.
Inherited metabolic disorders characterized by deficient activities of biotin-dependent carboxylases are termed multiple carboxylase deficiency. These include deficiencies in the enzymes holocarboxylase synthetase or biotinidase. Holocarboxylase synthetase deficiency prevents the body's cells from using biotin effectively, and thus interferes with multiple carboxylase reactions. Biochemical and clinical manifestations include: ketolactic acidosis, organic aciduria, hyperammonemia, skin rash, feeding problems, hypotonia, seizures, developmental delay, alopecia, and coma.
Biotinidase deficiency is not due to inadequate biotin, but rather to a deficiency in the enzymes that process it. Biotinidase catalyzes the cleavage of biotin from biocytin and biotinyl-peptides (the proteolytic degradation products of each holocarboxylase) and thereby recycles biotin. It is also important in freeing biotin from dietary protein-bound biotin. General symptoms include decreased appetite and growth. Dermatologic symptoms include dermatitis, alopecia, and achromotrichia (absence or loss of pigment in the hair). Perosis (a shortening and thickening of bones) is seen in the skeleton. Fatty liver and kidney syndrome and hepatic steatosis also can occur.
Use in biotechnology.
Biotin is widely used throughout the biotechnology industry to conjugate proteins for biochemical assays. Biotin's small size means the biological activity of the protein will most likely be unaffected. This process is called biotinylation. Because both streptavidin and avidin bind biotin with high affinity (Kd of 10−14 mol/l to 10−15 mol/l) and specificity, biotinylated proteins of interest can be isolated from a sample by exploiting this highly stable interaction. The sample is incubated with streptavidin/avidin beads, allowing capture of the biotinylated protein of interest. Any other proteins binding to the biotinylated molecule will also stay with the bead and all other unbound proteins can be washed away. However, due to the extremely strong streptavidin-biotin interaction, very harsh conditions are needed to elute the biotinylated protein from the beads (typically 6M guanidine HCl at pH 1.5), which often will denature the protein of interest. To circumvent this problem, beads conjugated to monomeric avidin can be used, which has a decreased biotin-binding affinity of ~10−8 mol/l, allowing the biotinylated protein of interest to be eluted with excess free biotin.
ELISAs often make use of biotinylated secondary antibodies against the antigen of interest, followed by a detection step using streptavidin conjugated to a reporter molecule, such as horseradish peroxidase or alkaline phosphatase.
Toxicity.
Animal studies have indicated few, if any, effects due to high level doses of biotin. This may provide evidence that both animals and humans could tolerate doses of at least an order of magnitude greater than each of their nutritional requirements. There are no reported cases of adverse effects from receiving high doses of the vitamin, in particular, when used in the treatment of metabolic disorders causing sebhorrheic dermatitis in infants.excess biotin accumulation can inhibit endogenous sirt activity leading to increased inflammation, cellularity, and collagen deposition and may be partly responsible for age related metabolic problems. Reversed by calorie restriction in mice.

</doc>
<doc id="54123" url="http://en.wikipedia.org/wiki?curid=54123" title="Timeline of ancient Greece">
Timeline of ancient Greece

This is a timeline of Ancient Greece from 800 BC to 146 BC.
For earlier times, see Greek Dark Ages, Aegean civilizations and Mycenaean Greece. For later times see Roman Greece, Byzantine Empire and Ottoman Greece.
For Modern Greece after 1820, see Timeline of modern Greek history.

</doc>
<doc id="54124" url="http://en.wikipedia.org/wiki?curid=54124" title="Rhyolite">
Rhyolite

Rhyolite is an igneous, volcanic rock, of felsic (silica-rich) composition (typically > 69% SiO2—see the TAS classification). It may have any texture from glassy to aphanitic to porphyritic. The mineral assemblage is usually quartz, sanidine and plagioclase (in a ratio > 2:1—see the QAPF diagram). Biotite and hornblende are common accessory minerals.
Geology.
Rhyolite can be considered as the extrusive equivalent to the plutonic granite rock, and consequently, outcrops of rhyolite may bear a resemblance to granite. Due to their high content of silica and low iron and magnesium contents, rhyolite melts are highly polymerized and form highly viscous lavas. They also occur as breccias or in volcanic plugs and dikes. Rhyolites that cool too quickly to grow crystals form a natural glass or vitrophyre, also called obsidian. Slower cooling forms microscopic crystals in the lava and results in textures such as flow foliations, spherulitic, nodular, and lithophysal structures. Some rhyolite is highly vesicular pumice. Many eruptions of rhyolite are highly explosive and the deposits may consist of fallout tephra/tuff or of ignimbrites.
History.
In North American pre-historic times, rhyolite was quarried extensively in eastern Pennsylvania in the United States. Among the leading quarries was the Carbaugh Run Rhyolite Quarry Site in Adams County, where as many as fifty small quarry pits are known.
Eruptions of this advanced form of Igneous rock are rare, only three eruptions of rhyolite have been recorded since the start of the 20th century—the eruptions were at the St. Andrew Strait Volcano in Papua New Guinea, Novarupta Volcano in Alaska, United States and Chaiten in Southern Chile.
Name.
The name rhyolite was introduced into science by the German traveler and geologist Ferdinand von Richthofen after his explorations in the Rocky Mountains in the 1860s.

</doc>
<doc id="54125" url="http://en.wikipedia.org/wiki?curid=54125" title="Breccia">
Breccia

Breccia ( or ; Italian: brecce) is a rock composed of broken fragments of minerals or rock cemented together by a fine-grained matrix that can be similar to or different from the composition of the fragments.
The word has its origins in the Italian language, in which it means either "loose gravel" or "stone made by cemented gravel". A breccia may have a variety of different origins, as indicated by the named types including sedimentary breccia, tectonic breccia, igneous breccia, impact breccia, and hydrothermal breccia.
Types.
Sedimentary.
Sedimentary breccias are a type of clastic sedimentary rock which are made of angular to subangular, randomly oriented clasts of other sedimentary rocks. A conglomerate, by contrast, is a sedimentary rock composed of rounded fragments or clasts of pre-existing rocks. Both breccias and conglomerates are composed of fragments averaging greater than 2 mm in size. The angular shape of the fragments indicates that the material has not been transported far from its source. 
Sedimentary breccias consist of angular, poorly sorted, immature fragments of rocks in a finer grained groundmass which are produced by mass wasting. They are lithified colluvium or scree. Thick sequences of sedimentary (colluvial) breccias are generally formed next to fault scarps in grabens. Breccias may occur along a buried stream channel where they indicate accumulation along a juvenile or rapidly flowing stream.
Sedimentary breccias may be formed by submarine debris flows. Turbidites occur as fine-grained peripheral deposit to a sedimentary breccia flow.
In a karst terrain a collapse breccia may form due to collapse into a sinkhole or in cave development.
Fault.
Fault breccias result from the grinding action of two fault blocks as they slide past each other. Subsequent cementation of these broken fragments may occur by means of the introduction of mineral matter in groundwater.
Igneous.
Igneous clastic (detrital) rocks can be divided into two classes:
Volcanic.
Volcanic pyroclastic rocks are formed by explosive eruption of lava and any rocks which are entrained within the eruptive column. This may include rocks plucked off the wall of the magma conduit, or physically picked up by the ensuing pyroclastic surge. Lavas, especially rhyolite and dacite flows, tend to form clastic volcanic rocks by a process known as "autobrecciation". This occurs when the thick, nearly solid lava breaks up into blocks and these blocks are then reincorporated into the lava flow again and mixed in with the remaining liquid magma. The resulting breccia is uniform in rock type and chemical composition.
Lavas may also pick up rock fragments, especially if flowing over unconsolidated rubble on the flanks of a volcano, and these form volcanic breccias, also called pillow breccias.
Within the volcanic conduits of explosive volcanoes the volcanic breccia environment merges into the intrusive breccia environment. There the upwelling lava tends to solidify during quiescent intervals only to be shattered by ensuing eruptions.
Intrusive.
Clastic rocks are also commonly found in shallow subvolcanic intrusions such as porphyry stocks, granites and kimberlite pipes, where they are transitional with volcanic breccias.
Intrusive rocks can become brecciated in appearance by multiple stages of intrusion, especially if fresh magma is intruded into partly consolidated or solidified magma. This may be seen in many granite intrusions where later aplite veins form a late-stage stockwork through earlier phases of the granite mass. When particularly intense, the rock may appear as a chaotic breccia.
Clastic rocks in mafic and ultramafic intrusions have been found and form via several processes:
Impact.
Impact breccias are thought to be diagnostic of an impact event such as an asteroid or comet striking the Earth and are normally found at impact craters. Impact breccia, a type of impactite, forms during the process of impact cratering when large meteorites or comets impact with the Earth or other rocky planets or asteroids. Breccia of this type may be present on or beneath the floor of the crater, in the rim, or in the ejecta expelled beyond the crater. Impact breccia may be identified by its occurrence in or around a known impact crater, and/or an association with other products of impact cratering such as shatter cones, impact glass, shocked minerals, and chemical and isotopic evidence of contamination with extraterrestrial material (e.g. iridium and osmium anomalies).
Hydrothermal.
Hydrothermal breccias usually form at shallow crustal levels (<1 km) between 150 to 350 °C, when seismic or volcanic activity causes a void to open along a fault deep underground. The void draws in hot water, and as pressure in the cavity drops, the water violently boils. In addition, the sudden opening of a cavity causes rock at the sides of the fault to destabilise and implode inwards, and the broken rock gets caught up in a churning mixture of rock, steam and boiling water. Rock fragments collide with each other and the sides of the void, and the angular fragments become more rounded. Volatile gases are lost to the steam phase as boiling continues, in particular carbon dioxide. As a result, the chemistry of the fluids changes and ore minerals rapidly precipitate. Breccia-hosted ore deposits are quite common.
The morphology of breccias associated with ore deposits varies from tabular sheeted veins and clastic dikes associated with overpressured sedimentary strata, to large-scale intrusive diatreme breccias (breccia pipes), or even some synsedimentary diatremes formed solely by the overpressure of pore fluid within sedimentary basins. Hydrothermal breccias are usually formed by hydrofracturing of rocks by highly pressured hydrothermal fluids. They are typical of the epithermal ore environment and are intimately associated with intrusive-related ore deposits such as skarns, greisens and porphyry-related mineralisation. Epithermal deposits are mined for copper, silver and gold.
In the mesothermal regime, at much greater depths, fluids under lithostatic pressure can be released during seismic activity associated with mountain building. The pressurised fluids ascend towards shallower crustal levels that are under lower hydrostatic pressure. On their journey, high-pressure fluids crack rock by hydrofracturing, forming an angular "in situ" breccia. Rounding of rock fragments is less common in the mesothermal regime, as the formational event is brief. If boiling occurs, methane and hydrogen sulfide may be lost to the steam phase, and ore may precipitate. Mesothermal deposits are often mined for gold.
Ornamental uses.
For thousands of years, the striking visual appearance of breccias has made them a popular sculptural and architectural material. Breccia was used for column bases in the Minoan palace of Knossos on Crete in about 1800 BC. Breccia was used on a limited scale by the ancient Egyptians; one of the best-known examples is the statue of the goddess Tawaret in the British Museum. It was regarded by the Romans as an especially precious stone and was often used in high-profile public buildings. Many types of marble are brecciated, such as Breccia Oniciata or Breche Nouvelle.
Breccia is most often used as an ornamental or facing material in walls and columns. A particularly striking example can be seen in the Pantheon in Rome, which features two gigantic columns of pavonazzetto, a breccia coming from Phrygia (in modern Turkey). Pavonazzetto obtains its name from its extremely colourful appearance, which is reminiscent of a peacock's feathers ("pavone" is "peacock" in Italian).

</doc>
<doc id="54128" url="http://en.wikipedia.org/wiki?curid=54128" title="Kart racing">
Kart racing

Kart racing or karting is a variant of open-wheel motorsport with small, open, four-wheeled vehicles called karts, go-karts, or gearbox/shifter karts depending on the design. They are usually raced on scaled-down circuits. Karting is commonly perceived as the stepping stone to the higher ranks of motorsports.
Karts vary widely in speed and some (known as Superkarts) can reach speeds exceeding 260 km/h, while amusement park go-karts intended for the general public may be limited to speeds of no more than 25 km/h.
History.
American Art Ingels is generally accepted to be the father of karting. A veteran hot rodder and a race car builder at Kurtis Kraft, he built the first kart in Southern California in 1956. Instantly popular, Karting rapidly spread to other countries, and currently has a large following in Europe.
The first kart manufacturer was an American company, Go Kart Manufacturing Co. (1958). In 1959, McCulloch was the first company, to produce engines for karts. Its first engine, the McCulloch MC-10, was an adapted chainsaw 2-stroke engine. Later, in the 1960s, motorcycle engines were also adapted for kart use, before dedicated manufacturers, especially in Italy (IAME), started to build engines for the sport.
Components.
Chassis.
The chassis are made of steel tubing. There is no suspension, therefore chassis have to be flexible enough to work as a suspension and stiff enough not to break or give way on a turn. Kart chassis are classified in the USA as 'Open', 'Caged', 'Straight' or 'Offset'. All Commission Internationale de Karting - Fédération Internationale de l'Automobile or CIK-FIA approved chassis are 'Straight' and 'Open'.
The stiffness of the chassis enables different handling characteristics for different circumstances. Typically, for dry conditions a stiffer chassis is preferable, while in wet or other poor traction conditions, a more flexible chassis may work better. The best chassis allow for stiffening bars at the rear, front and side to be added or removed according to race conditions.
Braking is achieved by a disc brake mounted on the rear axle. Front disc brakes are used in most shifter kart classes and are increasingly popular in other classes; however, certain classes do not allow them. Shifter karts have dual master cylinders, one for the front and one for the rear and are adjustable to allow for front/ rear bias changes.
Professionally raced karts typically weigh 165 to, complete without driver. Avanti, Tony Kart, Trulli, Birel, CRG, Gillard, Intrepid, Kosmic, Zanardi or FA Kart are a few well known examples of the many European manufacturers of race-quality chassis. Emmick, Coyote, Bandit, Shadow, MGM, PRC and Margay are American companies producing kart chassis.
Engines.
Amusement park go-karts can be powered by 4-stroke engines or electric motors, while racing karts use small 2-stroke or 4-stroke engines.
Transmission.
Karts do not have a differential. The lack of a differential means that one rear tire must slide while cornering; this is achieved by designing the chassis so that the inside rear tire lifts up slightly when the kart turns the corner. This allows the tire to lose some of its grip and slide or lift off the ground completely.
Power is transmitted from the engine to the rear axle by a chain. Both engine and axle sprockets are removable; their ratio must be adapted to the track configuration in order to get the most from the engine.
In the early days, karts were direct drive only (requiring push starts), but the inconvenience of that setup soon led to the centrifugal clutch for the club level classes. Dry centrifugal clutches are now used in many categories (Rotax Max is one example) and have become the norm as the top international classes have switched to 125 cc clutched engines as of January 2007.
Tires.
Wheels and tires are much smaller than those used on a normal car. Rims are made of magnesium alloy, aluminum, or composite materials. Tires can support cornering forces in excess of 2 g (20 m/s²), depending on chassis, engine, and motor setup. Some car tire manufacturers, such as Bridgestone, Dunlop or Maxxis, make tires for karts. There are also specific kart tire manufacturers, which include MG, MOJO, and Vega.
Similar to other motorsports, kart tires have different types for use appropriate to track conditions:
Data acquisition.
As in other motor sports, several data acquisition systems have been developed for kart racing. These systems allow the driver to monitor from a display fixed on the steering wheel some parameters such as RPM, timing of laps (including sectors), number of laps, best lap, cooling system temperature, exhaust gas temperature and sometimes speed or even gear for shifter karts.
Some of those systems are able to record (logging) laps data from the sensors, allowing replay of an entire running session or/and direct download to a personal computer equipped with a data analysis software. More sophisticated systems allow for more information such as lateral and longitudinal acceleration (g-force), throttle position, steering wheel position and brake pressure.
Racing.
Kart racing is generally accepted as the most economic form of motorsport available on four wheels. As a free-time activity, it can be performed by almost anybody, and as a motorsport in itself, it is one of the sports regulated by FIA (under the name of CIK), permitting licensed racing for anyone from the age of 8 onward.
In the USA, there is not as much FIA involvement; instead, many organizations regulate racing, such as the IKF (International Kart Federation), WKA (World Karting Association), KART (Karters of America Racing Triad).
In the UK, the MSA (Motor Sports Association) regulates most 'owner driver' Karting. Some associations, such as NatSKA (National Schools Karting Association), organize race meetings throughout the country under the authority of the MSA.
Various four-stroke 'hire kart' series such as EPEC (European Prokart Endurance Championship) or () fall outside the governance of the MSA. Billed as the UK's first national karting "league," the Elite Karting League also falls outside of MSA governance.
In Australia, kart racing is administered by the Australian Karting Association on the behalf of FIA and CAMS. There is a manual released every year detailing the various rules and regulations that race meetings and drivers have to follow.
Racing classes start at age 7 or 8 (5 in the US with "Kid Karts") and generally run in 3-year age groupings or weight divisions until "senior" status is reached at age 15 or 16, depending on the series.
Racing formats.
Typically, race formats are one of the following:
Sprint.
Sprint racing takes place on dedicated kart circuits resembling small road courses, with left and right turns. Tracks range from 1/4 mile (400 metres) to over 1 mile (1,600 metres) in length.
The sprint format is a series of short-duration races, normally for a small number of laps, that qualify for a final, with a variety of point scoring calculations to determine the event's overall winner. Typical duration does not normally exceed 15 minutes. Here, speed and successful passing is of the most importance. It normally occurs in the format of three qualifying heats and a final race for trophy positions.
The FIA championships, including the Karting World Championship, take place in this format.
Endurance.
Endurance races last for an extended period, ranging from 30 minutes up to 24 hours or more, for one or more drivers. In general, consistency, reliability, and pit strategy is of greater importance than all out speed.
Called "Enduro" racing in the USA, most WKA & IKF sanctioned events typically last 30 minutes (Sprint Enduro) or 45 minutes (Laydown Enduro) and are run continuous without pit stops. Enduro events are held on full-size road racing circuits that are usually between 1.5 & 4 miles in length.
As well as the famous 24 Hours of Le Mans race for automobiles there is also a 24 hours event for karts which takes place at the kart circuit Alain Prost at Le Mans, France. This race has taken place since 1986 and its winners list include four times Champ Car champion Sébastien Bourdais (in 1996).
Speedway.
Speedway racing takes place on asphalt or clay oval tracks which are normally between 1/6 mile and 1/4 mile long. Tracks primarily consist of two straights and four left-turn corners, few tracks are symmetric and often the shape parallels that of an egg or a tri-oval.
'Offset' kart chassis have been developed for precise handling and adjustability in left-turn-only racing competition taking place on oval and tri-oval tracks.
Speedway kart races range in length from 4 laps for a trophy dash, to 20 laps for a main event.
The two chief racing formats used in dirt speedway karting are heat races and timed laps qualification:
Racing categories.
There are many different classes or formula in karting.
International.
The CIK-FIA sanctions international championships in KF1, KF2, KF3, KZ1, KZ2 and Superkart. These are regarded as the top level classes of karting and are also raced in national championships worldwide. The World Championship is decided here. The current 2010 World Champion is Nyck de Vries from the Netherlands.
CIK-FIA categories:
Non CIK-FIA categories:
The " (or KWC) as opposed to the FIA's 'Karting World Championship' uses 4-stroke rental karts and travels to a different country each year.
National.
In the UK, the most celebrated karting series is the National karting series, also known as Super One. There are three types of Super One championships:
Other UK National Championships include:
Birel Easykart (MSA Approved) series: Cadet 60cc, Junior 100cc, Senior Light 125cc, Senior Heavy 125cc
The is the UK's rental karting National championship, and the UK's official feeder series to the rental .
NatSKA is a budget karting association set up for schools and youth groups in the UK, with 13 classes.
In the United States, Dirt oval classes (which often use Briggs & Stratton industrial engines) are prominent in the Southeast and Midwest. In the West, European style sprint racing is much more common. In particular, 125cc shifter karts using Honda CR125 power units have gained tremendous popularity in recent years.
In Australia, classes include Cadet (previously called Midget), Rookie, Junior National Pro, Junior National, Junior Clubman, Junior Rotax (Jmax), KF3, Senior National, Senior Rotax, Senior Clubman, Senior TAG (Restricted and Unrestricted). Most classes run a light and heavy category (with some running super heavy).
Many people race worldwide in Spec series such as Rotax Max (a TaG class) or those using the Yamaha KT100 engine.
Racing licenses.
As in other disciplines in motorsports, a license is required to drive a racing kart on a circuit or enter competitions. The licenses, issued by governing bodies, are provided by clubs or associations. Most of the time, but not always, a basic insurance coverage is included in the licence annual fee. In some countries, such as France, regulations require the drivers to pass a medical exam each year.
License classes differ between countries according to age groups or levels. Most of the time a Practice License can be easily obtained, while a Racing License might require a capability assessment.
Driver equipment.
For their safety, kart drivers are required to wear proper equipment:
Rib protector and neck brace, although highly recommended, are optional in most countries. None of the above need to be made of fire retardant material. Superkart drivers are required to wear leather overalls, similar to those used in motorcycling.
Karting as a learning tool.
Kart racing is usually used as a low-cost and relatively safe way to introduce drivers to motor racing. Many Formula One drivers grew up racing karts, most prominent among them, World Champions Ayrton Senna, Michael Schumacher, Alain Prost, Fernando Alonso, Kimi Räikkönen, Jenson Button, Lewis Hamilton and Sebastian Vettel. Many NASCAR drivers also got their start in racing from karts, such as Darrell Waltrip, Danica Patrick, Lake Speed, Ricky Rudd, Juan Pablo Montoya, Tony Stewart, and Jeff Gordon. 
In August 2009, in anticipation to a possible return to F1 with Ferrari, Formula One world champion Michael Schumacher did some preparation driving a kart in Lonato, Italy. Schumacher also raced at the SKUSA SuperNationals, an event taking place each year in Las Vegas, along with F1 drivers Sébastien Buemi and Nelson Piquet, Jr.. Felipe Massa also used karting in September 2009 to test his condition in Brazil, two months after his Hungarian Grand Prix accident during qualifying.
See also.
Related :
External links.
Governing Bodies:

</doc>
<doc id="54132" url="http://en.wikipedia.org/wiki?curid=54132" title="Olof Palme">
Olof Palme

Sven Olof Joachim Palme (Swedish: "Olof Palme"; ]; 30 January 1927 – 28 February 1986) was a Swedish Social Democratic politician, statesman and prime minister. A longtime protégé of Prime Minister Tage Erlander, Palme led the Swedish Social Democratic Party SAP from 1969 until his assassination in 1986, and was a two-term Prime Minister of Sweden, heading a Privy Council Government from 1969 to 1976 and a cabinet government from 1982 until his death. Electoral defeats in 1976 and 1979 marked the end of Social Democratic hegemony in Swedish politics, which had seen 40 years of unbroken rule by the party. While leader of opposition, he parted domestic and international interests and served as special mediator of the United Nations in the Iran–Iraq War, but returned to power as Prime Minister after electoral victories in 1982 and 1985.
A pivotal, renowned, and polarizing figure domestically as well as in international politics since the 1960s, Palme was steadfast in his non-alignment policy towards the superpowers, juxtaposed to support of numerous third world liberation movements following the process of decolonization including, most controversially, economic and vocal support for a number of Third World governments which were guilty of gross violations of human rights. Most famously, he was the first Western Head of Government to visit Cuba after its revolution, giving a speech in Santiago praising contemporary Cuban and Cambodian revolutionaries.
Frequently a critic of US and Soviet foreign policy, he resorted to fierce and often polarizing criticism in pinpointing his resistance towards imperialist ambitions and authoritarian regimes, including those of Francisco Franco of Spain, António de Oliveira Salazar of Portugal, Gustáv Husák of Czechoslovakia, B J Vorster and P W Botha of South Africa. His 1972 condemnation of the Hanoi bombings, notably comparing the tactic to the Treblinka extermination camp, resulted in a temporary freeze in Sweden–United States relations. Palme's steadfast opposition to apartheid, which he labeled "a particularly gruesome system", gave rise to theories of South African involvement in his death, which were further fueled when Eugene de Kock claimed South African security forces had orchestrated his death. His murder by an unapprehended assailant on a street in Stockholm on 28 February 1986 was the first of its kind in modern Swedish history, the first of a national leader since Gustav III, and had a great impact across Scandinavia. Local convict and addict Christer Pettersson was convicted of the murder but was acquitted on appeal by the Svea Court of Appeal.
Early life.
Palme was born into an upper-class, conservative Lutheran family in Östermalm, Stockholm, Sweden. His father, a businessman, was of Dutch ancestry, and his mother, Freiin von Knieriem, was of Baltic German origin and had arrived in Sweden as a refugee in 1915. Great-grandfather Alexander von Knieriem (1837 - 1904) was an attorney general of the Senate of Russian Empire, senator and member of the State Council of Imperial Russia. Palme's father died when he was six years old. Despite his upper-class background, his political orientation came to be influenced by Social Democratic attitudes. His travels in the Third World, as well as the United States, where he saw deep economic inequality and racial segregation, helped to develop these views.
A sickly child, Olof Palme received his education from private tutors. Even as a child he gained knowledge of two foreign languages - German and English. He studied at the Sigtuna School of Liberal Arts, one of Sweden's few residential high schools, and passed the university entrance examination with high marks at the age of 17. He was drafted into the Army in January 1945 and did his compulsory military service at A 1 between 1945 and 1947, became in 1956 a reserve officer with the rank of Captain in the Artillery. After he was discharged from military service in March 1947, he enrolled at the University of Stockholm.
On a scholarship, he studied at Kenyon College, Ohio 1947–1948, graduating with a B.A.. Inspired by radical debate in the student community, he wrote a critical essay on Friedrich Hayek's "The Road to Serfdom". Palme wrote his senior honour thesis on the United Auto Workers union, led at the time by Walter Reuther. After graduation he traveled throughout the country and eventually ended up in Detroit, where his hero Reuther agreed to an interview which lasted several hours. In later years, Palme regularly remarked during his many subsequent American visits, that the United States had made him a socialist, a remark that often has caused confusion. Within the context of his American experience, it was not that Palme was repelled by what he found in America, but rather that he was inspired by it.
After hitchhiking through the USA and Mexico, he returned to Sweden to study law at Stockholm University. In 1949 he became a member of the Swedish Social Democratic Party. During his time at university, Palme became involved in student politics, working with the Swedish National Union of Students. In 1951, he became a member of the social democratic student association in Stockholm, although it is asserted he did not attend their political meetings at the time. The following year he was elected President of the Swedish National Union of Students. As a student politician he concentrated on international affairs and traveled across Europe.
Palme attributed his becoming a socialist to three major influences:
Political career.
In 1953, Palme was recruited by the social democratic prime minister Tage Erlander to work in his secretariat. From 1955 he was a board member of the Swedish Social Democratic Youth League and lectured at the Youth League College Bommersvik. He also was a member of the Worker's Educational Association.
In 1957 he was elected as an Member of Parliament (Swedish: "riksdagsledamot") represented Jönköping County in the directly-elected First Chamber ("Första kammaren") of the Riksdag. In the early 1960s Palme became a member of the Agency for International Assistance (NIB) and was in charge of inquiries into assistance to the developing countries and educational aid. In 1963, he became a member of the Cabinet - as Minister without Portfolio in the Cabinet Office, and retained his duties as a close political adviser to Prime Minister Tage Erlander. In 1965, he became Minister of Transport and Communications. One issue of special interest to him was the further development of radio and television, while ensuring their independence from commercial interests. In 1967 he became Minister of Education, and the following year, he was the target of strong criticism from left-wing students protesting against the government's plans for university reform. The protests culminated with the occupation of the Student Union Building in Stockholm; Palme came there and tried to comfort the students, urging them to use democratic methods for the pursuit of their cause. When party leader Tage Erlander stepped down in 1969, Palme was elected as the new leader by the Social Democratic party congress and succeeded Erlander as Prime Minister.
His protégé and political ally, Bernt Carlsson, who was appointed UN Commissioner for Namibia in July 1987, was killed in the bombing of Pan Am Flight 103 over Lockerbie, Scotland on 21 December 1988 "en route" to the UN signing ceremony of the New York Accords the following day.
Palme was said to have had a profound impact on people's emotions; he was very popular among the left, but harshly detested by most liberals and conservatives. This was due in part to his international activities, especially those directed against the US foreign policy, and in part to his aggressive and outspoken debating style.
Policies.
As leader of a new generation of Swedish Social Democrats, Olof Palme was often described as a "revolutionary reformist". Domestically, his democratic socialist views, especially the drive to expand Labour Union influence over business ownership, engendered a great deal of hostility from the organized business community.
During the tenure of Olof Palme, several major reforms in the Swedish constitution were carried out, such as orchestrating a switch from bicameralism to unicameralism in 1969 and in 1975 replacing the 1809 Instrument of Government (at the time the oldest political constitution in the world after that of the United States) with a new one officially establishing parliamentary democracy rather than "de jure" monarchic autocracy, abolishing the Cabinet meetings chaired by the King and stripping the monarchy of all formal political powers.
His reforms on labour market included establishing a law which increased job security. In the Swedish 1973 general election, the Socialist-Communist and the Liberal-Conservative blocs got 175 places each in the Riksdag. The Palme cabinet continued to govern the country but several times they had to draw lots to decide on some issues, although most important issues were decided through concessional agreement. Tax rates also rose from being fairly low even by European standards to the highest levels in the Western world.
Under Olof Palme's permiership tenure, matters concerned with child care centers, social security, protection of the elderly, accident safety, and housing problems received special attention. Under Palme the public health system in Sweden became efficient, with the infant mortality rate standing at 12 per 1,000 live births. An ambitious redistributive programme was carried out, with special help provided to the disabled, immigrants, the low paid, single-parent families, and the old. The Swedish welfare state was significantly expanded from a position already one of the most far-reaching in the world during his time in office. As noted by Isabela Mares, during the first half of the Seventies “the level of benefits provided by every subsystem of the welfare state improved significantly.” Various policy changes increased the basic old-age pension replacement rate from 42% of the average wage in 1969 to 57%, while a health care reform carried out in 1974 integrated all health services and increased the minimum replacement rate from 64% to 90% of earnings. In 1974, supplementary unemployment assistance was established, providing benefits to those workers ineligible for existing benefits. In 1971, eligibility for invalidity pensions was extended with greater opportunities for employees over the age of 60. In 1974, universal dental insurance was introduced, and former maternity benefits were replaced by a parental allowance. In 1974, housing allowances for families with children were raised and these allowances were extended to other low-income groups. Childcare centres were also expanded under Palme, and separate taxation of husband and wife introduced. Access to pensions for older workers in poor health was liberalised in 1970, and a disability pension was introduced for older unemployed workers in 1972.
The Palme cabinet was also active in the field of education, introducing such reforms as a system of loans and benefits for students, regional universities, and preschool for all children. Under a law of 1970, in the upper secondary school system “gymnasium,” “fackskola” and vocational “yrkesskola” were integrated to form one school with 3 sectors (arts and social science, technical and natural sciences, economic and commercial). In 1975, a law was passed that established free admission to universities. A number of reforms were also carried out to enhance workers' rights. An employment protection Act of 1974 introduced rules regarding consultation with unions, notice periods, and grounds for dismissal, together with priority rules for dismissals and re-employment in case of redundancies. That same year, work-environment improvement grants were introduced and made available to modernising firms “conditional upon the presence of union-appointed ‘safety stewards’ to review the introduction of new technology with regard to the health and safety of workers.” In 1976, an Act on co-determination at work was introduced that allowed unions to be consulted at various levels within companies before major changes were enforced that would affect employees, while management had to negotiate with labour for joint rights in all matters concerning organisation of work, hiring and firing, and key decisions affecting the workplace.
Olof Palme's last government, elected during a time when Sweden's economy was in difficult shape, sought to pursue a "third way," designed to stimulate investment, production, and employment, having ruled out classical Keynesian policies as a result of the growing burden of foreign debt, together with the big balance of payments and budget deficits. This involved "equality of sacrifice," whereby wage restraint would be accompanied by increases in welfare provision and more progressive taxation. For instance, taxes on wealth, gifts, and inheritance were increased, while tax benefits to shareholders were either reduced or eliminated. In addition, various welfare cuts carried out before Olof's return to office were rescinded. The previous system of indexing pensions and other benefits was restored, the grant-in-aid scheme for municipal child care facilities was re-established, unemployment insurance was restored in full, and the so-called “no benefit days” for those drawing sickness benefits were cancelled. Increases were also made to both food subsidies and child allowances, while the employee investment funds (which represented a radical form of profit-sharing) were introduced.
An outspoken supporter of gender equality, Palme sparked interest for women's' rights issues by attending a World Women's Conference in Mexico. In 1968 Palme was a driving force behind the release of documentary Dom kallar oss mods. The controversial movie, depicting two social outcasts, was scheduled to be released in an edited form but Palme thought the material was too socially important to be cut.
As a forerunner in green politics Olof Palme was a firm believer in nuclear power as a necessary form of energy, at least for a transitional period to curb the influence of fossil fuel. His intervention in Sweden's 1980 referendum on the future of nuclear power is often pinpointed by opponents of nuclear power as saving it. As of 2011, nuclear power remains one of the most important sources of energy in Sweden, much attributed to Palme's actions.
Shortly before his assassination, Palme had been accused of being pro-Soviet and not sufficiently safeguarding Sweden's national interest. Arrangements had therefore been made for him to go to Moscow to discuss a number of contentious bilateral issues, including alleged Soviet submarine incursions into Swedish waters (see "U 137").
On the international scene, Palme was a widely recognised political figure because of his:
All of this ensured that Palme had many opponents (as well as many friends) abroad.
On 21 February 1968, Palme (then Minister of Education) participated in a protest in Stockholm against U.S. involvement in the war in Vietnam together with the North Vietnamese Ambassador to the Soviet Union Nguyen Tho Chan. The protest was organized by the Swedish Committee for Vietnam and Palme and Nguyen were both invited as speakers. As a result of this, the U.S. recalled its Ambassador from Sweden and Palme was fiercely criticised by the opposition for his participation in the protest.
On 23 December 1972, Palme (then Prime Minister) made a speech in Swedish national radio where he compared the ongoing U.S. bombings of Hanoi to historical atrocities, namely the bombing of Guernica, the massacres of Oradour-sur-Glane, Babi Yar, Katyn, Lidice and Sharpeville, and the extermination of Jews and other groups at Treblinka. The US government called the comparison a "gross insult" and once again decided to freeze its diplomatic relations with Sweden (this time the freeze lasted for over a year).
Despite such associations and contrary to stated Social Democratic Party policy, Sweden had in fact secretly maintained extensive military co-operation with NATO over a long period, and was even under the protection of a US military security guarantee (see Swedish neutrality during the Cold War).
In response to Palme's remarks in a meeting with the US ambassador to Sweden ahead of the Socialist International Meeting in Helsingør in January 1976, Kissinger asked the US ambassador to "(...) convey my personal appreciation to Palme for his frank presentation (...).
Assassination.
Security had never been a major issue, and Olof Palme could often be seen without any bodyguard protection. The night of his murder was one such occasion. Walking home from a cinema with his wife Lisbet Palme in the central Stockholm street Sveavägen, close to midnight on 28 February 1986, the couple was attacked by an assassin. Palme was fatally shot in the back at close range. A second shot was fired at Lisbet Palme, the bullet grazing her back. She survived without serious injuries.
Police said that a taxi driver used his radio to raise the alarm. Two young girls sitting in a car close to the scene of the shooting also tried to help the prime minister. He was rushed to hospital but was pronounced dead on arrival at 00:06 CET the next day. Deputy Prime Minister Ingvar Carlsson immediately assumed the duties of Prime Minister, a post he retained until 1991 (and then again in 1994-1996). He also took over the leadership of the Social Democratic Party, which he held until 1996.
Two years later, Christer Pettersson (d. 2004), a small-time criminal and drug addict, was arrested, tried and convicted for Palme's murder. Pettersson's conviction was later overturned on appeal to the Svea Court of Appeal. The crime remains unsolved and alternative theories as to who carried out the murder have since been proposed.
In January 2011 the German magazine "Focus" cited German interrogation records in connection with another investigation from 2008 as showing that the assassination had been carried out by an operative of the Yugoslavian UDBA who now lives in Zagreb, Croatia.
Bibliography.
</dl>

</doc>
<doc id="54136" url="http://en.wikipedia.org/wiki?curid=54136" title="Lesbos Prefecture">
Lesbos Prefecture

Lesbos Prefecture (Greek: Νομός Λέσβου) was one of the prefectures of Greece. It comprised three main islands: Lesbos itself, Lemnos, and the smaller island of Agios Efstratios. In 2011 the prefecture was abolished and the territory is now covered by the regional units of Lesbos and Lemnos. Its capital was the town of Mytilene, on Lesbos.
Provinces.
"Note:" Provinces no longer hold any legal status in Greece.

</doc>
<doc id="54137" url="http://en.wikipedia.org/wiki?curid=54137" title="Methane clathrate">
Methane clathrate

Methane clathrate (CH4·5.75H2O), also called methane hydrate, hydromethane, methane ice, fire ice, natural gas hydrate, or gas hydrate, is a solid clathrate compound (more specifically, a clathrate hydrate) in which a large amount of methane is trapped within a crystal structure of water, forming a solid similar to ice. Originally thought to occur only in the outer regions of the Solar System, where temperatures are low and water ice is common, significant deposits of methane clathrate have been found under sediments on the ocean floors of the Earth.
Methane clathrates are common constituents of the shallow marine geosphere and they occur in deep sedimentary structures and form outcrops on the ocean floor. Methane hydrates are believed to form by migration of gas from deep along geological faults, followed by precipitation or crystallization, on contact of the rising gas stream with cold sea water. In 2008 research on Antarctic Vostok and EPICA Dome C ice cores revealed that methane clathrates were also present in deep Antarctic ice cores and record a history of atmospheric methane concentrations, dating to 800,000 years ago. The ice-core methane clathrate record is a primary source of data for global warming research, along with oxygen and carbon dioxide.
Structure and composition.
The nominal methane clathrate hydrate composition is (CH4)4(H2O)23, or 1 mole of methane for every 5.75 moles of water, corresponding to 13.4% methane by weight, although the actual composition is dependent on how many methane molecules fit into the various cage structures of the water lattice. The observed density is around 0.9 g/cm3, which means that methane hydrate will float to the surface of the sea or of a lake unless it is bound in place by being formed in or anchored to sediment. One litre of fully saturated methane clathrate solid would therefore contain about 120 grams of methane (or around 169 litres of methane gas at 0°C and 1 atm).
Methane forms a structure I hydrate with two dodecahedral (12 vertices, thus 12 water molecules) and six tetradecahedral (14 water molecules) water cages per unit cell. (Because of sharing of water molecules between cages, there are only 46 water molecules per unit cell.) This compares with a hydration number of 20 for methane in aqueous solution. A methane clathrate MAS NMR spectrum recorded at 275 K and 3.1 MPa shows a peak for each cage type and a separate peak for gas phase methane. In 2003, a clay-methane hydrate intercalate was synthesized in which a methane hydrate complex was introduced at the interlayer of a sodium-rich montmorillonite clay. The upper temperature stability of this phase is similar to that of structure I hydrate.
Natural deposits.
Methane clathrates are restricted to the shallow lithosphere (i.e. < 2,000 m depth). Furthermore, necessary conditions are found only in either continental sedimentary rocks in polar regions where average surface temperatures are less than 0 °C; or in oceanic sediment at water depths greater than 300 m where the bottom water temperature is around 2 °C. In addition, deep fresh water lakes may host gas hydrates as well, e.g. the fresh water Lake Baikal, Siberia. Continental deposits have been located in Siberia and Alaska in sandstone and siltstone beds at less than 800 m depth. Oceanic deposits seem to be widespread in the continental shelf (see Fig.) and can occur within the sediments at depth or close to the sediment-water interface. They may cap even larger deposits of gaseous methane.
Oceanic.
There are two distinct types of oceanic deposit. The most common is dominated (> 99%) by methane contained in a structure I clathrate and generally found at depth in the sediment. Here, the methane is isotopically light (δ13C < -60‰) which indicates that it is derived from the microbial reduction of CO2. The clathrates in these deep deposits are thought to have formed in situ from the microbially produced methane, since the δ13C values of clathrate and surrounding dissolved methane are similar. However, it is also thought that fresh water used in the pressurization of oil and gas wells in permafrost and along the continental shelves world wide, combine with natural methane to form clathrate at depth and pressure, since methane hydrates are more stable in fresh water than in salt water. Local variations may be very common, since the act of forming hydrate, which extracts pure water from saline formation waters, can often lead to local, and potentially significant increases in formation water salinity. Hydrates normally exclude the salt in the pore fluid from which it forms, thus they comprise high electric resistivity just like ice, and sediments containing hydrates have a higher resistivity compared to sediments without gas hydrates (Judge [67]):9
These deposits are located within a mid-depth zone around 300–500 m thick in the sediments (the gas hydrate stability zone, or GHSZ) where they coexist with methane dissolved in the fresh, not salt, pore-waters. Above this zone methane is only present in its dissolved form at concentrations that decrease towards the sediment surface. Below it, methane is gaseous. At Blake Ridge on the Atlantic continental rise, the GHSZ started at 190 m depth and continued to 450 m, where it reached equilibrium with the gaseous phase. Measurements indicated that methane occupied 0-9% by volume in the GHSZ, and ~12% in the gaseous zone.
In the less common second type found near the sediment surface some samples have a higher proportion of longer-chain hydrocarbons (< 99% methane) contained in a structure II clathrate. Carbon from this type of clathrate is isotopically heavier (δ13C is -29 to -57 ‰) and is thought to have migrated upwards from deep sediments, where methane was formed by thermal decomposition of organic matter. Examples of this type of deposit have been found in the Gulf of Mexico and the Caspian Sea.
Some deposits have characteristics intermediate between the microbially and thermally sourced types and are considered to be formed from a mixture of the two.
The methane in gas hydrates is dominantly generated by microbial consortia degrading organic matter in low oxygen environments, with the methane itself produced by methanogenic archaea. Organic matter in the uppermost few centimetres of sediments is first attacked by aerobic bacteria, generating CO2, which escapes from the sediments into the water column. Below this region of aerobic activity, anaerobic processes take over, including, successively with depth, the microbial reduction of nitrite/nitrate, metal oxides, and then sulfates are reduced to sulfides. Finally, once sulfate is used up, methanogenesis becomes a dominant pathway for organic carbon remineralization.
If the sedimentation rate is low (about 1 cm/yr), the organic carbon content is low (about 1% ), and oxygen is abundant, aerobic bacteria can use up all the organic matter in the sediments faster than oxygen is depleted, so lower-energy electron acceptors are not used. But where sedimentation rates and the organic carbon content are high, which is typically the case on continental shelves and beneath western boundary current upwelling zones, the pore water in the sediments becomes anoxic at depths of only a few centimeters or less. In such organic-rich marine sediments, sulfate then becomes the most important terminal electron acceptor due to its high concentration in seawater, although it too is depleted by a depth of centimeters to meters. Below this, methane is produced. This production of methane is a rather complicated process, requiring a highly reducing environment (Eh -350 to -450 mV) and a pH between 6 and 8, as well as a complex syntrophic consortia of different varieties of archaea and bacteria, although it is only archaea that actually emit methane.
In some regions (e.g., Gulf of Mexico) methane in clathrates may be at least partially derived from thermal degradation of organic matter, dominantly in petroleum. The methane in clathrates typically has a biogenic isotopic signature and highly variable δ13C (-40 to -100‰), with an approximate average of about -65‰ . Below the zone of solid clathrates, large volumes of methane may form bubbles of free gas in the sediments.
The presence of clathrates at a given site can often be determined by observation of a "bottom simulating reflector" (BSR), which is a seismic reflection at the sediment to clathrate stability zone interface caused by the unequal densities of normal sediments and those laced with clathrates.
Reservoir size.
The size of the oceanic methane clathrate reservoir is poorly known, and estimates of its size decreased by roughly an order of magnitude per decade since it was first recognized that clathrates could exist in the oceans during the 1960s and '70s. The highest estimates (e.g. 3×1018 m³) were based on the assumption that fully dense clathrates could litter the entire floor of the deep ocean. Improvements in our understanding of clathrate chemistry and sedimentology have revealed that hydrates form in only a narrow range of depths (continental shelves), at only some locations in the range of depths where they could occur (10-30% of the GHSZ), and typically are found at low concentrations (0.9-1.5% by volume) at sites where they do occur. Recent estimates constrained by direct sampling suggest the global inventory occupies between 1×1015and 5×1015 m³ (0.24 to 1.2 million cubic miles). This estimate, corresponding to 500-2500 gigatonnes carbon (Gt C), is smaller than the 5000 Gt C estimated for all other geo-organic fuel reserves but substantially larger than the ~230 Gt C estimated for other natural gas sources. The permafrost reservoir has been estimated at about 400 Gt C in the Arctic, but no estimates have been made of possible Antarctic reservoirs.
These are large amounts; for comparison the total carbon in the atmosphere is around 800 gigatons (see Carbon: Occurrence).
These modern estimates are notably smaller than the 10,000 to 11,000 Gt C (2×1016 m³) proposed by previous researchers as a reason to consider clathrates to be a geo-organic fuel resource (MacDonald 1990, Kvenvolden 1998). Lower abundances of clathrates do not rule out their economic potential, but a lower total volume and apparently low concentration at most sites does suggest that only a limited percentage of clathrates deposits may provide an economically viable resource.
Continental.
Methane clathrates in continental rocks are trapped in beds of sandstone or siltstone at depths of less than 800 m. Sampling indicates they are formed from a mix of thermally and microbially derived gas from which the heavier hydrocarbons were later selectively removed. These occur in Alaska, Siberia, and Northern Canada.
In 2008, Canadian and Japanese researchers extracted a constant stream of natural gas from a test project at the Mallik gas hydrate site in the Mackenzie River delta. This was the second such drilling at Mallik: the first took place in 2002 and used heat to release methane. In the 2008 experiment, researchers were able to extract gas by lowering the pressure, without heating, requiring significantly less energy. The Mallik gas hydrate field was first discovered by Imperial Oil in 1971-1972.
Commercial use.
The sedimentary methane hydrate reservoir probably contains 2–10 times the currently known reserves of conventional natural gas, . This represents a potentially important future source of hydrocarbon fuel. However, in the majority of sites deposits are thought to be too dispersed for economic extraction. Other problems facing commercial exploitation are detection of viable reserves and development of the technology for extracting methane gas from the hydrate deposits.
A research and development project in Japan is aiming for commercial-scale extraction near Aichi Prefecture by 2016. In August 2006, China announced plans to spend 800 million yuan (US$100 million) over the next 10 years to study natural gas hydrates. A potentially economic reserve in the Gulf of Mexico may contain approximately 100 e9m3 of gas. Bjørn Kvamme and Arne Graue at the Institute for Physics and technology at the University of Bergen have developed a method for injecting CO2 into hydrates and reversing the process; thereby extracting CH4 by direct exchange. The University of Bergen's method is being field tested by ConocoPhillips and state-owned Japan Oil, Gas and Metals National Corporation (JOGMEC), and partially funded by the U.S. Department of Energy. The project has already reached injection phase and was analyzing resulting data by March 12, 2012.
On March 12, 2013, JOGMEC researchers announced that they had successfully extracted natural gas from frozen methane hydrate. In order to extract the gas, specialized equipment was used to drill into and depressurize the hydrate deposits, causing the methane to separate from the ice. The gas was then collected and piped to surface where it was ignited to prove its presence. According to an industry spokesperson, "It [was] the world's first offshore experiment producing gas from methane hydrate". Previously, gas had been extracted from onshore deposits, but never from offshore deposits which are much more common. The hydrate field from which the gas was extracted is located 50 km from central Japan in the Nankai Trough, 300 m under the sea. A spokesperson for JOGMEC remarked "Japan could finally have an energy source to call its own". The experiment will continue for two weeks before it is determined how efficient the gas extraction process has been. Marine geologist Mikio Satoh remarked "Now we know that extraction is possible. The next step is to see how far Japan can get costs down to make the technology economically viable." Japan estimates that there are at least 1.1 trillion cubic meters of methane trapped in the Nankai Trough, enough to meet the country's needs for more than ten years.
Hydrates in natural gas processing.
Routine operations.
Methane clathrates (hydrates) are also commonly formed during natural gas production operations, when liquid water is condensed in the presence of methane at high pressure. It is known that larger hydrocarbon molecules like ethane and propane can also form hydrates, although longer molecules (butanes, pentanes) cannot fit into the water cage structure and tend to destabilise the formation of hydrates.
Once formed, hydrates can block pipeline and processing equipment. They are generally then removed by reducing the pressure, heating them, or dissolving them by chemical means (methanol is commonly used). Care must be taken to ensure that the removal of the hydrates is carefully controlled, because of the potential for the hydrate to undergo a phase transition from the solid hydrate to release water and gaseous methane at a high rate when the pressure is reduced. The rapid release of methane gas in a closed system can result in a rapid increase in pressure.
It is generally preferable to prevent hydrates from forming or blocking equipment. This is commonly achieved by removing water, or by the addition of ethylene glycol (MEG) or methanol, which act to depress the temperature at which hydrates will form (i.e. common antifreeze). In recent years, development of other forms of hydrate inhibitors have been developed, like Kinetic Hydrate Inhibitors (which by far slow the rate of hydrate formation) and anti-agglomerates, which do not prevent hydrates forming, but do prevent them sticking together to block equipment.
Effect of hydrate phase transition during deep water drilling.
When drilling in oil- and gas-bearing formations submerged in deep water, the reservoir gas may flow into the well bore and form gas hydrates owing to the low temperatures and high pressures found during deep water drilling. The gas hydrates may then flow upward with drilling mud or other discharged fluids. When the hydrates rise, the pressure in the annulus decreases and the hydrates dissociate into gas and water. The rapid gas expansion ejects fluid from the well, reducing the pressure further, which leads to more hydrate dissociation and further fluid ejection. The resulting violent expulsion of fluid from the annulus is one potential cause or contributor to the "kick". (Kicks, which can cause blowouts, typically do not involve hydrates: see Blowout: formation kick).
Measures which reduce the risk of hydrate formation include:
Blowout recovery.
At sufficient depths, methane complexes directly with water to form methane hydrates, as was observed during the Deepwater Horizon oil spill in 2010. BP engineers developed and deployed a subsea oil recovery system over oil spilling from a deepwater oil well 5000 ft below sea level to capture escaping oil. This involved placing a 125 t dome over the largest of the well leaks and piping it to a storage vessel on the surface. This option had the potential to collect some 85% of the leaking oil but was previously untested at such depths. BP deployed the system on May 7–8, but it failed due to buildup of methane clathrate inside the dome; with its low density of approximately 0.9 g/cm3 the methane hydrates accumulated in the dome, adding buoyancy and obstructing flow.
Methane clathrates and climate change.
Methane is a powerful greenhouse gas. Despite its short atmospheric half life of 7 years, methane has a global warming potential of 86 over 20 years and 34 over 100 years (IPCC, 2013). The sudden release of large amounts of natural gas from methane clathrate deposits has been hypothesized as a cause of past and possibly future climate changes. Events possibly linked in this way are the Permian-Triassic extinction event and the Paleocene-Eocene Thermal Maximum.
Climate scientists like James E. Hansen predict that methane clathrates in the permafrost regions will be released because of global warming, unleashing powerful feedback forces which may cause runaway climate change that cannot be halted.
Recent research carried out in 2008 in the Siberian Arctic has shown millions of tonnes of methane being released with concentrations in some regions reaching up to 100 times above normal.
In their Correspondence in the September 2013 "Nature Geoscience" journal, Vonk and Gustafsson cautioned that the most probable mechanism to strengthen global warming is large-scale thawing of Arctic permafrost which will release methane clathrate into the atmosphere. While performing research in July in plumes in the East Siberian Arctic Ocean, Gustafsson and Vonk were surprised by the high concentration of methane.
In 2014 based on their research on the northern United States Atlantic marine continental margins from Cape Hatteras to Georges Bank, a group of scientists from the US Geological Survey, the Department of Geosciences, Mississippi State University, Department of Geological Sciences, Brown University and Earth Resources Technology, claimed there was widespread leakage of methane.
Natural gas hydrates versus liquified natural gas in transportation.
Since methane clathrates are stable at a higher temperature than liquefied natural gas (LNG) (−20 vs −162 °C), there is some interest in converting natural gas into clathrates rather than liquifying it when transporting it by seagoing vessels. A significant advantage would be that the production of natural gas hydrate (NGH) from natural gas at the terminal would require a smaller refrigeration plant and less energy than LNG would. Offsetting this, for 100 tonnes of methane transported, 750 tonnes of methane hydrate would have to be transported; since this would require a ship of 7.5 times greater displacement, or require more ships, it is unlikely to prove economic.

</doc>
<doc id="54139" url="http://en.wikipedia.org/wiki?curid=54139" title="Bureau of Land Management">
Bureau of Land Management

The Bureau of Land Management (BLM) is an agency within the United States Department of the Interior that administers more than 247.3 e6acre of public lands in the United States constituting one-eighth of the landmass of the country. President Harry S. Truman created the BLM in 1946 by combining two existing agencies— the General Land Office and the Grazing Service. The agency in addition manages the federal government's nearly 700 e6acre of subsurface mineral estate located beneath federal, state and private lands severed from their surface rights by the Homestead Act of 1862. Most BLM public lands are located in one of 12 western states: Alaska, Arizona, California, Colorado, Idaho, Montana, Nevada, New Mexico, Oregon, Utah, Washington and Wyoming.
The mission of the BLM is "to sustain the health, diversity, and productivity of the public lands for the use and enjoyment of present and future generations." Originally BLM holdings were described as "land nobody wanted" because homesteaders had passed them by. All the same, ranchers hold nearly 18,000 permits and leases for livestock grazing on 155 e6acre of BLM public lands. The agency manages 221 wilderness areas, 20 national monuments and some 636 other protected areas as part of the National Landscape Conservation System totaling about 30 e6acre. There are more than 63,000 oil and gas wells on BLM public lands; total energy leases generated approximately $5.4 billion in 2013, an amount divided among the Treasury, the states and Native American groups.
History.
The BLM's roots go back to the Land Ordinance of 1785 and the Northwest Ordinance of 1787. These laws provided for the survey and settlement of the lands that the original 13 colonies ceded to the federal government after the American Revolution. As additional lands were acquired by the United States from Spain, France and other countries, the United States Congress directed that they be explored, surveyed, and made available for settlement. During the Revolutionary War, military bounty land was promised to soldiers who fought for the colonies. After the war, the Treaty of Paris of 1783, signed by the United States, England, France, and Spain, ceded territory to the United States. In the 1780s, other states relinquished their own claims to land in modern-day Ohio. By this time, the United States needed revenue to function. Land was sold so that the government would have money to survive. In order to sell the land, surveys needed to be conducted. The Land Ordinance of 1785 instructed a geographer to oversee this work as undertaken by a group of surveyors. The first years of surveying were completed by trial and error; once the territory of Ohio had been surveyed, a modern public land survey system had been developed. In 1812, Congress established the General Land Office as part of the Department of the Treasury to oversee the disposition of these federal lands. By the early 1800s, promised bounty land claims were finally fulfilled.
Over the years, other bounty land and homestead laws were enacted to dispose of federal land. Several different types of patents existed. These include cash entry, credit, homestead, Indian, military warrants, mineral certificates, private land claims, railroads, state selections, swamps, town sites, and town lots. A system of local land offices spread throughout the territories, patenting land that was surveyed via the corresponding Office of the Surveyor General of a particular territory. This pattern gradually spread across the entire United States. The laws that spurred this system with the exception of the General Mining Law of 1872 and the Desert Land Act of 1877 have since been repealed or superseded.
In the early 20th century, Congress took additional steps toward recognizing the value of the assets on public lands and directed the Executive Branch to manage activities on the remaining public lands. The Mineral Leasing Act of 1920 allowed leasing, exploration, and production of selected commodities, such as coal, oil, gas, and sodium to take place on public lands. The Taylor Grazing Act of 1934 established the United States Grazing Service to manage the public rangelands by establishment of advisory boards that set grazing fees. The Oregon and California Revested Lands Sustained Yield Management Act of 1937, commonly referred as the O&C Act, required sustained yield management of the timberlands in western Oregon.
In 1946, the Grazing Service was merged with the General Land Office to form the Bureau of Land Management within the Department of the Interior. It took several years for this new agency to integrate and reorganize. In the end, the Bureau of Land Management became less focused on land disposal and more focused on the long term management and preservation of the land. The agency achieved its current form by combining offices in the western states and creating a corresponding office for lands both east of and alongside the Mississippi River. As a matter of course BLM's emphasis fell on activities in the western states as most of the mining, land sales, and federally owned areas are located west of the Mississippi.
BLM personnel on the ground have typically been oriented toward local interests, while bureau management in Washington are led by presidential guidance. By means of the Federal Land Policy and Management Act of 1976, Congress created a more unified bureau mission and recognized the value of the remaining public lands by declaring that these lands would remain in public ownership. The law directed that these lands be managed with a view toward "multiple use" defined as "management of the public lands and their various resource values so that they are utilized in the combination that will best meet the present and future needs of the American people."
Since the Reagan years of the 1980s, Republicans have often given priority to local control and to grazing, mining and petroleum production, while Democrats have more often emphasized environmental concerns even when granting mining and drilling leases. In September 1996, then President Bill Clinton used his authority under the Antiquities Act to establish the Grand Staircase-Escalante National Monument in southern Utah, the first of now 20 national monuments established on BLM lands and managed by the agency. The establishment of Grand Staircase-Escalante foreshadowed later creation of the BLM's National Landscape Conservation System in 2000. Use of the Antiquities Act authority, to the extent it effectively scuttled a coal mine to have been operated by Andalex Resources, delighted recreation and conservation enthusiasts but set up larger confrontations with state and local authorities. The changing demographics in the western states have led some to suggest that the BLM, long derided as the "Bureau of Livestock and Mines," is in the midst of becoming the "Bureau of Landscapes and Monuments."
National Landscape Conservation System.
Established in 2000, the National Landscape Conservation System is overseen by the BLM. The National Landscape Conservation System lands constitute just about 12% of the lands managed by the BLM. Congress passed Title II of the Omnibus Public Land Management Act of 2009 (Public Law 111-11) to make the system a permanent part of the public lands protection system in the United States. By designating these areas for conservation, the law directed the BLM to ensure these places are protected for future generations, similar to national parks and wildlife refuges.
Law enforcement and security.
The BLM, through its Office of Law Enforcement & Security, functions as a federal law enforcement agency of the United States Government. BLM law enforcement rangers and special agents receive their training through Federal Law Enforcement Training Center (FLETC). Full-time staffing for these positions approaches 300.
Uniformed rangers enforce laws and regulations governing BLM lands and resources. As part of that mission, these BLM rangers carry firearms, defensive equipment, make arrests, execute search warrants, complete reports and testify in court. They seek to establish a regular and recurring presence on a vast amount of public lands, roads and recreation sites. They focus on the protection of natural and cultural resources, other BLM employees and visitors. Given the many locations of BLM public lands, these rangers use canines, helicopters, snowmobiles, dirt bikes and boats to perform their duties.
By contrast BLM special agents are criminal investigators who plan and conduct investigations concerning possible violations of criminal and administrative provisions of the BLM and other statutes under the United States Code. Special agents are normally plain clothes officers who carry concealed firearms, and other defensive equipment, make arrests, carry out complex criminal investigations, present cases for prosecution to local United States Attorneys and prepare investigative reports. Criminal investigators occasionally conduct internal and civil claim investigations.
Wild Horse and Burro Program.
The BLM manages free-roaming horses and burros on public lands in ten western states. Though they are feral, the agency is obligated to protect them under the Wild and Free-Roaming Horses and Burros Act of 1971 (WFRHBA). As the horses have few natural predators, populations have grown substantially. WFRHBA as enacted provides for the removal of excess animals; the destruction of lame, old, or sick animals; the private placement or adoption of excess animals; and even the destruction of healthy animals if range management required it. In fact, the destruction of healthy or unhealthy horses has almost never occurred. Pursuant to the Public Rangelands Improvement Act of 1978, the BLM has established 179 "herd management areas" (HMAs) covering 31.6 e6acre acres where feral horses can be found on federal lands.
In 1973, BLM began a pilot project on the Pryor Mountains Wild Horse Range known as the Adopt-A-Horse initiative. The program took advantage of provisions in the WFRHBA to allow private "qualified" individuals to "adopt" as many horses as they wanted if they could show that they could provide adequate care for the animals. At the time, title to the horses remained permanently with the federal government. The pilot project was so successful that BLM allowed it to go nationwide in 1976. The Adopt-a-Horse program quickly became the primary method of removing excess feral horses from BLM land given the lack of other viable methods. The BLM also uses limited amounts of contraceptives in the herd, in the form of PZP vaccinations; advocates say that additional use of these vaccines would help to diminish the excess number of horses currently under BLM management.
Despite the early successes of the adoption program, the BLM has struggled to maintain acceptable herd levels, as without natural predators, herd sizes can double every four years. As of 2014, there were more than 49,000 horses and burros on BLM-managed land, exceeding the BLM's estimated "appropriate management level" (AML) by almost 22,500.
Renewable energy.
In 2009, BLM opened Renewable Energy Coordination Offices in order to approve and oversee wind, solar, biomass, and geothermal projects on BLM-managed lands. The offices were located in the four states where energy companies had shown the greatest interest in renewable energy development: Arizona, California, Nevada, and Wyoming.

</doc>
<doc id="54140" url="http://en.wikipedia.org/wiki?curid=54140" title="Clathrate hydrate">
Clathrate hydrate

Clathrate hydrates (or "gas clathrates", "gas hydrates", "clathrates", "hydrates", etc.)
are crystalline water-based solids physically resembling ice, in which small non-polar molecules (typically gases) or polar molecules with large hydrophobic moieties are trapped inside "cages" of hydrogen bonded, frozen water molecules. In other words, clathrate hydrates are clathrate compounds in which the host molecule is water and the guest molecule is typically a gas or liquid. Without the support of the trapped molecules, the lattice structure of hydrate clathrates would collapse into conventional ice crystal structure or liquid water. Most low molecular weight gases, including O2, H2, N2, CO2, CH4, H2S, Ar, Kr, and Xe, as well as some higher hydrocarbons and freons, will form hydrates at suitable temperatures and pressures. Clathrate hydrates are not officially chemical compounds, as the sequestered molecules are never bonded to the lattice. The formation and decomposition of clathrate hydrates are first order phase transitions, not chemical reactions. Their detailed formation and decomposition mechanisms on a molecular level are still not well understood.
Clathrate hydrates were first documented in 1810 by Sir Humphry Davy who found that water was a primary component of what was earlier thought to be solidified chlorine.
Clathrates have been found to occur naturally in large quantities. Around 6.4 trillion (6.4×1012) tonnes of methane is trapped in deposits of methane clathrate on the deep ocean floor. Such deposits can be found on the Norwegian continental shelf in the northern headwall flank of the Storegga Slide. Clathrates can also exist as permafrost, as at the Mallik gas hydrate site in the Mackenzie Delta of northwestern Canadian Arctic. These natural gas hydrates are seen as a potentially vast energy resource, but an economical extraction method has so far proven elusive. Hydrocarbon clathrates cause problems for the petroleum industry, because they can form inside gas pipelines, often resulting in obstructions. Deep sea deposition of carbon dioxide clathrate has been proposed as a method to remove this greenhouse gas from the atmosphere and control climate change.
Clathrates are suspected to occur in large quantities on some outer planets, moons and trans-Neptunian objects, binding gas at fairly high temperatures.
Structure.
Gas hydrates usually form two crystallographic cubic structures – structure (Type) I and structure (Type) II of space groups formula_1 and formula_2 respectively. Seldom, a third hexagonal structure of space group formula_3 may be observed (Type H).
The unit cell of Type I consists of 46 water molecules, forming two types of cages – small and large. The unit cell contains two small cages and six large ones. The small cage has the shape of a pentagonal dodecahedron (512) (which is not a regular dodecahedron) and the large one that of a tetradecahedron, specifically a hexagonal truncated trapezohedron (51262). Together, they form a version of the Weaire-Phelan structure. Typical guests forming Type I hydrates are CO2 in carbon dioxide clathrate and CH4 in methane clathrate.
The unit cell of Type II consists of 136 water molecules, again forming two types of cages – small and large. In this case there are sixteen small cages and eight large ones in the unit cell. The small cage again has the shape of a pentagonal dodecahedron (512), but the large one is a hexadecahedron (51264). Type II hydrates are formed by gases like O2 and N2.
The unit cell of Type H consists of 34 water molecules, forming three types of cages – two small ones of different types, and one "huge". In this case, the unit cell consists of three small cages of type 512, two small ones of type 435663 and one huge of type 51268. The formation of Type H requires the cooperation of two guest gases (large and small) to be stable. It is the large cavity that allows structure H hydrates to fit in large molecules (e.g. butane, hydrocarbons), given the presence of other smaller help gases to fill and support the remaining cavities. Structure H hydrates were suggested to exist in the Gulf of Mexico. Thermogenically-produced supplies of heavy hydrocarbons are common there.
Hydrates in the Universe.
Iro "et al.", trying to interpret the nitrogen deficiency in comets, stated most of the conditions for hydrate formation in the protoplanetary nebulae, surrounding the pre-main and main sequence stars were fulfilled, despite the rapid grain growth to meter scale. The key was to provide enough microscopic ice particles exposed to a gaseous environment. Observations of the radiometric continuum of circumstellar discs around formula_4-Tauri and Herbig Ae/Be stars suggest massive dust disks consisting of millimeter-sized grains, which disappear after several million years (e.g.,). A lot of work on detecting water ices in the Universe was done on the Infrared Space Observatory (ISO). For instance, broad emission bands of water ice at 43 and 60 μm were found in the disk of the isolated Herbig Ae/Be star HD 100546 in Musca. The one at 43 μm is much weaker than the one at 60 μm, which means the water ice, is located in the outer parts of the disk at temperatures below 50 K. There is also another broad ice feature between 87 and 90 μm, which is very similar to the one in NGC 6302 (the Bug or Butterfly nebula in Scorpius). Crystalline ices were also detected in the proto-planetary disks of ε-Eridani and the isolated Fe star HD 142527 in Lupus. 90% of the ice in the latter was found crystalline at temperature around 50 K. HST demonstrated that relatively old circumstellar disks, as the one around the 5-million-year-old B9.5Ve Herbig Ae/Be star HD 141569A, are dusty. Li & Lunine found water ice there. Knowing the ices usually exist at the outer parts of the proto-planetary nebulae, Hersant "et al." proposed an interpretation of the volatile enrichment, observed in the four giant planets of the Solar System, with respect to the Solar abundances. They assumed the volatiles had been trapped in the form of hydrates and incorporated in the planetesimals flying in the protoplanets’ feeding zones.
Kieffer "et al." (2006) suggest that the geyser activity in the south polar region of Saturn's moon Enceladus originates from clathrate hydrates, where carbon dioxide, methane, and nitrogen are released when exposed to the vacuum of space by the "Tiger Stripe" fractures found in that area.
Carbon dioxide clathrate is believed to play a major role in different processes on Mars. Hydrogen clathrate is likely to form in condensation nebulae for gas giants.
Hydrates on Earth.
Natural gas hydrates.
Naturally on Earth gas hydrates can be found on the seabed, in ocean sediments, in deep lake sediments (e.g. Lake Baikal), as well as in the permafrost regions. The amount of methane potentially trapped in natural methane hydrate deposits may be significant (1015 to 1017 cubic metres), which makes them of major interest as a potential energy resource. Catastrophic release of methane from the decomposition of such deposits may lead to a global climate change, because CH4 is more of an efficient greenhouse gas than CO2 (see Atmospheric methane). The fast decomposition of such deposits is considered a geohazard, due to its potential to trigger landslides, earthquakes and tsunamis. However, natural gas hydrates do not contain only methane but also other hydrocarbon gases, as well as H2S and CO2. Air hydrates are frequently observed in polar ice samples.
Pingos are common structures in permafrost regions. Similar structures are found in deep water related to methane leakages.
Significantly, gas hydrates can even be formed in the absence of a liquid phase. Under that situation, water is dissolved in gas or in liquid hydrocarbon phase.
Gas hydrates in pipelines.
Thermodynamic conditions favouring hydrate formation are often found in pipelines. This is highly undesirable, because the clathrate crystals might agglomerate and plug the line and cause flow assurance failure and damage valves and instrumentation. The results can range from flow reduction to equipment damage.
Hydrate formation, prevention and mitigation philosophy.
Hydrates have a strong tendency to agglomerate and to adhere to the pipe wall and thereby plug the pipeline. Once formed, they can be decomposed by increasing the temperature and/or decreasing the pressure. Even under these conditions, the clathrate dissociation is a slow process.
Therefore, preventing hydrate formation appears to be the key to the problem. A hydrate prevention philosophy could typically be based on three levels of security, listed in order of priority:
The actual philosophy would depend on operational circumstances such as pressure, temperature, type of flow (gas, liquid, presences of water etc.)
Hydrate inhibitors.
When operating within a set of parameters where hydrates could be formed, there are still ways to avoid their formation. Altering the gas composition by adding chemicals can lower the hydrate formation temperature and/or delay their formation. Two options generally exist:
The most common thermodynamic inhibitors are methanol, monoethylene glycol (MEG), and diethylene glycol (DEG), commonly referred to as glycol. All may be recovered and recirculated, but the economics of methanol recovery is not favourable in most cases. MEG is preferred over DEG for applications where the temperature is expected to be −10 °C or lower due to high viscosity at low temperatures. Triethylene glycol (TEG) has too low vapour pressure to be suited as an inhibitor injected into a gas stream. More methanol is lost in the gas phase when compared to MEG or DEG.
The use of kinetic inhibitors and anti-agglomerants in actual field operations is a new and evolving technology. It requires extensive tests and optimisation to the actual system. While kinetic inhibitors work by slowing down the kinetics of the nucleation, anti-agglomerants do not stop the nucleation, but stop the agglomeration (sticking together) of gas hydrate crystals. These two kinds of inhibitors are also known as Low-Dosage-Hydrate-Inhibitors, because they require much smaller concentrations than the conventional thermodynamic inhibitors. Kinetic inhibitors, which do not require water and hydrocarbon mixture to be effective, are usually polymers or copolymers and anti-agglomerants (requires water and hydrocarbon mixture) are polymers or zwitterionic — usually ammonium and COOH — surfactants being both attracted to hydrates and hydrocarbons.

</doc>
<doc id="54146" url="http://en.wikipedia.org/wiki?curid=54146" title="Breadfruit">
Breadfruit

Breadfruit (Artocarpus altilis) is a species of flowering tree in the mulberry family, Moraceae originating in the South Pacific and that was eventually spread to the rest of Oceania. British and French navigators introduced a few Polynesian seedless varieties to Caribbean islands during the late 18th century and today it is grown in some 90 countries throughout South and Southeast Asia, the Pacific Ocean, the Caribbean, Central America and Africa. Its name is derived from the texture of the cooked moderately ripe fruit, which has a potato-like flavor, similar to freshly baked bread.
Ancestors of the Polynesians found the trees growing in the northwest New Guinea area around 3,500 years ago. They gave up the rice cultivation they had brought with them from Taiwan, and raised breadfruit wherever they went in the Pacific (except Easter Island and New Zealand, which are too cold). Their ancient eastern Indonesian cousins spread the plant west and north through insular and coastal Southeast Asia. It has, in historical times, also been widely planted in tropical regions elsewhere.
Description.
Breadfruit trees grow to a height of 25 m. The large and thick leaves are deeply cut into pinnate lobes. All parts of the tree yield latex, a milky juice, which is useful for boat caulking.
The trees are monoecious, with male and female flowers growing on the same tree. The male flowers emerge first, followed shortly afterward by the female flowers, which grow into capitula, which are capable of pollination just three days later. The compound, false fruit develops from the swollen perianth, and originates from 1,500-2,000 flowers. These are visible on the skin of the fruit as hexagon-like disks.
Breadfruit is one of the highest-yielding food plants, with a single tree producing up to 200 or more grapefruit-sized fruits per season, and only requires very limited care. In the South Pacific, the trees yield 50 to 150 fruits per year. In southern India, normal production is 150 to 200 fruits annually. Productivity varies between wet and dry areas. In the Caribbean, a conservative estimate is 25 fruits per tree. Studies in Barbados indicate a reasonable potential of 16 to 32 tons per hectare (6.7-13.4 tons/acre). The ovoid fruit has a rough surface, and each fruit is divided into many achenes, each achene surrounded by a fleshy perianth and growing on a fleshy receptacle. Most selectively bred cultivars have seedless fruit.
The breadfruit is closely related to the breadnut, from which it might have been selected, and to the jackfruit.
Habitat.
Breadfruit, an equatorial lowland species, grows best below elevations of 650 m, but is found at elevations of 1550 m. Its preferred rainfall is 1500 – per year. Preferred soils are neutral to alkaline (pH of 6.1-7.4) and either sand, sandy loam, loam or sandy clay loam. Breadfruit is able to grow in coral sands and saline soils.
Uses.
Breadfruit is a staple food in many tropical regions. The trees were first propagated far outside their native range by Polynesian voyagers who transported root cuttings and air-layered plants over long ocean distances. Breadfruit are very rich in starch, and before being eaten, they are roasted, baked, fried or boiled. When cooked, the taste of moderately ripe breadfruit is described as potato-like, or similar to freshly baked bread. Very ripe breadfruit becomes sweet, as the starch converts to sugar.
Because breadfruit trees usually produce large crops at certain times of the year, preservation of the harvested fruit is an issue. One traditional preservation technique is to bury peeled and washed fruits in a leaf-lined pit where they ferment over several weeks and produce a sour, sticky paste. So stored, the product may last a year or more, and some pits are reported to have produced edible contents more than 20 years later. Fermented breadfruit mash goes by many names such as "mahr", "ma", "masi", "furo", and "bwiru", among others.
Most breadfruit varieties also produce a small number of fruits throughout the year, so fresh breadfruit is always available, but somewhat rare when not in season.
Breadfruit can be eaten once cooked, or can be further processed into a variety of other foods. A common product is a mixture of cooked or fermented breadfruit mash mixed with coconut milk and baked in banana leaves. Whole fruits can be cooked in an open fire, then cored and filled with other foods, such as coconut milk, sugar and butter, cooked meats, or other fruits. The filled fruit can be further cooked so the flavor of the filling permeates the flesh of the breadfruit.
The Hawaiian staple food called "poi", made of mashed taro root, is easily substituted for, or augmented with, mashed breadfruit. The resulting "breadfruit poi" is called "poi ʻulu". In Puerto Rico, breadfruit is called "panapen" or "pana", for short and in some in-land regions it's also called "mapén". "Pana" is often served boiled with a mixture of sauteed" bacalao" (salted cod fish), olive oil and onions. It is also served as "tostones" or "mofongo". In the Dominican Republic, it is known by the name "buen pan" or "good bread". Breadfruit is also found in Indonesia and Malaysia, where it is called "sukun". In the South Indian state of Kerala and coastal Karnataka, especially on the sides of Mangalore, where it is widely grown and cooked, it is known as "kada chakka" or "seema chakka" and "deegujje", respectively. In Belize, the Mayan people call it "masapan".
Breadfruit is roughly 25% carbohydrates and 70% water. It has an average amount of vitamin C (20 mg/100 g), small amounts of minerals (potassium and zinc) and thiamin (100 μg/100 g).
Breadfruit was widely and diversely used among Pacific Islanders. Its lightweight wood (specific gravity of 0.27) is resistant to termites and shipworms, so is used as timber for structures and outrigger canoes. Its wood pulp can also be used to make paper, called breadfruit "tapa". It is also used in traditional medicine to treat illnesses that range from sore eyes to sciatica. Native Hawaiians used its sticky latex to trap birds, whose feathers were made into cloaks.
In a 2012 research study published in the Journal of Agricultural and Food Chemistry, scientists at the Agricultural Research Service (ARS), a division of the USDA, and collaborators at the University of British Columbia in Okanagan, Canada, "identified three breadfruit compounds — capric, undecanoic and lauric acids — that act as insect repellents." These saturated fatty acids were "found to be significantly more effective at repelling mosquitoes than DEET."
In history.
Sir Joseph Banks and others saw the value of breadfruit as a highly productive food in 1769, when stationed in Tahiti as part of the "Endeavour" expedition commanded by Captain James Cook. The late-18th-century quest for cheap, high-energy food sources for slaves in British colonies prompted colonial administrators and plantation owners to call for the introduction of this plant to the Caribbean. As President of The Royal Society, Banks provided a cash bounty and gold medal for success in this endeavor, and successfully lobbied his friends in government and the Admiralty for a British Naval expedition. In 1787, William Bligh was appointed Captain of the HMS "Bounty", and was instructed to proceed to the South Pacific for this task. Banks appointed a gardener for the expedition and gave detailed instructions on how the plants were to be maintained. The "Bounty" remained in Tahiti for five idyllic months, during which over 1000 plants were collected, potted and transferred to the ship. However, within a month of leaving, many of the crew mutinied, expelling Captain Bligh and supporters in a long-boat, and returned to Tahiti. Bligh survived the ordeal, sailing with 18 loyal crew the 3618 nmi to Timor, reaching there in late 1789. In 1791, Bligh commanded a second expedition with the "Providence" and the "Assistant", which collected live breadfruit plants in Tahiti and transported these to St Helena, in the Atlantic, and St. Vincent and Jamaica in the West Indies. Although Bligh won the Royal Society medal for his efforts, the introduction was not entirely successful, as the slaves refused to eat breadfruit. However, breadfruit was accepted into the cuisine of Puerto Rico.
In culture.
On Puluwat in the Caroline Islands, in the context of sacred "yitang" lore, breadfruit ("poi") is a figure of speech for knowledge — in fact, this lore is organized in to five categories: war, magic, meetings, navigation, and "breadfruit".
According to an etiological Hawaiian myth, the breadfruit originated from the sacrifice of the war god Kū. After deciding to live secretly among mortals as a farmer, Kū married and had children. He and his family lived happily until a famine seized their island. When he could no longer bear to watch his children suffer, Kū told his wife that he could deliver them from starvation, but to do so he would have to leave them. Reluctantly she agreed, and at her word, Kū descended into the ground right where he had stood until only the top of his head was visible. His family waited around the spot he had last been, day and night, watering it with their tears until suddenly, a small green shoot appeared where Kū had stood. Quickly, the shoot grew into a tall and leafy tree that was laden with heavy breadfruits that Kū's family and neighbors gratefully ate, joyfully saved from starvation.
Though they are widely distributed throughout the Pacific, many breadfruit hybrids and cultivars are seedless or otherwise biologically incapable of naturally dispersing long distances. Therefore, their distribution in the Pacific was clearly enabled by humans, specifically prehistoric groups who colonized the Pacific Islands. To investigate the patterns of human migration throughout the Pacific, scientists have used molecular dating of breadfruit hybrids and cultivars in concert with anthropological data. Results support the west-to-east migration hypothesis, in which the Lapita people are thought to have traveled from Melanesia to numerous Polynesian islands.
The world's largest collection of breadfruit varieties has been established by botanist Diane Ragone, from over 20 years' travel to 50 Pacific islands, on a 10 acre plot outside of Hana, Hawaii, on the isolated east coast of Maui.
The wood of the breadfruit tree was one of the most valuable timbers in the construction of traditional houses in Samoan architecture.
Recipes for breadfruit.
There are many ways to cook breadfruit. In countries such as Sri Lanka, it is either cooked as a curry using coconut milk and spices (which becomes a side dish) or consumed after boiling. Boiled breadfruit is a famous main meal and is often consumed with scraped coconut, or "sambal" made out of coconut and chilies. Fritters of breadfruit are also a local delicacy of coastal Karnataka.
In Seychelles, it was traditionally eaten as a substitute for rice, as an accompaniment to the mains. It would either be consumed boiled ("friyapen bwi") or grilled ("friyapen griye"), where it would be put whole in the wood fire used for cooking the main meal and then taken out when ready. It is also eaten as a dessert, called "ladob friyapen", where it is boiled in coconut milk, sugar, vanilla, cinnamon and a pinch of salt. 
It is often said in Seychelles, that travelers who visit Seychelles will always come back if they eat breadfruit cooked in Seychelles.
In Puerto Rico, it is traditionally eaten boiled with bacalao (salted codfish). It is also used to make "rellenos de pana" (mashed breadfruit filled with seasoned meat), mofongo, "tostones de pana" (double fried breadfruit), and even "lasaña de pana" (cooked mashed breadfruit layered with meat and topped with cheese). A popular dessert is also made with sweet ripe breadfruit: "flan de pana" (breadfruit custard).
In Barbados, breadfruit is boiled with salted meat and mashed with butter to make breadfruit coucou. It is usually eaten with saucy meat dishes.
Both ripe and unripe fruits have culinary uses, but unripe breadfruit is consumed cooked.
External links.
 (2002): Hawaiian Legend of the Guardian Spirits. "University of Hawaii Press, Honolulu".

</doc>
<doc id="54147" url="http://en.wikipedia.org/wiki?curid=54147" title="Bremsstrahlung">
Bremsstrahlung

Bremsstrahlung (], from "bremsen" "to brake" and "Strahlung" "radiation", i.e. "braking radiation" or "deceleration radiation") is electromagnetic radiation produced by the deceleration of a charged particle when deflected by another charged particle, typically an electron by an atomic nucleus. The moving particle loses kinetic energy, which is converted into a photon, thus satisfying the law of conservation of energy. The term is also used to refer to the process of producing the radiation. Bremsstrahlung has a continuous spectrum, which becomes more intense and whose peak intensity shifts toward higher frequencies as the change of the energy of the accelerated particles increases.
Strictly speaking, braking radiation is any radiation due to the acceleration of a charged particle, which includes synchrotron radiation, cyclotron radiation, and the emission of electrons and positrons during beta decay. However, the term is frequently used in the more narrow sense of radiation from electrons (from whatever source) slowing in matter.
Bremsstrahlung emitted from plasma is sometimes referred to as "free-free radiation". This refers to the fact that the radiation in this case is created by charged particles that are free both before and after the deflection (acceleration) that caused the emission.
Particle in vacuum.
A charged particle accelerating in a vacuum radiates power, as described by the Larmor formula and its relativistic generalizations. Although the term "bremsstrahlung" is "usually" reserved for charged particles accelerating in matter, not vacuum, the formulas are similar. (In this respect, bremsstrahlung differs from Cherenkov radiation, another kind of braking radiation which occurs "only" in matter, and not in a vacuum.)
Total radiated power.
The most established relativistic formula for total radiated power is given by
where formula_2 (the velocity of the particle divided by the speed of light), formula_3 is the Lorentz factor, formula_4 signifies a time derivative of formula_5, and "q" is the charge of the particle. This is commonly written in the mathematically equivalent form:
In the case where velocity is parallel to acceleration (for example, linear motion), the formula simplifies to
where formula_8 is the acceleration. For the case of acceleration perpendicular to the velocity (formula_9) (a case that arises in circular particle accelerators known as synchrotrons), the total power radiated reduces to
The total power radiated in the two limiting cases is proportional to formula_11 (formula_12) or formula_13 (formula_14). Since formula_15, we see that the total radiated power goes as formula_16 or formula_17, which accounts for why electrons lose energy to bremsstrahlung radiation much more rapidly than heavier charged particles (e.g., muons, protons, alpha particles). This is the reason a TeV energy electron-positron collider (such as the proposed International Linear Collider) cannot use a circular tunnel (requiring constant acceleration), while a proton-proton collider (such as the Large Hadron Collider) can utilize a circular tunnel. The electrons lose energy due to bremsstrahlung at a rate formula_18 times higher than protons do.
Angular distribution.
The most general formula for radiated power as a function of angle is:
However, a much simpler expression for the same integral can be found in (Eq. 2BN) and in (Eq. 4.1).
An analysis of the doubly differential cross section above shows that electrons whose kinetic energy is larger than the rest energy (511 keV) emit photons in forward direction while electrons with a small energy emit photons isotropically.
Electron-electron bremsstrahlung.
One mechanism which is important for small atomic numbers formula_20, is the scattering of a free electron at the shell electrons of an atom or molecule. Since electron-electron bremsstrahlung is a function of formula_20 and the usual electron-nucleus bremsstrahlung is a function of formula_22, electron-electron bremsstrahlung is negligible for metals. For air, however, it plays an important role in the production of terrestrial gamma-ray flashes.

</doc>
<doc id="54149" url="http://en.wikipedia.org/wiki?curid=54149" title="Dicotyledon">
Dicotyledon

The dicotyledons, also known as dicots, were one of the two groups into which all the flowering plants or angiosperms were formerly divided. The name refers to one of the typical characteristics of the group, namely that the seed typically has two embryonic leaves or cotyledons. There are around 200,000 species within this group. The other group of flowering plants were called monocotyledons or monocots, typically having one cotyledon. Historically, these two groups formed the two divisions of the flowering plants.
Largely from the 1990s onwards, molecular phylogenetic research confirmed what had already been suspected, namely that dicotyledons are not a group made up of all the descendants of a common ancestor (i.e. they are not a monophyletic group). Rather a number of lineages, such as the magnoliids and groups now collectively known as the basal angiosperms diverged earlier than the monocots did. The traditional dicots are thus a paraphyletic group. The largest clade of the dicotyledons are known as the eudicots. They are distinguished from all other flowering plants by the structure of their pollen. Other dicotyledons and monocotyledons have monosulcate pollen, or forms derived from it, whereas eudicots have tricolpate pollen, or derived forms, the pollen having three or more pores set in furrows called colpi.
Compared to Monocotyledons.
Aside from cotyledon number, other broad differences have been noted between monocots and dicots, although these have proven to be differences primarily between monocots and eudicots. Many early-diverging dicot groups have "monocot" characteristics such as scattered vascular bundles, trimerous flowers, and non-tricolpate pollen. In addition, some monocots have dicot characteristics such as reticulated leaf veins.
Classification.
Historical.
Traditionally the dicots have been called the Dicotyledones (or Dicotyledoneae), at any rank. If treated as a class, as in the Cronquist system, they could be called the Magnoliopsida after the type genus "Magnolia". In some schemes, the eudicots were treated as a separate class, the Rosopsida (type genus "Rosa"), or as several separate classes. The remaining dicots (palaeodicots or basal angiosperms) may be kept in a single paraphyletic class, called Magnoliopsida, or further divided. Some botanists prefer to retain the dicotyledons as a valid class, arguing its practicality and that it makes evolutionary sense.
APG (Angiosperm Phylogeny Group) vs. Cronquist Classification.
The following lists show the orders in the APG III system traditionally called dicots, together with the older Cronquist system.
Dahlgren and Thorne systems.
In the Dahlgren and the Thorne systems, the subclass name Magnoliidae was used for the dicotyledons. This is also the case in some of the systems derived from the Cronquist system. For each system, only the superorders are listed. The sequence of each system has been altered to pair corresponding taxa, although circumscription of superorders with the same name is not always the same. The Thorne system (1992) as depicted by Reveal is:

</doc>
<doc id="54151" url="http://en.wikipedia.org/wiki?curid=54151" title="Pope Liberius">
Pope Liberius

Pope Liberius (died 24 September 366) was Pope from 17 May 352 to his death in 366. According to the "Catalogus Liberianus", he was consecrated on 22 May as the successor of Pope Julius I.
Life.
He is not mentioned as a saint in the Roman Martyrology, making him the earliest pontiff to not as yet be canonized. However, he is recognized as a Saint within the Eastern Orthodox Church. His first recorded act was, after a synod had been held at Rome, to write to Emperor Constantius II, then in quarters at Arles (353–354), asking that a council might be called at Aquileia with reference to the affairs of Athanasius of Alexandria, but his messenger Vincentius of Capua was compelled by the emperor at a conciliabulum held in Arles to subscribe against his will to a condemnation of the orthodox patriarch of Alexandria.
At the end of an exile of more than two years in Thrace, after which it seems he may have temporarily relented to the Arian cause, or been set up to appear to have relented – partially evidenced by three letters, quite possibly forgeries, ascribed to Liberius, the emperor recalled him, but, as the Roman See was officially occupied by Antipope Felix II, a year passed before Liberius was sent to Rome. It was the emperor's intention that Liberius should govern the Church jointly with Felix, but on the arrival of Liberius, Felix was expelled by the Roman people. Neither Liberius nor Felix took part in the Council of Rimini (359).
After the death of the Emperor Constantius in 361, Liberius annulled the decrees of that assembly but, with the concurrence of bishops Athanasius and Hilary of Poitiers, retained the bishops who had signed and then withdrew their adherence. In 366, Liberius gave a favourable reception to a deputation of the Eastern episcopate, and admitted into his communion the more moderate of the old Arian party. He died on 24 September 366.
Some historians have postulated that Liberius resigned the papacy in 365, in order to make sense of the reign of Antipope Felix II.
Legacy.
Pope Pius IX noted in "Quartus Supra" that Liberius was falsely accused by the Arians and he had refused to condemn Athanasius of Alexandria. In his encyclical "Principi Apostolorum Petro", Pope Benedict XV noted that Pope Liberius went fearlessly into exile in defence of the orthodox faith. 
In the Eastern Orthodox Church, he is a saint whose feast is celebrated on August 27.
The Basilica di Santa Maria Maggiore in Rome is sometimes referred to as the Liberian Basilica.

</doc>
<doc id="54157" url="http://en.wikipedia.org/wiki?curid=54157" title="Peugeot">
Peugeot

Peugeot (; ; ]) is a French cars brand, part of PSA Peugeot Citroën.
The family business that preceded the current Peugeot company was founded in 1810, and manufactured coffee mills and bicycles. On 20 November 1858, Emile Peugeot applied for the lion trademark. Armand Peugeot built the concern's first car, an unreliable steam tricycle, in collaboration with Leon Serpollet in 1889; this was followed in 1890 by an internal combustion car with a Panhard-Daimler engine. Due to family discord, Armand Peugeot in 1896 founded the Société des Automobiles Peugeot.
The Peugeot company and family are originally from Sochaux, France. Peugeot retains a large manufacturing plant and Peugeot Museum there. In February 2014, the shareholders agreed to a recapitalisation plan, in which Dongfeng Motors and the French government each bought a 14% stake in the company.
Peugeot has received many international awards for its vehicles, including four European Car of the Year awards. In 2013 and 2014, Peugeot ranked at the second lowest average CO2 emissions among generalist brands in Europe, the Renault car maker group being ranked first, with 114.9g CO2/km. Peugeot is known as a very reliable brand, citing how its 1950s and 1960s models are still running in Africa or Cuba in the 2010s, where Peugeot is called "the Lion".
Peugeot has an impressive history in motor sport for more than a century. Peugeot Sport won the World Rally Championship five times, the Intercontinental Le Mans Cup twice (2010, 2011), surpassing Toyota and Audi, the World Endurance Championship twice (1992, 1993), and the Intercontinental Rally Challenge Championship three times. During the last year, Peugeot Sport has surpassed the record set in the ascent to Pikes Peak with the Peugeot 208 T16 driven by Sébastien Loeb, and got a triple victory of the Peugeot 208 GTi in its class at the 24 Hours Nürburgring race. In 2015, Peugeot returned to the Dakar Rally after its four victories in the 1980s.
Early history.
The Peugeot family of Valentigney, Montbéliard, Franche-Comté, France, began in the manufacturing business in the 18th century. In 1842, they added production of coffee, pepper, and salt grinders. The company's entry into the vehicle market was by means of crinoline dresses, which used steel rods, leading to umbrella frames, saw blades, wire wheels, and ultimately bicycles. Armand Peugeot introduced his "Le Grand Bi" penny-farthing in 1882, along with a range of other bicycles. The car company and bike company parted ways in 1926 but Peugeot bicycles continued to be built until very recently.
Armand Peugeot became interested in the automobile early on and, after meeting with Gottlieb Daimler and others, was convinced of its viability. The first Peugeot automobile, a three-wheeled, steam-powered car designed by Léon Serpollet, was produced in 1889; only four examples were made. Steam power was heavy and bulky and required lengthy warmup times. In 1890, after meeting Daimler and Émile Levassor, steam was abandoned in favour of a four-wheeled car with a petrol-fuelled internal combustion engine built by Panhard under Daimler licence. The car was more sophisticated than many of its contemporaries, with a three-point suspension and a sliding-gear transmission. An example was sold to the young Alberto Santos-Dumont, who exported it to Brazil.
More cars followed, 29 being built in 1892, 40 in 1894, 72 in 1895, 156 in 1898, and 300 in 1899. These early models were given "Type" numbers with the Type 12, for example, dating from 1895. Peugeot became the first manufacturer to fit rubber tyres (solid, rather than pneumatic) to a petrol-powered car that year.
Peugeot was an early pioneer in motor racing, with Albert Lemaître winning the world's first motor race, the Paris–Rouen (motor race), in a 3 hp Peugeot. Five Peugeots qualified for the main event, and all finished. Lemaître finished 3 min 30 sec behind the Comte de Dion whose steam-powered car was ineligible for the official competition. Three Peugeots were entered in the Paris–Bordeaux–Paris, where they were beaten by Panhard's car (despite an average speed of 20.8 km/h and taking the 31,500 "franc" prize. This also marked the debut of Michelin pneumatic tyres in racing, also on a Peugeot; they proved insufficiently durable. Nevertheless, the vehicles were still very much horseless carriages in appearance and were steered by a tiller.
In 1896, the first Peugeot engines were built; no longer were they reliant on Daimler. Designed by Rigoulot, the first engine was an 8 hp horizontal twin fitted to the back of the Type 15. It also served as the basis of a nearly exact copy produced by Rochet-Schneider. Further improvements followed: the engine moved to the front on the Type 48 and was soon under a hood (bonnet) at the front of the car, instead of hidden underneath; the steering wheel was adopted on the Type 36; and they began to look more like the modern car.
Also in 1896, Armand Peugeot broke away from Les Fils de Peugeot Frères to form his own company, Société Anonyme des Automobiles Peugeot, building a new factory at Audincourt to focus entirely on cars. In 1899, sales hit 300; total car sales for all of France that year were 1,200. The same year, Lemaître won the Nice-Castellane-Nice Rally in a special 5850 cc 20 hp racer.
At the 1901 Paris "Salon", Peugeot debuted a tiny shaft-driven 652 cc 5 hp one-cylinder, dubbed "Bébé" (Baby), and shed its conservative image, becoming a style leader. After placing 19th in the 1902 Paris-Vienna rally with a 50 hp 11322 cc racer, and failing to finish with two similar cars, Peugeot quit racing.
Peugeot added motorcycles to its range in 1903, and they have been built under the Peugeot name ever since. By 1903, Peugeot produced half of the cars built in France, and they offered the 5 hp "Bébé", a 6.5 hp four-seater, and an 8 hp and 12 hp resembling contemporary Mercedes models.
The 1907 "Salon" showed Peugeot's first six-cylinder, and marked Tony Huber joining as engine builder. By 1910, Peugeot's product line included a 1149 cc two-cylinder and six four-cylinders, of between 2 and 6 liters. In addition, a new factory opened the same year at Sochaux, which became the main plant in 1928.
A more famous name, Ettore Bugatti, designed the new 850 cc four-cylinder "Bébé" of 1912. The same year, Peugeot returned to racing with a team of three driver-engineers (a breed typical of the pioneer period, exemplified by Enzo Ferrari among others): Jules Goux (graduate of "Arts et Metiers", Paris), Paolo Zuccarelli (formerly of Hispano-Suiza), and Georges Boillot (collectively called "Les Charlatans"), with 26-year-old Swiss engineer Ernest Henry to make their ideas reality. The company decided "voiturette" (light car) racing was not enough, and chose to try "grandes épreuves" (grand touring). They did so with an engineering "tour de force": a DOHC 7.6-liter four-cylinder (110x200 mm) with four valves "per" cylinder. It proved faster than other cars of its time, and Boillot won the 1912 French Grand Prix at an average of 68.45 mph, despite losing third gear and taking a 20-minute pit stop. In May 1913, Goux took one to Indianapolis, and won at an average of 75.92 mph, recording straightaway speeds of 93.5 mph. making Peugeot the first non-American-based auto company to win at the Indianapolis Motor Speedway. In 1914, Boillot's 3-liter L5 set a new Indy lap record of 99.5 mph, and Duray placed second (beaten by ex-Peugeot ace René Thomas in a 6235 cc Delage). Another (driven by Boillot's brother, André) placed in 1915; similar models won in 1916 (Dario Resta) and 1919 (Howdy Wilcox).
For the 1913 French Grand Prix, an improved L5 (with 5655 cc engine) was produced with a pioneering ballbearing crankshaft, gear-driven camshafts, and dry sump lubrication, all of which soon became standard on racing cars; unfortunately, Zuccarelli was killed during testing on public roads, but Boillot easily won the event, making him (and Peugeot) the race's first double winner. For the 1914 French GP, Peugeot was overmatched by Mercedes, and despite a new innovation, four-wheel brakes (against the Mercedes' rear-only), Georges proved unable to match them and the car broke down. (Surprisingly, a 1914 model turned a 103 mph lap in practice at Indy in 1949, yet it failed to qualify.) Peugeot was more fortunate in 1915, winning at the French GP and Vanderbilt Cup.
During the First World War, Peugeot turned largely to arms production, becoming a major manufacturer of arms and military vehicles, from bicycles to tanks and shells.
Interwar years.
After the war, car production resumed in earnest. Racing continued as well, with Boillot entering the 1919 Targa Florio in a 2.5-liter (150-in3) car designed for an event pre-empted by World War I; the car had 200000 km on it, yet Boillot won with an impressive drive (the best of his career) Peugeots in his hands were third in the 1925 Targa, first in the 1922 and 1925 Coppa Florios, first in the 1923 and 1925 Touring Car Grands Prix, and first at the 1926 Spa 24 Hours. Peugeot introduced a five-valve-"per"-cylinder, triple-overhead-cam engine for the Grand Prix, conceived by Marcel Gremillon (who had criticised the early DOHC), but the engine was a failure.
The same year, Peugeot debuted 10 hp and 14 hp fours, the larger based on the Type 153, and a 6-liter 25 hp sleeve valve six, as well as a new cyclecar, "La Quadrilette".
During the 1920s, Peugeot expanded, in 1926 splitting the cycle (pedal and motor) business off to form Cycles Peugeot, the consistently profitable cycle division seeking to free itself from the rather more cyclical auto business, and taking over the defunct Bellanger and De Dion companies in 1927. In 1928, the Type 183 was introduced.
"Peugeot Sochaux production (units):
New for 1929 was the Peugeot 201, the cheapest car on the French market, and the first to use the later Peugeot trademark (and registered as such)—three digits with a central zero. The 201 would get independent front suspension in 1931, Soon afterwards, the Depression hit; Peugeot sales decreased, but the company survived.
In 1933, attempting a revival of fortune, the company unveiled a new, aerodynamically styled range. In 1934, Peugeot introduced the 402 BL Éclipse Décapotable, the first convertible with a retractable hardtop — an idea followed later by the Ford Skyliner in the 1950s and revived in the modern era by the Mitsubishi 3000GT Spyder in 1995. More recently, many manufacturers have offered retractable hardtops, including Peugeot itself with the 206-cc.
Three models of the 1930s were the Peugeot 202, Peugeot 302, and Peugeot 402. These cars had curvaceous bodies, with headlights behind sloping grille bars, evidently inspired by the Chrysler Airflow. The 2.1-liter 402 entered production in 1935 and was produced until the end of 1941, despite France's occupation by the Nazis. For 1936, the new Airflow-inspired 302 (which ran until 1938) and a 402-based large model, designed by Andrean, featured a vertical fin and bumper, with the first high-mounted taillight. The entry-level 202 was built in series from 1938 to 1942, and about 20 more examples were built from existing stocks of supplies in February 1945. The 202 lifted Peugeot's sales in 1939 to 52,796, just behind Citroën. Regular production began again in mid-1946, and lasted into 1949.
After World War II.
In 1946, the company restarted car production with the 202, delivering 14,000 copies. In 1947, Peugeot introduced the Peugeot 203, with coil springs, rack-and-pinion steering, and hydraulic brakes. The 203 set new Peugeot sales records, remaining in production until 1960.
Peugeot took over Chenard-Walcker in 1950, having already been required to acquire a controlling interest in Hotchkiss in 1942. A popular model introduced in 1955 was the Peugeot 403. With a 1.5-liter engine, it sold one million copies by the end of its production run in 1962, famously including one driven by TV detective Columbo.
The company began selling cars in the United States in 1958, and in 1960 introduced the Peugeot 404, which used a 1618 cc version of the 403 engine, tilted 45°. The 404 proved rugged enough to win the East African Safari Rally, in four of the six years between 1963 and 1968.
More models followed, many styled by Pininfarina, such as the 504, one of Peugeot's most distinctive models. Like many European manufacturers, collaboration with other firms increased; Peugeot worked with Renault from 1966 and Volvo from 1972.
Several Peugeot models were assembled in Australia, commencing with the 203 in 1953. These were followed by 403, 404 and 504 models with Australian assembly ending with the 505 in the early 1980s.
Takeover of Citroën and Chrysler Europe.
In 1974, Peugeot bought a 30% share of Citroën, and took it over completely in 1975 after the French government gave large sums of money to the new company. Citroën was in financial trouble because it developed too many radical new models for its financial resources. Some of them, notably the Citroën SM and the Comotor Wankel engine venture proved unprofitable. Others, the Citroën CX and Citroën GS for example, proved very successful in the marketplace.
The joint parent company became the PSA (Peugeot Société Anonyme) group, which aimed to keep separate identities for both the Peugeot and Citroën brands, while sharing engineering and technical resources. Peugeot thus briefly controlled the Italian Maserati marque, but disposed of it in May 1975.
The group then took over the European division of Chrysler (which were formerly Rootes and Simca), in 1978 as the American auto manufacturer struggled to survive. Soon, the whole Chrysler/Simca range was sold under the revived Talbot badge until production of Talbot-branded passenger cars was shelved in 1987 and on commercial vehicles in 1992.
1980s and 1990s.
In 1983, Peugeot launched the successful Peugeot 205 supermini, which is largely credited for turning the company's fortunes around. The 205 was regularly the bestselling car in France, and was also very popular in other parts of Europe, including Britain, where sales regularly topped 50,000 a year by the late 1980s. It won plaudits for its styling, ride and handling. It remained on sale in many markets until 1998, overlapping with the introduction of the 106 in 1991, and ceasing production at the launch of the 206, which also proved hugely popular across Europe.
As part of the Guangzhou Peugeot Automobile Company (GPAC) joint venture, the Peugeot 504 and 505 were built in China from 1985 to 1997.
By 1987, the company had dropped the Talbot brand for passenger cars when it ceased production of the Simca-based Horizon, Alpine, and Solara models, as well as the Talbot Samba supermini which was based on the Peugeot 104. What was to be called the Talbot Arizona became the Peugeot 309, with the former Rootes plant in Ryton and Simca plant in Poissy being turned over for Peugeot assembly. Producing Peugeots in Ryton was significant, as it signalled the first time Peugeots would be built in Britain. The 309 was the first Peugeot-badged hatchback of its size, and sold well across Europe. The 309's successor, the 306, was also built at Ryton.
The 405 saloon was launched in 1987 to compete with the likes of the Ford Sierra, and was voted European Car of the Year. This, too, was a very popular car across Europe, and continued to be available in Africa and Asia after it was replaced by the 406 nearly a decade later. Production of the 405 in Europe was divided between Britain and France, although its 406 successor was only produced in France. The 106, Peugeot's entry-level model from 1991, was also produced solely in France.
The Talbot name survived for a little longer on commercial vehicles until 1992 before being shelved completely. As experienced by other European volume car makers, Peugeot's United States and Canadian sales faltered and finally became uneconomical, as the Peugeot 505 design aged. For a time, distribution in the Canadian market was handled by Chrysler. Several ideas to turn around sales in the United States, such as including the Peugeot 205 in its lineup, were considered but not pursued. In the early 1990s, the newly introduced 405 proved uncompetitive with domestic and import models in the same market segment, and sold less than 1,000 units. Total sales fell to 4,261 units in 1990 and 2,240 through July 1991, which caused the company to cease its U.S. and Canada operations after 33 years. There are no plans to return to the U.S. market.
In 1997, just six years after pulling out of both United States and Canadian markets, Peugeot returned to Mexico after a 36-year absence, under the Chile–Mexico Free Trade Agreement. Peugeot models (1992–present) cannot be bought or imported into the United States from Mexico.
2000s to present.
On 18 April 2006, PSA Peugeot Citroën announced the closure of the Ryton manufacturing facility in Coventry, England. This announcement resulted in the loss of 2,300 jobs, as well as about 5,000 jobs in the supply chain. The plant produced its last Peugeot 206 on 12 December 2006, and finally closed down in January 2007.
Peugeot is a long way from its ambitious target of selling 4 million units annually by the end of the decade. In 2008, its sales stayed below the 2 million mark. In mid-2009, "adverse market and industry conditions" were blamed for falls in sales and operating losses. Christian Streiff was replaced by Philippe Varin (CEO) and Jean-Pierre Ploué (Head Design) was transferred from his post at Citroën. In 2009, Peugeot returned to the Canadian market with the scooter brand only.
Peugeot still plans on developing new models to compete in segments where it currently does not compete. Collin claimed that the French automaker competed in 72% of market segments in 2007, but he wanted to get that figure up to 90%. Despite Peugeot's sportscar racing program, the company is not prepared to build a pure sportscar any more hardcore than the RC Z sports-coupe. It is also pursuing government funding to develop a diesel-hybrid drivetrain, which might be key to its expansion.
By 2010, Peugeot planned on pursuing new markets, mainly in China, Russia, and South America. In 2011 it decided to re-enter India after 14 years with a new factory at Sanand, Gujarat.
Peugeot re-entered the Philippines in 2012 after having a short presence in 2005 with distribution done by the Alvarez Group.
In March 2012, General Motors purchased a 7% share in Peugeot for 320 million euros as part of a cooperation aimed at finding savings through joint purchasing and product development. In December 2013, GM sold its entire Peugeot stake, taking a loss of about 70 million euros.
In October 2013, Peugeot closed their production plant at Aulnay-sous-Bois as part of a restructuring plan to reduce overcapacity in the face of a shrinking domestic market. By December 2013, Chinese investors were rumoured to be potential investors. In February 2014, the Peugeot family agreed to give up control of the company by reducing its holdings from 25% to 14%. As part of this agreement, Dongfeng Motors and the French government were each to buy 14% stakes in the company, creating three partners with equal voting rights. The board of directors was to be composed of six independent members, two representatives of each Dongfeng, the French state and the Peugeot family, and two members representing employees and employees shareholders. The French government took the view the deal did not require approval by Brussels as EU competition rules do not count public investment in a company on the same terms as a private investor as state aid. The equity participation by Dongfeng expanded an already budding relationship with Peugeot. The pair at the time were jointly operating three car-manufacturing plants in China, with a capacity of producing 750,000 vehicles a year. In July 2014, the joint venture, Dongfeng Peugeot-Citroën, disclosed they were building a fourth factory in China in Chengdu, in Sichuan Province, targeting the manufacture of 300,000 sport-utility and multipurpose vehicles a year, starting towards the end of 2016.
Vehicles.
Awards.
European Car of the Year.
Peugeot has produced four winners of the European Car of the Year award.
Four other Peugeot models got either second or third in the contest.
Semperit Irish Car of the Year award.
Peugeot has produced two Car of the Year award winners in Ireland since 1978. It is judged by the Irish Motoring Writers Association (IMWA).
Car of the Year award in Italy.
Peugeot S.A. has produced four ""Car of the Year" Auto Europa" award winners in Italy in 28 years, since 1987. "Auto Europa" is the prize awarded by the jury of the Italian Union of Automotive Journalists (UIGA), which annually celebrates the best car produced at least at 10,000 units in the 27 countries of the European Union, and sold between September and August the previous year.
Car of the Year award in Spain.
Peugeot S.A. has produced nine Car of the year award winners in Spain in 40 years, since 1974.
Electric and hybrid vehicles.
Peugeot presented a new concept hybrid electric sports sedan at the 2008 Paris Motor Show called the Peugeot RC HYmotion4. Similar to the drivetrain model used in the upcoming Chevrolet Volt, the RC concept promises the ability to run solely on electric power for extended periods, with a hybrid electric powertrain filling in the gaps when extra range is needed. The RC HYmotion4 includes a 70-kW electric motor at the front wheels. The Peugeot Prologue HYmotion4 was also shown at the 2008 Paris show and is in many ways the opposite of the RC HYmotion4 concept. The Prologue puts the internal combustion engine up front and runs on diesel instead of gasoline, with the electric motor going at the back.
The Peugeot BB1 is an electric concept car with in-wheel motors in its rear wheels first shown in September 2009 at the Frankfurt Motor Show.
In 2010, Peugeot started selling the electric Peugeot iOn, a rebadged and revised version of the Mitsubishi i-MiEV.
Motorsport.
Early.
Peugeot was involved in motorsport from the earliest days and entered five cars for the Paris-Rouen Trials in 1894 with one of them, driven by Lemaître, finishing second. These trials are usually regarded as the first motor sporting competition. Participation in a variety of events continued until World War I, but in 1912, Peugeot made its most notable contribution to motor sporting history when one of their cars, driven by Georges Boillot, won the French Grand Prix at Dieppe. This revolutionary car was powered by a straight-4 engine designed by Ernest Henry under the guidance of the technically knowledgeable racing drivers Paul Zuccarelli and Georges Boillot. The design was very influential for racing engines as it featured for the first time DOHC and four valves per cylinder, providing for high engine speeds, a radical departure from previous racing engines which relied on huge displacement for power. In 1913, Peugeots of similar design to the 1912 Grand Prix car won the French Grand Prix at Amiens and the Indianapolis 500. When one of the Peugeot racers remained in the United States during World War I and parts could not be acquired from France for the 1914 season, owner Bob Burma had it serviced in the shop of Harry Miller by a young mechanic named Fred Offenhauser. Their familiarity with the Peugeot engine was the basis of the famed Miller racing engine, which later developed into the Offenhauser.
Rallying.
Peugeot Sport is one of the most successful winners in rallying, with also Citroën Racing (eight-time WRC winner), by winning five times the World Rally Championship Manufacturer's Title (1985-1986, 2000-2002), four times the Dakar Rally (1987-1990), three times the European Rally Championship (2002-2003, 2008), three times the Intercontinental Rally Challenge (2007-2009).
Peugeot's East African importers had a very impressive record in rallying in the 1960s; Nick Nowicki and Paddy Cliff won the East African Safari in 1963 with a Marshall's-entered 404 sedan. In 1966 and 1967, Tanzania's Tanganyika Motors entered the winning 404 Injection sedan, piloted by the late Bert Shanlkand and Chris Rothwell. They might have won again in 1968, but while in second place, their engine blew and ultimately Nick Nowicki and Paddy Cliff upheld Peugeot's honour by winning the rally. Peugeot also won the Safari Rally in 1975 (Andersson in a 504 Injection sedan) and in 1978 (Nicolas in a 504 Coupé V6), both cars being factory team entries.
Peugeot also had further success in international rallying, most notably in the World Rally Championship with the four-wheel-drive turbo-charged versions of the Peugeot 205, and more recently the Peugeot 206. In 1981, Jean Todt, former co-driver for Hannu Mikkola, Timo Mäkinen, and Guy Fréquelin, among others, was asked by Jean Boillot, the head of Automobiles Peugeot, to create a competition department for PSA Peugeot Citroën. The resulting Peugeot Talbot Sport, established at Bois de Boulogne near Paris, debuted its Group B 205 Turbo 16 at the 1984 Tour de Corse in May, and took its first world rally win that same year at the 1000 Lakes Rally in August, in the hands of Ari Vatanen. Excluding an endurance rally where Peugeot were not participating, Vatanen went on win five world rallies in a row.
Peugeot's domination continued in the 1985 season. Despite Vatanen's nearly fatal accident in Argentina, in the middle of the season, his team-mate and compatriot Timo Salonen led Peugeot to its first drivers' and manufacturers' world championship titles, well ahead of Audi and their Audi Sport Quattro. In the 1986 season, Vatanen's young replacement Juha Kankkunen beat Lancia's Markku Alén to the drivers' title and Peugeot took its second manufacturers' title ahead of Lancia. Following FIA's banning of Group B cars for 1987, in May after Henri Toivonen's fatal accident, Todt was outraged and even (unsuccessfully) pursued legal action against the federation. Peugeot then switched to rally raids. Using the 205 and a 405, Peugeot won the Dakar Rally four times in a row from 1987 to 1990; three times with Vatanen and once with Kankkunen. In 2015 Peugeot again took part in the Rally Dakar with a newly constructed buggy.
In 1999, Peugeot returned to the World Rally Championship with the 206 WRC. The car was immediately competitive against such opposition as the Subaru Impreza WRC, the Ford Focus WRC, and the Mitsubishi Lancer Evolution. Marcus Grönholm gave the car its first win at the 2000 Swedish Rally, and Peugeot went on to win the manufacturers' title in their first full year since the return, and Grönholm the drivers' title in his first full WRC season. After successfully but narrowly defending their manufacturers' title in 2001, Peugeot Sport dominated the 2002 season, taking eight wins in the hands of Grönholm and Gilles Panizzi. Grönholm also took the drivers' title. For the 2004 season, Peugeot retired the 206 WRC in favour of the new 307 WRC. The 307 WRC did not match its predecessor in success, but Grönholm took three wins with the car, one in 2004 and two in 2005. PSA Peugeot Citroën withdrew Peugeot from the WRC after the 2005 season, while Citroën took a sabbatical year in 2006 and returned for the next season. Meanwhile, Gronholm departed Peugeot when they quit at the end of 2005 to partner young compatriot Mikko Hirvonen at Ford.
Peugeot 207 S2000, winner of the Intercontinental Rally Challenge from 2007 to 2009. 
Touring car racing.
In 2013, the Peugeot 208GTi won a one-two-three at the 24 Hours Nürburgring endurance race.
The Peugeot 306 GTi won the prestigious Spa 24 hours endurance race in 1999 and 2000.
Peugeot has been racing successfully in the Asian Touring Car Series series, winning the 2000, 2001, and 2002 championships with the Peugeot 306 GTi.
Peugeot has been racing successfully in the Stock Car Brasil series since 2007 and won the 2008, 2009, and 2011 championships.
Peugeot has been racing successfully in the Asian Touring Car Series series, winning the 2000, 2001, and 2002 championships with the Peugeot 306 GTi.
Peugeot won five times the Danish Touringcar Championship, with both the Peugeot 306 -winner in 1999, 2000 and 2001- and the Peugeot 307 winner in 2002 and 2003.
With his Peugeot 406, Laurent Aiello won the 1997 Super Tourenwagen Cup season.
Throughout the mid-1990s, the Peugeot 406 saloon (called a sedan in some countries) contested touring car championships across the world, enjoying success in France, Germany and Australia, yet failing to win a single race in the British Touring Car Championship despite a number of podium finishes under the command of 1992 British Touring Car Champion Tim Harvey. In Gran Turismo 2 the 406 saloon description sums its racing career up as "a competitive touring car which raced throughout Europe".
The British cars were prepared by a team from the Peugeot UK factory in Coventry in 1996, when they sported a red livery, and by MSD in 1997–98, when they wore a distinctive green and gold-flame design. Initially the 406's lack of success was blamed on suspension problems. During 1998 the 406 apparently lacked sufficient horsepower to compete with the front runners' Nissan Primeras and Honda Accords; this was mentioned during a particularly strong showing from Harvey's 406 at the Oulton Park BTCC meeting of 1998, when motorsport commentator Charlie Cox stated "some people say (the 406) is down on power – you're kidding". During the first BTCC meeting at Silverstone in the same year, Cox mentions that MSD re-designed the 406 touring car "from the ground up".
In 2001, Peugeot entered three 406 coupes into the British touring car championship to compete with the dominant Vauxhall Astra coupes. Unfortunately the 406 coupe was at the end of its product lifecycle and was not competitive, despite some promise towards the end of the year, notably when Peugeot's Steve Soper led a race only to suffer engine failure in the last few laps. The 406 coupes were retired at the end of the following year and replaced with the Peugeot 307—again, uncompetitively—in 2003.
Sports car racing.
In the 1990s the company competed in endurance racing, including the World Sportscar Championship and the 24 Hours of Le Mans race with the 905. The sportscar team was established at Vélizy-Villacoublay, France. After early problems with reliability and aerodynamics, the 905 was successful in the World Sportscar Championship, winning eight of the 14 races across the 1991 and 1992 seasons and winning the team and driver titles in 1992. Peugeot also won the 24 Hours of Le Mans in 1992 and 1993.
Peugeot returned to sportscar racing and Le Mans in 2007 with the diesel-powered Peugeot 908 HDi FAP. At the 2007 24 Hours of Le Mans, Stéphane Sarrazin secured pole position but the 908s proved unreliable and ceded victory to Audi. In 2008, the Sarrazin again earned a pole position but Audi prevailed once again. For the 2009 24 Hours of Le Mans, the Peugeot 908 HDi FAPs finished first and second overall, led by drivers Marc Gené, David Brabham, and Alexander Wurz.
Pike's Peak Hillclimb.
After Ari Vatanen and Bobby Unser, in the late 1980s, won the Pike's Peak Hillclimb Race, Peugeot Sport and Sebastien Loeb decided to unite their respective strengths and go for it. The Ari Vatanen performence won sereval awards with the "Climb Dance" films (Grand Prix du film de Chamonix 1990, Gold Award at International Film Festival in Houston, Silver Screen of the US Industrial Film & Video Festival in Chicago, 1990 Prix spécial du Jury at the Festival International du Film d'aventure in Val d'Isère).
In April 2013, a 208 T16 was tested by Sébastien Loeb at Mont Ventoux. Loosely based on the shape and design of the production 208, the T16 is a lightweight 875 kg vehicle that uses the rear wing from the Peugeot 908, and has a 3.2-litre, twin-turbo V6 engine, developing 875 bhp with the aim of competing at the Pikes Peak International Hill Climb. 30 June 2013 saw this car demolish the standing record on Pikes Peak by over a minute and a half, with an overall time of 8:13.878.
Formula One.
The company has also been involved in providing engines to Formula One teams, notably to McLaren in 1994, to Jordan for the 1995, 1996 and 1997 seasons, and to Prost for the 1998, 1999 and 2000 seasons. Peugeot's F1 interests were sold to Asiatech at the end of the 2000 season.
Concept cars.
Motorcycles.
Peugeot Motorcycles company remains a major producer of scooters, underbones, mopeds, and bicycles in Europe. Peugeot produced an electric motor scooter, the Peugeot Scoot'Elec, from 1996 to 2006, and is projected to re-enter the market in 2011 with the E-Vivacity.
Bicycles.
Peugeot also produced bicycles starting in 1882 in Beaulieu, France (with ten Tour de France wins between 1903 and 1983), followed by motorcycles and cars in 1889. In the late 1980s Peugeot sold the North American rights to the Peugeot bicycle name to ProCycle, a Canadian company which also sold bicycles under the CCM and Velo Sport names. The European rights were briefly sold to Cycleurope S.A., returning to Peugeot in the 1990s.
Peugeot Avenue.
Peugeot has flagship dealerships, named Peugeot Avenue, located on the Champs-Élysées in Paris, and in Berlin. The Berlin showroom is larger than the Paris one, but both feature regularly changing mini-exhibitions displaying production and concept cars. Both also feature a small Peugeot Boutique, and they are popular places for Peugeot fans to visit. Peugeot Avenue Berlin also features a café, called Café de France. The Peugeot Avenue at Berlin closed in 2009.

</doc>
<doc id="54159" url="http://en.wikipedia.org/wiki?curid=54159" title="Belmont, New York">
Belmont, New York

Belmont is a village within the town of Amity in Allegany County, New York, United States. Belmont is the county seat of Allegany County. The population was 969 at the 2010 census. The name means "beautiful hill". The village is centrally located in Amity and is northeast of Olean.
History.
The village of Belmont was incorporated in 1871 as "Philipsville", named after early settler Philip Church. The settlement was originally called "Philipsburg". When the village assumed the community of Miltonville on the east bank of the Genesee River, it was renamed "Belmont".
The village became the county seat in 1859, replacing the village of Angelica.
The following are listed on the National Register of Historic Places: Belmont Grange No. 1243, Belmont Literary and Historical Society Free Library, and the Belmont Hotel.
Geography.
Belmont is located at (42.2257, -78.0319).
According to the United States Census Bureau, the village has a total area of 1.0 sqmi, all of it land.
The village is split by the Genesee River and is at the junctions of NY Route 19, NY Route 244 and County Road 48. Belmont is on the mainline of the Western New York and Pennsylvania Railroad.
Demographics.
As of the census of 2000, there were 952 people, 392 households, and 241 families residing in the village. The population density was 952.9 people per square mile (367.6/km²). There were 449 housing units at an average density of 449.4 per square mile (173.4/km²). The racial makeup of the village was 96.11% White, 0.95% Black or African American, 0.11% Native American, 0.11% Asian, 0.21% from other races, and 2.52% from two or more races. 1.05% of the population were Hispanic or Latino of any race.
There were 392 households out of which 30.1% had children under the age of 18 living with them, 44.9% were married couples living together, 11.7% had a female householder with no husband present, and 38.5% were non-families. 33.7% of all households were made up of individuals and 18.4% had someone living alone who was 65 years of age or older. The average household size was 2.31 and the average family size was 2.98.
In the village the population was spread out with 25.3% under the age of 18, 7.7% from 18 to 24, 28.5% from 25 to 44, 22.0% from 45 to 64, and 16.6% who were 65 years of age or older. The median age was 38 years. For every 100 females there were 104.7 males. For every 100 females age 18 and over, there were 98.1 males.
The median income for a household in the village was $29,545, and the median income for a family was $35,625. Males had a median income of $28,365 versus $20,781 for females. The per capita income for the village was $14,149. About 9.9% of families and 12.7% of the population were below the poverty line, including 13.8% of those under age 18 and 6.1% of those age 65 or over.

</doc>
<doc id="54160" url="http://en.wikipedia.org/wiki?curid=54160" title="Leaving Las Vegas">
Leaving Las Vegas

Leaving Las Vegas is a 1995 romantic drama film written and directed by Mike Figgis and based on a semi-autobiographical novel of the same name by John O'Brien. Nicolas Cage stars as a suicidal alcoholic who has ended his personal and professional life to drink himself to death in Las Vegas. While there, he develops a relationship with a hardened prostitute played by Elisabeth Shue, which forms the center of the film. O'Brien committed suicide two weeks after principal photography of the film began.
"Leaving Las Vegas" was filmed in super 16mm instead of 35 mm film, which is most commonly used for mainstream film; although 16 mm is common for art house films. After limited release in the United States on October 27 1995, "Leaving Las Vegas" was released nationwide on February 9 1996, receiving strong praise from both critics and audiences. Cage received the Golden Globe Award for Best Actor - Motion Picture Drama and the Academy Award for Best Actor, while Shue was nominated for the Academy Award for Best Actress. The film also received nominations for Best Adapted Screenplay and Best Director.
Plot.
Ben Sanderson (Cage) is a Hollywood screenwriter whose alcoholism costs him his job, family, and friends. With nothing left to live for, he moves to Las Vegas to drink himself to death. As he drives drunkenly down the Las Vegas Strip, he nearly hits a woman, Sera (Shue), on the crosswalk. Sera chastises him and walks away. Sera is a prostitute working for an abusive pimp, Yuri Butso (Julian Sands), a Latvian immigrant. Polish mobsters are after Yuri, so he breaks his relationship with Sera in fear that the Poles may hurt her. Yuri is murdered (off-screen) shortly afterwards.
On his second day in Las Vegas, Ben meets Sera, introduces himself and offers $500 to go to his room for an hour. Sera agrees but Ben does not want sex. Instead, they only talk and form a bizarre romantic relationship. They move in together shortly afterward. Ben instructs Sera to never ask him to stop drinking. Sera reciprocates and instructs Ben to not criticize her occupation. At first the two are stable as Ben is "totally at ease with this (Sera's prostitution)". However, each becomes frustrated with the other's behavior. Sera begs Ben to see a doctor. Furious, Ben returns to their shared home with another prostitute (Mariska Hargitay). Sera returns home and throws Ben out. Shortly afterward, while working, she is approached by three college students at the Excalibur hotel and casino. She initially rejects their offer by stating that she only "dates" one at a time, but eventually acquiesces when she is offered an increased price. When she enters their hotel room, the college students change the deal and request anal sex, which Sera refuses. When she attempts to leave, she is brutally attacked and raped as one of the college students films the entire event on a video camera. The next morning, Sera returns with injuries that make her occupation obvious, resulting in her eviction. She then receives a call from Ben, who is on his deathbed. Sera visits Ben and he dies while they make love. His last word is "wow". In the final scene, Sera explains to her therapist that she accepted Ben for who he was, liked his drama, and loved him.
Production.
Development.
Mike Figgis based "Leaving Las Vegas" on a 1990 autobiographical novel by John O'Brien, who committed suicide in April 1994, shortly after finding out his novel was being made into a film. Despite basing most of his screenplay on O'Brien's novel, Figgis spoke of a personal attachment with the novel, stating "Anything I would do would be because I had a sympathetic feeling towards it. That's why I did "Mr. Jones", because I think manic-depression is a fascinating, sad, and amazing phenomenon. It's not a coincidence that some of the greatest artists have been manic-depressive[s]. That made it, to me, a fascinating subject that, alas, did not come out in the film".
Casting.
Figgis encouraged the lead actors to experience their characters' ordeals first-hand by extensive research. He told "Film Critic": "It was just a week and a half of rehearsal. A lot of conversations. A lot of communication in the year before we made the film. Reading the book. I encouraged them [Cage and Shue] to do their own research, which they wanted to do anyway, and then ultimately the three of us got together and just started talking...talking about anything, not necessarily about the film or the script, about anything that came up". Cage researched by binge drinking in Dublin for two weeks and had a friend videotape him so he could study his speech. He also visited hospitalized career alcoholics. He said "it was one of the most enjoyable pieces of research I've ever had to do for a part." Shue spent time interviewing several Las Vegas prostitutes.
Filming.
The limited budget dictated the production and Figgis ended up filming in super 16mm and composing his own score. He remarked, "We didn't have any money, and we weren't pretending to be something we weren't. We couldn't shut down The Strip to shoot".
Figgis had problems because permits were not issued for some street scenes. This caused him to film some scenes on the Las Vegas strip in one take to avoid the police, which Figgis said benefited production and the authenticity of the acting, remarking "I've always hated the convention of shooting on a street, and then having to stop the traffic, and then having to tell the actors, 'Well, there's meant to be traffic here, so you're going to have to shout'. And they're shouting, but it's quiet and they feel really stupid, because it's unnatural. You put them up against a couple of trucks, with it all happening around them, and their voices become great".
The film was shot in Burbank, California, Los Angeles, Las Vegas, Laughlin, Nevada, and Halifax, Nova Scotia in Canada.
Themes.
"Leaving Las Vegas" is a bittersweet love story of dependence and obsession. Ben and Sera build their relationship on the foundation that neither of them can change who they are if they are going to continue pursuing a life together, further validating the theme of a tragic love story born in a desperate world between two self-destructive people (Ben with alcohol and Sera with prostitution). Nicolas Cage called Ben "crumbled elegance", and viewed him as a man who once had it all; Cage thus tried to give the character a kind of "continental elegance when he was in a bad situation". Cage continued by saying that the elegance is imploding on him because of the booze, causing it to fall apart, "But you still get the idea of what it used to be". There is hope, however, with Sera's character, who, despite having nobody to turn to, is less unfortunate and dependent. Shue perceived her character in a similar light, stating "She is a wounded soul. She is clinging to hope in the midst of desperation. I think they are not of the world, there is a mythical nature to their love. A couple with a positive energy. A contradiction to other elements".
Release.
"Leaving Las Vegas" had a limited release on October 27, 1995. After praise from critics and four Academy Award nominations, the film was released nationwide February 9, 1996. United Artists company distributed the film in North America, RCV Film Distribution with Atalanta Filmes in Europe, and in Australia 21st Century Film Corporation distributed the film.
Reception.
"Leaving Las Vegas" was received very well by critics, scoring 82 metapoints out of 100 on Metacritic. Critics such as Roger Ebert from "Chicago Sun-Times" and Rick Groen from "The Globe and Mail" gave the film high marks. Ebert wrote, "They [the characters] are the drunk and the whore with a heart of gold. Cage and Shue make these clichés into unforgettable people". Ebert named the film 'best of 1995' and included it with his 'best of the decade' list ("Leaving Las Vegas" was #8). Leonard Klady from "Variety" said "Leaving Las Vegas" was "certainly among a scant handful of films that have taken an unflinching view of dependency". On Rotten Tomatoes, the film received 90% overall approval out of 48 reviews. Overall, the film was a success at the box office, particularly considering its budget, grossing $32,029,928.
Home media releases.
Video cassettes and DVD of the film were distributed by MGM. The video cassettes were distributed on November 12, 1996 in two languages, English and Russian, while the DVD was distributed on January 1, 1998 in English for USA and Canada. Australian and UK editions were later released. The DVD contains a supplemental "Hidden Page" menu feature. The film is also released on Blu-ray, HD DVD and LaserDisc.
In popular culture.
The success of "Leaving Las Vegas" has had a moderate effect on the media. It spawned a direct-spoof, "Eating Las Vegas", about a binge eater who travels to Las Vegas to eat himself to death, and the film is also alluded to in the documentary "Super Size Me" (2004). It was also briefly mentioned in the "Family Guy" episode "Movin' Out (Brian's Song)". The Spanish pop band Amaral based their song "Moriría por vos", included in their 2002 album Estrella de mar, upon the film.
Soundtrack.
A soundtrack album, consisting mainly of film score composed and performed by Mike Figgis, was released November 7, 1995. The soundtrack also included three jazz standards performed by Sting and excerpts of dialogue from the film. A version of "Lonely Teardrops" performed by Michael McDonald that features in the film is not included.
All songs written and composed by Mike Figgis except as noted. 

</doc>
<doc id="54161" url="http://en.wikipedia.org/wiki?curid=54161" title="Pope Pius IX">
Pope Pius IX

Pope Pius IX (Latin: "Pius IX"; 13 May 1792 – 7 February 1878), born Giovanni Maria Mastai-Ferretti, reigned from 16 June 1846 to his death in 1878. He was the longest-reigning elected pope in the history of the Catholic Church – over 31 years. During his pontificate, he convened the First Vatican Council (1869–70), which decreed papal infallibility, but the council was cut short due to the loss of the Papal States.
Pius IX defined the dogma of the Immaculate Conception of the Blessed Virgin Mary, meaning that Mary was conceived without original sin. Pius IX also conferred the title Our Mother of Perpetual Help on a famous Byzantine icon from Crete entrusted to the Redemptorists.
He was also the last pope to rule as the Sovereign of the Papal States, which fell completely to the Italian army in 1870 and were incorporated into the Kingdom of Italy. After this, he was referred to – chiefly by himself – as the "Prisoner of the Vatican".
After his death in 1878, his canonization process was opened on 11 February 1907 by Pope Pius X and it drew considerable controversy over the years. It was closed on several occasions during the pontificates of Pope Benedict XV and Pope Pius XI. On 7 December 1954, Pope Pius XII re-opened the cause and Pope John Paul II proclaimed him Venerable on 6 July 1985. Together with Pope John XXIII he was beatified on 3 September 2000 after the recognition of a miracle and was assigned the liturgical feast day of February 7 which is the date of his death.
Overview.
Europe, including the Italian peninsula, was in the midst of considerable political ferment when the bishop of Spoleto, Cardinal Giovanni Maria Mastai-Ferretti, was elected pope. He took the name Pius, after his generous patron and the long-suffering prisoner of Napoleon Bonaparte, Pius VII. He had been elected by the faction of cardinals sympathetic to the political liberalization coursing across Europe, and his initial governance of the Papal States gives evidence of his own liberal sympathies: Under his direction various sorts of political prisoners in the Papal States were released and the city of Rome was granted a constitutional framework under guidance of his friend, philosopher-prince Antonio Rosmini-Serbati. A series of terrorist acts sponsored by Italian liberals and nationalists, which included the assassination of his Minister of the Interior, Pellegrino Rossi, among others, and which forced him briefly to flee Rome in 1848 led to his growing skepticism towards the liberal, nationalist agenda. Through the 1850s and 1860s, Italian nationalists made military gains against the Papal States, which culminated in the seizure of the city of Rome in 1870. Thereafter, Pius IX refused to accept the Law of Guarantees from the Italian government, which would have made the Holy See dependent on legislation that the Italian parliament could modify at any time. His Church policies towards other countries, such as Russia, Germany and France, were not always successful, due in part, to changing secular institutions and internal developments within these countries. However, concordats were concluded with numerous states such as Austria-Hungary, Portugal, Spain, Canada, Tuscany, Ecuador, Venezuela, Honduras, El Salvador and Haiti.
Many contemporary Church historians and journalists question his approaches. His appeal for public worldwide support of the Holy See after he became "The prisoner of the Vatican" resulted in the revival and spread to the whole Catholic Church of Peter's Pence, which is used today to enable the Pope "to respond to those who are suffering as a result of war, oppression, natural disaster, and disease". In his Syllabus of Errors, still highly controversial, Pius IX condemned the heresies of secular society, especially modernism.
He was a Marian pope, who in his encyclical "Ubi primum" described Mary as a Mediatrix of salvation. In 1854, he promulgated the dogma of the Immaculate Conception, articulating a long-held Catholic belief that Mary, the Mother of God, was conceived without original sin. In 1862, he convened 300 bishops to the Vatican for the canonization of Twenty-six Martyrs of Japan. His most important legacy is the First Vatican Council, which convened in 1869. This Council discussed many issues, especially the dogma of papal infallibility, which Pius was eager to have officially defined by the council; but the council was interrupted as Italian nationalist troops threatened Rome. The council is considered to have contributed to a centralization of the Church in the Vatican.
Pius IX, who suffered from epilepsy, was beatified by Pope John Paul II on 3 September 2000. His Feast Day is 7 February.
Early life and ministry.
Giovanni Maria Mastai-Ferretti was the ninth child born in Senigallia into the noble family of Girolamo dei conti Ferretti, and was baptized on the same day of his birth with the name of Giovanni Maria Giambattista Pietro Pellegrino Isidoro. He was educated at the Piarist College in Volterra and in Rome. As a theology student in his hometown Sinigaglia, in 1814 he met Pope Pius VII, who had returned from French captivity. In 1815, he entered the Papal Noble Guard but was soon dismissed after an epileptic seizure. He threw himself at the feet of Pius VII, who elevated him and supported his continued theological studies.
The pope originally insisted that another priest should assist Mastai during Holy Mass, a stipulation that was later rescinded, after the seizure attacks became less frequent. Mastai was ordained priest in April 1819. He initially worked as the rector of the Tata Giovanni Institute in Rome. Shortly before his death, Pius VII sent him as Auditor to Chile and Peru in 1823 and 1825 to assist the Apostolic Nuncio, Monsignore Giovanni Muzi and Monsignore Bradley Kane, in the first mission to post-revolutionary South America. The mission had the objective to map out the role of the Catholic Church in the newly independent South American republics. He was thus the first pope ever to have been in America. When he returned to Rome, the successor of Pius VII, Pope Leo XII appointed him head of the hospital of San Michele in Rome (1825–1827) and canon of Santa Maria in Via Lata.
Pope Leo XII appointed Father Mastai-Ferretti Archbishop of Spoleto, his own hometown, in 1827 at the age of 35. In 1831, the abortive revolution that had begun in Parma and Modena spread to Spoleto; the Archbishop obtained a general pardon after it was suppressed, gaining him a reputation for being liberal. During an earthquake, he made a reputation as an efficient organizer of relief and great charity. The following year he was moved to the more prestigious diocese of Imola, was made a cardinal "in pectore" in 1839, and in 1840 was publicly announced as Cardinal-Priest of Santi Marcellino e Pietro. As in Spoleto, his episcopal priorities were the formation of priests through improved education and charities. He became known for visiting prisoners in jail, and for programs for street children. According to historians, Cardinal Mastai-Ferretti was considered a liberal during his episcopate in Spoleto and Imola because he supported administrative changes in the Papal States and sympathized with the nationalist movement in Italy.
Papal election.
The conclave of 1846, following the death of Pope Gregory XVI (1831–46), took place in an unsettled political climate within Italy. Because of this, many foreign Cardinals decided not to attend the conclave. At its start, only 46 out of 62 cardinals were present.
Moreover, the conclave of 1846 was steeped in a factional division between conservatives and liberals. The conservatives supported Luigi Lambruschini, Gregory XVI's Cardinal Secretary of State. Liberals supported two candidates: Pasquale Tommaso Gizzi and the then 54-year-old Mastai-Ferretti. A fourth "papabile" was Cardinal Ludovico Micara the Dean of the College of Cardinals who was favored by the residents of Rome itself but he never gained support among the cardinals.
During the first ballot, Mastai-Ferretti received 15 votes, the rest going to Cardinal Lambruschini and Cardinal Gizzi. Lambruschini received a majority of the votes in the early ballots, but failed to achieve the required two-thirds majority. Cardinal Gizzi was favored by the French government but failed to get further support from the cardinals and the conclave ended up ultimately as a contest between Cardinals Lambruschini and Mastai-Ferretti. In the meantime, Cardinal Tommaso Bernetti reportedly received information that Karl Kajetan von Gaisruck the Austrian Archbishop of Milan was on his way to the conclave to veto the election of Mastai-Ferretti. According to historian Valèrie Pirie, Cardinal Bernetti realized that if Lambruschini was to be stopped and Mastai-Ferretti was to be elected he had to convince the cardinals within a few hours or accept the election of Lambruschini. Bernetti then on his own initiative personally convinced the majority of the electors to switch their support to Mastai-Ferretti. Cardinal Mastai-Ferretti himself however made no effort to campaign for the papacy, made no promises and maintained aloofness throughout the process.
Faced with deadlock and persuaded by Bernetti to keep Lambruschini from being elected pope, liberals and moderates decided to cast their votes for Mastai-Ferretti in a move that contradicted the general mood throughout Europe. By the second day of the conclave, on 16 June 1846, during an evening ballot, Mastai-Ferretti was elected pope. "He was a glamorous candidate, ardent, emotional with a gift for friendship and a track-record of generosity even towards anti-Clericals and Carbonari. He was a patriot, known to be critical of Gregory XVI " Because it was night, no formal announcement was given, just the signal of white smoke. Many Catholics had assumed that Gizzi had been elected successor of St. Peter. In fact, celebrations began to take place in his hometown, and his personal staff, following a long-standing tradition, burned his cardinalitial vestments.
On the following morning, the senior Cardinal-Deacon, Tommaso Riario Sforza, announced the election of Mastai-Ferretti before a crowd of faithful Catholics. When Mastai-Ferretti appeared on the balcony, the mood became joyous. Mastai-Ferretti chose the name of Pius IX in honor of Pope Pius VII (1800–23), who had encouraged his vocation to the priesthood despite his childhood epilepsy.
However, Mastai-Ferretti, now Pope Pius IX, had little diplomatic and no curial experience at all, which did cause some controversy. The government of the Empire of Austria as represented by Prince Metternich in its foreign affairs objected to even the possible election of Mastai-Ferretti. Thus, Cardinal Gaisruck, Archbishop of Milan, was sent to present the Austrian official veto against Mastai-Ferretti. However, Gaisruck arrived too late; the new Pope was already elected. Pius IX was crowned on 21 June 1846.
Papacy.
The election of the liberal Pius IX created much enthusiasm in Europe and elsewhere. Although he was not unknown and had done nothing on an administrative level before his election, and although there were no utterances from him, he increased in fame and popularity.
English Protestants celebrated him as a friend of light and a reformer of Europe towards freedom and progress. He was elected without political influences from outside and in the best years of his life. He was pious, progressive, intellectual, decent, friendly, and open to everybody.
Governing the Church.
Centralization.
The end of the Papal States was not the only important event in the long pontificate of Pius. His leadership of the Church contributed to an ever-increasing centralization and consolidation of power in Rome and the papacy. While his political views and policies were hotly debated, his personal life style was above any criticism; he was considered a model of simplicity and poverty in his every day affairs. More than his predecessors, Pius used the papal pulpit to address the bishops of the world. The First Vatican Council, which he convened to consolidate papal authority further, was considered a milestone not only in his pontificate but also for Church history.
Church rights.
The Church policies of Pius IX were dominated with a defence of the rights of the Church and the free exercise of religion for Catholics in countries like Russia and the Ottoman Empire. He also fought against what he perceived to be anti-Catholic philosophies in countries like Italy, Germany and France. Many of the Pope's subjects wanted to be Italian instead. The soldiers who guarded the Pope from Italians (between 1849 and 1870) were largely French and Austrian. The Pope considered moving to Germany (see below).
After the French loss in the Franco-Prussian War of 1870–1871, the Papal States lost its protector and were absorbed by Italy. Germany actively persecuted the Church for a decade after the war.
Jubilees.
Pius IX celebrated several jubilees including the 300th anniversary of the Council of Trent. Pius celebrated the 1,800th anniversary of the martyrdom of the Apostle Peter and Apostle Paul on 29 June 1867 with 512 bishops, 20,000 priests and 140,000 lay persons in Rome. A large gathering was organized in 1871 to commemorate the 25th anniversary of his papacy. The Italian government in 1870 outlawed many popular pilgrimages. The faithful of Bologna organized a nationwide "spiritual pilgrimage" to the pope and the tombs of the apostles in 1873. In 1875, Pius declared a Holy Year that was celebrated throughout the Catholic world. On the 50th anniversary of his episcopal consecration, people from all parts of the world came to see the old pontiff from 30 April 1877 to 15 June 1877. He was a bit shy, but he valued initiative within the Church and created several new titles, rewards and orders to elevate those who in his view deserved merit.
Consistories.
Pius IX created a total of 122 new Cardinals – the limit of the College of Cardinals was 70 – of which 64 were alive at his death. Noteworthy elevations included Vincenzo Pecci, his eventual successor Leo XIII; Nicholas Wiseman of Westminster; Henry Edward Manning; and John McCloskey, the first American ever to be elevated into the College of Cardinals.
Sovereign of the Papal States.
Pius IX was not only pope, but until 1870, also the Sovereign Ruler of the Papal States. His rule was considered secular, and as such, he was occasionally accorded the title "king." However, whether this was ever a title accepted by the Holy See is unclear. One of the most fervent contemporary critics of his infallibility dogma, Ignaz von Döllinger, considered the political regime of the pope in the Papal States "as wise, well-intentioned, mild-natured, frugal and open for innovations." Yet there was controversy. In the period before the 1848 revolution, Pius was a most ardent reformer advised by such innovative thinkers as Rosmini who were able to reconcile the new "free" thinking concerning human rights with the classical natural law tradition of the Church's teaching in political affairs and economic order (social justice teachings). After the revolution however, his political reforms and constitutional improvements were considered minimalist, remaining largely within the framework of the 1850 laws mentioned above.
Reforms in the Papal States.
 As liberal Europe applauded his election, he introduced political reforms on a broad scale. He initiated the construction of railways, and the installation of street lighting throughout Rome. He improved agricultural technology and productivity via farmer education in newly created scientific agricultural institutes. He abolished the requirements for Jews to attend Christian services and sermons and opened the papal charities to the needy of them. He gave much to charities, living like a pauper. The new pope freed all political prisoners by giving amnesty to revolutionaries, which horrified the conservative monarchies in the Austrian Empire and elsewhere Within one year of his election, he appointed an assembly of lay people to assist in the governing of the Papal States. His actions were applauded by Protestant statesmen. "He was celebrated in New York, London and Berlin as a model ruler."
Governmental structure.
In 1848, Pius IX released a new constitution titled the Fundamental Statute for the Secular Government of the States of the Church.
The governmental structure of the Papal States reflected the dual spiritual-secular character of the papacy. The secular or laypersons were strongly in the majority with 6,850 persons versus 300 members of the clergy. Nevertheless, the clergy made key decisions and every job applicant had to present a character evaluation from his parish priest to be considered.
Finance.
Financial administration in the Papal States under Pius IX was increasingly put in the hands of laypersons. The budget and financial administration in the Papal States had long been subject to criticism even before Pius IX, and did not end with his papacy. In 1850, he created a governmental finance congregation consisting of four laypersons with finance background for the 20 provinces.
Commerce and trade.
Pius IX is credited with systematic efforts to improve manufacturing and trade by giving advantages and papal prizes to domestic producers of wool, silk and other materials destined for export. He improved the transportation system by building roads, viaducts, bridges and seaports. A series of new railway links connected the Papal States to northern Italy. It became soon visible, that the Northern Italians were more adept to exploit economically the modern means of communication than the inhabitants in central and Southern Italy.
Justice.
The justice system of the Papal States was subject to numerous accusations, not unlike the justice systems in the rest of Italy. There was a general lack of legal books and standards and accusations of partiality of the judges. Throughout Italy but also in the Papal States, mafia-type criminal bands threatened commerce and travellers in several regions, engaging in robbery and murder at will.
133 people were executed during Pius IX's rule in the Papal States.
Military.
A unique position was granted to the papal army, at that time consisting almost exclusively of foreigners: the Roman Black Nobility was not willing to serve, and the population resisted military service despite a decent salary structure and the potential for promotion. A main element of the papal army was the Swiss Guard. The number of papal soldiers in 1859 was 15,000.
Universities.
The two papal universities in Rome and Bologna suffered much from revolutionary activities in 1848 but their standards in the areas of science, mathematics, philosophy and theology were considered adequate. Pius recognized that much had to be done and instituted a reform commission in 1851.
During his tenure, Catholics and Protestants collaborated to found a school in Rome to study international law and train international mediators committed to conflict resolution.
Social life.
There was one newspaper, "Giornale di Roma," and one periodical, "Civilta Cattolica," run by Jesuits. When Marcantonio Pacelli, the grandfather of Eugenio Pacelli, approached Pius about an official newspaper, "L’Osservatore Romano," which printed what the pope said and did the previous day, Pius turned him down. Pacelli published anyway, and Leo XIII bought it from him a few years later.
Arts.
Like most of his predecessors, Pius IX was a patron of the arts. He supported art, architecture, painting, sculpture, music, goldsmiths, coppersmiths and more, and handed out numerous rewards to its representatives. Much of his efforts were oriented to Churches in Rome and in the Papal States, many of which were renovated and improved.
Restorations and discoveries.
Great efforts were undertaken to restore historic walls, fountains, streets and bridges. He ordered the excavation of Roman sites, which led to several major discoveries. He ordered the strengthening of the Colosseum, which was threatened with collapse. Huge sums were spent in the discovery of Christian catacombs, for which Pius created a new archaeological commission in 1853.
Protestants and Jews.
The Papal States were a theocracy in which the Catholic Church and Catholics had more rights than members of other religions. Pius IX's policies became increasingly reactionary over time: At the beginning of his pontificate, together with other liberal measures, Pius opened the Jewish ghetto in Rome. After returning from exile in 1850, during which the Roman Republic issued sharp anti-Church measures, the Pope issued a series of anti-liberal measures, including re-instituting the Ghetto.
In 1858, in a highly publicized case, the police of the Papal States seized a 6-year-old Jewish boy, Edgardo Mortara, from his parents. A Christian servant girl of the family, fearing he would die, had reportedly baptized him while he was ill. The Papal state law did not permit Christians to be raised by Jews, even their own parents. Pius raised the boy in the papal household and the boy later was ordained a priest.
Policies toward other nations.
Pius IX was the last pope who was also a secular ruler as monarch of the Papal States. As sovereign-ruler of the Papal States, he ruled over 3 million people and conducted diplomatic relations with other states, the most important of which was Italy, which in 1870 ended the independent Papal States and reduced the papacy to a miniature state.
Italy.
Well aware of the political pressures within the Papal States, Pius IX's first act of general amnesty for political prisoners did not consider the potential implications and consequences: The freed revolutionaries merely resumed their previous activities and his concessions only provoked greater demands as patriotic Italian groups sought not only a constitutional government – which he was sympathetic to – but also the Unification of Italy under his leadership and a war of liberation against Catholic Austria, which claimed the northern Italian provinces as its own.
By early 1848, all of Western Europe began to be convulsed in various revolutionary movements. The Pope, claiming to be above national interests, refused to go to war with Austria, which totally reversed the up to now popular view of him in his native Italy. In a calculated, well-prepared move, Rossi was assassinated on 15 November 1848, and in the days following, the Swiss Guards were disarmed, making the Pope a prisoner in his palace.
A Roman Republic was declared in February 1849. Pius responded from his exile by excommunicating all participants.
He visited the hospitals to comfort the wounded and sick but he seemed to have lost both some of his liberal tastes and his confidence in the Romans, who had turned against him in 1848. Pius decided to move his residence from the Quirinal Palace inside Rome to the Vatican, where popes have lived ever since. He reformed the governmental structure of the Papal States on 10 September 1850 and its finances on 28 October in the same year. 
After defeating the papal army on 18 September 1860 at the Battle of Castelfidardo, and on 30 September at Ancona, Victor Emmanuel took all the Papal territories except Latium with Rome. In 1866 he granted Pius IX the Law of Guarantees (13 May 1871) which gave the Pope the use of the Vatican but denied him sovereignty over this territory, nevertheless granting him the right to send and receive ambassadors and a budget of 3.25 million liras annually. Pius IX officially rejected this offer (encyclical "Ubi nos," 15 May 1871), retaining his claim to all the conquered territory.
Mexico.
With Napoleon III's establishment of the Second Mexican Empire and Maximilian I of Mexico as its ruler in 1864, the Church was looking for some relief from a friendly government after the anti-clerical actions of Benito Juárez. Juárez had recently suspended payment on foreign debt and seized Church property.
Pius had blessed Maximilian and his wife Charlotte of Belgium before they set off for Mexico to begin their reign. But the friction between the Vatican and Mexico would continue with the new Emperor when Maximilian insisted on freedom of religion, which Pius opposed. Relations with the Vatican would only be resumed when Maximilian sent a recently converted American Catholic priest Father Fischer to Rome as his envoy.
Contrary to Fischer's reports back to Maximilian, the negotiations did not go well and the Vatican would not budge.
Maximilian sent his wife Charlotte to Europe to plead against the withdrawal of French troops. After an unsuccessful attempt at negotiating with Napoleon III, Charlotte then traveled to Rome to plead with Pius in 1866. As the days passed Charlotte's mental state became overtly paranoid.
She sought refuge with the pope, and she would eat and drink only what was prepared for him, fearful that everything else might be poisoned. The pope, though alarmed, was accommodating to her and even agreed to let her stay in the Vatican one night after she voiced anxiety about her safety. She and her assistant were the first women to stay the night inside the Vatican.
United Kingdom.
England for centuries was considered missionary territory for the Catholic Church. Pius IX changed that with the Bull "Universalis Ecclesiae" (29 September 1850). He re-established the Catholic hierarchy in England and Wales, under the newly appointed Archbishop and Cardinal Nicholas Wiseman with 12 additional episcopal seats: Southwark, Hexham, Beverly, Liverpool, Salford, Shrewsbury, Newport, Clifton, Plymouth, Nottingham, Birmingham and Northampton. Some violent street protests against the "papal aggression" resulted in the Ecclesiastical Titles Act 1851 being passed by Parliament, which on penalty of imprisonment and fines forbade any Catholic bishop to use any episcopal title 'of any city, town or place, or of any territory or district (under any designation or description whatsoever), in the United Kingdom'. The law was never enforced and was revoked twenty years later.
Netherlands.
The Dutch government instituted religious freedom for Catholics in 1848. In 1853, Pius erected the Archdiocese of Utrecht and four dioceses in Haarlem, Den Bosch, Breda and Roermond under it. As in England, this resulted in a popular outburst of anti-Catholic sentiment, which as in England, soon subsided.
Spain.
Spain – traditionally Catholic – offered a challenge to Pius IX as anti-clerical governments were in power from 1832, resulting in the expulsion of religious orders, the closing of convents, the closing of Catholic schools and libraries, the seizure and sale of churches and religious properties and the inability of the Church to fill vacant dioceses. In 1851, Pius IX concluded a concordat with Queen Isabella II, which stipulated that unsold Church properties were to be returned, while the Church renounced properties that had already passed owners. This flexibility of Pius led to Spain guaranteeing the freedom of the Church in religious education.
United States.
Pope Pius IX approved the unanimous request of American bishops that the Immaculate Conception be invoked as the Patroness of the United States of America on 7 February 1847.
A letter Pius IX wrote to Jefferson Davis, addressing him as the "Illustrious and Honorable President of the Confederate States of America," was seen by some as the highest international recognition the Confederate States of America ever received.
Pius IX elevated John McCloskey as the first American to the College of Cardinals on 15 March 1875.
Canada.
Pius IX increased the number of Canadian dioceses from four to 21 with 1,340 churches and 1,620 priests in 1874.
Concordats.
Pius IX signed concordats with Spain, Austria, Tuscany, Portugal, Haiti, Honduras, Ecuador, Nicaragua, El Salvador and Russia.
Austria.
The 1848 revolution had mixed results for the Catholic Church in Austria-Hungary. It freed the Church from the heavy hand of the state in its internal affairs, which was applauded by Pius IX. Similar to other countries, Austria-Hungary had significant anti-Catholic political movements, mainly liberals, which forced the emperor Franz-Joseph I in 1870, to renounce the 1855 concordat with the Vatican. Austria had already in 1866 nullified several of its sections concerning the freedom of Catholic schools and prohibition of civil marriages. After diplomatic approaches failed, Pius responded with an encyclical on 7 March 1874, demanding religious freedom and freedom of education. Despite these developments, there was no equivalent to the German Kulturkampf in Austria, and Pius created new dioceses throughout Austria-Hungary.
Russia.
The Pontificate of Pius IX began in 1847 with an "Accomodamento," a generous agreement, which allowed Pius to fill vacant Episcopal Sees of the Latin rites both in Russia (Baltic countries) and the Polish provinces of Russia. The short-lived freedoms were undermined by the Orthodox Church, Polish political aspirations in the occupied lands and the tendency of imperial Russia to act against any dissent. Pius first tried to position himself in the middle, strongly opposing revolutionary and violent opposition against the Russian authorities, and, appealing to them for more Church freedom.
After the failure of the Polish uprising in 1863, Pius sided with the persecuted Poles, protesting their persecutions, infuriating the Tsarist government to the point that all Catholic dioceses were eliminated by 1870. Pius criticized the Tsar—without naming him—for expatriating whole communities to Siberia, exiling priests, condemning them to labour camps and abolishing Catholic dioceses. He pointed to Siberian villages Tounka and Irkout, where in 1868, 150 Catholic priests were awaiting death.
Plans to leave Rome.
Several times during his pontificate, Pius IX considered leaving Rome. One occurrence was in 1862, when Giuseppe Garibaldi was in Sicily gathering volunteers for a campaign to take Rome under the slogan "Roma o Morte" (Rome or Death). On 26 July 1862, before Garibaldi and his volunteers were stopped at Aspromonte:
Pius IX confided his fears to Lord Odo Russell, the British Minister in Rome, and asked whether he would be granted political asylum in England after the Italian troops had marched in. Odo Russell assured him that he would be granted asylum if the need arose, but said that he was sure that the Pope's fears were unfounded.
Two other instances occurred after the Capture of Rome and the suspension of the First Vatican Council. Otto von Bismarck confided these to Moritz Busch:
As a matter of fact, he [Pius IX] has already asked whether we could grant him asylum. I have no objection to it—Cologne or Fulda. It would be passing strange, but after all not so inexplicable, and it would be very useful to us to be recognised by Catholics as what we really are, that is to say, the sole power now existing that is capable of protecting the head of their Church. [...] But the King [William I] will not consent. He is terribly afraid. He thinks all Prussia would be perverted and he himself would be obliged to become a Catholic. I told him, however, that if the Pope begged for asylum he could not refuse it. He would have to grant it as ruler of ten million Catholic subjects who would desire to see the head of their Church protected.
Rumours have already been circulated on various occasions to the effect that the Pope intends to leave Rome. According to the latest of these the Council, which was adjourned in the summer, will be reopened at another place, some persons mentioning Malta and others Trient. [... ] Doubtless the main object of this gathering will be to elicit from the assembled fathers a strong declaration in favour of the necessity of the Temporal Power. Obviously a secondary object of this Parliament of Bishops, convoked away from Rome, would be to demonstrate to Europe that the Vatican does not enjoy the necessary liberty, although the Act of Guarantee proves that the Italian Government, in its desire for reconciliation and its readiness to meet the wishes of the Curia, has actually done everything that lies in its power.
Theology.
Pius was adamant about his role as the highest teaching authority in the Church. He promoted the foundations of Catholic Universities in Belgium and France and supported Catholic associations with the intellectual aim to explain the faith to non-believers and non-Catholics. The "Ambrosian Circle" in Italy, the "Union of Catholic Workers" in France and the "Pius Verein" and the "Deutsche Katholische Gesellschaft" in Germany all tried to bring the Catholic faith in its fullness to people outside of the Church.
Mariology.
Pius shared a strong devotion to the Virgin Mary with many of his contemporaries, who contributed to Roman Catholic Mariology. Marian doctrines featured prominently in 19th century theology, especially the issue of the Immaculate Conception of Mary. During his pontificate, petitions increased requesting the dogmatization of the Immaculate Conception. In 1848 Pius appointed a theological commission to analyze the possibility for a Marian dogma.
Thirty-eight Encyclicals.
Pius issued a record 38 encyclicals. They include:
"Qui pluribus" (1846) dealt with faith and religion; "Praedecessores nostros" (1847) with aid for Ireland; "Ubi primum" 1848 with The Immaculate Conception; "Nostis et nobiscum" 1849 with the Church in the Papal States; "Neminem vestrum" 1854 with the bloody Persecution of Armenians; "Cum nuper" 1858 with the care for Clerics; "Amantissimus" 1862 with the Care of the Churches; "Meridionali Americae" 1865 with the Seminary for the Native Clergy; "Omnem sollicitudinem" 1874 about the Greek-Ruthenian Rite; "Quod nunquam" 1875 the Church in Prussia. On 7 February 1862 he issued the papal constitution "Ad universalis Ecclesiae," dealing with the conditions for admission to religious orders of men in which solemn vows are prescribed. Unlike popes in the 20th century, Pius IX did not use encyclicals to explain the faith, but to condemn what he considered errors. Pius IX was the first pope to popularize encyclicals on a large scale to foster his views.
First Vatican Council.
Pius decisively acted on the century-old disagreement between Dominicans and Franciscans regarding the Immaculate Conception of Mary, deciding in favor of the Franciscan view. However, this decision, which he formulated as an infallible dogma, raised a question: Can a pope make such decisions without the bishops? This foreshadowed one topic of the First Vatican Council, which he later convened for 1869. The Pope did consult the bishops beforehand with his encyclical "Ubi primum" (see below), but insisted on having this issue clarified nevertheless. The Council was to deal with Papal Infallibility, enhancing the role of the papacy and decreasing the role of the bishops. The role of the bishops was to be dealt with at the Council, but it was disbanded because of the imminent attack by Italy against the Papal States. Thus, the major achievements of Pius IX are his Mariology and Vatican I.
Influence.
Pius IX approved 74 new religious congregations for women alone. In France, Pius IX created over 200 new dioceses and created new hierarchies in several countries.
Last years and death.
Pius IX lived just long enough to witness the death of his old adversary, Victor Emmanuel II of Italy in January 1878. As soon as he learned about the seriousness of the situation of the king, he absolved him of all excommunications and other ecclesiastical punishments. Pius IX died one month later on 7 February 1878 at 5:40 pm, of epilepsy, which led to a seizure and a sudden heart attack, while saying the rosary with his staff.
Since 1868, the Pope was plagued first by facial erysipelas and then by open sores on his legs. Nevertheless, he insisted on celebrating daily Mass. The extraordinary heat of the summer of 1877 worsened the sores to the effect that he had to be carried. He underwent several painful medical procedures, which he undertook with remarkable patience. He spent most of his last few weeks in his library, where he received cardinals and held audiences. On 8 December, the Feast of the Immaculate Conception, his situation improved markedly to the point that he could walk again. By February, he could say Mass again on his own in standing position, enjoying the popular celebration of the 75th anniversary of his first communion. Bronchitis, a fall to the floor, and rising temperature worsened his situation after 4 February 1878. He continued joking about himself, when the Cardinal Vicar of Rome ordered bell-ringing and non-stop prayers for his recuperation. "Why do you want to stop me from going to heaven?" he asked with a smile. He told his doctor that his time had come. Pope Pius IX died on 7 February 1878, aged 85, concluding the longest pontificate in papal history, after that of St Peter whom tradition holds had reigned for 37 years. His last words were "Guard the church I loved so well and sacredly," as recorded by the Cardinals kneeling beside his bedside. His body was originally buried in St. Peter's grotto, but was moved in a night procession on 13 July 1881 to the Basilica of Saint Lawrence outside the Walls. When the cortege approached the Tiber River, a group of anticlerical Romans threatened to throw the coffin into the river but a contingent of militia arrived.
Beatification.
The process for his beatification, which in the early stages was strongly opposed by the Italian government, was begun on 11 February 1907, and recommenced three times. The Italian government had since 1878 strongly opposed beatification of Pius IX. Without Italian opposition, Pope John Paul II declared him venerable on 6 July 1985, and beatified him on 3 September 2000 (his commemoration is 7 February).
The beatification of Pius IX was controversial, and was criticized by Jews and Christians because of what was perceived as his authoritarian, reactionary politics; the accusation of abuse of episcopal powers; and anti-Semitism (specifically, in the case of Edgardo Mortara). Critics contend that his beatification placed "an unbearable burden on relations between Jews and Catholics," especially given Pope John Paul II's conciliatory gestures toward Judaism. The process coincided with the canonization of Edith Stein, likewise controversial. Hans Küng saw the beatification of Pius IX as evidence of the degeneration of canonizations to "gestures of church politics."
Legacy.
Pius IX celebrated his silver jubilee in 1871, going on to have the longest reign in the history of the post-apostolic papacy, 31 years, 7 months and 23 days. As his temporal sovereignty was lost, the Church rallied around him, and the papacy became more centralized, to which his personal life-style of simplicity and poverty is considered to have contributed. From this point on, the papacy became and continues to become increasingly a spiritual, and less a temporal, authority. Pius IX's pontificate marks the beginning of the modern papacy.
Having started as a liberal, Pius IX turned conservative after being thrown out of Rome. Thereafter, he was considered politically conservative, but a restless and radical reformer and innovator of Church life and structures. Church life, religious vocations, new foundations and religious enthusiasm all flourished at the end of his pontificate. Politically, his pontificate ended with the isolation of the papacy from most major powers of the world: "The prisoner of the Vatican" had poor relations with Russia, Germany, and the United States, poor relations with France and open hostility with Italy. Yet he was most popular with the faithful in all these countries, in many of which Pope Pius associations were formed in his support. He made lasting Church history with his 1854 infallible decision of the Immaculate Conception, which was the basis for the later dogma on the Assumption. His other lasting contribution is the invocation of the ecumenical council Vatican One, which promulgated the definition of Papal infallibility. With his advice he helped Saint John Bosco found the Salesian Society, for which reason he is also called "don Bosco's Pope".
The Prophecy of the Popes, attributed to Saint Malachy, is a list of 112 short phrases in Latin. They purport to describe each of the popes. It describes Pius IX as "Crux de Cruce," Cross of the cross.
Photos of Pope Pius IX.
The art of photography developed during Pius IX's pontificate, and he was the first pope to be photographed, mainly in his later years.
Some contemporaries of Pius IX like Cardinal Giuseppe Pecci considered photography inferior to painting and refused to be photographed. Pius, however, was open to the new form of art.
Further reading.
</dl>

</doc>
<doc id="54162" url="http://en.wikipedia.org/wiki?curid=54162" title="V8 Supercars">
V8 Supercars

V8 Supercars is a touring car racing category based in Australia and run as an International Series under Fédération Internationale de l'Automobile (FIA) regulations.
V8 Supercar events take place in all Australian states and territories, excluding the Australian Capital Territory (which formerly held the Canberra 400). An overseas round is also held in New Zealand, with events previously held in China, Bahrain, the United Arab Emirates and the United States. A non-championship event is also held in support of the Australian Grand Prix. Race formats vary between each event with sprint races between 100 and 200 kilometres in length, street races between 125 and 250 kilometres, and two-driver endurance races held at Sandown, Bathurst and Gold Coast. The series is broadcast in 137 countries and has an average event attendance of over 100,000, with over 250,000 people attending major events such as the Clipsal 500.
The vehicles used in the series are loosely based on road-going, four-door saloon cars. Cars are custom made using a control chassis, with only certain body panels being common between the road cars and race cars. To ensure parity between each make of car, many control components are utilised. All cars must use a 5.0-litre, naturally aspirated V8-engine. Originally only for Ford Falcons and Holden Commodores, the New Generation V8 Supercar regulations, introduced in 2013, opened up the series to more manufacturers. Nissan were the first new manufacturer to commit to the series with four Nissan Altimas, followed by Erebus Motorsport with three Mercedes-Benz E63 AMGs. Volvo entered the series in 2014 with Garry Rogers Motorsport racing the Volvo S60.
History.
Group 3A.
The concept of a formula centred around V8-engined Fords and Holdens for the Australian Touring Car Championship had been established as early as mid-1991. With the new regulations set to come into effect in 1993, Ford and Holden were both keen to know the details of the new formula by the end of 1991, putting pressure on the Confederation of Australian Motor Sport (CAMS) to provide clarity on the matter. However, CAMS was waiting to see what the FIA did with its proposed international formula for 2.5 and 2.0-litre touring cars.
The new rules for the ATCC were announced in November 1991 and indicated that the V8 cars would be significantly faster than the smaller engined cars. During 1992, CAMS looked at closing the performance gap between the classes, only to have protests from Ford and Holden, who didn't want to see their cars beaten by the smaller cars. In June 1992, the class structure was confirmed:
Both the Ford Falcon EB and Holden Commodore VP ran American-based engines which were restricted to 7,500 rpm and a compression ratio of 10:1. The Holden teams had the option of using the Group A-developed 5.0-litre Holden V8 engine, although this was restricted to the second tier 'privateer' teams from 1994 onwards, forcing the major Holden runners to use the more expensive Chevrolet engine. The V8s were first eligible to compete in the endurance races of 1992. The distinctive aerodynamics package, consisting of large front and rear spoilers, was designed partly with this in mind, to give the new cars a better chance of beating the Nissan Skyline GT-Rs in those races.
The new rules meant that cars such as the turbocharged Nissan Skyline GT-R and Ford Sierra RS500 Cosworth were not eligible to compete in 1993, while cars such as the BMW M3 were. However, the M3 received few of the liberal concessions given to the new V8s and also had an extra 100 kg added to its minimum weight so, with the Class C cars eligible for 1993 only, the German manufacturer’s attention switched to the 2.0-litre class for 1994.
Cars from all three classes would contest the 1993 Australian Touring Car Championship as well as non-championship Australian touring car events such as the Bathurst 1000. However, for the purposes of race classification and points allocation, cars competed in two classes:
Originally the 2.0-litre class cars competed in a separate race to the V8s. This was changed for the second round of 1993, after there were only nine entrants in the 2.0-litre class for the first round at Amaroo.
With the new regulations intended to be a parity formula, there were protests by the Holden teams that the Fords had an aerodynamic advantage after they won the opening three rounds, beating the Commodore comprehensively. After round five at Winton, Holden was granted a new front and rear wing package. The BMWs were also allowed a new splitter and a full DTM-specification rear wing. Disparity between the Fords and Holdens continued to be a talking point during the next few years, with various concessions given to each manufacturer to try and equalise the two cars.
From 1995, the 2.0-litre cars, now contesting their own series as Super Touring cars, became ineligible for the Australian Touring Car Championship. They did not contest the endurance races at Sandown and Bathurst, leaving these open solely to the 5.0-litre Ford and Holden models.
V8 Supercars.
The Australian Vee Eight Super Car Company (AVESCO) – a joint venture between the Touring Car Entrants Group of Australia (TEGA), sports promoters IMG and the Australian Motor Sports Commission – was formed in November 1996 to run the series. This set the foundation for the large expansion of the series during the following years. The category also adopted the name 'V8 Supercars' at this time, though the cars themselves were much unchanged. A new television deal with Network Ten was organised, although this had follow-on effects for the Bathurst 1000 later in the year.
In February 1997, Tony Cochrane and James Erskine left IMG. Together with David Coe, they formed Sports & Entertainment Limited (SEL) in April 1997. TEGA would have a 75% share in AVESCO, with SEL owning the other 25%. TEGA was responsible for the rules and technical management of the series and the supply of cars and drivers while SEL was responsible for capturing and maintaining broadcasting rights, sponsorship, licensing and sanction agreements.
The expansion of the series began in 1998, with the first round to be held in the Northern Territory taking place at Hidden Valley Raceway. In 1999, a new street-race on a shortened version of the Adelaide Grand Prix Circuit became one of the first festival-style events which would become common in later years. Australia's capital city, Canberra, hosted its first event in 2000. In 2001, a championship round was held in New Zealand for the first time, at Pukekohe Park Raceway. In 2002, the V8 Supercar support event at the Indy 300 on the Gold Coast became a championship round, having been a non-championship event since 1994.
Major format changes were made for 1999, with the incorporation of the endurance races into the championship. Control tyres were used for the first time, with Bridgestone selected as the supplier. The series was also renamed from the 'Australian Touring Car Championship' to the 'Shell Championship Series', by virtue of Shell's sponsorship of the category. Reverse-grid races were introduced for multiple rounds in 2000 before being confined to just the Canberra round for 2001. Also in 2001, compulsory pit stops were introduced at certain rounds and the Top Ten Shootout was used at all rounds. The control tyre supplier changed from Bridgestone to Dunlop in 2002 and the series name was changed to the 'V8 Supercar Championship Series' after Shell discontinued their sponsorship.
Project Blueprint.
Discussions about parity had returned in 2000, with 100-millimetres trimmed from the front spoiler of the Commodore after Holden, in particular the Holden Racing Team, had dominated in 1998 and 1999. Ford had threatened to withdraw from the series, but nothing came of this. After Holden again dominated in 2001 and 2002, a new set of regulations, dubbed 'Project Blueprint', was introduced in 2003 to close the performance gap between the Commodore and the Falcon, thus creating closer, fairer racing. Project Blueprint was developed by Paul Taylor and Wayne Cattach, who spent two years designing a formula which would eliminate most of the differences between the Fords and Holdens.
Project Blueprint saw the chassis pick-up points, wheelbase, track and driving position become common across both manufacturers. The Holdens were now required to use double wishbone front suspension, similar to that of the Falcon, rather than the MacPherson struts used previously. The aerodynamic packages were comprehensively tested and revised and differences in the porting of each of the manufacturers' engines were also removed. The performance of the new Ford Falcon BA and Holden Commodore VY and VZs was fairly even for the next four years, with Ford winning the championship in 2003, 2004 and 2005 and Holden winning in 2006. Reverse-grid races were used at certain events in 2006 before unpopularity with the drivers, teams and fans saw them abolished halfway through the season.
The Holden Commodore VE caused controversy when it was introduced in 2007. The production model was longer, wider and taller than the rival Ford Falcon BF and outside of the limits set by Project Blueprint. As a result, the VE race car was granted custom body work - namely shortened rear doors and a lowered roof line - in order to meet the regulations. Despite this, the VE was approved for use in the series, along with the BF Falcon, after several months of pre-season testing. Sequential gearboxes were introduced in 2008 and became compulsory by the end of the year. In 2009, E85 (a fuel consisting of 85% ethanol and 15% unleaded petrol) was introduced in an effort to improve the environmental image of the sport. Carbon dioxide emissions decreased by up to 50%, however fuel consumption was increased by 30% to produce the same power as before. 2009 also saw the introduction of a soft compound tyre at certain events to try and improve the quality of the racing and create different strategies.
In 2005, AVESCO changed its name to V8 Supercars Australia (VESA). The series continued to expand during this time, with races held outside of Australasia for the first time. The series travelled to the Shanghai International Circuit in China in 2005, originally on a five-year agreement, however the promoter of the race dropped their support and the series did not return thereafter. 2006 saw the series travel to the Middle East, with an event held at the Bahrain International Circuit in Bahrain. Multiple new street circuits appeared on the calendar in 2008 and 2009, with new events held in Hamilton in New Zealand, Townsville in North Queensland and Sydney Olympic Park. The series' Middle East expansion continued in 2010 with a second round held at the Yas Marina Circuit in Abu Dhabi. In November 2010, the series was granted international status by the FIA for the 2011 season, allowing the series to race at up to six international venues each year. As a result, the series name was changed to the 'International V8 Supercars Championship'.
2008 saw the separate boards of directors of VESA and TEGA merge into a single board that was solely responsible for the administration of the category. The new board of directors was composed of four TEGA representatives, two members from SEL and two independent directors. In 2011, TEGA and SEL entered a sale agreement with Australian Motor Racing Partners (AMRP), which had significant financial backing from Archer Capital. This agreement saw SEL lose its 25% stake in V8 Supercars, with Archer Capital taking up a 60% share and TEGA the other 40%. A new board of directors was appointed, with two TEGA representatives and two AMRP representatives.
New Generation V8 Supercar.
In the middle of 2008, a project led by Mark Skaife was organised by V8 Supercars to investigate future directions for the sport. The project had the primary objective of cutting costs to $250,000 per car through the use of control parts and to create a pathway for new manufacturers to enter the series, provided that they have a four-door saloon car in mass production. The new formula, called 'Car of the Future', was scheduled to be introduced before or during the 2012 season. The plan was publicly unveiled in March 2010 and was shown to incorporate several key changes to the internal workings of the car. The chassis and the cooling, fuel and electronics systems would all be changed to control parts, with changes to the engine, drivetrain, rear suspension, wheels and the control brake package. The safety of the cars was also to be reviewed and improved. While the plans were well received by all of the teams, Holden Motorsport boss Simon McNamara warned potential new manufacturers to stay out of the championship just hours after the plans were released, claiming that they would "gain nothing" from entering the series.
Major changes were revealed to be a switch from a live rear axle to independent rear suspension, the use of a rear transaxle instead of a mid-mounted gearbox, the repositioning of the fuel tank in front of the rear axle to improve safety, replacing the windscreen with a polycarbonate unit and a switch from 17-inch to 18-inch wheels. In 2011, it was announced that the Car of the Future wouldn't be introduced until 2013. In February 2012, Nissan confirmed that they would enter the series under Car of the Future regulations with Kelly Racing. Later in 2012, Australian GT Championship team Erebus Racing announced they would be running Mercedes-Benz cars in the championship, taking over Stone Brothers Racing. In June 2013, Volvo announced it would enter the series in 2014 in a collaboration with its motorsport arm, Polestar Racing, and Garry Rogers Motorsport.
The series continued its international expansion in 2013, with the first event in North America held at the Circuit of the Americas in Austin, Texas. In November 2013 the Car of the Future moniker was dropped in favour of the New Generation V8 Supercar.
V8 Supercar specifications.
The current New Generation V8 Supercar regulations are an evolution of the previous Project Blueprint regulations. The regulations control many aspects of the car to ensure parity between the manufacturers, allowing for minor differences in the engines and body shapes so that the cars bear some resemblance to their production counterparts. The regulations were also designed to lower the costs of building and repairing a car.
Bodyshell.
The body of each car is based on its corresponding production car. However, due to the regulations governing the dimensions of the cars to ensure parity, the race cars are lowered and shortened or lengthened to meet the regulations. As of 2014, only the Ford Falcon FG, Holden Commodore VF, Mercedes-Benz E63 AMG W212, Nissan Altima L33 and Volvo S60 are eligible to compete. To save costs, the front guards, passenger-side front door, rear doors and rear quarter panels are made from composite materials. The head lights and tail lamps are carried over from the road car, while the windscreen is replaced by a polycarbonate unit.
The bodies are built around a control chassis, featuring a full roll cage, originally designed by Pace Innovations but which can be made, or partially made, by other accredited builders, including certain race teams. Many safety features are utilised to protect the driver in the event of a crash. The fuel tank is positioned in front of the rear axle to prevent it from being damaged or ruptured in a rear end impact. The driver is seated towards the centre of the car and extra reinforcement is used on the roll cage on the drivers' side to lessen the risk of injury in a side-on collision. The cars also feature a collapsible steering column and a fire extinguisher system.
Aerodynamics.
All cars have an aerodynamics package consisting of a front spoiler and splitter, side skirts and a rear wing. The aerodynamics package for each manufacturer is homologated after a series of tests which ensure that the different body styles produce near-identical downforce and drag numbers.
Weight.
The minimum weight of each car is 1410 kg including the driver, with a minimum load of 750 kg over the front axle. The minimum weight for the driver is 100 kg and includes the driver dressed in full racing apparel, the seat and seat mountings and any ballast needed to meet the minimum weight. Some other components also have a minimum weight, such as the engine (200 kg) and the front uprights (10.5 kg each).
Engine and drivetrain.
All cars must be front-engined and rear-wheel drive. All cars use a 5.0-litre, naturally aspirated V8-engine with electronic fuel injection, capable of producing between 460 and 485 kW (620–650 bhp). Manufacturers are free to choose between using an engine based on one from their own line up or a generic engine provided by V8 Supercars. Both Ford and Holden use US-based racing engines with pushrod actuated valves and two valves per cylinder. Mercedes, Nissan and Volvo use modified versions of their own engines, with hydraulic-lift valves and four valves per cylinder. All engines are electronically limited to 7,500 rpm and have a compression ratio of 10:1.
Power is transferred from the engine to the rear wheels through a six-speed sequential transaxle with an integrated spool differential. The individual gear ratios and the final drive ratio are fixed with drop gears at the front of the transaxle allowing the teams to alter the overall transmission ratio for different circuits. The cars use a triple plate clutch. The cars run on E85 fuel with a fuel tank capacity of 112 litres.
An electronic control unit (ECU), provided by MoTeC, is used to monitor and optimise various aspects of the engine's performance. Numerous sensors in the car collect information which is then transmitted to the team, allowing them to monitor things such as tyre wear and fuel consumption and find potential problems with the car. The ECU is also used by officials during the scrutineering process.
Suspension.
All cars are required to use a double wishbone setup for the front suspension and independent rear suspension. Both the front and rear suspension systems feature adjustable shock absorbers and an anti-roll bar which can be adjusted from the cockpit.
Brakes.
The cars use disc brakes supplied by AP Racing on the front and rear, with the master cylinders provided by former control brake supplier Alcon. The front discs have a diameter of 395 mm and a six-piston caliper, while the rear discs are 355 mm diameter and have a four-piston caliper.
Wheels and tyres.
The cars use 18-inch control wheels, produced by Rimstock and supplied by Racer Industries, and control tyres from Dunlop. The slick tyre is available in both hard and soft compounds, with teams required to use either or both compounds in each race, depending on the event. A grooved wet tyre is used in damp conditions.
Cost.
The New Generation V8 Supercar regulations are intended to reduce the cost of building a car (without engine) from around $450,000 to $250,000, with the cost of an engine coming down from around $120,000 to $50,000. These targets are not expected to be met until after the initial development phase has transitioned to replicated manufacture.
Series structure.
Teams and drivers.
In order to compete in the V8 Supercars Championship, drivers are required to hold a CAMS National Circuit Competition Licence, or a licence of an equivalent or higher level. Each car entered is required to have a Racing Entitlements Contract (REC). An REC is a contract between V8 Supercars and a team which outlines the team's entitlements and obligations. RECs may be leased by their owners to another party for a maximum of two years, after which the owner must either use it themselves or sell it. A racing number is tied to each REC, with teams able to apply for an REC number to be changed. The defending series champion is entitled to use the number 1, with the original REC number of that car reserved and not able to be used by another team without the agreement of its owner.
The RECs were originally issued in 1999. Known as TEGA franchise agreements, they were divided into three categories – Level 1, Level 2 and Level 3. Twelve Level 1 franchises were issued to those teams that had competed in the series full-time since its inception in 1997:
A thirteenth was later issued to Bob Forbes Racing. A Level 1 franchise required a team to race at least one car at all events, and at various times allowed a team to enter up to four cars. Other teams received Level 2 and Level 3 franchises based on their level of participation. The structure was changed a number of times, before the present system of 28 RECs was arrived at in 2011. V8 Supercars bought a number of RECs as they became available in order to achieve a long-held desire to reduce the field to 28 cars.
At the end of 2013, Lucas Dumbrell Motorsport, Tony D'Alberto Racing and Triple F Racing each returned a REC to V8 Supercars. These were put up for sale in 2014, but no bids were received. One was reclaimed by Lucas Dumbrell Motorsport in 2015 after a legal fight. At the end of 2014, a further REC was returned by James Rosenberg Racing. In April 2015, V8 Supercars launched a tender for one REC for the 2016 season.
Teams consist of one, two or four cars, with most one-car teams forming an alliance with a two-car team. These single-car teams are known as "satellite teams" of the two car teams. Only the REC holders are allowed to compete at each event, although "wildcard" entries are accepted for the endurance races, with a maximum of six extra cars on top of the regular 28. Both V8 Supercar and Development Series teams have entered wildcard entries in previous years. In 2014, the first wildcard entry for a sprint race was issued when Dick Johnson Racing entered a third car for Marcos Ambrose at the Sydney 500.
Teams are required to employ a co-driver for each car during the three endurance races due to the increased race distance and the need for driver substitutions during the race. Teams were able to pair their full-time drivers in one car until a rule change in 2010 that required each full-time driver to remain in his own car and be joined by a co-driver not competing full-time in the series.
The Drivers Championship title is awarded to the driver who accumulates the most points over the course of the season. If there is a points tie for the series win, the champion will be decided based on the number of races won by each driver (if there is still a tie, it is based on second place finishes and so on). Teams also compete for the Teams Championship, with the champion team being decided in the same manner as the Drivers Championship. For Teams Championship points scoring purposes, teams with four cars are separated into a pair of two car teams.
Development series.
A second-tier series, the Dunlop V8 Supercar Series, is run as a support category to the main series at certain events. Initially for privateers who didn't have the funding of the professional teams in the late 1990s, the series now serves the dual purpose of developing young drivers before they compete in the main series and a means for main series teams to give their endurance co-drivers more racing experience prior to the endurance races. Teams in the Dunlop Series compete with cars previously used in the main series.
A third V8 Supercar-based series, the Kumho Tyres V8 Touring Car Series, has been run since 2008 but has no involvement with the International V8 Supercars Championship or the Dunlop V8 Supercar Series, instead running on the programme of the Shannons Nationals Motor Racing Championships.
Race formats.
The are three types of events held in V8 Supercars, each with its own race format: Super Sprint events, Super Street events and Endurance Cup events.
Super Sprint.
The Super Sprint format is used at the Tasmania 400, Winton 400, ITM 500 Auckland, Perth 400, Skycity Triple Crown, Ipswich 400, Sydney Motorsport Park 400 and Phillip Island 400.
Two one-hour practice sessions take place on the Friday at each Super Sprint event with the exception of the ITM 500 Auckland, which has only a single thirty-minute session.
The Super Sprint format features two fifteen-minute qualifying sessions held on Saturday to decide the grid for the two races the same day. A single twenty-minute session is held on Sunday morning to decide the grid for the Sunday race. The Pukekohe event features an extra twenty-minute session for the Friday race.
Super Sprint events feature two 100 km races on Saturday with a single 200 km race held on Sunday. The ITM Auckland 500 features an additional 100 km race held on Friday.
Super Street.
The Super Street format is used at the Clipsal 500 Adelaide, Townsville 500 and Sydney 500.
Four 30-minute practice sessions take place at each Super Street event – three on Friday and one on Saturday. Qualifying consists of two 15-minute sessions held on Friday to determine the grid for the Saturday races and a 20-minute session followed by a top ten shootout (a session where the fastest ten qualifiers complete one flying lap each to determine the top ten on the grid) held on Sunday.
Super Street events feature two 125 km races held on Saturday and a single 250 km race held on Sunday.
Endurance Cup.
There are three endurance events held during the year: the Sandown 500, the Bathurst 1000 and the Gold Coast 600. These events require two drivers per car and together they form the Endurance Cup, a prize awarded to the driver or drivers who score the most points across the three events.
The Sandown 500 and the Gold Coast 600 both feature four forty-minute practice sessions, held across Friday and Saturday. The Bathurst 1000 consists of three fifty-minute and two forty-five-minute sessions held during Thursday and Friday.
Qualifying for the Sandown 500 involves a twenty-minute session followed by a pair of 60 km "qualifying races" held on Saturday. The grid for the first race is based on the qualifying session; the grid for the second race is based on the results of the first. The results of the second race determine the grid for the main race on Sunday. Co-drivers must compete in the first of the qualifying races while the main driver must compete in the second. The Bathurst 1000 features a single forty-minute qualifying session on Friday afternoon followed by a top ten shootout on Saturday. The Gold Coast 600 has two thirty-minute qualifying sessions, one each on Saturday and Sunday, with the Saturday session followed by a top ten shootout. The Sandown 500 and Bathurst 1000 both have a twenty-minute warm-up session on Sunday morning.
The Sandown 500 and the Bathurst 1000 feature single races held on Sunday, at 500 km and 1000 km in length respectively. The Gold Coast 600 consists of two 300 km races with one held on Saturday and one on Sunday.
Points system.
Points are awarded as follows at all championship events. Various different points scales are applied to events having one, two, three or four races, ensuring that a driver will be awarded 300 points for winning all races at any event. Points are awarded to all cars that have covered 75% of the race distance, provided they are running at the completion of the final lap and with a final lap time within 200% of the race winner's fastest lap. At the endurance events, both drivers earn the total points awarded to the finishing position of the car.
Tyre allocation.
Tyres are allocated at each event as follows:
Notable events.
Bathurst 1000.
The Bathurst 1000, also known as the "Great Race" and held in some form since 1960, is the most famous race on the V8 Supercars calendar, as well as the longest both in terms of race distance and race time. The race is run over 161 laps of the Mount Panorama Circuit, 1000 km in total, with the race taking between six and seven hours to complete. The event has attracted crowds of nearly 200,000 people. The Peter Brock Trophy, named after nine-time Bathurst 1000 winner Peter Brock, is awarded to the winners of the race. The trophy was introduced in 2006 following Brock's death in a crash at the Targa West rally one month prior to the race.
Sandown 500.
The Sandown 500 was first held as a six-hour race in 1964 and has been labelled as the traditional "Bathurst warm-up" race. Like the Bathurst 1000, the Sandown 500 is run over 161 laps. Due to the shorter track length of Sandown Raceway the race is only 500 km and runs for between three and four hours. The Sandown 500 was not held for V8 Supercars from 1999 to 2002 and from 2008 to 2011. During these years, the 500 km endurance races took place at Queensland Raceway (1999–2002) and the Phillip Island Grand Prix Circuit (2008–2011).
Clipsal 500 Adelaide.
The Clipsal 500 has been held since 1999 and has become the traditional season-opening event. It is run on a shortened version of the former Adelaide Grand Prix Circuit. Consisting of two 250 km races run on Saturday and Sunday, the event has been labelled the most physically demanding by the drivers, due to the length of each race, the nature of the circuit and the effect of the heat. The event's format was changed for 2014, with the Saturday race being replaced with a pair of 125 km races. The event attracts crowds of over 250,000 people and is the only event to be inducted into the V8 Supercar Hall of Fame. The Clipsal 500 was the first carnival-style event which would become common in the ten years after its inception, with music concerts held during the night.
Gold Coast 600.
The Gold Coast 600 was introduced in 2009 after the American IndyCar Series elected not to return to the Surfers Paradise circuit that year. The A1 Grand Prix series was scheduled to fill the void left by IndyCar, however the owners of the series went into liquidation in June 2009 and, as a result, the A1 Grand Prix cars were withdrawn from the event. In order to compensate for this, V8 Supercars introduced a new four-race format, with two 150 km races held on each day. In 2010 the format changed to include two 300 km races and it became a two-driver event. To restore the event's previous international flavour, each team was required to have at least one co-driver with an 'international reputation' (that is, they were recognised for exploits in motorsport outside of Australia). In 2011 and 2012, all entries required an international co-driver. In 2013 the international co-driver rule was dropped, due to a number of incidents during the 2012 event and the formation of the Endurance Cup, but teams could still choose to employ an international driver for the endurance races.
Sydney 500.
In 2004, V8 Supercars introduced the name "Grand Finale" for the final round of the season (having called it "The Main Event" in 2003). The Grand Finale was held at Sydney Motorsport Park in 2003 and 2004, Phillip Island in 2005, 2006 and 2007 and Oran Park Raceway in 2008. The Grand Finale name was used until 2008 before the Sydney 500 became the final event of the series in 2009. The Sydney 500 is held around the streets of Sydney Olympic Park. Its format is similar to the Clipsal 500, with a 250 km race held on both Saturday and Sunday. Despite having a relatively simple layout, the circuit is one of the most challenging on the calendar.
Future.
When the Car of the Future plans were released in 2010, then-V8 Supercars Australia chairman Tony Cochrane detailed plans dubbed "Phase Two", which intended to look at the direction of the sport in the first five years after the Car of the Future regulations were introduced. In addition to enticing more manufacturers to join the series, Phase Two plans include adding to the sport's international appeal by including races in India and the Philippines.
In December 2014, V8 Supercars released details concerning the future of the category from 2017 onwards. New regulations, dubbed "Gen2 Supercar", will be introduced in 2017 and will allow the use of two-door coupé body styles and turbocharged four- or six-cylinder engines. Cars will still be required to be based on front-engined, rear wheel drive, four seater production cars that are sold in Australia. The chassis and control components will be carried over from the New Generation V8 Supercar regulations, while engine and aerodynamic parity will be reviewed. The category will also be rebranded, with a new logo to be used from 2015.
Media coverage.
Television.
After the new Group 3A regulations were adopted in 1993, the Seven Network continued to broadcast the series as it had done since 1985. Shortly after AVESCO was formed, a new television deal with Network Ten was announced, beginning in 1997. This deal lasted for ten years until a new deal with Seven was put together in 2007, which was renewed in 2013. In addition to the Seven's live coverage, a weekly 25-minute show titled "V8Xtra" was broadcast on non-racing weekends. The program covered news and feature items relating to the series. The coverage is produced by V8 Media, a specialist production company for V8 Supercars Australia. During the years of Seven Network's broadcast rights, Network Ten continued to broadcast the series once a year when they appeared on the support program for the Australian Grand Prix, which is broadcast by Ten. All support category races are tied up with the Grand Prix broadcast rights as a package. In December 2013 it was announced that Fox Sports and Network Ten had signed a $241 million deal to jointly televise the series for a six-year period, starting in 2015.
V8 Media records the series in 1080i high-definition, with many cars carrying four or more onboard-cameras. High-definition was used to broadcast the Bathurst 1000 and the Gold Coast 600 in 2011, the first time that V8 Supercars races were available in HD. However, HD coverage was not continued in 2012. From 2015 onwards, HD coverage became available to subscribers of Foxtel HD, coinciding with the new media rights deal with Fox Sports. For North American audiences, races were screened in 720p HD, as Speed's live motorsport coverage was usually screened in HD format.
Current TV broadcasters.
V8 Supercar races are broadcast on the following channels:
Other media.
The series has its own live streaming pay-per-view service, V8 Superview. The service, which started in 2013, currently shows all races as well as qualifying sessions. The service is not available in New Zealand due to their current broadcasting rights with Sky Sport and has limited coverage in Australia due to the new broadcasting rights with Fox Sports and Foxtel.
The series has its own website, which contains information about the series, drivers, teams and events and news articles, and a radio show, V8 Insiders. News is also featured on motorsport websites such as Speedcafe and Touring Car Times. A media deal with News Limited has been in place since 2009.
External links.
 Media related to at Wikimedia Commons

</doc>
