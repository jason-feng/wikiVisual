<doc id="57905" url="http://en.wikipedia.org/wiki?curid=57905" title="Sakha Republic">
Sakha Republic

The Sakha (Yakutia) Republic (Russian: Республика Саха (Якутия), "Respublika Sakha (Yakutiya)"; ]; Sakha: Саха Өрөспүүбүлүкэтэ, "Sakha Öröspǖbülükete") is a federal subject of Russia (a republic). It has a population of 958,528 (2010 Census), consisting mainly of ethnic Yakuts and Russians.
Comprising half of the Far Eastern Federal District, it is the largest subnational governing body by area in the world at 3083523 km2 and the eighth largest territory in the world, if the federal subjects of Russia were compared with other countries. It is larger than Argentina and just smaller than India which covers an area of 3287590 km2. Its capital is the city of Yakutsk. The Sakha Republic is one of the ten autonomous Turkic Republics within the Russian Federation.
Geography.
Sakha stretches to the Henrietta Island in the far north and is washed by the Laptev and Eastern Siberian Seas of the Arctic Ocean. These waters, the coldest and iciest of all seas in the Northern Hemisphere, are covered by ice for 9–10 months of the year. New Siberian Islands are a part of the republic's territory. After Nunavut was separated from Canada's Northwest Territories, Sakha became the largest subnational entity (statoid) in the world, with an area of 3083523 km2, slightly smaller than the territory of India (3.3 million km2).
Sakha can be divided into three great vegetation belts. About 40% of Sakha lies above the Arctic circle and all of it is covered by permafrost which greatly influences the region's ecology and limits forests in the southern region. Arctic and subarctic tundra define the middle region, where lichen and moss grow as great green carpets and are favorite pastures for reindeer. In the southern part of the tundra belt, scattered stands of dwarf Siberian pine and larch grow along the rivers. Below the tundra is the vast taiga forest region. Larch trees dominate in the north and stands of fir and pine begin to appear in the south. Taiga forests cover about 47% of Sakha and almost 90% of the cover is larch.
The Sakha Republic is the site of Pleistocene Park, a project directed at recreating pleistocene tundra grasslands by stimulating the growth of grass with the introduction of animals which thrived in the region during the late Pleistocene — early Holocene period.
Time zones.
Sakha spans three different time zones (no Daylight Saving Time in summer):
Rivers.
Navigable Lena River (4,310 km), as it moves northward, includes hundreds of small tributaries located in the Verkhoyansk Range. Other major rivers include:
Lakes.
There are over 800,000 lakes in the republic. Major lakes and reservoirs include:
Mountains.
Sakha's greatest mountain range, the Verkhoyansk Range, runs parallel and east of the Lena River, forming a great arc that begins the Sea of Okhotsk and ends in the Laptev Sea.
The Chersky Range runs east of the Verkhoyansk Range and has the highest peak in Sakha, Peak Pobeda (3,147 m). The second highest peak is Peak Mus-Khaya reaching 3,011 m.
The Stanovoi Range borders Sakha in the south.
Natural resources.
Sakha is well endowed with raw materials. The soil contains large reserves of oil, gas, coal, diamonds, gold, silver, tin, tungsten and many others. Sakha produces 99% of all Russian diamonds and over 25% of the diamonds mined in the world.
Climate.
Sakha is known for its climate extremes, with the Verkhoyansk Range being the coldest area in the Northern Hemisphere. Some of the lowest natural temperatures ever recorded have been here. The Northern Hemisphere's Pole of Cold is at Verkhoyansk, where the temperatures reached as low as −67.8 C in 1892, and at Oymyakon, where the temperatures reached as low as −71.2 C in 1926.
History.
Early history.
The Turkic Sakha people or "Yakuts" probably settled in the area in the 13th and 14th centuries, migrating north from the Lake Baikal area to the middle Lena. From their new center along the middle Lena they gradually expanded northeast and west beyond the Lena basin towards the Arctic Ocean.
The name "Sakha" is of Turkic origin, "saqa-saha" meaning "cue" or "bat". The term "yakut" is a Turkic word, a corruption of "zhaqut - yakut" "precious stone", referring to the ruby.
The Sakha displaced earlier, much smaller populations who lived on hunting and reindeer herding, introducing the pastoralist economy of Central Asia. The indigenous populations of Paleosiberian and Tungusic stock
were mostly assimilated to the Sakha by the 17th century.
Russian conquest.
The Tsardom of Russia began its conquest of the region in the 17th century, moving east after the defeat of the Khanate of Sibir. Tygyn, a king of the Khangalassky Yakuts, granted territory for Russian settlement in return for a military pact that included war against indigenous rebels of all North Eastern Asia (Magadan, Chukotka, Kamchatka and Sakhalin). Kull, a king of the Megino-Khangalassky Yakuts, began a Sakha conspiracy by allowing the first stockade construction.
In August 1638, the Moscow Government formed a new administrative unit with the administrative center of Lensky Ostrog (Fort Lensky), the future city of Yakutsk, which had been founded by Pyotr Beketov in 1632.
The arrival of the Russian settlers at the remote Russkoye Ustye in the Indigirka delta likely also dates to the 17th century. The Siberian Governorate was established as part of the Russian Tsardom in 1708.
Russian settlers began to form a community in the 18th century, which adopted certain Yakut customs and was often called "Yakutyane" (Якутя́не) or Lena Early Settlers (ленские старожилы). However, the influx of later settlers assimilated them into the Russian mainstream by the 20th century.
Russian Empire.
In an administrative reform of 1782, Irkutsk Governorate was created. In 1805, Yakutsk Oblast was split from Irkutsk Governorate.
Yakutsk Oblast in the early 19th century marked the easternmost territory of the Russian Empire, including such Far Eastern (Pacific) territories as were acquired, known as Okhotsk Okrug within Yakutsk Oblast. With the formation of Primorskaya Oblast in 1856, the Russian territories of the Pacific were detached from Yakutia.
The Russians established agriculture in the Lena River basin. The members of religious groups who were exiled to Sakha in the second half of the 19th century began to grow wheat, oats, and potatoes. The fur trade established a cash economy. Industry and transport began to develop at the end of the 19th century and in the beginning of the Soviet period. This was also the beginning of geological prospecting, mining, and local lead production. The first steam-powered ships and barges arrived.
Yakutia's remoteness, even compared to the rest of Siberia, made it a place of exile of choice for both Czarist and Communist governments of Russia. Among the famous Tsarist-era exiles were the democratic writer Nikolay Chernyshevsky, Doukhobor conscientious objectors (whose story was told to Leo Tolstoy by Vasily Pozdnyakov), the Socialist Revolutionary and writer Vladimir Zenzinov, who left an interesting account of his Arctic experiences, and Polish socialist activist Wacław Sieroszewski who pioneered in ethnographic research on Yakut people.
Soviet era.
On April 27, 1922, former Yakutsk Oblast was proclaimed the Yakut ASSR, although in fact the eastern part of the territory, including the city of Yakutsk, was controlled by the White Russians (see Yakut Revolt).
In 1992, after the fall of the Soviet Union, Yakutia was recognized in Moscow as the Sakha (Yakutia) Republic under the jurisdiction of the Russian Federation.
Yakutia is historically part of Russian Siberia, but since the formation of the Far Eastern Federal District in 2000, it is administratively part of the Russian Far East.
Demographics.
Population:  (2010 Census);  (2002 Census);  (1989 Census)
Ethnic groups.
According to the 2010 Census, the ethnic composition was:
Historical population figures are shown below:
Languages.
The official languages are both Russian and Sakha, also known as Yakut, which is spoken by approximately 40% of the population. The Yakut language is a member of the Turkic language family.
Religion.
Religion in Yakutia (2012)
   Russian Orthodox
 (37.8%)   Tengrist or Yakut shaman
 (13%)   Muslim
 (2%)   Unaffiliated Christian
 (1%)   Protestant
 (1%)   Buddhist
 (0.4%)   Atheist
 (26%)  Spiritual but not religious (17%)  Other or undeclared (1.8%)
Before the arrival of the Russian Empire, the majority of the local population believed in Tengrianism common to Turkic-language people of Central Asia, or in Paleoasian indigenous shamanism with both 'light' (community leading) and 'dark' (healing through spirit journey) shamans. Under the Russians, the local population was converted to the Russian Orthodox Church and required to take Orthodox Christian names, but in practice generally continued to follow traditional religions. During the Soviet era, most or all of the shamans died without successors.
In the 1990s, a neopagan shamanist movement called "aiyy yeurekhé" was founded by the controversial journalist Ivan Ukhkhan and a philologist calling himself Téris.<Ref></ref> This group and others cooperated to build a shaman temple in downtown Yakutsk in 2002.<Ref></ref>
Currently, while Orthodox Christianity maintains a following (however, with very few priests willing to be stationed outside of Yakutsk), there is interest and activity toward renewing the traditional religions. As of 2008, Orthodox leaders described the world view of the republic's indigenous population (or, rather, those among the population who are not completely indifferent to religion) as "dvoyeverie" (dual belief system), or a "tendency toward syncretism", as evidenced by the locals sometimes first inviting a shaman, and then an Orthodox priest to carry out their rites in connection with some event in their life.
According to the Information Center under the President of Sakha Republic (Информационный центр при Президенте РС(Я)), the religious demography of the republic was as follows: Orthodoxy: 44.9%, shamanism: 26.2%, non-religious: 23.0%, new religious movements: 2.4%, Islam: 1.2%, Buddhism: 1.0%, Protestantism: 0.9%, Catholicism: 0.4%.
According to a 2012 official survey 37.8% of the population of Yakutia adheres to the Russian Orthodox Church, 1% are unaffiliated generic Christians, 13% of the population adheres to Tengrism or Yakut shamanism, 2% to Islam, 1% to forms of Protestantism, and 0.4% to Tibetan Buddhism. In addition, 17% of the population deems itself to be "spiritual but not religious", 26% is atheist, and 1.8% follows other religions or did not give an answer to the question.
Politics.
The head of government in Sakha is the Head (previously President). The first Head of the Sakha Republic was Mikhail Yefimovich Nikolayev. As of 2010, the president is Yegor Borisov, who took office on May 31, 2010; his vice president is Evgeniya Mikhailova.
The supreme legislative body of state authority in Sakha is a unicameral State Assembly known as the "Il Tumen". The government of the Sakha (Yakutia) Republic is the executive body of state authority.
The republic fosters close cultural, political, economic, and industrial relations with the independent Turkic states through membership in organizations such as the Turkic Council and the Joint Administration of Turkic Arts and Culture.
Economy.
Industry generates slightly above 50% of the gross national product of Sakha, stemming primarily from mineral exploitation. Industrial enterprises are concentrated in the capital Yakutsk, as well as in Aldan, Mirny, Neryungri, Pokrovsk, and Udachny. The diamond, gold and tin ore mining industries are the major focus of the economy. Uranium ore is beginning to be mined. Turkic-language Sakha are in politics, government, finance, economy and cattle-breeding (horses and cows for milk and meat). The Paleoasian indigenous peoples are hunters, fishermen, and reindeer herders. As of 2008, Sakha Republic is the 19th most developed federal subject in Russia.
Transportation.
Water transport ranks first for cargo turnover. There are six river ports, two sea ports (Tiksi and Zelyony Mys). Four shipping companies, including the "Arctic Sea Shipping Company", operate in the republic. The republic's main waterway is the Lena River, which links Yakutsk with the rail station of Ust-Kut in Irkutsk Oblast.
Air transport is the most important for transporting people. Airlines connect the republic with most regions of Russia. Yakutsk Airport has an international terminal.
Two federal roads pass the republic. They are Yakutsk–Skovorodino (M56 Lena highway) and Yakutsk–Magadan (M56 Kolyma Highway).
However, due to the presence of permafrost, use of asphalt is not practical, and therefore the roads are made of clay. When heavy rains blow over the region, the roads often turn to mud, sometimes stranding hundreds of travellers in the process.
The Berkakit–Tommot railroad is currently in operation. It links the Baikal Amur Mainline with the industrial centers in South Yakutia. Construction of the Amur Yakutsk Mainline continues northward; the railway was completed to Nizhny Bestyakh, across the river from Yakutsk, in 2013. Though this one track railroad from Tommot to Nizhny Bestyakh is under temporary operation (30% of its full capacity), the main customer - the Federal agency for railways declared that this railroad will be in full operation in fall of 2015. Also the private company is now constructing the transport and logistic center in Nizhny Bestyakh.
Education.
The most important facilities of higher education include North-Eastern Federal University (previously Yakutsk State University) and Yakutsk State Agricultural Academy.
Culture.
The cultural life of Yakutsk is constantly developing. There are many places worth visiting.
These include: the State Russian drama theatre named after A. S. Pushkin; the Sakha Theater named after P. A. Oiyunsky; the State Academic Opera and Ballet Theatre named after D. K. Sivtsev; and Suorun Omoloon, Young Spectator's Theatre.
There are a number of interesting museums as well. These include the National Fine Arts Museum of Sakha, the Museum of Local Lore and History named after E. Yaroslavsky, and the Khomus Museum and Museum of Permafrost.

</doc>
<doc id="57906" url="http://en.wikipedia.org/wiki?curid=57906" title="Metz">
Metz

Metz (]; ]) is a city in the northeast of France located at the confluence of the Moselle and the Seille rivers. Metz is the capital and the prefecture of both the Lorraine region and the Moselle department. Located near the tripoint along the junction of France, Germany, and Luxembourg, the city forms a central place of the European Greater Region and the SaarLorLux euroregion.
Metz has a rich 3,000-year-history, having variously been a Celtic oppidum, an important Gallo-Roman city, the Merovingian capital of the Austrasia kingdom, the birthplace of the Carolingian dynasty, a cradle of the Gregorian chant, and one of the oldest republics in Europe. The city has been steeped in Romance culture, but has been strongly influenced by Germanic culture due to its location and history.
Because of its historical, cultural, and architectural background, Metz has been submitted on the France's UNESCO World Heritage Tentative List. The city features noteworthy buildings such as the Gothic Saint-Stephen Cathedral with its largest expanse of stained-glass windows in the world, the Basilica of Saint-Pierre-aux-Nonnains being the oldest church in France, its Imperial Station Palace displaying the apartment of the German Kaiser, or its Opera House, the oldest one working in France. Metz is home to some world-class venues including the Arsenal Concert Hall and the Centre Pompidou-Metz museum.
A basin of urban ecology, Metz gained its nickname of The Green City (French: "La Ville Verte"), as it has extensive open grounds and public gardens. The historic city centre is one of the largest commercial pedestrian areas in France.
A historic garrison town, Metz is the economic heart of the Lorraine region, specialising in information technology and automotive industries. Metz is home to the University of Lorraine and a centre for applied research and development in the materials sector, notably in metallurgy and metallography, the heritage of the Lorraine region's past in the iron and steel industry.
Etymology.
In ancient times, the town was known as "city of Mediomatrici", being inhabited by the tribe of the same name. After its integration into the Roman Empire, the city was called "Divodurum Mediomatricum," meaning Holy Village or Holy Fortress of the Mediomatrici, then it was known as "Mediomatrix". During the 5th century AD, the name evolved to "Mettis", which gave rise to Metz.
History.
Metz has a recorded history dating back over 3,000 years. Before the conquest of Gaul by Julius Caesar in 52 BC, it was the oppidum of the Celtic Mediomatrici tribe. Integrated into the Roman Empire, Metz became quickly one of the principal towns of Gaul with a population of 40,000, until the barbarian depredations and its transfer to the Franks about the end of the 5th century. Between the 6th and 8th centuries, the city was the residence of the Merovingian kings of Austrasia. After the Treaty of Verdun in 843, Metz became the capital of the kingdom of Lotharingia and was ultimately integrated into the Holy Roman Empire, being granted semi-independent status. During the 12th century, Metz rose to the status of Republic and the Republic of Metz ruled until the 15th century. With the signature of the Treaty of Chambord in 1552, Metz was passed to the hands of the Kings of France. Under French rule, Metz was selected as capital of the Three Bishoprics and became a strategic fortified town. With creation of the departments by the Estates-General of 1789, Metz was chosen as capital of the Department of Moselle. After the defeat of France during the Franco-Prussian War and according to the Treaty of Frankfurt of 1871, the city was annexed into the German Empire, being part of the Imperial Territory of Alsace-Lorraine and serving as capital of the German Department of Lorraine. Metz remained German until the end of World War I, when it reverted to France. However, after the Battle of France during the Second World War, the city was annexed once more by the German Third Reich. In 1944, the attack on the city by the U.S. Third Army freed the city from German rule and Metz reverted one more time to France after World War II.
During the 1950s, Metz was chosen to be the capital of the newly created Lorraine region. With the creation of the European Community and the later European Union, the city has become central to the Greater Region and the SaarLorLux Euroregion.
Geography.
Metz is located on the banks of the Moselle and the Seille rivers, 43 km from the Schengen tripoint where the borders of France, Germany, and Luxembourg meet. The city was built in a place where many branches of the Moselle river creates several islands, which are encompassed within the urban planning.
The terrain of Metz forms part of the Paris Basin and presents a plateau relief cut by river valleys presenting cuestas in the north-south direction. Metz and its surrounding countryside are included in the forest and crop Lorraine Regional Natural Park, covering a total area of 205,000 ha.
Climate.
The climate of Lorraine is a semi-continental climate. The summers are humid and hot, sometimes stormy, and the warmest month of the year is August, when temperatures average approximately 26 °C. The winters are cold and snowy with temperature dropping to an average of -0.5 °C in January. Lows can be much colder through the night and early morning and the snowy period extends from November to February.
The length of the day varies significantly over the course of the year. The shortest day is 21 December with 8:01 hours of sunlight; the longest day is 20 June with 15:58 hours of sunlight. The median cloud cover is 93% and does not vary substantially over the course of the year.
Demographics.
Population.
The inhabitants of Metz are called "Messin(e)s". Statistics on the ethnic and religious make up of the population of Metz are haphazard, as the French Republic prohibits making distinctions between citizens regarding race, beliefs, and political and philosophic opinions in the process of census taking.
The French national census of 2009 estimated the population of Metz to be 121,841, while the population of Metz urban agglomeration was about 389,851. Through history, Metz's population has been impacted by the vicissitudes of the wars and annexations involving the city, which have prevented continuous population growth. More recently, the city has suffered from the restructuring of the military and the metallurgy industry. The historical population for the current area of Metz municipality is as follows:
Notable people linked to the city.
Several well-known figures have been linked to the city of Metz throughout its history. Renowned "Messins" include poet Paul Verlaine, composer Ambroise Thomas, and mathematician Jean-Victor Poncelet; numerous well-known German figures were also born in Metz notably during the annexation periods. Moreover, the city has been the residence of people such as writer François Rabelais, Cardinal Mazarin, political thinker Alexis de Tocqueville, French patriot and American Revolutionary War hero the Marquis de La Fayette, and Luxembourg-born German-French statesman Robert Schuman.
Law and government.
Local law.
The Local Law (French: "droit local") applied in Metz is a legal system that operates in parallel with French law. Created in 1919, it preserves the French laws applied in France before 1870 and maintained by the Germans during the annexation of Alsace-Lorraine, but repealed in the rest of France after 1871. It also maintains German laws enacted by the German Empire between 1871 and 1918, specific provisions adopted by the local authorities, and French laws that have been enacted after 1919 to be applicable only in Alsace-Lorraine. This specific local legislation encompasses different areas including religion, social work and finance.
The most striking of the legal differences between France and Alsace-Lorraine is the absence in Alsace-Lorraine of strict secularism, even though a constitutional right of freedom of religion is guaranteed by the French government. Alsace-Lorraine is still governed by a pre-1905 law established by the Concordat of 1801, which provides for the public subsidy of the Roman Catholic, Lutheran, and Calvinist churches and the Jewish religion.
Administration.
Like every commune of the present French Republic, Metz is managed by a mayor (French: "maire") and a municipal council (French: "conseil municipal"), democratically elected by two-round proportional voting for six years. The mayor is assisted by 54 municipal councillors, and the municipal council is held on the last Thursday of every month. Since 2008, the mayor of Metz has been socialist Dominique Gros.
The city belongs to the Metz Metropole union of cities, which includes the 40 cities of the Metz urban agglomeration. Metz is the seat of government of Lorraine region and the prefecture of the Moselle, based in the former Saint-Clement Abbey and Intendant Palace, respectively.
City administrative divisions.
The city of Metz is divided into 14 administrative divisions:
Cityscape and environmental policy.
Metz contains a mishmash of architectural layers, bearing witness to centuries of history at the crossroads of different cultures, and features a number of architectural landmarks. The city possesses one of the largest Urban Conservation Areas in France, and more than 100 of the city's buildings are classified on the Monument Historique list. Because of its historical and cultural background, Metz is designated as French Town of Art and History, and has been submitted on to France's UNESCO World Heritage Tentative List.
The city is famous for its yellow limestone architecture, a result of the extensive use of Jaumont stone. The historic district has kept part of the Gallo-Roman city with Divodurum's Cardo Maximus, then called Via Scarponensis (today the Trinitaires, Taison, and Serpenoise streets), and the Decumanus Maximus (today En Fournirue and d'Estrées streets). At the Cardo and Decumanus intersection was situated the Roman forum, today the Saint-Jacques Square.
Civilian architecture.
From its Gallo-Roman past, the city preserves vestiges of the thermae (in the basement of the Golden Courtyard museum), parts of the aqueduct, and the Basilica of Saint-Pierre-aux-Nonnains.
Saint Louis' square with its vaulted arcades and a Knights Templar chapel remains a major symbol of the city's High Medieval heritage. The Gothic Saint-Stephen Cathedral, several churches and Hôtels, and two remarkable municipal granaries reflect the Late Middle Ages. Examples of Renaissance architecture can be seen in Hôtels from the 16th century, such as the House of Heads (French: "Maison des Têtes").
The city hall and the buildings surrounding the town square are by French architect Jacques-François Blondel, who was awarded the task of redesigning and modernizing the centre of Metz by the Royal Academy of Architecture in 1755 the context of the Enlightenment. Neoclassical buildings from the 18th century, such as the Opera House, the Intendant Palace (the present-day prefecture), and the Royal Governor's Palace (the present-day courthouse) built by Charles-Louis Clérisseau, are also found in the city.
The Imperial District was built during the first annexation of Metz by the German Empire. In order to "germanise" the city, Emperor Wilhelm II decided to create a new district shaped by a distinctive blend of Germanic architecture, including Renaissance, neo-Romanesque and neo-Classical, mixed with elements of Art Nouveau, Art Deco, Alsatian and mock-Bavarian styles. Instead of Jaumont stone, commonly used everywhere else in the city, stone used in the Rhineland, such as pink and grey sandstone, granite and basalt were used. The district features noteworthy buildings including the impressive station and the Central Post Office by German architect Jürgen Kröger.
Modern architecture can also be seen in the town with works of French architects Roger-Henri Expert (Sainte-Thérèse-de-l'Enfant-Jésus church, 1934), Georges-Henri Pingusson (Fire Station, 1960), and Jean Dubuisson (subdivisions, 1960s). The refurbishment of the former Ney Arsenal as a Concert Hall in 1989 and the erection of the Metz Arena in 2002, by Spanish and French architects Ricardo Bofill and French Paul Chemetov represent the Postmodern movement.
The Centre Pompidou-Metz museum in the Amphitheatre District represents a strong architectural initiative to mark the entrance of Metz into the 21st century. Designed by Japanese architect Shigeru Ban, the building is remarkable for the complex, innovative carpentry of its roof, and integrates concepts of sustainable architecture. The project encompasses the architecture of two recipients of the Pritzker Architecture Prize, Shigeru Ban (2014) and French Christian de Portzamparc (1994). The Amphitheatre District is also conceived by French architects Nicolas Michelin, Jean-Paul Viguier, and Jean-Michel Wilmotte and designer Philippe Starck. The urban project is expected to be completed by 2023. Further, a contemporary music venue designed by contextualist French architect Rudy Ricciotti stands in the Borny District.
Urban ecology.
Under the leadership of such people as botanist Jean-Marie Pelt, Metz pioneered a policy of urban ecology during the early 1970s. Because of the failure of post-war urban planning and housing estate development in Europe during the 1960s, mostly based on the concepts of CIAM, Jean-Marie Pelt, then municipal councillor of Metz, initiated a new approach to the urban environment.
Based initially on the ideas of the Chicago School, Pelt's theories pleaded for better integration of humans into their environment and developed a concept centered on the relationship between "stone and water". His policy was realized in Metz by the establishment of extensive open areas surrounding the Moselle and the Seille rivers and the development of large pedestrian areas. As a result Metz has over 37 m2 of open areas per inhabitant in the form of numerous public gardens in the city.
The principles of urban ecology are still applied in Metz with the implementation of a local Agenda 21 action plan. The municipal ecological policy encompasses the sustainable refurbishment of ancient buildings, the erection of sustainable districts and buildings, green public transport, and the creation of public gardens by means of landscape architecture.
Additionally, the city has developed its own combined heat and power station, using waste wood biomass from the surrounding forests as a renewable energy source. With a thermal efficiency above 80%, the 45MW boiler of the plant provides electricity and heat for 44,000 dwellings. The Metz power station is the first local producer and distributor of energy in France.
Military architecture.
As a historic Garrison town, Metz has been heavily influenced by military architecture throughout its history. From ancient history to the present, the city has been successively fortified and modified to accommodate the troops stationed there. Defensive walls from classical antiquity to the 20th century are still visible today, incorporated into the design of public gardens along the Moselle and Seille rivers. A medieval bridge castle from the 13th century, named Germans' Gate (French: "Porte des Allemands"), today converted into a convention and exhibition centre, has become one of the landmarks of the city. Remains of the citadel from the 16th century and fortifications built by Louis de Cormontaigne are still visible today. Important barracks, mostly from the 18th and 19th centuries, are spread around the city: some, which are of architectural interest, have been converted to civilian use, such as the Arsenal Concert Hall by Spanish architect Ricardo Bofill.
The extensive fortifications of Metz, which ring the city, include early examples of Séré de Rivières system forts. Other forts were incorporated into the Maginot Line. A hiking trail on the Saint-Quentin plateau passes through a former military training zone and ends at the now abandoned military forts, providing a vantage point from which to survey the city.
Economy.
Although the steel industry has historically dominated Moselle's economy, Metz's efforts at economic diversification have created a base in the sectors of commerce, tourism, information technology and the automotive industry. The city is the economic heart of the Lorraine region and around 73,000 people work daily within the urban agglomeration. The transport facilities found in the conurbation, including the international high-speed railway, motorway, inland connections and the local bus rapid transit system, have made the city a transport hub in the heart of the European Union. Metz is home to the biggest harbour handling cereals in France with over 4,000,000 tons/year.
Metz is home to the Moselle Chamber of Commerce. International companies such as PSA Peugeot Citroën, ArcelorMittal, SFR, and TDF have established plants and centres in the Metz conurbation. Metz is also the regional headquarters of the Caisse d'Epargne and Banque Populaire banking groups.
Metz is an important commercial centre of northern France with France's biggest retailer federation, consisting of around 2,000 retailers. Important store companies are found in the city, such as the Galeries Lafayette, the Printemps department store and the Fnac entertainment retail chain. The historic city centre displays one of the largest commercial pedestrian areas in France and a mall, the Saint-Jacques centre. In addition there are several multiplex movie theatres and malls found in the urban agglomeration.
In recent years, Metz municipality have promoted an ambitious policy of tourism development, including urban revitalization and refurbishment of buildings and public squares. This policy has been spurred by the creation of the Centre Pompidou-Metz in 2010. Since its inauguration, the institution has become the most popular cultural venue in France outside Paris, with 550,000 visitors per year. Meanwhile Saint-Stephen Cathedral is the most visited building in the city, accommodating 652,000 visitors per year.
Culture and contemporary life.
Museums and exhibition halls.
In addition, Metz features other museums and exhibition venues, such as:
Entertainment and performing arts.
Metz has several venues for the performing arts. The Opera House of Metz, the oldest working opera house in France, features plays, dance, and lyric poetry. The Arsenal Concert Hall, dedicated to art music, is widely renowned for its excellent acoustics and considered as one of the most beautiful concert halls in Europe. The Trinitarians Club is a multi-media arts complex housed in the vaulted cellar and chapel of an ancient convent, the city's prime venue for jazz music. The Music Box (French: "Boite à Musique"), familiarly known as BAM, is the concert venue dedicated to rock and electronic music. The Braun Hall and the Koltès Theater feature plays, and the city has two movie theaters specializing in Auteur cinema. The Saint-Jacques Square, surrounded by busy bars and pubs whose open-air tables fill the centre of the square, contributes to the quality of life in Metz, as do numerous other associations, private music bars and theaters.
Since 2014, the former bus garage has been converted to accommodate over thirty artists in residence, in a space where they can create and rehearse artworks and even build set decorations. The artistic complex, called Metz Network of All Cultures (French: "Toutes les Cultures en Réseau à Metz") and familiarly known as TCRM-Blida, encompasses a large hall of 3,000 m2 while theater and dance companies benefit from a studio of 800 m2 with backstages.
Metz in the arts.
Metz was an important cultural centre during the Carolingian Renaissance. For example, Gregorian chant was created in Metz during the 8th century as a fusion of Gallican and ancient Roman repertory. Then called Messin Chant, it remains the oldest form of music still in use in Western Europe. The bishops of Metz, notably Saint-Chrodegang promoted its use for the Roman liturgy in Gallic lands under the favorable influence of the Carolingian monarchs. Messin chant made two major contributions to the body of chant: it fitted the chant into the ancient Greek octoechos system, and invented an innovative musical notation, using neumes to show the shape of a remembered melody. Metz was also an important centre of illumination of Carolingian manuscripts, producing such monuments of Carolingian book illumination as the Drogo Sacramentary.
The Metz School (French: "École de Metz") was an art movement in Metz and the region between 1834 and 1870, centred on Charles-Laurent Maréchal. The term was originally proposed in 1845 by the poet Charles Baudelaire, who appreciated the works of the artists. They were influenced by Eugène Delacroix and inspired by the medieval heritage of Metz and its romantic surroundings. The Franco-Prussian War and the annexation of the territory by the Germans resulted in the dismantling of the movement. The main figures of the Metz School were Charles-Laurent Maréchal, Auguste Migette, Auguste Hussenot, Louis-Théodore Devilly, Christopher Fratin, and Charles Pêtre. Their works include paintings, engravings, drawings, stained-glass windows, and sculptures.
The Graoully dragon as symbol of the city.
The Graoully is depicted as a fearsome dragon, vanquished by the sacred powers of Saint Clement of Metz, the first Bishop of the city. The Graoully quickly became a symbol of Metz and can be seen in numerous insignia of the city, from the 10th century on. Writers from Metz tend to present the legend as an allegory of Christianity's victory over paganism, represented by the harmful dragon.
Cuisine.
Local specialties include the quiche, the potée, the Lorrain pâté, and also the suckling pig. Different recipes, such as jam, tart, charcuterie and fruit brandy, are made from the Mirabelle and Damson plums. Also, Metz is the cradle of some pastries like the Metz cheese pie and the Metz Balls (French: "boulet de Metz"), a ganache-stuffed biscuit coated with marzipan, caramel, and dark chocolate. Local beverages include Moselle wine and Amos beer.
The Covered Market of Metz is one of the oldest, most grandiose in France and is home to traditional local food producers and retailers. Originally built as the bishop's palace, the French Revolution broke out before the Bishop of Metz could move in and the citizens decided to turn it into a food market. The adjacent Chamber's Square (French: "Place de la Chambre") is surrounded by numerous local food restaurants.
Celebrations and events.
Many events are celebrated in Metz throughout the year. The city of Metz dedicates two weeks to the Mirabelle plum during the popular Mirabelle Festival held in August. During the festival, in addition to open markets selling fresh plums, mirabelle tarts, and mirabelle liquor, there are live music, fireworks, parties, art exhibits, a parade with floral floats, a competition, the crowning of the Mirabelle Queen and a gala of celebration.
A literature festival is held in June. The Montgolfiades hot air balloon festival is organized in September. The second most popular Christmas Market in France is held in November and December. Finally, a Saint Nicholas parade honors the patron saint of the Lorraine region in December.
Sports.
Metz is home to the Football Club of Metz (FC Metz), a football association club in Ligue 1, the highest division of French football. FC Metz has won three times the Ligue 2 (1935, 2007, and 2014), twice the Coupe de France (in 1984 and 1988) and the French League Cup (in 1986 and 1996), and was French championship runner-up in 1998. FC Metz has also gained recognition in France and Europe for its successful youth academy, winning the Gambardella Cup 3 times in 1981, 2001, and 2010. The Saint-Symphorien stadium has been the home of FC Metz since the creation of the club.
Metz Handball is a Team Handball club. Metz Handball has won the French Women's First League championship 19 times, the French Women's League Cup eight times and the Women's France Cup seven times. The Metz Arena has been the home of Metz Handball since 2002.
Since 2003, Metz has been home to the Moselle Open, an ATP World Tour 250 tournament played on indoor hard courts, which usually takes place in September.
Education.
High schools.
Metz has numerous high schools, including the Fabert High School and the Lycée of Communication. Some of these institutions offer higher education programs such as classes préparatoires (undergraduate school) or BTS (technician certificate).
University of Lorraine.
Metz is also home to the University of Lorraine (often abbreviated in UdL). 
The university is divided into two university centers, one in Metz (material sciences, technology, and management) and one in Nancy (biological sciences, health care, administration, and management). The University of Lorraine has a student body of over 55,000 and offers 101 accredited research centers organized in 9 research areas and 8 doctoral colleges. The Metz campus, built on three different sites within the city, enjoys a privileged position at a hub open to Germany and the Benelux countries, and has gained recognition for the development of joint Franco-German curricula. 
The University of Lorraine was ranked 11th among French universities in 2014 and is among the top 300 universities in the world, according to the Academic Ranking of World Universities.
Graduate schools.
At the end of the 1990s, the city expanded and the Metz Science Park was created in the southern area. Along with this expansion, several graduate schools took the opportunity to establish campuses in the park. At first, facilities were grouped around the lake Symphony, like Supélec in 1985 and Georgia Tech Lorraine in 1990. In 1996, the engineering school Arts et Métiers ParisTech (ENSAM) built a research and learning center next to the golf course. This opened the way to the development of a new area, where the Franco-German university (ISFATES) and the ENIM moved in 2010. These graduate schools often cooperate with the University of Lorraine. For instance, the university and ENSAM share research teams, laboratories, equipments, and doctoral programs.
Transport.
Local transport.
Public transport includes a bus rapid transit system, called Mettis. Mettis vehicles are high-capacity hybrid bi-articulated buses built by Van Hool, and stop at designated elevated tubes, complete with disability access. Mettis has its own planned and integrated transportation system, which includes two dedicated lines that spread out into the Metz conurbation. Mettis lanes A and B serve the city's major facilities (e.g. city centre, university campus, and hospitals), and a transport hub is located next to the railway station.
Railways.
Metz Railway Station is connected to the French high speed train (TGV) network, which provides a direct rail service to Paris and Luxembourg. The time from Paris (Gare de l'Est) to Metz is 82 minutes. Additionally, Metz is served by the Lorraine TGV railway station, located at Louvigny, 25 kmto the south of Metz, for high speed trains going to Nantes, Rennes, Lille and Bordeaux (without stopping in Paris). Also, Metz is one of the main stations of the regional express trains system, Métrolor.
Motorways.
Metz is located at the intersection of two major road axes: the Eastern Motorway, itself a part of the European route E50 connecting Paris to Prague, and the A31 Motorway, which goes north to Luxembourg and south to the Mediterranean Sea towards Nancy, Dijon, and Lyon.
Airports.
The Luxembourg International Airport is the nearest international airport, connected to Metz by Métrolor train. The Lorraine TGV Station is 75 minutes by train from France international Paris-Charles de Gaulle Airport. Finally, Metz-Nancy-Lorraine Airport is located in Goin, 16.5 km southeast of Metz..
Waterways.
Metz is located at the confluence of the Moselle and the Seille rivers, both navigable waterways. The marina connects Metz to the cities of the Moselle valley (i.e. Trier, Schengen, and Koblenz) via the Moselle river.
International relations.
Metz is a member of the QuattroPole union of cities, along with Luxembourg, Saarbrücken, and Trier (neighbouring countries: Luxembourg, France, and Germany). Metz has a central place in the Greater Region and of the economic SaarLorLux Euroregion. Metz is also twin town with:
 Saint-Denis, Réunion, France, from 1986
 Hradec Králové, Czech Republic, from 2001
References.
 incorporates text from a publication now in the public domain: 

</doc>
<doc id="57909" url="http://en.wikipedia.org/wiki?curid=57909" title="Battle of Evesham">
Battle of Evesham

The Battle of Evesham was one of the two main battles of 13th century England's Second Barons' War. It marked the defeat of Simon de Montfort, Earl of Leicester, and the rebellious barons by Prince Edward – later King Edward I – who led the forces of his father, King Henry III. It took place on 4 August 1265, near the town of Evesham, Worcestershire.
With the Battle of Lewes Montfort had won control of royal government, but after the defection of several close allies and the escape from captivity of Prince Edward, he found himself on the defensive. Forced to engage the royalists at Evesham, he faced an army twice the size of his own. The battle soon turned into a massacre; Montfort himself was killed and his body mutilated. Though the battle effectively restored royal authority, scattered resistance remained until the Dictum of Kenilworth was signed in 1267.
Background.
Simon de Montfort, 6th Earl of Leicester, had gained a dominant position in the government of the Kingdom of England after his victory at the Battle of Lewes a year earlier. He also held the King, Prince Edward, and the King's brother Richard of Cornwall in his custody. However, his sphere of influence rapidly began to deteriorate due to loss of key allies. In February, Robert de Ferrers, Earl of Derby was arrested and imprisoned in the Tower. An even more important collaborator, Gilbert de Clare, the Earl of Gloucester, deserted to the side of the King in May of the same year. With Gloucester's assistance, Prince Edward escaped from Montfort's captivity.
With the Lords of the Welsh Marches now in rebellion, Montfort solicited the aid of Llywelyn ap Gruffudd, the Prince of Wales. Llywelyn agreed to help, in return for full recognition of his title, and the promise that he could keep all military gains. Whatever benefits this alliance might have brought Montfort, the great concessions cost him popularity at home. Meanwhile Edward laid siege to the town of Gloucester, which fell on 29 June. Montfort's goal now became to unite with the forces of his son Simon, and engage with the royal army, but the younger Simon moved much too slowly westwards from London. Eventually Simon made it to the baronial stronghold of Kenilworth, but Edward managed to inflict great losses on the enemy, many of whom were quartered outside the castle walls. From there the Prince moved south, where, on 4 August, he managed to trap the older Montfort in a loop of the Avon, blocking off the only bridge and thereby forcing Montfort to fight without his son's reinforcements. When Montfort realized this, he allegedly commented: "May the Lord have mercy upon our souls, as our bodies are theirs."
Battle.
Along a ridge called Green Hill, just north of Evesham, Edward set up his forces on the left, with Gloucester commanding the right. At about eight in the morning, Montfort left the town of Evesham as a great thunderstorm began to rage. At the Battle of Lewes, the baronial forces had gained confidence to win the day by a sense of divine destiny, reinforced by white crosses on their uniforms. This time the royal army had taken their lead, and wore a red cross as their distinguishing mark. According to the chronicler William Rishanger, when Montfort saw the advance of the royal troops, he exclaimed that "They have not learned that for themselves, but were taught it by me."
The respective forces of the royal and baronial armies have been estimated to be 10,000 and 5,000 strong. Montfort, facing such unfavourable numbers, decided to concentrate his forces on the centre of the enemy’s front, hoping to drive a wedge through the line. Though the tactics were initially successful, the baronial forces soon lost the initiative, especially as the Welsh infantry provided by Llywelyn ap Gruffudd had proved unreliable, and deserted at an early point. The flanks of the royal army closed in on Montfort's, surrounding them. With Montfort confronted by a force twice the size of his own, on unfavourable ground, the battle rapidly turned into a massacre.
With the Battle of Lewes still fresh in memory, the royalists fought with a strong sense of bitterness and resentment. As a result, and despite attempts to surrender, most of the baronial rebels were killed on the battlefield rather than taken prisoner and ransomed, as was the common custom and practice. In what has been referred to as "an episode of noble bloodletting unprecedented since the Conquest", Montfort's son Henry was killed first, then Simon himself lost his horse and died fighting. His body was mutilated; his head, hands, feet and testicles cut off. King Henry himself, who had been in the custody of Montfort and dressed up in his colours, was barely rescued from the mêlée by Roger de Leybourne, a converted rebel.
Aftermath.
The royals were eager to settle scores after Montfort’s defeat. At the Parliament at Winchester in September the same year, all those who had taken part in the rebellion were disinherited. Yet even though the uprising of the younger Simon Montfort in Lincolnshire was over by Christmas, scattered resistance remained. The main problem was the garrison encamped at the virtually impregnable Kenilworth Castle, and a siege started in the summer of 1266 seemed futile. By the end of October, the royals drew up the so-called Dictum of Kenilworth, whereby rebels were allowed to buy back their land at prices dependent on their level of involvement in the rebellion. The defenders of the castle turned down the offer at first, but by the end of the year conditions had become intolerable, and in 1267 the Dictum was agreed upon.
As far as wide-scale confrontations went, the Battle of Evesham and its aftermath marked the end of baronial opposition in the reign of Henry III. The kingdom now entered into a period of unity and progress that lasted until the early 1290s.

</doc>
<doc id="57912" url="http://en.wikipedia.org/wiki?curid=57912" title="Brest, France">
Brest, France

 
Brest (]; ]) is a city in the Finistère département in Brittany in northwestern France. Located in a sheltered position not far from the western tip of the Breton peninsula, and the western extremity of metropolitan France, Brest is an important harbour and the second French military port after Toulon. The city is located on the western edge of continental Europe. With 142,722 inhabitants in a 2007 census, Brest is at the centre of Western Brittany's largest metropolitan area (with a population of 300,300 in total), ranking third behind only Nantes and Rennes in the whole of historic Brittany, and the 22nd most populous city in France; moreover, Brest provides services to the one million inhabitants of Western Brittany. Although Brest is by far the largest city in Finistère, the "préfecture" (regional capital) of the department is the much smaller Quimper.
During the Middle Ages, the history of Brest was the history of its castle. Then Richelieu made it a military harbour. Brest grew around its arsenal, until the second part of the 20th century. Heavily damaged by the Allies' bombing raids during World War II, the city centre was completely rebuilt after the war. At the end of the 20th century and the beginning of the 21st century, the deindustrialization of the city was followed by the development of the service sector. Nowadays, Brest is an important university town with 23,000 students. Besides a multidisciplinary university, the University of Western Brittany, Brest and its surrounding area possess several prestigious French elite schools such as "École Navale" (the French Naval Academy), "Télécom Bretagne" and the Superior National School of Advanced Techniques of Brittany (ENSTA Bretagne, formerly ENSIETA). Brest is also an important research centre, mainly focused on the sea, with among others the largest Ifremer (French Research Institute for Exploitation of the Sea) centre, "le Cedre" (Centre of Documentation, Research and Experimentation on Accidental Water Pollution) and the French Polar Institute.
Brest’s history has always been linked to the sea: the "Académie de Marine" (Naval Academy) was founded in 1752 in this city as well as the aircraft carrier Charles-de-Gaulle was built there. Every four years, Brest hosts the international festival of the sea, boats and sailors: it is a meeting of old riggings from around the world.
History.
Nothing definite is known of Brest before about 1240 , when a count of Léon ceded it to John I, Duke of Brittany. In 1342, John IV, Duke of Brittany, surrendered Brest to the English, in whose possession it was to remain until 1397. The importance of Brest in medieval times was great enough to give rise to the saying, "He is not the Duke of Brittany who is not the Lord of Brest". With the marriage of Francis I of France to Claude, the daughter of Anne of Brittany, the definitive overlordship of Brest – together with the rest of the duchy – passed to the French crown.
The advantages of Brest's situation as a seaport town were first recognized by Cardinal Richelieu, who in 1631 constructed a harbor with wooden wharves. This soon became a base for the French Navy. Jean-Baptiste Colbert, finance minister under Louis XIV, rebuilt the wharves in masonry and otherwise improved the harbour. Fortifications by Vauban (1633–1707) followed in 1680–1688. These fortifications, and with them the naval importance of the town, were to continue to develop throughout the 18th century.
In 1694, an English squadron under Lord Berkeley, was soundly defeated in its attack on Brest.
In 1917, during the First World War, Brest was used as the disembarking port for many of the troops coming from the United States. Thousands of such men came through the port on their way to the front lines. The United States Navy established a naval air station on 13 February 1918 to operate seaplanes. The base closed shortly after the First Armistice at Compiègne.
In the Second World War, the Germans maintained a large U-boat submarine base at Brest. In 1944, after the Allied invasion of Normandy, the city was almost totally destroyed during the Battle for Brest, with only a tiny number of buildings left standing. After the war, the West German government paid several billion "Deutschmarks" in reparations to the homeless and destitute civilians of Brest in compensation for the destruction of their city. Large parts of today's rebuilt city consist of utilitarian granite and concrete buildings. The French naval base now houses the Brest Naval Training Centre. A wartime German navy memorandum suggested that the town should perhaps serve as a German enclave after the war.
In 1972, the French Navy opened its nuclear weapon-submarine (deterrence) base at Île Longue in the "Rade de Brest" (Brest roadstead). This continues to be an important base for the French nuclear-armed ballistic missile submarines.
Coat of arms.
The meaning of the coat of arms of Brest is half France (the three fleurs-de-lis of the former kingdom of France), half Brittany ("semé d'hermine" of Brittany). These arms were used for the first time in a register of deliberations of the city council dated the 15 July 1683.
Sights.
Brest is best known for its "Pont de Recouvrance" (Recouvrance Bridge, a massive drawbridge 64 m/210 ft high), the military arsenal and the "rue de Siam" (Siam Street). The castle and the Tanguy tower are the oldest monuments of Brest.
The "Musée de la Tour Tanguy", in the Tanguy tower, houses a collection of dioramas that depict the city of Brest on the eve of World War II. The "Musée national de la Marine de Brest", housed in the ancient castle, contains exhibits which outline Brest's maritime tradition, as well as an aquarium, the Océanopolis marine centre. The city also has a notable botanical garden specializing in endangered species, the "Conservatoire botanique national de Brest", as well as the "Jardin botanique de l'Hôpital d'Instruction des Armées Clermont-Tonnerre".
The city of Brest does not have much remaining historical architecture, apart from a few select monuments such as the castle and the Tanguy tower. This is due to heavy bombing by the Allies during World War II, in an attempt to destroy the submarine base the Germans had built in the harbour. In the 1950s, the town was hastily rebuilt using a large amount of concrete. In Recouvrance, the west bank of the town, there remains an authentic street of the 17th century, Saint-Malo Street.
A few kilometres out of town, there are more impressive landscapes, from sandy beaches to grottos to tall granite cliffs. Sunbathing, windsurfing, yachting and fishing are enjoyed in the area. Brest was an important warship-producing port during the Napoleonic wars. The naval port, which is in great part excavated in the rock, extends along both banks of the Penfeld river.
Geography.
Brest is located amidst a dramatic landscape near the entrance of the natural "rade de Brest" (Brest roadstead), at the west end of Brittany.
It is situated to the north of a magnificent landlocked bay, and occupies the slopes of two hills divided by the river Penfeld. The part of the town on the left bank is regarded as Brest proper, while the part on the right is known as Recouvrance. There are also extensive suburbs to the east of the town. The hillsides are in some places so steep that the ascent from the lower to the upper town has to be effected by flights of steps and the second or third storey of one house is often on a level with the ground storey of the next.
Transport.
The railway station of Brest, Gare de Brest, is linked to Rennes and Paris as well as services to Brittany. TGV trains to Paris take approximately four and a half hours to reach the capital.
A new 28 stop, 14.3 km tram line connecting Porte de Plouzané in the west with Porte de Gouesnou and Porte de Guipavas northeast of the city centre opened in June 2012.
Brest international airport, Brest Bretagne Airport, is mainly linked to Paris, London, Nice, Lyon, Dublin. The primarily operator is Air France (via its subsidiary HOP!). Brest international airport is the main airport of the region of Brittany in terms passager traffic with 45% of this traffic of the region, representing 919,404 passengers in 2010. A new terminal has been in service since 12 December 2007 and can accommodate up to 1.8 million passengers annually.
The harbour of Brest is mainly dedicated to bulk, hydrocarbon and freight containers. The harbour's facilities can accommodate the largest modern ships.
Economy.
Due to its location, Brest is regarded as the first French port that can be accessed from the Americas. Shipping is big business, although Nantes and Saint-Nazaire offer much larger docks and attract more of the larger vessels. Brest has the 9th French commercial harbour including ship repairs and maintenance. The protected location of Brest means that its harbor is ideal to receive any type of ship, from the smallest dinghy to the biggest aircraft carrier (the USS "Nimitz" has visited a few times). Naval construction is also an important activity: for example, the French aircraft carrier Charles de Gaulle (R91) was built by Direction des Constructions Navales (DCN) in Brest.
Despite its image of an industrialised city whose activity depends mainly on military order, the service sector represents 75% of the economic activity. The importance of service sector is still increasing while the industrialised activity decaying, explaining the unchanged rate of working-class in Brest. Brest also hosts headquarters for many subsidiaries like the banking group Arkéa... Research and conception is taking an increasing importance. Brest claims to be the largest European centre for sciences and techniques linked to the sea: 60% of the French research in the maritime field is based in Brest.
Breton language.
Breton is not commonly spoken in the city of Brest, which was the only French-speaking city in western Brittany before the 1789 French Revolution, despite the surrounding countryside being fully Breton-speaking at that time. Like other French minority languages, Breton does not have any official language status in France.
The municipality launched a linguistic plan to revive Breton as a language through "Ya d'ar brezhoneg" on 16 June 2006. In 2008, 1.94% of primary-school children attended French-Breton bilingual Diwan schools. Besides bilingual schools, the Breton language is also taught in some schools and universities.
The association "Sked" federates all Breton cultural activities.
Culture.
The city is host to several events to celebrate its long maritime history. The largest is held every four years, when the town organises a tall ship meeting. The last such tall ship event is .
Brest also hosts an annual Short Film Festival called "Festival Européen du Film Court de Brest".
The city was the setting for the 1982 art film "Querelle", directed by Rainer Werner Fassbinder.
Food.
Brittany's most famous local delicacy, the Breton crêpe, is the main culinary feature apart from seafood. There are many crêpe restaurants (called "crêperies"). Breton apple cider is often featured.
Traditional biscuits include "Traou Mad", which is a full-fat butter biscuit, similar to Scottish shortbread.
Sport.
Since 1901 Brest has served as the midpoint for the 1200 km bicycle endurance event, Paris–Brest–Paris. Brest is home to Stade Brestois 29, a football team in Ligue 2.
The 2008 Tour de France started in Brest.
Brest is also home to Les Albatros, an ice hockey team in Ligue Magnus, and 2 league titles in the 90's.
Research and education.
Primarily research centre of western Brittany, Brest and its surrounding area is the home of several research and elite educational establishments:
Personalities.
Brest was the birthplace of:
International relations.
Twin towns – Sister cities.
Brest is twinned with:
Friendly relationship.
Brest has an official friendly relationship ("protocole d'amitié") with:

</doc>
<doc id="57915" url="http://en.wikipedia.org/wiki?curid=57915" title="Verkhoyansk">
Verkhoyansk

Verkhoyansk (Russian: Верхоянск; ]; Sakha: Верхоянскай) is a town in Verkhoyansky District of the Sakha Republic, Russia, located on the Yana River near the Arctic Circle, 675 km north of Yakutsk. Population:  (2010 Census);  (2002 Census);  (1989 Census)
History.
Cossacks founded an ostrog in 1638, 90 km southwest of the modern town. The ostrog's name "Verkhoyansky", roughly translating from Russian as "Town on the Upper Yana", derived from its geographical location on the upper reaches of the Yana River.
In 1775, it was moved to the left bank of the Yana River to facilitate tax collection. It was granted town status in 1817. Between the 1860s and 1917, the town was a place of political exile, with some of the more prominent exiles including the Polish writer Wacław Sieroszewski, as well as Bolshevik revolutionaries Ivan Babushkin and Viktor Nogin.
In January 2012, the town was attacked by a pack of about 400 wolves. According to biologists, the attack was due to a mass migration caused by a shortage in the wolves' natural food sources, in particular blue hares. About 3,500 wolves are believed to live in the Sakha Republic, an area larger than Argentina; however, according to the local government, the area can realistically only support 500 wolves. Locals were forced to patrol on snowmobiles until government forces could reach the area. According to the Agriculture Ministry, wolves killed 313 horses and over 16,000 reindeer in 2012.
Administrative and municipal status.
As an inhabited locality, Verkhoyansk is classified as a town under district jurisdiction. Within the framework of administrative divisions, it is incorporated within Verkhoyansky District as the Town of Verkhoyansk. As a municipal division, the Town of Verkhoyansk is incorporated within Verkhoyansky Municipal District as Verkhoyansk Urban Settlement.
Economy.
There is a river port, an airport, a fur-collecting depot, and the center of a reindeer-raising area.
Climate.
Verkhoyansk is notable chiefly for its exceptionally low winter temperatures and some of the greatest temperature differences on Earth between summer and winter. Average monthly temperatures range from -45.4 C in January to +16.5 C in July. Mean monthly temperatures are below freezing from October through April and exceed +10 C from June through August, with the intervening months of May and September constituting very short transitional seasons. Verkhoyansk has an extreme subarctic climate (Köppen "Dfd") dominated much of the year by high pressure. This has the effect of cutting off the region from warming influences in winter, and together with a lack of cloud cover leads to extensive heat losses during the cooler months.
Verkhoyansk is one of the places considered the northern Pole of Cold, the other being Oymyakon. The lowest temperature recorded there, in February 1892, was -69.8 C, recorded three days in a row on February 5, 6, and 7, along with -68.8 C on February 8, 1892, although there is some question as to exactly what these original measurements were. On January 1 and 15, 1885 and February 9, 1892, a temperature of -67.8 C was recorded: if the February 1892 readings are disregarded, these would be, together with the same reading at Oymyakon, the lowest temperature ever recorded in the Northern Hemisphere. Only Antarctica has recorded lower temperatures: the world record temperature of −89.2 °C or −128.6 °F was recorded at the Vostok Station in Antarctica on July 21, 1983. 
In this area, temperature inversions consistently form in winter due to the extremely cold and dense air of the Siberian High pooling in deep hollows, so that temperatures increase rather than decrease with higher altitude. In Verkhoyansk it sometimes happens that the average minimum temperatures for January, February, and December are below −50 C. Oymyakon and Verkhoyansk are the only two permanently populated places in the world that have recorded temperatures below -60.0 C every day of January.
In June, July, and August, daytime temperatures over +30 C are not uncommon. The warmest month on record is July 2010, at +20.8 C. The average annual temperature for Verkhoyansk is -14.5 C. On July 25, 1988, Verkhoyansk recorded a temperature of +37.3 °C, yielding a temperature range of 105 C-change based on reliable records, which is one of the greatest temperature ranges in the world. Oymyakon and Yakutsk are the only other places in the world with a temperature range higher than 100 C-change. Verkhoyansk has never recorded a temperature above freezing between November 10 and March 14. 
Verkhoyansk has a dry climate with little rainfall or snowfall: the average annual precipitation is 180 mm. Although no month can be described as truly wet, there are strong seasonal differences in precipitation, with the summer being much wetter than the winter. Winter precipitation is extremely light, largely because of the dominance of high pressure at this time of year. Snow is actually most likely in October and May, when the weather is less dry than in winter.

</doc>
<doc id="57916" url="http://en.wikipedia.org/wiki?curid=57916" title="Antigone">
Antigone

In Greek mythology, Antigone ( ; Greek: Ἀντιγόνη) is the daughter of Oedipus and his mother, Jocasta. The meaning of the name is, as in the case of the masculine equivalent Antigonus, "worthy of one's parents" or "in place of one's parents".
Classical depictions.
Antigone is the subject of a popular story in which she attempts to secure a respectable burial for her brother Polynices, who was killed in battle between him and his brother Eteocles even though he is seen as a traitor to Thebes and the law forbids even mourning for him, punishable by death.
In the oldest version of the story, the burial of Polynices takes place during Oedipus' reign in Thebes, before Oedipus marries Jocasta. However, in the best-known versions, Sophocles' tragedies "Oedipus at Colonus" and "Antigone", it occurs in the years after Oedipus' banishment and death, and Antigone has to struggle against Creon. Creon was next in line to throne, as he was Jocasta's brother by Menoeceus. In Sophocles' version, after Oedipus' death, it was decided that the two brothers, Eteocles and Polynices were to reign over Thebes taking turns. In the fight against Thebes, the two brothers kill each other. Antigone is brought before Creon, and states that she knew Creon's law but chose to break it, expounding upon the superiority of 'divine law' to that made by man. She puts the will of the gods ahead of manmade laws, responding to the decision of not granting Polynices a burial with courage, passion, and determination.
Sophocles' "Antigone" ends in disaster, with Antigone being locked in a tomb on Creon's orders, and Creon's son Hæmon (or Haimon.) Although Creon had a change of heart and was headed to the tomb to release Antigone, Haimon who loved and was engaged to Antigone, stabbed himself after seeing that Antigone had hanged herself in the tomb. (Also see Oedipus for a variant of this story.) Queen Eurydice, wife of King Creon, also kills herself eventually due to such actions allowed by her husband. She had been forced to weave throughout the entire story and her death alludes to The Fates.
The dramatist Euripides also wrote a play called "Antigone", which is lost, but some of the text was preserved by later writers and in passages in his "Phoenissae". In Euripides, the calamity is averted by the intercession of Dionysus and is followed by the marriage of Antigone and Hæmon. Antigone also plays a role in Euripides extant play "The Phoenician Women".
Different elements of the legend appear in other places. A description of an ancient painting by Philostratus ("Imagines" ii. 29) refers to Antigone placing the body of Polynices on the funeral pyre, and this is also depicted on a sarcophagus in the Villa Doria Pamphili in Rome. And in Hyginus' version of the legend, founded apparently on a tragedy by some follower of Euripides, Antigone, on being handed over by Creon to her lover Hæmon to be slain, is secretly carried off by him and concealed in a shepherd's hut, where she bears him a son, Maeon. When the boy grows up, he attends some funeral games at Thebes, and is recognized by the mark of a dragon on his body. This leads to the discovery that Antigone is still alive. The demi-god Heracles then intercedes and pleads with Creon to forgive Hæmon, but in vain. Hæmon then kills Antigone and himself. The intercession by Heracles is also represented on a painted vase (circa 380-300 BC).
Adaptations.
The stories of Antigone has been a popular subject for books, plays, and other works, including:

</doc>
<doc id="57918" url="http://en.wikipedia.org/wiki?curid=57918" title="Verkhoyansk Range">
Verkhoyansk Range

The Verkhoyansk Range (Russian: Верхоянский хребет) is a mountain range of eastern Siberia, spanning roughly 1000 km (600 m.), across the Sakha Republic. It forms a vast arc between the Lena and Aldan rivers to the west and the Yana River to the east. It rises to ca. 2,480 m (8,150 ft) in the south. There are coal, silver, lead, and zinc deposits. It lies just west of the boundary of the Eurasian and the North American tectonic plates.
The world's lowest temperatures for inhabited places have been recorded in this region, and there is quite deep snow cover for most of the year. During the Last Glacial Maximum the range contained extensive glaciers, and the scenery in the summer is typical of "alpine" mountains.

</doc>
<doc id="57921" url="http://en.wikipedia.org/wiki?curid=57921" title="Desmond Llewelyn">
Desmond Llewelyn

Desmond Wilkinson Llewelyn (12 September 1914 – 19 December 1999) was a Welsh actor. He played Q in 17 of the "James Bond" films between 1963 and 1999.
Biography.
Early life.
Llewelyn was born in Newport, Wales, the son of Mia (née Wilkinson) and Ivor Llewelyn, who was a coal mining engineer. He originally wanted to be a minister, but during his education at Radley College, he worked as a stagehand in the school's productions and occasionally picked up small roles. His son Justin followed him to Radley, and was also a leading light of the school's stage productions.
He was brought up in Blaen-y-Pant House situated on Bettws Lane, Bettws. The house is now used as a care home for the elderly.
Second World War.
The outbreak of the Second World War in September 1939 halted his acting career; Llewelyn was commissioned as a second lieutenant in the British Army, serving with the Royal Welch Fusiliers. In 1940, he was captured by the German Army in France, and was held as a prisoner of war for five years.
Bond career.
Llewelyn was chosen for the role of Q because of his work with director Terence Young in the 1950 war film "They Were Not Divided", in which he played a tank gunner. Beginning with "From Russia with Love" in 1963, Llewelyn appeared as Q, the quartermaster of the MI6 gadget lab (also known as Q branch), in every EON Bond film until his death, with the exception of "Live and Let Die" in 1973, in which the character Q did not appear.
His last appearance as Q prior to his death was in "The World Is Not Enough" in 1999. During his briefing of 007 in the film, Q introduces John Cleese's character, R, as his heir presumptive, and the film alludes to Q's retirement—to which Bond, after seeing Q, expresses his hope that it will not be any time soon. Q's response is to admonish Bond to "always have an escape plan", after which he lowers himself through the floor of his lab. Llewelyn had stated not long before his death that he had no plans to retire and that he would continue playing Q "as long as the producers want me and the Almighty doesn't."
In the 2002 film "Die Another Day", John Cleese's character is the head of Q branch, having inherited the title of quartermaster from his predecessor. In all, Llewelyn appeared in 17 Bond films, more than any other actor, and worked with the first five "James Bond" actors. He also portrayed Q in a 1967 EON-produced made-for-television documentary entitled "Welcome to Japan, Mr. Bond", which was included in the 2006 special edition DVD release of "You Only Live Twice".
Other work.
Although one of British cinema's most recognisable characters and an important and long-standing element in the 'Bond' franchise, 'Q' did not make Llewelyn rich—the actor was merely paid 'by the day' for his few hours of work on-set, and did not share in the money made by the films. Nevertheless, because Llewelyn was considered one of the franchise's major institutions and he was immensely popular among "Bond" fans, Llewelyn starred in several commercials, including ones to promote the video games "GoldenEye 007" and "Tomorrow Never Dies".
Llewelyn made a brief appearance in "Little Mother", an episode of "The Adventures of Robin Hood". He also appeared in other films such as the Ealing comedy "The Lavender Hill Mob" (1951), the 1963 film "Cleopatra" (as a Roman senator), and the 1981 PBS production of "Dr. Jekyll and Mr. Hyde", and he had a small role in the musical "Chitty Chitty Bang Bang" (1968) which was itself based on a children's book by Bond author Ian Fleming. In 1961 he made an uncredited cameo who appears early on as one of the Marques’s servants in the Hammer Film Productions of "The Curse of the Werewolf." He also acted on stage with Laurence Olivier and Vivien Leigh (appearing as an extra in Olivier's 1948 film "Hamlet") and appeared as Geoffrey Maddocks ('The Colonel') in the British television series "Follyfoot" from 1971 to 1973. The Bond film "Live and Let Die" was filmed during the third series of "Follyfoot" and Llewelyn was written out of the series for three episodes to appear in the film. However, the Bond producers ultimately decided to leave the character out of the film anyway, much to Llewelyn's annoyance.
Personal life.
Despite playing an inventor in the "Bond" films, Llewelyn always maintained that he was totally lost in the world of technology, a trait that also plagued his successor, John Cleese. A biography entitled "" was written by Sandy Hernu and released on 1 November 1999.
Death.
On 19 December 1999, while driving home alone from a book signing event, Llewelyn was involved in a fatal car crash. His Renault Megane collided head-on with a Fiat Bravo driven by a 35-year-old man on the A27 near the village of Berwick, East Sussex. Despite attention from a doctor called to scene and transfer by helicopter to Eastbourne District General Hospital, he died shortly thereafter. The other driver was seriously injured. An inquest recorded a verdict of accidental death. Llewelyn's death occurred three weeks after the premiere of "The World is Not Enough". Pierce Brosnan, who starred with Llewelyn in three of his four "Bond" movies, spoke at his funeral on 6 January 2000.
His widow, Pamela Mary Llewelyn, died in East Sussex in 2001, aged 85. His son, Justin Llewelyn, died in 2012, aged 59.

</doc>
<doc id="57925" url="http://en.wikipedia.org/wiki?curid=57925" title="Pituitary gland">
Pituitary gland

In vertebrate anatomy, the pituitary gland, or hypophysis, is an endocrine gland about the size of a pea and weighing 0.5 g in humans. It is a protrusion off the bottom of the hypothalamus at the base of the brain. The hypophysis rests upon the hypophysial fossa of the sphenoid bone in the center of the middle cranial fossa and is surrounded by a small bony cavity (sella turcica) covered by a dural fold (diaphragma sellae). The anterior pituitary (or adenohypophysis) is a lobe of the gland that regulates several physiological processes (including stress, growth, reproduction, and lactation). The intermediate lobe synthesizes and secretes melanocyte-stimulating hormone. The posterior pituitary (or neurohypophysis) is a lobe of the gland that is functionally connected to the hypothalamus by the median eminence via a small tube called the pituitary stalk (also called the infundibular stalk or the infundibulum).
Hormones secreted from the pituitary gland help control: growth, blood pressure, certain functions of the sex organs, thyroid glands and metabolism as well as some aspects of pregnancy, childbirth, nursing, water/salt concentration and the kidneys, temperature regulation and pain relief.
Structure.
The pituitary gland is a pea-sized gland that sits in a protective bony enclosure called the sella turcica. It is composed of three lobes: anterior, intermediate, and posterior. In many animals, these three lobes are distinct. However, in humans, the intermediate lobe is but a few cell layers thick and indistinct; as a result, it is often considered part of the anterior pituitary. In all animals, the fleshy, glandular anterior pituitary is distinct from the neural composition of the posterior pituitary. It belongs to the diencephalon.
Anterior.
The anterior pituitary arises from an invagination of the oral ectoderm and forms Rathke's pouch. This contrasts with the posterior pituitary, which originates from neuroectoderm.
Endocrine cells of the anterior pituitary are controlled by regulatory hormones released by parvocellular neurosecretory cells in the hypothalamus. The latter release regulatory hormones into hypothalamic capillaries leading to infundibular blood vessels, which in turn lead to a second capillary bed in the anterior pituitary. This vascular relationship constitutes the hypothalamo-hypophyseal portal system. Diffusing out of the second capillary bed, the hypothalamic releasing hormones then bind to anterior pituitary endocrine cells, upregulating or downregulating their release of hormones.
The anterior pituitary is divided into anatomical regions known as the pars tuberalis, pars intermedia, and pars distalis. It develops from a depression in the dorsal wall of the pharynx (stomal part) known as Rathke's pouch. The pars intermedia is also considered as a separate intermediate lobe.
Posterior.
The posterior lobe develops as an extension of the hypothalamus. The magnocellular neurosecretory cells of the posterior side possess cell bodies located in the hypothalamus that project axons down the infundibulum to terminals in the posterior pituitary. This simple arrangement differs sharply from that of the adjacent anterior pituitary, which does not develop from the hypothalamus. The release of pituitary hormones by both the anterior and posterior lobes is under the control of the hypothalamus, albeit in different ways.
Function.
Anterior.
The anterior pituitary synthesizes and secretes hormones. All releasing hormones (-RH) referred to, can also be referred to as releasing factors (-RF).
Somatotrophins:
Thyrotrophins:
Corticotropins:
Lactotrophins:
Gonadotropins:
These hormones are released from the anterior pituitary under the influence of the hypothalamus. Hypothalamic hormones are secreted to the anterior lobe by way of a special capillary system, called the hypothalamic-hypophysial portal system.
Intermediate.
The intermediate lobe synthesizes and secretes the following important endocrine hormone:
Posterior.
The posterior pituitary stores and secretes (but does not synthesize) the following important endocrine hormones:
Magnocellular Neurons:
Hormones.
Hormones secreted from the pituitary gland help control the following body processes:
Clinical significance.
Some of the diseases involving the pituitary gland are:
All of the functions of the pituitary gland can be adversely affected by an over or under production of associated hormones.
History.
Etymology.
The Greek physician Galen referred to the pituitary gland by only using the (Ancient Greek) name ἀδήν, "gland". He described the pituitary gland as part of a series of secretory organs for the excretion of nasal mucus. Anatomist Andreas Vesalius translated ἀδήν with "glans, in quam pituita destillat", "gland in which slime ("pituita") drips". Besides this 'descriptive' name, Vesalius used "glandula pituitaria", from which the English name "pituitary gland" is ultimately derived. 
The expression "glandula pituitaria" is still used as official synonym beside "hypophysis" in the official Latin nomenclature "Terminologia Anatomica". In the seventeenth century the supposed function of the pituitary gland to produce nasal mucus was debunked. The expression "glandula pituitaria" and its English equivalent "pituitary gland" can only be justified from a historical point of view. The inclusion of this synonym is merely justified by noting that the main term "hypophysis" is a much less popular term.
The anatomist Samuel Thomas von Sömmerring coined the name "hypophysis". This name consists of ὑπό ('under') and φύειν ('to grow'). In later Greek ὑπόφυσις is used differently by Greek physicians as "outgrowth". Sömmering also used the equivalent expression "appendix cerebri", with "appendix" as "appendage". In various languages, "Hirnanhang" in German and "hersenaanhangsel" in Dutch, the terms are derived from "appendix cerebri".
Other animals.
The pituitary gland is found in all vertebrates, but its structure varies between different groups.
The division of the pituitary described above is typical of mammals, and is also true, to varying degrees, of all tetrapods. However, only in mammals does the posterior pituitary have a compact shape. In lungfish, it is a relatively flat sheet of tissue lying above the anterior pituitary, but in amphibians, reptiles, and birds, it becomes increasingly well developed. The intermediate lobe is, in general, not well developed in any species and is entirely absent in birds.
The structure of the pituitary in fish, apart from the lungfish, is generally different from that in other animals. In general, the intermediate lobe tends to be well developed, and may equal the remainder of the anterior pituitary in size. The posterior lobe typically forms a sheet of tissue at the base of the pituitary stalk, and in most cases sends irregular finger-like projection into the tissue of the anterior pituitary, which lies directly beneath it. The anterior pituitary is typically divided into two regions, a more anterior "rostral" portion and a posterior "proximal" portion, but the boundary between the two is often not clearly marked. In elasmobranchs there is an additional, "ventral lobe" beneath the anterior pituitary proper.
The arrangement in lampreys, which are among the most primitive of all fish, may indicate how the pituitary originally evolved in ancestral vertebrates. Here, the posterior pituitary is a simple flat sheet of tissue at the base of the brain, and there is no pituitary stalk. Rathke's pouch remains open to the outside, close to the nasal openings. Closely associated with the pouch are three distinct clusters of glandular tissue, corresponding to the intermediate lobe, and the rostral and proximal portions of the anterior pituitary. These various parts are separated by meningial membranes, suggesting that the pituitary of other vertebrates may have formed from the fusion of a pair of separate, but associated, glands.
Most armadillos also possess a neural secretory gland very similar in form to the posterior pituitary, but located in the tail and associated with the spinal cord. This may have a function in osmoregulation.
There is a structure analogous to the pituitary in the octopus brain.
Intermediate lobe.
Although rudimentary in humans (and often considered part of the anterior pituitary), the intermediate lobe located between the anterior and posterior pituitary is important to many animals. For instance, in fish, it is believed to control physiological color change. In adult humans, it is just a thin layer of cells between the anterior and posterior pituitary. The intermediate lobe produces melanocyte-stimulating hormone (MSH), although this function is often (imprecisely) attributed to the anterior pituitary.
The intermediate lobe is, in general, not well developed in tetrapods, and is entirely absent in birds.

</doc>
<doc id="57927" url="http://en.wikipedia.org/wiki?curid=57927" title="Sea of Okhotsk">
Sea of Okhotsk

The Sea of Okhotsk (Russian: Охо́тское мо́ре, "Okhotskoye More"; ]; Japanese: オホーツク海 "Ohōtsuku-kai") is a marginal sea of the western Pacific Ocean, lying between the Kamchatka Peninsula on the east, the Kuril Islands on the southeast, the island of Hokkaidō to the south, the island of Sakhalin along the west, and a long stretch of eastern Siberian coast (including the Shantar Islands) along the west and north. The northeast corner is the Shelikhov Gulf. The sea is named after Okhotsk, the first Russian settlement in the Far East.
Geography.
The Sea of Okhotsk covers an area of 1,583,000 km2, with a mean depth of 859 m and a maximum depth of 3372 m. It is connected to the Sea of Japan on either side of Sakhalin: on the west through the Sakhalin Gulf and the Gulf of Tartary; on the south, through the La Pérouse Strait.
In winter, navigation on the Sea of Okhotsk becomes difficult, or even impossible, due to the formation of large ice floes, because the large amount of freshwater from the Amur River lowers the salinity which results in raising the freezing point of the sea. The distribution and thickness of ice floes depends on many factors: the location, the time of year, water currents, and the sea temperatures.
With the exception of Hokkaidō, one of the Japanese home islands, the sea is surrounded on all sides by territory administered by the Russian Federation.
Extent.
The International Hydrographic Organization defines the limits of the Sea of Okhotsk as follows:
Islands.
Some of the Sea of Okhotsk's islands are quite large, including Japan's second largest island, Hokkaidō, as well as Russia's largest island, Sakhalin. Practically all of the sea's islands are either in coastal waters or belong to the various islands making up the Kuril Islands chain. These fall either under undisputed Japanese or Russian ownership or disputed ownership between Japan and Russia. Iony Island is the only island located in open waters and belongs to the Khabarovsk Krai of the Russian Federation. The majority of the sea's islands are uninhabited making them ideal breeding grounds for seals, sea lions, seabirds, and other sea island fauna. Large colonies, with over a million individuals, of crested auklets use the Sea of Okhotsk as a nesting site.
History.
Russian explorers Ivan Moskvitin and Vassili Poyarkov were the first Europeans to visit the Sea of Okhotsk (and, probably, the island of Sakhalin) in the 1640s.
The Dutch captain Maarten Gerritsz Vries in the "Breskens" entered the Sea of Okhotsk from the south-east in 1643, and charted parts of the Sakhalin coast and Kurile Islands, but failed to realize that either Sakhalin or Hokkaido are islands.
The first and foremost Russian settlement on the shore was the port of Okhotsk, which relinquished commercial supremacy to Ayan in the 1840s. The Russian-American Company all but monopolized the commercial navigation of the sea in the first half of the 19th century.
The Second Kamchatka Expedition under Vitus Bering systematically mapped the entire coast of the sea, starting in 1733. Jean-François de La Pérouse and William Robert Broughton were the first non-Russian European navigators known to have passed through these waters other than Maarten Gerritsz Vries. Ivan Krusenstern explored the eastern coast of Sakhalin in 1805. Mamiya Rinzō and Gennady Nevelskoy determined that the Sakhalin was indeed an island separated from the mainland by a narrow strait. The first detailed summary of the hydrology of the Okhotsk sea was prepared and published by Stepan Makarov in 1894.
During the Cold War, the Sea of Okhotsk was the scene of several successful U.S. Navy operations (including Operation Ivy Bells) to tap Soviet Navy undersea communications cables. These operations were documented in the book "". The sea (and surrounding area) were also the scene of the Soviet "PVO Strany" attack on Korean Air Flight 007 in 1983. The Soviet Pacific Fleet used the Sea as a ballistic missile submarine bastion, a strategy that Russia continues.
In the Japanese language, the sea has no traditional Japanese name despite its close location to the Japanese territories and is called "Ohōtsuku-kai" (オホーツク海), which is a transcription of the Russian name. Additionally, Okhotsk Subprefecture, Hokkaidō which faces the sea, also known as Okhotsk region (オホーツク地方, Ohōtsuku-chihō), is named after the sea.
The Sea of Okhotsk was a hotbed for whaling in the middle of the 19th century. Beginning in 1845, American whaleships began hunting right whales in the southeastern part of the Sea of Okhotsk near the Kurile Islands. The first bowheads were caught in 1847. From 1849 bowheads dominated the catch. Between 1850 and 1853 the majority of the fleet focused their efforts on bowheads in the Bering Strait region. Following poor catches there, whaleships began shifting their attention to the stock of bowhead whales in the Sea of Okhotsk. In 1854 alone some 160 vessels visited the region. Next year more than 130 ships. The next year, in 1856, nearly 150 ships sailed to the Okhotsk. By 1857, the number of ships had declined to a little over 100. With declining catches from 1858 to 1860, the fleet shifted its focus back to the Bering Strait region. Many of the ships converged on the Shantar Islands, anchoring within the archipelago's many sheltered bays. On July 28, 1854 the New Bedford ship "Isabella" reported 94 ships in sight from her deck. A few days later, the "Lexington" of Nantucket reported one hundred whaleboats were about chasing whales. Ships continued to hunt whales in the Sea of Okhotsk until the early 20th century.
Oil and gas exploration.
29 zones of possible oil and gas accumulation have been identified on the Sea of Okhotsk shelf, which runs along the coast. Total reserves are estimated at 3.5 billion tons of equivalent fuel, including 1.2 billion tons of oil and 1.5 billion cubic meters of gas.
On 18 December 2011 the Russian oil drilling rig Kolskaya capsized and sank in a storm in the Sea of Okhotsk, some 124 km from Sakhalin Island, where it was being towed from Kamchatka. Reportedly its pumps failed, causing it to take on water and sink. The platform carried 67 people, of which 14 were initially rescued by the icebreaker Magadan and the tugboat Natftogaz-55. The platform was subcontracted to a company working for the Russian energy giant Gazprom.

</doc>
<doc id="57928" url="http://en.wikipedia.org/wiki?curid=57928" title="Fritz Walter">
Fritz Walter

Friedrich "Fritz" Walter (31 October 1920 – 17 June 2002) was a German footballer. In his time with the German national team, he made 61 caps and scored 33 goals. He usually played as an inside forward or attacking midfielder.
Life and career.
Early club career.
Walter was exposed to football early with his parents working at the 1. FC Kaiserslautern club restaurant. By 1928 he had joined the Kaiserslautern youth academy, and he made his first team debut at 17, continuing an association with the club that would be his only professional club.
International pro teams had repeatedly offered him hefty sums, but with support from his wife always declined in order to stay at home, to play for his home town, the national team and "Chef" (German for "boss") Herberger.
International debut.
Walter debuted with the German national team in 1940 under Sepp Herberger, and scored a hat-trick against Romania.
War.
Walter was drafted into the armed forces in 1942, however, the end of the war found 24-year old Walter in a Prisoner of War camp in Maramures in which he played with Hungarian and Slovakian guards. When the Soviets arrived they in general took all German prisoners back to a Gulag in Soviet Union where life expectancy was about five years. Fortunately, one of the Hungarian prison guards had seen Walter playing for Germany, and told them that Fritz was not German but from the Saar Territory.
Return to Germany.
Upon his return in 1945, Walter, who by now suffering from malaria, again played for Kaiserslautern, leading them to German championships in 1951 and 1953. Sepp Herberger recalled him to the national team in 1951, and he was named captain.
He was captain of the West German team that won their first World Cup in 1954. Ironically, given the intervention of the Hungarian guards during the war, that win came over Hungary. He and his brother, Ottmar Walter, became the first brothers to play in a World Cup winning team.
But in 1956, after the crackdown by the Soviets of the Hungarian Uprising, the Hungarian football team were caught away from home, and for two years, Fritz managed their games and provided the financial backing and in small measure, paid them back for having saved his life. Walter received his last cap during the semi-final against Sweden in the 1958 World Cup, suffering an injury which ended his international career, and he retired from football in 1959.
Later life and legacy.
The home stadium of FC Kaiserslautern was renamed the Fritz-Walter-Stadion in 1985.
Fritz Walter was named an honorary captain of the German football squad in 1958. The other four are Uwe Seeler, Franz Beckenbauer, Lothar Matthäus and Bettina Wiegmann.
Walter died in Enkenbach-Alsenborn on 17 June 2002, aged 81. It was his dream to see the World Cup 2006 in "his" town Kaiserslautern as the town had not been selected in the smaller tournament of 1974, but it was denied with his death. But on the fourth year anniversary of his death on 17 June 2006, the United States played Italy in Kaiserslautern and a minute of silence was observed in his memory. Today people may visit the "Fritz Walter Haus" in the town of Enkenbach-Alsenborn approx. 20 km east of Kaiserslautern (first exit from Kaiserslautern on Bundesautobahn 6 direction Mannheim).
In November 2003, to celebrate UEFA's 50th anniversary, the German Football Association selected him as its Golden Player of the past 50 years (from 1954 to 2003). 
During the eighties and nineties, there was another successful Bundesliga striker called "Fritz Walter", who mainly played for VfB Stuttgart. Although he had no relationship to the great Kaiserslautern captain, sports fans jokingly called him "Fritz Walter junior".
Personal life.
Walter's wife of five decades was Italia Walter, a woman from Italy.
It was popular knowledge in Germany that Walter appeared to play better the worse the weather was, and so now the term "Fritz Walter's weather" is used to describe rainy weather conditions, often rendered with odd local dialect grammar "of Fritz, his weather". This is because he, as many other soldiers, had contracted malaria during the war, thus rendering him unable to stand the heat of the sun. The 1954 World Cup final was played in "Fritz Walter's weather" conditions.
On 6 October 1956 Walter scored a spectacular goal in Leipzig in front of 100,000 East Germans during a friendly against Wismut Aue, when he hit the ball back-heel while diving forward. 

</doc>
<doc id="57930" url="http://en.wikipedia.org/wiki?curid=57930" title="Petropavlovsk-Kamchatsky">
Petropavlovsk-Kamchatsky

Petropavlovsk-Kamchatsky (Russian: Петропа́вловск-Камча́тский) is the city and the administrative, industrial, scientific, and cultural center of Kamchatka Krai, Russia. Population:  (2010 Census);  (2002 Census);  (1989 Census)
Geography.
The city is situated on high hills and surrounded by volcanoes. The surrounding terrain is mountainous enough that the horizon cannot be seen clearly from any point in town. Across Avacha Bay from the city is Russia's largest submarine base, the Rybachiy Nuclear Submarine Base, established during the Soviet regime and still used by the Russian Navy. The city is located 6766 km from Moscow and about 2220 km from Vladivostok.
History.
The city was founded by Danish navigator Vitus Bering in the service of the Russian Navy. Bering reached Avacha Bay in late 1740 and laid the foundation stone for the harbor town, naming the new settlement "Petropavlovsk" (Peter and Paul) after his two ships, the "St. Peter" and the "St. Paul", built in Okhotsk for his second expedition. The town's location on the sheltered Avacha Bay and at the mouth of the Avacha River saw it develop to become the most important settlement in Kamchatka. It was granted town status on April 9, 1812.
During the 1854–1855 Crimean War, the city was put under siege by the Anglo-French forces, but never fell. The city had been fortified under the command of Nikolay Muravyov-Amursky in the years prior, but only possessed a small garrison of a few hundred soldiers and sixty-seven cannons. After much exchange of fire, 600 allied troops landed south of the city, but were forced to retreat by only 230 Russian troops after heavy fighting. One week later, 900 allied troops landed east of the town, but were again repelled by the Russians. The allied ships then retreated from Russian waters. The total Russian losses were reported at around 100 men; those of the allies at least five times that number.
Petropavlovsk was a great source of fish, particularly salmon, and crab meat for the Soviet Union in the 20th century. Since the end of the Soviet era, fishing rights have also been granted to foreign interests. Poaching of salmon for their caviar at Petropavlovsk-Kamchatsky remains a problem, unhampered by lax law enforcement and widespread corruption.
Administrative and municipal status.
Petropavlovsk-Kamchatsky is the administrative center of the krai. Within the framework of administrative divisions, it is incorporated as Petropavlovsk-Kamchatsky City Under Krai Jurisdiction—an administrative unit with the status equal to that of the districts. As a municipal division, Petropavlovsk-Kamchatsky City Under Krai Jurisdiction is incorporated as Petropavlovsk-Kamchatsky Urban Okrug.
Tourism.
The city has developed a tourist infrastructure. About twenty large tourism companies offer a wide range of services from bear hunting to paragliding. No roads connect the Kamchatka Peninsula to the rest of the world. Travel to Petropavlovsk-Kamchatsky is expensive but is growing in popularity because of the remarkable scenery throughout the peninsula. The city is served by Petropavlovsk-Kamchatsky Airport.
Demographics.
Ethnic Russians and Ukrainians make up the majority of the population; the city on its own has more inhabitants than the entire neighboring Chukotka Autonomous Okrug or Magadan Oblast.
The population was 179,780 in 2010; 179,800 in 2011; 179,784 in 2012; and 181,618 in 2013.
Climate.
The climate is boreal (Köppen "Dfc") and precipitation averages are estimated at 1150 mm, or about three-and-a-half times as much as most of Siberia averages, with most falling as snow. Temperatures in winter are much milder than in Siberia—a typical January day averages -7 C, while in summer +14 C constitutes an average August high. In warm years monthly high averages in July–August reach +18 C and higher.
Despite the generally high precipitation, the weather is less cloudy than in the adjacent Kuril Islands that are one of the least sunny places in the world, since the city is located behind a peninsula to the north that blocks some of the fog from the Oyashio Current. Oceanic water in Avacha Bay and adjacent bays is also warmer than coastal waters of Kuril Islands and Okhotsk sea coast (except Southern Kuriles and Southern Sakhalin).
Twin towns and sister cities.
Petropavlovsk-Kamchatsky is twinned with:

</doc>
<doc id="57931" url="http://en.wikipedia.org/wiki?curid=57931" title="Vitus Bering">
Vitus Bering

Vitus Jonassen Bering (baptised 5 August 1681, died 19 December 1741) also known as Ivan Ivanovich Bering was a Danish explorer and officer in the Russian Navy. He is known for his two explorations of the north-eastern coast of the Asian continent and from there the western coast on the North American continent. The Bering Strait, the Bering Sea, Bering Island, the Bering Glacier and the Bering Land Bridge have since all been (posthumously) named in his honour.
Taking to the seas at the age of 18, Bering travelled extensively over the next eight years, as well as taking naval training at Amsterdam. In 1704, he enrolled with the rapidly expanding Russian navy of Peter the Great. After serving with the navy in significant but non-combat roles during the Great Northern War, Bering resigned in 1724 to avoid the continuing embarrassment of his low rank to Anna, his wife of eleven years. Having obtained a promotion on his retirement to the level of first captain, Bering kept this rank when he decided to rejoin the Russian navy later the same year. He was selected by Peter to captain the first Kamchatka expedition, an expedition set to sail north from Russian outposts on the Kamchatka peninsula, probably with the greatest emphasis on mapping the new areas visited (and particularly establishing if Asia and America shared a land border). Bering departed St. Petersburg in February 1725 at the head of a 34-man expedition, aided by the expertise of lieutenants Martin Spangberg and Aleksei Chirikov. The party took on men as it headed towards Okhotsk, encountering many difficulties (most notably a lack of food) before they arrived in the settlement. From there, they sailed to the Kamchatka peninsula, preparing new ships there and sailing north (repeating a little documented journey of Semyon Dezhnyov eighty years previously). In August 1728, Bering decided that they had sufficient evidence that there was clear sea between Asia and America, which he did not sight during the trip. For the first expedition, Bering was rewarded with money, prestige, and a promotion to the noble rank of "Captain Commander". He immediately started preparations for a second trip.
Having returned to Okhotsk with a much larger, better prepared, and much more ambitious expedition, Bering set off for an expedition towards North America in 1741. While doing so, the expedition spotted Mount Saint Elias, and sailed past Kodiak Island. A storm separated the ships, but Bering sighted the southern coast of Alaska, and a landing was made at Kayak Island or in the vicinity. Adverse conditions forced Bering to return, and he discovered some of the Aleutian Islands on his way back. One of the sailors died and was buried on one of these islands, and the group was named after him (as the Shumagin Islands). Bering himself became too ill to command his ship, which was at last driven to seek refuge on an uninhabited island in the Commander Islands group ("Komandorskiye Ostrova") in the southwest Bering Sea. On 19 December 1741 Vitus Bering died on the island, which was given the name Bering Island after him, near the Kamchatka Peninsula, reportedly from scurvy (although this has been contested), along with 28 men of his company.
Biography.
Early life.
Vitus Bering was born in the port town of Horsens in Denmark to Anne Pedderdatter and her husband Jonas Svendsen (a "customs inspector and churchwarden"), being baptised in the Lutheran church there on 5 August 1681. He was named after a maternal great-uncle, Vitus Pedersen Bering, who had been a chronicler in the royal court, and was not long deceased at the time of Vitus Jonassen Bering's birth. The family enjoyed reasonable financial security, with two of Vitus' elder half-brothers both attending the University of Copenhagen. Vitus, however, did not, and instead signed on at age 15 as a ship's boy. Between 1696 and 1704, Bering travelled the seas, reaching India and the Dutch East Indies, whilst also finding time to complete naval officer training in Amsterdam. He would also claim later (and, it seems, not without some supporting evidence) to have served on Danish whalers in the North Atlantic, visiting European colonies in the Caribbean and on the eastern seaboard of North America. It was in Amsterdam, however, that in 1704 and under the guidance of Norwegian-born Russian admiral Cornelius Cruys, Bering enlisted with the Russian navy, taking the rank of sub-lieutenant. He would be repeatedly promoted in Peter the Great's rapidly evolving navy, reaching the rank of second captain by 1720. In that time, it appears he was not involved in any sea battles, but commanded several vessels in potentially dangerous missions, including the transport of a ship from the Azov Sea on Russia's southern coast to the Baltic on her northern coast. His work in the latter stages of the Great Northern War (ending in 1721), for example, was dominated by lightering duties.
On 8 October 1713, Bering married Anna Christina Pülse; the ceremony took place in the Lutheran church at Vyborg, only recently annexed from Sweden. Over the next 18 years, they had 9 children, of which 4 survived childhood. During his time with the Russian navy – particularly as part of the Great Northern War – he was unable to spend much time with Anna, who was approximately eleven years Bering's junior and the daughter of a Swedish merchant. At the war's conclusion in 1721, Bering was not promoted like many of his contemporaries. The omission proved particularly embarrassing when, in 1724, Anna's younger sister Eufemia upstaged her by marrying Thomas Saunders, already a Rear-Admiral despite a much shorter period of service. In order to save face, the 42-year-old Bering decided to retire from the navy, securing two months' pay and a notional promotion to first captain. Shortly after, the family – Bering, his wife Anna, and two young sons – moved out of St. Petersburg to live with Anna's family in Vyborg. After a period of joblessness lasting five months, however, Bering (keenly aware of his dependents), decided to reapply to the Admiralty. He was accepted for a renewed period of active service the same day. By 2 October 1724, Bering (retaining the rank of first captain he had secured earlier in the year) was back on the sea, commanding the ninety-gun "Lesnoe". The Tsar would soon have a new command for him, however.
First Kamchatka expedition.
St. Petersburg to Okhotsk.
On 29 December 1725 , Peter I of Russia asked Bering to command a voyage east, probably to map the lands (and possibly seas) between Russia's eastern boundary and the North America continent. Preparations for the trip had begun some years before, but with his health rapidly deteriorating, the Tsar had ordered that the process be hurried, and it was with this backdrop that Bering (with his knowledge of both the Indian Ocean and the eastern seaboard of North America, good personal skills and experience in transporting goods) was selected ahead of the experienced cartographer K. P. von Verd. His lieutenants for the journey, which would become known as the "First Kamchatka Expedition", were the hardened fellow Dane Martin Spangberg and the well-educated but relatively inexperienced Russian Aleksei Chirikov, a respected naval instructor. They would receive annual salaries of some 180 roubles during the trip; Bering would be paid 480. The final papers from Peter before his death on 28 January made it clear to Bering that he should proceed to the Kamchatka peninsula, build one or two ships there, and, keeping the land on his left, sail northwards until the land turned westwards, making it clear that there existed sea between Asia and North America. Instructions were left on how to proceed if North America was sighted during the voyage, which was scheduled to last three years. The natural route to Kamchatka was along tributaries of the Lena; but after the Treaty of Nerchinsk (1689) this looked politically infeasible. Instead, Bering's party, it was decided, would travel over land and river from St. Petersburg to Okhotsk, a small port town on Russia's eastern coast, and then by sea from Okhotsk to the Kamchatka peninsula, where they could start their voyage of exploration. On 24 January, Chirikov departed with 26 of the 34-strong expedition along the well-travelled roads to Vologda, 411 miles to the east. Having waited for the necessary paperwork to be completed, Bering and the remaining members of the expedition followed on 6 February. Bering was supplied with what few maps Peter had managed to commission in the preceding years.
Both parties used horse-drawn sledges and made good time over the first legs of the journey. On 14 February they were reunited in Vologda, and, now travelling together, headed eastwards across the Ural mountains, arriving in the small city of Tobolsk (one of the main stopping points of the journey) on 16 March. They had already travelled over 1750 miles. At Tobolsk, Bering took on more men to help the party through the more difficult journey ahead. He asked for 24 more from the garrison, before upping the request to 54 after hearing that the ship the party required at Okhotsk (the "Vostok") would need significant manpower to repair. In the end, the governor could spare only 39, but it still represented a significant expansion in numbers for the party. In addition, Bering wanted 60 carpenters and 7 blacksmiths; the governor responded that half of these would have to be taken on later, at Yeniseysk. After some delays preparing equipment and funds, on 14 May the now much enlarged party left Tobolsk, heading along the Irtysh. The journey ahead to the next major stopping point Yakutsk, was well-worn, but rarely by groups as large as Bering's, who had the additional difficulty of needing to take on more men as the journey progressed. As a result, the party ran behind schedule, reaching Surgut on 30 May and Makovsk in late June before entering Yeniseysk, where the additional men could be taken on; Bering would later claim that "few were suitable". In any case, the party left Yeniseysk on 12 August, desperately needing to make up lost time. On 26 September they arrived at Ilimsk, just three days before the river froze over. After the party had completed an eighty-mile trek to Ust-Kut, a town on the Lena where they could spend the winter, Bering travelled on to the town of Irkutsk both to get a sense of the conditions and to seek advice on how best to get their large party across the mountains separating Yakutsk (their next stop) to Okhotsk on the coast.
After leaving Ust-Kut when the river ice melted in the spring of 1726, the party rapidly travelled down the River Lena, reaching Yakutsk in the first half of June. Despite the need for hurry and men being sent in advance, the governor was slow to grant them the resources they needed, prompting threats from Bering. On 7 July, Spangberg left with a detachment of 209 men and much of the cargo; on 27 July apprentice shipbuilder Fyodor Kozlov led a small party to reach Okhotsk ahead of Spangberg, both to prepare food supplies and to start work repairing the "Vostok" and building a new ship (the "Fortuna") needed to carry the party across the bay from Okhotsk to the Kamchatka peninsula. Bering himself left on 16 August, whilst it was decided that Chirikov would follow the next spring with fresh supplies of flour. The journeys were as difficult as Bering had worried they would be. Both men and horses died, whilst other men (46 from Bering's party alone) deserted with their horses and portions of the supplies as they struggled to build roads across difficult marshland and river terrain. If Bering's party (which reached Okhotsk in October) fared badly, however, Spangberg's fared far worse. His heavily loaded boats could be tugged at no more than one mile a day – and they had some 685 miles to cover. When the rivers froze, the cargo was transferred to sleds and the expedition continued, enduring blizzards and waist-high snow. Even provisions left by Bering at Yudoma Cross could not fend off starvation. On 6 January 1727 Spangberg and two other men, who had together formed an advance party carrying the most vital items for the expedition, reached Okhotsk; ten days later sixty others joined them, although many were ill. Parties sent by Bering back along the trail from Okhotsk rescued seven men and much of the cargo that had been left behind. Okhotsk's inhabitants described the winter as the worst they could recall; Bering seized flour from the local villagers to ensure that his party too could take advantage of their stocks and consequently the whole village soon faced the threat of starvation. The explorer later reported how it was only the arrival of an advance party of Chirikov's division in June with 27 tons of flour that ensured his party (by then diminished in numbers) could be fed.
Okhotsk to Kamchatka and beyond.
The "Vostok" was readied and the "Fortuna" built at a rapid pace, with the first party (48 men commanded by Spangberg and comprising those required to start work on the ships that would have to be built in Kamchatka itself as soon as possible) leaving in June 1727. Chirikov himself arrived in Okhotsk soon after, bringing further supplies of food. He had had a relatively easy trip, losing none of his men and only 17 of the 140 horses he had set out with. On 22 August, the remainder of the party sailed for Kamchatka. Had the route been charted, they should have sailed around the peninsula and made port on its eastern coast; instead, they landed on the west and made a gruelling trip from the settlement of Bolsheretsk in the South-West, north to the Upper Kamchatka Post and then east along the Kamchatka River to the Lower Kamchatka Post. This Spangberg's party did before the river froze; next, a party led by Bering completed this final stint of approximately 580 miles over land without the benefit of the river; and finally, in the spring of 1728, the last party to leave Bolsheretsk, headed by Chirikov, reached the Lower Kamchatka Post. The outpost was six thousand miles from St. Petersburg and the journey itself (the first time "so many [had] gone so far") had taken some three years. The lack of immediate food available to Spangberg's advance party slowed their progress, which hastened dramatically after Bering's and Chirikov's group arrived with provisions. As a consequence, the ship they constructed (named the "Archangel Gabriel") was ready to be launched as soon as 9 June 1728 from its construction point upriver at Ushka. It was then fully rigged and provisioned by 9 July, and on 13 July set sail downstream, anchoring offshore that evening. On 14 July, Bering's party began their first exploration, hugging the coast in not a northerly direction (as they had expected) but a north-easterly one. The ship's log records a variety of landmarks spotted (including St. Lawrence Island) many of which the expedition took the opportunity to name. Translation problems hindered the exploration attempt, however, as Bering was unable to discuss the local geography with locals he encountered. Sailing further north, Bering entered for the first time the strait that would later bear his name.
Reaching a cape (which Chirikov named Cape Chukotsky), the land turned westwards, and Bering asked his two lieutenants on 13 August 1728 whether or not they could reasonably claim it was turning westwards for good: that is to say, whether they had proven that Asia and America were separate land masses. The rapidly advancing ice prompted Bering to make the controversial decision not to deviate from his remit: the ship would sail for a few more days, but then turn back. The expedition was neither at the most easterly point of Asia (as Bering had supposed) nor had it succeed in discovering the Alaskan coast of America, which on a good day would have been visible to the east. As promised, on 16 August, Bering turned the "Gabriel" around, heading back towards Kamchatka. Not before a storm forced hasty repairs, the ship was back at the mouth of the Kamchatka River, fifty days after it had left. The mission was at its conclusion, but the party still needed to make it back to St. Petersburg to document the voyage (thus avoiding the fate of Semyon Dezhnyov who, unbeknownst to Bering, had made a similar expedition eighty years previously). In the spring of 1729, the "Fortuna", which had sailed round the Kamchatka Peninsula to bring supplies to the Lower Kamchatka Post, now returned to Bolsheretsk; and shortly after, so did the "Gabriel". The delay was caused by a four-day journey Bering had embarked upon directly eastwards in search of North America, to no avail. By July 1729 the two vessels were back at Okhotsk, where they were moored alongside the "Vostok"; the party, no longer needing to carry shipbuilding materials made good time on the return journey from Okhotsk, and by 28 February 1730 Bering was back in the Russian capital. In December 1731 he would be awarded 1000 roubles and promoted to captain-commander, his first noble rank (Spangberg and Chirikov were similarly promoted to captain). It had been a long and expensive expedition, costing 15 men and souring relations between Russia and her native peoples: but it had provided useful new (though not perfect) insights into the geography of Eastern Siberia, and presented useful evidence that Asia and North America were separated by sea. Bering had not, however, proved the separation beyond doubt.
Second Kamchatka expedition and death.
Preparations.
Bering soon proposed a second Kamchatka expedition, much more ambitious than the first and with an explicit aim of sailing east in search of North America. The political situation in the Russian Empire was difficult, however, and this meant delays. In the interim, the Berings enjoyed their new-found status and wealth: there was a new house and a new social circle for the newly ennobled Berings. Bering also made a bequest to the poor of Horsens, had two children with Anna and even attempted to establish his familial coat of arms. The proposal, when it was accepted, would a significant affair, which involved 600 people from the outset and several hundred added along the way. Though Bering seems to have been primarily interested in landing in North America, he recognised the importance of secondary objectives: the list of which expanded rapidly under the guidance of planners Nikolai Fedorovich Golovin (head of the Admiralty); Ivan Kirilov, a highly ranked politician with an interest in geography, and Andrey Osterman, a close adviser of the new Empress, Anna Ivanovna. As Bering waited for Anna to solidify her grip on the throne, he and Kirilov worked to find a new, more dependable administrator to run Okhotsk and to begin work on improving the roads between Yakutsk and the coastal settlement. Their choice for the post of administrator, made remotely, was Grigory Skornyakov-Pisarev; possibly the least bad candidate, he would nevertheless turn out to be a poor choice. In any case, Skornyakov-Pisarev was ordered in 1731 to proceed to Okhotsk, with directions to expand it into a proper port. He did not leave for Okhotsk for another four years, by which time Bering's own expedition (in time for which Okhotsk was supposed to have been prepared) was not far off.
In 1732, however, Bering was still at the planning stage in Moscow, having taken a short leave of absence for St. Petersburg. The better positioned Kirilov oversaw developments, eyeing up not only the chance of discovering North America, but of mapping the whole Arctic coast, finding a good route south to Japan, landing on the Shantar Islands and even making contact with Spanish America. On 12 June the Senate approved resources to fund an academic contingent for the expedition, and three academics – Johann Georg Gmelin (a natural historian), Louis De l’Isle de la Croyère (an astronomer), and Gerhard Friedrich Müller (an anthropologist) – were selected by the Academy of Sciences. Owen Brazil, a Moscow native but of Irish descent, was selected as the expedition's quartermaster and was placed in charge of packaging and storing supplies, such as fudge, sausages and biscuits. Bering was wary of this expansion in the proposed size of the whole expedition, given the food shortages experienced on the first voyage. Proposals were made to transports goods or men to Kamchatka by sea via Cape Horn, but these were not approved. Other than a broad oversight role, Bering's personal instructions from the Admiralty were surprisingly simple. Given on 16 October 1732, they amounted only to recreating his first expedition, but with the added task of heading east and finding North America (a feat which had in fact just been completed by Mikhail Gvozdev, though this was not known at the time). The suggestion was made that Bering share more of his command with the Chirikov, suggesting that the 51-year-old Bering was slowly being edged out. Elsewhere, instructions were sent ahead to Yakutsk, Irkutsk and Okhotsk to aid Bering's second expedition – and thus, the naivety of the first expedition in assuming compliance was repeated. Further follies included plans to send ships north along the rivers Ob and Lena towards the Arctic.
St. Petersburg to Kamchatka.
Spangberg left St. Petersburg in February 1733 with the first (small) detachment of the second expedition, bound for Okhotsk. Chirikov followed on 18 April with the main contingent (initially 500 people and eventually swelling to approximately 3000 after labourers were added). Following them, on 29 April Bering followed with Anna and their two youngest children – their two eldest, both sons, were left with friends in Reval. The academic contingent, including the three professors, left in August. Soon catching the main party, Bering and Chirikov led the group eastwards, descending on Tobolsk for the winter. The arrival of such a large party with such great demands – and so soon after Spangberg had made similar demands – put a strain on the town. Bering and a small advance party left Tobolsk in later February, stopping at Irkutsk to pick up gifts for the native tribes they would later encounter; it arrived at Yakustsk in August 1734. The main grouping, now under Chirikov's command left Tobolsk in May 1734, but had a more difficult trek and one which required harsh discipline be imposed to prevent desertions. Nonetheless, it arrived in Yakutsk in June 1735. Whilst Spangberg headed east to Okhotsk, Bering waited in Yakutsk, preparing two ships on the Lena (one would be captained by Vasili Pronchishchev and the other first by Peter Lassenius and later by Dmitry Laptev). Both were to sail northwards, and over the coming years to chart the Arctic coastline and to test whether it was navigable. Nevertheless, Bering soon found he was quickly bogged down in Yakutsk; two parties sent east to find a better route to the Okhotsk Sea were both failures (the second coming far closer than it realised), and yet this was information the expedition desperately needed. Bering decided to prepare a similar land route to the one he had used on the first expedition instead, constructing huts along the route in advance. It was work, however, that was still unfinished even by the summer of 1737, such were the delays.
At Okhotsk things were little better; it was "ill-suited to be a permanent port", and Skornyakov-Pisarev was slow to construct the buildings needed. Spangberg was, however, able to ready the ships the expedition needed. By the end of 1737 the "Gabriel" had been refitted; additionally, two new ships, the "Archangel Michael" and the "Nadezhda", had been constructed and were rapidly readied for a voyage to Japan, a country with which Russia had never had contact. The same year, Bering took up residence in Okhotsk. It was the fifth year of the expedition, and the original costings now looked naive compared to the true costs of the trip. The additional costs (300,000 roubles compared to the 12,000 budgeted) brought poverty to the whole region. On 29 June 1738, Spangberg set off for the Kuril Islands with the three ships he had prepared. After he had left there were further delays, probably due to a lack of natural resources. Over the next three years, Bering himself was criticised on an increasingly regular basis (his salary had already been halved in 1737 when the originally planned four years ran out); the delays also caused friction between Bering, Chirikov (who felt unduly constrained) and Spangberg (who felt Bering was too weak in his dealings with the local peoples). The two key figures who had been so useful to Bering in St. Petersburg back in the early 1730s (Saunders and Kirilov) were now dead, and there were occasional moves to either terminate the expedition or to replace Bering. Meanwhile, a fourth ship, the "Bolsheretsk" was constructed and Spangberg (having identified some 30 Kuril Islands on his first trip) led the four ships on a second voyage, which saw the first Russians land in Japan. In August 1740, with the main, America-bound expedition almost ready, Anna Bering returned to St. Petersburg with her and Vitus' younger children. Bering would never see his wife again. Those without places on a ship also began the long journey home. As they left, a messenger arrived; the admiralty was demanding a progress update. Bering delayed, promising a partial report from Spangberg and a fuller report later.
Sea voyage, death and achievements.
With time now of the essence, the "Okhotsk" (a new construction) left for Bolsheretsk, arriving there in mid-September. Another new ship, the "St. Peter" ("Sviatoi Piotr"), captained by Bering, also left. It was accompanied by its sister creation the "St. Paul" ("Sviatoi Pavel") and the "Nadezhda". Delayed by the "Nadezhda"‍ '​ hitting a sand bank – and then being beaten by a storm, such that it was forced to stay at Bolsheretsk – the two other ships arrived in their destination, Avacha Bay in south-eastern Kamchatka, on 6 October. Several buildings had been constructed there on Bering's orders the year before, and now the explorer was able to found the port of Petropavlovsk-Kamchatsky in the bay. Over the winter, Bering recruited for the trip ahead naturalist Georg Steller and completed the report he had promised to send. At the same time, however, the murder of several Russians under Bering's command by native tribesmen prompted him to send armed men to the north, with orders not to use force if it could be avoided. Apparently it could not, because the detachment killed several native Koryaks in the settlement of Utkolotsk and enslaved the remainder, bringing them back south. Steller was horrified to see the Koryaks tortured in search of the murderers. His ethical complaints, like Chirikov's more practical ones before him, were suppressed. From Petropavlovsk, Bering led his expedition towards North America.
The expedition spotted the volcano Mount Saint Elias on 16 July 1741, where it briefly landed. His objective complete, ill and exhausted, Bering turned ship and headed back towards port. The return journey then included the discovery of Kodiak Island. A storm separated the ships, but Bering sighted the southern coast of Alaska, and a landing was made at Kayak Island or in the vicinity. Under the command of Aleksei Chirikov, the second ship discovered the shores of northwest America (Aleksander Archipelago of present-day Alaska). Steller ensured the voyage recorded the wildlife it encountered, discovering and describing several species of plant and animal native to the North Pacific and North America during the expedition (including the Steller sea cow and Steller's Jay). Bering himself was forced by adverse conditions to return, and he discovered some of the Aleutian Islands on his way back. One of the sailors died and was buried on one of these islands, and the group was named after him (as the Shumagin Islands). Suffering from scurvy like many of his crew, Bering steadily became too ill to command the ship, passing control to Sven Waxell. Storms however meant that the crew of "Saint Peter" was soon driven to refuge on an uninhabited island in the Commander Islands group ("Komandorskiye Ostrova") in the south-west Bering Sea. On 8 December 1741 Vitus Bering died on the uninhabited island near the Kamchatka Peninsula, which was later given the name Bering Island in his honour. Like 28 men of his company, Bering's death was commonly assumed to have been the result of scurvy (although this has since been contested); certainly, it had afflicted him in the final months. The situation was still dire for Bering's expedition (now headed by Waxell), many of them, including Waxell, were still ill and the "Saint Peter" was in poor condition. By April 1742 the party had ascertained that they were on an island. They decided to construct a new vessel from the remnants of the ship in order to return home. By August it was ready, successfully reaching Avacha Bay later in the month. There, the party discovered that Chirikov had led a rescue mission during 1741 that came within miles of the stranded group. Out of 77 men aboard "Sv. Piotr", only 46 survived the hardships of the expedition, which claimed its last victim just one day before coming into home port. Its builder, Starodubtsev, returned home with government awards and later built several other seaworthy ships.
Assessing the scale of Bering's achievements is difficult, given that he was neither the first Russian to sight North America (that having been completed by Gvozdev during the 1730s), nor the first Russian to pass through the strait which now bears his name (an honour which goes to the relatively unknown 17th-century expedition of Semyon Dezhnev). Reports from his second voyage were jealously guarded by the Russian administration, preventing Bering's story from being retold in full for at least a century after his death. Nonetheless, Bering's achievements, both as an individual explorer and as a leader of the second expedition are regarded as substantial. Consequently, Bering's name has since been used for the Bering Strait (named by Captain James Cook despite knowledge of Dezhnev's earlier expedition), the Bering Sea, Bering Island, Bering Glacier and the Bering Land Bridge.

</doc>
<doc id="57932" url="http://en.wikipedia.org/wiki?curid=57932" title="Battle of Culloden">
Battle of Culloden

The Battle of Culloden (Scottish Gaelic: "Blàr Chùil Lodair") was the final confrontation of the 1745 Jacobite Rising. On 16 April 1746, the Jacobite forces of Charles Edward Stuart fought loyalist troops commanded by William Augustus, Duke of Cumberland near Inverness in the Scottish Highlands. The Hanoverian victory at Culloden decisively halted the Jacobite intent to overthrow the House of Hanover and restore the House of Stuart to the British throne; Charles Stuart never mounted any further attempts to challenge Hanoverian power in Great Britain. The conflict was the last pitched battle fought on British soil.
Charles Stuart's Jacobite army consisted largely of Scottish Highlanders, as well as a number of Lowland Scots and a small detachment of Englishmen from the Manchester Regiment. The Jacobites were supported and supplied by the Kingdom of France from Irish and Scots units in the French service. A composite battalion of infantry ("Irish Picquets") comprising detachments from each of the regiments of the Irish Brigade plus one squadron of Irish cavalry in the French army served at the battle alongside the regiment of Royal Scots (Royal Ecossais) raised the previous year to support the Stuart claim. The British Government (Hanoverian loyalist) forces were mostly English, along with a significant number of Scottish Lowlanders and Highlanders, a battalion of Ulstermen and some Hessians from Germany and Austrians. The quick and bloody battle on Culloden Moor was over in less than an hour when after an unsuccessful Highland charge against the government lines, the Jacobites were routed and driven from the field.
Between 1,500 and 2,000 Jacobites were killed or wounded in the brief battle. Government losses were lighter with 50 dead and 259 wounded although recent geophysical studies on the government burial pit suggest the figure to be nearer 300. The battle and its aftermath continue to arouse strong feelings: the University of Glasgow awarded Cumberland an honorary doctorate, but many modern commentators allege that the aftermath of the battle and subsequent crackdown on Jacobitism were brutal, and earned Cumberland the sobriquet "Butcher". Efforts were subsequently taken to further integrate the comparatively wild Highlands into the Kingdom of Great Britain; civil penalties were introduced to weaken Gaelic culture and attack the Scottish clan system.
Background.
Charles Edward Stuart, known as "Bonnie Prince Charlie" or the "Young Pretender", arrived in Scotland in 1745 to incite a rebellion of Stuart sympathizers against the House of Hanover. He successfully raised forces, mainly of Scottish Highland clansmen, and slipped past the Hanoverian stationed in Scotland and defeated a force of militiamen at the Battle of Prestonpans. The city of Edinburgh was occupied, but the castle held out and most of the Scottish population remained hostile to the rebels; others, while sympathetic, were reluctant to lend overt support to a movement whose chances were unproven. The British government recalled forces from the war with France in Flanders to deal with the rebellion.
After a lengthy wait, Charles persuaded his generals that English Jacobites would stage an uprising in support of his cause. He was convinced that France would launch an invasion of England as well. His army of around 5,000 invaded England on 8 November 1745. They advanced through Carlisle and Manchester to Derby and a position where they appeared to threaten London. It is often alleged that King George II made plans to decamp to Hanover, but there is no evidence for this and the king is on record as stating that he would lead the troops against the rebels himself if they approached London. The Jacobites met only token resistance. There was, however, little support from English Jacobites, and the French invasion fleet was still being assembled. The armies of Field Marshal George Wade and of William Augustus, Duke of Cumberland, were approaching. In addition to the militia, London was defended by nearly 6,000 infantry, 700 horse and 33 artillery pieces and the Jacobites received (fictitious) reports of a third army closing on them. The Jacobite general, Lord George Murray, and the Council of War insisted on returning to join their growing force in Scotland. On 6 December 1745, they withdrew, with Charles Edward Stuart leaving command to Murray.
On the long march back to Scotland, the Highland Army wore out its boots and demanded all the boots and shoes of the townspeople of Dumfries as well as money and hospitality. The Jacobites reached Glasgow on 25 December. There they reprovisioned, having threatened to sack the city, and were joined by a few thousand additional men. They then defeated the forces of General Henry Hawley at the Battle of Falkirk Muir. The Duke of Cumberland arrived in Edinburgh on 30 January to take over command of the government army from General Hawley. He then marched north along the coast, with the army being supplied by sea. Six weeks were spent at Aberdeen training.
The King's forces continued to pressure Charles. He retired north, losing men and failing to take Stirling Castle or Fort William. But he invested Fort Augustus and Fort George in Inverness-shire in early April. Charles then took command again, and insisted on fighting a defensive action.
Hugh Rose of Kilravock entertained Charles Edward Stuart and the Duke of Cumberland respectively on 14 and 15 April 1746, before the Battle of Culloden. Charles' manners and deportment were described by his host as most engaging. Having walked out with Mr. Rose, before sitting down he watched trees being planted. He remarked, "How happy, Sir, you must feel, to be thus peaceably employed in adorning your mansion, whilst all the country round is in such commotion." Kilravock was a firm supporter of the house of Hanover, but his adherence was not solicited, nor were his preferences alluded to. The next day, the Duke of Cumberland called at the castle gate, and when Kilravock went to receive him, he bluffly observed, "So you had my cousin Charles here yesterday." Kilravock replied, "What am I to do, I am Scots", to which Cumberland replied, "You did perfectly right."
Opposing forces.
Jacobite army.
The bulk of the Jacobite army was made up of Highlanders and most of its strength was volunteers. These men made up the gentlemen (officers), cavalry and Lowland units, and as such did much of the fighting during the campaign. The clans which supported the Jacobite cause tended to be Roman Catholic and Scottish Episcopalian, while clans which tended to be Presbyterian sided more with the British government. Nearly three-quarters of the Jacobite army was composed of Highland clansmen who were either Roman Catholic or Episcopalian. The Highlanders served in the clan regiments which were recruited largely from the Highlands of Scotland.
One of the fundamental problems with the Jacobite army was the lack of trained officers. The lack of professionalism and training was readily apparent; even the colonels of the Macdonald regiments of Clanranald and Keppoch considered their men to be uncontrollable. A typical clan regiment was made up of a small minority of gentlemen (tacksmen) who would bear the "clan name", and under them the common soldiers or "clansmen" who bore a mixed bag of names. The clan gentlemen formed the front ranks of the unit and were more heavily armed than their impoverished tenants who made up the bulk of the regiment. Because they served in the front ranks, the gentlemen suffered higher proportional casualties than the common clansman. The gentlemen of the Appin Regiment suffered one quarter of those killed, and one third of those wounded from their regiment. The Jacobites started the campaign poorly armed. At the Battle of Prestonpans, some only had swords, Lochaber axes, pitchforks and scythes. Although popular imagination pictures the common highlander as being equipped with a broadsword, targe and pistol, it was only officers or gentlemen who were equipped in this way. Further illustrating this point, following the conclusion of the battle, Cumberland reported that there were 2,320 firelocks recovered from the battlefield, but only 190 broadswords. From this, it can be determined that of the roughly 1,000 Jacobites killed at Culloden, no more than one fifth carried a sword. As the campaign progressed, the Jacobites improved their equipment considerably. For instance, 1,500–1,600 stack of arms were landed in October. In consequence, by the time of the Battle of Culloden, the Jacobite army was equipped with 0.69 in calibre French and Spanish firelocks.
During the latter stage of the campaign, the Jacobites were reinforced with units of French regulars. These units, like Fitzjames' Horse, and the Irish Picquets, were drawn from the Irish Brigade (Irish units in French service). Another unit was the "Royal Écossais" ("Royal Scots"), which was a Scottish unit in French service. The majority of these troops were Irish born. Lists of prisoners at Marshalsea, Berwick and prison interviews conducted by Captain Eyre show some of these men to be English born, claiming to have been press-ganged or seized as prisoners on British ships. Fitzjames' Horse was the only Jacobite cavalry unit to fight the whole battle on horseback. Around 500 Irish Picquets in the French army fought in the battle, some of whom were thought to have been press-ganged from 6th (Guise's) Foot taken at Fort Augustus. The "Royal Écossais" also contained deserters, and the commander, Drummond, attempted to raise a second battalion after the unit had arrived in Scotland. The Jacobite artillery has been generally regarded as being ineffective in the battle. Some modern accounts claim that the Jacobite artillery suffered from having cannon with different calibres of shot. In fact, all but one of the Jacobite cannon were 3-pounders.
Government Army.
The Government army at the Battle of Culloden was made up of infantry, cavalry, and artillery. Of the army's 16 infantry battalions present, four were Scottish units and one was Irish. The officers of the infantry were from the upper classes and aristocracy, while the rank and file were made up of poor agricultural workers. On the outbreak of the Jacobite rising, extra incentives were given to lure recruits to fill the ranks of depleted units. For instance, on 6 September 1745, every recruit who joined the Guards before 24 September was given £6, and those who joined in the last days of the month were given £4. Regiments were named after their Colonel. In theory, an infantry regiment would comprise up to ten companies of up to 70 men. They would then be 815 strong, including officers. However, regiments were rarely anywhere near this large, and at the Battle of Culloden, the regiments were not much larger than about 400 men.
The Government cavalry arrived in Scotland in January 1746. They were not combat experienced, having spent the preceding years on anti-smuggling duties. A standard cavalryman had a Land Service pistol and a carbine. However, the main weapon used by the British cavalry was a sword with a 35-inch blade.
The Royal Artillery vastly out-performed their Jacobite counterparts during the Battle of Culloden. However, up until this point in the campaign, the Government artillery had performed dismally. The main weapon of the artillery was the 3-pounder. This weapon had a range of 500 yd and fired two kinds of shot: round iron and canister. The other weapon used was the Coehorn mortar. These had a calibre of 4 2⁄5 inches (11 cm).
Lead up to battle.
On 30 January, the Duke of Cumberland arrived in Scotland to take command of the government forces after the previous failures by Cope and Hawley. Cumberland decided to wait out the winter, and moved his troops northwards to Aberdeen. Around this time, the army was increased by 5,000 Hessian troops. The Hessian force, led by Prince Frederick of Hesse, took up position to the south to cut off any path of retreat for the Jacobites. The weather had improved to such an extent by 8 April that Cumberland again resumed the campaign. The government army reached Cullen on 11 April, where it was joined by six battalions and two cavalry regiments. Days later, the government army approached the River Spey, which was guarded by a Jacobite force of 2,000, made up of the Jacobite cavalry, the Lowland regiments and over half of the army's French regulars. The Jacobites quickly turned and fled, first towards Elgin and then to Nairn. By 14 April, the Jacobites had evacuated Nairn, and Cumberland camped his army at Balblair just west of the town.
The Jacobite forces of about 5,400 left their base at Inverness, leaving most of their supplies, and assembled 5 miles (8 km) to the east near Drummossie, around 12 miles (19 km) before Nairn. Charles Edward Stuart had decided to personally command his forces and took the advice of his adjutant general, Secretary O’Sullivan, who chose to stage a defensive action at Drummossie Moor, a stretch of open moorland enclosed between the walled Culloden enclosures to the North and the walls of Culloden Park to the South. Lord George Murray "did not like the ground" and with other senior officers pointed out the unsuitability of the rough moorland terrain which was highly advantageous to the Duke with the marshy and uneven ground making the famed Highland charge somewhat more difficult while remaining open to Cumberland’s powerful artillery. They had argued for a guerrilla campaign, but Charles Edward Stuart refused to change his mind.
Night attack at Nairn.
On 15 April, the government army celebrated Cumberland's twenty-fifth birthday by issuing two gallons of brandy to each regiment. At Murray's suggestion, the Jacobites tried that evening to repeat the success of Prestonpans by carrying out a night attack on the government encampment. Murray proposed that they set off at dusk and march to Nairn. Murray planned to have the right wing of the first line attack Cumberland's rear, while Perth with the left wing would attack the government's front. In support of Perth, Charles Edward Stuart would bring up the second line. The Jacobite force however started out well after dark at about 20:00. Murray led the force cross country with the intention of avoiding government outposts. This however led to very slow going in the dark. Murray's one time "aide-de-camp", James Chevalier de Johnstone later wrote, "this march across country in a dark night which did not allow us to follow any track, and accompanied with confusion and disorder". By the time the leading troop had reached Culraick, still 2 mi from where Murray's wing was to cross the River Nairn and encircle the town, there was only one hour left before dawn. After a heated council with other officers, Murray concluded that there was not enough time to mount a surprise attack and that the offensive should be aborted. O'Sullivan went to inform Charles Edward Stuart of the change of plan, but missed him in the dark. Meanwhile, instead of retracing his path back, Murray led his men left, down the Inverness road. In the darkness, while Murray led one-third of the Jacobite forces back to camp, the other two-thirds continued towards their original objective, unaware of the change in plan. One account of that night even records that Perth and Drummond made contact with government troops before realising the rest of the Jacobite force had turned home. Not long after the exhausted Jacobite forces had made it back to Culloden, reports came of the advancing government troops. By then, many Jacobite soldiers had dispersed in search of food, while others were asleep in ditches and outbuildings.
However, military historian Jeremy Black has contended that even though the Jacobite force had become disordered and lost the element of surprise the night attack remained viable, and that if the Jacobites had advanced the conditions would have made British morale vulnerable and disrupted their fire discipline.
Battle on Culloden Moor.
Early on a rainy 16 April, the well rested Government army struck camp and at about 05:00 set off towards the moorland around Culloden and Drummossie. Jacobite pickets first sighted the Government advance guard at about 08:00, when the advancing army came within 4 mi of Drummossie. Cumberland's informers alerted him that the Jacobite army was forming up about 1 mi from Culloden House—upon Culloden Moor. At about 11:00 the two armies were within sight of one another with about 2 mi of open moorland between them. As the Government forces steadily advanced across the moor, the driving rain and sleet blew from the north-east into the faces of the exhausted Jacobite army.
Opening moves.
The Jacobite army was originally arrayed between the corners of Culloden and Culwhiniac parks (from left to right): the three Macdonald battalions; a small one of Chisholms; another small one of Macleans and Maclachlans; Lady Mackintosh and Monaltrie's regiments; Lord Lovat's Regiment; Ardsheal's Appin Stewarts; Lochiel's Regiment; and three battalions of the Atholl Brigade. Murray who commanded the right wing, however became aware of the Leanach enclosure that lay ahead of him would become an obstacle in the event of a Jacobite advance. Without any consultation he then moved the brigade down the moor and formed into three columns. It seems probable that Murray intended to shift the axis of the Jacobite advance to a more northerly direction, thus having the right wing clear the Leanach enclosure and possibly taking advantage of the downward slope of the moor to the north.
However, the Duke of Perth seems to have misinterpreted Murray's actions as only a general advance, and the Macdonalds on the far left simply ignored him. The result was the skewing of the Jacobite front line, with the (left wing) Macdonalds still rooted on the Culloden Parks wall and the (right wing) Atholl Brigade halfway down the Culwhiniac Parks wall. In consequence, large gaps immediately appeared in the severely over-stretched Jacobite lines. A shocked Sullivan had no choice but to position the meagre 'second line' to fill the gaps. This second line was (left to right): the Irish Picquets; the Duke of Perth's Regiment; Glenbuchat's; Lord Kilmarnock's Footguards; John Roy Stuart's Regiment; two battalions of Lord Ogilvy's Regiment; the "Royal Écossais"; two battalions of Lord Lewis Gordon's Regiment. Farther back were cavalry units. On the left were: Lord Strathallan's Horse Bagot's Hussars and possibly Balmerino's Lifeguards. On the right were Lord Elcho's Lifeguards and Fitzjames's Horse. And in the centre was Charles Edward Stuart's tiny escort made up of Fitzjames's Horse and Lifeguards. When Sullivan's redeployment was completed Perth's and Glenbuchat's regiments were standing on the extreme left wing and John Roy Stuart's was standing beside Ardsheal's.
Cumberland brought forward the 13th and 62nd to extend his first and second lines. At the same time, two squadrons of Kingston's Horse were brought forward to cover the right flank. These were then joined by two troops of Cobham's 10th Dragoons. While this was taking place, Hawley began making his way through the Culwhiniac Parks intending to outflank the Jacobite right wing. Anticipating this, the two battalions of Lord Lewis Gordon's regiment had lined the wall. However, since the Government dragoons stayed out of range, and the Jacobites were partly in dead ground they moved back and formed up on a re-entrant at Culchunaig, facing south and covering the army's rear. Once Hawley had led the dragoons through the Parks he deployed them in two lines beneath the Jacobite guarded re-entrant. By this time the Jacobites were guarding the re-entrant from above with four battalions of Lord Lewis Gordon's and Lord Ogilvy's regiments, and the combined squadron of Fitzjames's Horse and Elcho's Lifeguards. Unable to see behind the Jacobites above him, Hawley had his men stand and face the enemy.
Over the next twenty minutes, Cumberland's superior artillery battered the Jacobite lines, while Charles, moved for safety out of sight of his own forces, waited for the Government forces to move. Inexplicably, he left his forces arrayed under Government fire for over half an hour. Although the marshy terrain minimized casualties, the morale of the Jacobites began to suffer. Several clan leaders, angry at the lack of action, pressured Charles to issue the order to charge. The Clan Chattan was first of the Jacobite army to receive this order, but an area of boggy ground in front of them forced them to veer right so that they obstructed the following regiments and the attack was pushed towards the wall. The Jacobites advanced on the left flank of the Government troops, but were subjected to volleys of musket fire and the artillery which had switched from roundshot to grapeshot.
Highland charge.
Despite this, many Jacobites reached the Government lines, and for the first time a battle was decided by a direct clash between charging highlanders and formed redcoats equipped with muskets and socket bayonets. The brunt of the Jacobite impact was taken by only two Government regiments—Barrell's 4th Foot and Dejean's 37th Foot. Barrell's regiment lost 17 and suffered 108 wounded, out of a total of 373 officers and men. Dejean's lost 14 and had 68 wounded, with this unit's left wing taking a disproportionately higher number of casualties. Barrell's regiment temporarily lost one of its two colours. Major-General Huske, who was in command of the Government second line, quickly organised the counter attack. Huske ordered forward all of Lord Sempill's Fourth Brigade which had a combined total of 1,078 men (Sempill's 25th Foot, Conway's 59th Foot, and Wolfe's 8th Foot). Also sent forward to plug the gap was Bligh's 20th Foot, which took up position between Sempill's 25th and Dejean's 37th. Huske's counter formed a five battalion strong horseshoe-shaped formation which trapped the Jacobite right wing on three sides.
 Poor Barrell's regiment were sorely pressed by those desperadoes and outflanked. One stand of their colours was taken; Collonel Riches hand cutt off in their defence... We marched up to the enemy, and our left, outflanking them, wheeled in upon them; the whole then gave them 5 or 6 fires with vast execution, while their front had nothing left to oppose us, but their pistolls and broadswords; and fire from their center and rear, (as, by this time, they were 20 or 30 deep) was vastly more fatal to themselves, than us.
 — Captain-Lieutenant James Ashe Lee of Wolfe's 8th Foot.
Located on the Jacobite extreme left wing were the Macdonald regiments. Popular legend has it that these regiments refused to charge when ordered to do so, due to the perceived insult of being placed on the left wing. Even so, due to the skewing of the Jacobite front lines, the left wing had a further 200 m of much boggier ground to cover than the right. When the Macdonalds charged, their progress was much slower than that of the rest of the Jacobite forces. Standing on the right of these regiments were the much smaller units of Chisholms and the combined unit of Macleans and Maclachlans. Every officer in the Chisholm unit was killed or wounded and Col. Lachlan Maclachlan, who led the combined unit of Macleans and Maclachlans, was gruesomely killed by a cannon shot. As the Macdonalds suffered casualties they began to give way. Immediately Cumberland then pressed the advantage, ordering two troops of Cobham's 10th Dragoons to ride them down. The boggy ground however impeded the cavalry and they turned to engage the Irish Picquets whom Sullivan had brought up in an attempt to stabilise the deteriorating Jacobite left flank.
Jacobite collapse and rout.
With the collapse of the left wing, Murray brought up the "Royal Écossais" and Kilmarnock's Footguards who were still at this time unengaged. However, by the time they had been brought into position, the Jacobite army was in rout. The "Royal Écossais" exchanged musket fire with Campbell's 21st and commenced an orderly retreat, moving along the Culwhiniac enclosure in order to shield themselves from artillery fire. Immediately the half battalion of Highland militia commanded by Captain Colin Campbell of Ballimore which had stood inside the enclosure ambushed the "Royal Écossais". Hawley had previously left this Highland unit behind the enclosure, with orders to avoid contact with the Jacobites, to limit any chance of a friendly fire incident. In the encounter Campbell of Ballimore was killed along with five of his men. The result was that the "Royal Écossais" and Kilmarnock's Footguards were forced out into the open moor and were rushed at by three squadrons of Kerr's 11th Dragoons. The fleeing Jacobites must have put up a fight for Kerr's 11th recorded at least 16 horses killed during the entirety of the battle. The Irish picquets bravely covered the Highlanders retreat from the battlefield and prevented a massacre. This action cost half of the 100 casualties suffered in the battle. The "Royal Écossais" appear to have retired from the field in two wings. One part of the regiment surrendered upon the field after suffering 50 killed or wounded, but their colours were not taken and a large number retired from the field with the Jacobite Lowland regiments.
This stand by the "Royal Écossais" may have given Charles Edward Stuart the time to make his escape. At the time when the Macdonald regiments were crumbling and fleeing the field, Stuart seems to have been rallying Perth's and Glenbuchat's regiments when O'Sullivan rode up to Captain Shea who commanded Stuart's bodyguard: "Yu see all is going to pot. Yu can be of no great succor, so before a general deroute wch will soon be, Seize upon the Prince & take him off...". Shea then led Stuart from the field along with Perth's and Glenbuchat's regiments. From this point on the fleeing Jacobite forces were split into two groups: the Lowland regiments retired in order southwards, making their way to Ruthven Barracks; the Highland regiments however were cut off by the Government cavalry, and forced to retreat down the road to Inverness. The result was that they were a perfect target for the Government dragoons. Bland led the charge against the fleeing Highlanders, giving "Quarter to None but about Fifty French Officers and Soldiers He picked up in his Pursuit".
Conclusion: casualties and prisoners.
The total of Jacobite casualties during the battle has been estimated at about 1,500–2,000 killed or wounded. Cumberland's official list of prisoners taken includes 154 Jacobites and 222 "French" prisoners (men from the 'foreign units' in the French service). Added to the official list of those apprehended were 172 of the Earl of Cromartie's men, captured after a brief engagement the day before near Littleferry. In striking contrast to the Jacobite losses, the Government forces suffered 50 dead and 259 wounded, although a high proportion of those recorded as wounded are likely to have died of their wounds. For example, only 29 out of 104 wounded from Barrell's 4th Foot survived to claim pensions. All six of the artillerymen recorded as wounded died. The only Government casualty of high rank was Lord Robert Kerr, the son of William Kerr, 3rd Marquess of Lothian.
Aftermath.
Collapse of the Jacobite campaign.
As the first of the fleeing Highlanders approached Inverness they were met by a battalion of Frasers led by the Master of Lovat. Tradition states that the Master of Lovat immediately about-turned his men and marched down the road back towards Inverness, with pipes playing and colours flying. There are however varying traditions as to what happened at the bridge which spans the River Ness. One tradition is that the Master of Lovat intended to hold the bridge until he was persuaded against it. Another is that the bridge was seized by a party of Argyll Militia who were involved in a skirmish when blocking the crossing of retreating Jacobites. While it is almost certain there was a skirmish upon the bridge, it has been proposed that the Master of Lovat shrewdly switched sides and turned upon the fleeing Jacobites. Such an act would explain his remarkable rise in fortune in the years that followed.
Following the battle, the Jacobites' Lowland units headed south, towards Corrybrough and made their way to Ruthven Barracks, while their Highland units headed north, towards Inverness and on through to Fort Augustus. There they were joined by Barisdale's Macdonalds and a small battalion of MacGregors. The roughly 1,500 men who assembled at Ruthven Barracks received orders from Charles Edward Stuart to the effect that all was lost and to "shift for himself as best he could". Similar orders must have been received by the Highland units at Fort Augustus. By 18 April the Jacobite army was disbanded. Officers and men of the units in the French service made for Inverness, where they surrendered as prisoners of war on 19 April. The rest of the army broke up, with men heading for home or attempting to escape abroad.
Some ranking Jacobites made their way to Loch nan Uamh, where Charles Edward Stuart had first landed at the outset of the campaign in 1745. Here on 30 April they were met by the two French frigates—the "Mars" and "Bellone". Two days later the French warships were spotted and attacked by the smaller Royal Navy sloops—the "Greyhound", "Baltimore", and "Terror". The result was the last real battle in the campaign. During the six hours in which the ferocious sea-battle raged the Jacobites recovered cargo on the beach which had been landed by the French ships. In all £35,000 of gold was recovered along with supplies. Invigorated by the vast amounts of loot and visible proof that the French had not deserted them, the group of Highland chiefs decided to prolong the campaign. On 8 May, nearby at Murlaggan, Lochiel, Lochgarry, Clanranald and Barisdale all agreed to rendezvous at Invermallie on 18 May. The plan was that there they would be joined by the what remained of Keppoch's men and Cluny Macpherson's regiment (which did not take part in the battle at Culloden). However, things did not go as planned. After about a month of relative inactivity, Cumberland moved his regulars into the Highlands. On 17 May three battalions of regulars and eight Highland companies reoccupied Fort Augustus. The same day the Macphersons surrendered. On the day of the planned rendezvous, Clanranald never appeared and Lochgarry and Barisdale only showed up with about 300 combined (most of whom immediately dispersed in search of food). Lochiel, who commanded possibly the strongest Jacobite unit at Culloden, was only able to muster about 300. The following morning Lochiel was alerted that a body of Highlanders was approaching. Assuming they were Barisdale's Macdonalds, Locheil waited until they were identified as Loudoun's by the "red crosses in their bonnets". Locheil's men dispersed without fighting. The following week the Government launched punitive expeditions into the Highlands which continued throughout the summer.
Following his flight from the battle, Charles Edward Stuart made his way towards the Hebrides with some supporters. By 20 April Stuart had reached Arisaig on the west coast of Scotland. After spending a few days with his close associates, Stuart left most of them in a small boat and made his way to the island of Benbecula in the Outer Hebrides. From there he travelled to Scalpay, between the islands Harris and Lewis, and from there made his way to Stornoway. For five months Stuart criss-crossed the Hebrides, constantly pursued by Government supporters and under threat from local lairds who were tempted to betray him for the £30,000 upon his head. During this time he met Flora Macdonald, who famously aided him in a narrow escape to Skye. Finally, on 19 September, Stuart reached Borrodale on Loch nan Uamh in Arisaig, where his party boarded two small French ships, which ferried them to France. He never returned to Scotland.
Repercussions and persecution.
The morning following the Battle of Culloden, Cumberland issued a written order reminding his men that "the public orders of the rebels yesterday was to give us no quarter". Cumberland alluded to the belief that such orders had been found upon the bodies of fallen Jacobites. In the days and weeks that followed, versions of the alleged orders were published in the "Newcastle Journal" and the "Gentleman's Journal". Today only one copy of the alleged order to "give no quarter" exists. It is however considered to be nothing but a poor attempt of forgery, for it is neither written nor signed by Murray, and it appears on the bottom half of a copy of a declaration published in 1745. In any event, Cumberland's order was not carried out for two days, after which contemporary accounts report then that for the next two days the moor was searched and all those wounded were put to death. The orders issued by Lord George Murray for the conduct of the aborted night attack in the early hours of 16 April suggest that it would have been every bit as merciless. The instructions were to use only swords, dirks and bayonets, to overturn tents locate "a swelling or bulge in the fallen tent, there to strike and push vigorously". In total, over 20,000 head of livestock, sheep, and goats were driven off and sold at Fort Augustus, where the soldiers split the profits.
While in Inverness, Cumberland emptied the gaols that were full of people imprisoned by Jacobite supporters, replacing them with Jacobites themselves. Prisoners were taken south to England to stand trial for high treason. Many were held on hulks on the Thames or in Tilbury Fort, and executions took place in Carlisle, York and Kennington Common. The common Jacobite supporters fared better than the ranking individuals. In total, 120 common men were executed, one third of them being deserters from the British Army. The common prisoners drew lots amongst themselves and only one out of twenty actually came to trial. Although most of those who did stand trial were sentenced to death, almost all of these had their sentences commuted to transportation to the British colonies for life. In all, 936 men were thus transported, and 222 more were banished. Even so, 905 prisoners were actually released under the Act of Indemnity which was passed in June 1747. Another 382 obtained their freedom by being exchanged for prisoners of war who were held by France. Of the total 3,471 prisoners recorded nothing is known of the fate of 648. The high ranking "rebel lords" were executed on Tower Hill in London.
Following up on the military success won by their forces, the British Government enacted laws to incorporate Scotland—specifically the Scottish Highlands—within the rest of Britain. Members of the Episcopalian clergy were required to give oaths of allegiance to the reigning Hanoverian dynasty. The Abolition of Heritable Jurisdictions Act of 1747 ended the hereditary right of landowners to govern justice upon their estates through barony courts. Previous to this act, feudal lords (which included clan chiefs) had considerable judicial and military power over their followers—such as the oft quoted power of "pit and gallows". Lords who were loyal to the Government were greatly compensated for the loss of these traditional powers, for example the Duke of Argyll was given £21,000. Those lords and clan chiefs who had supported the Jacobite rebellion were stripped of their estates and these were then sold and the profits were used to further trade and agriculture in Scotland. The forfeited estates were managed by factors who were much more efficient than a hereditary chief could ever have been. Anti-clothing measures were taken against the highland dress by an Act of Parliament in 1746. The result was that the wearing of tartan was banned except as a uniform for officers and soldiers in the British Army and later landed men and their sons.
Culloden battlefield today.
Today, a visitor centre is located near the site of the battle. This centre was first opened in December 2007, with the intention of preserving the battlefield in a condition similar to how it was on 16 April 1746. One difference is that it currently is covered in shrubs and heather; during the 18th century, however, the area was used a common grazing ground, mainly for tenants of the Culloden estate. Those visiting can walk the site by way of footpaths on the ground and can also enjoy a view from above on a raised platform. Possibly the most recognisable feature of the battlefield today is the 20 ft tall memorial cairn, erected by Duncan Forbes in 1881. In the same year Forbes also erected headstones to mark the mass graves of the clans. The thatched roofed farmhouse of Leanach which stands today dates from about 1760; however, it stands on the same location as the turf-walled cottage that probably served as a field hospital for Government troops following the battle. A stone, known as "The English Stone", is situated west of the Old Leanach cottage and is said to mark the burial place of the Government dead. West of this site lies another stone, erected by Forbes, marking the place where the body of Alexander McGillivray of Dunmaglass was found after the battle. A stone lies on the eastern side of the battlefield that is supposed to mark the spot where Cumberland directed the battle. The battlefield has been inventoried and protected by Historic Scotland under the Historic Environment (Amendment) Act 2011.
Since 2001, the site of the battle has undergone topographic, geophysical, and metal detector surveys in addition to archaeological excavations. Interesting finds have been made in the areas where the fiercest fighting occurred on the Government left wing, particularly where Barrell's and Dejean's regiments stood. For example, pistol balls and pieces of shattered muskets have been uncovered here which indicate close quarters fighting, as pistols were only used at close range and the musket pieces appear to have been smashed by pistol/musket balls or heavy broadswords. Finds of musket balls appear to mirror the lines of men who stood and fought. Some balls appear to have been dropped without being fired, some missed their targets, and others are distorted from hitting human bodies. In some cases it may be possible to identify whether the Jacobites or Government soldiers fired certain rounds, because the Jacobite forces are known to have used a large quantity of French muskets which fired a slightly smaller calibre shot than that of the British Army's "Brown Bess". Analysis of the finds confirms that the Jacobites used muskets in greater numbers than has traditionally been thought. Not far from where the hand-to-hand fighting took place, fragments of mortar shells have been found. Though Forbes's headstones mark the graves of the Jacobites, the location of the graves of about sixty Government soldiers is unknown. The recent discovery of a 1752 silver Thaler, from the Duchy of Mecklenburg-Schwerin, may however lead archaeologists to these graves. A geophysical survey, directly beneath the spot where the coin was found, seems to indicate the existence of a large rectangular burial pit. It is thought possible that the coin was dropped by a soldier who once served on the continent, while he visited the graves of his fallen comrades.
Order of battle: Culloden, 16 April 1746.
Jacobite army.
Charles Edward Stuart
Colonel John William Sullivan
Government Army.
Captain-General: HRH Duke of Cumberland
Commander-in-Chief North Britain: Lieutenant-General Henry Hawley
The Battle of Culloden in art.
The Battle of Culloden and consequent imprisonment and execution of the Jacobite prisoners of war is depicted in the song ("Where the Big Water Fleet flows") by the Czech Celtic-rock band .
References.
Bibliography.
</dl>
Further reading.
"The Battle of Culloden" (TV Movie, BBC, 1964), http://www.imdb.com/title/tt0057982/

</doc>
<doc id="57933" url="http://en.wikipedia.org/wiki?curid=57933" title="Bonnie Prince Charlie (disambiguation)">
Bonnie Prince Charlie (disambiguation)

Bonnie Prince Charlie may refer to:-

</doc>
<doc id="57934" url="http://en.wikipedia.org/wiki?curid=57934" title="Okhotsk">
Okhotsk

Okhotsk (Russian: Охотск; ]) is an urban locality (a work settlement) and the administrative center of Okhotsky District of Khabarovsk Krai, Russia, located at the mouth of the Okhota River on the Sea of Okhotsk. Population:  (2010 Census);  (2002 Census);  (1989 Census)
History.
It was the main Russian base on the Pacific coast from about 1650 to 1860, but lost its importance after the Amur Acquisition in 1860. It is located at the east end of the Siberian River Routes on the Sea of Okhotsk where the Okhota and the Kukhtuy Rivers join to form a poor but usable harbor. 
In 1639 the Russians first reached the Pacific 65 miles southeast at the mouth of the Ulya River. In 1647 Semyon Shelkovnikov built winter quarters at Okhotsk. In 1649 a fort was built (Kosoy Ostrozhok). In 1653 Okhotsk was burned by the local Lamuts. Although the Russian pioneers were skilled builders of river boats they lacked the knowledge and equipment to build seagoing vessels which meant that Okhotsk remained a coastal settlement and not a port. In 1682 Okhotsk had eight dwellings and five other buildings. When the Russians entered the Kamchatka Peninsula they had to travel overland from the north. 
In 1714, Peter the Great sent a party of shipbuilders to Okhotsk to allow faster access to the furs of Kamchatka. In 1715, they built the "Vostok" and in 1716–17 Kozma Sokolov sailed it to Kamchatka. For the next 145 years Okhotsk was the main Russian seaport on the Pacific, supplying Kamchatka and other coastal settlements. In 1731 the Siberian Military Flotilla was established here. In 1736, Okhotsk was moved two miles downstream to a spit of land at the mouth of the Okhota, converting the "ostrog" into a proper port. Vitus Bering's two Pacific expeditions (1725–1729 and 1733–1742) brought in large numbers of people and the first scholars and expert sailors and led to a great deal of building. In 1742 there were 57 buildings, 45 other buildings in the Bering's "expedition settlement" and eight ships in the harbor. Anton de Vieira, of Portuguese origin (son of a Jewish father and Christian mother), was the town's governor at that time. From 1737 to 1837 there was a salt works several miles west on the coast that produced 14–36 tons annually. In 1827 it was worked by 150 exiles and about 100 guards and overseers.
Bering's men found valuable sea otters east of Kamchatka. Fur hunters began island-hopping along the Aleutian Islands. Furs were brought back to Okhotsk and carried inland, mostly to be sold to the Chinese at Kyakhta. The Russian-American Company was founded in 1799 with its base at Okhotsk. This brought in more money. In 1822 the English traveler Captain John Cochrane ranked Okhotsk just after Barnaul as the neatest, cleanest and most pleasant town he had seen in Siberia.
From at least 1715 it was clear that Okhotsk was a poor site. In addition to the difficult track inland, (see Okhotsk Coast) the harbor was poor and the short growing season and lack of plowland meant that food had to be imported. Around 1750 there were only 37 peasant families and a number of Yakut cattlemen. There was so little pasture in the area that pack horses sometimes had to be returned to Yakutsk unloaded. The harbor was ice-free from May to November but the sailing season was only four months from June through September. The town was built on a low narrow spit blocking the mouths of the two rivers. The harbor inside the spit was large, but three quarters of it was a mud flat during low water. Large ships could only cross the bar on an incoming or outgoing high tide and sailing ships sometimes had to wait for days for the wind to blow in the right direction. Ice-choked water during the spring breakup frequently flooded the town (20 times from 1723 to 1813), as did high surf on a number of occasions. In 1810 the Okhota, its mouth jammed by ice, cut a new channel through the spit and isolated the townsite. In 1815 the town was moved to the spit east of the harbor mouth. Goods now had to be unloaded and barged across the harbor. Because the harbor was shallow, Yakuts had to wade with loads from shore to barge. Fresh water had to be fetched from two and a half miles away. Goods could not be brought down along the Kukhtui River because of swamps. 
In 1840 Vasily Zavoyko became head of the Russian-America Company post at Okhotsk and decided to move RAC post south to Ayan. This was done in 1845. The Yakutsk-Ayan Track was built and then rebuilt in 1852 at a cost of 20,000 rubles. In 1849 Siberian governor Nikolay Muravyov-Amursky decided to move the Siberian Flotilla to Petropavlovsk-Kamchatsky and other government facilities to Ayan. The Amur Acquisition in 1860 shifted most things south. From 1870 Okhotsk was supplied form Nikolayevsk-on-Amur. In 1867 Russian America was sold to the United States. The population of Okhotsk declined from 1,660 in 1839 to 100 in 1865.
Okhotsk was of some military importance during the Russian Civil War, when the White army generals Vasily Rakitin and Anatoly Pepelyayev used it as their place of arms in the Far East.
Okhotsk was also a launch site of sounding rockets between 1981 and 2005. The rockets reached altitudes of up to 1,000 km .
The importance and population of Okhotsk sharply declined following the demise of the Soviet Union.
Transportation.
Okhotsk is served by the Okhotsk Airport.
Climate.
Okhotsk has a subarctic climate (Köppen climate classification "Dwc") with very cold, dry winters and mild, wet summers.

</doc>
<doc id="57938" url="http://en.wikipedia.org/wiki?curid=57938" title="Petropavlovsk">
Petropavlovsk

Petropavlovsk may refer to:

</doc>
<doc id="57939" url="http://en.wikipedia.org/wiki?curid=57939" title="Petropavlovsk, Russia">
Petropavlovsk, Russia

Petropavlovsk (Russian: Петропавловск) is the name of several inhabited localities in Russia.

</doc>
<doc id="57941" url="http://en.wikipedia.org/wiki?curid=57941" title="Fafhrd and the Gray Mouser">
Fafhrd and the Gray Mouser

Fafhrd and the Gray Mouser are two sword-and-sorcery heroes appearing in stories written by American author Fritz Leiber. They are the protagonists of what are probably Leiber's best-known stories. One of his motives in writing them was to have a couple of fantasy heroes closer to true human nature than the likes of Howard's Conan the Barbarian or Burroughs's Tarzan.
Fafhrd is a very tall (seven feet) and strong northern barbarian, skilled at both swordsmanship and singing; the Mouser is a small (not much more than five feet) mercurial thief, gifted and deadly at swordsmanship (often using a sword in one hand and a long dagger in the other), and a former wizard's apprentice who retains some skill at magic. Fafhrd talks like a romantic, but his strong practicality usually wins through, while the cynical-sounding Mouser is prone to showing strains of sentiment at unexpected times. Both are rogues, existing within a decadent world where to be so is a requirement of survival. They spend a lot of time drinking, feasting, wenching, brawling, stealing, and gambling, and are seldom fussy about who hires their swords. But they are humane and—most of all—relish true adventure.
The characters were loosely modeled upon Leiber himself and his friend Harry Otto Fischer. Fischer initially created them in a letter to Leiber in September 1934, naming at the same time their home city of Lankhmar. In 1936, Leiber finished the first Fafhrd and Gray Mouser novella, "Adept's Gambit", and began work on a second, "The Tale of the Grain Ships." At the same time, Fischer was writing the beginning of "The Lords of Quarmall." "Adept's Gambit" would not see publication until 1947, while "The Lords of Quarmall" would be finished by Leiber and published in 1964 and "The Tale of the Grain Ships" would become the prototype for "Scylla's Daughter" (1961) and, later, the novel "The Swords of Lankhmar" (1968).
The stories of the two were only loosely connected until the 1960s, when Leiber organized them chronologically and added additional material in preparation for paperback publication. Starting as young men, the two separately meet their female lovers, meet each other, and lose both their lovers in the same night, which explains both their friendship and the arrested adolescence of their lifestyles. However, in later stories, the two mature, learn leadership, and eventually settle down with new female partners on the Iceland-like Rime Isle. Leiber contemplated continuing the series beyond this point, but died prior to doing so.
Setting.
The majority of the stories are set in the fictional world of Nehwon ("ne hwon", or 'Nowhen' backwards: contrasted to Samuel Butler's 1872 'Erehwon' (Nowhere)). Many of them take place in and around its greatest city, Lankhmar. It is described as "a world like and unlike our own". Theorists in Nehwon believe that it may be shaped like a bubble, floating in the waters of eternity.
Technology in Nehwon varies between the Iron Age and the medieval. Leiber wrote of Lankhmarts: "They may be likened to the Romans or be thought of as, if I may use such a term, southern medievals." About his Eastern Lands, he wrote "think of Saracens, Arabs, Parthians, Assyrians even. They ride the camel and elephant, and use the bow extensively."
The series includes many bizarre and outlandish characters. The two who most influence — and, some would say, cause the most trouble for — Fafhrd and the Gray Mouser are their sorcerous advisers, Ningauble of the Seven Eyes and Sheelba of the Eyeless Face. These two lead the two heroes into some of their most interesting and dangerous adventures.
Publication history.
The first story appeared in "Unknown" in 1939 and the last in "The Knight and Knave of Swords" in 1988. Although Leiber credited his friend, Harry Otto Fischer, with the original concepts for the characters, it was Leiber who wrote nearly all the stories. 10,000 words of "The Lords of Quarmall" were penned by Fischer early in the development of the series; the story was completed by Leiber in 1964. Fischer also wrote "The Childhood and Youth of the Gray Mouser", published in 1978. The stories' style and tone vary considerably, but nearly all contain an often dark sense of humor, which ranges from the subtle and character-based to the Pythonesque. The earlier tales owe as much to Clark Ashton Smith as to Robert E. Howard. 
The stories have been collected in the so-called "Swords" series:
In 2009, Benjamin Szumskyj's "Strange Wonders" included the first few chapters of "The Tale of the Grain Ships," written in the 1930s. This unfinished fragment depicts the Gray Mouser in Rome during the reign of the Emperor Claudius.
Omnibus editions.
Several omnibus editions have also been published:
Comics adaptations.
In 1972, Fafhrd and the Mouser began their comics career, appearing in "Wonder Woman" #202 alongside the title character and Catwoman in a story scripted by award-winning SF writer Samuel R. Delany. In 1973, DC Comics began an ongoing series, "Sword of Sorcery", featuring the duo. The title was written by Denny O'Neil and featured art by Howard Chaykin, Walt Simonson and Jim Starlin; the well-received title ran only five issues. Stories included adaptations of "The Price of Pain-Ease", "Thieves' House", "The Cloud of Hate", and "The Sunken Land", as well as original stories.
In 1991, Epic Comics published a four-issue comic book adaptation of seven of the stories: "Ill Met in Lankhmar" (issue 1), "The Circle Curse" and "The Howling Tower" (issue 2), "The Price of Pain Ease" and "Bazaar of the Bizarre" (issue 3), and "Lean Times in Lankhmar" and "When the Sea King's Away" (issue 4). The comics were scripted by Howard Chaykin, who had drawn several issues of the earlier DC title, and pencilled by Mike Mignola, whose "Hellboy" comic book often has a similar feel to Leiber's work. Mignola also did the jacket covers and interior art for the White Wolf collection. This series was collected by Dark Horse Comics in a trade paperback collection published in March 2007.
Marvel Comics created their own version of Fafhrd and the Gray Mouser, when they introduced the Vanir Fafnir and his companion Blackrat to the Conan comics. The pairs of characters were very much alike and Roy Thomas, who wrote the original Conan comics, made no secret that it was his intention to create characters that were a tribute to Fritz Leiber's creations.
Games.
In 1937, Leiber and his college friend Harry Otto Fischer created a complex wargame set within the world of Nehwon, which Fischer had helped to create. Later, they created a simplified board game entitled simply "Lankhmar" which was released by TSR in 1976. This is a rare case of a game adaptation written by the creators of the stories that the game is based on.
Nehwon, and some of its more interesting inhabitants, are described in the early Dungeons and Dragons supplement "Deities and Demigods", and the stories themselves were a significant influence on the Dungeons and Dragons role playing game.
In 1986 Fafhrd and the Gray Mouser were featured in a 1-on-1 Adventure Gamebook set, "Dragonsword of Lankhmar". One player controlled Fafhrd and the Gray Mouser, who were trying to find a magical sword beneath an altar (just which one, they were not sure) in Lankhmar. The other player controlled assassins from the local thieves' guild, who were trying to kill the famous rogues for operating in the city without permission from the guild.
Ningauble and Sheelba.
Ningauble of the Seven Eyes and Sheelba of the Eyeless Face are two wizards who serve as patrons for Fafhrd and the Mouser. Patron warlock of Fafhrd, Ningauble is so named due to his seven (sometimes only six) glowing eyes, seen roving within, and sometimes projecting from, the hood of his cloak. Along with the Gray Mouser's patron warlock Sheelba, Ningauble often sends his hapless minion on ludicrous missions such as recovering the mask of Death or to steal the very stars from the highest mountain. Ningauble's mysterious cavern has obscure space-time linkages which permit Fafhrd and the Mouser to be sent to other worlds. Ningauble is referred to as the "gossiper of the gods", for his fondness for stories of an unusual nature (whether or not they are true seems irrelevant) and his sometimes bizarre spies and informants. Ningauble is a mysterious being with a manipulative character, as described in this passage from "Adept's Gambit:"
Some said that Ningauble had been created by the Elder Gods for men to guess about and to sharpen their imaginations for even tougher riddles. None knew whether he had the gift of foresight, or whether he merely set the stage for future events with such a bewildering cunning that only an efreet or an adept could evade acting the part given him.
The relationship between Fafhrd and Ningauble of the Seven Eyes is captured well in this exchange from "The Swords of Lankhmar:"
Ningauble shrugged his cloaked, bulbous shoulders. "I thought you were a brave man, addicted to deeds of derring-do."
Fafhrd cursed sardonically, then demanded, "But even if I should go clang those rusty bells, how can Lankhmar hold out until then with her walls breached and the odds fifty to one against her?"
"I'd like to know that myself," Ningauble assured him.
"And how do I get to the temple when the streets are crammed with warfare?"
Ningauble shrugged once again. "You're a hero. You should know."
The Mouser's patron, Sheelba of the Eyeless Face is named for the featureless darkness within his hood. In contrast to Ningauble's love of often pointless storytelling, Sheelba is taciturn, choosing his words as if they were valuables to be disbursed parsimoniously. That the stoic Fafhrd is paired with the voluble Ningauble, while the story-loving Mouser with the laconic Sheelba is doubly ironic. Sheelba's sigil is an empty oval (presumably signifying an empty hooded face).
Sheelba's gender is ambiguous: Harry Fischer, who first conceived of the character, claimed Sheelba was female, while to Fischer's surprise Leiber referred to Sheelba as male beginning in "The Swords of Lankhmar". In fact, Leiber refers to Sheelba as "he" throughout the six books of the series, switching to "she" for the first time only in the last book, The Knight and Knave of Swords, without explanation. Leiber's friend, Frederick MacKnight, who introduced Leiber and Fischer and was involved in the earliest days of the characters, called Sheelba "she-he (or it)". Fischer may have created Sheelba as a tribute to his wife Martha.
Sheelba's house is a small hut which strides about the swamps not far from Lankhmar on five chicken leg-like posts, which bend and scuttle like the legs of a great crab or spider. Sheelba's hut is similar in description to the Russian legend of the witch Baba Yaga, which is referenced in other Leiber works such as "The Wanderer", where Baba Yaga is the name of a lunar lander.
Weapons of Fafhrd and the Gray Mouser.
Fafhrd commonly uses a sword which he names Graywand, a two-hand sword that he's able to use one-handed too. He also carries a poignard named Heartseeker and a short hand-axe which has never been named. For combat at a distance, he often carries a bow and arrow which he wields effectively even while on horseback or at sea. The Mouser - in an episode defined "the best swordsman in the World" - also fights with a pair of weapons: a "slim, curving" sword called Scalpel and a dagger called Cat's Claw, the latter usually hidden in the small of the Mouser's back, and the original of which had a very subtle curve. (It was a straight-bladed weapon by the events of "Lean Times in Lankhmar".) As the pair are often divested of their property, these are names they apply to any of their appropriate weapons and not necessarily names of specific ones. They are not magic weapons: both the wielders are just very able to use them. The Mouser is also an expert with the sling.
References in other works.
Joanna Russ was familiar with and appreciative of the Fafhrd and the Gray Mouser series, and in addition to critical reviews of Leiber, also referenced them in her own fiction, referencing Fafhrd in at least one short story in her "The Adventures of Alyx" sequence as one of Alyx's former lovers in "The Adventuress" (1968; aka "Bluestocking"). Leiber then included Alyx in two Fafhrd and the Gray Mouser stories, "The Two Best Thieves in Lankhmar" (1968) and "Under the Thumbs of the Gods" (1975).
In Terry Pratchett's "The Colour of Magic", Fafhrd and the Gray Mouser are parodied as Bravd and the Weasel. Although Ankh-Morpork bears more than a passing resemblance to Lankhmar, Pratchett, known for the use of pastiche in his early works, has been quoted as not intending a direct takeoff. Some of the features of similarity (e.g. a thieves' guild, and a general air of degeneracy) may instead be common tropes of fantasy literature, although it could be argued, especially in the case of the thieves' guild, that many of the tropes in question originated with Leiber.
An issue of Conan the Barbarian written by Roy Thomas and drawn by Barry Smith features two thieves called Fafnir and Blackrat. Fafnir appears to be killed in their encounter with Conan, but returns in later issues of the comic.
In Issue #77 and #78 of Vertigo Comic's "Fables", characters Freddy (Fafhrd) and Mouse (Gray Mouser) are incorporated as local rogues who unleash Mr. Dark into the world.
Playing off the visit of Fafhrd and the Grey Mouser to our world in "Adept's Gambit" (set in second century B.C. Tyre), Steven Saylor's short story "Ill Seen in Tyre" takes his Roma Sub Rosa series hero Gordianus to the city of Tyre a hundred years later, where the two visitors from Nehwon are remembered as local legends.
The Grey Mouser's dirk "Cat Claw" has appeared as a weapon in several role-playing video games, including early installments in the Final Fantasy series.

</doc>
<doc id="57942" url="http://en.wikipedia.org/wiki?curid=57942" title="Bratsk">
Bratsk

Bratsk (Russian: Братск; ]) is a city in Irkutsk Oblast, Russia, located on the Angara River near the vast Bratsk Reservoir. Population:  (2010 Census);  (2002 Census);  (1989 Census)
Etymology.
Although the name sounds like the Russian word for "brother" ("брат", "brat"), it actually comes from 'bratskiye lyudi', an old name for the Buryats".
History.
The first Europeans in the area arrived in 1623, intending to collect taxes from the local Buryat population. Permanent settlement began with the construction of an "ostrog" (fortress) in 1636 at the junction of the Oka and Angara rivers. Several wooden towers from the 17th-century fort are now exhibited in Kolomenskoye Estate of Moscow.
During World War II, there was an increase in industrial activity in Siberia, as Soviet industry was moved to the lands east of the Ural Mountains. After the war's end, development slowed as resources were required in the rebuilding of European Russia.
In 1947, the Gulag Angara prison labor camp was constructed near Bratsk, with capacity for up to 44,000 prisoners for projects such as the construction of the railway from Tayshet to Ust-Kut via Bratsk (now the western section of the Baikal-Amur Mainline).
The city's rapid development commenced with the announcement in 1952 that a dam and hydroelectric plant would be built at Bratsk on the Angara River. Town status was granted to Bratsk in 1955. The 4,500-megawatt Bratsk Hydroelectric Power Station was built between 1954 and 1966, bringing numerous workers to the town.
Other industries in the city include an aluminum smelter and a pulp mill.
Politics.
On November 2013 the city council amended the charter to institute direct mayoral elections which were abolished in 2011.
Administrative and municipal status.
Within the framework of administrative divisions, Bratsk serves as the administrative center of Bratsky District, even though it is not a part of it. As an administrative division, it is incorporated separately as the City of Bratsk—an administrative unit with the status equal to that of the districts. As a municipal division, the City of Bratsk is incorporated as Bratsk Urban Okrug.
Territorial divisions.
For administrative purposes, the city is divided into three districts (populations are as of the 2010 Census):
Residential districts of the city, some of which are separated by open country, include: Bikey, Chekanovsky, Energetik, Gidrostroitel, Osinovka, Padun, Porozhsky, Sosnovy, Stenikha, Sukhoy, Tsentralny, and Yuzhny Padun.
Climate.
Bratsk has a subarctic climate (Köppen climate classification "Dfc"). Winters are very cold and long with average temperatures from −24.9 C to −17.1 C in January, while summers are mild to warm with average temperatures from +12.5 C to +23.6 C in July. Precipitation is moderate and is significantly higher in summer than at other times of the year.
Economy and infrastructure.
Bratsk is served by the Baikal-Amur Mainline railway and by the Bratsk Airport. There is a hydrofoil up the Angara to Irkutsk. Public transport includes buses and trolleybuses (only in the central district)
The city's economy is largely reliant on heavy industry, including one of Russia's largest aluminum plants, lumber mills, chemical works, and a coal-fired power station.
Higher educational facilities include the Bratsk State University and a branch of the Irkutsk State University.
Pollution.
Bratsk was among the Blacksmith Institute's "Dirty Thirty", the thirty most polluted places in the world.
Until recently, the Bratsk Reservoir—one of the world's largest—was a source of drinking water for many nearby cities. In 1998, after tons of mercury were found at the bottom of the reservoir, warnings were posted urging local citizens to avoid the reservoir at all costs. However, owing to Russia's economic troubles, the reservoir still remains a source of fish and other food products for many hard-pressed local residents. According to Yuri Udodov, head of the Federal Committee on Ecology (FCE) in the state of Irkutsk, this region has "the highest rate of discharge of metallic mercury into the environment [in] all of Siberia." The extent of mercury pollution in the ground around the nearby Usolye chemical plant is equal to half the total global production of mercury in 1992.
Bratsk has been declared an ecological disaster zone. The Bratsk Aluminum Plant has been polluting its surroundings to such great degree that Chikanovsky was evacuated in 2001 due to repeated health emergencies.
International relations.
Twin towns and sister cities.
Bratsk is twinned with:

</doc>
<doc id="57944" url="http://en.wikipedia.org/wiki?curid=57944" title="Koryaks">
Koryaks

Koryaks (or Koriak) are an indigenous people of Kamchatka Krai in the Russian Far East, who inhabit the coastlands of the Bering Sea to the south of the Anadyr basin and the country to the immediate north of the Kamchatka Peninsula, the southernmost limit of their range being Tigilsk, Russia. They are akin to the Chukchis, whom they closely resemble in culture and physique. They are more distantly related to the Kamchadal (Itelmens) on the Kamchatka Peninsula.
The Koryaks' neighbors are the Evens to the west of Koryak lands, the Alutor to the south on the isthmus of Kamchatka Peninsula, the Kerek to the east, and the Chukchi to the northeast.
The Koryak are typically split into two groups: the coastal people "Nemelan" (or "Nymylan") meaning 'village dwellers,' due to their living in villages. Their sedentary lifestyle is based on local fishing. The inland Koryak, reindeer herders, are called "Chaucu" (or "Chauchuven"), meaning 'rich in reindeer.' They are more nomadic, following the herds as they graze with the seasons.
The Koryak language and its relative, Alutor, are linguistically very close to Chukchi. They are members of the Chukotko-Kamchatkan language family. According to the 2010 census, there were 7,953 Koryaks in Russia.
Etymology.
The name Koryak was from the exonym word 'Korak,' meaning 'with the reindeer (kor)' in a nearby group Chukotko-Kamchatkan language. The earliest references to the name 'Koryak' were recorded in the writings of the Russian cossack Vladimir Atlasov, who conquered Kamchatka for the Tsar in 1695. The variant name was adopted by Russia in official state documents, hence popularizing it ever since.
Origin.
The origin of the Koryak is unknown. Anthropologists have speculated that a land bridge connected the Eurasian and North American continent during Late Pleistocene. It is possible that migratory peoples crossed the modern-day Koryak land "en route" to North America. Scientists have suggested that people traveled back and forth between the two areas before the ice age receded. They theorize that the ancestors of the Koryak had returned to Siberian Asia from North America during this time. Cultural and some linguistic similarity exist between the Nivkh and the Koryak.
History.
The Koryak once occupied a much larger area of the Russian Far East. Their overlapping borders extended to the Nivkh areas in Khabarovsk Krai until the Evens arrived, and pushed them into their present region. A smallpox epidemic in 1769-1770 and warfare with Russian Cossacks reduced the Koryak population from 10-11,000 in 1700 to 4,800 in 1800.
Under the Soviet Union, a Koryak Autonomous Okrug was formed in 1931 and named for this people. Based on the local referendum in 2005, this was merged with Kamchatka Krai effective July 1, 2007.
Culture.
Families usually gathered into groups of six or seven, forming bands. The nominal chief had no predominating authority, and the groups relied on consensus to make decisions, resembling common small group egalitarianism.
The lives of the people in the interior revolved around reindeer, their main source of food. They also used all the parts of its body to make sewing materials and clothing, tools and weapons. The meat was mostly eaten roasted and the blood, marrow and milk were drunk or eaten raw. The liver, heart, kidneys and tongue were considered delicacies. Salmon and other freshwater fish as well as berries and roots played a major part in the diet, as reindeer flesh did not contain some necessary vitamins and minerals, nor dietary fibre, needed to survive in the harsh tundra. The people produced cheese, butter and fermented milk from reindeer milk.
Today the Koryaks also buy processed food, such as bread, cereal and tinned fish. They sell some reindeer each year for money, but can build up their herds due to the large population of reindeer.
Clothing was made out of reindeer hides, but nowadays men and women often have replaced that with cloth. The men wore baggy pants and a hide shirt, which often had a hood attached to it, boots and traditional caps made of reindeer skin. They still use the boots and caps. The women wore the same as the men, but with a longer shirt reaching to the calves. Today women often wear a head cloth and skirt, but wear the reindeer skin robe in cold weather.
The Koryak lived in conical shaped huts, called "chum," similar to a tipi of the American Plains Indians, but less vertical. The framework was covered in many reindeer skins. Many families still use the chum as dwellings, but some live in log cabins. The centre of the chum had a hearth, which has been replaced by an iron stove. Reindeer hide beds are placed to the east in the chum. They used small cupboards to store the families' food, clothing and personal items.
Transportation.
The Koryak rode reindeer to get around, cutting off their horns to prevent injuries. They also fitted a team of reindeer with harnesses and attached them to sleds to transport goods and people when moving camp. Today the Koryak use snowmobiles more often than reindeer. Most inter-village transport is by air or boat, although tracked vehicles are used for travel to neighboring villages.
They developed snowshoes, which they used in winter (and still do) when the snow is deep. Snowshoes are made by lashing reindeer sinew and hide strips to a tennis racket-shaped birch bark or willow hoop. The sinew straps are used to attach the shoe to the foot.
Children learned to ride a reindeer, sleigh, and use snowshoes at a very young age.
Religion.
Koryaks practice a form of animist belief system, especially via shamanism. Koryak mythology centers around the supernatural shaman "Quikil" (Big-Raven), who was the first man and protector of the Koryak. Big Raven myths are also found among the Tlingit, Tsimshian, and other Alaskan natives and Northwest Coast Amerindians.
Environment.
Koryak lands are mountains and volcanic, covered in mostly Arctic tundra. Coniferous trees lie near the southern regions along the coast of the Shelekhova Bay of the Sea of Okhotsk. The northern regions inland are much colder, where only various shrubs grow, but these are enough to sustain reindeer migration. The mean temperature in winter is –25 °C (-13 °F) while short summers are +12 °C (53 °F). The area they covered before Russian colonization was 301,500 km² (116,410 mi²), roughly corresponding to the Koryak Okrug, of which the administrative centre is Palana. Today the Koryak are the largest minority group with 8,743 people. The krai's population is now majority ethnic Russian, descendants of the Cossack colonizers.
References.
</dl>
Further reading.
</dl>

</doc>
<doc id="57947" url="http://en.wikipedia.org/wiki?curid=57947" title="Theobroma cacao">
Theobroma cacao

Theobroma cacao also cacao tree and cocoa tree, is a small (4 - tall) evergreen tree in the family Malvaceae, native to the deep tropical regions of Central and South America. Its seeds, cocoa beans, are used to make cocoa mass, cocoa powder, and chocolate.
Description.
Leaves are alternate, entire, unlobed, 10 - long and 5 - broad.
The flowers are produced in clusters directly on the trunk and older branches; this is known as cauliflory. The flowers are small, 1 - diameter, with pink calyx. The floral formula is ✶ K5 C5 A(5°+5²) G(5). While many of the world's flowers are pollinated by bees (Hymenoptera) or butterflies/moths (Lepidoptera), cacao flowers are pollinated by tiny flies, "Forcipomyia" midges in the order Diptera. The fruit, called a cacao pod, is ovoid, 15 - long and 8 - wide, ripening yellow to orange, and weighs about 500 g when ripe. The pod contains 20 to 60 seeds, usually called "beans", embedded in a white pulp. The seeds are the main ingredient of chocolate, while the pulp is used in some countries to prepare refreshing juice, smoothies, jelly, and nata. The fermented pulp, until recently discarded in Ecuador, Dominican Republic and Peru, is now being distilled there into a popular alcoholic beverage sold in the United States. Each seed contains a significant amount of fat (40–50%) as cocoa butter. Their most noted active constituent is theobromine, a compound similar to caffeine.
Taxonomy and nomenclature.
Cacao ("Theobroma cacao") belongs to the genus "Theobroma" classified under the subfamily Sterculioidea of the mallow family Malvaceae. Cacao is one of 22 species of "Theobroma".
The generic name is derived from the Greek for "food of the gods"; from θεος ("theos"), meaning "god," and βρῶμα ("broma"), meaning "food".
The specific name "cacao" is derived from the native name of the plant in indigenous Mesoamerican languages. The cacao was known as "kakaw" in Tzeltal, K’iche’ and Classic Maya; "kagaw" in Sayula Popoluca; and "cacahuatl" in Nahuatl.
Cupuaçu, "Theobroma grandiflorum", is a closely related species found in Colombia, Peru, Bolivia and Brazil. Like cacao, it is also the source for a kind of chocolate known as "cupulate" or cupuaçu chocolate. Cupuaçu is considered as having high potential by the food and cosmetics industries.
Distribution and domestication.
"T. cacao" is widely distributed from southeastern Mexico to the Amazon basin. There were originally two hypotheses about its domestication; one said that there were two foci for domestication, one in the Lacandon area of Mexico and another in lowland South America. More recent studies of patterns of DNA diversity, however, suggest that this is not the case. Motomayor "et al." sampled 1241 trees and classified them into 10 distinct genetic clusters. This study also identified areas, for example around Iquitos in modern Peru, where representatives of several genetic clusters originated. This result suggests that this is where "T. cacao" was originally domesticated, probably for the pulp that surrounds the beans, which is eaten as a snack and fermented into a mildly alcoholic beverage. Using the DNA sequences obtained by Motomayor "et al." and comparing them with data derived from climate models and the known conditions suitable for cacao, Thomas "et al." have further refined the view of domestication, linking the area of greatest cacao genetic diversity to a bean-shaped area that encompasses the border between Brazil and Peru and the southern part of the Colombian-Brazilian border. Climate models indicate that at the peak of the last ice age 21,000 years ago, when habitat suitable for cacao was at its most reduced, this area was still suitable, and so provided a refugium for the species. Thomas "et al." speculate that from there people took cacao to Mexico, where selection for the beans took place.
Cacao trees grow well as understory plants in humid forest ecosystems. This is equally true of abandoned cultivated trees, making it difficult to distinguish truly wild trees from those whose parents may originally have been cultivated.
History of cultivation.
Cultivation, use, and cultural elaboration of cacao were early and extensive in Mesoamerica. Ceramic vessels with residues from the preparation of cacao beverages have been found at archaeological sites dating back to the Early Formative (1900-900 BC) period. For example, one such vessel found at an Olmec archaeological site on the Gulf Coast of Veracruz, Mexico dates cacao's preparation by pre-Olmec peoples as early as 1750 BC. On the Pacific coast of Chiapas, Mexico, a Mokaya archaeological site provides evidence of cacao beverages dating even earlier, to 1900 BC.
The initial domestication was probably related to the making of a fermented, thus alcoholic beverage.
Several mixtures of cacao are described in ancient texts, for ceremonial or medicinal, as well as culinary, purposes. Some mixtures included maize, chili, vanilla ("Vanilla planifolia"), and honey. Archaeological evidence for use of cacao, while relatively sparse, has come from the recovery of whole cacao beans at Uaxactun, Guatemala and from the preservation of wood fragments of the cacao tree at Belize sites including Cuello and Pulltrouser Swamp. In addition, analysis of residues from ceramic vessels has found traces of theobromine and caffeine in early formative vessels from Puerto Escondido, Honduras (1100-900 BC) and in middle formative vessels from Colha, Belize (600-400 BC) using similar techniques to those used to extract chocolate residues from four classic period ("circa" 400 AD) vessels from a tomb at the Maya archaeological site of Rio Azul. As cacao is the only known commodity from Mesoamerica containing both of these alkaloid compounds, it seems likely these vessels were used as containers for cacao drinks. In addition, cacao is named in a hieroglyphic text on one of the Rio Azul vessels. Cacao was also believed to be ground by the Aztecs and mixed with tobacco for smoking purposes.
Currency system.
Cacao beans constituted both a ritual beverage and a major currency system in pre-Columbian Mesoamerican civilizations. At one point, the Aztec empire received a yearly tribute of 980 loads ("xiquipil" in Nahuatl) of cacao, in addition to other goods. Each load represented exactly 8,000 beans. The buying power of quality beans was such that 80-100 beans could buy a new cloth mantle. The use of cacao beans as currency is also known to have spawned counterfeiters during the Aztec empire.
Mythology.
The Maya believed the "kakaw" (cacao) was discovered by the gods in a mountain that also contained other delectable foods to be used by them. According to Maya mythology, the Plumed Serpent gave cacao to the Maya after humans were created from maize by divine grandmother goddess Xmucane. The Maya celebrated an annual festival in April to honor their cacao god, Ek Chuah, an event that included the sacrifice of a dog with cacao-colored markings, additional animal sacrifices, offerings of cacao, feathers and incense, and an exchange of gifts. In a similar creation story, the Mexica (Aztec) god Quetzalcoatl discovered cacao ("cacahuatl": "bitter water"), in a mountain filled with other plant foods. Cacao was offered regularly to a pantheon of Mexica deities and the Madrid Codex depicts priests lancing their ear lobes (autosacrifice) and covering the cacao with blood as a suitable sacrifice to the gods. The cacao beverage as ritual was used only by men, as it was believed to be toxic for women and children. I think it interesting.
Modern History.
The first Europeans to encounter cacao were Christopher Columbus and his crew in 1502, when they captured a canoe at Guanaja that contained a quantity of mysterious-looking "almonds". The first real European knowledge about chocolate came in the form of a beverage which was first introduced to the Spanish at their meeting with Moctezuma in the Aztec capital of Tenochtitlan in 1519. Cortez and others noted the vast quantities of this beverage the Aztec emperor consumed, and how it was carefully whipped by his attendants beforehand. Examples of cacao beans, along with other agricultural products, were brought back to Spain at that time, but it seems the beverage made from cacao was introduced to the Spanish court in 1544 by Kekchi Maya nobles brought from the New World to Spain by Dominican friars to meet Prince Philip. Within a century, the culinary and medical uses of chocolate had spread to France, England and elsewhere in Western Europe. Demand for this beverage led the French to establish cacao plantations in the Caribbean, while Spain subsequently developed their cacao plantations in their Venezuelan and Philippine colonies (Bloom 1998, Coe 1996). The Nahuatl-derived Spanish word "cacao" entered scientific nomenclature in 1753 after the Swedish naturalist Linnaeus published his taxonomic binomial system and coined the genus and species "Theobroma cacao".
Traditional pre-Hispanic beverages made with cacao are still consumed in Mesoamerica. These include the Oaxacan beverage known as "tejate".
Cultivation.
Cacao is cultivated on roughly 17000000 acre worldwide. According to the Food and Agriculture Organization (FAO), the top 20 cacao-producing countries in 2005 were as follows:
Cacao production has increased from 1.5 million tons in 1983-1984 to 3.5 million tons in 2003-2004, almost entirely due to the expansion of the production area rather than to yield increases. Cacao is grown both by large agroindustrial plantations and small producers, the bulk of production coming from millions of farmers who have a few trees each.
A tree begins to bear when it is four or five years old. A mature tree may have 6,000 flowers in a year, yet only about 20 pods. About 1,200 seeds (40 pods) are required to produce 1 kg (2.2 lb) of cocoa paste.
Historically, chocolate makers have recognized three main cultivar groups of cacao beans used to make cocoa and chocolate. The most prized, rare, and expensive is the Criollo group, the cocoa bean used by the Maya. Only 10% of chocolate is made from Criollo, which is less bitter and more aromatic than any other bean. The cacao bean in 80% of chocolate is made using beans of the Forastero group. Forastero trees are significantly hardier than Criollo trees, resulting in cheaper cacao beans. Trinitario, a hybrid of Criollo and Forastero, is used in about 10% of chocolate. The criollo cacao beans from Chuao in Aragua, Venezuela are widely regarded as some of the finest in the world. In November 2000, the cacao beans coming from said region were awarded an appellation of origin under the title "Cacao de Chuao" (from Spanish-"cacao of Chuao") effectively making this one of the most expensive and sought after types of cacao.
A new, genetically based classification of 10 groups may well help breeders to create new varieties that are both pest- and disease-resistant and contain valued flavours.
Major cocoa bean processors include Hershey's, Nestlé and Mars, all of which purchase cocoa beans via various sources.
In June 2009, Mars Botanicals, a division of Mars, launched Cirku, a cocoa extract product that provides cocoa ﬂavanols made with a patented process that contains a high level of phytonutrients.
Pests.
Various plant pests and diseases can cause serious problems for cacao production.
Conservation.
The pests and diseases to which cacao is subject, along with climate change, mean that new varieties will be needed to respond to these challenges. Breeders rely on the genetic diversity conserved in field genebanks to create new varieties, because cacao has recalcitrant seeds that cannot be stored in a conventional genebank. In an effort to improve the diversity available to breeders, and ensure the future of the field genebanks, experts have drawn up A Global Strategy for the Conservation and Use of Cacao Genetic Resources, as the Foundation for a Sustainable Cocoa Economy. The strategy has been adopted by the cacao producers and their clients, and seeks to improve the characterization of cacao diversity, the sustainability and diversity of the cacao collections, the usefulness of the collections, and to ease access to better information about the conserved material. Some natural areas of cacao diversity are protected by various forms of conservation, for example national parks. However, a recent study of genetic diversity and predicted climates suggests that many of those protected areas will no longer be suitable for cacao by 2050. It also identifies an area around Iquitos in Peru that will remain suitable for cacao and that is home to considerable genetic diversity, and recommends that this area be considered for protection.
Cacao genome.
The genome of "T. cacao" is diploid, its size is 430 Mbp, and it comprises 10 chromosome pairs (2n=2x=20). In September 2010, a team of scientists announced a draft sequence of the cacao genome (Matina1-6 genotype). In a second, unrelated project, the International Cocoa Genome Sequencing Consortium-ICGS, co-ordinated by CIRAD, first published in December 2010 (online, paper publication in January 2011), the sequence of the cacao genome, of the Criollo cacao (of a landrace from Belize, B97-61/B2). In their publication, they reported a detailed analysis of the genomic and genetic data.
The sequence of the cacao genome identified 28,798 protein-coding genes, compared to the roughly 23,000 protein-coding genes of the human genome. About 20% of the cacao genome consists of transposable elements, a low proportion compared to other plant species. Many genes were identified as coding for flavonoids, aromatic terpenes, theobromine and many other metabolites involved in cocoa flavor and quality traits, among which a relatively high proportion code for polyphenols, which constitute up to 8% of cacao pods dry weight. The cacao genome appears close to the hypothetical hexaploid ancestor of all dicotyledonous plants, and it is proposed as an evolutionary mechanism by which the 21 chromosomes of the dicots' hypothetical hexaploid ancestor underwent major fusions leading to cacao's 10 chromosome pairs.
The genome sequence will help accelerate research on cacao molecular biology and breeding for elite varieties through marker-assisted selection, in particular for genetic resistance to fungal, oomycete and viral diseases responsible for huge yield losses each year.

</doc>
<doc id="57948" url="http://en.wikipedia.org/wiki?curid=57948" title="NORAD (disambiguation)">
NORAD (disambiguation)

NORAD may refer to:

</doc>
<doc id="57950" url="http://en.wikipedia.org/wiki?curid=57950" title="Chukchi people">
Chukchi people

The Chukchi, Eskimos of Western Chukotka (Russian: чукчи ("plural"), чукча ("singular")) are an indigenous people inhabiting the Chukchi Peninsula and the shores of the Chukchi Sea and the Bering Sea region of the Arctic Ocean within the Russian Federation. They speak the Chukchi language. The Chukchi originated from the people living around the Okhotsk Sea.
Cultural history.
The majority of Chukchi reside within Chukotka Autonomous Okrug, but some also reside in the neighboring Sakha Republic to the west, Magadan Oblast to the southwest, and Koryak Autonomous Okrug to the south. Some Chukchi also reside in other parts of Russia, as well as in Europe and North America. The total number of Chukchi in the world slightly exceeds 16,000.
The Chukchi are traditionally divided into the "Maritime Chukchi", who had settled homes on the coast and lived primarily from sea mammal hunting, and the "Reindeer Chukchi", who nomadised in the inland tundra region with their herds of reindeer. The Russian name "Chukchi" is derived from the Chukchi word "Chauchu" ("rich in reindeer"), which was used by the 'Reindeer Chukchi' to distinguish themselves from the 'Maritime Chukchi,' called "Anqallyt" ("the sea people"). The indigenous name for a member of the Chukchi ethnic group as a whole is "Luoravetlan" (literally 'true person').
In Chukchi religion, every object, whether animate or inanimate, is assigned a spirit. This spirit can be either harmful or beneficial. Some of Chukchi myths reveal a dualistic cosmology. Chukchi religious practices were prohibited by the Soviet Union in the 1920s.
After the collapse of the Soviet Union, the state-run farms were reorganized and nominally privatized. This process was ultimately destructive to the village-based economy in Chukotka, and the region has still not fully recovered. Many rural Chukchi, as well as Russians in Chukotka's villages, have survived in recent years only with the help of direct humanitarian aid. Some Chukchi have attained university degrees, becoming poets, writers, politicians, teachers, and doctors.
Subsistence.
In prehistoric times, the Chukchi engaged in nomadic hunter gatherer modes of existence. In current times, there continue to be some elements of subsistence hunting, including that of polar bears, marine mammals and reindeer. Beginning in the 1920s, the Soviets organized the economic activities of both coastal and inland Chukchi and eventually established 28 collectively run, state-owned enterprises in Chukotka. All of these were based on reindeer herding, with the addition of sea mammal hunting and walrus ivory carving in the coastal areas. Chukchi were educated in Soviet schools and today are almost 100% literate and fluent in the Russian language. Only a portion of them today work directly in reindeer herding or sea mammal hunting, and continue to live a nomadic lifestyle in yaranga tents.
Relations with Russians.
Russians first began contacting the Chukchis when they reached the Kolyma river (1643) and the Anadyr River (1649). The route from Nizhnekolymsk to the fort at Anadyrsk along the southwest of the main Chukchi area became a major trade route. The overland journey from Yakutsk to Anadyrsk took about six months.
The Chukchis were generally ignored for the next 50 years because they were warlike and had few furs. Fighting flared up around 1700 when the Russians began operating in the Kamchatka Peninsula and needed to protect their communications from the Chukchis and Koryaks. The first attempt to conquer them was made in 1701. Other expeditions were sent out in 1708, 1709 and 1711 with considerable bloodshed but little success. War was renewed in 1729, when the Chukchis defeated an expedition from Okhotsk and its commander was killed. Command passed to Major Dmitry Pavlutsky who adopted very destructive tactics, burning, killing, driving off reindeer and capturing women and children. In 1742, Saint Petersburg ordered another war in which the Chukchis and Koryaks were to be "totally extirpated". The war (1744–7) was conducted with similar brutality and ended when Pavlutsky was killed in March 1747. It is said that the Chukchis kept his head as a trophy for a number of years. There was more war in the 1750s.
In 1762, Saint Petersburg adopted a different policy. Maintaining the fort at Anadyrsk had cost some 1,380,000 rubles, but the area had returned only 29,150 rubles in taxes. Anadyrsk was abandoned in 1764. The Chukchis, no longer provoked, began to trade peacefully with the Russians. From 1788, there was an annual trade fair on the lower Kolyma. Another was established on the Angarka, a tributary of the Bolshoy Anyuy River in 1775. This trade declined in the late 19th century when American whalers and others began landing goods on the coast. The first Orthodox missionaries entered Chukchi territory some time after 1815.
Soviet Period.
Apart from four Orthodox schools, there were no schools in the Chukchi land until the late 1920s. In 1926, there were 72 literate Chukchis. A Latin alphabet was introduced in 1932 and replaced with Cyrillic in 1937. In 1934, 71% of the Chukchis were still nomadic. In 1941, 90% of the reindeer were still privately owned. So-called kulaks still roamed with their private herds up into the 1950s. After 1990, there was a major exodus of Russians.
Population estimates from Forsyth: 1700: 6,000, 1800: 8–9,000, 1926: 13,100, 1930s:12,000, 1939: 13,900, 1959: 11,700, 1979: at least 13,169.
Chukchi in Ukraine.
According to the latest, 2001 Ukrainian national census, there are 30 Chukchi living in Ukraine. Of these, only 3 indicated Chukchi language as their native. For the most (24) it is Russian and for 2 Chukchis it is Ukrainian.

</doc>
<doc id="57951" url="http://en.wikipedia.org/wiki?curid=57951" title="Provinces of the Netherlands">
Provinces of the Netherlands

A Dutch province represents the administrative layer in the Netherlands between the national government and the local municipalities, having the responsibility for matters of subnational or regional importance. 
The government of provinces.
The government of each province consists of three major parts: 
Elections.
The members of the Provinciale Staten are elected every four years by direct voting. To a large extent, the same political parties are enlisted in these elections in the national elections. The chosen provincial councillors will elect the members of the national Senate (Eerste Kamer in Dutch), within 3 months after the elections. 
At the same date as the provincial election, each four years, the elections for the Water boards take place. 
The core tasks.
The provinces of the Netherlands have 7 core tasks
Finance.
The provinces of the Netherlands are financed to a large extent by the national government of The Netherlands. Besides that, provinces have income from a part of the road tax. Several provinces have made a large profit in the past from privatising utility companies, which were originally owned or partly owned by the provinces. An example is the Essent, which was originally owned by 6 provinces and more than 100 municipalities and was sold for around 9.3 billion euros.
List of provinces.
The currently existing country of the Netherlands, being the largest part of the Kingdom of the Netherlands, is divided into twelve provinces ("provincies" in Dutch) and three overseas special municipalities, the Caribbean Netherlands that are not part of any province. Previously these were part of public bodies ("openbare lichamen"). 
The twelve provinces are listed below.
Statistics.
The province with most inhabitants is Zuid Holland. This province has in 2009 over 3.5 million inhabitants. With approximately 381,000 Zeeland has the smallest population. Gelderland, with 5,136 km2 is the largest province in terms of area. The smallest province of Utrecht, with 1,449 km2. In total about 13.000 people had a job working in a province in 2009.
Common interest.
The provinces of the Netherlands are joined in the Association of Provinces of the Netherlands (IPO). This organisation promotes the common interests of the provinces in the national government of The Netherlands in The Hague and within the EU in Brussels.
History.
Nearly all Dutch provinces can trace their origin to a medieval county or duchy, as can the provinces of regions in Belgium. Their status changed when they came under a single ruler who centralised their administration, reducing their powers. There were 17 in total: from these unified Netherlands, seven northern provinces formed from 1588 the Republic of the Seven United Provinces in the 17th century, namely Holland, Zeeland, Gelderland, Utrecht, Friesland, Overijssel and Groningen. The Republic's lands also included Drenthe (one of the 17, but without the autonomous status of the others), and parts of Brabant, Limburg and Flanders, which were considered to be "conquered lands" and were governed directly by the "Staten-Generaal", the parliament, hence their name Generality Lands. They were called "Staats-Brabant", "Staats-Limburg" and "Staats-Vlaanderen", meaning "state-owned". Each of these "Netherlands" had a high degree of autonomy, cooperating with each other mainly on defense and foreign relations, but otherwise keeping to their own affairs.
On January 1, 1796, under the Batavian Republic, Drenthe and Staats-Brabant became the eighth and ninth provinces of the Netherlands. The latter, which had been known as "Bataafs Brabant", Batavian Brabant, changed its name to "Noord Brabant", North Brabant, in 1815 when it became part of the United Kingdom of the Netherlands, which also contained (then) South Brabant, a province now in Belgium. This new unified state featured the provinces in their modern form, as non-autonomous subdivisions of the national state, and again numbering 17, though they were not all the same as the 16th century ones. In 1839, following the separation of Belgium, the original single province of Limburg was divided between the two countries, each now having a province called Limburg. A year later, Holland, the largest and most populous of the Dutch provinces, was also split into two provinces, for a total of 11. The 12th member was to be Flevoland, a province consisting almost entirely of reclaimed land, established on January 1, 1986.
French Period.
During the Batavian Republic, the Netherlands was from 1798 to 1801 completely reorganised into eight new departments, most named after rivers, inspired by the French revolutionary example, in an attempt to do away with the old semi-autonomous status of the provinces. They are listed below, with their capitals and the territory of the former provinces that they mostly incorporated:
 
After only three years, following a coup d'etat, the borders of the former provinces were restored, though not their autonomous status. They were now also called "departments" and Drenthe was added to Overijssel. In 1806 the Kingdom of Holland replaced the republic to further French interests. It was during this administration that Holland was first split in two, with the department of "Amstelland" to the north and that of "Maasland" to the south. East Frisia, then as now in Germany, was added to the kingdom as a department in 1807 and Drenthe split off again making a total of 11 departments.
When the Netherlands finally did become fully part of France in 1810, the departments of the kingdom and their borders were largely maintained, with some joined together. They were however nearly all renamed, again mainly after rivers, though the names differed from their Batavian counterparts. Following are their names and the modern day province they corresponded for the most part to:
 
With the defeat and withdrawal of the French in 1813, the old provinces and their names were re-established, Holland was reunited and East-Frisia went its separate way. The 17 provinces of the United Kingdom of the Netherlands were for a significant part based on the former French departments and their borders, in particular in what would later become Belgium.
Future.
There is continuous discussion within The Netherlands about the future of the provinces. Before 2014, the national government was planning to join the provinces Flevoland, Noord-Holland and Utrecht in a single province (Noordvleugelprovincie). Due to a lot of protets, the plan was abandoned

</doc>
<doc id="57953" url="http://en.wikipedia.org/wiki?curid=57953" title="Montgomery County, Georgia">
Montgomery County, Georgia

Montgomery County is a county in the U.S. state of Georgia. As of the 2010 census, the population was 9,123. The county seat is Mount Vernon.
Montgomery County is part of the Vidalia, GA Micropolitan Statistical Area.
History.
Montgomery County is named in honor of Richard Montgomery, an American Revolutionary War general killed in 1775 while attempting to capture Quebec City, Canada. It was created on December 19, 1793.
More recently, the county is noted for its practice of organizing segregated proms, a practice that has continued since integration of its schools in the 1970s.
Geography.
According to the U.S. Census Bureau, the county has a total area of 245 sqmi, of which 240 sqmi is land and 5.2 sqmi (2.1%) is water.
Demographics.
As of the census of 2000, there were 8,270 people, 2,919 households, and 2,063 families residing in the county. The population density was 13/km² (34/mi²). There were 3,492 housing units at an average density of 6/km² (14/mi²). The racial makeup of the county was 69.72% White, 27.24% Black or African American, 0.07% Native American, 0.19% Asian, 0.02% Pacific Islander, 2.13% from other races, and 0.62% from two or more races. 3.28% of the population were Hispanic or Latino of any race.
There were 2,919 households out of which 34.00% had children under the age of 18 living with them, 53.10% were married couples living together, 13.50% had a female householder with no husband present, and 29.30% were non-families. 25.60% of all households were made up of individuals and 10.20% had someone living alone who was 65 years of age or older. The average household size was 2.57 and the average family size was 3.08.
In the county the population was spread out with 25.00% under the age of 18, 12.80% from 18 to 24, 30.20% from 25 to 44, 21.40% from 45 to 64, and 10.60% who were 65 years of age or older. The median age was 34 years. For every 100 females there were 105.10 males. For every 100 females age 18 and over, there were 105.50 males.
The median income for a household in the county was $30,240, and the median income for a family was $38,418. Males had a median income of $27,572 versus $21,342 for females. The per capita income for the county was $14,182. About 15.80% of families and 19.90% of the population were below the poverty line, including 24.70% of those under age 18 and 23.90% of those age 65 or over.

</doc>
<doc id="57954" url="http://en.wikipedia.org/wiki?curid=57954" title="Montgomery County, Illinois">
Montgomery County, Illinois

Montgomery County is a county located in the U.S. state of Illinois. According to the 2010 census, it had a population of 30,104. Its county seat is Hillsboro.
History.
Montgomery County was formed in 1821 out of Bond and Madison counties. It was named in honor of Richard Montgomery, an American Revolutionary War general killed in 1775 while attempting to capture Quebec City, Canada. Perrin's 1882 "History of Montgomery County" relates that the County was named in honor of Gen. Montgomery, but goes on to say that "others are dubious as to whence it received its name."
Geography.
According to the U.S. Census Bureau, the county has a total area of 710 sqmi, of which 704 sqmi is land and 6.0 sqmi (0.8%) is water.
Climate and weather.
In recent years, average temperatures in the county seat of Hillsboro have ranged from a low of 21 °F in January to a high of 91 °F in July, although a record low of -22 °F was recorded in February 1905 and a record high of 114 °F was recorded in July 1954. Average monthly precipitation ranged from 2.00 in in February to 4.31 in in May.
Transportation.
Airports.
Litchfield Municipal Airport is located in Montgomery County, two nautical miles (3.7 km) southwest of the central business district of Litchfield, Illinois.
Demographics.
As of the census of 2000, there were 30,652 people, 11,507 households, and 7,928 families residing in the county. The population density was 44 people per square mile (17/km²). There were 12,525 housing units at an average density of 18 per square mile (7/km²). The racial makeup of the county was 94.88% White, 3.73% Black or African American, 0.21% Native American, 0.23% Asian, 0.03% Pacific Islander, 0.47% from other races, and 0.46% from two or more races. 1.06% of the population were Hispanic or Latino of any race. 33.7% were of German, 19.3% American, 12.6% English and 9.2% Irish ancestry according to Census 2000.
There were 11,507 households out of which 31.90% had children under the age of 18 living with them, 56.10% were married couples living together, 8.90% had a female householder with no husband present, and 31.10% were non-families. 27.80% of all households were made up of individuals and 14.70% had someone living alone who was 65 years of age or older. The average household size was 2.44 and the average family size was 2.97.
In the county the population was spread out with 23.70% under the age of 18, 8.30% from 18 to 24, 29.30% from 25 to 44, 21.70% from 45 to 64, and 17.00% who were 65 years of age or older. The median age was 38 years. For every 100 females there were 106.40 males. For every 100 females age 18 and over, there were 106.40 males.
The median income for a household in the county was $33,123, and the median income for a family was $39,923. Males had a median income of $30,657 versus $20,563 for females. The per capita income for the county was $16,272. About 10.60% of families and 13.40% of the population were below the poverty line, including 18.40% of those under age 18 and 11.00% of those age 65 or over.

</doc>
<doc id="57955" url="http://en.wikipedia.org/wiki?curid=57955" title="Montgomery County, Arkansas">
Montgomery County, Arkansas

Montgomery County is a county located in the U.S. state of Arkansas. As of the 2010 census, the population was 9,487. The county seat is Mount Ida. Montgomery County is Arkansas's 45th county, formed on December 9, 1842, and named after Richard Montgomery, an American Revolutionary War general.
History.
Stone spear and dart points found in the area verify that people from the Dalton Culture were present in Mongomery County around 8500 BC. Early signs of houses and American Indian cemeteries are present in and around Caddo Gap, Arkansas, indicating the definite presence of the Caddo Indians having settled in the area in the 13th century and 14th century. In 1541, the explorer Hernando de Soto fought the Tula Indians at Caddo Gap, and that he was injured during that battle.
The first white settlers arrived in 1812, when Martin and Mary Collier settled what is now Caddo Gap. They befriended the local tribes, and seemingly had no problems from them whatsoever. Granville Whittington arrived in 1835, and built a road that led from Hot Springs, Arkansas to his farm about a mile north of the settlement of Montgomery. By 1836 when Arkansas received statehood, most of the native Indians were gone. Some of the native Indian women had intermingled and intermarried with local white settlers. Whittington opened a general store that drew customers from the surrounding area, and in 1842 he opened the Mount Ida Post Office in Mount Ida. West of the Ouachita River, settlers from a wagon train wintered in what is now Oden, and decided to stay when the weather cleared. Montgomery County was named after General Richard Montgomery, an American general who died during the American Revolution.
Originally part of the Louisiana Purchase, it was first claimed by Spain, then France, and in 1813 was part of Arkansas County, then in 1818 was part of Clark County. On December 9, 1842, Montgomery County became its own county, with Montgomery as its county seat. In 1850 Salem became the county seat, but later that same year the county seat changed again, to Mount Ida, where Whittington's Post Office was located. Mount Ida incorporated in 1854.
Civil War era.
When the Civil War broke out, most of Montgomery County favored the Confederacy. Mount Ida settlers John Lavender and John Simpson formed one company to serve in the Confederate Army, and the 4th Arkansas Infantry originated in Mount Ida also, but after the war few from the company organized by Lavender and Simpson returned to Montgomery County. With mostly women left to tend to the farms, soldiers from both the Confederate and the Union Army raided homes and farms for supplies, leaving settlers with little to eat. After the war, soldiers from both armies settled in the area, building schools and homes. In 1884 Oden built a steam saw, a cotton gin and a gristmill.
Up to modern times.
With the arrival of the Missouri Pacific Railroad in Caddo Gap around the turn of the 20th century, Caddo Gap and Black Springs began to thrive. In 1910 the county population reached its peak, with sawmills springing up in several locations. That same year, the town of Womble was settled. It changed its name to Norman in 1925. In 1918 the logging camp of Mauldin, Arkansas sprang up, and a railroad line was built to it from Norman. However, almost overnight in 1936, Mauldin closed up, dismantled everything, and moved on having depleted the virgin timber in the area. This, combined with the Great Depression, had a devastating effect on the county.
Many people moved away to find work elsewhere, while others found employment with the Civilian Conservation Corps. During World War II, people continued to leave Montgomery County, with the men going off to war, and others leaving to find employment in war plants. Mining became one source of local employment for a time, but did not last. Most mines were due to a large abundance of quartz in the county. In 1922 there were eighty three school districts in Montgomery County. Today there are three, Caddo Hills, Mount Ida, and Ouachita River. Cattle, swine, and poultry are now the main areas of employment in the region.
Geography.
According to the U.S. Census Bureau, the county has a total area of 800 sqmi, of which 780 sqmi is land and 20 sqmi (2.6%) is water.
Demographics.
As of the 2000 United States Census, there were 9,245 people, 3,785 households, and 2,747 families residing in the county. The population density was 12 people per square mile (5/km²). There were 5,048 housing units at an average density of 6 per square mile (2/km²). The racial makeup of the county was 95.42% White, 0.29% Black or African American, 1.11% Native American, 0.37% Asian, 0.01% Pacific Islander, 1.56% from other races, and 1.23% from two or more races. 2.53% of the population were Hispanic or Latino of any race.
There were 3,785 households out of which 28.00% had children under the age of 18 living with them, 62.60% were married couples living together, 7.00% had a female householder with no husband present, and 27.40% were non-families. 24.50% of all households were made up of individuals and 12.20% had someone living alone who was 65 years of age or older. The average household size was 2.41 and the average family size was 2.85.
In the county the population was spread out with 23.50% under the age of 18, 6.20% from 18 to 24, 25.00% from 25 to 44, 26.30% from 45 to 64, and 18.90% who were 65 years of age or older. The median age was 42 years. For every 100 females there were 96.20 males. For every 100 females age 18 and over, there were 95.00 males.
The median income for a household in the county was $28,421, and the median income for a family was $32,769. Males had a median income of $25,865 versus $18,063 for females. The per capita income for the county was $14,668. About 13.00% of families and 17.00% of the population were below the poverty line, including 22.50% of those under age 18 and 16.00% of those age 65 or over.
Communities.
Townships.
Townships in Arkansas are the divisions of a county. Each township includes unincorporated areas; some may have incorporated cities or towns within part of their boundaries. Arkansas townships have limited purposes in modern times. However, the United States Census does list Arkansas population based on townships (sometimes referred to as "county subdivisions" or "minor civil divisions"). Townships are also of value for historical purposes in terms of genealogical research. Each town or city is within one or more townships in an Arkansas county based on census maps and publications. The townships of Montgomery County are listed below; listed in parentheses are the cities, towns, and/or census-designated places that are fully or partially inside the township.

</doc>
<doc id="57956" url="http://en.wikipedia.org/wiki?curid=57956" title="Montgomery County, Iowa">
Montgomery County, Iowa

Montgomery County is a county located in the southwestern area of the U.S. state of Iowa. As of the 2010 census, the population was 10,740. Its population has declined since a peak in 1900, since urbanization and decline of family farms. The county seat is Red Oak. The county was founded by European-American migrants from eastern areas in 1851. It was named in honor of Richard Montgomery, an American Revolutionary War general killed in 1775 while trying to capture Quebec City, Canada.
The county has been largely rural and devoted to agriculture. It is famous as the location of the unsolved Villisca Axe Murders committed in 1912.
Geography.
According to the U.S. Census Bureau, the county has a total area of 425 sqmi, of which 424 sqmi is land and 0.9 sqmi (0.2%) is water.
Demographics.
2010 census.
The 2010 census recorded a population of 10,740 in the county, with a population density of . There were 5,239 housing units, of which 4,558 were occupied.
2000 census.
As of the census of 2000, there were 11,771 people, 4,886 households, and 3,258 families residing in the county. The population density was 28 people per square mile (11/km²). There were 5,399 housing units at an average density of 13 per square mile (5/km²). The racial makeup of the county was 98.20% White, 0.08% Black or African American, 0.35% Native American, 0.25% Asian, 0.01% Pacific Islander, 0.68% from other races, and 0.44% from two or more races. 1.30% of the population were Hispanic or Latino of any race.
There were 4,886 households out of which 29.70% had children under the age of 18 living with them, 54.40% were married couples living together, 8.70% had a female householder with no husband present, and 33.30% were non-families. 29.50% of all households were made up of individuals and 14.70% had someone living alone who was 65 years of age or older. The average household size was 2.36 and the average family size was 2.91.
In the county the population was spread out with 25.00% under the age of 18, 6.50% from 18 to 24, 25.50% from 25 to 44, 22.80% from 45 to 64, and 20.30% who were 65 years of age or older. The median age was 40 years. For every 100 females there were 90.20 males. For every 100 females age 18 and over, there were 87.30 males.
The median income for a household in the county was $33,214, and the median income for a family was $40,129. Males had a median income of $28,531 versus $20,835 for females. The per capita income for the county was $16,373. About 6.50% of families and 9.10% of the population were below the poverty line, including 12.30% of those under age 18 and 6.00% of those age 65 or over.

</doc>
<doc id="57957" url="http://en.wikipedia.org/wiki?curid=57957" title="Montgomery County, Kentucky">
Montgomery County, Kentucky

Montgomery County is a county located in the U.S. state of Kentucky. As of the 2010 census, the population was 26,499. Its county seat is Mount Sterling. With regard to the sale of alcohol, it is classified as a moist county—a county in which alcohol sales are prohibited (a dry county), but containing a "wet" city where package alcohol sales are allowed, in this case Mount Sterling.
Montgomery County is part of the Mount Sterling, KY Micropolitan Statistical Area, which is also included in the Lexington-Fayette-Richmond-Frankfort, KY Combined Statistical Area.
History.
Montgomery County was established in 1796 from land given by Clark County. Montgomery was the 22nd Kentucky county in order of formation.
Montgomery County was named in honor of Richard Montgomery, an American Revolutionary War Brigadier General killed in 1775 while attempting to capture Quebec City, Canada. An alternative story holds that the County was named for Thomas Montgomery, from Virginia, who served in the Revolutionary War. In 1793 Thomas Montgomery settled in Mt. Sterling. In 1805, Thomas Montgomery moved on to Gibson County, Indiana.
Geography.
According to the U.S. Census Bureau, the county has a total area of 199 sqmi, of which 197 sqmi is land and 1.5 sqmi (0.7%) is water.
Demographics.
As of the census of 2000, there were 22,554 people, 8,902 households, and 6,436 families residing in the county. The population density was 114 /sqmi. There were 9,682 housing units at an average density of 49 /sqmi. The racial makeup of the county was 95.07% White, 3.48% Black or African American, 0.15% Native American, 0.11% Asian, 0.03% Pacific Islander, 0.35% from other races, and 0.82% from two or more races. 1.15% of the population were Hispanic or Latino of any race.
There were 8,902 households out of which 33.60% had children under the age of 18 living with them, 57.70% were married couples living together, 11.20% had a female householder with no husband present, and 27.70% were non-families. 23.90% of all households were made up of individuals and 10.50% had someone living alone who was 65 years of age or older. The average household size was 2.49 and the average family size was 2.93.
The age distribution was 24.90% under the age of 18, 8.70% from 18 to 24, 30.20% from 25 to 44, 23.40% from 45 to 64, and 12.90% who were 65 years of age or older. The median age was 36 years. For every 100 females there were 94.60 males. For every 100 females age 18 and over, there were 91.00 males.
The median income for a household in the county was $31,746, and the median income for a family was $36,939. Males had a median income of $31,428 versus $20,941 for females. The per capita income for the county was $16,701. About 12.50% of families and 15.20% of the population were below the poverty line, including 18.10% of those under age 18 and 17.30% of those age 65 or over.

</doc>
<doc id="57958" url="http://en.wikipedia.org/wiki?curid=57958" title="Montgomery County, Kansas">
Montgomery County, Kansas

Montgomery County (county code MG) is a county located in the U.S. state of Kansas. As of the 2010 census, the county population was 35,471. Its county seat is Independence, and its most populous city is Coffeyville.
The Coffeyville, KS Micropolitan Statistical Area includes all of Montgomery County.
History.
Montgomery County was established February 26, 1867. It was named in honor of Richard Montgomery, an American Revolutionary War general killed in 1775 while attempting to capture Quebec City, in Canada, after successfully capturing two forts and the city of Montreal.
When Kansas was admitted to the Union as a state in 1861, the Osage Indian reservation occupied a large tract of land near the southern border. The reservation had been established in 1825. After the Civil War ended, the Osage lands were coveted as the largest and last reserve of good land in the eastern part of the state. As early as 1866, the Osages were forced to cede tracts at the eastern and northern edges of the reservation. This treaty conceded white settlement on land in the eastern part of what is now Montgomery County.
For a brief time, the Osages attempted to maintain a boundary at the Verdigris River. The Verdigris flows from north to south through the center of Montgomery County. From the west the Elk River joins the Verdigris at a confluence slightly northwest of the geographical center of the county. In 1867 Frank and Fred Bunker established a primitive cattle camp on the west side of the Verdigris south of the confluence. Like the Osages, the Bunkers thought they were beyond the boundaries of civilization.
Early in 1869, however, settlers began to cross the Verdigris River, "at first under protest of the Indians, but the immense throng of settlers soon made all protests futile." Montgomery County was surveyed and organized in 1869; the governor appointed commissioners June 3.
Law and government.
Following amendment to the Kansas Constitution in 1986, the county remained a prohibition, or "dry", county until 1998, when voters approved the sale of alcoholic liquor by the individual drink without a food sales requirement.
Geography.
According to the U.S. Census Bureau, the county has a total area of 651 sqmi, of which 644 sqmi is land and 8.0 sqmi (1.2%) is water. The lowest point in the state of Kansas is located on the Verdigris River in Cherokee Township in Montgomery County (just southeast of Coffeyville), where it flows out of Kansas and into Oklahoma.
Demographics.
As of the U.S. Census in 2000, there were 36,252 people, 14,903 households, and 9,955 families residing in the county. The population density was 56 people per square mile (22/km2). There were 17,207 housing units at an average density of 27 per square mile (10/km2). The racial makeup of the county was 85.77% White, 6.07% Black or African American, 3.19% Native American, 0.47% Asian, 0.02% Pacific Islander, 1.13% from other races, and 3.34% from two or more races. Hispanic or Latino of any race were 3.08% of the population.
There were 14,903 households out of which 29.80% had children under the age of 18 living with them, 53.00% were married couples living together, 10.10% had a female householder with no husband present, and 33.20% were non-families. 29.70% of all households were made up of individuals and 14.70% had someone living alone who was 65 years of age or older. The average household size was 2.37 and the average family size was 2.93.
In the county the population was spread out with 25.00% under the age of 18, 8.60% from 18 to 24, 24.70% from 25 to 44, 23.30% from 45 to 64, and 18.30% who were 65 years of age or older. The median age was 39 years. For every 100 females there were 93.20 males. For every 100 females age 18 and over, there were 88.60 males.
The median income for a household in the county was $30,997, and the median income for a family was $38,516. Males had a median income of $29,745 versus $20,179 for females. The per capita income for the county was $16,421. About 9.20% of families and 12.60% of the population were below the poverty line, including 16.80% of those under age 18 and 10.90% of those age 65 or over.
Communities.
Townships.
Montgomery County is divided into twelve townships. The cities of Caney, Cherryvale, Coffeyville, and Independence are considered "governmentally independent" and are excluded from the census figures for the townships. In the following table, the population center is the largest city (or cities) included in that township's population total, if it is of a significant size.
See also.
Information on this and other counties in Kansas
Other information for Kansas

</doc>
<doc id="57959" url="http://en.wikipedia.org/wiki?curid=57959" title="Montgomery County, Mississippi">
Montgomery County, Mississippi

Montgomery County is a county located in the U.S. state of Mississippi. As of the 2010 census, the population was 10,925. Its county seat is Winona. The county was either named in honor of Richard Montgomery, an American Revolutionary War general killed in 1775 while attempting to capture Quebec City, Canada, or for Montgomery County, Tennessee, from which an early settler came. In that latter case, it would have been indirectly named for John Montgomery, a settler in Montgomery County, Tennessee, who founded the city of Clarksville, Tennessee, in that county.
Geography.
According to the U.S. Census Bureau, the county has a total area of 408 sqmi, of which 407 sqmi is land and 0.9 sqmi (0.2%) is water. It is the fourth-smallest county in Mississippi by total area.
Demographics.
As of the 2010 United States Census, there were 10,925 people residing in the county. 53.0% were White, 45.5% Black or African American, 0.4% Asian, 0.1% Native American, 0.5% of some other race and 0.5% of two or more races. 0.9% were Hispanic or Latino (of any race).
As of the census of 2000, there were 12,189 people, 4,690 households, and 3,367 families residing in the county. The population density was 30 people per square mile (12/km²). There were 5,402 housing units at an average density of 13 per square mile (5/km²). The racial makeup of the county was 54.25% White, 44.95% Black or African American, 0.08% Native American, 0.25% Asian, 0.02% Pacific Islander, 0.07% from other races, and 0.37% from two or more races. 0.85% of the population were Hispanic or Latino of any race.
According to the census of 2000, the largest ancestry groups in Montgomery County were African 44.95%, English 42.1%, and Scots-Irish 1%.
There were 4,690 households out of which 32.60% had children under the age of 18 living with them, 48.50% were married couples living together, 18.80% had a female householder with no husband present, and 28.20% were non-families. 26.10% of all households were made up of individuals and 13.60% had someone living alone who was 65 years of age or older. The average household size was 2.57 and the average family size was 3.10.
In the county the population was spread out with 26.80% under the age of 18, 8.90% from 18 to 24, 25.30% from 25 to 44, 22.40% from 45 to 64, and 16.70% who were 65 years of age or older. The median age was 37 years. For every 100 females there were 86.40 males. For every 100 females age 18 and over, there were 81.10 males.
The median income for a household in the county was $25,270, and the median income for a family was $31,602. Males had a median income of $26,590 versus $17,639 for females. The per capita income for the county was $14,040. About 21.90% of families and 24.30% of the population were below the poverty line, including 34.80% of those under age 18 and 25.40% of those age 65 or over.

</doc>
<doc id="57960" url="http://en.wikipedia.org/wiki?curid=57960" title="Dilworth">
Dilworth

Dilworth may refer to:

</doc>
<doc id="57961" url="http://en.wikipedia.org/wiki?curid=57961" title="Montgomery County, Tennessee">
Montgomery County, Tennessee

Montgomery County is a county located in the U.S. state of Tennessee. As of the 2010 census, the population was 172,331. The county seat is Clarksville. The county was created in 1836.
Montgomery County is included in the Clarksville, TN–KY Metropolitan Statistical Area.
History.
The county was named for John Montgomery, a soldier in the American Revolution and an early settler who founded the city of Clarksville. It was formed when Tennessee County, North Carolina, was split in 1796, when Tennessee became a state, to reduce confusion. The same year, much of the eastern portion of the county was combined with land taken from Sumner County to form Robertson County. Later acts of the Tennessee General Assembly further reduced the county to its current size and boundaries by 1871.
Montgomery County was the site of several early saltpeter mines. Saltpeter is the main ingredient of gunpowder and was obtained by leaching the earth from several local caves. Bellamy Cave, located near Stringtown, still contains the remains of two dozen saltpeter leaching vats and apparently was a large operation. Cooper Creek Cave also shows evidence of extensive mining and contains the remains of "many saltpeter hoppers". Both were probably mined during the War of 1812. Dunbar Cave is reported to have been mined for saltpeter during the Mexican War, but commercial development has destroyed any evidence of this. Little mining is likely to have happened here during the Civil War, since the Union Army captured this part of Tennessee in early 1862.
Geography.
According to the U.S. Census Bureau, the county has a total area of 544 sqmi, of which 539 sqmi is land and 4.7 sqmi (0.9%) is water.
Dunbar Cave.
Montgomery County lies in a region of well-developed karst topography and has a cave system named Dunbar Cave. Dunbar Cave is the centerpiece of Dunbar Cave State Park, which encompasses approximately 110 acres and is one of the most visited units in the Tennessee State Park System.
Dunbar Cave was explored by prehistoric Indians. Remains of their cane torches have been found in the cave and archaeologists have excavated numerous artifacts inside the entrance. During a research trip into the cave on January 15, 2005, Park Ranger Amy Wallace, History Professor Joe Douglas, local historian Billyfrank Morrison, and Geologist Larry E. Matthews, discovered Indian Glyphs on the walls of the cave. Subsequent investigations by archaeologists from the University of Tennessee at Knoxville confirmed that these drawings were left by Mississippian-era Indians. These Indian Glyphs were featured on the tour of the cave. However, in 2009 the cave was closed due to the presence of White Nose Syndrome detected in one single bat. The above ground portion of the Park is still open to the public.
Demographics.
As of the census of 2000, there were 134,768 people, 48,330 households, and 35,957 families residing in the county. The population density was 250 people per square mile (96/km²). There were 52,167 housing units at an average density of 97 per square mile (37/km²). The racial makeup of the county was 73.17% White, 19.18% Black or African American, 0.53% Native American, 1.82% Asian, 0.21% Pacific Islander, 2.18% from other races, and 2.91% from two or more races. 5.16% of the population were Hispanic or Latino of any race.
There were 48,330 households out of which 40.70% had children under the age of 18 living with them, 58.70% were married couples living together, 12.20% had a female householder with no husband present, and 25.60% were non-families. 20.20% of all households were made up of individuals and 5.50% had someone living alone who was 65 years of age or older. The average household size was 2.70 and the average family size was 3.11.
In the county, the population was spread out with 28.40% under the age of 18, 12.30% from 18 to 24, 34.30% from 25 to 44, 17.20% from 45 to 64, and 7.80% who were 65 years of age or older. The median age was 30 years. For every 100 females there were 101.20 males. For every 100 females age 18 and over, there were 98.80 males.
The median income for a household in the county was $38,981, and the median income for a family was $43,023. Males had a median income of $30,696 versus $22,581 for females. The per capita income for the county was $17,265. About 7.90% of families and 10.00% of the population were below the poverty line, including 12.70% of those under age 18 and 10.70% of those age 65 or over.
Government.
The County Council has 21 members, each elected from a single-member district. In addition, voters elect a County Mayor at-large and certain other county-level positions, including the sheriff.

</doc>
<doc id="57962" url="http://en.wikipedia.org/wiki?curid=57962" title="Thomas Dilworth">
Thomas Dilworth

The Reverend Mr. Thomas Dilworth (died 1780) was an English cleric and author of a widely used schoolbook, both in Great Britain and America, "A New Guide to the English Tongue." Noah Webster as a boy studied Dilworth's book, and was inspired partly by it to create his own spelling book on completely different principles, using pictures and stories of interest to children. By some accounts Dilworth was one of the few schoolbooks used by Abraham Lincoln. Published in 1740, by 1773, it was in its thirty-sixth edition. The last American edition was published in 1827 in New Haven, Connecticut. The full-page frontispiece portrait of the author was well-known to generations of doodling school children and is mentioned in Dickens; in "Sketches by Boz." Chapter X there is a humorous description of rowers' togs on the Thames:
The other front matter provides an extensive preface, a dedication to the Anglican schools of Great Britain and Ireland, recommendations from educators and a full-page poetic encomium to Dilworth by J. Duick:
 What thanks, my friend, should to thy care be given
 Which makes the paths to science smooth and even. 
 Henceforth our youth who tread thy flowery way,
 Shall ne'er from rules of proper diction stray;
 No more their speech with barbarous terms be filled
 No more their pens a crop of nonsense yield.
Dilworth's book plays the part of a paragon in the poem "The Rising Village" by Oliver Goldsmith about the influences of improper education in a Nova Scotia community.
Dilworth also wrote other schoolbooks on arithmetic and bookkeeping.

</doc>
<doc id="57963" url="http://en.wikipedia.org/wiki?curid=57963" title="Montgomery County, Missouri">
Montgomery County, Missouri

Montgomery County is a county located in the eastern portion of the U.S. state of Missouri. As of the 2010 census, the population was 12,236. Its county seat is Montgomery City. The county was named in honor of Richard Montgomery, an American Revolutionary War general killed in 1775 while attempting to capture Quebec City, Canada.
With a branch of Stone Hill Winery in New Florence, the county is part of the Missouri Rhineland. It is located approximately halfway between Columbia and St. Louis.
History.
The county has evidence of human habitation from 10,000 years ago, the Archaic period of indigenous Americans. An ancient site was found during archaeological excavations at Graham Cave on the Loutre River.
In the early 19th century, European settlement started at a greater pace, after exploration during previous decades by French trappers and British and American fur traders.
Although the Loutre Island area is commonly associated with the German-founded towns of Rhineland and Starkenburg, established by immigrants of the mid-19th century and later, it was originally settled by Missouri's Anglo-southern settlers from places such as Kentucky or Virginia. Although the southern part of the county is more closely associated with Missouri's Rhineland, its northern part is more associated with Missouri's "Little Dixie" region, earning Montgomery county the nickname "Gateway to Little Dixie".
An early house of worship was a log church, which is still maintained as a chapel. St. Martin's Church is also located in Starkenburg, built in 1873 and listed on the National Register of Historic Places. Above its entrance is the text: "This is the House Of God and the Gate Of Heaven."
Starkenburg is also the site of the Shrine of Our Lady of Sorrows Catholic Church, built in the early 20th century and listed on the NRHP. For further devotions and pilgrimage, the community created an outdoor area for representations of the Stations of the Cross, Mount Calvary and Holy Sepulchre. Starkenburg is located inland from the Missouri River. After the destructive Great Flood of 1993, Rhineland citizens used federal funds to relocate their houses 1.5 mi inland away from the river.
Geography.
According to the U.S. Census Bureau, the county has a total area of 542 sqmi, of which 536 sqmi is land and 5.8 sqmi (1.1%) is water.
Demographics.
As of the census of 2000, there were 12,136 people, 4,775 households, and 3,337 families residing in the county. The population density was 23 people per square mile (9/km²). There were 5,726 housing units at an average density of 11 per square mile (4/km²). The racial makeup of the county was 95.97% White, 2.04% Black or African American, 0.24% Native American, 0.26% Asian, 0.01% Pacific Islander, 0.21% from other races, and 1.28% from two or more races. Approximately 0.77% of the population were Hispanic or Latino of any race. 39.1% were of German, 18.4% American, 10.2% English and 9.2% Irish ancestry according to Census 2000.
There were 4,775 households out of which 31.30% had children under the age of 18 living with them, 56.90% were married couples living together, 8.60% had a female householder with no husband present, and 30.10% were non-families. 26.30% of all households were made up of individuals and 13.20% had someone living alone who was 65 years of age or older. The average household size was 2.47 and the average family size was 2.97.
In the county the population was spread out with 25.40% under the age of 18, 7.40% from 18 to 24, 26.10% from 25 to 44, 23.90% from 45 to 64, and 17.20% who were 65 years of age or older. The median age was 39 years. For every 100 females there were 98.10 males. For every 100 females age 18 and over, there were 93.70 males.
The median income for a household in the county was $32,772, and the median income for a family was $38,632. Males had a median income of $27,933 versus $19,809 for females. The per capita income for the county was $15,092. About 8.40% of families and 11.80% of the population were below the poverty line, including 15.60% of those under age 18 and 10.60% of those age 65 or over.
Politics.
Local.
The Republican Party predominantly controls politics at the local level in Montgomery County. Republicans hold all but one of the elected positions in the county.
State.
Montgomery County is divided into two legislative districts in the Missouri House of Representatives, both of which are held by Republicans.
All of Montgomery County is a part of Missouri’s 16th District in the Missouri Senate and is currently represented by (R-Rolla. Brown defeated Democratic incumbent State Senator Frank A. Barnitz in 2010.
Federal.
All of Montgomery County is included in Missouri's 9th congressional district and is represented by Blaine Luetkemeyer (R-St. Elizabeth) in the U.S. House of Representatives.

</doc>
<doc id="57965" url="http://en.wikipedia.org/wiki?curid=57965" title="Moraceae">
Moraceae

The Moraceae — often called the mulberry family or fig family — are a family of flowering plants comprising about 40 genera and over 1000 species. Most are widespread in tropical and subtropical regions, less so in temperate climates. The only synapomorphy within Moraceae is presence of laticifers and milky sap in all parenchymatous tissues, but generally useful field characters include two carpels sometimes with one reduced, compound inconspicuous flowers, and compound fruits. Included are well-known plants such as the fig, banyan, breadfruit, mulberry, and Osage-orange. The 'flowers' of Moraceae are often pseudanthia (reduced inflorescences).
Classification.
Formerly included within the now defunct order Urticales, recent molecular studies have resulted in its placement within Rosales in a clade called the urticalean rosids that also includes Ulmaceae, Celtidaceae, Cannabaceae and Urticaceae. "Cecropia", which has variously been placed in Moraceae, Urticaceae, or their own family, Cecropiaceae, is now included in Urticaceae.
Dioecy (having individuals with separate sexes) appears to be the primitive state in Moraceae. Monoecy has evolved independently at least four times within the family.
Genera.
The five tribes of Moraceae are: Artocarpeae; Castilleae; Dorstenieae; Ficeae; and Moreae.
References.
 (2004): On the origin of the fig:Phylogenetic relationships of Moraceae from "ndhF" sequences. "American Journal of Botany" 91(5): 767-777. 
 (2008): Plant Systematics: A Phylogenetic Approach. Sinauer Associates, Inc. Sunderland, MA.
 (2002): Urticalean rosids: Circumscription, rosid ancestry, and phylogenetics based on "rbcL", "trnL-F", and "ndhF" sequences. "American Journal of Botany" 89(9): 1531-1546. 
 (2005): Biogroegraphy and divergence times in the mulberry family (Moraceae). "Molecular Phylogenetics and Evolution" 37(2): 402-416. 

</doc>
<doc id="57969" url="http://en.wikipedia.org/wiki?curid=57969" title="JATO">
JATO

JATO (acronym for jet-assisted take off), is a type of assisted take-off for helping overloaded aircraft into the air by providing additional thrust in the form of small rockets. The term "JATO" is used interchangeably with the (more specific) term RATO, for "Rocket-Assisted Take Off" (or, in RAF parlance, RATOG for "Rocket-Assisted Take Off Gear").
Early experiments and World War II.
Early experiments using rockets to boost gliders into the air were conducted in Germany in the 1920s (Lippisch Ente), and later both the Royal Air Force and the Luftwaffe introduced such systems in World War II. The British system used fairly large solid fuel rockets to shoot planes (typically the Hawker Hurricane) off a small ramp fitted to the fronts of merchant ships, known in service as Catapult armed merchantmen (or CAM Ships), in order to provide some cover against German maritime patrol planes. After firing, the rocket was released from the back of the plane to fall into the water and sink. The task done, the pilot would fly to friendly territory if possible or parachute from the plane, hopefully to be picked up by one of the escort vessels. Over two years the system was only employed nine times to attack German aircraft with eight kills recorded for the loss of a single pilot.
The Luftwaffe also used the technique with both liquid-fueled and solid fuel, often jettisonable rocket motors in order to help their small bombers, and the enormous "Gigant", Messerschmitt Me 321 glider, conceived in 1940 for the invasion of Britain, and used to supply the Russian front which also had air tow assistance from up to three Messerschmitt Bf 110 heavy fighters in a so-called "Troika-Schlepp" arrangement, into the air with loads that would have made the takeoff run too long otherwise. This became especially important late in the war when the lengths of usable runways were severely curtailed due to the results of Allied bombing. Their system typically used Walter HWK 109-500 or -501 "Starthilfe" ("start-help") liquid-fuel monopropellant rocket engines driven by chemical decomposition of "T-Stoff", essentially almost pure hydrogen peroxide. A parachute pack at the blunt-contour front of the motor's exterior housing was used to slow its fall after being released from the plane, so the system could be re-used. First experiments were held in 1937 on an Heinkel He 111, piloted by test-pilot Erich Warsitz at Neuhardenberg, a large field about 70 kilometres east of Berlin, listed as a reserve airfield in the event of war. Other German experiments with JATO were aimed at assisting the launch of interceptor aircraft such as the Messerschmitt Me 262C, as the "Heimatschützer" special versions, usually fitted with either a version of the Walter HWK 109-509 liquid fuelled rocket engine from the Me 163 "Komet" program either in the extreme rear of the fuselage or semi-"podded" beneath it just behind the wing's trailing edge, to assist its Junkers Jumo 004 turbojets, or a pair of specially rocket-boosted BMW 003R combination jet-rocket powerplants in place of the Jumo 004s, so that the Me 262C "Heimatschützer" interceptors could reach enemy bomber formations sooner. Two prototypes of the "Heimatschützer" versions of the Me 262 were built and test flown, of the three designs proposed.
In early 1939, the United States National Academy of Sciences provided $1,000 to Theodore von Kármán and the Rocket Research Group (including Jack Parsons, Frank Malina, Edward Forman and Apollo M. O. Smith) at the Guggenheim Aeronautical Laboratory to research rocket-assisted take-off of aircraft. This JATO research was the first rocket research to receive financial assistance from the U.S. government since World War I when Robert Goddard had an Army contract to develop solid fuel rocket weapons. 
In late 1941 von Kármán and his team attached several 50-pound thrust, solid fuel Aerojet JATOs to a light Ercoupe plane, and Army Captain Homer Boushey took off on test runs. On the last run they removed the propeller, attached six JATO units under the wings, and Boushey was thrust into the air for a short flight, the first American to fly by rocket power only. Both armed services used solid fuel JATO during the war.:329
Post WWII.
After World War II JATO became particularly common owing to the low slow-speed thrust of then-current jet engines or for assisting heavy aircraft; the prop-engined Avro Shackelton used Armstrong Siddeley Viper turbojets for takeoff. 
As the take-off thrust of jet engines has grown, JATO has fallen from favor. It is still used, however, when heavily-laden aircraft need to take off from short runways or when operating in "Hot and high" conditions.
Two similar zero-length launch experimental programs were carried out by the US Air Force and by the Soviet VVS at around the same time in the late 1950s, both using high-thrust, short thrust duration booster designs of very similar appearance and function. The US Air Force used a modified Republic F-84, designated EF-84G, which used the MGM-1 Matador cruise missile's solid fuel booster. The Soviet VVS used a modified MiG-19 fighter, designated SM-30, launched from a special launcher, and using a nearly identical solid-fueled rocket booster design to that of the EF-84G. The F-100 and F-104 were also used for zero-length launch experiments.
Operation Credible Sport was a United States military operation plan in late 1980 to rescue hostages held by Iran using C-130 cargo planes modified with rocket engines to enable a very short take off and landing. The plan was canceled after an accident during the test landing when JATO units designed to cushion the landing fired too soon, causing the aircraft to crash-land.
The JATO JUNIOR Was an attempt by Aerojet Engineering to introduce smaller JATO unit to small commercial aircraft, but was blocked by the U.S. Navy Bureau of Aeronautics. Aerojet claimed than the smaller JATO bottle, delivering 250 pounds of thrust for 12 seconds can help a light private plane, that normally requires almost 900 feet of runway to clear a 50 foot high obstacle, could do the same with 300 feet of runway with a JATO Jr unit.
The Boeing 727 had provision for Aerojet JATO assist for use in "hot and high" situations.
Urban legend.
The JATO Rocket Car is an urban legend that relates the story of a car equipped with JATO units that is later found smashed into a mountainside. This story is often given as an example of a Darwin Award; however it appears to be apocryphal, with no basis in fact. The legend has been examined several times on the Discovery Channel show "MythBusters". For the first attempt, in a 2003 pilot episode, the crew replicated the scene and the thrust of the JATO with some commercially-available amateur rocket motors. The car did go very fast, outrunning the chase helicopter, but nowhere near the 300 mph (500 km/h) reported in the original story, and failed to become airborne. The myth was revisited in 2007, using a different configuration of rockets in an attempt to make the car fly; however, it exploded before reaching the end of its launch ramp. The myth was again revisited in 2013 in the 1st Episode of Mythbusters Series 12 - as a celebration for the 10th year on air.
References.
Notes

</doc>
<doc id="57970" url="http://en.wikipedia.org/wiki?curid=57970" title="Hawker Hurricane">
Hawker Hurricane

The Hawker Hurricane is a British single-seat fighter aircraft that was designed and predominantly built by Hawker Aircraft Ltd for the Royal Air Force (RAF). Although largely overshadowed by the Supermarine Spitfire, the aircraft became renowned during the Battle of Britain, accounting for 60% of the RAF's air victories in the battle, and served in all the major theatres of the Second World War.
The 1930s design evolved through several versions and adaptations, resulting in a series of aircraft which acted as interceptor-fighters, fighter-bombers (also called "Hurribombers"), and ground support aircraft. Further versions known as the Sea Hurricane had modifications which enabled operation from ships. Some were converted as catapult-launched convoy escorts, known as "Hurricats". More than 14,583 Hurricanes were built by the end of 1944 (including at least 800 converted to Sea Hurricanes and some 1,400 built in Canada by Canadian Car and Foundry).
Design and development.
Origins.
At the time that the Hurricane was developed, RAF Fighter Command consisted of just 13 squadrons, each equipped with either the Hawker Fury, Hawker Demon, or the Bristol Bulldog, all biplanes with fixed-pitch wooden propellers and non-retractable undercarriages. Sydney Camm's design to meet F.7/30, the Hawker P.V.3, was essentially a scaled-up version of the Fury and was not among the proposals submitted to the Air Ministry selected for building as a government sponsored prototype. After the rejection of the P.V.3, Camm started work on a cantilever monoplane with a fixed undercarriage armed with four machine guns and powered by the Rolls-Royce Goshawk. Detail drawings were finished by January 1934, but failed to impress the Air Ministry enough for a prototype to be ordered. Camm's response was to further develop the design, introducing a retractable undercarriage and replacing the unsatisfactory Goshawk with a new Rolls-Royce design, the PV-12, later to become famous as the Merlin.
In August 1934, a one-tenth scale model was made and sent to the National Physical Laboratory at Teddington. A series of wind tunnel tests confirmed the aerodynamic qualities of the design were in order, and in September Camm approached the Air Ministry again. This time, the response was favourable, and a prototype of the "Interceptor Monoplane" was ordered.
In November 1934, the Air Ministry issued Specification F.5/34 which, drawing on the work of Squadron Leader Ralph Sorley, called for fighter aircraft to be armed with eight guns. However, by this time, work had progressed too far to immediately modify the planned four-gun installation. By January 1935, a wooden mock-up had been finished, and although a number of suggestions for detail changes were made, construction of the prototype was approved, and a new specification (F.36/34) was written around the design. In July 1935, this specification was amended to include installation of eight guns.
Work on the airframe was completed at the end of August 1935 and the aircraft components were taken to Brooklands, where Hawkers had an assembly shed, and re-assembled on 23 October 1935. Ground testing and taxi trials took place over the following two weeks. On 6 November 1935, the prototype "K5083" took to the air for the first time at the hands of Hawker's chief test pilot, Flight Lieutenant (later Group Captain) George Bulman. Bulman was assisted by two other pilots in subsequent flight testing; Philip Lucas flew some of the experimental test flights, while John Hindmarsh conducted the firm's production flight trials.
RAF trials of the aircraft at Martlesham Heath began in February 1936. Sammy Wroath, later to be the founding Commandant of the Empire Test Pilot School, was the RAF test pilot for the Hurricane: his report was favorable, stating, "The aircraft is simple and easy to fly and has no apparent vices" and going on to praise its control response. The type name "Hurricane" proposed by Hawker was approved by the Air Ministry on 26 June; an informal christening ceremony was carried out the next month when King Edward VIII paid a visit to Martlesham Heath.
Further testing showed that the Hurricane had poor spin recovery characteristics, with all rudder authority being lost. Hawker's response was to request that spinning tests be waived, but the Air Ministry refused the request; the situation was resolved by the Royal Aircraft Establishment, who established that the problem was caused by a breakdown of the airflow over the lower fuselage, and could be cured by the addition of a small ventral fairing and extension of the bottom of the rudder. This discovery came too late to be incorporated in the first production aircraft, but was introduced in the 61st built and all subsequent aircraft.
Design.
Though faster and more advanced than the RAF's current front line biplane fighters, the Hurricane's constructional design was already outdated when introduced. It used the traditional Hawker construction techniques, with a Warren truss box-girder primary fuselage structure with high-tensile steel longerons and duralumin cross-bracing using mechanically fastened rather than welded joints. Over this, wooden formers and stringers carried the doped linen covering.
Initially, the wing structure consisted of two steel spars, and was also fabric-covered. An all-metal, stressed-skin wing of duraluminium (a DERD specification similar to AA2024) was introduced in April 1939 and was used for all of the later marks. "The metal skinned wings allowed a diving speed that was 80 mph higher than the fabric-covered ones. They were very different in construction but were interchangeable with the fabric-covered wings; one trials Hurricane, "L1877", was even flown with a fabric-covered port wing and metal-covered starboard wing. The great advantage of the metal-covered wings over the fabric ones was that the metal ones could carry far greater stress loads without needing so much structure beneath."
Several fabric-wing Hurricanes were still in service during the Battle of Britain, although a good number had had their wings replaced during servicing or after repair. Changing the wings only required three hours work per aircraft.
The prototype and early production Hurricanes were fitted with a Watts two-bladed fixed-pitch wooden propeller. Since this was inefficient at low airspeeds, the aircraft required a long ground run to get airborne, causing concern at Fighter Command. Trials with a De Havilland variable-pitch propeller reduced the take-off run from 1230 to. Deliveries of these began in April 1939: this was later replaced by the hydraulically operated constant-speed Rotol propeller, which came into service in time for the Battle of Britain.
Then, with tail trimmer set, throttle and mixture lever fully forward... and puffs of grey exhaust smoke soon clearing at maximum r.p.m. came the surprise! There was no sudden surge of acceleration, but with a thunderous roar from the exhausts just ahead on either side of the windscreen, only a steady increase in speed... In retrospect that first Hurricane sortie was a moment of elation, but also of relief. Apart from the new scale of speeds that the pilot had to adapt to, the Hurricane had all the qualities of its stable, secure biplane predecessor the Hart, but enhanced by livelier controls, greater precision and all this performance.
One of Camm's priorities was to provide the pilot with good all-round visibility. To this end, the cockpit was mounted reasonably high in the fuselage, creating a distinctive "hump-backed" silhouette. Pilot access to the cockpit was aided by a retractable "stirrup" mounted below the trailing edge of the port wing. This was linked to a spring-loaded hinged flap which covered a handhold on the fuselage, just behind the cockpit. When the flap was shut, the footstep retracted into the fuselage. In addition, both wing roots were coated with strips of non-slip material.
An advantage of the steel-tube structure was that cannon shells could pass right through the wood and fabric covering without exploding. Even if one of the steel tubes were damaged, the repair work required was relatively simple and could be done by groundcrew at the airfield. Damage to a stressed skin structure, as used by the Spitfire, required more specialised equipment to repair. The old-fashioned structure also permitted the assembly of Hurricanes with relatively basic equipment under field conditions. Crated Hurricanes were assembled in West Africa and flown across the Sahara to the Middle East theatre and, to save space, some Royal Navy aircraft carriers carried their reserve Sea Hurricanes dismantled into their major assemblies, which were slung up on the hangar bulkheads and deckhead for reassembly when needed.
In contrast, the contemporary Spitfire used all-metal monocoque construction and was thus both lighter and stronger, though less tolerant to bullet damage. With its ease of maintenance, widely set landing gear and benign flying characteristics, the Hurricane remained in use in theatres of operations where reliability, easy handling and a stable gun platform were more important than performance, typically in roles like ground attack. One of the design requirements of the original specification was that both the Hurricane and the Spitfire were also to be used as a night fighter. The Hurricane proved to be a relatively simple aircraft to fly at night and was to be instrumental in shooting down several German aircraft during the nocturnal hours. From early 1941, the Hurricane would also be used as an "intruder" aircraft, patrolling German airfields in France at night in an attempt to catch night bombers during takeoffs or landings.
Production.
The Hurricane was ordered into production in June 1936, mainly due to its relatively simple construction and ease of manufacture. As war was looking increasingly likely, and time was of the essence in providing the RAF with an effective fighter aircraft, it was unclear if the more advanced Spitfire would enter production smoothly, while the Hurricane used well-understood manufacturing techniques. This was true for service squadrons as well, which were experienced in working on and repairing aircraft whose construction employed the same principles as the Hurricane, and the simplicity of its design enabled the improvisation of some remarkable repairs in squadron workshops. The Hurricane was also significantly cheaper than the Spitfire, requiring 10,300 man hours to produce versus 15,200 for the Spitfire.
The maiden flight of the first production aircraft, powered by a Merlin II engine, took place on 12 October 1937. The first four aircraft to enter service with the RAF joined No. 111 Squadron RAF at RAF Northolt the following December. By the outbreak of the Second World War, nearly 500 Hurricanes had been produced, and had equipped 18 squadrons.
During 1940, Lord Beaverbrook, who was the Minister of Aircraft Production, established an organisation in which a number of manufacturers were seconded to repair and overhaul battle-damaged Hurricanes. The Civilian Repair Organisation also overhauled battle-weary aircraft, which were later sent to training units or to other air forces; one of the factories involved was the Austin Aero Company's Cofton Hackett plant. Another was David Rosenfield Ltd, based at Barton aerodrome near Manchester.
Some 14,000 Hurricanes and Sea Hurricanes were produced. Most Hurricanes were built by Hawker (which produced them until 1944), with Hawker's sister company, the Gloster Aircraft Company, making 2,750. The Austin Aero Company built 300. Canada Car and Foundry in Fort William, Ontario, Canada, (where the Chief Engineer, Elsie MacGill, became known as the "Queen of the Hurricanes") was responsible for production of 1,400 Hurricanes, known as the Mk X. 
In 1939, production of 100 Hurricanes was initiated in Yugoslavia by Zmaj and Rogožarski. Of these, 20 were built by Zmaj by April 1941. One of these was fitted with a DB 601 and test flown in 1941.
A contract for 80 Hurricanes was placed with Fairey's Belgian subsidiary Avions Fairey SA for the Belgian Air Force in 1938, with the intention of arming these aircraft with four 13.2 mm machine guns. Three were built and two flown with this armament by the time of the "Blitzkrieg" in May 1940, with at least 12 more built by Avions Fairey with the conventional eight rifle calibre machine gun armament.
Operational history.
The first 50 Hurricanes had reached squadrons by the middle of 1938. At that time, production was slightly greater than the RAF's capacity to introduce the new aircraft and the government gave Hawkers the clearance to sell the excess to nations likely to oppose German expansion. As a result, there were some modest sales to other countries. Production was then increased with a plan to create a reserve of aircraft as well as re-equip existing squadrons and newly formed ones such as those of the Auxiliary Air Force. Expansion scheme E included a target of 500 fighters of all types by the start of 1938. By the time of the Munich Crisis, there were only two fully operational squadrons of the planned 12 with Hurricanes.
By the time of the German invasion of Poland, there were 18 operational Hurricane squadrons and three more converting.
The Phoney War.
The Hurricane had its baptism of fire on 21 October 1939, at the start of the Phoney War. That day, “A” Flight of 46 Squadron took off from North Coates satellite airfield, on the Lincolnshire coast, and was directed to intercept a formation of nine Heinkel He 115B floatplanes from 1/KüFlGr 906, searching for ships to attack in the North Sea. The Heinkels had already been attacked and damaged by two Spitfires from 72 Squadron when six Hurricanes intercepted the Heinkels, which were flying at sea level in an attempt to avoid fighter attacks. Nevertheless, the Hurricanes, in rapid succession, shot down four of the enemy (46 Squadron claiming five and the Spitfire pilots two).
In response to a request from the French government for 10 fighter squadrons to provide air support, Air Chief Marshal Sir Hugh Dowding, Commander-in-Chief of RAF Fighter Command, insisted that this number would deplete British defences severely, and so initially only four squadrons of Hurricanes, 1, 73, 85 and 87, were relocated to France, keeping Spitfires back for "Home" defence. The first to arrive was No.73 Squadron on 10 September 1939, followed shortly by the other three. A little later, 607 and 615 Squadrons joined them.
After his first flight in October 1939, Hurricane pilot Roland Beamont subsequently flew operationally with 87 Squadron, claiming three enemy aircraft during the French campaign, and delivered great praise for his aircraft's performance:
On 30 October, Hurricanes saw action over France. That day, Pilot Officer P.W.O. “Boy” Mould of 1st Squadron, flying Hurricane L1842, shot down a Dornier Do 17P from 2(F)/123. The German aircraft, sent to photograph Allied airfields close to the border, fell in flames about 10 mi west of Toul. Mould was the first RAF pilot to down an enemy aircraft on the continent in the Second World War.
On 6 November 1939, Pilot Officer P.V. Ayerst from 73 Squadron, was the first to clash with a Messerschmitt Bf 109. After the dogfight, he came back with five holes in his fuselage. Flying Officer E. J. "Cobber" Kain, a New Zealander, was responsible for 73 Squadron's first victory on 8 November 1939 while stationed at Rouvres. He went on to become one of the RAF's first fighter aces of the war, being credited with 16 kills.
On 22 December, the Hurricanes in France suffered their first losses. Three Hawker fighters, while trying to intercept an unidentified aircraft, between Metz and Thionville, were jumped by four Bf 109Es from III./JG 53, with the "Gruppenkommandeur", Spanish Civil War ace Captain Werner Mölders in the lead. Mölders and "Leutnant" Hans von Hahn shot down the Hurricanes of Sergeant R.M. Perry and J. Winn for no loss.
Battle of France.
In May 1940, Nos. 3, 79 and 504 Squadrons reinforced the earlier units as Germany's "Blitzkrieg" gathered momentum. On 10 May, the first day of the Battle of France, Flight Lieutenant R. E. Lovett and Flying Officer "Fanny" Orton, of 73 Squadron, were the two first RAF pilots to engage German aircraft. They attacked one of the three Dornier Do 17s from "4. Staffel/KG 2" that were flying over their airfield at Rouvres-en-Woevre. The Dornier went away unscathed, while Orton was hit by defensive fire and had to force land. On the same day, the Hurricane squadrons claimed 42 German aircraft shot down during 208 sorties, although none of these were fighters, while seven Hurricanes were lost but no pilots were killed.
On 12 May, several Hurricanes units were committed to escort bombers. That morning, five Fairey Battle volunteer crews from 12 Squadron took off from Amifontaine base to bomb Vroenhoven and Veldwezelt bridges on the Meuse, at Maastricht. The escort consisted of eight Hurricanes of 1 Squadron, with Squadron Leader P. J. H. "Bull" Halahan in the lead. When the formation approached Maastricht, it was bounced by 16 Bf 109Es from "2./JG 27". Two Battles and two Hurricanes (including Halahan's) were shot down, two more Battles were brought down by flak and the fifth bomber was forced to crash land. The 1 Squadron pilots claimed four Messerschmitts and two Heinkel He 112s, while the Luftwaffe actually lost only one Bf 109.
On 13 May 1940, a further 32 Hurricanes arrived. All ten requested Hurricane squadrons were then operating from French soil and felt the full force of the Nazi offensive. The following day, Hurricanes suffered heavy losses: 27 being shot down, 22 by Messerschmitts, with 15 pilots killed (another died some days later), including Squadron Leader J. B. Parnall (504 Sqn), and the Australian ace Flying Officer Les Clisby (1 Sqn). On the same day, 3 Squadron claimed 17 German aircraft shot down, 85 and 87 Squadrons together claimed four victories, while 607 Squadron claimed nine. During the following three days (15–17 May), no fewer than 51 Hurricanes were lost, in combat or in accidents.
By 17 May, the end of the first week of fighting, only three of the squadrons were near operational strength, but despite their heavy losses, the Hurricanes had managed to destroy nearly double the number of German aircraft.
On 18 May 1940, air combat continued from dawn to dusk; Hurricanes pilots claimed 57 German aircraft and 20 probables (Luftwaffe records show 39 aircraft lost). The following day, 1 and 73 Squadrons claimed 11 German aircraft (three by "Cobber" Kain and three by Paul Richey). But in these two days, Hurricanes suffered heavier losses, with 68 Hurricanes shot down or forced to crash land due to combat damage. Fifteen pilots were killed, eight were taken prisoner and 11 injured. Two thirds of the Hurricanes had been shot down by Messerschmitt Bf 109s and Bf 110s.
In the afternoon of 20 May 1940, the Hurricane units based in northern France were ordered to abandon their bases on the continent and return to Great Britain. On the same day, "Bull" Halahan requested the repatriation of the pilots serving in 1 Squadron. During the previous 10 days, the unit had been the most successful of the campaign; it had claimed 63 victories for the loss of five pilots: two killed, one taken prisoner and two hospitalized. 1 Squadron was awarded ten DFCs and three DFMs during the "Blitzkrieg". On the evening of 21 May, the only Hurricanes still operative were those of the AASF that had been moved to bases around Troyes.
During the 11 days of fighting in France and over Dunkirk on 10—21 May 1940, Hurricane pilots claimed 499 kills and 123 probables. Contemporary German records, examined postwar, attribute 299 Luftwaffe aircraft destroyed and 65 seriously damaged by RAF fighters. When the last Hurricanes left France on 21 June, of the 452 Hawker fighters engaged during the "Blitzkrieg", only 66 came back to Great Britain with 178 abandoned at several airfields, notably Merville, Abbeville, and Lille/Seclin.
Operation Dynamo.
During Operation Dynamo (the evacuation from Dunkirk of British, French and Belgian troops cut off by the German army during the Battle of Dunkirk), the Hawker Hurricanes operated from British bases. Between 26 May and 3 June 1940, the 14 Hurricane units involved were credited with 108 air victories. A total of 27 Hurricane pilots became aces during Operation Dynamo, led by Canadians, Pilot Officer W. L. Willie McKnight (10 victories) and Pilot Officer Percival Stanley Turner (seven victories), who served in No. 242 Squadron, consisting mostly of Canadian personnel. Losses were 22 pilots killed and three captured.
On 27 May 1940, in one of the final mass encounters of the "Blitzkrieg", 13 Hurricanes from 501 Squadron intercepted 24 Heinkel He 111s escorted by 20 Bf 110s; during the ensuing battle, 11 Heinkels were claimed as "kills" and others damaged, with little damage to the Hurricanes.
"Over Dunkirk, the Luftwaffe suffered its first serious rebuff of the war. As Galland has noted, the nature and style of the air battles over the beaches should have provided a warning as to the inherent weaknesses of the Luftwaffe's force structure. Admittedly, the Germans fought at a disadvantage. Although positioned forward at captured airfields, the Bf 109 was at the outer limits of its range and possessed less flying time over Dunkirk than did the "Hurricanes" and "Spitfires" operating from southern England. German bombers were still located in western Germany and had even farther to fly. Thus, the Luftwaffe could not bring its full weight to bear so that when its bombers hammered those on the beaches or embarking, the RAF intervened in a significant fashion. German aircraft losses were high, and British fighter attacks often prevented German bombers from performing with full effectiveness. Both sides suffered heavy losses. During the nine days from May 26 through June 3, the RAF lost 177 aircraft destroyed or damaged; the Germans lost 240. For much of the Luftwaffe, Dunkirk came as a nasty shock. Fliegerkorps II reported in its war diary that it lost more aircraft on the 27th attacking the evacuation than it had lost in the previous ten days of the campaign."
On 7 June 1940, "Cobber" Kain, the first RAF ace of the war, got word that he was to return to England for "rest leave" at an Operational Training Unit. On leaving his airfield, he put on an impromptu aerobatic display and was killed when his Hurricane crashed after completing a loop and attempting some low altitude "flick" rolls.
Initial engagements with the Luftwaffe had showed the Hurricane to be a tight-turning and steady platform, but the Watts two-bladed propeller was clearly unsuitable. At least one pilot complained of how a Heinkel 111 was able to pull away from him in a chase, yet by this time the Heinkel was obsolete. At the start of the war, the engine ran on standard 87 octane aviation spirit. From early 1940, increasing quantities of 100 octane fuel imported from the U.S. became available. In February 1940, Hurricanes with the Merlin II and III engines began to receive modifications to allow for an additional 6 psi of supercharger boost for five minutes (although there are accounts of its use for 30 minutes continuously). The extra supercharger boost, which increased engine output by nearly 250 hp, gave the Hurricane an approximate increase in speed of 25 to, under 15000 ft altitude and greatly increased the aircraft's climb rate. "Overboost" or "pulling the plug", a form of war emergency power as it was called in later Second World War aircraft, was an important wartime modification that allowed the Hurricane to be more competitive against the Bf 109E and to increase its margin of superiority over the Bf 110C, especially at low altitude. With the +12 psi "emergency boost", the Merlin III was able to generate 1,310 hp at 9000 ft.
Flt Lt Ian Gleed of 87 Squadron wrote about the effect of using the extra boost on the Hurricane while chasing a Bf 109 at low altitude on 19 May 1940:
Gleed ran out of ammunition before he could shoot the 109 down although he left it heavily damaged and flying at about 50 ft.
Hurricanes equipped with Rotol constant-speed propellers were delivered to RAF squadrons in May 1940, with deliveries continuing throughout the Battle of Britain; the Rotol propeller transformed the Hurricane's performance from "disappointing" to one of "acceptable mediocrity" and modified aircraft were certainly much sought after among squadrons equipped with aircraft having the older de Havilland two-position propeller.
Battle of Britain.
At the end of June 1940, following the fall of France, the majority of the RAF's 36 fighter squadrons were equipped with Hurricanes. The Battle of Britain officially lasted from 10 July until 31 October 1940, but the heaviest fighting took place between 8 August and 21 September. Both the Supermarine Spitfire and the Hurricane are renowned for their part in defending Britain against the Luftwaffe; generally, the Spitfire would intercept the German fighters, leaving Hurricanes to concentrate on the bombers, but despite the undoubted abilities of the "thoroughbred" Spitfire, it was the "workhorse" Hurricane that scored the higher number of RAF victories during this period, accounting for 55 percent of the 2,739 German losses, according to Fighter Command, compared with 42 per cent by Spitfires.
As a fighter, the Hurricane had some drawbacks. It was slower than both the Spitfire I and II and the Messerschmitt Bf 109E, and the thick wings compromised acceleration, but it could out-turn both of them. In spite of its performance deficiencies against the Bf 109, the Hurricane was still capable of destroying the German fighter, especially at lower altitudes. The standard tactic of the 109s was to attempt to climb higher than the RAF fighters and "bounce" them in a dive; the Hurricanes could evade such tactics by turning into the attack or going into a "corkscrew dive", which the 109s, with their lower rate of roll, found hard to counter. If a 109 was caught in a dogfight, the Hurricane was just as capable of out-turning the 109 as the Spitfire. In a stern chase, the 109 could easily evade the Hurricane.
In September 1940, the more powerful Mk IIa series 1 Hurricanes started entering service, although only in small numbers. This version was capable of a maximum speed of 342 mi/h.
The Hurricane was a steady gun platform, and had demonstrated its ruggedness, as several were badly damaged, yet returned to base. But, whilst it was sturdy and stable, the Hurricane's construction made it dangerous in the event of the aircraft catching fire; the wood frames and fabric covering of the rear fuselage meant that fire could spread through the rear fuselage structure quite easily. In addition, the gravity fuel tank in the forward fuselage sat right in front of the instrument panel, without any form of protection for the pilot. Many Hurricane pilots were seriously burned as a consequence of a jet of flame which could burn through the instrument panel. This became of such concern to Hugh Dowding that he had Hawker retrofit the fuselage tanks of the Hurricanes with a self-expanding rubber coating called Linatex. If the tank happened to be punctured by a bullet, the linatex coating would expand when soaked with petrol and seal it Some Hurricane pilots also felt that the fuel tanks in the wings, although they were protected with a layer of Linatex, were vulnerable from behind, and it was thought that these, not the fuselage tank, were the main fire risk.
From 10 July to 11 August 1940, RAF fighters fired at 114 German bombers and shot down 80, a destruction ratio of 70%. Against the Bf 109, the RAF fighters attacked 70 and shot down 54 of these, a ratio of 77%. Part of the success of the British fighters was possibly due to the use of the de Wilde incendiary round.
As in the Spitfire, the Merlin engine suffered from negative-G cut-out, a problem not cured until the introduction of Miss Shilling's orifice in early 1941.
The only Battle of Britain Victoria Cross, and the only one awarded to a member of Fighter Command during the war, was awarded to Flight Lieutenant Eric Nicolson of 249 Squadron as a result of an action on 16 August 1940 when his section of three Hurricanes was "bounced" from above by Bf 110 fighters. All three were hit simultaneously. Nicolson was badly wounded, and his Hurricane was damaged and engulfed in flames. While attempting to leave the cockpit, Nicolson noticed that one of the Bf 110s had overshot his aircraft. He returned to the cockpit, which by now was an inferno, engaged the enemy, and may have shot down the Bf 110.
Night fighters and Intruders.
Following the Battle of Britain, the Hurricane continued to give service, and through the Blitz of 1941, was the principal single-seat night fighter in Fighter Command. F/Lt. Richard Stevens claimed 14 Luftwaffe bombers flying Hurricanes in 1941.
1942 saw the cannon-armed Mk IIc perform further afield in the night intruder role over occupied Europe. F/Lt. Karel Kuttelwascher of 1 Squadron proved the top scorer, with 15 Luftwaffe bombers claimed shot down.
1942 also saw the manufacture of twelve Hurricane II C(NF) night fighters equipped with pilot-operated Air Interception Mark VI radar. After a brief operational deployment with No.245 and No. 247 Squadron RAF during which these aircraft proved too slow to serve effectively in Europe, these aircraft were sent to India to serve with No. 176 Squadron RAF in the defence of Calcutta. They were withdrawn from service at the end of December 1943.
North Africa.
The Hurricane Mk II was hastily tropicalised following Italy's entry into the war in June 1940. These aircraft were initially ferried through France by air to 80 Squadron in Egypt to replace Gladiators. The Hurricane claimed its first kill in the Mediterranean on 19 June 1940, when F/O P.G. Wykeham-Barnes reported shooting down two Fiat CR.42s.
Hurricanes served with several British Commonwealth squadrons in the Desert Air Force.
They suffered heavy losses over North Africa after the arrival of Bf 109E and F-variants and were progressively replaced in the air superiority role from June 1941 by Curtiss Tomahawks/Kittyhawks. However, fighter-bomber variants ("Hurribombers") retained an edge in the ground attack role, due to their impressive armament of four 20 mm (.79 in) cannon and a 500 lb bombload.
From November 1941, beginning in the Libyan desert, it had to face a new formidable opponent: the new Regia Aeronautica Macchi C.202 "Folgore". The Italian aircraft proved superior to the Hawker fighter. The C.202, thanks to its excellent agility and a new, more powerful inline engine license-built by Alfa Romeo, could outperform it in a dogfight.
During and following the five-day El Alamein artillery barrage that commenced on the night of 23 October 1942, six squadrons of Hurricanes, including the 40 mm cannon-armed Hurricane Mk.IID version, claimed to have destroyed 39 tanks, 212 lorries and armoured troop-carriers, 26 bowsers, 42 guns, 200 various other vehicles and four small fuel and ammunition dumps, flying 842 sorties with the loss of 11 pilots. Whilst performing in a ground support role, Hurricanes based at RAF Castel Benito, Tripoli, knocked out six tanks, 13 armoured vehicles, 10 lorries, five half-tracks, a gun and trailer, and a wireless van on 10 March 1943, with no losses to themselves.
Defence of Malta.
The Hurricane played a significant role in the defence of Malta. When Italy entered the war on 10 June 1940, Malta's air defence rested on Gloster Gladiators which managed to hold out against vastly superior numbers of the Italian air force during the following 17 days. (According to myth, after the first one was lost, the remaining three were named “Faith, Hope and Charity”; in reality, there were at least six Gladiators.) Four Hurricanes joined them at the end of June, and together they faced attacks throughout July from the 200 enemy aircraft based in Sicily, with the loss of one Gladiator and one Hurricane. Further reinforcements arrived on 2 August in the form of 12 more Hurricanes and two Blackburn Skuas. 
For weeks a handful of Hurricane IIs, aided by Group Captain A.B. Woodhall's masterly controlling, had been meeting, against all the odds, the rising crescendo of Field Marshal Kesselring's relentless attacks on Grand Harbour and the airfields. Outnumbered, usually, by 12 or 14 to one and, later – with the arrival of the Bf 109Fs in Sicily – outperformed, the pilots of the few old aircraft which the ground crews struggled valiantly to keep serviceable, went on pressing their attacks, ploughing their way through the German fighter screens, and our flak, to close in with the Ju 87s and 88s as they dived for their targets.
The increasing number of British aircraft on the island, at last, prompted the Italians to employ German Junkers Ju 87 dive bombers to try to destroy the airfields. Finally, in an attempt to overcome the stiff resistance put up by these few aircraft, the Luftwaffe took up base on the Sicilian airfields, only to find that Malta was not an easy target. After numerous attacks on the island over the following months, and the arrival of an extra 23 Hurricanes at the end of April 1941, and a further delivery a month later, the Luftwaffe left Sicily for the Russian Front in June that year.
As Malta was situated on the increasingly important sea supply route for the North African campaign, the Luftwaffe returned with a vengeance for a second assault on the island at the beginning of 1942. It wasn't until March, when the onslaught was at its height, that 15 Spitfires flew in off the carrier HMS "Eagle" to join with the Hurricanes already stationed there and bolster the defence, but many of the new aircraft were lost on the ground and it was again the Hurricane that bore the brunt of the early fighting until further reinforcements arrived.
Air defence in Russia.
The Hawker Hurricane was the first Allied Lend-Lease aircraft to be delivered to the USSR with a total of 2,952 Hurricanes eventually delivered, becoming the most numerous British aircraft in Soviet service. Many Soviet pilots were disappointed by the Hawker fighter, regarding it as inferior to both German and Russian aircraft.
Mk II Hurricanes played an important air defence role in 1941, when the Soviet Union found itself under threat from the German Army approaching on a broad front stretching from Leningrad, Moscow, and to the oil fields in the south. Britain's decision to aid the Soviets meant sending supplies by sea to the far northern ports, and as the convoys would need to sail within range of enemy air attack from the Luftwaffe based in neighbouring Finland, it was decided to deliver a number of Hurricane Mk IIBs, flying with Nos. 81 and 134 Squadrons of No. 151 Wing RAF, to provide protection. Twenty-four were transported on the carrier "Argus", arriving just off Murmansk on 28 August 1941, and another 15 crated aircraft on board merchant vessels. In addition to their convoy protection duties, the aircraft also acted as escorts to Russian bombers.
Enemy attention to the area declined in October, at which point the RAF pilots trained their Soviet counterparts to operate the Hurricanes themselves. By the end of the year, the RAF's role had ended, but the aircraft remained behind and became the first of thousands of Allied aircraft that were accepted by the Soviet Union.
Although Soviet pilots were not universally enthusiastic about the Hurricane, Hero of the Soviet Union (twice), Lt. Col Boris Safonov "... loved the Hurricane ..." and RAF Hurricane Mk IIB fighters operating from Soviet soil in defence of Murmansk, destroyed 15 Luftwaffe aircraft for only one loss in combat. However, in some Soviet war memoirs the Hurricane is described very unflatteringly.
The "Soviet" Hurricane had quite a few drawbacks. First of all, it was 40–50 km/h (25/31 mph) slower than its main opponent, the Bf 109E, at low and medium height, and had a slower rate of climb. The Messerschmitt could outdive the Hurricane because of the thicker wing profile of the British fighter. But the main source of complaints was the Hurricane's armament. Often the eight or 12 small-calibre machine guns did not damage the sturdy and heavily armoured German aircraft; consequently, Soviet ground crews started to remove the Brownings. Retaining only four or six of the 12 machine guns, two 12.7 mm Berezin UBs or two or even four 20 mm ShVAK cannons were substituted, but overall performance deteriorated.
Burma, Ceylon, Singapore, and the Netherlands East Indies.
Following the outbreak of the war with Japan, 51 Hurricane Mk IIBs were disassembled and sent in crates to Singapore; these and the 24 pilots (many of whom were veterans of the Battle of Britain) who had been transferred to the theatre formed the nucleus of five squadrons. They arrived on 3 January 1942, by which time the Allied fighter squadrons in Singapore, flying Brewster Buffalos, had been overwhelmed during the Malayan campaign. The Imperial Japanese Army Air Force's fighter force, especially the Nakajima Ki-43, had been underestimated in its capability, numbers and the strategy of its commanders.
Thanks to the efforts of the 151st Maintenance unit, the 51 Hurricanes were assembled and ready for testing within 48 hours, and of these, 21 were ready for operational service within three days. The Hurricanes were fitted with bulky 'Vokes' dust filters under the nose and were armed with 12, rather than eight, machine guns. The additional weight and drag made them slow to climb and unwieldy to manoeuvre at altitude, although they were more effective bomber killers.
The recently arrived pilots were formed into 232 Squadron. In addition, 488(NZ) Squadron, a Buffalo squadron, converted to Hurricanes. On 18 January, the two squadrons formed the basis of 226 Group. 232 Squadron became operational on 22 January and suffered the first losses and victories for the Hurricane in Southeast Asia. Between 27 and 30 January, another 48 Hurricanes (Mk IIA) arrived with the aircraft carrier HMS "Indomitable", from which they flew to airfields code-named P1 and P2, near Palembang, Sumatra in the Netherlands East Indies.
Because of inadequate early warning systems (the first British radar stations became operational only towards the end of February), Japanese air raids were able to destroy 30 Hurricanes on the ground in Sumatra, most of them in one raid on 7 February. After Japanese landings in Singapore, on 10 February, the remnants of 232 and 488 Squadrons were withdrawn to Palembang. However, Japanese paratroopers began the invasion of Sumatra on 13 February. Hurricanes destroyed six Japanese transport ships on 14 February, but lost seven aircraft in the process. On 18 February, the remaining Allied aircraft and aircrews moved to Java. By this time, only 18 serviceable Hurricanes remained out of the original 99.
That same month, 12 Hurricane Mk IIB Trops were supplied to the Dutch forces on Java. With dust filters removed and fuel and ammo load in wings halved, these were able to stay in a turn with the Oscars they fought. After Java was invaded, some of the New Zealand pilots were evacuated by sea to Australia. One aircraft which had not been assembled, was transferred to the RAAF, becoming the only Hurricane to see service in Australia, in training and other non-combat units.
When a Japanese carrier task force under the command of Admiral Chūichi Nagumo made a sortie into the Indian Ocean in April 1942, RAF Hurricanes based on Ceylon saw action against Nagumo's forces during attacks on Colombo on 5 April 1942 and on Trincomalee harbour on 9 April 1942.
On 5 April 1942, Captain Mitsuo Fuchida of the Imperial Japanese Navy, who led the attack on Pearl Harbor, led a strike against Colombo with 53 Nakajima B5N torpedo bombers and 38 Aichi D3A dive bombers, escorted by 36 Mitsubishi A6M Zero fighters. They were opposed by 35 Hurricane I and IIBs of 30 and 258 Squadrons, together with six Fairey Fulmars of 803 and 806 Squadrons of the Fleet Air Arm. The Hurricanes mainly tried to shoot down the attacking bombers, but were engaged heavily by the escorting Zeros. A total of 21 Hurricanes were shot down (although two of these were repairable), together with four Fulmars and six Swordfish of 788 Naval Air Squadron that had been surprised in flight by the raid. While the RAF claimed 18 Japanese aircraft destroyed, seven probably destroyed and nine damaged, with one aircraft claimed by a Fulmar and five by anti-aircraft fire. This compared with actual Japanese losses of one Zero and six D3As, with a further seven D3As, five B5Ns and three Zeros damaged.
On 9 April 1942, the Japanese task force sent 91 B5Ns escorted by 41 Zeros against Trincomalee port and the nearby China Bay airfield. A total of 16 Hurricanes opposed the raid, of which eight were lost with a further three damaged. They claimed eight Japanese aircraft destroyed with a further four probably destroyed and at least five damaged. Actual Japanese losses were three A6Ms and two B5Ns, with a further 10 B5Ns damaged.
Epilogue.
The battles over the Arakan in 1943 represented the last large-scale use of the Hurricane as a pure day fighter. But they were still used in the fighter-bomber role in Burma until the end of the war and they were occasionally caught up in air combat as well. For example, on 15 February 1944, Flg Off Jagadish Chandra Verma of No 6 Sqdn of Indian Air Force shot down a Japanese Ki-43 Oscar: it was the only IAF victory of the war. The Hurricane remained in service as a fighter-bomber over the Balkans and at home as well where it was used mainly for second-line tasks and occasionally flown by ace pilots. For example, in mid-1944, ace Sqdn Leader 'Jas' Storrar flew No 1687 Hurricane to deliver priority mail to Allied armies in France during the Normandy invasion.
Aircraft carrier operations.
The Sea Hurricane became operational in mid-1941 and scored its first kill while operating from HMS "Furious" on 31 July 1941. During the next three years, Fleet Air Arm Sea Hurricanes were to feature prominently while operating from Royal Navy aircraft carriers. The Sea Hurricane scored an impressive kill-to-loss ratio, primarily while defending Malta convoys, and operating from escort carriers in the Atlantic Ocean. As an example, on 26 May 1944, Royal Navy Sea Hurricanes operating from the escort carrier HMS "Nairana" claimed the destruction of three Ju 290 reconnaissance aircraft during the defence of a convoy.
Hurricane aces.
The top scoring Hurricane pilot was Squadron Leader Marmaduke "Pat" Pattle, DFC & Bar, with 35 Hawker fighter victories (out of career 50 total, with two shared) serving with No. 80 and 33 Squadrons. All of his Hurricane kills were achieved over Greece in 1941. He was shot down and killed in the Battle of Athens. Wing Commander Frank Reginald Carey claimed 28 air victories while flying Hurricanes during 1939–43, and Squadron Leader William "Cherry" Vale DFC and Bar, AFC totalled 20 kills (of 30) in Greece and Syria with No. 80 Squadron. Czech pilot F/Lt Karel M. Kuttelwascher achieved all of his 18 air victories with the Hurricane, most as an intruder night fighter with No. 1 Squadron. Pilot Officer V.C. Woodward (33 and 213 Squadrons) was another top-scoring ace with 14 (out of 18 total, three of which are shared), while F/Lt Richard P. Stevens claimed all of his 14.5 enemy aircraft flying the Hurricane. Richard "Dickie" Cork was the leading Fleet Air Arm Sea Hurricane ace, with nine destroyed, two shared, one probable, four damaged and seven destroyed on the ground. Czech pilot Josef František, flying with 303 Polish Squadron, shot down at least 17 enemy aircraft over southeast England during September–October 1940. Polish pilot Witold Urbanowicz, flying with 303 Polish Squadron, had 15 confirmed kills and one probable during the Battle of Britain.
Operators.
Due to its lightweight, yet robust, construction and ease of maintenance, the Hurricane had a long operational life in many theatres of war. It was also built by, or exported to, several other countries. The Hurricane was unusual in that it was flown operationally by both the Allies and the Axis during the war. In some cases (e.g. Portugal) the Hurricane was pressed into service after being forced to land in a neutral country.
In 1939 Latvia ordered 30 Hurricane fighters and paid for them. However, due to the start of the Second World War in September 1939, the aircraft were never delivered.
Survivors.
Of more than 14,583 Hurricanes that were built, only 12 (including three Sea Hurricanes) survive in airworthy condition worldwide, although other non-flying examples survive in various air museums.
References.
Bibliography.
</dl>

</doc>
<doc id="57973" url="http://en.wikipedia.org/wiki?curid=57973" title="Tony Robinson">
Tony Robinson

Sir Anthony "Tony" Robinson (born 15 August 1946) is an English actor, comedian, amateur historian, TV presenter and political activist. He is known for playing Baldrick in the BBC television series "Blackadder" and for hosting Channel 4 programmes such as "Time Team" and "The Worst Jobs in History". Robinson is a member of the Labour Party and has served on its National Executive Committee. He has also written sixteen children's books.
Early life.
Born in Homerton in the London Borough of Hackney, London, Robinson attended the independent Woodford Green Preparatory School followed by Wanstead High School in what is now the London Borough of Redbridge. He performed in his first professional acting role at the age of 12, as a member of Fagin's gang in the original production of the musical "Oliver!", including a stint as the Artful Dodger when the boy playing the role didn't turn up. Over the next five years, he appeared in a number of West End shows, in film and on television.
At school, Robinson passed four O-Levels (English Language, English Literature, History and Geography) and went on to study for A-Levels. However, he did not complete his A-Levels and decided to study at a drama school instead.
Career.
Early career.
Too young to attend the Royal Academy of Dramatic Art, Robinson instead studied at the Central School of Speech and Drama. After leaving, he spent four years in repertory theatre most notably at the West Yorkshire Playhouse in Leeds.
He won an Arts Council bursary to work as a director at the Midland Arts Centre, Birmingham and founded the Avon Touring Company, a Bristol-based community theatre company, with writer David Illingworth. He played a small role as student doctor Grace in the 1972–73 series of "Doctor In Charge".
He appeared in the 1974–75 season at Chichester Festival Theatre, as Angel Chicago in the nativity musical "Follow The Star". In the 1975 season, he appeared as Hovstad in Henrik Ibsen's "Enemy of the People". In 1976, he appeared as Feste in "Twelfth Night", and as Majorin in "Monsieur Perrichon's Travels".
In 1972 he starred in the children's educational programme "Sam on Boffs' Island" and was later a presenter on "Play Away". He also appeared in the award-winning "Horizon" documentary "Joey", and in the title role in the BBC production of "The Miracle of Brother Humphrey". He also had a minor part in the film "Brannigan" starring John Wayne.
He was also one of the "Who Dares Wins" team in the Channel 4 comedy/satirical show in the early/mid-1980s.
"Blackadder" period (1983–1989).
Robinson came to prominence in 1983 for his role in the British historical sitcom "Blackadder", as Edmund Blackadder's dogsbody Baldrick. In the first series, broadcast as "The Black Adder", he was quite astute, while his master was an idiot. Later series ("Blackadder II", "Blackadder the Third", "Blackadder Goes Forth") moved the duo through history and switched the relationship: the Edmund Blackadder of "Blackadder II" was a brilliant schemer, whereas Baldrick had devolved into a buffoon whose catchphrase was "I have a cunning plan" (which he rarely had).
In addition to his acting on "Blackadder", Robinson also wrote and narrated several "Jackanory"-style children's programmes, encouraged by Richard Curtis. Programmes in this style included "Tales From Fat Tulip's Garden" (continued in "Fat Tulip Too"), "Odysseus: The Greatest Hero of Them All" (a retelling of the "Iliad" and the "Odyssey") and "Blood and Honey" (tales from the Old Testament, filmed on location).
After "Blackadder" (1989–1999).
After "Blackadder", Robinson became the narrator and one of the lead actors for the British animated series "Nellie the Elephant", based on a song of the same name. The series ran from 1989 to 1991 and was shown on Children's ITV.
He also provided voice-over to the "Free-ranger" Chicken cartoon short, an English child-scripted arts-funded production in 1989. Robinson also presented the early-Saturday evening series "Stay Tooned" for BBC 1, which featured a selection of classic Warner Brothers and MGM cartoons. In 1989 he created the children's comedy TV series "Maid Marian and her Merry Men", a loose retelling of the legend of Robin Hood in which he appeared as the Sheriff of Nottingham. Four series were broadcast on BBC1 during 1989–94. In 1990 he appeared as "Shlomo Denkoviz" in Series 8, Episode 2 of "Bergerac" - "My Name’s Sergeant Bergerac".
In 1994, Robinson began presenting "Time Team", a TV programme devoted to archaeological investigations limited to three days (the outcome was never guaranteed, varying from spectacular to disappointing). In 2005, Exeter University conferred an Honorary Doctorate on Robinson, and Honorary Professorships on principal presenter Mick Aston and producer Tim Taylor, to reflect its great appreciation for what "Time Team" has done for the public understanding of archaeology in the UK. In the 2011 episode "Hitler's Island Fortress", Robinson described himself as an amateur archaeologist.
Also in 1994, Robinson played a minor part in an episode called "One Flew Over the Parents Nest" in the TV series "Minder", playing a character called "Willie the Weed". Robinson was drafted to present other history-based shows on Channel 4, including "The Worst Jobs in History", researching and re-enacting some of the more horrible jobs of the past millennium. He also took this show on tour around the country along with an autobiographical question and answer session. This first series was followed by "The Worst Christmas Jobs in History" in December 2005 and then a second series of "The Worst Jobs in History" on Channel 4 in April 2006.
Career 1999–2010.
In 1999, Robinson returned to star in a one-off "Blackadder" short film to celebrate the new millennium, entitled "". This short film was shown in the Millennium Dome throughout 2000 and was later aired on BBC One in 2002.
Robinson also contributed the voiceover for the TV series "Airline" in its set of new series from 1999 focusing on the daily routine of EasyJet staff at a selection of airports. The show was made for ITV and is often repeated today on Sky Real Lives, Sky 1, Sky 2, Sky 3 (now Pick TV) & ITV2. He worked as the narrator for six of the remaining nine series until 2006 when the series ended. "Tony Robinson's Cunning Night Out", a largely improvised stage show, followed in early 2005 and included a mix of the many themes from his career for which Robinson is famous. He also edited and presented "The Real Da Vinci Code", a documentary for Channel 4's "Weird World" series which countered the claims made by Dan Brown in his novel "The Da Vinci Code".
In addition to telling his own stories, Robinson narrated the abridged audiobook versions of Terry Pratchett's "Discworld" novels. Nigel Planer, Celia Imrie and Stephen Briggs narrated the unabridged versions. He also provided the voicing for several characters in the videogame "Discworld". He followed on this "Discworld" work by playing a role in the live action television dramatisation of "Hogfather", broadcast on Sky over the Christmas season in 2006.
Robinson also presented Classic FM's "Friendly Guide to Classical Music" which aired on a Sunday at 4 pm. The whole 16-episode series was repeated on 26 December 2006. He revealed on the BBC Radio 2 feature "Tracks of My Years" that his favourite songs are: "I Can Help" by Billy Swan, "Bleeding Love" by Leona Lewis, "Chasing Cars" by Snow Patrol, "Beautiful" by Christina Aguilera, "Unfinished Sympathy" by Massive Attack, "Tangled Up In Blue" by Bob Dylan, "Shoulda Woulda Coulda" by Beverley Knight, "This Woman's Work" by Maxwell, "He's So Fine" by the Chiffons and "Falling Slowly" by the Frames.
In 2007, Robinson narrated television advertisements for Honda, in the humorous style of "Tales From Fat Tulip's Garden". The advertisements feature plastic cars with expressive faces (similar to "Thomas the Tank Engine"). He has also done voiceovers for laundry product Vanish as of 2007. In the spring of 2007 Robinson visited thirty towns in Britain and Ireland with his one-man show, "A Cunning Night Out". The show was released on DVD.
With Channel 4 Robinson presented "Tony Robinson's Crime and Punishment" and "Catastrophe" and "Man on Earth" focusing on humanity's struggle with climate change in the past 200,000 years. "Tony Robinson and the Paranormal" was first broadcast on Channel 4 in December 2008. In this series, Robinson investigates paranormal phenomena combining the fields of archaeology, parapsychology, history and spiritualism to investigate paranormal evidence.
In July 2009, he appeared in the light-hearted BBC1 series "Hotel Babylon" as sly hit-man named Arthur Barnes. The character is knocked unconscious by a flying bottle expertly lobbed by the hotel manageress during a showdown in the lobby.
Career 2010 to date.
In February 2010 Robinson, described as the 'stunt Pratchett', read the main part of Terry Pratchett's BBC "Richard Dimbleby Lecture".
From 1 September 2010, Robinson hosted a new series on National Geographic Channel called "Birth of Britain" which was repeated on Channel 4 beginning in January 2011. "Tony Robinson Explores Australia" was first broadcast in the first half of 2012. Filmed in High Definition, the series roughly follows a chronology from the earliest sightings of "Terra Australis Incognita" through to the present with each era defined by a theme rather than equal blocks of time.
From 10 September 2012, Robinson hosted a new series on History Channel Australia called "Tony Robinson's Time Walks". The series uncovers stories that shaped the character of various cities and suburbs around Australia, including Fremantle, Melbourne, Hobart, Woolloomooloo, Bendigo, Newcastle, Carlton, Brisbane, St Kilda and Adelaide.
During October 2012, it was announced that "Time Team" would be cancelled after nearly 20 years on television. Tara Conlan from the Guardian called the show "television history". When talking about the successful run of the show, Tony Robinson said "Not many performers are given the privilege of featuring in two iconic TV series – but I've been lucky." It is said that the show is being cancelled due to dwindling viewing figures.
Between 2012 and 2014, Tony Robinson presented a series of programmes for Channel 4 called "Walking through history". It featured Robinson hiking through iconic British landscapes, including the Cairngorms, the Jurassic Coast and Stonehenge. As of November 2014, 16 hour-long episodes have been broadcast in four series.
In September 2013 Sir Jonathan Miller directed the Gala Performance of William Shakespeare's "King Lear" at the Old Vic in London. Robinson played the Fool.
In 2014 Robinson played the eponymous title role in a touring production of "The Hypochondriac", Richard Bean's new translation of Molière's "Le malade imaginaire", directed by Lindsay Posner.
Politics and personal life.
Robinson and his former wife Mary Shepherd were active in Bristol Labour politics from the early 1980s.
From 1996 to 2000, he was vice-president of the actors' union Equity, helping with a huge restructuring programme which turned a £500,000 deficit into a small surplus. He continues to work within Equity. In 2000 he was elected to the Labour Party's National Executive Committee, a position he held to 2004.
He was also active in the "Make Poverty History" campaign during early 2005, in the lead-up to the G8 summit in Scotland, and is the patron for UK-based charity Street Child Africa.
In March 2011, Robinson participated in the 'March for the Alternative' protests in Central London, which opposed the Conservative led Coalition UK Government's spending cuts programme.
In 2006 he appeared in "Tony Robinson: Me and My Mum", a documentary surrounding Robinson's decision to find a nursing home for his mother, and the difficulty he had with doing so. The documentary showed his mother's death in the home. It also featured stories from other families in similar situations. It appeared as part of Channel 4's short season of programmes entitled "The Trouble with Old People".
He previously supported the football clubs Tottenham Hotspur and Stoke City, but now supports League One side Bristol City. He also follows Spanish Liga BBVA side Valencia, often spending his holidays in the country.
He is honorary president of the Young Archaeologists' Club of the Council for British Archaeology. Robinson has shown his support for the Burma Campaign UK, an NGO that aims to highlight human rights violations in Burma under the State Peace and Development Council.
He is a big fan of the rock band Genesis and provided sleeve notes for the reissue of the album "The Lamb Lies Down on Broadway" as part of the "Genesis 1970–1975" box set.
In late 2009 he was invited to be guest speaker at the Pride of Craegmoor Awards, where he gave a speech about his time with his mother and finding a care home. He then went on to give the prizes to Craegmoor's Shining Star and Leading Light.
Robinson married Louise Hobbs on 24 June 2011.
It came as quite a shock to many when Robinson was knighted in the 2013 Birthday Honours for public and political service. Robinson was quoted as saying "I’ll use my new title with abandon to highlight the causes I believe in, particularly the importance of culture, the arts and heritage and the plight of the infirm elderly and their carers," adding, “I also pledge that from this day on I’ll slaughter all unruly dragons, and rescue any damsels in distress who request my help.”
In August 2014, Robinson was one of 200 public figures who were signatories to a letter to "The Guardian" opposing Scottish independence in the run-up to September's referendum on that issue.

</doc>
<doc id="57974" url="http://en.wikipedia.org/wiki?curid=57974" title="Battle of Britain">
Battle of Britain

The Battle of Britain (German: "Luftschlacht um England", literally "Air battle for England") is the name given to the Second World War air campaign waged by the German Air Force (Luftwaffe) against the United Kingdom during the summer and autumn of 1940. The Battle of Britain was the first major campaign to be fought entirely by air forces, and was also the largest and most sustained aerial bombing campaign to that date.
The German objective was to gain air superiority over the Royal Air Force (RAF), especially Fighter Command. From July 1940, coastal shipping convoys and shipping centres, such as Portsmouth, were the main targets; one month later, the Luftwaffe shifted its attacks to RAF airfields and infrastructure. As the battle progressed, the Luftwaffe also targeted aircraft factories and ground infrastructure. Eventually the Luftwaffe resorted to attacking areas of political significance and using terror bombing strategy.
By preventing Germany from gaining air superiority, the British forced Hitler to postpone and eventually cancel Operation "Sea Lion", a planned amphibious and airborne invasion of Britain. However, Germany continued bombing operations on Britain, known as The Blitz. The failure of Germany to achieve its objectives of destroying Britain's air defences, or forcing Britain to negotiate an armistice or even an outright surrender, is considered its first major defeat and a crucial turning point in the Second World War.
The Battle of Britain has an unusual distinction in that it gained its name prior to being fought. The name is derived from a famous speech delivered by Prime Minister Winston Churchill in the House of Commons more than three weeks prior to the generally accepted date for the start of the battle:
 ... What General Weygand has called The Battle of France is over. The Battle of Britain is about to begin."
 — Winston Churchill
Background.
 The early stages of the Second World War saw successful German invasions on the continent supported by Luftwaffe air power able to establish tactical air superiority. In early May 1940, the Norway Debate questioned the fitness for office of the British Prime Minister Neville Chamberlain. On 10 May, the same day Winston Churchill became British Prime Minister, the Germans invaded France. RAF Fighter Command was desperately short of trained pilots and aircraft, but despite the objections of its commander Hugh Dowding that this left home defences under-strength, Churchill sent fighter squadrons to support operations in France, where the RAF suffered heavy losses.
After the evacuation of British and French soldiers from Dunkirk and the French surrender on 22 June 1940, Hitler was mainly focused on the possibilities of invading the Soviet Union while believing that the British, defeated on the continent and without European allies, would quickly come to terms. Germans were so convinced of an imminent armistice that they began constructing street decorations for homecoming parades of victorious troops. Although the Foreign Secretary, Lord Halifax, and an element of British public and political sentiment favoured a negotiated peace with an ascendant Germany, Churchill and a majority of his Cabinet refused to consider an armistice with Hitler. Instead, Churchill used his skilful rhetoric to harden public opinion against capitulation, and to prepare the British for a long war. In his "This was their finest hour" speech on 18 June 1940, he said "the Battle of France is over. I expect that the Battle of Britain is about to begin."
After a series of victories, Germany ruled most of central Europe; from Poland to France, Denmark and Norway. Hitler hoped for a negotiated peace with Britain, but had made no preparations for amphibious assault on a hostile shore; at the time, the only forces with modern equipment and experience were the Japanese at the Battle of Wuhan. On 11 July, Grand Admiral Erich Raeder, Commander-in-Chief of the "Kriegsmarine" (German Navy), told Hitler that an invasion could only be contemplated as a last resort, and only after full air superiority had been achieved. The "Kriegsmarine" had been nearly crippled by the Norwegian Campaign, with many of its ships having been sunk or damaged, while the Royal Navy still had over 50 destroyers, 21 cruisers and eight battleships in the British Home Fleet. There was little the weakened "Kriegsmarine" could do to stop the Royal Navy from intervening. The only alternative was to use the "Luftwaffe"'s dive bombers and torpedo bombers, which required air superiority to operate effectively. Grand Admiral Raeder said, "A powerful and effective air force "might" create conditions favourable for an invasion, whether it could was not in the Navy War Staff's province."
On 16 July, although he agreed with Raeder, Hitler ordered the preparation of a plan to invade Britain; he also hoped that news of the preparations would frighten Britain into peace negotiations. "Directive No. 16; On the Preparation of a Landing Operation against England" read, in part, as follows:
Since England, despite its militarily hopeless situation, still has not shown any signs of being prepared to negotiate, I have decided to prepare a landing operation against England and, if necessary, carry it out.
The objective of this operation is to eliminate the English home country as a base for the continuation of the war against Germany ... 
2) Included in these preparations is the bringing about of those preconditions which make a landing in England possible;
a) "The English air force must have been beaten down to such an extent morally and in fact that it can no longer muster any power of attack worth mentioning against the German crossing." (italics added)
All preparations were to be made by mid-August. For secrecy, this directive was only issued to Commanders in Chief, but Hermann Göring passed it on to his "Luftwaffe" Air Fleet commanders by coded radio messages, which were intercepted by Britain's Y-Service and successfully decrypted by Hut 6 at Bletchley Park.
The "Kriegsmarine" produced a draft plan for achieving a narrow beachhead near Dover. On 28 July the army responded that they wanted landings all along the South Coast of England. Hitler held a meeting of his army and navy chiefs on 31 July in his Berghof, and on 1 August the OKW ("Oberkommando der Wehrmacht" or "High Command of the Armed Forces") issued its plan. The plan, code named "Unternehmen Seelöwe" ("Operation "Sea Lion""), was scheduled to take place in mid-September 1940. "Seelöwe" called for landings on the south coast of Great Britain, backed by an airborne assault. Neither Hitler nor OKW believed it would be possible to carry out a successful amphibious assault on Britain until the RAF had been neutralised. Raeder believed that air superiority might make a successful landing possible although it would be a risky operation and required "absolute mastery over the Channel by our air forces".
Conversely, Grand Admiral Karl Dönitz believed air superiority was "not enough". Dönitz later stated, "we possessed neither control of the air or the sea; nor were we in any position to gain it." Some writers, such as Derek Robinson, have agreed with Dönitz. Robinson argues that the massive superiority of the Royal Navy over the "Kriegsmarine" would have made Sea Lion a disaster and the "Luftwaffe" could not have prevented decisive intervention by British cruisers and destroyers, even with air superiority. Williamson Murray argued that the task facing the Germans in summer 1940 was beyond their capabilities. The three German armed services were not capable of solving the problem of invading the British Isles. Murray contends that the "Kriegsmarine" had been effectively eliminated owing to heavy losses during the Norwegian Campaign. Murray states it is doubtful that the "Kriegsmarine" and "Luftwaffe" could have prevented the Royal Navy from engaging the invasion fleet.
The "Luftwaffe" had not been represented at the Berghof, but Göring was confident that air victory was possible. Like many commanders in other air forces, including the RAF, he was convinced by the ideas of Giulio Douhet that "The bomber will always get through" and if attacks on military targets failed, bombing civilians could force the British government to surrender.
Opposing forces.
The "Luftwaffe" faced a more capable opponent than any it had previously met: a sizeable, highly coordinated, well-supplied, modern air force.
Fighters.
The "Luftwaffe"'s Messerschmitt Bf 109E and Bf 110C fought against the RAF's workhorse Hurricane Mk I and the less numerous Spitfire Mk I, Hurricanes outnumbered Spitfires in RAF Fighter Command by about two to one when war broke out. The Bf 109E had a better climb rate and was up to 40 mph faster in level flight than the Rotol (constant speed propellor) equipped Hurricane Mk I, depending on altitude, the speed and climb disparity with the original non Rotol Hurricane was even greater. In spring and summer 1940, RAF fighters benefited from increased availability of 100 octane aviation fuel, which allowed their Merlin engines to generate significantly more power and an approximately 30 mph increase in speed at low altitudes through the use of an Emergency Boost Override. In September 1940, the more powerful Mk IIa series 1 Hurricanes started entering service in small numbers. This version was capable of a maximum speed of 342 mph, some 20 mph more than the original (non Rotol) Mk I, though it was still 15 to 20 mph slower than a Bf109 (depending on altitude)
The performance of the Spitfire over Dunkirk came as a surprise to the "Jagdwaffe", although the German pilots retained a strong belief that the 109 was the superior fighter. The British fighters were equipped with eight Browning .303 (7.7mm) machine guns, while most Bf 109Es had two 7.92mm machine guns supplemented by two 20mm cannons. The latter was much more effective than the .303; many German planes landed despite large numbers of .303 hits. At some altitudes, the Bf 109 could outclimb the British fighter. It could also engage in vertical-plane negative-"g" manoeuvres without the engine cutting out because its DB 601 engine used fuel injection; this allowed the 109 to dive away from attackers more readily than the carburettor equipped Merlin. On the other hand, the Bf 109E had a much larger turning circle than its two foes. In general, though, as Alfred Price noted in "The Spitfire Story":
... the differences between the Spitfire and the Me 109 in performance and handling were only marginal, and in a combat they were almost always surmounted by tactical considerations: which side had seen the other first, had the advantage of sun, altitude, numbers, pilot ability, tactical situation, tactical co-ordination, amount of fuel remaining, etc.
The Bf 109E was also used as a "Jabo" ("jagdbomber", fighter-bomber)—the E-4/B and E-7 models could carry a 250 kg bomb underneath the fuselage, the later model arriving during the Battle. The Bf 109, unlike the "Stuka", could fight on equal terms with RAF fighters after releasing its ordnance.
At the start of the battle, the twin-engined Messerschmitt Bf 110C long range "Zerstörer" ("Destroyer") was also expected to engage in air-to-air combat while escorting the "Luftwaffe" bomber fleet. Although the 110 was faster than the Hurricane and almost as fast as the Spitfire, its lack of manoeuvrability and acceleration meant that it was a failure as a long-range escort fighter. On 13 and 15 August, 13 and 30 aircraft were lost, the equivalent of an entire "Gruppe", and the type's worst losses during the campaign. This trend continued with a further eight and fifteen lost on 16 and 17 August. Göring ordered the Bf 110 units to operate "where the range of the single-engined machines were not sufficient".
The most successful role of the Bf 110 during the battle was as a "Schnellbomber" (fast bomber). The Bf 110 usually used a shallow dive to bomb the target and escape at high speed. One unit, "Erprobungsgruppe 210" – initially formed as the service test unit ("Erprobungskommando") for the emerging successor to the 110, the Me 210 – proved that the Bf 110 could still be used to good effect in attacking small or "pinpoint" targets.
The RAF's Boulton Paul Defiant had some initial success over Dunkirk because of its resemblance to the Hurricane; Luftwaffe fighters attacking from the rear were surprised by its unusual gun turret. However, during the Battle of Britain, this single-engined two-seater proved hopelessly outclassed. For various reasons, the Defiant lacked any form of forward-firing armament, and the heavy turret and second crewman meant it could not outrun or outmanoeuvre either the Bf 109 or Bf 110. By the end of August, after disastrous losses, the aircraft was withdrawn from daylight service.
Bombers.
The Luftwaffe's primary bombers were the Heinkel He 111, Dornier Do 17, and Junkers Ju 88 for level bombing at medium to high altitudes, and the Junkers Ju 87 "Stuka" for dive bombing tactics. The He 111 was used in greater numbers than the others during the conflict. Forming the main brunt of the heavy formations, it is better known, partly due to its distinctive wing shape. Each level bomber also had a few reconnaissance versions accompanying them that were used during the battle.
Although it was successful in previous Luftwaffe engagements, the "Stuka" suffered heavy losses in the Battle of Britain, particularly on 18 August, due to its slow speed and vulnerability to fighter interception after dive bombing a target. As the losses went up along with their limited payload and range, "Stuka" units were largely removed from operations over England and diverted to concentrate on shipping instead until they were eventually re-deployed to the Eastern Front in 1941. However, for some raids, they were called back, such as on 13 September to attack Tangmere airfield.
The remaining three bomber types differed in their capabilities; the Heinkel 111 was the slowest; the Ju 88 was the fastest once its mainly external bomb load was dropped; and the Do 17 had the smallest bomb load. All three bomber types suffered heavy losses from the home-based British fighters, but the Ju 88 disproportionately so. The German bombers required constant protection by the Luftwaffe's fighter force. German escorts, however, were not enough. Bf 109Es were ordered to support more than 300–400 bombers on any given day. Later in the conflict, when night bombing became more frequent, all three were used. However, due to its reduced bomb load, the lighter Do 17 was used less than the He 111 and Ju 88 for this purpose.
On the British side, three bomber types were mostly used on night operations against targets such as factories, invasion ports and railway centres; the Armstrong Whitworth Whitley, the Handley-Page Hampden and the Vickers Wellington were classified as heavy bombers by the RAF, although the Hampden was a medium bomber comparable to the He 111. The twin-engined Bristol Blenheim and the obsolescent single-engined Fairey Battle were both light bombers; the Blenheim was the most numerous of the aircraft equipping RAF Bomber Command and was used in attacks against shipping, ports, airfields and factories on the continent by day and by night. The Fairey Battle squadrons, which had suffered heavy losses in daylight attacks during the Battle of France, were brought up to strength with reserve aircraft and continued to operate at night in attacks against the invasion ports, until the Battle was withdrawn from UK front line service in October 1940.
Pilots.
Before the war, the RAF's processes for selecting potential candidates were opened to men of all social classes through the creation of the RAF Volunteer Reserve in 1936 which "... was designed to appeal, to ... young men ... without any class distinctions ..." The older squadrons of the Royal Auxiliary Air Force did retain some of their upper-class exclusiveness but their number were soon swamped by the newcomers of the RAFVR and by 1 September 1939, 6646 pilots had been trained through the RAFVR.
By summer 1940, there were about 9,000 pilots in the RAF for approximately 5,000 aircraft, most of which were bombers. Fighter Command was never short of pilots, but the problem of finding sufficient numbers of fully trained fighter pilots became acute by mid-August 1940. With aircraft production running at 300 each week, only 200 pilots were trained in the same period. In addition, more pilots were allocated to squadrons than there were aircraft, as this allowed squadrons to maintain operational strength despite casualties and still provide for pilot leave. Another factor was that only about 30% of the 9,000 pilots were assigned to operational squadrons; 20% of the pilots were involved in conducting pilot training, and a further 20% were undergoing further instruction, like those offered in Canada and in Southern Rhodesia to the Commonwealth trainees, although already qualified. The rest were assigned to staff positions, since RAF policy dictated that only pilots could make many staff and operational command decisions, even in engineering matters. At the height of fighting, and despite Churchill's insistence, only 30 pilots were released to the front line from administrative duties.
For these reasons, and the permanent loss of 435 pilots during the Battle of France alone along with many more wounded, and others lost in Norway, the RAF had fewer experienced pilots at the start of the initial defence of their home. It was the lack of trained pilots in the fighting squadrons, rather than the lack of aircraft, that became the greatest concern for Air Chief Marshal Hugh Dowding, Commander of Fighter Command. Drawing from regular RAF forces, the Auxiliary Air Force and the Volunteer Reserve, the British were able to muster some 1,103 fighter pilots on 1 July. Replacement pilots, with little flight training and often no gunnery training, suffered high casualty rates thus exacerbating the problem.
The Luftwaffe on the other hand, were able to muster a larger number (1,450) of more experienced fighter pilots. Drawing from a cadre of Spanish Civil War veterans, these pilots already had comprehensive courses in aerial gunnery and instructions in tactics suited for fighter-versus-fighter combat. Training manuals discouraged heroism, stressing the importance of attacking only when the odds were in the pilot's favour. Despite the high levels of experience, German fighter formations did not provide a sufficient reserve of pilots to allow for losses and leave, and the Luftwaffe was unable to produce enough pilots to prevent a decline in operational strength as the battle progressed. Eventually, without the personnel available to continue the assault, the Luftwaffe failed during this segment of the war.
International participation.
Allies.
The Royal Air Force roll of honour for the Battle of Britain recognises 595 non-British pilots (out of 2,936) as flying at least one authorised operational sortie with an eligible unit of the RAF or Fleet Air Arm between 10 July and 31 October 1940. These included 145 Poles, 127 New Zealanders, 112 Canadians, 88 Czechoslovaks, 10 Irish, 32 Australians, 28 Belgians, 25 South Africans, 13 French, 7 Americans, 3 Southern Rhodesians and one each from Jamaica and Mandatory Palestine. "Altogether in the fighter battles, the bombing raids, and the various patrols flown between 10 July and 31 October 1940 by the Royal Air Force, 1495 aircrew were killed, of whom 449 were fighter pilots, 718 aircrew from Bomber Command, and 280 from Coastal Command. Among those killed were 47 airmen from Canada, 24 from Australia, 17 from South Africa, 35 from Poland, 20 from Czechoslovakia and six from Belgium. Forty-seven New Zealanders lost their lives, including 15 fighter pilots, 24 bomber and eight coastal aircrew. The names of these Allied and Commonwealth airmen are inscribed in a memorial book which rests in the Battle of Britain Chapel in Westminster Abbey. In the chapel is a stained glass window which contains the badges of the fighter squadrons which operated during the battle and the flags of the nations to which the pilots and aircrew belonged."
Axis.
An element of the Italian Royal Air Force ("Regia Aeronautica") called the Italian Air Corps ("Corpo Aereo Italiano" or CAI) first saw action in late October 1940. It took part in the latter stages of the battle, but achieved limited success. The unit was redeployed in early 1941.
Luftwaffe strategy.
The Luftwaffe was devised to provide tactical support for the army on the battlefield. During the "blitzkrieg" offensives against Poland, Denmark and Norway, France and the Low Countries, the Luftwaffe had co-operated fully with the "Wehrmacht". For the Battle of Britain however, the "Luftwaffe" had to operate in a strategic role, something for which it was unsuited. Its main task was to ensure air supremacy over southeast England, to pave the way for an invasion fleet.
The Luftwaffe regrouped after the Battle of France into three "Luftflotten" (Air Fleets) on Britain's southern and northern flanks. "Luftflotte" 2, commanded by "Generalfeldmarschall" Albert Kesselring, was responsible for the bombing of southeast England and the London area. "Luftflotte" 3, under "Generalfeldmarschall" Hugo Sperrle, targeted the West Country, Wales, the Midlands, and northwest England. "Luftflotte" 5, led by "Generaloberst" Hans-Jürgen Stumpff from his headquarters in Norway, targeted the north of England and Scotland. As the battle progressed, command responsibility shifted, with "Luftflotte" 3 taking more responsibility for the night-time "Blitz" attacks while the main daylight operations fell upon "Luftflotte" 2's shoulders.
Initial Luftwaffe estimates were that it would take four days to defeat the RAF Fighter Command in southern England. This would be followed by a four-week offensive during which the bombers and long-range fighters would destroy all military installations throughout the country and wreck the British aircraft industry. The campaign was planned to begin with attacks on airfields near the coast, gradually moving inland to attack the ring of sector airfields defending London. Later reassessments gave the Luftwaffe five weeks, from 8 August to 15 September, to establish temporary air superiority over England. To achieve this goal, Fighter Command had to be destroyed, either on the ground or in the air, yet the Luftwaffe had to be able to preserve its own strength to be able to support the invasion; this meant that the Luftwaffe had to maintain a high "kill ratio" over the RAF fighters. The only alternative to the goal of air superiority was a terror bombing campaign aimed at the civilian population, but this was considered a last resort and it was (at this stage of the battle) expressly forbidden by Hitler.
The Luftwaffe kept broadly to this scheme, but its commanders had differences of opinion on strategy. Sperrle wanted to eradicate the air defence infrastructure by bombing it. His counterpart, Kesselring, championed attacking London directly— either to bombard the British government into submission, or to draw RAF fighters into a decisive battle. Göring did nothing to resolve this disagreement between his commanders, and only vague directives were set down during the initial stages of the battle, with Göring seemingly unable to decide upon which strategy to pursue. He seemed at times obsessed with maintaining his own power base in the Luftwaffe and indulging his outdated beliefs on air fighting, which would later lead to tactical and strategic errors.
Tactics.
Fighter formations.
Luftwaffe formations employed a loose section of two (nicknamed the "Rotte"), based on a leader ("Rottenführer") followed at a distance of about 183 m by his wingman (nicknamed the "Rottenhund" or "Katschmareks"), who also flew slightly higher and was trained always to stay with his leader. With more room between them, both pilots could spend less time maintaining formation and more time looking around and covering each other's blind spots. Attacking aircraft could be sandwiched between the two 109s. The "rotte" allowed the "Rottenführer" to concentrate on getting kills, but few wingmen had the chance, leading to some resentment in the lower ranks where it was felt that the high scores came at their expense. Two sections were usually teamed up into a "Schwarm", where all the pilots could watch what was happening around them. Each "Schwarm" in a "Staffel" flew at staggered heights and with 183 m of room between them, making the formation difficult to spot at longer ranges and allowing for a great deal of flexibility. By utilising a tight "cross-over" turn, a "Schwarm" could quickly change direction.
The Bf 110s adopted the same "Schwarm" formation as the 109s, but were seldom able to use this to the same advantage. The Bf 110's most successful method of attack was the "bounce" from above. When attacked, "Zerstörergruppen" increasingly resorted to forming large "defensive circles", where each Bf 110 guarded the tail of the aircraft ahead of it. Göring ordered that they be renamed "offensive circles" in a vain bid to improve rapidly declining morale. These conspicuous formations were often successful in attracting RAF fighters that were sometimes "bounced" by high-flying Bf 109s. This led to the often repeated myth that the Bf 110s were escorted by Bf 109s.
Higher-level dispositions.
Luftwaffe tactics were influenced by their fighters. The Bf 110 proved too vulnerable to the nimble single-engined RAF fighters. This meant the bulk of fighter escort duties fell on the Bf 109. Fighter tactics were then complicated by bomber crews who demanded closer protection. After the hard-fought battles of 15 and 18 August, Göring met with his unit leaders. During this conference, the need for the fighters to meet up on time with the bombers was stressed. It was also decided that one bomber "Gruppe" could only be properly protected by several "Gruppen" of 109s. In addition, Göring stipulated that as many fighters as possible were to be left free for "Freie Jagd" ("Free Hunts": a free-roving fighter sweep preceded a raid to try to sweep defenders out of the raid's path). The Ju 87 units, which had suffered heavy casualties, were only to be used under favourable circumstances. In early September, due to increasing complaints from the bomber crews about RAF fighters seemingly able to get through the escort screen, Göring ordered an increase in close escort duties. This decision shackled many of the Bf 109s to the bombers and, although they were more successful at protecting the bomber forces, casualties amongst the fighters mounted primarily because they were forced to fly and manoeuvre at reduced speeds.
The Luftwaffe consistently varied its tactics in its attempts to break through the RAF defences. It launched many "Freie Jagd" to draw up RAF fighters. RAF fighter controllers, however, were often able to detect these and position squadrons to avoid them, keeping to Dowding's plan to preserve fighter strength for the bomber formations. The Luftwaffe also tried using small formations of bombers as bait, covering them with large numbers of escorts. This was more successful, but escort duty tied the fighters to the bombers' slow speed and made them more vulnerable.
By September, standard tactics for raids had become an amalgam of techniques. A "Freie Jagd" would precede the main attack formations. The bombers would fly in at altitudes between 16000 ft and 20000 ft, closely escorted by fighters. Escorts were divided into two parts (usually "Gruppen"), some operating in close contact with the bombers, and others a few hundred yards away and a little above. If the formation was attacked from the starboard, the starboard section engaged the attackers, the top section moving to starboard and the port section to the top position. If the attack came from the port side the system was reversed. British fighters coming from the rear were engaged by the rear section and the two outside sections similarly moving to the rear. If the threat came from above, the top section went into action while the side sections gained height to be able to follow RAF fighters down as they broke away. If attacked, all sections flew in defensive circles. These tactics were skilfully evolved and carried out, and were extremely difficult to counter.
Adolf Galland noted:
We had the impression that, whatever we did, we were bound to be wrong. Fighter protection for bombers created many problems which had to be solved in action. Bomber pilots preferred close screening in which their formation was surrounded by pairs of fighters pursuing a zigzag course. Obviously, the visible presence of the protective fighters gave the bomber pilots a greater sense of security. However, this was a faulty conclusion, because a fighter can only carry out this purely defensive task by taking the initiative in the offensive. He must never wait until attacked because he then loses the chance of acting.
We fighter pilots certainly preferred the free chase during the approach and over the target area. This gives the greatest relief and the best protection for the bomber force.
The biggest disadvantage faced by Bf 109 pilots was that without the benefit of long-range drop tanks (which were introduced in limited numbers in the late stages of the battle), usually of 300 l capacity, the 109s had an endurance of just over an hour and, for the 109E, a 600 km range. Once over Britain, a 109 pilot had to keep an eye on a red "low fuel" light on the instrument panel: once this was illuminated, he was forced to turn back and head for France. With the prospect of two long flights over water, and knowing their range was substantially reduced when escorting bombers or during combat, the "Jagdflieger" coined the term "Kanalkrankheit" or "Channel sickness".
Intelligence.
The Luftwaffe was ill-served by its lack of military intelligence about the British defences. The German intelligence services were fractured and plagued by rivalries; their performance was "amateurish". By 1940, there were few German agents operating in Great Britain and a handful of bungled attempts to insert spies into the country were foiled.
As a result of intercepted radio transmissions, the Germans began to realise that the RAF fighters were being controlled from ground facilities; in July and August 1939, for example, the airship "Graf Zeppelin", which was packed with equipment for listening in on RAF radio and RDF transmissions, flew around the coasts of Britain. Although the Luftwaffe correctly interpreted these new ground control procedures, they were incorrectly assessed as being rigid and ineffectual. A British radar system was well known to the Luftwaffe from intelligence gathered before the war, but the highly developed "Dowding system" linked with fighter control had been a well-kept secret. Even when good information existed, such as a November 1939 "Abwehr" assessment of Fighter Command strengths and capabilities by "Abteilung V", it was ignored if it did not match conventional preconceptions.
On 16 July 1940, "Abteilung V", commanded by "Oberstleutnant" "Beppo" Schmid, produced a report on the RAF and on Britain's defensive capabilities which was adopted by the frontline commanders as a basis for their operational plans. One of the most conspicuous failures of the report was the lack of information on the RAF's RDF network and control systems capabilities; it was assumed that the system was rigid and inflexible, with the RAF fighters being "tied" to their home bases. An optimistic and, as it turned out, erroneous conclusion reached was:
D. Supply Situation... At present the British aircraft industry produces about 180 to 300 first line fighters and 140 first line bombers a month. In view of the present conditions relating to production (the appearance of raw material difficulties, the disruption or breakdown of production at factories owing to air attacks, the increased vulnerability to air attack owing to the fundamental reorganisation of the aircraft industry now in progress), it is believed that for the time being output will decrease rather than increase.
In the event of an intensification of air warfare it is expected that the present strength of the RAF will fall, and this decline will be aggravated by the continued decrease in production.
Because of this statement, reinforced by another more detailed report, issued on 10 August, there was a mindset in the ranks of the Luftwaffe that the RAF would run out of frontline fighters. The Luftwaffe believed it was weakening Fighter Command at three times the actual attrition rate. Many times, the leadership believed Fighter Command's strength had collapsed, only to discover that the RAF were able to send up defensive formations at will.
Throughout the battle, the Luftwaffe had to use numerous reconnaissance sorties to make up for the poor intelligence. Reconnaissance aircraft (initially mostly Dornier Do 17s, but increasingly Bf 110s) proved easy prey for British fighters, as it was seldom possible for them to be escorted by Bf 109s. Thus, the Luftwaffe operated "blind" for much of the battle, unsure of its enemy's true strengths, capabilities, and deployments. Many of the Fighter Command airfields were never attacked, while raids against supposed fighter airfields fell instead on bomber or coastal defence stations. The results of bombing and air fighting were consistently exaggerated, due to inaccurate claims, over-enthusiastic reports and the difficulty of confirmation over enemy territory. In the euphoric atmosphere of perceived victory, the Luftwaffe leadership became increasingly disconnected from reality. This lack of leadership and solid intelligence meant the Germans did not adopt consistent strategy, even when the RAF had its back to the wall. Moreover, there was never a systematic focus on one type of target (such as airbases, radar stations, or aircraft factories); consequently, the already haphazard effort was further diluted.
Navigational aids.
While the British were using radar for air defence more effectively than the Germans realised, the Luftwaffe attempted to press its own offensive with advanced radio navigation systems of which the British were initially not aware. One of these was "Knickebein" ("bent leg"); this system was used at night and for raids where precision was required. It was rarely used during the Battle of Britain (see Reginald Victor Jones and Battle of the Beams).
Air-sea rescue.
The Luftwaffe was much better prepared for the task of air-sea rescue than the RAF, specifically tasking the "Seenotdienst" unit, equipped with about 30 Heinkel He 59 floatplanes, with picking up downed aircrew from the North Sea, English Channel and the Dover Straits. In addition, Luftwaffe aircraft were equipped with life rafts and the aircrew were provided with sachets of a chemical called fluorescein which, on reacting with water, created a large, easy-to-see, bright green patch. In accordance with the Geneva Convention, the He 59s were unarmed and painted white with civilian registration markings and red crosses. Nevertheless, RAF aircraft attacked these aircraft, as some were escorted by Bf 109s.
After single He 59s were forced to land on the sea by RAF fighters, on 1 and 9 July respectively, a controversial order was issued to the RAF on 13 July; this stated that from 20 July, "Seenotdienst" aircraft were to be shot down. One of the reasons given by Churchill was:
We did not recognise this means of rescuing enemy pilots so they could come and bomb our civil population again ... all German air ambulances were forced down or shot down by our fighters on definite orders approved by the War Cabinet.
The British also believed that their crews would report on convoys, the Air Ministry issuing a communiqué to the German government on 14 July that Britain was
unable, however, to grant immunity to such aircraft flying over areas in which operations are in progress on land or at sea, or approaching British or Allied territory, or territory in British occupation, or British or Allied ships. Ambulance aircraft which do not comply with the above will do so at their own risk and peril
The white He 59s were soon repainted in camouflage colours and armed with defensive machine guns. Although another four He 59s were shot down by RAF aircraft, the "Seenotdienst" continued to pick up downed Luftwaffe and Allied aircrew throughout the battle, earning praise from Adolf Galland for their bravery.
RAF strategy.
The Dowding System.
During early tests of the Chain Home system, the slow flow of information from the CH radars and observers to the aircraft often caused them to miss their "bandits". The solution, today known as the "Dowding system", was to create a set of reporting chains to move information from the various observation points to the pilots in their fighters. It was named after its chief architect, "Stuffy" Dowding.
Reports from CH radars and the Observer Corps were sent directly to Fighter Command Headquarters (FCHQ) at Bentley Priory where they were "filtered" to combine multiple reports of the same formations into single tracks. Telephone operators would then forward only the information of interest to the Group headquarters, where the map would be re-created. This process was repeated to produce another version of the map at the Sector level, covering a much smaller area. Looking over their maps, Group level commanders could select squadrons to attack particular targets. From that point the Sector operators would give commands to the fighters to arrange an interception, as well as return them to base. Sector stations also controlled the anti-aircraft batteries in their area; an army officer sat beside each fighter controller and directed the gun crews when to open and cease fire.
The Dowding system dramatically improved the speed and accuracy of the information that flowed to the pilots. During the early war period it was expected that an average interception mission might have a 30% chance of ever seeing their target. During the Battle, the Dowding system maintained an average rate over 75%, with several examples of 100% rates - every fighter dispatched found and intercepted its target. In contrast, Luftwaffe fighters attempting to intercept raids had to randomly seek their targets and often returned home having never seen enemy aircraft. The result is what is now known as an example of "force multiplication"; RAF fighters were as effective as two or more Luftwaffe fighters, greatly offsetting, or overturning, the disparity in actual numbers.
Effect of signals intelligence.
It is unclear how much the British intercepts of the Enigma cipher, used for high-security German radio communications, affected the battle. Ultra, the information obtained from Enigma intercepts, gave the highest echelons of the British command a view of German intentions. According to F. W. Winterbotham, who was the senior Air Staff representative in the Secret Intelligence Service, Ultra helped establish the strength and composition of the Luftwaffe's formations, the aims of the commanders and provided early warning of some raids. In early August it was decided that a small unit would be set up at FCHQ, which would process the flow of information from Bletchley and provide Dowding only with the most essential Ultra material; thus the Air Ministry did not have to send a continual flow of information to FCHQ, preserving secrecy, and Dowding was not inundated with non-essential information. Keith Park and his controllers were also told about Ultra. In a further attempt to camouflage the existence of Ultra, Dowding created a unit named No. 421 (Reconnaissance) Flight RAF. This unit (which later became No. 91 Squadron RAF), was equipped with Hurricanes and Spitfires and sent out aircraft to search for and report Luftwaffe formations approaching England. In addition the radio listening service (known as Y Service), monitoring the patterns of Luftwaffe radio traffic, contributed considerably to the early warning of raids.
Air-sea rescue.
One of the biggest oversights of the entire system was the lack of adequate air-sea rescue organisation. The RAF had started organising a system in 1940 with High Speed Launches (HSLs) based on flying boat bases and at a number of overseas locations, but it was still believed that the amount of cross-Channel traffic meant that there was no need for a rescue service to cover these areas. Downed pilots and aircrew, it was hoped, would be picked up by any boats or ships which happened to be passing by. Otherwise the local life boat would be alerted, assuming someone had seen the pilot going into the water.
RAF aircrew were issued with a life jacket, nicknamed the "Mae West," but in 1940 it still required manual inflation, which was almost impossible for someone who was injured or in shock. The waters of the English Channel and Dover Straits are cold, even in the middle of summer, and clothing issued to RAF aircrew did little to insulate them against these freezing conditions. The RAF also imitated the German practice of issuing fluorescein. A conference in 1939 had placed air-sea rescue under Coastal Command. Because a number of pilots had been lost at sea during the "Channel Battle", on 22 August, control of RAF rescue launches was passed to the local naval authorities and 12 Lysanders were given to Fighter Command to help look for pilots at sea. In all some 200 pilots and aircrew were lost at sea during the battle. No proper air-sea rescue service was formed until 1941.
Tactics.
Fighter formations.
In the late 1930s, Fighter Command expected to face only bombers over Britain, not single-engined fighters. A series of "Fighting Area Tactics" were formulated and rigidly adhered to, involving a series of manoeuvres designed to concentrate a squadron's firepower to bring down bombers. RAF fighters flew in tight, v-shaped sections ("vics") of three, with four such "sections" in tight formation. Only the squadron leader at the front was free to watch for the enemy; the other pilots had to concentrate on keeping station. Training also emphasised by-the-book attacks by sections breaking away in sequence. Fighter Command recognised the weaknesses of this structure early in the battle, but it was felt too risky to change tactics during the battle, because replacement pilots—often with only minimal flying time—could not be readily retrained, and inexperienced pilots needed firm leadership in the air only rigid formations could provide. German pilots dubbed the RAF formations "Idiotenreihen" ("rows of idiots") because they left squadrons vulnerable to attack.
Front line RAF pilots were acutely aware of the inherent deficiencies of their own tactics. A compromise was adopted whereby squadron formations used much looser formations with one or two "weavers" flying independently above and behind to provide increased observation and rear protection; these tended to be the least experienced men and were often the first to be shot down without the other pilots even noticing that they were under attack. During the battle, 74 Squadron under Squadron Leader Adolph "Sailor" Malan adopted a variation of the German formation called the "fours in line astern", which was a vast improvement on the old three aircraft "vic". Malan's formation was later generally used by Fighter Command.
Squadron- and higher-level deployment.
The weight of the battle fell upon 11 Group. Keith Park's tactics were to dispatch individual squadrons to intercept raids. The intention was to subject incoming bombers to continual attacks by relatively small numbers of fighters and try to break up the tight German formations. Once formations had fallen apart, stragglers could be picked off one by one. Where multiple squadrons reached a raid the procedure was for the slower Hurricanes to tackle the bombers while the more agile Spitfires held up the fighter escort. This ideal was not always achieved, resulting in occasions when Spitfires and Hurricanes reversed roles. Park also issued instructions to his units to engage in frontal attacks against the bombers, which were more vulnerable to such attacks. Again, in the environment of fast moving, three-dimensional air battles, few RAF fighter units were able to attack the bombers from head-on.
During the battle, some commanders, notably Leigh-Mallory, proposed squadrons be formed into "Big Wings," consisting of at least three squadrons, to attack the enemy "en masse", a method pioneered by Douglas Bader.
Proponents of this tactic claimed interceptions in large numbers caused greater enemy losses while reducing their own casualties. Opponents pointed out the big wings would take too long to form up, and the strategy ran a greater risk of fighters being caught on the ground refuelling. The big wing idea also caused pilots to overclaim their kills, due to the confusion of a more intense battle zone. This led to the belief big wings were far more effective than they were.
The issue caused intense friction between Park and Leigh-Mallory, as 12 Group was tasked with protecting 11 Group's airfields whilst Park's squadrons intercepted incoming raids. However, the delay in forming up Big Wings meant the formations often did not arrive at all or until after German bombers had hit 11 Group's airfields. Dowding, to highlight the problem of the Big Wing's performance, submitted a report compiled by Park to the Air Ministry on 15 November. In the report, he highlighted that during the period of 11 September – 31 October, the extensive use of the Big Wing had resulted in just 10 interceptions and one German aircraft destroyed, but his report was ignored. Post-war analysis agrees Dowding and Park's approach was best for 11 Group.
Dowding's removal from his post in November 1940 has been blamed on this struggle between Park and Leigh-Mallory's daylight strategy. However, the intensive raids and destruction wrought during the Blitz damaged both Dowding and Park in particular, for the failure to produce an effective night-fighter defence system, something for which the influential Leigh-Mallory had long criticised them.
Bomber and Coastal Command contributions.
Bomber Command and Coastal Command aircraft flew offensive sorties against targets in Germany and France during the battle. After the initial disasters of the war, with Vickers Wellington bombers shot down in large numbers attacking Wilhelmshaven and the slaughter of the Fairey Battle squadrons sent to France, it became clear that Bomber Command would have to operate mainly at night to achieve any results without incurring very high losses. From 15 May 1940, a night time bomber campaign was launched against the German oil industry, communications, and forests/crops, mainly in the Ruhr area.
As the threat mounted, Bomber Command changed targeting priority on 3 June 1940 to attack the German aircraft industry. On 4 July, the Air Ministry gave Bomber Command orders to attack ports and shipping. By September, the build-up of invasion barges in the Channel ports had become a top priority target. On 7 September, the government issued a warning that the invasion could be expected within the next few days and, that night, Bomber Command attacked the Channel ports and supply dumps. On 13 September, they carried out another large raid on the Channel ports, sinking 80 large barges in the port of Ostend. 84 barges were sunk in Dunkirk after another raid on 17 September and by 19 September, almost 200 barges had been sunk. The loss of these barges may have contributed to Hitler's decision to postpone Operation "Sea Lion" indefinitely. The success of these raids was in part because the Germans had few Freya radar stations set up in France, so that air defences of the French harbours were not nearly as good as the air defences over Germany; Bomber Command had directed some 60% of its strength against the Channel ports.
The Bristol Blenheim units also raided German-occupied airfields throughout July to December 1940, both during daylight hours and at night. Although most of these raids were unproductive, there were some successes; on 1 August, five out of 12 Blenheims sent to attack Haamstede and Evere (Brussels) were able to bomb, destroying or heavily damaging three Bf 109s of II./JG 27 and apparently killing a "Staffelkapitän" identified as a "Hauptmann" Albrecht von Ankum-Frank. Two other 109s were claimed by Blenheim gunners. Another successful raid on Haamstede was made by a single Blenheim on 7 August which destroyed one 109 of 4./JG 54, heavily damaged another and caused lighter damage to four more.
There were some missions which produced an almost 100% casualty rate amongst the Blenheims; one such operation was mounted on 13 August 1940 against a Luftwaffe airfield near Aalborg in north-eastern Denmark by 12 aircraft of 82 Squadron. One Blenheim returned early (the pilot was later charged and due to appear before a court martial, but was killed on another operation), the other 11, which reached Denmark, were shot down, five by flak and six by Bf 109s. Of the 33 crewmen who took part in the attack, 20 were killed and 13 captured.
As well as the bombing operations, Blenheim-equipped units had been formed to carry out long-range strategic reconnaissance missions over Germany and German-occupied territories. In this role, the Blenheims again proved to be too slow and vulnerable against Luftwaffe fighters, and they took constant casualties.
Coastal Command directed its attention towards the protection of British shipping, and the destruction of enemy shipping. As invasion became more likely, it participated in the strikes on French harbours and airfields, laying mines, and mounting numerous reconnaissance missions over the enemy-held coast. In all, some 9,180 sorties were flown by bombers from July to October 1940. Although this was much less than the 80,000 sorties flown by fighters, bomber crews suffered about half the total number of casualties borne by their fighter colleagues. The bomber contribution was, therefore, much more dangerous on a loss-per-sortie comparison.
Bomber, reconnaissance, and antisubmarine patrol operations continued throughout these months with little respite and none of the publicity accorded to Fighter Command. In his famous 20 August speech about "The Few", praising Fighter Command, Churchill also made a point of mentioning Bomber Command's contribution, adding that bombers were even then striking back at Germany; this part of the speech is often overlooked, even today. The Battle of Britain Chapel in Westminster Abbey lists in a Roll of Honour, 718 Bomber Command crew members, and 280 from Coastal Command who were killed between 10 July and 31 October.
Phases of the battle.
The Battle can be roughly divided into four phases:
Channel battles.
The "Kanalkampf" comprised a series of running fights over convoys in the English Channel. It was launched partly because Kesselring and Sperrle were not sure about what else to do, and partly because it gave German aircrews some training and a chance to probe the British defences. Dowding could only provide minimal shipping protection, and these battles off the coast tended to favour the Germans, whose bomber escorts had the advantage of altitude and outnumbered the RAF fighters. From 9 July reconnaissance probing by Dornier Do 17 bombers put a severe strain on RAF pilots and machines, with high RAF losses to Bf 109s. When nine 141 Squadron Defiants went into action on 19 July six were lost to Bf 109s before a squadron of Hurricanes intervened. On 25 July a coal convoy and escorting destroyers suffered such heavy losses to attacks by Stuka dive bombers that the Admiralty decided convoys should travel at night: the RAF shot down 16 raiders but lost 7 aircraft. By 8 August 18 coal ships and 4 destroyers had been sunk, but the Navy was determined to send a convoy of 20 ships through rather than move the coal by railway. After repeated Stuka attacks that day, six ships were badly damaged, four were sunk and only four reached their destination. The RAF lost 19 fighters and shot down 31 German aircraft. The Navy now cancelled all further convoys through the Channel and sent the cargo by rail. Even so these early combat encounters provided both sides with experience.
Main assault.
The main attack upon the RAF's defences was code-named "Adlerangriff" ("Eagle Attack").
Poor weather delayed "Adlertag" ("Eagle Day") until 13 August 1940. On 12 August, the first attempt was made to blind the Dowding system, when aircraft from the specialist fighter-bomber unit "Erprobungsgruppe" 210 attacked four radar stations. Three were briefly taken off the air but were back working within six hours. The raids appeared to show that British radars were difficult to knock out. The failure to mount follow-up attacks allowed the RAF to get the stations back on the air, and the Luftwaffe neglected strikes on the supporting infrastructure, such as phone lines and power stations, which could have rendered the radars useless, even if the towers themselves (which were very difficult to destroy) remained intact.
"Adlertag" opened with a series of attacks, led again by "Epro" 210, on coastal airfields used as forward landing grounds for the RAF fighters, as well as 'satellite airfields' (including Manston and Hawkinge). As the week drew on, the airfield attacks moved further inland, and repeated raids were made on the radar chain. 15 August was "The Greatest Day" when the Luftwaffe mounted the largest number of sorties of the campaign. "Luftflotte" 5 attacked the north of England. Believing Fighter Command strength to be concentrated in the south, raiding forces from Denmark and Norway ran into unexpectedly strong resistance. Inadequately escorted by Bf 110s, bombers were shot down in large numbers. North East England was attacked by 65 Heinkel 111s escorted by 34 Messerschmitt 110s, and RAF Great Driffield was attacked by 50 unescorted Junkers 88s. Out of 115 bombers and 35 fighters sent, 16 bombers and 7 fighters were destroyed. As a result of these casualties, "Luftflotte" 5 did not appear in strength again in the campaign.
18 August, which had the greatest number of casualties to both sides, has been dubbed "The Hardest Day". Following this grinding battle, exhaustion and the weather reduced operations for most of a week, allowing the Luftwaffe to review their performance. "The Hardest Day" had sounded the end for the Ju 87 in the campaign. This veteran of "Blitzkrieg" was too vulnerable to fighters to operate over Britain. So as to preserve the "Stuka" force, Göring withdrew them from the fighting. This removed the main Luftwaffe precision-bombing weapon and shifted the burden of pinpoint attacks on the already-stretched "Erpro" 210. The Bf 110 proved too clumsy for dogfighting with single-engined fighters, and its participation was scaled back. It would only be used when range required it or when sufficient single-engined escort could not be provided for the bombers.
Göring made yet another fateful decision: to order more bomber escorts at the expense of free-hunting sweeps. To achieve this, the weight of the attack now fell on "Luftflotte" 2, and the bulk of the Bf 109s in "Luftflotte 3" were transferred to Kesselring's command, reinforcing the fighter bases in the Pas-de-Calais. Stripped of its fighters, "Luftflotte 3" would concentrate on the night bombing campaign. Göring, expressing disappointment with the fighter performance thus far in the campaign, also made sweeping changes in the command structure of the fighter units, replacing many "Geschwaderkommodore" with younger, more aggressive pilots like Adolf Galland and Werner Mölders.
Finally, Göring stopped the attacks on the radar chain. These were seen as unsuccessful, and neither the "Reichsmarschall" nor his subordinates realised how vital the Chain Home stations were to the defence systems. It was known that radar provided some early warning of raids, but the belief among German fighter pilots was that anything bringing up the "Tommies" to fight was to be encouraged.
The Luftwaffe targets RAF airfields.
Battle.
Göring ordered attacks on aircraft factories on 19 August 1940; on 23 August 1940 he ordered that RAF airfields be attacked. That evening an attack was mounted on a tyre factory in Birmingham. Raids on airfields continued through 24 August, and Portsmouth was hit by a major attack. That night, several areas of London were bombed; the East End was set ablaze and bombs landed on central London. Some historians believe that these bombs were dropped accidentally by a group of Heinkel He 111s which had failed to find their target; this account has been contested. In retaliation, the RAF bombed Berlin on the night of 25–26 August, and continued bombing raids on Berlin. Göring's pride was hurt, as he had previously claimed the British would never be able to bomb the city. The attacks enraged Hitler, who ordered retaliatory attacks on London.
From 24 August onwards, the battle was a fight between Kesselring's "Luftflotte" 2 and Park's 11 Group. The Luftwaffe concentrated all their strength on knocking out Fighter Command and made repeated attacks on the airfields. Of the 33 heavy attacks in the following two weeks, 24 were against airfields. The key sector stations were hit repeatedly: Biggin Hill and Hornchurch four times each; Debden and North Weald twice each. Croydon, Gravesend, Rochford, Hawkinge and Manston were also attacked in strength. Coastal Command's Eastchurch was bombed at least seven times because it was believed to be a Fighter Command aerodrome. At times these raids caused some damage to the sector stations, threatening the integrity of the Dowding system.
To offset some losses, some 58 Fleet Air Arm fighter pilot volunteers were seconded to RAF squadrons, and a similar number of former Fairey Battle pilots were used. Most replacements from Operational Training Units (OTUs) had as little as nine hours flying time and no gunnery or air-to-air combat training. At this point, the multinational nature of Fighter Command came to the fore. Many squadrons and personnel from the air forces of the Dominions were already attached to the RAF, including top level commanders – Australians, Canadians, New Zealanders, Rhodesians and South Africans. In addition, there were other nationalities represented, including Free French, Belgian and a Jewish pilot from the British mandate of Palestine.
They were bolstered by the arrival of fresh Czechoslovak and Polish squadrons. These had been held back by Dowding, who mistakenly thought non-English speaking aircrew would have trouble working within his control system: Polish and Czech fliers proved to be especially effective. The pre-war Polish Air Force had lengthy and extensive training, and high standards; with Poland conquered and under brutal German occupation, the pilots of No. 303 (Polish) Squadron, the highest-scoring Allied unit, were strongly motivated. Josef František, a Czech regular airman who had flown from the occupation of his own country to join the Polish and then French air forces before arriving in Britain, flew as a guest of 303 Squadron and was ultimately credited with the highest "RAF score" in the Battle of Britain.
The RAF had the advantage of fighting over home territory. Pilots who bailed out of their downed aircraft could be back at their airfields within hours, while if low on fuel and/or ammunition they could be immediately rearmed. One RAF pilot interviewed in late 1940 had been shot down five times during the Battle of Britain, but was able to crash land in Britain or bail out each time. For Luftwaffe aircrews, a bailout over England meant capture – in the critical August period, almost exactly as many Luftwaffe pilots were taken prisoner as were killed – while parachuting into the English Channel often meant drowning or death from exposure. Morale began to suffer, and "Kanalkrankheit" ("Channel sickness") – a form of combat fatigue – began to appear among the German pilots. Their replacement problem was even worse than the British.
Impact of offensive.
The effect of the German attacks on airfields is unclear. According to Stephen Bungay, Dowding, in a letter to Hugh Trenchard accompanying Park's report on the period 8 August – 10 September 1940, states that the Luftwaffe "achieved very little" in the last week of August and the first week of September. The only Sector Station to be shut down operationally was Biggin Hill, and it was non-operational for just two hours. Dowding admitted 11 Group's efficiency was impaired but, despite serious damage to some airfields, only two out of 13 heavily attacked airfields were down for more than a few hours. The German refocus on London was not critical.
Retired air marshal Peter Dye, head of the RAF Museum, discussed the logistics of the battle in 2000 and 2010, dealing specifically with the single-seat fighters. Dye contends that not only was British aircraft production replacing aircraft, but replacement pilots were keeping pace with losses. The number of pilots in RAF Fighter Command increased during July, August and September. The figures indicate the number of pilots available never decreased. From July, 1,200 were available. In 1 August, 1,400 were available. Just over that number were in the field by September. In October the figure was nearly 1,600. By 1 November 1,800 were available. Throughout the battle, the RAF had more fighter pilots available than the Luftwaffe. Although the RAF's reserves of single seat fighters fell during July, the wastage was made up for by an efficient Civilian Repair Organisation (CRO), which by December had repaired and put back into service some 4,955 aircraft, and by aircraft held at Air Servicing Unit (ASU) airfields.
Richard Overy agrees with Dye and Bungay. Overy asserts only one airfield was temporarily put out of action and "only" 103 pilots were lost. British fighter production produced 496 new aircraft in July and 467 in August, and another 467 in September (not counting repaired aircraft), covering the losses of August and September. Overy indicates the number of serviceable and total strength returns reveal an "increase" in fighters from 3 August to 7 September, 1,061 on strength and 708 serviceable to 1,161 on strength and 746 serviceable. Moreover, Overy points out that the number of RAF fighter pilots grew by one-third between June and August 1940. Personnel records show a constant supply of around 1,400 pilots in the crucial weeks of the battle. In the second half of September it reached 1,500. The shortfall of pilots was never above 10%. The Germans never had more than between 1,100 and 1,200 pilots, a deficiency of up to one-third. "If Fighter Command were 'the few', the German fighter pilots were fewer".
Other scholars assert that this period was the most dangerous of all. In "The Narrow Margin", published in 1961, historians Derek Wood and Derek Dempster believed that the two weeks from 24 August to 6 September represented a real danger. According to them, from 24 August to 6 September 295 fighters had been totally destroyed and 171 badly damaged, against a total output of 269 new and repaired Spitfires and Hurricanes. They assert that 103 pilots were killed or missing and 128 were wounded, which represented a total wastage of 120 pilots per week out of a fighting strength of just fewer than 1,000. They conclude that during August no more than 260 fighter pilots were turned out by OTUs and casualties in the same month were just over 300. A full squadron establishment was 26 pilots whereas the average in August was 16. In their assessment, the RAF was losing the battle. Denis Richards, in his 1953 contribution to the official British account "History of the Second World War", agreed that lack of pilots, especially experienced ones, was the RAF's greatest problem. He states that between 8 and 18 August 154 RAF pilots were killed, severely wounded, or missing, while only 63 new pilots were trained. Availability of aircraft was also a serious issue. While its reserves during the Battle of Britain never declined to a half dozen planes as some later claimed, Richards describes 24 August to 6 September as the critical period because during these two weeks Germany destroyed far more aircraft through its attacks on 11 Group's southeast bases than Britain was producing. Three more weeks of such a pace would indeed have exhausted aircraft reserves. Germany had seen heavy losses of pilots and aircraft as well however, thus its shift to night-time attacks in September. On 7 September RAF aircraft losses fell below British production and remained so until the end of the war.
Raids on British cities.
Hitler's No. 17 Directive on the conduct of war against England, issued on 1 August 1940, specifically prohibited the Luftwaffe from conducting terror raids on its own initiative, and reserved the right of ordering terror attacks as means of reprisal for the Führer himself:
The war against England is to be restricted to destructive attacks against industry and air force targets which have weak defensive forces ... The most thorough study of the target concerned, that is vital points of the target, is a pre-requisite for success. It is also stressed that every effort should be made to avoid unnecessary loss of life amongst the civilian population.
The Luftwaffe offensive against Britain had included numerous raids on major ports since August, but Hitler had issued a directive that London was not to be bombed save on his sole instruction. However, on the afternoon of 15 August, "Hauptmann" Walter Rubensdörffer leading "Erprobungsgruppe" 210 mistakenly bombed the Croydon airfield (on the outskirts of London) instead of the intended target, RAF Kenley; this was followed on the night of 23/24 August by the accidental bombing of Harrow, also on the outskirts of London, as well as raids on Aberdeen, Bristol, and South Wales. The focus on attacking airfields had also been accompanied by a sustained bombing campaign which began on 24 August with the largest raid so far, killing 100 in Portsmouth, and that evening the first night raid on London as described above. On 25 August 1940, 81 bombers of Bomber Command were sent out to raid industrial and commercial targets in Berlin. Clouds prevented accurate identification and the bombs fell across the city, causing some casualties among the civilian population as well as damage to residential areas. Continuing RAF raids on Berlin in retaliation led to Hitler withdrawing his directive, and on 3 September Göring planned to bomb London daily, with General Albert Kesselring's enthusiastic support, having received reports the average strength of RAF squadrons was down to five or seven fighters out of twelve and their airfields in the area were out of action. Hitler issued a directive on 5 September to attack cities including London. In his speech delivered on 4 September 1940, Hitler threatened to obliterate ("ausradieren") British cities if British bombing runs against Germany did not stop.
On 7 September, a massive series of raids involving nearly four hundred bombers and more than six hundred fighters targeted docks in the East End of London, day and night. The raids were code named Operation "Loge". The RAF anticipated attacks on airfields and 11 Group rose to meet them, in greater numbers than the Luftwaffe expected. The first official deployment of 12 Group's Lee-Mallory's Big Wing took twenty minutes to form up, missing its intended target, but encountering another formation of bombers while still climbing. They returned, apologetic about their limited success, and blamed the delay on being scrambled too late. Fighter Command had been at its lowest ebb, short of men and machines, and the break from airfield attacks allowed them to recover. 11 Group had considerable success in breaking up daytime raids. 12 Group repeatedly disobeyed orders and failed to meet requests to protect 11 Group airfields, but their experiments with increasingly large Big Wings had some success. The Luftwaffe began to abandon their morning raids, with attacks on London starting late in the afternoon for fifty-seven consecutive nights.
The most damaging aspect to the Luftwaffe of targeting London was the increase in range. The Bf 109E escorts had a limited fuel capacity resulting in only a 660 km (410 mile) maximum range solely on internal fuel, and when they arrived had only 10 minutes of flying time before turning for home, leaving the bombers undefended by fighter escorts. Its eventual stablemate, the Focke-Wulf Fw 190A, was only flying in prototype form in the summer of 1940; the first 28 Fw 190s were not delivered until November 1940. The Fw 190A-1 had a maximum range of 940 km (584 miles) on internal fuel, 40% greater than the Bf 109E. The Messerschmitt Bf 109E-7 corrected this deficiency by adding a ventral center-line ordnance rack to take either an SC 250 bomb or a standard 300 litre Luftwaffe drop tank to double the range to 1,325 km (820 mi). The ordnance rack was not retrofitted to earlier Bf 109Es until October 1940. 
On 14 September, Hitler chaired a meeting with the OKW staff. Göring was in France directing the decisive battle, so Erhard Milch deputized for him. Hitler asked "Should we call it off altogether?". General Hans Jeschonnek, Luftwaffe Chief of Staff, begged for a last chance to defeat the RAF and for permission to launch attacks on civilian residential areas to cause mass panic. Hitler refused the latter, perhaps unaware of how much damage had already been done to civilian targets. He reserved for himself the power to unleash the terror weapon. Instead political will was to be broken by destroying the material infrastructure, the weapons industry, and stocks of fuel and food.
On 15 September, two massive waves of German attacks were decisively repulsed by the RAF by deploying every aircraft in 11 Group. Sixty German and 26 RAF aircraft were shot down. Two days after the German defeat Hitler postponed preparations for the invasion of Britain. Henceforth, in the face of mounting losses in men, aircraft and the lack of adequate replacements, the Luftwaffe switched from daylight to nighttime bombing. 15 September is commemorated as Battle of Britain Day.
On 16 September, Göring ordered the air fleets to begin the new phase of the battle. Hitler hoped this might result in "eight million going mad" (referring to the population of London in 1940), which would "cause a catastrophe" for the British. In those circumstances, Hitler said, "even a small invasion might go a long way". Hitler was against cancelling the invasion as "the cancellation would reach the ears of the enemy and strengthen his resolve".
A Junkers Ju 88 returning from a raid on London was shot down in Kent on 27 September resulting in the Battle of Graveney Marsh, the last action between British and foreign military forces on British mainland soil.
Hitler postponed the invasion on 13 October "until the spring of 1941", and October is regarded as the month regular bombing of Britain ended. It was not until Hitler's Directive 21 was issued, on 18 December 1940, that the threat of invasion finally ended.
During the battle, and for the rest of the war, an important factor in keeping public morale high was the continued presence in London of King George VI and his wife Queen Elizabeth. When war broke out in 1939, the King and Queen decided to stay in London and not flee to Canada, as had been suggested. George VI and Elizabeth officially stayed in Buckingham Palace throughout the war, although they often spent weekends at Windsor Castle to visit their daughters, Elizabeth (the future queen) and Margaret. Buckingham Palace was damaged by bombs which landed in the grounds on 10 September and, on 13 September, more serious damage was caused by two bombs which destroyed the Royal Chapel. The royal couple were in a small sitting room about 80 yards from where the bombs exploded. On 24 September, in recognition of the bravery of civilians, King George VI inaugurated the award of the George Cross.
Attrition statistics.
Overall, by 2 November, the RAF fielded 1,796 pilots, an increase of over 40% from July 1940's count of 1,259 pilots. Based on German sources (from a Luftwaffe intelligence officer Otto Bechtle attached to KG 2 in February 1944) translated by the Air Historical Branch, Stephen Bungay asserts German fighter and bomber "strength" declined without recovery, and that from August – December 1940, the German fighter and bomber strength declined by 30 and 25 percent. In contrast, Williamson Murray, argues (using translations by the Air Historical Branch) that 1,380 German bombers were on strength on 29 June 1940, 1,420 bombers on 28 September, 1,423 level bombers on 2 November and 1,393 bombers on 30 November 1940. In July – September the number of Luftwaffe pilots available fell by 136, but the number of operational pilots had shrunk by 171 by September. The training organisation of the Luftwaffe was failing to replace losses. German fighter pilots, in contrast to popular perception, were not afforded training or rest rotations unlike their British counterparts. The first week of September accounted for 25% of the Fighter Command, and 24% of the "Luftwaffe's" overall losses. Between the dates 26 August – 6 September, on only one day (1 September) did the Germans destroy more aircraft than they lost. Losses were 325 German and 248 British.
Luftwaffe losses for August numbered 774 aircraft to all causes, representing 18.5% of all combat aircraft at the beginning of the month. Fighter Command's losses in August were 426 fighters destroyed, amounting to 40 per cent of 1,061 fighters available on 3 August. In addition, 99 German bombers and 27 other types were destroyed between 1 and 29 August.
From July to September, the Luftwaffe's loss records indicate the loss of 1,636 aircraft, 1,184 to enemy action. This represented 47% of the initial strength of single-engined fighters, 66% of twin-engined fighters, and 45% of bombers. This indicates the Germans were running out of aircrews as well as aircraft.
Throughout the battle, the Germans greatly underestimated the size of the RAF and the scale of British aircraft production. Across the Channel, the Air Intelligence division of the Air Ministry consistently overestimated the size of the German air enemy and the productive capacity of the German aviation industry. As the battle was fought, both sides exaggerated the losses inflicted on the other by an equally large margin. However, the intelligence picture formed before the battle encouraged the Luftwaffe to believe that such losses pushed Fighter Command to the very edge of defeat, while the exaggerated picture of German air strength persuaded the RAF that the threat it faced was larger and more dangerous than was the case. This led the British to the conclusion that another fortnight of attacks on airfields might force Fighter Command to withdraw their squadrons from the south of England. The German misconception, on the other hand, encouraged first complacency, then strategic misjudgement. The shift of targets from air bases to industry and communications was taken because it was assumed that Fighter Command was virtually eliminated.
Between the 24 August and 4 September, German serviceability rates, which were acceptable at "Stuka" units, were running at 75% with Bf 109s, 70% with bombers and 65% with Bf 110s, indicating a shortage of spare parts. All units were well below established strength. The attrition was beginning to affect the fighters in particular." By 14 September, the Luftwaffe's Bf 109 "Geschwader" possessed only 67% of their operational crews against authorised aircraft. For Bf 110 units it was 46 per cent; and for bombers it was 59 per cent. A week later the figures had dropped to 64 per cent, 52% and 52 per cent. Serviceability rates in Fighter Command's fighter squadrons, between the 24 August and 7 September, were listed as: 64.8% on 24 August; 64.7% on 31 August and 64.25% on 7 September 1940.
Due to the failure of the Luftwaffe to establish air supremacy, a conference assembled on 14 September at Hitler's headquarters. Hitler concluded that air superiority had not yet been established and "promised to review the situation on 17 September for possible landings on 27 September or 8 October. Three days later, when the evidence was clear that the German Air Force had greatly exaggerated the extent of their successes against the RAF, Hitler postponed "Sea Lion" indefinitely."
Aftermath.
The Battle of Britain marked the first defeat of Hitler's military forces, with air superiority seen as the key to victory. Pre-war theories had led to exaggerated fears of strategic bombing, and British public opinion was buoyed by coming through the ordeal. For the RAF, Fighter Command had achieved a great victory in successfully carrying out Sir Thomas Inskip's 1937 air policy of preventing the Germans from knocking Britain out of the war. Churchill concluded his famous 18 June 'Battle of Britain' speech in the House of Commons by referring to pilots and aircrew who fought the Battle: "... if the British Empire and its Commonwealth lasts for a thousand years, men will still say, 'This was their finest hour.'"
The Battle also significantly shifted American opinion. During the battle, many Americans accepted the view promoted by Joseph Kennedy, the American ambassador in London, who believed that Great Britain could not survive. Roosevelt wanted a second opinion, and sent "Wild Bill" Donovan on a brief visit to Britain; he became convinced Britain would survive and should be supported in every possible way. Before the end of the year, American journalist Ralph Ingersoll, who had been in Britain, published an influential book concluding that "Adolf Hitler met his first defeat in eight years" in what might "go down in history as a battle as important as Waterloo or Gettysburg". The turning point was when the Germans reduced the intensity of the Blitz after 15 September. According to Ingersoll, "[a] majority of responsible British officers who fought through this battle believe that if Hitler and Göring had had the courage and the resources to lose 200 planes a day for the next five days, nothing could have saved London"; instead, "[the Luftwaffe's] morale in combat is definitely broken, and the RAF has been gaining in strength each week."
Both sides in the battle made exaggerated claims of numbers of enemy aircraft shot down. In general, claims were two to three times the actual numbers, because of the confusion of fighting in dynamic three-dimensional air battles. Postwar analysis of records has shown that between July and September, the RAF claimed 2,698 kills, while the Luftwaffe fighters claimed 3,198 RAF aircraft downed. Total losses, and start and end dates for recorded losses, vary for both sides. Luftwaffe losses from 10 July to 30 October 1940 total 1,652 aircraft, including 229 twin- and 533 single-engined fighters. In the same period, RAF Fighter Command aircraft losses number 1,087, including 53 twin-engined fighters. To the RAF figure should be added 376 Bomber Command and 148 Coastal Command aircraft conducting bombing, mining, and reconnaissance operations in defence of the country.
Dr. Andrew Gordon, who lectures at the Joint Services Command and Staff College, and a former lecturer Professor Gary Sheffield, have suggested the existence of the Royal Navy was enough to prevent the Germans from invading; even had the Luftwaffe won the air battle, the Germans had limited means with which to combat the Royal Navy, which would have intervened to prevent a landing. Some veterans of the battle point out the Royal Navy would have been vulnerable to air attack by the Luftwaffe if Germany had achieved air superiority, citing the sinking of "Prince of Wales" and "Repulse" in December 1941 by an attack by Japanese aircraft. In late May 1941 during the successful German airborne assault which seized Crete, the Royal Navy was able to prevent attempted German seaborne landings on the coast of Crete, but they due to undisputed Luftwaffe air supremacy and the British were forced to evacuate the island. Churchill later wrote that the Royal Navy's defeat of "these practically defenceless convoys of troops across waters of which they did not possess naval command as well as that of the air is a sample of what might have happened on a gigantic scale in the North Sea and English Channel in September 1940."
A considered view of the battle also has to take into account the vital role of the Royal Navy. It was widely acknowledged by both sides that the only way of achieving a successful invasion of the British Isles was through the establishment of naval supremacy. Given the inability of the Luftwaffe to effect real damage on the RN throughout the battle and during the Dunkirk and Norwegian campaigns, as well as the lack of surface assets in the Kreigsmarine's inventory, sea control of the Channel by Germany was impossible. As one of 'the Few', Wg Cdr H R Allen said, "It was sea power that ruled the day in 1940, and fortunately Britain had a sufficiency. The air situation was, of course, important, but by no means fundamental. Without doubt the five hundred or so section, flight and squadron commanders in Fighter Command earned their laurels. But the real victor was the Royal Navy, the Silent Service."
The Luftwaffe had 1,380 bombers on 29 June 1940. By 2 November 1940, this had increased to 1,423, and to 1,511 by 21 June 1941, prior to Operation "Barbarossa", but showing a drop of 200 from 1,711 reported on 11 May 1940. 1,107 single- and 357 twin-engined daylight fighters were reported on strength prior to the battle on 29 June 1940, compared to 1,440 single- and 188 twin-engined fighters, plus 263 night fighters, on 21 June 1941.
There is a consensus among historians that the Luftwaffe simply could not crush the RAF. Stephen Bungay described Dowding and Park's strategy of choosing when to engage the enemy whilst maintaining a coherent force as vindicated; their leadership, and the subsequent debates about strategy and tactics, however, had created enmity among RAF senior commanders and both were sacked from their posts in the immediate aftermath of the battle. All things considered, the RAF proved to be a robust and capable organisation which was to use all the modern resources available to it to the maximum advantage. Richard Evans wrote:
Irrespective of whether Hitler was really set on this course, he simply lacked the resources to establish the air superiority that was the sine qua non-of a successful crossing of the English Channel. A third of the initial strength of the German air force, the Luftwaffe, had been lost in the western campaign in the spring. The Germans lacked the trained pilots, the effective fighter aircraft, and the heavy bombers that would have been needed.
The Germans launched some spectacular attacks against important British industries, but they could not destroy the British industrial potential, and made little systematic effort to do so. Hindsight does not disguise the fact the threat to Fighter Command was very real, and for the participants it seemed as if there was a narrow margin between victory and defeat. Nevertheless, even if the German attacks on the 11 Group airfields which guarded southeast England and the approaches to London had continued, the RAF could have withdrawn to the Midlands out of German fighter range and continued the battle from there. The victory was as much psychological as physical. Writes Alfred Price:
The truth of the matter, borne out by the events of 18 August is more prosaic: neither by attacking the airfields, nor by attacking London, was the Luftwaffe likely to destroy Fighter Command. Given the size of the British fighter force and the general high quality of its equipment, training and morale, the Luftwaffe could have achieved no more than a Pyrrhic victory. During the action on 18 August it had cost the Luftwaffe five trained aircrew killed, wounded or taken prisoner, for each British fighter pilot killed or wounded; the ratio was similar on other days in the battle. And this ratio of 5:1 was very close to that between the number of German aircrew involved in the battle and those in Fighter Command. In other words the two sides were suffering almost the same losses in trained aircrew, in proportion to their overall strengths. In the Battle of Britain, for the first time during the Second World War, the German war machine had set itself a major task which it patently failed to achieve, and so demonstrated that it was not invincible. In stiffening the resolve of those determined to resist Hitler the battle was an important turning point in the conflict.
The British victory in the Battle of Britain was achieved at a heavy cost. Total British civilian losses from July to December 1940 were 23,002 dead and 32,138 wounded, with one of the largest single raids on 19 December 1940, in which almost 3,000 civilians died. With the culmination of the concentrated daylight raids, Britain was able to rebuild its military forces and establish itself as an Allied stronghold, later serving as a base from which the Liberation of Western Europe was launched.
Battle of Britain Day.
Winston Churchill summed up the effect of the battle and the contribution of Fighter Command with the words, "Never in the field of human conflict was so much owed by so many to so few". Pilots who fought in the Battle have been known as "The Few" ever since; at times being specially commemorated for on "Battle of Britain Day" the 15th of September. On this day in 1940, the Luftwaffe embarked on their largest bombing attack yet, forcing the engagement of the entirety of the RAF in defence of London and the South East, which resulted in a decisive victory in favour of Britain that proved to mark a turning point in Britain's favour.
Within the Commonwealth, Battle of Britain Day has been observed more usually on the third Sunday in September, and even as the 2nd Thursday of September in some areas in the British Channel Islands.
The day has been observed by many artists over the years, including works that shop the battle itself. Many Mixed Media artists have also created pieces in honor of the Battle of Britain.
Film.
The story of the battle was documented in, amongst many others, the 1969 film "Battle of Britain", which drew many respected British actors to act key figures of the battle, including Sir Laurence Olivier as Hugh Dowding and Trevor Howard as Keith Park. It also starred Michael Caine, Christopher Plummer and Robert Shaw as Squadron Leaders. Former participants of the battle served as technical advisors including Douglas Bader, James Lacey, Robert Stanford Tuck, Adolf Galland and Dowding himself. An Italian film around the same time titled "Eagles Over London" (1969) also featured the Battle of Britain.
It was also the subject of the 1941 Allied propaganda film "Churchill's Island", winner of the first-ever Academy Award for Documentary Short Subject.
In 2010, actor Julian Glover played a 101-year-old Polish veteran RAF pilot in the short film, "Battle for Britain".
Bibliography.
General.
</dl>
Autobiographies and biographies.
</dl>
Aircraft.
</dl>
Additional references.
</dl>

</doc>
<doc id="57975" url="http://en.wikipedia.org/wiki?curid=57975" title="Time Team">
Time Team

Time Team is a British television series which has been aired on British Channel 4 from 1994. Created by television producer Tim Taylor and presented by actor Tony Robinson, each episode featured a team of specialists carrying out an archaeological dig over a period of three days, with Robinson explaining the process in layman's terms. This team of specialists changed throughout the series' run, although has consistently included professional archaeologists such as Mick Aston, Carenza Lewis, Francis Pryor and Phil Harding. The sites excavated over the show's run have ranged in date from the Palaeolithic to the Second World War.
In October 2012, Channel 4 announced that the final series would be broadcast in 2013. Series 20 was screened in January–March 2013 and a number of specials were screened in 2014.
Format.
A team of archaeologists, usually led by either Mick Aston or Francis Pryor (the latter usually heads Bronze Age and Iron Age digs), and including field archaeologist Phil Harding, congregate at a site, usually in the United Kingdom. The site is frequently suggested by a member of the viewing public who knows of an unsolved archaeological mystery, or who owns property that has not been excavated and is potentially interesting. "Time Team" uncover as much as they can about the archaeology and history of the site in three days.
At the start of the programme, Tony Robinson explains, in an opening "piece to camera", the reasons for the team's visit to the site, and during the dig he enthusiastically encourages the archaeologists to explain their decisions, discoveries and conclusions. He tries to ensure that everything is comprehensible to the archaeologically uninitiated.
Excavations are not just carried out to entertain viewers. Tony Robinson claims that the archaeologists involved with "Time Team" have published more scientific papers on excavations carried out in the series than all British university archaeology departments put together over the same period; and also that, as of 2013, the programme had become the biggest funder of field archaeology in the country.
"Time Team" developed from an earlier Channel 4 series, "Time Signs", first broadcast in 1991. Produced by Taylor, "Time Signs" had featured Aston and Harding, who both went on to appear on "Time Team". Following that show's cancellation, Taylor went on to develop a more attractive format, producing the idea for "Time Team", which Channel 4 also picked up, broadcasting the first series in 1994. "Time Team" has had many companion shows during its run, including "Time Team Extra" (1998), "History Hunters" (1998-1999) and "Time Team Digs" (1997-2006), whilst several spin-off books have also been published. The series also features special episodes, often documentaries on history or archaeology, and live episodes. "Time Team America", a US version of the programme, was broadcast on PBS in 2009, and co-produced by Oregon Public Broadcasting and Videotext/C4i. The programme has been exported to 35 other countries
In February 2012, it was announced that expert Mick Aston had quit the show due to format changes. The disputed changes included hiring a former model (Mary Ann Ochota) as a co-presenter, the letting go of other archaeologists, and what he thought were plans to "cut down the informative stuff about the archaeology". "The time had come to leave. I never made any money out of it, but a lot of my soul went into it. I feel really, really angry about it," he told "British Archaeology" magazine. "Time Team" producer Tim Taylor released a statement in response to the news reports saying "His concerns are of great importance to me. We have addressed some of them", and that "you’ve not heard the last of Mick on "Time Team"".
Other team members.
The regular team also includes:
The original "Time Team" line-up from 1994 has altered over the years. The historian Robin Bush was a regular in the first nine series, having been involved with the programme through his long friendship with Mick Aston. In 2005, Carenza Lewis left to pursue other interests. She was replaced by Anglo-Saxon specialist Helen Geake. Architectural historian Beric Morley featured in ten episodes between 1995 and 2002.
The team is supplemented by experts appropriate for the period and type of site. Guy de la Bédoyère has often been present for Roman digs, as well as those involving the Second World War such as D-Day and aircraft (such as the Spitfire). Architectural historian Jonathan Foyle has appeared in episodes relating to excavations of country estates. Paul Blinkhorn (pottery), Mark Corney (coins), Danielle Wootton (small finds) and Jackie McKinley (bones) have appeared from time to time. Mick ‘the dig’ Worthington, an excavator in the early series, occasionally returns as a dendrochronologist. Margaret Cox often assisted with forensic archaeology, mainly between 1998 and 2005. Other specialists who appear from time to time include historian Bettany Hughes and David S. Neal, expert on Roman mosaics. Local historians also join in when appropriate.
More recent regular team members have included archaeologist Neil Holbrook, Roman coins specialist Philippa Walton, and historian Sam Newton.
Younger members of "Time Team" who have made, or currently make, regular appearances include:
Production.
"Time Team" is commissioned by Channel 4 Television (the broadcaster) and made in partnership between VideoText Communications Ltd and Picturehouse Television Co. Ltd (based in London). Recently formed Wildfire Television was involved in the production of "The Big Roman Dig" (2005) and "The Big Royal Dig" (2006). It is produced by Tim Taylor, the show's originator, with Associate Producer Tony Robinson.
Sites.
Time Team excavating Groby Castle and Old Hall in 2010
Sites may be suggested by landowners, local archaeologists, academics, interested bodies or members of the general public, and have included everything from the Paleolithic period to World War II. For example programmes have featured the excavation of Bronze Age and Iron Age settlements, Roman villas and medieval churches. Several excavations have resulted in the discovery of sites of national significance.
DVD releases.
Complete series have been released in Australia starting with Series 15 in 2010. Since then, Series 12 (2014), Series 14 (2012), Series 16 (2010), Series 17 (2011), Series 18 (2012), Series 19 (2012) and Series 20 (2013) have all been released in Australia. 'Best Of' DVDs were released in the UK over the years however a complete series had never been released until Series 18 was released by Acorn Media UK on 6 February 2012. On 15 May 2012, Acorn Media released a collection of Roman themed episodes on Region One DVD.
Other formats.
Other shows.
"Time Team's Big Dig" was an expansion on the live format. A weekend of live broadcasts in June 2003 was preceded by a week of daily short programmes. It involved about a thousand members of the public in excavating test pits each one metre square by fifty centimetres deep. Most of these pits were in private gardens and the project stirred up controversies about approaches to public archaeology.
"Time Team's Big Roman Dig" (2005) saw this format altered, in an attempt to avoid previous controversies, through the coverage of nine archaeological sites around the UK which were already under investigation by professional archaeologists. "Time Team" covered the action through live link-ups based at a Roman Villa at Dinnington in Somerset - itself a "Time Team" excavation from 2003. Over 60 other professionally-supervised excavations were supported by "Time Team" and carried out around the country in association with the programme. A further hundred activities relating to Roman history were carried out by schools and other institutions around the UK.
"Time Team Specials" are documentary programmes about topics in history and archaeology made by the same production company. They are generally presented by Tony Robinson and often feature one or more of the familiar faces from the regular series of "Time Team". In some cases the programme makers have followed the process of discovery at a large commercial or research excavation by another body, such as that to commemorate the 90th anniversary of the ending of the First World War at the Vampire dugout in Belgium. "Time Team" usually does not carry out excavations for these programmes, but may contribute a reconstruction.
"Time Team History of Britain" saw Tony and the team document everything they have learned up to now and show a history of Britain.
"Behind the Scenes of Time Team" showed meetings of the archaeologists, and material not transmitted during the episode of the dig.
"10 Years of Time Team" presented a round-up of what has happened in Time Team over the past 10 years and what they expect to happen in the future.
2007 accident.
On 13 September 2007, during the filming of a jousting reenactment for a special episode of "Time Team", a splinter from a balsa wood lance went through the eye-slit in the helmet of one of the participants and entered his eye socket. 54-year-old Paul Anthony Allen, a member of a re-enactment society, died a week later in hospital. Channel 4 stated that the programme would be shown, but without the re-enactment sequence. The episode, dedicated to Mr Allen, was transmitted on 25 February 2008.
Influence.
"Time Team" has been credited with promoting archaeology in the UK. In a 2008 report produced by English Heritage, a working group of Palaeolithic specialists recognised the importance of the show in "promoting public awareness" of Palaeolithic Britain, something which they argued was to be encouraged.
Cancellation.
It was announced in 2012 that the final series would be broadcast in 2013. In 2008 the show hit the 2.5 million viewer mark, but the audience numbers had slowly declined with just 1.5 million watching a special called 'Brunel's Last Launch' in November 2011. Mick Aston left the show, criticising changes in the show leading to less archaeological material.
In October 2013 the "Radio Times" carried an interview with Tony Robinson in which he stated his belief that "Time Team" had still got life in it and suggested that after a three- or four-year absence it could make a return. He also expressed support for the fan-organised Facebook Campaign to bring the "Time Team" crew together again to carry out a dig in memory of Aston, who died on 24 June 2013.
References.
Bibliography.
</dl>

</doc>
<doc id="57976" url="http://en.wikipedia.org/wiki?curid=57976" title="Eusko Abendaren Ereserkia">
Eusko Abendaren Ereserkia

Eusko Abendaren Ereserkia ("Anthem of the Basque Ethnicity"), also known as Euskadiko Ereserkia, is the official anthem of the Basque Country (Spain). The original title uses the orthography "Euzko".
It should not be confused with Eusko Gudariak ("Basque Soldiers"), the anthem of the "Eusko Gudarostea" (the Basque Army during the Spanish Civil War) or with the "Gernikako Arbola" ("The tree of Guernica"), a popular Basque song.
It is sung to a traditional Basque tune. One of the most prominent Basque nationalists, Sabino Arana, wrote the lyrics. It was used by his party (PNV) and in the 1930s adopted by the first Basque government.
Its re-proclamation by the Basque Parliament on 14 April 1983 was opposed by several parties that deemed it still to be bound to the PNV rather than to the rest of the Basques.
The law makes official the music with no lyrics, since opposition parties felt the Arana text too religious and linked to PNV.
It is a testament to the word usage of Sabino Arana that the three words of the title are neologisms he created himself.

</doc>
<doc id="57977" url="http://en.wikipedia.org/wiki?curid=57977" title="Mad scientist">
Mad scientist

Mad scientist (also called a mad doctor or mad professor or evil genius) is a scientist or professor who is mad – a synonym for insane, owing to a combination of unusual or unsettling personality traits and the unabashedly ambitious, taboo and/or hubristic nature of their experiments. The mad scientist may be villainous or antagonistic, benign or neutral; may be insane, eccentric, or clumsy; and often works with fictional technology or fails to recognize or value common human objections to attempting to play God. Some may have benevolent or good-spirited intentions, even if their actions are dangerous or questionable, which can make them accidental villains. Some are protagonists or allies thereof, such as Dexter in the animated series "Dexter's Laboratory"; Professor Calculus in "The Adventures of Tintin"; Dr. Muto; Professor Farnsworth on "Futurama"; Philo in "UHF"; Dr. Benjamin Jeffcoat of "My Secret Identity"; Emmett Brown of "Back to the Future", Dr. Walter Bishop of Fringe, or Okabe Rintarou from the anime series "Steins;Gate". Occasionally, there are parodies of mad scientists making fun of this stereotype.
Beside its popular diffusion this stereotype has some scientific grounds; various recent studies have highlighted the connection between creativity and mood disorders 
and between excellent school performance at age 16 and risk of developing adult bipolar disorder.
History.
Precursors.
Perhaps the closest figure in Western mythology to the modern mad scientist was Daedalus, creator of the labyrinth, who was then imprisoned by King Minos. To escape, he invented two pairs of wings made from feathers and beeswax, one for himself and the other for his son Icarus. While Daedalus himself managed to fly to safety, Icarus flew too close to the sun, which melted the wax of his wings, casting him down into the sea below. In history, Archimedes shares some of the elements of the mad scientist, but was closer to the more benign archetype of the absent-minded professor (anecdotally, as in the story of the Golden Crown or the accounts of his death). Another archetypal mad scientist is Faust, or Dr. Faustus. The Faust legend is a widely recognized and referenced example of selling one's soul to the devil. In almost all cases, Faust is selling his soul for wealth, knowledge or supernatural power.
A more whimsical prototype of the mad scientist can be found in Aristophanes' comedy "The Clouds". The play depicts Socrates, a contemporary of Aristophanes, as tinkering with odd devices and performing implausible experiments to determine the nature of clouds and sky, and presents his philosophical method as a means for deceiving others and escaping blame, resembling later descriptions of his opponents, the Sophists. While this is at variance with the depictions by Plato and Xenophon, two of Socrates' students, it is plausible that Aristophanes' parody of Socrates is more accurate than their panegyrics. One of Plato's students, Aristotle, is known to have also been an experimentalist, and may have taken the concept from his teacher's teacher. A similar parody of insane and pointless experimentation may be found in the Academy of Lagado in "Gulliver's Travels" (1726).
The protoscience of alchemy long had a resemblance to mad science with its lofty goals and bizarre experiments. It is known certain alchemists behaved strangely, sometimes as a result of handling dangerous substances (such as mercury poisoning in the case of Sir Isaac Newton). The famous alchemist Paracelsus claimed to be able to create a homunculus. Scientists and inventors of the modern era have also contributed to the development of common tropes surrounding the mad scientist. Nikola Tesla in his later years conceptualized a so-called "death ray" (a directed energy weapon) and was sensationalized in the media, notably the New York Times and the New York Sun, as a prototypical mad scientist for it.
Films and fiction.
Since the 19th century, fictitious depictions of science have vacillated between notions of science as the salvation of society or its doom. Consequently, portrayal of scientists in fiction ranged between the virtuous and the depraved, the sober and the insane. Until the 20th century, optimism about progress was the most common attitude towards science (with notable exceptions as Herbert G. Wells), but latent anxieties about disturbing "the secrets of nature" would surface following the increasing role of science in wartime affairs, as well as increased scrutiny of vivisection and the development of the animal rights movement.
The prototypical fictional mad scientist was Victor Frankenstein, creator of his eponymous monster, who made his first appearance in 1818, in the novel "Frankenstein, or the Modern Prometheus" by Mary Shelley. Though Frankenstein is a sympathetic character, the critical element of conducting forbidden experiments that cross "boundaries that ought not to be crossed", heedless of the consequences, is present in Shelley's novel. Frankenstein was trained as both alchemist and modern scientist which makes him the bridge between two eras of an evolving archetype. The book is the precursor of a new genre, science fiction, though as an example of Gothic horror it is connected with other antecedents as well.
1896 saw the publication of H. G. Wells' "The Island of Doctor Moreau", in which the titular doctor—a controversial vivisectionist—has isolated himself entirely from civilisation in order to continue his experiments in surgically reshaping animals into humanoid forms, heedless of the suffering he causes.
Fritz Lang's 1927 movie "Metropolis" brought the archetypical mad scientist to the screen in the form of Rotwang, the evil genius whose machines gave life to the dystopian city of the title. Rotwang's laboratory influenced many subsequent movie sets with its electrical arcs, bubbling apparatus, and bizarrely complicated arrays of dials and controls. Portrayed by actor Rudolf Klein-Rogge, Rotwang himself is the prototypically conflicted mad scientist; though he is master of almost mystical scientific power, he remains slave to his own desires for power and revenge. Rotwang's appearance was also influential—the character's shock of flyaway hair, wild-eyed demeanor, and his quasi-fascist laboratory garb have all been adopted as shorthand for the mad scientist "look". Even his mechanical right hand has become a mark of twisted scientific power, echoed notably in Stanley Kubrick's "Dr. Strangelove" and in the novel The Three Stigmata of Palmer Eldritch (1965) by Philip K. Dick.
Nevertheless, the essentially benign and progressive impression of science in the public mind continued unchecked, exemplified by the optimistic "Century of Progress" exhibition in Chicago, 1933, and the "World of Tomorrow" at the New York World's Fair of 1939. However, after the first World War, public attitudes began to shift, if only subtly, when chemical warfare and the airplane were the terror weapons of the day. As an example, of all science fiction before 1914 which dealt with the end of the world, two-thirds were about naturalistic endings (such as collision with an asteroid), and the other third was devoted to endings caused by humans (about half were accidental, half purposeful). After 1914, the idea of any human actually killing the remainder of humanity became a more imaginable fantasy (even if it was still impossible), and the ratio switched to two-thirds of all end-of-the-world scenarios being the product of human maliciousness or error. Though still drowned out by feelings of optimism, the seeds of anxiety had been thoroughly sown.
The most common tool of mad scientists in this era was electricity. It was viewed widely as a quasi-mystical force with chaotic and unpredictable properties by an ignorant public.
A recent survey of 1,000 horror films distributed in the UK between the 1930s and 1980s reveals mad scientists or their creations have been the villains of 30 percent of the films; scientific research has produced 39 percent of the threats; and, by contrast, scientists have been the heroes of a mere 11 percent. (Christopher Frayling, "New Scientist", 24 September 2005)
In comic books many of the earliest foes were mad scientists. The Ultra-Humanite, an evil crippled scientific genius, was Superman's first recurring foe and possibly the first comic book supervillain. He apparently served as a model for the more well-known Lex Luthor. Other examples include early Batman foe Hugo Strange. However, many of these villains come more under the classification of evil genius.
After 1945.
Mad scientists were most conspicuous in popular culture after World War II. The sadistic medical "experiments" of the Nazis, especially those of Josef Mengele, and the invention of the atomic bomb gave rise in this period to genuine fears that science and technology had gone out of control. The scientific and technological build up during the Cold War, with its increasing threats of unparalleled destruction, did not lessen the impression. Mad scientists frequently figure in science fiction and motion pictures from the period. Kubrick's "" (1963), in which Peter Sellers plays the titular Dr. Strangelove, is perhaps the ultimate expression of this fear of the power of science, or the misuse of this power. In the 1950s there was a great deal of enthusiasm for scientific progress, perhaps typified in films such as Disney's Our Friend the Atom, in which a scientist holds a piece of radioactive Uranium and discusses the positive benefits radioactivity will bring, without due consideration to the potential downsides. Another popular example is the scientist Davros, creator of the villainous Dalek race in long-running British science-fiction series Doctor Who. Davros has similarities to Hitler with his speeches of Dalek supreme power, but ultimately his creations turn on him as he made them consider all other forms of life enemies.
In more recent years, the mad scientist as a lone investigator of the forbidden unknown has tended to be replaced by mad corporate executives who plan to profit from defying the laws of nature and humanity regardless of who suffers; these people hire a salaried scientific staff to pursue their twisted dreams. This shift is typified by the revised history of Superman's archenemy, Lex Luthor: originally conceived in the 1930s as a typically solitary mad scientist, a major retcon of the character's origins in 1986 made Lex Luthor the head of a megacorporation who also plays a leading role in his research and development department.
The techniques of mad science also changed after Hiroshima. Electricity was replaced by radiation as the new tool to create, enlarge, or deform life ("e.g.", Godzilla). As audiences became more savvy, quantum mechanics, genetic engineering, and artificial intelligence have taken the spotlight ("e.g.", "Blade Runner"). Some more recent depictions have had the mad scientist focused upon sacrificing humanity for their creation, with sacrifices ranging from a few people to the entire world population.
In the 2000s, a number of works have featured the trappings of mad science as familiar, even mundane elements, and shifted to toying with the implications of a setting where mad scientists may live and thrive. The webcomic "Narbonic" ostensibly chronicles the daily grind of an evil laboratory in a world where henchmen have unionized and the "New Journal of Malology" competes with "Modern Madiagnosis". Madwoman/small business owner Helen Narbon plays counter to type by being a plump, cheerful twenty-something blonde, obsessed with the color pink and hideous biological experiments involving gerbils. Comic book turned webcomic "Girl Genius" takes a combination of mad science and steampunk to a logical extreme: a Europe reduced to scattered city-states, divided by the clockwork and biological abominations unleashed by its "Spark" overlords. Other commercial examples are "Dr. Horrible's Sing-Along Blog" by Joss Whedon, where the main character has a vocal coach to help him develop a maniacal laugh, and the novel "Soon I Will Be Invincible" by Austin Grossman. The 2008 animated feature film "Igor" depicts an entire nation of mad scientists. The 2011 anime work "Steins;Gate" is known for featuring mad scientist Rintarō Okabe who is known for his catchphrase "I am the mad scientist of insanity, Hououin Kyouma!" (Japanese: 俺は狂気のマッドサイエンティスト鳳凰院凶真) which is said throughout the series.

</doc>
<doc id="57979" url="http://en.wikipedia.org/wiki?curid=57979" title="Disarmament">
Disarmament

Disarmament is the act of reducing, limiting, or abolishing weapons. Disarmament generally refers to a country's military or specific type of weaponry. Disarmament is often taken to mean total elimination of weapons of mass destruction, such as nuclear arms. General and Complete Disarmament was defined by the United Nations General Assembly as the elimination of all WMD, coupled with the “balanced reduction of armed forces and conventional armaments, based on the principle of undiminished security of the parties with a view to promoting or enhancing stability at a lower military level, taking into account the need of all States to protect their security.”.
History.
Before WWI at the Hague Peace Conferences in 1899 and 1907 government delegations debated about disarmament and the creation of an international court with binding powers. The court was considered necessary because it was understood that nation-states could not disarm into a vacuum. After the war revulsion at the futility and tremendous cost of the war was widespread. A commonly held belief was that the cause of the war had been the escalating buildup of armaments in the previous half century among the great powers (see Anglo-German naval arms race). Although the Treaty of Versailles effectively disarmed Germany, a clause was inserted that called on all the great powers to likewise progressively disarm over a period of time. The newly formed League of Nations made this an explicit goal in the covenant of the league, which committed its signatories to reduce armaments ‘to the lowest point consistent with national safety and the enforcement by common action of international obligations’.
One of the earliest successful achievements in disarmament was obtained with the Washington Naval Treaty. Signed by the governments of the United Kingdom, the United States, Japan, France, and Italy, it prevented the continued construction of capital ships and limited ships of other classification to under 10,000 tons displacement. The size of the three country's navies (the Royal Navy, United States Navy and Imperial Japanese Navy) was set at the ratio 5-5-3.
In 1921 the Temporary Mixed Commission on Armaments was set up by the League of Nations to explore possibilities for disarmament. Proposals ranged from abolishing chemical warfare and strategic bombing to the limitation of more conventional weapons, such as tanks. A draft treaty was assembled in 1923 that made aggressive war illegal and bound the member states to defend victims of aggression by force. Since the onus of responsibility would, in practice, be on the great powers of the League, it was vetoed by the British, who feared that this pledge would strain its own commitment to police the empire.
A further commission in 1926, set up to explore the possibilities for the reduction of army size, met similar difficulties, prompting the French Foreign Minister Aristide Briand and US Secretary of State Frank Kellogg to draft a treaty known as the Kellogg-Briand Pact, which denounced war of aggression. Although there were 65 signatories to the pact, it achieved nothing, as it set out no guidelines for action in the event of a war.
A final attempt was made at the Geneva Disarmament Conference from 1932–37, chaired by former British Foreign Secretary Arthur Henderson. Germany demanded the revision of the Versailles Treaty and the granting of military parity with the other powers, while France was determined to keep Germany demilitarised for its own security. Meanwhile, the British and Americans were not willing to offer France security commitments in exchange for conciliation with Germany. The talks broke down in 1933, when Adolf Hitler withdrew Germany from the conference.
Nuclear disarmament.
Nuclear disarmament refers to both the act of reducing or eliminating nuclear weapons and to the end state of a nuclear-free world, in which nuclear weapons are completely eliminated.
In the United Kingdom, the Campaign for Nuclear Disarmament held an inaugural public meeting at Central Hall, Westminster, on 17 February 1958, attended by five thousand people. After the meeting a few hundred left to demonstrate at Downing Street.
CND's declared policies were the unconditional renunciation of the use, production of or dependence upon nuclear weapons by Britain and the bringing about of a general disarmament convention. The first Aldermaston March was organised by the CND and took place at Easter 1958, when several thousand people marched for four days from Trafalgar Square, London, to the Atomic Weapons Research Establishment close to Aldermaston in Berkshire, England, to demonstrate their opposition to nuclear weapons. The Aldermaston marches continued into the late 1960s when tens of thousands of people took part in the four-day marches.
In 1961, US President John F. Kennedy gave a speech before the UN General Assembly where he announced the US "intention to challenge the Soviet Union, not to an arms race, but to a peace race - to advance together step by step, stage by stage, until general and complete disarmament has been achieved." He went on to call for a global general and complete disarmament, offering a rough outline for how this could be accomplished:
Major nuclear disarmament groups include Campaign for Nuclear Disarmament, Greenpeace and International Physicians for the Prevention of Nuclear War. There have been many large anti-nuclear demonstrations and protests. On June 12, 1982, one million people demonstrated in New York City's Central Park against nuclear weapons and for an end to the cold war arms race. It was the largest anti-nuclear protest and the largest political demonstration in American history.
Definitions of disarmament.
In his definition of "disarmament", David Carlton writes in the Oxford University Press Political dictionary, "But confidence in such measures of arms control, especially when unaccompanied by extensive means of verification, has not been strengthened by the revelation that the Soviet Union in its last years successfully concealed consistent and systematic cheating on its obligations under the Biological Weapons Convention." He also notes, "Now a freeze or a mutually agreed increase is not strictly speaking disarmament at all. And such measures may not even be intended to be a first step towards any kind of reduction or abolition. For the aim may simply be to promote stability in force structures. Hence a new term to cover such cases has become fashionable since the 1960s, namely, arms control."
The book by Seymour Melman, "Inspection for Disarmament", addresses various problems related to the problem of inspection for disarmament, evasion teams, and capabilities and limitations of aerial inspection. Gradually, as the idea of arms control displaced the idea of disarmament, the weaknesses of the present arms control paradigm have created problems for the idea of disarmament itself. 
References and footnotes.
Specific references:
General references:

</doc>
<doc id="57980" url="http://en.wikipedia.org/wiki?curid=57980" title="Shortwave radio">
Shortwave radio

Shortwave radio is radio transmission using shortwave frequencies, generally 1.6–30 MHz, just above the medium wave band.
Shortwave radio is used for long distance communication by means of "skywave" or "skip" propagation, in which the radio waves are reflected or refracted back to Earth from the ionosphere, allowing communication around the curve of the Earth. Shortwave radio is used for broadcasting of voice and music, and long-distance communication to ships and aircraft, or to remote areas out of reach of wired communication or other radio services. Additionally, it is used for two-way international communication by amateur radio enthusiasts for hobby, educational and emergency purposes.
Frequency classifications.
The widest popular definition of the shortwave frequency interval is the ITU Region 1 (EU+Africa+Russia...) definition, and is the span 1.6–30 MHz, just above the medium wave band, which ends approximately at 1.6 MHz.
There are also other definitions of the shortwave frequency interval:
Shortwave radio received its name because the wavelengths in this band are shorter than 200 m (1500 kHz) which marked the original upper limit of the medium frequency band first used for radio communications. The broadcast medium wave band now extends above the 200 m/1500 kHz limit, and the amateur radio 1.8 MHz – 2.0 MHz band (known as the "top band") is the lowest-frequency band considered to be 'shortwave'.
History.
Development.
Early radio telegraphy had used long wave transmissions. The drawbacks to this system included a very limited spectrum available for long distance communication, and the very expensive transmitters, receivers and gigantic antennas that were required. It was also difficult to beam the radio wave directionally with long wave, resulting in a major loss of power over long distances. Prior to the 1920s, the shortwave frequencies above 2 MHz were regarded as useless for long distance communication and were designated in many countries for amateur use.
Guglielmo Marconi, pioneer of radio, commissioned his assistant Charles Samuel Franklin to carry out a large scale study into the transmission characteristics of short wavelength waves and to determine their suitability for long distance transmissions. Franklin rigged up a large antenna at Poldhu Wireless Station, Cornwall, running on 25 kW of power. In June and July 1923, wireless transmissions were completed during nights on 97 meters from Poldhu to Marconi's yacht "Elettra" in the Cape Verde Islands.
In September 1924, Marconi transmitted during daytime and nighttime on 32 meters from Poldhu to his yacht in Beirut. Franklin went on to refine the directional transmission, by inventing the curtain array aerial system. In July 1924, Marconi entered into contracts with the British General Post Office (GPO) to install high speed shortwave telegraphy circuits from London to Australia, India, South Africa and Canada as the main element of the Imperial Wireless Chain. The UK-to-Canada shortwave "Beam Wireless Service" went into commercial operation on 25 October 1926. Beam Wireless Services from the UK to Australia, South Africa and India went into service in 1927.
Shortwave communications began to grow rapidly in the 1920s, similar to the internet in the late 20th century. By 1928, more than half of long distance communications had moved from transoceanic cables and longwave wireless services to shortwave and the overall volume of transoceanic shortwave communications had vastly increased. Shortwave also ended the need for multi-million dollar investments in new transoceanic telegraph cables and massive longwave wireless stations, although some existing transoceanic telegraph cables and commercial longwave communications stations remained in use until the 1960s.
The cable companies began to lose large sums of money in 1927, and a serious financial crisis threatened the viability of cable companies that were vital to strategic British interests. The British government convened the Imperial Wireless and Cable Conference in 1928 "to examine the situation that had arisen as a result of the competition of Beam Wireless with the Cable Services". It recommended and received Government approval for all overseas cable and wireless resources of the Empire to be merged into one system controlled by a newly formed company in 1929, Imperial and International Communications Ltd. The name of the company was changed to Cable and Wireless Ltd. in 1934.
Amateur use of shortwave propagation.
Amateur radio operators also discovered that long-distance communication was possible on shortwave bands. Early long-distance services used surface wave propagation at very low frequencies, which are attenuated along the path. Longer distances and higher frequencies using this method meant more signal attenuation. This, and the difficulties of generating and detecting higher frequencies, made discovery of shortwave propagation difficult for commercial services.
Radio amateurs may have conducted the first successful transatlantic tests in December 1921, operating in the 200 meter mediumwave band (1500 kHz)—the shortest wavelength then available to amateurs. In 1922 hundreds of North American amateurs were heard in Europe at 200 meters and at least 20 North American amateurs heard amateur signals from Europe. The first two-way communications between North American and Hawaiian amateurs began in 1922 at 200 meters. Although operation on wavelengths shorter than 200 meters was technically illegal (but tolerated as the authorities mistakenly believed at first that such frequencies were useless for commercial or military use), amateurs began to experiment with those wavelengths using newly available vacuum tubes shortly after World War I.
Extreme interference at the upper edge of the 150-200 meter band—the official wavelengths allocated to amateurs by the Second National Radio Conference in 1923—forced amateurs to shift to shorter and shorter wavelengths; however, amateurs were limited by regulation to wavelengths longer than 150 meters (2 MHz). A few fortunate amateurs who obtained special permission for experimental communications below 150 meters completed hundreds of long distance two way contacts on 100 meters (3 MHz) in 1923 including the first transatlantic two way contacts.
By 1924 many additional specially licensed amateurs were routinely making transoceanic contacts at distances of 6000 miles (~9600 km) and more. On 21 September several amateurs in California completed two way contacts with an amateur in New Zealand. On 19 October amateurs in New Zealand and England completed a 90-minute two-way contact nearly halfway around the world. On October 10, the Third National Radio Conference made three shortwave bands available to U.S. amateurs at 80 meters (3.75 MHz), 40 meters (7 MHz) and 20 meters (14 MHz). These were allocated worldwide, while the 10-meter band (28 MHz) was created by the Washington International Radiotelegraph Conference on 25 November 1927. The 15-meter band (21 MHz) was opened to amateurs in the United States on 1 May 1952.
Propagation characteristics.
Shortwave radio frequency energy is capable of reaching any location on the Earth as it is influenced by ionospheric reflection back to the earth by the ionosphere, (a phenomenon known as "skywave propagation"). A typical phenomenon of shortwave propagation is the occurrence of a skip zone (see first figure on that page) where reception fails. With a fixed working frequency, large changes in ionospheric conditions may create skip zones at night.
As a result of the multi-layer structure of the ionosphere, propagation often simultaneously occurs on different paths,
scattered by the E or F region and with different numbers of hops, a phenomenon that may be disturbed for certain techniques. Particularly for lower frequencies of the shortwave band, absorption of radio frequency energy in the lowest ionospheric layer, the D layer, may impose a serious limit. This is due to collisions of electrons with neutral molecules, absorbing some of a radio frequency's energy and converting it to heat.
Predictions of skywave propagation depend on:
Types of modulation.
Several different types of modulation are used to impress information on a short-wave transmission.
Amplitude modulation is the simplest type and the most commonly used for shortwave broadcasting. The instantaneous amplitude of the carrier is controlled by the amplitude of the signal (speech, or music, for example). At the receiver, a simple detector recovers the desired modulation signal from the carrier.
Single sideband transmission is a form of amplitude modulation but in effect filters the result of modulation. An amplitude-modulated signal has frequency components both above and below the carrier frequency. If one set of these components is eliminated as well as the residual carrier, only the remaining set is transmitted. This saves power in the transmission, as roughly 2/3 of the energy sent by an AM signal is unnecessary to recover the information contained on it. It also saves "bandwidth", allowing about one-half the carrier frequency spacing to be used. The drawback is that the receiver is more complicated, since it must re-recreate the carrier to recover the signal. Small errors in the detector process can greatly affect the pitch of the received signal, so single side band is not usual for music or general broadcast. Single side band is used for long-range voice communications by ships and aircraft, Citizen's Band, and amateur radio operators. LSB (lower sideband) is generally used below 9 MHz and USB (upper sideband) above 9 MHz.
Vestigal sideband transmits the carrier and one complete side-band, but filters out the redundant side-band. It is a compromise between AM and SSB, allowing simple receivers to be used but requiring almost as much transmitter power as AM. One advantage is that only half the bandwidth of an AM signal is used. It can be heard in the transmission of certain radio time signal stations.
Continuous wave (CW) is on-and-off keying of a carrier, used only for Morse code communications.
Narrow-band frequency modulation (NBFM) is mainly used in the higher HF frequencies (typically above 20 MHz). Because of the larger bandwidth required, NBFM is much more commonly used for VHF communication. Regulations limit the bandwidth of a signal transmitted in the HF bands, and the advantages of frequency modulation are greatest if the FM signal is allowed to have a wider bandwidth. NBFM is limited to short-range SW transmissions due to the multiphasic distortions created by the ionosphere.
Digital Radio Mondiale (DRM) is a digital modulation for use on bands below 30 MHz.
Radioteletype, fax, digital, slow-scan television and other systems use forms of frequency-shift keying or audio subcarriers on a shortwave carrier. These generally require special equipment to decode, such as software on a computer equipped with a sound card.
Uses.
Some major uses of the shortwave radio band are:
The term DXing, in the context of listening to radio signals of any user of the shortwave band, is the activity of monitoring distant stations. In the context of amateur radio operators, the term "DXing" refers to the two-way communications with a distant station, using shortwave radio frequencies.
The Asia-Pacific Telecommunity estimates that there are approximately 600,000,000 shortwave broadcast-radio receivers in use in 2002. WWCR claims that there are 1.5 billion shortwave receivers worldwide.
Shortwave broadcasting.
"See International broadcasting for details on the history and practice of broadcasting to foreign audiences."
"See Shortwave relay station for the actual kinds of integrated technologies used to bring high power signals to listeners."
Frequency allocations.
The World Radiocommunication Conference (WRC), organized under the auspices of the International Telecommunication Union, allocates bands for various services in conferences every few years. The last WRC took place in 2007.
At WRC-97 in 1997, the following bands were allocated for international broadcasting. AM shortwave broadcasting channels are allocated with a 5 kHz separation for traditional analog audio broadcasting.
Although countries generally follow the table above, there may be small differences between countries or regions. For example, in the official bandplan of the Netherlands, the 49 m band starts at 5,950 kHz, the 41 m band ends at 7,450 kHz, the 11 m band starts at 25,670 kHz, and the 120, 90 and 60 m bands are absent altogether. Additionally, international broadcasters sometimes operate outside the normal WRC-allocated bands or use off-channel frequencies. This is done for practical reasons, or to attract attention in crowded bands (60m, 49m, 40m, 41m, 31m, 25m).
The new digital audio broadcasting format for shortwave DRM operates 10 kHz or 20 kHz channels. There are some ongoing discussions with respect to specific band allocation for DRM, as it mainly transmitted in 10 kHz format.
The power used by shortwave transmitters ranges from less than one watt for some experimental and amateur radio transmissions to 500 kilowatts and higher for intercontinental broadcasters and over-the-horizon radar. Shortwave transmitting centers often use specialized antenna designs (like the ALLISS antenna technology) to concentrate radio energy at the target area.
Advantages.
Shortwave does possess a number of advantages over newer technologies, including the following:
Disadvantages.
Shortwave radio's benefits are sometimes regarded as being outweighed by its drawbacks, including:
Shortwave listening.
Many hobbyists listen to shortwave broadcasters without operating their own transmitters. In some cases, the goal is to hear as many stations from as many countries as possible "(DXing)"; others listen to specialized shortwave utility, or "ute", transmissions such as maritime, naval, aviation, or military signals. Others focus on intelligence signals from numbers stations,stations which transmit strange broadcast usually for intelligence operations, or the two way communications by amateur radio operators. Some short wave listeners behave analogously to "lurkers" on the Internet, in that they listen only and never make any attempt to send out their own signals. Other listeners participate in clubs, or actively send and receive QSL cards, or become involved with amateur radio and start transmitting on their own.
Many listeners tune the shortwave bands for the programmes of stations broadcasting to a general audience (such as Radio Taiwan International, Voice of Russia, China Radio International, Radio Canada International, Voice of America, Radio France Internationale, BBC World Service, Radio Australia, Radio Netherlands, Voice of Korea, Radio Free Sarawak etc.). Today, through the evolution of the Internet, the hobbyist can listen to shortwave signals via around the world, even without owning a shortwave radio. Many international broadcasters (such as Radio Canada International , the BBC and Radio Australia) offer live streaming audio on their websites.
Shortwave listeners, or SWLs, can obtain QSL cards from broadcasters, utility stations or amateur radio operators as trophies of the hobby. Some stations even give out special certificates, pennants, stickers and other tokens and promotional materials to shortwave listeners.
Amateur radio.
The practice of operating a shortwave radio transmitter for non-commercial two-way communications is known as amateur radio. Licenses are granted by authorized government agencies.
Amateur radio operators have made many technical advancements in the field of radio, and make themselves available to transmit emergency communications when normal communications channels fail. Some amateurs practice operating "off the power grid" so as to be prepared for power loss. Many amateur radio operators started out as Shortwave Listeners (SWLs) and actively encourage SWLs to become amateur radio operators.
Utility stations.
Utility stations are stations that do not intentionally broadcast to the general public (although their signals can be received by anybody with appropriate equipment). There are shortwave bands allocated to the use of merchant shipping, marine weather, and ship-to-shore stations; for aviation weather and air-to-ground communications; for military communications; for long-distance governmental purposes, and for other non-broadcast communications. Many radio hobbyists specialize in listening to "ute" broadcasts, which often originate from geographic locations without known shortwave broadcasters.
Unusual signals.
The short wave bands are also used by unlicensed individuals who may want mostly short-range "party line" like communications. Two examples are the use of HF for communication between fishing boats in many areas of the world, and the unlicensed use of the 11-meter band, which is effectively permitted in some areas of the world. Unlicensed operators, called "pirates", can cause signal interference to licensed stations. Many third-world countries have shops selling HF transmitter radios to any customer without regard to license or operator knowledge. As of 2012, there were virtually no national or international efforts to control such pirate operations.
The short wave bands are also used for various experiments, some continuing for years. In 2011, signals traceable to China regularly sent powerful HF transmissions scanning wide ranges of HF frequencies, perhaps to determine the maximum usable frequency (MUF) or other variables. 
Numbers stations are broadcasts on shortwave radio that are coded into groups of numbers. Their content is 
generally encrypted and their purpose remains a mystery.
Shortwave broadcasts and music.
Some musicians have been attracted to the unique aural characteristics of shortwave radio which—due to the nature of amplitude modulation, varying propagation conditions, and the presence of interference—generally has lower fidelity than local broadcasts (particularly via FM stations). Shortwave transmissions often have bursts of distortion, and "hollow" sounding loss of clarity at certain aural frequencies, altering the harmonics of natural sound and creating at times a strange "spacey" quality due to echoes and phase distortion. Evocations of shortwave reception distortions have been incorporated into rock and classical compositions, by means of delays or feedback loops, equalizers, or even playing shortwave radios as live instruments. Snippets of broadcasts have been mixed into electronic sound collages and live musical instruments, by means of analogue tape loops or digital samples. Sometimes the sounds of instruments and existing musical recordings are altered by remixing or equalizing, with various distortions added, to replicate the garbled effects of shortwave radio reception.
The first attempts by serious composers to incorporate radio effects into music may be those of the Russian physicist and musician Léon Theremin, who perfected a form of radio oscillator as a musical instrument in 1928 (regenerative circuits in radios of the time were prone to breaking into oscillation, adding various tonal harmonics to music and speech); and in the same year, the development of a French instrument called the Ondes Martenot by its inventor Maurice Martenot, a French cellist and former wireless telegrapher. A notable chamber piece by Mexican composer Silvestre Revueltas—"Ocho x radio", 1933—features a complex texture of pseudo-mariachi musics, overlapping and cross-fading as if heard from distant stations: quite similar to shortwave radio signal propagation disturbance. John Cage used actual radios (of unspecified wavelength) live on several occasions, starting in 1942 with "Credo in Us", while Karlheinz Stockhausen used shortwave radio and effects in works including "Hymnen" (1966–67), "Kurzwellen" (1968)—adapted for the Beethoven Bicentennial in "Opus 1970" with filtered and distorted snippets of Beethoven pieces—"Spiral" (1968), "Pole", "Expo" (both 1969–70), and "Michaelion" (1997).
Holger Czukay, a student of Stockhausen, was one of the first to use shortwave in a rock music context. In 1975, German electronic music band Kraftwerk recorded a full length concept album around simulated radiowave and shortwave sounds, entitled "Radio-Activity". Among others, The The whose Radio Cineola monthly broadcasts draw heavily on shortwave radio sound, The B-52s, Shearwater, Tom Robinson, Peter Gabriel, Pukka Orchestra, AMM, John Duncan, Orchestral Manoeuvres in the Dark (on their "Dazzle Ships" album), Pat Metheny, Aphex Twin, Boards of Canada, PressureWorks, Rush, Able Tasmans, Team Sleep, Underworld, Meat Beat Manifesto, Tim Hecker, Jonny Greenwood of Radiohead, Roger Waters (on "Radio KAOS" album), Wilco, code 000 and Samuel Trim have also used or been inspired by shortwave broadcasts. 
Shortwave's future.
The development of direct broadcasts from satellites has reduced the demand for shortwave receiver hardware, but there are still a great number of shortwave broadcasters. A new digital radio technology, Digital Radio Mondiale (DRM), is expected to improve the quality of shortwave audio from very poor to standards comparable to the FM broadcast band. The future of shortwave radio is threatened by the rise of power line communication (PLC), also known as Broadband over Power Lines (BPL), which uses a data stream transmitted over unshielded power lines. As the BPL frequencies used overlap with shortwave bands, severe distortions can make listening to analog shortwave radio signals near power lines difficult or impossible. However, because shortwave is a cheap and effective way to receive communications in countries with poor infrastructure, it will be around for years to come.
Shortwave use by hobbyists and licensed amateur ham radio operators continues, and after declining interest for a few years due to competing interests in computers and other communication devices, a new resurgence of interest has occurred as evidenced by the increase of new amateur operator licenses issued worldwide. Some hobbyists have combined amateur radio HF with computers for experimental and established data modes that can communicate very close to under the noise floor of receivers - e.g. WSJT, WSPR.

</doc>
<doc id="57983" url="http://en.wikipedia.org/wiki?curid=57983" title="Datura stramonium">
Datura stramonium

Datura stramonium, known by the common names Jimson weed, Devil's snare, or datura, is a plant in the Solanaceae (nightshade) family. It is believed to have originated in the Americas, but is now found around the world.<ref name= 'NPGS/GRIN'></ref> Other common names for "D. stramonium" include thornapple and moon flower, and it has the Spanish name Toloache. Other names for the plant include hell's bells,
devil’s trumpet, devil’s weed, tolguacha, Jamestown weed, stinkweed, locoweed, pricklyburr, and devil’s cucumber.
For centuries, datura has been used as an herbal medicine to relieve asthma symptoms and as an analgesic during surgery or bonesetting. It is also a powerful hallucinogen and deliriant, which is used spiritually for the intense visions it produces. However, the tropane alkaloids responsible for both the medicinal and hallucinogenic properties are fatally toxic in only slightly higher amounts than the medicinal dosage, and careless use often results in hospitalizations and deaths.
Description.
"D. stramonium" is a foul-smelling, erect, annual, freely branching herb that forms a bush up to 2 to tall.
The root is long, thick, fibrous and white. The stem is stout, erect, leafy, smooth, and pale yellow-green. The stem forks off repeatedly into branches, and each fork forms a leaf and a single, erect flower.
The leaves are about 3 to- long, smooth, toothed, soft, and irregularly undulated. The upper surface of the leaves is a darker green, and the bottom is a light green. The leaves have a bitter and nauseating taste, which is imparted to extracts of the herb, and remains even after the leaves have been dried.
"D. stramonium" generally flowers throughout the summer. The fragrant flowers are trumpet-shaped, white to creamy or violet, and 2+1/2 to- long, and grow on short stems from either the axils of the leaves or the places where the branches fork. The calyx is long and tubular, swollen at the bottom, and sharply angled, surmounted by five sharp teeth. The corolla, which is folded and only partially open, is white, funnel-shaped, and has prominent ribs. The flowers open at night, emitting a pleasant fragrance, and are fed upon by nocturnal moths.
The egg-shaped seed capsule is 1 to- in diameter and either covered with spines or bald. At maturity, it splits into four chambers, each with dozens of small, black seeds.
Range and habitat.
"D. stramonium" is native to North America, but was spread to the Old World early. It was scientifically described and named by Swedish botanist Carl Linnaeus in 1753, although it had been described a century earlier by herbalists, such as Nicholas Culpeper. Today, it grows wild in all the world's warm and moderate regions, where it is found along roadsides and at dung-rich livestock enclosures. In Europe, it is found as a weed on wastelands and in garbage dumps.
The seed is thought to be carried by birds and spread in their droppings. Its seeds can lie dormant underground for years and germinate when the soil is disturbed. People who discover it growing in their gardens, and are worried about its toxicity, have been advised to dig it up or have it otherwise removed.
Toxicity.
All parts of "Datura" plants contain dangerous levels of the tropane alkaloids atropine, hyoscyamine, and scopolamine, which are classified as deliriants, or anticholinergics. The risk of fatal overdose is high among uninformed users, and many hospitalizations occur amongst recreational users who ingest the plant for its psychoactive effects.
The amount of toxins varies widely from plant to plant. As much as a 5:1 variation can be found between plants, and a given plant's toxicity depends on its age, where it is growing, and the local weather conditions. Additionally, within a given datura plant, toxin concentration varies by part and even from leaf to leaf. When the plant is younger, the ratio of scopolamine to atropine is about 3:1; after flowering, this ratio is reversed, with the amount of scopolamine continuing to decrease as the plant gets older. This variation makes "Datura" exceptionally hazardous as a drug. In traditional cultures, a great deal of experience with and detailed knowledge of "Datura" was critical to minimize harm. An individual datura seed contains about 0.1 mg of atropine, and the approximate fatal dose for adult humans is >10 mg atropine or >2–4 mg scopolamine.
"Datura" intoxication typically produces delirium (as contrasted to hallucination), hyperthermia, tachycardia, bizarre behavior, and severe mydriasis with resultant painful photophobia that can last several days. Pronounced amnesia is another commonly reported effect. The onset of symptoms generally occurs around 30 to 60 minutes after ingesting the herb. These symptoms generally last from 24 to 48 hours, but have been reported in some cases to last as long as two weeks.
As with other cases of anticholinergic poisoning, intravenous physostigmine can be administered in severe cases as an antidote.
Use in traditional medicine.
In traditional Ayurvedic medicine in India, datura has long been used for asthma symptoms. The active agent is atropine. The leaves are generally smoked either in a cigarette or a pipe. During the late 18th century, James Anderson, the English Physician General of the East India Company, learned of the practice and popularized it in Europe.
The Zuni once used datura as an analgesic, to render patients unconscious while broken bones were set. The Chinese also used it in this manner, as a form of anaesthesia during surgery.
Spiritual uses.
The ancient inhabitants of what is today central and southern California used to ingest the small black seeds of datura to "commune with deities through visions". Across the Americas, other indigenous peoples such as the Algonquin, Cherokee, Marie Galente, and Luiseño also used this plant in sacred ceremonies for its hallucinogenic properties. In Ethiopia, some students and "debtrawoch" (lay priests), use "D. stramonium" to "open the mind" to be more receptive to learning, and creative and imaginative thinking.
In his book, "The Serpent and the Rainbow", Canadian ethnobotanist Wade Davis identified "D. stramonium", called "zombi (sic) cucumber" in Haiti, as a central ingredient of the concoction vodou priests use to create zombies.
The common name "datura" has its roots in ancient India, where the plant is considered particularly sacred—believed to be a favorite of the Hindu god Shiva Nataraja.
Cultivation.
Datura prefers rich, calcareous soil. Adding nitrogen fertilizer to the soil will increase the concentration of alkaloids present in the plant. Datura can be grown from seed, which is sown with several feet between each plant. Datura is sensitive to frost, so should be sheltered during cold weather. The plant is harvested when the fruits are ripe, but still green. To harvest, the entire plant is cut down, the leaves are stripped from the plant, and everything is left to dry. When the fruits begin to burst open, the seeds are harvested. A single intensively planted acre can produce 1,000 to 1,500 pounds (1,100–1,700 kg/ha) of leaf and 700 pounds (780 kg/ha) of seed.
Etymology.
The genus name is derived from "dhatura", an ancient Hindu word for a plant. "Stramonium" is originally from Greek, "strychnos" στρύχνος "nightshade" and "maniakos" μανιακός "mad".
In the United States, the plant is called jimson weed, or more rarely Jamestown weed; it got this name from the town of Jamestown, Virginia, where British soldiers consumed it while attempting to suppress Bacon's Rebellion. They spent 11 days in altered mental states:
 The James-Town Weed (which resembles the Thorny Apple of Peru, and I take to be the plant so call'd) is supposed to be one of the greatest coolers in the world. This being an early plant, was gather'd very young for a boil'd salad, by some of the soldiers sent thither to quell the rebellion of Bacon (1676); and some of them ate plentifully of it, the effect of which was a very pleasant comedy, for they turned natural fools upon it for several days: one would blow up a feather in the air; another would dart straws at it with much fury; and another, stark naked, was sitting up in a corner like a monkey, grinning and making mows [grimaces] at them; a fourth would fondly kiss and paw his companions, and sneer in their faces with a countenance more antic than any in a Dutch droll.In this frantic condition they were confined, lest they should, in their folly, destroy themselves — though it was observed that all their actions were full of innocence and good nature. Indeed, they were not very cleanly; for they would have wallowed in their own excrements, if they had not been prevented. A thousand such simple tricks they played, and after eleven days returned themselves again, not remembering anything that had passed.
 – "The History and Present State of Virginia", 1705

</doc>
<doc id="57985" url="http://en.wikipedia.org/wiki?curid=57985" title="Ian Fleming">
Ian Fleming

Ian Lancaster Fleming (28 May 1908 – 12 August 1964) was an English author, journalist and naval intelligence officer, best known for his James Bond series of spy novels. Fleming came from a wealthy family connected to the merchant bank Robert Fleming & Co., and his father was the Member of Parliament for Henley from 1910 until his death on the Western Front in 1917. Educated at Eton, Sandhurst and, briefly, the universities of Munich and Geneva, Fleming moved through several jobs before he started writing.
While working for Britain's Naval Intelligence Division during the Second World War, Fleming was involved in planning Operation Goldeneye and in the planning and oversight of two intelligence units, 30 Assault Unit and T-Force. His wartime service and his career as a journalist provided much of the background, detail and depth of the James Bond novels.
Fleming wrote his first Bond novel, "Casino Royale", in 1952. It was a success, with three print runs being commissioned to cope with the demand. Eleven Bond novels and two short-story collections followed between 1953 and 1966. The novels revolved around James Bond, an officer in the Secret Intelligence Service, commonly known as MI6. Bond was also known by his code number, 007, and was a commander in the Royal Naval Reserve. The Bond stories rank among the best-selling series of fictional books of all time, having sold over 100 million copies worldwide. Fleming also wrote the children's story "Chitty-Chitty-Bang-Bang" and two works of non-fiction. In 2008, "The Times" ranked Fleming 14th on its list of "The 50 greatest British writers since 1945".
He was married to Ann Charteris, who was divorced from the second Viscount Rothermere as a result of her affair with Fleming. Fleming and Charteris had a son, Caspar. Fleming was a heavy smoker and drinker who suffered from heart disease; he died in 1964, aged 56, from a heart attack. Two of his James Bond books were published posthumously; other writers have since produced Bond novels. Fleming's creation has appeared in film twenty-five times, portrayed by seven actors.
Biography.
Birth and family.
Ian Fleming was born on 28 May 1908, at 27 Green Street in the wealthy London district of Mayfair. His mother was Evelyn St Croix Rose, and his father was Valentine Fleming, the Member of Parliament for Henley from 1910. Fleming was the grandson of the Scottish financier Robert Fleming, who founded the Scottish American Investment Trust and the merchant bank Robert Fleming & Co. In 1914, with the start of the First World War, Valentine joined "C" Squadron, Queen's Own Oxfordshire Hussars, and rose to the rank of major. He was killed by German shelling on the Western Front on 20 May 1917; Winston Churchill wrote an obituary that appeared in "The Times". Because the family owned an estate at Arnisdale, Valentine's death was commemorated on the Glenelg War Memorial.
Fleming's elder brother Peter (1907–1971) became a travel writer and married actress Celia Johnson. Peter served with the Grenadier Guards during the Second World War, was later commissioned under Colin Gubbins to help establish the Auxiliary Units, and became involved in behind-the-lines operations in Norway and Greece during the war. Fleming also had two younger brothers, Michael (1913–1940) and Richard (1911–1977), and a younger maternal half-sister born out of wedlock, cellist Amaryllis Fleming (1925–1999), whose father was the artist Augustus John. Amaryllis was conceived during a long-term affair between John and Evelyn that started in 1923, some six years after the death of Valentine.
Education and early life.
In 1914 Fleming attended Durnford School, a preparatory school on the Isle of Purbeck in Dorset. He did not enjoy his time at Durnford; he suffered unpalatable food, physical hardship and bullying.
In 1921 Fleming enrolled at Eton College. Although not a high achiever academically, he excelled at athletics and held the title of "Victor Ludorum" ("Winner of the Games") for two years between 1925 and 1927. He also edited a school magazine, "The Wyvern". His lifestyle at Eton brought him into conflict with his housemaster, E. V. Slater, who disapproved of Fleming's attitude, his hair oil, his ownership of a car and his relations with women. Slater persuaded Fleming's mother to remove him from Eton a term early for a crammer course to gain entry to the Royal Military College at Sandhurst. He spent less than a year there, leaving in 1927 without gaining a commission, after contracting gonorrhea.
In 1927, to prepare Fleming for possible entry into the Foreign Office, his mother sent him to the Tennerhof in Kitzbühel, Austria, a small private school run by the Adlerian disciple and former British spy Ernan Forbes Dennis and his novelist wife, Phyllis Bottome. After improving his language skills there, he studied briefly at Munich University and the University of Geneva. While in Geneva, Fleming began a romance with Monique Panchaud de Bottomes and the couple were briefly engaged in 1931. His mother disapproved and made him break off the relationship. He applied for entry to the Foreign Office, but failed the examinations. His mother again intervened in his affairs, lobbying Sir Roderick Jones, head of Reuters News Agency, and in October 1931 he was given a position as a sub-editor and journalist for the company. In 1933 Fleming spent time in Moscow, where he covered the Stalinist show trial of six engineers from the British company Metropolitan-Vickers. While there he applied for an interview with Soviet premier Joseph Stalin, and was amazed to receive a personally signed note apologising for not being able to attend.
Fleming bowed to family pressure in October 1933, and went into banking with a position at the financiers Cull & Co. In 1935 he moved to Rowe and Pitman on Bishopsgate as a stockbroker. Fleming was unsuccessful in both roles. Early in 1939 Fleming began an affair with Ann O'Neill (née Charteris), who was married to the 3rd Baron O'Neill; she was also having an affair with Esmond Harmsworth, the heir to Lord Rothermere, owner of the "Daily Mail".
Second World War.
In May 1939 Fleming was recruited by Rear Admiral John Godfrey, Director of Naval Intelligence of the Royal Navy, to become his personal assistant. He joined the organisation full-time in August 1939, with the codename "17F", and worked out of Room 39 at The Admiralty. Fleming's biographer, Andrew Lycett, notes that Fleming had "no obvious qualifications" for the role. As part of his appointment, Fleming was commissioned into the Royal Naval Volunteer Reserve in July 1939, initially as lieutenant, but promoted to commander a few months later.
Fleming proved invaluable as Godfrey's personal assistant and excelled in administration. Godfrey was known as an abrasive character who made enemies within government circles. He frequently used Fleming as a liaison with other sections of the government's wartime administration, such as the Secret Intelligence Service, the Political Warfare Executive, the Special Operations Executive (SOE), the Joint Intelligence Committee and the Prime Minister's staff.
On 29 September 1939, soon after the start of the war, Godfrey circulated a memorandum that, "bore all the hallmarks of ... Lieutenant Commander Ian Fleming", according to historian Ben Macintyre. It was called the Trout Memo and compared the deception of an enemy in wartime to fly fishing. The memo contained a number of schemes to be considered for use against the Axis powers to lure U-boats and German surface ships towards minefields. Number 28 on the list was an idea to plant misleading papers on a corpse that would be found by the enemy; the suggestion is similar to Operation Mincemeat, the successful 1943 plan to conceal the intended invasion of Italy from North Africa, although that idea was developed by Charles Cholmondoley in October 1942. The recommendation in the Trout Memo was titled: "A Suggestion (not a very nice one)", and continued: "The following suggestion is used in a book by Basil Thomson: a corpse dressed as an airman, with despatches in his pockets, could be dropped on the coast, supposedly from a parachute that has failed. I understand there is no difficulty in obtaining corpses at the Naval Hospital, but, of course, it would have to be a fresh one."
In 1940 Fleming and Godfrey contacted Kenneth Mason, Professor of Geography at Oxford University, about the preparation of reports on the geography of countries involved in military operations. These reports were the precursors of the "Naval Intelligence Division Geographical Handbook Series" produced between 1941 and 1946.
Operation Ruthless, a plan aimed at obtaining details of the Enigma codes used by Nazi Germany's navy, was instigated by a memo written by Fleming to Godfrey on 12 September 1940. The idea was to "obtain" a German bomber, man it with a German-speaking crew dressed in Luftwaffe uniforms, and crash it into the English Channel. The crew would then attack their German rescuers and bring their boat and Enigma machine back to England. Much to the annoyance of Alan Turing and Peter Twinn at Bletchley Park, the mission was never carried out. According to Fleming's niece, Lucy, an official of the Royal Air Force pointed out that if they were to drop a downed Heinkel bomber in the English Channel, it would probably sink rather quickly.
Fleming also worked with Colonel "Wild Bill" Donovan, President Franklin D. Roosevelt's special representative on intelligence co-operation between London and Washington. In May 1941 Fleming accompanied Godfrey to the United States, where he assisted in writing a blueprint for the Office of the Coordinator of Information, the department that turned into the Office of Strategic Services and eventually became the CIA.
Admiral Godfrey put Fleming in charge of Operation Goldeneye between 1941 and 1942; Goldeneye was a plan to maintain an intelligence framework in Spain in the event of a German takeover of the territory. Fleming's plan involved maintaining communication with Gibraltar and launching sabotage operations against the Nazis. In 1941 he liaised with Donovan over American involvement in a measure intended to ensure that the Germans did not dominate the seaways.
30 Assault Unit.
In 1942 Fleming formed a unit of commandos, known as No. 30 Commando or 30 Assault Unit (30AU), composed of specialist intelligence troops. 30AU's job was to be near the front line of an advance—sometimes in front of it—to seize enemy documents from previously targeted headquarters. The unit was based on a German group headed by Otto Skorzeny, who had undertaken similar activities in the Battle of Crete in May 1941. The German unit was thought by Fleming to be "one of the most outstanding innovations in German intelligence".
Fleming did not fight in the field with the unit, but selected targets and directed operations from the rear. On its formation the unit was only thirty strong, but it grew to five times that size. The unit was filled with men from other commando units, and trained in unarmed combat, safe-cracking and lock-picking at the SOE facilities. In late 1942 Captain (later Rear-Admiral) Edmund Rushbrooke replaced Godfrey as head of the Naval Intelligence Division, and Fleming's influence in the organisation declined, although he retained control over 30AU. Fleming was unpopular with the unit's members, who disliked his referring to them as his "Red Indians".
Before the 1944 Normandy landings, most of 30AU's operations were in the Mediterranean, although it secretly participated in the Dieppe Raid in a failed pinch raid for an Enigma machine and related materials. Because of its successes in Sicily and Italy, 30AU became greatly trusted by naval intelligence.
In March 1944 Fleming oversaw the distribution of intelligence to Royal Navy units in preparation for Operation Overlord He was replaced as head of 30AU on 6 June 1944, but maintained some involvement, He visited 30AU in the field during and after Overlord, especially following an attack on Cherbourg for which he was concerned that the unit had been incorrectly used as a regular commando force rather than an intelligence-gathering unit. This wasted the men's specialist skills, risked their safety on operations that did not justify the use of such skilled operatives, and threatened the vital gathering of intelligence. Afterwards, the management of these units was revised. He also followed the unit into Germany after it located, in Tambach Castle, the German naval archives from 1870.
In December 1944 he was posted on an intelligence fact-finding trip to the Far East on behalf of the Director of Naval Intelligence. Much of the trip was spent identifying opportunities for 30AU in the Pacific, although the unit ultimately saw little action because of the Japanese surrender.
T-Force.
The success of 30AU led to the August 1944 decision to establish a "Target Force", which became known as T-Force. The official memorandum, held at The National Archives in London, describes the unit's primary role: "T-Force = Target Force, to guard and secure documents, persons, equipment, with combat and Intelligence personnel, after capture of large towns, ports etc. in liberated and enemy territory."
Fleming sat on the committee that selected the targets for the T-Force unit, and listed them in the "Black Books" that were issued to the unit's officers. The infantry component of T-Force was in part made up of the 5th Battalion, King's Regiment, which supported the Second Army. It was responsible for securing targets of interest for the British military, including nuclear laboratories, gas research centres and individual rocket scientists. The unit's most notable discoveries came during the advance on the German port of Kiel, in the research centre for German engines used in the V-2 rocket, Messerschmitt Me 163 fighters and high-speed U-boats. Fleming would later use elements of the activities of T-Force in his writing, particularly in his 1955 Bond novel "Moonraker".
In 1942 Fleming attended an Anglo-American intelligence summit in Jamaica and, despite the constant heavy rain during his visit, he decided to live on the island once the war was over. His friend Ivar Bryce helped find a plot of land in Saint Mary Parish where, in 1945, Fleming had a house built, which he named Goldeneye. The name of the house and estate where he wrote his novels has many possible sources. Fleming himself mentioned both his wartime Operation Goldeneye and Carson McCullers' 1941 novel "Reflections in a Golden Eye", which described the use of British naval bases in the Caribbean by the American navy.
Post-war.
Upon Fleming's demobilisation in May 1945, he became the Foreign Manager in the Kemsley newspaper group, which at the time owned "The Sunday Times". In this role he oversaw the paper's worldwide network of correspondents. His contract allowed him to take three months holiday every winter, which he took in Jamaica. Fleming worked full-time for the paper until December 1959, but continued to write articles and attend the Tuesday weekly meetings until at least 1961.
After Ann Charteris' first husband died in the war, she expected to marry Fleming, but he decided to remain a bachelor. On 28 June 1945, she married the second Viscount Rothermere. Nevertheless, Charteris continued her affair with Fleming, travelling to Jamaica to see him under the pretext of visiting his friend and neighbour Noël Coward. In 1948 she gave birth to Fleming's daughter, Mary, who was stillborn. Rothermere divorced Charteris in 1951 because of her relationship with Fleming, and the couple married on 24 March 1952 in Jamaica, a few months before their son Caspar was born in August. Both Fleming and Ann had affairs during their marriage, she, most notably, with Hugh Gaitskell, the Leader of the Labour Party and Leader of the Opposition. Fleming had a long-term affair in Jamaica with one of his neighbours, Blanche Blackwell, mother of Chris Blackwell of Island Records.
1950s.
"The scent and smoke and sweat of a casino are nauseating at three in the morning. Then the soul erosion produced by high gambling — a compost of greed and fear and nervous tension — becomes unbearable and the senses awake and revolt from it."
 Opening lines of "Casino Royale"
Fleming had first mentioned to friends during the war that he wanted to write a spy novel, an ambition he achieved within two months with "Casino Royale". He started writing the book at Goldeneye on 17 February 1952, gaining inspiration from his own experiences and imagination. He claimed afterwards that he wrote the novel to distract himself from his forthcoming wedding to the pregnant Charteris, and called the work his "dreadful oafish opus". His manuscript was typed in London by Joan Howe, (mother of travel writer Rory MacLean) and Fleming's red-haired secretary at "The Times" on whom the character Miss Moneypenny was partially based. Clare Blanchard, a former girlfriend, advised him not to publish the book, or at least to do so under a pseudonym.
During "Casino Royale's" final draft stages, Fleming allowed his friend William Plomer to see a copy, and remarked "so far as I can see the element of suspense is completely absent". Despite this, Plomer thought the book had sufficient promise and sent a copy to the publishing house Jonathan Cape. At first, they were unenthusiastic about the novel, but Fleming's brother Peter, whose books they managed, persuaded the company to publish it. On 13 April 1953 "Casino Royale" was released in the UK in hardcover, priced at 10s 6d, with a cover designed by Fleming. It was a success and three print runs were needed to cope with the demand.
The novel centres on the exploits of James Bond, an officer in the Secret Intelligence Service, commonly known as MI6. Bond was also known by his code number, 007, and was a commander in the Royal Naval Reserve. Fleming took the name for his character from that of the American ornithologist James Bond, an expert on Caribbean birds and author of the definitive field guide "Birds of the West Indies". Fleming, himself a keen birdwatcher, had a copy of Bond's guide, and later told the ornithologist's wife, "that this brief, unromantic, Anglo-Saxon and yet very masculine name was just what I needed, and so a second James Bond was born". In a 1962 interview in "The New Yorker", he further explained: "When I wrote the first one in 1953, I wanted Bond to be an extremely dull, uninteresting man to whom things happened; I wanted him to be a blunt instrument ... when I was casting around for a name for my protagonist I thought by God, [James Bond] is the dullest name I ever heard."
Fleming based his creation on individuals he met during his time in the Naval Intelligence Division, and admitted that Bond "was a compound of all the secret agents and commando types I met during the war". Among those types were his brother Peter, whom he worshipped, and who had been involved in behind-the-lines operations in Norway and Greece during the war. Fleming envisaged that Bond would resemble the composer, singer and actor Hoagy Carmichael, although others, such as author and historian Ben Macintyre, identify aspects of Fleming's own looks in his description of Bond. General references in the novels describe Bond as having "dark, rather cruel good looks".
Fleming also modelled aspects of Bond on Conrad O'Brien-ffrench, a spy whom Fleming had met while skiing in Kitzbühel in the 1930s, Patrick Dalzel-Job, who served with distinction in 30AU during the war, and Bill "Biffy" Dunderdale, station head of MI6 in Paris, who wore cufflinks and handmade suits and was chauffeured around Paris in a Rolls-Royce. Sir Fitzroy Maclean was another possible model for Bond, based on his wartime work behind enemy lines in the Balkans, as was the MI6 double agent Dušan Popov. Fleming also endowed Bond with many of his own traits, including the same golf handicap, his taste for scrambled eggs, his love of gambling, and use of the same brand of toiletries.
After the publication of "Casino Royale", Fleming used his annual holiday at his house in Jamaica to write another Bond story. Twelve Bond novels and two short-story collections were published between 1953 and 1966, the last two ("The Man with the Golden Gun" and "Octopussy and The Living Daylights") posthumously. Much of the background to the stories came from Fleming's previous work in the Naval Intelligence Division or from events he knew of from the Cold War. The plot of "From Russia, with Love" uses a fictional Soviet Spektor decoding machine as a lure to trap Bond; the Spektor had its roots in the wartime German Enigma machine. The novel's plot device of spies on the Orient Express was based on the story of Eugene Karp, a US naval attaché and intelligence agent based in Budapest who took the Orient Express from Budapest to Paris in February 1950, carrying papers about blown US spy networks in the Eastern Bloc. Soviet assassins already on the train drugged the conductor, and Karp's body was found shortly afterwards in a railway tunnel south of Salzburg.
Many of the names used in the Bond works came from people Fleming knew: Scaramanga, the principal villain in "The Man with the Golden Gun", was named after a fellow Eton schoolboy with whom Fleming fought; Goldfinger, from the eponymous novel, was named after British architect Ernő Goldfinger, whose work Fleming abhorred; Sir Hugo Drax, the antagonist of "Moonraker", was named after Fleming's acquaintance Admiral Sir Reginald Aylmer Ranfurly Plunkett-Ernle-Erle-Drax; Drax's assistant, Krebs, bears the same name as Hitler's last Chief of Staff; and one of the homosexual villains from "Diamonds Are Forever", "Boofy" Kidd, was named after one of Fleming's close friends—and a relative of his wife—Arthur Gore, 8th Earl of Arran, known as Boofy to his friends.
Fleming's first work of non-fiction, "The Diamond Smugglers", was published in 1957 and was partly based on background research for his fourth Bond novel, "Diamonds Are Forever". Much of the material had appeared in "The Sunday Times" and was based on Fleming's interviews with John Collard, a member of the International Diamond Security Organisation who had previously worked in MI5. The book received mixed reviews in the UK and US.
For the first five books ("Casino Royale", "Live and Let Die", "Moonraker", "Diamonds Are Forever" and "From Russia, with Love") Fleming received broadly positive reviews. That began to change in March 1958 when Bernard Bergonzi, in the journal "Twentieth Century", attacked Fleming's work as containing "a strongly marked streak of voyeurism and sado-masochism" and wrote that the books showed "the total lack of any ethical frame of reference". The article compared Fleming unfavourably with John Buchan and Raymond Chandler on both moral and literary criteria. A month later, "Dr. No" was published, and Fleming received harsh criticism from a number of reviewers who, in the words of Ben Macintyre, "rounded on Fleming, almost as a pack". The most strongly worded of the critiques came from Paul Johnson of the "New Statesman", who, in his review "Sex, Snobbery and Sadism", called the novel "without doubt, the nastiest book I have ever read". Johnson went on to say that "by the time I was a third of the way through, I had to suppress a strong impulse to throw the thing away". Although Johnson recognised that in Bond there "was a social phenomenon of some importance", this was seen as a negative element, as the phenomenon concerned "three basic ingredients in "Dr No", all unhealthy, all thoroughly English: the sadism of a schoolboy bully, the mechanical, two-dimensional sex-longings of a frustrated adolescent, and the crude, snob-cravings of a suburban adult." Johnson saw no positives in "Dr. No", and said, "Mr Fleming has no literary skill, the construction of the book is chaotic, and entire incidents and situations are inserted, and then forgotten, in a haphazard manner."
Lycett notes that Fleming "went into a personal and creative decline" after marital problems and the attacks on his work. "Goldfinger" had been written before the publication of "Dr. No"; the next book Fleming produced after the criticism was "For Your Eyes Only", a collection of short stories derived from outlines written for a television series that did not come to fruition. Lycett noted that, as Fleming was writing the television scripts and the short stories, "Ian's mood of weariness and self-doubt was beginning to affect his writing", which can be seen in Bond's thoughts.
1960s.
In 1960 Fleming was commissioned by the Kuwait Oil Company to write a book on the country and its oil industry. The Kuwaiti Government disapproved of the typescript, "State of Excitement: Impressions of Kuwait", and it was never published. According to Fleming: "The Oil Company expressed approval of the book but felt it their duty to submit the typescript to members of the Kuwait Government for their approval. The Sheikhs concerned found unpalatable certain mild comments and criticisms and particularly the passages referring to the adventurous past of the country which now wishes to be 'civilised' in every respect and forget its romantic origins."
Fleming followed the disappointment of "For Your Eyes Only" with "Thunderball", the novelization of a film script on which he had worked with others. The work had started in 1958 when Fleming's friend Ivar Bryce introduced him to a young Irish writer and director, Kevin McClory, and the three, together with Fleming and Bryce's friend Ernest Cuneo, worked on a script. In October McClory introduced experienced screenwriter Jack Whittingham to the newly formed team, and by December 1959 McClory and Whittingham sent Fleming a script. Fleming had been having second thoughts on McClory's involvement and, in January 1960, explained his intention of delivering the screenplay to MCA, with a recommendation from him and Bryce that McClory act as producer. He additionally told McClory that if MCA rejected the film because of McClory's involvement, then McClory should either sell himself to MCA, back out of the deal, or file a suit in court.
Working at Goldeneye between January and March 1960, Fleming wrote the novel "Thunderball", based on the screenplay written by himself, Whittingham and McClory. In March 1961 McClory read an advance copy, and he and Whittingham immediately petitioned the High Court in London for an injunction to stop publication. After two court actions, the second in November 1961, Fleming offered McClory a deal, settling out of court. McClory gained the literary and film rights for the screenplay, while Fleming was given the rights to the novel, provided it was acknowledged as "based on a screen treatment by Kevin McClory, Jack Whittingham and the Author".
Fleming's books had always sold well, but in 1961 sales increased dramatically. On 17 March 1961, four years after its publication and three years after the heavy criticism of "Dr. No", an article in "Life Magazine" listed "From Russia, with Love" as one of US President John F. Kennedy's ten favourite books. Kennedy and Fleming had previously met in Washington. This accolade and the associated publicity led to a surge in sales that made Fleming the biggest-selling crime writer in the US. Fleming considered "From Russia, with Love" to be his best novel, although he admitted, "the great thing is that each one of the books seems to have been a favourite with one or other section of the public and none has yet been completely damned."
In April 1961, shortly before the second court case on "Thunderball", Fleming suffered a heart attack during a regular weekly meeting at "The Sunday Times". While he was convalescing, one of his friends, Duff Dunbar, gave him a copy of Beatrix Potter's "The Tale of Squirrel Nutkin" and suggested that he take the time to write up the bedtime story that Fleming used to tell to his son Caspar each evening. Fleming attacked the project with gusto and wrote to his publisher, Michael Howard of Jonathan Cape, joking that "There is not a moment, even on the edge of the tomb, when I am not slaving for you"; the result was Fleming's only children's novel, "Chitty-Chitty-Bang-Bang", which was published in October 1964, two months after his death.
In June 1961 Fleming sold a six-month option on the film rights to his published and future James Bond novels and short stories to Harry Saltzman. Saltzman formed the production vehicle Eon Productions along with Albert R. "Cubby" Broccoli, and after an extensive search, they hired Sean Connery on a five-film deal, beginning with "Dr. No" (1962). Connery's depiction of Bond affected the literary character; in "You Only Live Twice", the first book written after "Dr. No" was released, Fleming gave Bond a sense of humour that was not present in the previous stories.
Fleming's second non-fiction book was published in November 1963: "Thrilling Cities", a reprint of a series of "Sunday Times" articles based on Fleming's impressions of a number of world cities in trips taken during 1959 and 1960. Approached in 1964 by producer Norman Felton to write a spy series for television, Fleming provided several ideas, including the names of characters Napoleon Solo and April Dancer, for the series "The Man from U.N.C.L.E." However, Fleming withdrew from the project following a request from Eon Productions, who were keen to avoid any legal problems that might occur if the project overlapped with the Bond films.
In January 1964 Fleming went to Goldeneye for what proved to be his last holiday and wrote the first draft of "The Man with the Golden Gun". He was dissatisfied with it and wrote to William Plomer, the copy editor of his novels, asking for it to be rewritten. Fleming became increasingly unhappy with the book and considered rewriting it, but was dissuaded by Plomer, who considered it viable for publication.
Death.
Fleming was a heavy smoker and drinker throughout his adult life, and suffered from heart disease. In 1961, aged 53, he suffered a heart attack and struggled to recuperate. On 11 August 1964, while staying at a hotel in Canterbury, Fleming went to the Royal St George's Golf Club for lunch and later dined at his hotel with friends. The day had been tiring for him, and he collapsed with another heart attack shortly after the meal. Fleming died at age 56 in the early morning of 12 August 1964—his son Caspar's twelfth birthday. His last recorded words were an apology to the ambulance drivers for having inconvenienced them, saying "I am sorry to trouble you chaps. I don't know how you get along so fast with the traffic on the roads these days." Fleming was buried in the churchyard of Sevenhampton village, near Swindon.
Fleming's last two books, "The Man with the Golden Gun" and "Octopussy and The Living Daylights", were published posthumously. "The Man with the Golden Gun" was published eight months after Fleming's death and had not been through the full editing process by Fleming. As a result, the novel was thought by publishing company Jonathan Cape to be thin and "feeble". The publishers had passed the manuscript to Kingsley Amis to read on holiday, although they did not use his suggestions. Fleming's biographer Henry Chandler observes that the novel "received polite and rather sad reviews, recognising that the book had effectively been left half-finished, and as such did not represent Fleming at the top of his game". The final Bond book, containing two short stories, "Octopussy and The Living Daylights", was published in Britain on 23 June 1966.
In October 1975, Fleming's son Caspar, aged 23, committed suicide by drug overdose and was buried with his father. Fleming's widow, Ann, died in 1981 and was buried with her husband and their son.
Writing.
The author Raymond Benson, who later wrote a series of Bond novels, noted that Fleming's books fall into two distinct periods along stylistic lines. Those books written between 1953 and 1960 tend to concentrate on "mood, character development, and plot advancement", while those released between 1961 and 1966 incorporate more detail and imagery. Benson argues that Fleming had become "a master storyteller" by the time he wrote "Thunderball" in 1961.
Jeremy Black divides the series based on the villains Fleming created, a division supported by fellow academic Christoph Linder. Thus the early books from "Casino Royale" to "For Your Eyes Only" are classed as "Cold War stories", with SMERSH as the antagonists, followed by Blofeld and SPECTRE as Bond's opponents in the three novels "Thunderball", "On Her Majesty's Secret Service" and "You Only Live Twice", after the thawing of East–West relations. Black and Linder both classify the remaining books—"The Man with the Golden Gun", "Octopussy and The Living Daylights" and "The Spy Who Loved Me"—as "the later Fleming stories".
Style and technique.
Fleming said of his work, "while thrillers may not be Literature with a capital L, it is possible to write what I can best describe as 'thrillers designed to be read as literature'". He named Raymond Chandler, Dashiell Hammett, Eric Ambler and Graham Greene as influences. William Cook in the "New Statesman" considered James Bond to be "the culmination of an important but much-maligned tradition in English literature. As a boy, Fleming devoured the Bulldog Drummond tales of Lieutenant Colonel H. C. McNeile (aka "Sapper") and the Richard Hannay stories of John Buchan. His genius was to repackage these antiquated adventures to fit the fashion of postwar Britain ... In Bond, he created a Bulldog Drummond for the jet age." Umberto Eco considered Mickey Spillane to have been another major influence.
In May 1963 Fleming wrote a piece for "Books and Bookmen" magazine in which he described his approach to writing Bond books: "I write for about three hours in the morning ... and I do another hour's work between six and seven in the evening. I never correct anything and I never go back to see what I have written ... By following my formula, you write 2,000 words a day." Benson identified what he described as the "Fleming Sweep", the use of "hooks" at the end of chapters to heighten tension and pull the reader into the next. The hooks combine with what Anthony Burgess calls "a heightened journalistic style" to produce "a speed of narrative, which hustles the reader past each danger point of mockery".
Umberto Eco analysed Fleming's works from a Structuralist point of view, and identified a series of oppositions within the storylines that provide structure and narrative, including:
Eco also noted that the Bond villains tend to come from Central Europe or from Slavic or Mediterranean countries and have a mixed heritage and "complex and obscure origins". Eco found that the villains were generally asexual or homosexual, inventive, organisationally astute, and wealthy. Black observed the same point: "Fleming did not use class enemies for his villains instead relying on physical distortion or ethnic identity ... Furthermore, in Britain foreign villains used foreign servants and employees ... This racism reflected not only a pronounced theme of interwar adventure writing, such as the novels of Buchan, but also wider literary culture." Writer Louise Welsh found that the novel "Live and Let Die" "taps into the paranoia that some sectors of white society were feeling" as the civil rights movements challenged prejudice and inequality.
Fleming used well-known brand names and everyday details to support a sense of realism. Kingsley Amis called this "the Fleming effect", describing it as "the imaginative use of information, whereby the pervading fantastic nature of Bond's world ... [is] bolted down to some sort of reality, or at least counter-balanced."
Major themes.
Britain's position in the world.
The Bond books were written in post-war Britain, when the country was still an imperial power. As the series progressed, the British Empire was in decline; journalist William Cook observed that "Bond pandered to Britain's inflated and increasingly insecure self-image, flattering us with the fantasy that Britannia could still punch above her weight." This decline of British power was referred to in several of the novels; in "From Russia, with Love", it manifested itself in Bond's conversations with Darko Kerim, when Bond admits that in England, "we don't show teeth any more—only gums." The theme is strongest in one of the later books of the series, the 1964 novel "You Only Live Twice", in conversations between Bond and the head of Japan's secret intelligence service, Tiger Tanaka. Fleming was acutely aware of the loss of British prestige in the 1950s and early 60s, particularly during the Indonesia–Malaysia confrontation, when he had Tanaka accuse Britain of throwing away the empire "with both hands".
Black points to the defections of four members of MI6 to the Soviet Union as having a major impact on how Britain was viewed in US intelligence circles. The last of the defections was that of Kim Philby in January 1963, while Fleming was still writing the first draft of "You Only Live Twice". The briefing between Bond and M is the first time in the twelve books that Fleming acknowledges the defections. Black contends that the conversation between M and Bond allows Fleming to discuss the decline of Britain, with the defections and the Profumo Affair of 1963 as a backdrop. Two of the defections had taken place shortly before Fleming wrote "Casino Royale", and the book can be seen as the writer's "attempt to reflect the disturbing moral ambiguity of a post-war world that could produce traitors like Burgess and Maclean", according to Lycett.
By the end of the series, in the 1965 novel, "The Man with the Golden Gun", Black notes that an independent inquiry was undertaken by the Jamaican judiciary, while the CIA and MI6 were recorded as acting "under the closest liaison and direction of the Jamaican CID": this was the new world of a non-colonial, independent Jamaica, further underlining the decline of the British Empire. The decline was also reflected in Bond's use of US equipment and personnel in several novels. Uncertain and shifting geopolitics led Fleming to replace the Russian organisation SMERSH with the international terrorist group SPECTRE in "Thunderball", permitting "evil unconstrained by ideology". Black argues that SPECTRE provides a measure of continuity to the remaining stories in the series.
Effects of the war.
A theme throughout the series was the effect of the Second World War. "The Times" journalist Ben Macintyre considers that Bond was "the ideal antidote to Britain's postwar austerity, rationing and the looming premonition of lost power", at a time when coal and many items of food were still rationed. Fleming often used the war as a signal to establish "good" or "evil" in characters: in "For Your Eyes Only", the villain, Hammerstein, is a former Gestapo officer, while the sympathetic Royal Canadian Mounted Police officer, Colonel Johns, served with the British under Montgomery in the Eighth Army. Similarly, in "Moonraker", Drax (Graf Hugo von der Drache) is a "megalomaniac German Nazi who masquerades as an English gentleman", and his assistant, Krebbs, bears the same name as Hitler's last Chief of Staff. In this, Fleming "exploits another British cultural antipathy of the 1950s. Germans, in the wake of the Second World War, made another easy and obvious target for bad press." As the series progressed, the threat of a re-emergent Germany was overtaken by concerns about the Cold War, and the novels changed their focus accordingly.
Comradeship.
Periodically in the series, the topic of comradeship or friendship arises, with a male ally who works with Bond on his mission. Raymond Benson believes that the relationships Bond has with his allies "add another dimension to Bond's character, and ultimately, to the thematic continuity of the novels". In "Live and Let Die", agents Quarrel and Leiter represent the importance of male friends and allies, seen especially in Bond's response to the shark attack on Leiter; Benson observes that "the loyalty Bond feels towards his friends is as strong as his commitment to his job". In "Dr. No", Quarrel is "an indispensable ally". Benson sees no evidence of discrimination in their relationship and notes Bond's genuine remorse and sadness at Quarrel's death.
The "traitor within".
From the opening novel in the series, the theme of treachery was strong. Bond's target in "Casino Royale", Le Chiffre, was the paymaster of a French communist trade union, and the overtones of a fifth column struck a chord with the largely British readership, as Communist influence in the trade unions had been an issue in the press and parliament, especially after the defections of Burgess and Maclean in 1951. The "traitor within" theme continued in "Live and Let Die" and "Moonraker".
Good versus evil.
Raymond Benson considered the most obvious theme of the series to be good versus evil. This crystallised in "Goldfinger" with the Saint George motif, which is stated explicitly in the book: "Bond sighed wearily. Once more into the breach, dear friend! This time it really was St George and the dragon. And St George had better get a move on and do something"; Black notes that the image of St. George is an English, rather than British personification.
Anglo-American relations.
The Bond novels also dealt with the question of Anglo-American relations, reflecting the central role of the US in the defence of the West. In the aftermath of the Second World War, tensions surfaced between a British government trying to retain its empire and the American desire for a capitalist new world order, but Fleming did not focus on this directly, instead creating "an impression of the normality of British imperial rule and action". Author and journalist Christopher Hitchens observed that "the central paradox of the classic Bond stories is that, although superficially devoted to the Anglo-American war against communism, they are full of contempt and resentment for America and Americans". Although Fleming was aware of this tension between the two countries, he did not focus on it strongly. Kingsley Amis, in his exploration of Bond in "The James Bond Dossier", pointed out that "Leiter, such a nonentity as a piece of characterization ... he, the American, takes orders from Bond, the Britisher, and that Bond is constantly doing better than he".
For three of the novels, "Goldfinger", "Live and Let Die" and "Dr. No", it is Bond the British agent who has to sort out what turns out to be an American problem, and Black points out that although it is American assets that are under threat in "Dr. No", a British agent and a British warship, HMS "Narvick", are sent with British soldiers to the island at the end of the novel to settle the matter. Fleming became increasingly jaundiced about America, and his comments in the penultimate novel "You Only Live Twice" reflect this; Bond's responses to Tanaka's comments reflect the declining relationship between Britain and America—in sharp contrast to the warm, co-operative relationship between Bond and Leiter in the earlier books.
Legacy.
In the late 1950s the author Geoffrey Jenkins had suggested to Fleming that he write a Bond novel set in South Africa, and sent him his own idea for a plot outline which, according to Jenkins, Fleming felt had great potential. After Fleming's death, Jenkins was commissioned by Bond publishers Glidrose Productions to write a continuation Bond novel, "Per Fine Ounce", but it was never published. Starting with Kingsley Amis' "Colonel Sun", under the pseudonym "Robert Markham" in 1968, several authors have been commissioned to write Bond novels, including Sebastian Faulks, who was asked by Ian Fleming Publications to write a new Bond novel in observance of what would have been Fleming's 100th birthday in 2008.
During his lifetime Fleming sold thirty million books; double that number were sold in the two years following his death. In 2008 "The Times" ranked Fleming fourteenth on its list of "The 50 greatest British writers since 1945". In 2002 Ian Fleming Publications announced the launch of the CWA Ian Fleming Steel Dagger award, presented by the Crime Writers' Association to the best thriller, adventure or spy novel originally published in the UK.
The Eon Productions series of Bond films, which started in 1962 with "Dr. No", continued after Fleming's death. Along with two non-Eon produced films, there have been twenty-three Eon films, with the most recent, "Skyfall", released in October 2012. The Eon Productions series has grossed $4,910,000,000 (over $12,360,000,000 when adjusted for inflation) worldwide, making it the second highest grossing film series, behind "Harry Potter".
The influence of Bond in the cinema and in literature is evident in films and books as diverse as the "Austin Powers" series, "Carry On Spying" and the Jason Bourne character. In 2011 Fleming became the first English-language writer to have an international airport named after him: Ian Fleming International Airport, near Oracabessa, Jamaica, was officially opened on 12 January 2011 by Jamaican Prime Minister Bruce Golding and Fleming's niece, Lucy.
Notes and references.
Notes
References
Sources.
</dl>

</doc>
<doc id="57986" url="http://en.wikipedia.org/wiki?curid=57986" title="Gladius">
Gladius

Gladius (Latin: "glădĭus") was one Latin word for sword and is used to represent the primary sword of Ancient Roman foot soldiers. Early ancient Roman swords were similar to those used by the Greeks. From the 3rd century BC, the Romans adopted swords similar to those used by the Celtiberians and others during the early part of the conquest of Hispania. This sword was known as the Gladius Hispaniensis, or "Hispanic Sword".
A fully equipped Roman legionary after the reforms of Gaius Marius was armed with a shield (scutum), one or two javelins (pila), a sword (gladius), often a dagger (pugio), and perhaps, in the later Empire period, darts (plumbatae). Conventionally, the javelins would be thrown to disable the shields and disrupt the formation of the enemy before engaging in close combat, for which the gladius would be drawn. The soldier generally led with his shield and thrust with his sword. All types of gladius appear to have also been suitable for cutting and chopping motions as well as for thrusting.
Name.
The name is a Latin masculine second declension noun, its plural being "gladiī".† However, the word "gladius" in Latin refers to any sword, not specifically the modern definition of a gladius. Gladius is used in literature as early as the plays of Plautus ("Casina", "Rudens").
Words derived from the word "gladius" include gladiator ("swordsman") and gladiolus ("little sword," from the diminutive form of "gladius"), a flowering plant with sword-shaped leaves.
Gladius is generally believed to be a Celtic loanword in Latin (perhaps via an Etruscan intermediary), derived from ancient Celtic "*kladi(b)os" or "*kladimos" "sword" (whence Modern Welsh "cleddyf" "sword", Modern Breton "klezeff", Old Irish "claideb"/Modern Irish "claidheamh" [itself perhaps a loan from Welsh]; the root of the word may survive in the Old Irish verb "claidid" "digs, excavates" and anciently attested in the Gallo-Brittonic place name element "cladia"/"clado" "ditch, trench, valley hollow").
Predecessors and origins.
Livy relates the story of Titus Manlius Torquatus accepting a challenge to a single combat by a large Gallic soldier at a bridge over the Anio river, where the Gauls and the Romans were encamped on opposite sides of the river. Manlius strapped on the Hispanic sword ("Gladius Hispanus"). During the combat he thrust twice with it under the shield of the Gaul, dealing fatal blows to the abdomen. He then removed the Gaul's torc and placed it around his own neck, hence the name, torquatus.
The combat happened in the consulships of C. Sulpicius and C. Licinius in about 361 BC, much before the Punic Wars, but during the frontier wars with the Gauls (366-341 BC). One theory therefore proposes the borrowing of the word gladius from *kladi- during this period, relying on the principle that k becomes g in Latin. Ennius attests the word. Gladius may have replaced "ensis", which in the literary periods was used mainly by the poets.
The exact origin of the gladius Hispanus is an argued topic, while it is likely that it descended ultimately from Celtic swords of the La Tene and Hallstat periods; it is unknown if it descended directly from Celtiberian troops of the Punic Wars, or through Gallic troops of the Gallic Wars.
The Celtiberian source of the weapon has been reinforced during the later decades. Recent findings of very early Roman gladii highlights that they were copies of Celtiberian models. The weapon was developed in Iberia after La Téne I models, which were adapted to traditional Celtiberian techniques during the late 4th and early 3rd centuries BC. These weapons are quite original in their design, so that they cannot be confused with Gallic types.
Manufacture.
By the time of the Roman Republic, which flourished during the Iron Age, the classical world was well-acquainted with steel and the steel-making process. Pure iron is relatively soft, but pure iron is never found in nature. Natural iron ore contains various impurities in solid solution, which harden the reduced metal by producing irregular-shaped metallic crystals. The Gladius is generally made out of steel.
In Roman times, ore was reduced in a bloomery furnace. The resulting pieces were called "blooms", which were further worked to remove slag inclusions from its porous surface.
A recent metallurgical study of two Etrurian swords, one in the form of a Greek kopis from 7th century BC Vetulonia, the other in the form of a gladius Hispaniensis from 4th century BC Chiusa, gives some insight concerning the manufacture of Roman swords. The Chiusa sword comes from Romanized Etruria; thus, regardless of the names of the forms (which the authors do not identify), the authors believe the process was continuous from the Etruscans to the Romans.
The Vetulonian sword was crafted by the pattern welding process from five blooms reduced at a temperature of 1163 °C. Five strips of varying carbon content were created. A central core of the sword contained the highest: 0.15–0.25% carbon. On its edges were placed four strips of low-carbon steel, 0.05–0.07%, and the whole thing was welded together by forging on the pattern of hammer blows. A blow increased the temperature sufficiently to produce a friction weld at that spot. Forging continued until the steel was cold, producing some central annealing. The sword was 58 cm (22.8 in) long.
The Chiusian sword was created from a single bloom by forging from a temperature of 1237 °C. The carbon content increased from 0.05–0.08% at the back side of the sword to 0.35–0.4% on the blade, from which the authors deduce some form of carburization may have been used. The sword was 40 cm (15.7 in) long and was characterized by a wasp-waist close to the hilt.
Roman swords continued to be forged both as composites and from single pieces. Inclusions of sand and rust weakened the two swords in the study and no doubt limited the strength of swords during the Roman period.
Description.
The word gladius acquired a general meaning as any type of sword. This use appears as early as the 1st century AD in the "Biography of Alexander the Great" by Quintus Curtius Rufus. The republican authors, however, appear to mean a specific type of sword, which is now known from archaeology to have had variants.
Gladii were two-edged for cutting and had a tapered point for stabbing during thrusting. A solid grip was provided by a knobbed hilt added on, possibly with ridges for the fingers. Blade strength was achieved by welding together strips, in which case the sword had a channel down the center, or by fashioning a single piece of high-carbon steel, rhomboidal in cross-section. The owner's name was often engraved or punched on the blade.
The hilt of a Roman sword was the "capulus". It was often ornate, especially the sword-hilts of officers and dignitaries.
Stabbing was a very efficient technique, as stabbing wounds, especially in the abdominal area, were almost always deadly (see the quotation from Vegetius under pugio). However, the gladius in some circumstances was used for cutting or slashing, as is indicated by Livy's account of the Macedonian Wars, wherein the Macedonian soldiers were horrified to see dismembered bodies.
Though the primary infantry attack was thrusting at stomach height, they were trained to take any advantage, such as slashing at kneecaps beneath the shield wall.
The gladius was sheathed in a scabbard mounted on a belt or shoulder strap, some say on the right, some say on the left (refer to the articles cited in the notes). Some say the soldier reached across his body to draw it, and others claim that the position of the shield made this method of drawing impossible. A centurion wore it on the opposite side as a mark of distinction.
Towards the end of the 2nd century AD and during the 3rd century the "spatha" gradually took the place of the gladius in the Roman legions.
Types.
Several different designs were used; among collectors and historical reenactors, the three primary kinds are known as the "Mainz gladius", the "Fulham gladius", and the "Pompeii gladius" (these names refer to where or how the canonical example was found). More recent archaeological finds have uncovered an earlier version, the "Gladius Hispaniensis" ("Hispanic sword").
The differences between these varieties are subtle. The original Hispanic sword, which was used during the republic, had a slight "wasp-waist" or "leaf-blade" curvature. The Mainz variety came into use on the frontier in the early empire. It kept the curvature, but shortened and widened the blade and made the point triangular. At home, the less battle-effective Pompeii version came into use. It eliminated the curvature, lengthened the blade, and diminished the point. The Fulham was a compromise, with straight edges and a long point.
Descriptions of the main types follow:
The Mainz and the Pompeii are the two main classification types and served side by side for many years and it was not uncommon to find 4th century legionaries carrying the earlier model.
Notes.
^ Please note that this is only true for the nominative case; For more information, see the Latin declension page.
External links.
The articles in the links below often differ both in theory and in detail. They should not necessarily be understood as fully professional articles but should be appreciated for their presentational value.

</doc>
<doc id="57987" url="http://en.wikipedia.org/wiki?curid=57987" title="Rudolf Carnap">
Rudolf Carnap

Rudolf Carnap (; ]; May 18, 1891 – September 14, 1970) was a German-born philosopher who was active in Europe before 1935 and in the United States thereafter. He was a major member of the Vienna Circle and an advocate of logical positivism.
Life and work.
Carnap's father had risen from the status of a poor ribbon-weaver to become the owner of a ribbon-making factory. His mother came from academic stock; her father was an educational reformer and her oldest brother was the archaeologist Wilhelm Dörpfeld. As a ten-year-old, Carnap accompanied his uncle on an expedition to Greece.
He began his formal education at the Barmen Gymnasium. From 1910 to 1914, he attended the University of Jena, intending to write a thesis in physics. But he also studied carefully Kant's "Critique of Pure Reason" during a course taught by Bruno Bauch, and was one of very few students to attend Gottlob Frege's courses in mathematical logic. While Carnap held moral and political opposition to World War I, he felt obligated to serve in the German army. After three years of service, he was given permission to study physics at the University of Berlin, 1917–18, where Albert Einstein was a newly appointed professor. Carnap then attended the University of Jena, where he wrote a thesis defining an axiomatic theory of space and time. The physics department said it was too philosophical, and Bruno Bauch of the philosophy department said it was pure physics. Carnap then wrote another thesis, with Bauch's supervision, on the theory of space in a more orthodox Kantian style, and published as "Der Raum" (Space) in a supplemental issue of Kant-Studien (1922). In it he makes the clear distinction between "formal," "physical" and "perceptual" (e.g., "visual") spaces.
Frege's course exposed him to Bertrand Russell's work on logic and philosophy, which put a sense of the aims to his studies. He accepted the effort to surpass traditional philosophy with logical innovations that inform the sciences. He wrote a letter to Russell, who responded by copying by hand long passages from his "Principia Mathematica" for Carnap's benefit, as neither Carnap nor his university could afford a copy of this epochal work. In 1924 and 1925, he attended seminars led by Edmund Husserl, the founder of phenomenology, and continued to write on physics from a logical positivist perspective.
Carnap discovered a kindred spirit when he met Hans Reichenbach at a 1923 conference. Reichenbach introduced Carnap to Moritz Schlick, a professor at the University of Vienna who offered Carnap a position in his department, which Carnap accepted in 1926. Carnap thereupon joined an informal group of Viennese intellectuals that came to be known as the Vienna Circle, directed largely by Moritz Schlick and including Hans Hahn, Friedrich Waismann, Otto Neurath, and Herbert Feigl, with occasional visits by Hahn's student Kurt Gödel. When Wittgenstein visited Vienna, Carnap would meet with him. He (with Hahn and Neurath) wrote the 1929 manifesto of the Circle, and (with Hans Reichenbach) initiated the philosophy journal "Erkenntnis".
In 1928, Carnap published two important books:
In February 1930 Tarski lectured in Vienna, and during November 1930 Carnap visited Warsaw. On these occasions he learned much about Tarski's model theoretic method of semantics. Rose Rand, another philosopher in the Vienna Circle, noted, "Carnap's conception of semantics starts from the basis given in Tarski's work but a distinction is made between logical and non-logical constants and between logical and factual truth... At the same time he worked with the concepts of intension and extension and took these two concepts as a basis of a new method of semantics."
In 1931, Carnap was appointed Professor at the German language University of Prague. There he wrote the book that was to make him the most famous logical positivist and member of the Vienna Circle, his "Logical Syntax of Language" (Carnap 1934). In this work, Carnap advanced his Principle of Tolerance, according to which there is not any such thing as a "true" or "correct" logic or language. One is free to adopt whatever form of language is useful for one's purposes. In 1933, W. V. Quine met Carnap in Prague and discussed the latter's work at some length. Thus began the lifelong mutual respect these two men shared, one that survived Quine's eventual forceful disagreements with a number of Carnap's philosophical conclusions.
Carnap, whose socialist and pacifist beliefs put him at risk in Nazi Germany, emigrated to the United States in 1935 and became a naturalized citizen in 1941. Meanwhile back in Vienna, Moritz Schlick was murdered in 1936. From 1936 to 1952, Carnap was a professor of philosophy at the University of Chicago. During the late 1930s, Carnap offered an assistant position in philosophy to Carl Gustav Hempel, who accepted. The two conducted research including "Logical Syntax". Thanks partly to Quine's help, Carnap spent the years 1939–41 at Harvard, where he was reunited with Tarski. Carnap (1963) later expressed some irritation about his time at Chicago, where he and Charles W. Morris were the only members of the department committed to the primacy of science and logic. (Their Chicago colleagues included Richard McKeon, Mortimer Adler, Charles Hartshorne, and Manley Thompson.) Carnap's years at Chicago were nonetheless very productive ones. He wrote books on semantics (Carnap 1942, 1943, 1956), modal logic, being very similar in Carnap (1956) to the now-standard possible worlds semantics for that logic Saul Kripke proposed starting in 1959, and on the philosophical foundations of probability and induction (Carnap 1950, 1952).
After a stint at the Institute for Advanced Study in Princeton, he joined the philosophy department at UCLA in 1954, Hans Reichenbach having died the previous year. He had earlier refused an offer of a similar job at the University of California, because accepting that position required that he sign a loyalty oath, a practice to which he was opposed on principle. While at UCLA, he wrote on scientific knowledge, the analytic – synthetic dichotomy, and the verification principle. His writings on thermodynamics and on the foundations of probability and induction, were published posthumously as Carnap (1971, 1977, 1980).
Carnap taught himself Esperanto when he was 14 years of age, and remained sympathetic to it (Carnap 1963). He later attended the World Congress of Esperanto in 1908 and 1922, and employed the language while traveling.
Carnap had four children by his first marriage to Elizabeth Schöndube, which ended in divorce in 1929. He married his second wife, Elizabeth Ina Stögner, in 1933. Ina committed suicide in 1964.
Logical syntax.
Carnap's "Logical Syntax of Language" can be regarded as a response to Wittgenstein 's "Tractatus".
Carnap elaborated and extended the concept of logical syntax proposed by Wittgenstein in the "Tractatus" (Section 3.325).
 " 3.325. In order to avoid such errors we must make use of a sign-language that excludes them by not using the same sign for different symbols and by not using in a superficially similar way signs that have different modes of signification: that is to say, a sign-language that is governed by logical grammar—by logical syntax. ...
 — Wittgenstein, "Section 3.325, "Tractatus ""
However, Wittgenstein stated that propositions cannot represent logical form.
 " 4.121. Propositions cannot represent logical form: it is mirrored in them. What finds its reflection in language, language cannot represent. What expresses itself in language, we cannot express by means of language.
Propositions show the logical form of reality. They display it.
 — Wittgenstein, "Section 4.121, "Tractatus ""
Carnap disagreed. Wittgenstein proposed the idea of logical syntax. It is Carnap who designed, formulated and implemented the details of logical syntax in philosophical analysis. Carnap defined logical syntax as:
 " By the logical syntax of a language, we mean the formal theory of the linguistic forms of that language – the systematic statement of the formal rules which govern it together with the development of the consequences which follow from these rules.
A theory, a rule, a definition, or the like is to be called formal when no reference is made in it either to the meaning of the symbols (for examples, the words) or to the sense of the expressions (e.g. the sentences), but simply and solely to the kinds and order of the symbols from which the expressions are constructed.
 — Carnap, "Page 1, " Logical Syntax of Language ""
In the U.S, the concept of logical syntax helped the development of natural language processing and compiler design.
The purpose of logical syntax.
The purpose of logical syntax is to provide a system of concepts, a language, by the help of which the results of logical analysis will be exactly formulable.
Carnap stated :
 " Philosophy is to be replaced by the logic of science – that is to say, by the logical analysis of the concepts and sentences of the sciences, for the logic of science is nothing other than the logical syntax of the language of science.
 — Carnap, "Foreword, " Logical Syntax of Language ""
 " ...According to this view, the sentences of metaphysics are pseudo-sentences which on logical analysis are proved to be either empty phrases or phrases which violate the rules of syntax. Of the so-called philosophical problems, the only questions which have any meaning are those of the logic of science. To share this view is to substitute logical syntax for philosophy.
 — Carnap, "Page 8, "Logical Syntax of Language ""
Carnap wanted only to end metaphysics but not philosophy.
Rejection of metaphysics.
Carnap, in his book "Philosophy and Logical Syntax", used the concept of verifiability to reject metaphysics.
The function of logical analysis.
Carnap used the method of logical analysis to reject metaphysics.
 " The function of logical analysis is to analyse all knowledge, all assertions of science and of everyday life, in order to make clear the sense of each such assertion and the connections between them. One of the principal tasks of the logical analysis of a given proposition is to find out the method of verification for that proposition.
 — Carnap , Page. 9-10, ' "Philosophy and Logical Syntax'
Selected publications.
For links to Carnap's publications and discussions of his work, see 
 Under construction, with no entries dated later than 1937.
For a more comprehensive bibliography, see also http://fr.wikipedia.org/wiki/Rudolf_Carnap

</doc>
<doc id="57988" url="http://en.wikipedia.org/wiki?curid=57988" title="Falchion">
Falchion

A falchion (; Old French: "fauchon"; Latin: "falx", "sickle") is a one-handed, single-edged sword of European origin, whose design is reminiscent of the Persian scimitar, the Chinese "dadao", and modern machete.
The weapon combined the weight and power of an axe with the versatility of a sword. Falchions are found in different forms from around the 11th century up to and including the sixteenth century. In some versions the falchion looks rather like the weapon-seax and later the sabre, and in some versions the form is irregular or like a machete with a crossguard.
Types.
The blade designs of falchions varied widely across the continent and through the ages. They almost always included a single edge with a slight curve on the blade towards the point on the end and most were also affixed with a quilloned crossguard for the hilt in the manner of the contemporary arming swords. Unlike the double-edged swords of Europe, few actual swords of this type have survived to the present day; fewer than a dozen specimens are currently known. Two basic types can be identified:
In addition, there are a group of 13th. and early 14th. century weapons sometimes identified with the falchion. These have a falchion-like blade mounted on a wooden haft 1 - long, sometimes ending in a curve like an umbrella. These are seen in numerous illustration in the mid-13th. century Maciejowski Bible.
A number of weapons superficially similar to the falchion existed in Western Europe, including the Messer, hanger and the backsword.
Status.
It is sometimes presumed that these swords had a lower quality and status than the longer, more expensive swords. It is possible that some falchions were used as axe-like tools between wars and fights, since they were practical pieces of equipment. While falchions are commonly thought to be peasants' weapons this is not always the case; the Conyers falchion belonged to a landed family, and the falchion is shown in illustrations of combat between mounted knights. Some later falchions were ornate and used by the nobility; there is an elaborately engraved and gold plated falchion from the 1560s in the Wallace Collection, engraved with the personal coat of arms of Cosimo I de' Medici, Grand Duke of Tuscany.

</doc>
<doc id="57989" url="http://en.wikipedia.org/wiki?curid=57989" title="PLUR">
PLUR

Peace Love Unity Respect, commonly shortened with PLUR, is the credo (see mantra) of the rave, goa trance, and Electronic Dance Music cultures. Originating from early online discussions about rave culture conducted on Usenet its usage has been common since the early 1990s, where it became "de rigueur" on club flyers and especially on club paraphernalia advertising underground outdoor trance parties. 
It may be interpreted as the raver or clubber's essential philosophy of life, at least insomuch as it relates to interpersonal relationships, with basic directions on how people are expected to behave at a rave gathering. This universalist philosophy underpinning the tribal dance culture which began circling the globe with the rise of the internet, theoretically takes precedence over any chemical or musical aspects of the rave scene. Raves represent a modern ritualistic experience, promoting a strong communal sense, where PLUR is considered an ideology.
Within the Kandi culture, there can be a symbolic handshake that rave-goers exchange with one another. This handshake usually includes the exchange of Kandi bracelets, which are handmade bracelets crafted with pony beads.
Origins.
PLUR dates back to the late '80s and early '90s rave scene in the UK which incorporated House and Acid House music that originated in Chicago during the '80s. The term began as an informal discussion on alt.rave and alt.culture.zippies usenet lists. SF-raves mailing list archived at hyperreal also noted the use of the term and there is a flyer archive which would be worth trawling for evidence of the existence of PLUR. It should be noted that the term is really an aggregation of ideas synonymous with the earlier hippies and also hip hop culture, with the peace movement being an essential starting point to any be-in encounter or rave.
One of the earliest uses of the term outside of usenet and the internet, most anecdotal, appears to be DJ Frankie Bones in June 1993. Supposedly in response to a fight that broke out at one of his epic Storm Raves in New York City, Bones is said to have got on the microphone and yelled: “If you don’t start showing some peace, love, and unity, I’ll break your faces.”
Variations.
Later incarnations and variations of PLUR can be seen in the adoption of Pronoia and also Ubuntu, with PLUR and Pronoia often being interchangeable terms, depending upon one's company.

</doc>
<doc id="57992" url="http://en.wikipedia.org/wiki?curid=57992" title="Monocoque">
Monocoque

Monocoque ( or ) is a structural approach whereby loads are supported through an object's external skin, similar to an egg shell. The technique may also be called structural skin. The word "monocoque" is a French term for "single shell" or (of boats) "single hull". 
Semi-monocoque.
Some structures have sub-components that are monocoques, but which form part of a composite frame structure. Alternative structures to "true" to monocoques include: trusses, unibodies, inflatable shells and semi-monocoque or stressed skin. The semi-monocoque is a hybrid combining a tensile shell and compressive structure made up of longerons and ribs or frames.
Aircraft.
Early aircraft were constructed using internal frames, typically of wood or steel tubing, which were then covered (or "skinned") with fabric such as irish linen or cotton. The skin added nothing to the structural strength of the airframe and was essentially dead weight beyond providing a smooth sealed surface. By thinking of the airframe as a whole, and not just the sum of its parts, it made sense to adopt a monocoque structure and it did not take long for various companies to adopt practices from the boat industry such as laminating thin strips of wood. In 1912, Deperdussin introduced a monocoque racer using a fuselage made up of three layers of laminated strips of glued poplar veneer, which provided both the external skin and the main load-bearing structure. This reduced drag so effectively it was able to win most of the races it was entered into. This style of construction was copied, with some variations, in Germany by LFG Roland — licensed by them to Pfalz Flugzeugwerke in the so-called, patented "Wickelrumpf" (wrapped body) form using two layers of plywood strips and fabric wrapping between them over a male mold for each half of the fuselage surface "shell"; while Albatros, Hannover and Siemens-Schuckert used four-sided panels of plywood instead, covering the light internal framework working forward from the tail, and upwards from the ventral side of the structure. However, it was prone to damage from moisture and delamination. Following the initial successes of all-metal aircraft from the Junkers firm as early as 1915 onwards, by the late 1930s, aluminum monocoque skin was used to form a pressurized cabin for high-altitude flight, such as in the Lockheed XC-35.
Automobiles.
Commercial car bodies are almost never monocoques; instead modern cars use "unitary body / chassis," "unitary construction." "unibody", or "Body Frame Integral" construction, with box sections, bulkheads and tubes providing most of the strength of the vehicle, while the skin adds relatively little to the strength or stiffness. The term monocoque has often been misused when referring to unibody cars. 
In modern motor racing however, the safety of the driver depends on the extraordinary strength of the car body which must meet stringent design regulations and a small number of cars have been built with monocoque structures. McLaren was the first company to utilize carbon-fiber-reinforced polymers to construct the monocoque of the McLaren MP4/1, which debuted in 1981. The strong and lightweight construction technique has become essential in high-end motorsport, and in 1992 McLaren made the F1 the first production car to use a carbon-fiber monocoque.
Armored vehicles.
Tanks and other armored vehicles such as the German Fuchs 2 and RG-33 may use a body which is built of armor rather than attaching armor to a frame. This reduces weight for a given amount of armor compared to vehicles to which armor has been attached to an underlying frame.
Two-wheeled vehicles.
Between 1958 and 1965 the UK firm Ariel Motorcycles manufactured two production monocoque motorcycle models, the Ariel Leader and its sibling, the Ariel Arrow.
A monocoque-framed motorcycle was developed by the Spanish motorcycle manufacturer, Ossa, for the 1967 Grand Prix motorcycle racing season. Although the single-cylinder Ossa had 20 hp less than its rivals, it was 45 lb lighter and its monocoque frame was much stiffer than conventional motorcycle frames, giving it superior agility on the racetrack. Ossa won four Grand Prix races with the monocoque bike before their rider was killed during the 1970 Isle of Man TT, causing the Ossa factory to withdraw from Grand Prix competition.
Notable designers such as Eric Offenstadt and Dan Hanebrink created unique monocoque designs in the early 1970s. The 1973 Isle of Man TT was won by Peter Williams on the monocoque-framed Norton John Player Special that he helped design. Honda also experimented with a monocoque Grand Prix racing motorcycle named the NR500 in 1979. However, the bike also featured other innovative features including an engine with oval shaped cylinders, and eventually succumbed to the problems associated with attempting to develop too many new technologies at once. In 1987 John Britten developed the Aero-D One, featuring a composite monocoque chassis that weighed only 12 kg. In 2009, Ducati introduced the Desmosedici GP9 with a carbon fibre semi-monocoque chassis.
Single-piece carbon fiber bicycle frames are sometimes described as monocoques however as most use the components to form a frame structure (even if molded in a single piece), these are frames and not monocoques, and the bike industry continues to refer to them as framesets.
Rockets.
Various rockets have used pressure-stabilized monocoque designs, such as Atlas and Falcon I. The Atlas was very light since a major portion of its structural support was provided by its single-wall steel balloon fuel tanks, which held their shape by internal pressure.

</doc>
<doc id="57993" url="http://en.wikipedia.org/wiki?curid=57993" title="Tragedy">
Tragedy

Tragedy (from the Greek: τραγῳδία, "tragōidia") is a form of drama based on human suffering that invokes in its audience an accompanying catharsis or pleasure in the viewing. While many cultures have developed forms that provoke this paradoxical response, the term "tragedy" often refers to a specific tradition of drama that has played a unique and important role historically in the self-definition of Western civilization. That tradition has been multiple and discontinuous, yet the term has often been used to invoke a powerful effect of cultural identity and historical continuity—"the Greeks and the Elizabethans, in one cultural form; Hellenes and Christians, in a common activity," as Raymond Williams puts it.
From its obscure origins in the theatre of ancient Greece 2500 years ago, from which there survives only a fraction of the work of Aeschylus, Sophocles and Euripides, through its singular articulations in the works of Shakespeare, Lope de Vega, Racine, and Schiller, to the more recent naturalistic tragedy of Strindberg, Beckett's modernist meditations on death, loss and suffering, Müller's postmodernist reworkings of the tragic canon, and Joshua Oppenheimer's incorporation of tragic pathos in his nonfiction film, The Act of Killing, tragedy has remained an important site of cultural experimentation, negotiation, struggle, and change. A long line of philosophers—which includes Plato, Aristotle, Saint Augustine, Voltaire, Hume, Diderot, Hegel, Schopenhauer, Kierkegaard, Nietzsche, Freud, Benjamin, Camus, Lacan, and Deleuze—have analysed, speculated upon, and criticised the tragic form.
In the wake of Aristotle's "Poetics" (335 BCE), tragedy has been used to make genre distinctions, whether at the scale of poetry in general (where the tragic divides against epic and lyric) or at the scale of the drama (where tragedy is opposed to comedy). In the modern era, tragedy has also been defined against drama, melodrama, the tragicomic, and epic theatre. Drama, in the narrow sense, cuts across the traditional division between comedy and tragedy in an anti- or a-generic deterritorialization from the mid-19th century onwards. Both Bertolt Brecht and Augusto Boal define their epic theatre projects (non-Aristotelian drama and Theatre of the Oppressed respectively) against models of tragedy. Taxidou, however, reads epic theatre as an incorporation of tragic functions and its treatments of mourning and speculation.
Origin.
The word "tragedy" appears to have been used to describe different phenomena at different times. It derives from Classical Greek τραγῳδία, contracted from "trag(o)-aoidiā" = "goat song", which comes from "tragos" = "he-goat" and "aeidein" = "to sing" ("cf." "ode"). Scholars suspect this may be traced to a time when a goat was either the prize in a competition of choral dancing or was that around which a chorus danced prior to the animal's ritual sacrifice. In another view on the etymology, Athenaeus of Naucratis (2nd–3rd century CE) says that the original form of the word was "trygodia" from "trygos" (grape harvest) and "ode" (song), because those events were first introduced during grape harvest.
Writing in 335 BCE (long after the Golden Age of 5th-century Athenian tragedy), Aristotle provides the earliest-surviving explanation for the origin of the dramatic art form in his "Poetics", in which he argues that tragedy developed from the improvisations of the leader of choral dithyrambs (hymns sung and danced in praise of Dionysos, the god of wine and fertility):
Anyway, arising from an improvisatory beginning (both tragedy and comedy—tragedy from the leaders of the dithyramb, and comedy from the leaders of the phallic processions which even now continue as a custom in many of our cities), [tragedy] grew little by little, as [the poets] developed whatever [new part] of it had appeared; and, passing through many changes, tragedy came to a halt, since it had attained its own nature.—Poetics IV, 1449a 10–15
In the same work, Aristotle attempts to provide a scholastic definition of what tragedy is:
Tragedy is, then, an enactment of a deed that is important and complete, and of [a certain] magnitude, by means of language enriched [with ornaments], each used separately in the different parts [of the play]: it is enacted, not [merely] recited, and through pity and fear it effects relief (catharsis) to such [and similar] emotions. —Poetics, VI 1449b 2–3
There is some dissent to the dithyrambic origins of tragedy, mostly based on the differences between the shapes of their choruses and styles of dancing. A common descent from pre-Hellenic fertility and burial rites has been suggested. Nietzsche discussed the origins of Greek tragedy in his early book . Here, he suggests the name originates in the use of a chorus of goat-like satyrs in the original dithyrambs from which the tragic genre developed.
Scott Scullion writes: There is abundant evidence for tragoidia understood as "song for the prize goat". The best-known evidence is Horace, Ars poetica 220-24 ("he who with a tragic song competed for a mere goat"); the earliest is the Parian Marble, a chronicle inscribed about 264/63 BCE, which records, under a date between 538 and 528 BCE: "Thespis is the poet ... first produced ... and as prize was established the billy goat" (FrGHist 239A, epoch 43); the clearest is Eustathius 1769.45: "They called those competing tragedians, clearly because of the song over the billy goat"...
Greek tragedy.
Athenian tragedy—the oldest surviving form of tragedy—is a type of dance-drama that formed an important part of the theatrical culture of the city-state. Having emerged sometime during the 6th century BCE, it flowered during the 5th century BCE (from the end of which it began to spread throughout the Greek world), and continued to be popular until the beginning of the Hellenistic period. No tragedies from the 6th century and only 32 of the more than a thousand that were performed in the 5th century have survived. We have complete texts extant by Aeschylus, Sophocles, and Euripides.
Athenian tragedies were performed in late March/early April at an annual state religious festival in honor of Dionysus. The presentations took the form of a contest between three playwrights, who presented their works on three successive days. Each playwright offered a tetralogy consisting of three tragedies and a concluding comic piece called a satyr play. The four plays sometimes featured linked stories. Only one complete trilogy of tragedies has survived, the "Oresteia" of Aeschylus. The Greek theatre was in the open air, on the side of a hill, and performances of a trilogy and satyr play probably lasted most of the day. Performances were apparently open to all citizens, including women, but evidence is scant. The theatre of Dionysus at Athens probably held around 12,000 people.
All of the choral parts were sung (to the accompaniment of an "aulos") and some of the actors' answers to the chorus were sung as well. The play as a whole was composed in various verse metres. All actors were male and wore masks. A Greek chorus danced as well as sang, though no one knows exactly what sorts of steps the chorus performed as it sang. Choral songs in tragedy are often divided into three sections: strophe ("turning, circling"), antistrophe ("counter-turning, counter-circling") and epode ("after-song").
Many ancient Greek tragedians employed the "ekkyklêma" as a theatrical device, which was a platform hidden behind the scene that could be rolled out to display the aftermath of some event which had happened out of sight of the audience. This event was frequently a brutal murder of some sort, an act of violence which could not be effectively portrayed visually, but an action of which the other characters must see the effects in order for it to have meaning and emotional resonance. A prime example of the use of the "ekkyklêma" is after the murder of Agamemnon in the first play of Aeschylus' "Oresteia", when the king's butchered body is wheeled out in a grand display for all to see. Variations on the "ekkyklêma" are used in tragedies and other forms to this day, as writers still find it a useful and often powerful device for showing the consequences of extreme human actions. Another such device was a crane, the mechane, which served to hoist a god or goddess on stage when they were supposed to arrive flying. This device gave origin to the phrase "deus ex machina" ("god out of a machine"), that is, the surprise intervention of an unforeseen external factor that changes the outcome of an event.
Roman tragedy.
Following the expansion of the Roman Republic (509–27 BCE) into several Greek territories between 270–240 BCE, Rome encountered Greek tragedy. From the later years of the republic and by means of the Roman Empire (27 BCE-476 CE), theatre spread west across Europe, around the Mediterranean and even reached England. While Greek tragedy continued to be performed throughout the Roman period, the year 240 BCE marks the beginning of regular Roman drama. Livius Andronicus began to write Roman tragedies, thus creating some of the first important works of Roman literature. Five years later, Gnaeus Naevius also began to write tragedies (though he was more appreciated for his comedies). No complete early Roman tragedy survives, though it was highly regarded in its day; historians know of three other early tragic playwrights—Quintus Ennius, Marcus Pacuvius and Lucius Accius.
From the time of the empire, the tragedies of two playwrights survive—one is an unknown author, while the other is the Stoic philosopher Seneca. Nine of Seneca's tragedies survive, all of which are "fabula crepidata" (tragedies adapted from Greek originals); his "Phaedra", for example, was based on Euripides' "Hippolytus". Historians do not know who wrote the only extant example of the "fabula praetexta" (tragedies based on Roman subjects), "Octavia", but in former times it was mistakenly attributed to Seneca due to his appearance as a character in the tragedy.
Seneca's tragedies rework those of all three of the Athenian tragic playwrights whose work has survived. Probably meant to be recited at elite gatherings, they differ from the Greek versions in their long declamatory, narrative accounts of action, their obtrusive moralizing, and their bombastic rhetoric. They dwell on detailed accounts of horrible deeds and contain long reflective soliloquies. Though the gods rarely appear in these plays, ghosts and witches abound. Senecan tragedies explore ideas of revenge, the occult, the supernatural, suicide, blood and gore. The Renaissance scholar Julius Caesar Scaliger (1484–1558), who knew both Latin and Greek, preferred Seneca to Euripides.
Renaissance tragedy.
Influence of Greek and Roman tragedy.
Classical Greek drama was largely forgotten in Western Europe from the Middle Ages to the beginning of the 16th century. Medieval theatre was dominated by mystery plays, morality plays, farces and miracle plays. In Italy, the models for tragedy in the later Middle Ages were Roman, particularly the works of Seneca, interest in which was reawakened by the Paduan Lovato de' Lovati (1241–1309). His pupil Albertino Mussato (1261–1329), also of Padua, in 1315 wrote the Latin verse tragedy "Eccerinis", which uses the story of the tyrant Ezzelino III da Romano to highlight the danger to Padua posed by Cangrande della Scala of Verona. It was the first secular tragedy written since Roman times, and may be considered the first Italian tragedy identifiable as a Renaissance work. "De casu caesenae", a contemporary account in Latin prose by Lodovico da Fabriano of Perugia of the sack in February 1377 of the city of Cesena and the massacre of its inhabitants by Breton mercenaries led by Giovanni Acuto (the English-born condottiere John Hawkwood), under the command of Robert, Cardinal of Geneva, is entitled "tragedy" by some copyists. The earliest tragedies to employ purely classical themes are the "Achilles" written before 1390 by Antonio Loschi of Vicenza (c.1365–1441) and the "Progne" of the Venetian Gregorio Correr (1409–1464) which dates from 1428–29.
In 1515 Gian Giorgio Trissino (1478–1550) of Vicenza wrote his tragedy "Sophonisba" in the vernacular that would later be called Italian. Drawn from Livy's account of Sophonisba, the Carthaginian princess who drank poison to avoid being taken by the Romans, it adheres closely to classical rules. It was soon followed by the "Oreste" and "Rosmunda" of Trissino's friend, the Florentine Giovanni di Bernardo Rucellai (1475–1525). Both were completed by early 1516 and are based on classical Greek models, "Rosmunda" on the "Hecuba" of Euripides, and "Oreste" on the "Iphigenia in Tauris" of the same author; like "Sophonisba", they are in Italian and in blank (unrhymed) hendecasyllables. Although these three are often cited, separately or together, as being the first regular tragedies in modern times, as well as the earliest substantial works to be written in blank hendecasyllables, they were apparently preceded by two other works in the vernacular: "Pamfila" or "Filostrato e Panfila" written in 1498 or 1508 by Antonio Cammelli (Antonio da Pistoia); and a "Sophonisba" by Galeotto del Carretto of 1502.
From about 1500 printed copies, in the original languages, of the works of Sophocles, Seneca, and Euripides, as well as comedic writers such as Aristophanes, Terence and Plautus, were available in Europe and the next forty years saw humanists and poets translating and adapting their tragedies. In the 1540s, the European university setting (and especially, from 1553 on, the Jesuit colleges) became host to a Neo-Latin theatre (in Latin) written by scholars. The influence of Seneca was particularly strong in its humanist tragedy. His plays, with their ghosts, lyrical passages and rhetorical oratory, brought a concentration on rhetoric and language over dramatic action to many humanist tragedies.
The most important sources for French tragic theatre in the Renaissance were the example of Seneca and the precepts of Horace and Aristotle (and contemporary commentaries by Julius Caesar Scaliger and Lodovico Castelvetro), although plots were taken from classical authors such as Plutarch, Suetonius, etc., from the Bible, from contemporary events and from short story collections (Italian, French and Spanish). The Greek tragic authors (Sophocles and Euripides) would become increasingly important as models by the middle of the 17th century. Important models were also supplied by the Spanish Golden Age playwrights Pedro Calderón de la Barca, Tirso de Molina and Lope de Vega, many of whose works were translated and adapted for the French stage. Greek tragedy was not the first
Britain.
In the English language, the most famous and most successful tragedies are those of William Shakespeare and his Elizabethan contemporaries. Shakespeare's tragedies include:
A contemporary of Shakespeare, Christopher Marlowe, also wrote examples of tragedy in English, notably:
John Webster (1580?–1635?), also wrote famous plays of the genre:
Opera as tragedy.
Contemporary with Shakespeare, an entirely different approach to facilitating the rebirth of tragedy was taken in Italy. Jacopo Peri, in the preface to his "Euridice" refers to "the ancient Greeks and Romans (who in the opinion of many sang their staged tragedies throughout in representing them on stage)." The attempts of Peri and his contemporaries to recreate ancient tragedy gave rise to the new Italian musical genre of opera. In France, tragic operatic works from the time of Lully to about that of Gluck were not called opera, but "tragédie en musique" ("tragedy in music") or some similar name; the "tragédie en musique" is regarded as a distinct musical genre. Some later operatic composers have also shared Peri's aims: Richard Wagner's concept of "Gesamtkunstwerk" ("integrated work of art"), for example, was intended as a return to the ideal of Greek tragedy in which all the arts were blended in service of the drama. Nietzsche, in his "The Birth of Tragedy" (1872) was to support Wagner in his claims to be a successor of the ancient dramatists.
Neo-classical tragedy.
For much of the 17th century, Pierre Corneille, who made his mark on the world of tragedy with plays like "Medée" (1635) and "Le Cid" (1636), was the most successful writer of French tragedies. Corneille's tragedies were strangely un-tragic (his first version of "Le Cid" was even listed as a tragicomedy), for they had happy endings. In his theoretical works on theatre, Corneille redefined both comedy and tragedy around the following suppositions:
Corneille continued to write plays through 1674 (mainly tragedies, but also something he called "heroic comedies") and many continued to be successes, although the "irregularities" of his theatrical methods were increasingly criticized (notably by François Hédelin, abbé d'Aubignac) and the success of Jean Racine from the late 1660s signaled the end of his preeminence.
Jean Racine's tragedies—inspired by Greek myths, Euripides, Sophocles and Seneca—condensed their plot into a tight set of passionate and duty-bound conflicts between a small group of noble characters, and concentrated on these characters' double-binds and the geometry of their unfulfilled desires and hatreds. Racine's poetic skill was in the representation of pathos and amorous passion (like Phèdre's love for her stepson) and his impact was such that emotional crisis would be the dominant mode of tragedy to the end of the century. Racine's two late plays ("Esther" and "Athalie") opened new doors to biblical subject matter and to the use of theatre in the education of young women. Racine also faced criticism for his irregularities: when his play, "Bérénice", was criticised for not containing any deaths, Racine disputed the conventional view of tragedy.
For more on French tragedy of the 16th and 17th centuries, see French Renaissance literature and French literature of the 17th century.
Bourgeois tragedy.
Bourgeois tragedy (German: Bürgerliches Trauerspiel) is a form that developed in 18th-century Europe. It was a fruit of the Enlightenment and the emergence of the bourgeois class and its ideals. It is characterized by the fact that its protagonists are ordinary citizens. The first true bourgeois tragedy was an English play, George Lillo's "The London Merchant; or, the History of George Barnwell", which was first performed in 1731. Usually, Gotthold Ephraim Lessing's play "Miss Sara Sampson", which was first produced in 1755, is said to be the earliest "Bürgerliches Trauerspiel" in Germany.
Modern development.
In modernist literature, the definition of tragedy has become less precise. The most fundamental change has been the rejection of Aristotle's dictum that true tragedy can only depict those with power and high status. Arthur Miller's essay "Tragedy and the Common Man" (1949) argues that tragedy may also depict ordinary people in domestic surroundings. British playwright Howard Barker has argued strenuously for the rebirth of tragedy in the contemporary theatre, most notably in his volume "Arguments for a Theatre". "You emerge from tragedy equipped against lies. After the musical, you're anybody's fool," he insists. Critics such as George Steiner have even been prepared to argue that tragedy may no longer exist in comparison with its former manifestations in classical antiquity. In "The Death of Tragedy" (1961) George Steiner outlined the characteristics of Greek tragedy and the traditions that developed from that period. In the Foreword (1980) to a new edition of his book Steiner concluded that ‘the dramas of Shakespeare are not a renascence of or a humanistic variant of the absolute tragic model. They are, rather, a rejection of this model in the light of tragi-comic and “realistic” criteria.’ In part, this feature of Shakespeare’s mind is explained by his bent of mind or imagination which was ‘so encompassing, so receptive to the plurality of diverse orders of experience.’ When compared to the drama of Greek antiquity and French classicism Shakespeare’s forms are ‘richer but hybrid'.
Theories of tragedy.
Aristotle.
Aristotle wrote in his work "Poetics" that
tragedy is characterized by seriousness and involves a great person who experiences a reversal of fortune ("Peripeteia"). Aristotle's definition can include a change of fortune from bad to good as in the "Eumenides", but he says that the change from good to bad as in "Oedipus Rex" is preferable because this induces pity and fear within the spectators. Tragedy results in a catharsis (emotional cleansing) or healing for the audience through their experience of these emotions in response to the suffering of the characters in the drama.
According to Aristotle, "the structure of the best tragedy should not be simple but complex and one that represents incidents arousing fear and pity—for that is peculiar to this form of art." This reversal of fortune must be caused by the tragic hero's "hamartia", which is often translated as either a character flaw, or as a mistake (since the original Greek etymology traces back to "hamartanein", a sporting term that refers to an archer or spear-thrower missing his target). According to Aristotle, "The misfortune is brought about not by [general] vice or depravity, but by some [particular] error or frailty." The reversal is the inevitable but unforeseen result of some action taken by the hero. It is also a misconception that this reversal can be brought about by a higher power (e.g. the law, the gods, fate, or society), but if a character’s downfall is brought about by an external cause, Aristotle describes this as a misadventure and not a tragedy.
In addition, the tragic hero may achieve some revelation or recognition (anagnorisis--"knowing again" or "knowing back" or "knowing throughout") about human fate, destiny, and the will of the gods. Aristotle terms this sort of recognition "a change from ignorance to awareness of a bond of love or hate."
In "Poetics", Aristotle gave the following definition in ancient Greek of the word "tragedy" (τραγῳδία):
"Ἔστιν οὖν τραγῳδία μίμησις πράξεως σπουδαίας καὶ τελείας μέγεθος ἐχούσης, ἡδυσμένῳ λόγῳ χωρὶς ἑκάστῳ τῶν εἰδῶν ἐν τοῖς μορίοις, δρώντων καὶ οὐ δι᾽ ἀπαγγελίας, δι᾽ ἐλέου καὶ φόβου περαίνουσα τὴν τῶν τοιούτων παθημάτων κάθαρσιν."
which means "Tragedy is an imitation of an action that is admirable, complete (composed of an introduction, a middle part and an ending), and possesses magnitude; in language made pleasurable, each of its species separated in different parts; performed by actors, not through narration; effecting through pity and fear the purification of such emotions."
Common usage of tragedy refers to any story with a sad ending, whereas to be an Aristotelian tragedy the story must fit the set of requirements as laid out by "Poetics". By this definition social drama cannot be tragic because the hero in it is a victim of circumstance and incidents that depend upon the society in which he lives and not upon the inner compulsions — psychological or religious — which determine his progress towards self-knowledge and death. Exactly what constitutes a "tragedy", however, is a frequently debated matter.
According to Aristotle, there are four species of tragedy:
1. Complex, which involves Peripety and Discovery
2. Suffering, tragedies of such nature can be seen in the Greek mythological stories of Ajaxes and Ixions
3. Character, a tragedy of moral or ethical character. Tragedies of this nature can be found in Phthiotides and Peleus
4. Spectacle, that of a horror-like theme. Examples of this nature are Phorcides and Prometheus
Hegel.
G.W.F. Hegel, the German philosopher most famous for his dialectical approach to epistemology and history, also applied such a methodology to his theory of tragedy. In his essay "Hegel's Theory of Tragedy," A.C. Bradley first introduced the English-speaking world to Hegel's theory, which Bradley called the "tragic collision", and contrasted against the Aristotelian notions of the "tragic hero" and his or her "hamartia" in subsequent analyses of the Aeschylus' Oresteia trilogy and of Sophocles' Antigone. Hegel himself, however, in his seminal "The Phenomenology of Spirit" argues for a more complicated theory of tragedy, with two complementary branches which, though driven by a single dialectical principle, differentiate Greek tragedy from that which follows Shakespeare. His later lectures formulate such a theory of tragedy as a conflict of ethical forces, represented by characters, in ancient Greek tragedy, but in Shakespearean tragedy the conflict is rendered as one of subject and object, of individual personality which must manifest self-destructive passions because only such passions are strong enough to defend the individual from a hostile and capricious external world:
The heroes of ancient classical tragedy encounter situations in which, if they firmly decide in favor of the one ethical pathos that alone suits their finished character, they must necessarily come into conflict with the equally ["gleichberechtigt"] justified ethical power that confronts them. Modern characters, on the other hand, stand in a wealth of more accidental circumstances, within which one could act this way or that, so that the conflict which is, though occasioned by external preconditions, still essentially grounded in the character. The new individuals, in their passions, obey their own nature... simply because they are what they are. Greek heroes also act in accordance with individuality, but in ancient tragedy such individuality is necessarily... a self-contained ethical pathos... In modern tragedy, however, the character in its peculiarity decides in accordance with subjective desires... such that congruity of character with outward ethical aim no longer constitutes an essential basis of tragic beauty...
Hegel's comments on a particular play may better elucidate his theory: "Viewed externally, Hamlet's death may be seen to have been brought about accidentally... but in Hamlet's soul, we understand that death has lurked from the beginning: the sandbank of finitude cannot suffice his sorrow and tenderness, such grief and nausea at all conditions of life... we feel he is a man whom inner disgust has almost consumed well before death comes upon him from outside."
Nietzsche.
Nietzsche, another German philosopher, dedicated his first full-length book, "The Birth of Tragedy" (1872), to a discussion of the origins of Greek tragedy. He traced the evolution of tragedy from early rituals, through the joining of Apollonian and Dionysian forces, until its early "death" in the hands of Socrates. In opposition to Schopenhauer, Nietzsche viewed tragedy as the art form of sensual acceptance of the terrors of reality and rejoicing in these terrors in love of fate ("amor fati"), and therefore as the antithesis to the Socratic Method, or the belief in the power of reason to unveil any and all of the mysteries of existence. Ironically, Socrates was fond of quoting from tragedies.
Nietzsche in "What I Owe to the Ancients" in his "Twilight of the Idols" wrote: "The psychology of the orgiastic as an overflowing feeling of life and strength, where even pain still has the effect of a stimulus, gave me the key to the concept of tragic feeling, which had been misunderstood both by Aristotle and even more by modern pessimists. Tragedy is so far from being a proof of the pessimism (in Schopenhauer's sense) of the Greeks that it may, on the contrary, be considered a decisive rebuttal and counterexample. Saying Yes to life even in its strangest and most painful episodes, the will to life rejoicing in its own inexhaustible vitality even as it witnesses the destruction of its greatest heroes — that is what I called Dionysian, that is what I guessed to be the bridge to the psychology of the tragic poet. Not in order to be liberated from terror and pity, not in order to purge oneself of a dangerous affect by its vehement discharge — which is how Aristotle understood tragedy — but in order to celebrate oneself the eternal joy of becoming, beyond all terror and pity — that tragic joy included even joy in destruction."
Similar dramatic forms in world theatre.
Ancient Indian drama.
The writer Bharata Muni, in his work on dramatic theory "A Treatise on Theatre" (Sanskrit: "Nātyaśāstra", नाट्य शास्त्र, c. 200 BCE – 200 CE), identified several "rasas" (such as pity, anger, disgust and terror) in the emotional responses of audiences for the Sanskrit drama of ancient India. The text also suggests the notion of musical modes or jatis which are the origin of the notion of the modern melodic structures known as ragas. Their role in invoking emotions are emphasized; thus compositions emphasizing the notes gandhara or rishabha are said to provoke "sadness" or "pathos" ("karuna rasa") whereas rishabha evokes heroism ("vira rasa"). Jatis are elaborated in greater detail in the text "Dattilam", composed around the same time as the "Treatise".
The celebrated ancient Indian epic, "Mahabharata", can also be related to tragedy in some ways. According to Hermann Oldenberg, the original epic once carried an immense "tragic force". It was common in Sanskrit drama to adapt episodes from the "Mahabharata" into dramatic form.
Sources.
</dl>

</doc>
<doc id="57994" url="http://en.wikipedia.org/wiki?curid=57994" title="Epiphyte">
Epiphyte

An epiphyte is a plant that grows harmlessly upon another plant (such as a tree), and derives its moisture and nutrients from the air, rain, and sometimes from debris accumulating around it, instead of the structure to which it is fastened. An epiphytic organism that is not a plant is called an epibiont. Epiphytes are usually found in the temperate zone (e.g., many mosses, liverworts, lichens, and algae) or in the tropics (e.g., many ferns, cacti, orchids, and bromeliads). Many houseplants are epiphyte species due to their minimal water and soil requirements. Epiphytes provide a rich and diverse habitat for other organisms including animals, fungi, bacteria, and myxomycetes.
Epiphyte is one of the subdivisions of the Raunkiær system.
The term "epiphytic" derives from the Greek "epi-" (meaning 'upon') and "phyton" (meaning 'plant'). Epiphytic plants are sometimes called "air plants" because they do not root in soil. However, there are many aquatic species of algae, including seaweeds, that are "epiphytes" on other aquatic plants (seaweeds or aquatic angiosperms).
Biodiversity.
The best-known epiphytic plants include mosses, orchids, and bromeliads such as Spanish moss (of the genus "Tillandsia"), but epiphytes may be found in every major group of the plant kingdom. 89% of epiphyte species (about 24,000) are flowering plants. The second largest group are the leptosporangiate ferns, with about 2800 species (10% of epiphytes). In fact, about one third of all ferns are epiphytes.
The third largest group is clubmosses, with 190 species, followed by a handful of species in each of the spikemosses, other ferns, Gnetales, and cycads.
Physiognomy.
Epiphytic organisms usually derive only physical support and not nutrition from their host, though they may sometimes damage the host. Parasitic and semiparasitic plants growing on other plants (mistletoe is well known) are not "true" epiphytes (a designation usually given to fully autotrophic epiphytes), but are still epiphytic in habit. Plants such as New Zealand species of "Griselinia" – which send long roots down towards the soil while fixed high in another plant and reliant upon it for physical support – are also epiphytic in habit.
Some epiphytic plants are large trees that begin their lives high in the forest canopy. Over decades they send roots down the trunk of a host tree eventually overpowering and replacing it. The strangler fig and the northern rātā ("Metrosideros robusta") of New Zealand are examples of this. Epiphytes that end up as free standing trees are also called hemiepiphytes.
Nutrition.
Epiphytic plants use photosynthesis for energy and (where non-aquatic) obtain moisture from the air or from dampness (rain and cloud moisture) on the surface of their hosts. Roots may develop primarily for attachment, and specialized structures (for example, cups and scales) may be used to collect or hold moisture.
Ecology.
The first important monograph on epiphytic plant ecology was written by A.F.W. Schimper ("Die epiphytische Vegetation Amerikas", 1888). Assemblages of large epiphytes occur most abundantly in moist tropical forests, but mosses and lichens occur as epiphytes in almost all biomes. In Europe there are no dedicated epiphytic plants using roots, but rich assemblages of mosses and lichens grow on trees in damp areas (mainly the western coastal fringe), and the common polypody fern grows epiphytically along branches. Rarely, grass, small bushes or small trees may grow in suspended soils up trees (typically in a rot-hole).
Epiphytic plants attached to their hosts high in the canopy have an advantage over herbs restricted to the ground where there is less light and herbivores may be more active. Epiphytic plants are also important to certain animals that may live in their water reservoirs, such as some types of frogs and arthropods.
Epiphytes can have a significant effect on the microenvironment of their host, and of ecosystems where they are abundant, as they hold water in the canopy and decrease water input to the soil. The epiphytes create a significantly cooler and moister environment in the host plant canopy, potentially greatly reducing water loss by the host through transpiration.

</doc>
<doc id="57996" url="http://en.wikipedia.org/wiki?curid=57996" title="Corticosteroid">
Corticosteroid

Corticosteroids are a class of chemicals that includes the steroid hormones that are produced in the adrenal cortex of vertebrates as well as the synthetic analogues of these hormones. Corticosteroids are involved in a wide range of physiological processes, including stress response, immune response, and regulation of inflammation, carbohydrate metabolism, protein catabolism, blood electrolyte levels, and behavior.
Some common natural hormones are corticosterone (C21H30O4), cortisone (C21H28O5, 17-hydroxy-11-dehydrocorticosterone) and aldosterone.
Medical uses.
Synthetic pharmaceutical drugs with corticosteroid-like effects are used in a variety of conditions, ranging from brain tumors to skin diseases. Dexamethasone and its derivatives are almost pure glucocorticoids, while prednisone and its derivatives have some mineralocorticoid action in addition to the glucocorticoid effect. Fludrocortisone (Florinef) is a synthetic mineralocorticoid. Hydrocortisone (cortisol) is available for replacement therapy, "e.g." in adrenal insufficiency and congenital adrenal hyperplasia.
Synthetic glucocorticoids are used in the treatment of joint pain or inflammation (arthritis), temporal arteritis, dermatitis, allergic reactions, asthma, hepatitis, systemic lupus erythematosus, inflammatory bowel disease (ulcerative colitis and Crohn's disease), sarcoidosis and for glucocorticoid replacement in Addison's disease or other forms of adrenal insufficiency. Topical formulations are also available for the skin, eyes (uveitis), lungs (asthma), nose (rhinitis), and bowels. Corticosteroids are also used supportively to prevent nausea, often in combination with 5-HT3 antagonists ("e.g." ondansetron).
Typical undesired effects of glucocorticoids present quite uniformly as drug-induced Cushing's syndrome. Typical mineralocorticoid side-effects are hypertension (abnormally high blood pressure), hypokalemia (low potassium levels in the blood), hypernatremia (high sodium levels in the blood) without causing peripheral edema, metabolic alkalosis and connective tissue weakness. There may also be impaired wound healing or ulcer formation because of the immunosuppressive effects.
Clinical and experimental evidence indicates that corticosteroids can cause permanent eye damage by inducing central serous retinopathy (CSR, also known as central serous chorioretinopathy, CSC). A variety of steroid medications, from anti-allergy nasal sprays (Nasonex, Flonase) to topical skin creams, to eye drops (Tobradex), to prednisone have been implicated in the development of CSR.
Corticosteroids have been widely used in treating people with traumatic brain injury. A systematic review identified 20 randomised controlled trials and included 12,303 participants, then compared patients who received corticosteroids with patients who received no treatment. The authors recommended people with traumatic head injury should not be routinely treated with corticosteroids.
Side effects.
Use of corticosteroids has numerous side-effects, some of which may be severe: 
Corticosteroids were voted Allergen of the Year in 2005 by the American Contact Dermatitis Society.
Biosynthesis.
The corticosteroids are synthesized from cholesterol within the adrenal cortex. Most steroidogenic reactions are catalysed by enzymes of the cytochrome P450 family. They are located within the mitochondria and require adrenodoxin as a cofactor (except 21-hydroxylase and 17α-hydroxylase).
Aldosterone and corticosterone share the first part of their biosynthetic pathway. The last part is mediated either by the aldosterone synthase (for aldosterone) or by the 11β-hydroxylase (for corticosterone). These enzymes are nearly identical (they share 11β-hydroxylation and 18-hydroxylation functions), but aldosterone synthase is also able to perform an 18-oxidation. Moreover, aldosterone synthase is found within the zona glomerulosa at the outer edge of the adrenal cortex; 11β-hydroxylase is found in the zona fasciculata and zona glomerulosa.
Classification.
Chemical structure.
In general, corticosteroids are grouped into four classes, based on chemical structure. Allergic reactions to one member of a class typically indicate an intolerance of all members of the class. This is known as the "Coopman classification", after S. Coopman, who defined this classification in 1989.
The highlighted steroids are often used in the screening of allergies to topical steroids.
Group A — Hydrocortisone type.
Hydrocortisone, hydrocortisone acetate, cortisone acetate, tixocortol pivalate, prednisolone, methylprednisolone, and prednisone (Short- to medium-acting glucocorticoids).
Group B — Acetonides (and related substances).
Triamcinolone acetonide, triamcinolone alcohol, mometasone, amcinonide, budesonide, desonide, fluocinonide, fluocinolone acetonide, and halcinonide.
Group C — Betamethasone type.
Betamethasone, betamethasone sodium phosphate, dexamethasone, dexamethasone sodium phosphate, and fluocortolone.
Group D — Esters.
Group D1 — Halogenated (less labile).
Hydrocortisone-17-valerate, halometasone, alclometasone dipropionate, betamethasone valerate, betamethasone dipropionate, prednicarbate, clobetasone-17-butyrate, clobetasol-17-propionate, fluocortolone caproate, fluocortolone pivalate, and fluprednidene acetate.
Group D2 — Labile prodrug esters.
Hydrocortisone-17-butyrate, hydrocortisone-17-aceponate, hydrocortisone-17-buteprate, ciclesonide and prednicarbate.
Route of administration.
Topical steroids.
For use topically on the skin, eye, and mucous membranes.
Topical corticosteroids are divided in potency classes I to IV,
Inhaled steroids.
for use to treat the nasal mucosa, sinuses, bronchii, and lungs.
This group includes:
There is also a combination preparation containing fluticasone propionate and salmeterol xinafoate (a long-acting bronchodilator). It is approved for children over 12 years old.
Oral forms.
Such as prednisone and prednisolone.
Systemic forms.
Available in injectables for intravenous and parenteral routes.
History.
First known use was in 1944. Tadeusz Reichstein together with Edward Calvin Kendall and Philip Showalter Hench were awarded the Nobel Prize for Physiology and Medicine in 1950 for their work on hormones of the adrenal cortex, which culminated in the isolation of cortisone.
Corticosteroids have been used as drug treatment for some time. Lewis Sarett of Merck & Co. was the first to synthesize cortisone, using a complicated 36-step process that started with deoxycholic acid, which was extracted from ox bile. The low efficiency of converting deoxycholic acid into cortisone led to a cost of US $200 per gram. Russell Marker, at Syntex, discovered a much cheaper and more convenient starting material, diosgenin from wild Mexican yams. His conversion of diosgenin into progesterone by a four-step process now known as Marker degradation was an important step in mass production of all steroidal hormones, including cortisone and chemicals used in hormonal contraception. In 1952, D.H. Peterson and H.C. Murray of Upjohn developed a process that used Rhizopus mold to oxidize progesterone into a compound that was readily converted to cortisone. The ability to cheaply synthesize large quantities of cortisone from the diosgenin in yams resulted in a rapid drop in price to US $6 per gram, falling to $0.46 per gram by 1980. Percy Julian's research also aided progress in the field. The exact nature of cortisone's anti-inflammatory action remained a mystery for years after, however, until the leukocyte adhesion cascade and the role of phospholipase A2 in the production of prostaglandins and leukotrienes was fully understood in the early 1980s.

</doc>
<doc id="57997" url="http://en.wikipedia.org/wiki?curid=57997" title="Adrenocorticotropic hormone">
Adrenocorticotropic hormone

Adrenocorticotropic hormone (ACTH), also known as corticotropin, is a polypeptide tropic hormone produced and secreted by the anterior pituitary gland. It is an important component of the hypothalamic-pituitary-adrenal axis and is often produced in response to biological stress (along with its precursor corticotropin-releasing hormone from the hypothalamus). Its principal effects are increased production and release of cortisol. Primary adrenal insufficiency, also called Addison's disease, occurs when adrenal gland production of cortisol is chronically deficient, resulting in chronically elevated ACTH levels; when a pituitary tumor is the cause of elevated ACTH (from the anterior pituitary) this is known as Cushing's Disease and the constellation of signs and symptoms of the excess cortisol (hypercortisolism) is known as Cushing's syndrome. A deficiency of ACTH is a cause of secondary adrenal insufficiency. ACTH is also related to the circadian rhythm in many organisms.
Production and regulation.
POMC, ACTH and β-lipotropin are secreted from corticotropes in the anterior lobe (or adenohypophysis) of the pituitary gland in response to the hormone corticotropin-releasing hormone (CRH) released by the hypothalamus. ACTH is synthesized from pre-pro-opiomelanocortin (pre-POMC). The removal of the signal peptide during translation produces the 241-amino acid polypeptide POMC, which undergoes a series of post-translational modifications such as phosphorylation and glycosylation before it is proteolytically cleaved by endopeptidases to yield various polypeptide fragments with varying physiological activity. These fragments include:
In order to regulate the secretion of ACTH, many substances secreted within this axis exhibit slow/intermediate and fast feedback-loop activity. Glucocorticoids secreted from the adrenal cortex work to inhibit CRH secretion by the hypothalamus, which in turn decreases anterior pituitary secretion of ACTH. Glucocorticoids may also inhibit the rates of POMC gene transcription and peptide synthesis. The latter is an example of a slow feedback loop, which works on the order of hours to days, whereas the former works on the order of minutes.
The half-life of ACTH in human blood is about ten minutes.
Structure.
ACTH consists of 39 amino acids, the first 13 of which (counting from the N-terminus) may be cleaved to form α-melanocyte-stimulating hormone (α-MSH). (This common structure is responsible for excessively tanned skin in Addison's disease.) After a short period of time, ACTH is cleaved into α-melanocyte-stimulating hormone (α-MSH) and CLIP, a peptide with unknown activity in humans.
Human ACTH has a molecular weight of 4,540 atomic mass units (Da).
Function.
ACTH stimulates secretion of glucocorticoid steroid hormones from adrenal cortex cells, especially in the zona fasciculata of the adrenal glands. ACTH acts by binding to cell surface ACTH receptors, which are located primarily on adrenocortical cells of the adrenal cortex. The ACTH receptor is a seven-membrane-spanning G protein-coupled receptor. Upon ligand binding, the receptor undergoes conformation changes that stimulate the enzyme adenylyl cyclase, which leads to an increase in intracellular cAMP and subsequent activation of protein kinase A.
ACTH influences steroid hormone secretion by both rapid short-term mechanisms that take place within minutes and slower long-term actions. The rapid actions of ACTH include stimulation of cholesterol delivery to the mitochondria where the P450scc enzyme is located. P450scc catalyzes the first step of steroidogenesis that is cleavage of the side-chain of cholesterol. 
ACTH also stimulates lipoprotein uptake into cortical cells. This increases the bio-availability of cholesterol in the cells of the adrenal cortex.
The long term actions of ACTH include stimulation of the transcription of the genes coding for steroidogenic enzymes, especially P450scc, steroid 11β-hydroxylase, and their associated electron transfer proteins. This effect is observed over several hours.
In addition to steroidogenic enzymes, ACTH also enhances transcription of mitochondrial genes that encode for subunits of mitochondrial oxidative phosphorylation systems. These actions are probably necessary to supply the enhanced energy needs of adrenocortical cells stimulated by ACTH.
ACTH receptors outside of the adrenal gland.
As indicated above, ACTH is a cleavage product of the pro-hormone, proopiomelanocortin (POMC), which also produces other hormones including α-MSH that stimulates the production of melanin. A family of related receptors mediates the actions of these hormones, the MCR, or melanocortin receptor family. These are mainly not associated with the pituitary-adrenal axis. MC2R is the ACTH receptor. While it has a crucial function in regulating the adrenal, it is also expressed elsewhere in the body, specifically in the osteoblast, which is responsible for making new bone, a continual and highly regulated process in the bodies of air-breathing vertebrates. The functional expression of MC2R on the osteoblast was discovered by Isales et alia in 2005. Since that time, it has been demonstrated that the response of bone forming cells to ACTH includes production of VEGF, as it does in the adrenal. This response might be important in maintaining osteoblast survival under some conditions. If this is physiologically important, it probably functions in conditions with short-period or intermittent ACTH signaling, since with continual exposure of osteoblasts to ACTH, the effect was lost in a few hours.
Synthetic ACTH.
An active synthetic form of ACTH, consisting of the first 24 amino acids of native ACTH, was first synthesized by Klaus Hofmann at the University of Pittsburgh.
ACTH is available as a synthetic derivative in the forms of cosyntropin, tradename Cortrosyn, and Synacthen (synthetic ACTH). Synacthen is not FDA approved but is used in the UK and Australia to conduct the ACTH stimulation test.
ACTH was first synthesized as a replacement for Acthar Gel, a long-lasting animal product used to treat infantile spasms. Once relatively inexpensive, Acthar Gel is currently an extremely expensive pharmaceutical product. Prices per vial have been as high as $36,000. Acthar gel has been proposed as a therapy to treat refractory autoimmune diseases and refractory nephrotic syndrome due to a variety of glomerular diseases.

</doc>
<doc id="57998" url="http://en.wikipedia.org/wiki?curid=57998" title="Battle of the Bulge">
Battle of the Bulge

The Battle of the Bulge (16 December 1944 – 25 January 1945) was a major German offensive campaign launched through the densely forested Ardennes region of Wallonia in Belgium, France, and Luxembourg on the Western Front toward the end of World War II in Europe. The surprise attack caught the Allied forces completely off guard. United States forces bore the brunt of the attack and incurred their highest casualties for any operation during the war. The battle also severely depleted Germany's armored forces on the western front which Germany was largely unable to replace. German personnel and Luftwaffe aircraft also sustained heavy losses.
Different forces referred to the battle by different names. The Germans referred to it as Unternehmen Wacht am Rhein ("Operation Watch on the Rhine"), while the French named it the Bataille des Ardennes ("Battle of the Ardennes"). The Allies called it the Ardennes Counteroffensive. The phrase "Battle of the Bulge" was coined by contemporary press to describe the way the Allied front line bulged inward on wartime news maps and became the best known name for the battle.
The German offensive was supported by several subordinate operations known as "Unternehmen Bodenplatte, Greif", and "Währung". As well as stopping Allied transport over the channel to the harbor of Antwerp, these operations were intended to split the British and American Allied line in half, so the Germans could then proceed to encircle and destroy four Allied armies, forcing the Western Allies to negotiate a peace treaty in the Axis Powers' favor. Once that was accomplished, Hitler could fully concentrate on the eastern theatre of war.
The offensive was planned by the German forces with utmost secrecy, minimizing radio traffic and moving troops and equipment under cover of darkness. Despite their efforts to keep it secret, the Third U.S. Army's intelligence staff intercepted German Ultra communications that indicated that a "substantial and offensive" operation was expected, although they could not predict a precise date or point of attack. Aircraft movement from the Russian Front and transport of forces by rail to the Ardennes was noticed but not acted upon, according to a report later written by Peter Calvocoressi and F. L. Lucas at the codebreaking centre Bletchley Park. These reports and predictions were not given any merit by the U.S. 12th Army Group.
Near-complete surprise was achieved by a combination of Allied overconfidence, preoccupation with Allied offensive plans, and poor aerial reconnaissance. The Germans attacked a weakly defended section of the Allied line, taking advantage of heavily overcast weather conditions, which grounded the Allies' overwhelmingly superior air forces. Fierce resistance on the northern shoulder of the offensive around Elsenborn Ridge and in the south around Bastogne blocked German access to key roads to the northwest and west that they counted on for success. Columns of armor and infantry that were supposed to advance along parallel routes found themselves on the same roads. This and terrain that favored the defenders threw the German advance behind schedule and allowed the Allies to reinforce the thinly placed troops. Improved weather conditions permitted air attacks on German forces and supply lines, which sealed the failure of the offensive. In the wake of the defeat, many experienced German units were left severely depleted of men and equipment, as survivors retreated to the defenses of the Siegfried Line.
The Germans' initial attack included 200,000 men, 340 tanks and 280 other tracked vehicles. Between 67,200 and 100,000 of their men were killed, missing or wounded.
For the Americans, 610,000 men were involved in the battle, of whom 89,000 were casualties, including up to 19,000 killed. It was the largest and bloodiest battle fought by the United States in World War II.
Background.
After the breakout from Normandy at the end of July 1944 and the landings in southern France on 15 August 1944, the Allies advanced toward Germany more quickly than anticipated. The Allies were faced with several military logistics issues: troops were fatigued by weeks of continuous combat, supply lines were stretched extremely thin, and supplies were dangerously depleted. General Eisenhower (the Supreme Allied Commander) and his staff chose to hold the Ardennes region which was occupied by the First United States Army. The Allies believed the Ardennes could be defended by as few troops as possible due to the favorable terrain, minimal road network, and limited number of Allied operational objectives. Also, the Wehrmacht was known to be using the area to the east across the German border as a rest-and-refit area for its troops.
The speed of the Allied advance coupled with an initial lack of deep-water ports presented the Allies with enormous supply problems. Over-the-beach supply operations using the Normandy landing areas and direct landing LSTs on the beaches were unable to meet operational needs. The only deep-water port the Allies had captured was Cherbourg, west of the original invasion beaches, but the Germans had thoroughly wrecked and mined the harbor before it could be taken. It took many months to build up its cargo-handling capability. The Allies captured the port of Antwerp intact in the first days of September, but it was not operational until 28 November. The estuary of the Scheldt River that controlled access to the port had to be cleared of both German troops and naval mines. The limitations led to differences between General Dwight D. Eisenhower and Field Marshal Bernard Montgomery over whether Montgomery or American General Omar Bradley in the south would get priority access to supplies.
German forces remained in control of several major ports on the English Channel coast until May 1945. The extensive destruction of the French railway system prior to D-Day, successful in hampering German response to the invasion, proved equally damaging to the Allies, as it took time to repair the system's tracks and bridges. A trucking system nicknamed the Red Ball Express brought supplies to front-line troops, but used up five times as much fuel to reach the front line near the Belgian border as was delivered. By early October, the Allies had suspended major offensives to improve their supply lines and availability.
Montgomery and Bradley both pressed for priority delivery of supplies to their respective armies so they could continue their individual lines of advance and maintain pressure on the Germans. Eisenhower, however, preferred a broad-front strategy. He gave some priority to Montgomery's northern forces, which had the short-term goal of opening the urgently needed port of Antwerp and the long-term goal of capturing the Ruhr area, the industrial heart of Germany. With the Allies stalled, German Field Marshal Gerd von Rundstedt was able to reorganize the disrupted German armies into a coherent defense.
Field Marshal Montgomery's Operation Market Garden only achieved some of its objectives, while its territorial gains left the Allied supply situation worse off than before. In October, the Canadian First Army fought the Battle of the Scheldt, opening the port of Antwerp to shipping. As a result, by the end of October the supply situation had eased somewhat.
Despite a lull along the front after the Scheldt battles, the German situation remained dire. While operations continued in the autumn, notably the Lorraine Campaign, the Battle of Aachen and fighting in the Hürtgen Forest, the strategic situation in the west had changed little. The Allies were slowly pushing towards Germany, but no decisive breakthrough was achieved. The Western Allies already had 96 divisions at or near the front, with an estimated ten more divisions en route from the United Kingdom. Additional Allied airborne units remained in England. The Germans could field a total of 55 understrength divisions.
Adolf Hitler promised his generals a total of 18 infantry and 12 armored or mechanized divisions "for planning purposes." The plan was to pull 13 infantry divisions, two parachute divisions and six panzer-type divisions from the Oberkommando der Wehrmacht (OKW) strategic reserve. On the Eastern Front, the Soviets' Operation Bagration during the summer had destroyed much of Germany's Army Group Center ("Heeresgruppe Mitte"). The extremely swift operation ended only when the advancing Red Army forces outran their supplies. By November, it was clear that Soviet forces were preparing for a winter offensive.
Meanwhile, the Allied air offensive of early 1944 had effectively grounded the Luftwaffe, leaving the German Army with little battlefield intelligence and no way to interdict Allied supplies. The converse was equally damaging; daytime movement of German forces was almost instantly noticed, and interdiction of supplies combined with the bombing of the Romanian oil fields starved Germany of oil and gasoline.
One of the few advantages held by the German forces in November 1944 was that they were no longer defending all of Western Europe. Their front lines in the west had been considerably shortened by the Allied offensive and were much closer to the German heartland. This drastically reduced their supply problems despite Allied control of the air. Additionally, their extensive telephone and telegraph network meant that radios were no longer necessary for communications, which lessened the effectiveness of Allied Ultra intercepts. Nevertheless, some 40–50 messages per day were decrypted by Ultra. They recorded the quadrupling of German fighter forces and a term used in an intercepted Luftwaffe message—"Jägeraufmarsch" (Fighter Marshalling Point)—implied preparation for an offensive operation. Ultra also picked up communiqués regarding extensive rail and road movements in the region, as well as orders that movements should be made on time.
Drafting the offensive.
German leader Adolf Hitler felt that his mobile reserves allowed him to mount one major offensive. Although he realised nothing significant could be accomplished in the Eastern Front, he still believed an offensive against the Western Allies, whom he considered militarily inferior to the Red Army, would have some chances of success. Hitler believed he could split the Allied forces and compel the Americans and British to settle for a separate peace, independent of the Soviet Union. Success in the west would give the Germans time to design and produce more advanced weapons (such as jet aircraft, new U-boat designs and super-heavy tanks) and permit the concentration of forces in the east. After the war ended, this assessment was generally viewed as unrealistic, given Allied air superiority throughout Europe and their ability to continually disrupt German offensive operations.
Given the reduced manpower of their land forces at the time, the Germans believed the best way to seize the initiative would be to attack in the West against the smaller Allied forces rather than against the vast Soviet armies. Even the encirclement and destruction of multiple Soviet armies like in 1941, would still have left the Soviets with a numerical superiority.
Several senior German military officers, including Field Marshal Walter Model and von Rundstedt, expressed concern as to whether the goals of the offensive could be realized. They offered alternative plans, but Hitler would not listen. The plan banked on unfavorable weather, including heavy fog and low-lying clouds, which would minimize the Allied air advantage. Hitler originally set the offensive for late November, before the anticipated start of the Russian winter offensive.
In the west supply problems began significantly to impede Allied operations, even though the opening of the port of Antwerp in late November improved the situation somewhat. The positions of the Allied armies stretched from southern France all the way north to the Netherlands. German planning for the counteroffensive rested on the premise that a successful strike against thinly-manned stretches of the line would halt Allied advances on the entire Western Front.
Model and von Rundstedt both believed aiming for Antwerp was too ambitious, given Germany's scarce resources in late 1944. At the same time they felt that maintaining a purely defensive posture (as had been the case since Normandy) would only delay defeat, not avert it. They thus developed alternative, less ambitious plans that did not aim to cross the Meuse River; Model's being "Unternehmen Herbstnebel" (Operation Autumn Mist) and von Rundstedt's "Fall Martin" ("Plan Martin"). The two field marshals combined their plans to present a joint "small solution" to Hitler. A second plan called for a classic "blitzkrieg" attack through the weakly defended Ardennes Mountains—mirroring the successful German offensive there during the Battle of France in 1940—aimed at splitting the armies along the U.S.—British lines and capturing Antwerp.
Hitler chose the second plan, believing a successful encirclement would have little impact on the overall situation and finding the prospect of splitting the Anglo-American armies more appealing. The disputes between Montgomery and Bradley were well known, and Hitler hoped he could exploit this disunity. If the attack were to succeed in capturing Antwerp, four complete armies would be trapped without supplies behind German lines. Both plans centered on attacks against the American forces.
Tasked with carrying out the operation were "Generalfeldmarschall" (Field Marshal) Walther Model, the commander of German Army Group B ("Heeresgruppe B"), and Field Marshal Gerd von Rundstedt, the overall commander of the German Army Command in the West ("Oberbefehlshaber West"), who had moved his base of operations to Kransberg Castle.
Operation names.
The "Wehrmacht"‍ '​s code name for the offensive was Unternehmen "Wacht am Rhein" ("Operation "Watch on the Rhine""), after the German patriotic hymn "Die Wacht am Rhein," a name that deceptively implied the Germans would be adopting a defensive posture along the Western Front. The Germans also referred to it as "Ardennenoffensive" (Ardennes Offensive) and "Rundstedtoffensive" (Von Rundstedt Offensive). The French name for the operation is "Bataille des Ardennes". The battle was militarily defined by the Allies as the Ardennes Counteroffensive, which included the German drive and the American effort to contain and later defeat it. The phrase "Battle of the Bulge" was coined by contemporary press to describe the way the Allied front line bulged inward on wartime news maps.
While the Ardennes Counteroffensive is the correct term in Allied military language, the official Ardennes-Alsace campaign reached beyond the Ardennes battle region, and the most popular description remains simply the Battle of the Bulge.
Planning.
OKW decided by mid-September, at Hitler's insistence, that the offensive would be mounted in the Ardennes, as was done in 1940. Many German generals objected, but the offensive was planned and carried out anyway. In 1940 German forces had passed through the Ardennes in three days before engaging the enemy, but the 1944 plan called for battle in the forest itself. The main forces were to advance westward to the Meuse River, then turn northwest for Antwerp and Brussels. The close terrain of the Ardennes would make rapid movement difficult, though open ground beyond the Meuse offered the prospect of a successful dash to the coast.
Four armies were selected for the operation. First was the Sixth Panzer Army, under SS General Sepp Dietrich—newly created on 26 October 1944, it incorporated the most senior and the most experienced formation of the "Waffen-SS": the 1st SS Panzer Division "Leibstandarte Adolf Hitler" as well as the 12th SS Panzer Division "Hitlerjugend". The 6th Panzer Army was designated the northernmost attack force, having its northernmost point on the pre-attack battlefront nearest the German town of Monschau. It was entrusted with the offensive's primary objective—capturing Antwerp.
The Fifth Panzer Army under General Hasso von Manteuffel was assigned to the middle attack route with the objective of capturing Brussels.
The Seventh Army, under General Erich Brandenberger, was assigned to the southernmost attack, having its southernmost point on the pre-attack battlefront nearest the Luxembourg town of Echternach, with the task of protecting the flank. This Army was made up of only four infantry divisions, with no large-scale armored formations to use as a spearhead unit. As a result, they made little progress throughout the battle.
Also participating in a secondary role was the Fifteenth Army, under General Gustav-Adolf von Zangen. Recently brought back up to strength and re-equipped after heavy fighting during Market Garden, it was located on the far north of the Ardennes battlefield and tasked with holding U.S. forces in place, with the possibility of launching its own attack given favorable conditions.
For the offensive to be successful, four criteria were deemed critical: the attack had to be a complete surprise; the weather conditions had to be poor to neutralize Allied air superiority and the damage it could inflict on the German offensive and its supply lines; the progress had to be rapid—the Meuse River, halfway to Antwerp, had to be reached by day 4; and Allied fuel supplies would have to be captured intact along the way because the Wehrmacht was short on fuel. The General Staff estimated they only had enough fuel to cover one-third to one-half of the ground to Antwerp in heavy combat conditions.
The plan originally called for just under 45 divisions, including a dozen panzer and panzergrenadier divisions forming the armored spearhead and various infantry units to form a defensive line as the battle unfolded. By this time, however, the German Army suffered from an acute manpower shortage, and the force had been reduced to around 30 divisions. Although it retained most of its armor, there were not enough infantry units because of the defensive needs in the East. These 30 newly rebuilt divisions used some of the last reserves of the German Army. Among them were "Volksgrenadier" units formed from a mix of battle-hardened veterans and recruits formerly regarded as too young or too old to fight. Training time, equipment and supplies were inadequate during the preparations. German fuel supplies were precarious—those materials and supplies that could not be directly transported by rail had to be horse-drawn to conserve fuel, and the mechanized and panzer divisions would depend heavily on captured fuel. As a result, the start of the offensive was delayed from 27 November to 16 December.
Before the offensive the Allies were virtually blind to German troop movement. During the liberation of France, the extensive network of the French resistance had provided valuable intelligence about German dispositions. Once they reached the German border, this source dried up. In France, orders had been relayed within the German army using radio messages enciphered by the Enigma machine, and these could be picked up and decrypted by Allied code-breakers headquartered at Bletchley Park, to give the intelligence known as Ultra. In Germany such orders were typically transmitted using telephone and teleprinter, and a special radio silence order was imposed on all matters concerning the upcoming offensive. The major crackdown in the "Wehrmacht" after the 20 July plot to assassinate Hitler resulted in much tighter security and fewer leaks. The foggy autumn weather also prevented Allied reconnaissance aircraft from correctly assessing the ground situation. German units assembling in the area were even issued charcoal instead of wood for cooking fires to cut down on smoke and reduce chances of Allied observers deducing a troop buildup was underway. 
For these reasons Allied High Command considered the Ardennes a quiet sector, relying on assessments from their intelligence services that the Germans were unable to launch any major offensive operations this late in the war. What little intelligence they had led the Allies to believe precisely what the Germans wanted them to believe-–that preparations were being carried out only for defensive, not offensive, operations. The Allies relied too much on Ultra, not human reconnaissance. In fact, because of the Germans' efforts, the Allies were led to believe that a new defensive army was being formed around Düsseldorf in the northern Rhine, possibly to defend against British attack. This was done by increasing the number of flak batteries in the area and the artificial multiplication of radio transmissions in the area. The Allies at this point thought the information was of no importance. All of this meant that the attack, when it came, completely surprised the Allied forces. Remarkably, the U.S. Third Army intelligence chief, Colonel Oscar Koch, the U.S. First Army intelligence chief and the SHAEF intelligence officer Brigadier General Kenneth Strong all correctly predicted the German offensive capability and intention to strike the U.S. VIII Corps area. These predictions were largely dismissed by the U.S. 12th Army Group. Strong had informed Bedell Smith in December of his suspicions. Bedell Smith sent Strong to warn Lieutenant General Omar Bradley, the commander of the 12th Army Group, of the danger. Bradley's response was succinct: "Let them come." Historian Patrick K. O'Donnell writes that on 8 December 1944, U.S. Rangers at great cost took Hill 400 during the Battle of the Hürtgen Forest. The next day GIs who relieved the Rangers reported a considerable movement of German troops inside the Ardennes in the enemy's rear, but that no one in the chain of command connected the dots.
Because the Ardennes was considered a quiet sector, economy-of-force considerations led it to be used as a training ground for new units and a rest area for units that had seen hard fighting. The U.S. units deployed in the Ardennes thus were a mixture of inexperienced troops (such as the raw U.S. 99th and 106th "Golden Lions" Divisions), and battle-hardened troops sent to that sector to recuperate (the 28th Infantry Division).
Two major special operations were planned for the offensive. By October it was decided that Otto Skorzeny, the German commando who had rescued the former Italian dictator Benito Mussolini, was to lead a task force of English-speaking German soldiers in "Operation Greif". These soldiers were to be dressed in American and British uniforms and wear dog tags taken from corpses and POWs. Their job was to go behind American lines and change signposts, misdirect traffic, generally cause disruption and seize bridges across the Meuse River between Liège and Namur. By late November, another ambitious special operation was added: Col. Friedrich August von der Heydte was to lead a "Fallschirmjäger" (paratrooper) "Kampfgruppe" in Operation Stösser, a night-time paratroop drop behind the Allied lines aimed at capturing a vital road junction near Malmedy.
German intelligence had set 20 December as the expected date for the start of the upcoming Soviet offensive, aimed at crushing what was left of German resistance on the Eastern Front and thereby opening the way to Berlin. It was hoped that Soviet leader Stalin would delay the start of the operation once the German assault in the Ardennes had begun and wait for the outcome before continuing.
After the 20 July plot attempt on Hitler's life, and the close advance of the Red Army which would seize the site on 27 January 1945, Hitler and his staff had been forced to abandon the Wolfsschanze headquarters in East Prussia, in which they had coordinated much of the fighting on the Eastern Front. After a brief visit to Berlin, Hitler travelled on his "Führersonderzug" (train) to Giessen on 11 December, taking up residence in the Adlerhorst command complex, co-located with OB West's base at Kransberg Castle. Believing in omens and the successes of his early war campaigns that had been planned at Kransberg, Hitler had chosen the site from which he had overseen the successful 1940 campaign against France and the Low Countries.
Von Rundstedt set up his operational headquarters near Limburg, close enough for the generals and Panzer Corps commanders who were to lead the attack to visit Adlerhorst on 11 December, travelling there in an SS-operated bus convoy. With the castle acting as overflow accommodation, the main party was settled into the Adlerhorst's Haus 2 command bunker, including Gen. Alfred Jodl, Gen. Wilhelm Keitel, Gen. Blumentritt, von Manteuffel and S.S. Gen. Sepp Dietrich. Von Rundstedt then ran through the battle plan, while Hitler made one of his stoic speeches.
In a personal conversation on 13 December between Walther Model and Friedrich von der Heydte, who was put in charge of Operation "Stösser", von der Heydte gave Operation "Stösser" less than a 10% chance of succeeding. Model told him it was necessary to make the attempt: "It must be done because this offensive is the last chance to conclude the war favorably."
Initial German assault.
On 16 December 1944, at 05:30, the Germans began the assault with a massive, 90-minute artillery barrage using 1,600 artillery pieces across a 80 mi front on the Allied troops facing the 6th Panzer Army. The Americans' initial impression was that this was the anticipated, localized counterattack resulting from the Allies' recent attack in the Wahlerscheid sector to the north, where the 2nd Division had knocked a sizable dent in the Siegfried Line. In the northern sector Dietrich's 6th Panzer Army was held up for almost 24 hours by a single reconnaissance platoon and four U.S. Forward Artillery Observers dug in on a ridge overlooking a key road intersection in the village of Lanzerath. They then assaulted Losheim Gap and Elsenborn Ridge in an effort to break through to Liège and Antwerp.
Heavy snowstorms engulfed parts of the Ardennes area. While having the effect of keeping the Allied aircraft grounded, the weather also proved troublesome for the Germans because poor road conditions hampered their advance. Poor traffic control led to massive traffic jams and fuel shortages in forward units.
In the center, von Manteuffel's Fifth Panzer Army attacked towards Bastogne and St. Vith, both road junctions of great strategic importance. In the south, Brandenberger's Seventh Army pushed towards Luxembourg in its efforts to secure the flank from Allied attacks. Only one month before 250 members of the Waffen-SS had unsuccessfully tried to recapture the town of Vianden with its castle from the Luxembourgish resistance during the Battle of Vianden.
Attack on the northern shoulder.
While the Siege of Bastogne is often credited as the central point where the German offensive was stopped, the battle for Elsenborn Ridge was a decisive component of the Battle of the Bulge, deflecting the strongest armored units of the German advance. The attack was led by one of the best equipped German divisions on the western front, the 1st SS Panzer Division (LSSAH). The division made up the lead unit for the entire German 6th Panzer Army. SS Obersturmbannführer Joachim Peiper led Kampfgruppe Peiper, consisting of 4,800 men and 600 vehicles. It was charged with leading the main effort. However, its newest and most powerful tank, the Tiger II heavy tank, consumed 1 gallon of fuel to go half a mile, and the Germans had a limited amount of fuel.
The attacks by the Sixth Panzer Army's infantry units in the north fared badly because of unexpectedly fierce resistance by the U.S. 2nd and 99th Infantry Divisions. On the first day, an entire German battalion of 500 men was held up for 10 hours at the small village of Lanzerath, through which passed a key route through the Losheim Gap. To preserve the quantity of armor available, the infantry of the 9th Fallschirmjaeger Regiment, 3rd Fallschirmjaeger Division, had been ordered to clear the village first. A single 18-man Intelligence and Reconnaissance Platoon from the 99th Infantry Division along with four Forward Air Controllers held up the battalion of about 500 German paratroopers until sunset, about 16:00, causing 92 casualties among the Germans.
This created a bottleneck in the German advance. Kampfgruppe Peiper, at the head of the SS Oberstgruppenführer Sepp Dietrich's Sixth Panzer Army, had been designated to take the Losheim-Losheimergraben road, but it was closed by two collapsed overpasses. Peiper did not begin his advance until nearly 16:00, more than 16 hours behind schedule.
Kampfgruppe Peiper reached Bucholz Station in the early morning of 17 December and quickly captured portions of the 3rd Battalion of the 394th Infantry Regiment. They shortly afterward seized a U.S. fuel depot at Büllingen, where they paused to refuel before continuing westward. To the north, the 277th Volksgrenadier Division attempted to break through the defending line of the U.S. 99th Infantry Division and positions of 2nd Infantry Division. The 12th SS Panzer Division, reinforced by additional infantry (Panzergrenadier and Volksgenadier) divisions, took the key road junction at Losheimergraben just north of Lanzerath and attacked the twin villages of Rocherath and Krinkelt.
Their intention was to control the twin villages of Rocherath-Krinkelt which would clear a path to the high ground of Elsenborn Ridge. Occupation of this dominating terrain would allow control of the roads to the south and west and ensure supply to Kampfgruppe Peiper's armored task force. The stiff American defense prevented the Germans from reaching the vast array of supplies near the Belgian cities of Liège and Spa and the road network west of the Elsenborn Ridge leading to the Meuse River. After more than ten days of intense battle, they pushed the Americans out of the villages, but were unable to dislodge them from the ridge, where elements of the V Corps of the First U.S. Army prevented the German forces from reaching the road network to their west.
The 99th Infantry Division as a whole, outnumbered five to one, inflicted casualties in the ratio of eighteen to one. The division lost about 20% of its effective strength, including 465 killed and 2,524 evacuated due to wounds, injuries, fatigue, or trench foot. German losses were much higher. In the northern sector opposite the 99th, this included more than 4,000 deaths and the destruction of sixty tanks and big guns. Historian John S.D. Eisenhower wrote, "... the action of the 2nd and 99th Divisions on the northern shoulder could be considered the most decisive of the Ardennes campaign."
Kampfgruppe Peiper drives west.
Driving to the south-east of Elsenborn, Kampfgruppe Peiper entered Honsfield, where they encountered one of the 99th Division's rest centers, clogged with confused American troops. They killed many, destroyed a number of American armored units and vehicles, and took several dozen prisoners who were murdered by elements of his force. Peiper easily captured the town and 50000 gal of fuel for his vehicles. Peiper then advanced north-west towards Büllingen, keeping to the plan to move west, apparently unaware he had nearly taken the town and unknowingly bypassed an opportunity to flank and trap the entire 2nd and 99th Divisions. Peiper turned south to detour around Hünningen, choosing a route designated Rollbahn D, as he had been given latitude to choose the best route west.
Malmedy massacre.
At 12:30 on 17 December, Kampfgruppe Peiper was near the hamlet of Baugnez, on the height halfway between the town of Malmedy and Ligneuville, when they encountered elements of the 285th Field Artillery Observation Battalion, U.S. 7th Armored Division. After a brief battle the lightly armed Americans surrendered. They were disarmed and, with some other Americans captured earlier (approximately 150 men), sent to stand in a field near the crossroads under light guard. About fifteen minutes after Peiper's advance guard passed through, the main body under the command of SS Sturmbannführer Werner Pötschke arrived. For reasons unknown to this day, the SS troopers suddenly opened fire on the prisoners. As soon as the firing began, the prisoners panicked. Most were shot where they stood, though some managed to flee. Accounts of the killing vary, but 84 of the POWs were murdered. A few survived, and news of the killings of prisoners of war raced through Allied lines. Following the end of the war, soldiers and officers of Kampfgruppe Peiper, including Joachim Peiper and SS general Sepp Dietrich, were tried for the incident at the Malmedy massacre trial.
Chenogne massacre.
Following the Malmedy massacre, on New Year's Day 1945, after having previously received orders to take no prisoners, American soldiers shot approximately sixty German prisoners of war near the Belgian village of Chenogne (8 km from Bastogne).
Germans advance west.
By the evening the spearhead had pushed north to engage the U.S. 99th Infantry Division and Kampfgruppe Peiper arrived in front of Stavelot. Peiper's forces was already behind his timetable because of the stiff American resistance and because when the Americans fell back, their engineers blew up bridges and emptied fuel dumps. Peiper's unit was delayed and his vehicles denied critically needed fuel. They took 36 hours to advance from Eifel to Stavelot, while the same advance had taken just nine hours in 1940.
Kampfgruppe Peiper attacked Stavelot on 18 December but was unable to capture the town before the Americans evacuated a large fuel depot. Three tanks attempted to take the bridge, but the lead vehicle was disabled by a mine. Following this, 60 grenadiers advanced forward but were stopped by concentrated American defensive fire. After a fierce tank battle the next day, the Germans finally entered the village when U.S. engineers failed to blow the bridge.
Capitalizing on his success and not wanting to lose more time, Peiper rushed an advance group toward the vital bridge at Trois-Ponts, leaving the bulk of his strength in Stavelot. When they reached it at 11:30 on 18 December, retreating U.S. engineers blew it up in their faces. Peiper detoured north towards the villages of La Gleize and Cheneux. At Cheneux, the advance guard was attacked by American fighter-bombers, destroying two tanks and five halftracks, blocking the narrow road. The group got moving again at dusk at 16:00 and was able to return to its original route at around 18:00. Of the two bridges now remaining between Kampfgruppe Peiper and the Meuse, the bridge over the Lienne was blown by the Americans as the Germans approached. Peiper turned north and halted his forces in the woods between La Gleize and Stoumont. He learned that Stoumont was strongly held and that the Americans were bringing up strong reinforcements from Spa.
To Peiper's south, the advance of Kampfgruppe Hansen had stalled. SS Oberführer Mohnke ordered Schnellgruppe Knittel, which had been designated to follow Hansen, to instead move forward to support Peiper. SS Sturmbannführer Knittel crossed the bridge at Stavelot around 19:00 against American forces trying to retake the town. Knittel pressed forward towards La Gleize, and shortly afterward the Americans recaptured Stavelot. Peiper and Knittel both faced the prospect of being cut off.
German advance halted.
At dawn on 19 December, Peiper surprised the American defenders of Stoumont by sending infantry from the 2nd SS Panzergrenadier Regiment in an attack and a company of Fallschirmjäger to infiltrate their lines. He followed this with a Panzer attack, gaining the eastern edge of the town. An American tank battalion arrived but, after a two-hour tank battle, Peiper finally captured Stoumont at 10:30. Knittel joined up with Peiper and reported the Americans had recaptured Stavelot to their east. Peiper ordered Knittel to retake Stavelot. Assessing his own situation, he determined that his Kampfgruppe did not have sufficient fuel to cross the bridge west of Stoumont and continue his advance. He maintained his lines west of Stoumont for a while, until the evening of 19 December when he withdrew them to the village edge. On the same evening the U.S. 82nd Airborne Division under Maj. Gen. James Gavin arrived and deployed at La Gleize and along Peiper's planned route of advance. German efforts to reinforce Peiper were unsuccessful. Kampfgruppe Hansen was still struggling against bad road conditions and stiff American resistance on the southern route. Schnellgruppe Knittel was forced to disengage from the heights around Stavelot. Kampfgruppe Sandig, which had been ordered to take Stavelot, launched another attack without success. Sixth Panzer Army commander SS-Oberstgruppenführer Sepp Dietrich ordered Hermann Prieß, commanding officer of the I SS Panzer Corps, to increase its efforts to back Peiper's Kampfgruppe, but Prieß was unable to break through.
Small units of the U.S. 2nd Battalion of the 119th Regiment attacked the dispersed units of Kampfgruppe Peiper during the morning of 21 December, but were pushed back and a number captured, including their battalion commander, Maj. Hal McCown. Peiper learned that German reinforcements were to be concentrated in La Gleize and withdrew his forces eastward, leaving wounded Americans and Germans in the Froidcourt castle. Attempting to withdraw from Cheneux, American paratroopers from the 82nd Airborne Division engaged the Germans in fierce house-to-house fighting. The Americans shelled Kampfgruppe Peiper on 22 December, and although the Germans had run out of food and had virtually no fuel, they continued to fight. A Luftwaffe resupply mission went badly when SS-Brigadeführer Wilhelm Mohnke insisted the grid coordinates supplied by Peiper were wrong, parachuting supplies into American hands in Stoumont.
In La Gleize, Peiper set up defenses waiting for German relief. When the relief force was unable to penetrate the Allied lines, he decided to break through the Allied lines and return to the German lines on 23 December. The men of the "Kampfgruppe" were forced to abandon their vehicles and heavy equipment, although most of what remained of the unit was able to escape.
Operation Stösser.
Operation Stösser was a paratroop drop into the American rear in the High Fens (French: "Hautes Fagnes"; German: "Hohes Venn"; Dutch: "Hoge Venen") area. The objective was the "Baraque Michel" crossroads. It was led by Oberst Friedrich August Freiherr von der Heydte, considered by Germans to be a hero of the Battle of Crete.
It was the German paratroopers' only nighttime drop during World War II. Von der Heydte was given only eight days to prepare prior to the assault. He was not allowed to use his own regiment because their movement might alert the Allies to the impending counterattack. Instead, he was provided with a Kampfgruppe of 800 men. The II Parachute Corps was tasked with contributing 100 men from each of its regiments. In loyalty to their commander, 150 men from von der Heydte's own unit, the 6th Parachute Regiment, went against orders and joined him. They had little time to establish any unit cohesion or train together.
The parachute drop was a complete failure. Von der Heydte ended up with a total of around 300 troops. Too small and too weak to counter the Allies, they abandoned plans to take the crossroads and instead converted his mission to reconnaissance. With only enough ammunition for a single fight, they withdrew towards Germany and attacked the rear of the American lines. Only about 100 of his weary men finally reached the German rear.
Wereth 11.
Another, smaller massacre was committed in Wereth, Belgium, approximately 1000 yards northeast of Saint-Vith, on 17 December 1944. Eleven black American soldiers were tortured after surrendering and then shot by men of the 1st SS Panzer Division belonging to Kampfgruppe Knittel. The perpetrators were never punished for this crime and recent research indicates that men from Third Company of the Reconnaissance Battalion were responsible.
Attack in the center.
The Germans fared better in the center (the 20 mi "Schnee Eifel" sector) as the Fifth Panzer Army attacked positions held by the U.S. 28th and 106th Infantry Divisions. The Germans lacked the overwhelming strength that had been deployed in the north, but still possessed a marked numerical and material superiority over the very thinly spread 28th and 106th divisions. They succeeded in surrounding two largely intact regiments (422nd and 423rd) of the 106th Division in a pincer movement and forced their surrender, a tribute to the way Manteuffel's new tactics had been applied. The official U.S. Army history states: "At least seven thousand [men] were lost here and the figure probably is closer to eight or nine thousand. The amount lost in arms and equipment, of course, was very substantial. The Schnee Eifel battle, therefore, represents the most serious reverse suffered by American arms during the operations of 1944–45 in the European theater."
Battle for St. Vith.
In the center the town of St. Vith, a vital road junction, presented the main challenge for both von Manteuffel's and Dietrich's forces. The defenders, led by the 7th Armored Division and including the remaining regiment of the 106th U.S. Infantry Division, with elements of the 9th Armored Division and 28th U.S. Infantry Division. These units, which operated under the command of Generals Robert W. Hasbrouck (7th Armored) and Alan W. Jones (106th Infantry), successfully resisted the German attacks, significantly slowing the German advance. At Montgomery's orders, St. Vith was evacuated on 21 December; U.S. troops fell back to entrenched positions in the area, presenting an imposing obstacle to a successful German advance. By 23 December, as the Germans shattered their flanks, the defenders' position became untenable and U.S. troops were ordered to retreat west of the Salm River. Since the German plan called for the capture of St. Vith by 18:00 on 17 December, the prolonged action in and around it dealt a major setback to their timetable.
Meuse River bridges.
To protect the river crossings on the Meuse at Givet, Dinant and Namur, Montgomery ordered those few units available to hold the bridges on 19 December. This led to a hastily assembled force including rear-echelon troops, military police and Army Air Force personnel. The British 29th Armored Brigade, which had turned in its tanks for re-equipping, was told to take back their tanks and head to the area. XXX Corps in the Netherlands began their move to the area on 20 December. The 6th Airborne Division in the UK was ordered to ports for ferrying to France.
Aside from the difficulties in the northern and southern sectors, the German advance in the center was the most successful. Fifth Panzer Army was spearheaded by the 2nd Panzer Division while Panzer Lehr Division came up from the south, leaving Bastogne to other units. The Ourthe River was passed at Ourtheville on 21 December. Lack of fuel held up the advance for one day, but on 23 December the offensive was resumed towards the two small towns of Hargimont and Marche. Hargimont was captured the same day, but Marche was strongly defended by the American 84th Division. Gen. Lüttwitz, commander of the XXXXVII Panzer Corps, ordered the Division to turn westwards towards Dinant and the Meuse, leaving only a blocking force at Marche. Although advancing only in a narrow corridor, 2nd Panzer Division was still making rapid headway, leading to jubilation in Berlin. Headquarters now freed up the 9th Panzer Division for Fifth Panzer Army, which was deployed at Marche.
On 22/23 December the woods of Foy-Notre-Dame were reached, only a few kilometers ahead of Dinant. However, the narrow corridor caused considerable difficulties, as constant flanking attacks threatened the division. On 24 December the furthest penetration was reached. Panzer Lehr Division took the town of Celles, while a bit farther north, parts of 2nd Panzer Division were in sight of the Meuse near Dinant at Foy-Notre-Dame. A hastily assembled Allied blocking force on the east side of the river, however, prevented the German probing forces from approaching the Dinant bridge. By late Christmas Eve the advance in this sector was stopped, as Allied forces threatened the narrow corridor held by the 2nd Panzer Division.
Operation Greif and Operation Währung.
For Operation Greif, Otto Skorzeny successfully infiltrated a small part of his battalion of English-speaking Germans disguised in American uniforms behind the Allied lines. Although they failed to take the vital bridges over the Meuse, their presence caused confusion out of all proportion to their military activities, and rumors spread quickly. Even General George Patton was alarmed and, on 17 December, described the situation to General Dwight Eisenhower as "Krauts…speaking perfect English…raising hell, cutting wires, turning road signs around, spooking whole divisions, and shoving a bulge into our defenses."
Checkpoints were set up all over the Allied rear, greatly slowing the movement of soldiers and equipment. American MPs at these checkpoints grilled troops on things that every American was expected to know, like the identity of Mickey Mouse's girlfriend, baseball scores, or the capital of a particular U.S. state—though many could not remember or did not know. General Omar Bradley was briefly detained when he correctly identified Springfield as the capital of Illinois because the American MP who questioned him mistakenly believed the capital was Chicago.
The tightened security nonetheless made things very hard for the German infiltrators, and a number of them were captured. Even during interrogation, they continued their goal of spreading disinformation; when asked about their mission, some of them claimed they had been told to go to Paris to either kill or capture General Dwight Eisenhower. Security around the general was greatly increased, and Eisenhower was confined to his headquarters. Because Skorzeny's men were captured in American uniforms, they were executed as spies. This was the standard practice of every army at the time, as many belligerents considered it necessary to protect their territory against the grave dangers of enemy spying. Skorzeny said that he was told by German legal experts that as long he did not order his men to fight in combat while wearing American uniforms, such a tactic was a legitimate ruse of war. Skorzeny and his men were fully aware of their likely fate, and most wore their German uniforms underneath their American ones in case of capture. Skorzeny was tried by an American military tribunal in 1947 at the Dachau Trials for allegedly violating the laws of war stemming from his leadership of Operation Greif, but was acquitted. He later moved to Spain and South America.
In Operation Währung, a small number of German agents infiltrated Allied lines in American uniforms. These agents were then to use an existing Nazi intelligence network to attempt to bribe rail and port workers to disrupt Allied supply operations. However, this operation was a failure.
Attack in the south.
Further south on Manteuffel's front, the main thrust was delivered by all attacking divisions crossing the River Our, then increasing the pressure on the key road centers of St. Vith and Bastogne. The more experienced 28th Infantry Division put up a much more dogged defense than the inexperienced (or "green") soldiers of the 106th Infantry Division. The 112th Infantry Regiment (the most northerly of the 28th Division's regiments), holding a continuous front east of the Our, kept German troops from seizing and using the Our River bridges around Ouren for two days, before withdrawing progressively westwards.
The 109th and 110th Regiments of the 28th Division, however, fared worse, as they were spread so thinly that their positions were easily bypassed. Both offered stubborn resistance in the face of superior forces and threw the German schedule off by several days. The 110th's situation was by far the worst, as it was responsible for an 11 mi front while its 2nd Battalion was withheld as the divisional reserve. Panzer columns took the outlying villages and widely separated strongpoints in bitter fighting, and advanced to points near Bastogne within four days. The struggle for the villages and American strongpoints, plus transport confusion on the German side, slowed the attack sufficiently to allow the 101st Airborne Division (reinforced by elements from the 9th and 10th Armored Divisions) to reach Bastogne by truck on the morning of 19 December. The fierce defense of Bastogne, in which American paratroopers particularly distinguished themselves, made it impossible for the Germans to take the town with its important road junctions. The "panzer" columns swung past on either side, cutting off Bastogne on 20 December but failing to secure the vital crossroads.
In the extreme south, Brandenberger's three infantry divisions were checked by divisions of the U.S. VIII Corps after an advance of 4 mi; that front was then firmly held. Only the 5th Parachute Division of Brandenberger's command was able to thrust forward 12 mi on the inner flank to partially fulfill its assigned role. Eisenhower and his principal commanders realized by 17 December that the fighting in the Ardennes was a major offensive and not a local counterattack, and they ordered vast reinforcements to the area. Within a week 250,000 troops had been sent. General Gavin of the 82nd Airborne Division arrived on the scene first and ordered the 101st to hold Bastogne while the 82nd would take the more difficult task of facing the SS Panzer Divisions; it was also thrown into the battle north of the bulge, near Elsenborn Ridge.
Siege of Bastogne.
By the time the senior Allied commanders met in a bunker in Verdun on 19 December, the town of Bastogne and its network of 11 hard-topped roads leading through the mountainous terrain and boggy mud of the Ardennes region were to have been in German hands for several days. By the time of that meeting, two separate westbound German columns that were to have bypassed the town to the south and north, the 2nd Panzer Division and Panzer-Lehr-Division of XLVII Panzer Corps, as well as the Corps' infantry (26th Volksgrenadier Division), coming due west had been engaged and much slowed and frustrated in outlying battles at defensive positions up to 10 mi from the town proper—and were gradually being forced back onto and into the hasty defenses built within the municipality. Moreover, the sole corridor that was open (to the southeast) was threatened and it had been sporadically closed as the front shifted, and there was expectation that it would be completely closed sooner than later, given the strong likelihood that the town would soon be surrounded.
Gen. Eisenhower, realizing that the Allies could destroy German forces much more easily when they were out in the open and on the offensive than if they were on the defensive, told his generals, "The present situation is to be regarded as one of opportunity for us and not of disaster. There will be only cheerful faces at this table." Patton, realizing what Eisenhower implied, responded, "Hell, let's have the guts to let the bastards go all the way to Paris. Then, we'll really cut 'em off and chew 'em up." Eisenhower, after saying he was not "that" optimistic, asked Patton how long it would take to turn his Third Army (located in northeastern France) north to counterattack. Patton replied that he could attack with two divisions within 48 hours, to the disbelief of the other generals present. However, before he had gone to the meeting Patton had ordered his staff to prepare three contingency plans for a northward turn in at least corps strength. By the time Eisenhower asked him how long it would take, the movement was already underway. On 20 December, Eisenhower removed the First and Ninth U.S. Armies from Gen. Bradley's 12th Army Group and placed them under Montgomery's 21st Army Group.
By 21 December the Germans had surrounded Bastogne, which was defended by the 101st Airborne Division and Combat Command B of the 10th Armored Division. Conditions inside the perimeter were tough—most of the medical supplies and medical personnel had been captured. Food was scarce, and by 22 December artillery ammunition was restricted to 10 rounds per gun per day. The weather cleared the next day, however, and supplies (primarily ammunition) were dropped over four of the next five days.
Despite determined German attacks, however, the perimeter held. The German commander, Lt. Gen. Heinrich Freiherr von Lüttwitz, requested Bastogne's surrender. When Brig. Gen. Anthony McAuliffe, acting commander of the 101st, was told of the Nazi demand to surrender, in frustration he responded, "Nuts!" After turning to other pressing issues, his staff reminded him that they should reply to the German demand. One officer, Lt. Col. Harry Kinnard, noted that McAuliffe's initial reply would be "tough to beat." Thus McAuliffe wrote on the paper, which was typed up and delivered to the Germans, the line he made famous and a morale booster to his troops: "NUTS!" That reply had to be explained, both to the Germans and to non-American Allies.
Both 2nd Panzer and Panzer Lehr moved forward from Bastogne after 21 December, leaving only Panzer Lehr's 901st Regiment to assist the 26th Volksgrenadier Division in attempting to capture the crossroads. The 26th VG received one panzergrenadier regiment from the 15th Panzergrenadier Division on Christmas Eve for its main assault the next day. Because it lacked sufficient troops and those of the 26th VG Division were near exhaustion, the XLVII Panzer Corps concentrated its assault on several individual locations on the west side of the perimeter in sequence rather than launching one simultaneous attack on all sides. The assault, despite initial success by its tanks in penetrating the American line, was defeated and all the tanks destroyed. The next day, 26 December, the spearhead of Gen. Patton's 4th Armored Division broke through and opened a corridor to Bastogne.
Allied counteroffensive.
On 23 December, the weather conditions started improving, allowing the Allied air forces to attack. They launched devastating bombing raids on the German supply points in their rear, and P-47 Thunderbolts started attacking the German troops on the roads. Allied air forces also helped the defenders of Bastogne, dropping much-needed supplies—medicine, food, blankets, and ammunition. A team of volunteer surgeons flew in by military glider and began operating in a tool room.
By 24 December, the German advance was effectively stalled short of the Meuse. Units of the British XXX Corps were holding the bridges at Dinant, Givet, and Namur and U.S. units were about to take over. The Germans had outrun their supply lines, and shortages of fuel and ammunition were becoming critical. Up to this point the German losses had been light, notably in armor, which was almost untouched with the exception of Peiper's losses. On the evening of 24 December, General Hasso von Manteuffel recommended to Hitler's Military Adjutant a halt to all offensive operations and a withdrawal back to the West Wall. Hitler rejected this.
However disagreement and confusion at the Allied command prevented a strong response, throwing away the opportunity for a decisive action. In the center, on Christmas Eve, the 2nd Armored Division attempted to attack and cut off the spearheads of the 2nd Panzer Division at the Meuse, while the units from the 4th Cavalry Group kept the 9th Panzer Division at Marche busy. As result, parts of the 2nd Panzer Division were cut off. Panzer Lehr tried to relieve them, but was only partially successful, as the perimeter held. For the next two days the perimeter was strengthened. On 26 and 27 December the trapped units of 2nd Panzer Division made two break-out attempts, again only with partial success, as major quantities of equipment fell into Allied hands. Further Allied pressure out of Marche finally led the German command to the conclusion that no further offensive action towards the Meuse was possible.
In the south, Patton's Third Army was battling to relieve Bastogne. At 16:50 on 26 December, the lead element, Company D, 37th Tank Battalion of the 4th Armored Division, reached Bastogne, ending the siege.
German counterattack.
On 1 January, in an attempt to keep the offensive going, the Germans launched two new operations. At 09:15, the "Luftwaffe" launched "Unternehmen Bodenplatte" (Operation Baseplate), a major campaign against Allied airfields in the Low Countries. Hundreds of planes attacked Allied airfields, destroying or severely damaging some 465 aircraft. However, the "Luftwaffe" lost 277 planes, 62 to Allied fighters and 172 mostly because of an unexpectedly high number of Allied flak guns, set up to protect against German V-1 flying bomb attacks and using proximity fused shells, but also by friendly fire from the German flak guns that were uninformed of the pending large-scale German air operation. The Germans suffered heavy losses at an airfield named Y-29, losing 24 of their own planes while downing only one American plane. While the Allies recovered from their losses in just days, the operation left the "Luftwaffe" weak and ineffective for the remainder of the war.
On the same day, German Army Group G ("Heeresgruppe G") and Army Group Upper Rhine ("Heeresgruppe Oberrhein") launched a major offensive against the thinly stretched, 70 mi line of the Seventh U.S. Army. This offensive, known as "Unternehmen Nordwind" (Operation North Wind), was the last major German offensive of the war on the Western Front. The weakened Seventh Army had, at Eisenhower's orders, sent troops, equipment, and supplies north to reinforce the American armies in the Ardennes, and the offensive left it in dire straits.
By 15 January, Seventh Army's VI Corps was fighting on three sides in Alsace. With casualties mounting, and running short on replacements, tanks, ammunition, and supplies, Seventh Army was forced to withdraw to defensive positions on the south bank of the Moder River on 21 January. The German offensive drew to a close on 25 January. In the bitter, desperate fighting of Operation Nordwind, VI Corps, which had borne the brunt of the fighting, suffered a total of 14,716 casualties. The total for Seventh Army for January was 11,609. Total casualties included at least 9,000 wounded. First, Third and Seventh Armies suffered a total of 17,000 hospitalized from the cold.
Allies prevail.
While the German offensive had ground to a halt, they still controlled a dangerous salient in the Allied line. Patton's Third Army in the south, centered around Bastogne, would attack north, Montgomery's forces in the north would strike south, and the two forces planned to meet at Houffalize.
The temperature during January 1945 was extremely low. Weapons had to be maintained and truck engines run every half-hour to prevent their oil from congealing. The offensive went forward regardless.
Eisenhower wanted Montgomery to go on the counter offensive on 1 January, with the aim of meeting up with Patton's advancing Third Army and cutting off most of the attacking Germans, trapping them in a pocket. However, Montgomery, refusing to risk underprepared infantry in a snowstorm for a strategically unimportant area, did not launch the attack until 3 January, by which time substantial numbers of German troops had already managed to fall back successfully, but at the cost of losing most of their heavy equipment.
At the start of the offensive, the First and Third U.S. Armies were separated by about 25 mi. American progress in the south was also restricted to about a kilometer a day. The majority of the German force executed a successful fighting withdrawal and escaped the battle area, although the fuel situation had become so dire that most of the German armor had to be abandoned. On 7 January 1945, Hitler agreed to withdraw all forces from the Ardennes, including the "SS Panzer" divisions, thus ending all offensive operations. However, considerable fighting went on for another 3 weeks; St. Vith was recaptured by the Americans on 23 January, and the last German units participating in the offensive did not return to their start line until 25 January.
Winston Churchill, addressing the House of Commons following the Battle of the Bulge said, "This is undoubtedly the greatest American battle of the war and will, I believe, be regarded as an ever-famous American victory."
Controversy at high command.
As the Ardennes crisis developed, at 10:30 a.m. on 20 December, Eisenhower telephoned Montgomery and ordered him to assume command of the American First (Hodges) and Ninth Army (Simpson) – which, until then, were under Bradley's overall command. This change in command was ordered because the northern armies had not only lost all communications with Bradley, who was based in Luxembourg, and the US command structure, but with adjacent units. Without radio or telephone communication Montgomery managed to improvise an effective command and control system based on those of the Duke of Wellington's 'gallopers' of the Battle of Waterloo.
Describing the situation as he found it on 20 December, Montgomery wrote; "The First Army was fighting desperately. Having given orders to Dempsey and Crerar, who arrived for a conference at 11 am, I left at noon for the H.Q. of the First Army, where I had instructed Simpson to meet me. I found the northern flank of the bulge was very disorganised. Ninth Army had two corps and three divisions; First Army had three corps and fifteen divisions. Neither Army Commander had seen Bradley or any senior member of his staff since the battle began, and they had no directive on which to work. The first thing to do was to see the battle on the northern flank "as one whole", to ensure the vital areas were held securely, and to create reserves for counter-attack. I embarked on these measures: I put British troops under command of the Ninth Army to fight alongside American soldiers, and made that Army take over some of the First Army Front. I positioned British troops as reserves behind the First and Ninth Armies until such time as American reserves could be created. Slowly but surely the situation was held, and then finally restored. Similar action was taken on the southern flank of the bulge by Bradley, with the Third Army."
Due to the news blackout imposed on the 16th, the change of leadership to Montgomery did not become known to the outside world until eventually SHAEF made a public announcement making clear that the change in command was "absolutely nothing to do with failure on the part of the three American generals". This resulted in headlines in British newspapers. The story was also covered in "Stars and Stripes" and for the first time British contribution to the fighting was mentioned.
Montgomery asked Churchill if he could give a conference to the press to explain the situation. Though some of his staff were concerned at the image it would give, the conference had been cleared by Alan Brooke, the CIGS, who was possibly the only person to whom Monty would listen.
On the same day as Hitler's withdrawal order, 7 January, Montgomery held his press conference at Zonhoven. Montgomery started with giving credit to the "courage and good fighting quality" of the American troops, characterizing a typical American as a "very brave fighting man who has that tenacity in battle which makes a great soldier", and went on to talk about the necessity of Allied teamwork, and praised Eisenhower, stating, "Teamwork wins battles and battle victories win wars. On our team, the captain is General Ike."
Then Montgomery described the course of the battle for a half-hour. Coming to the end of his speech he said he had "employed the whole available power of the British Group of Armies; this power was brought into play very gradually ... Finally it was put into battle with a bang ... you thus have the picture of British troops fighting on both sides of the Americans who have suffered a hard blow." He stated that he (i.e., the German) was "headed off ... seen off ... and ... written off". "The battle has been the most interesting, I think possibly one of the most interesting and tricky battles I have ever handled.".
Despite his positive remarks about American soldiers, the overall impression given by Montgomery, at least in the ears of the American military leadership, was that he had taken the lion's share of credit for the success of the campaign, and had been responsible for rescuing the besieged Americans.
His comments were interpreted as self-promoting, particularly his claiming that when the situation "began to deteriorate," Eisenhower had placed him in command in the north. Patton and Eisenhower both felt this was a misrepresentation of the relative share of the fighting played by the British and Americans in the Ardennes (for every British soldier there were thirty to forty Americans in the fight), and that it belittled the part played by Bradley, Patton and other American commanders. In the context of Patton's and Montgomery's well-known antipathy, Montgomery's failure to mention the contribution of any American general beside Eisenhower was seen as insulting. Indeed, General Bradley and his American commanders were already starting their counterattack by the time Montgomery was given command of 1st and 9th U.S. Armies. Focusing exclusively on his own generalship, Montgomery continued to say he thought the counteroffensive had gone very well but did not explain the reason for his delayed attack on 3 January. He later attributed this to needing more time for preparation on the northern front. According to Winston Churchill, the attack from the south under Patton was steady but slow and involved heavy losses, and Montgomery was trying to avoid this situation.
Many American officers had already grown to dislike Montgomery, who was seen by them as an overly cautious commander, arrogant, and all too willing to say uncharitable things about the Americans. The British Prime Minister Winston Churchill found it necessary in a speech to Parliament to explicitly state that the Battle of the Bulge was purely an American victory.
Montgomery subsequently recognized his error and later wrote: "Not only was it probably a mistake to have held this conference at all in the sensitive state of feeling at the time, but what I said was skilfully distorted by the enemy. Chester Wilmot ("The Struggle for Europe", p. 611) has explained that his dispatch to the BBC about it was intercepted by the German wireless, re-written to give it an anti-American bias, and then broadcast by Arnhem Radio, which was then in Goebbels' hands. Monitored at Bradley's H.Q., this broadcast was mistaken for a B.B.C. transmission and it was this twisted text that started the uproar."
"Distorted or not, I think now that I should never have held that press conference. So great were the feelings against me on the part of the American generals that whatever I said was bound to be wrong. I should therefore have said nothing." Eisenhower commented in his own memoirs: "I doubt if Montgomery ever came to realize how resentful some American commanders were. They believed he had belittled them—and they were not slow to voice reciprocal scorn and contempt."
Bradley and Patton both threatened to resign unless Montgomery's command was changed. Eisenhower, encouraged by his British deputy Arthur Tedder, had decided to sack Montgomery. However, intervention by Montgomery's and Eisenhower's Chiefs of Staff, Maj. Gen. Freddie de Guingand, and Lt. Gen. Walter Bedell Smith, moved Eisenhower to reconsider and allowed Montgomery to apologize.
The German commander of the 5th Panzer Army, Hasso von Manteuffel said of Montgomery's leadership:
The operations of the American 1st Army had developed into a series of individual holding actions. Montgomery's contribution to restoring the situation was that he turned a series of isolated actions into a coherent battle fought according to a clear and definite plan. It was his refusal to engage in premature and piecemeal counter-attacks which enabled the Americans to gather their reserves and frustrate the German attempts to extend their breakthrough.
Casualties.
Casualty estimates for the battle vary widely. According to the U.S. Department of Defense, American forces suffered 89,500 casualties including 19,000 killed, 47,500 wounded and 23,000 missing. An official report by the United States Department of the Army lists 108,347 casualties, including 19,246 killed, 62,489 wounded, and 26,612 captured or missing. A preliminary Army report restricted to the First and Third U.S. Armies listed 75,000 casualties (8,400 killed, 46,000 wounded and 21,000 missing). The Battle of the Bulge was the bloodiest battle for U.S. forces in World War II. British losses totaled 1,400. The German High Command's official figure for the campaign was 84,834 German casualties, and other estimates range between 60,000 and 100,000.
The Allies pressed their advantage following the battle. By the beginning of February 1945, the lines were roughly where they had been in December 1944. In early February, the Allies launched an attack all along the Western front: in the north under Montgomery toward Aachen; in the center, under Courtney Hodges; and in the south, under Patton. Montgomery's behavior during the months of December and January, including the press conference on 7 January where he appeared to downplay the contribution of the American generals, further soured his relationship with his American counterparts through to the end of the war.
The German losses in the battle were especially critical: their last reserves were now gone, the Luftwaffe had been shattered, and remaining forces throughout the West were being pushed back to defend the Siegfried Line.
In response to the early success of the offensive, on 6 January Churchill contacted Stalin to request that the Soviets put pressure on the Germans on the Eastern Front. On 12 January, the Soviets began the massive Vistula–Oder Offensive, originally planned for 20 January.
During World War II, most U.S. black soldiers still served only in maintenance or service positions, or in segregated units. Because of troop shortages during the Battle of the Bulge, Eisenhower decided to integrate the service for the first time. This was an important step toward a desegregated United States military. More than 2,000 black soldiers had volunteered to go to the front. A total of 708 black Americans were killed in combat during World War II.
Battle credit.
After the war ended, the U.S. Army issued battle credit in the form of the Ardennes-Alsace campaign citation to units and individuals that took part in operations in northwest Europe. The citation covered the Ardennes sector where the actual battle took place and units further south in the Alsace sector. The southern units held the line in their region but were not involved in the battle except for elements they sent north as reinforcements.
In entertainment.
The battle has been depicted in numerous works of fiction and entertainment, including the films "Battleground" (1949) and "Battle of the Bulge" (1965). In video games alone, it has received about thirty treatments as of 2014, mostly in strategy games, beginning with "Tigers in the Snow" (1981).
Bibliography.
</dl>

</doc>
<doc id="58001" url="http://en.wikipedia.org/wiki?curid=58001" title="Teleportation (disambiguation)">
Teleportation (disambiguation)

Teleportation is the fictional or imagined process by which matter is instantaneously transferred from one place to another.
Teleportation may also refer to:

</doc>
<doc id="58003" url="http://en.wikipedia.org/wiki?curid=58003" title="Gentiana">
Gentiana

Gentiana is a genus of flowering plants belonging to the gentian family (Gentianaceae), the tribe Gentianeae, and the monophyletic subtribe Gentianinae. With about 400 species it is considered a large genus. They are notable for their mostly large, trumpet-shaped flowers, which are often of an intense blue.
The genus name is a tribute to Gentius, an Illyrian king who may have been the discoverer of tonic properties in gentians.
Habitat.
This is a cosmopolitan genus, occurring in alpine habitats in temperate regions of Asia, Europe and the Americas. Some species also occur in northwestern Africa, eastern Australia, and New Zealand. They are annual, biennial, and perennial plants. Some are evergreen, others are not.
Many gentians are difficult to grow outside their wild habitat, but several species are available in cultivation. Gentians are fully hardy and can grow in full sun or partial shade. They grow in well-drained, neutral to acid soils rich in humus. They are popular in rock gardens.
Uses.
Many beverages are made with gentian root. It is used to produce "gentian", a distilled beverage produced in the Alps. Some species are harvested for the manufacture of apéritifs, liqueurs, and tonics.
Gentian root is a common beverage flavouring for bitters. The soft drink Moxie contains gentian root. The French liqueur Suze is made with gentian. Americano apéritifs contain gentian root for bitter flavoring. It is an ingredient in the Italian liqueur Aperol. It is also used as the main flavor in the German after-dinner digestif called Underberg, and the main ingredient in Angostura bitters.
Pharmacological Uses.
Gentian is used in herbal medicine to treat digestive problems, fever, hypertension, muscle spasms, parasitic worms, wounds, cancer, sinusitis, and malaria. Gentian has also been listed as one of the 38 plants that are used to prepare Bach flower remedies
"Gentiana punctata" leaves and roots have been used in the traditional Austrian medicine internally and externally as liqueur or tea for treatment of disorders of the gastrointestinal tract, skin, locomotor system, liver and bile, for paediatric problems, fever, flu, rheumatism and gout.
Species.
General.
Gentians have oppositely arranged leaves, sometimes in a basal rosette. The trumpet-shaped flowers are usually deep blue or azure, but can be white, cream, yellow, or red. Many species are polymorphic with respect to flower color, bearing flowers of different colors. Blue-flowered species predominate in the Northern Hemisphere, with red-flowered species dominant in the Andes, where bird pollination is probably more often favored by natural selection. White-flowered species are scattered throughout the range of the genus but dominate in New Zealand. Most flowers are pentamerous, with 5 lobes in the corolla and 5 sepals. A few species have 4 to 7 flower parts. The corolla has folds called plicae between the lobes. The style is short or absent. The ovary is mostly sessile and has nectary glands.

</doc>
<doc id="58004" url="http://en.wikipedia.org/wiki?curid=58004" title="Gentiana acaulis">
Gentiana acaulis

Gentiana acaulis (stemless gentian) is a species of flowering plant in the family Gentianaceae, native to central and southern Europe, from Spain east to the Balkans, growing especially in mountainous regions, such as the Alps, Cevennes and Pyrenees, at heights of 800 -.
It is a perennial plant, growing to 2 cm tall and 10 cm or more wide. The leaves are evergreen, 2-3.5 cm long, in a basal rosette, forming clumps. The trumpet-shaped terminal flowers are blue with olive-green spotted longitudinal throats. They grow on a very short peduncle, 3–6 cm long. The flower stem is often without leaves, or has 1 or 2 pairs of leaves. It likes full sun, is fully hardy and flowers in late spring and summer.
This plant, like others of its genus, is valued in cultivation for the unusually pure intense blue of its blooms. It has gained the Royal Horticultural Society's Award of Garden Merit.
The Latin specific epithet "acaulis" means "short-stemmed".
The closely related "Gentiana clusii", often called by the same common name as this species, differs by growing on limy soils. It also has shorter leaves and the flowers have no olive-green stripes.
A depiction of a gentian flower can be seen on the obverse side of Austrian € 0.01 euro coins.

</doc>
<doc id="58005" url="http://en.wikipedia.org/wiki?curid=58005" title="Airship">
Airship

An airship or dirigible is a type of aerostat or lighter-than-air aircraft which can navigate through the air under its own power. Aerostats gain their lift from large gas bags filled with a lifting gas that is less dense than the surrounding air.
In early dirigibles, the lifting gas used was hydrogen, due to its high lifting capacity and ready availability. Helium gas has almost the same lifting capacity and is nonflammable, unlike hydrogen, but is rare and relatively expensive. Significant amounts were first discovered in the United States and, for a while, helium was rarely used for airships outside the United States. Most airships built since the 1960s have used helium, though some have used hot air.
The outer envelope of an airship may be formed from its single gas bag, or may be a separate supported skin. Besides the main envelope, an airship also has engines and crew and/or payload accommodation, typically in a gondola hung beneath the envelope.
The main types of airship are non-rigid, semi-rigid, and rigid. Non-rigid airships, often called "blimps", rely on internal pressure to maintain the shape of the airship. Semi-rigid airships maintain the envelope shape by internal pressure, but have some form of supporting structure, such as a fixed keel, attached to it. Rigid airships have an outer structural framework which maintains the shape and carries all structural loads, while the lifting gas is contained in one or more internal gas bags or cells. Rigid airships were first flown by Count Zeppelin and the vast majority of rigid airships built were manufactured by the firm he founded. As a result, all rigid airships are sometimes called zeppelins.
Airships were the first aircraft capable of controlled powered flight, and were most commonly used before the 1940s, but their use decreased over time as their capabilities were surpassed by those of aeroplanes. Their decline was accelerated by a series of high-profile accidents, including the 1930 crash and burning of British "R101" in France, the 1933 storm-related crash of the USS "Akron" and the 1937 burning of the hydrogen-filled "Hindenburg". From the 1960s, helium airships have been used in applications where the ability to hover in one place for an extended period outweighs the need for speed and manoeuvrability such as advertising, tourism, camera platforms, geological surveys, and aerial observation.
Classification.
Airships are classified, according to their method of construction, into rigid, semi-rigid and non-rigid types.
Rigid airships.
A rigid airship has a rigid framework covered by an outer skin or envelope. The interior contains one or more gas bags, cells or balloons to provide lift. Rigid airships are typically unpressurised and can be made to virtually any size. Most, but not all, of the German Zeppelin airships have been of this type.
Semi-rigid airships.
A semi-rigid airship has some kind of supporting structure but the main envelope is held in shape by the internal pressure of the lifting gas. Typically the airship has an extended, usually articulated keel running along the bottom of the envelope to stop it kinking in the middle by distributing suspension loads into the envelope, while also allowing lower envelope pressures.
Non-rigid airships.
Non-rigid airships are often called "Blimps". Most, but not all, of the American Goodyear airships have been blimps.
A non-rigid airship relies entirely on internal gas pressure to retain its shape during flight. Unlike the rigid design, the nonrigid airship's gas envelope has no compartments. However it typically has smaller internal bags or "ballonets" containing air. At sea level, the ballonets are filled with air. As altitude is increased, the lifting gas expands and air from the ballonets is expelled through valves to maintain the hull shape. To return to sea level, the process is reversed. Air is forced back into the ballonets by both scooping air from the engine exhaust and using auxiliary blowers.
Terminology.
Airship.
During the pioneer years of aeronautics, terms such as "airship", "air-ship", "air ship" and "ship of the air" meant any kind of navigable or dirigible flying machine. In 1919 Frederick Handley Page was reported as referring to "ships of the air," with smaller passenger types as "Air yachts." In the 1930s, large intercontinental flying boats were also sometimes referred to as "ships of the air" or "flying-ships". Nowadays the term "airship" is used only for powered, dirigible balloons, with sub-types being classified as rigid, semi-rigid or non-rigid.
Aerostat.
An "aerostat" is an aircraft which remain aloft using buoyancy or static lift, as opposed to the aerodyne which obtains lift by moving through the air. Airships are a type of "aerostat".
The term "aerostat" has also been used to indicate a tethered or moored balloon as opposed to a free-floating balloon.
Dirigible.
Airships were originally called "dirigible balloons" from the French ("dirigible", meaning steerable or navigable). This came to be shortened to "dirigible" and this term is still sometimes used to mean an airship. In modern usage, balloon usually refers to an unpowered aerostat.
Blimp.
A blimp is a non-rigid aerostat. In American usage it refers specifically to a non-rigid type of dirigible balloon or airship. In British usage it refers to any non-rigid aerostat, including barrage balloons and other kite balloons, having a streamlined shape and stabilising tail fins.
Zeppelin.
The term zeppelin is a genericized trademark that originally referred to airships manufactured by the German Zeppelin Company, which pioneered the use of very large airships in the early years of the twentieth century. The initials LZ, for "Luftschiff Zeppelin" (German for "Zeppelin airship"), usually prefixed their craft's serial identifiers.
In technical usage, "rigid airship" is the term used for all aircraft of this type, with "zeppelin" referring only to aircraft of that manufacture.
In modern common usage, the terms "zeppelin" and "airship" are used interchangeably for any type of rigid airship.
Construction.
The two main parts of an airship are its gas-containing envelope and a gondola or similar structure slung beneath and containing crew and other equipment. The engines may be mounted in the gondola or elsewhere off the envelope.
Structure.
The basic structure of an airship may be rigid, semi-rigid or non-rigid, as described.
Envelope.
The envelope itself is the outer surface, usually surrounding one or more gas-bags and/or ballonets within it.
Fins at the rear of the envelope stabilise the airship, allowing it to fly straight. On some smaller designs these fins are themselves part of a gas bag and gain their shape only when inflated.
A few airships have been metal-clad, with rigid and nonrigid examples made. Each kind used a thin gastight metal envelope, rather than the usual rubber-coated fabric envelope. Only four metal-clad ships are known to have been built, and only two actually flew: Schwarz's first aluminum rigid airship of 1893 collapsed, while his second flew; the nonrigid ZMC-2 built for the US Navy flew from 1929 to 1941 when it was scrapped as too small for operational use on anti-submarine patrols; while the 1929 nonrigid Slate Aircraft Corporation "City of Glendale" collapsed on its first flight attempt. Both nonrigid ships nevertheless had strong metal monocoque envelopes which, while they maintained their shape uninflated, required an overpressure during flight.
Lifting gas.
Early airships used hydrogen as their lifting gas, which is the lightest available. Typically it was generated during the filling process, by reacting dilute sulphuric acid with metal filings. The first hydrogen balloon in 1783 used iron filings, while the British Nulli Secundus of 1907 used zinc.
Later, the USA began to use helium because it is non-flammable and has 92.7% of the buoyancy (lifting power) of hydrogen. Following a series of airship disasters in the 1930s, and especially the Hindenburg disaster where the airship burst into flames, hydrogen fell into disuse.
Thermal airships use a heated lifting gas, usually air, in a fashion similar to hot air balloons. The first to do so was flown in 1973 by the British company Cameron Balloons.
Gondola.
The term "gondola" is used to describe a crew car of an airship, slung beneath the centre of the envelope. These may be short, for cockpit and landing gear alone, or longer to provide passenger space. Early gondolas were open structures slung beneath the envelope, later ones were enclosed and hung directly from the internal framing. A nonrigid blimp carries all of its passengers within a gondola. Rigid airships may have further passenger or cargo space inside the envelope. The large airship "Graf Zeppelin" was noted for its distinctively short passenger gondola, mounted far forward so as to improve ground clearance. The majority of crew accommodation and cargo holds were placed inside the envelope.
Propulsion and control.
Small airships carry their engine(s) in their gondola. Where there were multiple engines on larger airships, these were placed in separate nacelles, termed "power cars" or "engine cars". To allow asymmetric thrust to be applied for maneuvering, these power cars were mounted towards the sides of the envelope, away from the centre line gondola. This also raised them above the ground, reducing the risk of a propeller strike when landing. Widely spaced power cars were also termed "wing cars", from the use of "wing" to mean being on the side of something, as in a theater, rather than the aerodynamic device. These engine cars carried a crew during flight who maintained the engines as needed, but who also worked the engine controls, throttle etc., mounted directly on the engine. Instructions were relayed to them from the pilot's station by a telegraph system, as on a ship.
While elevators and swivelling propellers provide fine control of altitude, larger changes of height used to be controlled by either venting gas to lose altitude or dropping ballast to gain altitude. Large airships typically carried several water tanks fore and aft, allowing them to adjust longitudinal trim as well as height. Some modern designs instead pump lifting gas between the gas bags and storage cylinders.
History.
Early pioneers.
In 1670 the Jesuit Father Francesco Lana de Terzi, sometimes referred to as the "Father of Aeronautics", published a description of an "Aerial Ship" supported by four copper spheres from which the air was evacuated. Although the basic principle is sound, such a craft was unrealizable then and remains so to the present day, since external air pressure would cause the spheres to collapse unless their thickness was such as to make them too heavy to be buoyant. A hypothetical craft constructed using this principle is known as a "Vacuum airship".
A more practical dirigible airship was described by Lieutenant Jean Baptiste Marie Meusnier in a paper entitled "Mémoire sur l’équilibre des machines aérostatiques" (Memorandum on the equilibrium of aerostatic machines) presented to the French Academy on 3 December 1783. The 16 water-color drawings published the following year depict a 260 ft streamlined envelope with internal ballonnets that could be used for regulating lift: this was attached to a long carriage that could be used as a boat if the vehicle was forced to land in water. The airship was designed to be driven by three propellers and steered with a sail-like aft rudder. In 1784 Jean-Pierre Blanchard fitted a hand-powered propeller to a balloon, the first recorded means of propulsion carried aloft. In 1785 he crossed the English Channel in a balloon equipped with flapping wings for propulsion and a birdlike tail for steering.
The 19th century saw continued attempts to add methods of propulsion to balloons. The Australian Dr. William Bland sent designs for his "Atmotic Airship" to the Great Exhibition held in London in 1851, where a model was displayed. This was an elongated balloon with a steam engine driving twin propellers suspended underneath. The lift of the balloon was estimated as 5 tons and the car with the fuel as weighing 3.5 tons, giving a payload of 1.5 tons. Bland believed that the machine could be driven at 80 km/h and could fly from Sydney to London in less than a week.
In 1852 Henri Giffard became the first person to make an engine-powered flight when he flew 27 km in a steam-powered airship. Airships would develop considerably over the next two decades. In 1872, the French naval architect Dupuy de Lome launched a large navigable balloon, which was driven by a large propeller turned by eight men. It was developed during the Franco-Prussian war and was intended as an improvement to the balloons used for communications between Paris and the countryside during the siege of Paris, but was completed only after the end of the war.
In 1872 Paul Haenlein flew an airship with an internal combustion engine running on the coal gas used to inflate the envelope, the first use of such an engine to power an aircraft. Charles F. Ritchel made a public demonstration flight in 1878 of his hand-powered one-man rigid airship, and went on to build and sell five of his aircraft.
In 1874 Micajah Clark Dyer filed US Patent 154,654 'Apparatus for Navigating the Air". It is believed successful trial flights were made between 1872-1874, but detailed dates are not available. The apparatus used a combination of wings and paddle wheels for navigation and propulsion. “In operating the machinery the wings receive an upward and downward motion, in the manner of the wings of a bird, the outer ends yielding as they are raised, but opening out and then remaining rigid while being depressed. The wings, if desired, may be set at an angle so as to propel forward as well as to raise the machine in the air. The paddle-wheels are intended to be used for propelling the machine, in the same way that a vessel is propelled in water. An instrument answering to a rudder is attached for guiding the machine. A balloon is to be used for elevating the flying ship, after which it is to be guided and controlled at the pleasure of its occupants.”. More details can be found in the book about his life.
In 1883 the first electric-powered flight was made by Gaston Tissandier, who fitted a 1.5 hp Siemens electric motor to an airship.
The first fully controllable free-flight was made in 1884 by Charles Renard and Arthur Constantin Krebs in the French Army airship "La France". La France made the first flight of an airship that landed where it took off; the 170 ft long, 66000 cuft airship covered 8 km in 23 minutes with the aid of an 8.5 hp electric motor, and a 435 kg battery. It made seven flights in 1884 and 1885.
In 1888 the Campbell Air Ship, designed by Professor Peter C. Campbell, was made by the Novelty Air Ship Company. This was lost at sea in 1889 while being flown by Professor Hogan during an exhibition flight.
In 1888–97 Dr. Frederich Wölfert built three airships powered by Daimler Motoren Gesellschaft-built petrol engines, the last of which caught fire in flight and killed both occupants in 1897. The 1888 version used a 2 hp single cylinder Daimler engine and flew 10 km from Canstatt to Kornwestheim.
In 1897 an airship with an aluminum envelope was built by the Hungarian engineer David Schwarz. It made its first flight at Tempelhof field in Berlin after Schwarz had died. His widow, Melanie Schwarz, was paid 15,000 marks by Count Ferdinand von Zeppelin to release the industrialist Carl Berg from his exclusive contract to supply Schwartz with aluminium.
Early 20th century.
In July 1900 the Luftschiff Zeppelin LZ1 made its first flight. This led to the most successful airships of all time: the Zeppelins, named after Count von Zeppelin who began working on rigid airship designs in the 1890s, leading to the flawed LZ1 in 1900 and the more successful LZ2 in 1906. The Zeppelin airships had a framework composed of triangular lattice girders covered with fabric which contained separate gas cells. At first multiplane tail surfaces were used for control and stability: later designs had simpler later cruciform tail surfaces. The engines and crew were accommodated in "gondolas" hung beneath the hull driving propellers attached to the sides of the frame by means of long drive shafts. Additionally, there was a passenger compartment (later a bomb bay) located halfway between the two engine compartments.
Alberto Santos-Dumont was a wealthy Brazilian who lived in France and had a passion for flying. He designed 18 balloons and dirigibles, including the first practical dirigible airship, before turning his attention to fixed-winged aircraft.
On 19 October 1901 he flew his airship "Number 6", a small semi-rigid with a detached keel, from the Parc Saint Cloud to and around the Eiffel Tower and back in under thirty minutes. This feat earned him the Deutsch de la Meurthe prize of 100,000 francs. Many inventors were inspired by Santos-Dumont's small airships and a veritable airship craze began worldwide. Many airship pioneers, such as the American Thomas Scott Baldwin, financed their activities through passenger flights and public demonstration flights. Stanley Spencer built the first British airship with funds from advertising baby food on the sides of the envelope. Others, such as Walter Wellman and Melvin Vaniman, set their sights on loftier goals, attempting two polar flights in 1907 and 1909, and two trans-Atlantic flights in 1910 and 1912.
In 1902, the Spanish engineer Leonardo Torres Quevedo published details of an innovative airship design in Spain and France. With a non-rigid body and internal bracing wires, it overcame the flaws of these types of aircraft as regards both rigid structure (zeppelin type) and flexibility, providing the airships with more stability during flight, and the capability of using heavier engines and a greater passenger load. In 1905, helped by Captain A. Kindelán, he built the airship "España" at the Guadalajara military base. Next year he patented his design without attracting official interest. In 1909 he patented an improved design which he offered to the French Astra company, who started mass-producing it in 1911 as the Astra-Torres airship. The distinctive three-lobed design was widely used during the Great War by the Entente powers.
Other airship builders were also active before the war: from 1902 the French company Lebaudy Frères specialized in semirigid airships such as the "Patrie" and the "République", designed by their engineer Henri Julliot, who later worked for the American company Goodrich; the German firm Schütte-Lanz built the wooden-framed SL series from 1911, introducing important technical innovations; another German firm Luft-Fahrzeug-Gesellschaft built the "Parseval-Luftschiff" (PL) series from 1909, and Italian Enrico Forlanini's firm had built and flown the first two Forlanini airships.
In Britain, the Army built their first dirigible, the "Nulli Secundus", in 1907. The Navy ordered the construction of an experimental rigid in 1908. Officially known as His Majesty's Airship No. 1 and nicknamed the "Mayfly", it broke its back in 1911 before making a single flight. Work on a successor did not start until 1913.
In 1910 Walter Wellman unsuccessfully attempted an aerial crossing of the Atlantic Ocean in the airship "America".
World War I.
The prospect of airships as bombers had been recognized in Europe well before the airships were up to the task. H. G. Wells' "The War in the Air" (1908) described the obliteration of entire fleets and cities by airship attack. The Italian forces became the first to use dirigibles for a military purpose during the Italo–Turkish War, the first bombing mission being flown on 10 March 1912. It was World War I, however, that marked the airship's real debut as a weapon. The Germans, French and Italians all used airships for scouting and tactical bombing roles early in the war, and all learned that the airship was too vulnerable for operations over the front. The decision to end operations in direct support of armies was made by all in 1917.
Many in the German military believed they had found the ideal weapon with which to counteract British naval superiority and strike at Britain itself. More realistic airship advocates believed the zeppelin's value was as a long range scout/attack craft for naval operations. Raids on England began in January 1915 and peaked in 1916: following losses to the British defenses only a few raids were made in 1917-8, the last in August 1918. Zeppelins proved to be terrifying but inaccurate weapons. Navigation, target selection and bomb-aiming proved to be difficult under the best of conditions and the cloud cover that were frequently encountered by the airships reduced accuracy even further. The physical damage done by airships over the course of the war was insignificant, and the deaths that they caused amounted to a few hundred. Nevertheless the raid caused a significant diversion of British resources to defense efforts. The airships were initially immune to attack by aircraft and antiaircraft guns: as the pressure in their envelopes was only just higher than ambient air, holes had little effect. But following the introduction of a combination of incendiary and explosive ammunition in 1916 their flammable hydrogen lifting gas made them vulnerable to the defending aeroplanes. Several were shot down in flames by British defenders, and many others destroyed in accidents. New designs capable of reaching greater altitude were developed, but although this made them immune from attack it made their bombing accuracy even worse.
Countermeasures by the British included sound detection equipment, searchlights and anti-aircraft artillery, followed by night fighters in 1915. One tactic used early in the war, when their limited range meant the airships had to fly from forward bases and the only zeppelin production facilities were in Friedrichshafen, was the bombing of airship sheds by the British Royal Naval Air Service. Later in the war, the development of the aircraft carrier led to the first successful carrier-based air strike in history: on the morning of 19 July 1918 seven Sopwith 2F.1 Camels were launched from HMS "Furious" and struck the airship base at Tondern, destroying the zeppelins L 54 and L 60.
The British Army had abandoned airship development in favour of aeroplanes by the start of the war, but the Royal Navy had recognized the need for small airships to counteract the submarine and mine threat in coastal waters. Beginning in February 1915, they began to develop the SS (Sea Scout) class of blimp. These had a small envelope of 1,699-1,982 m³ (60–70,000 ft³) and at first used aircraft fuselages without the wing and tail surfaces as control cars. Eventually more advanced blimps with purpose built gondolas were built. The NS class (North Sea) were largest and most effective nonrigid airships in British service. These had a gas capacity of 360000 cuft, a crew of 10 and an endurance of 24 hours. Six 230 lb bombs were carried, as well as three to five machine guns. British blimps were used for scouting, mine clearance, and convoy patrol duties. During the war, the British operated over 200 nonrigid airships. Several were sold to Russia, France, the United States, and Italy. The large number of trained crews, low attrition rate and constant experimentation in handling techniques meant that at the war's end Britain was the world leader in nonrigid airship technology.
The Royal Navy continued development of rigid airships until the end of the war. Eight rigid airships had been completed by the armistice, (No. 9r, four 23 Class, two R23X Class and one R31 Class), although several more were in an advanced state of completion by the war's end.
Both France and Italy continued to use airships throughout the war. France preferred the nonrigid type, whereas Italy flew 49 semirigid airships in both the scouting and bombing roles.
Aeroplanes had essentially replaced airships as bombers by the end of the war, and Germany's remaining zeppelins were destroyed by their crews, scrapped or handed over to the Allied powers as war reparations. The British rigid airship program, which had mainly been a reaction to the potential threat of the German airships, was wound down.
The interwar period.
A number of nations operated airships between the two world wars. Britain, the United States and Germany were the only constructors of rigid airships, with Italy and France making limited use of Zeppelins handed over as war reparations. Italy, the Soviet Union, the United States and Japan mainly operated semirigid airships.
Under the terms of the Treaty of Versailles Germany was not allowed to build airships of greater capacity than a million cubic ft. Two small passenger airships, LZ 120 "Bodensee" and its sister-ship LZ 121 "Nordstern", were built immediately after the war but were confiscated following the sabotage of the wartime Zeppelins that were to have been handed over as war reparations: "Bodensee" was given to Italy and LZ 121 "Nordstern" to France. On May 12, 1926, the Italian semirigid airship "Norge" was the first aircraft to fly over the North Pole.
The British R33 and R34 were near-identical copies of the German L 33 which had come down almost intact in Yorkshire on 24 September 1916. Despite being almost three years out of date by the time they were launched in 1919, they became two of the most successful airships in British service. The creation of the Royal Air Force (RAF) in early 1918 created a hybrid British airship program. The RAF was not interested in airships and the Admiralty was, so a deal was made where the Admiralty would design any future military airships while the RAF would handle manpower, facilities and operations. On 2 July 1919, R34 began the first double crossing of the Atlantic by an aircraft. It landed at Mineola, Long Island on 6 July after 108 hours in the air. The return crossing began on 8 July and took 75 hours. This feat failed to generate enthusiasm for continued airship development, and the British airship program was rapidly wound down.
During World War One the US Navy acquired it first airship, the DH-1, but it was destroyed while being inflated shortly after delivery to the Navy. After the war the US Navy contracted to buy the R 38 which was being built in Britain, but before it was handed over to the US it was destroyed because of a structural failure during a test flight.
America then started constructing the USS "Shenandoah", designed by the Bureau of Aeronautics and based on the Zeppelin L 49. Assembled in Hangar No. 1 and first flown on 4 September 1923 at Lakehurst, New Jersey. It was the first airship to be inflated with the noble gas helium, which was then so scarce that the "Shenandoah" contained most of the world's supply. A second airship, USS "Los Angeles", was built by the Zeppelin company as compensation for the airships which should have been handed over as war reparations according to the terms of the Versailles Treaty but had been sabotaged by their crews. This construction order saved the Zeppelin works from the threat of closure. The success of the "Los Angeles", which was flown successfully for 8 years, encouraged the US Navy to invest in its own, larger airships. When the "Los Angeles" was delivered, the two airships had to share the limited supply of helium, and thus alternated operating and overhauls.
In 1922 Sir Dennistoun Burney suggested a plan for a subsidised air service throughout the British Empire using airships (the Burney Scheme). Following the coming to power of Ramsay MacDonald's Labour government in 1924, the Burney scheme was transformed into the Imperial Airship Scheme, under which two airships were built, one by a private company, and the other by the Royal Airship Works under Air Ministry control. The two designs were radically different. The "capitalist" ship, the "R100", was more conventional, while the "socialist" ship, the R101, had many innovative design features. Construction of both took longer than expected, and the airships did not fly until 1929. Neither airship was capable of the service intended, though the R100 did complete a proving flight to Canada and back in 1930. However, on 5 October 1930 the R101, which had not been thoroughly tested after major modifications, crashed on its maiden voyage at Beauvais in France killing 48 of the 54 people aboard. Among the dead were the craft's chief designer and the Secretary of State for Air. The disaster put an end to further British airship development.
The Locarno Treaties of 1925 lifted the restrictions on German airship construction, and the Zeppelin company started construction of the "Graf Zeppelin" (LZ 127), the largest airship that could be built in the company's existing shed, and intended to stimulate interest in passenger airships. The "Graf Zeppelin" burned "blau gas", similar to propane, stored in large gas bags below the hydrogen cells, as fuel. Since its density was similar to that of air, it avoided the weight change as fuel was used, and thus the need to valve hydrogen. The "Graf Zeppelin" was a great success and had an impressive safety record, flying over 1600000 km (including the first circumnavigation of the globe by air) without a single passenger injury.
The US Navy experimented with the use of airships as airborne aircraft carriers, developing an idea pioneered by the British. The USS Los Angeles was used for initial experiments, and the USS "Akron" and "Macon", the world's largest at the time, were used to test the principle in naval operations. Each carried four F9C Sparrowhawk fighters in its hangar, and could carry a fifth on the trapeze. The idea had mixed results. By the time the Navy started to develop a sound doctrine for using the ZRS-type airships, the last of the two built, USS "Macon", had been lost. The seaplane had become more capable, and was considered a better investment.
Eventually the US Navy lost all three American-built rigid airships to accidents. USS "Shenandoah" flew into a severe thunderstorm over Noble County, Ohio while on a poorly planned publicity flight on 3 September 1925. It broke into pieces, killing 14 of its crew. USS "Akron" was caught in a severe storm and flown into the surface of the sea off the shore of New Jersey on 3 April 1933. It carried no life boats and few life vests, so 73 of its crew of 76 died from drowning or hypothermia.
USS "Macon" was lost after suffering a structural failure offshore near Point Sur Lighthouse on 12 February 1935. The failure caused a loss of gas, which was made much worse when the aircraft was driven over pressure height causing it to lose too much helium to maintain flight. Only 2 of its crew of 83 died in the crash thanks to the inclusion of life jackets and inflatable rafts after the "Akron" disaster.
The Empire State Building was completed in 1931 with a dirigible mast, in anticipation of passenger airship service. Various entrepreneurs experimented with commuting and shipping freight via airship.
In the 1930s the German Zeppelins successfully competed with other means of transport. They could carry significantly more passengers than other contemporary aircraft while providing amenities similar to those on ocean liners, such as private cabins, observation decks, and dining rooms. Less importantly, the technology was potentially more energy-efficient than heavier-than-air designs. Zeppelins were also faster than ocean liners. On the other hand, operating airships was quite involved. Often the crew would outnumber passengers, and on the ground large teams were necessary to assist mooring and very large hangars were required at airports.
By the mid-1930s only Germany still pursued airship development. The Zeppelin company continued to operate the "Graf Zeppelin" on passenger service between Frankfurt and Recife in Brazil, taking 68 hours. Even with the small "Graf Zeppelin", the operation was almost profitable. In the mid-1930s work started to build an airship designed specifically to operate a passenger service across the Atlantic. The "Hindenburg" (LZ 129) completed a very successful 1936 season carrying passengers between Lakehurst, New Jersey and Germany. However, 1937 started with the most spectacular and widely remembered airship accident. Approaching the mooring mast minutes before landing on 6 May 1937, the "Hindenburg" burst into flames and crashed. Of the 97 people aboard, 36 died: 13 passengers, 22 aircrew, and one American ground-crewman. The disaster happened before a large crowd, was filmed and a radio news reporter was recording the arrival. This was a disaster which theatergoers could see and hear in newsreels. The "Hindenburg" disaster shattered public confidence in airships, and brought a definitive end to their "golden age". The day after the "Hindenburg" crashed, the "Graf Zeppelin" landed at the end of its flight from Brazil. This was the last international passenger airship flight.
"Hindenburg"‍ '​s sister ship, the "Graf Zeppelin II" (LZ 130), could not perform commercial passenger flights without helium, which the United States refused to sell. The "Graf Zeppelin" flew some test flights and conducted electronic espionage until 1939 when it was grounded due to the start of the war. The last two Zeppelins were scrapped in 1940.
Development of airships continued only in the United States, and to a smaller extent, the Soviet Union. The Soviet Union had several semirigid and nonrigid airships. The semirigid dirigible SSSR-V6 OSOAVIAKhIM was among the largest of these craft, and it set the longest endurance flight at the time of over 130 hours. However, it crashed into a mountain in 1938, killing 13 of the 19 people on board. While this was a severe blow to the Soviet airship program, they continued to operate nonrigid airships until 1950.
World War II.
While Germany determined that airships were obsolete for military purposes in the coming war and concentrated on the development of aeroplanes, the United States pursued a program of military airship construction even though it had not developed a clear military doctrine for airship use. When the Japanese attacked Pearl Harbor on 7 December 1941, bringing the United States into World War II, the U.S. Navy had 10 nonrigid airships:
Only "K"- and "TC"-class airships were suitable for combat and they were quickly pressed into service against Japanese and German submarines which were then sinking American shipping within visual range of the American coast. U.S. Navy command, remembering airship's anti-submarine success in World War I, immediately requested new modern antisubmarine airships and on 2 January 1942 formed the ZP-12 patrol unit based in Lakehurst from the four "K" airships. The ZP-32 patrol unit was formed from two "TC" and two "L" airships a month later, based at NAS Moffett Field in Sunnyvale, California. An airship training base was created there as well. The status of submarine-hunting Goodyear airships in the early days of World War II has created significant confusion. Although various accounts refer to airships "Resolute" and "Volunteer" as operating as "privateers" under a Letter of Marque, Congress never authorized a commission, nor did the President sign one.
In the years 1942–44, approximately 1,400 airship pilots and 3,000 support crew members were trained in the military airship crew training program and the airship military personnel grew from 430 to 12,400. The U.S. airships were produced by the Goodyear factory in Akron, Ohio. From 1942 till 1945, 154 airships were built for the U.S. Navy (133 "K"-class, 10 "L"-class, seven "G"-class, four "M"-class) and five "L"-class for civilian customers (serial numbers "L-4" to "L-8").
The primary airship tasks were patrol and convoy escort near the American coastline. They also served as an organization centre for the convoys to direct ship movements, and were used in naval search and rescue operations. Rarer duties of the airships included aerophoto reconnaissance, naval mine-laying and mine-sweeping, parachute unit transport and deployment, cargo and personnel transportation. They were deemed quite successful in their duties with the highest combat readiness factor in the entire US air force (87%).
During the war, some 532 ships without airship escort were sunk near the US coast by enemy submarines. Only one ship, the tanker "Persephone", of the 89,000 or so in convoys escorted by blimps was sunk by the enemy. Airships engaged submarines with depth charges and, less frequently, with other on-board weapons. They were excellent at driving submarines down, where their limited speed and range prevented them from attacking convoys. The weapons available to airships were so limited that until the advent of the homing torpedo they had little chance of sinking a submarine.
Only one airship was ever destroyed by U-boat: on the night of 18/19 July 1943, a "K"-class airship ("K-74") from ZP-21 division was patrolling the coastline near Florida. Using radar, the airship located a surfaced German submarine. The K-74 made her attack run but the U-boat opened fire first. "K-74"‍ '​s depth charges did not release as she crossed the U-boat and the "K-74" received serious damage, losing gas pressure and an engine but landing in the water without loss of life. The crew was rescued by patrol boats in the morning, but one crewman, Aviation Machinist's Mate Second Class Isadore Stessel, died from a shark attack. The U-Boat, "submarine U-134", was slightly damaged and the next day or so was attacked by aircraft, sustaining damage that forced it to return to base. It was finally sunk on 24 August 1943 by a British Vickers Wellington near Vigo, Spain.
Fleet Airship Wing One operated from Lakehurst, NJ, Glynco, GA, Weeksville, NC, South Weymouth NAS Massachusetts, Brunswick NAS and Bar Harbor ME, Yarmouth, Nova Scotia, and Argentia, Newfoundland.
Some US airships saw action in the European war theater. In 1944-45, the U.S. Navy moved an entire squadron of eight Goodyear K class blimps (K-123, K-130, K-109, K-134, K-101, K-112, K-89, & K-114) with flight and maintenance crews from Weeksville Naval Air Station in North Carolina to Naval Air Station Port Lyautey, French Morocco. Their mission was to locate and destroy German U-boats in the relatively shallow waters around the Strait of Gibraltar where magnetic anomaly detection (MAD) was viable. PBY aircraft had been searching these waters but MAD required low altitude flying that was dangerous at night for these aircraft. The blimps were considered a perfect solution to establish a 24/7 MAD barrier (fence) at the Straits of Gibraltar with the PBYs flying the day shift and the blimps flying the night shift. The first two blimps (K-123 & K-130) left South Weymouth NAS on 28 May 1944 and flew to Argentia, Newfoundland, the Azores, and finally to Port Lyautey where they completed the first transatlantic crossing by nonrigid airships on 1 June 1944. The blimps of USN Blimp Squadron ZP-14 (Blimpron 14, aka "The Africa Squadron") also conducted mine-spotting and mine-sweeping operations in key Mediterranean ports and various escorts including the convoy carrying United States President Franklin D. Roosevelt and British Prime Minister Winston Churchill to the Yalta Conference in 1945. Airships from the ZP-12 unit took part in the sinking of the last U-Boat before German capitulation, sinking "U-881" on 6 May 1945 together with destroyers Atherton and Mobery.
Other airships patrolled the Caribbean, Fleet Airship Wing Two, Headquartered at NAS Richmond, Florida, covered the Gulf of Mexico from Richmond and Key West, FL, Houma, Louisiana, as well as Hitchcock and Brownsville, Texas. FAW 2 also patrolled the northern Caribbean from San Julian, the Isle of Pines (now called Isla de la Juventud) and Guantanamo Bay, Cuba as well as Vernam Field, Jamaica.
Navy blimps of Fleet Airship Wing Five, (ZP-51) operated from bases in Trinidad, British Guiana and Paramaribo, Suriname. Fleet Airship Wing Four operated along the coast of Brazil. Two squadrons, VP-41 and VP-42 flew from bases at Amapá, Igarape Assu, Sao Luiz, Fortaleza, Fernando de Noronha, Recife, Maceió, Ipitanga (near Salvador, Bahia), Caravellas, Vitoria and the hangar built for the "Graf Zeppelin" at Santa Cruz, Rio de Janeiro.
Fleet Airship Wing Three operated squadrons, ZP-32 from Moffett Field, ZP-31 at NAS Santa Ana, and ZP-33 at NAS Tillamook, Oregon. Auxiliary fields were at Del Mar, Lompoc, Watsonville and Eureka, CA, North Bend and Astoria, Oregon, as well as Shelton and Quillayute in Washington.
From 2 January 1942 until the end of war airship operations in the Atlantic, the airships of the Atlantic fleet made 37,554 flights and flew 378,237 hours. Of the over 70,000 ships in convoys protected by blimps, only one was sunk by a submarine while under blimp escort.
The Soviet Union used a single airship during the war. The "W-12", built in 1939, entered service in 1942 for paratrooper training and equipment transport. It made 1432 runs with 300 metric tons of cargo until 1945. On 1 February 1945, the Soviets constructed a second airship, a "Pobeda"-class ("Victory"-class) unit (used for mine-sweeping and wreckage clearing in the Black Sea) which crashed on 21 January 1947. Another "W"-class - W-12bis "Patriot" - was commissioned in 1947 and was mostly used for crew training, parades and propaganda.
Postwar period.
Although airships are no longer used for passenger transport, they are still used for other purposes such as advertising, sightseeing, surveillance, research and advocacy.
In the 1980s, Per Lindstrand and his team introduced the "GA-42" airship, the first airship to use fly-by-wire flight control which considerably reduced the pilot's workload.
The world's largest thermal airship (300,000 cubic feet/8,495 m³) was constructed by the Per Lindstrand company for French botanists in 1993. The "AS-300" carried an under-slung raft, which was positioned by the airship on top of tree canopies in the rain forest, allowing the botanists to carry out their treetop research without significant damage to the rainforest. When research was finished at a given location, the airship returned to pick up and relocate the raft.
In the spring of 2004, Lindstrand Technologies supplied the world's first fully functional unmanned airship to the Ministry of Defense in Spain. This airship carried a 42 kg classified payload and its surveillance mission was also classified. Four years later, this airship, which is designated "GA-22", still flies on an almost daily basis.
In June 1987, the US Navy awarded a US$168.9 million contract to Westinghouse Electric and Airship Industries of the UK to demonstrate whether a blimp could be used as an airborne platform to detect the threat of sea-skimming missiles, such as the Exocet. At 2.5 million cubic feet, the Westinghouse/Airship Industries Sentinel 5000 (Redesignated YEZ-2A by the U. S. Navy) prototype design was to have been the largest blimp ever constructed. However, additional funding for the Naval Airship Program was killed in 1995 and development was discontinued.
The "CA-80" airship, which was launched in 2000 by Shanghai Vantage Airship Manufacture Co., Ltd., had a successful trial flight in September 2001. This model of airship was designed for the purpose of advertisement and propagation, air-photo, scientific test, tour and surveillance duties. It was certified as a grade-A Hi-Tech introduction program (№ 20000186) in Shanghai, China. The CAAC authority granted a type design approval and certificate of airworthiness for the model CA-80 airship, which has been published in the Jane's All the World's Aircraft for five times (2003–08).
In the 1990s, the Zeppelin company reentered the airship business. Their new model, designated the Zeppelin NT, made its maiden flight on 18 September 1997. s of 2009[ [update]], there were four NT aircraft flying, a fifth completed in March 2009 and an expanded NT-14 (14,000 cubic meters of helium, capable of carrying 19 passengers) under construction. One was sold to a Japanese company, and was planned to be flown to Japan in the summer of 2004. Due to delays getting permission from the Russian government, the company decided to transport the airship to Japan by ship. One of the four NT craft is in South Africa carrying diamond detection equipment from De Beers, an application at which the very stable low vibration NT platform excels. The project included design adaptations for high heat operation and desert climate, as well as a separate mooring mast and a very heavy mooring truck. NT-4 belongs to Airship Ventures of Moffett Field, Mountain View in the San Francisco Bay Area, and provides sight-seeing tours.
Blimps are used for advertising and as TV camera platforms at major sporting events. The most iconic of these are the Goodyear Blimps. Goodyear operates three blimps in the United States, and The Lightship Group, now , operates up to 19 advertising blimps around the world. Airship Management Services owns and operates three Skyship 600 blimps. Two operate as advertising and security ships in North America and the Caribbean. Airship Ventures operates a Zeppelin NT for advertising, passenger service and special mission projects. They are the only airship operator in the U.S. authorized to fly commercial passengers.
Skycruise Switzerland AG owns and operates two Skyship 600 blimps. One operates regularly over Switzerland used on sightseeing tours.
The Switzerland-based Skyship 600 has also played other roles over the years. For example, it was flown over Athens during the 2004 Summer Olympics as a security measure. In November 2006, it carried advertising calling it "The Spirit of Dubai" as it began a publicity tour from London to Dubai, UAE on behalf of The Palm Islands, the world's largest man-made islands created as a residential complex.
Los Angeles-based Worldwide Aeros Corp. produces FAA Type Certified Aeros 40D Sky Dragon airships.
In May 2006, the US Navy began to fly airships again after a hiatus of nearly 44 years. The program uses a single American Blimp Company A-170 nonrigid airship, with designation MZ-3A. Operations focus on crew training and research, and the platform integrator is Northrop Grumman. The program is directed by the Naval Air Systems Command and is being carried out at NAES Lakehurst, the original centre of U.S. Navy lighter-than-air operations in previous decades.
In November 2006, the U.S. Army bought an A380+ airship from American Blimp Corporation through a Systems level contract with Northrop Grumman and Booz Allen Hamilton. The airship started flight tests in late 2007, with a primary goal of carrying 2500 lb of payload to an altitude of 15000 ft under remote control and autonomous waypoint navigation. The program will also demonstrate carrying 1000 lb of payload to 20000 ft The platform could be used for Multi-Intelligence collections. In 2008, the "CA-150" airship was launched by Vantage Airship. This is an improved modification of model "CA-120" and completed manufacturing in 2008. With larger volume and increased passenger capacity, it is the largest manned nonrigid airship in China at present.
An airship was prominently featured in the James Bond film "A View to a Kill", released in 1985. The Skyship 500 had the livery of Zorin Industries.
In late June 2014 the Electronic Frontier Foundation flew the GEFA-FLUG AS 105 GD/4 blimp AE Bates (owned by, and in conjunction with, Greenpeace) over the NSA's Bluffdale Utah Data Center in protest.
Postwar projects.
Hybrid designs such as the Heli-Stat airship/helicopter, the Aereon aerostatic/aerodynamic craft, and the CycloCrane (a hybrid aerostatic/rotorcraft), struggled to take flight. The Cyclocrane was also interesting in that the airship's envelope rotated along its longitudinal axis.
In 2005, a short-lived project of the US Defense Advanced Research Projects Agency (DARPA) was Walrus HULA which explored the potential for using airships as long-distance, heavy lift craft. The primary goal of the research program was to determine the feasibility of building an airship capable of carrying 500 ST of payload a distance of 12000 mi and land on an unimproved location without the use of external ballast or ground equipment (such as masts). In 2005, two contractors, Lockheed Martin and US Aeros Airships were each awarded approximately $3 million to do feasibility studies of designs for WALRUS. Congress removed funding for Walrus HULA in 2006.
Modern airships.
Military airships.
In 2010, the US Army awarded a $517 million (£350.6 million) contract to Northrop Grumman and partner Hybrid Air Vehicles, to develop a Long Endurance Multi-Intelligence Vehicle (LEMV) system, in the form of three HAV 304's. The project was cancelled in February 2012, due to it being behind schedule and over budget; also the forthcoming US withdrawal from Afghanistan where it was intended to be deployed.
A-NSE, a French company, manufactures and operates airships and aerostats. For 2 years, A-NSE has been testing its airships for the French Army. Airships and aerostats are operated to provide intelligence, surveillance, and reconnaissance (ISR) support. Many innovations are developed by A-NSE : water ballast take-off and landing system, variable geometry envelope, thrust–vectoring system etc.…
The US government has funded two major projects in the high altitude arena. The Composite Hull High Altitude Powered Platform (CHHAPP) is sponsored by US Army Space and Missile Defense Command. This aircraft is also sometimes called "HiSentinel High-Altitude Airship". This prototype ship made a five-hour test flight in September 2005. The second project, the high-altitude airship (HAA), is sponsored by DARPA. In 2005, DARPA awarded a contract for nearly $150 million to Lockheed Martin for prototype development. First flight of the HAA was planned for 2008 but suffered programmatic and funding delays. The HAA project evolved into the High Altitude Long Endurance-Demonstrator (HALE-D). The U.S. Army and Lockheed Martin launched the first-of-its kind HALE-D on July 27, 2011. After attaining an altitude of 32000 ft, due to an anomaly, the company decided to abort the mission. The airship made a controlled descent in an unpopulated area of southwest Pennsylvania.
On 31 January 2006 Lockheed Martin made the first flight of their secretly built hybrid airship designated the P-791. The design is very similar to the SkyCat, unsuccessfully promoted for many years by the British company Advanced Technologies Group (ATG). Although Lockheed Martin is developing a design for the DARPA WALRUS HULA project, it claimed that the P-791 is unrelated to WALRUS. Nonetheless, the design represents an approach that may well be applicable to WALRUS. Some believe that Lockheed Martin had used the secret P-791 program as a way to get a head start on the other WALRUS competitor, US Aeros Airships.
Passenger transport.
In the 1990s, the successor of the original Zeppelin company in Friedrichshafen, the "Zeppelin Luftschifftechnik GmbH", reengaged in airship construction. The first experimental craft (later christened "Friedrichshafen") of the type ″Zeppelin NT″ flew in September 1997. Though larger than common blimps, the "Neue Technologie" (New Technology) zeppelins are much smaller than their giant ancestors and not actually Zeppelin-types in the classical sense. They are sophisticated semirigids. Apart from the greater payload, their main advantages compared to blimps are higher speed and excellent maneuverability. Meanwhile, several "Zeppelin NT" have been produced and operated profitably in joyrides, research flights and similar applications.
In June 2004, a Zeppelin NT was sold for the first time to a Japanese company, Nippon Airship Corporation, for tourism and advertising mainly around Tokyo. It was also given a role at the 2005 Expo in Aichi. The aircraft began a flight from Friedrichshafen to Japan, stopping at Geneva, Paris, Rotterdam, Munich, Berlin, Stockholm and other European cities to carry passengers on short legs of the flight. However, Russian authorities denied overflight permission so the airship had to be dismantled and shipped to Japan rather than following the historic "Graf Zeppelin" flight from Germany to Japan.
In 2008, Airship Ventures Inc. began operations from Moffett Federal Airfield near Mountain View, California and until November 2012 offered tours of the San Francisco Bay Area for up to 12 passengers.
Exploration.
In November 2005, De Beers, the diamond mining company, launched an airship exploration program over the remote Kalahari desert. A Zeppelin, equipped with a Bell Geospace gravity gradiometer, is used to find potential diamond mines by scanning the local geography for low-density rock formations - so-called kimberlite pipes. On 21 September 2007, the airship was severely damaged by a whirlwind while in Botswana. One crew member, who was on watch aboard the moored craft, was slightly injured but released after overnight observation in hospital.
Thermal airships.
Several companies, such as Cameron Balloons in Bristol, United Kingdom, build hot-air airships. These combine the structures of both hot-air balloons and small airships. The envelope is the normal cigar shape, complete with tail fins, but is inflated with hot air instead of helium to provide the lifting force. A small gondola, carrying the pilot and passengers, a small engine, and the burners to provide the hot air are suspended below the envelope, beneath an opening through which the burners protrude.
Hot-air airships typically cost less to buy and maintain than modern helium-based blimps, and can be quickly deflated after flights. This makes them easy to carry in trailers or trucks and inexpensive to store. They are usually very slow moving, with a typical top speed of 25–30 km/h (15–20 mph, 6.7–8.9 m/s). They are mainly used for advertising, but at least one has been used in rainforests for wildlife observation, as they can be easily transported to remote areas.
Unmanned remotes.
Remote-controlled (RC) airships, a type of unmanned aerial system (UAS), are sometimes used for commercial purposes such as advertising and aerial video and photography as well as recreational purposes. They are particularly common as an advertising mechanism at indoor stadiums. While RC airships are sometimes flown outdoors, doing so for commercial purposes is illegal in the US. Commercial use of an unmanned airship must be certified under part 121.
Current design projects.
Today, with large, fast, and more cost-efficient fixed-wing aircraft and helicopters, it is unknown whether huge airships can operate profitably in regular passenger transport though, as energy costs rise, attention is once again returning to these lighter-than-air vessels as a possible alternative. At the very least, the idea of comparatively slow, "majestic" cruising at relatively low altitudes and in comfortable atmosphere certainly has retained some appeal. There have been some niches for airships in and after World War II, such as long-duration observations, antisubmarine patrol, platforms for TV camera crews, and advertising; these, however, generally require only small and flexible craft, and have thus generally been better fitted for cheaper (non-passenger) blimps.
Heavy lifting.
It has periodically been suggested that airships could be employed for cargo transport, especially delivering extremely heavy loads to areas with poor infrastructure over great distances. This has also been called roadless trucking. Also, airships could be used for heavy lifting over short distances (e.g. on construction sites); this is described as heavy-lift, short-haul. In both cases, the airships are heavy haulers. One recent enterprise of this sort was the "Cargolifter" project, in which a hybrid (thus not entirely Zeppelin-type) airship even larger than "Hindenburg" was projected. Around 2000, CargoLifter AG built the world's largest cantilever shop hall measuring 360 m long, 210 m wide and 107 m high about 60 km south of Berlin. In May 2002, the project was stopped for financial reasons; the company had to file bankruptcy. The enormous CargoLifter hangar was later converted to house the Tropical Islands Resort. Although no rigid airships are currently used for heavy lifting, hybrid airships are being developed for such purposes. John McPhee's "The Deltoid Pumpkin Seed" is the story of one company attempting this.
Metal-clad airships.
A metal-clad airship has a very thin metal envelope, rather than the usual fabric. The shell may be either internally braced or monocoque as in the ZMC-2 which flew many times in the 1920s, the only example ever to do so. The shell may be gas-tight as in a non-rigid blimp, or the design may employ internal gas bags as in a rigid airship. Compared to a fabric envelope the metal cladding is expected to be more durable.
Hybrid airships.
A hybrid airship is a general term for an aircraft that combines characteristics of heavier-than-air (aeroplane or helicopter) and lighter-than-air technology. Examples include helicopter/airship hybrids intended for heavy lift applications and dynamic lift airships intended for long-range cruising. It should be noted that most airships, when fully loaded with cargo and fuel, are usually ballasted to be heavier than air, and thus must use their propulsion system and shape to create aerodynamic lift, necessary to stay aloft. All airships can be operated to be slightly heavier than air at periods during flight (descent). However, the term "hybrid airship" refers to craft that obtain a significant portion of their lift from aerodynamic lift or other kinetic means.
For example, the Aeroscraft is a buoyancy assisted air vehicle that generates lift through a combination of aerodynamics, thrust vectoring and gas buoyancy generation and management, and for much of the time will fly heavier than air. Aeroscraft is Worldwide Aeros Corporation's continuation of DARPA's now cancelled Walrus HULA (Hybrid Ultra Large Aircraft) project.
Comparison with heavier-than-air aircraft.
The advantage of airships over aeroplanes is that static lift sufficient for flight is generated by the lifting gas and requires no engine power. This was an immense advantage before the middle of World War I and remained an advantage for long distance, or long duration operations until World War II. Modern concepts for high altitude airships include photovoltaic cells to reduce the need to land to refuel, thus they can remain in the air until consumables expire.
The disadvantages are that an airship has a very large reference area and comparatively large drag coefficient, thus a larger drag force compared to that of aeroplanes and even helicopters. Given the large frontal area and wetted surface of an airship, a practical limit is reached around 80 –. Thus airships are used where speed is not critical.
The gross lift capability of an airship is equal to the buoyant force minus the weight of the airship. This assumes standard air temperature and pressure conditions. Corrections are usually made for water vapor and impurity of lifting gas, as well as percentage of inflation of the gas cells at liftoff. Based on specific lift (lifting force per unit volume of gas), the greatest static lift is provided by hydrogen (11.15 N/m3 or 71 lbf/1000 cu ft) with helium (10.37 N/m3 or 66 lbf/1000 cu ft) a close second. At 6.13 N/m3 (39 lbf/1000 cu ft), steam is a distant third. Other cheap gases, such as methane, carbon monoxide, ammonia and natural gas have even less lifting capacity and are flammable, toxic, corrosive, or all three (neon is even more costly than helium, with less lifting capacity). Operational considerations such as whether the lift gas can be economically vented and produced in flight for control of buoyancy (as with hydrogen) or even produced as a byproduct of propulsion (as with steam) affect the practical choice of lift gas in airship designs.
In addition to static lift, an airship can obtain a certain amount of dynamic lift from its engines. Dynamic lift in past airships has been about 10% of the static lift. Dynamic lift allows an airship to "take off heavy" from a runway similar to fixed-wing and rotary-wing aircraft. However, this requires additional weight in engines, fuel and landing gear, negating some of the static lift capacity.
The altitude at which an airship can fly largely depends on how much lifting gas it can lose due to expansion before stasis is reached. The ultimate altitude record for a rigid airship was set in 1917 by the L-55 under the command of Hans-Kurt Flemming when he forced the airship to 24000 ft attempting to cross France after the "Silent Raid" on London. The L-55 lost lift during the descent to lower altitudes over Germany and crashed due to loss of lift. While such waste of gas was necessary for the survival of airships in the later years of World War I, it was impractical for commercial operations, or operations of helium-filled military airships. The highest flight made by a hydrogen-filled passenger airship was 5500 ft on the "Graf Zeppelin's" around the world flight. The practical limit for rigid airships was about 3000 ft, and for pressure airships around 8000 ft.
Modern airships use dynamic helium volume. At sea level altitude, helium only takes up a small part of the hull, while the rest is filled with air. As the airship ascends, the helium inflates with reduced outer pressure, and air is pushed out and released from the downward valve. This allows an airship to reach any altitude with balanced inner and outer pressure if the buoyancy is enough. Some civil aerostats could reach 100000 ft without explosion due to overloaded inner pressure.
The greatest disadvantage of the airship is size, which is essential to increasing performance. As size increases, the problems of ground handling increase geometrically. As the German Navy changed from the P class of 1915 with a volume of over 1100000 cuft to the larger Q class of 1916, the R class of 1917, and finally the W class of 1918, at almost 2200000 cuft ground handling problems reduced the number of days the Zeppelins were able to make patrol flights. This availability declined from 34% in 1915, to 24.3% in 1916 and finally 17.5% in 1918.
So long as the power-to-weight ratios of aircraft engines remained low and specific fuel consumption high, the airship had an edge for long range or duration operations. As those figures changed, the balance shifted rapidly in the aeroplane's favour. By mid-1917, the airship could no longer survive in a combat situation where the threat was aeroplanes. By the late 1930s, the airship barely had an advantage over the aeroplane on intercontinental over-water flights, and that advantage had vanished by the end of World War II.
This is in face-to-face tactical situations. Currently, a High-altitude airship project is planned to survey hundreds of kilometres as their operation radius, often much farther than the normal engagement range of a military aeroplane. For example, a radar mounted on a vessel platform 30 m high has radio horizon at 20 km range, while a radar at 18000 m altitude has radio horizon at 480 km range. This is significantly important for detecting low-flying cruise missiles or fighter-bombers.
Today, airships are used primarily for command, control and as a communication platform; to establish and maintain reliable and secure connectivity among all forces, provide transparent data across the echelons; precisely locate friendly and enemy forces; detect targets on an extended battlefield at a minimal exposure to enemy forces; real time targeting; navigation assistance; battle management; monitor radio conversations, etc.
Safety.
The most commonly used lifting gas, helium, is inert so presents no fire risk. Modern airships have a natural buoyancy and special design that offers a virtually zero catastrophic failure mode. A series of vulnerability tests were done by the UK Defence Evaluation and Research Agency DERA on a Skyship 600. Since the internal gas pressure was maintained at only 1–2% above the surrounding air pressure, the vehicle proved highly tolerant to physical damage or to attack by small-arms fire or missiles. Several hundred high-velocity bullets were fired through the hull, and even two hours later the vehicle would have been able to return to base. Ordnance passed through the envelope without causing critical helium loss. In all instances of light armament fire evaluated under both test and live conditions, the airship was able to complete its mission and return to base.
References.
Bibliography.
</dl>

</doc>
<doc id="58008" url="http://en.wikipedia.org/wiki?curid=58008" title="Bachem Ba 349">
Bachem Ba 349

The Bachem Ba 349 Natter (English: Colubrid, grass-snake) was a World War II German point-defence rocket-powered interceptor, which was to be used in a very similar way to a manned surface-to-air missile. After a vertical take-off, which eliminated the need for airfields, most of the flight to the Allied bombers was to be controlled by an autopilot. The primary role of the relatively untrained pilot was to aim the aircraft at its target bomber and fire its armament of rockets. The pilot and the fuselage containing the rocket-motor would then land using separate parachutes, while the nose section was disposable. The only manned vertical take-off flight on 1 March 1945 ended in the death of the test pilot, Lothar Sieber.
Development.
In 1943 "Luftwaffe" air superiority was being challenged by the Allies over the "Reich" and radical innovations were required to overcome the crisis. Surface-to-air missiles appeared to be a promising approach to counter the Allied strategic bombing offensive; a variety of projects were started, but invariably problems with the guidance and homing systems prevented any of these from attaining operational status. Providing the missile with a pilot, who could operate a weapon during the brief terminal approach phase, offered a solution. Submissions for a simple target defence interceptor were requested by the "Luftwaffe" in early 1944 under the umbrella of the "Emergency Fighter Program". A number of simple designs were proposed, including the Heinkel P.1077 "Julia", in which the pilot lay prone (on his stomach), to reduce the frontal area. The "Julia" was the front-runner for the contract. The initial plan was to launch the aircraft vertically, but this concept was later changed to a conventional horizontal take-off from a tricycle-wheeled trolley, similar to that used by the first eight prototypes of the Arado Ar 234 jet reconnaissance bomber.
Bachem's proposal.
Erich Bachem's BP-20 ("Natter") was a development from a design he had worked on at Fieseler, the Fi 166 concept, but considerably more radical than the other submissions. It was built using glued and nailed wooden parts with an armour-plated bulkhead and bulletproof glass windshield at the front of the cockpit. The initial plan was to power the machine with a Walter HWK 109-509A2 rocket motor; however, only the 109-509A1, as used in the Me 163, was available. It had a sea level thrust of 1,700 lb with its quartet of Schmidding SG34 solid fuel rocket boosters used in its vertical launch to provide an additional 4,800 kg thrust for 10 seconds before they burned out and were jettisoned. The experimental prototypes slid up a 20 m-tall vertical steel launch tower for a maximum sliding length of 17 m in three guideways, one for each wing tip and one for the lower tip of the ventral tail fin. By the time the aircraft left the tower it was hoped that it would have achieved sufficient speed to allow its aerodynamic surfaces to provide stable flight.
Under operational conditions, once the Natter had left the launcher, it would be guided to the proximity of the Allied bombers by an autopilot with the possibility of an added beam guidance similar to that used in some V-2 rocket launches. Only then would the pilot take control, aim and fire the armament, which was originally proposed to be a salvo of 19 R4M rockets. Later, 28 R4Ms or a number of Henschel Hs 297 "Föhn" rockets were suggested, with either variety of unguided rocket fired from the Natter's nose-mount cellular launch tubes contained in its nose. The Natter was intended to fly up and over the bombers, by which time its Walter motor would probably be out of propellant. Following its one-time attack with its rockets, the pilot would dive his Natter, now effectively a glider, to an altitude of around 3,000 m, flatten out, release the nose of the aircraft and a small braking parachute from the rear fuselage. The fuselage would decelerate and the pilot would be ejected forwards by his own inertia and land by means of a personal parachute.
In an early proposal in August 1944, the Natter design had a concrete nose; it was suggested that the machine might ram a bomber, but this proposal was subsequently withdrawn in later Project Natter outlines. Bachem stated clearly in the initial proposal that the Natter was not a suicide weapon and much effort went into designing safety features for the pilot. However, owing to the potential dangers for the pilot inherent in the operation of this precarious aircraft, the Natter is sometimes listed as a suicide craft. The design had one decisive advantage over its competitors – it eliminated the necessity to land an unpowered gliding machine at an airbase, which, as the history of the Me 163 rocket aircraft had clearly demonstrated, made an aircraft extremely vulnerable to attack by Allied fighters.
Modifications.
Bachem's design caught the eye of Heinrich Himmler. The "Reichsführer-SS" granted Bachem an interview and fully supported the project. In the middle of September 1944 the Technical Office of the "Waffen-SS" made an order for Bachem to develop and manufacture the Natter at his Waldsee factory. In December 1944 the project came largely under the control of the SS and Hans Kammler. This decision is said to have been the only time the SS significantly interfered with aircraft design and air fighting strategy. Early-on in the project, the "Reichsluftfahrtministerium" ("RLM") undertook an engineering assessment of the Natter, which it reported on 28 October 1944. Various stringent economies were imposed on an already frugal design.
The Natter had no landing gear, which saved weight, expense and construction time. Consequently one of the most unusual features of the machine was the escape of the pilot and recovery of the machine. The proposed sequence of these events was as follows: After the attack, the Natter might dive to a lower altitude and flatten out into level flight. The pilot would then proceed with a well-practised escape sequence. He would open the cockpit canopy latch; the canopy flicking backwards on its hinge in the airstream; he would undo his seat belt and remove his feet from the rudder pedal stirrups. By squeezing a lever mounted on the control column, he would release a lock at the base of the column, which would allow him to tilt the column forwards where it could engage in and undo a safety latch for the nose release mechanism. He would then lean a little further forward and pull a lever hinged near the floor at the front of the cockpit. This action frees the nose section, which flies off as a result of the reduced aerodynamic pressure at the front of the fuselage. As the nose section separates, it was intended to briefly pull on two cables that release a small ribbon parachute stored on the starboard side of the rear fuselage. The parachute subsequently opens and decelerates the Natter. The pilot would be ejected from the cockpit by his own inertia and as soon as he is clear of the fuselage, he would open his personal parachute and descend to the ground.
Although it was originally planned to recover the Walter liquid propulsion unit, which was probably the most expensive single component of the machine, using two salvage parachutes, associated problems were still not fully resolved prior to the war's end.
Professor Wilhelm Fuchs reportedly calculated the Natter's aerodynamics at the "Technische Hochschule", Aachen using a large analog computer. Wind tunnel testing on a wooden model, scaled to 40% of full size, was performed at the "Deutsche Versuchsanstalt für Luftfahrt" (DVL), the Institute for Aerodynamics at Berlin-Adlershof in September 1944 at speeds up to 504 km/h. Results from these tests were reported in January 1945 to the Bachem-Werk. Further model tests were carried out at "Luftfahrtforschungsanstalt Hermann Göring" (LFA), Braunschweig at speeds close to Mach 1. In March the Bachem-Werk simply received a statement that satisfactory flying qualities should be expected with speeds up to 1,100 km/h.
Testing.
Construction of the first experimental prototype "Natter, Versuchsmuster 1", was completed on 4 October 1944. V1 was subsequently referred to as "Baumuster1" ("BM1") and later still the "B" was dropped and the machine became known as the M1. Most subsequent prototypes were known by 'M' codes, as the later prototypes of the Heinkel He 162 were. Manned glider flights began on 3 November 1944. The first glider M1 was towed to around 3,000 m by a Heinkel He 111 bomber with a cable ("Tragschlepp" mode) at Neuburg an der Donau. The pilot was Erich Klöckner, who made all four documented "Tragschlepp" flights. After carrying out the test programme of the M1, he bailed out and the machine crashed into the ground. Unfortunately it was found that the towing cable, and in the case of the M3, the undercarriage interfered with the flight characteristics of the gliders and consequently the results were difficult to interpret. To clear any lingering doubts about the Natter in the glider mode, Hans Zübert made a daring free flight in the M8 on the 14 February, and showed that the Natter was indeed a very good flying machine.
The vertical take-off (VTO) trials were conducted on high ground called the Ochsenkopf at the "Truppenübungsplatz" (military training area) Heuberg near Stetten am kalten Markt, Würtemberg. The first successful unmanned vertical take-off from the experimental launch tower occurred on 22 December 1944. The test machine, the M16, was powered only by the Schmidding solid boosters, as were all the early VTO trials. Up to and including 1 March 1945, 16 prototypes had been used, eight in glider trials and eight in VTO trials.
Manned VTO test flight.
By January 1945 Bachem was under pressure from the authorities in Berlin to carry out a manned VTO flight by the end of February. On 25 February, M22 was in the experimental launch tower. It was as complete an operational machine as possible with the Walter HWK 109-509 A1 motor installed for the first time. A dummy pilot was in the cockpit. Lift-off from the tower was perfect. The engineers and ground crew watched spellbound as the M22 ascended under the combined power of the four Schmidding boosters and the Walter motor, an estimated total thrust of 6,500 kg. The nose separated as programmed and the dummy pilot descended "safely" under its personal parachute. The remainder of the fuselage came down under its two large salvage parachutes, but when it hit the ground the Walter liquid-propellant rocket motor's residual hypergolic propellants ("T-Stoff" oxidizer and "C-Stoff" fuel) exploded and the machine was destroyed.
Despite Bachem's concerns that the test programme had been significantly cut short, a young volunteer "Luftwaffe" test pilot, Lothar Sieber, climbed into the cockpit of the fully fuelled M23 on 1 March. The aircraft was equipped with an FM transmitter for the purpose of transmitting flight data from various monitoring sensors in the machine.
A hard wire intercom appears to have been provided between Sieber and the engineers in the launch bunker using a system similar to that used in the manned glider flights. Around 1100 am, the M23 was ready for take-off. Low stratus clouds lay over the Ocksenkopf. The Walter motor built up to full thrust and Sieber pushed the button to ignite the four solid boosters. With a roar, the M23 rose out of a cloud of steam and rocket smoke straight up, displaying its camouflage paintwork. At an altitude of about 100 to, the Natter suddenly pitched backwards into an inverted curve. Initially it climbed at about 30° to the vertical. At about 500 m the cockpit canopy was seen to fly off. The Natter continued to climb at high speed at an angle of 15° from the horizontal and disappeared into the clouds. The Walter motor stalled about 15 seconds after take-off. It is estimated the Natter reached 1500 m, at which point it nose-dived and hit the ground with great force about 32 seconds later, some kilometres from the launch site. Unknown at the time, one of the Schmidding boosters failed to jettison and its remains were dug up at the crash site in 1998.
Bachem surmised Sieber had involuntarily pulled back on the control column under the effect of the 3 G acceleration. Examination of the canopy, which fell near the launch site, showed the tip of the latch was bent, suggesting it may not have been in the fully closed position at launch. The pilot's headrest had been attached to the underside of the canopy and as the canopy flew off the pilot's head would have snapped back suddenly about 25 cm, hitting the solid wooden rear upper cockpit bulkhead, and either knocking Sieber unconscious or breaking his neck.
This tragedy reinforced Bachem's long held belief that the take-off and flight in the vicinity of the target bombers should be fully automated. The canopy latch was strengthened and the headrest was attached to the backboard of the cockpit. Before the introduction of the autopilot in the test programme, the control column would have a temporary locking device on it, which would allow the machine to ascend vertically to at least 1,000 m and then be removed by the pilot. The Walter motor probably ceased operation because the Natter was virtually upside-down and air may have entered the intake pipes in the propellant tanks, starving the motor. Sieber had become the first man to take off vertically from the ground under pure rocket power.
Production.
Much debate has surrounded the number of Natters built at the Bachem-Werk and their disposition. According to Bachem, 36 "Natters" were produced at the Bachem-Werk in Waldsee by the end of the war. Up to April 1945, 17 aircraft had been used in unmanned trials comprising five gliders, all slung under an He 111 in the "Mistelschlepp" configuration prior to launch, and 12 VTO examples. Five aircraft were prepared for manned trials, four gliders and one VTO version. The M3 was flown twice, and then rebuilt at which time it was given the new code BM3a but was never flown. The total number of launches to early April 1945 was 22, as was the total number of Natters constructed up to that time. Bachem reported further that there were 14 more finished or almost finished aircraft in April 1945. Four of these were prototype A1 operational Natters built for test launching from a wooden pole launcher, which had been designed for field deployment. This new launcher was also constructed on the Heuberg, not far from the experimental steel tower. There is documentary evidence for two pole launches in April but not three as claimed by Bachem in his post-war presentation. The documentation for this third flight may have been destroyed by the SS at war's end. Ten A1 operational Natters, called "K-Maschinen", were constructed for the "Krokus-Einsatz" ("Operation Crocus").
The fate of these 14 A1 Natters was as follows:
Three were fired from the pole launcher according to Bachem, four were burnt at Waldsee, two were burnt at "Lager" Schlatt, Oetztal, Austria, four were captured by US troops at Sankt Leonhard im Pitztal, Austria and one, which had been sent as a sample model to a new factory in Thuringia, was captured by the Red Army. Consequently, the total of 36 test and operational aircraft constructed at the Bachem-Werk can be accounted for. However, Natter carcasses were used for a variety of ground-based purposes; for example, as a static booster rocket, armament and strength testing and pilot seat position tests. Some fuselages were reused after flight testing; for example, the M5, 6 and 7.
Of the four Natters captured at Sankt Leonhard im Pitztal, two went to the United States. Only one original Natter built in Germany in the Second World War survives in storage at the Paul E. Garber Preservation, Restoration, and Storage Facility in Suitland, Maryland, under the auspices of the Smithsonian Institution. The fate of the other Natter brought to the US is unknown. There is no documentary evidence that a Natter was ever flown from Muroc Field. The tail section of one of the Natters at Sankt Leonhard im Pitztal was broken off while it still rested on its trailer. The remaining machine was possibly destroyed when the CIOS Field Team left the area. Despite being promised one of these Natters, there is no evidence that a machine ever reached UK shores.
Stability.
In early February 1945 the positions of the centre of gravity for the A1 operational machine during its flight profile were giving the RLM and the SS cause for concern. They wanted these figures to be decided upon for the upcoming construction of the A1 aircraft for "Krokus-Einsatz" (Operation Crocus), the field deployment of the Natter. The position of the centre of gravity is expressed as a percentage of the chord (distance between the leading and trailing edges) of the main wing. Thus 0% is the leading edge and 100% is the trailing edge. In the manned glider trials the centre of gravity had been varied between 20 and 34%. At a meeting of engineers held on 8 February, the variations in the centre of gravity expected in the A1 "Krokus" machine were discussed. At take-off with the weight of the four solid boosters, the centre of gravity would be brought back to 65%, but after releasing these rockets it would move forwards to 22%. The free flight by Zübert on 14 February had showed unequivocally that the little Natter had excellent flying characteristics as a glider. The centre of gravity problem was solved initially by the addition of one-metre-square auxiliary tailfins that were released simultaneously with the jettisoning of the boosters. The "Krokus" aircraft had vanes that would direct the Walter rocket exhaust gases so as to assist vehicle stabilisation at low speed similar to those used in the V-2 rocket.
Legacy.
French forces had captured Waldsee by 25 April 1945 and presumably took control of the Bachem-Werk. Shortly before the French troops arrived, a group of Bachem-Werk personnel set out for Austria with five A1 Natters on trailers. At Bad Wörishofen, the group waited for another squad retreating from Nabern unter Teck with one completed Natter. Both groups then set out for the Austrian Alps. One group with two Natters ended up at the junction of the river Inn and one of its tributaries, the Ötztaler Ache, at Camp Schlatt. The other group went to St. Leonhard im Pitztal with four aircraft. US troops captured the first group at Camp Schlatt around 4 May and the second group on the following day.
At some time during the project, the Bachem-Werk was ordered to give complete details of the BP-20 Natter to the Japanese, but there was doubt over whether they had received them. They were, however, known to have a general knowledge of the Natter and showed considerable interest in the project.
"Operation Krokus" launch pads at Hasenholz wood.
An operational launch site for the first Ba 349A-1 operational Natters under the code name Operation "Krokus" was being established in a small wooded area called Hasenholz, south of the Stuttgart to Munich autobahn and to the east of Nabern unter Teck. Around the end of February and the beginning of March the Todt Organisation was in action, constructing each set of the trios of concrete foundations (or "footings") for the launch towers. These three launch pads and their towers were arranged at the corners of an equilateral triangle, 120 m per side. The specific locations are said to be , and . In the centre of each of the three concrete footings is a square hole approximately 50 centimeters deep, which once served as the foundation for the launch tower. Beside each hole is a pipe, cut off at ground level, which was probably once a cable pit. These three concrete pads were noticed by a surveyor in the autumn of 1945, but not rediscovered until 1999. In March 1945 eight pilots, who were experienced, mostly highly decorated and volunteers for the first operational flights, started training at the Lager Heuberg. This training continued until the first half of April at which time they moved to the Hasenholz operational area. The first three manned and fully armed A1 "Krokus" examples were scheduled to be launched from 20 April, which was Hitler's birthday. But on that day the US 10th Armored Division drove its tanks into Kirchheim unter Teck to the northwest of Hasenholz wood. The next day it crossed the autobahn and headed straight for the Natter operational area. The Natter group subsequently retreated to Waldsee.
Survivor and reproductions.
Only one original A1 Natter survives; it is stored in the Paul E. Garber Preservation, Restoration, and Storage Facility in Suitland, Maryland, USA. It is in a poor state of repair and is no longer accessible to the general public. The evidence supports the proposition that this machine was captured at St. Leonhard im Pitztal, Austria in May 1945 by US troops. The Natter displayed at the Deutsches Museum is said to have been reconstructed partly from sub-assemblies that survived the end of the war. This machine is of the experimental type as launched from the steel tower and is painted to look like an M17. There are several static reproductions of Natters around the world, for example at the Planes of Fame Air Museum, Chino, California and Fantasy of Flight, Polk City, Florida, US.
Specifications (Ba 349B-1).
"Data from" </ul>Armament
References.
</dl>

</doc>
<doc id="58009" url="http://en.wikipedia.org/wiki?curid=58009" title="Good Friday">
Good Friday

Good Friday is a Christian religious holiday commemorating the crucifixion of Jesus Christ and his death at Calvary. The holiday is observed during Holy Week as part of the Paschal Triduum on the Friday preceding Easter Sunday, and may coincide with the Jewish observance of Passover. It is also known as Holy Friday, Great Friday, Black Friday, or Easter Friday, though the last term properly refers to the Friday in Easter week.
Good Friday is a public holiday in many countries, including in most of the Western world (especially Anglican and Catholic countries) as well as in 12 U.S. states.
Etymology.
The etymology of the term "good" in the context of Good Friday is contested. Some sources claim it is from the senses "pious", "holy" of the word "good", while others contend that it is a corruption of "God Friday". The "Oxford English Dictionary" supports the first etymology, giving "of a day or season observed as holy by the church" as an archaic sense of "good" ("good", adj. 8c), and providing examples of "good tide" meaning "Christmas" or "Shrove Tuesday", and "Good Wednesday" meaning the Wednesday in Holy Week.
In German-speaking countries, the Good Friday is generally referred as "Karfreitag" ("Kar" from Old High German "kara"‚ "bewail", "grieve"‚ "mourn", Freitag for "Friday"): Mourning Friday. The "Kar" prefix is an ancestor of the English word care in the sense of cares and woes; it meant mourning. The day is also known as "Stiller Freitag" ("Silent Friday") and "Hoher Freitag" ("High Friday, Holy Friday").
Biblical accounts.
According to the accounts in the Gospels, the Temple Guards, guided by Jesus' disciple Judas Iscariot, arrested Jesus in the Garden of Gethsemane. Judas received money (30 pieces of silver) () for betraying Jesus and told the guards that whomever he kisses is the one they are to arrest. Following his arrest, Jesus was brought to the house of Annas, the father-in-law of the high priest, Caiaphas. There he was interrogated with little result and sent bound to Caiaphas the high priest where the Sanhedrin had assembled ().
Conflicting testimony against Jesus was brought forth by many witnesses, to which Jesus answered nothing. Finally the high priest adjured Jesus to respond under solemn oath, saying "I adjure you, by the Living God, to tell us, are you the Anointed One, the Son of God?" Jesus testified ambiguously, "You have said it, and in time you will see the Son of Man seated at the right hand of the Almighty, coming on the clouds of Heaven." The high priest condemned Jesus for blasphemy, and the Sanhedrin concurred with a sentence of death (). Peter, waiting in the courtyard, also denied Jesus three times to bystanders while the interrogations were proceeding just as Jesus had predicted.
In the morning, the whole assembly brought Jesus to the Roman governor Pontius Pilate under charges of subverting the nation, opposing taxes to Caesar, and making himself a king (). Pilate authorized the Jewish leaders to judge Jesus according to their own law and execute sentencing; however, the Jewish leaders replied that they were not allowed by the Romans to carry out a sentence of death ().
Pilate questioned Jesus and told the assembly that there was no basis for sentencing. Upon learning that Jesus was from Galilee, Pilate referred the case to the ruler of Galilee, King Herod, who was in Jerusalem for the Passover Feast. Herod questioned Jesus but received no answer; Herod sent Jesus back to Pilate. Pilate told the assembly that neither he nor Herod found guilt in Jesus; Pilate resolved to have Jesus whipped and released (). Under the guidance of the chief priests, the crowd asked for Barabbas, who had been imprisoned for committing murder during an insurrection. Pilate asked what they would have him do with Jesus, and they demanded, "Crucify him" (). Pilate's wife had seen Jesus in a dream earlier that day, and she forewarned Pilate to "have nothing to do with this righteous man" (). Pilate had Jesus flogged and then brought him out to the crowd to release him. The chief priests informed Pilate of a new charge, demanding Jesus be sentenced to death "because he claimed to be God's son." This possibility filled Pilate with fear, and he brought Jesus back inside the palace and demanded to know from where he came ().
Coming before the crowd one last time, Pilate declared Jesus innocent and washed his own hands in water to show he has no part in this condemnation. Nevertheless, Pilate handed Jesus over to be crucified in order to forestall a riot () and ultimately to keep his job.
The sentence written was "Jesus of Nazareth, King of the Jews." Jesus carried his cross to the site of execution (assisted by Simon of Cyrene), called the "place of the Skull", or "Golgotha" in Hebrew and in Latin "Calvary". There he was crucified along with two criminals ().
Jesus agonized on the cross for six hours. During his last three hours on the cross, from noon to 3 pm, darkness fell over the whole land. Jesus spoke from the cross, saying "My God, my God, why have you forsaken me?"
With a loud cry, Jesus gave up his spirit. There was an earthquake, tombs broke open, and the curtain in the Temple was torn from top to bottom. This tear signified a removal of restriction of the common Jews from the Temple's "Holiest of Holies", and that God's people now could, themselves, communicate directly with their advocate before God, Jesus the Christ, rather than needing the Temple's High Priest as an intercessor. The centurion on guard at the site of crucifixion declared, "Truly this was God's Son!" ()
Joseph of Arimathea, a member of the Sanhedrin and secret follower of Jesus, who had not consented to his condemnation, went to Pilate to request the body of Jesus (). Another secret follower of Jesus and member of the Sanhedrin named Nicodemus brought about a hundred-pound weight mixture of spices and helped wrap the body of Jesus (). Pilate asked confirmation from the centurion of whether Jesus was dead (). A soldier pierced the side of Jesus with a lance causing blood and water to flow out (), and the centurion informed Pilate that Jesus was dead ().
Joseph of Arimathea took Jesus' body, wrapped it in a clean linen shroud, and placed it in his own new tomb that had been carved in the rock () in a garden near the site of crucifixion. Nicodemus () also brought 75 pounds of myrrh and aloes, and placed them in the linen with the body, in keeping with Jewish burial customs ().
They rolled a large rock over the entrance of the tomb (). Then they returned home and rested, because Shabbat had begun at sunset ().
Matt. 28:1 "After the Sabbath, at dawn on the first day of the week, Mary Magdalene and the other Mary went to look at the tomb". i.e. "After the Sabbath, at dawn on the first day of the week...". "He is not here; he has risen, just as he said...".(Matt. 28:6) On the third day, which is now known as Easter Sunday (or Pascha), Jesus rose from the dead.
In Eastern and Oriental Orthodox Christianity.
Byzantine Christians (Eastern Christians who follow the Rite of Constantinople: Orthodox Christians and Greek-Catholics) call this day "Great and Holy Friday", or simply "Great Friday".
Because the sacrifice of Jesus through his crucifixion is commemorated on this day, the Divine Liturgy (the sacrifice of bread and wine) is never celebrated on Great Friday, except when this day coincides with the Great Feast of the Annunciation, which falls on the fixed date of 25 March (for those churches which follow the traditional Julian Calendar, 25 March currently falls on 7 April of the modern Gregorian Calendar). Also on Great Friday, the clergy no longer wear the purple or red that is customary throughout Great Lent, but instead don black vestments. There is no "stripping of the altar" on Holy and Great Thursday as in the West; instead, all of the church hangings are changed to black, and will remain so until the Divine Liturgy on Great Saturday.
The faithful revisit the events of the day through public reading of specific Psalms and the Gospels, and singing hymns about Christ's death. Rich visual imagery and symbolism as well as stirring hymnody are remarkable elements of these observances. In the Orthodox understanding, the events of Holy Week are not simply an annual commemoration of past events, but the faithful actually participate in the death and resurrection of Jesus.
Each hour of this day is the new suffering and the new effort of the expiatory suffering of the Savior. And the echo of this suffering is already heard in every word of our worship service – unique and incomparable both in the power of tenderness and feeling and in the depth of the boundless compassion for the suffering of the Savior. The Holy Church opens before the eyes of believers a full picture of the redeeming suffering of the Lord beginning with the bloody sweat in the Garden of Gethsemane up to the crucifixion on Golgotha. Taking us back through the past centuries in thought, the Holy Church brings us to the foot of the cross of Christ erected on Golgotha, and makes us present among the quivering spectators of all the torture of the Savior.
Great and Holy Friday is observed as a strict fast, and adult Byzantine Christians are expected to abstain from all food and drink the entire day to the extent that their health permits. "On this Holy day neither a meal is offered nor do we eat on this day of the crucifixion. If someone is unable or has become very old [or is] unable to fast, he may be given bread and water after sunset. In this way we come to the holy commandment of the Holy Apostles not to eat on Great Friday."
Matins of Holy and Great Friday.
The Byzantine Christian observance of Holy and Great Friday, which is formally known as The Order of Holy and Saving Passion of our Lord Jesus Christ, begins on Thursday night with the Matins of the Twelve Passion Gospels. Scattered throughout this Matins service are twelve readings from all four of the Gospels which recount the events of the Passion from the Last Supper through the Crucifixion and burial of Jesus. Some churches have a candelabrum with twelve candles on it, and after each Gospel reading one of the candles is extinguished.
The first of these twelve readings is the longest Gospel reading of the liturgical year, and is a concatenation from all four Gospels. Just before the sixth Gospel reading, which recounts Jesus being nailed to the cross, a large cross is carried out of the sanctuary by the priest, accompanied by incense and candles, and is placed in the center of the nave (where the congregation gathers), with a two-dimensional painted icon of the body of Christ (Greek: "soma") affixed to it. As the cross is being carried, the priest or a chanter chants a special antiphon, "Sēmeron Kremātai Epí Xýlou":
Today He who hung the earth upon the waters is hung upon the Cross "(three times)".<br>He who is King of the angels is arrayed in a crown of thorns.<br>He who wraps the Heavens in clouds is wrapped in the purple of mockery. <br>He who in Jordan set Adam free receives blows upon His face.<br>The Bridegroom of the Church is transfixed with nails. <br>The Son of the Virgin is pierced with a spear.<br>We venerate Thy Passion, O Christ "(three times)".<br>Show us also Thy glorious Resurrection.
During the service, all come forward to kiss the feet of Christ on the cross. After the Canon, a brief, moving hymn, "The Wise Thief" is chanted by singers who stand at the foot of the cross in the center of the nave. The service does not end with the First Hour, as usual, but with a special dismissal by the priest:
May Christ our true God, Who for the salvation of the world endured spitting, and scourging, and buffeting, and the Cross, and death, through the intercessions of His most pure Mother, of our holy and God-bearing fathers, and of all the saints, have mercy on us and save us, for He is good and the Lover of mankind.
Royal Hours.
The next day, in the forenoon on Friday, all gather again to pray the Royal Hours, a special expanded celebration of the Little Hours (including the First Hour, Third Hour, Sixth Hour, Ninth Hour and Typica) with the addition of scripture readings (Old Testament, Epistle and Gospel) and hymns about the Crucifixion at each of the Hours (some of the material from the previous night is repeated). This is somewhat more festive in character, and derives its name of "Royal" from both the fact that the Hours are served with more solemnity than normal, commemorating Christ the King who humbled himself for the salvation of mankind, and also from the fact that this service was in the past attended by the Emperor and his court.
Vespers of Holy and Great Friday.
In the afternoon, around 3 pm, all gather for the Vespers of the Taking-Down from the Cross, commemorating the Deposition from the Cross. The Gospel reading is a concatenation taken from all four of the Gospels. During the service, the body of Christ (the "soma") is removed from the cross, as the words in the Gospel reading mention Joseph of Arimathea, wrapped in a linen shroud, and taken to the altar in the sanctuary. Near the end of the service an "epitaphios" or "winding sheet" (a cloth embroidered with the image of Christ prepared for burial) is carried in procession to a low table in the nave which represents the Tomb of Christ; it is often decorated with an abundance of flowers. The epitaphios itself represents the body of Jesus wrapped in a burial shroud, and is a roughly full-size cloth icon of the body of Christ. Then the priest may deliver a homily and everyone comes forward to venerate the epitaphios. In the Slavic practice, at the end of Vespers, Compline is immediately served, featuring a special "Canon of the Crucifixion of our Lord and the Lamentation of the Most Holy Theotokos" by Symeon the Logothete.
Matins of Holy and Great Saturday.
On Friday night, the Matins of Holy and Great Saturday, a unique service known as The Lamentation at the Tomb ("Epitáphios Thrēnos") is celebrated. This service is also sometimes called "Jerusalem Matins". Much of the service takes place around the tomb of Christ in the center of the nave.
A unique feature of the service is the chanting of the Lamentations or Praises ("Enkōmia"), which consist of verses chanted by the clergy interspersed between the verses of Psalm 119 (which is, by far, the longest psalm in the Bible). The "Enkōmia" are the best-loved hymns of Byzantine hymnography, both their poetry and their music being uniquely suited to each other and to the spirit of the day. They consist of 185 tercet antiphons arranged in three parts ("stáseis" or "stops"), which are interjected with the verses of Psalm 119, and nine short "doxastiká" ("Gloriae") and "Theotókia" (invocations to the Virgin Mary). The three "stáseis" are each set to its own music, and are commonly known by their initial antiphons: Ἡ ζωὴ ἐν τάφῳ, "Life in a grave", Ἄξιον ἐστί, "Worthy it is", and Αἱ γενεαὶ πᾶσαι, "All the generations". Musically they can be classified as strophic, with 75, 62, and 48 tercet stanzas each, respectively. The climax of the "Enkōmia" comes during the third "stásis", with the antiphon "Ō glyký mou Éar", a lamentation of the Virgin for her dead Child ("O, my sweet spring, my sweetest child, where has your beauty gone?"). The author(s) and date of the "Enkōmia" are unknown. Their High Attic linguistic style suggests a dating around the 6th century, possibly before the time of St. Romanos the Melodist.
At the end of the Great Doxology, while the Trisagion is sung, the epitaphios is taken in procession around the outside the church, and is then returned to the tomb. Some churches observe the practice of holding the epitaphios at the door, above waist level, so the faithful most bow down under it as they come back into the church, symbolizing their entering into the death and resurrection of Christ. The epitaphios will lay in the tomb until the Paschal Service early Sunday morning. In some churches, the epitaphios is never left alone, but is accompanied 24 hours a day by a reader chanting from the Psalter.
The Troparion (hymn of the day) of Good Friday is:
<poem>
The noble Joseph, when he had taken down Thy most pure Body from the tree, wrapped it in fine linen, and anointed it with spices, and placed it in a new tomb.
Glory to the Father, and to the Son, and to the Holy Spirit, both now and ever, and unto ages of ages. Amen.
The angel came to the myrrh-bearing women at the tomb and said:
Myrrh is fitting for the dead, but Christ has shown Himself a stranger to corruption.
</poem>
In the Roman Catholic Church.
Day of Fasting.
The Catholic Church treats Good Friday as a fast day, which in the Latin Church is understood as having only one full meal (but smaller than a regular meal) and two collations (a smaller repast, two of which together do not equal one full meal) and on which the faithful abstain from eating meat. This is why many places have the typical 'Fish Friday'. In countries where Good Friday is not a day of rest from work, the afternoon liturgical service is usually put off until a few hours after the recommended time of 3 pm.
Services on the day.
The Roman Rite has no celebration of Mass between the Lord's Supper on Holy Thursday evening and the Easter Vigil unless a special exemption is granted for rare solemn or grave occasions by the Vatican or the local bishop. The only sacraments celebrated during this time are Baptism (for those in danger of death), Penance, and Anointing of the Sick. While there is no celebration of the Eucharist, it is distributed to the faithful only in the Service of the Passion of the Lord, but can also be taken at any hour to the sick who are unable to attend this service. During this period crosses, candlesticks, and altar cloths are removed from the altar which remains completely bare. It is also customary to empty the holy water fonts in preparation of the blessing of the water at the Easter Vigil. Traditionally, no bells are rung on Good Friday or Holy Saturday until the Easter Vigil.
The Celebration of the Passion of the Lord takes place in the afternoon, ideally at three o'clock, but for pastoral reasons a later hour may be chosen. The vestments used are red (more commonly) or black (more traditionally).
Before 1970, vestments were black except for the Communion part of the rite when violet was used. Before 1955 black was used throughout. If a bishop or abbot celebrates, he wears a plain mitre ("mitra simplex").
Liturgy.
The Good Friday liturgy consists of three parts: the Liturgy of the Word, the Veneration of the Cross, and Holy Communion.
Stations of the Cross.
In addition to the prescribed liturgical service, the Stations of the Cross are often prayed either in the church or outside, and a prayer service may be held from midday to 3.00 pm, known as the Three Hours' Agony. In countries such as Malta, Italy, Philippines, Puerto Rico and Spain, processions with statues representing the Passion of Christ are held.
In Rome, since the papacy of Saint John Paul II, the heights of the Temple of Venus and Roma and their position opposite the main entrance to the Colosseum have been used to good effect as a public address platform. This may be seen in the photograph below where a red canopy has been erected to shelter the Pope as well as an illuminated cross, on the occasion of the Way of the Cross ceremony. The Pope, either personally or through a representative, leads the faithful through meditations on the stations of the cross while a cross is carried from there to the Colosseum.
In Polish churches, a tableau of Christ's Tomb is unveiled in the sanctuary. Many of the faithful spend long hours into the night grieving at the Tomb, where it is customary to kiss the wounds on the Lord's body. A life-size figure of Jesus lying in his tomb is widely visited by the faithful, especially on Holy Saturday. The tableaux may include flowers, candles, figures of angels standing watch, and the three crosses atop Mt Calvary, and much more. Each parish strives to come up with the most artistically and religiously evocative arrangement in which the Blessed Sacrament, draped in a filmy veil, is prominently displayed.
Acts of Reparation to Jesus Christ.
The Roman Catholic tradition includes specific prayers and devotions as "acts of reparation" for the sufferings and insults that Jesus suffered during his Passion on Good Friday. These "Acts of Reparation to Jesus Christ" do not involve a petition for a living or deceased beneficiary, but aim to "repair the sins" against Jesus. Some such prayers are provided in the Raccolta Catholic prayer book (approved by a Decree of 1854, and published by the Holy See in 1898) which also includes prayers as Acts of Reparation to the Virgin Mary.
In his encyclical "Miserentissimus Redemptor" on reparations, Pope Pius XI called Acts of Reparation to Jesus Christ a duty for Catholics and referred to them as ""some sort of compensation to be rendered for the injury" with respect to the sufferings of Jesus.
Pope John Paul II referred to Acts of Reparation as the "unceasing effort to stand beside the endless crosses on which the Son of God continues to be crucified"".
Anglican Communion.
The 1662 Book of Common Prayer did not specify a particular rite to be observed on Good Friday but local custom came to mandate an assortment of services, including the Seven Last Words from the Cross and a three-hour service consisting of Matins, Ante-communion (using the Reserved Sacrament in high church parishes) and Evensong. In recent times revised editions of the Prayer Book and Common Worship have re-introduced pre-Reformation forms of observance of Good Friday corresponding to those in today's Roman Catholic Church, with special nods to the rites that had been observed in the Church of England prior to the Henrican, Edwardian and Elizabethan reforms, including Creeping to the Cross.
Lutheran Church.
In Lutheran tradition from the 16th to the 20th century, Good Friday was the most important religious holiday, and abstention from all worldly works was expected. During that time, Lutheranism had no restrictions on the celebration of the Eucharist on Good Friday; on the contrary, it was a prime day on which to receive the Eucharist, and services were often accentuated by special music such as the "St Matthew Passion" by Johann Sebastian Bach.
More recently, Lutheran liturgical practice has recaptured Good Friday as part of the larger sweep of the great Three Days: Maundy Thursday, Good Friday, and the Vigil of Easter. The Three Days remain one liturgy which celebrates the death and resurrection of Jesus. As part of the liturgy of the Three Days, Lutherans generally fast from the Eucharist on Good Friday. Rather, it is celebrated in remembrance of the Last Supper on Maundy Thursday and at the Vigil of Easter. One practice among Lutheran churches is to celebrate a tenebrae service on Good Friday, typically conducted in candlelight and consisting of a collection of passion accounts from the four gospels. While being called "Tenebrae" it holds little resemblance to the now-suppressed Catholic monastic rite of the same name. The Good Friday liturgy appointed in "Evangelical Lutheran Worship", the worship book of the Evangelical Lutheran Church in America, specifies a liturgy similar to the revised Roman Catholic liturgy. A rite for adoration of the crucified Christ includes the optional singing of the Solemn Reproaches in an updated and revised translation which eliminates some of the anti-Jewish overtones in previous versions. Influenced by the ecumenical liturgical renewal movement and in an attempt to recover patterns of worship from the early church, many Lutheran congregations are moving away from long preaching services centered on a dramatic and sentimentalized remembrance of the "Seven Last Words," sayings of Jesus assembled from the four gospels, toward a more devotional practice that places an emphasis on the triumph of the cross, and a singular biblical account of the Passion narrative from the Gospel of John.
Other Protestant traditions.
Many other Protestant communities hold special services on this day as well. Moravians hold a Lovefeast on Good Friday as they receive Holy Communion on Maundy Thursday. The Methodist Church commemorates Good Friday with a service of worship, often based on the Seven Last Words from the Cross. It is not uncommon for some communities to hold interdenominational services on Good Friday.
Some Baptist, Pentecostal, many Sabbatarian and non-denominational churches oppose the observance of Good Friday, regarding it as a papist tradition, and instead observe the Crucifixion on Wednesday to coincide with the Jewish sacrifice of the Passover Lamb (which Christians believe is an Old Testament pointer to Jesus Christ). A Wednesday Crucifixion of Jesus allows for him to be in the tomb ("heart of the earth") for three days and three nights as he told the Pharisees he would be (Matthew 12:40), rather than two nights and a day if he had died on a Friday. Preparation Day (14 Nisan on the Hebrew calendar) – which is the day before Passover (15 Nisan), instead of the Friday morning found in the Synoptic Gospels.
Coptic Church.
The Rite of Good Friday begins with the usual Paschal Prime Prayers. The Icon of Crucifixion is then adorned with roses, with lit candles and censors around it. The Rite continues with the prayers of the Third Hour in the same manner as the rest of the Pascha Week. The priests will then wear their dark cloaks and the deacons their liturgical vestments with their blue stoles as a sign of mourning. Following this, the prayers of the Sixth Hour commence with the reading of the prophecies in Coptic and/or the languages of understanding and the Paschal Praise. The priest will then raise incense before the Icon while the deacons chant Tai soury in the mournful tune, followed by Vai `etafenf and Tenouwst , after which the Pauline is read in Coptic and/or the language of understanding. This is concluded by the hymn, }`epictoly . After praying the Litanies of the Sixth Hour with its responses, the deacons chant the Greek hymn `o Monogenyc , followed by the Trisagion in the mournful tune. Afterwards, the Psalm is chanted in the Attribi tune, commonly known as Ke upertou , and the reading of the Gospel in Coptic and/or the language of understanding. As soon as the reader says the words “and there was darkness on the earth,” the candles are blown out and the lights of the Church switched off, in remembrance of the darkness that fell upon the earth during the Crucifixion of our Lord. The exposition is then read, followed by the litanies and the melismatic Kuri`e `eleycon , which is chanted three times. The prayer is then concluded with the blessing, and the Thief’s Faithfulness is read with its appropriate responses.
The prayer of the Ninth Hour begins with the Raising of Incense before the Icon of the Crucifixion, during which the deacons chant the hymns }souri , Vai `etafenf and Tenouwst , followed by the reading of the Pauline in Coptic, which is the hymn E;be ]anactacic , and its translation in the language of understanding. The litanies of the hour and the appropriate responses are then chanted, followed by the mournful Trisagion. The Psalm is then chanted in the Attribi tune, commonly known as Ke upertou . Then, the Gospel is read in Coptic and/or the language of understanding. In conclusion, the exposition is read, then the litanies, and the melismatic Kuri`e `eleycon , which is chanted three times. The prayer concludes with the blessing.
The prayer of the Eleventh Hour is similar to that of the Third Hour except that the melismatic Kuri`e `eleycon is chanted.
In commencing the prayer of the Twelfth Hour, the deacons move up to the first chorus, and the veil of the sanctuary is opened. The black curtain covering the veil of the sanctuary, as well as those on the lecterns, are lifted and the candles are lit once more. As the priests wear their seasonal garments, the Lamentations of Jeremiah are read, followed by the Paschal Praise, one verse from the raised podium and the other from lower podium. In churches without podiums, the Paschal Praise is chanted one verse inside the sanctuary and the other from outside. The Psalm Pek`;ronoc is then chanted in the Shamy tune from the podium of the church, if one is present, followed by the hymn Ke upertou and the Gospel reading in Coptic and/or the language of understanding. Following this, the exposition is read and the litanies are prayed, concluded with Kuri`e `eleycon, to be chanted four hundred times with full prostrations (metanoias). These prostrations are done periodically with one hundred in each direction, starting with the east, then west, north, and ending with south.
The priest and deacons then begin the procession three times around the altar, then three times around the church’s nave, ending with one final procession around the altar. The Icon of the Crucifixion is carried throughout the procession, during which Kuri`e `eleycon is chanted in a melismatic tune. When the procession is completed, the deacons begin to chant the hymn Golgotha, during which the senior priest buries the Icon while anointing it with spices, fragrances and roses. All one hundred and fifty psalms are then read, and the prayer is concluded with the blessing. It is of interest to note that the Rite of the Twelfth Hour is both mournful and joyous. This is because the Church joins in the mourning of the slain Christ for our sins, meanwhile, it also rejoices as mankind is granted Salvation from the bondage of Satan by Christ’s death.
Associated customs.
In many countries with a strong Christian tradition such as Australia, Bermuda, Brazil, Canada, the countries of the Caribbean, Chile, Colombia, Costa Rica, Ecuador, Finland, Germany, Malta, Mexico, New Zealand, Peru, the Philippines, Singapore, Spain, Sweden, the United Kingdom, and Venezuela, the day is observed as a public or federal holiday. In the United States, 12 states observe Good Friday as state holiday: Connecticut, Texas, Delaware, Hawaii, Indiana, Tennessee, Florida, Kentucky, Louisiana, New Jersey, North Carolina and North Dakota. Germany and some other countries have laws prohibiting certain acts, such as dancing and horse racing, that are seen as profaning the solemn nature of the day.
Cuba.
In an online article posted on Catholic News Agency by Alejandro Bermúdez on 31 March 2012, Cuban President Raúl Castro, with the Communist Party and his advisers, decreed that Good Friday that year would be a holiday. This was Castro's response to a request made personally to him by Pope Benedict XVI during the latter's Apostolic Visitation to the island and León, Mexico that month. The move followed the pattern of small advances in Cuba's relations with the Vatican, mirroring Pope John Paul II's success in getting Fidel Castro to declare Christmas Day a holiday. Both Good Friday and Christmas are now annual holidays in Cuba.
Ireland.
In the Republic of Ireland, it is illegal to sell alcoholic beverages on Good Friday—a ban dating back to 1927. Pubs are closed entirely, and shops and restaurants are not allowed to offer or sell alcohol to their patrons. There have been exceptions to this ban; alcohol can still be served at greyhound tracks, military canteens, the National Concert Hall, on trains and at licensed theatres on Good Friday. Following a successful lobbying campaign, the city of Limerick was granted an exception to the ban in 2010 so that pubs could open for a major Celtic League rugby match that had been scheduled on Good Friday that year. Pubs in Northern Ireland sometimes see increased business from Irish tourists on Good Friday as it does not have such a ban.
There have been calls for the ban to be lifted in 2016 for the centenary of the Easter Uprising; critics of the ban believe that it encourages binge drinking in the days leading to Good Friday, and that the lack of open pubs disappoints foreign tourists, resulting in a loss of potential sales. However, a sizable portion of those surveyed supported the continuation of this tradition. Christy Burke, Lord Mayor of Dublin, remarked that on the eve of Good Friday, Irish supermarkets are often "overloaded with people stocking up [on alcohol] as if the city was going to shut down forever."
Malta.
The Holy Week commemorations reach their peak on Good Friday as the Roman Catholic Church celebrates the passion of Jesus. Solemn celebrations take place in all churches together with processions in different villages around Malta and Gozo. During the celebration, the narrative of the passion is read in some localities, while the Adoration of the Cross follows. Good Friday processions take place in Birgu, Bormla, Għaxaq, Luqa, Mosta, Naxxar, Paola, Qormi, Rabat, Senglea, Valletta, Żebbuġ (Città Rohan) and Żejtun. Processions in Gozo will be in Nadur, Victoria (St. George and Cathedral), Xagħra and Żebbuġ, Gozo.
The Philippines.
In predominantly Roman Catholic Philippines, the day is commemorated with street processions, the Way of the Cross, the chanting of the "Pasyón", and performances of the "Senákulo" or Passion play. Some devotees engage in self-flagellation and even have themselves crucified as expressions of penance despite health issues and strong disapproval from the Church.
Church bells are not rung and Masses are not celebrated, while television and radio have shorter hours, broadcasting mostly religious content. Malls and shops are generally closed, as are restaurants as it is the second of three public holidays within the week.
After three o'clock in the afternoon (the time at which Jesus is traditionally believed to have died), the faithful venerate the cross in the local church and follow the procession of the Burial of Jesus. The image of the dead Christ is then laid in state to be venerated, and sometimes treated in accordance with local burial customs.
In Cebu and many parts of the Visayan Islands, people usually eat "binignit" and "biko" as a form of fasting.
United Kingdom.
In England, Wales, Scotland and Northern Ireland, Good Friday is an official public holiday (a.k.a. Bank Holiday). All schools are closed and most businesses treat it as a holiday for staff; however, many retail stores now remain open. Government services in Northern Ireland operate as normal on Good Friday substituting the holiday for Easter Tuesday.
There has traditionally been no horse racing on Good Friday in the UK. However, in 2008, betting shops and stores opened for the first time on this day and in 2014 Lingfield Park and Musselburgh staged the UK's first Good Friday race meetings. The BBC has for many years introduced its 7 am News broadcast on Radio 4 on Good Friday with a verse from Isaac Watts' hymn "When I Survey the Wondrous Cross".
United States.
In the United States, Good Friday is not a government holiday at the federal level; however, individual states, counties and municipalities may observe the holiday. Good Friday is a state holiday in Connecticut, Delaware, Florida, Hawaii, Indiana, Kentucky, Louisiana, New Jersey, North Carolina, North Dakota, Tennessee and Texas. State and local government offices and courts are closed, as well as some banks and postal offices in these states, and in those counties and municipalities where Good Friday is observed as a holiday. Good Friday is also a holiday in the U.S. territories of Guam, U.S. Virgin Islands and Puerto Rico.
The stock markets are closed on Good Friday but the foreign exchange and bond trading markets open for a partial business day. Most retail stores remain open, while some of them may close early. Public schools and universities are often closed on Good Friday, either as a holiday of its own, or part of spring break. The postal service operates, and banks regulated by the federal government do not close for Good Friday. In some governmental contexts Good Friday has been referred to by a generic name, particularly "spring holiday", presumably to avoid accusations of violating the Establishment Clause of the First Amendment of the U.S. Constitution.
Calculating the date.
Good Friday is the Friday before Easter, which is calculated differently in Eastern Christianity and Western Christianity (see Computus for details). Easter falls on the first Sunday following the Paschal Full Moon, the full moon on or after 21 March, taken to be the date of the vernal equinox. The Western calculation uses the Gregorian calendar, while the Eastern calculation uses the Julian calendar, whose 21 March now corresponds to the Gregorian calendar's 3 April. The calculations for identifying the date of the full moon also differ. See Computus.
In Eastern Christianity, Easter can fall between 22 March and 25 April on Julian Calendar (thus between 4 April and 8 May in terms of the Gregorian calendar, during the period 1900 and 2099), so Good Friday can fall between 20 March and 23 April, inclusive (or between 2 April and 6 May in terms of the Gregorian calendar).
Cultural references.
Good Friday assumes a particular importance in the plot of Richard Wagner's music drama "Parsifal", which contains an orchestral interlude known as the "Good Friday Music".
On Good Friday April 14, 1865, American President Abraham Lincoln was fatally shot by actor John Wilkes Booth.

</doc>
<doc id="58010" url="http://en.wikipedia.org/wiki?curid=58010" title="Pascha">
Pascha

Pascha may refer to:

</doc>
<doc id="58014" url="http://en.wikipedia.org/wiki?curid=58014" title="Basque">
Basque

Basque may refer to:
In geography:
In other uses:

</doc>
<doc id="58015" url="http://en.wikipedia.org/wiki?curid=58015" title="Mohave people">
Mohave people

Mohave or Mojave (Mojave: 'Aha Makhav) are a Native American people indigenous to the Colorado River in the Mojave Desert. The Fort Mojave Indian Reservation includes territory within the borders of California, Arizona, and Nevada. The Colorado River Indian Reservation includes parts of California and Arizona and is shared by members of the Chemehuevi, Hopi, and Navajo peoples.
The original Colorado River and Fort Mojave reservations were established in 1865 and 1870, respectively. Both reservations include substantial senior water rights in the Colorado River; water is drawn for use in irrigated farming. Though the four combined tribes sharing the Colorado River Indian Reservation function today as one geo-political unit known as the federally recognized Colorado River Indian Tribes, each continues to maintain and observe its individual traditions, distinct religions, and culturally unique identities.
The tribal headquarters, library and museum are in Parker, Arizona, about 40 miles (64 km) north of I-10. The National Indian Days Celebration is held annually in Parker, from Thursday through Sunday during the last week of September. The All-Indian Rodeo is also celebrated annually, on the first weekend in December. RV facilities are available along the Colorado River.
Culture.
In the 1930s, George Devereux, a Hungarian-French anthropologist, did fieldwork and lived among the Mohave for an extended period of study. He published extensively about their culture and incorporated psychoanalytic thinking in his interpretation of their culture.
Language.
The Mojave language belongs to the River Yuman branch of the Yuman language family. In 1994 approximately 75 people in total on the Colorado River and Fort Mojave reservations spoke the language according to Leanne Hinton. The tribe has published language materials, and there are new efforts to teach the language to their children.
Religion.
The Mohave creator is "Matevilya," who gave them their names and their commandments. His son is "Mastamho," who gave them the River and taught them how to plant. Historically this was an agrarian culture; they planted in the fertile floodplain of the untamed river, following the age-old customs of the Aha macave. They have traditionally used Datura in a religious sacrament. A Mohave who is coming of age must consume the plant in a rite of passage, in order to enter a new state of consciousness.
History.
Much of early Mojave history remains unwritten, since the Mojave language was not written in precolonial times. They depended on oral communication to transmit their history and culture from one generation to the next. The disruption of disease, outside cultures and encroachment on their territory disrupted their social organization. Together with having to adapt to a majority culture of another language, this resulted in interrupting the Mojave transmission of their stories and songs to the following generations.
The tribal name has been spelled in Spanish and English transliteration in more than 50 variations, such as "Hamock avi", "Amacava," "A-mac-ha ves", "A-moc-ha-ve", "Jamajabs", and "Hamakhav". This has led to misinterpretations of the tribal name, also partly traced to a translation error in Frederick W. Hodge's 1917 "Handbook of the American Indians North of Mexico" (1917). This incorrectly defined the name Mohave as being derived from "hamock," (three), and "avi," (mountain). According to this source, the name refers to the mountain peaks known as The Needles in English, located near the Colorado River. (The city of Needles, California is located a few miles north from here). But, the Mojave call these peaks "Huqueamp avi," which means "where the battle took place," referring to the battle in which the God-son, Mastamho, slew the sea serpent.
Ancestral lands.
The Mojave held lands along the river that stretched from Black Canyon, where the tall pillars of First House of Mutavilya loomed above the river, past Avi kwame or Spirit Mountain, the center of spiritual things, to the Quechan Valley, where the lands of other tribes began. Translated into present landmarks, their lands began in the north at Hoover Dam and ended about one hundred miles below Parker Dam on the Colorado River, or "aha kwahwat" in Mojave.
19th–20th centuries.
In mid-April 1859, United States troops of the Expedition of the Colorado, led by Lieutenant Colonel William Hoffman, moved upriver into Mojave country with the well-publicized objective of establishing a military post. It was intended to protect east-west European-American emigrants from attack by the Mojave. By that time, white immigrants and settlers had begun to encroach on Mojave lands. In competition for scarce resources in the desert, they sometimes got into violent conflict with the indigenous people, who were trying to protect their territory. Hoffman sent couriers among the tribes, warning that the post would be gained by force if they or their allies chose to resist. Instead, the army occupied the site without armed conflict.
The Mojave warriors withdrew as Hoffman's formidable armada approached, and the expedition posted camp near the future Fort Mojave. Hoffman ordered the Mojave men to assemble at the armed stockade adjacent to his headquarters; two days later, on April 23, 1859, clan chiefs came as ordered to hear Hoffman's terms of peace. Hoffman gave them the choice of submission or extermination. They chose peace. At that time, the Mojave had a traditional culture that had existed for centuries, unchanged by the few parties of white men who had traveled through their country. Among a Mojave population estimated to be about 4,000 in total, they had 22 clans identified by totems.
During most of the period of military occupation, the Mojave were technically under the jurisdiction of the Office of Indian Affairs of the Department of the Interior. Legally they belonged on the Colorado River Reservation after it was established in 1865. But when many Mojave refused to leave their ancestral homes in the Mojave Valley, the War Department declined to try to force them onto the reservation. The US Indian Agent could not supervise them at a distance. As long as Fort Mojave was garrisoned by the War Department, the Mojave in that area were relatively free to follow their tribal ways. In the midsummer of 1890, the War Department withdrew its troops, after the end of the period of migration and Indian Wars. The post was transferred to the Department of the Interior and its Office of Indian Affairs.
Beginning in August 1890, Indian Affairs began an intensive program of assimilation; federal policy was based on the belief that this was the only way the peoples could survive. The US Indian agent forced the Mohave and other native children living on reservations into schools to learn to speak, write, and read English. Fort Mojave was converted into an boarding school for Fort Mojave and other "non-reservation" Indians. Until 1931, forty-one years later, all Fort Mojave boys and girls between the ages of six and eighteen were compelled to live at this school or to attend an advanced Indian boarding school remote from Fort Mojave.
In this period, the federal government was trying to assimilate Indians to European-American culture by breaking up tribal culture and governments. The schools taught American culture, customs and English, and insisted that Indian children follow the patterns of the majority culture. At the school the students were required to cut their hair and use European-American hairstyles, clothing, habits of eating, sleeping, toiletry, manners, industry, and language. They were forbidden to use their own language and customs. These were punished when observed. Five lashes of the whip was the penalty for the first offense of speaking in their native tongue. Such corporal punishment of children scandalized the Mojave, who did not discipline their children this way.
The administrators of the reservations' school systems assigned English names to the children. They were registered with the Department of the Interior as members of two tribes, the Mojave Tribe on the Colorado River Reservation and the Fort Mojave Indian Tribe on the Fort Mojave Indian Reservation. These divisions did not reflect the traditional Mojave clan and kinship system. By the late 1960s, 18 of the traditional clans survived.
Population.
Estimates for the pre-contact populations of most native groups in California have varied substantially. The Franciscan missionary-explorer Francisco Garcés estimated the Mohave population in 1776 as approximately 3,000 Mojave Indians (Garcés 1900(2):450). Alfred L. Kroeber (1925:883) also put the 1770 population of the Mohave at 3,000.
A.L. Kroeber estimated the population of the Mohave in 1910 as 1,050. Lorraine M. Sherer's research revealed that by 1963, the population of Fort Mojave was 438 and that of the Colorado River Reservation approximately 550.

</doc>
<doc id="58017" url="http://en.wikipedia.org/wiki?curid=58017" title="Microwave oven">
Microwave oven

A microwave oven, commonly referred to as a microwave, is a kitchen appliance that heats and cooks food by exposing it to electromagnetic radiation in the microwave spectrum. This induces polarized molecules in the food to rotate and produce thermal energy in a process known as dielectric heating. Microwave ovens heat foods quickly and efficiently because excitation is fairly uniform in the outer 25–38 mm (1–1.5 inches) of a homogenous (high water content) food item; food is more evenly heated throughout (except in heterogeneous, dense objects) than generally occurs in other cooking techniques.
Percy Spencer invented the first microwave oven after World War II from radar technology developed during the war. Named the "Radarange", it was first sold in 1946. Raytheon later licensed its patents for a home-use microwave oven that was first introduced by Tappan in 1955, but these units were still too large and expensive for general home use. The countertop microwave oven was first introduced in 1967 by the Amana Corporation, and their use has spread into commercial and residential kitchens around the world.
Microwave ovens are popular for reheating previously cooked foods and cooking a variety of foods. They are also useful for rapid heating of otherwise slowly prepared cooking items, such as hot butter, fats, and chocolate. Unlike conventional ovens, microwave ovens usually do not directly brown or caramelize food, since they rarely attain the necessary temperatures to produce Maillard reactions. Exceptions occur in rare cases where the oven is used to heat frying-oil and other very oily items (such as bacon), which attain far higher temperatures than that of boiling water. Microwave ovens have a limited role in professional cooking, because the boiling-range temperatures produced in especially hydrous foods impede flavors produced by the higher temperatures of frying, browning, or baking. However, additional heat sources can be added to microwave ovens, or into combination microwave ovens, to produce these other heating effects, and microwave heating may cut the overall time needed to prepare such dishes. Some modern microwave ovens may be part of an over-the-range unit with built-in extractor hoods.
History.
Early developments.
The exploitation of high frequency radio waves for heating substances was made possible by the development of vacuum tube radio transmitters around 1920. By 1930 the application of short waves to heat human tissue had developed into the medical therapy of diathermy. At the 1933 Chicago World's Fair, Westinghouse demonstrated the cooking of foods between two metal plates attached to a 10 kW, 60 MHz shortwave transmitter. The Westinghouse team, led by I. F. Mouromtseff, found that foods like steaks and potatoes could be cooked in minutes. 
The 1937 United States patent application by Bell Laboratories states and also in Canada:
 "This invention relates to heating systems for dielectric materials and the object of the invention is to heat such materials uniformly and substantially simultaneously throughout their mass. ... It has been proposed therefore to heat such materials simultaneously throughout their mass by means of the dielectric loss produced in them when they are subjected to a high voltage, high frequency field."
However, lower-frequency dielectric heating, as described in the aforementioned patent, is (like induction heating) an electromagnetic heating effect, the result of the so-called near-field effects that exist in an electromagnetic cavity that is small compared with the wavelength of the electromagnetic field. This patent proposed radio frequency heating, at 10 to 20 megahertz (wavelength 15 to 30 meters). Heating from microwaves that have a wavelength that is small relative to the cavity (as in a modern microwave oven) is due to "far-field" effects that are due to classical electromagnetic radiation that describes freely propagating light and microwaves suitably far from their source. Nevertheless, the primary heating effect of all types of electromagnetic fields at both radio and microwave frequencies occurs via the dielectric heating effect, as polarized molecules are affected by a rapidly alternating electric field.
Cavity magnetron.
The invention of the cavity magnetron made possible the production of electromagnetic waves of a small enough wavelength (microwaves). The magnetron was originally a crucial component in the development of short wavelength radar during World War II. In 1937–1940, a multi-cavity magnetron was built by the British physicist Sir John Turton Randall, FRSE, together with a team of British coworkers, for the British and American military radar installations in World War II. A more high-powered microwave generator that worked at shorter wavelengths was needed, and in 1940, at the University of Birmingham, John Randall and Harry Boot produced a working prototype.
Sir Henry Tizard travelled to the U.S. to offer them the magnetron in exchange for their financial and industrial help (see Tizard Mission). An early 6 kW version, built in England by the General Electric Company Research Laboratories, Wembley, London, was given to the U.S. government in September 1940. Contracts were awarded to Raytheon and other companies for mass production of the magnetron.
Discovery.
In 1945 the specific heating effect of a high-power microwave beam was accidentally discovered by Percy Spencer, an American self-taught engineer from Howland, Maine. Employed by Raytheon at the time he noticed that microwaves from an active radar set he was working on started to melt a candy bar he had in his pocket. The first food deliberately cooked with Spencer's microwave was popcorn, and the second was an egg, which exploded in the face of one of the experimenters. To verify his finding, Spencer created a high density electromagnetic field by feeding microwave power from a magnetron into a metal box from which it had no way to escape. When food was placed in the box with the microwave energy, the temperature of the food rose rapidly.
On 8 October 1945, Raytheon filed a United States patent application for Spencer's microwave cooking process, and an oven that heated food using microwave energy from a magnetron was soon placed in a Boston restaurant for testing. The first time the public was able to use a microwave oven was in January 1947, when the Speedy Weeny vending machine was placed in Grand Central Terminal to dispense "sizzling delicious" hot dogs. Among those on the development team was robotics pioneer George Devol, who had spent the last part of the war developing radar countermeasures.
Commercial availability.
In 1947, Raytheon built the "Radarange", the first commercially available microwave oven. It was almost 1.8 m tall, weighed 340 kg and cost about US$5,000 ($ in today's dollars) each. It consumed 3 kilowatts, about three times as much as today's microwave ovens, and was water-cooled. An early Radarange was installed (and remains) in the galley of the nuclear-powered passenger/cargo ship NS "Savannah". An early commercial model introduced in 1954 consumed 1.6 kilowatts and sold for US$2,000 to US$3,000 ($ to $ in today's dollars). Raytheon licensed its technology to the Tappan Stove company of Mansfield, Ohio in 1952. They tried to market a large 220 volt wall unit as a home microwave oven in 1955 for a price of US$1,295 ($ in today's dollars), but it did not sell well. In 1965, Raytheon acquired Amana. In 1967, they introduced the first popular home model, the countertop Radarange, at a price of US$495 ($ in today's dollars).
In the 1960s, Litton bought Studebaker's Franklin Manufacturing assets, which had been manufacturing magnetrons and building and selling microwave ovens similar to the Radarange. Litton then developed a new configuration of the microwave: the short, wide shape that is now common. The magnetron feed was also unique. This resulted in an oven that could survive a no-load condition: an empty microwave oven where there is nothing to absorb the microwaves. The new oven was shown at a trade show in Chicago, and helped begin a rapid growth of the market for home microwave ovens. Sales volume of 40,000 units for the U.S. industry in 1970 grew to one million by 1975. Market penetration was faster in Japan, due to a re-engineered magnetron allowing for less expensive units.
Several other companies joined in the market, and for a time most systems were built by defense contractors, who were most familiar with the magnetron. Litton was particularly well known in the restaurant business.
Residential use.
By the late 1970s, technological advances led to rapidly falling prices. Often called "electronic ovens" in the 1960s, the name "microwave oven" later gained currency, and they are now informally called "microwaves".
Formerly found only in large industrial applications, microwave ovens increasingly became a standard fixture of residential kitchens in developed countries. By 1986, roughly 25% of households in the U.S. owned a microwave oven, up from only about 1% in 1971; the U.S. Bureau of Labor Statistics reported that over 90% of American households owned a microwave oven in 1997. In Australia, a 2008 market research study found that 95% of kitchens contained a microwave oven and that 83% of them were used daily. In Canada, fewer than 5% of households had a microwave oven in 1979, but more than 88% of households owned one by 1998. In France, 40% of households owned a microwave oven in 1994, but that number had increased to 65% by 2004.
Adoption has been slower in less-developed countries, as households with disposable income concentrate on more important household appliances like refrigerators and ovens. In India in 2013, for example, only about 5% of households owned a microwave, well behind refrigerators at 31% ownership. Microwave ovens are gaining popularity, however. In Russia, the number of households with a microwave grew from almost 24% in 2002 to almost 40% in 2008. Almost twice as many households in South Africa owned microwaves in 2008 (38.7%) than in 2002 (19.8%). Microwave ownership in Vietnam was at 16% of households in 2008—versus 30% ownership of refrigerators—but this rate was up significantly from 6.7% microwave ownership in 2002—and 14% for refrigerators.
Principles.
A microwave oven heats food by passing microwave radiation through it. Microwaves are a form of non-ionizing electromagnetic radiation with a frequency higher than ordinary radio waves but lower than infrared light. Microwave ovens use frequencies in one of the ISM (industrial, scientific, medical) bands, which are reserved for this use, so they don't interfere with other vital radio services. Consumer ovens usually use 2.45 gigahertz (GHz)—a wavelength of 12.2 cm—while large industrial/commercial ovens often use 915 megahertz (MHz)—32.8 cm. Water, fat, and other substances in the food absorb energy from the microwaves in a process called dielectric heating. Many molecules (such as those of water) are electric dipoles, meaning that they have a partial positive charge at one end and a partial negative charge at the other, and therefore rotate as they try to align themselves with the alternating electric field of the microwaves. Rotating molecules hit other molecules and put them into motion, thus dispersing energy. This energy, when dispersed as molecular vibration in solids and liquids (i.e. as both potential energy and kinetic energy of atoms), is heat. Sometimes, microwave heating is explained as a resonance of water molecules, but this is incorrect; such resonances occur only at above 1 terahertz (THz).
Microwave heating is more efficient on liquid water than on frozen water, where the movement of molecules is more restricted. Dielectric heating of liquid water is also temperature-dependent: At 0 °C, dielectric loss is greatest at a field frequency of about 10 GHz, and for higher water temperatures at higher field frequencies.
Compared to liquid water, microwave heating is less efficient on fats and sugars (which have a smaller molecular dipole moment). Sugars and triglycerides (fats and oils) absorb microwaves due to the dipole moments of their hydroxyl groups or ester groups. However, due to the lower specific heat capacity of fats and oils and their higher vaporization temperature, they often attain much higher temperatures inside microwave ovens. This can induce temperatures in oil or very fatty foods like bacon far above the boiling point of water, and high enough to induce some browning reactions, much in the manner of conventional broiling (UK: grilling), braising, or deep fat frying. Foods high in water content and with little oil rarely exceed the boiling temperature of water.
Microwave heating can cause localized thermal runaways in some materials with low thermal conductivity which also have dielectric constants that increase with temperature. An example is glass, which can exhibit thermal runaway in a microwave to the point of melting if preheated. Additionally, microwaves can melt certain types of rocks, producing small quantities of synthetic lava. Some ceramics can also be melted, and may even become clear upon cooling. Thermal runaway is more typical of electrically conductive liquids such as salty water.
A common misconception is that microwave ovens cook food "from the inside out", meaning from the center of the entire mass of food outwards. This idea arises from heating behavior seen if an absorbent layer of water lies beneath a less absorbent drier layer at the surface of a food; in this case, the deposition of heat energy inside a food can exceed that on its surface. This can also occur if the inner layer has a lower heat capacity than the outer layer causing it to reach a higher temperature, or even if the inner layer is more thermally conductive than the outer layer making it feel hotter despite having a lower temperature. In most cases, however, with uniformly structured or reasonably homogenous food item, microwaves are absorbed in the outer layers of the item at a similar level to that of the inner layers. Depending on water content, the depth of initial heat deposition may be several centimetres or more with microwave ovens, in contrast to broiling/grilling (infrared) or convection heating—methods which deposit heat thinly at the food surface. Penetration depth of microwaves is dependent on food composition and the frequency, with lower microwave frequencies (longer wavelengths) penetrating further.
Heating efficiency.
A microwave oven converts only part of its electrical input into microwave energy. An average consumer microwave oven consumes 1100 W of electricity in producing 700 W of microwave power, an efficiency of 64%. The other 400 W are dissipated as heat, mostly in the magnetron tube. Additional power is used to operate the lamps, AC power transformer, magnetron cooling fan, food turntable motor and the control circuits. Such wasted heat, along with heat from the product being microwaved, is exhausted as warm air through cooling vents.
For cooking or reheating small amounts of food, the microwave oven may use less energy than a cook stove. Although microwave ovens are touted as the most efficient appliance, the energy savings are largely due to the reduced heat mass of the food's container. The amount of energy used to heat food is generally small compared to total energy usage in typical residences in the United States.
Design.
A microwave oven consists of:
Modern microwave ovens use either an analog dial-type timer or a digital control panel for operation. Control panels feature an LED, liquid crystal or vacuum fluorescent display, numeric buttons for entering the cook time, a power level selection feature and other possible functions such as a defrost setting and pre-programmed settings for different food types, such as meat, fish, poultry, vegetables, frozen vegetables, frozen dinners, and popcorn. In most ovens, the magnetron is driven by a linear transformer which can only feasibly be switched completely on or off. As such, the choice of power level does not affect the intensity of the microwave radiation; instead, the magnetron is cycled on and off every few seconds. Newer models have inverter power supplies that use pulse width modulation to provide effectively continuous heating at reduced power, so that foods are heated more evenly at a given power level and can be heated more quickly without being damaged by uneven heating.
The microwave frequencies used in microwave ovens are chosen based on regulatory and cost constraints. The first is that they should be in one of the industrial, scientific, and medical (ISM) frequency bands set aside for non-communication purposes. For household purposes, 2.45 GHz has the advantage over 915 MHz in that 915 MHz is only an ISM band in the ITU Region 2 while 2.45 GHz is available worldwide. Three additional ISM bands exist in the microwave frequencies, but are not used for microwave cooking. Two of them are centered on 5.8 GHz and 24.125 GHz, but are not used for microwave cooking because of the very high cost of power generation at these frequencies. The third, centered on 433.92 MHz, is a narrow band that would require expensive equipment to generate sufficient power without creating interference outside the band, and is only available in some countries.
The cooking chamber is similar to a Faraday cage (but there is no continuous metal-to-metal contact around the rim of the door), and prevents the waves from coming out of the oven. The oven door usually has a window for easy viewing, with a layer of conductive mesh some distance from the outer panel to maintain the shielding. Because the size of the perforations in the mesh is much less than the microwaves' wavelength (12.2 cm for the usual 2.45 GHz), most of the microwave radiation cannot pass through the door, while visible light (with its much shorter wavelength) can.
Variants and accessories.
A quantitative, model-based understanding of heat exchange in infrared and combined infrared-microwave heating of food inside an oven is developed. A variant of the conventional microwave is the convection microwave. A convection microwave oven is a combination of a standard microwave and a convection oven. It allows food to be cooked quickly, yet come out browned or crisped, as from a convection oven. Convection microwaves are more expensive than conventional microwave ovens. Some convection microwaves—those with exposed heating elements—can produce smoke and burning odors as food spatter from earlier microwave-only use is burned off the heating elements.
In 2000, some manufacturers began offering high power quartz halogen bulbs to their convection microwave models, marketing them under names such as "Speedcook", "Advantium" , "Lightwave" and "Optimawave" to emphasize their ability to cook food rapidly and with good browning. The bulbs heat the food's surface with infrared (IR) radiation, browning surfaces as in a conventional oven. The food browns while also being heated by the microwave radiation and heated through conduction through contact with heated air. The IR energy which is delivered to the outer surface of food by the lamps is sufficient to initiate browning caramelization in foods primarily made up of carbohydrates and Maillard reactions in foods primarily made up of protein. These reactions in food produce a texture and taste similar to that typically expected of conventional oven cooking rather than the bland boiled and steamed taste that microwave-only cooking tends to create.
In order to aid browning, sometimes an accessory browning tray is used, usually composed of glass or porcelain. It makes food crisp by oxidizing the top layer until it turns brown. Ordinary plastic cookware is unsuitable for this purpose because it could melt.
Frozen dinners, pies, and microwave popcorn bags often contain a susceptor made from thin aluminium film in the packaging or included on a small paper tray. The metal film absorbs microwave energy efficiently and consequently becomes extremely hot and radiates in the infrared, concentrating the heating of oil for popcorn or even browning surfaces of frozen foods. Heating packages or trays containing susceptors are designed for single use and are discarded as waste.
Microwave-safe plastics.
Some current plastic containers and food wraps are specifically designed to resist radiation from microwaves. Products may use the term "microwave safe", may carry a microwave symbol (three lines of waves, one above the other) or simply provide instructions for proper microwave use. Any of these is an indication that a product is suitable for microwaving when used in accordance with the directions provided.
Benefits and safety features.
Commercial microwave ovens all use a timer in their standard operating mode; when the timer runs out, the oven turns itself off.
Microwave ovens heat food without getting hot themselves. Taking a pot off a stove, unless it is an induction cooktop, leaves a potentially dangerous heating element or trivet that will stay hot for some time. Likewise, when taking a casserole out of a conventional oven, one's arms are exposed to the very hot walls of the oven. A microwave oven does not pose this problem.
Food and cookware taken out of a microwave oven are rarely much hotter than 100 C. Cookware used in a microwave oven is often much cooler than the food because the cookware is transparent to microwaves; the microwaves heat the food directly and the cookware is indirectly heated by the food. Food and cookware from a conventional oven, on the other hand, are the same temperature as the rest of the oven; a typical cooking temperature is 180 C. That means that conventional stoves and ovens can cause more serious burns.
The lower temperature of cooking (the boiling point of water) is a significant safety benefit compared to baking in the oven or frying, because it eliminates the formation of tars and char, which are carcinogenic. Microwave radiation also penetrates deeper than direct heat, so that the food is heated by its own internal water content. In contrast, direct heat can fry the surface while the inside is still cold. Pre-heating the food in a microwave oven before putting it into the grill or pan reduces the time needed to heat up the food and reduces the formation of carcinogenic char. Unlike frying and baking, microwaving does not produce acrylamide in potatoes, however unlike deep-frying, it is of only limited effectiveness in reducing glycoalkaloid (i.e. solanine) levels. Acrylamide has been found in other microwaved products like popcorn.
Heating characteristics.
Microwave ovens are frequently used for reheating leftover food, and bacterial contamination may not be repressed if the safe temperature is not reached, resulting in foodborne illness, as with all inadequate reheating methods.
Uneven heating in microwaved food can be partly due to the uneven distribution of microwave energy inside the oven, and partly due to the different rates of energy absorption in different parts of the food. The first problem is reduced by a stirrer, a type of fan that reflects microwave energy to different parts of the oven as it rotates, or by a turntable or carousel that turns the food; turntables, however, may still leave spots, such as the center of the oven, which receive uneven energy distribution. The location of dead spots and hot spots in a microwave can be mapped out by placing a damp piece of thermal paper in the oven. When the water saturated paper is subjected to the microwave radiation it becomes hot enough to cause the dye to be released which will provide a visual representation of the microwaves. If multiple layers of paper are constructed in the oven with a sufficient distance between them a three-dimensional map can be created. Many store receipts are printed on thermal paper which allows this to be easily done at home.
The second problem is due to food composition and geometry, and must be addressed by the cook, by arranging the food so that it absorbs energy evenly, and periodically testing and shielding any parts of the food that overheat. In some materials with low thermal conductivity, where dielectric constant increases with temperature, microwave heating can cause localized thermal runaway. Under certain conditions, glass can exhibit thermal runaway in a microwave to the point of melting.
Due to this phenomenon, microwave ovens set at too-high power levels may even start to cook the edges of frozen food while the inside of the food remains frozen. Another case of uneven heating can be observed in baked goods containing berries. In these items, the berries absorb more energy than the drier surrounding bread and cannot dissipate the heat due to the low thermal conductivity of the bread. Often this results in overheating the berries relative to the rest of the food. "Defrost" oven settings use low power levels designed to allow time for heat to be conducted within frozen foods from areas that absorb heat more readily to those which heat more slowly. In turntable-equipped ovens, more even heating will take place by placing food off-centre on the turntable tray instead of exactly in the centre.
Microwave heating can be deliberately uneven by design. Some microwavable packages (notably pies) may include materials that contain ceramic or aluminium flakes, which are designed to absorb microwaves and heat up, thereby converting microwaves to less penetrating infrared, which aids in baking or crust preparation by depositing more energy shallowly in these areas. Such ceramic patches affixed to cardboard are positioned next to the food, and are typically smokey blue or gray in colour, usually making them easily identifiable; the cardboard sleeves included with Hot Pockets, which have a silver surface on the inside, are a good example of such packaging. Microwavable cardboard packaging may also contain overhead ceramic patches which function in the same way. The technical term for such a microwave-absorbing patch is a susceptor.
Effects on food and nutrients.
Comparative cooking method studies generally find that, if properly used, microwave cooking does not affect the nutrient content of foods to a larger extent than conventional heating, and that there is a tendency towards greater retention of many micronutrients with microwaving, probably due to the reduced preparation time. Microwaving human milk at high temperatures is contraindicated, due to a marked decrease in activity of anti-infective factors.
Any form of cooking will destroy some nutrients in food, but the key variables are how much water is used in the cooking, how long the food is cooked, and at what temperature. Nutrients are primarily lost by leaching into cooking water, which tends to make microwave cooking healthier, given the shorter cooking times it requires. Like other heating methods, microwaving converts vitamin B12 from an active to inactive form. The amount inactivated depends on the temperature reached, as well as the cooking time. Boiled food reaches a maximum of 100 Celsius (the boiling point of water), whereas microwaved food can get locally hotter than this, leading to faster breakdown of vitamin B12. The higher rate of loss is partially offset by the shorter cooking times required. A single study indicated that microwaving broccoli loses 74% or more of phenolic compounds (97% of flavonoids), while boiling loses 66% of flavonoids, and high-pressure boiling loses 47%, though the study has been contradicted by other studies. To minimize phenolic losses in potatoes, microwaving should be done at 500W.
Spinach retains nearly all its folate when cooked in a microwave; in comparison, it loses about 77% when boiled, leaching out nutrients. Bacon cooked by microwave has significantly lower levels of carcinogenic nitrosamines than conventionally cooked bacon. Steamed vegetables tend to maintain more nutrients when microwaved than when cooked on a stovetop. Microwave blanching is 3-4 times more effective than boiled water blanching in the retaining of the water-soluble vitamins folic acid, thiamin and riboflavin, with the exception of ascorbic acid, of which 28.8% is lost (vs. 16% with boiled water blanching).
Use in cleaning kitchen sponges.
Studies have investigated the use of the microwave to clean non-metallic domestic sponges which have been thoroughly wetted. A 2006 study found that microwaving wet sponges for two minutes (at 1000 watt power) removed 99% of coliforms, E. coli and MS2 phages, and Bacillus cereus spores were killed at 4 minutes of microwaving. 
Hazards.
High temperatures.
Homogeneous liquids can superheat when heated in a microwave oven in a container with a smooth surface. That is, the liquid reaches a temperature slightly above its normal boiling point without bubbles of vapour forming inside the liquid. The boiling process can start explosively when the liquid is disturbed, such as when the user takes hold of the container to remove it from the oven or while adding solid ingredients such as powdered creamer or sugar. This can result in spontaneous boiling (nucleation) which may be violent enough to eject the boiling liquid from the container and cause severe scalding.
Closed containers, such as eggs, can explode when heated in a microwave oven due to the increased pressure from steam. Insulating plastic foams of all types generally contain closed air pockets, and are generally not recommended for use in a microwave, as the air pockets explode and the foam (which can be toxic if consumed) may melt. Not all plastics are microwave-safe, and some plastics absorb microwaves to the point that they may become dangerously hot.
Products that are heated for too long can catch fire. Though this is inherent to any form of cooking, the rapid cooking and unattended nature of the use of microwave ovens results in additional hazard.
Metal objects.
Any metal or conductive object placed into the microwave will act as an antenna to some degree, resulting in an electric current. This causes the object to act as a heating element. This effect varies with the object's shape and composition, and is sometimes utilized for cooking.
Any object containing pointed metal can create an electric arc (sparks) when microwaved. This includes cutlery, crumpled aluminium foil (though some foil used in microwaves are safe, see below), twist-ties containing metal wire, the metal wire carry-handles in paper Chinese take-out food containers, or almost any metal formed into a poorly conductive foil or thin wire; or into a pointed shape. Forks are a good example: the tines of the fork respond to the electric field by producing high concentrations of electric charge at the tips. This has the effect of exceeding the dielectric breakdown of air, about 3 megavolts per meter (3×106 V/m). The air forms a conductive plasma, which is visible as a spark. The plasma and the tines may then form a conductive loop, which may be a more effective antenna, resulting in a longer lived spark. When dielectric breakdown occurs in air, some ozone and nitrogen oxides are formed, both of which are unhealthy in large quantities.
It is possible for metal objects to be microwave-oven compatible, although experimentation by users is not encouraged. Microwaving an individual smooth metal object without pointed ends, for example, a spoon or shallow metal pan, usually does not produce sparking. Thick metal wire racks can be part of the interior design in microwave ovens (see illustration). In a similar way, the interior wall plates with perforating holes which allow light and air into the oven, and allow interior-viewing through the oven door, are all made of conductive metal formed in a safe shape.
The effect of microwaving thin metal films can be seen clearly on a Compact Disc or DVD (particularly the factory pressed type). The microwaves induce electric currents in the metal film, which heats up, melting the plastic in the disc and leaving a visible pattern of concentric and radial scars. Similarly, porcelain with thin metal films can also be destroyed or damaged by microwaving. Aluminium foil is thick enough to be used in microwave ovens as a shield against heating parts of food items, if the foil is not badly warped. When wrinkled, aluminium foil is generally unsafe in microwaves, as manipulation of the foil causes sharp bends and gaps that invite sparking. The USDA recommends that aluminium foil used as a partial food shield in microwave cooking cover no more than one quarter of a food object, and be carefully smoothed to eliminate sparking hazards.
Another hazard is the resonance of the magnetron tube itself. If the microwave is run without an object to absorb the radiation, a standing wave will form. The energy is reflected back and forth between the tube and the cooking chamber. This may cause the tube to overload and burn out. For the same reason, dehydrated food, or food wrapped in metal which does not arc, is problematic for overload reasons, without necessarily being a fire hazard.
Certain foods such as grapes, if properly arranged, can produce an electric arc. Prolonged arcing from food carries similar risks to arcing from other sources as noted above.
Some other objects that may conduct sparks are plastic/holographic print thermoses (such as Starbuck's novelty cups) or cups with metal lining. If any bit of the metal is exposed, all the outer shell will burst off the object or melt.
The high electrical fields generated inside a microwave often can be illustrated by placing a radiometer or neon glow-bulb inside the cooking chamber, creating glowing plasma inside the low-pressure bulb of the device.
Direct microwave exposure.
Direct microwave exposure is not generally possible, as microwaves emitted by the source in a microwave oven are confined in the oven by the material out of which the oven is constructed. Furthermore, ovens are equipped with redundant safety interlocks, which remove power from the magnetron if the door is opened. This safety mechanism is required by United States federal regulations. Tests have shown confinement of the microwaves in commercially available ovens to be so nearly universal as to make routine testing unnecessary. According to the United States Food and Drug Administration's Center for Devices and Radiological Health, a U.S. Federal Standard limits the amount of microwaves that can leak from an oven throughout its lifetime to 5 milliwatts of microwave radiation per square centimeter at approximately 5 cm (2 in) from the surface of the oven. This is far below the exposure level currently considered to be harmful to human health.
The radiation produced by a microwave oven is non-ionizing. It therefore does not have the cancer risks associated with ionizing radiation such as X-rays and high-energy particles. Long-term rodent studies to assess cancer risk have so far failed to identify any carcinogenicity from 2.45 GHz microwave radiation even with chronic exposure levels (i.e. large fraction of life span) far larger than humans are likely to encounter from any leaking ovens. However, with the oven door open, the radiation may cause damage by heating. Every microwave oven sold has a protective interlock so that it cannot be run when the door is open or improperly latched.
Microwaves generated in microwave ovens cease to exist once the electrical power is turned off. They do not remain in the food when the power is turned off. They do not make the food or the oven radioactive. There is some evidence that nutritional content of some foods may be altered differently by cooking in a microwave oven, compared to conventional cooking, but there is no indication of detrimental health issues associated with microwaved food. 
There are, however, a few cases where people have been exposed to direct microwave radiation, either from appliance malfunction or deliberate action.
Chemical exposure.
Some magnetrons have ceramic insulators with beryllium oxide (beryllia) added. The beryllium in such oxides is a serious chemical hazard if crushed and ingested (for example, by inhaling dust). In addition, beryllia is listed as a confirmed human carcinogen by the IARC; therefore, broken ceramic insulators or magnetrons should not be handled. This is obviously a danger only if the microwave oven becomes physically damaged, such as if the insulator cracks, or when the magnetron is opened and handled directly, and as such should not be a concern during normal usage.

</doc>
<doc id="58018" url="http://en.wikipedia.org/wiki?curid=58018" title="Tora! Tora! Tora!">
Tora! Tora! Tora!

Tora! Tora! Tora! (Japanese: トラ・トラ・トラ) is a 1970 American–Japanese war film that dramatizes the Japanese attack on Pearl Harbor. The film was directed by Richard Fleischer and stars an ensemble cast, including Martin Balsam, Joseph Cotten, Sō Yamamura, E. G. Marshall, James Whitmore and Jason Robards.
The title is the Japanese codeword used to indicate that complete surprise had been achieved. "Tora" (虎, ]) literally means "tiger", but in this case was an acronym for "totsugeki raigeki"　(突撃雷撃, "lightning attack").
Plot.
In 1941, the newly appointed Commander-in-Chief of the Combined Fleet Admiral Isoroku Yamamoto (Sō Yamamura) and his predecessor, Zengo Yoshida (Junya Usami), discuss America's embargo that starves Japan of raw materials. While both agree that a war with the United States would be a complete disaster, army hotheads and politicians push through an alliance with Germany and start planning for war. With the U.S. Pacific fleet at Pearl Harbor, Yamamoto orders the planning of a preventive strike, believing Japan's only hope is to annihilate the American Pacific fleet at the outset of hostilities.
When planning the attack, the Japanese commanders modify their torpedoes to dive to only 35 ft, negating Pearl Harbor’s shallow waters, which the Americans feel is a natural defense against torpedoes. In a major intelligence victory, American intelligence in Washington manages to break the Japanese "Purple Code", allowing the United States to intercept secret Japanese radio transmissions. Monitoring the transmissions are U.S. Army Col. Bratton (E. G. Marshall) and
U.S. Navy Lt. Commander Kramer (Wesley Addy).
Japanese commanders call on the famous Air Staff Officer Minoru Genda (Tatsuya Mihashi) to mastermind the attack. Genda's Japanese Naval Academy classmate, Mitsuo Fuchida (Takahiro Tamura), is chosen to be the leader of the attack. At Pearl Harbor, although hampered by a late-arriving critical intelligence report about the attack fleet, Admiral Kimmel (Martin Balsam) and General Short (Jason Robards) do their best to enhance defenses. Short orders his aircraft to be concentrated in the middle of their airfields to prevent sabotage, though leaving them vulnerable to an air raid.
Diplomatic tensions increase between the U.S. and Japan as the Japanese ambassador continues negotiations to avoid war. Army General Hideki Tojo (Asao Uchida) is adamantly opposed to any last minute attempts at peace. The Japanese commence a series of 14 radio messages from Tokyo to the Japanese embassy in Washington that will conclude with the declaration of war. The final message will be received precisely at 1:00 pm on December 7, after which the Japanese embassy is to destroy the code machines, an ominous point. Attempts to convey this message to American commanders fail because it is Sunday and they have the day off. Finally, Chief of Naval Operations Harold R. Stark (Edward Andrews) is informed of the increased threat, but decides not to inform Hawaii until after calling the President, although it is not clear if he takes any action at all.
Finally, at 11:30 am, Colonel Bratton convinces the Army Chief of Staff, General George Marshall (Keith Andes), that a greater threat exists, and Marshall orders that Pearl Harbor be notified of an impending attack. An American destroyer, USS "Ward", spots a Japanese midget submarine trying to slip through the defensive net and enter Pearl Harbor, sinks it, and notifies the base. Although the receiving officer, Lieutenant Kaminsky (Neville Brand), takes the report of an attempted foreign incursion seriously, Captain John Earle (Richard Anderson) at Pearl Harbor demands confirmation before calling an alert. Admiral Kimmel later learns of this negligence and is furious he was not told of this foreign action immediately. Meanwhile, the two privates posted at the remote radar spot the incoming Japanese aircraft and inform the Hickham Field Information Center, but the Army Air Forces Lieutenant in charge, Kermit Tyler (Jerry Cox), dismisses the report, thinking it is a group of American B-17 bombers coming from the mainland.
The Japanese intend to break off negotiations at 1:00 pm, 30 minutes before the attack. However, the typist for the Japanese ambassador is slow, and cannot decode the 14th message fast enough. A final attempt to warn Pearl Harbor is stymied by poor atmospherics and bungling when the telegram is not marked urgent; it will be received by Pearl Harbor after the attack. The incoming Japanese fighter pilots don't even receive any anti-aircraft fire as they approach the base. As a result, the squadron leader radios in the code phrase marking that complete surprise for the attack has been achieved: "Tora! Tora! Tora!"
Once the attack is launched, the Americans are not even aware that they are under an organized attack until the first bomb detonates, and their resulting hasty response is desperate and only partially effective. The aircraft security precautions prove a disastrous mistake that allows the Japanese aerial forces to destroy the U.S. aircraft on the ground with ease, thereby crippling an effective aerial counter-attack: all the aircraft on the runways at the major airfields were destroyed either as they took off or while they were still parked. Two American fighter pilots (portrayals of Second Lieutenants Ken Taylor and George Welch) race to remote Haleiwa and manage to take off to engage the attacking planes, as the Japanese have not hit the smaller airfields.
The catastrophic damage to the naval base is widespread, with sailors fighting as long as they can and then abandoning sinking ships and jumping into the water with burning oil on the surface. At the end of the attacks, with the Pearl Harbor base in flames, its frustrated commanders finally get the Pentagon's telegram warning them of impending danger. The Secretary of State, Cordell Hull (George Macready), is stunned at learning of this brazen attack and urgently requests confirmation of it before receiving the Japanese ambassador, who is waiting just outside his office. In Washington, the distraught Japanese ambassador (Shōgo Shimada), helpless to explain the late ultimatum and the unprovoked sneak attack, is bluntly rebuffed by Hull.
The Japanese fleet commander, Admiral Chuichi Nagumo (Eijiro Tono), refuses to launch the third wave of carrier aircraft out of fear of exposing his six carriers to increased risk of detection and destruction from the still-absent U.S. carriers. At his home base, Admiral Yamamoto laments the fact that the Americans did not receive the declaration of war until after the attack had started, noting that nothing would infuriate the Americans more. He says: "I fear all we have done is to awaken a sleeping giant and fill him with a terrible resolve."
Cast.
The film was deliberately cast with actors who were not true box-office stars, in order to place the emphasis on the story rather than the actors who were in it. The original cast list had included many Japanese amateurs.
Cast in credits order:
Production.
Veteran 20th Century Fox executive Darryl F. Zanuck, who had earlier produced "The Longest Day" (1962), wanted to create an epic that depicted what "really happened on December 7, 1941", with a "revisionist's approach". He believed that the commanders in Hawaii, General Short and Admiral Kimmel, though scapegoated for decades, provided adequate defensive measures for the apparent threats, including relocation of the fighter aircraft at Pearl Harbor to the middle of the base, in response to fears of sabotage from local Japanese. Despite a breakthrough in intelligence, they had received limited warning of the increasing risk of aerial attack. Recognizing that a balanced and objective recounting was necessary, Zanuck developed an American-Japanese co-production, allowing for "a point of view from both nations." He was helped out by his son, Richard D. Zanuck, who was chief executive at Fox during this time.
Production on "Tora! Tora! Tora!" took three years to plan and prepare for the eight months of principal photography. The film was created in two separate productions, one based in the United States, directed by Richard Fleischer, and one based in Japan. The Japanese side was initially to be directed by Akira Kurosawa, who worked on script development and pre-production for two years. But after two weeks of shooting, he was replaced by Toshio Masuda and Kinji Fukasaku, who directed the Japanese sections.
Richard Fleischer said of Akira Kurosawa's role in the project:
Well, I always thought that even though Kurosawa was a genius at film making and indeed he was, I sincerely believe that he was miscast for this film, this was not his type of film to make, he never made anything like it and it just wasn't his style. I felt he was not only uncomfortable directing this kind of movie but also he wasn't used to having somebody tell him how he should make his film. He always had complete autonomy, and nobody would dare make a suggestion to Kurosawa about the budget, or shooting schedule, or anything like that. And then here he was, with Darryl Zanuck on his deck and Richard Zanuck on him and Elmo Williams and the production managers, and it was all stuff that he never had run into before, because he was always untouchable. I think he was getting more and more nervous and more insecure about how he was going to work on this film. And of course, the press got a hold of a lot of this unrest on the set and they made a lot out of that in Japan, and it was more pressure on him, and he wasn't used to that kind of pressure.
Larry Forrester and frequent Kurosawa collaborators Hideo Oguni and Ryuzo Kikushima wrote the screenplay, based on books written by Ladislas Farago and Gordon Prange of the University of Maryland, who served as a technical consultant. Numerous technical advisors on both sides, some of whom had participated in the battle and/or planning, were crucial in maintaining the accuracy of the film. Minoru Genda, the man who largely planned and led the attack on Pearl Harbor was an uncredited technical advisor for the film.
Four cinematographers were involved in the main photography: Charles F. Wheeler, Sinsaku Himeda, Masamichi Satoh and Osami Furuya. They were jointly nominated for the Academy Award for Best Cinematography. A number of well-known cameramen also worked on the second units without credit, including Thomas Del Ruth and Rexford Metz. The second unit doing miniature photography was directed by Ray Kellogg, while the second unit doing plane sequences was directed by Robert Enrietto.
Noted composer Jerry Goldsmith composed the film score and Robert McCall painted several scenes for various posters of the film.
The flying scenes were complex to shoot, and can be compared to the 1969 film "Battle of Britain". The 2001 film "Pearl Harbor" would contain cut scenes from both films.
The carrier entering Pearl Harbor towards the end of the film was in fact the Iwo Jima-class amphibious assault ship USS "Tripoli", returning to port. The "Japanese" aircraft carrier was the anti-submarine carrier USS "Yorktown". The Japanese A6M Zero fighters, and somewhat longer "Kate" torpedo bombers or "Val" dive bombers were heavily modified RCAF Harvard (T-6 Texan) and BT-13 Valiant pilot training aircraft. The large fleet of Japanese aircraft was created by Lynn Garrison, a well-known aerial action coordinator, who produced a number of conversions. Garrison and Jack Canary coordinated the actual engineering work at facilities in the Los Angeles area. These aircraft still make appearances at air shows.
In preparation for filming, USS "Yorktown" was berthed at North Island in San Diego to load all the aircraft, maintenance, and film crew prior to sailing to Hawaii. The night before filming the "Japanese" take-off scenes she sailed to a spot a few miles west of San Diego and at dawn the film crew filmed the launches of all the aircraft. Since these "Japanese" aircraft were not actual carrier based aircraft they did not have arresting gear with which to land back on the carrier, and continued on to land at North Island Naval Air Station. USS "Yorktown" sailed back to North Island and re-loaded the aircraft. She then sailed to Hawaii and the aircraft were off-loaded and used to film the attack scenes in and around Pearl Harbor. Aircraft Specialties of Mesa, AZ performed maintenance on the aircraft while in Hawaii.
A Boeing B-17 Flying Fortress’s actual crash landing during filming, a result of a jammed landing gear, was filmed and used in the final cut. The film crew received word that one of the B-17's could not lower their starboard landing gear so they quickly set up to film the "single gear" landing. The aircraft stayed aloft to use up as much fuel as possible, which gave the film crew some time to prepare, prior to landing. After viewing the "single gear" landing footage they decided to include it in the movie. In the sequence depicting the crash, only the final crash was actual footage. For the scenes leading up to the crash they manually retracted the starboard landing gear on a functioning B-17 and filmed the scenes of its final approach. After touching down on one wheel the pilot simply applied power and took off again. In the movie, all the approach footage was of this aircraft, and then, right at the moment of touchdown, they switch to the actual crash footage. The difference in production values between the actual footage and the final approach footage is quite clear. The B-17 that actually landed with one gear up sustained only minor damage to the starboard wing and propellers and was repaired and returned to service. A total of five Boeing B-17s were obtained for filming. Other U.S. aircraft used are the Consolidated PBY Catalina and, especially, the Curtiss P-40 Warhawk (two flyable examples were used). Predominately, P-40 fighters are used to depict the U.S. defenders with a full-scale P-40 used as a template for fiberglass replicas (some with working engines and props) that were strafed and blown up during filming. Fleischer also said a scene involving a P-40 model crashing into the middle of a line of P-40s was unintended, as it was supposed to crash at the end of the line. The stuntmen involved in the scene were actually running for their lives.
Historical accuracy.
Parts of the film showing the takeoff of the Japanese aircraft utilize an "Essex"-class aircraft carrier, USS "Yorktown", which was commissioned in 1943 and modernized after the war to have an angled flightdeck. The ship was leased by the film producers, who needed an aircraft carrier for the film; "Yorktown" was scheduled to be decommissioned shortly afterwards. It was used largely in the takeoff sequence of the Japanese attack aircraft. The sequence shows interchanging shots of models of the Japanese aircraft carriers and the "Yorktown". It does not look like any of the Japanese carriers involved in the attack, due to its large bridge island and its angled landing deck. The Japanese carriers had small bridge islands, and angled flight decks were not invented until after the war. In addition, during the scene in which Admiral Halsey is watching bombing practice an aircraft carrier with the hull number 14 is shown. Admiral Halsey was on the USS "Enterprise", not the "Essex"-class carrier USS "Ticonderoga", which would not be commissioned until 1944. This is understandable, however, as both the "Enterprise" and all six of the Japanese carriers from the attack had been scrapped and sunk, respectively. "Enterprise" was scrapped in 1959, and four of the six, including "Akagi", were sunk not six months after the attack at the Battle of Midway.
In "Tora! Tora! Tora!", an error involves the model of the Japanese carrier "Akagi". In the film, "Akagi's" bridge island is positioned on the starboard side of the ship, which is typical on most aircraft carriers. However, the aircraft carrier "Akagi" was an exception; its bridge island was on the port side of the ship. Despite this, the bridge section appeared accurately as a mirrored version of "Akagi's" real port-side bridge. Secondly, all the Japanese aircraft in the footage bear the markings of "Akagi"‍ '​s aircraft (a single vertical red stripe following the red sun symbol of Japan), even though five other aircraft carriers participated, each having its own markings. In addition, the markings do not display the aircraft's identification numbers as was the case in the actual battle. The white surround on the roundel on the Japanese aircraft was only used from 1942 onwards. Prior to this the roundel was red only.
The USS "Ward" was an old "4-piper" destroyer commissioned in 1918; the ship used in the movie, USS "Savage", which portrays the "Ward" looked far different from the original destroyer. In addition, in the movie she fired two shots from her #1 turret. In reality, the "Ward" fired the first shot from the #1 4" un-turreted gunmount and the second shot from the #3 wing mount.
A stern section of the USS "Nevada" was built that was also used to portray the USS "Arizona" and other U.S. battleships. The lattice mast (or cage mast) section of the "Tennessee-class"/"Maryland-class" battleship was built beside the set of the USS "Nevada" stern section, but not built upon a set of a deck, but on the ground as the footage in the movie only showed the cage mast tower. The large scale model of the stern shows the two aft gun turrets with three gun barrels in each; in reality, "Nevada" had two heightened fore and aft turrets with two barrels each while the lower two turrets fore and aft had three barrels each. Another model of "Nevada", used in the film to portray the whole ship, displays the turrets accurately. It should be noted that the reason for this anomaly is because the aft section model was used in the film to portray both USS "Nevada" "and" USS "Arizona". The ships looked remarkably similar except that "Arizona" had four triple turrets and a slightly different stern section. Footage and photographs not used in the film show the cage mast as being built on the ground. The USS "Nevada"/USS "Arizona" stern section was shown exploding to represent the explosion that destroyed the "Arizona".
The film has a Japanese Zero fighter being damaged over a naval base and then deliberately crashing into a naval base hangar. This is actually a composite of three incidents at Pearl Harbor attack: in the first wave, a Japanese Zero crashed into Fort Kamehameha's ordnance building; in the second wave, a Japanese Zero did deliberately crash into a hillside after U.S. Navy CPO John William Finn at Naval Air Station at Kāneʻohe Bay had shot and damaged the aircraft; also during the second wave, a Japanese aircraft that was damaged crashed into the seaplane tender USS "Curtiss".
During a number of shots of the attack squadrons traversing across Oahu, a small cross can be seen on one of the mountainsides. The cross was actually erected after the attack as a memorial to the victims of the attack.
Reception.
At the time of its initial movie release, "Tora! Tora! Tora!" was thought to be a box office flop in North America, although its domestic box office of $29,548,291 made it the ninth highest-grossing film of 1970. It was a major hit in Japan and over the years, home media releases provided a larger overall profit.
Roger Ebert felt that "Tora! Tora! Tora!" was "one of the deadest, dullest blockbusters ever made" and suffered from not having "some characters to identify with." In addition, he criticized the film for poor acting and special effects in his 1970 review. Vincent Canby, reviewer for "The New York Times", was similarly unimpressed, noting the film was "nothing less than a $25-million irrelevancy." "Variety" also found the film to be boring; however, the magazine praised the film's action sequences and production values. James Berardinelli, however, said it was "rare for a feature film to attain the trifecta of entertaining, informing, and educating." Charles Champlin in his review for the "Los Angeles Times" on September 23, 1970, considered the movie's chief virtues as a "spectacular", and the careful recreation of an historical event.
Despite the initial negative reviews, the film was critically acclaimed for its vivid action scenes, and found favor with aviation and history aficionados. However, even the team of Jack Hardwick and Ed Schnepf who have been involved in research on aviation films, had relegated "Tora! Tora! Tora!" to the "also-ran" status, due to its slow-moving plotline. The film holds a 59% "Fresh" rating on the review aggregate website Rotten Tomatoes, based on 27 critical reviews. In 1994, a survey at the USS Arizona Memorial in Honolulu determined that for Americans the film was the most common source of popular knowledge about the Pearl Harbor attack.
Several later films and TV series relating to World War II in the Pacific have used footage from "Tora! Tora! Tora!". These productions include the films "Midway" (1976; in the "Tora! Tora! Tora!" DVD commentary, Fleischer is angry that Universal used the footage), "All This and World War II" (film 1976), "Pearl" (TV mini-series 1978), "From Here to Eternity" (TV mini-series 1979), "The Final Countdown" (1980), and "Australia" (2008) as well as the "Magnum, P. I." television series episode titled "Lest We Forget" (first airdate February 12, 1981).
Honors.
"Tora! Tora! Tora!" was nominated for five Academy Awards, winning one for Visual Effects.
In popular culture.
The name of the film has been borrowed – and parodied – for various media productions, including the "Torah Torah Torah" episodes of the television shows "Magnum, P.I." and "NYPD Blue", the band Tora! Tora! Torrance!, the Toyah Willcox live album "Toyah! Toyah! Toyah!", the Depeche Mode song "Tora! Tora! Tora!" from their first album "Speak & Spell", and the "Tory! Tory! Tory!" documentary on Thatcherism.
References.
Notes
Citations
Bibliography
</dl>

</doc>
<doc id="58019" url="http://en.wikipedia.org/wiki?curid=58019" title="Harvard architecture">
Harvard architecture

The Harvard architecture is a computer architecture with physically separate storage and signal pathways for instructions and data. The term originated from the Harvard Mark I relay-based computer, which stored instructions on punched tape (24 bits wide) and data in electro-mechanical counters. These early machines had data storage entirely contained within the central processing unit, and provided no access to the instruction storage as data. Programs needed to be loaded by an operator; the processor could not initialize itself.
Today, most processors implement such separate signal pathways for performance reasons, but actually implement a modified Harvard architecture, so they can support tasks like loading a program from disk storage as data and then executing it.
Memory details.
In a Harvard architecture, there is no need to make the two memories share characteristics. In particular, the word width, timing, implementation technology, and memory address structure can differ. In some systems, instructions can be stored in read-only memory while data memory generally requires read-write memory. In some systems, there is much more instruction memory than data memory so instruction addresses are wider than data addresses.
Contrast with von Neumann architectures.
Under pure von Neumann architecture the CPU can be either reading an instruction or reading/writing data from/to the memory. Both cannot occur at the same time since the instructions and data use the same bus system. In a computer using the Harvard architecture, the CPU can both read an instruction and perform a data memory access at the same time, even without a cache. A Harvard architecture computer can thus be faster for a given circuit complexity because instruction fetches and data access do not contend for a single memory pathway.
Also, a Harvard architecture machine has distinct code and data address spaces: instruction address zero is not the same as data address zero. Instruction address zero might identify a twenty-four bit value, while data address zero might indicate an eight-bit byte that isn't part of that twenty-four bit value.
Contrast with modified Harvard architecture.
A modified Harvard architecture machine is very much like a Harvard architecture machine, but it relaxes the strict separation between instruction and data while still letting the CPU concurrently access two (or more) memory buses. The most common modification includes separate instruction and data caches backed by a common address space. While the CPU executes from cache, it acts as a pure Harvard machine. When accessing backing memory, it acts like a von Neumann machine (where code can be moved around like data, which is a powerful technique). This modification is widespread in modern processors, such as the ARM architecture and x86 processors. It is sometimes loosely called a Harvard architecture, overlooking the fact that it is actually "modified".
Another modification provides a pathway between the instruction memory (such as ROM or flash memory) and the CPU to allow words from the instruction memory to be treated as read-only data. This technique is used in some microcontrollers, including the Atmel AVR. This allows constant data, such as text strings or function tables, to be accessed without first having to be copied into data memory, preserving scarce (and power-hungry) data memory for read/write variables. Special machine language instructions are provided to read data from the instruction memory. (This is distinct from instructions which themselves embed constant data, although for individual constants the two mechanisms can substitute for each other.)
Speed.
In recent years, the speed of the CPU has grown many times in comparison to the access speed of the main memory. Care needs to be taken to reduce the number of times main memory is accessed in order to maintain performance. If, for instance, every instruction run in the CPU requires an access to memory, the computer gains nothing for increased CPU speed—a problem referred to as being memory bound.
It is possible to make extremely fast memory, but this is only practical for small amounts of memory for cost, power and signal routing reasons. The solution is to provide a small amount of very fast memory known as a CPU cache which holds recently accessed data. As long as the data that the CPU needs are in the cache, the performance is much higher than it is when the cache has to get the data from the main memory.
Internal vs. external design.
Modern high performance CPU chip designs incorporate aspects of both Harvard and von Neumann architecture. In particular, the "split cache" version of the modified Harvard architecture is very common. CPU cache memory is divided into an instruction cache and a data cache. Harvard architecture is used as the CPU accesses the cache. In the case of a cache miss, however, the data is retrieved from the main memory, which is not formally divided into separate instruction and data sections, although it may well have separate memory controllers used for concurrent access to RAM, ROM and (NOR) flash memory.
Thus, while a von Neumann architecture is visible in some contexts, such as when data and code come through the same memory controller, the hardware implementation gains the efficiencies of the Harvard architecture for cache accesses and at least some main memory accesses.
In addition, CPUs often have write buffers which let CPUs proceed after writes to non-cached regions. The von Neumann nature of memory is then visible when instructions are written as data by the CPU and software must ensure that the caches (data and instruction) and write buffer are synchronized before trying to execute those just-written instructions.
Modern uses of the Harvard architecture.
The principal advantage of the pure Harvard architecture—simultaneous access to more than one memory system—has been reduced by modified Harvard processors using modern CPU cache systems. Relatively pure Harvard architecture machines are used mostly in applications where trade-offs, like the cost and power savings from omitting caches, outweigh the programming penalties from featuring distinct code and data address spaces.
Even in these cases, it is common to employ special instructions in order to access program memory as though it were data for read-only tables, or for reprogramming; those processors are modified Harvard architecture processors.

</doc>
<doc id="58023" url="http://en.wikipedia.org/wiki?curid=58023" title="Lewis–Clark State College">
Lewis–Clark State College

Lewis–Clark State College is a public undergraduate college in the northwest United States, located in Lewiston, Idaho. Founded in 1893, it has an annual enrollment of approximately 3,500 students. The college offers over 83 degrees and is well known for its criminal justice, education, nursing, and technical programs.
History.
In 1893, Idaho Governor William J. McConnell signed an act on January 27 authorizing the establishment of the Lewiston State Normal School in Lewiston. There was a catch, however: "Provided the mayor and common council of that city on or before May 1, 1893, donate ten acres, within the city limits and known as part of the city park, and authorizing the said mayor and council to convey to the trustees of said normal school the said tract of land," etc.
The first Trustees on the school's Board were James W. Reid (who had done the most to shepherd the authorization bill through the legislature), Norman B. Willey (who had just stepped down as Idaho governor), Benjamin Wilson (a previous gubernatorial candidate), J. Morris Howe, and C. W. Schaff. Reid was elected President of the Board, a position he held until his death in 1902.
Lewiston residents lost no time in obtaining the required space for the school. However, the legislature acted slowly in providing construction funds, and then construction lagged. George E. Knepper had been hired as first President of the Normal School. Frustrated by the delays in getting his building, Knepper leased space in downtown Lewiston and opened for classes on January 6, 1896. The building itself was not ready until May. Over the next several years, more structures were added to the campus, including dormitories and a gymnasium.
In keeping with the Normal school philosophy, Lewiston Normal focused on practical, hands-on training for new teachers. That meant they provided a great deal of “manual training” – what we would call vocational education. Also, to insure that teachers truly knew how to handle a classroom, the School ran an on-campus training school. In it, real teachers taught real pupils, but student teachers also learned-by-doing under the supervision of experienced teacher-critics.
Until the 1920s one-room schools served well over half of Idaho’s primary students. In most, only the teacher knew anything at all about running a school. Thus, in Keith Petersen’s words, “teachers assumed responsibility for shaping a district's entire educational policy.”
World War I certainly impacted the nation’s normal schools, but not as much as it did conventional institutions. Generally, male students were in the majority at regular colleges, many of which experienced brutal enrollment losses. Normal schools attracted a predominantly female student body, so the declines were much smaller – about 15% at Lewiston Normal.
The school experienced a painful crisis on December 5, 1917, when the Administration Building suffered severe damage in a fire,
 later determined to be arson by a student. Its cupola collapsed into the gutted interior of the main structure and the older east wing was totally destroyed. Lewiston Normal survived that disaster and continued to grow, as the demand for pre-college teachers increased. However, by the late 1920s, the "normal school" idea was being supplanted by a "teachers college" approach. Such colleges still focused on teacher education, but now students could earn a bachelor’s degree – more and more often required for certification. Recognizing this trend, school supporters began a campaign to change Lewiston Normal’s status. They also began the painful process of upgrading the faculty – inciting much ill will.
Supporters also fought an ongoing battle just to keep the school open; some legislators still wanted to close the Normals to save money. The advent of World War II squelched that notion. Not only did the school continue to turn out desperately needed teachers, it also expanded its nurse-training program, and produced large numbers of fliers in its Navy Air School. In 1943, the Board of Education raised the school to full four-year status. Now with the ability to grant a B.Ed., school leaders took it upon themselves to use the name Northern Idaho College of Education (NICE), and the legislature approved the name change in 1947.
The school got another temporary reprieve from the cost-cutters when a deluge of veterans funded by the G.I. Bill hit the campus after the war. However, that wave passed, and in 1951 budget hawks succeeded in closing the school, as well as its counterpart, SICE in Albion in southern Idaho. The state’s other colleges had assured legislators that they could supply all the teachers needed. That promise proved disastrously wrong: In just three years, the state found itself issuing nearly 40% more provisional teaching certificates than it had in 1951.
Under that pressure, the legislature re-opened the school as Lewis–Clark Normal School in 1955 as a two-year school under the administration of the University of Idaho, thirty miles (50 km) north in Moscow. The first dean of LCSN was appointed for the third year in 1957, and enrollment was 319 in the fall of 1961. The arrangement with UI proved difficult and it ended abruptly in 1963 when the affiliation seemed like it might damage the university’s academic accreditation.
The ongoing need for teachers, a developing shortage of nurses, and a new push for vocational education from the federal government combined to rescue the school from oblivion. The state legislature voted to elevate it to four-year status in 1963 but did not approve funding until two years later. Enrollment of the now-independent, four-year school grew, by from 465 in 1964 to 1,033 in the fall of 1968. It continued to grow and in July 1971 the name was officially changed to Lewis–Clark State College. It was the very last Normal school in the country to make the change.
Students and faculty.
Over 3,500 students from over 30 different states and 20 different countries are enrolled at LCSC. Women outnumber men in the student body by five to three.
School reputation.
Lewis-Clark Normal School became a state college in 1966 and gained its current name in 1971. Lewis–Clark State College has been ranked as one of the top public colleges in the West in the Comprehensive-Bachelor’s Degree categories – including No. 1 in 2002, 2005, & 2007 – by U.S. News & World Report in its annual rankings of colleges and universities.
Athletics.
Lewis–Clark State competes in inercollegiate athletics in the National Association of Intercollegiate Athletics (NAIA), primarily in the Frontier Conference. The school colors are navy blue, white, & red with a team nickname of the Warriors. Men's sports include baseball, basketball, cross country golf, tennis, and track & field. Women's sports teams are nicknamed "Lady Warriors" and include basketball, cross country, golf, tennis, track & field, and volleyball.
"Warriors" was adopted in the 1950s; earlier nicknames include "Pioneers" in the 1930s, and "Loggers" in the late 1940s and early 1950s.
Baseball.
Since 1984, the Lewis–Clark State baseball team has won a record 16 NAIA national championships. All were under head coach Ed Cheff, who retired after 34 years in 2010. LCSC has hosted the NAIA World Series at Harris Field since 2000; it also hosted from 1984–1991.

</doc>
<doc id="58031" url="http://en.wikipedia.org/wiki?curid=58031" title="Bourgeoisie">
Bourgeoisie

The bourgeoisie (Eng.: ; ]), is a polysemous French term, because it means both:
The "bourgeoisie" in its original sense, is intimately linked to the existence of cities recognized as such by their urban charters (e.g. municipal charter, town privileges, German town law) so there was no bourgeoisie "outside the walls of the city" beyond which the people were "peasants" submitted to the stately courts and manorialism (except for the travelling "Fair bourgeoisie" living outside urban territories, who retained their city rights and domicile).
In Marxist philosophy the bourgeoisie is the social class who owns the means of production and whose societal concerns are the value of property and the preservation of capital, to ensure the perpetuation of their economic supremacy in society. Joseph Schumpeter instead saw the creation of new bourgeoisie as the driving force behind the capitalist engine, particularly entrepreneurs who took risks to bring innovation to industries and the economy through the process of creative destruction.
Etymology.
The Modern French word "bourgeois" derived from the Old French "burgeis" (walled city), which derived from "bourg" (market town), from the Old Frankish "burg" (town); in other European languages, the etymologic derivations are the Middle English "burgeis", the Middle Dutch "burgher", the German "Bürger", the Modern English "burgess", and the Polish "burżuazja", which occasionally is synonymous with the intelligentsia. In English, "bourgeoisie" (a French citizen-class) identified a social class oriented to economic materialism and hedonism, and to upholding the extreme political and economic interests of the capitalist ruling class. In the 18th century, before the French Revolution (1789–99), in the French feudal order, the masculine and feminine terms "bourgeois" and "bourgeoise" identified the rich men and women who were members of the urban and rural Third Estate – the common people of the French realm, who violently deposed the absolute monarchy of the Bourbon King Louis XVI (r. 1774–91), his clergy, and his aristocrats. Hence, since the 19th century, the term "bourgeoisie" usually is politically and sociologically synonymous with the ruling upper class of a capitalist society.
Historically, the medieval French word "bourgeois" denoted the inhabitants of the "bourgs" (walled market-towns), the craftsmen, artisans, merchants, and others, who constituted "the bourgeoisie", they were the socio-economic class between the peasants and the landlords, between the workers and the owners of the means of production. As the economic managers of the (raw) materials, the goods, and the services, and thus the capital (money) produced by the feudal economy, the term "bourgeoisie" evolved to also denote the middle class – the businessmen and businesswomen who accumulated, administered, and controlled the capital that made possible the development of the bourgs into cities.
Contemporarily, the terms "bourgeoisie" and "bourgeois" identify the ruling class in capitalist societies, as a social stratum; while "bourgeois" describes the "Weltanschauung" (worldview) of men and women whose way of thinking is socially and culturally determined by their economic materialism and philistinism, a social identity catalogued and described in "drame bourgeois" (bourgeois drama), which satirises buying the trappings of a noble-birth identity as the means climbing the social ladder. (See: "Le Bourgeois gentilhomme", 1670.)
History.
Origins and rise.
In the 11th century, the bourgeoisie emerged as a historical and political phenomenon when the "bourgs" of Central and Western Europe developed into cities dedicated to commerce. The organised economic concentration that made possible such urban expansion derived from the protective self-organisation into guilds, which became necessary when individual businessmen (craftsmen, artisans, merchants, "et alii") conflicted with their rent-seeking feudal landlords who demanded greater-than-agreed rents. In the event, by the end of the Middle Ages (ca. AD 1500), under régimes of the early national monarchies of Western Europe, the bourgeoisie acted in self-interest, and politically supported the king or the queen against the legal and financial disorder caused by the greed of the feudal lords. In the late-16th and early 17th centuries, the bourgeoisies of England and the Netherlands had become the financial – thus political – forces that deposed the feudal order; economic power had vanquished military power in the realm of politics.
From progress to reaction.
During the 17th and 18th centuries, the bourgeoisie were the politically progressive social class who supported the principles of constitutional government and of natural right, against the Law of Privilege and the claims of rule by divine right that the nobles and prelates had autonomously exercised during the feudal order. The motivations for the English Civil War (1642–51), the American War of Independence (1775–83), and French Revolution (1789–99) partly derived from the desire of the bourgeoisie to rid themselves of the feudal trammels and royal encroachments upon their personal liberty, commercial rights, and the ownership of property. In the 19th century, the bourgeoisie propounded liberalism, and gained political rights, religious rights, and civil liberties for themselves and the lower social classes; thus was the bourgeoisie then a progressive philosophic and political force in modern Western societies.
By the middle of the 19th century, subsequent to the Industrial Revolution (1750–1850), the great expansion of the bourgeoisie social class caused its self-stratification – by business activity and by economic function – into the "haute bourgeoisie" (bankers and industrialists) and the "petite bourgeoisie" (tradesmen and white-collar workers). Moreover, by the end of the 19th century, the capitalists (the original bourgeoisie) had ascended to the upper class, whilst the developments of technology and technical occupations allowed the ascension of working-class men and women to the lower strata of the bourgeoisie; yet the social progress was incidental.
In the event, despite its initial philosophic progressivism – from feudalism to liberalism to capitalism – the bourgeoisie social class (haute and petite) became reactionary in their refusal to allow the ascension (economic, social, political) of people from the proletariat (peasants and urban workers) to maintain hegemony.
Denotations.
Dictatorship of the bourgeoisie.
In the Middle Ages (AD 500–1500), the bourgeois usually was a self-employed businessman – such as a merchant, banker, or entrepreneur – whose economic role in society was being the financial intermediary to the feudal landlord and the peasant who worked the fief, the land of the lord. Yet, by the 18th century, the time of the Industrial Revolution (1750–1850) and of industrial capitalism, the bourgeoisie had become the economic ruling class who owned the means of production (capital and land), and who controlled the means of coercion (armed forces and legal system, police forces and prison system). In such a society, the bourgeoisie's ownership of the means of production enabled their employment and exploitation of the wage-earning working class (urban and rural), people whose sole economic means is labour; and the bourgeois control of the means of coercion suppressed the socio-political challenges of the lower classes, and so preserved the economic status quo; workers remained workers, and employers remained employers.
In the 19th century, the German economist Karl Marx distinguished two types of bourgeois capitalist: (i) the functional capitalist, the business administrator of the means of production; and (ii) the rentier capitalist whose livelihood derives either from the rent of property or from the interest-income produced by finance capital, or both. In the course of economic relations, the working class and the bourgeoisie continually engage in class struggle, wherein the capitalists exploit the workers, whilst the workers resist their economic exploitation, which occurs because the worker owns no means of production, and, to earn a living, he or she seeks employment from the bourgeois capitalist; the worker produces goods and services that are property of the employer, who sells them for a price. The money generated by the sale of the goods and services yields three sums (i) the wages of the worker, (ii) the costs of production, and (iii) profit (surplus value). Thereby, the capitalist profits (makes extra money) by selling the surplus value of the labour of the workers; hence is new wealth created through work.
Besides describing the social class who own the means of production, the Marxist usage of the term "bourgeois" also describes the consumerist style of life derived from the ownership of capital and real property. As an economist Karl Marx acknowledged the bourgeois industriousness that created wealth, yet criticised the moral hypocrisy of the bourgeoisie when they ignored the true origins of their wealth – the exploitation of the proletariat, the urban and rural workers. Further sense denotations of "bourgeois" describe ideologic concepts such as "bourgeois freedom", which is opposed to substantive forms of freedom; "bourgeois independence"; "bourgeois personal individuality"; the "bourgeois family"; et cetera, all derived from owning capital and property. (See: "The Communist Manifesto", 1848.)
"Nomenklatura".
In the 20th century, some communist states, particularly the Soviet Union, developed a category of people called a "nomenklatura", the bureaucrats who administered the country's government, industry, agriculture, education, system of state capitalism, et cetera.
France and French-speaking countries.
In English, the term "bourgeoisie" is often used to denote the middle classes. In fact, the French term encompasses both the upper and middle classes, a misunderstanding which has occurred in other languages as well. The bourgeoisie in France and many French-speaking countries consists of four evolving social layers: "la petite bourgeoisie", "la moyenne bourgeoisie", "la grande bourgeoisie", and "la haute bourgeoisie".
"La Petite Bourgeoisie".
The "petite bourgeoisie" consists of people who have experienced a brief ascension in social mobility for one or two generations. It usually starts with a trade or craft, and by the second and third generation, a family may rise another level. The "petite bourgeois" would belong to the British middle middle class and would be part of the American lower middle class. They are distinguished mainly by their mentality, and would differentiate themselves from the "proletariat" or working class. This class would include artisans, small traders, shopkeepers, and small farm owners. They are not employed, but may not be able to afford employees themselves.
"La Moyenne Bourgeoisie".
People who belong to the "moyenne bourgeoisie" or middle bourgeoisie, have solid incomes and assets, but without the aura of those who have become established at a higher level. They tend to belong to a family that has been bourgeois for three or more generations. Some members of this class may have relatives from similar backgrounds, or may even have aristocratic connections. The "moyenne bourgeoisie" would be the equivalent of the British and American upper-middle classes.
"La Grande Bourgeoisie".
The "grande bourgeoisie" are families that have been bourgeois since the 19th century, or for at least four or five generations. Members of these families tend to marry with the aristocracy or make other advantageous marriages. This bourgeoisie family has acquired an established historical and cultural heritage over the decades. The names of these families are generally known in the city where they reside, and their ancestors have often contributed to the region's history. These families are respected and revered. They belong to the upper class, and in the British class system would be considered part of the gentry. In the French-speaking countries they are sometimes referred "la petite haute bourgeoisie".
"La Haute Bourgeoisie".
The "haute bourgeoisie" is a social rank in the bourgeoisie that can only be acquired through time. In France, it is composed of bourgeois families that have existed since the French Revolution. They hold only honourable professions and have experienced many illustrious marriages in their family's history. They have rich cultural and historical heritages, and their financial means are more than secure. These families exude an aura of nobility, which prevents them from certain marriages or occupations. They only differ from nobility in that due to circumstances, the lack of opportunity, and/or political regime, they have not been ennobled. These people nevertheless live a lavish lifestyle, enjoying the company of the great artists of the time. In France, the families of the "haute bourgeoisie" are also referred to as "les 200 familles", a term which was coined in the first half of the 20th century. Michel Pinçon and Monique Pinçon-Charlot have studied the lifestyle of the French bourgeoisie, and how they boldly guard their world from the "nouveau riche", or newly rich.
In the French language, the term "bourgeoisie" almost designates a caste by itself, even though social mobility into this socio-economic group is possible. Nevertheless, the "bourgeoisie" is differentiated from "la classe moyenne", or the middle class, which consists mostly of white-collar employees, by holding a profession referred to as a "profession libérale", which "la classe moyenne", in its definition does not hold. Yet, in English the definition of a white-collar job encompasses the "profession libérale". As the world becomes globalised and society moves towards a corporate one, the term "la bourgeoisie" in its pure form has become a somewhat outdated term, which requires a more up-to-date definition.
Modern history.
Because of their ascribed cultural excellence as a social class, the Italian fascist régime (1922–45) of Prime Minister Benito Mussolini regarded the bourgeoisie as an obstacle to Modernism in aid to transforming Italian society. Nonetheless, despite such intellectual and social hostility, the Fascist State ideologically exploited the Italian bourgeoisie and their materialistic, middle-class spirit, for the more efficient cultural manipulation of the upper (aristocratic) and the lower (working) classes of Italy. In 1938, Prime Minister Mussolini gave a speech wherein he established a clear ideological distinction between capitalism (the social function of the bourgeoisie) and the bourgeoisie (as a social class), whom he dehumanised by reducing them into high-level abstractions: a moral category and a state of mind. Culturally and philosophically, Mussolini isolated the bourgeoisie from Italian society by portraying them as social parasites upon the Fascist Italian State and "The People"; as a social class who drained the human potential of Italian society, in general, and of the working class, in particular; as exploiters who victimised the Italian nation with an approach to life characterised by hedonism and materialism. Nevertheless, despite the slogan "The Fascist Man Disdains the ″Comfortable″ Life", which epitomised the anti-bourgeois principle, in its final years of power, for mutual benefit and profit, the Mussolini Fascist régime transcended ideology to merge the political and financial interests of Prime Minister Benito Mussolini with the political and financial interests of the bourgeoisie, the Catholic social circles who constituted the ruling class of Italy.
Philosophically, as a materialist creature, the bourgeois man was irreligious; thus, to establish an existential distinction between the supernatural faith of the Roman Catholic Church and the materialist faith of temporal religion; in "The Autarchy of Culture: Intellectuals and Fascism in the 1930s", the priest Giuseppe Marino said that:
 Christianity is essentially anti-bourgeois. ... A Christian, a true Christian, and thus a Catholic, is the opposite of a bourgeois.
Culturally, the bourgeois man is unmanly, effeminate, and infantile; describing his philistinism in "Bonifica antiborghese" (1939), Roberto Paravese said that the:
 Middle class, middle man, incapable of great virtue or great vice: and there would be nothing wrong with that, if only he would be willing to remain as such; but, when his child-like or feminine tendency to camouflage pushes him to dream of grandeur, honours, and thus riches, which he cannot achieve honestly with his own "second-rate" powers, then the average man compensates with cunning, schemes, and mischief; he kicks out ethics, and becomes a bourgeois.
The bourgeois is the average man who does not accept to remain such, and who, lacking the strength sufficient for the conquest of essential values—those of the spirit—opts for material ones, for appearances.
The economic security, financial freedom, and social mobility of the bourgeoisie threatened the philosophic integrity of Italian Fascism, the ideologic monolith that was the régime of Prime Minister Benito Mussolini. Any assumption of legitimate political power (government and rule) by the bourgeoisie represented a Fascist loss of totalitarian State power for social control through political unity—one people, one nation, one leader. Sociologically, to the fascist man, to become a bourgeois was a character flaw inherent to the masculine mystique; therefore, the ideology of Italian Fascism scornfully defined the bourgeois man as "spiritually castrated".
Bourgeois culture.
Cultural hegemony.
Karl Marx said that the culture of a society is dominated by the mores of the ruling-class, wherein their superimposed value system is abided by each social class (the upper, the middle, the lower) regardless of the socio-economic results it yields to them. In that sense, contemporary societies are bourgeois to the degree that they practice the mores of the small-business "shop culture" of early modern France; which the writer Émile Zola (1840–1902) naturalistically presented, analysed, and ridiculed in the twenty-two-novel series (1871–1893) about "Les Rougon-Macquart" family; the thematic thrust is the necessity for social progress, by subordinating the economic sphere to the social sphere of life.
Conspicuous consumption.
The critical analyses of the bourgeois mentality by the German intellectual Walter Benjamin (1892–1940) indicated that the shop culture of the petite bourgeoisie established the sitting room as the centre of personal and family life; as such, the English bourgeois culture is a sitting-room culture of prestige through conspicuous consumption. The material culture of the bourgeoisie concentrated on mass-produced luxury goods of high quality; between generations, the only variance was the materials with which the goods were manufactured. In the early part of the 19th century, the bourgeois house contained a home that first was stocked and decorated with hand-painted porcelain, machine-printed cotton fabrics, machine-printed wallpaper, and Sheffield steel (crucible and stainless). The utility of these things was inherent to their practical functions. By the latter part of the 19th century, the bourgeois house contained a home that had been remodelled by conspicuous consumption. Here, the goods were bought to display wealth (discretionary income), rather than for their practical utility. The bourgeoisie had transposed the wares of the shop window to the sitting room, where the clutter of display signalled bourgeois success. (See: "Culture and Anarchy", 1869.)
Two spatial constructs manifest the bourgeois mentality: (i) the shop-window display, and (ii) the sitting room. In English, the term "sitting-room culture" is synonymous for "bourgeois mentality", a philistine cultural perspective from the Victorian Era (1837–1901), especially characterised by the repression of emotion and of sexual desire; and by the construction of a regulated social-space where "propriety" is the key personality trait desired in men and women. Nonetheless, from such a psychologically constricted worldview, regarding the rearing of children, contemporary sociologists claim to have identified "progressive" middle-class values, such as respect for non-conformity, self-direction, autonomy, gender equality and the encouragement of innovation; as in the Victorian Era, the transposition to the US of the bourgeois system of social values has been identified as a requisite for employment success in the professions.
Representations.
Beyond the intellectual realms of political economy, history, and political science that discuss, describe, and analyse the "bourgeoisie" as a social class, the colloquial usage of the sociological terms "bourgeois" and "bourgeoise" describe the social stereotypes of the old money and of the "nouveau riche", who is a politically timid conformist satisfied with a wealthy, consumerist style of life characterised by conspicuous consumption and the continual striving for prestige. This being the case, the cultures of the world describe the philistinism of the middle-class personality, produced by the excessively rich life of the bourgeoisie, is examined and analysed in comedic and dramatic plays, novels, and films. (See: Authenticity.)
Theatre.
"Le Bourgeois gentilhomme" (The Would-be Gentleman, 1670) by Molière (Jean-Baptiste Poquelin), is a comedy-ballet that satirises Monsieur Jourdain, the prototypical nouveau riche man who buys his way up the social-class scale, to realise his aspirations of becoming a gentleman, to which end he studies dancing, fencing, and philosophy, the trappings and accomplishments of a gentleman, to be able to pose as a man of noble birth, someone who, in 17th-century France, was a man to the manor born; Jourdain's self-transformation also requires managing the private life of his daughter, so that her marriage can also assist his social ascent.
Literature.
"Buddenbrooks" (1901), by Thomas Mann (1875–1955), chronicles the moral, intellectual, and physical decay of a rich family through its declines, material and spiritual, in the course of four generations, beginning with the patriarch Johann Buddenbrook Sr. and his son, Johann Buddenbrook Jr., who are typically successful German businessmen; each is a reasonable man of solid character. Yet, in the children of Buddenbrook Jr., the materially comfortable style of life provided by the dedication to solid, middle-class values elicits decadence: The fickle daughter, Toni, lacks and does not seek a purpose in life; son Christian is honestly decadent, and lives the life of a ne’er-do-well; and the businessman son, Thomas, who assumes command of the Buddenbrook family fortune, occasionally falters from middle-class solidity by being interested in art and philosophy, the impractical life of the mind, which, to the bourgeoisie, is the epitome of social, moral, and material decadence.
"Babbitt" (1922), by Sinclair Lewis (1885–1951), satirises the American bourgeois George Follansbee Babbitt, a middle-aged realtor, booster, and joiner in the Midwestern city of Zenith, who – despite being unimaginative, self-important, and hopelessly conformist and middle-class – is aware that there must be more to life than money and the consumption of the best things that money can buy. Nevertheless, he fears being excluded from the mainstream of society more than he does living for himself, by being true to himself – his heart-felt flirtations with independence (dabbling in liberal politics and a love affair with a pretty widow) come to naught because he is existentially afraid.
Yet, George F. Babbitt sublimates his desire for self-respect, and encourages his son to rebel against the conformity that results from bourgeois prosperity, by recommending that he be true to himself:
 Don't be scared of the family. No, nor all of Zenith. Nor of yourself, the way I've been.
Films.
The comedy films by the Spanish film director Luis Buñuel (1900–83) examine the mental and moral effects of the bourgeois mentality, its culture, and the stylish way of life it provides for its practitioners.

</doc>
<doc id="58032" url="http://en.wikipedia.org/wiki?curid=58032" title="Control Data Corporation">
Control Data Corporation

Control Data Corporation (CDC) was a supercomputer firm. CDC was one of the nine major United States computer companies through most of the 1960s; the others were IBM, Burroughs Corporation, DEC, NCR, General Electric, Honeywell, RCA, and UNIVAC. CDC was well-known and highly regarded throughout the industry at the time. For most of the 1960s, Seymour Cray worked at CDC and developed a series of machines that were the fastest computers in the world by far. CDC only lost that title in the 1970s after Cray left the company to found Cray Research (CRI). After several years of losses in the early 1980s, CDC made the decision to leave the computer manufacturing business and sell those parts of the company in 1988, a process that was completed in 1992 with the creation of Control Data Systems, Inc. The remaining businesses of CDC currently operate as Ceridian.
Background and origins: World War II–1957.
During World War II the U.S. Navy had built up a team of engineers to build codebreaking machinery for both Japanese and German electro-mechanical ciphers. A number of these were produced by a team dedicated to the task working in the Washington, D.C., area. With the post-war wind-down of military spending, the Navy grew increasingly worried that this team would break up and scatter into various companies, and it started looking for ways to covertly keep the team together.
Eventually they found their solution; the owner of a Chase Aircraft affiliate in St. Paul, Minnesota, John Parker, was about to lose all his contracts with the end of the war. The Navy never told Parker exactly what the team did, since it would have taken too long to get top secret clearance. Instead they simply said the team was important, and they would be very happy if he hired them all. Parker was obviously wary, but after several meetings with increasingly high-ranking Naval officers it became apparent that whatever it was, they were serious, and he eventually agreed to give this team a home in his military glider factory.
The result was Engineering Research Associates (ERA), a contract engineering company that worked on a number of seemingly unrelated projects in the early 1950s. One of these was one of the first commercial stored program computers, the 36-bit ERA 1103. The machine was built for the Navy, which intended to use it in their non-secret code-breaking centers. In the early 1950s a minor political debate broke out in Congress about the Navy essentially "owning" ERA, and the ensuing debates and legal wrangling left the company drained of both capital and spirit. In 1952, Parker sold ERA to Remington Rand.
Although Rand kept the ERA team together and developing new products, it was most interested in ERA's magnetic drum memory systems. Rand soon merged with Sperry Corporation to become Sperry Rand. In the process of merging the companies, the ERA division was folded into Sperry's UNIVAC division. At first this did not cause too many changes at ERA, since the company was used primarily to provide engineering talent to support a variety of projects. However, one major project was moved from UNIVAC to ERA, the UNIVAC II project, which led to lengthy delays and upsets to nearly everyone involved.
Since the Sperry "big company" mentality encroached on the decision-making powers of the ERA founders, they left Sperry to form the Control Data Corp. in 1957, setting up shop in an old warehouse across the river from Sperry's St. Paul laboratory, in Minneapolis at 501 Park Avenue. Of the members forming CDC, William Norris was the unanimous choice to become the chief executive officer of the new company. Seymour Cray soon became the chief designer, though at the time of CDC's formation he was still in the process of completing a prototype for the Naval Tactical Data System (NTDS), and he did not leave Sperry to join CDC until it was complete.
Early designs and Cray's big plan.
CDC started business by selling subsystems, mostly drum memory systems, to other companies. Cray joined the next year, and he immediately built a small transistor-based 6-bit machine known as the "CDC Little Character" to test his ideas on large-system design and transistor-based machines. "Little Character" was a great success.
In 1959 CDC released a 48-bit transistorized version of their 1103 re-design as the CDC 1604, with the first machine delivered to the U.S. Navy in 1960 at the Naval Postgraduate School in Monterey, CA. Legend has it that the 1604 designation was chosen by adding CDC's first street address (501 Park Avenue) to Cray's former project, the ERA-Univac 1103.
A 12-bit cut-down version was also released as the CDC 160A in 1960, often considered among the first minicomputers. The 160A was particularly notable as it was built as a standard office desk, which was unusual packaging for that era. New versions of the basic 1604 architecture were rebuilt into the CDC 3000 series, which sold through the early and mid-1960s.
Cray immediately turned to the design of a machine that would be the fastest (or in the terminology of the day, largest) machine in the world, setting the goal at 50 times the speed of the 1604. This required radical changes in design, and as the project "dragged on" — it had gone on for about four years by then — the management got increasingly upset and it demanded greater oversight. Cray in turn demanded (in 1962) to have his own remote lab, saying that otherwise, he would quit. Norris agreed, and Cray and his team moved to Cray's home town, Chippewa Falls, Wisconsin. Not even Bill Norris, the founder and president of CDC, could visit Cray's laboratory without an invitation.
Peripherals business.
In the early 1960s, the corporation moved to Ford Parkway in the Highland Park neighborhood of St. Paul where Norris lived. Through this period, Norris became increasingly worried that CDC had to develop a "critical mass" in order to compete with IBM. In order to do this, he started an aggressive program of buying up various companies to round out CDC's peripheral lineup. In general, they tried to offer a product to compete with any of IBM's, but running 10% faster and costing 10% less. This was not always easy to achieve.
One of its first peripherals was a tape transport, which led to some internal wrangling as the Peripherals Equipment Division attempted to find a reasonable way to charge other divisions of the company for supplying the devices. If the division simply "gave" them away at cost as part of a system purchase, they would never have a real budget of their own. Instead, a plan was established in which it would share profits with the divisions selling its peripherals, a plan eventually used throughout the company.
The tape transport was followed by the "405 Card Reader" and the "415 Card Punch", followed by a series of tape drives and drum printers, all of which were designed in-house. The printer business was initially supported by Holley Carburetor in the Rochester, Michigan suburb outside of Detroit. They later formalized this by creating a jointly held company, Holley Computer Products. Holley later sold its stake back to CDC, the remainder becoming the Rochester Division. 
Train printers and band printers in Rochester were developed in a joint venture with NCR and ICL, with CDC holding controlling interest. This joint venture was known as Computer Peripherals, Inc. (CPI). In the early 80s, it was merged with dot matrix computer manufacturer Centronics.
Norris was particularly interested in breaking out of the punched card–based workflow, where IBM held a stranglehold. He eventually decided to buy Rabinow Engineering, one of the pioneers of optical character recognition (OCR) systems. The idea was to bypass the entire punched card stage by having the operators simply type onto normal paper pages with an OCR-friendly typewriter font, and then submit those pages to the computer. Since a typewritten page contains much more information than a punched card (which has essentially one line of text from a page), this would offer savings all around. Unfortunately, this seemingly simple task turned out to be much harder than anyone expected, and while CDC became a major player in the early days of OCR systems, OCR has remained a niche product to this day. Rabinow's plant in Rockville, MD was closed in 1976, and CDC left the business.
With the continued delays on the OCR project, it became clear that punched cards were not going to go away any time soon, and CDC had to address this as quickly as possible. Although the 405 remained in production, it was an expensive machine to build. So another purchase was made, Bridge Engineering, which offered a line of lower-cost as well as higher-speed card punches. All card-handling products were moved to what became the Valley Forge Division after Bridge moved to a new factory, with the tape transports to follow. Later on, the Valley Forge and Rochester divisions were spun off to form a new joint company with National Cash Register (later NCR Corporation), Computer Peripherals Inc (CPI), in order to share development and production costs across the two companies. ICL later joined the effort. Eventually the Rochester Division was sold to Centronics in 1982.
Another side-effect of Norris's attempts to diversify was the creation of a number of service bureaus that ran jobs on behalf of smaller companies that could not afford to buy computers. This was never very profitable, and in 1965, several managers suggested that the unprofitable centers be closed in a cost-cutting measure. Nevertheless, Norris was so convinced of the idea that he refused to accept this, and ordered an across-the-board "belt tightening" instead.
CDC 6600: defining supercomputing.
Meanwhile at the new Chippewa Falls lab, Seymour Cray, Jim Thornton, and Dean Roush put together a team of 34 engineers, which continued work on the new computer design. One of the ways they hoped to improve the CDC 1604 was to use better transistors, and Cray used the new silicon transistors using the planar process, developed by Fairchild Semiconductor. These were much faster than the germanium transistors in the 1604, without the drawbacks of the older mesa silicon transistors. The speed of light restriction forced a more compact design with refrigeration designed by Dean Roush. In 1964, the resulting computer was released onto the market as the CDC 6600, out-performing everything on the market by roughly ten times. When it sold over 100 units at $8 million each it was considered a supercomputer.
The 6600 had a 100ns, transistor-based CPU (Central Processing Unit) with multiple asynchronous functional units, using 10 logical, external I/O processors to off-load many common tasks and core memory. That way, the CPU could devote all of its time and circuitry to processing actual data, while the other controllers dealt with the mundane tasks like punching cards and running disk drives. Using late-model compilers, the machine attained a standard mathematical operations rate of 500 kilo-FLOPS, but the handcrafted computer assembler managed to deliver approximately 1 mega-FLOPS. A simpler, albeit much slower and less expensive version, implemented using a more traditional serial processor design rather than the 6600's parallel functional units, was released as the CDC 6400, and a two-processor version of the 6400 was called the CDC 6500.
A FORTRAN compiler, known as MNF (Minnesota FORTRAN), was developed by Lawrence A. Liddiard and E. James Mundstock at the University of Minnesota for the 6600.
It was after the delivery of the 6600 that IBM took notice of this new company. In 1965, IBM started an effort to build its own machine that would be even faster than the 6600, the ACS-1. Two hundred people were gathered together on the U.S. West Coast to work on the project, away from corporate prodding, in an attempt to mirror Cray's off-site lab. The project produced interesting computer architecture and technology, but it was not compatible with IBM's hugely successful System/360 line of computers. The engineers were directed to make it 360-compatible, but that compromised its performance. The ACS was canceled in 1969, without ever being produced for customers. Many of the engineers left the company, leading to a brain-drain in IBM's high-performance departments.
In the meantime, IBM announced a new version of the famed System/360, the Model 92, which would be just as fast as CDC's 6600. This machine did not exist, but its nonexistence did not stop sales of the 6600 from drying up, while people waited for the release of the mythical Model 92. Norris did not take this tactic, dubbed as fear, uncertainty and doubt (FUD), lying down, and in an extensive antitrust lawsuit launched against IBM a year later, he eventually won a settlement valued at $80 million. As part of the settlement, he picked up IBM's subsidiary, Service Bureau Corporation (SBC), which ran computer processing for other corporations on its own computers. SBC fit nicely into CDC's existing service bureau offerings.
During the designing of the 6600, CDC had set up "Project SPIN" to supply the system with a high speed hard disk memory system. At the time, it was unclear if disks would replace magnetic memory drums, nor was it clear at the time whether fixed or removable disks would become the more prevalent. Thus, SPIN explored all of these approaches, and eventually it delivered a very large 28" diameter fixed disk and also a smaller multi-platter 14" removable disk-pack system. Over time, the hard disk business pioneered in SPIN would turn into a major product line.
CDC 7600 and 8600.
In the same month it won its lawsuit against IBM, CDC also announced its new computer, the CDC 7600 (previously referred to as the 6800 within CDC). This machine's hardware clock speed was almost four times that of the 6600 (36 MHz vs. 10 MHz) a 27.5 ns clock cycle, and it offered considerably more than four times the total throughput.
Much of this speed increase was due to extensive use of pipelining, a technique that allows different parts of the CPU to work simultaneously on different parts of successive instructions of the process at the same time. This works in the same way that an automotive assembly line can produce one vehicle every 90 seconds, and thus easily 300 vehicles per 8 hour shift by doing a partial assembly of each vehicle simultaneously every 90 seconds. Any one vehicle will still take several hours to be completely assembled. In computers, pipelining uses separate circuits to work on different parts of different instructions at the same time, in a fashion similar to the many stations on an assembly line. Any one instruction completes processing no faster, but the program as a whole moves through the computer more quickly.
The 7600 did not do well in the marketplace because it was introduced in the 1969 downturn in the U.S. national economy. Its complexity had led to poor reliability. The machine was slightly incompatible with the 6000-series, so it required a completely different operating system, which like most new OSs, was primitive. The 7600 project paid for itself, yet it damaged CDC's reputation. The 7600 memory had a split primary- and secondary-memory which required user management but was more than fast enough to make it the fastest uniprocessor 1969 to 1976. A few dozen 7600s were the supercomputer of choice at supercomputer centers around the US and world.
Cray then turned to the design of the CDC 8600. This design included four 7600-like processors in a single, smaller case. The smaller size and shorter signal paths allowed the 8600 to run at much higher clock speeds, and in combination with higher speed memory, these features provided most of the performance gains. The 8600, however, belonged to the "old school" in terms of its physical construction, and it used individual components soldered to circuit boards. The design was so compact that cooling and servicing the CPU modules proved effectively impossible. An abundance of hot-running solder joints ensured that the machines did not work reliably; Cray recognized that a re-design was needed.
The STAR and the Cyber.
In addition to the redesign of the 8600, CDC had another project called the CDC STAR-100 underway, led by Cray's former collaborator on the 6600/7600, Jim Thornton. Unlike the 8600's "four computers in one box" solution to the speed problem, the STAR was a new design using a unit that we know today as the vector processor. By highly pipelining math instructions with purpose-built instructions and hardware, math processing is dramatically improved in a machine that was otherwise slower than a 7600. Although the particular set of problems it would be best at solving was limited - in comparison to the general-purpose 7600, it was for solving exactly these problems that customers would buy CDC machines.
Since these two projects competed for limited funds during the late 1960s, Norris felt that the company could not support simultaneous development of the STAR and a complete redesign of the 8600. Therefore, Cray left CDC to form the Cray Research company in 1972. Norris remained, however, a staunch supporter of Cray, and he even invested money into Cray's new company. In 1974, CDC released the STAR, designated as the Cyber 203. It turned out to have "real world" performance that was considerably worse than expected. STAR's chief designer, Jim Thornton, then left CDC to form the Network Systems Corporation.
A variety of systems based on the basic 6600/7600 architecture were repackaged in different price/performance categories of the CDC Cyber, which became CDC's main product line in the 1970s. An updated version of the STAR architecture, the Cyber 205, had considerably better performance than the original. By this time, however, Cray's own designs, like the Cray-1, were using the same basic design techniques as the STAR, but were computing much faster.
Sales of the STAR were weak, but Control Data Corp. produced a successor system, the Cyber 200/205, that gave Cray Research some competition. CDC also embarked on a number of special projects for its clients, who produced an even smaller number of black project computers. The CDC Advanced Flexible Processor (AFP), also known as CYBER PLUS, was one such machine.
Another design direction was the "Cyber 80" project, which was aimed at release in 1980. This machine could run old 6600-style programs, and also had a completely new 64-bit architecture. The concept behind Cyber 80 was that current 6000-series users would migrate to these machines with relative ease. The design and debugging of these machines went on past 1980, and the machines were eventually released under other names.
CDC was also attempting to diversify its revenue from hardware into services and this included its promotion of the PLATO (computer system) computer-aided learning system, which ran on Cyber hardware and incorporated many early computer interface innovations including bit-mapped touchscreen terminals.
Magnetic Peripherals Inc..
Magnetic Peripherals Inc., originally a joint venture with Honeywell and Honeywell Bull, became a major player in the hard disk drive market. It was the world wide leader in 14 inch disk drive technology in the OEM marketplace in the 1970s and early 1980s especially with its SMD (Storage Module Drive) and CMD (Cartridge Module Drive), with its plant at Brynmawr in the South Wales valleys running 24/7 production. The Magnetic Peripherals division in Brynmawr celebrated the production of 1 million disks and 3 million magnetic tapes in October 1979. CDC was an early developer of the eight-inch drive technology with products from its MPI Oklahoma City Operation. Its CDC Wren series drives were particularly popular with "high end" users, although it was behind the capacity growth and performance curves of numerous startups such as Micropolis, Atasi, Maxtor, and Quantum. CDC also co-developed the now universal Advanced Technology Attachment (ATA) interface with Compaq and Western Digital, which was aimed at lowering the cost of adding low-performance drives. 
CDC founded a separate division called "Rigidyne" in Simi Valley, California, to develop 3.5-inch drives using technology from the Wren series. These were marketed by CDC as the "Swift" series, and were some of the first high-performance 3.5-inch drives on the market at their introduction in 1987.
in September 1988, CDC merged Rigidyn and MPI into the umbrella subsidiary of Imprimis Technology. The next year, Seagate Technology purchased Imprimis for $250 million in cash, 10.7 million in Seagate stock and a $50 million promissory note.
ETA Systems, wind-down and sale of assets.
CDC decided to fight for the high-performance niche, but Norris recognized that the company had become moribund in his opinion and unable to quickly design competitive machines. So in 1983, he set up a spinoff company, ETA Systems, whose design goal was a machine processing data at 10 GFLOPs, about 40 times the speed of the Cray-1. The design never fully matured, and it was unable to reach its goals. Nevertheless, the product was one of the fastest computers on the market, and 7 liquid nitrogen-cooled and 27 smaller air cooled versions of the computers were sold during the next few years. They used the new CMOS chips, which produced much less heat. The effort ended after half-hearted attempts to sell ETA Systems. In 1989, most of the employees of ETA Systems were laid off, and the remaining ones were folded into CDC.
Despite having valuable technology, CDC still suffered from huge losses in 1985 and 1986 while attempting to reorganize. As a result, in 1987 it sold its PathLab Laboratory Information System to 3M. While CDC was still making computers, it was decided that hardware manufacturing was no longer as profitable as it used to be, and so in 1988, the decision to leave the industry, bit by bit, was made. The first division to go Imprimis. After that, CDC sold other assets such as VTC (a chip maker that specialized in mass-storage circuitry and was closely linked with MPI), as well as non-computer-related assets like Ticketron. Finally, in 1992, the computer hardware and service businesses were spun out as Control Data Systems, Inc. (CDS). In 1999, CDS was bought out by Syntegra (USA), a subsidiary of the BT Group, and merged into BT's Global Services organization.
CDC's Energy Management Division was one of the most successful CDC business units, providing control systems solutions that managed as much as 25% of all electricity on the planet. In 1988 or 1989 this division was renamed Empros and was later sold to Siemens as CDC broke apart.
Finally, after the CDS spinout, all that was left of CDC was its services business, and it became known as the Ceridian Corporation. Ceridian continues as a successful outsourced IT company focusing on human resources. In 1997 General Dynamics acquired the Computing Devices International Division of Ceridian. Computing Devices, headquartered in Bloomington, Minnesota, was a defense electronics and systems integration business, originally Control Data's Government Systems Division.
Commercial Credit Corporation.
In 1968, Commercial Credit Corporation was the target of a hostile takeover by Loews Inc. Loews had acquired nearly 10% of CCC, which it intended to break up on acquisition. To avoid the takeover, CCC forged a deal with CDC lending them the money to purchase control in CCC instead, and "That is how a computer company came to own a fleet of fishing boats in the Chesapeake Bay."
By the 1980s, Control Data entered an unstable period, which resulted in the company liquidating many of their assets. In 1986, Sandy Weill convinced the Control Data management to spin off their Commercial Credit subsidiary to prevent the company's potential liquidation. Over a period of years, Weill used Commercial Credit to build an empire that became Citigroup. In 1999, Commercial Credit was renamed CitiFinancial, and in 2011, the full-service network of US CitiFinancial branches were renamed OneMain Financial.

</doc>
<doc id="58034" url="http://en.wikipedia.org/wiki?curid=58034" title="Chemehuevi">
Chemehuevi

The Chemehuevi are an indigenous people of the Great Basin. They are the southernmost branch of Paiute people. Today, Chemehuevi people are enrolled in the following federally recognized tribes:
Some Chemehuevi are also part of the Soboba Band of Luiseno Indians, which members are mostly "Sovovatum" or "Soboba band" members of Cahuilla and Luiseño people.
Name.
"Chemehuevi" has multiple interpretations. It is considered to either be a Mojave term meaning "those who play with fish;" or a Quechan word meaning "nose-in-the-air-like-a-roadrunner." The Chemehuevi call themselves "Nüwüwü" ("The People", singular "Nüwü") or "Tantáwats", meaning "Southern Men."
Language.
The language, Chemehuevi, is a Colorado River Numic language, in the Numic language branch of the Uto-Aztecan language family. First transcribed by John P. Harrington and Carobeth Laird in the early 20th Century, it was studied in the 1970s by linguist Margaret L. Press. whose field notes and extensive sound recordings remain available. The language is now near extinction; during the filming of Ironbound Films' 2008 American documentary film "The Linguists", linguists Greg Anderson and K. David Harrison interviewed and recorded one of the last remaining 3 speakers.
History and traditional culture.
The Chemehuevi were originally a desert tribe among the Numu or Paiute-Shoshone nations. Post-contact, they lived primarily in the eastern Mojave Desert and later the Chemehuevi Valley along the Colorado River in California. They were a nomadic people living in small groups given the sparse resources available in the desert environment. Carobeth Laird indicates their traditional territory spanned the High Desert from the Colorado River on the east to the Tehachapi Mountains on the west and from the Las Vegas area and Death Valley on the north to the San Bernardino and San Gabriel Mountains in the south. They are most closely identified as among the Great Basin Indians. Among others they are cousins of the Kawaiisu.
The most comprehensive collection of Chemehuevi history, culture and mythology was gathered by Carobeth Laird (1895–1983) and her second husband, George Laird, one of the last Chemehuevi to have been raised in the traditional culture. Carobeth Laird, a linguist and ethnographer, wrote a comprehensive account of the culture and language as George Laird remembered it, and published their collaborative efforts in her 1976 "The Chemehuevis", the first and, to date, only ethnography of the Chemehuevi traditional culture.
Describing the Chemehuevi as she knew them, and presenting the texture of traditional life amongst the people, Carobeth Laird writes:
The Chemehuevi character is made up of polarities which are complementary rather than contradictory. They are loquacious yet capable of silence; gregarious yet so close to the earth that single families or even men alone might live and travel for long periods away from other human beings; proud, yet capable of a gentle self-ridicule. They are conservative to a degree, yet insatiably curious and ready to inquire into and even to adopt new ways: to visit all tribes, whether friends or enemies; to speak strange tongues, sing strange songs, and marry strange wives.
Population.
Estimates for the pre-contact populations of most native groups in California have varied substantially. Alfred L. Kroeber estimated the combined 1770 population of the Chemehuevi, Koso (Western Shoshone), and Kawaiisu as 1,500, and the combined population of the Chemehuevi, Koso (Western Shoshone), and Kawaiisu in 1910 as 500. An Indian agent reported the Chemehuevi population in 1875 to be 350. Kroeber estimated U.S. Census data put the Chemehuevi population in 1910 as 355.

</doc>
<doc id="58035" url="http://en.wikipedia.org/wiki?curid=58035" title="Hopi">
Hopi

The Hopi are a federally recognized tribe of Native American people, who primarily live on the 2,531.773 sqmi Hopi Reservation in northeastern Arizona. As of 2010, there were 18,327 Hopi in the United States, according to the 2010 census. The Hopi language is one of the 30 of the Uto-Aztecan language family.
When first encountered by the Spanish in the 16th century, the Hopi and the surrounding cultures were referred to as Pueblo people, because they lived in villages ("pueblos" in the Spanish language). The Hopi are descended from the Ancient Pueblo Peoples (Hopi: "Hisatsinom" or Navajo: "Anasazi") who constructed large apartment-house complexes in northeastern Arizona, northwestern New Mexico, and southwestern Colorado. They lived along the Mogollon Rim, especially from AD 1100s–1300s, when they abandoned their large villages.
The name "Hopi" is a shortened form of their autonym, "Hopituh Shi-nu-mu" ("The Peaceful People" or "Peaceful Little Ones"). The "Hopi Dictionary" gives the primary meaning of the word "Hopi" as: "behaving one, one who is mannered, civilized, peaceable, polite, who adheres to the Hopi way." In the past, Hopi sometimes used the term "Hopi" and its cognates to refer to the Pueblo peoples in general, in contrast to other, more warlike tribes.
"Hopi" is a concept deeply rooted in the culture's religion, spirituality, and its view of morality and ethics. To be Hopi is to strive toward this concept, which involves a state of total reverence and respect for all things, to be at peace with these things, and to live in accordance with the instructions of "Maasaw", the Creator or Caretaker of Earth. The Hopi observe their traditional ceremonies for the benefit of the entire world.
Traditionally, Hopi are organized into matrilineal clans. When a man marries, the children from the relationship are members of his wife's clan. These clan organizations extend across all villages. Children are named by the women of the father's clan. On the twentieth day of a baby's life, the women of the paternal clan gather, each woman bringing a name and a gift for the child. In some cases where many relatives would attend, a child could be given over forty names, for example. The child's parents generally decide the name to be used from these names. Current practice is to either use a non-Hopi or English name or the parent's chosen Hopi name. A person may also change the name upon initiation into one of the religious societies, such as the Kachina society, or with a major life event.
The Hopi have always viewed their land as sacred. Agriculture is a very important part of their culture, and their villages are spread out across the northern part of Arizona. The Hopi and the Navajo did not have a conception of land being bounded and divided. They lived on the land that their ancestors did. On December 16, 1882 President Arthur passed an executive order creating a reservation for the Hopi. It was much smaller than the Navajo reservation, which was the largest in the country.
On October 24, 1936 the Hopi people ratified a Constitution. That Constitution created a unicameral government where all powers are vested in a Tribal Council. While there is an executive branch (tribal chairman and vice chairman) and judicial branch, their powers are limited under the Hopi Constitution. The traditional powers and authority of the Hopi Villages was preserved in the 1936 Constitution.
Today, the Hopi Reservation is entirely surrounded by the much larger Navajo Reservation. The two nations used to share the "Navajo–Hopi Joint Use Area", but this was a source of conflict. The partition of this area, commonly known as Big Mountain, by Acts of Congress in 1974 and 1996, has also resulted in long-term controversy.
Hopi History.
The Hopi are one of many Native American cultures in the Southwestern United States. When first encountered by the Spanish in the 16th century, these cultures were referred to as Pueblo people because they lived in villages ("pueblos" in the Spanish language). The Hopi are descended from the Ancient Pueblo Peoples (Hopi: "Hisatsinom" or Navajo: "Anasazi") who constructed large apartment-house complexes in northeastern Arizona, northwestern New Mexico, and southwestern Colorado. They lived along the Mogollon Rim, especially from AD 1100s–1300s, when they abandoned their large villages. No researchers have been able to determine the reason, although it is likely that a drying of water sources would have forced the people away.
Oraibi.
Old Oraibi is one of four original Hopi villages, and one of the oldest continuously inhabited villages within the territory of the United States. In the 1540s the village was recorded as having 1,500–3,000 residents.
Early European contact, 1540–1680.
The first recorded European contact with the Hopi was by the Spanish in A.D 1540. Spanish General Francisco Vásquez de Coronado went to North America to explore the land. While at the Zuni villages, he learned of the Hopi tribe. Coronado dispatched Pedro de Tovar and other members of their party to find the Hopi villages. The Spanish wrote that the first Hopi village they visited was "Awatovi". They noted that there were about 16,000 Hopi and Zuni people. A few years later, the Spanish explorer García López de Cárdenas investigated the Rio Grande and met the Hopi. They warmly entertained Cardenas and his men and directed him on his journey.
In 1582–1583 the Hopi were visited by Antonio de Espejo’s expedition. He noted that there were five Hopi villages and around 12,000 Hopi people. During these early years, the Spanish explored and colonized the southwestern region of the New World, but never sent many forces or settlers to the Hopi country. Their visits to the Hopi were random and spread out over many years. Many times the visits were from military explorations.
The Spanish colonized near the Rio Grande and, because the Hopi did not live near rivers that gave access to the Río Grande, the Spanish never left any troops on their land. The Spanish were accompanied by missionaries, Catholic friars. Beginning in 1629, with the arrival of 30 friars in Hopi country, the Franciscan Period started. The Franciscans had missionaries assigned and built a church at Awatovi. The Hopi originally were against conversion to Catholicism. After an incident where Father Porras purportedly restored the sight of a blind youth by placing a cross over his eyes, the Hopi at Awatovi believed in Christianity. Most Hopi in the other villages continued to resist conversion, wanting to maintain their own ways.
Pueblo Revolt of 1680.
Spanish Roman Catholic priests were only marginally successful in converting the Hopi and persecuted them in a draconian manner for adhering to Hopi religious practices. The Spanish occupiers in effect enslaved the Hopi populace, compelling them to endure forced labor and hand over goods and crops. Spanish oppression and attempts to convert the Hopi caused the Hopi over time to become increasingly intolerant towards their occupiers. The only significant conversions were at the pueblo of Awatovi. Eventually in the year 1680 the Rio Grande Pueblo Indians put forward the suggestion to revolt and garnered Hopi support.
The Hopi and Pueblo Revolt was the first time that diverse Pueblo groups had worked in unison to drive out the Spanish colonists. In the Hopi revolt against the Spanish, local Catholic Church missions were attacked, friars and priests were all put to death, and the churches and mission buildings were dismantled stone by stone. It took two decades for the Spanish to reassert their control over the Rio Grande Pueblos but thereafter Spanish influence in the more distant Hopi area was more limited. By 1700, the Spanish friars had begun rebuilding a smaller church at Awatovi. During the winter of 1700–01, selected teams of men from the other Hopi villages sacked Awatovi at the request of the village chief, killed all the men of the village, and removed the women and children to other Hopi villages, then completely destroyed the village and burned it to the ground. Thereafter, despite intermittent attempts in the course of the 17th century, the Spanish failed subsequently to ever re-establish a presence in Hopi country.
Hopi-U.S relations, 1849–1946.
In 1849, James S. Calhoun was appointed official Indian agent of Indian Affairs for the Southwest Territory of the U.S. He had headquarters in Santa Fe and was responsible for all of the Indian residents of the area. The first formal meeting between the Hopi and the U.S government occurred in 1850 when seven Hopi leaders made the trip to Santa Fe to meet with Calhoun. They wanted the government to provide protection against the Navajo, an Apachean-language tribe, but distinct from other Apache. At this time, the Hopi leader was "Nakwaiyamtewa".
The US established Fort Defiance in 1851 in Arizona, and placed troops in Navajo country to deal with their threats to the Hopi. General James J. Carleton, with the assistance of Kit Carson, was assigned to travel through the area. They "captured" the Navajo natives and forced them to the fort. As a result of the Long Walk of the Navajo, the Hopi enjoyed a short period of peace.
In 1847, Mormons settled in Utah and tried to convert the Indians to Mormonism. Jacob Hamblin, a Mormon missionary, first made a trip into Hopi country in 1858. He was on good terms with the Hopi Indians, and in 1875 an LDS Church was built on Hopi land.
Education.
In 1875, the English trader Thomas Keams escorted Hopi leaders to meet President Chester A. Arthur in Washington D.C. "Loololma," village chief of "Oraibi" at the time, was very impressed with Washington. As he concluded that education allowed the whites to live that way, he returned wanting a formal school to be built for the Hopi children. In 1886, twenty of the Hopi leaders signed a petition sent to the Commissioner of Indian Affairs requesting that a school be built on their land. In 1887, Thomas Keams opened Keams Canyon Boarding School at Keams Canyon for the Hopi children.
The Oraibi people did not support the school and refused to send their children 35 mi away from their villages. The Keams School was organized to teach the Hopi youth the ways of European-American civilization: forcing them to use English and give up their traditional ways. The children were forced to abandon their tribal identity and completely take on the European-American culture. They received haircuts, new clothes, took on Anglo names, and learned English. The boys learned farming and carpentry skills, while the girls were taught ironing, sewing and "civilized" dining. Keams School also reinforced European-American religions. The American Baptist Home Mission Society provided the students with services every morning and religious teachings during the week. In 1890, the Commissioner of Indian Affairs arrived in Hopi country with other government officials to review the progress of the new school. Seeing that few students were enrolled, they returned with federal troops who threatened to arrest the Hopi parents if they refused to send their children to school. The Commissioner took children to fill the school.
Hopi land.
The Hopi have always viewed their land as sacred. Agriculture is a very important part of their culture, and their villages are spread out across the northern part of Arizona. The Hopi and the Navajo did not have a conception of land being bounded and divided. They lived on the land that their ancestors did. On December 16, 1882 President Arthur passed an executive order creating a reservation for the Hopi. It was much smaller than the Navajo reservation, which was the largest in the country.
The Hopi reservation was originally a rectangle 55 by 70 mi, in the middle of the Navajo Reservation, with their village lands taking about half of the land. The reservation prevented encroachment by white settlers, but it did not protect the Hopis against the Navajos.
The Hopi and the Navajo continued to fight over land, and they had different models of sustainability, as the Navajo were sheepherders. Eventually the Hopi went before the Senate Committee of Interior and Insular Affairs to ask them to help provide a solution to the dispute. The tribes argued over around 1800000 acre of land in northern Arizona. In 1887 the U.S government passed the Dawes Allotment Act. The purpose was to divide up communal tribal land into individual allotments by household, to encourage a model of European-American style subsistence farming on individually owned family plots of 640 acre or less. The Department of Interior would declare remaining land "surplus" to the tribe's needs and make it available for purchase by U.S citizens. For the Hopi, the Act would destroy their ability to farm, which was their main means of income. The Bureau of Indian Affairs did not set up land allotments in the Southwest.
Oraibi split.
The chief of the Oraibi, Lololoma enthusiastically supported Hopi education, but the people were divided on this issue. Most of the village was conservative and refused to allow their children to attend school. The Indians were referred to as the "hostiles" because they opposed the American government and its attempts to force assimilation. The rest of the Oraibi were called the "friendlies" because of their acceptance of the white people. The "hostiles" refused to let their children attend school. In 1893, the Oraibi Day School was opened in the Oraibi village. Although the school was within the village, the traditional parents still refused to allow their children to attend.
In 1894, a group of Hopi parents announced that they were against the ideas of Washington and did not want their children to be exposed to the culture of the white American people. The government sent in troops to arrest the 19 parents and sent them to Alcatraz Prison, where they stayed for a year. Another Oraibi leader, "Lomahongyoma", competed with "Lololoma" for village leadership. In 1906 the village split after a conflict between Hostiles and Friendlies. The conservative Hostiles left and formed a new village, known as "Hotevilla".
Hopi recognition.
At dawn of the 20th century, the US government established day schools, missionaries, farming assistants and physicians on every Indian reservation. This policy required that every reservation set up its own Indian-police and Tribal courts, and appoint a chief or leader who would represent their tribe within the U.S government. In 1910 in the Census for Indians, the Hopi Tribe had a total of 2,000 members, which was the highest in 20 years. The Navajo at this time had 22,500 members and have consistently increased in population. During the early years of this century, only about 3% of Hopis lived off the reservation. In 1924 Congress officially declared Native Americans to be U.S citizens.
Under the Indian Reorganization Act of 1934, the Hopi established a constitution to create their own tribal government, and in 1936 elected a Tribal Council. The Preamble to the Hopi constitution states that they are a self-governing tribe, focused on working together for peace and agreements between villages in order to preserve the "good things of Hopi life." The Constitution consists of thirteen different "Articles," all with a different topic of interest. The articles cover the topics of territory, membership, and organization of their government with a legislative, executive and judicial branch. The rest of the articles discuss the twelve villages recognized by the tribe, lands, elections, Bill of Rights and more.
Hopi-Navajo land disputes.
From the 1940s to the 1970s, the Navajo kept moving their villages closer and closer to Hopi land, causing the Hopi to raise the land issue with the U.S government. This resulted in the establishment of "District 6" which placed a boundary around the Hopi villages on the first, second, and third mesas, thinning the reservation to 501501 acre. In 1962 the courts issued the "Opinion, Findings of Fact and Conclusions of Law and Judgment," which stated that the U.S government did not grant the Navajo any type of permission to reside on the Hopi Reservation that was declared in 1882; and that the remaining Hopi land was to be shared with the Navajo.
Between 1961–1964, the Hopi tribal council signed leases with the U.S government that allowed for companies to explore and drill for oil, gas and minerals within Hopi country. This drilling brought over 3 million dollars to the Hopi Tribe. In 1974, The Navajo-Hopi Land Settlement Act was passed. It created the Navajo-Hopi Indian Relocation Commission, which forced the relocation of any Hopi or Navajo living on the other’s land. In 1992, the Hopi Reservation was increased to 1500000 acre.
Today's Hopi Reservation is bisected by Arizona State Route 264, which is an expansive scenic paved road that links together the numerous Hopi villages.
The Modern Tribal Government is Created.
On October 24, 1936 the Hopi people ratified a Constitution. That Constitution created a unicameral government where all powers are vested in a Tribal Council. While there is an executive branch (tribal chairman and vice chairman) and judicial branch, their powers are limited under the Hopi Constitution. The traditional powers and authority of the Hopi Villages was preserved in the 1936 Constitution.
The Hopi Tribal Government Today.
The Hopi tribe is federally recognized and headquartered in Kykotsmovi, Arizona.
Tribal Officers:
The current tribal officers are:
Chairman: Herman G. Honanie,
Vice Chairman: Alfred Lomahquahu, Jr.,
Tribal Secretary: Vernita Selestewa,
Treasurer: Vacant,
Sergeant-at-Arms: Alfonso Sakeva
The Tribal Council
Representatives to the council are selected either by a community election or by an appointment from the village kikmongwi, or leader. Each representative serves a two-year term. Tribal Representation on the Tribal Council as of 2014 is as follows:
Village of Upper Moenkopi:
Daniel Honahni,
Danny Humetewa, Sr.,
Leroy Sumatzkuku,
Michael Elmer
Village of Bakabi:
Davis F. Pecusa,
Leroy G. Kewanimptewa, Jr.,
Lamar Keevama
Village of Kykotsmovi:
Alban Mooya, Jr.,
Caleb H. Johnson,
Nada Talayumptewa,
Norman Honanie
Village of Sipaulovi:
George Mase,
Rosa Honanie
Village of Mishongnovi:
Annette F. Talayumptewa,
Arthur Batala,
Marilyn Tewa,
Mervin Yoyetewa
Currently, the villages of Mishongnovi, Shungopavi, Oraibi, Hotevilla, Lower Moenkopi and First Mesa Consolidated Villages (Walpi, Shitchumovi and Tewa) do not have a representative on council. The Hopi Villages select Council representatives, and may decline to send any representative. The declination has been approved by the Hopi Courts.
Tribal Courts
The Hopi Tribal Government operates a Trial Court and Appellate Court in Keams Canyon. These courts operate under an amended Tribal Code, which was amended August 28, 2012.
Economic development.
The Hopi tribe earns most of its income from natural resources. On the 1800000 acre Navajo reservation, a significant amount of coal is mined yearly from which the Hopi Tribe shares mineral royalty income. Peabody Western Coal Company is one of the largest coal operations on Hopi land, with long-time permits for continued mining.
The tribe's 2010 operating budget was $21.8 million, and projected mining revenues for 2010 was $12.8 million.
The Hopi Economic Development Corporation is the tribal enterprise tasked with creating diverse, viable economic opportunities. The HEDC oversees the Hopi Cultural Center and Walpi Housing Management. Other HEDC businesses include the Hopi Three Canyon Ranches, between Flagstaff and Winslow; and the 26 Bar Ranch in Eagar; Hopi Travel Plaza in Holbrook; three commercial properties in Flagstaff; and the Kokopelli Inn in Sedona.
Tourism is a source of income, and the tribe's opening of the 100-room in Moenkopi, Arizona, near Tuba City, Arizona, is the second hotel on the reservation. It provides non-Hopi a venue for entertainment, lectures, and educational demonstrations, as well as tours and lodging. The project is expected to support 400 jobs. The tribe operates the Tuvvi Travel Center and Tuvvi Café in Moenkopi.
The Hopi people have repeatedly voted against gambling casinos as an economic opportunity.
Culture.
The name "Hopi" is a shortened form of their autonym, "Hopituh Shi-nu-mu" ("The Peaceful People" or "Peaceful Little Ones"). The "Hopi Dictionary" gives the primary meaning of the word "Hopi" as: "behaving one, one who is mannered, civilized, peaceable, polite, who adheres to the Hopi way." In the past, Hopi sometimes used the term "Hopi" and its cognates to refer to the Pueblo peoples in general, in contrast to other, more warlike tribes.
"Hopi" is a concept deeply rooted in the culture's religion, spirituality, and its view of morality and ethics. To be Hopi is to strive toward this concept, which involves a state of total reverence and respect for all things, to be at peace with these things, and to live in accordance with the instructions of "Maasaw", the Creator or Caretaker of Earth. The Hopi observe their traditional ceremonies for the benefit of the entire world.
Traditionally, Hopi are organized into matrilineal clans. When a man marries, the children from the relationship are members of his wife's clan. These clan organizations extend across all villages. Children are named by the women of the father's clan. On the twentieth day of a baby's life, the women of the paternal clan gather, each woman bringing a name and a gift for the child. In some cases where many relatives would attend, a child could be given over forty names, for example. The child's parents generally decide the name to be used from these names. Current practice is to either use a non-Hopi or English name or the parent's chosen Hopi name. A person may also change the name upon initiation into one of the religious societies, such as the Kachina society, or with a major life event.
The Hopi practice a complete cycle of traditional ceremonies although not all villages retain or had the complete ceremonial cycle. These ceremonies take place according to the lunar calendar and are observed in each of the Hopi villages. Like other Native American groups, the Hopi have been influenced by Christianity and the missionary work of several Christian denominations. Few have converted enough to Christianity to drop their traditional religious practices.
Traditionally the Hopi are highly skilled micro or subsistence farmers. The Hopi also are part of the wider cash economy; a significant number of Hopi have mainstream jobs; others earn a living by creating high-quality Hopi art, notably the carving of Kachina dolls, the expert crafting of earthenware ceramics, and the design and production of fine jewelry, especially sterling silver.
The Hopi collect and dry a native perennial plant called Thelesperma megapotamicum, known by the common name Hopi tea, and use it to make an herbal tea, as a medicinal remedy and as a yellow dye.
Albinism.
The Hopi have a high rate of albinism - about 1 in 200 individuals.
Further reading.
Harry James, "Pages from Hopi History" University of Arizona Press, 1974
Harold Courlander, "Fourth World of the Hopi" University of New Mexico Press, 1987

</doc>
<doc id="58036" url="http://en.wikipedia.org/wiki?curid=58036" title="Lancaster County, Nebraska">
Lancaster County, Nebraska

Lancaster County is a county located in the U.S. state of Nebraska. As of the 2010 census, the population was 285,407, making it the second-most populous county in Nebraska. Its county seat is Lincoln, the state capital. The county was created in 1859, and the original county seat was the village of Lancaster.
Lancaster County is part of the Lincoln, NE Metropolitan Statistical Area.
In the Nebraska license plate system, Lancaster County was represented by the prefix 2 (it had the second-largest number of vehicles registered in the state when the license plate system was established in 1922). In 2002, the state discontinued the 1922 system in Lancaster, Douglas and Sarpy counties.
Geography.
According to the U.S. Census Bureau, the county has a total area of 846 sqmi, of which 838 sqmi is land and 8.8 sqmi (1.0%) is water.
Climate.
In 2004, Lancaster County was named a StormReady county by the National Weather Service.
Demographics.
As of the census of 2000, there were 250,291 people, 99,187 households, and 60,702 families residing in the county. The population density was 298 people per square mile (115/km²). There were 104,217 housing units at an average density of 124 per square mile (48/km²). The racial makeup of the county was 90.07% White, 2.82% Black or African American, 0.64% Native American, 2.86% Asian American, 0.06% Pacific Islander, 1.69% from other races, and 1.87% from two or more races. 3.37% of the population were Hispanic or Latino of any race. 39.1% were of German, 7.9% English and 7.8% Irish ancestry according to Census 2000.
There were 99,187 households out of which 30.30% had children under the age of 18 living with them, 48.80% were married couples living together, 9.10% had a female householder with no husband present, and 38.80% were non-families. 29.10% of all households were made up of individuals and 8.30% had someone living alone who was 65 years of age or older. The average household size was 2.40 and the average family size was 3.00.
In the county the population was spread out with 23.50% under the age of 18, 15.40% from 18 to 24, 30.40% from 25 to 44, 20.30% from 45 to 64, and 10.40% who were 65 years of age or older. The median age was 32 years. For every 100 females there were 99.80 males. For every 100 females age 18 and over, there were 98.50 males.
The median income for a household in the county was $41,850, and the median income for a family was $53,676. Males had a median income of $34,720 versus $25,614 for females. The per capita income for the county was $21,265. About 5.50% of families and 9.50% of the population were below the poverty line, including 9.90% of those under age 18 and 6.10% of those age 65 or over.
Communities.
Census divisions.
Lancaster County is divided into the following census divisions, called precincts, except for the City of Lincoln.

</doc>
<doc id="58038" url="http://en.wikipedia.org/wiki?curid=58038" title="Oliver Goldsmith">
Oliver Goldsmith

Oliver Goldsmith (10 November 1728 – 4 April 1774) was an Anglo-Irish novelist, playwright and poet, who is best known for his novel "The Vicar of Wakefield" (1766), his pastoral poem "The Deserted Village" (1770), and his plays "The Good-Natur'd Man" (1768) and "She Stoops to Conquer" (1771, first performed in 1773). He is thought to have written the classic children's tale "The History of Little Goody Two-Shoes", the source of the phrase "goody two-shoes".
Biography.
Goldsmith's birth date and year are not known with certainty. According to the Library of Congress authority file, he told a biographer that he was born on 10 November 1728.
The location of his birthplace is also uncertain. He was born either in the townland of Pallas, near Ballymahon, County Longford, Ireland, where his father was the Anglican curate of the parish of Forgney, or at the residence of his maternal grandparents, at the Smith Hill House in the diocese of Elphin, County Roscommon where his grandfather Oliver Jones was a clergyman and master of the Elphin diocesan school, and where Oliver studied. When Goldsmith was two years old, his father was appointed the rector of the parish of "Kilkenny West" in County Westmeath. The family moved to the parsonage at Lissoy, between Athlone and Ballymahon, and continued to live there until his father's death in 1747.
In 1744 Goldsmith went up to Trinity College, Dublin. His tutor was Theaker Wilder. Neglecting his studies in theology and law, he fell to the bottom of his class. In 1747, along with four other undergraduates, he was expelled for a riot in which they attempted to storm the Marshalsea Prison. He was graduated in 1749 as a Bachelor of Arts, but without the discipline or distinction that might have gained him entry to a profession in the church or the law; his education seemed to have given him mainly a taste for fine clothes, playing cards, singing Irish airs and playing the flute. He lived for a short time with his mother, tried various professions without success, studied medicine desultorily at the University of Edinburgh from 1752 to 1755, and set out on a walking tour of Flanders, France, Switzerland and Northern Italy, living by his wits (busking with his flute).
He settled in London in 1756, where he briefly held various jobs, including an apothecary's assistant and an usher of a school. Perennially in debt and addicted to gambling, Goldsmith produced a massive output as a hack writer for the publishers of London, but his few painstaking works earned him the company of Samuel Johnson, with whom he was a founding member of "The Club". The combination of his literary work and his dissolute lifestyle led Horace Walpole to give him the epithet "inspired idiot". During this period he used the pseudonym "James Willington" (the name of a fellow student at Trinity) to publish his 1758 translation of the autobiography of the Huguenot Jean Marteilhe.
Goldsmith was described by contemporaries as prone to envy, a congenial but impetuous and disorganised personality who once planned to emigrate to America but failed because he missed his ship. Thomas De Quincey wrote of him 'All the motion of Goldsmith's nature moved in the direction of the true, the natural, the sweet, the gentle'.
His premature death in 1774 may have been partly due to his own misdiagnosis of his kidney infection. Goldsmith was buried in Temple Church in London. The inscription reads; "HERE LIES/OLIVER GOLDSMITH". There is a monument to him in the centre of Ballymahon, also in Westminster Abbey with an epitaph written by Samuel Johnson.
Works.
"See The Vicar of Wakefield, The Good-Natur'd Man, The Traveller, and She Stoops to Conquer."
"The Citizen of the World".
In 1760 Goldsmith began to publish a series of letters in the "Public Ledger" under the title "The Citizen of the World". Purportedly written by a Chinese traveller in England by the name of Lien Chi, they used this fictional outsider's perspective to comment ironically and at times moralistically on British society and manners. It was inspired by the earlier essay series "Persian Letters" by Charles de Secondat, Baron de Montesquieu.
"The Hermit".
Goldsmith wrote this romantic ballad of precisely 160 lines in 1765. The hero and heroine are Edwin, a youth without wealth or power, and Angelina, the daughter of a lord "beside the Tyne." Angelina spurns many wooers, but refuses to make plain her love for young Edwin. "Quite dejected with my scorn," Edwin disappears and becomes a hermit. One day, Angelina turns up at his cell in boy's clothes and, not recognising him, tells him her story. Edwin then reveals his true identity, and the lovers never part again. The poem is notable for its interesting portrayal of a hermit, who is fond of the natural world and his wilderness solitude but maintains a gentle, sympathetic demeanor toward other people. In keeping with eremitical tradition, however, Edwin the Hermit claims to "spurn the [opposite] sex." This poem appears under the title of "A Ballad" sung by the character of Mr. Burchell in Chapter 8 of Goldsmith's novel, "The Vicar of Wakefield."
"The Deserted Village".
In the 1760s Goldsmith witnessed the demolition of an ancient village and destruction of its farms to clear land to become a wealthy man's garden. His poem "The Deserted Village", published in 1770, expresses a fear that the destruction of villages and the conversion of land from productive agriculture to ornamental landscape gardens would ruin the peasantry.
Memorials concerning Oliver Goldsmith.
Goldsmith lived in Kingsbury, now in North-West London between 1771 and 1774 and Oliver Goldsmith Primary School and Goldsmith Lane there are named after him.
In the play "Marx in Soho" by Howard Zinn, Marx makes a reference to Goldsmiths' poem, "The Deserted Village".
A statue of him by JH Foley stands at the Front Arch of Trinity College, Dublin (see image).
His name has been given to a new lecture theatre and student accommodation on the Trinity College campus: Goldsmith Hall.
Somerset Maugham used the last line from "An Elegy on the Death of a Mad Dog" in his novel "The Painted Veil" (1925). The character Walter Fane's last words are "The dog it was that died".
Auburn, Alabama, and Auburn University were named for the first line in Goldsmith's poem: "Sweet Auburn, loveliest village of the plain." Auburn is still referred to as the 'loveliest village on the plain.'
There is a statue in Ballymahon County Longford.
London Underground locomotive number 16 (used on the Metropolitan line of the London Underground until 1962) was named "Oliver Goldsmith".
Longford based band Goldsmith are named after the famous writer.
Athlone Institute of Technology library is named the Goldsmith Library
In popular culture.
Two characters in the 1951 comedy "The Lavender Hill Mob" quote the same line from Goldsmith's poem "The Traveller" – a subtle joke, because the film's plot involves the recasting of stolen gold.

</doc>
<doc id="58039" url="http://en.wikipedia.org/wiki?curid=58039" title="Stuckism">
Stuckism

Stuckism is an international art movement founded in 1999 by Billy Childish and Charles Thomson to promote figurative painting as opposed to conceptual art. By July 2012 the initial group of 13 British artists had expanded to 233 groups in 52 countries.
Childish and Thomson have issued several manifestos. The first one was "The Stuckists", consisting of 20 points starting with "Stuckism is a quest for authenticity". "Remodernism", the other well-known manifesto of the movement, is a criticism of postmodernism; it aims to get back to the true spirit of modernism, to produce art with spiritual value regardless of style, subject matter or medium. In another manifesto they define themselves as "anti-anti-art" which is against anti-art and for art.
After exhibiting in small galleries in Shoreditch, London, the Stuckists' first show in a major public museum was held in 2004 at the Walker Art Gallery, as part of the Liverpool Biennial. The group has demonstrated annually at Tate Britain against the Turner Prize since 2000, sometimes dressed in clown costumes. They have also come out in opposition to the Charles Saatchi-patronised Young British Artists.
Although painting is the dominant artistic form of Stuckism, artists using other media such as photography, sculpture, film and collage have also joined, and share the Stuckist opposition to conceptualism and ego-art.
Name, founding and origin.
The name "Stuckism" was coined in January 1999 by Charles Thomson in response to a poem read to him several times by Billy Childish. In it, Childish recites that his former girlfriend, Tracey Emin had said he was "stuck! stuck! stuck!" with his art, poetry and music. Later that month, Thomson approached Childish with a view to co-founding an art group called Stuckism, which Childish agreed to, on the basis that Thomson would do the work for the group, as Childish already had a full schedule.
There were eleven other founding members: Philip Absolon, Frances Castle, Sheila Clark, Eamon Everall, Ella Guru, Wolf Howard, Bill Lewis, Sanchia Lewis, Joe Machine, Sexton Ming, and Charles Williams. The membership has evolved since its founding through creative collaborations: the group was originally promoted as working in paint, but members have since worked in various other media, including poetry, fiction, performance, photography, film and music.
In 1979, Thomson, Childish, Bill Lewis and Ming were members of The Medway Poets performance group, to which Absolon and Sanchia Lewis had earlier contributed. Peter Waite's Rochester Pottery staged a series of solo painting shows. In 1982, TVS broadcast a documentary on the poets. That year, Emin, then a fashion student, and Childish started a relationship; her writing was edited by Bill Lewis, printed by Thomson and published by Childish. Group members published dozens of works. The poetry group dispersed after two years, reconvening in 1987 to record "The Medway Poets" LP. Clark, Howard and Machine became involved over the following years. Thomson got to know Williams, who was a local art student and whose girlfriend was a friend of Emin; Thomson also met Everall. During the foundation of the group, Ming brought in his girlfriend, Guru, who in turn invited Castle.
Manifestos.
In August 1999, Childish and Thomson wrote "The Stuckists manifesto" which stress the value of painting as a medium, its use for communication, and the expression of emotion and experience – as opposed to what Stuckists see as the superficial novelty, nihilism and irony of conceptual art and postmodernism. The most contentious statement in the manifesto is: "Artists who don't paint aren't artists".
The second and third manifestos, "An Open Letter to Sir Nicholas Serota" and "Remodernism" respectively, were sent to the director of the Tate, Nicholas Serota. He sent a brief reply: "Thank you for your open letter dated 6 March. You will not be surprised to learn that I have no comment to make on your letter, or your manifesto 'Remodernism'."
In the "Remodernism" manifesto, the Stuckists declared that they aimed to replace postmodernism with remodernism, a period of renewed spiritual (as opposed to religious) values in art, culture and society. Other manifestos have included "Handy Hints", "Anti-anti-art", "The Cappuccino writer and the Idiocy of Contemporary Writing", "The Turner Prize", "The Decreptitude of the Critic" and "Stuckist critique of Damien Hirst".
Manifestos have been written by other Stuckists, including the Students for Stuckism group. An "Underage Stuckists" group was founded in 2006 with a manifesto for teenagers written by two 16-year olds, Liv Soul and Rebekah Maybury, on MySpace.
Growth in UK.
In July 1999, the Stuckists were first mentioned in the media, in an article in "The Evening Standard" and soon gained other coverage, helped by press interest in Tracey Emin, who had been nominated for the Turner Prize.
The first Stuckist show was "Stuck! Stuck! Stuck!" in September 1999 in Joe Crompton's in Shoreditch Gallery 108 (now defunct), followed by "The Resignation of Sir Nicholas Serota". In 2000 they staged "The Real Turner Prize Show" at the same time as the Tate Gallery's Turner Prize exhibition.
A "Students for Stuckism" group was founded in 2000 by students from Camberwell College of Arts, who staged their own exhibition. S.P. Howarth was expelled from the painting degree course at Camberwell college for his paintings, and had the first solo exhibit at the Stuckism International Gallery in 2002, named "I Don't Want a Painting Degree if it Means Not Painting".
Thomson stood as a Stuckist candidate for the 2001 British General Election, in the constituency of Islington South & Finsbury, against Chris Smith, the then Secretary of State for Culture. He picked up 108 votes (0.4%). Childish left the group at this time because he objected to Thomson's leadership.
From 2002 to 2005 Thomson ran the Stuckism International Centre and Gallery in Shoreditch, London. In 2003, under the title "A Dead Shark Isn't Art", the gallery exhibited a shark which had first been put on public display in 1989 (two years before Damien Hirst's) by Eddie Saunders in his Shoreditch shop, JD Electrical Supplies. It was suggested that Hirst may have seen this and copied it.
In 2003 they reported Charles Saatchi to the UK Office of Fair Trading, complaining that he had an effective monopoly on art. The complaint was not upheld. In 2003, an allied group, Stuckism Photography, was founded by Larry Dunstan and Andy Bullock. In 2005 the Stuckists offered a donation of 175 paintings from the Walker show to the Tate, but it was rejected by the Tate's trustees.
In August 2005 Thomson alerted the press to the fact that the Tate had purchased a work by Chris Ofili, "The Upper Room", for £705,000 while the artist was a serving Tate trustee. Fraser Kee Scott, owner of A Gallery, demonstrated with the Stuckists outside the Tate Gallery against the gallery's purchase of "The Upper Room". Scott said in "The Daily Telegraph" that the Tate Gallery's chairman, Paul Myners, was hypocritical for refusing to divulge the price paid. Ofili had asked other artists to donate work to the gallery. In July 2006 the Charity Commission censured the gallery for acting outside its legal powers. Sir Nicholas Serota stated that the Stuckists had "acted in the public interest".
In October 2006, the Stuckists staged their first exhibition, "Go West", in a commercial West End gallery, Spectrum London, signalling their entry as "major players" in the art world.
An international symposium on Stuckism took place in October 2006 at the Liverpool John Moores University during the Liverpool Biennial. The programme was led by Naive John, founder of the Liverpool Stuckists. There was an accompanying exhibition in the 68 Hope Gallery at Liverpool School of Art and Design (John Moores University Gallery).
By 2006 there were 63 Stuckist groups in the UK. Members include Naive John, Mark D, Elsa Dax, Paul Harvey, Jane Kelly, Udaiyan, Peter McArdle, Peter Murphy, Rachel Jordan, Guy Denning and Abby Jackson. John Bourne opened Stuckism Wales at his home, a permanent exhibition of (mainly Welsh) paintings. Mandy McCartin is a regular guest artist.
In 2010, Paul Harvey's painting of Charles Saatchi was banned from the window display of the Artspace Gallery in Maddox Street, London, on the grounds that it was "too controversial for the area". It was the centrepiece of the show, "Stuckist Clowns Doing Their Dirty Work", the first exhibition of the Stuckists in Mayfair, and depicted Saatchi with a sheep at his feet and a halo made from a cheese wrapper. The Saatchi Gallery said that Saatchi "would not have any problem" with the painting's display. The gallery announced they were shutting down the show. Harvey said, "I did it to make Saatchi look friendly and human. It's a ludicrous decision".
The Stuckists considered legal action, and protested with emails to the gallery. Subsequently, the painting was reinstated and the show continued.
Demonstrations.
The Stuckists gained significant media coverage for eight years of protests (2000-2006 and 2008) outside Tate Britain against the Turner Prize, sometimes dressed as clowns. In 2001 they demonstrated in Trafalgar Square at the unveiling of Rachel Whiteread's "Monument". In 2002, they carried a coffin marked "The Death of Conceptual Art" to the White Cube Gallery. In 2004 outside the launch of "The Triumph of Painting" at the Saatchi Gallery they wore tall hats with Charles Saatchi's face emblazoned and carried placards claiming that Saatchi had copied their ideas.
Events outside Britain have included "The Clown Trial of President Bush" held in New Haven in 2003 to protest against the Iraq War. Michael Dickinson has exhibited political and satirical collages in Turkey for which he was arrested, and charged, but acquitted of any crime—an outcome which was seen to have positive implications for Turkey's relationship with the European Union.
The Stuckists Punk Victorian.
"The Stuckists Punk Victorian" was the first national gallery exhibition of Stuckist art. It was held at the Walker Art Gallery and Lady Lever Art Gallery and was part of the 2004 Liverpool Biennial. It consisted of over 250 paintings by 37 artists, mostly from the UK but also with a representation of international Stuckist artists from the US, Germany and Australia. There was an accompanying exhibition of Stuckist photographers. A book, "The Stuckists Punk Victorian", was published to accompany the exhibition. "Daily Mail" journalist Jane Kelly exhibited a painting of Myra Hindley in the show, which may have been the cause of her dismissal from her job.
A Gallery.
In July 2007, the Stuckists held an exhibition at A Gallery, "I Won't Have Sex with You as long as We're Married", titled after words apparently said to Thomson by his ex-wife, Stella Vine on their wedding night. The show coincided with the opening of Vine's major show at Modern Art Oxford and was prompted by Thomson's anger that the material promoting her show did not mention her time with the Stuckists. Tate chairman Paul Myners visited both shows.
Sir Nicholas Serota Makes an Acquisitions Decision.
Charles Thomson's painting, "Sir Nicholas Serota Makes an Acquisitions Decision", as Charlotte Cripps of The Independent wrote is one of the best known paintings to come out of the Stuckist movement, and as Jane Morris wrote in "The Guardian" it's a likely "signature piece" for the movement, standing for its opposition to conceptual art. Painted in 2000, the piece has been exhibited in laterStuckist shows, and featured on placards in Stuckist demonstrations against the Turner Prize. It depicts Sir Nicholas Serota, Director of the Tate Gallery and the usual chairman of the Turner Prize jury, and satirises Young British Artist Tracey Emin's installation, "My Bed", consisting of her bed and objects, including knickers, which she exhibited in 1999 as a Turner Prize nominee.
International movement.
In 2000 Regan Tamanui started the first Stuckist group outside Britain in Melbourne, Australia, and it was decided that other artists should be free to start their own groups also, named after their locality. Stuckism has since grown into an international art movement of 233 groups in 52 countries, as of July 2012.
Africa.
Mafa Bamba founded "The Abidgan Stuckists" in 2001 in Ivory Coast and Kari Seid founded "The Cape Town Stuckists" in 2008 in South Africa.
America.
In 2000, Susan Constanse founded the first US group "The Pittsburgh Stuckists" in Pittsburgh—the second group to be founded outside the UK. This was announced in the "In Pittsburgh Weekly", 1 November 2000: "The new word in art is Stuckism. A Stuckist paints their life, mind and soul with no pretensions and no excuses." By 2011 there are 44 US Stuckist groups. There have been Stuckist shows and demonstrations in the US, and American Stuckists have also exhibited in international Stuckist shows abroad. US Stuckists include Jeffrey Scott Holland, Tony Juliano, Frank Kozik and Terry Marks. There are also 4 Stuckist groups in Canada including "The White Rock Stuckists" in British Columbia founded by David Wilson.
Asia.
Asim Butt founded the first Pakistani Stuckist group, "The Karachi Stuckists", in 2005. At the end of 2009 he was thinking of expanding "The Karachi Stuckists" with new members, but on 15 January 2010 he committed suicide. In 2011 Sheherbano Husain restarted the group.
"The Tehran Stuckists" is an Iranian Stuckist, Remodernist and anti-anti-art group of painters founded in 2007 in Tehran, which is a major protagonist of Asian Stuckism. In April 2010 they curated the first Stuckist exhibition in Iran, "Tehran Stuckists: Searching for the Unlimited Potentials of Figurative Painting", at Iran Artists Forum, Mirmiran Gallery. Their second exhibition, "International Stuckists: Painters Out of Order", including paintings by Stuckists from Iran, Britain, USA, Spain, South Africa, Pakistan and Turkey was held at Day Gallery in November 2013. Although one of the main aspects of Stuckism movement is that "the Stuckist allows him/herself uncensored expression", but "The Tehran Stuckists"' exhibitions in Iran are censored and they are not allowed to exhibit some of their artworks in Iranian galleries. The group has also participated in Stuckist exhibitions in Britain, Lithuania and Spain.
Other Asian Stuckists are Shelley Li (China), Smeetha Boumik (India), Joko Apridinoto (Indonesia), Elio Yuri Figini (Japan) and Fady Chamaa (Lebanon).
Europe.
Despite Stuckists in UK, "The Prague Stuckists", founded in 2005 in Czech by Robert Janás, is a flourishing Stuckist group. Other Stuckist artists in Europe include Peter Klint (Germany), Michael Dickinson (Turkey), Odysseus Yakoumakis (Greece), Artista Eli (Spain), Kloot Per W (Belgium), Jaroslav Valecka (Czech), Marketa Koreckova (Czech), Jan Macko (Slovakia) and Pavel Lefterov (Bulgaria).
Oceania.
In October 2000, Regan Tamanui founded "The Melbourne Stuckists" in Melbourne, the fourth Stuckist group to be started and the first one outside the UK. On 27 October 2000, he staged the "Real Turner Prize Show" at the Dead End Gallery in his home, concurrent with three shows with the same title in England (London, Falmouth and Dartington) and one in Germany in protest against the Tate Gallery's Turner Prize. Other Australian Stuckists include Godfrey Blow, who exhibited in "The Stuckists Punk Victorian". In 2005 Mike Mayhew also founded "The Christchurch Stuckists" in New Zealand.
Ex Stuckists.
Co-founder, Billy Childish left the group in 2001, but has stated that he remains committed to its principles. Sexton Ming left to concentrate on a solo career with the Aquarium Gallery. Wolf Howard left in 2006, but has exhibited with the group since. Jesse Richards who ran the Stuckism Centre USA in New Haven, left the group in 2006 to focus on Remodernist film.
In June 2000, Stella Vine went to a talk given by Childish and Thomson on Stuckism and Remodernism in London. At the end of May 2001, she exhibited some of her paintings publicly for the first time in the "Vote Stuckist" show in Brixton, and formed The Westminster Stuckists group. On 4 June, she took part in a Stuckist demonstration in Trafalgar Square. By 10 July, she renamed her group The Unstuckists. In mid-August, Thomson and Vine were married. A work by her was shown in the Stuckist show in Paris, which ended in mid-November, by which time she had rejected the Stuckists, and the marriage had ended.
In February 2004, Charles Saatchi bought a painting of Diana, Princess of Wales by Vine and was credited with "discovering" her. Thomson said it was the Stuckists and not Saatchi who had discovered her. At the end of March 2004, Thomson made a formal complaint about Saatchi to the Office of Fair Trading, claiming that Saatchi's leading position was monopolistic "to the detriment of smaller competitors", citing Vine as an example of this. On 15 April, the OFT closed the file on the case on the basis that Saatchi was not "in a dominant position in any relevant market."
Responses.
In 1999, two performance artists, Yuan Chai and Jian Jun Xi, jumped on Tracey Emin's installation "My Bed", a work consisting of the artist's own unmade bed, at the Tate Gallery's Turner Prize, in an unauthorised art intervention. Chai had written, among other things, the words "Anti Stuckism" on his bare back. Fiachra Gibbons of "The Guardian" wrote (in 1999) that the event "will go down in art history as the defining moment of the new and previously unheard of Anti-Stuckist Movement." Writing in "The Guardian" ten years later, Jonathan Jones described the Stuckists as "enemies of art", and what they say as "cheap slogans" and "hysterical rants".
The artist Max Podstolski wrote that the art world needed a new manifesto, as confrontational as that of Futurism or Dadaism, "written with a heart-felt passion capable of inspiring and rallying art world outsiders, dissenters, rebels, the neglected and disaffected", and suggests that "Well now we've got it, in the form of Stuckism".
New York art gallery owner Edward Winkleman wrote in 2006 that he had never heard of the Stuckists, so he "looked them up on Wikipedia", and stated he was "turned off by the their anti-conceptual stance, not to mention the inanity of their statement about painting, but I'm more than a bit interested in the democratization their movement represents." Thomson responded to Winkleman directly.
Also in 2006, Colin Gleadell, writing in "The Telegraph", noted that the Stuckist's first exhibition in central London had brought "multiple sales" for leading artists of the movement, and that this raised the question of how good they were at painting. He observed that "Whatever the critics may say, buyers from the UK, the US and Japan have already taken a punt. Six of Thomson's paintings have sold for between £4,000 and £5,000 each. Joe Machine, a former jailbird who paints for therapeutic reasons, has also sold six paintings for the same price."
The BBC arts correspondent Lawrence Pollard wrote in 2009 that the way was paved for "cultural agitators" like the Stuckists, as well as the Vorticists, Surrealists and others, by the Futurist Manifesto of 20 February 1909.
Gallery.
Some UK artists.

</doc>
<doc id="58041" url="http://en.wikipedia.org/wiki?curid=58041" title="Bromeliaceae">
Bromeliaceae

The Bromeliaceae (the bromeliads) are a family of monocot flowering plants of around 3,170 species native mainly to the tropical Americas, with a few species found in the American subtropics and one in tropical west Africa, "Pitcairnia feliciana". They are among the basal families within the Poales and are unique because they are the only family within the order that has septal nectaries and inferior ovaries. These inferior ovaries characterize the Bromelioideae, a subfamily of the Bromeliaceae. The family includes both epiphytes, such as Spanish moss ("Tillandsia usneoides"), and terrestrial species, such as the pineapple ("Ananas comosus"). Many bromeliads are able to store water in a structure formed by their tightly-overlapping leaf bases. However, the family is diverse enough to include the tank bromeliads, grey-leaved epiphyte "Tillandsia" species that gather water only from leaf structures called trichomes, and a large number of desert-dwelling succulents.
The largest bromeliad is "Puya raimondii", which reaches 3–4 m tall in vegetative growth with a flower spike 9–10 m tall, and the smallest is Spanish moss.
Description.
Bromeliads are plants that are adapted to a number of climates. Foliage takes different shapes, from needle-thin to broad and flat, symmetrical to irregular, spiky to soft. The foliage, which usually grows in a rosette, is widely patterned and colored. Leaf colors range from maroon, through shades of green, to gold. Varieties may have leaves with red, yellow, white and cream variations. Others may be spotted with purple, red, or cream, while others have different colors on the tops and bottoms of the leaves.
The inflorescences produced by bromeliads are also regarded as considerably more diverse than any other plant family. Some flower spikes may reach 10 meters tall, while others only measure 2–3 mm across. Upright stalks may be branched or simple with spikes retaining their color from two weeks up to 12 months, depending on species. In some species, the flower remains unseen, growing deep in the base of the plants.
Root systems vary according to plant type. Terrestrial bromeliad species have complex root systems that gather water and nutrients, while epiphytic bromeliads only grow hard, wiry roots to attach themselves to trees and rocks.
Some bromeliads are faintly scented, while others are heavily perfumed. Blooms from the species "Tillandsia cyanea" have a fragrance resembling that of clove spice.
One study found 175,000 bromeliads per hectare (2.5 acres) in one forest; that many bromeliads can sequester 50,000 liters (more than 13,000 gallons) of water.
A wide variety of organisms takes advantage of the pools of water trapped by bromeliads. A study of 209 plants from the Ecuadorian lowlands identified 11,219 animals, representing more than 300 distinct species, many of which are found only on bromeliads. Examples include some species of ostracods, small salamanders about 2.5 cm (1 in) in length, and tree frogs. Jamaican bromeliads are home to "Metopaulias depressus", a reddish-brown crab 2 cm (0.75 inch) across, which has evolved social behavior to protect its young from predation by "Diceratobasis macrogaster", a species of damselfly whose larvae live in bromeliads. Some bromeliads even form homes for other species of bromeliads.
Distribution.
Plants in the Bromeliaceae are widely represented in their natural climates across the Americas. One species can be found in Africa. They can be found at altitudes from sea level to 4200 meters, from rainforests to deserts. Approximately half the species are epiphytes, some are lithophytes, and some are terrestrial. Accordingly, these plants can be found in the Andean highlands, from northern Chile to Colombia, in the Sechura Desert of coastal Peru, in the cloud forests of Central and South America, in southern United States from southern Virginia to Florida to Texas, and in far southern Arizona.
Evolution.
Bromeliads are among the more recent plant groups to have emerged. The greatest number of primitive species resides in the Andean highlands of South America, where they originated in the tepuis of the Guyana Shield. The most basal genus, "Brocchinia", is endemic to these tepuis, and is placed as the sister group to the remaining genera in the family. The west African species "Pitcairnia feliciana" is the only bromeliad not endemic to the Americas, and is thought to have reached Africa via long-distance dispersal about 12 million years ago.
Adaptations.
Bromeliads are able to live in a vast array of environmental conditions due to their many adaptations. Trichomes, in the form of scales or hairs, allow bromeliads to capture water in cloud forests and help to reflect sunlight in desert environments. Some bromeliads have also developed an adaptation known as the tank habit, which involves them forming a tightly bound structure with their leaves that helps to capture water and nutrients in the absence of a well-developed root system. Bromeliads also use crassulacean acid metabolism (CAM) photosynthesis to create sugars. This adaptation allows bromeliads in hot or dry climates to open their stomates at night rather than during the day, which reduces water loss.
Classification.
The family Bromeliaceae is currently placed in the order Poales.
Subfamilies.
The family Bromeliaceae is organized into three subfamilies:
Cultivation and uses.
Humans have been using bromeliads for thousands of years. The Incas, Aztecs, Maya and others used them for food, protection, fiber and ceremony, just as they are still used today. European interest began when Spanish conquistadors returned with pineapple, which became so popular as an exotic food that the image of the pineapple was adapted into European art and sculpture. In 1776, the species "Guzmania lingulata" was introduced to Europe, causing a sensation among gardeners unfamiliar with such a plant. In 1828, "Aechmea fasciata" was brought to Europe, followed by "Vriesea splendens" in 1840. These transplants were so successful, they are still among the most widely grown bromeliad varieties.
In the 19th century, breeders in Belgium, France and the Netherlands started hybridizing plants for wholesale trade. Many exotic varieties were produced until World War I, which halted breeding programs and led to the loss of some species. The plants experienced a resurgence of popularity after World War II. Since then, Dutch, Belgian and North American nurseries have greatly expanded bromeliad production.
Only one bromeliad, the pineapple ("Ananas comosus"), is a commercially important food crop. Bromelain, a common ingredient in meat tenderizer, is extracted from pineapple stems. Many other bromeliads are popular ornamental plants, grown as both garden and houseplants.
Collectors.
Édouard André was a French collector/explorer whose many discoveries of bromeliads in the Cordilleras of South America would be influential on horticulturists to follow. He served as a source of inspiration to 20th-century collectors, in particular Mulford B. Foster and Lyman Smith of the United States and Werner Rauh of Germany.

</doc>
<doc id="58043" url="http://en.wikipedia.org/wiki?curid=58043" title="Chinese sovereign">
Chinese sovereign

Chinese sovereign is the ruler of a particular period in ancient China. Several titles and naming schemes have been used throughout history.
Imperial titles.
Emperor.
The characters "Huang" (皇 huáng "god-king") and "Di" (帝 dì "sage king") had been used separately and never consecutively (see Three August Ones and Five Emperors). The character was reserved for mythological rulers until the first emperor of Qin (Qin Shi Huang), who created a new title "Huangdi" (皇帝 in pinyin: huáng dì) for himself in 221 BCE, which is commonly translated as "Emperor" in English. This title continued in use until the fall of the Qing dynasty in 1911.
From the Han Dynasty, the title "Huangdi" could also be abbreviated to "huang" or "di". The former nobility titles "Qing" (卿), "Daifu" (大夫) and "Shi" (仕) became synonyms for court officials.
The power of the emperor varied between emperors and dynasties, with some emperors being absolute rulers and others being figureheads with actual power lying in the hands of court factions, eunuchs, the bureaucracy or noble families. In principle, the title of emperor was transmitted from father to son via primogeniture, as endorsed by Confucianism. However, there are many exceptions to this rule. For example, because the Emperor usually had many concubines, the first born of the queen (i.e. the wife) is usually the heir apparent. However, Emperors could elevate another more favoured child or the child of a favourite concubine to the status of Crown Prince. Disputes over succession occurred regularly and have led to a number of civil wars. In the Qing dynasty, primogeniture was abandoned altogether, with the designated heir kept secret until after the Emperor's death.
Of the San Huang Wu Di, the three first of them were called 皇 (huang, "god-king") and the five last were called 帝 (di, "sage-king"), which can translate as either emperor, demigod human, or a superhuman. This title may have been used in the Shang and Xia dynasties, though oracle bones were found from the Shang Dynasty showing the title 王 (wáng, "king").
King.
The king (王, "wáng") was the Chinese head of state during the Zhou Dynasty. Its use during the Xia and Shang is uncertain but possible: the character has been found upon oracle bones. It was abolished under the Qin and, after that, the same term was used for (and translated as) royal princes. The title was commonly given to members of the Emperor's family and could be inherited. A poem from about 2,500 years ago said "普天之下,莫非王土.率土之賓,莫非王臣" which roughly translates as "Under the sky, nothing isn't the king's land; the people who lead the lands, no one isn't the king's subjects."
Son of Heaven.
The Son of Heaven was a title of the Emperor based on the Mandate of Heaven. The Son of Heaven is a universal emperor who rules tianxia comprising "all under heaven". The title was not interpreted literally. The monarch is a mortal chosen by Heaven, not its actual descendant. The title comes from the Mandate of Heaven, created by the monarchs of the Zhou dynasty to justify deposing the Shang dynasty. They declared that Heaven had revoked the mandate from the Shang and given it to the Zhou in retaliation for their corruption and misrule. Heaven bestowed the mandate to whoever was best fit to rule. The title held the emperor responsible for the prosperity and security of his people through the threat of losing the mandate.
Unlike the Japanese emperor for example, Chinese political theory allowed for a change of dynasty as imperial families could be replaced. This is based on the concept of "Mandate of Heaven". The theory behind this was that the Chinese emperor acted as the "Son of Heaven". As the only legitimate ruler, his authority extended to "All under heaven" and had neighbors only in a geographical sense. He holds a mandate to which he had a valid claim to rule over (or to lead) everyone else in the world as long as he served the people well. If the ruler became immoral, then rebellion is justified and heaven would take away that mandate and give it to another. This single most important concept legitimized the dynastic cycle or the change of dynasties regardless of social or ethnic background. This principle made it possible for dynasties founded by non-noble families such as Han Dynasty and Ming Dynasty or non-ethnic Han dynasties such as the Mongol-led Yuan Dynasty and Manchu-led Qing Dynasty. It was moral integrity and benevolent leadership that determined the holder of the "Mandate of Heaven." Every dynasty that self-consciously adopted this administrative practice powerfully reinforced this Sinocentric concept throughout the history of imperial China. Historians noted that this was one of the key reasons why imperial China in many ways had the most efficient system of government in ancient times.
Finally, it was generally not possible for a woman to succeed to the throne and in the history of China there has only been one reigning Empress, Wu Zetian (624–705 CE) who usurped power under the Tang dynasty.
How to read the titles of a Chinese sovereign.
All sovereigns are denoted by a string of Chinese characters. 
Examples:
The first character(s) are the name of the dynasty or kingdom.
e.g. Hàn, Táng, Wèi and Hòu Hàn.
Then come the characters of how the sovereign is commonly called, in most cases the posthumous names or the temple names.
e.g. Gāo Zǔ, Tài Zōng, Wǔ Dì, Guāng Wǔ Dì.
Then follow the characters of their family and given names.
e.g. "Liú Bāng", "Lǐ Shì Mín", "Cáo Cāo", "Liú Zhī Yuǎn" and "Liú Xiù".
In contemporary historical texts, the string including the name of dynasty and temple or posthumous names is sufficient enough as a clear reference to a particular sovereign.
e.g. Hàn Gāo Zǔ
Note that Wèi Wǔ Dì "Cáo Cāo" was never a sovereign in his own right but his son was. Thus his imperial style of Wǔ Dì was added only after his son had ascended to the throne. Such cases were common in Chinese history, i.e., the first emperor of a new dynasty often accorded posthumous imperial titles to his father or sometimes even further paternal ancestors.
Tang Dynasty naming conventions.
All sovereigns starting from the Tang Dynasty are contemporarily referred to using the temple names. They also had posthumous names that were less used, except in traditional historical texts. The situation was reversed before Tang as posthumous names were contemporarily used. 
e.g. The posthumous name of Táng Tài Zōng "Lǐ Shì Mín" was Wén Dì (文帝)
If sovereigns since Tang were referenced using posthumous names, they were the last ones of their sovereignties or their reigns were short and unpopular.
e.g. Táng Āi Dì "Lǐ Zhù" (唐哀帝 "李柷"), also known as Táng Zhāo Xuān Dì (唐昭宣帝), was last emperor of the Tang Dynasty reigning from 904 to 907.
Hàn Guāng Wǔ Dì is equivalent to Dōng Hàn Guāng Wǔ Dì since he was the founder of the Eastern (dōng) Han Dynasty. All dōng (east)-xī (west), nán (south)-běi (north), qián (former)-hòu (later) conventions were invented only by past or present historiographers for denoting a new era of a dynasty. They were never used during that era.
Self-made titles.
Xiang Yu styled himself, Xīchǔ Bàwáng (“西楚霸王,” lit. Hegemon-King of Western Chu).
Foreign titles taken by Chinese rulers.
Emperor Taizong of Tang was crowned Tian Kehan 天可汗, or "heavenly Khagan", after defeating the Gokturks, (Tujue).
Common naming conventions.
Here is a quick guide of the most common style of reference (but not a thorough explanation) in contemporary use. Using an emperor's different titles or styles is nevertheless considered correct but not as common.

</doc>
<doc id="58045" url="http://en.wikipedia.org/wiki?curid=58045" title="LL parser">
LL parser

In computer science, an LL parser is a top-down parser for a subset of context-free languages. It parses the input from Left to right, performing Leftmost derivation of the sentence.
An LL parser is called an LL("k") parser if it uses "k" tokens of lookahead when parsing a sentence. If such a parser exists for a certain grammar and it can parse sentences of this grammar without backtracking then it is called an LL("k") grammar. LL parsers can only parse languages that have LL("k") grammars without ε-rules. LL("k") grammars without ε-rules can generate more languages the higher the number "k" of lookahead tokens. A corollary of this is that not all context-free languages can be recognized by an LL(k) parser. An LL parser is called an LL("*") parser (an LL-regular parser) if it is not restricted to a finite "k" tokens of lookahead, but can make parsing decisions by recognizing whether the following tokens belong to a regular language (for example by means of a Deterministic Finite Automaton).
LL grammars, particularly LL(1) grammars, are of great practical interest, as parsers for these grammars are easy to construct, and many computer languages are designed to be LL(1) for this reason. LL parsers are table-based parsers, similar to LR parsers. LL grammars can also be parsed by recursive descent parsers.
General case.
The parser works on strings from a particular context-free grammar.
The parser consists of
The parser applies the rule found in the table by matching the top-most symbol on the stack (row) with the current symbol in the input stream (column).
When the parser starts, the stack already contains two symbols:
 [ S, $ ]
where '$' is a special terminal to indicate the bottom of the stack and the end of the input stream, and 'S' is the start symbol of the grammar. The parser will attempt to rewrite the contents of this stack to what it sees on the input stream. However, it only keeps on the stack what still needs to be rewritten.
Concrete example.
Set up.
To explain an LL(1) parser's workings we will consider the following small LL(1) grammar:
and parse the following input:
We construct a parsing table for this grammar by expanding all the terminals by column and all nonterminals by row. Later, the expressions are numbered by the position where the columns and rows cross. For example, the terminal '(' and non-terminal 'S' match for expression number 2. The table is as follows:
Parsing procedure.
In each step, the parser reads the next-available symbol from the input stream, and the top-most symbol from the stack. If the input symbol and the stack-top symbol match, the parser discards them both, leaving only the unmatched symbols in the input stream and on the stack.
Thus, in its first step, the parser reads the input symbol '(' and the stack-top symbol 'S'. The parsing table instruction comes from the column headed by the input symbol '(' and the row headed by the stack-top symbol 'S'; this cell contains '2', which instructs the parser to apply rule (2). The parser has to rewrite 'S' to '( S + F )' on the stack by removing 'S' from stack and pushing '(', 'S', '+', 'F', ')' onto the stack and this writes the rule number 2 to the output. The stack then becomes:
 [ (, S, +, F, ), $ ]
Since the '(' from the input stream did not match the top-most symbol, 'S', from the stack, it was not removed, and remains the next-available input symbol for the following step.
In the second step, the parser removes the '(' from its input stream and from its stack, since they now match. The stack now becomes:
 [ S, +, F, ), $ ]
Now the parser has an 'a' on its input stream and an 'S' as its stack top. The parsing table instructs it to apply rule (1) from the grammar and write the rule number 1 to the output stream. The stack becomes:
 [ F, +, F, ), $ ]
The parser now has an 'a' on its input stream and an 'F' as its stack top. The parsing table instructs it to apply rule (3) from the grammar and write the rule number 3 to the output stream. The stack becomes:
 [ a, +, F, ), $ ]
In the next two steps the parser reads the 'a' and '+' from the input stream and, since they match the next two items on the stack, also removes them from the stack. This results in:
 [ F, ), $ ]
In the next three steps the parser will replace 'F' on the stack by 'a', write the rule number 3 to the output stream and remove the 'a' and ')' from both the stack and the input stream. The parser thus ends with '$' on both its stack and its input stream.
In this case the parser will report that it has accepted the input string and write the following list of rule numbers to the output stream:
This is indeed a list of rules for a leftmost derivation of the input string, which is:
Parser implementation in C++.
Below follows a C++ implementation of a table-based LL parser for the example language:
Remarks.
As can be seen from the example the parser performs three types of steps depending on whether the top of the stack is a nonterminal, a terminal or the special symbol $:
These steps are repeated until the parser stops, and then it will have either completely parsed the input and written a leftmost derivation to the output stream or it will have reported an error.
Constructing an LL(1) parsing table.
In order to fill the parsing table, we have to establish what grammar rule the parser should choose if it sees a nonterminal "A" on the top of its stack and a symbol "a" on its input stream. 
It is easy to see that such a rule should be of the form "A" → "w" and that the language corresponding to "w" should have at least one string starting with "a". 
For this purpose we define the "First-set" of "w", written here as Fi("w"), as the set of terminals that can be found at the start of some string in "w", plus ε if the empty string also belongs to "w". 
Given a grammar with the rules "A"1 → "w"1, ..., "A""n" → "w""n", we can compute the Fi("w""i") and Fi("A""i") for every rule as follows:
Unfortunately, the First-sets are not sufficient to compute the parsing table. 
This is because a right-hand side "w" of a rule might ultimately be rewritten to the empty string. 
So the parser should also use the rule "A" → "w" if ε is in Fi("w") and it sees on the input stream a symbol that could follow "A". Therefore we also need the "Follow-set" of "A", written as Fo("A") here, which is defined as the set of terminals "a" such that there is a string of symbols "αAaβ" that can be derived from the start symbol. 
Computing the Follow-sets for the nonterminals in a grammar can be done as follows:
Now we can define exactly which rules will be contained where in the parsing table. 
If "T"["A", "a"] denotes the entry in the table for nonterminal "A" and terminal "a", then
If the table contains at most one rule in every one of its cells, then the parser will always know which rule it has to use and can therefore parse strings without backtracking. 
It is in precisely this case that the grammar is called an "LL(1) grammar".
Constructing an LL("k") parsing table.
Until the mid-1990s, it was widely believed that LL("k") parsing (for "k" > 1) was impractical, since the parser table would have exponential size in "k" in the worst case. This perception changed gradually after the release of the Purdue Compiler Construction Tool Set around 1992, when it was demonstrated that many programming languages can be parsed efficiently by an LL("k") parser without triggering the worst-case behavior of the parser. Moreover, in certain cases LL parsing is feasible even with unlimited lookahead. By contrast, traditional parser generators like yacc use LALR(1) parser tables to construct a restricted LR parser with a fixed one-token lookahead.
Conflicts.
As described in the introduction, LL(1) parsers recognize languages that have LL(1) grammars, which are a special case of context-free grammars (CFGs); LL(1) parsers cannot recognize all context-free languages. The LL(1) languages are a proper subset of the LR(1) languages which in turn are a proper subset of all context-free languages. In order for a CFG to be an LL(1) grammar, certain conflicts must not arise, which we describe in this section.
Terminology.
Let A be a non-terminal. FIRST(A) is (defined to be) the set of terminals that can appear in the first position of any string derived from A. FOLLOW(A) is the union over FIRST(B) where B is any non-terminal that immediately follows A in the right hand side of a production rule.
LL(1) Conflicts.
There are 2 main types of LL(1) conflicts:
FIRST/FIRST Conflict.
The FIRST sets of two different grammar rules for the same non-terminal intersect.
An example of an LL(1) FIRST/FIRST conflict:
 S -> E | E 'a'
 E -> 'b' | ε
FIRST(E) = {'b', ε} and FIRST(E 'a') = {'b', 'a'}, so when the table is drawn, there is conflict under terminal 'b' of production rule S.
Special Case: Left Recursion.
Left recursion will cause a FIRST/FIRST conflict with all alternatives.
 E -> E '+' term | alt1 | alt2
FIRST/FOLLOW Conflict.
The FIRST and FOLLOW set of a grammar rule overlap. With an empty string (ε) in the FIRST set it is unknown which alternative to select.
An example of an LL(1) conflict:
 S -> A 'a' 'b'
 A -> 'a' | ε
The FIRST set of A now is {'a', ε} and the FOLLOW set {'a'}.
Solutions to LL(1) Conflicts.
Left Factoring.
For a general method, see removing left recursion.
A common left-factor is "factored out".
 A -> X | X Y Z
becomes
 A -> X B
 B -> Y Z | ε
Can be applied when two alternatives start with the same symbol like a FIRST/FIRST conflict.
Another example (more complex) using above FIRST/FIRST conflict example:
 S -> E | E 'a'
 E -> 'b' | ε
becomes (merging into a single non-terminal)
 S -> 'b' | ε | 'b' 'a' | 'a'
then through left-factoring, becomes
 S -> 'b' E | E
 E -> 'a' | ε
Substitution.
Substituting a rule into another rule to remove indirect or FIRST/FOLLOW conflicts.
Note that this may cause a FIRST/FIRST conflict.
Left recursion removal.
A simple example for left recursion removal:
The following production rule has left recursion on E
 E -> E '+' T
 -> T
This rule is nothing but list of Ts separated by '+'. In a regular expression form T ('+' T)*.
So the rule could be rewritten as 
 E -> T Z
 Z -> '+' T Z
 -> ε
Now there is no left recursion and no conflicts on either of the rules.
However, not all CFGs have an equivalent LL(k)-grammar, e.g.:
 S -> A | B
 A -> 'a' A 'b' | ε
 B -> 'a' B 'b' 'b' | ε
It can be shown that there does not exist any LL(k)-grammar accepting the language generated by this grammar.

</doc>
<doc id="58046" url="http://en.wikipedia.org/wiki?curid=58046" title="Figure-eight knot">
Figure-eight knot

The figure-eight knot or figure-of-eight knot is a type of knot. It is very important in both sailing and rock climbing as a method of stopping ropes from running out of retaining devices. Like the overhand knot, which will jam under strain, often requiring the rope to be cut, the figure-of-eight will also jam, but is usually more easily undone than the overhand knot.
Different types of figure-eight knots.
Figure-eight loop.
The figure-eight loop is used like an overhand loop knot. This type of knot can be used in prusik climbing when used in conjunction with a climbing harness, a climbing rope, and locking carabiner designed for climbing, to ascend or descend with minimal equipment and effort.
Figure-eight bend.
The figure-eight bend knot is used to "splice" together two ropes, not necessarily of equal diameter. This knot is tied starting with a loose figure-eight knot on one rope (the larger-diameter one if unequal), and threading of the other rope's running end through the first figure eight, starting at the first figure-eight's running end and paralleling the path of the first rope through the figure eight until the second's ropes running end lies parallel against first's standing end. The result is two figure-eight knots, each partly inside the other and tightening its hold on the other when they are pulled in opposite directions. This can be a permanent or temporary splice. While it precludes the ropes' slipping relative to each other, it is a typical knot in having less strength than the straight ropes.
In heraldry, this knot is known as Savoy knot.
Offset figure-eight bend.
The offset figure-eight bend is a poor knot that has been implicated in the deaths of several rock climbers.
Stein knot.
The stein knot (aka stone knot) is a variation of the figure-eight knot. It is used to secure a rope that is already passed around a post or through a ring. It is quick and easy to tie and untie. It is a device rigging rather than a true knot.
In canyoneering, it is used to isolate rope strands to allow one person to rappel while another is getting on the rappel, or allow rappellers the option of using a single or a double rope.
It is also used to make baskets.

</doc>
<doc id="58055" url="http://en.wikipedia.org/wiki?curid=58055" title="Bering Sea">
Bering Sea

The Bering Sea is a marginal sea of the Pacific Ocean. It comprises a deep water basin, which then rises through a narrow slope into the shallower water above the continental shelves.
The Bering Sea is separated from the Gulf of Alaska by the Alaska Peninsula. It covers over 2,000,000 km2 bordered on the east and northeast by Alaska, on the west by Russia's Far East and Kamchatka Peninsula, on the south by the Alaska Peninsula and the Aleutian Islands and on the far north by the Bering Strait, which connects the Bering Sea to the Arctic Ocean's Chukchi Sea. Bristol Bay is the portion of the Bering Sea which separates the Alaska Peninsula from mainland Alaska. The Bering Sea is named for Vitus Bering, a Danish navigator in Russian service, who in 1728 was the first European to systematically explore it, sailing from the Pacific Ocean northward to the Arctic Ocean.
The Bering Sea ecosystem includes resources within the jurisdiction of the United States and Russia, as well as international waters in the middle of the sea (known as the "Donut Hole"). The interaction between currents, sea ice, and weather makes for a vigorous and productive ecosystem.
History.
Most scientists believe that during the most recent ice age, sea level was low enough to allow humans and other animals to migrate on foot from Asia to North America across what is now the Bering Strait. This is commonly referred to as the "Bering land bridge" and is believed by some—though not all— to be the first point of entry of humans into the Americas.
There is a small portion of the Kula Plate in the Bering Sea. The Kula Plate is an ancient tectonic plate that used to subduct under Alaska during the Triassic period.
Geography.
Extent.
The International Hydrographic Organization defines the limits of the Bering Sea as follows:
Islands.
Islands of the Bering Sea include:
Regions.
Regions of the Bering Sea include:
The Bering Sea contains 16 submarine canyons including the largest submarine canyon in the world, Zhemchug Canyon.
Ecosystem.
The Bering Sea shelf break is the dominant driver of primary productivity in the Bering Sea. This zone, where the shallower continental shelf drops off into the North Aleutians Basin is also known as the “Greenbelt”. Nutrient upwelling from the cold waters of the Aleutian basin flowing up the slope and mixing with shallower waters of the shelf provide for constant production of phytoplankton.
The second driver of productivity in the Bering Sea is seasonal sea ice that, in part, triggers the spring phytoplankton bloom. Seasonal melting of sea ice causes an influx of lower salinity water into the middle and other shelf areas, causing stratification and hydrographic effects which influence productivity. In addition to the hydrographic and productivity influence of melting sea ice, the ice itself also provides an attachment substrate for the growth of algae as well as interstitial ice algae.
Some evidence suggests that great changes to the Bering Sea ecosystem have already occurred. Warm water conditions in the summer of 1997 resulted in a massive bloom of low energy coccolithophorid phytoplankton (Stockwell et al. 2001). A long record of carbon isotopes, which is reflective of primary production trends of the Bering Sea, exists from historical samples of bowhead whale baleen. Trends in carbon isotope ratios in whale baleen samples suggest that a 30–40% decline in average seasonal primary productivity has occurred over the last 50 years. The implication is that the carrying capacity of the Bering Sea is much lower now than it has been in the past.
Biodiversity.
The sea supports many endangered whale species including bowhead whale, blue whale, fin whale, sei whale, humpback whale, sperm whale and the rarest in the world, the North Pacific right whale. Other marine mammals include walrus, Steller sea lion, northern fur seal, beluga, orca and polar bear.
The Bering Sea is very important to the seabirds of the world. Over 30 species of seabirds and approximately 20 million individuals breed in the Bering Sea region. Seabird species include tufted puffins, the endangered short-tailed albatross, spectacled eider, and red-legged kittiwakes. Many of these species are unique to the area, which provides highly productive foraging habitat, particularly along the shelf edge and in other nutrient-rich upwelling regions, such as the Pribilof, Zhemchug, and Pervenets canyons. The Bering Sea is also home to colonies of crested auklets, with upwards of a million individuals.
Two Bering Sea species, the Steller's sea cow ("Hydrodamalis gigas") and spectacled cormorant ("Phalacrocorax perspicillatus"), are extinct because of overexploitation by man. In addition, a small subspecies of Canada goose, the Bering Canada goose ("Branta canadensis asiatica") is extinct due to overhunting and introduction of rats to their breeding islands.
The Bering Sea supports many species of fish. Some species of fish support large and valuable commercial fisheries. Commercial fish species include 6 species of Pacific salmon, Alaska pollock, red king crab, "Chionoecetes", Pacific cod, Pacific halibut, yellowfin sole, Pacific ocean perch and sablefish.
Fish biodiversity is high, and at least 419 species of fish have been reported from the Bering Sea.
Fisheries.
The Bering Sea is world renowned for its enormously productive and profitable fisheries, such as king crab, opilio and tanner crabs, Bristol Bay salmon, pollock and other groundfish. These fisheries rely on the productivity of the Bering Sea via a complicated and little understood food web. The continued existence of these fisheries requires an intact, healthy, and productive ecosystem.
Commercial fishing is big business in the Bering Sea, which is relied upon by the largest seafood companies in the world to produce fish and shellfish. On the U.S. side, commercial fisheries catch approximately $1 billion worth of seafood annually, while Russian Bering Sea fisheries are worth approximately $600 million annually.
The Bering Sea also serves as the central location of the Alaskan king crab and opilio crab seasons, which are chronicled on the Discovery Channel television program "Deadliest Catch". Landings from Alaskan waters represents half the U.S. catch of fish and shellfish.
Change.
Because of the changes going on in the Arctic, future evolution of the Bering Sea climate/ecosystem is uncertain. Between 1979 and 2012 the region experienced small growth in sea ice extent, standing in stark contrast to the substantial loss of summer sea ice in the Arctic Ocean to the north

</doc>
