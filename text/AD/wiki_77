<doc id="56435" url="http://en.wikipedia.org/wiki?curid=56435" title="Obesity">
Obesity

Obesity is a medical condition in which excess body fat has accumulated to the extent that it may have a negative effect on health, leading to reduced life expectancy and/or increased health problems. In Western countries, people are considered obese when their body mass index (BMI), a measurement obtained by dividing a person's weight by the square of the person's height, exceeds , with the range 25- defined as overweight. Some East Asian countries use stricter criteria.
Obesity increases the likelihood of various diseases, particularly heart disease, type 2 diabetes, obstructive sleep apnea, certain types of cancer, and osteoarthritis. Obesity is most commonly caused by a combination of excessive food energy intake, lack of physical activity, and genetic susceptibility, although a few cases are caused primarily by genes, endocrine disorders, medications, or psychiatric illness. Evidence to support the view that some obese people eat little yet gain weight due to a slow metabolism is limited. On average, obese people have a greater energy expenditure than their thin counterparts due to the energy required to maintain an increased body mass.
Dieting and exercising are the main treatments for obesity. Diet quality can be improved by reducing the consumption of energy-dense foods, such as those high in fat and sugars, and by increasing the intake of dietary fiber. With a suitable diet, anti-obesity drugs may be taken to reduce appetite or decrease fat absorption. If diet, exercise, and medication are not effective, a gastric balloon may assist with weight loss, or surgery may be performed to reduce stomach volume and/or bowel length, leading to feeling full earlier and a reduced ability to absorb nutrients from food.
Obesity is a leading preventable cause of death worldwide, with increasing rates in adults and children. Authorities view it as one of the most serious public health problems of the 21st century. Obesity is stigmatized in much of the modern world (particularly in the Western world), though it was widely seen as a symbol of wealth and fertility at other times in history and still is in some parts of the world. In 2013, the American Medical Association classified obesity as a disease.
Classification.
Obesity is a medical condition in which excess body fat has accumulated to the extent that it may have an adverse effect on health. It is defined by body mass index (BMI) and further evaluated in terms of fat distribution via the waist–hip ratio and total cardiovascular risk factors. BMI is closely related to both percentage body fat and total body fat.
In children, a healthy weight varies with age and sex. Obesity in children and adolescents is defined not as an absolute number but in relation to a historical normal group, such that obesity is a BMI greater than the 95th percentile. The reference data on which these percentiles were based date from 1963 to 1994, and thus have not been affected by the recent increases in weight.
BMI is defined as the subject's weight divided by the square of their height and is calculated as follows.
BMI is usually expressed in kilograms per square metre, resulting when weight is measured in kilograms and height in metres. To convert from pounds per square inch multiply by 703 (kg/m2)/(lb/sq in).
The most commonly used definitions, established by the World Health Organization (WHO) in 1997 and published in 2000, provide the values listed in the table at right.
Some modifications to the WHO definitions have been made by particular bodies. The surgical literature breaks down "class III" obesity into further categories whose exact values are still disputed.
As Asian populations develop negative health consequences at a lower BMI than Caucasians, some nations have redefined obesity; the Japanese have defined obesity as any BMI greater than 25 kg/m2 while China uses a BMI of greater than 28 kg/m2.
Effects on health.
Excessive body weight is associated with various diseases, particularly cardiovascular diseases, diabetes mellitus type 2, obstructive sleep apnea, certain types of cancer, osteoarthritis and asthma. As a result, obesity has been found to reduce life expectancy.
Mortality.
Obesity is one of the leading preventable causes of death worldwide. Large-scale American and European studies have found that mortality risk is lowest at a BMI of 20–25 kg/m2 in non-smokers and at 24–27 kg/m2 in current smokers, with risk increasing along with changes in either direction. In Asians risk begins to increase between 22–25 kg/m2. A BMI above 32 kg/m2 has been associated with a doubled mortality rate among women over a 16-year period. In the United States obesity is estimated to cause 111,909 to 365,000 deaths per year, while 1 million (7.7%) of deaths in Europe are attributed to excess weight. On average, obesity reduces life expectancy by six to seven years, a BMI of 30–35 kg/m2 reduces life expectancy by two to four years, while severe obesity (BMI > 40 kg/m2) reduces life expectancy by ten years.
Morbidity.
Obesity increases the risk of many physical and mental conditions. These comorbidities are most commonly shown in metabolic syndrome, a combination of medical disorders which includes: diabetes mellitus type 2, high blood pressure, high blood cholesterol, and high triglyceride levels.
Complications are either directly caused by obesity or indirectly related through mechanisms sharing a common cause such as a poor diet or a sedentary lifestyle. The strength of the link between obesity and specific conditions varies. One of the strongest is the link with type 2 diabetes. Excess body fat underlies 64% of cases of diabetes in men and 77% of cases in women.
Health consequences fall into two broad categories: those attributable to the effects of increased fat mass (such as osteoarthritis, obstructive sleep apnea, social stigmatization) and those due to the increased number of fat cells (diabetes, cancer, cardiovascular disease, non-alcoholic fatty liver disease). Increases in body fat alter the body's response to insulin, potentially leading to insulin resistance. Increased fat also creates a proinflammatory state, and a prothrombotic state.
Survival paradox.
Although the negative health consequences of obesity in the general population are well supported by the available evidence, health outcomes in certain subgroups seem to be improved at an increased BMI, a phenomenon known as the obesity survival paradox. The paradox was first described in 1999 in overweight and obese people undergoing hemodialysis, and has subsequently been found in those with heart failure and peripheral artery disease (PAD).
In people with heart failure, those with a BMI between 30.0 and 34.9 had lower mortality than those with a normal weight. This has been attributed to the fact that people often lose weight as they become progressively more ill. Similar findings have been made in other types of heart disease. People with class I obesity and heart disease do not have greater rates of further heart problems than people of normal weight who also have heart disease. In people with greater degrees of obesity, however, the risk of further cardiovascular events is increased. Even after cardiac bypass surgery, no increase in mortality is seen in the overweight and obese. One study found that the improved survival could be explained by the more aggressive treatment obese people receive after a cardiac event. Another found that if one takes into account chronic obstructive pulmonary disease (COPD) in those with PAD, the benefit of obesity no longer exists.
Causes.
At an individual level, a combination of excessive food energy intake and a lack of physical activity is thought to explain most cases of obesity. A limited number of cases are due primarily to genetics, medical reasons, or psychiatric illness. In contrast, increasing rates of obesity at a societal level are felt to be due to an easily accessible and palatable diet, increased reliance on cars, and mechanized manufacturing.
A 2006 review identified ten other possible contributors to the recent increase of obesity: (1) insufficient sleep, (2) endocrine disruptors (environmental pollutants that interfere with lipid metabolism), (3) decreased variability in ambient temperature, (4) decreased rates of smoking, because smoking suppresses appetite, (5) increased use of medications that can cause weight gain (e.g., atypical antipsychotics), (6) proportional increases in ethnic and age groups that tend to be heavier, (7) pregnancy at a later age (which may cause susceptibility to obesity in children), (8) epigenetic risk factors passed on generationally, (9) natural selection for higher BMI, and (10) assortative mating leading to increased concentration of obesity risk factors (this would increase the number of obese people by increasing population variance in weight). While there is substantial evidence supporting the influence of these mechanisms on the increased prevalence of obesity, the evidence is still inconclusive, and the authors state that these are probably less influential than the ones discussed in the previous paragraph.
Diet.
1961
2001–03
Map of dietary energy availability per person per day in 1961 (left) and 2001–2003 (right) Calories per person per day (kilojoules per person per day)
Dietary energy supply per capita varies markedly between different regions and countries. It has also changed significantly over time. From the early 1970s to the late 1990s the average food energy available per person per day (the amount of food bought) increased in all parts of the world except Eastern Europe. The United States had the highest availability with 3654 Cal per person in 1996. This increased further in 2003 to 3754 Cal. During the late 1990s Europeans had 3394 Cal per person, in the developing areas of Asia there were 2648 Cal per person, and in sub-Saharan Africa people had 2176 Cal per person. Total food energy consumption has been found to be related to obesity.
The widespread availability of nutritional guidelines has done little to address the problems of overeating and poor dietary choice. From 1971 to 2000, obesity rates in the United States increased from 14.5% to 30.9%. During the same period, an increase occurred in the average amount of food energy consumed. For women, the average increase was 335 Cal per day (1542 Cal in 1971 and 1877 Cal in 2004), while for men the average increase was 168 Cal per day (2450 Cal in 1971 and 2618 Cal in 2004). Most of this extra food energy came from an increase in carbohydrate consumption rather than fat consumption. The primary sources of these extra carbohydrates are sweetened beverages, which now account for almost 25 percent of daily food energy in young adults in America, and potato chips. Consumption of sweetened drinks such as soft drinks, fruit drinks, iced tea, and energy and vitamin water drinks is believed to be contributing to the rising rates of obesity and to an increased risk of metabolic syndrome and type 2 diabetes.
As societies become increasingly reliant on energy-dense, big-portions, and fast-food meals, the association between fast-food consumption and obesity becomes more concerning. In the United States consumption of fast-food meals tripled and food energy intake from these meals quadrupled between 1977 and 1995.
Agricultural policy and techniques in the United States and Europe have led to lower food prices. In the United States, subsidization of corn, soy, wheat, and rice through the U.S. farm bill has made the main sources of processed food cheap compared to fruits and vegetables. Calorie count laws and nutrition facts labels attempt to steer people toward making healthier food choices, including awareness of how much food energy is being consumed.
Obese people consistently under-report their food consumption as compared to people of normal weight. This is supported both by tests of people carried out in a calorimeter room and by direct observation.
Sedentary lifestyle.
A sedentary lifestyle plays a significant role in obesity. Worldwide there has been a large shift towards less physically demanding work, and currently at least 30% of the world's population gets insufficient exercise. This is primarily due to increasing use of mechanized transportation and a greater prevalence of labor-saving technology in the home. In children, there appear to be declines in levels of physical activity due to less walking and physical education. World trends in active leisure time physical activity are less clear. The World Health Organization indicates people worldwide are taking up less active recreational pursuits, while a study from Finland found an increase and a study from the United States found leisure-time physical activity has not changed significantly.
In both children and adults, there is an association between television viewing time and the risk of obesity. A review found 63 of 73 studies (86%) showed an increased rate of childhood obesity with increased media exposure, with rates increasing proportionally to time spent watching television.
Genetics.
Like many other medical conditions, obesity is the result of an interplay between genetic and environmental factors. Polymorphisms in various genes controlling appetite and metabolism predispose to obesity when sufficient food energy is present. As of 2006, more than 41 of these sites on the human genome have been linked to the development of obesity when a favorable environment is present. People with two copies of the FTO gene (fat mass and obesity associated gene) have been found on average to weigh 3–4 kg more and have a 1.67-fold greater risk of obesity compared with those without the risk allele. The differences in BMI between people that are due to genetics varies depending on the population examined from 6% to 85%.
Obesity is a major feature in several syndromes, such as Prader–Willi syndrome, Bardet–Biedl syndrome, Cohen syndrome, and MOMO syndrome. (The term "non-syndromic obesity" is sometimes used to exclude these conditions.) In people with early-onset severe obesity (defined by an onset before 10 years of age and body mass index over three standard deviations above normal), 7% harbor a single point DNA mutation.
Studies that have focused on inheritance patterns rather than on specific genes have found that 80% of the offspring of two obese parents were also obese, in contrast to less than 10% of the offspring of two parents who were of normal weight. Different people exposed to the same environment have different risks of obesity due to their underlying genetics.
The thrifty gene hypothesis postulates that, due to dietary scarcity during human evolution, people are prone to obesity. Their ability to take advantage of rare periods of abundance by storing energy as fat would be advantageous during times of varying food availability, and individuals with greater adipose reserves would be more likely to survive famine. This tendency to store fat, however, would be maladaptive in societies with stable food supplies. This theory has received various criticisms, and other evolutionarily-based theories such as the drifty gene hypothesis and the thrifty phenotype hypothesis have also been proposed.
Other illnesses.
Certain physical and mental illnesses and the pharmaceutical substances used to treat them can increase risk of obesity. Medical illnesses that increase obesity risk include several rare genetic syndromes (listed above) as well as some congenital or acquired conditions: hypothyroidism, Cushing's syndrome, growth hormone deficiency, and the eating disorders: binge eating disorder and night eating syndrome. However, obesity is not regarded as a psychiatric disorder, and therefore is not listed in the DSM-IVR as a psychiatric illness. The risk of overweight and obesity is higher in patients with psychiatric disorders than in persons without psychiatric disorders.
Certain medications may cause weight gain or changes in body composition; these include insulin, sulfonylureas, thiazolidinediones, atypical antipsychotics, antidepressants, steroids, certain anticonvulsants (phenytoin and valproate), pizotifen, and some forms of hormonal contraception.
Social determinants.
While genetic influences are important to understanding obesity, they cannot explain the current dramatic increase seen within specific countries or globally. Though it is accepted that energy consumption in excess of energy expenditure leads to obesity on an individual basis, the cause of the shifts in these two factors on the societal scale is much debated. There are a number of theories as to the cause but most believe it is a combination of various factors.
The correlation between social class and BMI varies globally. A review in 1989 found that in developed countries women of a high social class were less likely to be obese. No significant differences were seen among men of different social classes. In the developing world, women, men, and children from high social classes had greater rates of obesity. An update of this review carried out in 2007 found the same relationships, but they were weaker. The decrease in strength of correlation was felt to be due to the effects of globalization. Among developed countries, levels of adult obesity, and percentage of teenage children who are overweight, are correlated with income inequality. A similar relationship is seen among US states: more adults, even in higher social classes, are obese in more unequal states.
Many explanations have been put forth for associations between BMI and social class. It is thought that in developed countries, the wealthy are able to afford more nutritious food, they are under greater social pressure to remain slim, and have more opportunities along with greater expectations for physical fitness. In undeveloped countries the ability to afford food, high energy expenditure with physical labor, and cultural values favoring a larger body size are believed to contribute to the observed patterns. Attitudes toward body weight held by people in one's life may also play a role in obesity. A correlation in BMI changes over time has been found among friends, siblings, and spouses. Stress and perceived low social status appear to increase risk of obesity.
Smoking has a significant effect on an individual's weight. Those who quit smoking gain an average of 4.4 kilograms (9.7 lb) for men and 5.0 kilograms (11.0 lb) for women over ten years. However, changing rates of smoking have had little effect on the overall rates of obesity.
In the United States the number of children a person has is related to their risk of obesity. A woman's risk increases by 7% per child, while a man's risk increases by 4% per child. This could be partly explained by the fact that having dependent children decreases physical activity in Western parents.
In the developing world urbanization is playing a role in increasing rate of obesity. In China overall rates of obesity are below 5%; however, in some cities rates of obesity are greater than 20%.
Malnutrition in early life is believed to play a role in the rising rates of obesity in the developing world. Endocrine changes that occur during periods of malnutrition may promote the storage of fat once more food energy becomes available.
Consistent with cognitive epidemiological data, numerous studies confirm that obesity is associated with cognitive deficits. Whether obesity causes cognitive deficits, or vice versa is unclear at present.
Infectious agents.
The study of the effect of infectious agents on metabolism is still in its early stages. Gut flora has been shown to differ between lean and obese humans. There is an indication that gut flora in obese and lean individuals can affect the metabolic potential. This apparent alteration of the metabolic potential is believed to confer a greater capacity to harvest energy contributing to obesity. Whether these differences are the direct cause or the result of obesity has yet to be determined unequivocally.
An association between viruses and obesity has been found in humans and several different animal species. The amount that these associations may have contributed to the rising rate of obesity is yet to be determined.
Pathophysiology.
There are many possible pathophysiological mechanisms involved in the development and maintenance of obesity. This field of research had been almost unapproached until the leptin gene was discovered in 1994 by J. M. Friedman's laboratory. These investigators postulated that leptin was a satiety factor. In the ob/ob mouse, mutations in the leptin gene resulted in the obese phenotype opening the possibility of leptin therapy for human obesity. However, soon thereafter J. F. Caro's laboratory could not detect any mutations in the leptin gene in humans with obesity. On the contrary Leptin expression was increased proposing the possibility of Leptin-resistance in human obesity. Since this discovery, many other hormonal mechanisms have been elucidated that participate in the regulation of appetite and food intake, storage patterns of adipose tissue, and development of insulin resistance. Since leptin's discovery, ghrelin, insulin, orexin, PYY 3-36, cholecystokinin, adiponectin, as well as many other mediators have been studied. The adipokines are mediators produced by adipose tissue; their action is thought to modify many obesity-related diseases.
Leptin and ghrelin are considered to be complementary in their influence on appetite, with ghrelin produced by the stomach modulating short-term appetitive control (i.e. to eat when the stomach is empty and to stop when the stomach is stretched). Leptin is produced by adipose tissue to signal fat storage reserves in the body, and mediates long-term appetitive controls (i.e. to eat more when fat storages are low and less when fat storages are high). Although administration of leptin may be effective in a small subset of obese individuals who are leptin deficient, most obese individuals are thought to be leptin resistant and have been found to have high levels of leptin. This resistance is thought to explain in part why administration of leptin has not been shown to be effective in suppressing appetite in most obese people.
While leptin and ghrelin are produced peripherally, they control appetite through their actions on the central nervous system. In particular, they and other appetite-related hormones act on the hypothalamus, a region of the brain central to the regulation of food intake and energy expenditure. There are several circuits within the hypothalamus that contribute to its role in integrating appetite, the melanocortin pathway being the most well understood. The circuit begins with an area of the hypothalamus, the arcuate nucleus, that has outputs to the lateral hypothalamus (LH) and ventromedial hypothalamus (VMH), the brain's feeding and satiety centers, respectively.
The arcuate nucleus contains two distinct groups of neurons. The first group coexpresses neuropeptide Y (NPY) and agouti-related peptide (AgRP) and has stimulatory inputs to the LH and inhibitory inputs to the VMH. The second group coexpresses pro-opiomelanocortin (POMC) and cocaine- and amphetamine-regulated transcript (CART) and has stimulatory inputs to the VMH and inhibitory inputs to the LH. Consequently, NPY/AgRP neurons stimulate feeding and inhibit satiety, while POMC/CART neurons stimulate satiety and inhibit feeding. Both groups of arcuate nucleus neurons are regulated in part by leptin. Leptin inhibits the NPY/AgRP group while stimulating the POMC/CART group. Thus a deficiency in leptin signaling, either via leptin deficiency or leptin resistance, leads to overfeeding and may account for some genetic and acquired forms of obesity.
Public health.
The World Health Organization (WHO) predicts that overweight and obesity may soon replace more traditional public health concerns such as undernutrition and infectious diseases as the most significant cause of poor health. Obesity is a public health and policy problem because of its prevalence, costs, and health effects. The United States Preventive Services Task Force recommends screening for all adults followed by behavioral interventions in those who are obese. Public health efforts seek to understand and correct the environmental factors responsible for the increasing prevalence of obesity in the population. Solutions look at changing the factors that cause excess food energy consumption and inhibit physical activity. Efforts include federally reimbursed meal programs in schools, limiting direct junk food marketing to children, and decreasing access to sugar-sweetened beverages in schools. When constructing urban environments, efforts have been made to increase access to parks and to develop pedestrian routes.
Many countries and groups have published reports pertaining to obesity. In 1998 the first US Federal guidelines were published, titled "Clinical Guidelines on the Identification, Evaluation, and Treatment of Overweight and Obesity in Adults: The Evidence Report". In 2006 the Canadian Obesity Network published the "Canadian Clinical Practice Guidelines (CPG) on the Management and Prevention of Obesity in Adults and Children". This is a comprehensive evidence-based guideline to address the management and prevention of overweight and obesity in adults and children.
In 2004, the United Kingdom Royal College of Physicians, the Faculty of Public Health and the Royal College of Paediatrics and Child Health released the report "Storing up Problems", which highlighted the growing problem of obesity in the UK. The same year, the House of Commons Health Select Committee published its "most comprehensive inquiry [...] ever undertaken" into the impact of obesity on health and society in the UK and possible approaches to the problem. In 2006, the National Institute for Health and Clinical Excellence (NICE) issued a guideline on the diagnosis and management of obesity, as well as policy implications for non-healthcare organizations such as local councils. A 2007 report produced by Sir Derek Wanless for the King's Fund warned that unless further action was taken, obesity had the capacity to cripple the National Health Service financially.
Comprehensive approaches are being looked at to address the rising rates of obesity. The Obesity Policy Action (OPA) framework divides measure into 'upstream' policies, 'midstream' policies, 'downstream' policies. 'Upstream' policies look at changing society, 'midstream' policies try to alter individuals' behavior to prevent obesity, and 'downstream' policies try to treat currently afflicted people.
Management.
The main treatment for obesity consists of dieting and physical exercise. Diet programs may produce weight loss over the short term, but maintaining this weight loss is frequently difficult and often requires making exercise and a lower food energy diet a permanent part of a person's lifestyle. All types of low-carbohydrate and low-fat diets appear equally beneficial. The heart disease and diabetes risks associated with different diets also appear to be similar. Success rates of long-term weight loss maintenance with lifestyle changes are low, ranging from 2–20%. Dietary and lifestyle changes are effective in limiting excessive weight gain in pregnancy and improve outcomes for both the mother and the child. Intensive behavioral counseling is recommended in those who are both obese and have other risk factors for heart disease.
Three medications, orlistat (Xenical), lorcaserin (Belviq) and a combination of phentermine and topiramate (Qsymia) are currently available and have evidence for long term use. Weight loss with orlistat is modest, an average of 2.9 kg (6.4 lb) at 1 to 4 years. Its use is associated with high rates of gastrointestinal side effects and concerns have been raised about negative effects on the kidneys. The other two medications are available in the United States but not Europe. Lorcaserin results in an average 3.1 kg weight loss (3% of body weight) greater than placebo over a year; however, it may increase heart valve problems. A combination of phentermine and topiramate is also somewhat effective; however, it may be associated with heart problems. There is no information on how these drugs affect longer-term complications of obesity such as cardiovascular disease or death.
The most effective treatment for obesity is bariatric surgery. Surgery for severe obesity is associated with long-term weight loss, improvement in obesity related conditions, and decreased overall mortality. One study found a weight loss of between 14% and 25% (depending on the type of procedure performed) at 10 years, and a 29% reduction in all cause mortality when compared to standard weight loss measures. Complications occur in about 17% of cases and reoperation is needed in 7% of cases. Due to its cost and risks, researchers are searching for other effective yet less invasive treatments including devices that occupy space in the stomach.
Epidemiology.
In earlier historical periods obesity was rare, and achievable only by a small elite, although already recognised as a problem for health. But as prosperity increased in the Early Modern period, it affected increasingly larger groups of the population. In 1997 the WHO formally recognized obesity as a global epidemic. As of 2008 the WHO estimates that at least 500 million adults (greater than 10%) are obese, with higher rates among women than men. The rate of obesity also increases with age at least up to 50 or 60 years old and severe obesity in the United States, Australia, and Canada is increasing faster than the overall rate of obesity.
Once considered a problem only of high-income countries, obesity rates are rising worldwide and affecting both the developed and developing world. These increases have been felt most dramatically in urban settings. The only remaining region of the world where obesity is not common is sub-Saharan Africa.
History.
Etymology.
"Obesity" is from the Latin "obesitas", which means "stout, fat, or plump". "Ēsus" is the past participle of "edere" (to eat), with "ob" (over) added to it. "The Oxford English Dictionary" documents its first usage in 1611 by Randle Cotgrave.
Historical attitudes.
Ancient Greek medicine recognizes obesity as a medical disorder, and records that the Ancient Egyptians saw it in the same way. Hippocrates wrote that "Corpulence is not only a disease itself, but the harbinger of others". The Indian surgeon Sushruta (6th century BCE) related obesity to diabetes and heart disorders. He recommended physical work to help cure it and its side effects. For most of human history mankind struggled with food scarcity. Obesity has thus historically been viewed as a sign of wealth and prosperity. It was common among high officials in Europe in the Middle Ages and the Renaissance as well as in Ancient East Asian civilizations.
With the onset of the industrial revolution it was realized that the military and economic might of nations were dependent on both the body size and strength of their soldiers and workers. Increasing the average body mass index from what is now considered underweight to what is now the normal range played a significant role in the development of industrialized societies. Height and weight thus both increased through the 19th century in the developed world. During the 20th century, as populations reached their genetic potential for height, weight began increasing much more than height, resulting in obesity. In the 1950s increasing wealth in the developed world decreased child mortality, but as body weight increased heart and kidney disease became more common.
During this time period insurance companies realized the connection between weight and life expectancy and increased premiums for the obese.
Many cultures throughout history have viewed obesity as the result of a character flaw. The "obesus" or fat character in Greek comedy was a glutton and figure of mockery. During Christian times food was viewed as a gateway to the sins of sloth and lust. In modern Western culture, excess weight is often regarded as unattractive, and obesity is commonly associated with various negative stereotypes. People of all ages can face social stigmatization, and may be targeted by bullies or shunned by their peers.
Public perceptions in Western society regarding healthy body weight differ from those regarding the weight that is considered ideal  – and both have changed since the beginning of the 20th century. The weight that is viewed as an ideal has become lower since the 1920s. This is illustrated by the fact that the average height of Miss America pageant winners increased by 2% from 1922 to 1999, while their average weight decreased by 12%. On the other hand, people's views concerning healthy weight have changed in the opposite direction. In Britain the weight at which people considered themselves to be overweight was significantly higher in 2007 than in 1999. These changes are believed to be due to increasing rates of adiposity leading to increased acceptance of extra body fat as being normal.
Obesity is still seen as a sign of wealth and well-being in many parts of Africa. This has become particularly common since the HIV epidemic began.
The arts.
The first sculptural representations of the human body 20,000–35,000 years ago depict obese females. Some attribute the Venus figurines to the tendency to emphasize fertility while others feel they represent "fatness" in the people of the time. Corpulence is, however, absent in both Greek and Roman art, probably in keeping with their ideals regarding moderation. This continued through much of Christian European history, with only those of low socioeconomic status being depicted as obese.
During the Renaissance some of the upper class began flaunting their large size, as can be seen in portraits of Henry VIII of England and Alessandro del Borro. Rubens (1577–1640) regularly depicted full-bodied women in his pictures, from which derives the term Rubenesque. These women, however, still maintained the "hourglass" shape with its relationship to fertility. During the 19th century, views on obesity changed in the Western world. After centuries of obesity being synonymous with wealth and social status, slimness began to be seen as the desirable standard.
Society and culture.
Economic impact.
In addition to its health impacts, obesity leads to many problems including disadvantages in employment and increased business costs. These effects are felt by all levels of society from individuals, to corporations, to governments.
In 2005, the medical costs attributable to obesity in the US were an estimated $190.2 billion or 20.6% of all medical expenditures, while the cost of obesity in Canada was estimated at CA$2 billion in 1997 (2.4% of total health costs). The total annual direct cost of overweight and obesity in Australia in 2005 was A$21 billion. Overweight and obese Australians also received A$35.6 billion in government subsidies. The estimate range for annual expenditures on diet products is $40 billion to $100 billion in the US alone.
Obesity prevention programs have been found to reduce the cost of treating obesity-related disease. However, the longer people live, the more medical costs they incur. Researchers therefore conclude that reducing obesity may improve the public's health, but it is unlikely to reduce overall health spending.
Obesity can lead to social stigmatization and disadvantages in employment. When compared to their normal weight counterparts, obese workers on average have higher rates of absenteeism from work and take more disability leave, thus increasing costs for employers and decreasing productivity. A study examining Duke University employees found that people with a BMI over 40 kg/m2 filed twice as many workers' compensation claims as those whose BMI was 18.5–24.9 kg/m2. They also had more than 12 times as many lost work days. The most common injuries in this group were due to falls and lifting, thus affecting the lower extremities, wrists or hands, and backs. The Alabama State Employees' Insurance Board approved a controversial plan to charge obese workers $25 a month for health insurance that would otherwise be free unless they take steps to lose weight and improve their health. These measures started in January 2010 and apply to those state workers whose BMI exceeds 35 kg/m2 and who fail to make improvements in their health after one year.
Some research shows that obese people are less likely to be hired for a job and are less likely to be promoted. Obese people are also paid less than their non-obese counterparts for an equivalent job; obese women on average make 6% less and obese men make 3% less.
Specific industries, such as the airline, healthcare and food industries, have special concerns. Due to rising rates of obesity, airlines face higher fuel costs and pressures to increase seating width. In 2000, the extra weight of obese passengers cost airlines US$275 million. The healthcare industry has had to invest in special facilities for handling severely obese patients, including special lifting equipment and bariatric ambulances. Costs for restaurants are increased by litigation accusing them of causing obesity. In 2005 the US Congress discussed legislation to prevent civil lawsuits against the food industry in relation to obesity; however, it did not become law.
With the American Medical Association's 2013 classification of obesity as a chronic disease, it is thought that health insurance companies will more likely pay for obesity treatment, counseling and surgery, and the cost of research and development of fat treatment pills or gene therapy treatments should be more affordable if insurers help to subsidize their cost. The AMA classification is not legally binding, however, so health insurers still have the right to reject coverage for a treatment or procedure.
In 2014, The European Court of Justice ruled that morbid obesity is a disability. The Court argued that if an employee's obesity prevents him from "full and effective participation of that person in professional life on an equal basis with other workers", then it shall be considered a disability and that firing someone on such grounds is discriminatory.
Size acceptance.
The principal goal of the fat acceptance movement is to decrease discrimination against people who are overweight and obese. However, some in the movement are also attempting to challenge the established relationship between obesity and negative health outcomes.
A number of organizations exist that promote the acceptance of obesity. They have increased in prominence in the latter half of the 20th century. The US-based National Association to Advance Fat Acceptance (NAAFA) was formed in 1969 and describes itself as a civil rights organization dedicated to ending size discrimination.
The International Size Acceptance Association (ISAA) is a non-governmental organization (NGO) which was founded in 1997. It has more of a global orientation and describes its mission as promoting size acceptance and helping to end weight-based discrimination. These groups often argue for the recognition of obesity as a disability under the US Americans With Disabilities Act (ADA). The American legal system, however, has decided that the potential public health costs exceed the benefits of extending this anti-discrimination law to cover obesity.
Childhood obesity.
The healthy BMI range varies with the age and sex of the child. Obesity in children and adolescents is defined as a BMI greater than the 95th percentile. The reference data that these percentiles are based on is from 1963 to 1994 and thus has not been affected by the recent increases in rates of obesity. Childhood obesity has reached epidemic proportions in the 21st century, with rising rates in both the developed and developing world. Rates of obesity in Canadian boys have increased from 11% in the 1980s to over 30% in the 1990s, while during this same time period rates increased from 4 to 14% in Brazilian children.
As with obesity in adults, many factors contribute to the rising rates of childhood obesity. Changing diet and decreasing physical activity are believed to be the two most important causes for the recent increase in the incidence of child obesity. Because childhood obesity often persists into adulthood and is associated with numerous chronic illnesses, children who are obese are often tested for hypertension, diabetes, hyperlipidemia, and fatty liver. Treatments used in children are primarily lifestyle interventions and behavioral techniques, although efforts to increase activity in children have had little success. In the United States, medications are not FDA approved for use in this age group.
Other animals.
Obesity in pets is common in many countries. In the United States, 23–41% of dogs are overweight, and about 5.1% are obese. The rate of obesity in cats was slightly higher at 6.4%. In Australia the rate of obesity among dogs in a veterinary setting has been found to be 7.6%. The risk of obesity in dogs is related to whether or not their owners are obese; however, there is no similar correlation between cats and their owners.
Notes.
</dl>
Further reading.
</dl>

</doc>
<doc id="56437" url="http://en.wikipedia.org/wiki?curid=56437" title="Infrared astronomy">
Infrared astronomy

Infrared astronomy is the branch of astronomy and astrophysics that studies astronomical objects visible in infrared (IR) radiation. The wavelength of infrared light ranges from 0.75 to 300 micrometers. Infrared falls in between visible radiation, which ranges from 380 to 750 nanometers, and submillimeter waves.
Infrared astronomy began in the 1830s, a few decades after the discovery of infrared light by William Herschel in 1800. Early progress was limited, and it was not until the early 20th century that conclusive detections of astronomical objects other than the Sun and Moon were detected in infrared light. After a number of discoveries were made in the 1950s and 1960s in radio astronomy, astronomers realized the information available outside of the visible wavelength range, and modern infrared astronomy was established.
Infrared and optical astronomy are often practiced using the same telescopes, as the same mirrors or lenses are usually effective over a wavelength range that includes both visible and infrared light. Both fields also use solid state detectors, though the specific type of solid state detectors used are different. Infrared light is absorbed at many wavelengths by water vapor in the Earth's atmosphere, so most infrared telescopes are at high elevations in dry places, above as much of the atmosphere as possible. There are also infrared observatories in space, including the Spitzer Space Telescope and the Herschel Space Observatory.
History.
The discovery of infrared radiation is attributed to William Herschel, who performed an experiment where he placed a thermometer in sunlight of different colors after it passed through a prism. He noticed that the temperature increase induced by sunlight was highest "outside" the visible spectrum, just beyond the red color. That the temperature increase was highest at infrared wavelengths was due to the spectral index of the prism rather than properties of the Sun, but the fact that there was any temperature increase at all prompted Herschel to deduce that there was invisible radiation from the Sun. He dubbed this radiation "calorific rays", and went on to show that it could be reflected, transmitted, and absorbed just like visible light.
Efforts were made starting in the 1830s and continuing through the 19th century to detect infrared radiation from other astronomical sources. Radiation from the Moon was first detected in 1873 by William Parsons, 3rd Earl of Rosse. Ernest Fox Nichols used a modified Crookes radiometer in an attempt to detect infrared radiation from Arcturus and Vega, but Nichols deemed the results inconclusive. Even so, the ratio of flux he reported for the two stars is consistent with the modern value, so George Rieke gives Nichols credit for the first detection of a star other than our own in the infrared.
The field of infrared astronomy continued to develop slowly in the early 20th century, as Seth Barnes Nicholson and Edison Pettit developed thermopile detectors capable of accurate infrared photometry and sensitive to a few hundreds of stars. The field was mostly neglected by traditional astronomers though until the 1960s, with most scientists who practiced infrared astronomy having actually been trained physicists. The success of radio astronomy during the 1950s and 1960s, combined with the improvement of infrared detector technology, prompted more astronomers to take notice, and infrared astronomy became well established as a subfield of astronomy.
Modern infrared astronomy.
Infrared radiation with wavelengths just longer than visible light, known as near-infrared, behaves in a very similar way to visible light, and can be detected using similar solid state devices. For this reason, the near infrared region of the spectrum is commonly incorporated as part of the "optical" spectrum, along with the near ultraviolet. Many optical telescopes, such as those at Keck Observatory, operate effectively in the near infrared as well as at visible wavelengths. The far-infrared extends to submillimeter wavelengths, which are observed by telescopes such as the James Clerk Maxwell Telescope at Mauna Kea Observatory.
Like all other forms of electromagnetic radiation, infrared is utilized by astronomers to study the universe. Indeed, infrared measurements taken by the 2MASS and WISE astronomical surveys have been particularly effective at unveiling previously undiscovered star clusters. Infrared telescopes, which includes most major optical telescopes as well as a few dedicated infrared telescopes, need to be chilled with liquid nitrogen and shielded from warm objects. The reason for this is that objects with temperatures of a few hundred Kelvin emit most of their thermal energy at infrared wavelengths. If infrared detectors were not kept cooled, the radiation from the detector itself would contribute noise that would dwarf the radiation from any celestial source. This is particularly important in the mid-infrared and far-infrared regions of the spectrum.
To achieve higher angular resolution, some infrared telescopes are combined to form astronomical interferometers. The effective resolution of an interferometer is set by the distance between the telescopes, rather than the size of the individual telescopes. When used together with adaptive optics, infrared interferometers, such as two 10 meter telescopes at Keck Observatory or the four 8.2 meter telescopes that make up the Very Large Telescope Interferometer, can achieve high angular resolution.
The principal limitation on infrared sensitivity from ground-based telescopes is the Earth's atmosphere. Water vapor absorbs a significant amount of infrared radiation, and the atmosphere itself emits at infrared wavelengths. For this reason, most infrared telescopes are built in very dry places at high altitude, so that they are above most of the water vapor in the atmosphere. Suitable locations on Earth include Mauna Kea Observatory at 4205 meters above sea level, the Paranal Observatory at 2635 meters in Chile and regions of high altitude ice-desert such as Dome C in Antarctic. Even at high altitudes, the transparency of the Earth's atmosphere is limited except in infrared windows, or wavelengths where the Earth's atmosphere is transparent. The main infrared windows are listed below:
As is the case for visible light telescopes, space is the ideal place for infrared telescopes. In space, images from infrared telescopes can achieve higher resolution, as they do not suffer from blurring caused by the Earth's atmosphere, and are also free from absorption caused by the Earth's atmosphere. Current infrared telescopes in space include the Herschel Space Observatory, the Spitzer Space Telescope, and the Wide-field Infrared Survey Explorer. Since putting telescopes in orbit is expensive, there are also airborne observatories, such as the Stratospheric Observatory for Infrared Astronomy and the Kuiper Airborne Observatory. These observatories place telescopes above most, but not all, of the atmosphere, which means there is absorption of infrared light from space by water vapor in the atmosphere.
Infrared technology.
One of the most common infrared detector arrays used at research telescopes is HgCdTe arrays. These operate well between 0.6 and 5 micrometre wavelengths. For longer wavelength observations or higher sensitivity other detectors may be used, including other narrow gap semiconductor detectors, low temperature bolometer arrays or photon-counting Superconducting Tunnel Junction arrays.
Special requirements for infrared astronomy include: very low dark currents to allow long integration times, associated low noise readout circuits and sometimes very high pixel counts.
Low temperature is often achieved by a coolant, which can run out. Space missions have either ended or shifted to "warm" observations when the coolant supply used up. For example, WISE ran out of coolant in October 2010,about ten months after being launched. (See also NICMOS, Spitzer Space Telescope)

</doc>
<doc id="56438" url="http://en.wikipedia.org/wiki?curid=56438" title="Akhnaten (opera)">
Akhnaten (opera)

Akhnaten is an opera in three acts based on the life and religious convictions of the pharaoh Akhenaten (Amenhotep IV), written by the American minimalist composer Philip Glass in 1983. Akhnaten had its world premiere on March 24, 1984 at the Stuttgart State Opera, under the German title "Echnaton". Paul Esswood sang the title role, German director Achim Freyer staged the opera in an abstract style with highly ritualistic movements. The American premiere was held on October 12, 1984 at the Houston Grand Opera, where Glass's opera "The Making of the Representative for Planet 8" also premiered.
According to the composer, this work is the culmination of his two other biographical operas, "Einstein on the Beach" (about Albert Einstein) and "Satyagraha" (about Mohandas Gandhi). These three people — Akhenaten, Einstein and Gandhi — were all driven by an inner vision which altered the age in which they lived, in particular Akhenaten in religion, Einstein in science, and Gandhi in politics.
The text, taken from original sources, is sung in the original languages, linked together with the commentary of a narrator in a modern language, such as English or German. Egyptian texts of the period are taken from a poem of Akhenaten himself, from the "Egyptian Book of the Dead", and from extracts of decrees and letters from the Amarna period, the seventeen-year period of Akhenaten's rule. Other portions are in Akkadian and Biblical Hebrew. Akhnaten's "Hymn to the Sun" is sung in the language of the audience.
Roles.
Small male chorus (Priests), Large opera chorus (The people of Egypt)
Music.
The orchestra's size is about the size employed for early 19th-century opera: 2 flutes (one doubling piccolo), 2 oboes (both doubling oboe d'amore), 2 clarinets, bass clarinet, 2 bassoons, 2 french horns, 2 trumpets, 2 trombones, tuba, percussion (3 players), celesta (doubling synthesizer), 12 violas, 8 celli, 6 double basses.
Since the Stuttgart State Opera house was being restored in 1984 and the orchestra pit of the Stuttgart State theater, where the premiere was to take place, was considerably smaller, Glass chose to completely leave out the violins (about 20), giving the orchestra a darker, sombre character, which fits the subject. Apart from this, this was Glass's most "conventional" opera orchestra until then (compared to "Einstein on the Beach", written for the six-piece Philip Glass Ensemble, and "Satyagraha", scored for woodwinds and strings only).
Generally speaking, for the unprepared listener the music of this opera is more accessible than that of its predecessors, the "hardcore" minimalist "Einstein" and the oratorio-like "Satyagraha". The music follows and underlines the dramatic context outlined by the story, and the harmonic and melodic language is more varied and changes more often, giving the music a more theatrical and almost "romantic" quality.
Synopsis.
The opera is divided into three acts:
Act 1: Year 1 of Akhnaten's Reign in Thebes.
"Prelude, Verse 1, Verse 2, Verse 3"
Set in the key of A minor, the strings introduce a ground bass theme, with following variations. (A passacaglia). The scribe recites funeral texts from the pyramids. 'Open are the double doors of the horizon; unlocked are its bolts.' 
"Scene 1: Funeral of Akhnaten's father Amenhotep III"
Heralded by hammering drums, Aye and a small male chorus chant a funeral hymn in Egyptian, later joined by the full chorus. The music is basically a march, based on the chords of A major and F♯ minor (with added major sixth), and grows to ecstatic intensity towards the end.
"Scene 2: The Coronation of Akhnaten"
After a lengthy orchestral introduction, during which Akhnaten appears, heralded by a solo trumpet, the High Priest, Aye, and Horemhab sing a ritual text. After that, the Narrator recites a list of royal titles bestowed upon Akhnaten, while he is crowned. After the coronation, the chorus repeats the ritual text from the beginning of the scene. Again, the main key is A minor. 
"Scene 3: The Window of Appearances"
After an introduction in A minor, dominated by tubular bells, Akhnaten sings a praise to the Creator (in Egyptian) at the window of public appearances. This is the first time he actually sings, after he has already been on stage for 20 minutes (and 40 minutes into the opera) and the effect of his countertenor voice (which in 1983 was even more rare than nowadays) is startling. He is joined by Nefertiti, who actually sings lower notes than he, and later by Queen Tye, whose soprano soars high above the intertwining voices of the royal couple.
Act 2: Years 5 to 15 in Thebes and Akhetaten.
"Scene 1: The Temple"
The scene opens again in A minor, with the High Priest and a group of priests singing a hymn to Amun, principal god of the old order, in his temple. The music becomes increasingly dramatic, as Akhnaten, together with Queen Tye and his followers, attack the temple. This scene has only wordless singing. The harmonies grow very chromatic, finally reaching A flat major and E minor. The temple roof is removed and the sun god Aten's rays invade the temple, thus ending Amun's reign and laying the foundation for the worship of the only god Aten.
"Scene 2: Akhnaten and Nefertiti"
Two solo celli introduce a "love theme". Accompanied by a solo trombone while the harmony switches to H(sus), the Narrator recites a prayer-like poem to the sun god. The strings softly take over the music in E minor, and the same poem is recited again, this time actually as a love poem from Akhnaten to Nefertiti. Then Akhnaten and Nefertiti sing the same text to each other (in Egyptian), as an intimate love duet. After a while, the trumpet associated with Akhnaten joins them as the highest voice, turning the duet into a trio.
"Scene 3: The City - Dance"
The Narrator speaks a text taken from the boundary stones of the new capital of the empire, Akhet-Aten (The Horizon of Aten), describing the construction of the city, with large, light-filled spaces. After a brass fanfare, the completion of the city is celebrated in a light-hearted dance, contrasting with the stark, ritualistic music with which this act began. (In the Stuttgart premiere, the dance actually described the construction of the city)
"Scene 4: Hymn"
What now follows is a hymn to the only god Aten, a long aria (alternating between A minor and A major) by Akhnaten, and the central piece of the opera. It is outstanding as it is the only text sung in the language of the audience, praising the sun giving life to everything. After the aria, an off-stage chorus sings Psalm 104 in Hebrew, dating some 400 years later, which has strong resemblances to Akhnaten's Hymn, thus emphasizing Akhnaten as the first founder of a monotheistic religion.
Act 3: Year 17 and the Present.
"Scene 1: The Family"
Two Oboe d'amore play the "love theme" from Act II. We see Akhnaten, with Nefertiti and their six daughters, singing wordlessly in contemplation. It is obvious that they are oblivious of what happens outside of the palace. As the music switches from E minor to F minor, the Narrator reads letters from Syrian vassals, asking for help against their enemies. Since the king does not send troops, his land is being seized and plundered by their enemies. The scene focuses again on Akhnaten and his family, still oblivious of the country falling apart.
"Scene 2: The Attack and Fall of the City"
The music moves again to a vigorous F minor. Horemhab, Aye and the High Priest of Aten instigate the people (as the chorus), singing part of the aforementioned letters (in their original Akkadian language) until finally the palace is attacked, the royal family killed, and the city of the sun destroyed. 
"Scene 3: The Ruins"
The music of the very beginning of the opera returns. The scribe recites an inscription on Aye's tomb, praising the death of "the heretic" and the new reign of the old gods. He then describes the restoration of Amun's temple by Akhnaten's son Tutenkhamun. The Prelude music grows stronger and the scene is moved to present-day Egypt, to the ruins of Amarna, the former capital Akhet-Aton. The Narrator appears as a modern tourist guide and speaks a text from a guide book, describing the ruins. "There is nothing left of this glorious city of temples and palaces".
"Scene 4: Epilogue"
The ghosts of Akhnaten, Nefertiti and Queen Tye appear, singing wordlessly amongst the ruins. The funeral procession from the beginning of the opera appears on the horizon, and they join it. The music introduces a bass line from the beginning of "Einstein on the Beach", which is the first part of Glass' "portrait" trilogy (The second one being "Satyagraha" and the third one "Akhnaten"), thus providing a musical bracket for the whole trilogy.

</doc>
<doc id="56439" url="http://en.wikipedia.org/wiki?curid=56439" title="Jeff Bridges">
Jeff Bridges

Jeffrey Leon "Jeff" Bridges (born December 4, 1949) is an American actor, singer, and producer. He comes from a well-known acting family and began his televised acting in 1958 as a child with his father, Lloyd Bridges, and brother, Beau, on television's "Sea Hunt". He won the Academy Award for Best Actor for his role as Otis "Bad" Blake in the 2009 film "Crazy Heart" and earned Academy Award nominations for his roles in "The Last Picture Show", "Thunderbolt and Lightfoot", "Starman", "The Contender", and "True Grit". Among his other better-known major motion films are: "The Big Lebowski", "Fearless", "Iron Man", "The Fabulous Baker Boys", "Jagged Edge", "Against All Odds", "The Fisher King", ', "Seabiscuit", "Arlington Road", "Tron", ' and "The Giver".
Early life.
Jeffrey Leon Bridges was born on December 4, 1949 in Los Angeles, California. He is the son of showbiz parents, actor Lloyd Bridges (1913–1998) and actress and writer Dorothy Bridges (née Simpson; 1915–2009). His older brother, Beau Bridges, is also an actor. He has a younger sister, Lucinda, and had another brother, Garrett, who died of sudden infant death syndrome in 1948. His maternal grandfather was an English immigrant from Liverpool.
Bridges and his siblings were raised in the Holmby Hills section of Los Angeles. Growing up, Bridges shared a close relationship with his brother Beau, who acted as a surrogate father when their father was working. He graduated from University High School in 1967. At age 17, Jeff toured with his father in a stage production of "Anniversary Waltz". After graduating from high school, Bridges moved to New York City, where he studied acting at the Herbert Berghof Studio. Also, after turning 18, Bridges joined the United States Coast Guard Reserve, where he served for seven years.
Career.
Film.
Bridges made his first screen appearances at the age of almost two years in "The Company She Keeps" in 1951. In his youth, Bridges and brother Beau made occasional appearances on their father's show "Sea Hunt" (1958–1961) and the CBS anthology series, "The Lloyd Bridges Show" (1962–1963). In 1971 he played the lead role Mike in the TV movie "In Search of America". His first major role came in the 1971 film "The Last Picture Show", for which he garnered a nomination for the Academy Award for Best Supporting Actor. He co-starred in the 1972 critically acclaimed neo-noir boxing film "Fat City", directed by John Huston. He was nominated again for Best Supporting Actor for his performance opposite Clint Eastwood in the 1974 film "Thunderbolt and Lightfoot". In 1976, he starred as the protagonist Jack Prescott in the first remake of "King Kong", opposite Jessica Lange. This film was a commercial success, earning $90 million worldwide, more than triple its $23 million budget, and also winning an Academy Award for special effects.
One of his better known roles was in the 1982 science fiction cult classic "Tron", in which he played Kevin Flynn, a video game programmer (a role he reprised in late 2010 with the sequel ""). The same year (1982) he also starred in "Kiss Me Goodbye", an American romantic comedy film directed by Robert Mulligan that also starred Sally Field. He was nominated for the Academy Award for Best Actor in 1984, for playing the alien in "Starman". He was also acclaimed for his roles in the thriller "Against All Odds" (1984) and the crime drama "Jagged Edge" (1985). His role in "Fearless" (1993) is thought by some critics to be one of his best performances. One critic dubbed it a masterpiece; Pauline Kael wrote that he "may be the most natural and least self-conscious screen actor that has ever lived." In 1998, he starred as what is arguably his most famous role, The Dude, in the Coen brothers' cult-classic film "The Big Lebowski". He has said that he relates to The Dude more than any of his other roles.
In 2000, he received his fourth Academy Award nomination, for his role in "The Contender". He also starred in the 2005 Terry Gilliam film "Tideland", his second with the director (the first being 1991's "The Fisher King"). He shaved his trademark mane of hair to play the role of Obadiah Stane in the 2008 Marvel comic book adaptation "Iron Man". In July 2008, at the San Diego Comic-Con International, he appeared in a teaser for "", shot as concept footage for director Joseph Kosinski; this developed into a full 3D feature release in 2010.
Bridges is one of the youngest actors ever to be nominated for an Academy Award (1972, age 22, Best Supporting Actor, "The Last Picture Show"), and one of the oldest ever to win (2010, age 60, Best Actor, "Crazy Heart"). "Crazy Heart" also won him the Golden Globe for Best Actor in a Drama, and the Screen Actors Guild Award for Outstanding Performance by a Male Actor in a Leading Role.
Bridges received his sixth Academy Award nomination for his role in "True Grit", a collaboration with the Coen brothers in which he starred alongside Matt Damon, Josh Brolin, Barry Pepper, and Hailee Steinfeld. Both the film, and Bridges's performance as Rooster Cogburn, were critically praised. Bridges lost to Colin Firth, whom he had beaten for the Oscar in the same category the previous year.
Music.
Referring to his career as an actor and his passion for music, Bridges says, "I dug what an actor did, but it took me a while to feel it, to truly appreciate the craft and the preparation. Plus, I was still playing music a lot, and I guess I had a hard time choosing: was I an actor or a musician, or could I be both?"
Bridges studied piano at a young age, strongly encouraged by his mother. While working on the 1980 film "Heaven's Gate", he often played guitar with his costar, singer/songwriter Kris Kristofferson, between takes. His character in "Crazy Heart", Bad Blake, was later based partly on Kristofferson. He released his debut album "Be Here Soon" on January 1, 2000. In 2005, Bridges, known as "The Dude" in the film "The Big Lebowski", showed up at a Lebowski Fest in Los Angeles singing and playing the film's theme song written by Bob Dylan, "Man in Me".
On January 15, 2010, Bridges performed the song "I Don't Know" from "Crazy Heart" on "The Tonight Show with Conan O'Brien". In the film "The Contender", in which he co-starred, Bridges recorded a version of Johnny Cash's standard "Ring of Fire" with Kim Carnes that played over the pivotal opening credits. In February 2010, he was among the nearly 80 musicians to sing on the charity-single remake of "We Are the World". On October 24, 2010, Bridges appeared at Neil Young's annual "Bridge School Benefit" concert and played a set with singer-songwriter Neko Case.
On April 19, 2011, Country Music Television announced that Bridges had signed a recording contract with Blue Note Records/EMI Music Group. He worked with producer T-Bone Burnett and released his second album, "Jeff Bridges," on August 16, 2011. On November 5, 2011, Bridges played Austin City Limits in support of this album.
In 2015, Jeff Bridges released an ambient/spoken-word album entitled "Sleeping Tapes". All proceeds from the album go directly to Bridges' charity .
Bridges plays many guitars, including the Gretsch Chet Atkins Country Gentlemen Model G6122-1959.
Other work.
Author.
In 2013, Bridges authored "The Dude and the Zen Master" with Bernie Glassman. Bridges found himself at a party with Glassman and Ram Dass and their conversation led to discussing the parallels between "The Dude" from "The Big Lebowski" and Zen Buddhism. The book was formed from what has been described as a "transcript of a five-day “hang” on a Montana ranch." 
Photography.
Bridges has been an amateur photographer since high school, and began taking photographs on film sets during "Starman", at the suggestion of co-star Karen Allen. Since 1980, he began photographing on and off set shot with his favorite camera, a Widelux F8. He published many of these photographs online and published a book in 2003 entitled, "Pictures: Photographs by Jeff Bridges".
Narrator.
Bridges narrated the documentary "Lost in La Mancha" (2002), about the making of a Terry Gilliam retelling of "Don Quixote", tentatively titled "The Man Who Killed Don Quixote", which would have starred Johnny Depp as Sancho Panza and Jean Rochefort as the quixotic hero. Bridges had previously appeared in Gilliam's "The Fisher King". Bridges also narrated the documentaries National Geographic's "Lewis & Clark: Great Journey West" (2002, IMAX), Discovery Channel's "Raising the Mammoth" (2000), and ABC's "Heroes of Rock and Roll" (1979). He also voiced the character Big Z in the animated picture "Surf's Up".
Bridges has performed TV commercial voiceover work as well, including Hyundai's 2007 "Think About It" advertising campaign as well as the Duracell advertisements in the "Trusted Everywhere" campaign.
On December 18, 2010, Bridges hosted NBC's "Saturday Night Live"; he had hosted the show before in 1983 with his brother, Beau. With the December 18, 2010 episode, Bridges beat Sigourney Weaver's record for longest gap between hosting appearances on "SNL" (Weaver had a 24-year gap between her first time hosting in 1986 and her second time hosting in 2010, while Bridges had a 27-year gap between his first appearance in 1983 and his most recent one, also in 2010).
Personal life.
Bridges married Susan Geston in 1977. They met on the film shoot of "Rancho Deluxe", which was filmed on a ranch where Geston was working as a maid. They have three daughters: Isabelle Annie (born August 6, 1981), Jessica Lily "Jessie" (born June 14, 1983), and Hayley Roselouise (born October 17, 1985). Bridges became a grandfather on March 31, 2011, when Isabelle gave birth to a daughter, Grace.
Bridges has studied Buddhism. He meditates for half an hour before beginning work on a film set. He has learned Transcendental Meditation.
Humanitarian efforts.
In 1984, Bridges and other entertainment industry leaders founded the End Hunger Network aimed at encouraging, stimulating and supporting action to end childhood hunger. He supports President Obama's initiative to End Childhood Hunger by 2015. In November 2010, Bridges became spokesman for the No Kid Hungry campaign of the organization Share our Strength. Its goal is to present and undertake a state-by-state strategy to end childhood hunger in the United States by 2015. Bridges also supports environmental causes and organizations such as the Amazon Conservation Team.

</doc>
<doc id="56440" url="http://en.wikipedia.org/wiki?curid=56440" title="Orbital inclination">
Orbital inclination

Orbital inclination is the angle between a reference plane and the orbital plane or axis of direction of an object in orbit around another object.
Orbits.
The inclination is one of the six orbital parameters describing the shape and orientation of a celestial orbit. It is the angular distance of the orbital plane from the plane of reference (usually the primary's equator or the ecliptic), normally stated in degrees.
In the Solar System, the inclination of the orbit of a planet is defined as the angle between the plane of the orbit of the planet and the ecliptic. Therefore Earth's inclination is, by definition, zero. Inclination could instead be measured with respect to another plane, such as the Sun's equator or even Jupiter's orbital plane, but the ecliptic is more practical for Earth-bound observers. Most planetary orbits in the Solar System have relatively small inclinations, both in relation to each other and to the Sun's equator. On the other hand, the dwarf planets Pluto and Eris have inclinations to the ecliptic of 17 degrees and 44 degrees respectively, and the large asteroid Pallas is inclined at 34 degrees.
Natural and artificial satellites.
The inclination of orbits of natural or artificial satellites is measured relative to the equatorial plane of the body they orbit if they do so close enough. The equatorial plane is the plane perpendicular to the axis of rotation of the central body.
For impact-generated moons of terrestrial planets not too far from their star, with a large planet–moon distance, it is expected that the orbital planes of moons will tend to be aligned with the planet's orbit around the star due to tides from the star, but if the planet–moon distance is small it may be inclined. For gas giants, the orbits of moons will tend to be aligned with the giant planet's equator because these formed in circumplanetary disks.
The term "critical inclination" is often used when describing artificial satellites in orbit around Earth. This term refers to a satellite orbiting with an inclination of 63.4°. This inclination is described as critical as there is zero apogee drift for satellites in elliptical orbits at this inclination.
Exoplanets and multiple star systems.
The inclination of exoplanets or members of multiple stars is the angle of the plane of the orbit relative to the plane perpendicular to the line-of-sight from Earth to the object.
Since the word 'inclination' is used in exoplanet studies for this line-of-sight inclination then the angle between the planet's orbit and the star's rotation must use a different word and is termed the spin-orbit angle or spin-orbit alignment. In most cases the orientation of the star's rotational axis is unknown.
Because the radial-velocity method more easily finds planets with orbits closer to edge-on, most exoplanets found by this method have inclinations between 45° and 135°, although in most cases the inclination is not known. Consequently, most exoplanets found by radial velocity have true masses no more than 70% greater than their minimum masses. If the orbit is almost face-on, especially for superjovians detected by radial velocity, then those objects may actually be brown dwarfs or even red dwarfs. One particular example is HD 33636 B, which has true mass 142 MJ, corresponding to an M6V star, while its minimum mass was 9.28 MJ.
If the orbit is almost edge-on, then the planet can be seen transiting its star.
Calculation.
In astrodynamics, the inclination formula_1 can be computed from the orbital momentum vector formula_2 (or any vector perpendicular to the orbital plane) as formula_3, where formula_4 is the z-component of formula_5.
Mutual inclination of two orbits may be calculated from their inclinations to another plane using cosine rule for angles.

</doc>
<doc id="56442" url="http://en.wikipedia.org/wiki?curid=56442" title="A Dictionary of Modern English Usage">
A Dictionary of Modern English Usage

A Dictionary of Modern English Usage (1926), by Henry Watson Fowler (1858–1933), is a style guide to British English usage, pronunciation, and writing. Covering topics including plurals and literary technique, distinctions among like words (such as homonyms and synonyms), and the use of foreign terms, it became the standard for most style guides that followed; thus, the 1926 first edition remains in print despite the existence of the 1965 second edition, and the 1996 and 2004 printings of the third edition, which was mostly rewritten as a usage dictionary incorporating corpus linguistics data; the 2015 fourth edition follows similar principles to the third. "A Dictionary of Modern English Usage" is informally known as Fowler’s Modern English Usage, Fowler, and Fowler’s.
Linguistic approach.
In "A Dictionary of Modern English Usage", Henry W. Fowler’s general approach encourages a direct, vigorous writing style, and opposes all artificiality, by firmly advising against convoluted sentence construction, the use of foreign words and phrases, and the use of archaisms. He opposed pedantry, and ridiculed artificial grammar rules unwarranted by natural English usage, such as bans on split infinitives and on ending a sentence with a preposition; rules on the placement of the word "only"; and rules distinguishing between "which" and "that". He classified and condemned every cliché, in the course of which he coined and popularised the terms "battered ornament", "Wardour Street", "vogue words", and "worn-out humour", while defending useful distinctions between words whose meanings were coalescing in practice, thereby guiding the speaker and the writer away from illogical sentence construction, and the misuse of words. In the entries "Pedantic Humour" and "Polysyllabic Humour" Fowler mocked the use of arcane words (archaisms) and the use of long words.
Quotations.
Widely and often cited, "A Dictionary of Modern English Usage" is renowned for its witty passages, such as:
Editions.
Before writing "A Dictionary of Modern English Usage", Henry Fowler and his younger brother, Francis George Fowler (1871–1918), wrote and revised "The King's English" (1906), a grammar and usage guide later superseded by this book in the 1930s. Moreover, he researched the "Dictionary" assisted by Francis, who died in 1918 of tuberculosis, which he contracted in service with the British Expeditionary Force in the First World War (1914–1918). Fowler thus dedicated the "Dictionary" to his brother, Francis George:
I think of it as it should have been, with its prolixities docked, its dullnesses enlivened, its fads eliminated, its truths multiplied . . . having been designed in consultation with him, it is the last fruit of a partnership that began in 1903 with our translation of Lucian.
The first edition of "A Dictionary of Modern English Usage" (1926) was much reprinted; thus, a reprint wherein the copyright page indicates 1954, as the most recent reprinting year, also notes that the 1930 and 1937 reprintings were "with corrections". The second edition, "Fowler’s Modern English Usage" (1965) was revised by Sir Ernest Gowers, who updated the text, contributed entries, and deleted articles "no longer relevant to [current] literary fashions". For the twenty-first century, the third edition, "The New Fowler’s Modern English Usage " (1996), was revised and published as "Fowler’s Modern English Usage" (2004), the editor of which, Robert Burchfield, in the preface acknowledges that, while "Fowler’s name remains on the title-page . . . his book has been largely rewritten." A fourth edition, edited by Jeremy Butterfield, was published by Oxford University Press in 2015. The substantive and editorial differences between the first and third editions are that the former is a prescriptive style guide to clear and expressive writing, while the latter is a descriptive usage guide to spoken and written English. The 2009 reprinting of the 1926 first edition contains an introduction and commentary by the linguist David Crystal. The "Pocket Fowler's Modern English Usage" edited by Robert Allen was published by OUP in 1999. It was based mainly on Burchfield's 1996 edition, abridged to 40% by omitting about half the entries and reducing others; there was also some new content. A second edition of Allen's "Pocket Fowler" was published in 2008, which OUP said "harks back to the original 1926 edition".

</doc>
<doc id="56443" url="http://en.wikipedia.org/wiki?curid=56443" title="Fowler">
Fowler

Fowler can refer to:

</doc>
<doc id="56444" url="http://en.wikipedia.org/wiki?curid=56444" title="Jeans">
Jeans

Jeans are trousers typically made from denim or dungaree cloth. Often the term "jeans" refers to a particular style of pants, called "blue jeans," which were invented by Jacob Davis in 1871 and patented by Davis and Levi Strauss on May 20, 1873. Starting in the 1950s, jeans, originally designed for cowboys and miners, became popular among teenagers, especially members of the greaser subculture. Historic brands include Levi's, Lee, and Wrangler. Jeans come in various fits, including skinny, tapered, slim, straight, boot cut, narrow bottom, low waist, anti-fit, and flare. Owing to their high durability as compared to other common fabrics, "distressed" (visibly aged and worn, but still intact and functional) jean trousers have become increasingly fashionable, making pre-sale "factory distressing" a common feature in commercially-sold jeans.
Jeans are now a very popular article of casual dress around the world. They come in many styles and colors. However, blue jeans are particularly identified with US culture, especially the United States Old West.
History.
Jean fabric.
Research on the trade of jean fabric shows that it emerged in the cities of Genoa, Italy, and Nimes, France. Gênes, the French word for Genoa, may be the origin of the word "jeans". In Nimes, weavers tried to reproduce jean but instead developed a similar twill fabric that became known as denim, from "de Nimes", meaning "from Nimes". Genoa’s jean was a fustian textile of “medium quality and of reasonable cost”, very similar to cotton corduroy for which Genoa was famous, and was "used for work clothes in general". Nimes’s “denim” was coarser, considered higher quality and was used "for over garments such as smocks or overalls". Nearly all Indigo, needed for dying, came from indigo bush plantations in India till the late 19th century. It was replaced by indigo synthesis method developed in Germany.
By the 17th century, jean was a crucial textile for working-class people in Northern Italy. This is seen in a series of genre paintings from around the 17th century attributed to an artist now named The Master of the Blue Jeans. The ten paintings depict impoverished scenes with lower-class figures wearing a fabric that looks like denim. The fabric would have been Genoese jean, which was cheaper. Genre painting came to prominence in late 16th century, and the low-life subject matter in all ten paintings places them among others that portray similar scenes. 
Denim is not the only sturdy cotton fabric used for everything from working clothes to fashion items. There is also dungaree.
Dungaree was mentioned for the first time in the 17th century, when it was referred to as cheap, coarse thick cotton cloth, often colored blue but sometimes white, worn by impoverished people in what was then a region of Bombay, India a dockside village called Dongri. The Hindi name of this cloth was "dungri". Dungri was exported to England and used for manufacturing of cheap, robust working clothes. English began to call "dungri" cloth a little different and it became "dungaree".
The importance of jean is also shown by the history of textile trade. Genoese sailors used jean to cover and protect their goods on the docks from the weather. During the Republic of Genoa (17th, 18th centuries), sailors exported jeans throughout Europe.
The invention of the zipper, by Whitcomb L. Judson, helped as well.
Jean became popular in the United States when Levi Strauss & Co.'s introduced blue jean overalls in 1873.
Riveted jeans.
Levi Strauss as a young man in 1851 emigrated from Germany to New York to join his older brothers who ran a dry goods store. In 1853, he moved to San Francisco to establish his own dry goods business. Jacob Davis was a tailor who often bought bolts of cloth from the Levi Strauss & Co. wholesale house. In 1872, Davis wrote to Strauss asking to partner with him to patent and sell clothing reinforced with rivet. The copper rivets were to reinforce the points of stress, such as pocket corners and at the bottom of the button fly. Levi accepted Davis's offer, and the two men received US patent No. 139,121 for an "Improvement in Fastening Pocket-Openings" on May 20,1873.
Davis and Strauss experimented with different fabrics. An early attempt was brown cotton duck, a bottom-weight fabric. Finding denim a more suitable material for work-pants, they began using it to manufacture their riveted pants. The denim used was produced by an American manufacturer, but popular legend states it was imported from Nimes, France. A popular myth is that Strauss initially sold brown canvas pants to miners, later dyed them blue, turned to using denim, and only after Davis wrote to him, added rivets.
Worldwide market for jeans.
North America accounts for 39% of global purchases for jeans, followed by Western Europe at 20%, Japan and Korea at 10% and the rest of the world at 31%.
United States citizens spent more than US$14 billion on jeans in 2004 and US$15 billion in 2005. US people bought US$13.8 billion of men's and women's jeans in the year which ended 30 April 2011, according to market-research firm NPD Group.
Evolution of the garment.
The term appears first in 1795, when a Swiss banker by the name Jean-Gabriel Eynard and his brother Jacques went to Genoa and both were soon heading a flourishing commercial concern. In 1800 Massena's troops entered the town and Jean-Gabriel was entrusted with their supply. In particular he furnished them with uniforms cut from blue cloth called "bleu de Genes" whence later derives the famous garment known worldwide as "blue jeans".
Initially, jeans were simply sturdy trousers worn by factory workers. During this period, men's jeans had the zipper down the front, whereas women's jeans had the zipper down the left side. Fewer jeans were made during World War II, but 'waist overalls' were introduced to the world by US soldiers, who sometimes wore them off duty. By the 1960s, both men's and women's jeans had the zipper down the front. Historic photographs indicate that in the decades before they became a staple of fashion, jeans generally fit quite loosely, much like a pair of bib overalls without the bib. Indeed, until 1960, Levi Strauss called its flagship product "waist overalls" rather than "jeans".
After James Dean popularized them in the movie "Rebel Without a Cause", wearing jeans became a symbol of youth rebellion during the 1950s. Because of this, they were sometimes banned in theaters, restaurants and schools.During the 1960s the wearing of jeans became more acceptable, and by the 1970s it had become general fashion in the United States for casual wear.
Michael Belluomo, editor of "Sportswear International Magazine", Oct/Nov 1987, P. 45, wrote that in 1965, Limbo, a boutique in the New York East Village, was "the first retailer to wash a new pair of jeans to get a used, worn effect, and the idea became a hit." He continued, "[Limbo] hired East Village artists to embellish the jeans with patches, decals, and other touches, and sold them for $200." In the early 1980s the denim industry introduced the stone-washing technique developed by GWG also known as "Great Western Garment Co." Donald Freeland of Edmonton, Alberta pioneered the method, which helped to bring denim to a larger and more versatile market. Acceptance of jeans continued through the 1980s and 1990s to the point where jeans are, in the first decade of 21st century, a wardrobe staple, with the average North American owning seven pairs. Currently, jeans may be seen worn by people of all genders and ages.
Manufacturing processes.
Dyeing.
Traditionally, jeans were dyed to a blue color using natural indigo dye. Most denim is now dyed using synthetic indigo. Approximately 20 thousand tons of indigo are produced annually for this purpose, though only a few grams of the dye are required for each pair. For other colors of denim other dyes must be used. Currently, jeans are produced in any color that can be achieved with cotton.
For more information on dyeing, refer to denim and the discussion there of using pigment dyes.
Pre-shrinking.
In 1963 Levi Strauss introduced pre-shrunk jeans, which did not shrink further after purchase, allowing the consumer to buy his or her correct size. These jeans were known as the 505 regular fit jeans. The 505 are almost identical to the 501s with the exception of the button-fly. The Levi's Corporation also introduced a slim boot-cut fit known as 517 and 527. The difference between the two is 517 sit at the waist line and the 527 sit below the waist line. Later, Levi's would develop other styles and fits such as the loose, slim, comfort, relaxed, skinny, and a regular fit with a tapered leg.
Used look.
The used or "acid wash" look is created by means of abrading the jeans and/or treating them with chemicals, such as acryl resin, phenol, a hypochlorite, potassium permanganate, caustic soda, acids etc.
Sandblasting or abrading with sandpaper.
Consumers wanting jeans that appear worn can buy jeans that have been specially treated. To give the fabrics the worn look, sandblasting done with chemicals or by adding pumice stone to the washing process or abrading with sandpaper is often done.
Environmental and humanitarian impact.
A typical pair of blue jeans consumes 919 gallons (3479 liters) of water during its life cycle. This includes the water to irrigate the cotton crop, manufacture the jeans, and the numerous washes by the consumer.
The production of jeans with a "used look" can be more environmentally damaging than regular jeans, depending on how the waste compounds are processed. Sandblasting and treating with sandpaper has the risk of causing silicosis to the workers, and in Turkey, more than 5,000 textile workers have been stricken with this disease, and 46 people are known to have died. Some companies have announced they are banning the use of sandblasting.
Care and wear.
Despite most jeans being “pre-shrunk”, they are still sensitive to slight further shrinkage and loss of color from being washed. The Levi Strauss company recommends avoiding washing jeans as much as possible. Carl Chiara, Levi Strauss director of brand and special projects, has a credo: The less you wash your jeans, the better your jeans become. These and other suggestions to avoid washing jeans where possible have encountered criticism. Cory Warren, editor of "LS&Co. Unzipped", clarifies in a response to such a criticism:
Our advice is to wash less often, but clearly, you have to judge for yourself what's appropriate. Hot day, dirty job? Wash your jeans. Please! Cold day, office job? Maybe you can wear them twice or more before they go back to the washing machine. Personally, if I wear a pair of jeans to work on Friday—cool climate, office job—I tend to wear them on Saturday. And if Saturday is spent indoors and I'm not spilling food all over myself, I might even wear them on Sunday.—Corey Warren
For those who prefer to refrain from washing their jeans there have been suggestions to freeze them in order to kill the germs that cause odor. However, this advice has been disputed as ineffective and replaced with the suggestion of baking them for ten minutes at 250 degrees Fahrenheit.
Jeans in the USSR.
Jeans were introduced to the USSR in 1957, during the World Festival of Youth and Students. Moscow and Leningrad (St. Petersburg) were the first cities where jeans showed up, appearing before any foreign students or tourists came along. (These two capitals have always been visited more often by foreign delegations.) According to a 1961 Russian textile dictionary, jeans were initially referred to as a "worker's uniform" (рабочий костюм, "rabochii kostyum").
In 1964, jeans appeared for the first time in port cities such as Odessa and Kaliningrad. In the same time frame, jeans started being mentioned in the works of Vasily Aksyonov and Yevgeny Yevtushenko. In 1962, during Khrushchev's famous meeting with some creative intellectuals, Voznesensky gained some notoriety because he came to the meeting in jeans.
The jeans brand Rokotov and Fainberg is named after the defendants in the Rokotov–Faibishenko case, who were executed for, among other things, trafficking in jeans.

</doc>
<doc id="56447" url="http://en.wikipedia.org/wiki?curid=56447" title="Theo Wade Brown">
Theo Wade Brown

Theo Wade Brown (26 May 1950 - 30 April 2002) British carpenter, designer and engineer.
Brown was also a bon viveur, amateur musician and genuine British eccentric. With his handlebar moustache and long red hair, he was an unmistakable figure.
Brown was a well-known member of the London film special effects community, and one of the core team at the Computer Film Company that won a Scientific and Technical Academy Award for developing digital film technology.
Brown later designed the Northlight film scanner for the Computer Film Company scanner division (now Filmlight), and was responsible not only for its remarkable engineering design, but also its 1920s-style marble and steel appearance—an artistic flourish that was characteristic of Brown's approach to life.
Brown suffered from bipolar disorder which led eventually to his death.
In 2010, he was posthumously awarded a Scientific and Technical Academy Award for his work at Filmlight on the Northlight scanner technology.

</doc>
<doc id="56452" url="http://en.wikipedia.org/wiki?curid=56452" title="Örnsköldsvik Municipality">
Örnsköldsvik Municipality

Örnsköldsvik Municipality ("Örnsköldsviks kommun") is one of Sweden's 290 municipalities, in Västernorrland County in northern Sweden. Its seat is in the town Örnsköldsvik. The present municipality was created in 1971 by the amalgamation of the "City of Örnsköldsvik" with seven former rural municipalities.
Geography.
Örnsköldsvik is situated near the northern end of the "High Coast", which is a UNESCO World Heritage Site and has the third longest suspension bridge in Europe, the Höga Kusten Bridge.
The city is located around 100 km south of Umeå and 550 km north of Stockholm. The area is dominated by forest, but it also contains minor areas of agriculture.
Population distribution (31 December 2005).
The municipality of Örnsköldsvik is built up from a number of parishes, within which are towns and villages. The population is distributed as follows:
Parish (town) number of citizens
Total: 54,943
Transportation.
Main road transportations are provided by the European route E4. The Örnsköldsvik Airport provides daily flights to and from the Stockholm-Arlanda Airport courtesy of Höga Kusten Flyg, and also charter flights to Turkey courtesy of Pegasus Airlines. Railway transportation will in the future be provided by high-speed railway Botniabanan, which is currently under construction. There is also a harbour, where cargo ships load and unload timber and other merchandise. In North America the town is known for its excellent hockey players, a number of whom play with the NHL.
Recreation and sports.
Due to the hilly surroundings, hiking and exploring the scenery of the High Coast is popular in the area. In the wintertime, skiing is popular. Both cross-country skiing, alpine skiing and even ski jumping is practiced almost in the downtown area. Since Örnsköldsvik is a coastal town, there are also beaches near town, as well as campsites. There's also an indoor water park called Paradisbadet, with one of the longest water slides in Europe.
Sports is also popular, the main spectator sport in town is ice hockey, with the local team Modo Hockey in Swedish Hockey League, the main league for ice hockey in Sweden. The local football teams are not quite as successful, but still pretty popular, on the men's side especially the teams Friska Viljor FC from central Örnsköldsvik and Anundsjö IF from Bredbyn outside of town, and women's Själevads IK. A couple floorball teams from town have also had some success.
Notable natives.
Örnsköldsvik is the birthplace of many world-famous ice hockey players, including Peter Forsberg, Markus Näslund, Niklas Sundström, and twins Daniel and Henrik Sedin. Samuel Påhlsson, also an ice hockey player, lived there for a long time but was born in Ånge. Many stars from hockey's previous generation, including Anders Hedberg, Thomas Gradin and Anders Kallur, were also either Örnsköldsvik natives (Hedberg) and/or played in the town for the Modo Hockey club.
Sister cities.
Örnsköldsvik's sister cities are:

</doc>
<doc id="56455" url="http://en.wikipedia.org/wiki?curid=56455" title="Antonio Stradivari">
Antonio Stradivari

Antonio Stradivari (]; 1644 – 18 December 1737) was an Italian luthier and a crafter of string instruments such as violins, cellos, guitars, violas, and harps. Stradivari is generally considered the most significant and greatest artisan in this field. The Latinized form of his surname, "Stradivarius", as well as the colloquial, "Strad", are often used to refer to his instruments. It is estimated that he made 1,000 to 1,100 instruments and that around 650 of these instruments survive, including 450 to 512 violins.
Biography.
Family background and early life.
Stradivari's ancestry consisted of notable citizens of Cremona, dating back to at least the 12th or 13th century. The earliest mention of the family name, or a variation upon it, is in a land grant dating from 1188. The origin of the name itself has several possible explanations; some sources say it is the plural of "Stradivare", essentially meaning "toll-man" in Lombard, while others say that the form "de Strataverta" derives from "Strada averta", which, in Cremonese dialect means "open road."
Antonio's parents were Alessandro Stradivari, son of Giulio Cesare Stradivari, and Anna Moroni, daughter of Leonardo Moroni. They married on 30 August 1622, and had at least three children between 1623 and 1628: Giuseppe Giulia Cesare, Carlo Felice, and Giovanni Battista. The baptismal records of the parish of S. Prospero then stop, and it is unknown whether they had any children from 1628 to 1644. This blank in the records may be due to the family leaving Cremona in response to war, famine, and plague in the city from 1628 to 1630, or the records may have been lost due to clerical reforms imposed by Joseph II of Austria in 1788. The latter explanation is supported by the word "Cremonensis" (of Cremona) on many of Stradivari's labels, which suggests that he was born in the city instead of merely moving back there to work. Antonio was born in 1644, a fact deducible from later violins. However, there are no records or information available on his early childhood, and the first evidence of his presence in Cremona is the label of his oldest surviving violin from 1666.
Stradivari likely began an apprenticeship with Nicolò Amati between the ages of 12 and 14, although a minor debate surrounds this fact. One of the few pieces of evidence supporting this is the label of his 1666 violin, which reads, "Alumnus Nicolai Amati, faciebat anno 1666". However, Stradivari did not repeatedly put Amati's name on his labels, unlike many of his other students. Stradivari's early violins actually bear less of a resemblance to those of Amati than his later instruments do. M. Chanot-Chardon, a well-known French luthier, asserted that his father had a label of Stradivari's stating, "Made at the age of thirteen, in the workshop of Nicolò Amati". This label has never been found or confirmed. Amati would also have been a logical choice for Antonio's parents, as he represented an old family of violin makers in Cremona, and was far superior to most other luthiers in Italy.
An alternative theory is that Stradivari started out as a woodworker: the house he lived in from 1667 to 1680 was owned by Francesco Pescaroli, a woodcarver and inlayer. Stradivari may even have been employed to decorate some of Amati's instruments, without being a true apprentice. This theory is supported by some of Stradivari's later violins, which have elaborate decorations and purfling.
Assuming that Stradivari was a student of Amati, he would have begun his apprenticeship in 1656–58 and produced his first decent instruments in 1660, at the age of 16. His first labels were printed from 1660 to 1665, which indicates that his work had sufficient quality to be offered directly to his patrons. However, he probably stayed in Amati's workshop until about 1684, using his master's reputation as a launching point for his career.
First marriage.
Stradivari married his first wife, Francesca Feraboschi, on 4 July 1667. Francesca was the young widow of the burgher Giacomo Capra, with whom she had two children, and who had been shot by Francesca's brother on the Piazza Garibaldi (formerly the Piazza Santa Agata). After their marriage, Stradivari moved into a house known as the Casa del Pescatore, or the Casa Nuziale, in his wife's parish. The couple had a daughter, Giulia Maria, three to four months later. They remained in this house until 1680, during which time they had four more children: Catterina, Francesco, Alessandro, and Omobono Stradivari, as well as an infant son who lived for only a week. 
Stradivari purchased a house now known as No. 1 Piazza Roma (formerly No. 2 Piazza San Domenico) around 1680. The house was just doors away from those of several other violin making families of Cremona, including the Amatis and Guarneris. Stradivari probably worked in the loft and attic, and he stayed in this house for the rest of his life.
Stradivari's wife Francesca died on 20 May 1698, and received an elaborate funeral five days later.
Second marriage.
Stradivari married his second wife, Zambelli Costa, on 24 August 1699. They had five children from 1700 to 1708—Francesca Maria, Giovanni Battista Giuseppe, Giovanni Battista Martino, Giuseppe Antonio, and Paolo. 
Death.
Stradivari died on 18 December 1737, aged 93. He is buried in the Church of San Domenico.
Career.
Early career.
Stradivari likely developed his own style slowly. His violins often used slightly smaller dimensions. A notable exception to this is the 1697 "Hellier" violin, which had much larger proportions. Stradivari's early (pre-1684) violins are in strong contrast to Amati's instruments from the same time period; Stradivari's have a stronger, more masculine build, and less rounded curves, with the purfling set farther in.
By 1680, Stradivari had acquired at least a small, yet growing, reputation. In 1682, a Venetian banker ordered a complete set of instruments, which he planned to present to King James II of England. The fate of these instruments is unknown. Cosimo de' Medici bought another five years later. Amati died in 1684, an event followed by a noticeable increase in Stradivari's production. The years 1684 and 1685 also marked an important development in his style – the dimensions he used generally increased, and his instruments were more in the style of Amati's work of the 1640s and 1650s. Stradivari's instruments underwent no major change in the next five years, although in 1688 he began cutting a more distinct bevel and began outlining the heads of instruments in black, a quite original improvement.
Stradivari's early career is marked by wide experimentation, and his instruments during this period are generally considered of a lesser quality than his later work. However, the precision with which he carved the heads and inserted the purfling quickly marked him as one of the most dextrous craftsmen in the world, a prime example of this being the 1690 "Tuscan" violin. Pre-1690 instruments are sometimes termed "Amatisé" but this is not completely accurate; it is largely because Stradivari created many more instruments later on that people try to connect his early work with Amati's style.
By 1680 Stradivari moved to No. 1 Piazza Roma (formally No. 2 Piazza San Domenico). The house was just doors away from those of several other violin making families of Cremona, including the Amatis and Guarneris. Stradivari probably worked in the loft and attic, and he stayed in this house for the rest of his life. 
"Golden" period and later years.
In the early 1690s, Stradivari made a pronounced departure from this earlier style of instrument-making, changing two key elements of his instruments. First, he began to make violins with a larger pattern than previous instruments, which are usually dubbed "Long Strads". He also switched to using a darker, richer varnish, as opposed to a yellower varnish similar to that used by Amati. He continued to use this pattern until 1698, with few exceptions. After 1698, he abandoned the Long Strad model and returned to a slightly shorter model, which he used until his death. The period from 1700 until the 1720s is often termed the "golden period" of his production. Instruments made during this time are usually considered of a higher quality than his earlier instruments. Late-period instruments made from the late 1720s until his death in 1737 show signs of Stradivari's advancing age. These late instruments may be a bit less beautiful than the Golden Period instruments, but many nonetheless possess a fine tone.
Stradivarius instruments.
Stradivari's instruments are regarded as amongst the finest bowed stringed instruments ever created, are highly prized, and are still played by professionals today. Only one other maker, Giuseppe Guarneri del Gesù, commands a similar respect among violinists. However, neither blind listening tests nor acoustic analysis have ever demonstrated that Stradivarius instruments are better than other high-quality instruments or even reliably distinguishable from them.
Fashions in music, as in other things, have changed over the centuries, and the supremacy of Stradivari's and Guarneri's instruments is accepted only today. In the past, instruments by Nicolò Amati and Jacob Stainer were preferred for their subtle sweetness of tone.
While the usual label for a Stradivarius instrument, whether genuine or false, uses the traditional Latin inscription, after the McKinley Tariff Act of 1890, copies were also inscribed with the country of origin. Since thousands of instruments are based on Stradivari's models and bear the same name as his models, many unwary people are deceived into purchasing forged Stradivarius instruments, which can be avoided by having an instrument authenticated.
Some violinists and cellists use Stradivari instruments in their work. Yo-Yo Ma currently uses the "Davidov Stradivarius", Julian Lloyd Webber employs the "Barjansky Stradivarius", and, until his death in 2007, Mstislav Rostropovich played on the "Duport Stradivarius". The "Soil" of 1714 is owned by virtuoso Itzhak Perlman. The "Countess Polignac" is currently played by Gil Shaham. The Vienna Philharmonic uses several Stradivari instruments that were purchased by the National Bank of Austria and other sponsors: "Chaconne", 1725; "ex-Hämmerle", 1709; "ex-Smith-Quersin", 1714; "ex-Arnold Rosé", "ex-Viotti", 1718; and "ex-Halphen", 1727.
The London sales of "The Mendelssohn" at £902,000 ($1,776,940) in 1990 and "The Kreutzer" for £947,500 in 1998 constitute two top-selling Stradivari. A record price paid at a public auction for a Stradivari was $2,032,000 for the "Lady Tennant" at Christie's in New York, April 2005. On 16 May 2006, Christie's auctioned Stradivari's 1707 "Hammer" for a new record of US$3,544,000. On 2 April 2007, Christie's sold a Stradivari violin, the 1729 "Solomon, Ex-Lambert", for more than $2.7 million to an anonymous bidder in the auction house's fine musical instruments sale. Its price, US$2,728,000 including the Christie's commission, far outdid its estimated value: $1 million to $1.5 million. On 14 October 2010, a 1697 Stradivari violin known as "The Molitor" was sold online by Tarisio Auctions for a world-record price of $3,600,000 to renowned concert violinist Anne Akiko Meyers: at the time its price was the highest for any musical instrument sold at auction. On 21 June 2011, a 1721 Stradivari violin known as "Lady Blunt" was auctioned by Tarisio to an anonymous bidder for £9,808,000 with all proceeds going to help the victims of the Japan earthquake. This was over four times the previous auction record for a Stradivari violin. The  1705 Baron von der Leyen Strad was auctioned by Tarisio on 26 April 2012, for $2.6 million.
Publicly displayed collections of Stradivari instruments are those of the Library of Congress with three violins, a viola, and a cello, the Agency of National Estates of Spain, with a quartet of two violins, the "Spanish I and II", the "Spanish Court" cello, and the "Spanish Court" viola, exhibited in the Music Museum at the Royal Palace of Madrid (Palacio Real de Madrid]] and the Royal Academy of Music's Collections with several instruments by Antonio Stradivari, including the "Joachim" (1698), "Rutson" (1694), the "Crespi" (1699), "Viotti ex-Bruce" (1709), "Kustendyke" (1699), "Maurin" (1718) and the "Ex Back" (1666) violins, "Ex Kux" (1714), and the "Archinto" (1696) violas, the "Marquis de Corberon" (1726) and the "Markevitch" (1709) celli. The Musée de la musique in Paris displays several beautiful Stradivari instruments that formerly belonged to the Paris Conservatory.
The collection of The New Jersey Symphony Orchestra had the largest number of Stradivari in its string section, purchased in 2003 from the collection of Herbert R. Axelrod, until it recently decided to sell them off. A collection assembled by Rodman Wanamaker in the 1920s contained as many as 65 stringed instruments by such masters as Stradivari, Gofriller, Baptiste and Giuseppe Guarneri. Included was "The Swan", the last violin made by Stradivari, and soloist instrument of the great Cuban 19th-century virtuoso Joseph White. The collection, known as The Cappella, was used in concerts with the Philadelphia Orchestra and Leopold Stokowski before being dispersed after Wanamaker's death. The Vienna Philharmonic uses four violins and one cello. The Metropolitan Museum of Art has three Stradivari violins dated 1693, 1694 and 1717. The National Music Museum, in Vermillion, South Dakota, has in its collection one of two known Stradivari guitars, one of eleven known violas da gamba, later modified into a cello form, one of two known choral mandolins, and one of six Stradivari violins that still retain their original neck. In the interests of conservation, the "Messiah Stradivarius" violin—on display in the Ashmolean Museum in Oxford, England—has not been played at all in recent years.
In fiction.
There are numerous references to Stradivari violins in fiction, including:
Literature
Television
Film
Video games
References.
Notes
Sources

</doc>
<doc id="56458" url="http://en.wikipedia.org/wiki?curid=56458" title="Apraxia">
Apraxia

Apraxia is a motor disorder caused by damage to the brain (specifically the Posterior Parietal Cortex), in which someone has difficulty with the motor planning to perform tasks or movements when asked, provided that the request or command is understood and he/she is willing to perform the task. Apraxia is an acquired disorder of motor planning, but is not caused by incoordination, sensory loss, or failure to comprehend simple commands (which can be tested by asking the person to recognize the correct movement from a series). It is caused by damage to specific areas of the cerebrum. Apraxia should not be confused with ataxia, a lack of coordination of movements; aphasia, an inability to produce and/or comprehend language; abulia, the lack of desire to carry out an action; or allochiria, in which patients perceive stimuli to one side of the body as occurring on the other. Developmental coordination disorder (DCD) is the developmental disorder of motor planning.
Types.
There are several types of apraxia including:
Each type may be tested at decreasing levels of complexity; if the person tested fails to execute the commands, you can make the movement yourself and ask that the person mimic it, or you can even give them a real object (like a toothbrush) and ask them to use it.
Apraxia of speech.
Apraxia of speech (AOS) involves the loss of previously acquired speech levels. It occurs in both children and adults who have (prior to the onset of apraxia) acquired some level of speaking ability. AOS affects an individual's volitional speech and is typically the result of a stroke, tumor, or other known neurological illness or injury. Apraxia may be accompanied by a language disorder called aphasia.
Symptoms of AOS include inconsistent articulatory errors, groping oral movements to locate the correct articulatory position, and increasing errors with increasing word and phrase length. Patients with apraxia find that vowels are easier to produce than consonants. Single consonants are easier than blends. As in stuttering, final consonants are easier than those in the initial position. This may occur because initial consonants are affected by anticipatory errors. Also, perhaps once an apraxic gets speech started with the production of a vowel, production continues in a more automatic fashion. Fricative and affricates are the most difficult phonemes for apraxics to produce. AOS often co-occurs with Oral Apraxia (during both speech and non-speech movements) and Limb Apraxia.
Developmental verbal dyspraxia presents in children who have no evidence of difficulty with strength or range of motion of the articulators, but are unable to execute speech movements because of motor planning and coordination problems.
Causes.
Apraxia is most often due to a lesion located in the left hemisphere of the brain, typically in the frontal and parietal lobes. Lesions may be due to stroke, acquired brain injuries, or neurodegenerative diseases such as Alzheimer's disease or other dementias, Parkinson's disease, or Huntington's disease. It is also possible for apraxia to be caused by lesions in other areas of the brain including the right hemisphere.
Ideomotor apraxia is typically due to a decrease in blood flow to the left hemisphere of the brain and particularly the parietal and premotor areas. It is frequently seen in patients with corticobasal degeneration.
Ideational apraxia often results in functional impairments in activities of daily living (ADLs) similar to those seen with late stage dementia. More recently, it has been observed in patients with lesions in the left hemisphere near areas associated with aphasia; however, more research is needed on ideational apraxia due to brain lesions. The localization of lesions in areas of the frontal and temporal lobes would provide explanation for the difficulty in motor planning seen in ideational apraxia as well as its difficulty to distinguish it from certain aphasias.
Constructional apraxia is often caused by lesions of the inferior right parietal lobe, and can be caused by brain injury, illness, tumor or other condition that can result in a brain lesion.
Assessment.
Although qualitative and quantitative studies exist, there is little consensus on the proper method to assess for apraxia. The criticisms of past methods include failure to meet standard psychometric properties as well as research-specific designs that translate poorly to non-research use.
The Test to Measure Upper Limb Apraxia (TULIA) is one method of determining upper limb apraxia through the qualitative and quantitative assessment of gesture production. In contrast to previous publications on apraxic assessment, the reliability and validity of TULIA was thoroughly investigated. The TULIA consists of subtests for the imitation and pantomime of non-symbolic (“put your index finger on top of your nose”), intransitive (“wave goodbye”) and transitive (“show me how to use a hammer”) gestures. Discrimination (differentiating between well- and poorly performed tasks) and recognition (indicating which object corresponds to a pantomimed gesture) tasks are also often tested for a full apraxia evaluation.
However, there may not be a strong correlation between formal test results and actual performance in everyday functioning or activities of daily living (ADLs). A comprehensive assessment of apraxia should include formal testing, standardized measurements of ADLs, observation of daily routines, self-report questionnaires and targeted interviews with the patients and their relatives.
As stated above, Apraxia should not be confused with Aphasia, however they are frequently accompanied with each other. It has been stated that apraxia is so often accompanied by aphasia that many believe that if a person displays AOS; it should be assumed that the patient also has some level of aphasia.
Treatment.
Treatment for individuals with apraxia includes speech therapy, occupational therapy, and physical therapy.
Yet, treatments for apraxia have received little attention for several reasons, including the tendency for the condition to resolve spontaneously in acute cases. Additionally, the very nature of the automatic-voluntary dissociation of motor abilities that defines apraxia means that patients may still be able to automatically perform activities if cued to do so in daily life. Nevertheless, research shows that patients experiencing apraxia have less functional independence in their daily lives, and that evidence for the treatment of apraxia is scarce. However, a literature review of apraxia treatment to date reveals that although the field is in its early stages of treatment design, certain aspects can be included to treat apraxia. One method is through rehabilitative treatment, which has been found to positively impact apraxia, as well as activities of daily living. In this review, rehabilitative treatment consisted of 12 different contextual cues, which were used in order to teach patients how to produce the same gesture under different contextual situations. Additional studies have also recommended varying forms of gesture therapy, whereby the patient is instructed to make gestures (either using objects or symbolically meaningful and non-meaningful gestures) with progressively less cuing from the therapist. No single type of therapy or approach has been proven as the best way to treat a patient with apraxia, since each patient's case varies. However, one-on-one sessions usually work the best, with the support of family members and friends. Since everyone responds to therapy differently, some patients will make significant improvements, while others will make less progress. The overall goal for treatment of apraxia is to treat the motor plans for speech, not treating at the phoneme (sound) level.
Prognosis.
The prognosis for individuals with apraxia varies. With therapy, some patients improve significantly, while others may show very little improvement. Some individuals with apraxia may benefit from the use of a communication aid.
However, many people with apraxia are no longer able to be independent. Those with limb-kinetic and/or gait apraxia should avoid activities in which they might injure themselves or others.
Occupational therapy, physical therapy, and play therapy may be considered as other references to support patients with apraxia. These team members could be work along with the SLP to provide the best therapy for people with apraxia. However, because people with limb apraxia may have trouble directing their motor movements, occupational therapy for stroke or other brain injury can be difficult.
No drug has been shown useful for treating apraxia.
References.
Manasco, H. (2014). Introduction to Neurogenic Communication Disorders. Jones & Bartlett Publishers.

</doc>
<doc id="56461" url="http://en.wikipedia.org/wiki?curid=56461" title="Canavan disease">
Canavan disease

Canavan disease, also called Canavan-Van Bogaert-Bertrand disease is an autosomal recessive degenerative disorder that causes progressive damage to nerve cells in the brain, and is one of the most common degenerative cerebral diseases of infancy. It is caused by a deficiency of the enzyme aminoacylase 2, and is one of a group of genetic diseases referred to as a leukodystrophies. It is characterized by degeneration of myelin in the phospholipid layer insulating the axon of a neuron and is associated with a gene located on human chromosome 17.
History.
Canavan disease was first described in 1931 by Myrtelle Canavan.
Greenberg v. Miami Children's Hospital Research Institute.
The discovery of the gene for Canavan disease, and subsequent events, generated considerable controversy. In 1987 the Greenbergs, a family with two children affected by Canavan disease, donated tissue samples to Reuben Matalon, a researcher at the University of Chicago who was looking for the Canavan gene. He successfully identified the gene in 1993 and developed a test for it that would enable antenatal (before birth) counseling of couples at risk of having a child with the disease. For a while, the Canavan Foundation offered free genetic testing with the test.
However in 1997, after relocating to Florida, Matalon's employer, Miami Children's Hospital, patented the gene and started claiming royalties on the genetic test, forcing the Canavan Foundation to withdraw their testing. A subsequent lawsuit brought by the Canavan Foundation against Miami Children's Hospital, and was resolved with a sealed out-of-court settlement. The case is sometimes cited in arguments about the appropriateness of patenting genes.
Prevalence.
Although Canavan disease may occur in any ethnic group, it affects people of Eastern European Jewish ancestry more frequently. About 1 in 40 (2.5%) individuals of Eastern European (Ashkenazi) Jewish ancestry are carriers.
Pathophysiology.
Canavan disease is inherited in an autosomal recessive fashion. When both parents are carriers, there is a 25% chance of having an affected child. Genetic counseling and genetic testing is recommended for families with two parental carriers.
Canavan disease is caused by a defective "ASPA" gene which is responsible for the production of the enzyme aspartoacylase. Decreased aspartoacylase activity prevents the normal breakdown of "N"-acetyl aspartate, wherein the accumulation of N-acetylaspartate, or lack of its further metabolism interferes with growth of the myelin sheath of the nerve fibers of the brain. The myelin sheath is the fatty covering that surrounds nerve cells and acts as an insulator, which allows for efficient transmission of nerve impulses.
Symptoms.
Symptoms of Canavan disease, which appear in early infancy and progress rapidly, may include intellectual disability, loss of previously acquired motor skills, feeding difficulties, abnormal muscle tone (i.e., floppiness or stiffness), poor head control, and megalocephaly (abnormally enlarged head). Paralysis, blindness, or seizures may also occur.
Treatment.
There is no cure for Canavan disease, nor is there a standard course of treatment. Treatment is symptomatic and supportive. There is also an experimental treatment using lithium citrate. When a person has Canavan disease, his or her levels of N-acetyl aspartate are chronically elevated. The lithium citrate has proven in a rat genetic model of Canavan disease to be able to significantly decrease levels of N-acetyl aspartate. When tested on a human, the subject reversed during a two week wash-out period after withdrawal of lithium.
The investigation revealed both decreased N-acetyl aspartate levels in regions of the brain tested and magnetic resonance spectroscopic values that are more characteristic of normal development and myelination. This evidence suggests that a larger controlled trial of lithium may be warranted as supportive therapy for children with Canavan disease.
In addition there are experimental trials of gene therapy, published in 2002, involving using a healthy gene to take over for the defective one that causes Canavan disease.
In human trials, the results of which were published in 2012, this method appeared to improve the life of the patient without long-term adverse effects during a 5 year follow-up.
Prognosis.
Death usually occurs before age 4, but some children with milder forms of the disease survive into their teens and twenties.
Current research.
Research involving triacetin supplementation has shown promise in a rat model. Triacetin, which can be enzymatically cleaved to form acetate, enters the brain more readily than the negatively charged acetate. The defective enzyme in Canavan disease, aspartoacylase, converts N-acetylaspartate into aspartate and acetate. Mutations in the gene for aspartoacylase prevent the breakdown of N-acetylaspartate, and reduce brain acetate availability during brain development. Acetate supplementation using Triacetin is meant to provide the missing acetate so that brain development can continue normally.
A team of researchers headed by Paola Leone are currently at the University of Medicine and Dentistry of New Jersey, in Stratford, New Jersey. The brain gene therapy is conducted at Cooper University Hospital. The procedure involves the insertion of six catheters into the brain that deliver a solution containing 600 billion to 900 billion engineered virus particles. The virus, a modified version of AAV, is designed to replace the aspartoacylase enzyme. Children treated with this procedure to date have shown marked improvements, including the growth of myelin with decreased levels of the n-acetyl-aspartate toxin.

</doc>
<doc id="56462" url="http://en.wikipedia.org/wiki?curid=56462" title="Carpal tunnel syndrome">
Carpal tunnel syndrome

Carpal tunnel syndrome (CTS) is a medical condition in which the median nerve is compressed as it travels through the wrist at the carpal tunnel and causes pain, numbness and tingling, in the part of the hand that receives sensation from the median nerve. The mechanism is not completely understood but there are a variety of contributing factors. Some of the individual predisposing factors include: diabetes, obesity, pregnancy, hypothyroidism, and a narrow-diameter carpal tunnel. CTS may also result from an injury that causes internal scarring or mis-aligned wrist bones. Occupational causes involve use of the hand and arm, such as heavy manual work, work with vibrating tools, and highly repetitive tasks even if they involve low force motions.
The main symptom of CTS is intermittent numbness of the thumb, index, and middle (long) fingers and the radial (thumb) side of the ring finger. The numbness often occurs at night, with hypothesized reasons related to sleep position, such as the wrists being held flexed during sleep or sleeping on one's side. It can be relieved by wearing a wrist splint that prevents flexion. Long-standing CTS leads to permanent nerve damage with constant numbness, atrophy of some of the muscles of the thenar eminence, and weakness of palmar abduction (see ).
Pain in carpal tunnel syndrome is primarily numbness that is so intense that it wakes one from sleep. Pain in electrophysiologically verified CTS is associated with misinterpretation of nociception and depression.
Conservative treatments include use of night splints and corticosteroid injection. The only scientifically established disease modifying treatment is surgery to cut the transverse carpal ligament.
Signs and symptoms.
 People with CTS experience numbness, tingling, or burning sensations in the thumb and fingers, in particular the index and middle fingers and radial half of the ring finger, because these receive their sensory and motor function (muscle control) from the median nerve. Less-specific symptoms may include pain in the wrists or hands, loss of grip strength, and loss of manual dexterity. 
Some suggest that median nerve symptoms can arise from compression at the level of the thoracic outlet or the area where the median nerve passes between the two heads of the pronator teres in the forearm, although this is debated.
Numbness and paresthesias in the median nerve distribution are the hallmark neuropathic symptoms (NS) of carpal tunnel entrapment syndrome. Weakness and atrophy of the thumb muscles may occur if the condition remains untreated, because the muscles are not receiving sufficient nerve stimulation.
Causes.
Most cases of CTS are of unknown causes, or idiopathic. Carpal tunnel syndrome can be associated with any condition that causes pressure on the median nerve at the wrist. Some common conditions that can lead to CTS include obesity, oral contraceptives, hypothyroidism, arthritis, diabetes, prediabetes (impaired glucose tolerance), and trauma. Carpal tunnel is also a feature of a form of Charcot-Marie-Tooth syndrome type 1 called hereditary neuropathy with liability to pressure palsies.
Other causes of this condition include intrinsic factors that exert pressure within the tunnel, and extrinsic factors (pressure exerted from outside the tunnel), which include benign tumors such as lipomas, ganglion, and vascular malformation. Carpal tunnel syndrome often is a symptom of transthyretin amyloidosis-associated polyneuropathy and prior carpal tunnel syndrome surgery is very common in individuals who later present with transthyretin amyloid-associated cardiomyopathy, suggesting that transthyretin amyloid deposition may cause carpal tunnel syndrome.
The median nerve can usually move up to 9.6 mm to allow the wrist to flex, and to a lesser extent during extension. Long-term compression of the median nerve can inhibit nerve gliding, which may lead to injury and scarring. When scarring occurs, the nerve will adhere to the tissue around it and become locked into a fixed position, so that less movement is apparent.
Normal pressure of the carpal tunnel has been defined as a range of 2–10 mm, and wrist flexion increases this pressure 8-fold, while extension increases it 10-fold. Repetitive flexion and extension in the wrist significantly increase the fluid pressure in the tunnel through thickening of the synovial tissue that lines the tendons within the carpal tunnel.
Work related.
The international debate regarding the relationship between CTS and repetitive motion in work is ongoing. The Occupational Safety and Health Administration (OSHA) has adopted rules and regulations regarding cumulative trauma disorders. Occupational risk factors of repetitive tasks, force, posture, and vibration have been cited. 
The relationship between work and CTS is controversial; in many locations, workers diagnosed with carpal tunnel syndrome are entitled to time off and compensation.
Some speculate that carpal tunnel syndrome is provoked by repetitive movement and manipulating activities and that the exposure can be cumulative. It has also been stated that symptoms are commonly exacerbated by forceful and repetitive use of the hand and wrists in industrial occupations, but it is unclear as to whether this refers to pain (which may not be due to carpal tunnel syndrome) or the more typical numbness symptoms.
A review of available scientific data by the National Institute for Occupational Safety and Health (NIOSH) indicated that job tasks that involve highly repetitive manual acts or specific wrist postures were associated with incidents of CTS, but causation was not established, and the distinction from work-related arm pains that are not carpal tunnel syndrome was not clear. It has been proposed that repetitive use of the arm can affect the biomechanics of the upper limb or cause damage to tissues. It has also been proposed that postural and spinal assessment along with ergonomic assessments should be included in the overall determination of the condition. Addressing these factors has been found to improve comfort in some studies. A 2010 survey by NIOSH showed that 2/3 of the 5 million carpal tunnel cases in the US that year were related to work. Women have more work-related carpal tunnel syndrome than men.
Speculation that CTS is work-related is based on claims such as CTS being found mostly in the working adult population, though evidence is lacking for this. For instance, in one recent representative series of a consecutive experience, most patients were older and not working. Based on the claimed increased incidence in the workplace, arm use is implicated, but the weight of evidence suggests that this is an inherent, genetic, slowly but inevitably progressive idiopathic peripheral mononeuropathy.
Associated conditions.
A variety of patient factors can lead to CTS, including heredity, size of the carpal tunnel, associated local and systematic diseases, and certain habits. Non-traumatic causes generally happen over a period of time, and are not triggered by one certain event. Many of these factors are manifestations of physiologic aging.
Examples include:
Diagnosis.
There is no consensus reference standard for the diagnosis of carpal tunnel syndrome. A combination of described symptoms, clinical findings, and electrophysiological testing may be used. CTS work up is the most common referral to the electrodiagnostic lab. Historically, diagnosis has been made with the combination of a thorough history and physical examination in conjunction with the use of electrodiagnostic (EDX) testing for confirmation. Additionally, evolving technology has included the use of ultrasonography in the diagnosis of CTS. However, it is well established that physical exam provocative maneuvers lack both sensitivity and specificity. Furthermore, EDX cannot fully exclude the diagnosis of CTS due to the lack of sensitivity. A Joint report published by the American Association of Electrodiagostic Medicine (AANEM), the American Academy of Physical Medicine and Rehabilitation (AAPM&R) and the American Academy of Neurology defines practice parameters, standards and guidelines for EDX studies of CTS based on an extensive critical literature review. This joint review concluded median and sensory nerve conduction studies are valid and reproducible in a clinical laboratory setting and a clinical diagnosis of CTS can be made with a sensitivity greater than 85% and specificity greater than 95%. Given the key role of electrodiagnostic testing in the diagnosis of CTS, The American Association of Neuromuscular & Electrodiagnostic Medicine has issued evidence-based practice guidelines, both for the diagnosis of carpal tunnel syndrome.
Numbness in the distribution of the median nerve, nocturnal symptoms, thenar muscle weakness/atrophy, positive Tinel's sign at the carpal tunnel, and abnormal sensory testing such as two-point discrimination have been standardized as clinical diagnostic criteria by consensus panels of experts. Pain may also be a presenting symptom, although less common then sensory disturbances. 
Electrodiagnostic testing (electromyography and nerve conduction velocity) can objectively verify the median nerve dysfunction. Normal nerve conduction studies, however, do not exclude the diagnosis of CTS. Clinical assessment by history taking and physical examination can support a diagnosis of CTS. If clinical suspicion of CTS is high, treatment should be initiated despite normal electrodiagnostic testing. 
Physical exam.
As a note, a patient with true carpal tunnel syndrome (entrapment of the median nerve within the carpal tunnel) will not have any sensory loss over the thenar eminence (bulge of muscles in the palm of hand and at the base of the thumb). This is because the palmar branch of the median nerve, which innervates that area of the palm, branches off of the median nerve and passes over the carpal tunnel. This feature of the median nerve can help separate carpal tunnel syndrome from thoracic outlet syndrome, or pronator teres syndrome.
Other conditions may also be misdiagnosed as carpal tunnel syndrome. Thus, if history and physical examination suggest CTS, patients will sometimes be tested electrodiagnostically with nerve conduction studies and electromyography. The goal of electrodiagnostic testing is to compare the speed of conduction in the median nerve with conduction in other nerves supplying the hand. When the median nerve is compressed, as in CTS, it will conduct more slowly than normal and more slowly than other nerves. There are many electrodiagnostic tests used to make a diagnosis of CTS, but the most sensitive, specific, and reliable test is the Combined Sensory Index (also known as Robinson index). Electrodiagnosis rests upon demonstrating impaired median nerve conduction across the carpal tunnel in context of normal conduction elsewhere. Compression results in damage to the myelin sheath and manifests as delayed latencies and slowed conduction velocities However, normal electrodiagnostic studies do not preclude the presence of carpal tunnel syndrome, as a threshold of nerve injury must be reached before study results become abnormal and cut-off values for abnormality are variable. Carpal tunnel syndrome with normal electrodiagnostic tests is very, very mild at worst.
The role of MRI or ultrasound imaging in the diagnosis of carpal tunnel syndrome is unclear.
Differential diagnosis.
Carpal tunnel syndrome is sometimes applied as a label to anyone with pain, numbness, swelling, and/or burning in the radial side of the hands and/or wrists. When pain is the primary symptom, carpal tunnel syndrome is unlikely to be the source of the symptoms. As a whole, the medical community is not currently embracing or accepting trigger point theories due to lack of scientific evidence supporting their effectiveness.
Pathophysiology.
The carpal tunnel is an anatomical compartment located at the base of the palm. Nine flexor tendons and the median nerve pass through the carpal tunnel that is surrounded on three sides by the carpal bones that form an arch. The median nerve provides feeling or sensation to the thumb, index finger, long finger, and half of the ring finger. At the level of the wrist, the median nerve supplies the muscles at the base of the thumb that allow it to abduct, or move away from the fingers, out of the plane of the palm. The carpal tunnel is located at the middle third of the base of the palm, bounded by the bony prominence of the scaphoid tubercle and trapezium at the base of the thumb, and the hamate hook that can be palpated along the axis of the ring finger. The proximal boundary is the distal wrist skin crease, and the distal boundary is approximated by a line known as Kaplan's cardinal line. This line uses surface landmarks, and is drawn between the apex of the skin fold between the thumb and index finger to the palpated hamate hook.
The median nerve can be compressed by a decrease in the size of the canal, an increase in the size of the contents (such as the swelling of lubrication tissue around the flexor tendons), or both. Simply flexing the wrist to 90 degrees will decrease the size of the canal.
Compression of the median nerve as it runs deep to the transverse carpal ligament (TCL) causes atrophy of the thenar eminence, weakness of the flexor pollicis brevis, opponens pollicis, abductor pollicis brevis, as well as sensory loss in the digits supplied by the median nerve. The superficial sensory branch of the median nerve, which provides sensation to the base of the palm, branches proximal to the TCL and travels superficial to it. Thus, this branch spared in carpal tunnel syndrome, and there is no loss of palmar sensation.
Prevention.
Suggested healthy habits such as avoiding repetitive stress, work modification through use of ergonomic equipment (wrist rest, mouse pad), taking proper breaks, using keyboard alternatives (digital pen, voice recognition, and dictation), and employing early treatments such as taking turmeric (anti-inflammatory), omega-3 fatty acids, and B vitamins have been proposed as methods to help prevent carpal tunnel syndrome. The potential role of B-vitamins in preventing or treating carpal tunnel syndrome has not been proven.
There is little or no data to support the concept that activity adjustment prevents carpal tunnel syndrome.
Stretches and isometric exercises will aid in prevention for persons at risk. Stretching before the activity and during breaks will aid in alleviating tension at the wrist. Place the hand firmly on a flat surface and gently pressing for a few seconds to stretch the wrist and fingers. An example for an isometric exercise of the wrist is done by clinching the fist tightly, releasing and fanning out fingers. None of these stretches or exercises should cause pain or discomfort.
Biological factors such as genetic predisposition and anthropometrics had significantly stronger causal association with carpal tunnel syndrome than occupational/environmental factors such as repetitive hand use and stressful manual work. This suggests that carpal tunnel syndrome might not be preventable simply by avoiding certain activities or types of work/activities.
Treatment.
Generally accepted treatments include: physiotherapy, steroids either orally or injected locally, splinting, and surgical release of the transverse carpal ligament. There is no or insufficient evidence for ultrasound, yoga, lasers, B6, and exercise therapy.
The American Academy of Orthopedic Surgeons recommends proceeding conservatively with a course of nonsurgical therapies tried before release surgery is considered. Early surgery with carpal tunnel release is indicated where there is evidence of median nerve denervation or a person elects to proceed directly to surgical treatment. The treatment should be switched when the current treatment fails to resolve the symptoms within 2 to 7 weeks. However, these recommendations have sufficient evidence for carpal tunnel syndrome when found in association with the following conditions: diabetes mellitus, coexistent cervical radiculopathy, hypothyroidism, polyneuropathy, pregnancy, rheumatoid arthritis, and carpal tunnel syndrome in the workplace.
Splints.
The importance of wrist braces and splints in the carpal tunnel syndrome therapy is known, but many people are unwilling to use braces. In 1993, The American Academy of Neurology recommend a non-invasive treatment for the CTS at the beginning (except for sensitive or motor deficit or grave report at EMG/ENG): a therapy using splints was indicated for light and moderate pathology. Current recommendations generally don't suggest immobilizing braces, but instead activity modification and non-steroidal anti-inflammatory drugs as initial therapy, followed by more aggressive options or specialist referral if symptoms do not improve.
Many health professionals suggest that, for the best results, one should wear braces at night and, if possible, during the activity primarily causing stress on the wrists.
Corticosteroids.
Corticosteroid injections can be effective for temporary relief from symptoms while a person develops a long-term strategy that fits their lifestyle. This treatment is not appropriate for extended periods, however. In general, local steroid injections are only used until other treatment options can be identified.
Surgery.
Release of the transverse carpal ligament is known as "carpal tunnel release" surgery. It is recommended when there is static (constant, not just intermittent) numbness, muscle weakness, or atrophy, and when night-splinting or other conservative interventions no longer control intermittent symptoms. In general, milder cases can be controlled for months to years, but severe cases are unrelenting symptomatically and are likely to result in surgical treatment.
Physical therapy.
A recent evidence based guideline produced by the American Academy of Orthopedic Surgeons assigned various grades of recommendation to physiotherapy (also called physical therapy) and other nonsurgical treatments. One of the primary issues with physiotherapy is that it attempts to reverse (often) years of pathology inside the carpal tunnel. Practitioners caution that any physiotherapy such as myofascial release may take weeks of persistent application to effectively manage carpal tunnel syndrome.
Again, some claim that pro-active ways to reduce stress on the wrists, which alleviates wrist pain and strain, involve adopting a more ergonomic work and life environment. For example, some have claimed that switching from a QWERTY computer keyboard layout to a more optimised ergonomic layout such as Dvorak was commonly cited as beneficial in early CTS studies, however some meta-analyses of these studies claim that the evidence that they present is limited.
Prognosis.
Most people relieved of their carpal tunnel symptoms with conservative or surgical management find minimal residual or "nerve damage". Long-term chronic carpal tunnel syndrome (typically seen in the elderly) can result in permanent "nerve damage", i.e. irreversible numbness, muscle wasting, and weakness. Those that undergo a carpal tunnel release are nearly twice as likely as those not having surgery to develop trigger thumb in the months following the procedure.
While outcomes are generally good, certain factors can contribute to poorer results that have little to do with nerves, anatomy, or surgery type. One study showed that mental status parameters or alcohol use yields much poorer overall results of treatment.
Recurrence of carpal tunnel syndrome after successful surgery is rare. If a person has hand pain after surgery, it is most likely not caused by carpal tunnel syndrome. It may be the case that the illness of a person with hand pain after carpal tunnel release was diagnosed incorrectly, such that the carpal tunnel release has had no positive effect upon the patient's symptoms.
Epidemiology.
Carpal tunnel syndrome can affect anyone. It accounts for about 90% of all nerve compression syndromes. In the U.S., roughly 1 out of 20 people will suffer from the effects of carpal tunnel syndrome. Caucasians have the highest risk of CTS compared with other races such as non-white South Africans. Women suffer more from CTS than men with a ratio of 3:1 between the ages of 45–60 years. Only 10% of reported cases of CTS are younger than 30 years. Increasing age is a risk factor. CTS is also common in pregnancy.
Occupational.
As of 2010, 8% of U.S. workers reported ever having carpal tunnel syndrome and 4% reported carpal tunnel syndrome in the past 12 months. Prevalence rates for carpal tunnel syndrome in the past 12 months were higher among females than among males; among workers aged 45–64 than among those aged 18–44. Overall, 67% of current carpal tunnel syndrome cases among current/recent workers were reportedly attributed to work by health professionals, indicating that the prevalence rate of work-related carpal tunnel syndrome among workers was 2%, and that there were approximately 3.1 million cases of work-related carpal tunnel syndrome among U.S. workers in 2010. Among current carpal tunnel syndrome cases attributed to specific jobs, 24% were attributed to jobs in the manufacturing industry, a proportion 2.5 times higher than the proportion of current/recent workers employed in the manufacturing industry, suggesting that jobs in this industry are associated with an increased risk of work-related carpal tunnel syndrome.
History.
The condition known as carpal tunnel syndrome had major appearances throughout the years but it was most commonly heard of in the years following World War II. Individuals who had suffered from this condition have been depicted in surgical literature for the mid-19th century. In 1854, Sir James Paget was the first to report median nerve compression at the wrist in a distal radius fracture. Following the early 20th century there were various cases of median nerve compression underneath the transverse carpal ligament. Carpal Tunnel Syndrome was most commonly noted in medical literature in the early 20th century but the first use of the term was noted 1939. Physician Dr. George S. Phalen of the Cleveland Clinic identified the pathology after working with a group of patients in the 1950s and 1960s.

</doc>
<doc id="56464" url="http://en.wikipedia.org/wiki?curid=56464" title="Joubert syndrome">
Joubert syndrome

Joubert syndrome is a rare genetic disorder that affects the cerebellum, an area of the brain that controls balance and coordination.
Diagnosis.
The disorder is characterized by absence or underdevelopment of the cerebellar vermis and a malformed brain stem (molar tooth sign). The most common features include ataxia (lack of muscle control), hyperpnea (abnormal breathing patterns), sleep apnea, abnormal eye and tongue movements, and hypotonia. Other malformations such as extra fingers and toes, cleft lip or palate, tongue abnormalities, and seizures may also occur. There may be mild or moderate intellectual disabilities. Joubert syndrome is one of the many genetic syndromes associated with syndromic retinitis pigmentosa. The syndrome was first identified by pioneering pediatric neurologist Marie Joubert in Montreal, Canada, while working at the Montreal Neurological Institute and McGill University.
Treatment.
Treatment for Joubert syndrome is symptomatic and supportive. Infant stimulation and physical, occupational,speech and hearing therapy may benefit some patients. Infants with abnormal breathing patterns should be monitored.
Prognosis.
The prognosis for individuals with Joubert syndrome varies. Some patients have a mild form with minimal motor disability and good mental development, while others may have severe motor disability and moderate mental developmental delays.
Genetics.
A number of mutations have been identified in individuals with Joubert syndrome (JBTS) which allowed for classification of the disorder into subtypes.
Ciliopathy.
Research has revealed that a number of genetic disorders, not previously thought to be related, may indeed be related as to their root cause. Joubert syndrome is one such disease. It is a member of an emerging class of diseases called ciliopathies.
The underlying cause of the ciliopathies may be a dysfunctional molecular mechanism in the primary cilia structures of the cell, organelles which are present in many cellular types throughout the human body. The cilia defects adversely affect "numerous critical developmental signaling pathways" essential to cellular development and thus offer a plausible hypothesis for the often multi-symptom nature of a large set of syndromes and diseases.
Currently recognized ciliopathies include Joubert syndrome, primary ciliary dyskinesia (also known as Kartagener Syndrome), Bardet-Biedl syndrome, polycystic kidney disease and polycystic liver disease, nephronophthisis, Alstrom syndrome, Meckel-Gruber syndrome and some forms of retinal degeneration.

</doc>
<doc id="56465" url="http://en.wikipedia.org/wiki?curid=56465" title="Cassava">
Cassava

Manihot esculenta, with common names cassava (), Brazilian arrowroot, manioc, and tapioca, a woody shrub of the Euphorbiaceae (spurge) family native to South America, is extensively cultivated as an annual crop in tropical and subtropical regions for its edible starchy tuberous root, a major source of carbohydrates. Though it is sometimes called yuca in Spanish, it differs from the yucca, an unrelated fruit-bearing shrub in the Asparagaceae family. Cassava, when dried to a powdery (or pearly) extract, is called tapioca; its fermented, flaky version is named garri.
Cassava is the third largest source of food carbohydrates in the tropics, after rice and maize. Cassava is a major staple food in the developing world, providing a basic diet for over half a billion people. It is one of the most drought-tolerant crops, capable of growing on marginal soils. Nigeria is the world's largest producer of cassava, while Thailand is the largest exporter of dried cassava.
Cassava is classified as sweet or bitter. Farmers often prefer the bitter varieties because they deter pests, animals, and thieves. Like other roots and tubers, both bitter and sweet varieties of cassava contain antinutritional factors and toxins. It must be properly prepared before consumption. Improper preparation of cassava can leave enough residual cyanide to cause acute cyanide intoxication and goiters, and may even cause ataxia or partial paralysis. The more toxic varieties of cassava are a fall-back resource (a "food security crop") in times of famine in some places.
Description.
The cassava root is long and tapered, with a firm, homogeneous flesh encased in a detachable rind, about 1 mm thick, rough and brown on the outside. Commercial varieties can be 5 to in diameter at the top, and around 15 to long. A woody vascular bundle runs along the root's axis. The flesh can be chalk-white or yellowish. Cassava roots are very rich in starch and contain significant amounts of calcium (50 mg/100g), phosphorus (40 mg/100g) and vitamin C (25 mg/100g). However, they are poor in protein and other nutrients. In contrast, cassava leaves are a good source of protein (rich in lysine) but deficient in the amino acid methionine and possibly tryptophan.
Vernacular names.
In the vernacular languages of the places where it is cultivated, cassava is called yuca (Spanish), mandi'o (Guaraní), mandioca (Spanish and Portuguese), aipim or macaxeira (Portuguese), manioka or maniota (Polynesian), balinghoy or kamoteng kahoy (in the Philippines), শিমলু আলু or "shimolu aalu" (Assamese), tabolchu (Garo), kuchik kilangu or maravallik kilangu (Tamil), akpụ (Igbo), rōgṑ (Hausa), mohogo (throughout Africa), and kappa (predominantly in India) and Muwogo in(Buganda Region of Uganda)
History.
Wild populations of "M. esculenta" subspecies "flabellifolia", shown to be the progenitor of domesticated cassava, are centered in west-central Brazil, where it was likely first domesticated more than 10,000 years BP. Forms of the modern domesticated species can also be found growing in the wild in the south of Brazil. By 4,600 BC, manioc pollen appears in the Gulf of Mexico lowlands, at the San Andrés archaeological site. The oldest direct evidence of cassava cultivation comes from a 1,400-year-old Maya site, Joya de Cerén, in El Salvador. With its high food potential, it had become a staple food of the native populations of northern South America, southern Mesoamerica, and the Caribbean by the time of the Spanish conquest. Its cultivation was continued by the colonial Portuguese and Spanish.
Cassava was a staple food for pre-Columbian peoples in the Americas and is often portrayed in indigenous art. The Moche people often depicted yuca in their ceramics.
Cassava was introduced to Africa by Portuguese traders from Brazil in the 16th century. Maize and cassava are now important staple foods, replacing native African crops. Cassava is sometimes described as the 'bread of the tropics' but should not be confused with the tropical and equatorial bread tree "(Encephalartos)", the breadfruit "(Artocarpus altilis)" or the African breadfruit "(Treculia africana)".
Economic importance.
World production of cassava root was estimated to be 184 million tonnes in 2002, rising to 230 million tonnes in 2008. The majority of production in 2002 was in Africa, where 99.1 million tonnes were grown; 51.5 million tonnes were grown in Asia; and 33.2 million tonnes in Latin America and the Caribbean. Nigeria is the world's largest producer of cassava. However, based on the statistics from the FAO of the United Nations, Thailand is the largest exporting country of dried cassava, with a total of 77% of world export in 2005. The second largest exporting country is Vietnam, with 13.6%, followed by Indonesia (5.8%) and Costa Rica (2.1%). Worldwide cassava production increased by 12.5% between 1988 and 1990.
In 2010, the average yield of cassava crops worldwide was 12.5 tonnes per hectare. The most productive cassava farms in the world were in India, with a nationwide average yield of 34.8 tonnes per hectare in 2010.
Cassava, yams ("Dioscorea" spp.) and sweet potatoes ("Ipomoea batatas") are important sources of food in the tropics. The cassava plant gives the third highest yield of carbohydrates per cultivated area among crop plants, after sugarcane and sugar beets. Cassava plays a particularly important role in agriculture in developing countries, especially in sub-Saharan Africa, because it does well on poor soils and with low rainfall, and because it is a perennial that can be harvested as required. Its wide harvesting window allows it to act as a famine reserve and is invaluable in managing labor schedules. It offers flexibility to resource-poor farmers because it serves as either a subsistence or a cash crop.
No continent depends as much on root and tuber crops in feeding its population as does Africa. In the humid and subhumid areas of tropical Africa, it is either a primary staple food or a secondary costaple. In Ghana, for example, cassava and yams occupy an important position the agricultural economy and contribute about 46% of the agricultural gross domestic product. Cassava accounts for a daily caloric intake of 30% in Ghana and is grown by nearly every farming family. The importance of cassava to many Africans is epitomised in the Ewe (a language spoken in Ghana, Togo and Benin) name for the plant, "agbeli", meaning "there is life". The price of cassava has risen significantly in the last half decade, and lower-income people have turned to other carbohydrate-rich foods, such as rice.
In Tamil Nadu, India, the National Highway 68 between Thalaivasal and Attur has many cassava processing factories alongside it—indicating a local abundance. Cassava is widely cultivated and eaten as a staple food in Andhra Pradesh and in Kerala besides being commonly cultivated and popular in Assam where it is an important source of carbohydrates specially for natives of hilly areas.
In the subtropical region of southern China, cassava is the fifth-largest crop in term of production, after rice, sweet potato, sugar cane and maize. China is also the largest export market for cassava produced in Vietnam and Thailand. Over 60% of cassava production in China is concentrated in a single province, Guangxi, averaging over 7 million tonnes annually.
Uses.
Alcoholic beverages.
Alcoholic beverages made from cassava include Cauim and tiquira (Brazil), kasiri (Sub-Saharan Africa), Impala (Mozambique) masato (Peruvian Amazonia chicha), parakari or kari (Guyana), nihamanchi (South America) aka nijimanche (Ecuador and Peru), ö döi (chicha de yuca, Ngäbe-Bugle, Panama), sakurá (Brazil, Surinam).
Culinary.
Cassava-based dishes are widely consumed wherever the plant is cultivated; some have regional, national, or ethnic importance. Cassava must be cooked properly to detoxify it before it is eaten.
Cassava can be cooked in many ways. The soft-boiled root of the sweet variety has a delicate flavor and can replace boiled potatoes in many uses: as an accompaniment for meat dishes or made into purées, dumplings, soups, stews, gravies, etc. This plant is used in cholent in some households, as well. Deep fried (after boiling or steaming), it can replace fried potatoes, bringing a distinctive flavor. It can be made into a flour that is used in breads, cakes and cookies. In Brazil, detoxified manioc is ground and cooked to a dry, often hard or crunchy meal known as "farinha" which is used as a condiment, toasted in butter, or eaten alone as a side dish.
Nutritional profile.
Cassava root is essentially a carbohydrate source. Its composition shows 60–65 percent moisture, 20–31 percent carbohydrate, 1–2 percent crude protein and a comparatively low content of vitamins and minerals. However, the roots are rich in calcium and vitamin C and contain a nutritionally significant quantity of thiamine, riboflavin and nicotinic acid. Cassava starch contains 70 percent amylopectin and 20 percent amylose. Cooked cassava starch has a digestibility of over 75 percent.
Cassava root is a poor source of protein. Despite the very low quantity, the quality of cassava root protein is fairly good in terms of essential amino acids. Methionine, cysteine and cystine are, however, limiting amino acids in cassava root.
Cassava is attractive as nutrition source in certain ecosystems because cassava is one of the most drought-tolerant crops, can be successfully grown on marginal soils, and gives reasonable yields where many other crops do not grow well. Cassava is well adapted within latitudes 30° north and south of the equator, at elevations between sea level and 2000 m above sea level, in equatorial temperatures, with rainfalls of 50 millimeters to 5 m annually, and to poor soils with a pH ranging from acidic to alkaline. These conditions are common in certain parts of Africa and South America.
Cassava is a highly productive crop in terms of food calories produced per unit land area per unit of time, significantly higher than other staple crops. Cassava can produce food calories at rates exceeding 250,000 cal/hectare/day compared with 176,000 for rice, 110,000 for wheat, and 200,000 for maize (corn).
Cassava, like other foods, also has antinutritional and toxic factors. Of particular concern are the cyanogenic glucosides of cassava (linamarin and lotaustralin). These, on hydrolysis, release hydrocyanic acid (HCN). The presence of cyanide in cassava is of concern for human and for animal consumption. The concentration of these antinutritional and unsafe glycosides varies considerably between varieties and also with climatic and cultural conditions. Selection of cassava species to be grown, therefore, is quite important. Once harvested, bitter cassava must be treated and prepared properly prior to human or animal consumption, while sweet cassava can be used after simple boiling.
Comparison with other major staple foods.
The following table shows the nutrient content of cassava and compares it with major staple foods in a raw form. Raw forms of these staples, however, are not edible and cannot be digested. These must be sprouted, or prepared and cooked as appropriate for human consumption. In sprouted or cooked form, the relative nutritional and antinutritional contents of each of these grains is remarkably different from that of raw form of these grains reported in this table. The nutrition value for each staple food in cooked form depends on the cooking method (boiling, baking, steaming, frying, etc.).
The table shows that cassava is a good energy source, but like potato, cassava's protein and essential nutrients density is lower than other staple foods.
Biofuel.
In many countries, significant research has begun to evaluate the use of cassava as an ethanol biofuel feedstock. Under the Development Plan for Renewable Energy in the Eleventh Five-Year Plan in the People's Republic of China, the target is to increase the application of ethanol fuel by nongrain feedstock to 2 million tonnes, and that of biodiesel to 200 thousand tonnes by 2010. This will be equivalent to a substitute of 10 million tonnes of petroleum. As a result, cassava (tapioca) chips have gradually become a major source for ethanol production. On December 22, 2007, the largest cassava ethanol fuel production facility was completed in Beihai, with annual output of 200 thousand tons, which would need an average of 1.5 million tons of cassava. In November 2008, China-based Hainan Yedao Group reportedly invested $51.5m (£31.8m) in a new biofuel facility that is expected to produce 33 e6USgal a year of bioethanol from cassava plants.
Animal feed.
Cassava tubers and hay are used worldwide as animal feed. Cassava hay is harvested at a young growth stage (three to four months) when it reaches about 30 to above ground; it is then sun-dried for one to two days until it has final dry matter content of less than 85%. Cassava hay contains high protein (20–27% crude protein) and condensed tannins (1.5–4% CP). It is valued as a good roughage source for ruminants such as dairy or beef cattle, buffalo, goats, and sheep, whether by direct feeding or as a protein source in concentrate mixtures.
Laundry starch.
Manioc is also used in a number of commercially-available laundry products, especially as starch for shirts and other garments. Using manioc starch diluted in water and spraying it over fabrics before ironing helps stiffen collars.
Medicinal use.
Cassava root has been promoted as a treatment for bladder and prostate cancer. However, according to the American Cancer Society, "there is no convincing scientific evidence that cassava or tapioca is effective in preventing or treating cancer".
Food use processing and toxicity.
Cassava roots,peels and leaves should not be consumed raw because they contain two cyanogenic glucosides, linamarin and lotaustralin. These are decomposed by linamarase, a naturally occurring enzyme in cassava, liberating hydrogen cyanide (HCN). Cassava varieties are often categorized as either sweet or bitter, signifying the absence or presence of toxic levels of cyanogenic glucosides, respectively. The so-called sweet (actually not bitter) cultivars can produce as little as 20 milligrams of cyanide (CN) per kilogram of fresh roots, whereas bitter ones may produce more than 50 times as much (1 g/kg). Cassavas grown during drought are especially high in these toxins. A dose of 25 mg of pure cassava cyanogenic glucoside, which contains 2.5 mg of cyanide, is sufficient to kill a rat. Excess cyanide residue from improper preparation is known to cause acute cyanide intoxication, and goiters, and has been linked to ataxia (a neurological disorder affecting the ability to walk, also known as "konzo"). It has also been linked to tropical calcific pancreatitis in humans, leading to chronic pancreatitis.
Societies that traditionally eat cassava generally understand some processing (soaking, cooking, fermentation, etc.) is necessary to avoid getting sick.
Symptoms of acute cyanide intoxication appear four or more hours after ingesting raw or poorly processed cassava: vertigo, vomiting, and collapse. In some cases, death may result within one or two hours. It can be treated easily with an injection of thiosulfate (which makes sulfur available for the patient's body to detoxify by converting the poisonous cyanide into thiocyanate).
"Chronic, low-level cyanide exposure is associated with the development of goiter and with tropical ataxic neuropathy, a nerve-damaging disorder that renders a person unsteady and uncoordinated. Severe cyanide poisoning, particularly during famines, is associated with outbreaks of a debilitating, irreversible paralytic disorder called konzo and, in some cases, death. The incidence of konzo and tropical ataxic neuropathy can be as high as 3% in some areas."
Brief soaking (four hours) of cassava is not sufficient, but soaking for 18–24 hours can remove up to half the level of cyanide. Drying may not be sufficient, either.
For some smaller-rooted, sweet varieties, cooking is sufficient to eliminate all toxicity. The cyanide is carried away in the processing water and the amounts produced in domestic consumption are too small to have environmental impact. The larger-rooted, bitter varieties used for production of flour or starch must be processed to remove the cyanogenic glucosides. The large roots are peeled and then ground into flour, which is then soaked in water, squeezed dry several times, and toasted. The starch grains that float to the surface during the soaking process are also used in cooking. The flour is used throughout South America and the Caribbean. Industrial production of cassava flour, even at the cottage level, may generate enough cyanide and cyanogenic glycosides in the effluents to have a severe environmental impact.
A safe processing method used by the pre-Columbian people of the Americas is to mix the cassava flour with water into a thick paste and then let it stand in the shade for five hours in a thin layer spread over a basket. In that time, about 83% of the cyanogenic glycosides are broken down by the linamarase; the resulting hydrogen cyanide escapes to the atmosphere, making the flour safe for consumption the same evening.
The traditional method used in West Africa is to peel the roots and put them into water for three days to ferment. The roots then are dried or cooked. In Nigeria and several other west African countries, including Ghana, Benin, Togo, Ivory Coast, and Burkina Faso, they are usually grated and lightly fried in palm oil to preserve them. The result is a foodstuff called "gari". Fermentation is also used in other places such as Indonesia (see Tapai). The fermentation process also reduces the level of antinutrients, making the cassava a more nutritious food.
The reliance on cassava as a food source and the resulting exposure to the goitrogenic effects of thiocyanate has been responsible for the endemic goiters seen in the Akoko area of southwestern Nigeria.
People dependent on cassava risk cyanide poisoning and malnutrition diseases such as kwashiorkor and endemic goiter.
A project called "BioCassava Plus" is developing a cassava with lower cyanogen glucosides and fortified with vitamin A, iron and protein to help the nutrition of people in sub-Saharan Africa. In 2011, the director of the program said he hoped to obtain regulatory approvals by 2017.
Farming.
Harvesting.
Cassava is harvested by hand by raising the lower part of the stem and pulling the roots out of the ground, then removing them from the base of the plant. The upper parts of the stems with the leaves are plucked off before harvest. Cassava is propagated by cutting the stem into sections of approximately 15 cm, these being planted prior to the wet season.
Postharvest handling and storage.
Cassava undergoes postharvest physiological deterioration, or PPD, once the tubers are separated from the main plant. The tubers, when damaged, normally respond with a healing mechanism. However, the same mechanism, which involves coumaric acids, initiates about 15 minutes after damage, and fails to switch off in harvested tubers. It continues until the entire tuber is oxidized and blackened within two to three days after harvest, rendering it unpalatable and useless. Recent work has indicated that PPD is related to the accumulation of reactive oxygen species (ROS)initiated by cyanide release during mechanical harvesting. Based on this research, cassava shelf life was increased to up to 2 weeks by overexpressing a cyanide insensitive alternative oxidase
PPD is one of the main obstacles currently preventing farmers from exporting cassavas abroad and generating income. Cassava can be preserved in various ways such as coating in wax or freezing.
The major cause of losses during cassava chip storage is infestation by insects. A wide range of species that feed directly on the dried chips have been reported as the cause of weight loss in the stored produce. Some loss assessment studies and estimations on dried cassava chips have been carried out in different countries. Hiranandan and Advani (1955) measured 12 - 14% post-harvest weight losses in India for chips stored for about five months. Killick (1966) estimated for Ghana that 19% of the harvest cassava roots are lost annually, and Nicol (1991) estimated a 15–20% loss of dried chips stored for eight months. Pattinson (1968) estimated for Tanzania a 12% weight loss of cassava chips stored for five months, and Hodges et al. (1985) assessed during a field survey postharvest losses of up to 19% after 3 months and up to 63% after four to five months due to the infestation of "Prostephanus truncatus" (Horn). In Togo, Stabrawa (1991) assessed postharvest weight losses of 5% after one month of storage and 15% after three months of storage due to insect infestation, and Compton (1991) assessed weight losses of about 9% for each store in the survey area in Togo. Wright et al. (1993) assessed postharvest losses of chips of about 14% after four months of storage, about 20% after seven months of storage and up to 30% when "P. truncatus" attacked the dried chips. In addition, Wright et al. (1993) estimated about 4% of the total national cassava production in Togo is lost during the chip storage. This was about equivalent to 0.05% of the GNP in 1989.
Plant breeding has resulted in cassava that is tolerant to PPD. Sánchez et al. identified four different sources of tolerance to PPD. One comes from Walker's Manihot ("M. walkerae") of southern Texas in the United States and Tamaulipas in Mexico. A second source was induced by mutagenic levels of gamma rays, which putatively silenced one of the genes involved in PPD genesis. A third source was a group of high-carotene clones. The antioxidant properties of carotenoids are postulated to protect the roots from PPD (basically an oxidative process). Finally, tolerance was also observed in a waxy-starch (amylose-free) mutant. This tolerance to PPD was thought to be cosegregated with the starch mutation, and is not a pleiotropic effect of the latter.
Pests.
In Africa, a previous issue of great significance was the cassava mealybug ("Phenacoccus manihoti") and cassava green mite ("Mononychellus tanajoa"). These pests can cause up to 80% crop loss, which is extremely detrimental to the production of subsistence farmers. These pests were rampant in the 1970s and 1980s but were brought under control following the establishment of the Biological Control Center for Africa of the IITA under the leadership of Dr. Hans Rudolf Herren. The Centre investigated biological control for cassava pests; two South American natural enemies "Apoanagyrus lopezi" (a parasitoid wasp) and "Typhlodromalus aripo" (a predatory mite) were found to effectively control the cassava mealybug and the cassava green mite, respectively.
The cassava mosaic virus causes the leaves of the cassava plant to wither, limiting the growth of the root. An outbreak of the virus in Africa in the 1920s led to a major famine. The virus is spread by the whitefly and by the transplanting of diseased plants into new fields. Sometime in the late 1980s, a mutation occurred in Uganda that made the virus even more harmful, causing the complete loss of leaves. This mutated virus has been spreading at a rate of 50 mi per year, and as of 2005 may be found throughout Uganda, Rwanda, Burundi, the Democratic Republic of the Congo and the Republic of the Congo.
Recently, brown streak disease has been identified as a major threat to cassava cultivation worldwide.
A wide range of plant parasitic nematodes have been reported associated with cassava worldwide. These include "Pratylenchus brachyurus"., "Rotylenchulus reniformis", "Helicotylenchus" spp., "Scutellonema" spp. and "Meloidogyne" spp., of which "Meloidogyne incognita" and "Meloidogyne javanica" are the most widely reported and economically important. "Meloidogyne" spp. feeding produces physically damaging galls with eggs inside them. Galls later merge as the females grow and enlarge, and they interfere with water and nutrient supply. Cassava roots become tough with age and restrict the movement of the juveniles and the egg release. It is therefore possible that extensive galling can be observed even at low densities following infection. Other pest and diseases can gain entry through the physical damage caused by gall formation, leading to rots. They have not been shown to cause direct damage to the enlarged storage roots, but plants can have reduced height if there was loss of enlarged root weight.
Research on nematode pests of cassava is still in the early stages; results on the response of cassava is, therefore, not consistent, ranging from negligible to seriously damaging. Since nematodes have such a seemingly erratic distribution in cassava agricultural fields, it is not easy to clearly define the level of direct damage attributed to nematodes and thereafter quantify the success of a chosen management method.
The use of nematicides has been found to result in lower numbers of galls per feeder root compared to a control, coupled with a lower number of rots in the storage roots. The nematicide Femaniphos, when used, did not affect crop growth and yield parameter variables measured at harvest. Nematicide use in cassava is neither practical nor sustainable; currently the use of tolerant and resistant varieties is the most practical and sustainable management method.

</doc>
<doc id="56466" url="http://en.wikipedia.org/wiki?curid=56466" title="Neurofibromatosis">
Neurofibromatosis

Neurofibromatosis (NF) refers to a number of inherited conditions that are clinically and genetically distinct and carry a high risk of tumor formation, particularly in the brain. Neurofibromatosis is an autosomal dominant disorder, which means only one copy of the affected gene is needed for the disorder to develop. Therefore, if only one parent has neurofibromatosis, his or her children have a 50% chance of developing the condition as well (it is rarely the case that one person has the mutated gene twice, which would imply a 100% chance of their children developing NF). The severity in affected individuals can vary; this may be due to variable expressivity. Approximately half of cases are due to "de novo" mutations and no other affected family members are seen. It affects males and females equally. In addition, some individuals may have "mosaic" NF, in which some but not all cells of the body carry the mutation. The neurofibromatoses are as follows:
Conditions which may be confused with NF-1 but which are not considered NF include:
The neurofibromatoses are considered as RASopathies and as members of the "neurocutaneous syndromes" ("phakomatoses"). In addition to the types of neurofibromatosis, the phakomatoses also include tuberous sclerosis, Sturge-Weber syndrome, and von Hippel-Lindau disease. This grouping is an artifact of an earlier time in medicine, before the distinct genetic basis of each of these diseases was understood.
Symptoms and Features.
 Symptoms of NF1, which may be evident at birth and nearly always by the time the child is 10 years old, may include light brown spots on the skin ("cafe-au-lait" spots), two or more growths on the iris of the eye, a tumor on the optic nerve, a larger than normal head circumference, and abnormal development of the spine, a skull bone, or the tibia. 
NF2 is less common and is characterized by slow-growing tumors on the eighth cranial nerves. The tumors cause pressure damage to neighboring nerves. [Diagnostic signs include] eighth nerve tumors, cataracts at an early age or changes in the retina that may affect vision, other nervous system tumors and similar signs and symptoms in a parent, sibling, or child. 
The distinctive feature of schwannomatosis is the development of multiple schwannomas (tumors made up of certain cells) everywhere in the body except on the vestibular branch of the 8th cranial nerve. The dominant symptom is pain, which develops as a schwannoma enlarges or compresses nerves or adjacent tissue. Some people may develop numbness, tingling, or weakness in the fingers and toes."
 — National Institute of Neurological Disorders and Stroke
Prognosis.
 In most cases, symptoms of NF1 are mild, and individuals live normal and productive lives. In some cases, however, NF1 can be severely debilitating and may cause cosmetic and psychological issues. The course of NF2 varies greatly among individuals. In some cases of NF2, the damage to nearby vital structures, such as other cranial nerves and the brain stem, can be life-threatening. Most individuals with schwannomatosis have significant pain. In some extreme cases the pain will be severe and disabling.
 — NINDS
Education.
Recently, non-profit and charitable organizations have started to bring awareness and education about Neurofibromatoses to mainstream media in order to better connect those afflicted with helpful resources to lead more productive and satisfying lives. Personalities with the condition, such as Reggie Bibbs, are becoming notable public figures around which others can rally to gain motivation and support.

</doc>
<doc id="56469" url="http://en.wikipedia.org/wiki?curid=56469" title="Pelizaeus–Merzbacher disease">
Pelizaeus–Merzbacher disease

Pelizaeus–Merzbacher disease (PMD) is a rare central nervous system disorder in which coordination, motor abilities, and intellectual function are delayed to variable extents.
Classification.
The disease is one in a group of genetic disorders collectively known as leukodystrophies that affect growth of the myelin sheath, the fatty covering—which acts as an insulator—on nerve fibers in the CNS. PMD is generally caused by a recessive mutation of the gene on the long arm of the X-chromosome (Xq21-22) that codes for a myelin protein called proteolipid protein 1 or PLP1. The majority of disease-causing mutations result in duplications of the entire PLP1 gene. There are several forms of Pelizaeus-Merzbacher disease including, classic, connatal, transitional, and adult variants. Interestingly, deletions at the PLP1 locus (which are rarer) cause a milder form of PMD than is observed with the typical duplication mutations, which demonstrates the critical importance of gene dosage at this locus for normal CNS function. Some of the remaining cases of PMD are accounted for by mutations in the gap junction A12 ("GJA12") gene, and are now called Pelizaeus-Merzbacher-like disease (PMLD). Other cases of apparent PMD do not have mutations in either the "PLP1" or "GJA12" genes, and are presumed to be caused either by mutations in other genes, or by mutations not detected by sequencing the "PLP1" gene exons and neighboring intronic regions of the gene. Among these is a new genetic disorder (discovered in 2003, 2004) which is caused by mutation in the transporter of thyroid hormone, MCT8, also known as SLC16A2, is believed to be account for a significant fraction of the undiagnosed neurological disorders (usually resulting in hypotonic/floppy infants with delayed milestones). This genetic defect was known as Allan-Herndon-Dudley syndrome (since 1944) without knowing its actual cause. Some of the signs for this disorder are as follows: normal to slightly elevated TSH, elevated T3 and reduced T4 (ratio of T3/T4 is about double its normal value). Normal looking at birth and for the first few years, hypotonic (floppy), in particular difficulty to hold the head, possibly difficulty to thrive, possibly with delayed myelination (if so, some cases are reported with an MRI pattern similar to Pelizaeus–Merzbacher disease, known as PMD,) possibly with decreased mitochondrial enzyme activities, possibly with fluctuating lactate level. Patients have an alert face, a limited IQ, patients may never talk/walk, 50% need feeding tube, patients have a normal life span. MCT8 can be ruled out with a simple TSH/T4/T3 thyroid test.
Milder mutations of the "PLP1" gene that mainly cause leg weakness and spasticity, with little or no cerebral involvement, are classified as spastic paraplegia 2 (SPG2). The onset of Pelizaeus–Merzbacher disease is usually in early infancy. The most characteristic early signs are nystagmus (rapid, involuntary, rhythmic motion of the eyes) and hypotonia (low muscle tone). Motor abilities are delayed or never acquired, mostly depending upon the severity of the mutation. Most children with PMD learn to understand language, and usually have some speech. Other signs may include tremor, lack of coordination, involuntary movements, weakness, unsteady gait, and over time, spasticity in legs and arms. Muscle contractures (shrinkage or shortening of a muscle) often occur over time. Mental functions may deteriorate. Some patients may have convulsions and skeletal deformation, such as scoliosis, resulting from abnormal muscular stress on bones.
Diagnosis.
The diagnosis of PMD is often first suggested after identification by magnetic resonance imaging (MRI) of abnormal white matter (high T2 signal intensity, i.e. T2 lengthening) throughout the brain, which is typically evident by about 1 year of age, but more subtle abnormalities should be evident during infancy. Unless there is a family history consistent with sex-linked inheritance, the condition is often misdiagnosed as cerebral palsy. Once a "PLP1" or "GJA12" mutation is identified, prenatal diagnosis or preimplantation genetic diagnostic testing is possible.
Treatment.
There is no cure for PMD, nor is there a standard course of treatment. Treatment, which is symptomatic and supportive, may include medication for seizures and spasticity. Regular evaluations by physical medicine and rehabilitation, orthopedic, developmental and neurologic specialists should be made to ensure optimal therapy and educational resources. The prognosis for those with Pelizaeus–Merzbacher disease is highly variable, with children with the most severe form (so-called connatal) usually not surviving to adolescence, but survival into the sixth or even seventh decades is possible, especially with attentive care. Genetic counseling should be provided to the family of a child with PMD.
In December 2008, StemCells Inc., a biotech company in Palo Alto, received clearance from the U.S. Food and Drug Administration (FDA) to conduct Phase I clinical trials in PMD to assess the safety of transplanting human neural stem cells as a potential treatment for PMD. The trial was initiated in November 2009 at the University of California, San Francisco (UCSF) Children's Hospital.

</doc>
<doc id="56470" url="http://en.wikipedia.org/wiki?curid=56470" title="Leopold I of Belgium">
Leopold I of Belgium

Leopold I (French: "Léopold Ier", German and Dutch: "Leopold I"; Coburg, 16 December 1790 – Laeken, 10 December 1865) was a German prince who became the first King of the Belgians following Belgian independence in 1830. He reigned between July 1831 and December 1865. He established the House of Saxe-Coburg and Gotha to which all subsequent Belgian Kings have belonged.
Born into the ruling family of the small Germany duchy of Saxe-Coburg-Saalfeld, Leopold took a commission in the Imperial Russian Army and fought against Napoleon after French troops overran Saxe-Coburg during the Napoleonic Wars. After Napoleon's defeat, Leopold moved to the United Kingdom where he married Princess Charlotte of Wales, the only child of the Prince Regent (the future King George IV), thus situating himself as a possible future prince consort of Great Britain. Charlotte died in 1817, although Leopold continued to enjoy considerable status in England.
After the Greek War of Independence (1821-32), Leopold was offered the position of King of Greece but turned it down, believing it to be too precarious. Instead, Leopold accepted the kingship of the newly-established Kingdom of Belgium in 1831. The Belgian government offered the position to Leopold because of his diplomatic connections with royal houses across Europe. In addition, because he was seen as a British-backed candidate, he was not affiliated to other powers, such as France, which were believed to have territorial ambitions in Belgium which might threaten the European balance of power created by the 1815 Congress of Vienna. 
Leopold was crowned in Belgium on 21 July 1831, an event commemorated annually as Belgian National Day. His reign was marked by attempts by the Dutch to recapture Belgium and, later, by internal political division between liberals and Catholics. As a Protestant, Leopold was considered liberal and encouraged economic modernisation, playing an important role in encouraging the creation of Belgium's first railway and in 1835 and subsequent industrialisation. As a result of the ambiguities in the Belgian Constitution, Leopold was able to slightly expand the monarch's powers during his reign. He also played an important role in stopping the spread of the Revolutions of 1848 into Belgium. He died in 1865 and was succeeded by his son, Leopold II.
Early life.
Leopold was born in Coburg in the tiny German duchy of Saxe-Coburg-Saalfeld in modern-day Bavaria on 16 December 1790. He was the youngest son of Francis, Duke of Saxe-Coburg-Saalfeld, and Countess Augusta Reuss-Ebersdorf. In 1826, Saxe-Coburg acquired the city of Gotha from the neighboring Duchy of Saxe-Gotha-Altenburg and gave up Saalfeld to Saxe-Meiningen, becoming Saxe-Coburg-Gotha.
Military career.
In 1795, at just five years old, Leopold was given an honorary commission of the rank of colonel in the "Izmaylovsky" Regiment, part of the Imperial Guard, in the Imperial Russian Army. Seven years later, he received a promotion to the rank of Major General.
When French troops occupied the Duchy of Saxe-Coburg in 1806 during the Napoleonic Wars, Leopold went to Paris where he became part of the Imperial Court of Napoleon. Napoleon offered him the position of adjutant, but Leopold refused. Instead, he went to Russia to take up a military career in the Imperial Russian cavalry, which was at war with France at the time. He campaigned against Napoleon and distinguished himself at the Battle of Kulm at the head of his "Cuirassier" division. In 1815, by the time of the final defeat of Napoleon and, aged 25, reached the rank of Lieutenant General.
Marriage to Charlotte.
Leopold received British citizenship in 1815. On 2 May 1816, Leopold married Princess Charlotte of Wales at Carlton House in London. Charlotte was the only legitimate child of the Prince Regent George (later King George IV) and therefore second in line to the British throne. The same year he received an honorary commission to the rank of Field Marshal and Knight of the Order of the Garter. On 5 November 1817, Princess Charlotte gave birth to a stillborn son. She herself died the following day following complications.
Had Charlotte survived, she would have become Queen of the United Kingdom on the death of her father and Leopold presumably would have assumed the role of prince consort, later taken by his nephew Prince Albert of Saxe-Coburg and Gotha. Despite Charlotte's death, the Prince Regent granted Prince Leopold the British style of "Royal Highness" by Order in Council on 6 April 1818.
From 1828 to 1829, Leopold had several-months long affair with the actress Caroline Bauer, who bore a striking resemblance to Charlotte. Caroline was a cousin of his advisor Christian Friedrich Freiherr von Stockmar. She came to England with her mother and took up residence at Longwood House, a few miles from Claremont House. But, by mid-1829, the liaison was over, and the actress and her mother returned to Berlin. Many years later, in memoirs published after her death, she declared that she and Leopold had engaged into a morganatic marriage and that he had bestowed upon her the title of Countess Montgomery. He would have broken this marriage when the possibility arose that he could become King of Greece. The son of Freiherr von Stockmar denied that these events ever happened, and indeed no records have been found of a civil or religious marriage with actress.
Refusal of the Greek throne.
Following the Greek rebellion against the Ottoman Empire, Leopold was offered the throne of Greece. Leopold, however, declined the offer, fearing that Greece was too politically unstable to remain a viable monarchy. The position was instead accepted by Otto of Wittelsbach in May 1832.
Acceptance of the Belgian throne.
Background.
At the end of August 1830, rebels in the Southern provinces (modern-day Belgium) of the United Netherlands rose up against Dutch rule. The rising, which began in Brussels, pushed the Dutch army back, and the rebels defended themselves against a Dutch attack. International powers meeting in London agreed to support the independence of Belgium, even though the Dutch refused to recognize the new state.
In November 1830, a National Congress was established in Belgium to create a constitution for the new state. Fears of "mob rule" associated with republicanism after the French Revolution of 1789, as well as the example of the recent, liberal July Revolution in France, led the Congress to decide that Belgium would be a popular, constitutional monarchy.
Search for a monarch.
The choice of candidates for the position was one of the most controversial issues faced by the revolutionaries. The Congress refused to consider any candidate from the Dutch ruling house of Orange-Nassau. Some Orangists had hoped to offer the position to King William I or his son, William, Prince of Orange, which would bring Belgium into personal union with the Netherlands like Luxembourg. The Great Powers also worried that a candidate from another state could risk destabilizing the international balance of power and lobbied for a neutral candidate. 
Eventually the Congress was able to draw up a shortlist. The three viable possibilities were felt to be Eugène de Beauharnais, a French nobleman and stepson of Napoleon; Auguste of Leuchtenberg, son of Eugene; and Louis, Duke of Nemours who was the son of the French King Louis-Philippe. All the candidates were French and the choice between them was principally between choosing the Bonapartism of Beauharnais or Leuchtenberg and supporting the July Monarchy of Louis-Philippe. Louis-Philippe realized that the choice of either of the Bonapartists could be first stage of a coup against him, but that his son would also be unacceptable to other European powers suspicious of French intentions. Nemours refused the offer. With no definitive choice in sight, Catholics and Liberals united to elect Erasme Louis Surlet de Chokier, a minor Belgian nobleman, as regent to buy more time for a definitive decision in February 1831.
Leopold of Saxe-Coburg had been proposed at an early stage, but had been dropped because of French opposition. The problems caused by the French candidates and the increased international pressure for a solution led to his reconsideration. On 22 April, he was finally approached by a Belgian delegation at Marlborough House to officially offer him the throne. Leopold, however, was reluctant to accept.
Coronation.
On 17 July 1831, Leopold travelled from Calais to Belgium, entering the country at De Panne. Travelling to Brussels, he was greeted with patriotic enthusiasm along his route. The coronation took place on 21 July on the Place Royale in Brussels. A stand had been erected on the steps of the church of Saint Jacques-sur-Coudenberg, surrounded by the names of revolutionaries fallen during the fighting in 1830. After a ceremony of resignation by the regent, Leopold, dressed in the uniform of a Belgian lieutenant-general, swore loyalty to the constitution and became King.
The coronation is generally used to mark end of the revolution and the start of the Kingdom of Belgium and is celebrated each year as the Belgian national holiday.
Reign.
Consolidation of independence.
Less than two weeks after Leopold's coronation, on 2 August, the Netherlands invaded Belgium, starting the Ten Days' Campaign. The small Belgian army was overwhelmed by the Dutch assault and was pushed back. Faced with a military crisis, Leopold appealed to the French for support. The French promised support, and the arrival of their "Armée du Nord" in Belgium forced the Dutch to accept a diplomatic mediation and retreat back to the pre-war border. Skirmishes continued for eight years, but in 1839, the two countries signed the Treaty of London establishing Belgium's independence.
Leopold was generally unsatisfied with the amount of power allocated to the monarch in the Constitution, and sought to extend it wherever the Constitution was ambiguous or unclear while generally avoiding involvement in routine politics.
Subsequent reign.
Leopold I's reign was also marked by an economic crisis which lasted until the late 1850s. In the aftermath of the revolution, the Dutch had closed the Scheldt to Belgian shipping, meaning that the port of Antwerp was effectively useless. The Netherlands and the Dutch colonies in particular, which had been profitable markets for Belgian manufacturers before 1830, were totally closed to Belgian goods. The period between 1845 and 1849 was particularly hard in Flanders, where harvests failed and a third of the population became dependent on poor relief, and have been described as the "worst years of Flemish history". The economic situation in Flanders also increased the internal migration to Brussels and the industrial areas of Wallonia, which continued throughout the period.
Politics in Belgium under Leopold I were polarized between liberal and Catholic political factions, though before 1847 they collaborated in "Unionist" governments. The liberals were opposed to the Church's influence in politics and society, while supporting free trade, personal liberties and secularization. The Catholics wanted religious teachings to be a fundamental basis for the state and society and opposed all attempts by the liberals to attack the Church's official privileges. Initially, these factions existed only as informal groups with which prominent politicians were generally identified. The liberals held power through much of Leopold I's reign. An official Liberal Party was formed in 1846, although a formal Catholic Party was only established in 1869. Leopold, who was himself a Protestant, tended to favor liberals and shared their desire for reform, even though he was not partisan. On his own initiative, in 1842, Leopold proposed a law which would have stopped women and children from working in some industries, but the bill was defeated. Leopold was an early supporter of railways, and Belgium's first stretch of this railway, between northern Brussels and Mechelen, was completed in 1835. When completed, it was one of the first passenger railways in continental Europe.
Revolution of 1848.
The success of economic reforms partially mitigated the effects of the economic downturn and meant that Belgium was not as badly affected as its neighbors by the Revolutions of 1848. Nevertheless, in early 1848, a large number of radical publications appeared. The most serious threat of the 1848 revolutions in Belgium was posed by Belgian émigré groups. Shortly after the revolution in France, Belgian migrant workers living in Paris were encouraged to return to Belgium to overthrow the monarchy and establish a republic. Around 6,000 armed émigrés of the "Belgian Legion" attempted to cross the Belgian frontier. The first group, travelling by train, was stopped and quickly disarmed at Quiévrain on 26 March 1848. The second group crossed the border on 29 March and headed for Brussels. They were confronted by Belgian troops at the hamlet of Risquons-Tout and, during fighting, seven émigrés were killed and most of the rest were captured. To defuse tension, Leopold theatrically offered his resignation if this was the wish of the majority of his people.
The defeat at Risquons-Tout effectively ended the revolutionary threat to Belgium, as the situation in Belgium began to recover that summer after a good harvest, and fresh elections returned a strong Liberal majority.
Role in international relations.
Because of his family connections and position at the head of a neutral and unthreatening power, Leopold acted as an important intermediary in European politics during his reign. Leopold played a particularly important role in moderating relations between the Great Powers and in particular between Great Britain and the French Empire under Napoleon III.
In 1840, Leopold arranged the marriage of his niece, Queen Victoria, the daughter of his sister, to his nephew, Prince Albert of Saxe-Coburg and Gotha, son of his brother. Even before she succeeded to the throne, Leopold had been advising Victoria by letter, and after her accession, continued to influence her.
In foreign policy, Leopold's principal object was the maintenance of Belgian neutrality, which he advocated despite pressure until after the Crimean War.
Second marriage and family.
In 1832, Leopold married his second wife, Louise-Marie of Orléans. Louise-Marie was the daughter of Louis Philippe I, the King of the French, enstated in 1830. Leopold and Louise-Marie had four children; the eldest, Louis Philippe, died in 1834 and Leopold (the future King Leopold II) became Crown Prince. Their third son was Philippe, the father of Belgium's third king, Albert I. Their youngest child was Charlotte, who would later marry Emperor Maximilian I.
On 11 October 1850, Queen Louise-Marie died of tuberculosis, aged 38. Leopold also had two sons, George and Arthur, by a mistress, Arcadie Meyer (née Claret). George was born in 1849, and Arthur was born in 1852. At Leopold's request, in 1862 the two sons were created Freiherr von Eppinghoven by his nephew, Ernest II, Duke of Saxe-Coburg and Gotha; in 1863 Arcadie was also created Baronin von Eppinghoven.
Death and commemoration.
Leopold died in Laeken near Brussels on 10 December 1865, aged 74. He is buried in the Royal Vault at the Church of "Notre-Dame de Laeken", next to Louise-Marie. He was succeeded by his son, Leopold II, aged 30, who would rule until 1909.
A number of Belgian naval vessels have been named in his honour, including current frigate "Leopold I". His monograph features on the flag of the Flemish town of Leopoldsburg. He has also featured on postage stamps and commemorative coins issued since his death.
In the 2009 film "The Young Victoria", directed by Jean-Marc Vallée, Leopold was played by Thomas Kretschmann.
Notes.
Bibliography.
</dl>

</doc>
<doc id="56472" url="http://en.wikipedia.org/wiki?curid=56472" title="Benjamin Netanyahu">
Benjamin Netanyahu

Benjamin (Binyamin) "Bibi" Netanyahu (Hebrew:   ; born 21 October 1949) is the current Prime Minister of Israel. He also currently serves as a member of the Knesset, Chairman of the Likud party and Minister of Public Diplomacy and Diaspora Affairs.
Born in Tel Aviv to secular Jewish parents, Netanyahu is the first Israeli prime minister born in Israel after the establishment of the state. Netanyahu joined the Israel Defense Forces during the Six-Day War in 1967 and became a team leader in the Sayeret Matkal special forces unit. He took part in many missions, including Operation Inferno (1968), Operation Gift (1968) and Operation Isotope (1972), during which he was shot in the shoulder. He fought on the front lines in the War of Attrition and the Yom Kippur War in 1973, taking part in special forces raids along the Suez Canal, and then leading a commando assault deep into Syrian territory. He achieved the rank of captain before being discharged. After graduating from MIT with S.B. and S.M. degrees, he was recruited as an economic consultant for the Boston Consulting Group. He returned to Israel in 1978 to found the Yonatan Netanyahu Anti-Terror Institute, named after his brother Yonatan Netanyahu, who died leading Operation Entebbe. Netanyahu served as the Israeli ambassador to the United Nations from 1984 to 1988.
Netanyahu became the leader of Likud in 1993. Netanyahu won the 1996 elections, becoming Israel's youngest ever Prime Minister, serving his first term from June 1996 to July 1999. He moved from the political arena to the private sector after being defeated in the 1999 election for Prime Minister by Ehud Barak. Netanyahu returned to politics in 2002 as Foreign Affairs Minister (2002–2003) and Finance Minister (2003–2005) in Ariel Sharon's governments, but he departed the government over disagreements regarding the Gaza disengagement plan. As Minister of Finance, Netanyahu engaged in a major reform of the Israeli economy, which was credited by commentators as having significantly improved Israel's subsequent economic performance. He retook the Likud leadership in December 2005, after Sharon left to form a new party, Kadima. In December 2006, Netanyahu became the official Leader of the Opposition in the Knesset and Chairman of Likud. Following the 2009 parliamentary election, in which Likud placed second and right-wing parties won a majority, Netanyahu formed a coalition government. After the victory in the 2013 elections, he became the second person to be elected to the position of Prime Minister for a third term, after Israel's founder David Ben-Gurion. In March 2015, Netanyahu was elected to his fourth term as Prime Minister.
Netanyahu has been elected Prime Minister of Israel four times, matching David Ben-Gurion's record. He is the only Prime Minister in Israel's history to have been elected three-times in a row. He is currently the second longest-serving Prime Minister in Israel's history after David Ben-Gurion, and if he completes his current term he will become the longest-serving Prime Minister in the history of Israel.
Biography.
Early life and career.
Netanyahu was born in 1949 in Tel Aviv, to Tzila Segal (28 August 1912 – 31 January 2000) and Prof. Benzion Netanyahu (1910–2012), the middle of three children. He was initially raised and educated in Jerusalem, where he attended Henrietta Szold Elementary School. A copy of his evaluation from his 6th grade teacher Ruth Rubenstein indicated that Netanyahu was courteous, polite, helpful, his work was "responsible and punctual", and that Netanyahu was friendly, disciplined, cheerful, brave, active and obedient.
Between 1956 and 1958, and again from 1963 to 1967, his family lived in the United States in Cheltenham Township, Pennsylvania, a suburb of Philadelphia, where he attended and graduated from Cheltenham High School and was active in a debate club. To this day, he speaks fluent English, with a noticeable Philadelphia accent.
After graduating from high school in 1967, Netanyahu returned to Israel to enlist in the IDF. He trained as a combat soldier and served for five years in an elite special forces unit of the IDF, Sayeret Matkal. He took part in numerous cross-border assault raids during the 1967–70 War of Attrition, rising to become a team-leader in the unit. He was wounded in combat on multiple occasions. He was involved in many other missions, including Operation Inferno (1968), and the rescue of the hijacked Sabena Flight 571 in May 1972 in which he was shot in the shoulder.
After completing his army service in 1972, Netanyahu returned to the United States in late 1972 to study architecture at the Massachusetts Institute of Technology. He returned to Israel in October 1973 to serve in the Yom Kippur War in the Sayeret Matkal commando unit. While there, he fought in special forces raids along the Suez Canal against the Egyptian forces, before leading a commando attack deep inside Syrian territory, whose mission remains classified today. 
"I have great respect for the unit. This is a unit that changes the reality of our lives even though its actions are a secret. Although it is a small unit, it influences all branches of the military... My service in the unit strengthened my understanding of the risks involved behind approving operations and the risks that fighters are taking on. It is tangible and not theoretical for me."
Benjamin Netanyahu, on Sayeret Matkal, ("Maariv" 2007)
He then returned to the United States and completed an S.B. degree in architecture in February 1975 and earned an S.M. degree from the MIT Sloan School of Management in 1977. Concurrently, he was studying towards a doctorate in political science at Harvard University, until his studies were broken off by the death of his brother in Operation Entebbe.
At MIT, Netanyahu studied a double-load, completing a S.M. (that would normally take 4 years) in only 2 1/2 years, despite taking a break to fight in the Yom Kippur War, and while simultaneously completing a thesis in a graduate course at Harvard. Professor Groisser at MIT recalled: "He did superbly. He was very bright. Organized. Strong. Powerful. He knew what he wanted to do and how to get it done."
At that time he changed his name to Benjamin Ben Nitai (Nitai, a reference to both Mount Nitai and to the eponymous Jewish sage Nittai of Arbela, was a pen name often used by his father for articles). Years later, in an interview with the media, Netanyahu clarified that he decided to do so to make it easier for Americans to pronounce his name. This fact has been used by his political rivals to accuse him indirectly of a lack of Israeli national identity and loyalty.
In 1976 Netanyahu lost his older brother Yonatan Netanyahu. Yonatan was serving as the commander of Benjamin's former unit, the Sayeret Matkal, and was killed in action during the counter-terrorism hostage-rescue mission Operation Entebbe in which his unit rescued more than 100 Israeli hostages hijacked by terrorists and flown to the Entebbe Airport in Uganda.
In 1976 Netanyahu graduated near the top of his class at the MIT Sloan School of Management, and was headhunted to be an economic consultant for the Boston Consulting Group in Boston, Massachusetts, working at the company between 1976 and 1978. At the Boston Consulting Group, he was a colleague of Mitt Romney, with whom he formed a lasting friendship. Romney remembers that Netanyahu at the time was: "[A] strong personality with a distinct point of view", and says "[w]e can almost speak in shorthand... [w]e share common experiences and have a perspective and underpinning which is similar." Netanyahu said that their “easy communication” was a result of “B.C.G.’s intellectually rigorous boot camp.”
In 1978, Netanyahu appeared on Boston local television, under the name of 'Ben Nitai', where he argued: "The real core of the conflict is the unfortunate Arab refusal to accept the State of Israel... For 20 years the Arabs had both the West Bank and the Gaza Strip, and if self-determination, as they now say, is the core of the conflict, they could have easily established a Palestinian state."
In 1978, Netanyahu returned to Israel. Between 1978 and 1980 he ran the Jonathan Netanyahu Anti-Terror Institute, a non-governmental organization devoted to the study of terrorism; the Institute held a number of international conferences focused on the discussion of international terrorism. From 1980 to 1982 he was director of marketing for Rim Industries in Jerusalem. During this period Netanyahu made his first connections with several Israeli politicians, including Minister Moshe Arens, who appointed him as his Deputy Chief of Mission at the Israeli Embassy in Washington, D.C., a position he held from 1982 until 1984. Between 1984 and 1988 Netanyahu served as the Israeli ambassador to the United Nations. Netanyahu was influenced by Rabbi Menachem M. Schneerson, with whom he formed a relationship during the 1980s. He referred to Schneerson as "the most influential man of our time."
Early political career: 1988–1996.
Prior to the 1988 Israeli legislative election Netanyahu returned to Israel and joined the Likud party. In the Likud's internal elections, Netanyahu was placed fifth on the party list. Later on he was elected as a Knesset member of the 12th Knesset, and was appointed as a deputy of the foreign minister Moshe Arens, and later on David Levy. Netanyahu and Levy did not cooperate and the rivalry between the two only intensified afterwards. During the Madrid Conference of 1991 Netanyahu was among members the Israeli delegation headed by Prime Minister Yitzhak Shamir. After the Madrid Conference Netanyahu was appointed as Deputy Minister in the Israeli Prime Minister's Office.
Following the defeat of the Likud party in the 1992 Israeli legislative elections the Likud party held a primary election in 1993 to select its leader, and Netanyahu was victorious, defeating Benny Begin, son of the late Prime Minister Menachem Begin, and veteran politician David Levy (Sharon initially sought Likud party leadership as well, but quickly withdrew when it was evident that he was attracting minimal support). Shamir retired from politics shortly after the Likud's defeat in the 1992 elections.
Following the assassination of Yitzhak Rabin, his temporary successor Shimon Peres decided to call early elections in order to give the government a mandate to advance the peace process. Netanyahu was the Likud's candidate for Prime Minister in the 1996 Israeli legislative election which took place on 26 May 1996 and were the first Israeli elections in which Israelis elected their Prime Minister directly. Netanyahu hired American Republican political operative Arthur Finkelstein to run his campaign, and although the American style of sound bites and sharp attacks elicited harsh criticism from inside Israel, it proved effective (the method was later copied by Ehud Barak during the 1999 election campaign in which Barak beat Netanyahu). When Netanyahu won the 1996 election, he became the youngest person in the history of the position and the first Israeli Prime Minister to be born in the State of Israel (Yitzhak Rabin was born in Jerusalem, under the British Mandate of Palestine, prior to the 1948 founding of the Israeli state).
Netanyahu's victory over the pre-election favorite Shimon Peres surprised many. The main catalyst in the downfall of the latter was a wave of suicide bombings shortly before the elections; on 3 and 4 March 1996, Palestinians carried out two suicide bombings, killing 32 Israelis, with Peres seemingly unable to stop the attacks. Unlike Peres, Netanyahu did not trust Yasser Arafat and conditioned any progress at the peace process on the Palestinian National Authority fulfilling its obligations – mainly fighting terrorism, and ran with the campaign slogan "Netanyahu – making a safe peace". However, although Netanyahu won the election for Prime Minister, Labor won the Knesset elections, beating the Likud–Gesher–Tzomet alliance, meaning Netanyahu had to rely on a coalition with the ultra-Orthodox parties, Shas and UTJ (whose social welfare policies flew in the face of his capitalistic outlook) in order to govern.
First Premiership: 1996–1999.
A spate of suicide bombings reinforced the Likud position for security. Hamas claimed responsibility for most of the bombings. As Prime Minister Netanyahu raised many questions about many central premises of the Oslo peace process. One of his main points was disagreement with the Oslo premise that the negotiations should proceed in stages, meaning that concessions should be made to Palestinians before any resolution was reached on major issues, such as the status of Jerusalem, and the amending of the Palestinian National Charter. Oslo supporters had claimed that the multi-stage approach would build goodwill among Palestinians and would propel them to seek reconciliation when these major issues were raised in later stages. Netanyahu said that these concessions only gave encouragement to extremist elements, without receiving any tangible gestures in return. He called for tangible gestures of Palestinian goodwill in return for Israeli concessions. Despite his stated differences with the Oslo Accords, Prime Minister Netanyahu continued their implementation, but his Premiership saw a marked slow-down in the Peace Process.
In 1996, Netanyahu and Jerusalem's mayor Ehud Olmert decided to open an exit in the Arab Quarter for the Western Wall Tunnel, which prior Prime Minister Shimon Peres had instructed to be put on hold for the sake of peace. This sparked three days of rioting by Palestinians, resulting in both Israelis and Palestinians being killed. In January 1997 Netanyahu signed the Hebron Protocol with the Palestinian Authority which resulted in the redeployment of Israeli forces in Hebron and the turnover of civilian authority in much of the area to the Palestinian Authority.
Eventually, the lack of progress of the peace process led to new negotiations which produced the Wye River Memorandum in 1998 which detailed the steps to be taken by the Israeli government and Palestinian Authority to implement the earlier Interim Agreement of 1995. It was signed by Netanyahu and PLO Chairman Yasser Arafat, and on 17 November 1998, Israel's 120 member parliament, the Knesset, approved the Wye River Memorandum by a vote of 75–19. As Prime Minister Netanyahu emphasized a policy of "three no(s)": no withdrawal from the Golan Heights, no discussion of the case of Jerusalem, no negotiations under any preconditions.
During his term, Netanyahu also began a process of economic liberalization, taking steps towards a free-market economy. Under his watch, the government began selling its shares in banks and major state-run companies. Netanyahu also abolished all of Israel's strict foreign exchange controls, enabling Israelis to take an unrestricted amount of money out of the country, open foreign bank accounts, hold foreign currency, and invest freely in other countries.
Throughout his term, Netanyahu was opposed by the political left wing in Israel and lost support from the right because of his concessions to the Palestinians in Hebron and elsewhere, and due to his negotiations with Arafat generally. Netanyahu lost favor with the Israeli public after a long chain of scandals involving his marriage and corruption charges. In 1997, police recommended that Netanyahu be indicted on corruption charges for influence-peddling. He was accused of appointing an attorney general who would reduce the charges and prosecutors ruled that there was insufficient evidence to go to trial. In 1999, Netanyahu faced another scandal when the Israel Police recommended that he be tried for corruption for $100,000 in free services from a government contractor; Israel's attorney general did not prosecute, citing difficulties with evidence.
After being defeated by Ehud Barak in the 1999 election for Prime Minister, Netanyahu temporarily retired from politics. He subsequently served as a senior consultant with Israeli communications equipment developer BATM for two years.
Political downturn and recovery: 2000–2003.
With the fall of the Barak government in late 2000, Netanyahu expressed his desire to return to politics. By law, Barak's resignation was supposed to lead to elections for the prime minister position only. Netanyahu insisted that general elections should be held, claiming that otherwise it would be impossible to have a stable government. Netanyahu decided eventually not to run for the prime minister position, a move which facilitated the surprising rise to power of Ariel Sharon, who at the time was considered less popular than Netanyahu. In 2002, after the Israeli Labor Party left the coalition and vacated the position of foreign minister, Prime Minister Ariel Sharon appointed Netanyahu as Foreign Minister. Netanyahu challenged Sharon for the leadership of the Likud party, but failed to oust Sharon.
On 9 September 2002, a scheduled speech by Netanyahu at Concordia University in Montreal, Quebec, Canada was canceled after hundreds of pro-Palestinian protesters overwhelmed security and smashed through a glass window. Netanyahu was not present at the protest, having remained at Montreal's Ritz-Carlton Hotel throughout the duration. He later accused the activists of supporting terrorism and "mad zealotry." Weeks later on 1 October 2002 around 200 protesters met Netanyahu outside his Heinz Hall appearance in Pittsburgh although Pittsburgh Police, Israeli security and a Pittsburgh SWAT unit allowed his speeches to continue downtown at the hall and the Duquesne Club as well as suburban Robert Morris University.
On 12 September 2002, Netanyahu testified (under oath as a private citizen) before the U.S. House of Representatives Committee on Oversight and Government Reform regarding the nuclear threat posed by the Iraqi régime: "There is no question whatsoever that Saddam is seeking and is working and is advancing towards the development of nuclear weapons – no question whatsoever,” he said. “And there is no question that once he acquires it, history shifts immediately.” Netanyahu and other high rank officials from different countries had suspected that Iraq could develop a nuclear capability, as the country began building a nuclear power plant program in 1959 with the USSR, but Israeli airstrikes had destroyed Iraq's nuclear reactor in 1981 (see Operation Opera).
Finance Minister: 2003–2005.
After the 2003 Israeli legislative election, in what many observers regarded as a surprise move, Sharon offered the Foreign Ministry to Silvan Shalom and offered Netanyahu the Finance Ministry. Some pundits speculated that Sharon made the move because he deemed Netanyahu a political threat given his demonstrated effectiveness as Foreign Minister, and that by placing him in the Finance Ministry during a time of economic uncertainty, he could diminish Netanyahu's popularity. Netanyahu accepted the new appointment after Sharon agreed to provide him with an unprecedented level of independence in running the ministry.
As Finance Minister, Netanyahu undertook an economic plan in order to restore Israel's economy from its low point during the Second Intifada. The plan involved a move toward more liberalized markets, although it was not without its critics. Netanyahu succeeded in passing several long-unresolved reforms, including an important reform in the banking system. However, opponents in the Labor party (and even a few within his own Likud) viewed Netanyahu's policies as "Thatcherite" attacks on the venerated Israeli social safety net.
As Minister of Finance, Netanyahu engaged in a major reform of the Israeli economy. He instituted a program to end welfare dependency by requiring people to apply for jobs or training. He reduced the size of the public sector, reformed and streamlined the taxation system and attacked monopolies and cartels to increase competition. As the Israeli economy started booming and unemployment fell significantly, Netanyahu was widely credited by commentators as having performed an 'economic miracle' by the end of his tenure.
Netanyahu threatened to resign from office in 2004 unless the Gaza pullout plan was put to a referendum. He later modified the ultimatum and voted for the program in the Knesset, indicating immediately thereafter that he would resign unless a referendum was held within 14 days. He submitted his resignation letter on 7 August 2005, shortly before the Israeli cabinet voted 17 to 5 to approve the initial phase of withdrawal from Gaza.
Likud leader and opposition leader: 2005–2009.
Following the withdrawal of Sharon from the Likud, Netanyahu was one of several candidates who vied for the Likud leadership. His most recent attempt prior to this was in September 2005 when he had tried to hold early primaries for the position of the head of the Likud party, while the party held the office of Prime Minister – thus effectively pushing Ariel Sharon out of office. The party rejected this initiative. Netanyahu retook the leadership on 20 December 2005, with 47% of the primary vote, to 32% for Silvan Shalom and 15% for Moshe Feiglin. In the March 2006 Knesset elections, Likud took the third place behind Kadima and Labor and Netanyahu served as Leader of the Opposition. On 14 August 2007, Netanyahu was reelected as chairman of the Likud and its candidate for the post of Prime Minister with 73% of the vote, against far-right candidate Moshe Feiglin and World Likud Chairman Danny Danon. He opposed the 2008 Israel–Hamas ceasefire, like others in the Knesset opposition. Specifically, Netanyahu said, "This is not a relaxation, it's an Israeli agreement to the rearming of Hamas ... What are we getting for this?"
In the first half of 2008, doctors removed a small colon polyp that proved to be benign.
Following Livni's election to head Kadima and Olmert's resignation from the post of Prime Minister, Netanyahu declined to join the coalition Livni was trying to form and supported new elections, which were held in February 2009. Netanyahu was the Likud's candidate for Prime Minister in the 2009 Israeli legislative election which took place on 10 February 2009, as Tzipi Livni, the previous Designated Acting Prime Minister under the Olmert government, had been unable to form a viable governing coalition. Opinion polls showed Likud in the lead, but with as many as a third of Israeli voters undecided.
In the election itself, Likud won the second highest number of seats, Livni's party having outnumbered the Likud by one seat. A possible explanation for Likud's relatively poor showing is that some Likud supporters defected to Avigdor Lieberman's Yisrael Beiteinu party. Netanyahu, however, claimed victory on the basis that right wing parties won the majority of the vote, and on 20 February 2009, Netanyahu was designated by Israeli President Shimon Peres to succeed Ehud Olmert as Prime Minister, and began his negotiations to form a coalition government.
Despite right wing parties winning a majority of 65 seats in the Knesset, Netanyahu preferred a broader centrist coalition and turned to his Kadima rivals, chaired by Tzipi Livni, to join his government. This time it was Livni's turn to decline to join, with a difference of opinion on how to pursue the peace process being the stumbling block. Netanyahu did manage to entice a smaller rival, the Labour party, chaired by Ehud Barak, to join his government, giving him a certain amount of centrist tone. Netanyahu presented his cabinet for a Knesset "Vote of Confidence" on 31 March 2009. The 32nd Government was approved that day by a majority of 69 lawmakers to 45 (with five abstaining) and the members were sworn in.
Second Premiership: 2009–2013.
In 2009, US Secretary of State Hillary Rodham Clinton voiced support for the establishment of a Palestinian state—a solution not endorsed by Prime Minister-designate Benjamin Netanyahu, with whom she had earlier pledged the United States' cooperation. Upon the arrival of President Obama administration's special envoy, George Mitchell, Netanyahu said that any furtherance of negotiations with the Palestinians would be conditioned on the Palestinians recognizing Israel as a Jewish state. US President Barack Obama told Netanyahu that a two state solution was a priority and called for settlement growth to be frozen, while Netanyahu refused to support the creation of a Palestinian state and stated that Israel has the right to continue settlements.
During President Obama's Cairo speech on 4 June 2009 in which Obama addressed the Muslim world, Obama stated, among other things, that "The United States does not accept the legitimacy of continued Israeli settlements." Following Obama's Cairo speech Netanyahu immediately called a special government meeting. On 14 June, ten days after Obama's Cairo speech, Netanyahu gave a speech at Bar-Ilan University in which he endorsed a "Demilitarized Palestinian State", though said that Jerusalem must remain the unified capital of Israel. Netanyahu stated that he would accept a Palestinian state if Jerusalem were to remain the united capital of Israel, the Palestinians would have no army, and the Palestinians would give up their demand for a right of return. He also argued the right for a "natural growth" in the existing Jewish settlements in the West Bank while their permanent status is up to further negotiation. Senior Palestinian official, Sereb Ereket, said that the speech had "closed the door to permanent status negotiations" due to Netanyahu's declarations on Jerusalem, refugees and settlements.
Three months after starting his term, Netanyahu remarked that his cabinet already had achieved several notable successes, such as the establishment of a working national unity government, and a broad consensus for a "Two-state solution". A July 2009 survey by Ha'aretz found that most Israelis support the Netanyahu government, giving him a personal approval rating of about 49 percent. Netanyahu has lifted checkpoints in the West Bank in order to allow freedom of movement and a flow of imports; a step that resulted in an economic boost in the West Bank. In 2009, Netanyahu welcomed the Arab Peace initiative (also known as the "Saudi Peace Initiative") and lauded a call by Bahrain's Crown Prince Salman bin Hamad bin Isa Al Khalifa to normalize relations with Israel.
In August 2009, Abbas declared that he would be willing to meet with Prime Minister Netanyahu at the UN General Assembly, where Netanyahu had accepted president Obama's invitation for a "triple summit," although he said it would not necessarily lead to negotiations. Netanyahu was reported to be in a pivotal moment over these understandings, that were reported to include a compromise over permission on continuing the already approved construction in the West Bank in exchange for freezing all settlements thereafter, as well as continuing building in East Jerusalem, and at the same time stopping the demolition of houses of Arab inhabitants there. On 4 September 2009, it was reported that Netanyahu was to agree to settlers' political demands to approve more settlement constructions before a temporary settlement freeze agreement took place. White House spokesman Robert Gibbs expressed "regret" over the move; however, one U.S. official said the move will not "derail [the] train".
On 7 September 2009, Netanyahu left his office without reporting where he was headed. The prime minister's military secretary, Maj. Gen. Meir Kalifi, later reported Netanyahu had visited a security facility in Israel. Several different news agencies reported several different stories about where he was. On 9 September 2009, Yedioth Ahronoth reported that the Israeli leader had made a secret flight to Moscow to try to persuade Russian officials not to sell S-300 anti-aircraft missile systems to Iran. Headlines branded Netanyahu a "liar" and dubbed the affair a "fiasco." It was later reported that the PM's military secretary will be dismissed due to the affair. "The Sunday Times" reported that the trip was made to share the names of Russian scientists that Israel believes are abetting the alleged Iranian nuclear weapons program.
On 24 September 2009, in an address to the United Nations General Assembly in New York, Netanyahu said Iran poses a threat to the peace of the world and that it is incumbent on the world body to prevent the Islamic Republic from obtaining nuclear weapons. Waving the blueprints for Auschwitz and invoking the memory of his own family members murdered by the Nazis, Netanyahu delivered a passionate and public riposte to Iranian president Mahmoud Ahmadinejad's questioning of the Holocaust, asking: "Have you no shame?"
In response to pressure from the Obama administration urging the sides to resume peace talks, on 25 November 2009 Netanyahu announced a partial 10 month settlement construction freeze plan. The announced partial freeze had no significant effect on actual settlement construction, according to an analysis by the major Israeli daily Haaretz. U.S. special envoy George Mitchell said, "while the United States shares Arab concerns about the limitations of Israel's gesture, it is more than any Israeli government has ever done". In his announcement Netanyahu called the move "a painful step that will encourage the peace process" and urged the Palestinians to respond. The Palestinians rejected the call, stating the gesture was "insignificant" in that thousands of recently approved settlement buildings in the West Bank would continue to be built and there would be no freeze of settlement activity in East Jerusalem.
In March 2010, Israel's government approved construction of an additional 1,600 apartments in a large Jewish housing development in northern East Jerusalem called Ramat Shlomo despite the position of the current U.S. Government that acts such as this thwart the peace talks between Israel and the Palestinians. The Israeli government's announcement occurred during a visit by U.S. Vice-President Joe Biden and the U.S. government subsequently issued a strongly worded condemnation of the plan. Netanyahu subsequently issued a statement that all previous Israeli governments had continuously permitted construction in the neighborhood, and that certain neighborhoods such as Ramat Shlomo and Gilo have always been included as part of Israel in any final agreement plan that has been proposed by either side to date. Netanyahu regretted the timing of the announcement but asserted that "our policy on Jerusalem is the same policy followed by all Israeli governments for the 42 years, and it has not changed."
In September 2010, Netanyahu agreed to enter direct talks, mediated by the Obama administration, with the Palestinians for the first time in a long while. The ultimate aim of these direct talks is to forge the framework of an official "final status settlement" to the Israeli-Palestinian conflict by forming a two-state solution for the Jewish people and the Palestinian people. On 27 September, the 10-month settlement freeze ended, and the Israeli government approved new construction in the West Bank, including East Jerusalem. On retiring from office in July 2011, former U.S. Secretary of Defense Robert Gates had said that Netanyahu was ungrateful to the United States and endangering Israel. Responding, the Likud party defended Netanyahu by saying that most Israelis supported the Prime Minister and that he had broad support in the United States.
In 2011, social justice protests broke out across Israel. Hundreds of thousands of people protested Israel's high cost of living throughout the country. In response, Netanyahu appointed the Trajtenberg Committee, headed by professor Manuel Trajtenberg, to examine the problems and propose solutions. The committee submitted recommendations to lower the high cost of living in September 2011. Although Netanyahu promised to push the proposed reforms through the cabinet in one piece, differences inside his coalition resulted in the reforms being gradually adopted.
In 2012, Netanyahu initially planned to call early elections, but subsequently oversaw the creation of a controversial government of national unity to see Israel through until the national elections of 2013. In May 2012, Netanyahu officially recognized for the first time the right for Palestinians to have their own state, though as before he declared it would have to be demilitarized. On 25 October 2012, Netanyahu and Foreign Minister Avigdor Lieberman announced that their respective political parties, Likud and Yisrael Beiteinu, had merged and would run together on a single ballot in Israel's 22 January 2013 general elections.
Third Premiership: 2013–15.
The 2013 election returned Netanyahu's Likud Beiteinu coalition with 11 fewer seats than the combined Likud and Yisrael Beiteinu parties had going into the vote. Nevertheless, as leader of what remained the largest faction in the Knesset, Israeli president Shimon Peres charged Netanyahu with the task of forming the Thirty-third government of Israel. The new coalition included the Yesh Atid, The Jewish Home and Hatnuah parties and excludes the ultra-Orthodox parties at the insistence of Yesh Atid and the Jewish Home.
During Netanyahu's third term, he continued his policy of economic liberalization. In December 2013, the Knesset approved the Business Concentration Law, which intended to open Israel's highly concentrated economy to competition to lower consumer prices, reduce income inequality, and increase economic growth. Netanyahu had formed the Concentration Committee in 2010, and the bill, which was pushed forward by his government, implemented its recommendations. The new law banned multi-tiered corporate holding structures, in which a CEO's family members or other affiliated individuals held public companies which in turn owned other public companies, and who were thus able to engage in price gouging. Under the law, corporations were banned from owning more than two tiers of publicly listed companies and from holding both financial and non-financial enterprises. All conglomerates were given four to six years to sell excess holdings. Netanyahu also began a campaign of port privatization to break what he viewed as the monopoly held by workers of the Israel Port Authority, so as to lower consumer prices and increase exports. In July 2013, he issued tenders for the construction of private ports in Haifa and Ashdod. Netanyahu has also pledged to curb excess bureaucracy and regulations to ease the burden on industry.
In April 2014, and again in June, Netanyahu spoke of his deep concerns when Hamas and the Palestinian Authority agreed and then formed a unity government, and was severely critical of both the United States and European governments' decision to work with the Palestinian coalition government. He blamed Hamas for the kidnapping and murder of three Israeli teenagers in June 2014, and launched a massive search and arrest operation on the West Bank, targeting members of Hamas in particular, and over the following weeks hit 60 targets in Gaza. Missile and rocket exchanges between Gaza militants and the IDF escalated after the bodies of the teenagers, who had been killed almost immediately as the government had good reasons to suspect, were discovered on 30 June 2014. After several Hamas operatives were killed, either in an explosion or from an Israeli bombing, Hamas officially declared it would launch rockets from Gaza into Israel, and Israel started Operation Protective Edge in the Gaza Strip, formally ending the November 2012 ceasefire agreement. The prime minister did a round of television shows in the United States and described Hamas as "genocidal terrorists" in an interview on CNN. When asked if Gazan casualties from the operation might spark "a third intifada", Netanyahu replied that Hamas was working towards that goal.
In October 2014, Netanyahu called restrictions on settlements "against the American values," a remark that earned him a sharp rebuke from the White House Press Secretary Josh Earnest, who noted that American values had resulted in Israel receiving not only consistent funding but protective technology such as Iron Dome. Not long thereafter, Jeffrey Goldberg of The Atlantic reported that the relationship between Netanyahu and the White House had reached a new low, with the U.S. administration angry over Israel's settlement policies, and Netanyahu expressing contempt for the American administration's grasp of the Middle East. Netanyahu explained that he does not accept restrictions on where Jews could live, and said that Jerusalem's Arabs and Jews should be able to buy homes wherever they want. He said he was "baffled" by the American condemnation. "It's against the American values. And it doesn't bode well for peace. The idea that we'd have this ethnic purification as a condition for peace, I think it's anti-peace."
On 2 December 2014 Netanyahu fired two of his ministers, Finance Minister Yair Lapid, who heads the centrist Yesh Atid party and Justice Minister Tzipi Livni, who heads Hatnua. The changes led to the dissolution of the government, with new elections expected on 17 March 2015.
In January 2015, Netanyahu was invited to address the US Congress. This speech marked Netanyahu's third speech to a joint session of Congress. The day before announcing he would address Congress, Time reported that he tried to derail a meeting between U.S. lawmakers and the head of Mossad, Tamir Pardo, who intended warning them against imposing further sanctions against Iran, a move that might derail nuclear talks. Leading up to the speech, on 3 March 2015, Israeli consuls general in the United States "expect[ed] fierce negative reaction from U.S. Jewish communities and Israel's allies." Objections included the arrangement of the speech without the support and engagement of the Obama administration and the timing of the speech before Israel's 17 March 2015 election. Seven American Jewish lawmakers met with Ron Dermer, Israel's ambassador to the U.S. and recommended that Netanyahu instead meet with lawmakers privately to discuss Iran. In making the speech, Netanyahu claimed to speak for all Jews worldwide, a claim disputed by others in the Jewish community. Rebecca Vilkomerson, executive director of Jewish Voice for Peace, stated that "American Jews are largely appalled by the notion that Netanyahu, or any other Israeli politician — one that we did not elect and do not choose to be represented by — claims to speak for us."
As election day approached in what was perceived to be a close race in the 2015 Israeli elections, Netanyahu answered 'indeed' when asked whether a Palestinian state would not be established in his term. He said that support of a Palestinian state is tantamount to yielding territory for radical Islamic terrorists to attack Israel.
2015 re-election and coalition negotiations period.
In the 2015 election, Netanyahu has returned with his party Likud leading the elections with 30 mandates, making it the single highest number of seats for the Israeli Knesset parliament. President Rivlin granted Netanyahu an extension until May 6, 2015 to build a coalition when one had not been finalized in the first four weeks of negotiations. He formed a coalition government within two hours of the midnight May 6 deadline. His Likud party formed the coalition with Jewish Home, United Torah Judaism, Kulanu, and Shas.
When a video of police brutality directed at an Ethiopian-born IDF soldier led to demonstrations and protests, at times turning violent, in Jerusalem and Tel Aviv, Netanyahu posted, "‘I was shocked by the pictures. We cannot accept this and we will change things." He held joint meetings with Ethiopian-Israeli community leaders and government leaders of several ministries, a separate meeting with the soldier, which was also attended by the minister of internal security and the head of Israel's police force.
Political positions.
Economic views.
"You want to have a meritocracy. You want to have initiative, risk, talent, the ability to create new products, new services to be rewarded... It's always been about competition. That's what human progress is about. You want to siphon it into productive ways."
Benjamin Netanyahu, "The Marker", 2014
Netanyahu has been described as 'the advocate of the free-market'. As Prime Minister in his first term, he significantly reformed the banking sector, removing barriers to investment abroad, mandatory purchases of government securities and direct credit. As Minister of Finance (2003-2005), Netanyahu introduced a major overhaul of the Israeli economy. He introduced a welfare to work program, he led a program of privatization, reduced the size of the public sector, reformed and streamlined the taxation system and passed laws against monopolies and cartels with the aim of increasing competition. Netanyahu extended capital gains taxes from companies to individuals, which allowed him to enlarge the tax base while reducing taxes on incomes. As the Israeli economy started booming and unemployment fell significantly, Netanyahu was widely credited by commentators as having performed an 'economic miracle' by the end of his tenure. Direct investment in the Israeli economy had increased by an annualized 380%. On the other hand, his critics have labelled his economic views as Margaret Thatcher-inspired 'popular capitalism'.
Netanyahu defines capitalism as "the ability to have individual initiative and competition to produce goods and services with profit, but not to shut out somebody else from trying to do the same." He says that his views developed while he was working as an economic consult for Boston Consulting Group: "It was the first time that the Boston Consulting Group looked at governments and worked for governments. They wanted to do a strategic plan for the government of Sweden. I was on that case and looked at other governments. So I went around to other governments in Europe in 1976 and I was looking at Britain. I was looking at France. I was looking at other countries, and I could see that they were stymied by concentrations of power that prevented competition. And I thought, hmm, as bad as they are, ours was worse because we had very little room for private sector competition to the extent that we had government-controlled or union-controlled companies, and so you really didn't get the competition or the growth... And I said, well, if I ever have a chance, I'll change that."
Oslo Accords.
Netanyahu opposed the Oslo accords from their inception. During his term as prime minister in the late 1990s, Netanyahu consistently reneged on commitments made by previous Israeli governments as part of the Oslo peace process, leading American peace envoy Dennis Ross to note that "neither President Clinton nor Secretary [of State Madeleine] Albright believed that Bibi had any real interest in pursuing peace." In a 2001 video, Netanyahu, reportedly unaware he was being recorded, said: "They asked me before the election if I'd honor [the Oslo Accords]," "I said I would, but ... I'm going to interpret the accords in such a way that would allow me to put an end to this galloping forward to the '67 borders. How did we do it? Nobody said what defined military zones were. Defined military zones are security zones; as far as I'm concerned, the entire Jordan Valley is a defined military zone. Go argue." However, this is clearly consistent with Yitzhak Rabin's October 1995 statement to the Knesset on the ratification of the interim Oslo agreement: "B. The security border of the State of Israel will be located in the Jordan Valley, in the broadest meaning of that term."
Prior to second term as Prime Minister.
Netanyahu had previously called U.S.-backed peace talks a waste of time, while at the same time refusing to commit to the same two-state solution as had other Israeli leaders, until a speech in June 2009. He repeatedly made public statements which advocated an "economic peace" approach, meaning an approach based on economic cooperation and joint effort rather than continuous contention over political and diplomatic issues. This is in line with many significant ideas from the Peace Valley plan. He raised these ideas during discussions with former U.S. Secretary of State Condoleezza Rice. Netanyahu continued to advocate these ideas as the Israeli elections approached. Netanyahu has said:
 Right now, the peace talks are based on only one thing, only on peace talks. It makes no sense at this point to talk about the most contractible issue. It's Jerusalem or bust, or right of return or bust. That has led to failure and is likely to lead to failure again ... We must weave an economic peace alongside a political process. That means that we have to strengthen the moderate parts of the Palestinian economy by handing rapid growth in those areas, rapid economic growth that gives a stake for peace for the ordinary Palestinians."
In January 2009, prior to the February 2009 Israeli elections Netanyahu informed Middle East envoy Tony Blair that he would continue the policy of the Israeli governments of Ariel Sharon and Ehud Olmert by expanding settlements in the West Bank, in contravention of the Road Map, but not building new ones.
Bar-Ilan speech.
On 14 June 2009, Netanyahu delivered a seminal address at Bar-Ilan University (also known as the "Bar-Ilan speech"), at Begin-Sadat Center for Strategic Studies, that was broadcast live in Israel and across parts of the Arab world, on the topic of the Middle East peace process. He endorsed for the first time the notion of a Palestinian state alongside Israel. Netanyahu's speech could be viewed in part as a response to Obama's 4 June speech at Cairo. "Yedioth Ahronoth" claimed that Obama's words had "resonated through Jerusalem's corridors".
As part of his proposal, Netanyahu demanded the full demilitarization of the proposed state, with no army, rockets, missiles, or control of its airspace, and said that Jerusalem would be undivided Israeli territory. He stated that the Palestinians should recognize Israel as the Jewish national state with an undivided Jerusalem. He rejected a right of return for Palestinian refugees, saying, "any demand for resettling Palestinian refugees within Israel undermines Israel's continued existence as the state of the Jewish people." He also stated that a complete stop to settlement building in the West Bank, as required by the 2003 Road Map peace proposal, was not possible and the expansions will be limited based on the "natural growth" of the population, including immigration, with no new territories taken in. Nevertheless, Netanyahu affirmed that he accepted the Road Map proposal. He did not discuss whether or not the settlements should be part of Israel after peace negotiations, simply stating that the "question will be discussed".
In a response to U.S. President Barack Obama's statements in his Cairo speech, Netanyahu remarked, "there are those who say that if the Holocaust had not occurred, the State of Israel would never have been established. But I say that if the State of Israel would have been established earlier, the Holocaust would not have occurred." He also said, "this is the homeland of the Jewish people, this is where our identity was forged." He stated that he would be willing to meet with any "Arab leader" for negotiations without preconditions, specifically mentioning Syria, Saudi Arabia, and Lebanon. In general, the address represented a new position for Netanyahu's government on the peace process.
Some right-wing members of Netanyahu's governing coalition criticized his remarks for the creation of a Palestinian State; believing that all of the land should become under Israeli sovereignty. Likud MK Danny Danon said that Netanyahu went "against the Likud platform", while MK Uri Orbach of Habayit Hayehudi said that it had "dangerous implications". Opposition party Kadima leader Tzipi Livni remarked after the address that she thinks Netanyahu does not really believe in the two-state solution at all; she thought that he only said what he did as a feigned response to international pressure. Peace Now blasted the speech, highlighting the fact that, in the group's opinion, it did not address the Palestinians as equal partners in the peace process. The Secretary General of Peace Now, Yariv Oppenheimer, said, "It's a rerun of Netanyahu from his first term".
On 9 August 2009, speaking at the opening of government meeting Netanyahu repeated his claims from the Palestinians: "We want an agreement with two factors, the first of which is the recognition of Israel as the national state of the Jewish people and (the second of which is) a security settlement".
Arab reaction.
Netanyahu's "Bar-Ilan speech" provoked mixed reaction from the international community. The Palestinian National Authority rejected the conditions on a Palestinian State given by Netanyahu. Senior official Saeb Erekat said, "Netanyahu's speech closed the door to permanent status negotiations". Hamas spokesman Fawzi Barhoum said it reflected a "racist and extremist ideology" and called on Arab nations to "form stronger opposition". Palestinian Islamic Jihad labeled it "misleading" and, like Hamas, demanded stronger opposition to Israel from Arab nations. According to The Jerusalem Post, some leaders advocated a third intifada in response to the speech. The Arab League dismissed the address, declaring in a statement that "Arabs would not make concessions regarding issues of Jerusalem and refugees" and that "we know his history and style of evasion", adding that the Arab League would not recognize Israel as a Jewish state. Referring to Netanyahu's demand that Palestinians recognize Israel as the state of the Jewish people, Egypt's president Hosni Mubarak remarked, "You won't find anyone to answer that call in Egypt, or in any other place." Issuing a less blunt response, the Egyptian Foreign Ministry said that the speech was "not complete" and that it hoped for another, "different Israeli proposal which is built on the commitment to the two-state solution". Syrian state media condemned the speech and wrote that "Netanyahu has confirmed that he rejects the Arab peace initiative for peace along with all the initiatives and resolutions of the Security Council to relative peace." Lebanese President Michel Suleiman called for unity among Arab leaders, saying that "Arab leaders should be more united and preserve the spirit of resistance to face the Israeli stands regarding the peace process and the Palestinian refugee issue." He called on the international community to exert more pressure on the Israeli government to accept the Arab Peace Initiative, as he said Israel still has a will of military confrontation which can be proved in its offensives on Lebanon and the Gaza Strip. Jordanian Minister of State for Media affairs and Communications, and Government spokesperson Nabil Sharif issued a statement saying "The ideas presented by Netanyahu do not live up to what was agreed on by the international community as a starting point for achieving a just and comprehensive peace in the region."
Iranian reaction.
Iranian president Mahmoud Ahmadinejad referred to the speech as "bad news".
European reaction.
The Czech Republic, which held the presidency of the European Union, praised Netanyahu's address. "In my view, this is a step in the right direction. The acceptance of a Palestinian state was present there," said Czech Foreign Minister Jan Kohout, whose country held the EU's six-month presidency at the time of the speech. President Barack Obama's press secretary, Robert Gibbs, said that the speech was an "important step forward". President Obama stated that "this solution can and must ensure both Israel's security and the Palestinians' legitimate aspirations for a viable state". Swedish Foreign Minister Carl Bildt stated that "the fact that he uttered the word state is a small step forward". He added that "whether what he mentioned can be defined as a state is a subject of some debate". France praised the speech but called on Israel to cease building settlements in the West Bank. French Foreign Minister Bernard Kouchner stated that "I can only welcome the prospect of a Palestinian state outlined by the Israeli Prime Minister." The Foreign Ministry of Russia called the speech "a sign of readiness for dialogue" but said that "it does not open up the road to resolving the Israeli-Palestinian problem. The conditions on the Palestinians would be unacceptable."
Stalled peace talks.
In 2013, Netanyahu denied reports that his government would agree to peace talks on the basis of the green line. In 2014 he agreed to the American framework based on the green line and said that Jewish settlers must be allowed the option of staying in their settlements under Palestinian rule.
Palestinian negotiator, Saeb Erekat criticized Netanyahu, calling him "ideology corrupt" and a war criminal.
Unilateral withdrawals.
On 9 August 2009, speaking at the opening of his weekly cabinet meeting, Netanyahu promised not to repeat the "mistake" of the Gaza unilateral pullout, saying, "We will not repeat this mistake. We will not create new evacuees", and adding that "the unilateral evacuation brought neither peace nor security. On the contrary", and that "We want an agreement with two factors, the first of which is the recognition of Israel as the national state of the Jewish people and [the second is] a security settlement. In the case of Gaza, both of these factors were lacking". He also said, "Should we achieve a turn toward peace with the more moderate partners, we will insist on the recognition of the State of Israel and the demilitarization of the future Palestinian state". In October 2014, Netanyahu said "We don’t just hand over territory, close our eyes and hope for the best. We did that in Lebanon and we got thousands of rockets. We did that in Gaza, we got Hamas and 15,000 rockets. So we’re not gonna just replicate that. We want to see genuine recognition of the Jewish state and rock solid security arrangements on the ground. That’s the position I’ve held, and it’s only become firmer."
Iran.
In an 8 March 2007 interview with CNN, opposition leader Netanyahu asserted that there is only one difference between Nazi Germany and the Islamic Republic of Iran, namely that the first entered a worldwide conflict and then sought atomic weapons, while the latter is first seeking atomic weapons and, once it has them, will then start a world war. Netanyahu repeated these remarks at a news conference in April 2008. This was similar to earlier remarks that "... it's 1938, and Iran is Germany, and Iran is racing to arm itself with atomic bombs".
On 20 February 2009, after being asked to be the prime minister of Israel, Netanyahu described Iran as the greatest threat that Israel has ever faced: "Iran is seeking to obtain a nuclear weapon and constitutes the gravest threat to our existence since the war of independence." Speaking before the UN General Assembly in New York on 24 September 2009, Netanyahu expressed a different opinion than Iranian President Mahmoud Ahmadinejad's speech at the forum, saying those who believe Tehran is a threat only to Israel are wrong. "The Iranian regime", he said, "is motivated by fanaticism ... They want to see us go back to medieval times. The struggle against Iran pits civilization against barbarism. This Iranian regime is fueled by extreme fundamentalism." "By focusing solely on Iran," columnist Yossi Melman speculated that Netanyahu's foreign policy, "... took the Palestinian issue off the world agenda." After four days of shelling from the Iranian-funded Palestinian Islamic Jihad, Melman asked, "Is it worth initiating a crisis with Iran? Will the Israeli public be able to cope with Iran's response?"
By 2012, Netanyahu is reported to have formed a close, confidential relationship with Defense Minister Ehud Barak as the two men consider possible Israeli military action against Iran's nuclear facilities, following Israel's established Begin Doctrine. The pair were accused of acting on "messianic" impulses by Yuval Diskin, former head of the Shin Bet, who added that their warmongering rhetoric appealed to "the idiots within the Israeli public". Diskin's remarks were supported by former Mossad chief Meir Dagan, who himself had previously said that an attack on Iran was "the stupidest thing I have ever heard". A few weeks later, the RAND Corporation (a leading American think tank that advises the Pentagon) also openly disagreed with Netanyahu's belligerent stance: "In doing so, and without naming names, RAND sided with former Mossad chief Meir Dagan and former head of the Shin Bet Yuval Diskin."
Early in 2012, he used the opening ceremony for Israel's Holocaust Remembrance Day to warn against the dangers of an Iranian nuclear bomb, saying he was following the example of Jewish leaders during World War II who struggled to raise the alarm about the Nazis' genocidal intentions. Israeli academic Avner Cohen accused Netanyahu of showing "contempt" for the Holocaust by putting it to "political use", and former Israeli foreign minister Shlomo Ben-Ami similarly condemned Netanyahu's "vulgar manipulation of the memory of the Holocaust". Immediately after the 2012 Burgas bus bombing, Netanyahu confirmed that the attack had been undertaken in coordination with Iran.
Netanyahu stated during a 29 July meeting that, in his opinion, "all the sanctions and diplomacy so far have not set back the Iranian programme by one iota." And in August he stated that the United States only might respond to a massive attack against Israel. On 28 September 2012, Netanyahu gave a speech to the UN General Assembly in which he set forward a "red line" of 90% uranium enrichment, stating that if Iran were to reach this level, it would become an intolerable risk for Israel. Netanyahu used a cartoon graphic of a bomb to illustrate his point, indicating three stages of uranium enrichment, noting that Iran had already completed the first stage, and stating that "By next spring, at most by next summer at current enrichment rates, [Iran] will have finished the medium enrichment and move on to the final stage. From there, it's only a few months, possibly a few weeks before they get enough enriched uranium for the first bomb." Netanyahu delivered his speech the day after Iranian President Mahmoud Ahmadinejad spoke on the Jewish holy day of Yom Kippur, a presentation that the American, Canadian, and Israeli delegations had deliberately not attended. At the time, according to cables leaked in 2015, Mossad's assessment was that Iran did not appear ready to enrich uranium to levels required for a nuclear bomb.
In an October 2013 interview with BBC Persian Service, Netanyahu praised the history of Persia and said: "if the Iranian regime has nuclear weapons, the Iranian people will never be free of dictatorship and will live in eternal servitude."
Jonathan Pollard.
Netanyahu has repeatedly called for the release of Jonathan Pollard, an American serving a life sentence for passing secret U.S. documents to Israel in 1987. Netanyahu has called for his release over the course of several presidential administrations. He raised the issue at the Wye River Summit in 1998, where he claimed that U.S. President Bill Clinton had privately agreed to release Pollard; Clinton denied the assertion. In 2002, Netanyahu visited Pollard at his North Carolina prison. The Israeli Prime Minister maintains contact with Pollard's wife, and has been active in pressing the Obama administration to release Pollard. Netanyahu has characterized Pollard as "a warmhearted Jew, proud and a real Zionist."
Bank of China terror financing case.
In 2013, Netanyahu found himself caught between conflicting commitments made to the family of American terror victim Daniel Wultz and the Government of China. Although Netanyahu was reported to have previously promised U.S. Representative Ileana Ros-Lehtinen that Israel would fully cooperate in the terror-financing case against Bank of China in U.S. District Court, the prime minister reportedly made a conflicting promise to the Government of China prior to a state visit to China in May 2013. Attorney David Boies, lead counsel for the Wultz family, told the Wall Street Journal, "While we are respectful of China’s interests, and of the diplomatic pressure to which Israel has been subjected, those interests and that pressure cannot be permitted to obstruct the ability of American courts to hear critical evidence.”
In August 2013, Ros-Lehtinen, chair of the House Middle East and South Asia subcommittee, told the Miami Herald she raised the issue while leading a congressional delegation to Israel, stressing to Israeli officials the importance of them providing the Wultz family what they need for their lawsuit. “I am hopeful that we can bring this case to a conclusion that is satisfactory to the family, but we need community support to not waver at this critical time,” Ros-Lehtinen said.
U.S. Representative Debbie Wasserman Schultz, chair of the Democratic National Committee, also spoke out on the issue with the Miami Herald: “In South Florida, we all know too well of the tragic circumstances surrounding the cowardly terrorist attack that took Daniel Wultz’s innocent life. I have been working, hand in hand with the Wultz family and the state of Israel to ensure any and all of those involved in this terrorist activity, including the Bank of China, pay for their crimes so that justice can be served.”
Defense and security.
In 2011, Netanyahu arranged for 1000 Hamas and Fatah prisoners to be swapped for Gilad Shalit, including terrorists with "blood on their hands." Israeli officials estimate that 60% of those who are released "resume terrorism attacks".
In 2011, Israeli General Staff concluded that the armed forces cannot maintain their battle readiness under Netanyahu's proposed cuts. However Netanyahu decided to cut social programs instead, and promised to increase the defense budget by about six percent. In spite of this, the Israeli military still fell NIS 3.7 million short from its projected budget, which could damage their war capabilities. According to a U.S. State Department representative in November 2011, under the leadership of Netanyahu and Obama, Israel and the United States have enjoyed unprecedented security cooperation.
Under Netanyahu's leadership, the Israeli National Security Council has seen an expanded role in foreign policy planning and decision-making.
Asylum seekers.
In 2012 the Netanyahu government passed the “Prevention of Infiltration Law,” which mandated automatic detention of all people, including asylum-seekers, who enters Israel without permission. Amnesty International called it "an affront to international law." Between 2009 and 2013, approximately 60,000 people crossed into Israel from various African countries. Netanyahu said that, "this phenomenon is very grave and threatens the social fabric of society, our national security and our national identity." Many of these migrants are held in detention camps in the Negev desert.When the Supreme Court of Israel declared the "Prevention of Infiltration Law" illegal for permitting immediate and indefinite detention of asylum seekers from Africa, Netanyahu requested new legislation to work around the Supreme Court ruling.
Personal life.
Family.
Netanyahu comes from a highly accomplished family. Related to Rabbi Eliyahu of Vilna (the Vilna Gaon) on his paternal side, Netanyahu was born in Tel Aviv, to Prof. Benzion Netanyahu (original name Mileikowsky) and Tzila (Cela; née Segal). His mother was born in 1912 in Petah Tikva, part of the future British Mandate of Palestine that eventually became Israel. Though all his grandparents were born in the Russian Empire (now Belarus, Lithuania and Poland), his mother's parents emigrated to Minneapolis in the United States.
Netanyahu's father, Benzion, was a professor of Jewish history at Cornell University, editor of the Encyclopaedia Hebraica, and a senior aide to Ze'ev Jabotinsky, who remained active in research and writing into his nineties. Regarding the Palestinian people, he stated: "That they won't be able to face [anymore] the war with us, which will include withholding food from Arab cities, preventing education, terminating electrical power and more. They won't be able to exist, and they will run away from here. But it all depends on the war, and whether we will win the battles with them." Netanyahu has dismissed those who note similarities between his relentlessly hawkish views and those of his late father as "psychobabble". For example, David Remnick has written: "To understand Bibi, you have to understand the father."
Netanyahu's paternal grandfather was Nathan Mileikowsky, a leading Zionist rabbi and JNF fundraiser. Netanyahu's older brother, Yonatan, was killed in Uganda during Operation Entebbe in 1976. His younger brother, Iddo, is a radiologist and writer. All three brothers served in the Sayeret Matkal reconnaissance unit of the Israel Defense Forces.
Marriages and relationships.
Netanyahu has been married three times. Netanyahu's first marriage was to Miriam Weizmann, whom he met in Israel. Weizmann lived near Yonatan Netanyahu's apartment in Jerusalem, where Netanyahu was based during his military service. By the time Netanyahu's service was finished, Weizmann had completed her own military service and a degree in chemistry from the Hebrew University of Jerusalem. In 1972, they both left to study in the United States, where she enrolled in Brandeis University, while Netanyahu studied at MIT. They married soon afterward. The couple had one daughter, Noa (born 29 April 1978).
In 1978, while Weizmann was pregnant, Netanyahu met a non-Jewish British student named Fleur Cates at the university library, and began an affair. His marriage ended in divorce soon afterward, when his wife Miriam discovered the affair. In 1981, Netanyahu married Cates, and she converted to Judaism, but the couple divorced in 1984.
Netanyahu met his third wife, Sara Ben-Artzi, while she was working as a flight attendant on an El Al flight from New York to Israel. Sara was working as a flight attendant while she was completing a master's degree in psychology. The couple married in 1991 and has two sons: Yair, a former soldier in the IDF Spokesperson's Unit, and Avner, a national Bible champion and winner of the National Bible Quiz for Youth in Kiryat Shmona.
In 1993, Netanyahu confessed on live television to having had an affair with Ruth Bar, his public relations adviser, claiming that a political rival had planted a secret video camera that had recorded him in a sexually compromising position with Bar, and that he had been threatened with the release of the tape to the press unless he quit the Likud leadership race. The crisis eventually subsided, with Benjamin and Sara repairing their marriage, and Netanyahu was elected to the leadership of Likud. In 1996, there were media reports of his 20-year friendship with Katherine Price-Mondadori, a married Italian-American woman. During the 1990s, Netanyahu criticized this media intrusion into his private life, claiming that political rivals including David Levy had hired spies on him in order to try to gather evidence of alleged affairs, although it was noted that the Israeli public (like the French public) are generally not interested in their politician's private lives and would prefer they remained private.
Netanyahu became a grandfather on 1 October 2009, when his daughter Noa Netanyahu-Roth (married to Daniel Roth) gave birth to a boy, Shmuel. In 2011, Noa and her husband Daniel had a second son named David.
Relations with foreign leaders.
Former French president Nicolas Sarkozy and Netanyahu originally became acquainted when Sarkozy was the mayor of Neuilly-sur-Seine, after an introduction by a mutual friend. The two had dined together in Paris and Israel. During the 2011 G-20 Cannes summit, Sarkozy was overheard saying to U.S. President Barack Obama, "I cannot bear Netanyahu, he's a liar". To this Obama reportedly responded, "You're fed up with him, but I have to deal with him every day." According to a reporter who was present, all of the journalists covering the event agreed among themselves not to publish details of the incident.
Apart from his lukewarm relationship with the Obama administration, Netanyahu has close ties with the U.S. Republican Party and its leadership in the House of Representatives. Netanyahu and 2012 Republican presidential nominee Mitt Romney have a close relationship that dates back to their work together at the Boston Consulting Group in the mid-1970s. U.S. Vice President Joe Biden, a Democrat, has been friendly with Netanyahu for many years. In November 2011 and in the 2012 U.S. vice presidential debate, Biden stated that the relationship has lasted for 39 years. Netanyahu remarked in March 2010 during a joint statement with Biden during his visit of Israel that their friendship had started almost three decades prior.
In October 2014, a senior official of the Obama administration called Netanyahu a "chickenshit" for his stance on Iran. Secretary of State John Kerry phoned Netanyahu to clarify that "such statements are disgraceful, unacceptable and damaging" and "do not reflect the position of the United States." Netanyahu responded by saying "I'm being attacked because of my determination to defend Israel's interests. The safety of Israel is not important to those who attack me anonymously and personally." Because of visible rifts between Netanyahu and members of the Obama administration, observers have characterized the relationship as having reached a crisis level by October 2014. The relationship between Netanyahu and the Obama administration had become problematic enough that Jeffrey Goldberg reported in November 2014 that his conversations with Netanyahu and other Israeli officials indicated Israel would wait until a new U.S. president is elected before attempting to repair the relationship with the White House. An opinion poll taken in cooperation with the Jerusalem Post Diplomatic Conference showed that the "overwhelming majority" of Israelis believe their country's relationship with the U.S. has been hurt as a result of the poor relationship between Obama and Netanyahu.
External links.
class="wikitable succession-box" style="margin:0.5em auto; font-size:95%;clear:both;"

</doc>
<doc id="56474" url="http://en.wikipedia.org/wiki?curid=56474" title="Kingston upon Hull">
Kingston upon Hull

Hull, officially Kingston upon Hull ( , ), is a city and unitary authority area in the ceremonial county of the East Riding of Yorkshire, England. It stands on the River Hull at its junction with the Humber estuary, 25 miles (40 km) inland from the North Sea. Hull has a resident population of 256,100 (2011 est.).
The town of Hull was founded late in the 12th century. The monks of Meaux Abbey needed a port where the wool from their estates could be exported. They chose a place at the junction of the rivers Hull and Humber to build a quay.
The exact year the town was founded is not known but it was first mentioned in 1193, as Wyke on Hull.
Renamed "Kings-town upon Hull" by King Edward I in 1299, the town and city of Hull has served as market town, military supply port, a trading hub, fishing and whaling centre, and industrial metropolis.
Hull was an early theatre of battle in the English Civil Wars. Its 18th-century Member of Parliament, William Wilberforce, played a key role in the abolition of the slave trade in Britain.
The city is unique in the UK in having had a municipally owned telephone system from 1902, sporting cream, not red, telephone boxes.
After suffering heavy damage during the Second World War (the 'Hull Blitz'), Hull weathered a period of post-industrial decline, during which the city gained unfavourable results on measures of social deprivation, education and policing. During the early 21st-century spending boom (before the late 2000s recession) the city saw large amounts of new retail, commercial, housing and public service construction spending.
Established tourist attractions include the historic Old Town and Museum Quarter, Hull Marina and The Deep, a city landmark. The redevelopment of one of Hull's main thoroughfares, Ferensway, included the opening of St. Stephen's Hull and the new Hull Truck Theatre. Spectator sporting activities include Premier League football and Super League Rugby. The KC Stadium houses the Hull City football club and Hull FC rugby club and Craven Park is home to rugby club Hull Kingston Rovers. Hull is also home to the Elite Ice Hockey League Hull Stingrays.
In November 2013, it was announced that Hull would be the 2017 UK City of Culture.
History.
Kingston upon Hull stands on the north bank of the Humber estuary at the mouth of its tributary, the River Hull. The valley of the River Hull has been inhabited since the early Neolithic period but there is little evidence of a substantial settlement in the area of the present city. The general area was attractive to early developers because it gave access to a prosperous hinterland and navigable rivers, but the actual site was not good, as it was remote and low-lying with no fresh water. It was originally an outlying part of the hamlet of Myton, named Wyke. The name is thought to originate either from a Scandinavian word "Vik" meaning creek, or from the Saxon "Wic" meaning dwelling place or refuge.
The River Hull was a good haven for shipping, whose trade included the export of wool from Meaux abbey. In 1293 the town was acquired from the abbey by King Edward I, who on 1 April 1299 granted it a royal charter that renamed the settlement "King's town upon Hull", or Kingston upon Hull. The charter is preserved in the archives of the city's Guildhall.
In 1440, a further charter incorporated the town and instituted local government consisting of a mayor, a sheriff, and twelve aldermen.
In his "Guide to Hull (1817)", J.C. Craggs provides a colourful background to Edward's acquisition and naming of the town. He writes that the King and a hunting party started a hare which "led them along the delightful banks of the River Hull to the hamlet of Wyke … [Edward], charmed with the scene before him, viewed with delight the advantageous situation of this hitherto neglected and obscure corner. He foresaw it might become subservient both to render the kingdom more secure against foreign invasion, and at the same time greatly to enforce its commerce". Pursuant to these thoughts, Craggs continues, Edward purchased the land from the Abbot of Meaux, had a manor hall built for himself, issued proclamations encouraging development within the town, and bestowed upon it the royal appellation, "King's Town".
The port served as a base for Edward I during the First War of Scottish Independence and later developed into the foremost port on the east coast of England. It prospered by exporting wool and woollen cloth, and importing wine and timber. Hull also established a flourishing commerce with the Baltic ports as part of the Hanseatic League.
From its medieval beginnings, Hull's main trading links were with Scotland and northern Europe. Scandinavia, the Baltic and the Low Countries were all key trading areas for Hull's merchants. In addition, there was trade with France, Spain and Portugal. As sail power gave way to steam, Hull's trading links extended throughout the world. Docks were opened to serve the frozen meat trade of Australia, New Zealand and South America. Hull was also the centre of a thriving inland and coastal trading network, serving the whole of the United Kingdom.
Sir William de la Pole was the town's first mayor. A prosperous merchant, de la Pole founded a family that became prominent in government. Another successful son of a Hull trading family was bishop John Alcock, who founded Jesus College, Cambridge and was a patron of the grammar school in Hull. The increase in trade after the discovery of the Americas and the town's maritime connections are thought to have played a part in the introduction of a virulent strain of syphilis through Hull and on into Europe from the New World.
The town prospered during the 16th and early 17th centuries, and Hull's affluence at this time is preserved in the form of several well-maintained buildings from the period, including Wilberforce House, now a museum documenting the life of William Wilberforce.
During the English Civil War, Hull became strategically important because of the large arsenal located there. Very early in the war, on 11 January 1642, the king named the Earl of Newcastle governor of Hull while Parliament nominated Sir John Hotham and asked his son, Captain John Hotham, to secure the town at once. Sir John Hotham and Hull corporation declared support for Parliament and denied Charles I entry into the town. Charles I responded to these events by besieging the town. This siege helped precipitate open conflict between the forces of Parliament and those of the Royalists.
Throughout the second half of the 19th century and leading up to the First World War, the Port of Hull played a major role in the transmigration of Northern European settlers to the New World, with thousands of emigrants sailing to the city and stopping for administrative purposes before travelling on to Liverpool and then North America.
Parallel to this growth in passenger shipping was the emergence of the Wilson Line of Hull. Founded in the city in 1825 by Thomas Wilson, by the early 20th century the company had grown – largely through its monopolisation of North Sea passenger routes and later mergers and acquisitions – to be the largest privately owned shipping company in the world, with over 100 ships sailing to different parts of the globe. The Wilson Line was sold to the Ellerman Line – which itself was owned by Hull-born magnate (and the richest man in Britain at the time) Sir John Ellerman.
Whaling played a major role in the town's fortunes until the mid-19th century. Hull's prosperity peaked in the decades just before the First World War; it was during this time, in 1897, that city status was granted. After the decline of the whaling industry, emphasis shifted to deep-sea trawling until the Anglo-Icelandic Cod War of 1975–1976. The conditions set at the end of this dispute initiated Hull's economic decline.
Many of the suburban areas on the western side of Hull were built in the 1930s, particularly Willerby Road and Anlaby Park, as well as most of Willerby itself. This was part of the biggest British housing boom of the 20th century (possibly ever).
Hull Blitz.
The city's port and industrial facilities, coupled with its proximity to mainland Europe and ease of location being on a major estuary, led to extremely widespread damage by bombing raids during the Second World War; much of the city centre was destroyed. Hull had 95% of its houses damaged or destroyed, making it the most severely bombed British city or town, apart from London, during the Second World War. More than 1,200 people died in air raids on the city and some 3,000 others were injured.
The worst of the bombing occurred in 1941. Little was known about this destruction by the rest of the country at the time, since most of the radio and newspaper reports did not reveal Hull by name but referred to it as "a North-East town" or "a northern coastal town". Most of the city centre was rebuilt in the years following the war. As recently as 2006 researchers found documents in the local archives that suggested an unexploded wartime bomb might be buried beneath a major new redevelopment, The Boom, in Hull.
Government.
Following the Local Government Act 1888, Hull became a county borough, a local government district independent of the East Riding of Yorkshire. This district was dissolved under the Local Government Act 1972, on 1 April 1974 when it became a non-metropolitan district of the newly created shire county of Humberside. Humberside (and its county council) was abolished on 1 April 1996 and Hull was made a unitary authority area.
The single-tier local authority of the city is now Hull City Council (officially Kingston upon Hull City Council), headquartered in the Guildhall in the city centre. The council was designated as the UK's worst performing authority in both 2004 and 2005, but in 2006 was rated as a two star 'improving adequate' council and in 2007 it retained its two stars with an 'improving well' status. In the 2008 corporate performance assessment the city retained its "improving well" status but was upgraded to a three star rating.
The Liberal Democrats won overall control of the City Council in the 2007 local elections, ending several years in which no single party had a majority. They retained control in the 2008 local elections by an increased majority and in the 2010 local elections. Following the UK's local elections of 2011, the Labour Party gained control of the council, increasing their majority in the 2012 and retained this following the 2014 local elections.
The city returned three Members of Parliament to the House of Commons and at the last general election, in 2015, elected three Labour MPs: Alan Johnson who was the former Home Secretary, Diana Johnson and Karl Turner.
William Wilberforce is the most celebrated of Hull's former MPs. He was a native of the city and the member for Hull from 1780 to 1784 when he was elected as an Independent member for Yorkshire.
It lies within the Yorkshire and the Humber constituency of the European Parliament, which in the May 2014 European Election elected three UKIP, two Labour and one Conservative MEPs.
Hull is the only city and forms the major urban area in the official government-defined Hull and Humber Ports City Region.
Geography.
At , 154 mi north of London, Kingston upon Hull is on the northern bank of the Humber estuary. The city centre is west of the River Hull and close to the Humber. The city is built upon alluvial and glacial deposits which overlie chalk rocks but the underlying chalk has no influence on the topography. The land within the city is generally very flat and is only 2 to 4 metres (6.5 to 13 ft) above sea level. Because of the relative flatness of the site there are few physical constraints upon building and many open areas are the subject of pressures to build.
The parishes of Drypool, Marfleet, Sculcoates, and most of Sutton parish, were absorbed within the borough of Hull in the 19th and 20th centuries. Much of their area has been built over, and socially and economically they have long been inseparable from the city. Only Sutton retained a recognisable village centre in the late 20th century, but on the south and east the advancing suburbs had already reached it. The four villages were, nevertheless, distinct communities, of a largely rural character, until their absorption in the borough—Drypool and Sculcoates in 1837, Marfleet in 1882, and Sutton in 1929. The current boundaries of the city are tightly drawn and exclude many of the metropolitan area's nearby villages, of which Cottingham is the largest. The city is surrounded by the rural East Riding of Yorkshire.
Some areas of Hull lie on reclaimed land at or below sea level. The Hull Tidal Surge Barrier is at the point where the River Hull joins the Humber estuary and is lowered at times when unusually high tides are expected. It is used between 8 and 12 times per year and protects the homes of approximately 10,000 people from flooding. Due to its low level, Hull is expected to be at increasing levels of risk from flooding due to global warming.
Many areas of Hull were flooded during the June 2007 United Kingdom floods, with 8600 homes and 1300 businesses affected.
Historically, Hull has been affected by tidal and storm flooding from the Humber; the last serious floods were in the 1950s, in 1953, 1954 and the winter of 1959.
Unlike many other English cities, Hull has no cathedral. It is in the Diocese of York and has a Suffragan bishop. However, Hull's Holy Trinity Church is the largest parish church in England when floor area is the measurement for comparison. The church dates to about 1300. Hull forms part of the Southern Vicariate of the Roman Catholic Diocese of Middlesbrough and included among Hull's Catholic churches is St Charles Borromeo, the oldest post-Reformation Roman Catholic church in the city.
There are several seamen's missions and churches in Hull. The Mission to Seafarers has a centre at West King George Dock and the St Nikolaj Danish Seamen's Church is located in Osborne Street.
Climate.
Located in Northern England, Hull has a temperate maritime climate which is dominated by the passage of mid-latitude depressions. The weather is very changeable from day to day and the warming influence of the Gulf Stream makes the region mild for its latitude. Locally, the area is sunnier than most areas this far north in the British Isles, and also considerably drier, due to the rain shadowing effect of the Pennines. It is also one of the most northerly areas where the July maximum temperature exceeds 21.5 C, although this appears to be very localised around the city itself.
The absolute maximum temperature recorded is 34.4 C, set in August 1990. Typically, the warmest day should reach 28.8 C, though slightly over 10 days should achieve a temperature of 25.1 C or more in an 'average' year. All averages refer to the 1981-2010 period.
The absolute minimum temperature is -11.1 C, recorded during January 1982. An average of 32.5 nights should report an air frost.
Seismic activity.
At around 00:56 GMT on 27 February 2008, Hull was 30 mi north of the epicentre of an earthquake measuring 5.3 on the Richter Scale which lasted for nearly 10 seconds. This was an unusually large earthquake for this part of the world.
Demography.
According to the 2001 UK census, Hull had a population of 243,589 living in 104,288 households. The population density was 34.1 per hectare. Of the total number of homes 47.85% were rented compared with a national figure of 31.38% rented. The population had declined by 7.5% since the 1991 UK census, and has been officially estimated as 256,200 in July 2006.
In 2001 approximately 53,000 people were aged under 16, 174,000 were aged 16–74, and 17,000 aged 75 and over. Of the total population 97.7% were white and the largest minority ethnic group was of 749 people who considered themselves to be ethnically Chinese. There were 3% of people living in Hull who were born outside the United Kingdom. In 2006 the largest minority ethnic grouping was Iraqi Kurds who were estimated at 3,000. Most of these people were placed in the city by the Home Office while their applications for asylum were being processed. In 2001, the city was 71.7% Christian. A further 18% of the population indicated they were of no religion while 8.4% did not specify any religious affiliation. In 2001, the city had the lowest church attendance in the United Kingdom.
Also in 2001, the city had a high proportion, at 6.2%, of people of working age who were unemployed, ranking 354th out of 376 local and unitary authorities within England and Wales. The distance travelled to work was less than 3 mi for 64,578 out of 95,957 employed people. A further 18,031 travelled between 5 and 10 kilometres (3.1 and 6.2 mi) to their place of employment. The number of people using public transport to get to work was 12,915 while the number travelling by car was 53,443.
Economy.
The economy of Hull was built on trading and seafaring, firstly whaling and later seafishing. Merchant's houses such as Blaydes House and some warehouses survive in the Old Town, where trade was centred on the River Hull, later shifting to the Humber docks. Another major industry was oilseed crushing. Although the fishing industry declined in the 1970s, the city remains a busy port, handling 13 million tonnes of cargo per year. The port operations run by Associated British Ports and other companies in the port employ 5,000 people. A further 18,000 are employed as a direct result of the port's activities.
The port area of the city has diversified to compensate for the decline in fishing by the introduction of Roll-on Roll-off ferry services to the continent of Europe. These ferries now handle over a million passengers each year.
Hull has exploited the leisure industry by creating Hull Marina from the old Humber Street Dock in the centre of the city. It opened in 1983 and has 270 berths for yachts and small sailing craft.
Industry in the city is focused on the chemical and health care sectors. Several well-known British companies, including BP, Smith & Nephew, Seven Seas, and Reckitt Benckiser, have facilities in Hull.
The health care sector is further enhanced by the research facilities provided by the University of Hull through the Institute of Woundcare and the Hull York Medical School partnerships. In recent years, with the decline of fishing and heavy industry, the retail sector, tourism, the arts and further and higher education sectors have played an increasingly prominent role in the process of economic regeneration and raising the profile of the city. In 2009 it was estimated that businesses in Hull deliver an annual turnover of almost £8 billion, and over 5 million annual visitors contribute almost £210 million to Hull's economy.
Retail.
As the biggest settlement in the East Riding of Yorkshire and the local transport hub, Hull is a natural focus for retail shoppers. Major department stores in Hull include Debenhams, House of Fraser and British Home Stores (BHS). The city centre has three main shopping centres, St. Stephen's, Princes Quay and the Prospect Centre. There are also a number of "retail parks", and suburban shopping centres including the North Point Shopping Centre at Bransholme, St Andrews Quay on the Humber bank, as well as near Great Gutter lane (Willerby), Mount Pleasant (Holderness Road), Priory Park (near Hessle) and Kingswood retail park (Kingswood)
Whitefriargate is one of the shopping streets, along with King Edward Street and Carr lane.
The electrical retailer Comet Group was founded in the city as "Comet Battery Stores Limited" in 1933; the company's first superstore was opened in Hull in 1968.
The city's branch of Woolworth's on King Edward Street closed in 2008,
as did the branch of T J Hughes on the site of the former C&A store on Ferensway in August 2011, following the parent companies' bankruptcies. The main out-of-town shopping streets are Hessle Road, Holderness Road, Chanterlands Avenue, Beverley Road, as well as Princes Avenue and Newland Avenue. Two covered shopping arcades remain in the town centre: the Hepworth and Paragon Arcades.
The "Prospect Centre" on Prospect Street is a smaller, older shopping centre with a range of chain stores, banks and fashion retailers. It contains branches of Boots, Claire's, a large Wilkinsons, Poundland, W H Smith, Santander, and Hull's main post office. At Bransholme, the "North Point Shopping Centre" (Bransholme Shopping Centre) contains a similar range of popular chain stores and budget-oriented retailers including Boyes and Heron Foods.
The "Princes Quay Shopping Centre" (1991) was built on stilts over the closed Prince's Dock, and houses a variety of chain stores and food outlets. It was originally built with four retail floors, known as "decks". The uppermost deck has housed a Vue cinema since December 2007.
There are a number of budget and discount retailers including four branches of Boyes, Primark, Peacocks, Poundland and Wilkinsons have branches in the city. Hull has a good selection of supermarkets, including several branches of Tesco, Sainsbury's, the Co-operative and budget food stores including Heron Foods and Iceland.
The "St. Stephen's" shopping centre development on Ferensway opened in 2007, is a 560000 sqft scheme, costing over £160 million. It is anchored by a large 24-hour Tesco Extra superstore and provides shop units, food outlets, a hotel, cinema, car parking; adjacent is Hull's Paragon Interchange completed in the same time period which includes a new bus station and renovated railway station with retail outlets.
Development, 2000–2010.
In addition to the St. Stephen's retail project, a number of other commercial, office and services developments were planned or took place during the first decade of the 21st century. One high profile project was the £165 million Humber Quays development, built near to the Humber estuary, which gained World Trade Centre status as the World Trade Centre Hull & Humber. Phase 1 of the project includes two office buildings and 51 new apartments. A second phase is expected to include a new 200-bedroom 4-star hotel, a restaurant, and more high-quality office space. The 50-stall indoor Edwardian Trinity Market, a grade II listed building, and Hepworth's arcade were modernised and renovated in the late 2000s. The city centre railway station, and adjacent bus terminal were also redeveloped, and were official opened in 2009, as the Hull Paragon Interchange.
Several large-scale developments also planned, including a £100 million residential development on east bank of the River Hull, called the "Boom", which would include over 600 luxury riverside apartments, shops, boutiques, bistro cafés, a 120-bed luxury hotel, and health and education facilities. Also planned and not built was the "Quay West" extension to the Princes Quay shopping centre, that was cancelled in 2010.
The late 2000s recession halted many of the building development projects. Additionally, the local development agency 'Hull Forward' lost funding in June 2010 due to governmental budgetary cuts on public spending . and the regional development agency, Yorkshire Forward was abolished.
The 'Boom' development was to be linked to the city centre by a new swing footbridge, Scale Lane Bridge, across the River Hull. The bridge was officially opened in June 2013.
An investment of £14.5 million by Network Rail was used to enhance the capacity of the port freight railway line, the Hull Docks branch, (completed 2008); the project was intended to increase its capacity from 10 trains per day to 22.
Development 2010 – present.
In January 2011 Siemens Wind Power and Associated British Ports signed a memorandum of understanding concerning the construction of wind turbine manufacturing plant at Alexander Dock. The plan would require some modification of the dock to allow the ships, used for transporting the wind turbines, to dock and be loaded.
Planning applications for the plant were submitted in December 2011, and affirmed in 2014, concerning 75 metre blades for the 6 MW offshore model. The creation of an enterprise zone, Humber Enterprise Zone, was announced in 2011 to encourage further industrial development in the Humber estuary region.
A 12.5-acre site waste-to-energy centre costing in the region of £150 million is also planned to be built by the Spencer Group. Announced in mid-2011, and named 'Energy Works', the proposed plant would process up to 200,000 tonnes of organic material per year, with energy produced via a waste gasification process.
In July 2014, demolition began in the Fruit Market to allow room for the construction of the C4DI (Centre for Digital Innovation), a technology hub whose aim is to promote the tech sector in Hull and East Yorkshire.
Culture.
Hull has a vibrant tradition of arts and culture with several museums of national importance. The city has a strong theatrical tradition with some famous actors and writers having been born and lived in Hull. The city's arts and heritage have played an important role in attracting visitors and encouraging tourism in recent efforts at regeneration. Hull has a diverse range of architecture and this is complemented by parks and squares and a number of statues and modern sculptures. The city has inspired many authors including Val Wood who has set many of her best-selling novels in the city.
In April 2013 Hull put forward a bid to be the UK City of Culture in 2017, reaching the shortlist of four in June 2013 along with Dundee, Leicester and Swansea Bay. On 20 November 2013, Maria Miller, the Culture Secretary, announced that Hull had won the award to become the UK City of Culture 2017.
Museums.
Hull's Museum Quarter, on the High Street in the heart of the Old Town, consists of Wilberforce House, the Arctic Corsair, the Hull and East Riding Museum (which contains the Hasholme Logboat – Britain's largest surviving prehistoric logboat), and the Streetlife Museum of Transport. Other museums and visitor attractions include the Ferens Art Gallery with a good range of art and regular exhibitions, the Maritime Museum in Victoria Square, the Spurn Lightship, the Yorkshire Water Museum, and the Deep, a public aquarium.
The recently refurbished Seven Seas Fish Trail marks Hull's fishing heritage, leading its followers through old and new sections of the city, following a wide variety of sealife engraved in the pavement.
Visual culture and sculpture.
Marine painter John Ward (1798–1849) was born, worked and died in Hull and a leading ship artist of his day.
Artist and Royal Academician David Remfry (born 1942) grew up in Hull and studied at the Hull College of Art (now part of Lincoln University) from 1959 to 1964. His tutor, Gerald T Harding, trained at the Royal College of Art, London and was awarded the Abbey Minor Travelling Scholarship in 1957 by the British School in Rome. Remfry has had two solo exhibitions at the Ferens Art Gallery in 1975 and 2005.
Hull has a number of historical statues such as the Wilberforce Memorial in Queen's Gardens and the gilded King William III statue on Market Place (known locally as "King Billy"). There is a statue of Hull-born Amy Johnson in Prospect Street. In recent years a number of modern art sculptures and heritage trails have been installed around Hull. These include a figure looking out to the Humber called 'Voyage' which has a twin in Iceland. In July 2011, this artwork was reported stolen. There is a shark sculpture outside The Deep and a fountain and installation called 'Tower of Light' outside Britannia House on the corner of Spring Bank.
Running along Spring Bank there is also an elephant trail, with stone pavers carved by a local artist to the designs of members of the community. This trail commemorates the Victorian Zoological Gardens and the route taken daily by the elephant as it walked from its house down Spring Bank to the zoo and back, stopping for gingerbread at a shop on the way. The animals are further represented on the Albany Street 'Home Zone' a project involving local residents and resulting in sculptures of a hippo ('Water Horse') at the bottom of Albany Street; an elephant balancing on its trunk on an island in the middle; and two bears climbing poles and reaching out to each other to form an open archway across the entrance to Albany street from Spring Bank. Other sculptural details of animals along the street represent the participation of street residents, either through workshops with artists and makers, or through independent work of their own.
In 2010 a public art event in Hull city centre entitled "Larkin with Toads" displayed 40 individually decorated giant toad models as the centrepiece of the Larkin 25 festival. Most of these sculptures have since been sold off for charity and transported to their new owners. Visitors to Hull's Paragon Interchange are now greeted by the new statue of Philip Larkin unveiled on 2 December 2010.
Theatres.
The city has two main theatres. Hull New Theatre, which opened in 1939, is the largest venue which features musicals, opera, ballet, drama, children's shows and pantomime.
The Hull Truck Theatre is a smaller independent theatre, established in 1971,
that regularly features plays, notably those written by John Godber.
Since April 2009, the Hull Truck Theatre has had a new £14.5 million, 440 seat venue in the St. Stephen's Hull development. This replaced the former home of the Hull Truck Theatre on Spring Street, a complex of buildings demolished in 2011. The playwright Alan Plater was brought up in Hull and was associated with Hull Truck Theatre.
Hull has produced several veteran stage and TV actors. Sir Tom Courtenay, Ian Carmichael and Maureen Lipman were born and brought up in Hull. Younger actors Reece Shearsmith, Debra Stephenson and Liam Garrigan were also born in Hull. Garrigan attended Hull's Northern Theatre Company and Wyke College.
In 1914, there were 29 cinemas in Hull but most of these have now closed. The first purpose-built cinema was the Prince's Hall in George Street which opened in 1910. It was subsequently renamed the Curzon.
Poetry.
Hull has attracted the attention of poets to the extent that the Australian author Peter Porter has described it as "the most poetic city in England".
Philip Larkin set many of his poems in Hull; these include "The Whitsun Weddings", "Toads", and "Here". Scottish-born Douglas Dunn's "Terry Street", a portrait of working-class Hull life, is one the outstanding poetry collections of the 1970s.
Dunn forged close associations with such Hull poets as Peter Didsbury and Sean O'Brien; the works of some of these writers appear in the 1982 Bloodaxe anthology "A Rumoured City", a work that Dunn edited. Andrew Motion, past Poet Laureate, lectured at the University of Hull between 1976 and 1981, and Roger McGough studied there. Both poets spoke at the Humber Mouth Festival in 2010. Contemporary poets associated with Hull are Maggie Hannan, David Wheatley, and Caitriona O'Reilly.
17th-century metaphysical poet and parliamentarian Andrew Marvell was born nearby, grew up and was educated in the city. There is a statue in his honour in the Market Square (Trinity Square), set against the backdrop of his alma mater Hull Grammar School.
Music.
Classical.
In the field of classical music, Hull is home to Hull Sinfonietta, the largest professional chamber ensemble in the Humber region, and also the Hull Philharmonic Orchestra, one of the oldest amateur orchestras in the country. and formerly The Hull Philharmonic Youth Orchestra, established in 1952,
the Hull Choral Union, the Hull Bach Choir – which specialises in the performance of 17th- and 18th-century choral music, the Hull Male Voice Choir, the Arterian Singers and two Gilbert & Sullivan Societies: the Dagger Lane Operatic Society and the Hull Savoyards are also based in Hull. There are two brass bands, the East Yorkshire Motor Services Band, who are the current North of England Area Brass Band Champions, and East Riding of Yorkshire Band who are the 2014 North of England Regional Champions within their section.
Hull City Hall annually plays host to major British and European symphony Orchestras with its 'International Masters' orchestral concert season. During the 2009–10 season visiting orchestra's included the St Petersburg Symphony Orchestra and the Czech National Symphony Orchestra. Internationally renowned touring pop, rock, and comedy acts also regularly play the City Hall.
In September 2013 a five-year partnership with the Royal Philharmonic Orchestra was announced by the City Council.
Rock, pop and folk.
On the popular music scene, in the 1960s, Mick Ronson of the Hull band "Rats" worked closely with David Bowie and was heavily involved in production of the album "The Rise and Fall of Ziggy Stardust and the Spiders from Mars". Ronson later went on to record with Lou Reed, Bob Dylan, Morrissey and the Wildhearts. There is a Mick Ronson Memorial Stage in Queen's Gardens in Hull. The 1960s were also notable for the revival of English folk music, of which the Hull-based quartet, the Watersons were prominent exponents.
In the 1980s, Hull groups such as the Red Guitars, the Housemartins and Everything but the Girl found mainstream success, followed by Kingmaker of 'Queen Jane' and 'Ten Years Asleep' fame, in the 1990s. Paul Heaton, former member of the Housemartins went on to front the Beautiful South. Another former member of the Housemartins, Norman Cook, now performs as Fatboy Slim. In 1982, Hull-born Paul Anthony Cook, Stuart Matthewman and Paul Spencer Denman formed the group Sade. In 1984, the singer Helen Adu signed to CBS Records and the group released the album "Diamond Life". The album went Triple Platinum in the UK and x4 Platinum in the USA for sales of 4 million. Vocalist and actor Roland Gift, who formed the Fine Young Cannibals, grew up in Hull.
The pioneering industrial band Throbbing Gristle formed in Hull; Genesis P-Orridge (Neil Megson) attended Hull University between 1968 and 1969, where he met Cosey Fanni Tutti (Christine Newby), who was born in the city, and first became part of the Hull performance art group COUM Transmissions in 1970.
The record label Pork Recordings started in Hull in the mid-1990s and has released music by Fila Brazillia,
The Adelphi is a popular local venue for alternative live music in the city, and has achieved notability outside Hull, having hosted such bands as the Stone Roses, Radiohead, Green Day, and Oasis in its history, while the Springhead caters to a variety of bands and has been recognised nationally as a Live Music Pub of the Year.
In the 2000s Hull Indie Rock band The Paddingtons saw mainstream success with two UK Top 40 singles in 2005., later reforming in 2014 for fans in Hull, performing at Humber Street Sesh with notable bands such as Sulu Babylon and Street Parade.
In the 1990s, the duo Scarlet from Hull had two Top 40 hits with 'Independent Love Song' and 'I Wanna Be Free (To Be With Him)' in 1995. The duo also released the albums Naked and Chemistry.
The Humber Street Sesh night has released four DIY compilations featuring the cream of Hull's live music scene and there are currently a few labels emerging in the city, including Purple Worm Records based at Hull College with bands like The Blackbirds showing a promising future.
Nightlife, bars and pubs.
The drinking culture in Hull city centre tends towards late bars, while the wine bars and pubs around Hull University and its accommodation area are popular with students. In particular, the areas around Newland Avenue and Prince's Avenue have seen a rapid expansion in continental-style bars and cafes encouraged by the redesign of the street layout.
Festivals.
"The Humber Mouth" literature festival is an annual event and the 2012 season featured artists such as John Cooper Clarke, Kevin MacNeil and Miriam Margolyes. 
The annual Hull Jazz Festival takes place around the Marina area for a week at the beginning of August.
As of 2008 Hull has also held Freedom Festival; an annual free arts and live music event that celebrates freedom in all its forms. Performers have included Pixie Lott, JLS and Martha Reeves and The Vandellas and The 1975 as well as featuring a torchlight procession, local bands like The Talks and Happy Endings from Fruit Trade Music label and a Ziggy Stardust photo exhibition including photos of the late-Hull-born Mick Ronson who worked with David Bowie.
Early October sees the arrival of Hull Fair which is one of Europe's largest travelling funfairs and takes place on land adjacent to the KC Stadium.
The Hull Global Food Festival held its third annual event in the city's Queen Victoria Square for three days – 4–6 September 2009. According to officials, the event in 2007 attracted 125,000 visitors and brought some £5 million in revenue to the area.
In 2007 the Hull Metalfest began in the Welly Club, it featured major label bands from the United States, Canada and Italy, as well as the UK.
The first Hull Comedy Festival, which included performers such as Stewart Lee and Russell Howard was held in 2007.
In 2010, Hull marked the 25th anniversary of the death of the poet Philip Larkin with the Larkin 25 Festival. This included the popular "Larkin with Toads" public art event. The 40 Larkin toads were displayed around Hull and later sold off in a charity auction. A charity appeal raised funds to cast a life-size bronze statue of Philip Larkin, to a design by Martin Jennings, at Hull Paragon Interchange. The statue was unveiled at a ceremony attended by the Lord Mayor of Hull on 2 December 2010, the 25th anniversary of Larkin's death. It bears an inscription drawn from the first line of Larkin's poem, 'The Whitsun Weddings'.
In 2013, from 29 April to 5 May, Hull Fashion Week took place with various events happening in venues in and around Hull's City centre. It finished with a finale on 5 May at Hull Paragon Interchange, when recently reformed pop group Atomic Kitten appeared in a celebrity fashion show.
On 3 August 2013, the second Humber Street Sesh Festival took place celebrating local music talent and arts, with several stages showcasing bands and artists from the Fruit Trade Music Label, Humber Street Sesh and Purple Worm Records.
Parks and green spaces.
Hull has a large number of parks and green spaces. These include East Park, Pearson Park, Pickering Park, Peter Pan Park (Costello Playing fields), and West Park. West Park is home to Hull's KC Stadium. Pearson Park contains a lake and a 'Victorian Conservatory' housing birds and reptiles. East Park has a large boating lake and a collection of birds and animals. East Park and Pearson Park are registered Grade II listed sites by English Heritage.
The city centre has the large Queen's Gardens parkland at its heart. This was originally built as formal ornamental gardens used to fill in the former Queen's Dock. It is now a more flexible grassed and landscaped area used for concerts and festivals, but retains a large ornamental flower circus and fountain at its western end.
The streets of Hull's suburban areas also lined with large numbers of trees, particularly the Avenues area around Princes Avenue and Boulevard to the west. Many of the old trees in the Avenues district have been felled in recent years with the stumps carved into a variety of 'living sculptures'. Other green areas include the University area and parts of Beverley Road to the north.
West Hull has a district known as 'Botanic'. This recalls the short-lived Botanic Garden that once existed on the site now occupied by Hymers College. Elephants once lived nearby in the former Zoological Gardens on Spring Bank and were paraded in the local streets. The land has since been redeveloped. There was also a former Botanic Garden between Hessle Road and the Anlaby Road commemorated by Linnaeus Street.
Media.
Hull's only local daily newspaper is the longstanding "Hull Daily Mail", whose circulation area covers much of the East Riding of Yorkshire too. A free paper, "The Hull Advertiser", used to be issued weekly by the same publisher. 
The city was once served by three competing daily newspapers, all operating from the Whitefriargate area "Eastern Morning News", "Hull News" and "Hull and East Yorkshire Times". On 17 April 1930 the last edition of "Evening News" was published after the paper was taken over by its longstanding rival the "Hull Daily Mail".
Local listings and what's-on guides include "Tenfoot City Magazine" and "Sandman Magazine" (combined into single volume covering all of England, print version then made defunct in favour of online site). The BBC has its "Yorkshire and Lincolnshire" regional headquarters at Queen's Gardens, from which the regional news programme "Look North" is broadcast.
Radio services broadcasting from the city are Hull's community radio station 106.9 West Hull FM (formerly 106.9FM WHCR) and the BBC's regional station BBC Radio Humberside, as well as commercial stations Viking FM, KCFM and Magic 1161 and Kingstown Radio, a hospital-based radio station founded in 1961, all of which broadcast to the wider East Riding of Yorkshire and Lincolnshire area.
The Hull University Union's student radio station Jam 1575, stopped broadcasting on MW due to funding cuts, but has recently (in 2014) re-launched as JamRadio, as an online only station, aimed at students at the University.
Sport.
The Hull area has available a wide range of both spectator and participatory sporting clubs and organisations. These are as various as professional football, rugby league, golf, darts, athletics and pigeon racing.
The city's professional football club, Hull City A.F.C. ("The Tigers"), played in the Championship, the second tier of the English football league system after relegation from the Premier League in season 2009–10. On Saturday 4 May 2013, they gained automatic promotion to the Premier League for the 2013–14 season after a nail-biting match against Cardiff City. The team play at the KC Stadium.
Hull is also a rugby league hub, having two clubs who play in the Super League competition. Hull F.C., alongside the city's football club Hull City, play at the KC Stadium while Hull Kingston Rovers play at Craven Park in East Hull. There are also several lower league teams in the city, such as East Hull, West Hull, Hull Dockers and Hull Isberg, who all play in the National Conference League. Rugby union is catered for by Hull Ionians who play at Brantingham Park. and Hull RUFC who are based in the city.
The city has two athletics clubs based at the Costello Stadium in the west of the city – Kingston upon Hull Athletics Club and Hull Achilies Athletics Club.
Cycling wise the city is home to Hull Cycle Speedway Club situated at the Hessle raceway near the Humber bridge. The side race in the sports Northern league and won both the league titles in 2008. Other cycling clubs also operate throughout the city including Hull Thursday, the areas road racing group.
The city also has Hull Arena, a large ice rink and concert venue, which is home to the Hull Stingrays ice hockey team who play in the Elite Ice Hockey League. It is also home to the Kingston Kestrels sledge hockey team. In August 2010, "Hull Daily Mail" reported that Hull Stingrays was facing closure, following a financial crisis. The club was subsequently saved from closure following a takeover by Coventry Blaze.
The Hull Hornets American Football (existed from 2005 until 2011) The Club which acquired full member status of the British American Football League on 5 November 2006 and played in the BAFL Division 2 Central league for 5 years. Greyhound racing returned to the city on 25 October 2007 when The Boulevard stadium re-opened as a venue for the sport.
In mid-2006 Hull was home to the professional wrestling company One Pro Wrestling, which held the Devils Due event on 27 July in the Gemtec Arena. From 16 May 2008, Hull gained its own homegrown wrestling company based at the Eastmount Recreation Centre-—New Generation Wrestling—-that have featured the likes of El Ligero, Kris Travis, Martin Kirby and Alex Shane.
Hull Lacrosse Club was formed in 2008 and currently plays in the Premier 3 division of the North of England Men's Lacrosse Association.
The city played host to the Clipper Round the World Yacht Race, a tough 35000 mi race around the globe, for the 2009–10 race which started on 13 September 2009 and finished on 17 July 2010. The locally named yacht, Hull and Humber, captained by Danny Watson, achieved second place in the 2007–2008 race.
The city will host The British Open Squash Championships at the KC Stadium in 2013 and 2014.
Transport.
The main road into and out of Hull is the M62 motorway/A63 road, one of the main east–west routes in Northern England. It provides a link to the cities of Leeds, Manchester and Liverpool, as well as the rest of the country via the UK motorway network. The motorway itself ends some distance from the city; the rest of the route is along the A63 dual carriageway. This east–west route forms a small part of the European road route E20.
Hull is close to the Humber Bridge, which provides road links to destinations south of the Humber. It was built between 1972 and 1981, and at the time was the longest single-span suspension bridge in the world. It is now seventh on the list.
Before the bridge was built, those wishing to cross the Humber had to either take a ferry or travel inland as far as Goole.
Public transport within the city is provided East Yorkshire Motor Services (EYMS), Stagecoach in Hull and CT Plus. Stagecoach In Hull provide the inter-city transport serving suburban areas such as Bransholme, Greatfield and Orchard Park, as well as going to places such as Cleethorpes, Grimsby and Scunthorpe. EYMS serve the outer-city and the East Riding of Yorkshire as well as places such as Pocklington, Scarborough, Whitby and York.
Hull Paragon Interchange, opened on 16 September 2007,
is the city's transport hub, combining the main bus and rail termini in an integrated complex. It is expected to have 24,000 people passing through the complex each day.
There is services that run to certain other parts of the UK. These include through expresses to London, up to seven per day provided by First Hull Trains and one a day (the "Hull Executive") by Virgin Trains East Coast. Other long-distance rail services are provided by First Transpennine Express serving Leeds and Manchester. The nearest access to fast East Coast Main Line services northwards to Teesside, Tyneside and Scotland is via either York or Doncaster, in either case requiring a connecting journey by local train from Hull. Hull also has no through trains to the West Midlands and beyond. Northern Rail operates regular local stopping trains to Beverley, Brough and Goole, and the coastal towns of Bridlington and Scarborough, along with services to Selby, York, Doncaster and Sheffield.
P&O Ferries provide daily overnight ferry services from King George Dock in Hull to Zeebrugge and Rotterdam.
Services to Rotterdam are worked by ferries MS "Pride of Rotterdam" and "MS Pride of Hull". Services to Zeebrugge are worked by ferries MS "Pride of Bruges" and MS Pride of York (previously named "MS Norsea"). Both Pride of Rotterdam and Pride of Hull are too wide to pass through the lock at Hull. "Associated British Ports" built a new terminal at Hull to accommodate the passengers using these two ferries. The "Rotterdam Terminal" at the "Port of Hull", was built at a cost of £14,300,000.
The nearest airport is Humberside Airport, 20 mi away in Lincolnshire, which provides a few charter flights but also has high-frequency flights to Amsterdam with KLM and Aberdeen with Eastern Airways each day. Robin Hood Airport in South Yorkshire is 48 mi from Hull city centre and provides a wider choice of charter flights as well as a number of low-cost flights to certain European destinations. The nearest airport with intercontinental flights is Leeds Bradford International Airport (70 miles).
Road transport in Hull suffers from delays caused both by the many bridges over the navigable River Hull, which bisects the city and which can cause disruption at busy times, and from the remaining three railway level crossings in the city. The level-crossing problem was greatly relieved during the 1960s by the closure of the Hornsea and Withernsea branch lines, by the transfer of all goods traffic to the high-level line that circles the city, and by the construction of two major road bridges on Hessle Road (1962) and Anlaby Road (1964).
According to the 2001 census data cycling in the city is well above the national average of 2%, with a 12% share of the travel to work traffic. A report by the University of East London in 2011 ranked Hull as the fourth-best cycling city in the United Kingdom.
Infrastructure.
Telephone system.
Hull is the only city in the UK with its own independent telephone network company, KC, formerly Kingston Communications, a subsidiary of KCOM Group. Its distinctive cream telephone boxes can be seen across the city. KC produces its own 'White Pages' telephone directory for Hull and the wider KC area. Colour Pages is KC's business directory, the counterpart to Yellow Pages. The company was formed in 1902 as a municipal department by the City Council and is an early example of municipal enterprise. It remains the only locally operated telephone company in the UK, although it is now privatised. KCOM's Internet brands are Karoo Broadband (ISP serving Hull) and Eclipse (national ISP)
Initially Hull City Council retained a 44.9 per cent interest in the company and used the proceeds from the sale of shares to fund the city's sports venue, the KC Stadium, among other things. On 24 May 2007 it sold its remaining stake in the company for over £107 million.
KC (Kingston Communications) was one of the first telecoms operators in Europe to offer ADSL to business users, and the first in the world to run an interactive television service using ADSL, known as Kingston Interactive TV (KiT), which has since been discontinued due to financial problems. In the last decade, the KCOM Group has expanded beyond Hull and diversified its service portfolio to become a nationwide provider of telephone, television, and Internet access services, having close to 180,000 customers projected for 2007. After its ambitious programme of expansion, KCOM has struggled in recent years and now has partnerships with other telecommunications firms such as BT who are contracted to manage its national infrastructure. Telephone House, on Carr Lane, the firm's 1960s-built headquarters, in stark modernist style, is a local landmark.
Public services.
Policing in Kingston upon Hull is provided by Humberside Police. In October 2006 the force was named (jointly with Northamptonshire Police) as the worst-performing police force in the United Kingdom, based on data released from the Home Office. However, after a year of "major improvements", the Home Office list released in October 2007 shows the force rising several places (although still among the bottom six of 43 forces rated). Humberside Police received ratings of "good" or "fair" in most categories.
HM Prison Hull is located in the city and is operated by HM Prison Service. It caters for up to 1,000 Category B/C adult male prisoners.
Statutory emergency fire and rescue service is provided by the Humberside Fire and Rescue Service, which has its headquarters near Hessle and five fire stations in Hull. This service was formed in 1974 following local government reorganisation from the amalgamation of the East Riding of Yorkshire County Fire Service, Grimsby Borough Fire and Rescue Service, Kingston Upon Hull City Fire Brigade and part of the Lincoln (Lindsey) Fire Brigade and a small part of the West Riding of Yorkshire County Fire and Rescue Service.
Hull and East Yorkshire Hospitals NHS Trust provides healthcare from three sites, Hull Royal Infirmary, Castle Hill Hospital and, until 2010, Princess Royal Hospital and there are several private hospitals including ones run by BUPA and Nuffield Hospitals. The Yorkshire Ambulance Service provides emergency patient transport. NHS primary health care services are commissioned by the Hull Clinical Commissioning Group and are provided at several smaller clinics and general practitioner surgeries across the city. NHS Mental health services in Hull are provided by Humber NHS Foundation Trust. It runs a memory clinic in Coltman Street, west Hull designed to help older people with early onset dementia.
Waste management is co-ordinated by the local authority. The Waste Recycling Group is a company which works in partnership with the Hull City and East Riding of Yorkshire councils to deal with the waste produced by residents. The company plans to build an energy from waste plant at Salt End to deal with 240,000 tonnes of rubbish and put waste to a productive use by providing power for the equivalent of 20,000 houses. Hull's Distribution Network Operator for electricity is CE Electric UK (YEDL); there are no power stations in the city. Yorkshire water manages Hull's drinking and waste water. Drinking water is provided by boreholes and aquifers in the East Riding of Yorkshire, and it is abstracted from the River Hull at Tophill Low, near Hutton Cranswick. Should either supply experience difficulty meeting demand, water abstracted from the River Derwent at both Elvington and Loftsome Bridge can be moved to Hull via the Yorkshire water grid. There are many reservoirs in the area for storage of potable and non-potable water. Waste water and sewage has to be transported in a wholly pumped system because of the flat nature of the terrain to a sewage treatment works at Salt End. The treatment works is partly powered by both a wind turbine and a biogas CHP engine.
Education.
Higher education.
University of Hull.
Kingston upon Hull is home to the University of Hull, which was founded in 1927 and received its Royal Charter in 1954. It now has a total student population of around 20,000 across its main campuses in Hull and Scarborough. The main University campus is in North Hull, on Cottingham Road. Notable alumni include former Deputy Prime Minister John Prescott, the poet Philip Larkin, social scientist Lord Anthony Giddens, "Woman's Hour" presenter and writer Jenni Murray, and the dramatist Anthony Minghella. Hull University is a partner in the new University Centre of the Grimsby Institute of Further and Higher Education (GIFE) being built in Grimsby, North Lincolnshire.
Hull York Medical School.
The Hull York Medical School (HYMS) is a joint venture between the University of Hull and the University of York. It first admitted students in 2003 as a part of the British government's attempts to train more doctors.
University of Lincoln.
The University of Lincoln grew out of the University of Humberside, a former polytechnic based in Hull. In the 1990s the focus of the institution moved to nearby Lincoln and the administrative headquarters and management moved in 2001. The University of Lincoln has retained a campus in George Street in Hull city centre whilst Hull University purchased the adjacent University of Lincoln campus site on Cottingham Road. Following government cuts to Higher Education funding, the George Street campus is due to close in 2013 with courses transferred to Lincoln.
Other institutions.
The Hull School of Art, founded in 1861, is regarded nationally and internationally for its excellence as a specialist creative centre for higher education.
The Northern Academy of Performing Arts and Northern Theatre School both provide education in musical theatre, performance and dance.
Schools and colleges.
Hull has over 100 local schools; of these, Hull City Council supports 14 secondary and 71 primary schools. The highest achieving state school in Hull is Malet Lambert School,
Schools which are independent of the City Council include Hymers College and Hull Collegiate School. The latter, which is run by the United Church Schools Trust, was formed by the merging of Hull Grammar School and Hull High School. There is a further education college, Hull College, and two large sixth form colleges, Wyke College and Wilberforce College. East Riding College operates a small adult education campus in the city, and Hull Trinity House School has been offering pre-sea training to prospective mariners since 1787.
There are only two single-sex schools in Hull: Trinity House, which teaches only boys, and Newland School for Girls.
Schools ratings.
The city has had a poor examination success rate for many years and is often at the bottom of government GCSE league tables.
In the 2007 the city moved off the bottom of these tables for pupils who achieve five A* to C grades, including English and Maths, at General Certificate of Secondary Education by just one place when it came 149th out of 150 local education authorities. However, the improvement rate of 4.1 per cent, from 25.9 per cent in 2006 to 30 per cent in summer 2007, was among the best in the country.
They returned to the bottom of the table in 2008 when 29.3 per cent achieved five A* to C grades which is well below the national average of 47.2 per cent.
Dialect and accent.
The local accent is quite distinctive and noticeably different from the rest of the East Riding; however it is still categorised among Yorkshire accents. The most notable feature of the accent is the strong I-mutation in words like "goat", which is [ˈɡəʊt] in standard English and [ˈɡoːt] across most of Yorkshire, becomes [ˈɡɵːt] ("gert") in and around parts of Hull, although there is variation across areas and generations.
In common with much of England (outside of the far north), another feature is dropping the H from the start of words, for example Hull is more often pronounced 'Ull in the city. The vowel in "Hull" is pronounced the same way as in northern English, however, and not as the very short /ʊ/ that exists in Lincolnshire. Though the rhythm of the accent is more like that of northern Lincolnshire than that of the rural East Riding, which is perhaps due to migration from Lincolnshire to the city during its industrial growth, one feature that it does share with the surrounding rural area is that an /aɪ/ sound in the middle of a word often becomes an /ɑː/: for example, "five" may sound like "fahve", "time" like "tahme".
The vowel sound in words such as "burnt, nurse, first" is pronounced with an /ɛ/ sound, as is also heard in Middlesbrough and in areas of Liverpool yet this sound is very uncommon in most of Yorkshire. The word pairs spur/spare and fur/fair illustrate this.
The generational and/or geographic variation can be heard in word pairs like pork/poke or cork/coke, or hall/hole, which some people pronounce almost identically, sounding to non-locals like they are using the second of the two variations - while others make more of a vocal distinction; anyone called "Paul" (for example) soon becomes aware of this (pall/pole).
Notable people.
People from Hull are called "Hullensians" and the city has been the birthplace and home to many notable people. Among the most notable persons of historic significance with a connection to Hull are William Wilberforce who was instrumental in the abolition of slavery
and Amy Johnson, aviator who was the first woman to fly solo from England to Australia.
Notable entertainers from the city include Dorothy Mackaill, actors Sir Tom Courtenay, Ian Carmichael and John Alderton and actress Maureen Lipman.
Playwrights Richard Bean, John Godber and Alan Plater have close connections with Hull.
Musicians include Paul Heaton of the Housemartins and The Beautiful South
and guitarist Mick Ronson who worked with David Bowie. The logician John Venn hailed from Hull. The poet Philip Larkin lived in Hull for 30 years and wrote much of his mature work in the city. Artist David Remfry RA studied at Hull College of Art before moving to London and New York where he has had over 50 solo exhibitions including two at the Ferens Art Gallery.
Chemist Professor George Gray, who had a 45-year career at the university, developed the first stable liquid crystals that became an immediate success for the screens of all sorts of electronic gadgets.
Notable sportspeople include Clive Sullivan, rugby league player, who played for both of Hull's professional rugby league teams and was the first black Briton to captain any national representative team. The main A63 road into the city from the Humber Bridge is named after him (Clive Sullivan Way). Nick Barmby is Hull's most famous footballing son, he played for Tottenham Hotspur, Middlesbrough, Everton, Liverpool, and Leeds United before returning to play for his hometown club Hull City, he also won 23 England caps and played in the famous 5-1 victory over Germany in 2001. Another footballer is Dean Windass, who had two spells with Hull City and scored the goal which helped the club to promotion to the top flight of English football for the first time in the club's history. On accepting a peerage, Welsh-born Baron Prescott of Kingston-upon-Hull (former MP and Deputy Prime Minister John Prescott) took his title from his adopted home city of Hull.
International relations.
Hull has formal twinning arrangements with
The following cities are named directly after Hull:
References.
Bibliography.
</dl>

</doc>
<doc id="56476" url="http://en.wikipedia.org/wiki?curid=56476" title="Rett syndrome">
Rett syndrome

Rett syndrome (RTT), originally termed cerebroatrophic hyperammonemia, is a rare genetic postnatal neurological disorder of the grey matter of the brain that almost exclusively affects females but has also been found in male patients. The clinical features include small hands and feet and a deceleration of the rate of head growth (including microcephaly in some). Repetitive stereotyped hand movements, such as wringing and/or repeatedly putting hands into the mouth, are also noted. People with Rett syndrome are prone to gastrointestinal disorders and up to 80% have seizures. They typically have no verbal skills, and about 50% of affected individuals do not walk. Scoliosis, growth failure, and constipation are very common and can be problematic.
The signs of this disorder are most easily confused with those of Angelman syndrome, cerebral palsy and autism. Rett syndrome occurs in approximately 1:10,000 live female births in all geographies, and across all races and ethnicities.
Rett syndrome was formerly classified as a pervasive developmental disorder by the "Diagnostic and Statistical Manual of Mental Disorders" (DSM), together with the autism spectrum disorders and childhood disintegrative disorder. Some argued against this classification because RTT is similar to non-autistic spectrum disorders such as fragile X syndrome, tuberous sclerosis, or Down syndrome where one can see autistic features. It was removed from the DSM-5 in 2013 because it has a known molecular etiology.
It was first described by Austrian pediatrician Andreas Rett in 1966. Huda Zoghbi demonstrated in 1999 that Rett syndrome is caused by mutations in the gene MECP2.
Signs and symptoms.
Initial development is normal. Onset occurs between 6 and 18 months of age. During this time there are subtle developmental deviations and early indicators of Rett syndrome. A period of developmental stagnation is followed by developmental regression where language and motor milestones regress, purposeful hand use is lost, and acquired deceleration in the rate of head growth (resulting in microcephaly in some) is seen. Hand stereotypes are typical, and breathing irregularities such as hyperventilation, breathholding, or sighing are seen in many. Early on, autistic-like behavior may be seen. The infant with Rett syndrome often avoids detection until 6–18 months, owing to a relatively normal appearance and some developmental progress. However, closer scrutiny reveals disturbance of the normal spontaneous limb and body movements that are thought to be regulated in the brainstem. The brief period of developmental progress is followed by stagnation and regression of previously acquired skills. During regression, some features are similar to those of autism. It is, hence, easy to mistakenly diagnose Rett syndrome for autism.
Signs of Rett syndrome that are similar to autism:
Signs of Rett syndrome that are also present in cerebral palsy (regression of the type seen in Rett syndrome would be unusual in cerebral palsy; this confusion could rarely be made):
Signs may stabilize for many decades, particularly for interaction and cognitive function such as making choices. Asocial behavior may change to highly social behavior. Motor functions may slow as rigidity and dystonia appear. Seizures may be problematic, with a wide range of severity. Scoliosis occurs in most, and may require corrective surgery. Those who remain ambulatory tend to have less progression of scoliosis.
Cause.
Genetically, Rett syndrome (RTT) is caused by mutations in the gene MECP2 located on the X chromosome, and can arise sporadically or from germline mutations. In less than 10% of RTT cases, mutations in the genes CDKL5 or FOXG1 have also been found to resemble it. Rett syndrome was initially diagnosed by clinical observation, but the diagnosis is definitive when there is a genetic defect in the MECP2 gene. In some very rare cases, no known mutated gene can be found suggesting changes in MECP2 that are not identified by presently used techniques or mutations in other genes that may result in clinical similarities.
It has been argued that Rett syndrome is in fact a neurodevelopmental condition as opposed to a neurodegenerative condition. One piece of evidence for this is that mice with induced Rett Syndrome show no neuronal death, and some studies have suggested that their phenotypes can be partially rescued by adding functional MeCP2 gene back when they are adults. This information has also helped lead to further studies aiming to treat the disorder.
Sporadic mutations.
In at least 95% of Rett syndrome cases, the cause is a "de novo" mutation in the child. That is, it is not inherited from either parent. Parents are generally genotypically normal, without a MECP2 mutation.
In cases of the sporadic form of RTT, the mutated MECP2 is thought to be derived almost exclusively from a de novo mutation on the male copy of the X chromosome. It is not yet known what causes the sperm to mutate, and such mutations are rare.
Germline mutations.
It can also be inherited from phenotypically normal mothers who have a germline mutation in the gene encoding "methyl-CpG-binding protein-2", MECP2. MECP2 is found near the end of the long arm of the X chromosome at Xq28. An atypical form of RTT, characterized by infantile spasms or early onset epilepsy, can also be caused by a mutation to the gene encoding "cyclin-dependent kinase-like 5" (CDKL5). Rett syndrome affects one in every 12,500 female live births by age 12 years.
Pontine noradrenergic deficits.
Brain levels of norepinephrine are lower in people with Rett syndrome (reviewed in). The genetic loss of "MECP2" changes the properties of cells in the locus coeruleus, the exclusive source of noradrenergic innervation to the cerebral cortex and hippocampus. These changes include hyperexcitability and decreased functioning of its noradrenergic innervation. Moreover, a reduction of the tyrosine hydroxylase (Th) mRNA level, the rate-limiting enzyme in catecholamine synthesis, was detected in the whole pons of "Mecp2"-null male as well as in adult heterozygous ("Mecp2"+/-) female mice. Using immunoquantitative techniques, a decrease of Th protein staining level, number of locus coeruleus TH-expressing neurons and density of dendritic arborization surrounding the structure was shown in symptomatic "Mecp2"-deficient mice. However, locus coeruleus cells are not dying, but are more likely losing their fully mature phenotype, since no apoptotic neurons in the pons were detected. Researchers have concluded that "Because these neurons are a pivotal source of norepinephrine throughout the brainstem and forebrain and are involved in the regulation of diverse functions disrupted in Rett syndrome, such as respiration and cognition, we hypothesize that the locus coeruleus is a critical site at which loss of "MECP2" results in CNS dysfunction." The restoration of normal locus coeruleus function may therefore be of potential therapeutic value in the treatment of Rett syndrome.
Midbrain dopaminergic disturbances.
The majority of dopamine in the mammalian brain is synthesized by nuclei located in the mesencephalon. The substantia nigra pars compacta (SNpc), the ventral tegmental area (VTA) and the retrorubral field (RRF) contains dopaminergic neurons expressing tyrosine hydroxylase (Th, i.e. the rate-limiting enzyme in catecholamine synthesis).
The nigro-striatal pathway originates from SNpc and irradiate its principal rostral target, the Caudate-Putamen (CPu) through the median forebrain bundle (MFB). This connection is involved in the tight modulation of motor strategies computed by a cortico-basal ganglia- thalamo-cortical loop.
Indeed, based on the canonical anatomofunctional model of basal ganglia, nigrostriatal dopamine is able to modulate the motor loop by acting on dopaminergic receptors located on striatal GABAergic medium spiny neurons.
Dysregulation of the nigrostriatal pathway is causative from Parkinson disease (PD) in humans. Toxic and/or genetic ablation of SNpc neurons produces experimental parkinsonism in mice and primates. The common features of PD and PD animal models are motor impairments (hypotonia, bradykinesia, hypokinesia).
RTT pathology, in some aspects, overlaps the motor phenotype observed in PD patients. Several neuropathological studies on postmortem brain samples argued for an SNpc alteration evidenced by neuromelanin hypopigmentation, reduction in the structure area, and even controversial, signs of apoptosis. In parallel, an hypometabolism was underlined by a reduction of several catecholamines (dopamine, noradrenaline, adrenaline) and their principal metabolic by-products. Mouse models of RTT are available and the most studied are constitutively deleted "Mecp2" mice developed by Adrian Bird or Rudolf Jaenisch laboratories.<Ref></ref>
In accordance with the motor spectrum of the RTT phenotype, "Mecp2"-nulls show motor abnormalities from postnatal day 30 that worsen until death. These models offer a crucial substrate to elucidate the molecular and neuroanatomical correlates of a "Mecp2"-deficiency. Recently (2008), it was shown that the conditional deletion of "Mecp2" in catecholaminergic neurons (by crossing of Th-Cre mice with loxP-flanked "Mecp2" ones) recapitulates a motor symptomatology, it was further documented that brain levels of Th in mice lacking "Mecp2" in catecholaminergic neurons only are reduced, participating to the motor phenotype.
However, the most studied model for the evaluation of therapeutics is the "Mecp2"-null mouse (totally devoid of "Mecp2"). In this context, a reduction in the number and soma size of Th-expressing neurons is present from 5 weeks of age and is accompanied by a decrease of Th immunoreativity in the caudate-putamen, the principal target of dopaminergic neurons arising from the SNpc. Moreover, a neurochemical analysis of dopaminergic contents in microdissected midbrain and striatal areas revealed a reduction of dopamine at five and nine weeks of age. It is noteworthy that later on (at nine weeks), the morphological parameters remain altered but not worsen, whereas the phenotype progresses and behavioral deficits are more severe. Interestingly, the amount of fully activated Th (Serine40-phosphorylated isoform) in neurons that remain in the SNpc is mildly affected at 5 weeks but severely impaired by 9 weeks. Finally, using a chronic and oral L-Dopa treatment on "Mecp2"-deficient mice authors reported an amelioration of some of the motor deficits previously identified. Altogether, these results argue for an alteration of the nigrostriatal dopaminergic pathway in "Mecp2"-deficient animals as a contributor of the neuromotor deficits.
There is an association of the disease with brain-derived neurotrophic factor (BDNF).
Treatment.
Currently there is no cure for Rett syndrome, but studies have shown that restoring MECP2 function may lead to a cure. One area of research is in the use of Insulin-like Growth Factor 1 (IGF-1), which has been shown to partially reverse signs in MeCP2 mutant mice.
Another promising area of therapeutic intervention is to counter the neuroexcitotoxic effect of increased spinal fluid levels of a neurotransmitter called glutamate and increased NMDA receptors in the brain of young Rett girls, by the use of dextromethorphan, which is an antagonist of the NMDA receptor in those below the age of 10 years.
Treatment of Rett syndrome includes:
Because of the increased risk of sudden cardiac death, when long QT syndrome is found on an annual screening EKG it is treated with an anti-arrhythmic such as a beta-blocker. There is some evidence that phenytoin may be more effective than a beta-blocker.
The challenge of developing therapies for MECP2 disorders.
Recent studies, funded by the International Rett Syndrome Foundation, demonstrate that neurological deficits resulting from loss of MECP2 can be reversed upon restoration of gene function. These studies are quite exciting because they show that neurons that have suffered the consequences of loss of MECP2 function are poised to regain functionality once MECP2 is provided gradually and in the correct spatial distribution. This provides hope for restoring neuronal function in patients with RTT.
However, the strategy in humans will require providing the critical factors that function downstream of MECP2 because of the challenges in delivering the correct MECP2 dosage only to neurons that lack it, given that the slightest perturbation in MECP2 level is deleterious. Thus, therapeutic strategies necessitate the identification of the molecular mechanisms underlying individual RTT phenotypes and picking out the candidates that can be therapeutically targeted.
The next phase of research needs to assess how complete the recovery is. Clearly, lethality, level of activity, and hippocampal plasticity are rescued, but are the animals free of any other RTT signs such as social behavior deficits, anxiety, and cognitive impairments? Since postnatal rescue results in viability, it will be important to evaluate if even the subtler phenotypes of RTT and MECP2 disorders are rescued when protein function is restored postnatally. This is particularly important given emerging data about early neonatal experiences and their long-term effects on behavior in adults.
Occupational, speech, and physical therapy.
The symptoms of RTT severely limit individuals from independently taking part in meaningful activities in their day-to-day lives. As a result, most people with this disorder are very dependent on their caregivers in most areas of their lives. Occupational therapists (OTs) try to find ways to encourage these individuals to take part in activities that are meaningful to them, as this has been shown to improve health and well being. The goals of occupational therapy interventions are to maintain or improve the functional abilities of individuals with this disorder. It is important to remember that services for each individual with RTT can differ greatly. OTs work together with clients and their families to help clients achieve their unique goals. OTs not only provide direct services for the client and families, but they can also connect family members to information and resources outside of occupational therapy. Services provided may include but are not limited to: maintaining motor and daily living skills and maintaining cognitive and communication functioning.
Self-care.
Some symptoms such as involuntary stereotypical hand movements can make eating a very difficult self-care task for individuals with RTT. One way OTs address this problem is by educating and encouraging caregivers to practice guided feeding. Guided feeding involves having the individual with RTT grasp the spoon and having the caregiver's hand over top of the child's in order to guide the movement of the individual to eat. The purpose of this therapy is to encourage involvement in this important self-care activity, particularly for individuals with severe cases of RTT. Signals such as opening their mouth in preparation for food, rejecting unwanted foods, and spending an increased amount of time watching their helpers, indicates that guided feeding therapy can increase engagement in eating in some cases.
Another way OTs may increase involvement in eating and hand function in general is by making hand splints. Research suggests that hand splints place the hand in a more functional position and prevent repetitive motion; this leads to better finger and spoon-feeding skills. Although fully independent feeding is rare for individuals with RTT, hand splints allow them to become more engaged in eating. Alternatively, active participation can be encouraged through the use of elbow splints, which decrease the repetitive stereotyped arm movements characteristic of RTT. As a result, socialization and interaction with the environment during eating may increase.
Other adaptations to eating include altering the pace of feeding and recommending specific foods and textures that the individual is easily able to swallow. In addition, OT’s provide adaptive devices such as cuffs and loops (to help the individual hold their utensils), large handled utensils that are easier to grasp, and cups with lids to assist with eating and address proper nutrition. In general, all of these therapeutic methods are aimed at improving the quality of the swallowing response and general eating performance. Although parental and self-reports indicate good appetite in most of the population, weight loss is an issue that many individuals with RTT face. This suggests the importance of proper nutritional education for both the individual and their caregivers. This education, along with meal management and planning, may be provided by the Speech and language therapist often in consultation with OT, a nutritionist or dietitian.
The Speech and Language Therapist will assess the person for signs of respiratory compromise and other symptoms of swallowing difficulty, and negotiate management strategies based on balancing and maintaining the persons physical safety, psychological well-being and quality of life. The speech pathologist works with the family, caregivers and client to improve communication and social interaction. This may include using an aac device, eye contact or using their body to communicate their wants and needs to others.
Seating and positioning the individual can also affect how they do daily tasks such as eating, dressing, and grooming. In order for an individual to engage in these tasks, OTs may adjust and modify tables, chairs, and wheelchairs to promote positive interactions within different social environments. OTs are also involved in educating families on various adaptive devices that can promote comfort, ease of use, and safety for children and their caregivers. Some of the commonly used adaptive devices include bath benches, toilet chairs, and movable shower heads. Finally, occupational therapists work with children and their families to develop skills required to brush their teeth and hair, bathe, and dress.
If children with RTT are in school during the day, OTs PTs and speech pathologists can play a role in teaching special education assistants (SEA’s) about the self-care needs of the child. This can include education on feeding techniques that are suitable for the child, proper mechanics of lifts and transfers, as well as toileting techniques and routines.
Productivity.
Occupational therapists and physical therapists are involved in helping children with RTT function optimally at school. One of their primary concerns is regarding the child’s seating and positioning in the school environment. As RTT highly impacts a child physically, they often require customized seating, whether it is in the form of a wheelchair or customized chair and desk combinations. The OT or PT consults and provides the equipment necessary for children to be stable and comfortable in their seats. This helps children with RTT stay more focused on their learning and classroom activities, instead of expending energy trying to stay seated upright and balanced. Ultimately, being properly seated may facilitate increased social skills; this is because a child is now able to maintain eye contact with their peers, look around the classroom, and engage with their social environment.
Additionally, OTs, PTs, and speech pathologists are very involved with consulting and educating the child’s teachers and SEAs to better facilitate the child’s learning and care within the school. The team of PT, OT, and speech pathologist may also provide adaptive tools including: boards, adaptive school supplies, and the use of eye-gaze and/or switches to activate educational programs on the computer. These tools may facilitate the individual's communication with other people; they may be able to better communicate their needs, preferences, and choices using these devices.
The team may also suggest certain physical adaptations within the school to better suit the needs of the child. This may include suggestions for classroom setup, adaptations to the washrooms, as well as the installation of ramps, lifts, and/or elevators.
Leisure.
Children with RTT need to engage and participate in leisure activities just like typically developing children. Play is the primary activity of childhood and is considered to be both a form of leisure and productivity; it is essential to development as it facilitates cognitive, physical, social, and emotional well-being. Play is an activity with multiple purposes; it provides opportunities for a child to grow and develop, explore, learn, build relationships, and develop interests. Because play is so central to a child's development, therapists try and find ways that allow these children to play. The support team including special ed teacher, OT pt, and speech pathologist work with clients and their family to make sure that the interventions focus on play activities that are meaningful to the child, whether it be arts, music, sports, computer games, and/or maintaining social relationships. There is no set list of the services that are provided in terms of leisure activities, as the team works with the child to find activities that he or she finds enjoyable and important. Some examples of how the team may facilitate play include adapting bicycles, providing switches so that the child can turn on music/video players, and connecting the child and her family to resources and programs within the community.
In addition, some therapeutic activities are regarded as highly enjoyable for children with RTT and can be considered a form of play as well as therapy. One such activity that children with RTT may participate in is aquatic, or swimming therapy. The aims of swimming therapy are to promote relaxation, improve circulation, strengthen muscles, and improve coordination and balance. Aquatic therapy is an enjoyable and relaxing activity for children with RTT, and in some cases therapy has been associated with a decrease in abnormal hand movements and an increase in goal directed hand movements and feeding skills. Examples of other activities that are therapeutic and enjoyable include horseback riding therapy and music therapy.
Communication.
Individuals with RTT often do not develop, or lose the ability to communicate through speech. If these individuals cannot communicate with their family and caregivers it makes it very difficult for them to participate in daily activities as they also have severe physical difficulties. Speech pathologists plan communication interventions that aim to increase the skills needed for carrying out self-care, productivity, and leisure tasks. Studies suggest that only twenty percent of the people with RTT had the use of words, and most of these words were used out of context and without meaning. As a result of their lack of spoken language, individuals with RTT can benefit from Augmentative and Alternative Communication (AAC), which are communication methods used in place of speech. Examples of AAC may be written language, body language, and facial expressions. It is within the scope of practice for speech-language pathologists to provide a thorough AAC evaluation taking into consideration all factors such as sensory, motor, kinesthetic, speech, and receptive as well as expressive language in its verbal and non-verbal forms. OTs are consulted in this process, to determine motor or sensory skills and deficits, as well as seating and positioning. This evaluation will result in a recommendation of AAC systems, which often include low-technology, mid-technology and high-technology systems. A speech-language pathologist will also provide therapy to help the client with RTT to access and learn the systems once they are procured, through private funds, school districts, or private/public medical insurance.
Some of the AAC systems common to individuals with RTT include eye-gaze boards, communication boards, switches, or voice output communication devices. Speech-Language Pathologists (SLPs), often with specialized AAC training and knowledge, provide education and training to families, educational teams, and other communication partners on these tools. AAC options are often divided into three levels of technology: no technology, low technology, and higher technology (mid-tech or high-tech, consisting of systems requiring the use of a battery or powercord). The simplest way to communicate is through ‘no technology’ or "unaided" methods in which the individuals with RTT indicates a response (i.e., points, blinks their eyes, raises their eyebrows) to indicate a response. The second type are ‘low technology’ communication systems which often include using pictures, symbols, and/or objects placed on a board. A person then uses eye gaze or finger pointing to show his or her choices. Communication boards can be set up by the SLP and OT in both home and school environments. The third and most complex level of technology is ‘higher technology’. Some of the more commonly used technological devices include voice output systems and computer communication software. Low-technology, mid-technology, and high-technology systems are considered "aided" systems, as they require the use of an object other than one's own body to communicate. The SLP and OT work with the child, as well as the family, caregivers, and school assistants to encourage the child to communicate as much as possible by using all these different tools.
Variants of Rett syndrome.
The clinical signs of Rett syndrome typical form are perfectly identified (e.g. see above).
In addition to the classical form of Rett syndrome, several «atypical forms» have been described over the years, the main groups are:
The definition itself of the Rett syndrome has been refined over the years: as the atypical forms subsist near to the classical form (Hagberg & Gillberg, 1993), the "Rett Complex" terminology has been introduced.
Prognosis.
Males with pathogenic "MECP2" mutations usually die within the first 2 years from severe encephalopathy, unless they have an extra X chromosome (often described as Klinefelter syndrome), or have somatic mosaicism.
Male fetuses with the disorder rarely survive to term. Because the disease-causing gene is located on the X chromosome, a female born with a MECP2 mutation on her X chromosome has another X chromosome with an ostensibly normal copy of the same gene, while a male with the mutation on his X chromosome has no other X chromosome, only a Y chromosome; thus, he has no normal gene. Without a normal gene to provide normal proteins in addition to the abnormal proteins caused by a MECP2 mutation, the XY karyotype male fetus is unable to slow the development of the disease, hence the failure of many male fetuses with a MECP2 mutation to survive to term. Females with a MECP2 mutation, however, have a non-mutant chromosome that provides them enough normal protein to survive longer. Research shows that males with Rett syndrome may result from Klinefelter's syndrome in which, the male has an XXY karyotype. Thus, a non-mutant "MECP2" gene is necessary for a Rett's-affected embryo to survive in most cases, and the embryo, male or female, must have another X chromosome.
There have, however, been several cases of 46,XY karyotype males with a MECP2 mutation (associated with classical Rett syndrome in females) carried to term, who were affected by neonatal encephalopathy and died before 2 years of age. The incidence of Rett syndrome in males is unknown, partly owing to the low survival of male fetuses with the Rett syndrome-associated MECP2 mutations, and partly to differences between signs caused by MECP2 mutations and those caused by Rett's.
Females can live up to 40 years or more. Laboratory studies on Rett syndrome may show abnormalities such as:
A high proportion of deaths are abrupt, but most have no identifiable cause; in some instances death is the result most likely of:

</doc>
<doc id="56478" url="http://en.wikipedia.org/wiki?curid=56478" title="North">
North

North is a noun, adjective, or adverb indicating direction or geography. North is one of the four cardinal directions or compass points. It is the opposite of south and is perpendicular to east and west.
Etymology.
The word "north" is related to the Old High German "nord", both descending from the Proto-Indo-European unit "ner-", meaning "down" (or "under"). (Presumably a natural primitive description of its concept is "to the left of the rising sun".)
The Latin word "borealis" comes from the Greek "boreas" "north wind, north", which, according to Ovid, was personified as the son of the river-god Strymon, the father of Calais and Zetes. "Septentrionalis" is from "septentriones", "the seven plow oxen", a name of "Ursa Maior". The Greek "arktikos" is named for the same constellation, and is the derivation of the English word "Arctic".
Other languages have sometimes more interesting derivations. For example, in Lezgian, "kefer" can mean both 'disbelief' and 'north', since to the north of the Muslim Lezgian homeland there are areas formerly inhabited by non-Muslim Caucasian and Turkic peoples. In many languages of Mesoamerica, "north" also means "up". In Hungarian the word for north is "észak", which is derived from "éjszaka" ("night"), since in the Northern Hemisphere the Sun never shines from the north.
Mapping.
By convention, the top side of a map is often north.
To go north using a compass for navigation, set a bearing or azimuth of 0° or 360°.
North is specifically the direction that, in Western culture, is treated as "the" fundamental direction:
Magnetic north and declination.
Magnetic north is of interest because it is the direction indicated as north on a properly functioning (but uncorrected) magnetic compass. The difference between it and true north is called the magnetic declination (or simply the declination where the context is clear). For many purposes and physical circumstances, the error in direction that results from ignoring the distinction is tolerable; in others a mental or instrument compensation, based on assumed knowledge of the applicable declination, can solve all the problems. But simple generalizations on the subject should be treated as unsound, and as likely to reflect popular misconceptions about terrestrial magnetism.
Maps intended for usage in orienteering by compass will clearly indicate the local declination for easy correction to true north. Maps may also indicate grid north, which is a navigational term referring to the direction northwards along the grid lines of a map projection.
Roles of north as prime direction.
The visible rotation of the night sky around the visible celestial pole provides a vivid metaphor of that direction corresponding to up. Thus the choice of the north as corresponding to up in the northern hemisphere, or of south in that role in the southern, is, prior to world-wide communication, anything but an arbitrary one. On the contrary, it is of interest that Chinese and Islamic culture even considered south as the proper top end for maps.
In Western culture:
Roles of east and west as inherently subsidiary directions.
While the choice of north over south as prime direction reflects quite arbitrary historical factors, east and west are not nearly as natural alternatives as first glance might suggest. Their folk definitions are, respectively, "where the sun rises" and "where it sets". Except on the Equator, however, these definitions, taken together, would imply that
Reasonably accurate folk astronomy, such as is usually attributed to Stone Age peoples or later Celts, would arrive at east and west by noting the directions of rising and setting (preferably more than once each) and choosing as prime direction one of the two mutually opposite directions that lie halfway between those two. The true folk-astronomical definitions of east and west are "the directions, a right angle from the prime direction, that are closest to the rising and setting, respectively, of the sun (or moon).
Cultural references.
Being the "default" direction on the compass, north is referred to frequently in Western popular culture. Some examples include:

</doc>
<doc id="56479" url="http://en.wikipedia.org/wiki?curid=56479" title="Theaetetus (dialogue)">
Theaetetus (dialogue)

The Theaetetus (; Greek: Θεαίτητος) is one of Plato's dialogues concerning the nature of knowledge, written "circa" 369 BC. 
In this dialogue, Socrates and Theaetetus discuss three definitions of knowledge: knowledge as nothing but "perception", knowledge as "true judgement", and, finally, knowledge as a "true judgement with an account." Each of these definitions is shown to be unsatisfactory. 
Socrates declares Theaetetus will have benefited from discovering what he does not know, and that he may be better able to approach the topic in the future. The conversation ends with Socrates' announcement that he has to go to court to face a criminal indictment.
The framing of the dialogue.
The dialogue is framed by a brief scene in which Euclides tells his friend Terpsion that he has a written record of a dialogue between Socrates and Theaetetus, which occurred when Theaetetus was quite a young man. This dialogue is then read aloud to the two men by a slave boy in the employ of Euclides.
Midwife to knowledge.
Socrates asks Theodorus if he knows of any geometry students who show particular promise. Theodorus assures him that he does, but that he does not want to over-praise the boy, lest anyone suspect he is in love with him. He says that the boy, Theaetetus, is a young Socrates look-alike, rather homely, with a snub-nose and protruding eyes. The two older men spot Theaetetus rubbing himself down with oil, and Theodorus reviews the facts about him, that he is intelligent, virile, and an orphan whose inheritance has been squandered by trustees.
Socrates tells Theaetetus that he cannot make out what knowledge is, and is looking for a simple formula for it. Theaetetus says he really has no idea how to answer the question, and Socrates tells him that he is there to help. Socrates says he has modelled his career after his midwife mother. She delivered babies and for his part, Socrates can tell when a young man is in the throes of trying to give birth to a thought.
Philosophical labor.
Socrates thinks that the idea that knowledge is perception must be identical in meaning, if not in actual words, to Protagoras' famous maxim "Man is the measure of all things." Socrates wrestles to conflate the two ideas, and stirs in for good measure a claim about Homer being the captain of a team of Heraclitan flux theorists. Socrates dictates a complete textbook of logical fallacies to the bewildered Theaetetus. When Socrates tells the child that he (Socrates) will later be smaller "without losing an inch" because Theaetetus will have grown relative to him, the child complains of dizziness (155c). In an often quoted line, Socrates says with delight that "wonder (thaumazein) belongs to the philosopher". He admonishes the boy to be patient and bear with his questions, so that his hidden beliefs may be yanked out into the bright light of day.
Examining the offspring.
When Socrates sums up what they have agreed on so far, it becomes problematic that knowledge is sense perception, for Socrates raises the question that "When the same wind blows, one of us feels cold and the other not?" As a result he introduces the idea of Heraclitean flux to act as a defense to the wind objection. Heracliteanism shows that "Nothing is in itself just one thing...Everything is in a process of coming to be". Thus as there is no fixed meaning in things, but they draw their meaning in a referential difference to other things, the wind objection can be incorporated into Theaetetus's claim that "Knowledge is sense perception". As a result they can then continue their inquiry as to the truth of this claim. It is important to note that the Heraclitean doctrine of Flux is not the same as the Protagorean doctrine. The Protagorean is radical truth relativism whereas the Heraclitean is radical reality relativism. It serves as a supporting theory to the Protagorean interpretation of Theaetetus's claim, in order that they might fully inquire as to the validity of this premise. Socrates admits that it is unfortunate that Protagoras is dead and cannot defend his idea against people such as himself. He says that the two of them are "trampling on his orphan" (164e) but the charge remains.
Abusing the "orphan" of Protagoras.
Since Protagoras is dead, Socrates puts himself in the sophist's shoes and tries to do him the favor of defending his idea (166a-168c). Socrates concedes that if Protagoras were still alive, he would have more to say in his own defense, and that they are now essentially mistreating "his orphan child." Putting words in the dead sophist's mouth, Socrates declares that Protagoras asserts with his maxim that all things are in motion and whatever seems to be the case, is the case for the perceiver, whether the individual or the state.
At the end of his speech, Socrates admits to Theodorus that Protagoras would have done a far better job of defending his own ideas. Theodorus tells Socrates that he must be kidding, that he has come to the task with boyish vigor. Theodorus does not claim to be a disciple of Protagoras, but states that he was a friend. Socrates invites Theodorus to put up a more vigorous defense of Protagoras, as he does not want it suggested that he has used the child's timidity (of Theaetetus) to aid him in his argument against the doctrine of Protagoras (168d).
Socrates, not at all certain that he has not misrepresented Protagoras in making each man the measure of his own wisdom, presses Theodorus on the question of whether any follower of Protagoras (himself included) would contend that nobody thinks anyone else is wrong (170c). Theodorus proves to be helpless against Socrates' arguments. He agrees that Protagoras concedes that those who disagree with him are correct (171a). In making Protagoras a complete epistemological relativist, where every person's individual perceptions are his reality and his truth, both Socrates and Theodorus paint Protagoras as maintaining an absurd position.
The absent-minded philosopher.
Socrates then proceeds to explain why philosophers seem clumsy and stupid to the common lot of humanity. Socrates explains that philosophers are open to mockery because they are not concerned about what interests most people: they could not care less about the scandals in their neighbor's house, the tracing of one's ancestry to Heracles, and so on. In contrast, the philosopher is concerned with things that "are", such as beauty and knowledge, which are "truly higher up". It is here that Socrates draws the classic portrait of the absent-minded intellectual who cannot make his bed or cook a meal (175e). Socrates adds a big bifurcation to this speech, saying that there are only two kinds of lives to be lived: a divinely happy one, lived by righteous philosophers or a godless, miserable one, such as most people live (176-177). Socrates admits this was a digression that threatens to drown his original project, which was to define knowledge. Theodorus, the old geometer, tells Socrates that he finds this sort of thing easier to follow than his earlier arguments.
The men of flux.
Socrates says that the men of flux, like Homer and Heraclitus, are really hard to talk to because you can't pin them down. When you ask them a question, he says, they pluck from their quiver a little aphorism to let fly at you, and as you try to figure that one out, they wing another one at you. They leave nothing settled either in discourse, or in their own minds. Socrates adds that the opposite school of thought, that teaches of the "immovable whole" is just as hard to talk to (181a,b). Socrates says he met the father of the idea, Parmenides, when he was quite young, but does not want to get into another digression over it.
The mind as a bird cage.
Perhaps the most delightful talk in the dialogue comes near the end, when Socrates compares the human mind to a birdcage. Socrates draws the distinction between "having" and "possessing"; the former typically implies the latter, though on the other hand, one can possess something, such as a bird, without actually having it (with them at any moment)(199a). Socrates says that as a man goes hunting about in his mind for knowledge of something, he might grab hold of the wrong thing. He says that mistaking "eleven" for "twelve" is like going in for a pigeon and coming up with a dove (199b). Theaetetus joins in the game, and says that to complete the picture, you need to envision pieces of ignorance flying around in there with the birds. But if this is the case, how would you be able to distinguish between the birds representing real knowledge and the ones representing false ones? Are there other birds that represent this type of knowledge? Socrates comes to the conclusion that this is absurd and therefore he discards the birdcage analogy.
Socrates and the Jury.
After discarding the bird-cage analogy, Socrates and Theaetetus return to the definition of knowledge as 'true judgement' (200e). This, Theaetetus argues, is true because it is 'free from mistakes' (200e). However Socrates introduces an example of a jury in the law-courts, being persuaded of an opinion by a lawyer. This persuasion is not the same as knowing the truth, as all is produced is 'conviction' in judging whatever the lawyers want (201a). Although Theaetetus hopes it is possible the lawyer will be able to 'persuade' the jury of the truth (201b), Socrates is unsatisfied as if they are justly persuaded, they will have true knowledge. However, in Socrates' belief, they cannot make a correct judgement as they would not have true knowledge (201c). With this conflict, Socrates decides that true judgement and knowledge must be different things.
Knowledge as judgement with an account.
After distinguishing between knowledge and true judgement, Theaetetus recalls being told that true judgement 'with an account ("logos") equates to knowledge (201d). Things without an account are 'unknowable', while things with an account are 'knowable'.
Socrates responds by telling of a dream, in which he overheard people talking of primary elements (201e). These primary elements can only be named, they cannot be thought of as existing or not - he gives examples of words like 'itself, or that, each, alone or this' (202a). While they can be added to other words, they by themselves are just a name. When these elements are added together, Socrates says that a 'complex' is formed (202b). The primary elements are 'unaccountable and unknowable, but perceivable' while the complexes are 'knowable and expressible' and so can be objects of 'true judgement' (202b). He concludes his dream by agreeing with Theaetetus that knowledge is 'true judgement with an account' (202c).
However, Socrates exposes some difficulties by examining letters. He takes the first two letters of his name, S and O to wonder if the syllable 'So' is knowable while the individual letters are not (203b-d). Theaetetus finds the idea strange, so Socrates deduces that in order to know the syllable, the letters must be known first (203e). Socrates proposes that the syllable can be a 'single form' produced from the letters. With this in mind, Socrates considers whether the 'sum' and the 'whole' are the same (204a). Theaetetus initially says they are not, but changes his mind in confusion when Socrates leads him through maths and the different ways of expressing the number six (204c-205b). After agreeing this, Socrates returns to the subject of syllables and letters to conclude from Theaetetus' answers that syllables are different from letters and cannot contain letters (205b). Theaetetus admits this idea is ridiculous (205c). Socrates returns to talking about elements and complexes to propose that they are in the same class, as they have 'no parts and [are] a single form' (205d).
Socrates sums up this reversal by remarking that if anyone tries to tell them the complex is knowable and expressable while the element is the opposite, 'we had better not listen to him' (205e). He cites the example of a musician distinguishing individual notes (conceded to be elements of music) to propose that elements are 'much more clearly known'(206b).
Socrates proposes an account to be 'making one's thought apparent vocally by means of words and verbal expressions' (206d). However, he wonders if that is so, everyone will be able to make judgement 'with an account' as they can all (except for the deaf and dumb) vocalize and express opinions on matters (206e). Socrates examines it further by suggesting that a man who can vocalize his judgement must be able to make reference to the primary elements of the subject (207a). Giving an example of defining a wagon by its individual parts (207a), agreement is reached that an account is 'going through a thing element by element'(207d). Socrates questions Theaetetus by drawing on his learning of how to write, and the idea that if you misplace individual elements (letters) of a name, that does not mean you have knowledge of it (208a). This finishes Socrates' second definition of an account as 'the way to the whole through the elements' (208c). The third definition Socrates offers is 'being able to tell some mark by which the object you are asked about differs from all other things' (208c), giving the example that the Sun is distinct for its brightness. However, this definition of an account fails as by getting to know the differentness of an object, you have to acquire knowledge about it. Thus the answer to the initial question 'What is knowledge' would be heavily circuitous - correct judgement accompanied by 'knowledge' of the differentness, which Socrates admits is 'silly' (210a).
Conclusion.
Socrates concludes the dialogue by announcing that all the two have produced is mere "wind-eggs" and that he must be getting on now to the courthouse to face his trial being brought against him by Meletus.
Significant references in the dialogue.
In this dialogue, Socrates refers to Epicharmus of Kos as "the prince of Comedy" and Homer as "the prince of Tragedy", and both as "great masters of either kind of poetry". This is significant because it is one of the very few extant references in greater antiquity (Fourth century BC) to Epicharmus and his work. Another reference is in Plato's "Gorgias" dialogue.

</doc>
<doc id="56480" url="http://en.wikipedia.org/wiki?curid=56480" title="Q fever">
Q fever

Q fever is a disease caused by infection with "Coxiella burnetii", a bacterium that affects humans and other animals. This organism is uncommon, but may be found in cattle, sheep, goats and other domestic mammals, including cats and dogs. The infection results from inhalation of a spore-like small cell variant, and from contact with the milk, urine, feces, vaginal mucus, or semen of infected animals. Rarely, the disease is tick borne. The incubation period is 9–40 days. Humans are vulnerable to Q-fever, and infection can result from even a few organisms. The bacterium is an obligate intracellular pathogenic parasite.
Signs and symptoms.
Incubation period is usually two to three weeks. The most common manifestation is flu-like symptoms with abrupt onset of fever, malaise, profuse perspiration, severe headache, muscle pain, joint pain, loss of appetite, upper respiratory problems, dry cough, pleuritic pain, chills, confusion and gastrointestinal symptoms, such as nausea, vomiting, and diarrhea. 
Approximately half of infected individuals exhibit no symptoms.
During its course, the disease can progress to an atypical pneumonia, which can result in a life-threatening acute respiratory distress syndrome (ARDS), whereby such symptoms usually occur during the first four to five days of infection.
Less often, Q fever causes (granulomatous) hepatitis, which may be asymptomatic or becomes symptomatic with malaise, fever, liver enlargement, and pain in the right upper quadrant of the abdomen. Whereas transaminase values are often elevated, jaundice is uncommon. Retinal vasculitis is a rare manifestation of Q fever.
The chronic form of Q fever is virtually identical to inflammation of the inner lining of the heart (endocarditis), which can occur months or decades following the infection. It is usually fatal if untreated. However, with appropriate treatment, the mortality falls to around 10%.
Clinical signs in animals.
Cattle, goats and sheep are most commonly infected, and can serve as a reservoir for the bacteria. Q fever is a well recognized cause of abortions in ruminants and in pets. "C. burnetii" infection in dairy cattle has been well documented and its association with reproductive problems in these animals has been reported in Canada, USA, Cyprus, France, Hungary, Japan, Switzerland and West Germany. For instance, in a study published in 2008, a significant association has been shown between the herds’ seropositivity and typical clinical signs of Q fever observed such as abortion, stillbirth, weak calves and repeat breeding. Moreover, experimental inoculation of "C. burnetii" in cattle induced not only respiratory disorders and cardiac failures (myocarditis) but also frequent abortions and irregular repeat breedings.
Diagnosis.
Diagnosis is usually based on serology (looking for an antibody response) rather than looking for the organism itself. Serology allows to detect chronic infection as high antibody levels are found against the virulent form of the bacterium. Molecular detection of bacterial DNA is increasingly used. Culture is technically difficult and not routinely available in most microbiology laboratories.
Q fever can cause endocarditis (infection of the heart valves) which may require transoesophageal echocardiography to diagnose. Q fever hepatitis manifests as an elevation of ALT and AST, but a definitive diagnosis is only possible on liver biopsy, which shows the characteristic fibrin ring granulomas.
Treatment.
Treatment of the acute Q fever with antibiotics is very effective and should take place in consultation with an infectious diseases specialist. Commonly used antibiotics include doxycycline, tetracycline, chloramphenicol, ciprofloxacin, ofloxacin, and hydroxychloroquine. The chronic form is more difficult to treat and can require up to four years of treatment with doxycycline and quinolones or doxycycline with hydroxychloroquine.
Q fever in pregnancy is especially difficult to treat because doxycycline and ciprofloxacin are contraindicated in pregnancy. The preferred treatment is five weeks of co-trimoxazole.
Prevention.
Protection is offered by Q-Vax, a whole-cell, inactivated vaccine developed by an Australian vaccine manufacturing company, CSL. The intradermal vaccination is composed of killed "Coxiella burnetii" organisms. Skin and blood tests should be done before vaccination to identify pre-existing immunity, because vaccinating subjects who already have an immunity can result in a severe local reaction. After a single dose of vaccine, protective immunity lasts for many years. Revaccination is not generally required. Annual screening is typically recommended.
In 2001, Australia introduced a national Q fever vaccination program for people working in "at risk" occupations.
The Soviet Union had earlier developed a killed vaccine, but its side effects prevented its licensing abroad.
Preliminary results suggest vaccination of animals may be a method of control. Published trials proved that use of a registered Phase I vaccine (Coxevac) in infected farms is a tool of major interest to manage or prevent early or late abortion, repeat breeding, anoestrus, silent oestrus, metritis and decreases in milk yield when "C. burnetii" is the major cause of these problems.
Epidemiology.
The pathogenic agent is found everywhere except New Zealand. The bacterium is extremely sustainable and virulent: a single organism is able to cause an infection. The common way of infection is inhalation of contaminated dust, contact with contaminated milk, meat, wool and particularly birthing products. Ticks can transfer the pathogenic agent to other animals. Transfer between humans seems extremely rare and has so far been described in very few cases.
Some studies have shown more men to be affected than women, which may be attributed to different employment rates in typical professions.
"At risk" occupations include, but are not limited to:
Biological warfare.
Q fever has been developed as a biological weapon. 
The United States investigated Q fever as a potential biological warfare agent in the 1950s, with eventual standardization as agent OU. At Fort Detrick and Dugway Proving Ground, human trials were conducted on Whitecoat volunteers to determine the median infective dose (18 MICLD50/person i.h.) and course of infection. The Deseret Test Center dispensed biological Agent OU with ships and aircraft, during Project 112 and Project SHAD. As a standardized biological, it was manufactured in large quantities at Pine Bluff Arsenal, with 5,098 gallons in the arsenal in bulk at the time of demilitarization in 1970. 
Q fever is currently ranked as a "Category B" bioterrorism agent by the CDC. It can be contagious, and is very stable in aerosols in a wide range of temperatures. Q fever microorganisms may survive on surfaces up to 60 days.
It is considered a good agent in part because its ID50 (number of bacilli needed to infect 50% of individuals) is considered to be 1, making it the lowest known to man.
History.
Q-fever was first described in 1935 by Edward Holbrook Derrick in abattoir workers in Brisbane, Queensland, Australia. The "Q" stands for "query" and was applied at a time when the causative agent was unknown; it was chosen over suggestions of "abattoir fever" and "Queensland rickettsial fever", to avoid directing negative connotations at either the cattle industry or the state of Queensland.
The pathogen of Q fever was discovered in 1937, when Frank Macfarlane Burnet and Mavis Freeman isolated the bacterium from one of Derrick’s patients. It was originally identified as a species of "Rickettsia". H.R. Cox and Gordon Davis elucidated the transmission when they isolated it from ticks in Montana, USA in 1938. It is a zoonotic disease whose most common animal reservoirs are cattle, sheep and goats. "Coxiella burnetii" — named for Cox and Burnet — is no longer regarded as closely related to Rickettsiae, but as similar to "Legionella" and "Francisella", and is a proteobacterium.
In popular culture.
An early mention of Q fever was important in one of the early Dr. Kildare films (1939, "Calling Dr. Kildare"). Kildare's mentor Dr. Gillespie (Lionel Barrymore) tires of his protege working fruitlessly on "exotic diagnoses" ("I think it's Q fever!") and sends him to work in a neighborhood clinic instead.
Q fever was also highlighted in an episode of the U.S. television medical drama "House" ("The Dig", Season 7, Episode 18).

</doc>
<doc id="56481" url="http://en.wikipedia.org/wiki?curid=56481" title="Tay–Sachs disease">
Tay–Sachs disease

Tay–Sachs disease (also known as GM2 gangliosidosis or hexosaminidase A deficiency) is a rare autosomal recessive genetic disorder. In its most common variant (known as infantile Tay–Sachs disease), it causes a progressive deterioration of nerve cells and of mental and physical abilities that begins around six months of age and usually results in death by the age of four. The disease occurs when harmful quantities of cell membrane components known as gangliosides accumulate in the brain's nerve cells, eventually leading to the premature death of the cells. A ganglioside is a form of sphingolipid, which makes Tay–Sachs disease a member of the sphingolipidoses. There is no known cure or treatment.
The disease is named after the British ophthalmologist Waren Tay, who in 1881 first described a symptomatic red spot on the retina of the eye; and after the American neurologist Bernard Sachs of Mount Sinai Hospital, New York, who described in 1887 the cellular changes of Tay–Sachs disease and noted an increased disease prevalence in Ashkenazi Jewish people.
Research in the late 20th century demonstrated that Tay–Sachs disease is caused by a genetic mutation in the "HEXA" gene on (human) chromosome 15. A large number of "HEXA" mutations have been discovered, and new ones are still being reported. These mutations reach significant frequencies in specific populations. French Canadians of southeastern Quebec have a carrier frequency similar to that seen in Ashkenazi Jews, but carry a different mutation. Cajuns of southern Louisiana carry the same mutation that is seen most commonly in Ashkenazi Jews. "HEXA" mutations are rare and are most seen in genetically isolated populations. Tay–Sachs can occur from the inheritance of either two similar, or two unrelated, causative mutations in the "HEXA" gene.
As an autosomal recessive disorder, two Tay–Sachs alleles are required for an individual to exhibit symptoms of the disease. 
Carriers of a single Tay–Sachs allele do not exhibit symptoms of the disease but appear to be protected to some extent against tuberculosis. This accounts for the persistence of the allele in certain populations in that it confers a selective advantage—in other words, being a heterozygote is advantageous.
Signs and symptoms.
Tay–Sachs disease is typically first noticed in infants around 6 months old displaying an abnormally strong response to sudden noises or other stimulus, known as the "startle response". There may also be listlessness or muscle stiffness (hypertonia). The disease is classified into several forms, which are differentiated based on the onset age of neurological symptoms.
Until the 1970s and 1980s, when the disease's molecular genetics became known, the juvenile and adult forms of the disease were not always recognized as variants of Tay–Sachs disease. Post-infantile Tay–Sachs was often misdiagnosed as another neurological disorder, such as Friedreich's ataxia.
Genetics.
Tay–Sachs disease is an autosomal recessive genetic disorder, meaning that when both parents are carriers, there is a 25% risk of giving birth to an affected child with each pregnancy. The affected child would have received a mutated copy of the gene from each parent.
Tay–Sachs results from mutations in the "HEXA" gene on human chromosome 15, which encodes the alpha-subunit of beta-N-acetylhexosaminidase A, a lysosomal enzyme. By 2000, more than 100 different mutations had been identified in the human "HEXA" gene. These mutations have included single base insertions and deletions, splice phase mutations, missense mutations, and other more complex patterns. Each of these mutations alters the gene's protein product (i.e., the enzyme), sometimes severely inhibiting its function. In recent years, population studies and pedigree analysis have shown how such mutations arise and spread within small founder populations. Initial research focused on several such founder populations:
In the 1960s and early 1970s, when the biochemical basis of Tay–Sachs disease was first becoming known, no mutations had been sequenced directly for genetic diseases. Researchers of that era did not yet know how common polymorphisms would prove to be. The "Jewish Fur Trader Hypothesis," with its implication that a single mutation must have spread from one population into another, reflected the knowledge at the time. Subsequent research, however, has proven that a large variety of different "HEXA" mutations can cause the disease. Because Tay–Sachs was one of the first genetic disorders for which widespread genetic screening was possible, it is one of the first genetic disorders in which the prevalence of compound heterozygosity has been demonstrated.
Compound heterozygosity ultimately explains the disease's variability, including the late-onset forms. The disease can potentially result from the inheritance of two unrelated mutations in the "HEXA" gene, one from each parent. Classic infantile Tay–Sachs disease results when a child has inherited mutations from both parents that completely stop the biodegradation of gangliosides. Late onset forms occur due to the diverse mutation base – people with Tay–Sachs disease may technically be heterozygotes, with two differing "HEXA" mutations that both inactivate, alter, or inhibit enzyme activity. When a patient has at least one "HEXA" copy that still enables some level of hexosaminidase A activity, a later onset disease form occurs. When disease occurs because of two unrelated mutations, the patient is said to be a compound heterozygote.
Heterozygous carriers (individuals who inherit one mutant allele) show abnormal enzyme activity, but manifest no disease symptoms. This phenomenon is called dominance; the biochemical reason for wild-type alleles' dominance over nonfunctional mutant alleles in inborn errors of metabolism comes from how enzymes function. Enzymes are protein catalysts for chemical reactions; as catalysts, they speed up reactions without being used up in the process, so only small enzyme quantities are required to carry out a reaction. Someone homozygous for a nonfunctional mutation in the enzyme-encoding gene has little or no enzyme activity, so will manifest the abnormal phenotype. A heterozygote (heterozygous individual) has at least half of the normal enzyme activity level, due to expression by the wild-type allele. This level is normally enough to enable normal function and thus prevent phenotypic expression.
Pathophysiology.
Tay–Sachs disease is caused by insufficient activity of the enzyme hexosaminidase A. Hexosaminidase A is a vital hydrolytic enzyme, found in the lysosomes, that breaks down glycolipids. When hexosaminidase A is no longer functioning properly, the lipids accumulate in the brain and interfere with normal biological processes. Hexosaminidase A specifically breaks down fatty acid derivatives called gangliosides; these are made and biodegraded rapidly in early life as the brain develops. Patients with and carriers of Tay–Sachs can be identified by a simple blood test that measures hexosaminidase A activity.
The hydrolysis of GM2-ganglioside requires three proteins. Two of them are subunits of hexosaminidase A; the third is a small glycolipid transport protein, the GM2 activator protein (GM2A), which acts as a substrate-specific cofactor for the enzyme. Deficiency in any one of these proteins leads to ganglioside storage, primarily in the lysosomes of neurons. Tay–Sachs disease (along with AB-variant GM2-gangliosidosis and Sandhoff disease) occurs because a mutation inherited from both parents deactivates or inhibits this process. Most Tay–Sachs mutations probably do not directly affect protein functional elements (e.g., the active site). Instead, they cause incorrect folding (disrupting function) or disable intracellular transport.
Diagnosis.
In patients with a clinical suspicion for Tay–Sachs disease, with any age of onset, the initial testing involves an enzyme assay to measure the activity of hexosaminidase in serum, fibroblasts or leukocytes. Total hexosaminidase enzyme activity is decreased in individuals with Tay-Sachs as is the percentage of hexosaminidase A. After confirmation of decreased enzyme activity in an individual, confirmation by molecular analysis can be pursued. All patients with infantile onset Tay–Sachs disease have a "cherry red" macula in the retina, easily observable by a physician using an ophthalmoscope. This red spot is a retinal area that appears red because of gangliosides in the surrounding retinal ganglion cells. The choroidal circulation is showing through "red" in this foveal region where all retinal ganglion cells are pushed aside to increase visual acuity. Thus, this cherry-red spot is the only normal part of the retina; it shows up in contrast to the rest of the retina. Microscopic analysis of the retinal neurons shows they are distended from excess ganglioside storage. Unlike other lysosomal storage diseases (e.g., Gaucher disease, Niemann–Pick disease, and Sandhoff disease), hepatosplenomegaly (liver and spleen enlargement) is not seen in Tay–Sachs.
Prevention.
Three main approaches have been used to prevent or reduce the incidence of Tay–Sachs:
Management.
There is currently no cure or treatment for Tay–Sachs disease. Even with the best care, children with infantile Tay–Sachs disease die by the age of 4. Although experimental work is underway, no current medical treatment of the root cause yet exists. Patients receive supportive care to ease the symptoms or extend life. Infants are given feeding tubes when they can no longer swallow. Improvements in life-extending care have somewhat lengthened the survival of children with Tay–Sachs disease, but no current therapy is able to reverse or delay the disease's progress. In late-onset Tay-Sachs, medication (e.g., lithium for depression) can sometimes control psychiatric symptoms and seizures, although some medications (e.g., tricyclic antidepressants, phenothiazines, haloperidol, and risperidone) are associated with significant adverse effects. In 2011, researchers discovered that Pyrimethamine can increase ß-hexosaminidase activity, thus slowing down the progression of Late-Onset Tay–Sachs disease.
Epidemiology.
Ashkenazi Jews have a high incidence of Tay–Sachs and other lipid storage diseases. In the United States, about 1 in 27 to 1 in 30 Ashkenazi Jews are a recessive carrier. The disease incidence is about 1 in every 3,500 newborn among Ashkenazi Jews. French Canadians and the Cajun community of Louisiana have an occurrence similar to the Ashkenazi Jews. Irish Americans have a 1 in 50 chance of being a carrier. In the general population, the incidence of carriers as heterozygotes is about 1 in 300. The incidence is approximately 1 in 320,000 newborns in the general population in United States.
Three general classes of theories have been proposed to explain the high frequency of Tay–Sachs carriers in the Ashkenazi Jewish population:
Tay–Sachs disease was one of the first genetic disorders for which epidemiology was studied using molecular data. Studies of Tay–Sachs mutations using new molecular techniques such as linkage disequilibrium and coalescence analysis have brought an emerging consensus among researchers supporting the founder effect theory.
History.
Waren Tay and Bernard Sachs, two physicians, described the disease's progression and provided differential diagnostic criteria to distinguish it from other neurological disorders with similar symptoms.
Both Tay and Sachs reported their first cases among Jewish families. Tay reported his observations in 1881 in the first volume of the proceedings of the British Ophthalmological Society, of which he was a founding member. By 1884, he had seen three cases in a single family. Years later, Bernard Sachs, an American neurologist, reported similar findings when he reported a case of "arrested cerebral development" to other New York Neurological Society members.
Sachs, who recognized that the disease had a familial basis, proposed that the disease should be called "amaurotic familial idiocy". However, its genetic basis was still poorly understood. Although Gregor Mendel had published his article on the genetics of peas in 1865, Mendel's paper was largely forgotten for more than a generation – not rediscovered by other scientists until 1899. Thus, the Mendelian model for explaining Tay–Sachs was unavailable to scientists and doctors of the time. The first edition of the Jewish Encyclopedia, published in 12 volumes between 1901 and 1906, described what was then known about the disease:
It is a curious fact that amaurotic family idiocy, a rare and fatal disease of children, occurs mostly among Jews. The largest number of cases has been observed in the United States—over thirty in number. It was at first thought that this was an exclusively Jewish disease, because most of the cases at first reported were between Russian and Polish Jews; but recently there have been reported cases occurring in non-Jewish children. The chief characteristics of the disease are progressive mental and physical enfeeblement; weakness and paralysis of all the extremities; and marasmus, associated with symmetrical changes in the macula lutea. On investigation of the reported cases, they found that neither consanguinity nor syphilitic, alcoholic, or nervous antecedents in the family history are factors in the etiology of the disease. No preventive measures have as yet been discovered, and no treatment has been of benefit, all the cases having terminated fatally.
Jewish immigration to the United States peaked in the period 1880–1924, with the immigrants arriving from Russia and countries in Eastern Europe; this was also a period of nativism (hostility to immigrants) in the United States. Opponents of immigration often questioned whether immigrants from southern and eastern Europe could be assimilated into American society. Reports of Tay–Sachs disease contributed to a perception among nativists that Jews were an inferior race.
In 1969, Shintaro Okada and John S. O'Brien showed that Tay–Sachs disease was caused by an enzyme defect; he also proved that Tay–Sachs patients could be diagnosed by an assay of hexosaminidase A activity. The further development of enzyme assays demonstrated that levels of hexosaminidases A and B could be measured in patients and carriers, allowing the reliable detection of heterozygotes. During the early 1970s, researchers developed protocols for newborn testing, carrier screening, and pre-natal diagnosis. By the end of 1979, researchers had identified three variant forms of GM2 gangliosidosis, including Sandhoff disease and the AB variant of GM2-gangliosidosis, accounting for false negatives in carrier testing.
Society and culture.
Since carrier testing for Tay–Sachs began in 1971, millions of Ashkenazi Jews have been screened as carriers. Jewish communities embraced the cause of genetic screening from the 1970s on. The success with Tay–Sachs disease has led Israel to become the first country that offers free genetic screening and counseling for all couples and opened discussions about the proper scope of genetic testing for other disorders in Israel.
Because Tay–Sachs disease was one of the first autosomal recessive genetic disorders for which there was an enzyme assay test (prior to polymerase chain reaction testing methods), it was intensely studied as a model for all such diseases, and researchers sought evidence of a selective process. A continuing controversy is whether heterozygotes (carriers) have or had a selective advantage. The presence of four different lysosomal storage disorders in the Ashkenazi Jewish population suggests a past selective advantage for heterozygous carriers of these conditions."
This controversy among researchers has reflected three debates among geneticists at large:
Research directions.
Enzyme replacement therapy.
Enzyme replacement therapy techniques have been investigated for lysosomal storage disorders, and could potentially be used to treat Tay–Sachs as well. The goal would be to replace the nonfunctional enzyme, a process similar to insulin injections for diabetes. However, in previous studies, the "HEXA" enzyme itself has been thought to be too large to pass through the specialized cell layer in the blood vessels that forms the blood–brain barrier in humans.
Researchers have also tried directly instilling the deficient enzyme hexosaminidase A into the cerebrospinal fluid (CSF) which bathes the brain. However, intracerebral neurons seem unable to take up this physically large molecule efficiently even when it is directly by them. Therefore, this approach to treatment of Tay–Sachs disease has also been ineffective so far.
Jacob sheep model.
Tay–Sachs disease exists in Jacob sheep. The biochemical mechanism for this disease in the Jacob sheep is virtually identical to that in humans, wherein diminished activity of hexosaminidase A results in increased concentrations of GM2 ganglioside in the affected animal. Sequencing of the "HEXA" gene cDNA of affected Jacobs sheep reveal an identical number of nucleotides and exons as in the human "HEXA" gene, and 86% nucleotide sequence identity. A missense mutation (G444R) was found in the "HEXA" cDNA of the affected sheep. This mutation is a single nucleotide change at the end of exon 11, resulting in that exon's deletion (before translation) via splicing. The Tay–Sachs model provided by the Jacob sheep is the first to offer promise as a means for gene therapy clinical trials, which may prove useful for disease treatment in humans.
Substrate reduction therapy.
Other experimental methods being researched involve substrate reduction therapy, which attempts to use alternative enzymes to increase the brain's catabolism of GM2 gangliosides to a point where residual degradative activity is sufficient to prevent substrate accumulation. One experiment has demonstrated that using the enzyme sialidase allows the genetic defect to be effectively bypassed, and as a consequence, GM2 gangliosides are metabolized so that their levels become almost inconsequential. If a safe pharmacological treatment can be developed – one that increases expression of lysosomal sialidase in neurons without other toxicity – then this new form of therapy could essentially cure the disease.
Another metabolic therapy under investigation for Tay–Sachs disease uses miglustat. This drug is a reversible inhibitor of the enzyme glucosylceramide synthase, which catalyzes the ﬁrst step in synthesizing glucose-based glycosphingolipids like GM2 ganglioside.
Increasing β-hexosaminidase A activity.
As Tay–Sachs disease is a deficiency of β-hexosaminidase A, by getting a substance that increases its activity, people affected will not be deteriorating as fast or not at all. While for infantile Tay–Sachs disease, there is no β-hexosaminidase A so then the treatment would be ineffective. However, for people affected by Late-Onset Tay–Sachs disease, they still have β-hexosaminidase A. The drug Pyrimethamine has been shown to increase activity of β-hexosaminidase A. However, the increased levels of β-hexosaminidase A still fall far short of the desired "10% of normal HEXA", above which the phenotypic symptoms begin to disappear.

</doc>
<doc id="56483" url="http://en.wikipedia.org/wiki?curid=56483" title="Tourette syndrome">
Tourette syndrome

Tourette syndrome (also called Tourette's syndrome, Tourette's disorder, Gilles de la Tourette syndrome, GTS or, more commonly, simply Tourette's or TS) is an inherited neuropsychiatric disorder with onset in childhood, characterized by multiple physical (motor) tics and at least one vocal (phonic) tic. These tics characteristically wax and wane, can be suppressed temporarily, and are preceded by a premonitory urge. Tourette's is defined as part of a spectrum of tic disorders, which includes provisional, transient and persistent (chronic) tics.
Tourette's was once considered a rare and bizarre syndrome, most often associated with the exclamation of obscene words or socially inappropriate and derogatory remarks (coprolalia), but this symptom is present in only a small minority of people with Tourette's. Tourette's is no longer considered a rare condition, but it is not always correctly identified because most cases are mild and the severity of tics decreases for most children as they pass through adolescence. Between 0.4% and 3.8% of children ages 5 to 18 may have Tourette's; the prevalence of other tic disorders in school-age children is higher, with the more common tics of eye blinking, coughing, throat clearing, sniffing, and facial movements. Extreme Tourette's in adulthood is a rarity, and Tourette's does not adversely affect intelligence or life expectancy.
Genetic and environmental factors play a role in the etiology of Tourette's, but the exact causes are unknown. In most cases, medication is unnecessary. There is no effective treatment for every case of tics, but certain medications and therapies can help when their use is warranted. Education is an important part of any treatment plan, and explanation and reassurance alone are often sufficient treatment. Comorbid conditions (co-occurring diagnoses other than Tourette's) such as attention-deficit hyperactivity disorder (ADHD) and obsessive–compulsive disorder (OCD) are present in many patients seen in tertiary specialty clinics. These other conditions often cause more functional impairment to the individual than the tics that are the hallmark of Tourette's; hence, it is important to correctly identify comorbid conditions and treat them.
The eponym was bestowed by Jean-Martin Charcot (1825–1893) on behalf of his resident, Georges Albert Édouard Brutus Gilles de la Tourette (1857–1904), a French physician and neurologist, who published an account of nine patients with Tourette's in 1885.
Classification.
Tics are sudden, repetitive, nonrhythmic movements (motor tics) and utterances (phonic tics) that involve discrete muscle groups. Motor tics are movement-based tics, while phonic tics are involuntary sounds produced by moving air through the nose, mouth, or throat.
Tourette's was classified by the fourth version of the "Diagnostic and Statistical Manual of Mental Disorders" (DSM-IV-TR) as one of several tic disorders "usually first diagnosed in infancy, childhood, or adolescence" according to type (motor or phonic tics) and duration (transient or chronic). Transient tic disorders consisted of multiple motor tics, phonic tics or both, with a duration between four weeks and twelve months. Chronic tic disorder was either single or multiple, motor or phonic tics (but not both), which were present for more than a year. Tourette's is diagnosed when multiple motor tics, and at least one phonic tic, are present for more than a year. The fifth version of the DSM (DSM-5), published in May 2013, reclassified Tourette's and tic disorders as motor disorders listed in the neurodevelopmental disorder category, and replaced transient tic disorder with provisional tic disorder, but made few other significant changes.
Tic disorders are defined only slightly differently by the World Health Organization International Statistical Classification of Diseases and Related Health Problems, ICD-10; code F95.2 is for combined vocal and multiple motor tic disorder [de la Tourette].
Although Tourette's is the more severe expression of the spectrum of tic disorders, most cases are mild. The severity of symptoms varies widely among people with Tourette's, and mild cases may be undetected.
Characteristics.
Tics are movements or sounds "that occur intermittently and unpredictably out of a background of normal motor activity", having the appearance of "normal behaviors gone wrong". The tics associated with Tourette's change in number, frequency, severity and anatomical location. Waxing and waning—the ongoing increase and decrease in severity and frequency of tics—occurs differently in each individual. Tics also occur in "bouts of bouts", which vary for each person.
Coprolalia (the spontaneous utterance of socially objectionable or taboo words or phrases) is the most publicized symptom of Tourette's, but it is not required for a diagnosis of Tourette's and only about 10% of Tourette's patients exhibit it. Echolalia (repeating the words of others) and palilalia (repeating one's own words) occur in a minority of cases, while the most common initial motor and vocal tics are, respectively, eye blinking and throat clearing.
In contrast to the abnormal movements of other movement disorders (for example, choreas, dystonias, myoclonus, and dyskinesias), the tics of Tourette's are temporarily suppressible, nonrhythmic, and often preceded by an unwanted premonitory urge. Immediately preceding tic onset, most individuals with Tourette's are aware of an urge, similar to the need to sneeze or scratch an itch. Individuals describe the need to tic as a buildup of tension, pressure, or energy which they consciously choose to release, as if they "had to do it" to relieve the sensation or until it feels "just right". Examples of the premonitory urge are the feeling of having something in one's throat, or a localized discomfort in the shoulders, leading to the need to clear one's throat or shrug the shoulders. The actual tic may be felt as relieving this tension or sensation, similar to scratching an itch. Another example is blinking to relieve an uncomfortable sensation in the eye. These urges and sensations, preceding the expression of the movement or vocalization as a tic, are referred to as "premonitory sensory phenomena" or premonitory urges. Because of the urges that precede them, tics are described as semi-voluntary or "unvoluntary", rather than specifically "involuntary"; they may be experienced as a "voluntary", suppressible response to the unwanted premonitory urge. Published descriptions of the tics of Tourette's identify sensory phenomena as the core symptom of the syndrome, even though they are not included in the diagnostic criteria.
While individuals with tics are sometimes able to suppress their tics for limited periods of time, doing so often results in tension or mental exhaustion. People with Tourette's may seek a secluded spot to release their symptoms, or there may be a marked increase in tics after a period of suppression at school or at work. Some people with Tourette's may not be aware of the premonitory urge. Children may be less aware of the premonitory urge associated with tics than are adults, but their awareness tends to increase with maturity. They may have tics for several years before becoming aware of premonitory urges. Children may suppress tics while in the doctor's office, so they may need to be observed while they are not aware they are being watched. The ability to suppress tics varies among individuals, and may be more developed in adults than children.
Although there is no such thing as a "typical" case of Tourette syndrome, the condition follows a fairly reliable course in terms of the age of onset and the history of the severity of symptoms. Tics may appear up to the age of eighteen, but the most typical age of onset is from five to seven. A 1998 study published by Leckman and colleagues from the Yale Child Study Center showed that the ages of highest tic severity are eight to twelve (average ten), with tics steadily declining for most patients as they pass through adolescence. The most common, first-presenting tics are eye blinking, facial movements, sniffing and throat clearing. Initial tics present most frequently in midline body regions where there are many muscles, usually the head, neck and facial region. This can be contrasted with the stereotyped movements of other disorders (such as stims and stereotypies of the autism spectrum disorders), which typically have an earlier age of onset, are more symmetrical, rhythmical and bilateral, and involve the extremities (e.g., flapping the hands). Tics that appear early in the course of the condition are frequently confused with other conditions, such as allergies, asthma, and vision problems: pediatricians, allergists and ophthalmologists are typically the first to see a child with tics.
Among patients whose symptoms are severe enough to warrant referral to clinics, obsessive–compulsive disorder (OCD) and attention-deficit hyperactivity disorder (ADHD) are often associated with Tourette's. Compulsions resembling tics are present in some individuals with OCD; "tic-related OCD" is hypothesized to be a subgroup of OCD, distinguished from non-tic related OCD by the type and nature of obsessions and compulsions. Not all persons with Tourette's have ADHD or OCD or other comorbid conditions, although in clinical populations, a high percentage of patients presenting for care do have ADHD. One author reports that a ten-year overview of patient records revealed about 40% of patients with Tourette's have "TS-only" or "pure TS", referring to Tourette syndrome in the absence of ADHD, OCD and other disorders. Another author reports that 57% of 656 patients presenting with tic disorders had uncomplicated tics, while 43% had tics plus comorbid conditions. People with "full-blown Tourette's" have significant comorbid conditions in addition to tics.
Causes.
The exact cause of Tourette's is unknown, but it is well established that both genetic and environmental factors are involved. Genetic epidemiology studies have shown that the overwhelming majority of cases of Tourette's are inherited, although the exact mode of inheritance is not yet known and no gene has been identified. In other cases, tics are associated with disorders other than Tourette's, a phenomenon known as "tourettism".
A person with Tourette's has about a 50% chance of passing the gene(s) to one of his or her children, but Tourette's is a condition of variable expression and incomplete penetrance. Thus, not everyone who inherits the genetic vulnerability will show symptoms; even close family members may show different severities of symptoms, or no symptoms at all. The gene(s) may express as Tourette's, as a milder tic disorder (provisional or chronic tics), or as obsessive–compulsive symptoms without tics. Only a minority of the children who inherit the gene(s) have symptoms severe enough to require medical attention. Gender appears to have a role in the expression of the genetic vulnerability: males are more likely than females to express tics.
Non-genetic, environmental, post-infectious, or psychosocial factors—while not causing Tourette's—can influence its severity. Autoimmune processes may affect tic onset and exacerbation in some cases. In 1998, a team at the US National Institute of Mental Health proposed a hypothesis based on observation of 50 children that both obsessive–compulsive disorder (OCD) and tic disorders may arise in a subset of children as a result of a poststreptococcal autoimmune process. Children who meet five diagnostic criteria are classified, according to the hypothesis, as having Pediatric Autoimmune Neuropsychiatric Disorders Associated with Streptococcal infections (PANDAS). This contentious hypothesis is the focus of clinical and laboratory research, but remains unproven.
Some forms of OCD may be genetically linked to Tourette's. A subset of OCD is thought to be etiologically related to Tourette's and may be a different expression of the same factors that are important for the expression of tics. The genetic relationship of ADHD to Tourette syndrome, however, has not been fully established.
Pathophysiology.
The exact mechanism affecting the inherited vulnerability to Tourette's has not been established, and the precise etiology is unknown. Tics are believed to result from dysfunction in cortical and subcortical regions, the thalamus, basal ganglia and frontal cortex. Neuroanatomic models implicate failures in circuits connecting the brain's cortex and subcortex, and imaging techniques implicate the basal ganglia and frontal cortex.
Diagnosis.
According to the fifth edition of the "Diagnostic and Statistical Manual of Mental Disorders" (DSM-5), Tourette’s may be diagnosed when a person exhibits both multiple motor and one or more vocal tics over the period of a year; the motor and vocal tics need not be concurrent. The onset must have occurred before the age of 18, and cannot be attributed to the effects of another condition or substance (such as cocaine). Hence, other medical conditions that include tics or tic-like movements—such as autism or other causes of tourettism—must be ruled out before conferring a Tourette's diagnosis. Since 2000, the DSM has recognized that clinicians see patients who meet all the other criteria for Tourette's, but do not have distress or impairment.
There are no specific medical or screening tests that can be used in diagnosing Tourette's; it is frequently misdiagnosed or underdiagnosed, partly because of the wide expression of severity, ranging from mild (the majority of cases) or moderate, to severe (the rare, but more widely recognized and publicized cases). Coughing, eye blinking, and tics that mimic unrelated conditions such as asthma are commonly misdiagnosed.
The diagnosis is made based on observation of the individual's symptoms and family history, and after ruling out secondary causes of tic disorders. In patients with a typical onset and a family history of tics or obsessive–compulsive disorder, a basic physical and neurological examination may be sufficient.
There is no requirement that other comorbid conditions (such as ADHD or OCD) be present, but if a physician believes that there may be another condition present that could explain tics, tests may be ordered as necessary to rule out that condition. An example of this is when diagnostic confusion between tics and seizure activity exists, which would call for an EEG, or if there are symptoms that indicate an MRI to rule out brain abnormalities. TSH levels can be measured to rule out hypothyroidism, which can be a cause of tics. Brain imaging studies are not usually warranted. In teenagers and adults presenting with a sudden onset of tics and other behavioral symptoms, a urine drug screen for cocaine and stimulants might be necessary. If a family history of liver disease is present, serum copper and ceruloplasmin levels can rule out Wilson's disease. Most cases are diagnosed by merely observing a history of tics.
Secondary causes of tics (not related to inherited Tourette syndrome) are commonly referred to as tourettism. Dystonias, choreas, other genetic conditions, and secondary causes of tics should be ruled out in the differential diagnosis for Tourette syndrome. Other conditions that may manifest tics or stereotyped movements include developmental disorders, autism spectrum disorders, and stereotypic movement disorder; Sydenham's chorea; idiopathic dystonia; and genetic conditions such as Huntington's disease, neuroacanthocytosis, Hallervorden-Spatz syndrome, Duchenne muscular dystrophy, Wilson's disease, and tuberous sclerosis. Other possibilities include chromosomal disorders such as Down syndrome, Klinefelter syndrome, XYY syndrome and fragile X syndrome. Acquired causes of tics include drug-induced tics, head trauma, encephalitis, stroke, and carbon monoxide poisoning. The symptoms of Lesch-Nyhan syndrome may also be confused with Tourette syndrome. Most of these conditions are rarer than tic disorders, and a thorough history and examination may be enough to rule them out, without medical or screening tests.
Screening.
Although not all people with Tourette's have comorbid conditions, most Tourette's patients presenting for clinical care at specialty referral centers may exhibit symptoms of other conditions along with their motor and phonic tics. Associated conditions include attention-deficit hyperactivity disorder (ADD or ADHD), obsessive–compulsive disorder (OCD), learning disabilities and sleep disorders. Disruptive behaviors, impaired functioning, or cognitive impairment in patients with comorbid Tourette's and ADHD may be accounted for by the comorbid ADHD, highlighting the importance of identifying and treating comorbid conditions. Disruption from tics is commonly overshadowed by comorbid conditions that present greater interference to the child. Tic disorders in the absence of ADHD do not appear to be associated with disruptive behavior or functional impairment, while impairment in school, family, or peer relations is greater in patients who have more comorbid conditions and often determines whether therapy is needed.
Because comorbid conditions such as OCD and ADHD can be more impairing than tics, these conditions are included in an evaluation of patients presenting with tics. "It is critical to note that the comorbid conditions may determine functional status more strongly than the tic disorder," according to Samuel Zinner, MD. The initial assessment of a patient referred for a tic disorder should include a thorough evaluation, including a family history of tics, ADHD, obsessive–compulsive symptoms, and other chronic medical, psychiatric and neurological conditions. Children and adolescents with TS who have learning difficulties are candidates for psychoeducational testing, particularly if the child also has ADHD. Undiagnosed comorbid conditions may result in functional impairment, and it is necessary to identify and treat these conditions to improve functioning. Complications may include depression, sleep problems, social discomfort and self-injury.
Management.
The treatment of Tourette's focuses on identifying and helping the individual manage the most troubling or impairing symptoms. Most cases of Tourette's are mild, and do not require pharmacological treatment; instead, psychobehavioral therapy, education, and reassurance may be sufficient. Treatments, where warranted, can be divided into those that target tics and comorbid conditions, which, when present, are often a larger source of impairment than the tics themselves. Not all people with tics have comorbid conditions, but when those conditions are present, they often take treatment priority.
There is no cure for Tourette's and no medication that works universally for all individuals without significant adverse effects. Knowledge, education and understanding are uppermost in management plans for tic disorders. The management of the symptoms of Tourette's may include pharmacological, behavioral and psychological therapies. While pharmacological intervention is reserved for more severe symptoms, other treatments (such as supportive psychotherapy or cognitive behavioral therapy) may help to avoid or ameliorate depression and social isolation, and to improve family support. Educating a patient, family, and surrounding community (such as friends, school, and church) is a key treatment strategy, and may be all that is required in mild cases.
Medication is available to help when symptoms interfere with functioning. The classes of medication with the most proven efficacy in treating tics—typical and atypical neuroleptics including risperidone (trade name Risperdal), ziprasidone (Geodon), haloperidol (Haldol), pimozide (Orap) and fluphenazine (Prolixin)—can have long-term and short-term adverse effects. The antihypertensive agents clonidine (trade name Catapres) and guanfacine (Tenex) are also used to treat tics; studies show variable efficacy, but a lower side effect profile than the neuroleptics. Stimulants and other medications may be useful in treating ADHD when it co-occurs with tic disorders. Drugs from several other classes of medications can be used when stimulant trials fail, including guanfacine (trade name Tenex), atomoxetine (Strattera) and tricyclic antidepressants. Clomipramine (Anafranil), a tricyclic, and SSRIs—a class of antidepressants including fluoxetine (Prozac), sertraline (Zoloft), and fluvoxamine (Luvox)—may be prescribed when a Tourette's patient also has symptoms of obsessive–compulsive disorder. Several other medications have been tried, but evidence to support their use is unconvincing.
Because children with tics often present to physicians when their tics are most severe, and because of the waxing and waning nature of tics, it is recommended that medication not be started immediately or changed often. Frequently, the tics subside with explanation, reassurance, understanding of the condition and a supportive environment. When medication is used, the goal is not to eliminate symptoms: it should be used at the lowest possible dose that manages symptoms without adverse effects, given that these may be more disturbing than the symptoms for which they were prescribed.
Cognitive behavioral therapy (CBT) is a useful treatment when OCD is present, and there is increasing evidence supporting the use of habit reversal (HRT) in the treatment of tics. There is evidence that HRT reduces tic severity, but there are methodological limitations in the studies, and a need for more trained specialists and better large-scale studies.
Relaxation techniques, such as exercise, yoga or meditation, may be useful in relieving the stress that may aggravate tics, but the majority of behavioral interventions (such as relaxation training and biofeedback, with the exception of habit reversal) have not been systematically evaluated and are not empirically supported therapies for Tourette's. Deep brain stimulation has been used to treat adults with severe Tourette's that does not respond to conventional treatment, but it is regarded as an invasive, experimental procedure that is unlikely to become widespread.
Prognosis.
Tourette syndrome is a spectrum disorder—its severity ranges over a spectrum from mild to severe. The majority of cases are mild and require no treatment. In these cases, the impact of symptoms on the individual may be mild, to the extent that casual observers might not know of their condition. The overall prognosis is positive, but a minority of children with Tourette syndrome have severe symptoms that persist into adulthood. A study of 46 subjects at 19 years of age found that the symptoms of 80% had minimum to mild impact on their overall functioning, and that the other 20% experienced at least a moderate impact on their overall functioning. The rare minority of severe cases can inhibit or prevent individuals from holding a job or having a fulfilling social life. In a follow-up study of thirty-one adults with Tourette's, all patients completed high school, 52% finished at least two years of college, and 71% were full-time employed or were pursuing higher education.
Regardless of symptom severity, individuals with Tourette's have a normal life span. Although the symptoms may be lifelong and chronic for some, the condition is not degenerative or life-threatening. Intelligence is normal in those with Tourette's, although there may be learning disabilities. Severity of tics early in life does not predict tic severity in later life, and prognosis is generally favorable, although there is no reliable means of predicting the outcome for a particular individual. The gene or genes associated with Tourette's have not been identified, and there is no potential "cure". A higher rate of migraines than the general population and sleep disturbances are reported.
Several studies have demonstrated that the condition in most children improves with maturity. Tics may be at their highest severity at the time that they are diagnosed, and often improve with understanding of the condition by individuals and their families and friends. The statistical age of highest tic severity is typically between eight and twelve, with most individuals experiencing steadily declining tic severity as they pass through adolescence. One study showed no correlation with tic severity and the onset of puberty, in contrast with the popular belief that tics increase at puberty. In many cases, a complete remission of tic symptoms occurs after adolescence. However, a study using videotape to record tics in adults found that, although tics diminished in comparison with childhood, and all measures of tic severity improved by adulthood, 90% of adults still had tics. Half of the adults who considered themselves tic-free still displayed evidence of tics.
Many people with TS may not realize they have tics; because tics are more commonly expressed in private, TS may go unrecognized or undetected. It is not uncommon for the parents of affected children to be unaware that they, too, may have had tics as children. Because Tourette's tends to subside with maturity, and because milder cases of Tourette's are now more likely to be recognized, the first realization that a parent had tics as a child may not come until their offspring is diagnosed. It is not uncommon for several members of a family to be diagnosed together, as parents bringing children to a physician for an evaluation of tics become aware that they, too, had tics as a child.
Children with Tourette's may suffer socially if their tics are viewed as "bizarre". If a child has disabling tics, or tics that interfere with social or academic functioning, supportive psychotherapy or school accommodations can be helpful. Because comorbid conditions (such as ADHD or OCD) can cause greater impact on overall functioning than tics, a thorough evaluation for comorbidity is called for when symptoms and impairment warrant.
A supportive environment and family generally gives those with Tourette's the skills to manage the disorder. People with Tourette's may learn to camouflage socially inappropriate tics or to channel the energy of their tics into a functional endeavor. Accomplished musicians, athletes, public speakers, and professionals from all walks of life are found among people with Tourette's. Outcomes in adulthood are associated more with the perceived significance of having severe tics as a child than with the actual severity of the tics. A person who was misunderstood, punished, or teased at home or at school will fare worse than children who enjoyed an understanding and supportive environment.
Epidemiology.
The tics of Tourette syndrome begin in childhood and tend to remit or subside with maturity; thus, a diagnosis may no longer be warranted for many adults, and observed prevalence rates are higher among children than adults. As children pass through adolescence, about one-quarter become tic-free, almost one-half see their tics diminish to a minimal or mild level, and less than one-quarter have persistent tics. Only 5 to 14% of adults experience worse tics in adulthood than in childhood.
Tourette syndrome is found among all social, racial and ethnic groups and has been reported in all parts of the world; it is three to four times more frequent among males than among females. The reported prevalence of TS varies "according to the source, age, and sex of the sample; the ascertainment procedures; and diagnostic system" from a low of .05% in a 1993 study to a high of 2.9% in a 1998 study.
Up to 1% of the overall population experiences tic disorders, including chronic tics and transient tics of childhood. Chronic tics affect 5% of children, and transient tics affect up to 20%. Robertson (2011) suggests that the prevalence of Tourette syndrome alone in the general population is also 1%, with a range reported between .4% and 3.8% for children ages 5 to 18. Singer (2011) states the prevalence of TS in the overall population at any time is .1% for impairing cases and .6% for all cases, while Bloch and colleagues (2011) state the overall prevalence as between .3 and 1%. According to Lombroso and Scahill (2008), the emerging consensus is that .1 to 1% of children have Tourette's, with several studies supporting a tighter range of .6 to .8%. Bloch and Leckman (2009) and Swain (2007) report a range of prevalence in children of .4 to .6%, Knight et al (2012) estimate .77% in children, and Du et al (2010) report that 1 to 3% of "Western" school-age children have Tourette's. Prevalence rates in special education populations are higher. Using year 2000 census data, a prevalence range of .1 to 1% yields an estimate of 53,000–530,000 school-age children with Tourette's in the US, and a prevalence estimate of .1% means that in 2001 about 553,000 people in the UK age 5 or older would have Tourette's. Most cases would be mild and almost unrecognizable in older individuals.
Tourette syndrome was once thought to be rare: in 1972, the US National Institutes of Health (NIH) believed there were fewer than 100 cases in the United States, and a 1973 registry reported only 485 cases worldwide. However, multiple studies published since 2000 have consistently demonstrated that the prevalence is much higher than previously thought. Discrepancies across current and prior prevalence estimates come from several factors: ascertainment bias in earlier samples drawn from clinically referred cases, assessment methods that may fail to detect milder cases, and differences in diagnostic criteria and thresholds. There were few broad-based community studies published before 2000 and until the 1980s, most epidemiological studies of Tourette syndrome were based on individuals referred to tertiary care or specialty clinics. Individuals with mild symptoms may not seek treatment and physicians may not confer an official diagnosis of TS on children out of concern for stigmatization; children with milder symptoms are unlikely to be referred to specialty clinics, so prevalence studies have an inherent bias towards more severe cases. Studies of Tourette syndrome are vulnerable to error because tics vary in intensity and expression, are often intermittent, and are not always recognized by clinicians, patients, family members, friends or teachers; approximately 20% of persons with Tourette syndrome do not recognize that they have tics. Newer studies—recognizing that tics may often be undiagnosed and hard to detect—use direct classroom observation and multiple informants (parent, teacher, and trained observers), and therefore record more cases than older studies relying on referrals. As the diagnostic threshold and assessment methodology have moved towards recognition of milder cases, the result is an increase in estimated prevalence.
Tourette's is associated with several comorbid conditions, or co-occurring diagnoses, which are often the major source of impairment for an affected child. Most individuals with tics do not seek medical attention, so epidemiological studies of TS "reflect a strong ascertainment bias", but among those who do warrant medical attention, the majority have other conditions, and up to 50% have ADHD or OCD. One author reports that a ten-year overview of patient records revealed about 40% of patients with Tourette's have "TS-only" or "pure TS", referring to Tourette syndrome in the absence of ADHD, OCD and other disorders. In children with tics, the additional presence of ADHD is associated with functional impairment, disruptive behavior, and tic severity. Other comorbid conditions include self-injurious behaviors (SIB), anxiety, depression, personality disorders, oppositional defiant disorder, and conduct disorders.
History and research directions.
The first presentation of Tourette syndrome is thought to be in the book, "Malleus Maleficarum" ("Witch's hammer") by Jakob Sprenger and Heinrich Kraemer, published in the late 15th century and describing a priest whose tics were "believed to be related to possession by the devil". A French doctor, Jean Marc Gaspard Itard, reported the first case of Tourette syndrome in 1825, describing Marquise de Dampierre, an important woman of nobility in her time. Jean-Martin Charcot, an influential French physician, assigned his resident Georges Albert Édouard Brutus Gilles de la Tourette, a French physician and neurologist, to study patients at the Salpêtrière Hospital, with the goal of defining an illness distinct from hysteria and from chorea.
In 1885, Gilles de la Tourette published an account in "Study of a Nervous Affliction" describing nine persons with "convulsive tic disorder", concluding that a new clinical category should be defined. The eponym was later bestowed by Charcot after and on behalf of Gilles de la Tourette.
Little progress was made over the next century in explaining or treating tics, and a psychogenic view prevailed well into the 20th century. The possibility that movement disorders, including Tourette syndrome, might have an organic origin was raised when an encephalitis epidemic from 1918–1926 led to a subsequent epidemic of tic disorders.
During the 1960s and 1970s, as the beneficial effects of haloperidol (Haldol) on tics became known, the psychoanalytic approach to Tourette syndrome was questioned. The turning point came in 1965, when Arthur K. Shapiro—described as "the father of modern tic disorder research"—treated a Tourette’s patient with haloperidol, and published a paper criticizing the psychoanalytic approach.
Since the 1990s, a more neutral view of Tourette's has emerged, in which biological vulnerability and adverse environmental events are seen to interact. In 2000, the American Psychiatric Association published the DSM-IV-TR, revising the text of DSM-IV to no longer require that symptoms of tic disorders cause distress or impair functioning, recognizing that clinicians often see patients who meet all the other criteria for Tourette's, but do not have distress or impairment.
Findings since 1999 have advanced TS science in the areas of genetics, neuroimaging, neurophysiology, and neuropathology. Questions remain regarding how best to classify Tourette syndrome, and how closely Tourette's is related to other movement disorders or psychiatric disorders. Good epidemiologic data is still lacking, and available treatments are not risk free and not always well tolerated. High-profile media coverage focuses on treatments that do not have established safety or efficacy, such as deep brain stimulation, and alternative therapies involving unstudied efficacy and side effects are pursued by many parents.
Society and culture.
Not everyone with Tourette's wants treatment or a "cure", especially if that means they may "lose" something else in the process. Researchers Leckman and Cohen, and former US Tourette Syndrome Association (TSA) national board member Kathryn Taubert, believe that there may be latent advantages associated with an individual's genetic vulnerability to developing Tourette syndrome, such as a heightened awareness and increased attention to detail and surroundings that may have adaptive value. There is evidence to support the clinical lore that children with "TS-only" (Tourette's in the absence of comorbid conditions) are unusually gifted: neuropsychological studies have identified advantages in children with TS-only. Children with TS-only are faster than the average for their age group on timed tests of motor coordination.
Notable individuals with Tourette syndrome are found in all walks of life, including musicians, athletes, media figures, teachers, physicians and authors. The best-known example of a person who may have used obsessive–compulsive traits to advantage is Samuel Johnson, the 18th-century English man of letters, who likely had Tourette syndrome as evidenced by the writings of James Boswell. Johnson wrote "A Dictionary of the English Language" in 1747, and was a prolific writer, poet, and critic. Tim Howard, described by the "Chicago Tribune" as the "rarest of creatures – an American soccer hero" and by the TSA as the "most notable individual with Tourette Syndrome around the world" says that his neurological makeup gave him an enhanced perception and an ability to hyper-focus that contributed to his success on the field.
Although it has been speculated that Mozart had Tourette's, no Tourette's expert or organization has presented credible evidence to support such a conclusion, and there are problems with the arguments supporting the diagnosis: tics are not transferred to the written form, as is supposed with Mozart's scatological writings; the medical history in retrospect is not thorough; side effects due to other conditions may be misinterpreted; "it is not proven whether written documents can account for the existence of a vocal tic" and "the evidence of motor tics in Mozart's life is doubtful".
Pre-dating Gilles de la Tourette's 1885 publication, likely portrayals of TS or tic disorders in fictional literature are Mr. Pancks in "Little Dorritt" by Charles Dickens and Nikolai Levin in "Anna Karenina" by Leo Tolstoy. The entertainment industry has been criticized for depicting those with Tourette syndrome as social misfits whose only tic is coprolalia, which has furthered stigmatization and the public's misunderstanding of those with Tourette's. The coprolalic symptoms of Tourette's are also fodder for radio and television talk shows in the US and in the British media.

</doc>
<doc id="56484" url="http://en.wikipedia.org/wiki?curid=56484" title="Low-pass filter">
Low-pass filter

A low-pass filter is a filter that passes signals with a frequency lower than a certain cutoff frequency and attenuates signals with frequencies higher than the cutoff frequency. The amount of attenuation for each frequency depends on the filter design. The filter is sometimes called a high-cut filter, or treble cut filter in audio applications. A low-pass filter is the opposite of a high-pass filter. A band-pass filter is a combination of a low-pass and a high-pass filter.
Low-pass filters exist in many different forms, including electronic circuits (such as a "hiss filter" used in audio), anti-aliasing filters for conditioning signals prior to analog-to-digital conversion, digital filters for smoothing sets of data, acoustic barriers, blurring of images, and so on. The moving average operation used in fields such as finance is a particular kind of low-pass filter, and can be analyzed with the same signal processing techniques as are used for other low-pass filters. Low-pass filters provide a smoother form of a signal, removing the short-term fluctuations, and leaving the longer-term trend.
An optical filter can correctly be called a low-pass filter, but conventionally is called a "longpass" filter (low frequency is long wavelength), to avoid confusion.
Examples.
Acoustics.
A stiff physical barrier tends to reflect higher sound frequencies, and so acts as a low-pass filter for transmitting sound. When music is playing in another room, the low notes are easily heard, while the high notes are attenuated.
Electronics.
In an electronic low-pass RC filter for voltage signals, high frequencies in the input signal are attenuated, but the filter has little attenuation below the cutoff frequency determined by its RC time constant. For current signals, a similar circuit, using a resistor and capacitor in parallel, works in a similar manner. (See current divider discussed in more detail below.)
Electronic low-pass filters are used on inputs to subwoofers and other types of loudspeakers, to block high pitches that they can't efficiently reproduce. Radio transmitters use low-pass filters to block harmonic emissions that might interfere with other communications. The tone knob on many electric guitars is a low-pass filter used to reduce the amount of treble in the sound. An integrator is another time constant low-pass filter.
Telephone lines fitted with DSL splitters use low-pass and high-pass filters to separate DSL and POTS signals sharing the same pair of wires.
Low-pass filters also play a significant role in the sculpting of sound created by analogue and virtual analogue synthesisers. "See subtractive synthesis."
Ideal and real filters.
An ideal low-pass filter completely eliminates all frequencies above the cutoff frequency while passing those below unchanged; its frequency response is a rectangular function and is a brick-wall filter. The transition region present in practical filters does not exist in an ideal filter. An ideal low-pass filter can be realized mathematically (theoretically) by multiplying a signal by the rectangular function in the frequency domain or, equivalently, convolution with its impulse response, a sinc function, in the time domain.
However, the ideal filter is impossible to realize without also having signals of infinite extent in time, and so generally needs to be approximated for real ongoing signals, because the sinc function's support region extends to all past and future times. The filter would therefore need to have infinite delay, or knowledge of the infinite future and past, in order to perform the convolution. It is effectively realizable for pre-recorded digital signals by assuming extensions of zero into the past and future, or more typically by making the signal repetitive and using Fourier analysis.
Real filters for real-time applications approximate the ideal filter by truncating and windowing the infinite impulse response to make a finite impulse response; applying that filter requires delaying the signal for a moderate period of time, allowing the computation to "see" a little bit into the future. This delay is manifested as phase shift. Greater accuracy in approximation requires a longer delay.
An ideal low-pass filter results in ringing artifacts via the Gibbs phenomenon. These can be reduced or worsened by choice of windowing function, and the design and choice of real filters involves understanding and minimizing these artifacts. For example, "simple truncation [of sinc] causes severe ringing artifacts," in signal reconstruction, and to reduce these artifacts one uses window functions "which drop off more smoothly at the edges."
The Whittaker–Shannon interpolation formula describes how to use a perfect low-pass filter to reconstruct a continuous signal from a sampled digital signal. Real digital-to-analog converters use real filter approximations.
Continuous-time low-pass filters.
There are many different types of filter circuits, with different responses to changing frequency. The frequency response of a filter is generally represented using a Bode plot, and the filter is characterized by its cutoff frequency and rate of frequency rolloff. In all cases, at the "cutoff frequency," the filter attenuates the input power by half or 3 dB. So the order of the filter determines the amount of additional attenuation for frequencies higher than the cutoff frequency.
On any Butterworth filter, if one extends the horizontal line to the right and the diagonal line to the upper-left (the asymptotes of the function), they intersect at exactly the "cutoff frequency". The frequency response at the cutoff frequency in a first-order filter is 3 dB below the horizontal line. The various types of filters (Butterworth filter, Chebyshev filter, Bessel filter, etc.) all have different-looking "knee curves". Many second-order filters have "peaking" or resonance that puts their frequency response at the cutoff frequency "above" the horizontal line. Furthermore, the actual frequency where this peaking occurs can be predicted without calculus, as shown by Cartwright et al. For third-order filters, the peaking and its frequency of occurrence can too be predicted without calculus as recently shown by Cartwright et al. "See electronic filter for other types."
The meanings of 'low' and 'high'—that is, the cutoff frequency—depend on the characteristics of the filter. The term "low-pass filter" merely refers to the shape of the filter's response; a high-pass filter could be built that cuts off at a lower frequency than any low-pass filter—it is their responses that set them apart. Electronic circuits can be devised for any desired frequency range, right up through microwave frequencies (above 1 GHz) and higher.
Laplace notation.
Continuous-time filters can also be described in terms of the Laplace transform of their impulse response, in a way that lets all characteristics of the filter be easily analyzed by considering the pattern of poles and zeros of the Laplace transform in the complex plane. (In discrete time, one can similarly consider the Z-transform of the impulse response.)
For example, a first-order low-pass filter can be described in Laplace notation as:
where "s" is the Laplace transform variable, "τ" is the filter time constant, and "K" is the filter passband gain.
Electronic low-pass filters.
First order.
RC filter.
One simple low-pass filter circuit consists of a resistor in series with a load, and a capacitor in parallel with the load. The capacitor exhibits reactance, and blocks low-frequency signals, forcing them through the load instead. At higher frequencies the reactance drops, and the capacitor effectively functions as a short circuit. The combination of resistance and capacitance gives the time constant of the filter formula_5 (represented by the Greek letter tau). The break frequency, also called the turnover frequency or cutoff frequency (in hertz), is determined by the time constant:
or equivalently (in radians per second):
This circuit may be understood by considering the time the capacitor needs to charge or discharge through the resistor:
Another way to understand this circuit is through the concept of reactance at a particular frequency:
The capacitor is not an "on/off" object (like the block or pass fluidic explanation above). The capacitor variably acts between these two extremes. It is the Bode plot and frequency response that show this variability.
RL filter.
A resistor–inductor circuit or RL filter is an electric circuit composed of resistors and inductors driven by a voltage or current source. A first order RL circuit is composed of one resistor and one inductor and is the simplest type of RL circuit.
A first order RL circuit is one of the simplest analogue infinite impulse response electronic filters. It consists of a resistor and an inductor, either in series driven by a voltage source or in parallel driven by a current source.
Second order.
RLC filter.
An RLC circuit (the letters R, L and C can be in other orders) is an electrical circuit consisting of a resistor, an inductor, and a capacitor, connected in series or in parallel. The RLC part of the name is due to those letters being the usual electrical symbols for resistance, inductance and capacitance respectively. The circuit forms a harmonic oscillator for current and will resonate in a similar way as an LC circuit will. The main difference that the presence of the resistor makes is that any oscillation induced in the circuit will die away over time if it is not kept going by a source. This effect of the resistor is called damping. The presence of the resistance also reduces the peak resonant frequency somewhat. Some resistance is unavoidable in real circuits, even if a resistor is not specifically included as a component. An ideal, pure LC circuit is an abstraction for the purpose of theory.
There are many applications for this circuit. They are used in many different types of oscillator circuits. Another important application is for tuning, such as in radio receivers or television sets, where they are used to select a narrow range of frequencies from the ambient radio waves. In this role the circuit is often referred to as a tuned circuit. An RLC circuit can be used as a band-pass filter, band-stop filter, low-pass filter or high-pass filter. The RLC filter is described as a "second-order" circuit, meaning that any voltage or current in the circuit can be described by a second-order differential equation in circuit analysis.
Higher order passive filters.
Higher order passive filters, can also be constructed (see diagram for a third order example).
Active electronic realization.
Another type of electrical circuit is an "active" low-pass filter.
In the operational amplifier circuit shown in the figure, the cutoff frequency (in hertz) is defined as:
or equivalently (in radians per second):
The gain in the passband is −"R"2/"R"1, and the stopband drops off at −6 dB per octave (that is −20 dB per decade) as it is a first-order filter.
Discrete-time realization.
Many digital filters are designed to give low-pass characteristics. Both infinite impulse response and finite impulse response low pass filters as well as filters using fourier transforms are widely used.
Simple infinite impulse response filter.
The effect of an infinite impulse response low-pass filter can be simulated on a computer by analyzing an RC filter's behavior in the time domain, and then discretizing the model.
From the circuit diagram to the right, according to Kirchhoff's Laws and the definition of capacitance:
where formula_11 is the charge stored in the capacitor at time formula_12. Substituting equation Q into equation I gives formula_13, which can be substituted into equation V so that:
This equation can be discretized. For simplicity, assume that samples of the input and output are taken at evenly-spaced points in time separated by formula_15 time. Let the samples of formula_16 be represented by the sequence formula_17, and let formula_18 be represented by the sequence formula_19, which correspond to the same points in time. Making these substitutions:
And rearranging terms gives the recurrence relation
That is, this discrete-time implementation of a simple RC low-pass filter is the exponentially-weighted moving average
By definition, the "smoothing factor" formula_23. The expression for formula_24 yields the equivalent time constant formula_25 in terms of the sampling period formula_15 and smoothing factor formula_24:
Recalling that
then formula_31 and formula_32 are related by:
and
If formula_35, then the formula_25 time constant is equal to the sampling period. If formula_37, then formula_25 is significantly larger than the sampling interval, and formula_39.
The filter recurrence relation provides a way to determine the output samples in terms of the input samples and the preceding output. The following pseudocode algorithm simulates the effect of a low-pass filter on a series of digital samples:
 // Return RC low-pass filter output samples, given input samples,
 // time interval "dt", and time constant "RC"
 function lowpass("real[0..n]" x, "real" dt, "real" RC)
 var "real[0..n]" y
 var "real" α := dt / (RC + dt)
 y[0] := x[0]
 for i from 1 to n
 y[i] := α * x[i] + (1-α) * y[i-1]
 return y
The loop that calculates each of the "n" outputs can be refactored into the equivalent:
 for i from 1 to n
 y[i] := y[i-1] + α * (x[i] - y[i-1])
That is, the change from one filter output to the next is proportional to the difference between the previous output and the next input. This exponential smoothing property matches the exponential decay seen in the continuous-time system. As expected, as the time constant formula_25 increases, the discrete-time smoothing parameter formula_24 decreases, and the output samples formula_19 respond more slowly to a change in the input samples formula_17; the system has more "inertia". This filter is an infinite-impulse-response (IIR) single-pole low-pass filter.
Finite impulse response.
Finite-impulse-response filters can be built that approximate to the sinc function time-domain response of an ideal sharp-cutoff low-pass filter. In practice, the time-domain response must be time truncated and is often of a simplified shape; in the simplest case, a running average can be used, giving a square time response.
Fourier transformation.
For minimum distortion the finite impulse response filter has an unbounded number of coefficients.
For non-realtime filtering, to achieve a low pass filter, the entire signal is usually taken as a looped signal, the Fourier transform is taken, filtered in the frequency domain, followed by an inverse Fourier transform. Only O(n log(n)) operations are required compared to O(n2) for the time domain filtering algorithm.
This can also sometimes be done in real-time, where the signal is delayed long enough to perform the Fourier transformation on shorter, overlapping blocks.

</doc>
<doc id="56486" url="http://en.wikipedia.org/wiki?curid=56486" title="High-pass filter">
High-pass filter

A high-pass filter is an electronic filter that passes signals with a frequency higher than a certain cutoff frequency and attenuates signals with frequencies lower than the cutoff frequency. The amount of attenuation for each frequency depends on the filter design. A high-pass filter is usually modeled as a linear time-invariant system. It is sometimes called a low-cut filter or bass-cut filter. High-pass filters have many uses, such as blocking DC from circuitry sensitive to non-zero average voltages or radio frequency devices. They can also be used in conjunction with a low-pass filter to produce a bandpass filter.
First-order continuous-time implementation.
The simple first-order electronic high-pass filter shown in Figure 1 is implemented by placing an input voltage across the series combination of a capacitor and a resistor and using the voltage across the resistor as an output. The product of the resistance and capacitance ("R"×"C") is the time constant (τ); it is inversely proportional to the cutoff frequency "f""c", that is,
where "f""c" is in hertz, "τ" is in seconds, "R" is in ohms, and "C" is in farads.
Figure 2 shows an active electronic implementation of a first-order high-pass filter using an operational amplifier. In this case, the filter has a passband gain of -"R"2/"R"1 and has a cutoff frequency of
Because this filter is active, it may have non-unity passband gain. That is, high-frequency signals are inverted and amplified by "R"2/"R"1.
Discrete-time realization.
Discrete-time high-pass filters can also be designed. Discrete-time filter design is beyond the scope of this article; however, a simple example comes from the conversion of the continuous-time high-pass filter above to a discrete-time realization. That is, the continuous-time behavior can be discretized.
From the circuit in Figure 1 above, according to Kirchhoff's Laws and the definition of capacitance:
where formula_4 is the charge stored in the capacitor at time formula_5. Substituting Equation (Q) into Equation (I) and then Equation (I) into Equation (V) gives:
This equation can be discretized. For simplicity, assume that samples of the input and output are taken at evenly-spaced points in time separated by formula_7 time. Let the samples of formula_8 be represented by the sequence formula_9, and let formula_10 be represented by the sequence formula_11 which correspond to the same points in time. Making these substitutions:
And rearranging terms gives the recurrence relation
That is, this discrete-time implementation of a simple continuous-time RC high-pass filter is
By definition, formula_15. The expression for parameter formula_16 yields the equivalent time constant formula_17 in terms of the sampling period formula_7 and formula_16:
Recalling that
then formula_16 and formula_24 are related by:
and
If formula_27, then the formula_17 time constant equal to the sampling period. If formula_29, then formula_17 is significantly smaller than the sampling interval, and formula_31.
Algorithmic implementation.
The filter recurrence relation provides a way to determine the output samples in terms of the input samples and the preceding output. The following pseudocode algorithm will simulate the effect of a high-pass filter on a series of digital samples:
 // Return RC high-pass filter output samples, given input samples,
 // time interval "dt", and time constant "RC"
 function highpass("real[0..n]" x, "real" dt, "real" RC)
 var "real[0..n]" y
 var "real" α := RC / (RC + dt)
 y[0] := x[0]
 for i from 1 to n
 y[i] := α * y[i-1] + α * (x[i] - x[i-1])
 return y
The loop which calculates each of the formula_32 outputs can be refactored into the equivalent:
 for i from 1 to n
 y[i] := α * (y[i-1] + x[i] - x[i-1])
However, the earlier form shows how the parameter α changes the impact of the prior output y[i-1] and current "change" in input (x[i] - x[i-1]). In particular,
Applications.
Audio.
High-pass filters have many applications. They are used as part of an audio crossover to direct high frequencies to a tweeter while attenuating bass signals which could interfere with, or damage, the speaker. When such a filter is built into a loudspeaker cabinet it is normally a passive filter that also includes a low-pass filter for the woofer and so often employs both a capacitor and inductor (although very simple high-pass filters for tweeters can consist of a series capacitor and nothing else).
As an example, the formula above, applied to a tweeter with R=10 Ohm, will determine the capacitor value for a cut-off frequency of 5 kHz.
formula_39, or approx 3.2 μF.
An alternative, which provides good quality sound without inductors (which are prone to parasitic coupling, are expensive, and may have significant internal resistance) is to employ bi-amplification with active RC filters or active digital filters with separate power amplifiers for each loudspeaker. Such low-current and low-voltage line level crossovers are called active crossovers.
Rumble filters are high-pass filters applied to the removal of unwanted sounds near to the lower end of the audible range or below. For example, noises (e.g., footsteps, or motor noises from record players and tape decks) may be removed because they are undesired or may overload the RIAA equalization circuit of the preamp.
High-pass filters are also used for AC coupling at the inputs of many audio power amplifiers, for preventing the amplification of DC currents which may harm the amplifier, rob the amplifier of headroom, and generate waste heat at the loudspeakers voice coil. One amplifier, the professional audio model DC300 made by Crown International beginning in the 1960s, did not have high-pass filtering at all, and could be used to amplify the DC signal of a common 9-volt battery at the input to supply 18 volts DC in an emergency for mixing console power. However, that model's basic design has been superseded by newer designs such as the Crown Macro-Tech series developed in the late 1980s which included 10 Hz high-pass filtering on the inputs and switchable 35 Hz high-pass filtering on the outputs. Another example is the QSC Audio PLX amplifier series which includes an internal 5 Hz high-pass filter which is applied to the inputs whenever the optional 50 and 30 Hz high-pass filters are turned off.
Mixing consoles often include high-pass filtering at each channel strip. Some models have fixed-slope, fixed-frequency high-pass filters at 80 or 100 Hz that can be engaged; other models have sweepable high-pass filters, filters of fixed slope that can be set within a specified frequency range, such as from 20 to 400 Hz on the Midas Heritage 3000, or 20 to 20,000 Hz on the Yamaha M7CL digital mixing console. Veteran systems engineer and live sound mixer Bruce Main recommends that high-pass filters be engaged for most mixer input sources, except for those such as kick drum, bass guitar and piano, sources which will have useful low frequency sounds. Main writes that DI unit inputs (as opposed to microphone inputs) do not need high-pass filtering as they are not subject to modulation by low-frequency stage wash—low frequency sounds coming from the subwoofers or the public address system and wrapping around to the stage. Main indicates that high-pass filters are commonly used for directional microphones which have a proximity effect—a low-frequency boost for very close sources. This low frequency boost commonly causes problems up to 200 or 300 Hz, but Main notes that he has seen microphones that benefit from a 500 Hz high-pass filter setting on the console.
Image.
High-pass and low-pass filters are also used in digital image processing to perform image modifications, enhancements, noise reduction, etc., using designs done in either the spatial domain or the frequency domain.
A high-pass filter, if the imaging software does not have one, can be done by duplicating the layer, putting a gaussian blur, inverting, and then blending with the original layer using an opacity (say 50%) with the original layer.
The unsharp masking, or sharpening, operation used in image editing software is a high-boost filter, a generalization of high-pass.

</doc>
<doc id="56487" url="http://en.wikipedia.org/wiki?curid=56487" title="Sax Rohmer">
Sax Rohmer

Arthur Henry Ward (15 February 1883 – 1 June 1959), better known as Sax Rohmer, was a prolific English novelist. He is best remembered for his series of novels featuring the master criminal Dr Fu Manchu.
Life and work.
Born in Birmingham to a working-class Irish Catholic family, Arthur Ward had an entirely working class education and early career before beginning to write. He initially pursued a career as a civil servant before concentrating on writing full-time. He worked as a poet, songwriter and comedy sketch writer for Music hall performers before creating the Sax Rohmer persona and pursuing a career writing weird fiction. 
Like his contemporaries Algernon Blackwood and Arthur Machen, Rohmer claimed membership to one of the factions of the qabbalistic Hermetic Order of the Golden Dawn. Rohmer also claimed ties to the Rosicrucians, but the validity of his claims has been questioned. His doctor and family friend, Dr R. Watson Councell may have been his only legitimate connection to such organisations. 
His first published work came in 1903, when the short story "The Mysterious Mummy" was sold to "Pearson's Weekly". Rohmer's main literary influences seem to have been Edgar Allan Poe, Arthur Conan Doyle and M. P. Shiel.
He gradually transitioned from writing for music hall performers to concentrating on short stories and serials for magazine publication. In 1909 he married Rose Elizabeth Knox.
He published his first book "Pause!" anonymously in 1910.
The Fu Manchu series.
After penning "Little Tich" in 1911 (as ghostwriter for the famous music hall entertainer of the same name: Little Tich) he issued the first Fu Manchu novel, "The Mystery of Dr. Fu-Manchu", serialised from October 1912 to June 1913. It was an immediate success, with its fast-paced story of Denis Nayland Smith and Dr. Petrie facing the worldwide conspiracy of the 'Yellow Peril'. The Fu Manchu stories, together with his more conventional detective series characters—Paul Harley, Gaston Max, Red Kerry, Morris Klaw (an occult detective), and The Crime Magnet—made Rohmer one of the most successful and well-paid authors of the 1920s and 1930s.
The first three Fu Manchu books were published in the four years 1913–17; but it was not until 1931 (some fourteen years after the third book in the series) that Rohmer returned to the series with "The Daughter of Fu Manchu". The reason for the long interval was that Rohmer wanted to be well and truly done with the series after "The Si-Fan Mysteries", much as Arthur Conan Doyle did with Sherlock Holmes. The first three books had been successfully filmed by Stoll in the twenties as a pair of serials. In 1928, Rohmer bowed to pressure and agreed to write a fourth novel as a serial for "Collier's". Paramount had the first Warner Oland picture gearing up for production and the daily newspaper strip based on the series was in the offing. There was public demand for the character's return. 
Rohmer's first effort at reviving the Fu Manchu property was eventually reworked as "The Emperor of America". The original intent had been for the head of the organisation to be Fu Manchu's daughter. He kept Head Centre as a female criminal mastermind to combat Drake Roscoe, but was very unhappy with the book both as it started and in its finished form. He would later return to Drake Roscoe and his female supervillain for the Sumuru series. In the meantime, he tried again to focus his energies on what was first titled "Fu Manchu's Daughter" for "Collier's" in 1930, but with an older (now knighted) Nayland Smith as the protagonist once more. The results were infinitely better and jump-started the series in the process.
In the 28 years from 1931 to 1959, Rohmer added no fewer than 10 new books to the Fu Manchu series, meaning the series totals thirteen books in all (not counting the posthumous collection "The Wrath of Fu Manchu"). The Fu Manchu series drew much criticism from the Chinese government and Chinese communities in the US for what was seen as negative ethnic stereotyping. Sociologist Virginia Berridge claims Rohmer created a false image of London's Chinese community as crime-ridden, further claiming that the Limehouse Chinese were one of the most law-abiding of London's ethnic minorities. Critic Jack Adrian notes that "Rohmer's own racism was careless and casual, a mere symptom of his times".
Other work.
Rohmer made friends with escape artist Harry Houdini, who wrote to him in praise of Rohmer's "The Romance of Sorcery". Rohmer based his mystery-solving magician character Bazarada on Houdini.
"The Orchard of Tears" is an odd book in the context of Sax Rohmer's other work. There are no oriental villains or exotic locations; rather, there are gentle rabbits and lambs in pastoral settings and a great deal of philosophical musing. As much as he enjoyed Fu Manchu—and the notoriety and income the character provided—Rohmer had other interests and a markedly serious side. The departure from his expected subject matter is plainly signalled by the book's dedication: "To the slaves of the pomegranate, sons of Adam and daughters of Eve, who drink at the fountain of life, this chalice is offered as a loving-cup".
In "The Quest of the Sacred Slipper" (1919) terror comes to Britain when a self-centered archaeologist unearths one of Islam's holiest relics—the sacred slipper of the prophet Mohammed. Until it is returned to its rightful people, the implacable Hassan of Aleppo vows his reign of death and destruction shall not cease. Behind these inhuman outrages is a secret group of fanatics. Not even the best men of Scotland Yard seem able to apprehend them. 
"Tales of Chinatown" (1922) is a collection of ten stories published in hardcover by Cassell in 1922 and Doubleday, Page and Company in 1922. All the stories first appeared in magazine format. This collection includes a story considered one of his best and also anthologised many times; "Tcheriapin." The story "The Hand of the Mandarin Quong" was rewritten for this; first published as "Hand of the White Sheikh" Rohmer changed the setting to a Chinatown background and published it as "The Mystery of the Shriveled Hand", the title then changed for this collection.
Rohmer also wrote several novels of supernatural horror, including "Brood of the Witch-Queen", described by Adrian as "Rohmer's masterpiece". Rohmer was very poor at managing his wealth, however, and made several disastrous business decisions that hampered him throughout his career. His final success came with a series of novels featuring a female variation on Fu Manchu, Sumuru. The Sumuru series consists of five books. Rohmer also wrote numerous short stories; "The Master of Hollow Grange" (1920), is a homage to M. R. James' story "Lost Hearts", featuring a mad scientist who preys on children.
Rohmer's work was banned in Nazi Germany, causing Rohmer to complain that he could not understand such censorship, stating "my stories are not inimical to Nazi ideals". 
After World War II, Rohmer and his wife moved to New York, only returning to London shortly before his death. He died in 1959, ironically due to an outbreak of influenza ("Asian Flu").
His wife, Rose Elizabeth (Knox) Ward (1886–1979), published her own mystery novel, "Bianca in Black", in 1958 under the pen name Elizabeth Sax Rohmer. Some editions of the book mistakenly credit her as Rohmer's daughter. She and Cay Van Ash (1918–1994), her husband's former assistant, wrote a biography of the author, "Master of Villainy", published in 1972. 
Bibliography.
For Rohmer's bibliography, see his full list of work.
Rohmer's wife published a number of works:
A note on texts: US editions of the Sumuru books (Gold Medal/Fawcett paperbacks) have texts which were frequently corrupted.

</doc>
<doc id="56488" url="http://en.wikipedia.org/wiki?curid=56488" title="Regina Maršíková">
Regina Maršíková

Regina Maršíková (born 11 December 1958 in Prague) is a former Czechoslovakian tennis player.
Maršíková's single titles were at Rome, Toronto and Christchurch in 1978, Phoenix, Arizona in 1980 and Berlin in 1981. In Grand Slam competition she never went further than the semifinals (three, all at the French Open, 1977–79).
Maršíková's major doubles win was at the French Open in 1977 with Pam Teeguarden.

</doc>
<doc id="56494" url="http://en.wikipedia.org/wiki?curid=56494" title="Bergen">
Bergen

Bergen (]) (Norwegian Nynorsk and Bokmål: /ˈbærɡn̩/, /-æɾɡ-/; Norwegian Bergensk: usually /ˈbæʁɡn̩/; British English: /ˈbəːɡən/; American English: /ˈbɜɹɡn̩/, /-ɡən/) is a city and municipality on the Bergen Peninsula in Hordaland county on the west coast of Norway. The city was established before 1070 AD. Bergen is the administrative centre of Hordaland.
As of 2014 the municipal population was making it, after Oslo, the second-most populous city in Norway. (The Greater Bergen Region population is .)
The area covered by the municipality is 465 km2, and it consists of eight boroughs.
The remains of the quays, Bryggen, is a World Heritage Site.
Bergen is an international centre for aquaculture, shipping, offshore petroleum industry and subsea technology, and a national centre for higher education, tourism and finance. Natives speak a distinctive dialect of Norwegian known as Bergensk. The city has an airport, a light rail system the busiest port in Norway and is the terminus of the Bergen Line;.
The city centre and northern neighbourhoods are located on the shoreline of Byfjorden fjord. Bergen is known as the city of the Seven Mountains.
Toponomy.
The Old Norse forms of the name were "Bergvin" and "Bjǫrgvin" (and in Icelandic and Faroese the city is still called "Björgvin"). The first element is "berg" (n.) or "bjǫrg" (n.), which translates to "mountain(s)". The last element is "vin" (f.), which means a new settlement where there used to be a pasture or meadow. The full meaning is then 'the meadow among the mountains'.
History.
Bergen received status as a city in 1070 AD during king Olav Kyrre's rule, according to the encyclopedia "Store norske leksikon".
Gitte Hansen's 2004 Ph.D. dissertation proposes that "Bergen was founded as a "handelsknutepunkt" [a crossroads for trading] sometime during the 1020s or 1030s". Later, in a 2004 NRK article, she said that "A king decided at the start of the 11th century, that here a city ought to be." Furthermore she said that king Olav Kyrre "was not the first [king] to start building a city [in Bergen].
The city was built on part of a royal estate, Alrekstad.
"The sagas tell that Olav Kyrre built a Christ Church at Holmen (later Bergenshus)"—made of wood—according to the encyclopedia "Store Norske Leksikon".
In 1068 the Diocese of Bergen was established.
Around 1100 the export (through Bergen) of dried cod from the northern Norwegian coast started, eventually becoming the principal export traded from Bergen.
Before the year 1110, Munkeliv Abbey was built.
The monarchy moved its quarters from the foot of Mount Ulriken, and at the new location wooden structures were eventually replaced by masonry, i.e. Haakon's Hall.
In 1163 the city's cathedral, the Christ Church, was the site of the first royal coronation in Norway.
The bishopric of Selja was moved to Bergen either in 1163 or, together with the relics of Sunniva, in 1170.
In 1181 the Birkebeiner defeated their opponents in the Battle of Bergen during the civil war era in Norway. "[The present-day neighbourhood] Engen was the battlefield in 1181 during the battle between king Sverre's men and "bondehæren" [the farmers' army]", according to the encyclopedia "Bergen byleksikon".)
After the 1181 Battle of Bergen.
Bergen was granted monopoly in regards to trade from the North of Norway, by king Haakon Haakonsson (1217-1263). Stockfish was the main reason that the city became one of North Europe's largest centres for trade at the time.
In 1281, a sixth coronation was held at Christ Church—the last one held there.
Some functions of the city were lost to Oslo during the reign of King Haakon V (1299–1319).
Bergen was Norway's most important city in the 13th century.
In 1343 (or in the 1350s) "the first Hanseatic commercial settlement was established in Bergen", according to Natascha Mehler.
German merchants formed a colony—protected by the Hanseatic League. Sources vary about whether it "was not an isolated German ghetto, but operated in vibrant interaction with its surroundings", or it was "separated from the Norwegian "bysamfunn" [city community]". This Kontor was located at Bryggen in Bergen. The Hanseatic merchants lived in their own separate quarter of town, where Middle Low German was spoken, enjoying exclusive rights to trade with the northern fishermen who each summer sailed to Bergen. During this century the Hanseatic merchants acquired monopolistic control over the trade in Bergen.
In 1349, the Black Death was inadvertently brought to Norway by the crew of an English ship arriving in Bergen.
By the late 14th century, Bergen had established itself as the centre of the trade in Norway.
On 22 April 1393 the Sacking of Bergen occurred. In 1395 the Victual Brothers attacked again.
In 1428, the city was attacked by the Victual Brothers, and they succeeded in burning the royal castle and much of the city.
During the Reformation, the "Kontor" at Bryggen experienced an economic backlash.
In 1560, the "Kontor" at Bryggen came under the legal jurisdiction of the authorities of Norway.
From around 1600, the Hanseatic dominance of the city's trade gradually declined in favour of Norwegian merchants (often of Hanseatic ancestry).
In 1630 the Hanseatic League was dissolved, but the "Kontor" continued operating.
In 1665, the city's harbour was the site of the Battle of Vågen, where an English naval flotilla attacked a Dutch merchant- and treasure fleet supported by the city's garrison.
In 1754, the operations of the "Kontor" at Bryggen, ended.
Until 1789, Bergen retained its monopoly to mediate trade between Northern Norway and abroad.
The website dagsdato.no has said that on 23 September 1814 the city had chosen representatives for the extraordinary [session of] Norway's parliament, but "sogneprest" Jonas Rein was not chosen.
In the 1830s, Oslo (the capital) surpassed Bergen as Norway's most populous city.
In 1882 the city's phone company was established.
In 1883 the rail line to Voss was completed—"Vossebanen".
In 1897 a trolley service started operating.
In 1900 utility services for electricity started.
In 1909 the rail line to Oslo opened—the Bergen Line.
In 1917 the pier Skoltegrunnskaien opened.
In 1932 the road to Hardanger was completed, connecting Bergen to a significant part of Norway's road network.
World War II.
During World War II Bergen was occupied on the first day of the German invasion on 9 April 1940, after a brief fight between German ships and the Norwegian coastal artillery. The German cruiser Königsberg was badly damaged by Norwegian coastal artillery at Kvarven Fort, and sunk by British bombers the following day, 10 April 1940, in the harbour. On 20 April 1944 the Dutch cargo ship "Voorbode" anchored off the Bergenhus Fortress, loaded with over 120 tons of explosives, blew up, killing at least 150 people and damaging historic buildings. The city was subject to some Allied bombing raids, aiming at German naval installations in the harbour. Some of these caused Norwegian civilian casualties numbering about 100.
On the morning of 8 May 1945, Wehrmacht's superior officer in Norway announced that he would follow orders to capitulate.
The resistance groups in Bergen were Saborg, Milorg, "Theta-gruppen", Sivorg, "Stein-organisasjonen" and the Communist Party.
After World War II.
9 July 1974 saw an accident on Ulriksbanen, which led to the largest rescue operation in the municipality, since World War II. Four people died.
In 1979 Bergen's old quayside, Bryggen, was listed on UNESCO's list of World Heritage Sites.
From county to municipality.
Bergen was separated from Hordaland as a county of its own in 1831. It was established as a municipality on 1 January 1838 (see formannskapsdistrikt). The rural municipality of Bergen landdistrikt was merged with Bergen on 1 January 1877. The rural municipality of Årstad was merged with Bergen on 1 July 1915. The rural municipalities of Arna, Fana, Laksevåg, and Åsane were merged with Bergen on 1 January 1972. The city lost its status as a separate county on the same date. Bergen is now a municipality, in the county of Hordaland.
From 1831 to 1972, Bergen was its own county. In 1972 the municipality absorbed four surrounding municipalities, and at the same time became a part of Hordaland county.
In 1772 "Hospitalssognet"—relating to St. Jørgens Hospital—consisted of Solheim, Kronstad, Landås and all of Årstad, according to a map from that year.
Fires.
In 1170 or 1171, the first great fire occurred.
In 1198, the Bagler-faction set fire to the city in connection with a battle against the Birkebeiner faction during the civil war. In 1248, "Holmen" and "Sverresborg" burned, and 11 churches were destroyed. In 1413 another fire struck the city, and 14 churches were destroyed. In 1428 the city was plundered by German pirates, and in 1455, Hanseatic merchants were responsible for burning down Munkeliv Abbey. In 1476, "Bryggen" burned down in a fire started by a drunk trader. In 1582, another fire hit the city centre and "Strandsiden". In 1675, 105 buildings burned down in "Øvregaten". In 1686 a new great fire hit "Strandsiden", destroying 231 city blocks and 218 boathouses. The greatest fire to date happened in 1702 when 90 percent of the city was burned to ashes. In 1751, there was a great fire at "Vågsbunnen". In 1756, a new fire at "Strandsiden" burned down 1,500 buildings, and further great fires hit "Strandsiden" in 1771 and 1901. In 1916, 300 buildings burned down in the city centre, and in 1955 parts of "Bryggen" burned down.
1918 campaign to revert to former name.
In 1918, there was a campaign to reintroduce the Norse form "Bjørgvin" as the name of the city. This was turned down – but as a compromise the name of the diocese was changed to "Bjørgvin bispedømme".
Geography.
Bergen occupies most of the peninsula of Bergenshalvøyen in the district of Midthordland in mid-western Hordaland. The municipality covers an area of 465 km2. Most of the urban area is located on or close to a fjord or bay, although there are several mountains located within the urban area.
Surrounding the centre of the city are the Seven Mountains, although there is disagreement as to which of the nine mountains constitute these. Ulriken, Fløyen, Løvstakken and Damsgårdsfjellet are always included as well as three of Lyderhorn, Sandviksfjellet, Blåmanen, Rundemanen, Kolbeinsvarden, and, at least until 1980, Askøyfjellet. Gullfjellet is the highest mountain in Bergen, at 987 m above mean sea level.
The population is 271,067 making the population density 583 people per km2. The main urban area of Bergen has 238,098 residents and covers an area of 96.71 km2. Other urban areas, as defined by Statistics Norway, consists of Indre Arna (6,536 residents), Fanahammeren (3,690), Ytre Arna (2,626), Hylkje (2,277) and Espeland (2,182).
Bergen is sheltered from the North Sea by the islands Askøy, Holsnøy (the municipality of Meland) and Sotra (the municipalities of Fjell and Sund). Bergen borders the municipalities Meland, Lindås and Osterøy to the north, Vaksdal and Samnanger to the east, Os and Austevoll to the south, and Sund, Fjell and Askøy to the west.
View of the city centre from Mt. Fløyen
Climate.
Bergen features a temperate oceanic climate (Köppen: Cfb). Areas of the municipality at some higher altitude (above ca 200 m amsl) are largely oceanic sub-polar (Cfc), with cool winters and mild summers. Bergen's weather is warmer than the city's latitude might suggest. The Gulf Stream provides the city with the warmest winters of all cities in the Nordic countries. Bergen experiences plentiful rainfall in all seasons, with annual precipitation measuring 2250 mm on average. This is because the city is surrounded by mountains that cause moist North Atlantic air to undergo orographic lift, yielding abundant rainfall. Rain fell every day between 29 October 2006 and 21 January 2007, 85 consecutive days. The highest temperature ever recorded was 31.8 °C on July 17, 2003 and the lowest was -16.3 °C in 1987. 
The high precipitation is often used in the marketing of the city, and figures to a degree on postcards sold in the city. For some time there were umbrella vending machines in the city, but these did not turn out to be a success. Compared to areas behind the mountains on the Scandinavian peninsula, Bergen is much wetter and has a narrower temperature range with very cool summers and mild winters. In terms of temperature and precipation, Bergen has more in common with the climate of Scotland across the sea than with Oslo and Sweden, where long heat and cold-waves occur regularly.
In recent years, precipitation and winds have increased in the city. In late 2005, heavy rains caused floods and several landslides, the worst of which killed three people on 14 September. Some indications are that, due to climate change, storms causing landslides and floods will become more severe in the area and in the surrounding counties. As a response, the municipality created a special 24-man rescue unit within the fire department in 2005, to respond to future slides and other natural disasters, and neighbourhoods considered at risk of slides were surveyed in 2006. The prediction was supported by over 480 landslides in Hordaland county from the spring of 2006 to the summer of 2007. Most of the slides hit roads however none of them had caused damage to cars, buildings, or people, until October 2007, when a large rock dislodged and killed the driver of a car. Another concern is the risk of rising sea levels. Already, Bryggen is regularly flooded at extreme tides, and it is feared that as sea levels rise, floods will become a major problem in Bergen. Floods may in the future reach the railroad tracks leading out of the city. It has therefore been suggested by among others Stiftelsen Bryggen, the foundation responsible for preserving the UNESCO site, that a sea wall, built so that it could be raised and lowered as demanded by the tides, be built outside the harbour to protect the city.
Demographics.
Ethnic Norwegians make up 84.5% of Bergen's residents. In addition, 8.1% were first or second generation immigrants of Western background and 7.4% were first or second generation immigrants of non-Western background. The population grew by 4,549 people in 2009, a growth rate of 1,8%. Ninety-six percent of the population live in urban areas. As of 2002, the average gross income for men above the age of 17 is 426,000 Norwegian krone (NOK), the average gross income for women above the age of 17 is NOK 238,000, with the total average gross income being NOK 330,000. In 2007, there were 104.6 men for every 100 women in the age group of 20–39. 22.8% of the population were under 17 years of age, while 4.5% were 80 and above.
The immigrant population (those with two foreign-born parents) in Bergen, includes 42,169 individuals with backgrounds from 180 countries representing 15.5% of the city's population (2014). Of these, 50.2% have background from Europe, 28.9% from Asia, 13.1% from Africa, 5.5% from Latin America, 1.9% from North America and 0.4% from Oceania. The immigrant population in Bergen in the period 1993–2008 increased by 119.7%, while the ethnic Norwegian population has grown by 8.1% during the same period. The national average is 138.0% and 4.2%. The immigrant population has thus accounted for 43.6% of Bergen's population growth and 60.8% of Norway's population growth during the period 1993–2008, compared with 84.5% in Oslo.
The immigrant population in Bergen has changed a lot since 1970. As of 1 January 1986, there were 2,870 persons with non-Western immigrant background in Bergen. In 2006, this figure had increased to 14,630, so the non-Western immigrant population in Bergen was five times higher than in 1986. This is a slightly slower growth than the national average, which has sextupled during the same period. Also in relation to the total population in Bergen, the proportion of non-Western increased significantly. In 1986, the proportion of the total population in the municipality of non-Western background was 3.6%. In January 2006, persons with non-Western immigrant background accounted for 6 percent of the population in Bergen. The share of Western immigrants has remained stable at around 2% in the period. The number of Poles in Bergen rose from 697 in 2006 to 3,128 in 2010.
The Church of Norway is the largest denomination in Bergen, with 201,006 (79.74%) adherents in 2012. Bergen is the seat of the Diocese of Bjørgvin with Bergen Cathedral as its centrepiece, which St John's Church is the city's most prominent. The state church is followed by 52,059 (13.55%) irreligious 12,000 Catholics belonging to Saint Paul Catholic Church 4,947 members of various Protestant free churches, 2,707 Muslims, 816 Hindus, 255 Russian Orthodox and 147 Oriental Orthodox. For a complete list of Church of Norway churches in Bergen, see the List of churches in Hordaland.
Cityscape.
The city centre of Bergen is located west in the municipality, facing the fjord of Byfjorden. It is situated among a group of mountains known as the Seven Mountains, although the number is a matter of definition. From here, the urban area of Bergen extends to the north, west and south, and to its east is a large mountain massif. Outside of the city centre and the surrounding neighbourhoods (i.e. Årstad, inner Laksevåg and Sandviken), the majority of the population lives in relatively sparsely populated residential areas that have been built since the 1950s. While some are dominated by apartment buildings and modern terraced houses (e.g. Fyllingsdalen), others are dominated by single-family homes.
The oldest part of Bergen is the area around the bay of Vågen in the city centre. Originally centred on the eastern side of the bay, Bergen eventually expanded west and southwards. Few buildings from the oldest period remain, the most significant being St Mary's Church from the 12th century. For several hundred years, the extent of the city remained almost constant. The population was stagnant, and the city limits were narrow. In 1702, ⅞ of the city burned. Most of the old buildings of Bergen, including Bryggen (which was rebuilt in a medieval style), were built after the fire. The fire marked a transition from tar covered houses, as well as the remaining log houses, to painted and some brick-covered wooden buildings.
The last half of the 19th century was a period of rapid expansion and modernisation of the city. The fire of 1855 west of Torgallmenningen led to the development of regularly sized city blocks in this area of the city centre. The city limits were expanded in 1876, and Nygård, Møhlenpris and Sandviken were urbanised with large-scale construction of city blocks housing both the poor and the wealthy. Their architecture is influenced by a variety of styles; historicism, classicism and Art Nouveau. The wealthy built villas between Møhlenpris and Nygård, and on the side of Mount Fløyen; these areas were also added to Bergen in 1876. Simultaneously, an urbanisation process was taking place in Solheimsviken in Årstad, at the time outside of Bergen municipality, centred on the large industrial activity in the area. The workers' homes in this area were poorly built, and little remains after large-scale redevelopment in the 1960s–1980s.
After Årstad became a part of Bergen in 1916, a development plan was applied to the new area. Few city blocks akin to those in Nygård and Møhlenpris were planned. Many of the worker class built their own homes, and many small, detached apartment buildings were built. After World War II, Bergen had again run short on land to build on, and, contrary to the original plans, many large apartment buildings were built in Landås in the 1950s and 1960s. Bergen acquired Fyllingsdalen from Fana municipality in 1955. Like similar areas in Oslo (e.g. Lambertseter), Fyllingsdalen was developed into a modern suburb with large apartment buildings, mid-rises, and some single-family homes, in the 1960s and 1970s. Similar developments took place outside of Bergen's city limits, for example in Loddefjord.
At the same time as planned city expansion took place inside Bergen, its extra-municipal suburbs too grew rapidly. Wealthy citizens of Bergen had been living in Fana since the 19th century, but as the city expanded it became more convenient to settle in the municipality. Similar processes took place in Åsane and Laksevåg. Most of the homes in these areas are detached row houses, single family homes or small apartment buildings. After the surrounding municipalities were merged with Bergen in 1972, expansion has continued in largely the same manner, although the municipality encourages condensing near commercial centres, future Bergen Light Rail stations, and elsewhere.
As part of the modernisation wave of the 1950s and 1960s, and due to damage caused by World War II, the city government ambitiously planned redevelopment of many areas in central Bergen. The plans involved demolition of several neighbourhoods of wooden houses, namely Nordnes, Marken, and Stølen. None of the plans was carried out in its original form; the Marken and Stølen redevelopment plans were discarded entirely and that of Nordnes only carried out in the area that had been most damaged by war. The city council of Bergen had in 1964 voted to demolish the entirety of Marken, however, the decision proved to be highly controversial and the decision was reversed in 1974. Bryggen was under threat of being wholly or partly demolished after the fire of 1955, when a large number of the buildings burned to the ground. Instead of being demolished, the remaining buildings were eventually restored and accompanied by reconstructions of some of the burned buildings.
Demolition of old buildings and occasionally whole city blocks is still taking place, the most recent major example being the 2007 razing of Jonsvollskvartalet at Nøstet.
Panorama of the reconstructed Hanseatic buildings of Bryggen, a World Heritage Site
Administration.
Since 2000, the city of Bergen has been governed by a city government ("byråd") based on the principle of parliamentarism. The government consists of 7 government members called commissioners, and is appointed by the city council, the supreme authority of the city. Since the local elections of 2007, the city has been ruled by a right-wing coalition of the Progress Party, the Christian Democratic Party and the Conservative Party, each with two commissioners. The Conservative Party member Trude Drevland is mayor, while conservative Ragnhild Stolt-Nielsen is the leader of the city government, the most powerful political position in Bergen.
2007 elections.
The 2007 city council elections were held on 10 September. The Socialist Left Party (SV) and the Pensioners Party (PP) ended up as the losers of the election, SV going from 11.6% of the votes in the 2003 elections to 7.1%, and PP losing 2.9% ending up at 1.2%. The Liberal Party more than doubled, going from 2.7% to 5.8%. The Conservative Party lost 1.1% of the votes, ending up at 26.3%, while the Progress Party got 20.2% of the votes, a gain of 3% since the 2003 elections. The Christian Democratic Party gained 0.2%, ending up at 6.3%. The Red Electoral Alliance lost 1.4%, ending up at 4.5%, while the Centre Party gained 1.2%, ending up at 2.8%. Finally, the Labour Party continued being the second largest party in the city, gaining 1% and ending up at 23.9%.
Boroughs.
Bergen is divided into 8 boroughs, as seen on the map to the left. Starting with the northernmost and going clockwise, the boroughs are Åsane, Arna, Fana, Ytrebygda, Fyllingsdalen, Laksevåg, Årstad and Bergenhus. The city centre is located in Bergenhus. Parts of Fana, Ytrebygda, Åsane and Arna are not part of the Bergen urban area, explaining why the municipality has approximately 20,000 more inhabitants than the urban area. The separate borough administrations were closed 30 June 2004, but were re-established 1 January 2008.
(Pertaining to the table above: The acreage figures include fresh water and uninhabited mountain areas, except: 
1 1 The borough Bergenhus is 8.73 km ², the rest is water and uninhabited mountain areas.
2 2 The borough Årstad is 8.47 km ², the rest is water and uninhabited mountain areas.)
A former borough, Sentrum.
Sentrum (literally, "Centre") was a borough (with the same name as a present-day neighbourhood). The borough was numbered "01", and its perimeter was from Store Lungegårdsvann and Strømmen along Puddefjorden around Nordnes and over to Skuteviken, up Mt. Fløyen east of Langelivannet, on to Skansemyren and over Forskjønnelsen to Store Lungegårdsvann, south of the railroad tracks.
The population of the (now defunct) borough, numbered in 1994 more than 18000 people.
Education.
There are 64 elementary schools, 18 lower secondary schools and 20 upper secondary schools in Bergen, as well as 11 combined elementary and lower secondary schools. Bergen Cathedral School is the oldest school in Bergen and was founded by Pope Adrian IV in 1153.
The "Bergen School of Meteorology" was developed at the Geophysical Institute beginning in 1917, the Norwegian School of Economics was founded in 1936, and the University of Bergen in 1946.
The University of Bergen has 16,000 students and 3,000 staff, making it the third-largest educational institution in Norway. Research in Bergen dates back to activity at Bergen Museum in 1825, although the university was not founded until 1946. The university has a broad range of courses and research in academic fields and three national centres of excellence, in climate research, petroleum research and medieval studies. The main campus is located in the city centre. The university cooperates with Haukeland University Hospital within medical research. The Chr. Michelsen Institute is an independent research foundation established in 1930 focusing on human rights and development issues.
Bergen University College has 6,000 students and 600 staff. It focuses on professional education, such as teaching, healthcare and engineering. The college was created through amalgamation in 1994; campuses are spread around town but will be co-located at Kronstad. The Norwegian School of Economics is located in outer Sandviken and is the leading business school in Norway, having produced three Economy Nobel Prize laureates. The school has more than 3000 students and approximately 400 staff. Other tertiary education institutions include the Bergen School of Architecture, the Bergen National Academy of the Arts, located in the city centre with 300 students, and the Norwegian Naval Academy located in Laksevåg. The Norwegian Institute of Marine Research has been located in Bergen since 1900. It provides research and advice relating to ecosystems and aquaculture. It has a staff of 700 people.
Economy.
In August 2004, "Time" magazine named the city one of Europe's 14 "secret capitals" where Bergen's capital reign is acknowledged within maritime businesses and activities such as aquaculture and marine research, with the Institute of Marine Research (IMR) (the second-largest oceanography research centre in Europe) as the leading institution. Bergen is the main base for the Royal Norwegian Navy (at Haakonsvern) and its international airport Flesland is the main heliport for the Norwegian North Sea oil and gas industry, from where thousands of offshore workers commute to their work places onboard oil and gas rigs and platforms.
One ship yard and a container terminal are located in Bergen.
Shopping centres include Lagunen Storsenter.
Fisketorget (English: fish market), a.k.a. "Torget" was found to be the city's largest tourist trap, according to a 2014 poll by local daily Bergens Tidende.
Tourism.
Tourism is an important income source for the city.
Bergen is Norway's largest cruise ship ports of call.
Hotel industry.
The hotels in the city may be full at times, due to the increasing number of tourists and conferences. Prior to the Rolling Stones concert in September 2006, many hotels were already fully booked several months in advance.
Office buildings in Bergen.
Transport.
Bergen Airport, Flesland, is located 18 km from the city centre, at Flesland. In 2013 the Avinor-operated airport served 6 million passengers. The airport serves as a hub for Scandinavian Airlines, Norwegian Air Shuttle and Widerøe; there are direct flights to 20 domestic and 53 international destinations.
The city centre is surrounded by an electronic toll collection ring using the Autopass system. The main motorways consist of E39, which runs north–south through the municipality, E16, which runs eastwards, and National Road 555, which runs westwards. There are four major bridges connecting Bergen to neighbouring municipalities: the Nordhordland Bridge, the Askøy Bridge, the Sotra Bridge and the Osterøy Bridge. Bergen connects to the island of Bjorøy via the subsea Bjorøy Tunnel.
Bergen Station is the terminus of the Bergen Line, which runs 496 km to Oslo. The Norwegian State Railways operates express trains to Oslo and the Bergen Commuter Rail to Voss. Between Bergen and Arna Station, the train runs every 30 minutes through the Ulriken Tunnel; there is no corresponding road tunnel, forcing road vehicles to travel via Åsane.
Bergen is one of the smallest cities in Europe to have both tram and trolleybus electric urban transport systems simultaneously. Public transport in Hordaland is managed by Skyss, which operates an extensive city bus network in Bergen and to many neighbouring municipalities, including one route which operates as a trolleybus. The trolleybus system in Bergen is the only one still in operation in Norway and one of two trolleybus systems in Scandinavia.
The modern tram Bergen Light Rail (Bybanen) opened between the city centre and Nesttun in 2010, extended to Rådal (Lagunen Storsenter) in 2013 and is scheduled to reach the airport in 2015. Extensions to other boroughs may occur later. Fløibanen is a funicular which runs from the city centre to Mount Fløyen and Ulriksbanen is an aerial tramway which runs to Mount Ulriken.
Roads that cross the boundaries of the municipality are Roads 555 (leading to islands (outside Bergen) that comprise Sotra), 562 (leading to Askøy via the Askøy Bridge), 163, E39 and E16.
Four bridges connect Bergen to its "suburban municipalities".
By sea.
Bergen Port, operated by Bergen Port Authority, is the largest seaport in Norway.
In 2011, the port saw 264 cruise calls with 350,248 visitors, In 2009, the port handled 56 million tonnes of cargo, making it the ninth-busiest cargo port in Europe. There are plans to relocate the port out of the city centre, but no location has been chosen. Fjord Line operates a cruiseferry service to Hirtshals, Denmark. Bergen is the southern terminus of Hurtigruten, the Coastal Express, which operates with daily services along the coast to Kirkenes. Passenger catamarans run from Bergen south to Haugesund and Stavanger, and north to Sognefjord and Nordfjord.
The city's piers include Dokkeskjærskaien.
Culture.
The city's cultural institutions include theatres (including Den Nationale Scene), the concert venue Grieg Hall, orchestras (Bergen Philharmonic Orchestra, founded in 1765), ensembles (incl. Bergen Woodwind Quintet) and dance companies (incl. Carte Blanche).
Festivals include the Bergen International Festival and the Bergen International Film Festival.
During the late 1990s and early 2000s, Bergen produced a series of successful pop, rock and black metal artists, collectively known as the Bergen Wave.
The contemporary art scene includes BIT Teatergarasjen, Bergen Kunsthall, United Sardines Factory (USF) and Bergen Centre for Electronic Arts (BEK).
Bergen was a European Capital of Culture in 2000.
News Media.
"Bergens Tidende" (BT) and "Bergensavisen" (BA) are the largest newspapers, with circulations of 87,076 and 30,719 in 2006, "BT" is a regional newspaper covering all of Hordaland and Sogn og Fjordane, while "BA" focuses on metropolitan Bergen. Other newspaper published in Bergen includes the Christian national "Dagen", with a circulation of 8.936, and "TradeWinds", an international shipping newspaper. Local newspapers are "Fanaposten" for Fana, "Sydvesten" for Laksevåg and Fyllingsdalen and "Bygdanytt" for Arna and the neighbouring municipality Osterøy. TV 2, Norway's largest private television company, is based in Bergen.
"Archery brigades" ("buekorps").
The youth organisations "buekorps" ("archery brigades"), unique to Bergen, drum and march (with imitation weapons) in the Constitution Day "Flaggtoget" parade. In the 2007 parade, there were 752 members—from 15 brigades.
Dialect.
Bergensk is the native dialect of Bergen and a variation of Vestnorsk. It was strongly influenced by Low German-speaking merchants from the mid-14th to mid-18th centuries. During the Dano-Norwegian period from 1536 to 1814, Bergen was more influenced by Danish than other areas of Norway. The Danish influence removed the female grammatical gender in the 16th century, making Bergensk one of very few Norwegian dialects with only two instead of three grammatical genders. The Rs are uvular trills, as in French, which probably spread to Bergen some time in the 18th century, overtaking the alveolar trill in the time span of two to three generations. Owing to an improved literacy rate, Bergensk was influenced by riksmål and bokmål in the 19th and 20th centuries. This led to large parts of the German-inspired vocabulary disappearing and pronunciations shifting slightly towards Eastern Norwegian (østnorsk).
Ruins.
Ruins include those of the Christ Church.
Museums.
Museums include Troldhaugen, Bryggens Museum, Hanseatic Museum and Schøtstuene and Bergen Kunstmuseum (including the Tower Hall—"Tårnsalen").
Monuments.
Monuments include the Ole Bull statue at Ole Bull's Place, and the Madam Felle monument in Sandviken.
Street art.
Bergen is looked upon as the street art capital of Norway; the famous artist Banksy visited the city in 2000 and inspired many to start with street art. Later the city brought the most famous street artist in Norway, Dolk, to town. His art can still be seen several places in the city, and in 2009 the city council chose to preserve Dolk's work "Spray" with protective glass. A five-year plan of action for street art to ensure that "Bergen will lead the fashion for street art as an expression both in Norway and Scandinavia" was launched by the city in 2011.
Sports.
After losing their bid to organise the 2016 UCI Road Cycling World Championships, Bergen is elected to host the 2017 UCI Road Cycling World Championships from 17–24 September.
SK Brann is Bergen's premier football team; founded in 1908, they have played in the (men's) Norwegian Premier League all but seven years since 1963 and consecutively since 1987. The team was the football champion in 1961–62, 1963 and 2007, and reached the quarter-finals of the Cup Winners' Cup in 1996–97. Brann plays their home games at the 17,824-seat Brann Stadion. FK Fyllingsdalen is the city's second-best team, playing in the Second Division at Varden Amfi. Its predecessor, Fyllingen, played in the Norwegian Premier League in 1990, 1991 and 1993. Arna-Bjørnar and Sandviken play in the Women's Premier League.
The city's main football team is SK Brann.
Bergen IK is the premier men's ice hockey team, playing at Bergenshallen in the First Division. Tertnes plays in the Women's Premier Handball League, and Fyllingen in the Men's Premier Handball League. In athletics, the city is dominated by IL Norna-Salhus, IL Gular and FIK BFG Fana, formerly also Norrøna IL and TIF Viking.
Recreation areas.
Beaches include the one on the lake Tennebekktjørna in the Nipedalen valley. Trails for hiking include those on Mt. Ulriken and in forests such as Kanadaskogen.
International relations.
Each year Bergen donates the Christmas Tree seen in Newcastle's Haymarket as a sign of the ongoing friendship between the sister cities. The Nordic friendship cities of Bergen, Gothenburg, Turku and Aarhus arrange inter-Nordic camps each year by inviting 10th grade school classes from each of the other cities to school camps. Bergen received a totem pole as a gift of friendship from the city of Seattle on the city's 900th anniversary in 1970. It is now placed in the Nordnes Park and gazes out over the sea towards the friendship city far to the west.
Public mass events.
The 7-Mountains Hike has been organised since 1948; it had 7916 participants in 2008.

</doc>
<doc id="56495" url="http://en.wikipedia.org/wiki?curid=56495" title="Mons">
Mons

Mons (]; Dutch: "Bergen" "mountains"; Picard: "Mont") is a Belgian city and municipality, and the capital of the province of Hainaut. The Mons municipality includes the former communes of Cuesmes, Flénu, Ghlin, Hyon, Nimy, Obourg, Baudour (partly), Jemappes, Ciply, Harmignies, Harveng, Havré, Maisières, Mesvin, Nouvelles, Saint-Denis, Saint-Symphorien, Spiennes, Villers-Saint-Ghislain, Casteau (partly), Masnuy-Saint-Jean (partly), and Ville-sur-Haine (partly). Together with the Czech city of Plzeň, Mons is the European Capital of Culture in 2015.
History.
Early settlements in the Middle Ages.
The first signs of activity in the region of Mons can be found at Spiennes, where some of the best flint tools in Europe were found dating from the Neolithic period. When Julius Caesar arrived in the region in the 1st century BC, the region was settled by the Nervii, a Belgian tribe. A castrum was built in Roman (Belgica) times, giving the settlement its Latin name Castrilocus; the name was later changed into Montes for the mountain on which the castrum was built. In the 7th century, Saint Ghislain and two of his disciples built an oratory or chapel dedicated to Saints Peter and Paul near the Mons hill, at a place called Ursidongus, now known as Saint-Ghislain. Soon after, Saint Waltrude (in French "Sainte Waudru"), daughter of one of Clotaire II’s intendants, came to the oratory and was proclaimed a saint upon her death in 688. She was canonized in 1039.
Like Ath, its neighbour to the north-west, Mons was made a fortified city by Baldwin IV, Count of Hainaut in the 12th century. The population grew quickly, trade flourished, and several commercial buildings were erected near the "Grand’Place". The 12th century also saw the appearance of the first town halls. The city had 4,700 inhabitants by the end of the 13th century. Mons succeeded Valenciennes as the capital of the county of Hainaut in 1295 and grew to 8,900 inhabitants by the end of the 15th century. In the 1450s, Matheus de Layens took over the construction of the Saint Waltrude church from Jan Spijkens and restored the town hall.
From 1500 to 1800.
In 1515, Charles V took an oath in Mons as Count of Hainaut. In this period of its history, the city became the target of various occupations, starting in May 1572 with the Protestant takeover by Louis of Nassau, who had hoped to clear the way for the French Protestant leader Gaspard de Coligny to oppose Spanish rule. After the murder of de Coligny during the St. Bartholomew's Day massacre, the Duke of Alba took control of Mons in September 1572 in the name of the Catholic King of Spain. This spelled the ruin of the city and the arrest of many of its inhabitants; from 1580 to 1584, Mons became the capital of the Southern Netherlands.
On April 8, 1691, after a nine-month siege, Louis XIV’s army stormed the city, which again suffered heavy casualties. From 1697 to 1701, Mons was alternately French or Austrian. After being under French control from 1701 to 1709, the Dutch army gained the upper hand in the Battle of Malplaquet. In 1715, Mons returned to Austria under the terms of the Treaty of Utrecht (1713). But the French did not give up easily; Louis XV besieged the city again in 1746. After the Battle of Jemappes (1792), the Hainaut area was annexed to France and Mons became the capital of the Jemappes district.
From 1800 to the present.
Following the fall of the First French Empire in 1814, King William I of the Netherlands fortified the city heavily. In 1830, however, Belgium gained its independence and the decision was made to dismantle fortified cities such as Mons, Charleroi, and Namur. The actual removal of fortifications only happened in the 1860s, allowing the creation of large boulevards and other urban projects. The Industrial Revolution and coal mining made Mons a center of heavy industry, which strongly influenced the culture and image of the Borinage region as a whole. It was to become an integral part of the sillon industriel, the industrial backbone of Wallonia.
Riots of Mons.
In 1893 (17 April), between Mons and Jemappes, seven strikers were killed by the civic guard at the end of the Belgian general strike of 1893.
The proposed law on universal suffrage was approved the day after by the Belgian Parliament.
This general strike was one of the first general strikes in an industrial country.
Battle of Mons.
On August 23 and 24, 1914, Mons was the location of the Battle of Mons - the first battle fought by the British Army in World War I (that started 28 July 1914). The British were forced to retreat with just over 1,600 casualties, and the town remained occupied by the Germans until its liberation by the Canadian Corps during the final days of the war.
Within the front entrance to the City hall, there are several memorial placards related to the WW1 battles and in particular, one has the inscription: 
Second World War.
During the Second World War, as an important industrial centre, the city was heavily bombed and several skirmishes took place in September 1944 between the American troops and the retreating German forces.
After 1945.
After the war, most industries went into decline.
NATO's Supreme Headquarters Allied Powers Europe (SHAPE) was relocated in Casteau, a village near Mons, from Fontainebleau after France's withdrawal from the military structure of the alliance in 1967. The relocation of SHAPE to this particular region of Belgium was largely a political decision, based in large part on the depressed economic conditions of the area at the time with the view to bolstering the economy of the region. A riot in the prison of Mons took place in April 2006 after prisoner complaints concerning living conditions and treatment; no deaths were reported as a result of the riot, but the event focused attention on prisons throughout Belgium. Today, the city is an important university town and commercial centre.
Festivities.
Tanks in town commemorates the liberation of Belgium during WWII by the 3rd Armored Division (United States), and is one of the largest gathering of World War II tanks, in the world.
Education.
There are several educational facilities in Mons:
Transportation.
Mons is located along N56 road.
It is also accessed via E42, which is a continuation of French Autoroute A2, linking the British WW1 battlefields of Mons with the Somme Battlefields,
Mons railway station opened on 19 December 1841.
A small, general aviation airfield Saint-Ghislain Airport is located nearby for private aircraft.
Sports.
The town hosts a football club named R.A.E.C. Mons, a professional Basketball team called Belfius Mons-Hainaut and a tennis tournament called the Ethias Trophy. There is also a horse racing venue at Hippodrome de Wallonie in Mons.
Planning and architectural heritage.
The centre consists largely of red brick houses. Although there are few old buildings and rarely new blue stone buildings, its use is generally limited to parts of the decorative walls. Much of the centre is made up of houses which are two or three storeys high. 
In commercial areas, the ground floor is used as commercial space, while other floors are used for housing. Generally behind the houses there is a small garden.
The outskirts of the city are also generally made of brick terraced houses. They nevertheless have the largest green spaces in the front or rear. In more remote areas of the centre, there are four façades of the villas.
After the Second World War the city experienced rather limited construction of buildings. 
Some public housing have been built in Ghlin, Hyon Jemappes and in the suburbs of the city. 
Since the late 1990s and especially since the arson which took place in one of these buildings, the city undertook a policy of deconstruction of these houses which is still in progress at the moment. A whole series of social buildings are evenly dispersed in the downtown and surrounding suburbs.
16,5% of the city's population lives in apartment (17% in Belgium) and 82.7% in single-family home (82.3% in Belgium). Of the 82.7% of single family homes, only 26% (37.3% in Belgium) are separate houses, while 55.7% (44.4 in Belgium) are detached or terraced houses. That's pretty much a small town in Belgium. Large municipalities have in fact less number of single family homes, but many more apartments whereas the smallest towns have few apartments and a lot of single family homes. It is interesting to note that the figures show very clearly the strong presence of terraced houses rather than separate houses: it exemplifies the urbanization of downtown, but also urban cores such as Jemappes et Cuesmes.
The main square.
The main square is the centre of the old city. It is situated near the shopping street (pedestrian) and the belfry. It is paved in the manner of old cities and is home to many cafes and restaurants, as well as the Town Hall.
The outskirts of the place is accessible by car, but it is forbidden to park or drive through the centre.
Each year it is represented as an action theatre called "Lumeçon", a battle between Saint George and Dragon.
The main square is also equipped with a fountain, which opened on none }}. It also hosts a Christmas market and sometimes an ice rink during holiday period.
The façade of the building called "au Blan Levrie" signifies care with which the city could unite the old and the modern. It is the first authorised building in the main square which was made of stone to avoid fire incidents.It was built in 1530 in Gothic style, for the rich family Malapert. In 1975, the architects A. Godart and O. Dupire were assigned to build a bank. They proceeded to undress complete interior volumes and precise survey of the whole and clear, before defining the restoration project. The façade had been completely restored as it was, sometimes (as below) by extending the design of mouldings remained intact in the columns. Or also for the fenestration impossible him to rebuild as it was given the lack of clues. Therefore, "The choice was directed towards a contemporary discrete, appearing in second test: they are steel frame whose profiles are thinner. » Impression yet reinforced by the way of which was treated at the entrance gate.
City Hall.
History.
Originally its communal organization, Mons was a City Hall called "House of Peace." Earlier the deputy mayors were on the castle of the Counts of Hainaut,and now it is only the conciergerier, Saint-Calixte chapel and some underground rooms and the chamber. This place is now Castle Park, where we can also see the belfry. Already in the 13th century, the counts mentioned the House of Peace, located in Nimy street. Other documents of the same team let suppose that there existed two Houses of Peace, the one in Nimy street and the other in the market area.
It was in 1323 that Count William I gave permission to build the House of Peace on the location of the current City Hall. This is called a "Town House" built in stones and bricks at the base, the superstructure is of wood. This building underwent various changes during the 15th century until 1477, when the nearby shop in the arsenal exploded.
The current City Hall.
The destroyed buildings were rebuilt and benefitted from new changes and additions over the centuries.
The architect of the City Hall of Leuven, Matthew Layens, was called to draw up plans. 
It should be a building in Gothic style, but it seems that the plan (which was not found) was not met, including the abandonment of the second floor, which was yet scheduled. The Renaissance campanile was added in the 18th century. It contains a bell dating from 1390, the Bancloque, and carries a clock dial overlooking the Grand Place and a light clock. The 19th century saw various modifications of the façade, the removal of stone mullions to the floor and various stone ornaments.
In its current state, the Town Hall has a remarkable collection of various buildings housing a large proportion of municipal services. These buildings have undergone many changes over the centuries, restorations and additions of elements from other buildings, such as a Gothic style fireplace of castle Trazegnies, carved doors of the 16th century from demolition, fireplace From the castle of Gouy-lez-Pedestrian, another fire in 1603 from the Chateau d'Havre.
On none }} was inaugurated a bronze statuary group by Garouste Gerard, author of a fresco for the wedding hall. The work, evoking the combat of St. George and the dragon is in front of City Hall, at the bottom of the stairs ramps providing access to one of the entrances of City Hall.
The Mayor's Garden.
These buildings surround a small, irregularly shaped square, the Mayor's Garden, from which the rue d'Enghien descends. The Ropieur Fountain, by sculptor Léon Gobert (1869–1935), can be found in the middle of the square. The ropieur symbolizes a young insolent resident of Mons, drenching passersby with water from the fountain.
The Guardhouse Monkey.
Outside the main entrance of City Hall is a small iron statue of a monkey. Its origin is not really known, but it dates back several centuries. Some historians claim it was placed there in order to bring luck to the city and its inhabitants. Today, the tradition is that whoever passes the monkey has to touch its head with his left hand for the fulfillment of a wish. You can clearly see in the picture that the monkey's head is no longer the same colour as the rest of his body as a result of the many many hands that have stroked it for luck. There are three hypotheses concerning the monkey's origins:
The Sainte-Waudru Collegiate Church.
Although located in the heart of the old County of Hainaut, Sainte-Waudru Collegiate Church is one of the most characteristic churches and most homogeneous of Brabantine Gothic architecture.
The collegiate was built in the 15th century on the orders of canons. Along with the nearby belfry it is considered as a major symbol of the city of Mons. It contains many works of Jacques du Broeucq.
It is made of local materials like sandstone, blue stone and brick It is designed in a classic form which is expressed by a Latin cross sign. It measures 115 metres long, 32 metres wide and rises to 24.5 metres at the keystone. The chancel is surrounded by an ambulatory and 15 chapels.
The Belfry.
Also called El Catiau by Montois, it was built in the 17th century. The belfry is the only baroque style building in Belgium that reaches a height of 87 meter. In its top section it contains a 49 bell carillon. It was classified as UNESCO World Heritage on December 1, 1999.
Victor Hugo described the belfry in a letter to his wife as "a coffeepot flanked by four smaller teapots".
Press house (Spanish house).
The Press House dates back to the 16th century, and is a rare example of a house in traditional Spanish style in Mons. It is made in a simple architectural way using brick. This material has economically developed after the fire incident in 1548, when it was rebuilt the cost of the stone had increased. In 1548 the deputy mayor prohibited the use of flammable materials.
The buildings were restored in 1919-1920, on the plans of the communal architect E. Bertiaux and are occupied by the Maison de la Presse.
The water machine.
This industrial hall is all that remains of the “machine” that supplied Mons with drinkable water from 1871, the year when the river Trouille was diverted. Designed by the architect Hubert and the engineer Celi Moullan, this impressive machinery of pipes and mains was built in metal and glass and forced the water from the valley level up to the town water tanks in the castle place yard.
The "water machine” still bears witness to the sanitary and hygiene concerns which arose in Mons in 1865-1870, it marks the transition from medieval water supply wells, springs and hand pumps, for operation of pumps suction and force.The water came from springs fed Mons de la Valliere and hole-to-mouse Spiennes Slutty using only force driving the hydraulic motor.
This progress at domestic level transformed the townspeople's way of life. They used to get water from wells or fountains, sometimes over a hundred yards from their homes. She has performed in the continuity of another urban project: the introduction in 1828 of city gas to illuminate new avenues and streets. These two changes are made possible by the demolition of the fortifications, which releases the land, and the diversion of Trouille including the strategic role of supply ditches was then passed.
The “water machine" was restored in the early 1990s and the building now hosts various cultural events.The machinery was dismantled.
Waux Hall.
Waux Hall park was built in the 19th century (1862–1864) at the initiative of the Society of Waux Hall created for this purpose by members of the bourgeoisie. It is therefore the source of a private park. It is located at the site of Fort said that the Dutch formed an outwork the last fortification (1815–1864). Remnants of the fort still exist under the current pavillon. The gardens were designed by Louis Fuchs and the central pavilion was built by architect Joseph Hubert in tavern style.
The Turkish hezel is one of the remarkable trees in the park.
A 5 hectare landscaped park was built in mid 19th century and consists of age-old trees, water features, lakes and lawns. Various memorials and outdoor sculptures, including works of sculptors Grard, Deville, Hupet, and Guilmot Harvent, are placed. The park also contains various species of age-old trees.
The Technical and Vocational School of Horticulture was established in 1863, it was installed under the authority of the corporation of Waux Hall. It became communal in 1892 at the time of acquisition of Waux Hall by the city of Mons, and then came under the authority of the province of Hainaut in 2006. In 2009 this event was moved to the Grand Place.
The Perfect Union.
The Lodge masonic the Perfect Union is the oldest in Belgium and perhaps even the continent. It was founded in 1721. At that time, Mons became a masonic center followed by the creation of several new lodges (Vraie et parfaite harmonie (1767), À l'Orient de Mons (1783) et la Ligue équitable (1786)).
After the French Revolution, the meetings were held in different locations, and an event was organized by The Perfect Union for the construction of a permanent building. The plans of the architect Hector Puchot were retained in 1890. The Neo-Egyptian style then became a reference for Masonic architecture, and we can consider the lodge of Mons as a model of its kind with its numerous motives "Egyptian" papyrus capitals, frieze lotus bud, etc..
Art Square.
William Barracks, renamed barracks Major Sabbe after the First World War and named for the 1990 Arts Square, dates from 1824–1827, at the time of the United Kingdom of the Netherlands. It is the work of the architect Rémi de Puydt (1789–1844). The façade and roof of the building were listed in 1983 on the advice of the Royal Commission of Monuments, Sites and Excavations.
Maintaining its military purpose until the late 1940s, the building was then used by the Royal Grammar School John Avesnes 1960s to early 1990s. Since the completion of the conversion carried out between 1993 and 1995, Carré des Arts hosts the Graduate School of Arts and visual (ESAPV) and regional television TV Borinage Mons (Tele MB).
The Red-Well.
Three wells, fountains that decorated the streets of Mons have survived until today. This is the case of the fountain-pillory, Louis XVI style, built in 1779 by the blue stone Ouvertus architect.
Built in 1831 by Albert Jamot, this well was transferred to the central Marché-aux-Herbes in 1877 and has served as a fountain after the development of water supply in city during the years 1869-1870. It has regained its original location at the corner of the Coupe and the Chaussée in 1981. After the Marché aux Herbes, the fountain (not connected to the water) was placed for a few years the Park at the far end of rue des 4 Fils Aymond.
The casemates.
The casemates and the bakery are the remains of military fortifications dating from the kingdom of the Netherlands (1814–1830). The law dividing the disassembly of the fortifications dates back to 1861. They are located near the Nervienne site. The roof of the old bakery has been transformed into a public park and fun for children, while the casemates accommodate themusée de la Route.
Valenciennois tower.
This is the last existing trace of the medieval walls surrounding the city. This defensive structure built of sandstone of Bray was built around 1358. Its walls equipped with loopholes have a thickness of up to 4 meters. The tower has lost about a third of its original size. A project to install a terrace on its top open to the public just been completed in 2009.
The tower has housed within it a sound installation in the festival of contemporary art audio-visual CitySonics when it reopened.
Concourse of the Courts.
In 1966, the Council of Ministers decided to build new buildings to house the Courts of Justice: Assize Court, Labour Court, Court of Appeal, Court of Commerce, ... The choice is the site of the former "Hall of exposure". The client is the Building Authority and the architects for the project is designated the Office Aura (John Bartholomew). The triangular shape of the land has created interior spaces, decreasing in height and width, forming a sort of "cathedral space" underlined by a continuous central luminous line. On this major axis, the backbone of the project, create spaces for encounter and release. The latest techniques have been implemented for the economic management of energy, giving maximum comfort to staff and the public while ensuring the development of architectural building.
Opened in May 2007, all buildings already present (January 2011) many problems of water seepage and stability. Thus one of the gateways weighing a hundred kilos is off its hinges and nearly fell on a lawyer who entered, cracks between concrete blocks, the joints of windows letting in wind and water, it rains in the concourse ... The lack of maintenance contract would be the cause of these problems, but minor departure from getting worse.
Patron saint.
The patron saint of Mons is Waltrude.

</doc>
<doc id="56498" url="http://en.wikipedia.org/wiki?curid=56498" title="Gand">
Gand

Gand can refer to

</doc>
<doc id="56499" url="http://en.wikipedia.org/wiki?curid=56499" title="Kingston">
Kingston

Kingston commonly refers to:
Kingston may also refer to:

</doc>
<doc id="56500" url="http://en.wikipedia.org/wiki?curid=56500" title="Bharata Natyam">
Bharata Natyam

Bharathanatyam (Tamil: பரதநாட்டியம்) is a form of Indian classical dance that originated in the temples of Tamil Nadu. It was described in the treatise "Natya Shastra" by Bharata around the beginning of the common era. Bharata Natyam is known for its grace, purity, tenderness, expression and sculpturesque poses. Lord Shiva is considered the God of this dance form. Today, it is one of the most popular and widely performed dance styles and is practiced by male and female dancers all over the world, although it is more commonly danced by women.
Etymology.
The name Bharata Natyam is of relatively recent origin when performers like Rukmini Devi revived the dance in the 20th century. The original names of Bharata Natyam were "Sadir", "Chinnamelan" and most commonly "Dasi Attam". A possible origin of the name is from Bharata Muni, who wrote the Natya Shastra. The word "Bharatnatyam" combines "Bhavam" meaning expression, "ragam" meaning music, "thalam" meaning rhythm and natyam meaning dance.
Dance tradition.
Surviving texts of the golden age of Tamil literature and poetry known during the Sangam period of "ca". 3rd century BCE to c. 4th century CE, such as the Tolkappiyam (தொல்காப்பியம்), as well as the later Silappadikaram (சிலப்பதிகாரம்), testify to a variety of dance traditions which flourished in these times. The latter work is of particular importance, since one of its main characters, the courtesan Madhavi, is a highly accomplished dancer. The Silappadikaram is a mine of information of ancient Tamil culture and society, in which the arts of music and dance were highly developed and played major roles.
Many of the ancient sculptures in Hindu temples are based on Bharata Natyam dance postures karanas. In fact, it is the celestial dancers, apsaras, who are depicted in many scriptures dancing the heavenly version of what is known on earth as Bharata Natyam. In the most essential sense, a Hindu deity is a revered royal guest in his temple/abode, to be offered the "sixteen hospitalities" - among which are music and dance, pleasing to the senses. Thus, many Hindu temples traditionally maintained complements of trained musicians and dancers, as did Indian rulers.
In Kali Yuga, the center of most arts in India is "Bhakti" (devotion) and therefore, Bharata Natyam as a dance form and carnatic music set to it are deeply grounded in Bhakti. Bharata Natyam, it is said, is the embodiment of music in visual form, a ceremony, and an act of devotion. Dance and music are inseparable forms; only with "Sangeetam" (words or syllables set to raga or melody) can dance be conceptualized. Bharata Natyam has three distinct elements to it: "Nritta" (rhythmic dance movements), "Natya" (mime, or dance with a dramatic aspect), and "Nritya" (combination of Nritta and Natya). "Natya" portrays a character and "Nritya" can be seen as a type of story telling, using lots of hand gestures and emotions.
Tamil Nadu, especially Tanjore, has always been the seat and centre of learning and culture. It was the famous quartet of Chinnayya, Ponniah, Sivanandam and Vadivelu of the Tanjore Court during the Marathi King Saraboji’s time (1798–1824) which made a rich contribution to music and Bharata Natyam and also completed the process of re-editing the Bharata Natyam programme into its present shape with its various forms like the Alarippu, Jathiswaram, Sabdham, Varnam, Tillana etc. The descendants of these four brothers formed the original stock of Nattuvanars or dance teachers of Bharata Natyam in Tanjore. The dance forms can be big or small.
Essential ideas.
Bharata Natyam is considered to be a fire-dance — the mystic manifestation of the metaphysical element of fire in the human body. It is one of the five major styles (one for each element) that include Odissi (element of water), Kuchipudi (element of earth), Mohiniattam (element of air) and Kathakali (element of sky or aether). The movements of an authentic Bharata Natyam dancer resemble the movements of a dancing flame. Contemporary Bharata Natyam is rarely practiced as Natya Yoga, a sacred meditational tradition, except by a few orthodox schools (see Yoga and dance).
Bharata Natyam proper is a solo dance, with two aspects, lasya, the graceful feminine lines and movements, and tandava Ananda Thandavam (Tamil) (the dance of Shiva), masculine aspect.
In most solo performances, Bharata Natyam involves many split characters that are depicted by the dancer. The dancer will take on numerous characters by switching roles through the swift turn in circle and creates a story line that can be easily followed by the feat of one individual. The characters will be understood by the narrative of the song and the expression, or "abhinaya." 
However, in more modern times, Bharata Natyam performances have taken stage as group performances involving dramatical performances that require many characters depicted by various dancers. In addition, these dance performances include numerous transitions and formations that are creatively choreographed to enhance the movements along with the music.
Spiritual symbolism.
Bharata Natyam is the manifestation of the ancient idea of the celebration of the eternal universe through the celebration of the beauty of the material body. Some Bharata Natyam techniques can be traced back to the Kaisiki style. The Natya(I.44) reads, "... I have seen the Kaisiki style during the dance of the blue-throated lord (Shiva). It consists of elaborate gestures (Mridu Angaharas, movements of limbs), sentiments (Rasas), emotional states (Bhavas). Actions (Kriyas) are its soul. The costume should be charmingly beautiful and love (Sringara) is its foundation. It cannot be adequately portrayed by men. Except for women, none can practise it properly".
Apart from the Kaisikii style, Bharata Natyam imbibed some others. These reflect other yogis of spiritual revelations, such as the vision of two sages, Vyagrapada and Pathanjali in Chidambaram. In Hindu mythology the whole universe is the dance of the Supreme Dancer, Nataraja, a name for Lord Shiva, the Hindu ascetic yogi and divine purveyor of destruction of evil. The symbolism of the dance of Shiva (in the form of Nataraja) is represented by the attitude called "Ananda Tandavam". Also known as the cosmic dancer, he is here the embodiment and manifestation of the eternal energy in five activities ("panch-kriya"): creation, pouring forth, unfolding; maintenance or duration ("sthiti"); destruction or taking back ("smhara"); concealing, veiling, hiding the transcendental essence behind the garb of apparitions ("tirobhava"); and favoring, bestowing grace through a manifestation that accepts the devotee ("anugraha"). Shiva is depicted dancing on the dwarfish body of the demon "Apasmara purusa", "forgetfulness, loss of memory" called in Tamil "Muyalaka" (PRIT) -- who represents ignorance, the destruction of which brings enlightenment, true wisdom, and release from the bondage of existences.
Medieval decline.
Local kings often invited temple dancers (devadasis) to dance in their courts, the occurrence of which created a new category of dancers - rajanarthakis—and modified the technique and themes of the recitals. A devadasi had to satisfy her own soul while she danced unwatched and offered herself (surrendered) to the Lord, but the rajanarthaki's dance was meant to be an entertainment.
The Natya Shastra-based margi elements, such as karanas, that were meant to spiritually enlighten the spectators, were gradually replaced by desi karanas which were later replaced by adavus. The Bharata Natyam recitals and ballets started more and more popularly viewed as a form of desi entertainment.
The quartet of Chinnayya Pillai, Ponniah Pillai, Sivanandam Pillai and Vadivelu Pillai of the Tanjore Court, during the rule of Maratha King Saraboji II (1798–1832), made a rich contribution to music and Bharatanatyam and also completed the process of re-editing the Bharatanatyam programme into its present shape with its various items. The descendants of these four brothers formed the original stock of Nattuvanars or dance teachers of Bharatanatyam in Tanjore. Some of the well known Nattuvanars were Guru Meenakshisundaram Pillai, Guru Muthukumara Swami Pillai, Guru Ramaiah Pillai, Guru Kittappa Pillai, Guru Kubernath Tanjorkar, Guru Dandayudhapani Pillai and others. The fall of the Hindu kingdoms in the South marked the eventual decline of Natya, as the Muslim invasion in the North has completely wiped out Natya there. The sacred dance, one of the constituents of the Sodasa Upacharam, was replaced by rice offerings.
Modern rebirth.
E. Krishna Iyer was one of those who raised the social status of Bharata Natyam and greatly popularized it. Rukmini Devi Arundale was also instrumental in modifying mainly the Pandanallur style of Bharata Natyam and bringing it to the attention of the West. E. Krishna Iyer said about Rukmini Devi, "There is no need to say that before she entered the field, the art was dead and gone or that it saw a renaissance only when she started to dance or that she created anything new that was not there before". Rukmini Devi Arundale introduced group performances and staged various Bharata Natyam-based ballets. According to Shri Sankara Menon, Rukmini Devi raised Bharata Natyam to a puritan art form, by removing certain emotional elements evocative of the erotic, such as hip, neck, lip and chest movements) from the Pandanallur style. Not all love was portrayed, at least outside parameters considered "chaste". Balasaraswati said that "the effort to purify Bharata Natyam through the introduction of novel ideas is like putting a gloss on burnished gold or painting the lotus". Having studied Bharata Natyam for three years, in 1936 Rukmini Devi Arundale founded the school Kalakshetra outside the city of Madras to teach it and to promote other studies in Indian music and art. She was one of first teachers to instruct a few men to perform the dance. The dance, at that time, was exclusively performed by women, while men, called "Nattuvanars", had only been teaching Bharata Natyam without actually performing it. It is worth noticing that most of the contemporary Bharata Natyam dancers do not satisfy the criteria for a professional danseuse stated in the scriptures.
Dr. Padma Subrahmanyam, who was originally trained in the Vazhuvoor style of Bharata Natyam, was another figure that greatly influenced the development of Bharata Natyam. She started her research on karanas in early sixties, and later announced the creation of a new Bharata Natyam variety, Bharatanrityam, which was a Bharata Natyam-based reconstruction of Natya Shastra's technique. While the Pandanallur style, Tanjore or Thanjavur, Vazhuvoor, Mysore, Kancheepuram were based on the art of rajadasis and are exoteric in nature, some others, like the Melattur style and Balasaraswati's style grew out of the devadasis' distinctly different esoteric art.
The development of the Bharata Natyam dance form has therefore been surrounded by controversy as some including Ashish Khokar the Indian dance historian have seen it as a means by which many women, have appropriated certain Devadasi traditions while disassociating themselves with other aspects of the contemporary devadasis' practices.
At present, Bharata Natyam recitals are usually not performed inside the temple shrine but outside it, and even outside the temple compounds at various festivals. Most contemporary performances are given on the stage with a live ensemble. In popular culture, the adapted, or "semi-classical", Bharata Natyam has been exposed largely through depiction in popular movies and TV programs.
Learning Bharata Natyam normally takes many years before the arangetram (debut). There are academic and commercialized dance institutes in many countries. Many people choose to learn Carnatic music along with Bharata Natyam as they go together.
At present, not only Hindus but many Christians and Muslims also learn it, bringing it beyond the rigid forms of religious boundaries.
A paradigm shift was introduced in the field of Bharatnatyam when it got introduced in Maharashtra. Shri Kamleshji Maharaj was the pioneer in Maharashtra who introduced a new confluence of bharatnatyam and local dances like tamasha to create a new form called Tattumucchlum.
Bharata Natyam simplified.
There are 3 aspects to dance; Nritta, Nritya and Natya.
Nritta is a pure dance without any emotions, expressions or sahityam. 
Nritya has sahityam (a sentence which means something). It has emotions, expressions and has a meaning shown by the hastas. 
Natya is when a person is portraying a character. 
There are 4 types of abhinaya in dance. They are
Items.
Typically a performance includes: 
Apart from these items, there are items such as Shlokam, Swarajathi, Krithi etc. The performance concludes with the chanting of a few religious verses as a form of benediction. Certain styles include more advanced items, such as Tharanga Nritham and Suddha Nritham. When a dancer has mastered all the elements of dance, as a coming out performance, he or she generally performs an Arangetram (debut).
Ideal qualities of dancers.
A professional Bharata Natyam dancer must demonstrate a number of qualities. As Sangitaratnakara puts it, the true dance is connected to the beauty of the body, therefore any other dance is simply a parody (VII.1246).
The "Abhinaya Darpana", one of the two most authoritative texts on Bharata Natyam, has a sloka that describes Patra Prana Dasha Smrutaha — the ten essentials of the dancer: Javaha (agility), Sthirathvam (steadiness), Rekha (graceful lines), Bhramari (balance in pirouettes), Drishti (glance), Shramaha (hard work), Medha (intelligence), Shraddha (devotion), Vacho (good speech), and Geetam (singing ability).
A professional danseuse (patra), according to the "Abhinaya Darpana", must possess the following qualities: She has to be youthful, slender, beautiful, with large eyes, with well-rounded breasts, self-confident, witty, pleasing, well aware of when to dance and when to stop, able to follow the flow of songs and music, and to dance to the time (thalam), with splendid costumes, and of a happy disposition.
As Natya Shastra states, "narthaki" (female dancers), are required to be "Women who have beautiful limbs, are conversant with the sixty-four arts and crafts (Kalā), are clever, courteous in behaviour, free from female diseases, always bold, free from indolence, inured to hard work, capable of practising various arts and crafts, skilled in dancing and songs, who excel by their beauty, youthfulness, brilliance and other qualities all other women standing by."

</doc>
<doc id="56502" url="http://en.wikipedia.org/wiki?curid=56502" title="Rockland County, New York">
Rockland County, New York

Rockland County is a suburban county in the U.S. state of New York. The county's population, as of the 2010 census, was 311,687, increasing by 3.9% to a 2014 Census estimate of 323,866. The county seat is New City. The name derives from "rocky land", as the area was described by early Dutch and English settlers.
Rockland County is included in the New York-Newark-Jersey City, NY-NJ-PA Metropolitan Statistical Area. Located 15 mi northwest of Manhattan, Rockland County is the smallest county by area in New York State outside of New York City.
The county comprises five towns and nineteen incorporated villages, with numerous unincorporated villages (sixteen) and hamlets. Rockland County is designated as a Preserve America Community, and roughly one-third of the county is parkland. The county has the largest Jewish population per capita of any U.S. county, with 31.4%, or 90,000 residents, being Jewish. Rockland also ranks 9th on the list of highest-income counties by median household income in the United States with $75,306 according to the 2000 census.
History.
The area that would become Rockland County was originally inhabited by Algonquian-speaking Aboriginals, including Munsees, or Lenni Lenape.
In 1609, Henry Hudson, thinking he had found the legendary "Northwest Passage", sailed on the "Half Moon" up the river that would one day bear his name and anchored near the area that is now Haverstraw before continuing to disillusionment north of Albany. The Dutch were the first Europeans to settle in the area, around 1675. These settlers, eager to escape "city life", moved from Manhattan to Rockland. A number of unique Dutch-style red sandstone houses still stand, and many place names in the county reveal their Dutch origin. When the Duke of York (who became King James II of England) established the first twelve counties of New York in 1683, present-day Rockland County was part of Orange County. Orangetown was created at the same time under a royal grant, originally encompassing all of modern Rockland County. Around this time, as the English began to colonize Nyack and Tappan, the Native Americans began to leave Rockland in search of undisturbed land further north.
The natural barrier of the Ramapo Mountains and the size of the county made it difficult to carry out governmental activities. At one point there were twin governments, one on each side of the Ramapo Mountains. For this reason, Rockland split off from Orange in 1798 to form its own county. That same year the county seat was transferred from Tappan to New City, where a new courthouse was built.
Haverstraw was separated from Orangetown in 1719 and became a town in 1788; it included the present-day Clarkstown, Ramapo and Stony Point. Clarkstown and Ramapo became towns in 1791, followed by Stony Point in 1865.
During the American Revolution, when control of the Hudson River was viewed by the British as strategic to dominating the American territories, Rockland saw skirmishes at Haverstraw, Nyack and Piermont, and significant military engagements at the Battle of Stony Point, where General "Mad" Anthony Wayne earned his nickname. George Washington had headquarters for a time at John Suffern's tavern, the later site of the village of Suffern. British Major John André met with American traitor Benedict Arnold near Stony Point to buy the plans for the fortifications at West Point. André was captured with the plans in Tarrytown on his way back to the British lines; he was brought to Tappan for trial in the Tappan church, found guilty, hanged and buried nearby. Still another important chapter in the story of the Revolution was written on May 5, 1783, when General Washington received Sir Guy Carleton at the DeWint House, where they discussed the terms of the peace treaty. Two days later Washington visited Sir Guy aboard a British war vessel. On this day the King's Navy fired its first salute to the flag of the United States of America.
In the decades following the Revolution, Rockland became popular for its stone and bricks. These products, however, required quarrying in land that many later believed should be set aside as a preserve. Many unsuccessful efforts were made to turn much of the Hudson Highlands on the northern tip of the county into a forest preserve. However, Union Pacific Railroad president E. H. Harriman donated land as well as large sums of money for the purchase of properties in the area of Bear Mountain. Bear Mountain/Harriman State Park became a reality in 1910, and by 1914 it was estimated that more than a million people a year were coming to the park.
Rockland remained semi-rural until the 1950s when the Palisades Interstate Parkway, Tappan Zee Bridge, and other major arteries were built. The idea of suburbia also helped transform the county. The county's population flourished, from 89,276 in 1950 to 265,475 in 1990.
Geography.
According to the U.S. Census Bureau, the county has a total area of 199 sqmi, of which 174 sqmi is land and 26 sqmi (13%) is water. It is the smallest county in the state outside of New York City.
Rockland County lies just north of the New Jersey-New York border, west of Westchester County across the Hudson River, and south of Orange County.
The county's elevations range from 1283 ft atop Rockhouse Mountain to sea level along the Hudson River. Approximately 30% of Rockland County is devoted to parkland, belonging to either the five towns, incorporated villages, the state, or the county. These parks provide walking and hiking trails, ballfields, dog runs, historic sites, ponds, streams, salt marshes, and equestrian trails. Some popular state parks include Bear Mountain State Park on the northernmost tip of the county, Harriman State Park also along the county's northern boundary, and Nyack Beach State Park along the Hudson River, with trails connecting to Rockland Lake State Park. In addition to parks, Rockland is home to several of the most beautiful public and private golf courses in the metro area, with the towns of Orangetown, Ramapo, Stony Point, and Haverstraw all operating public golf courses within their towns, offering discounted rates to their respective residents. The Palisades Interstate Park Commission also operates two golf courses in Rockland Lake State Park with sweeping views of the park. Notable private courses in the county include Dellwood Country Club, Manhattan Woods Golf Course (designed by PGA great Gary Player), Minisceongo Golf Club (Ramapo), and Rockland Country Club (Sparkill).
Adjacent counties.
Rockland's borders with Putnam and Passaic counties are short, totaling less than one mile (1.6 km).
Demographics.
As of the census of 2000, there were 286,753 people, 92,675 households, and 70,989 families residing in the county. The population density was 1,646 people per square mile (636/km²). There were 94,973 housing units at an average density of 545 per square mile (210/km²). However, residents live closer together than the census numbers indicate, as 30% of the county is reserved as parkland. 9% of residents reported speaking Spanish at home, 5% Yiddish, 3% French-based creole, 1.5% Italian, 1.3% Tagalog, 1.3% Hebrew, 1.2% French, and 1% Russian. Other languages spoken at home by at least 1000 people include Malayalam, Korean, Chinese, German, and Polish.
In 2000, there were 92,675 households out of which 38% had children under the age of 18 living with them, 63% were married couples living together, 10% had a female householder with no husband present, and 23% were non-families. 19% of all households were made up of individuals and 8% had someone living alone who was 65 years of age or older. The average household size was 3 and the average family size was 3.5.
In the county the population was spread out with 28% under the age of 18, 8% from 18 to 24, 28% from 25 to 44, 24.30% from 45 to 64, and 12% who were 65 years of age or older. The median age was 36 years. For every 100 women there were 95 men. For every 100 women age 18 and over, there were 91 men.
The median income for a household in the county was $68,000 and the median income for a family was $80,000. Males had a median income of $58,000 versus $39,000 for females. The per capita income for the county was $28,000. The mean, or average, income for a family in Rockland County is $73,500 according to the 2004 census. About 6% of families and 10% of the population were below the poverty line, including 14% of those under age 18 and 8% of those age 65 or over.
Education.
The county is home to several Blue Ribbon School of Excellence Award winners, awarded by the U.S. Department of Education.
Colleges and universities.
The county is home to several colleges and universities, including Nyack College, St. Thomas Aquinas College, Rockland Community College, Long Island University, Dominican College, Columbia University's Lamont–Doherty Earth Observatory, and others.
Transportation.
The Tappan Zee Bridge connects South Nyack in Rockland County and Tarrytown in Westchester County across the Hudson River in the Lower Hudson Valley of New York State. Federal and state authorities are currently planning a $4 billion Tappan Zee replacement bridge.
Major highways.
The county is served by several major highways, including Interstate 87/287 (the New York Thruway), opening from Suffern to Yonkers in 1955. The Tappan Zee Bridge also opened the same year, finally connecting Rockland and Westchester, allowing the population in Rockland to grow rapidly over the next several decades. The Palisades Interstate Parkway, built by master planner Robert Moses between 1947 and 1958, connects the county directly to the George Washington Bridge due south. Another vital artery, the Garden State Parkway, opened in 1955, connecting New Jersey to I-87/287.
The highways in Rockland County are:
For further information
Bus.
The Transport of Rockland operates several local bus routes throughout the county, as well as an express bus route to Tarrytown and White Plains in Westchester County. TOR provides connections to other neighborhood bus operations – Minitrans and connections to commuter lines, Rockland Coaches and Short Line providing service to northern New Jersey and New York City.
Railroad.
New Jersey Transit/Metro-North Railroad operates the Port Jervis Line, which stops at the Suffern Railroad Station, and the Pascack Valley Line, whose stops include Pearl River, Nanuet and Spring Valley in their respective hamlets and village of the same name. Connections on this line are available at Secaucus for service to Penn Station in Midtown Manhattan and service to the Meadowlands Sports Complex in East Rutherford, New Jersey. The southern terminus of both lines is Hoboken Terminal, where connections can be made to several NJ Transit bus lines, ferries, and PATH trains to the city.
Ferry.
NY Waterway operates a ferry service between Haverstraw and Ossining in Westchester County for the Metropolitan Transportation Authority. Commuters are able to take the Transport of Rockland's Ferry Express route to the Haverstraw ferry terminal for service to Metro-North's Hudson Line service to Grand Central Terminal. Ferry service is typically suspended in the colder months when the Hudson freezes over, and commuters must take shuttle buses across the Tappan Zee Bridge.
Airports.
Nearby airports include:
Law, government and politics.
United States House of Representatives.
All of Rockland County falls within the 17th Congressional District, along with central and western Westchester County and is represented by Congresswoman Nita M. Lowey.
New York State politicians.
The county of Rockland is represented in the New York State Senate by David Carlucci (D) of the 38th district and William Larkin (R) of the 39th district.
County politicians.
The head of Rockland County is the county executive, Ed Day, a Republican elected in 2013. The previous county executive was Republican C. Scott Vanderhoef, who was re-elected in 2009 to his fifth four-year term. Day is the third county executive in Rockland history, with Vanderhoef having defeated the incumbent, John T. Grant (D), in 1993. Prior to 1985, Rockland County did not have a county executive.
The county is divided into 17 single-member . There are 12 Democrats and 5 Republicans. The Chairman of the Legislature is Alden H. Wolfe. The other legislators are:
Law enforcement.
The county is served by ten town and village police departments in addition to the county's Sheriff's Police Division. The ten town and village departments are responsible for incidents occurring in their respective municipalities, while the county sheriff responds to incidents countywide. The County Sheriff provides most of the specialized divisions: Marine, aviation, mounted, crime scene, bomb unit, arson, computer crimes as well as drug, arson and bomb K9 as per a memorandum of agreement between local departments.
Town governments.
The five towns of Rockland County are led by Town Supervisors and Town Boards. The villages encompassed in the towns are led by Mayors and Village Trustees.
County courts.
There are three types of general trial courts in Rockland County: the New York Supreme Court, the County Court and the Justice Courts. The Supreme Court is the trial level court of the New York State Unified Court System, which presents some confusion as the Supreme Court is the highest court of appeals in the federal system as well as in most states (the Court of Appeals is the highest court in New York State). The Supreme Court has broad authority over all categories of cases, both civil and criminal. Generally the Supreme Court in Rockland County hears civil cases involving claims in excess of $25,000. While the Supreme Court has jurisdiction over criminal cases in most counties this is handled by the County Courts. In Rockland however, the Supreme Court does exercise jurisdiction over some criminal cases.
The County Court is inferior to the Supreme Court and is authorized to hear all criminal cases that have occurred in the county as well as limited jurisdiction over civil cases. The County Court handles felony cases exclusively and shares jurisdiction with the town and village justice courts on misdemeanor cases and other minor offenses and violations. The County Court's jurisdiction on civil cases is limited to those involving less than $25,000.
Each of the towns and fifteen of the villages have Justice Courts. These courts mostly hear routine traffic ticket cases, especially from the New York State Thruway and the Palisades Interstate Parkway. They also handle drunk driving charges, lower-level criminal misdemeanor matters, and they will occasionally perform arraignment on felonies (most felony proceedings are heard in County Court). These courts generally handle the highest volume of cases, which, considering the population density and highways in the county, is not surprising.
Pollution.
According to Scorecard.org, which integrates data from different sources including the U.S. Environmental Protection Agency (EPA), in 2002, Rockland County ranked among the worst 10% in the United States in terms of air releases. Recent EPA statistics show that a total of 66 facilities active today in Rockland County are currently regulated. In Scorecard's list of Top 10 polluters from 2002, the Lovett generating station, located in Tompkins Cove, is the top polluter, releasing 1,523,339 pounds of toxic emissions into the air. Two studies, one in 2000 and the other in 2004, were issued by the Clean Air Task Force to study the impacts of power plant emissions in the United States. Data specific for Rockland county shows that a total of $2,150,800 was paid in compensation for numerous illnesses caused by power plant pollution, including asthma attacks, heart attacks and death. Prior to 2014 the Lovett generating station was closed and dismantled. It no longer exists.
Solar field.
Clarkstown is building a first-of-its-kind in New York State, a 2.3-megawatt solar system consisting of about 4,300 panels on top of a closed, highly regulated, flat shadeless 13-acre section of the former garbage landfill in West Nyack which will generate 3 million kilowatt-hours – enough power to supply about 200 homes, that will cover about one-third of the electric needs of the Town of Clarkstown government. The Clarkstown solar field project is at the maximum size that is currently allowed by New York State. 
Of the 1,200 installations in Orange and Rockland system, 450, or 32 percent, are in Rockland County and will save taxpayers as much as $4 million over 30 years by reducing the amount of the town’s annual electric bill – which is about $2 million and produce 10 percent of all the electricity that O&R gets through solar power. This project was scheduled to be on line by the fall of 2014.
Neighborhoods.
Paul W. Adler, the chairperson of the Rockland County's Jewish Community Relations Council, said in a 1997 "New York Times" article that "There are two reasons villages get formed in Rockland. One is to keep the Hasidim out and the other is to keep the Hasidim in."
There are five towns in Rockland County. The most populous is Ramapo, with 126,595 people, while the least populous is Stony Point, with 15,059 people, according to the 2010 US Census.
There are nineteen incorporated villages in Rockland County, twelve of which are located at least partially in the town of Ramapo, and none of which are in Stony Point. There are seventeen Census-designated places and seven Hamlets within the five towns of Rockland County.

</doc>
<doc id="56504" url="http://en.wikipedia.org/wiki?curid=56504" title="Monarchy of Canada">
Monarchy of Canada

The monarchy of Canada is the core of both Canada's federalism and its Westminster-style parliamentary democracy, being the foundation of the executive, legislative, and judicial branches of the federal and each provincial government. The current Canadian monarch, since 6 February 1952, is Queen Elizabeth II. As the sovereign, she is the personal embodiment of the Canadian Crown. Although the person of the sovereign is equally shared with 15 other independent countries within the Commonwealth of Nations, each country's monarchy is separate and legally distinct. As a result, the current monarch is officially titled "Queen of Canada" and, in this capacity, she, her consort, and other members of the Royal Family undertake public and private functions domestically and abroad as representatives of the Canadian state. However, the Queen is the only member of the Royal Family with any constitutional role. The Queen lives predominantly in the United Kingdom and, while several powers are the sovereign's alone, most of the royal governmental and ceremonial duties in Canada are carried out by the Queen's representative, the governor general. In each of Canada's provinces, the monarch is represented by a lieutenant governor, while the territories are not sovereign and thus do not have a viceroy.
Some of the powers of the Crown are exercisable by the monarch (such as appointing governors general), others by the governor general (such as calling parliamentary elections), and some others by either figure (such as giving or withholding Royal Assent to bills). Further, the royal sign-manual is required for letters patent and orders in council. But, the authority for these acts stems from the Canadian populace and, within the conventional stipulations of constitutional monarchy, the sovereign's direct participation in any of these areas of governance is limited, with most related powers entrusted for exercise (via advice or direction to the monarch or the viceroy) by the elected and appointed parliamentarians, the ministers of the Crown generally drawn from among them, and the judges and justices of the peace. The Crown today primarily functions as a guarantor of continuous and stable governance and a nonpartisan safeguard against the abuse of power, the sovereign acting as a custodian of the Crown's democratic powers and a representation of the "power of the people above government and political parties".
The historical roots of the Canadian monarchy date back to approximately the turn of the 16th century, when European kingdoms made the first claims to what is now Canadian territory. Monarchical governance thenceforth evolved under a continuous succession of French and British sovereigns and eventually the federal Canadian monarchy of today, which is sometimes colloquially referred to as the "Maple Crown".
International and domestic aspects.
The person who is the Canadian sovereign is equally shared with 15 other monarchies (a grouping, including Canada, known informally as the Commonwealth realms) in the 54-member Commonwealth of Nations, with the monarch residing predominantly in the oldest and most populous realm, the United Kingdom, and viceroys acting as the sovereign's representatives in Canada. The emergence of this arrangement paralleled the fruition of Canadian nationalism following the end of the First World War and culminated in the passage of the Statute of Westminster in 1931. Since then, the pan-national Crown has had both a shared and a separate character and the sovereign's role as monarch of Canada has been distinct to his or her position as monarch of any other realm, including the United Kingdom. Only Canadian federal ministers of the Crown may advise the sovereign on all matters of the Canadian state, of which the sovereign, when not in Canada, is kept abreast by weekly communications with the federal viceroy. The monarchy thus ceased to be an exclusively British institution and in Canada became a Canadian, or "domesticated", establishment, though it is still often denoted as "British" in both legal and common language, for reasons historical, political, and of convenience.
This division is illustrated in a number of ways: The sovereign, for example, holds a unique Canadian title and, when she and other members of the Royal Family are acting in public specifically as representatives of Canada, they will use, where possible, Canadian symbols, including the country's national flag, unique royal symbols, armed forces uniforms, and the like, as well as Canadian Forces aircraft or other Canadian-owned vehicles for travel. Once in Canadian airspace, or arrived at a Canadian event taking place abroad, the Canadian Secretary to the Queen, officers of the Royal Canadian Mounted Police, and other Canadian officials will take over from whichever of their other realms' counterparts were previously escorting the Queen or other member of the Royal Family.
The sovereign similarly only draws from Canadian coffers for support in the performance of her duties when in Canada or acting as Queen of Canada abroad; Canadians do not pay any money to the Queen or any other member of the Royal Family, either towards personal income or to support royal residences outside of Canada. Normally, tax dollars pay only for the costs associated with the governor general and ten lieutenant governors as instruments of the Queen's authority, including travel, security, residences, offices, ceremonies, and the like. In the absence of official reports on the full cost of the monarchy, the Monarchist League of Canada regularly issues a survey based on various federal and provincial budgets, expenditures, and estimates; the 2013 edition found that the institution cost roughly $57 million in 2012; $1.63 per Canadian.
Succession and regency.
Succession is by male-preference (agnatic) primogeniture governed by common law and the Act of Settlement, 1701; the Bill of Rights, 1689; Order in Council P.C. 3144 and the Succession to the Throne Act 1937; and the Royal Marriages Act, 1772. This legislation limits the succession to the non-adopted, legitimate descendants of Sophia of Hanover and stipulates that the monarch cannot be a Roman Catholic, nor married to one, and must be in communion with the Church of England upon ascending the throne; these particular clauses have prompted legal challenge.
Though Canada's adoption of the Statute of Westminster 1931 means these laws, as part of the constitution of Canada, lie within the full control of the Canadian parliament, it also means Canada agreed not to change its rules of succession without the unanimous consent of, and a parallel change of succession in, the other realms, unless explicitly leaving the shared monarchy relationship; a situation that applies symmetrically in all the other realms and has been likened to a treaty amongst these countries. However, there is no provision in Canadian law requiring that the King or Queen of Canada must be the same person as the King or Queen of the United Kingdom; if the UK were to breach the convention set out in the preamble to the Statute of Westminster and unilaterally change the line of succession to the British throne, the alteration would have no effect on the reigning sovereign of Canada or his or her heirs and successors. As such, the rules for succession are not fixed, but may be changed by a constitutional amendment. Along with the other Commonwealth realms, Canada in 2011 committed to the Perth Agreement, which proposed changes to the laws governing succession, including altering the primogeniture to absolute cognatic.
Upon a "demise of the Crown" (the death or abdication of a sovereign), the late sovereign's heir immediately and automatically succeeds, without any need for confirmation or further ceremony—hence arises the phrase "The King is dead. Long live the King." It is customary, though, for the accession of the new monarch to be publicly proclaimed by the governor general on behalf of the Queen's Privy Council for Canada, which meets at Rideau Hall after the accession. Following an appropriate period of mourning, the monarch is also crowned in the United Kingdom in an ancient ritual, but one not necessary for a sovereign to reign. By the Interpretation Act of 2005, no incumbent appointee of the Crown is affected by the death of the monarch, nor are they required to take the Oath of Allegiance again, and all references in legislation to previous monarchs, whether in the masculine (e.g. "His Majesty") or feminine (e.g. "the Queen"), continue to mean the reigning sovereign of Canada, regardless of his or her gender. After an individual ascends the throne, he or she typically continues to reign until death, being unable, by the tenets of constitutional monarchy, to abdicate unilaterally.
Canada has no laws allowing for a regency, should the sovereign be a minor or debilitated; none have been passed by the Canadian parliament and it was made clear by successive Cabinets since 1937 that the United Kingdom's Regency Act had no applicability to Canada, as the Canadian Cabinet had not requested otherwise when the act was passed that year and again in 1943 and 1953. As the 1947 Letters Patent issued by King George VI permit the Governor General of Canada to exercise almost all of the monarch's powers in respect of Canada, the viceroy is expected to continue to act as the personal representative of the monarch, and not any regent, even if the monarch is a child or incapacitated. It is unclear, however, how those duties that are the sole domain of the monarch would be carried out at such a time.
Federal and provincial aspects.
Canada's monarchy was established at Confederation, when its executive government and authority were declared (in section 9 of the Constitution Act, 1867) "to continue and be vested in the Queen." The Canadian monarchy is a federal one in which the Crown is unitary throughout all jurisdictions in the country, the sovereignty of the different administrations being passed on through the overreaching Crown itself as a part of the executive, legislative, and judicial operations in each of the federal and provincial spheres and the headship of state being a part of all equally. The Crown thus links the various governments into a federal state, though it is simultaneously also "divided" into eleven legal jurisdictions, or eleven "crowns"—one federal and ten provincial—with the monarch taking on a distinct legal persona in each. As such, the constitution instructs that any change to the position of the monarch or his or her representatives in Canada requires the consent of the Senate, the House of Commons, and the legislative assemblies of all the provinces.
The monarch is personally represented in each area by a viceroy who carries out the majority of the Queen's duties on her behalf: the Governor General of Canada in the federal sphere, appointed by the Queen on the advice of her federal prime minister, and a lieutenant governor in each province, appointed by the governor general on the advice of the federal prime minister, with input from the relevant provincial premier. The commissioners of Canada's territories are appointed by the federal Governor-in-Council, at the recommendation of the Minister of Indian Affairs and Northern Development; but, as the territories are not sovereign entities, the commissioners are not personal representatives of the sovereign. The Advisory Committee on Vice-Regal Appointments selects candidates for appointment as governor general, lieutenant governor, and commissioner.
Personification of the Canadian state.
"The Crown is an integral part of a practical form of government, and as such it has a direct and substantive part to play in the lives of all Canadians."
David E. Smith, "The Invisible Crown", 1995
As the living embodiment of the Crown, the sovereign is regarded as the personification of the Canadian state and, 
as such, must, along with his or her viceregal representatives, "remain strictly neutral in political terms". The body of the reigning sovereign thus holds two distinct personas in constant coexistence: that of a natural-born human being and that of the state as accorded to him or her through law; the Crown and the monarch are "conceptually divisible but legally indivisible ... [t]he office cannot exist without the office-holder", so, even in private, the monarch is always "on duty". The terms "the state", "the Crown", "The Crown in Right of Canada", "Her Majesty The Queen in Right of Canada" (French: "Sa Majesté la Reine du chef du Canada"), and similar are all synonymous and the monarch's legal personality is sometimes referred to simply as "Canada".
As such, the king or queen of Canada is the employer of all government officials and staff (including the viceroys, judges, members of the Canadian Forces, police officers, and parliamentarians), the guardian of foster children ("Crown wards"), as well as the owner of all state lands ("Crown land"), buildings and equipment ("Crown held property"), state owned companies ("Crown corporations"), and the copyright for all government publications ("Crown copyright"). This is all in his or her position as sovereign, and not as an individual; all such property is held by the Crown in perpetuity and cannot be sold by the sovereign without the proper advice and consent of his or her ministers.
The monarch is at the apex of the Canadian order of precedence and, as the embodiment of the state, is also the locus of oaths of allegiance, required of many of the aforementioned employees of the Crown, as well as by new citizens, as by the Oath of Citizenship. Allegiance is given in reciprocation to the sovereign's Coronation Oath, wherein he or she promises "to govern the Peoples of... Canada... according to their respective laws and customs".
Head of state.
Though it has been argued that the term "head of state" is a republican one inapplicable in a constitutional monarchy such as Canada, where the monarch is the embodiment of the state and thus cannot be head of it, the sovereign is regarded by official government sources, judges, constitutional scholars, and pollsters as the head of state, while the governor general and lieutenant governors are all only representatives of, and thus equally subordinate to, that figure. Some governors general, their staff, government publications, and constitutional scholars like Edward McWhinney and C. E. S. Franks have, however, referred to the position of governor general as that of Canada's head of state, though sometimes qualifying the assertion with "de facto" or "effective"; Franks has hence recommended that the governor general be named officially as the head of state. Since 1927, governors general have been received on state visits abroad as though they were heads of state.
Officials at Rideau Hall have pointed to the Letters Patent of 1947 as justification for describing the governor general as head of state, but others countered that the document makes no such distinction, either literally or implicitly, nor does it effect an abdication of the sovereign's powers in favour of the viceroy. Michael D. Jackson, former protocol officer for Saskatchewan, pointed out that Rideau Hall had been attempting to "recast" the governor general as head of state since the 1970s and that doing so preempted both the Queen and all of the lieutenant governors. This caused not only "precedence wars" at provincial events (where the governor general usurped the lieutenant governor's proper spot as most senior official in attendance) and the Governor General to accord herself precedence before the Queen at a national occasion, but also constitutional issues by "unbalancing [...] the federalist symmetry". This has been regarded as both a natural evolution and as a dishonest effort to alter the constitution without public scrutiny. Still others view the role of head of state as being shared by both the sovereign and her viceroys.
In a poll conducted by Ipsos-Reid following the first prorogation of the 40th parliament on 4 December 2008, it was found that 42% of the sample group thought the prime minister was head of state, while 33% felt it was the governor general. Only 24% named the Queen as head of state, a number up from 2002, when the results of an EKOS Research Associates survey showed only 5% of those polled knew the Queen was head of state (69% answered that it was the prime minister).
Federal constitutional role.
Canada's constitution is based on the Westminster parliamentary model, wherein the role of the Queen is both legal and practical, but not political. The sovereign is vested with all the powers of state, collectively known as the royal prerogative, leading the populace to be considered subjects of the Crown. However, as the sovereign's power stems from the people and the monarch is a constitutional one, he or she does not rule alone, as in an absolute monarchy. Instead, the Crown is regarded as a corporation sole, with the monarch being the centre of a construct in which the power of the whole is shared by multiple institutions of government—the executive, legislative, and judicial—acting under the sovereign's authority, which is entrusted for exercise by the politicians (the elected and appointed parliamentarians and the ministers of the Crown generally drawn from amongst them) and the judges and justices of the peace. The monarchy has thus been described as the underlying principle of Canada's institutional unity and the monarch as a "guardian of constitutional freedoms" whose "job is to ensure that the political process remains intact and is allowed to function."
The Crown is the pinnacle of the Canadian Forces, with the constitution placing the monarch in the position of commander-in-chief of the entire force, though the governor general carries out the duties attached to the position and also bears the title of "Commander-in-Chief in and over Canada". Further, included in Canada's constitution are the various treaties between the Crown and Canadian First Nations, Inuit, and Métis peoples, who view these documents as agreements directly and only between themselves and the reigning monarch, illustrating the relationship between sovereign and aboriginals.
Executive (Queen-in-Council).
The government of Canada—formally termed "Her Majesty's Government"—is defined by the constitution as the Queen acting on the advice of her Privy Council; what is technically known as the "Queen-in-Council", or sometimes the "Governor-in-Council", referring to the governor general as the Queen's stand-in. One of the main duties of the Crown is to "ensure that a democratically elected government is always in place," which means appointing a prime minister to thereafter head the Cabinet—a committee of the Privy Council charged with advising the Crown on the exercise of the royal prerogative. The Queen is informed by her viceroy of the swearing-in and resignation of prime ministers and other members of the ministry, remains fully briefed through regular communications from her Canadian ministers, and holds audience with them whenever possible. By convention, the content of these communications and meetings remains confidential so as to protect the impartiality of the monarch and her representative. The appropriateness and viability of this tradition in an age of social media has been questioned.
In the construct of constitutional monarchy and responsible government, the ministerial advice tendered is typically binding, meaning the monarch "reigns" but does not "rule", the Cabinet ruling "in trust" for the monarch. This has been the case in Canada since the Treaty of Paris ended the reign of the territory's last absolute monarch, King Louis XV. However, the royal prerogative belongs to the Crown and not to any of the ministers and the royal and viceroyal figures may unilaterally use these powers in exceptional constitutional crisis situations (an exercise of the reserve powers), thereby allowing the monarch to make sure "that the government conducts itself in compliance with the constitution." There are also a few duties which must be specifically performed by, or bills that require assent by, the Queen.
The royal prerogative also extends to foreign affairs, including the ratification of treaties, alliances, international agreements, and declarations of war, the accreditation of Canadian high commissioners and ambassadors and receipt of similar diplomats from foreign states, and the issuance of Canadian passports, which remain the sovereign's property.
Parliament (Queen-in-Parliament).
All laws in Canada are the monarch's and the sovereign is one of the three components of parliament—formally called the "Queen-in-Parliament"—but the monarch and viceroy do not participate in the legislative process save for the granting of Royal Assent, which is necessary for a bill to be enacted as law. Either figure or a delegate may perform this task and the constitution allows the viceroy the option of deferring assent to the sovereign. The governor general is further responsible for summoning the House of Commons, while either the viceroy or monarch can prorogue and dissolve the legislature, after which the governor general usually calls for a general election. The new parliamentary session is marked by either the monarch, governor general, or some other representative reading the Speech from the Throne. Despite this exclusion, members of the commons must still recite the Oath of Allegiance before they may take their seat. Further, the official opposition is traditionally dubbed as "Her Majesty's Loyal Opposition", illustrating that, while its members are opposed to the incumbent government, they remain loyal to the sovereign (as personification of the state and its authority).
The monarch does not have the prerogative to impose and collect new taxes without the authorization of an Act of Parliament. The consent of the Crown must, however, be obtained before either of the houses of parliament may even debate a bill affecting the sovereign's prerogatives or interests and no act of parliament binds the Queen or her rights unless the act states that it does.
Courts (Queen-on-the-Bench).
The sovereign is responsible for rendering justice for all her subjects, and is thus traditionally deemed the "fount of justice", her position in the Canadian courts formally dubbed the "Queen on the Bench". Though the monarch does not personally rule in judicial cases, this function of the royal prerogative instead performed in trust and in the Queen's name by officers of Her Majesty's court, common law holds the notion that the sovereign "can do no wrong": the monarch cannot be prosecuted in her own courts—judged by herself—for criminal offences. Civil lawsuits against the Crown in its public capacity (that is, lawsuits against the Queen-in-Council) are permitted, but lawsuits against the monarch personally are not cognizable. In international cases, as a sovereign and under established principles of international law, the Queen of Canada is not subject to suit in foreign courts without her express consent. The monarch, and by extension the governor general, also grants immunity from prosecution, exercises the "royal prerogative of mercy" and may pardon offences against the Crown, either before, during, or after a trial.
An image of the Queen and/or the Arms of Her Majesty in Right of Canada is always displayed in Canadian federal courtrooms. Itinerant judges will display an image of the Queen and the Canadian flag when holding a session away from established courtrooms; such situations occur in parts of Canada where the stakeholders in a given court case are too isolated geographically to be able to travel for regular proceedings.
Cultural role.
Royal presence and duties.
Members of the Royal Family have been present in Canada since the late 18th century, their reasons including participating in military manoeuvres, serving as the federal viceroy, or undertaking official royal tours. A prominent feature of the latter are numerous royal walkabouts, the tradition of which was initiated in 1939 by Queen Elizabeth when she was in Ottawa and broke from the royal party to speak directly to gathered veterans. Usually important milestones, anniversaries, or celebrations of Canadian culture will warrant the presence of the monarch, while other royals will be asked to participate in lesser occasions. A household to assist and tend to the monarch forms part of the royal party.
"Official duties" involve the sovereign representing the Canadian state at home or abroad, or her relations as members of the Royal Family participating in government organized ceremonies either in Canada or elsewhere; sometimes these individuals are employed in asserting Canada's sovereignty over its territories. The advice of the Canadian Cabinet is the impetus for royal participation in any Canadian event, though, at present, the Chief of Protocol and his staff in the Department of Canadian Heritage are, as part of the State Ceremonial and Canadian Symbols Program, responsible for orchestrating any official events in or for Canada that involve the Royal Family.
Conversely, "unofficial duties" are performed by Royal Family members on behalf of Canadian organizations of which they may be patrons, through their attendance at charity events, visiting with members of the Canadian Forces as colonel-in-chief, or marking certain key anniversaries. The invitation and expenses associated with these undertakings are usually borne by the associated organization. In 2005 members of the Royal Family were present at a total of 76 Canadian engagements, as well as several more through 2006 and 2007.
Apart from Canada, the Queen and other members of the Royal Family regularly perform public duties in the other fifteen nations of the Commonwealth in which the Queen is head of state. This situation, however, can mean the monarch and/or members of the Royal Family will be promoting one nation and not another; a situation that has been met with criticism.
Symbols, associations, and awards.
The main symbol of the monarchy is the sovereign herself, described as "the personal expression of the Crown in Canada," and her image is thus used to signify Canadian sovereignty and government authority—her effigy, for instance, appearing on currency, and her portrait in government buildings. The sovereign is further both mentioned in and the subject of songs, loyal toasts, and salutes. A royal cypher, appearing on buildings and official seals, or a crown, seen on provincial and national coats of arms, as well as police force and Canadian Forces regimental and maritime badges and rank insignia, is also used to illustrate the monarchy as the locus of authority, the latter without referring to any specific monarch.
Since the days of King Louis XIV, the monarch is the fount of all honours in Canada and new orders, decorations, and medals, which form "an integral element of the Crown," may only be created with the approval of the sovereign through letters patent. Hence, the insignia and medallions for these awards bear a crown, cypher, and/or effigy of the monarch. Similarly, the country's heraldic authority was created by the Queen and, operating under the authority of the governor general, grants new coats of arms, flags, and badges in Canada. Use of the royal crown in such symbols is a gift from the monarch showing royal support and/or association, and requires her approval before being added.
Members of the Royal Family also act as ceremonial colonels-in-chief of various military regiments, reflecting the Crown's relationship with the armed forces through participation in events both at home and abroad. The monarch also serves as the Commissioner-in-Chief, Prince Charles as Honorary Commissioner, and Prince Edward as Honorary Deputy Commissioner of the Royal Canadian Mounted Police.
A number of Canadian civilian organizations have association with the monarchy, either through their being founded via a royal charter, having been granted the right to use the prefix "royal" before their name, or because at least one member of the Royal Family serves as a patron. In addition to the The Prince's Charities Canada, established by Charles, Prince of Wales, some other charities and volunteer organizations have also been founded as gifts to, or in honour of, some of Canada's monarchs or members of the Royal Family, such as the Victorian Order of Nurses (a gift to Queen Victoria for her Diamond Jubilee in 1897), the Canadian Cancer Fund (set up in honour of King George V's Silver Jubilee in 1935), and the Queen Elizabeth II Fund to Aid in Research on the Diseases of Children. A number of awards in Canada are likewise issued in the name of previous or present members of the Royal Family. Further, organizations will give commemorative gifts to members of the Royal Family to mark a visit or other important occasion.
Royal family and house.
The Canadian Royal Family is a group of people related to the monarch of Canada and, as such, belonging to the House of Windsor. There is no strict legal or formal definition of who is or is not a member of the group, though the Department of Canadian Heritage maintains a list of immediate members and the Department of National Defence stipulates that those in the direct line of succession who bear the style of "Royal Highness" ("Altesse Royale") are subjects of, and owe their allegiance specifically to, the reigning king or queen of Canada.
The family members bear lineage from, among others, Arab, Armenian, Cuman, French, German, Hungarian, Italian, Mongolian, Portuguese, and Serbian ethnicities. Moreover, they are distant relations of the Belgian, Danish, Greek, Norwegian, Spanish, and Swedish royal families and, given the shared nature of the Canadian monarch, most are also of members of the British Royal Family. However, because Canada and the UK are independent of one another, it is incorrect to refer in the Canadian context to the family of the monarch as the "British Royal Family"—as is frequently done by Canadian and other media—and there exist some differences between the official lists of each. Further, in addition to the five Canadian citizens in the Royal Family, the sovereign and those among her relations who do not meet the requirements of Canadian citizenship law are considered Canadian, which entitles them to Canadian consular assistance and the protection of the Queen's armed forces of Canada when they are in need of protection or aid outside of the Commonwealth realms, as well as to substantive appointment to Canadian orders or receipt of Canadian decorations. Beyond legalities, members of the Royal Family have, on occasion, been said by the media and non-governmental organisations to be Canadian, have declared themselves to be Canadian, and some past members have lived in Canada for extended periods as viceroy or for other reasons.
Unlike in the United Kingdom, the monarch is the only member of the Royal Family with a title established through Canadian law. It would be possible for others to be granted distinctly Canadian titles (as is the case for the Duke of Rothesay (Prince Charles) in Scotland), but they have always been, and continue to only be, accorded the use of a courtesy title in Canada, which is that which they have been granted via letters patent in the UK, though they are also in Canada translated to French.
According to the Canadian Royal Heritage Trust, Prince Edward Augustus, Duke of Kent and Strathearn—due to his having lived in Canada between 1791 and 1800, and fathering Queen Victoria—is the "ancestor of the modern Canadian Royal Family." Nonetheless, the concept of the Canadian Royal Family did not emerge until after the passage of the Statute of Westminster in 1931, when Canadian officials only began to overtly consider putting the principles of Canada's new status as an independent kingdom into effect. At first, the monarch was the only member of the Royal Family to carry out public ceremonial duties solely on the advice of Canadian ministers; King Edward VIII became the first to do so when in July 1936 he dedicated the Canadian National Vimy Memorial in France. Over the decades, however, the monarch's children, grandchildren, cousins, and their respective spouses began to also perform functions at the direction of the Canadian Crown-in-Council, representing the monarch within Canada or abroad. But, it was not until October 2002 when the term "Canadian Royal Family" was first used publicly and officially by one of its members: in a speech to the Nunavut legislature at its opening, Queen Elizabeth II stated: "I am proud to be the first member of the Canadian Royal Family to be greeted in Canada's newest territory." Princess Anne used it again when speaking at Rideau Hall in 2014. By 2011, both Canadian and British media were referring to "Canada's royal family" or the "Canadian royal family".
The press frequently follows the movements of the Royal Family, and can, at times, affect the group's popularity, which has fluctuated over the years. Mirroring the mood in the United Kingdom, the family's lowest approval was during the mid-1980s to 1990s, when the children of the monarch were enduring their divorces and were the targets of negative tabloid reporting.
Federal residences and royal household.
A number of buildings across Canada are reserved by the Crown for the use of the monarch and her viceroys. The sovereign's principal official residence, as well as that primarily used by the governor general, is Rideau Hall, located in Ottawa, Ontario. A secondary residence is the Citadelle, in Quebec City. Each of these royal seats holds pieces from the Crown Collection. Further, though neither was ever used for their intended purpose, Hatley Castle in British Columbia was purchased in 1940 by King George VI in Right of Canada to use as his home during the course of World War II, and the Emergency Government Headquarters, built in 1959 at CFS Carp and decommissioned in 1994, included a residential apartment for the sovereign or governor general in the case of a nuclear attack on Ottawa.
Monarchs and members of their family have also owned in a private capacity homes and land in Canada: King Edward VIII owned Bedingfield Ranch, near Pekisko, Alberta; the Marquess of Lorne and Princess Louise owned a cottage on the Cascapédia River in Quebec; and Princess Margaret owned Portland Island between its gifting to her by the Crown in Right of British Columbia in 1958 and her death in 2002, though she offered it back to the Crown on permanent loan in 1966 and the island and surrounding waters eventually became Princess Margaret Marine Park.
To assist the Queen in carrying out her official duties on behalf of Canada, she appoints various people to her Canadian household. Along with the Canadian Secretary to the Queen, the monarch's entourage includes two ladies-in-waiting, the Canadian Equerry-in-Waiting to the Queen, the Queen's Police Officer, the Duke of Edinburgh's Police Officer, the Queen's Honorary Physician, the Queen's Honorary Dental Surgeon, and the Queen's Honorary Nursing Officer—the latter three being drawn from the Canadian Forces. Prince Edward, Earl of Wessex, also has a Canadian private secretary and his wife, Sophie, Countess of Wessex, a lady-in-waiting. Air transportation for the Royal Family is provided by the Royal Canadian Air Force 412 Transport Squadron.
There are three household regiments specifically attached to the Royal Household—the Governor General's Foot Guards, the Governor General's Horse Guards, and the Canadian Grenadier Guards. There are also two chapels royal in Ontario. Though not officially a royal chapel, St. Bartholomew's Anglican Church, located across MacKay Street from Rideau Hall, is regularly used by governors general and their families and sometimes by the sovereign and other members of the Royal Family, as well as by viceregal household staff, their families, and members of the Governor General's Foot Guards, for whom the church also serves as a regimental chapel.
History.
The Canadian monarchy can trace its ancestral lineage back to the kings of the Angles and the early Scottish kings, through centuries since parts of the territories that today comprise Canada were claimed by King Henry VII in 1497 and others by King Francis I in 1534; both being blood relatives of the current Canadian monarch. Prime Minister Stephen Harper said of the Crown that it "links us all together with the majestic past that takes us back to the Tudors, the Plantagenets, the Magna Carta, "habeas corpus", petition of rights, and English common law." Though the first French and British colonizers of Canada interpreted the hereditary nature of some indigenous North American chieftainships as a form of monarchy, it is generally accepted that Canada has been a territory of a monarch or a monarchy in its own right only since the establishment of New France in the early 17th century; according to historian Jacques Monet, the Canadian Crown is one of the few that have survived through uninterrupted succession since before its inception.
After the Canadian colonies of France were, via war and treaties, ceded to the British Crown, and the population was greatly expanded by those loyal to George III fleeing north from persecution during and following the American Revolution, British North America was in 1867 confederated by Queen Victoria to form Canada as a kingdom in its own right. By the end of the First World War, the increased fortitude of Canadian nationalism inspired the country's leaders to push for greater independence from the King in his British Council, resulting in the creation of the uniquely Canadian monarchy through the Statute of Westminster, which was granted Royal Assent in 1931. Only five years later, Canada had three successive kings in the space of one year, with the death of George V, the accession and abdication of Edward VIII, and his replacement by George VI.
The latter became in 1939 the first reigning monarch of Canada to tour the country (though previous kings had done so before their accession). As the ease of travel increased, visits by the sovereign and other Royal Family members became more frequent and involved, seeing Queen Elizabeth II officiate at various moments of importance in the nation's history, one being when she proclaimed the country to be fully independent, via constitutional patriation, in 1982. That act is said to have entrenched the monarchy in Canada, due to the stringent requirements, as laid out in the amending formula, that must be met in order to alter the monarchy in any way.
Through the 1960s and 1970s, the rise of Quebec nationalism and changes in Canadian identity created an atmosphere where the purpose and role of the monarchy came into question. Some references to the monarch and the monarchy were removed from the public eye and moves were made by the federal government to constitutionally alter the Crown's place and role in Canada, first by explicit legal amendments and later by subtle attrition impelled by elements of the public service, the Cabinet, and governors general and their staff alike. But, provincial and federal ministers, along with loyal national citizen's organizations, ensured that the system remained the same in essence. By 2002, the royal tour and associated fêtes for the Queen's Golden Jubilee proved popular with Canadians across the country, though Canada's first republican organization since the 1830s was also founded that year. Celebrations took place to mark Queen Elizabeth II's Diamond Jubilee in 2012, the first such event in Canada since 1897, when Victoria marked her 60th year on the throne.
Public understanding.
Commentators have in the late 20th and early 21st centuries stated that contemporary Canadians had and have a poor understanding of the Canadian monarchy, Michael D. Jackson saying in his book "The Crown and Canadian Federalism" that this is part of a wider ignorance about Canadian civics. Former Governor General Adrienne Clarkson said there is "an abysmal lack of knowledge about the system" and Senator Lowell Murray wrote in 2003: "The Crown has become irrelevant to most Canadian's understanding of our system of Government," which he attributed to the "fault of successive generations of politicians, of an educational system that has never given the institution due study, and of past vice-regal incumbents themselves." These comments were echoed by teacher and author Nathan Tidridge, who asserted in his 2011 book, "Canada's Constitutional Monarchy: An Introduction to Our Form of Government", that, beginning in the 1960s, the role of the Crown disappeared from provincial education curricula, as the general subject of civics came to receive less attention. He said Canadians are being "educated to be illiterate, ambivalent, or even hostile toward our constitutional monarchy." Michael Valpy also pointed to the fact that "The crown's role in the machinery of Canada's constitutional monarchy rarely sees daylight. Only a handful of times in our history has it been subjected to glaring sunshine, unfortunately resulting in a black hole of public understanding as to how it works."
The position of prime minister has simultaneously undergone what has been described as a "presidentialisation", to the point that its incumbents publicly outshine the actual head of state. David S. Donovan felt that Canadians mostly considered the monarch and her representatives as purely ceremonial and symbolic figures. It was argued by Alfred Neitsch that this undermined the Crown's legitimacy as a check and balance in the governmental system.
Debate.
To date, outside of academic circles, there has been little national debate on the Canadian monarchy, a subject about which most Canadians are generally unaware. Out of Canada's three most prominent political parties, neither the Liberal Party nor the Conservative Party is officially in favour of abolishing the monarchy (though the latter makes support for constitutional monarchy a founding principle in its policy declaration) and the New Democratic Party (NDP) has no official position on the role of the Crown. Only some Members of Parliament belonging to these parties and the leaders of the Bloc Québécois have made any statements suggesting abolition of the monarchy. Canada has two special-interest groups representing the debate, who frequently argue the issue in the media: the Monarchist League of Canada and Citizens for a Canadian Republic. There are also other organizations that support and advocate the monarchy, such as the United Empire Loyalists' Association of Canada, the Canadian Royal Heritage Trust, the Orange Order in Canada, and the Friends of the Canadian Crown.
The idea of a uniquely Canadian monarch, either one descended from the present queen or coming from a First Nations royal house, has been proffered as an alternative. However, there has been no popular or official support for such a change.
References.
</dl>

</doc>
<doc id="56505" url="http://en.wikipedia.org/wiki?curid=56505" title="Schoharie County, New York">
Schoharie County, New York

Schoharie County is a county located in the U.S. state of New York. As of the 2010 census, the population was 32,749, making it the fifth-least populous county in New York. The county seat is Schoharie. The name of the county and the county seat come from a Mohawk word meaning "floating driftwood."
Schoharie County is part of the Albany-Schenectady-Troy, NY Metropolitan Statistical Area.
History.
The large territory of the county (much of upstate and western New York) was long occupied by the Mohawk Indians and, to the west, other four tribes of the Iroquois League (increased to six with the migration of the Tuscarora from the South to New York in 1722). After European colonization of the Northeast started, the Mohawk had a lucrative fur trade with the French coming down from Canada, as well as the early Dutch colonists, and later British and German colonists.
Some Palatine Germans, who worked in camps on the Hudson to pay off their passage in 1710, later settled in this county in the 1720s and 30s. In addition, Scots-Irish immigrants settled in the present Schoharie County area before the American Revolutionary War, especially near Cherry Creek.
Political organization.
After Great Britain defeated the Dutch and took over their colony in 1664, they began to establish counties in the New York territory in 1683. The present Schoharie County was first part of Albany County. This was an enormous county, including the northern part of New York State as well as all of the present State of Vermont. In theory, it extended westward to the Pacific Ocean, as the colonists wanted to keep their options open. This county was reduced in size on July 3, 1766 by the creation of Cumberland County, and further on March 16, 1770 by the creation of Gloucester County, both containing territory now part of Vermont.
On March 12, 1772, what was left of Albany County was split into three parts, one remaining under the name Albany County. Tryon County was formed from the western portion of the territory (and thus, since no western boundary was specified, theoretically still extended west to the Pacific). The eastern boundary of Tryon County was approximately five miles west of the present city of Schenectady, and the county included the western part of the Adirondack Mountains and the area west of the West Branch of the Delaware River. The area then designated as Tryon County was eventually organized into what are now 37 counties of New York State. The county was named for William Tryon, colonial governor of New York.
In the years prior to 1776, as social and political tensions rose in the colony, most of the Loyalists in Tryon County, then on the frontier, fled to Canada. In 1784, following the peace treaty that ended the Revolutionary War and establishment of states, the new government changed the name of Tryon County. They renamed it as Montgomery County to honor United States General Richard Montgomery, who had captured several places in Canada and died trying to capture the city of Quebec.
The state continued to organize new counties. In 1789, Montgomery County was reduced in size by the splitting off of Ontario County. It was originally much larger than the present county, including present-day Allegany, Cattaraugus, Chautauqua, Erie, Genesee, Livingston, Monroe, Niagara, Orleans, Steuben, Wyoming, Yates, and part of Schuyler and Wayne counties.
In 1791, Otsego County was one of three counties split off from Montgomery (the other two being Herkimer and Tioga County).
In 1795, Schoharie County was created by joining portions of Otsego and Albany counties.
Revolutionary War.
This was an area of fighting during the American Revolutionary War. On the frontier, colonists were subject to raids by British and their Iroquois allies. Four of the six tribes allied with the British, hoping to repel the colonists from their territory.
Geography.
According to the U.S. Census Bureau, the county has a total area of 626 sqmi, of which 622 sqmi is land and 4.5 sqmi (0.7%) is water.
Schoharie County is in central New York State, west of Albany and southeast of Utica.
Much of the southern portion of the county lies within the Catskill Mountains. Land rises in both directions quite rapidly from Schoharie Creek in the middle of the county. In contrast, the northern part of the county is predominately small hills and valleys. More than 75% of the county's population lives in the north, closer to the Mohawk River, the historic transportation route east and west through the state. Schoharie Creek is a northward-flowing tributary of the Mohawk River. The Schoharie Creek watershed spans an area of approximately 950 sqmi. The course of Schoharie Creek includes two reservoir-dam systems.
The Gilboa Dam and the Schoharie Reservoir are part of the New York City Water Supply System. The New York Power Authority operates the Blenheim-Gilboa Dam and its reservoir to produce hydroelectric power. The headwaters of the Delaware River is located in the Town of Jefferson. Despite its proximity to Albany, the county has remained relatively rural.
The highest point is found at the summit of Huntersfield Mountain on the southern boundary with Greene County, at 3,423 feet (1,043 m) above sea level. The lowest point is where the Montgomery County line meets Schoharie Creek, 520 feet (158 m) above sea level. The most prominent geological feature is Vroman's Nose, near the village of Middleburgh, New York in the Town of Fulton.
Demographics.
As of the census of 2000, there were 31,582 people, 11,991 households and 8,177 families residing in the county. The population density was 51 people per square mile (20/km²). There were 15,915 housing units at an average density of 26 per square mile (10/km²). The racial makeup of the county was 95.06% White, 2.14% Black or African American, 0.30% Native American, 0.49% Asian, 0.02% Pacific Islander, 0.36% from other races, and 0.93% from two or more races. 1.86% of the population were Hispanic or Latino of any race. 20.9% were of German, 15.6% Irish, 11.5% American, 10.8% Italian and 9.7% English ancestry according to Census 2000. 95.5% spoke English, 1.7% Spanish and 1.0% German as their first language.
There were 11,991 households out of which 31.20% had children under the age of 18 living with them, 54.20% were married couples living together, 9.30% had a female householder with no husband present, and 31.80% were non-families. 25.80% of all households were made up of individuals and 11.70% had someone living alone who was 65 years of age or older. The average household size was 2.49 and the average family size was 2.98.
In the county the population was spread out with 24.00% under the age of 18, 10.60% from 18 to 24, 26.20% from 25 to 44, 24.40% from 45 to 64, and 14.90% who were 65 years of age or older. The median age was 38 years. For every 100 females there were 99.00 males. For every 100 females age 18 and over, there were 97.80 males.
The median income for a household in the county was $36,585, and the median income for a family was $43,118. Males had a median income of $31,725 versus $24,475 for females. The per capita income for the county was $17,778. About 7.90% of families and 11.40% of the population were below the poverty line, including 13.70% of those under age 18 and 8.60% of those age 65 or over.
Economy.
The primary industry of Schoharie County is agriculture. Farms are situated all over the county, and farm stands featuring local produce are operated in the Schoharie Valley. Many people also work in the capital region, which is within commuting distance.
Wal-Mart has a distribution center located in the Village of Sharon Springs, and a supercenter in Cobleskill.
The Catskills-area villages have a number of historic hotels, as it was a vacation destination in the early 20th century. Some buildings have been restored, and some people come to the area for second or summer homes.
A small but growing tourist industry attracts visitors for recreation, the landscape and historic destinations. Visitors come to visit Howe Caverns, Secret Caverns, the Carrot Barn, the Apple Barrel Country Store and Cafe, Vroman's Nose, the Old Stone Fort, and the Iroquois Indian Museum. The Old Blenheim Bridge was among the attractions, but it was destroyed by Hurricane Irene in August 2011.
Notable sites.
A prominent site in the county is the Old Stone Fort, used for defense against British and allied Indian attacks during the Revolution. It was later used as an armory during the Civil War.
During the nineteenth century, the Middleburgh-Schoharie Railroad was constructed through the county.
In 1981 the Iroquois Indian Museum opened in a new building near Howe Caverns in the town of Cobleskill, New York. It has the largest collection of Iroquois art in the United States. The museum includes a performance center, where Iroquois present traditional and contemporary music and dance.

</doc>
<doc id="56506" url="http://en.wikipedia.org/wiki?curid=56506" title="Saratoga County, New York">
Saratoga County, New York

Saratoga County is a county located in the U.S. state of New York. As of the 2014 U.S. Census estimate, the county's population was 224,921, representing a 2.4% increase from the 2010 population of 219,607, one of the fastest growth rates in the northeastern United States. The county seat is Ballston Spa. Saratoga County is included in the Albany-Schenectady-Troy, New York Metropolitan Statistical Area.
The name of Saratoga County was derived from the Native American word "sah-rah-ka", or "Sarach-togue", meaning "the hill beside the river", referring to the Hudson River bordering the county on its eastern flank and the Mohawk River delineating its southern border. Saratoga County, bisected by the toll-free, six-lane Adirondack Northway, serves as an outdoor recreational haven and as the gateway to the Adirondack Mountains and State Park for the populations of the Albany and New York City metropolitan areas. The county is also home to the internationally renowned Saratoga Race Course, one of the oldest venues in horse racing.
Saratoga County lies at the heart of eastern New York State's Tech Valley, a growing center for nanotechnology, semiconductor manufacturing, and other high technology research and development, manufacturing, and venture capital investment. The "Fab 8" campus of GlobalFoundries, a company specializing in the semiconductor industry, is a multibillion-dollar venture being developed in Saratoga County.
History.
When counties were established in the Province of New York in 1683, the present Saratoga County was part of Albany County. This was an enormous county, including the northern part of New York State as well as all of the present State of Vermont and, in theory, extending westward to the Pacific Ocean. This large county was progressively reduced in size by the separation of several counties until 1791, when Saratoga County as well as Rensselaer County were split off from Albany County. The Battles of Saratoga (September 19 and October 7, 1777) marked the climax of the Saratoga campaign, giving a decisive victory to the Americans over the British in the American Revolutionary War.
During the nineteenth century, Saratoga County was an important industrial center. Its location 30 miles north of Albany on the Delaware and Hudson Railway, as well as its proximity to water power from the Hudson River and the Kayaderosseras Creek, led to rapid industrial development beginning in the early nineteenth century. Some of the most important industrial employers were paper mills, tanneries, foundries, and textile mills.
Since the construction of the Adirondack Northway in the 1960s, Saratoga County has consistently been the fastest-growing county in the Capital District and indeed, in Upstate New York, and one of the fastest-growing in the U.S. Northeast. The county has historically maintained a low county tax rate; according to its official website, Saratoga County levies one of the lowest county tax rates in New York State.
Geography.
Saratoga County is situated in the northeastern part of New York State, north of Albany, northwest of Troy, and east of Utica. According to the U.S. Census Bureau, the county has a total area of 844 sqmi, of which 810 sqmi is land and 34 sqmi (4.0%) is water. The Hudson River forms the eastern border of the county, while the Mohawk River demarcates its southern border. The highest elevation in Saratoga County is at the peak of Hadley Mountain in the Adirondack Mountains, at 2,675 feet (815 meters), while the lowest elevation is 69 feet (21 meters), at the waterfront of the Village of Waterford, at the confluence of the Mohawk and Hudson rivers.
Demographics.
In 1960, Saratoga County had a population of only 89,000, less than half of its population in 2014, estimated at 224,921. 
2010 Census.
As of the 2010 United States Census, there were 219,607 people, 88,296 households, and 58,814 families residing in Saratoga County. The population density was 271 people per square mile (105/km²). There were 98,656 housing units at an average density of 122 per square mile (41/km²). The racial makeup of the county was 94.3% White, 1.8% Asian, 1.5% Black or African American, 0.2% Native American, 0.0% Pacific Islander, 0.5% from other races, and 1.7% from two or more races. 2.4% of the population were Hispanic or Latino of any race.
There were 88,296 households out of which 29.5% had children under the age of 18 living with them, 53.3% were married couples living together, 9.1% had a female householder with no husband present, and 33.4% were non-families. 26.1% of all households were made up of individuals, 31.5% of households had individuals under 18 years, and 9.5% had someone living alone who was 65 years of age or older. The average household size was 2.44 and the average family size was 2.96.
Of Saratoga County's population in 2010, 6.3% were between ages of 5 and 9 years, 6.7% between 10 and 14 years, 6.5% between 15 and 19 years, 5.5% between 20 and 24 years, 5.5% between 25 and 29 years, 5.8% between 30 and 34 years, 6.6% between 35 and 39 years, 7.9% between 40 and 44 years, 8.5% between 45 and 49 years, 8.0% between 50 and 54 years, 7.0% between 55 and 59 years, 6.4% between 60 and 64 years, and 13.7% of age 65 years and over. 22.7% of the county's population was under age 18. The median age was 40.9 years.
According to the 2009-2013 American Community Survey, the median income for a household in Saratoga County was $69,826, and the median income for a family was $87,058. Males had a median income of $59,636 versus $44,743 for females. The per capita income for the county was $35,176. About 4.0% of families and 6.5% of the population were below the poverty line, including 7.4% of those under age 18 and 6.1% of those age 65 or over.
Transportation.
Adirondack Northway.
The toll-free, six-lane Adirondack Northway bisects Saratoga County, running in a south-north direction. This highway, designated Interstate 87, is the primary conduit connecting the capital of New York State, Albany, northward across the Thaddeus Kosciusko Bridge into and through Saratoga County, then past Lake George in the Adirondack Park, through the Adirondack Mountains, and eventually to the Canada-United States border, where it continues seamlessly as Quebec Autoroute 15 to Montreal. This freeway has been a major catalyst for the growth of population and commerce in Saratoga County.
Rail.
The Saratoga and North Creek Railway is a heritage railway that began operation in July 2011 and currently operates between the Saratoga Springs Amtrak station at its southern terminus and North Creek in the Adirondack Park at its northern terminus, where it connects with Amtrak's "Ethan Allen Express" and "Adirondack" services. Its commercial operations were originally built by the Adirondack Railway.
Airports.
The following public-use airports are located in Saratoga County:
Recreation.
Saratoga County is extremely popular between late July and early September each year due to the Saratoga Race Course being open. This world-famous track dates back to 1863. Thoroughbred horse racing in the United States has its own Hall of Fame in Saratoga Springs, which honors remarkable horses, jockeys, owners, and trainers. Horse-racing fans come from all over to watch the races. 
The Saratoga National Historical Park is located along the Hudson River in Stillwater, and features a drive-around trail where one can drive up to each station. The park is also famous for its outstanding views of the area's natural scenery and Vermont's Green Mountains in the distance.
The Saratoga Spa State Park capitalizes on the culture and the mineral springs that once drove Saratoga County. This is a large state park and includes a hotel, 2 pool complexes, mineral baths, Saratoga Performing Arts Center, picnic areas, hiking trails, and numerous mineral springs.
Saratoga County serves as the southern gateway to the Adirondack Park, the largest park in the contiguous United States, covering approximately 6.1 e6acre, a land area roughly the size of Vermont and greater than the areas of the National Parks of Yellowstone, Grand Canyon, Glacier, and Great Smoky Mountains combined. A portion of northwestern Saratoga County lies within the boundaries of the Adirondack Park and includes Hadley Mountain.
Government.
Saratoga County is governed by a Board Of Supervisors, with each town Supervisor acting as the representative from that community. The City of Saratoga Springs elects two Supervisors and the City of Mechanicville elects one supervisor to sit on the Board of Supervisors, but have no power on their respective city. The Town of Clifton Park also elects two Supervisors, one being the elected Town Supervisor, and one having only County duties. Voting is by weighted vote of each of the communities based on population, which is the reason why Saratoga Springs and Clifton Park, the two largest communities in Saratoga County, elect two Supervisors. The political makeup of the 2012-2013 Board consists of nineteen Republicans, three Democrats, and one Independence Party member. Republicans hold the county-wide offices of Sheriff, District Attorney, County Clerk, Treasurer, and Judges of the County, Family, and the Surrogate Courts.
Saratoga County has been a Republican-leaning county in most major elections. George W. Bush won the county narrowly in 2004 with 53% of the vote, while Barack Obama slightly edged out John McCain in 2008, receiving 51% of the vote countywide becoming the first Democrat to win Saratoga County since 1996. The majority of the county is represented in the U.S. Congress by Republican Chris Gibson, with the exception being the town of Waterford, which is represented by Democrat Paul Tonko.
In the State Senate, the county is divided between Republicans Roy McDonald and Hugh Farley, while in the State Assembly Democrats Ronald Canestrari and Robert Reilly, along with Republicans James Tedisco, Teresa Sayward, and Tony Jordan each represent portions of the county.
James A. Murphy III, a Republican, is the County Court Judge and a former District Attorney.
Sheriff James A. Bowen is the dean of NYS Sheriffs, having served as Sheriff since 1972, when he was appointed by Governor Nelson A. Rockefeller. Bowen won election in own right in 1973, and his been elected every four years since winning his tenth four year term in the 2009 General Election
Democratic strength is best shown in the City of Saratoga Springs, which has voted Democratic in every presidential election since 1988. Republican strength is concentrated in the western part of the county, which is mostly rural or exurban. In 2005, the Democrats gained a majority on the Saratoga Springs City Council after decades of Republican dominance. The Republicans, however, reclaimed the council majority in the 2007 General Elections due to a split Democratic Party in the mayor's race. In 2009, the Republicans reclaimed their supermajority (4-1) on the City Council, by winning every contested election (Mayor, Finance, Public Safety, and Public Works). In 2011, Democrats reclaimed the Majority on the City Council, while Republican Scott Johnson was reelected as Mayor. At the Saratoga County Board of Supervisors, the City is split, with one Republican and one Democrat holding the two Supervisor seats.

</doc>
<doc id="56507" url="http://en.wikipedia.org/wiki?curid=56507" title="Marlinespike hitch">
Marlinespike hitch

The marlinespike hitch is a temporary knot used to attach a rod to a rope in order to form a handle. This allows more tension than could be produced comfortably by gripping the rope with the hands alone. It is useful when tightening knots and for other purposes in ropework. 
As the name suggests, the type of rod traditionally used with this hitch is a marlinespike. The advantages of this hitch over others which might serve the purpose are its quickness of tying and ease of releasing. Topologically it is a form of the noose, but in practice this hitch is not allowed to collapse into that shape. When it does capsize into a traditional noose it can jam against the rod, making it much more difficult to release.
The hitch is frequently used by hammock campers to attach whoopie slings to tree huggers.
Tying.
Below is a basic method of tying. The knot can also be made by using the rod itself to form the loop, but the tying method does not affect the performance of the resulting hitch.
Begin with an overhand loop. That is, a loop which the working part passes over the standing part.
Fold the loop over the working part, towards the standing part such that the standing part is visible through the center of the loop. In stiffer material the first two steps can be accomplished in a single motion by twisting the working part with the fingers until a loop forms and flops over the standing part.
Use the rod to snag a bight of the standing part through the loop. That is, pass the rod over the near side of the loop, under the standing part and then over the far side of the loop.
Before tensioning, excess slack can be removed by pulling "simultaneously" on both the working and standing parts. In actual use the hitch should be loaded only from the standing side.
Undesirable capsized form.
If the working end is loaded rather than the standing part, the knot will capsize into an overhand noose. While this form may still hold when the standing part is subsequently loaded, it can jam badly against the rod. This is especially troublesome if the rod is not tapered.

</doc>
<doc id="56508" url="http://en.wikipedia.org/wiki?curid=56508" title="Judi Bari">
Judi Bari

Judi Bari (November 7, 1949 – March 2, 1997) was an American environmentalist and labor leader, a feminist, and the principal organizer of Earth First! campaigns against logging in the ancient redwood forests of Northern California in the 1980s and '90s. She also organized efforts through Earth First! - Industrial Workers of the World Local 1 to bring timber workers and environmentalists together in common cause.
Family background and early life.
Bari was born and raised in Silver Spring, Maryland, the daughter of mathematician Ruth Aaronson Bari and diamond setter Arthur Bari. The elder Baris were both active in left-wing politics; they advocated for civil rights and opposed the Vietnam War. One of Judi Bari's sisters is "New York Times" science journalist Gina Kolata; the other sister, Martha Bari, is an art historian. Bari's father was of Italian descent and her mother was Jewish. Although Judi attended the University of Maryland for five years, she dropped out without graduating. She admitted that her college career was most notable for "anti-Vietnam War rioting".
Prior to her move to northern California, Bari was a clerk for a chain grocery store and became a union organizer in its work force. At her next job as a mail handler, she organized a wildcat strike in the United States Postal Service bulk mail facility in Maryland.
Bari moved to Ukiah in Sonoma County, California, and settled into married life with her husband Mike Sweeny, whom she had met while still living on the East Coast.
Pre-bombing political and conservation activities.
During the early to mid-1980s Bari devoted her time to Pledge of Resistance, a group that opposed US policies in Central America. She was a self-proclaimed virtuoso on the bullhorn. She edited, wrote and drew cartoons for political leaflets and publications. She was flamboyant and articulate.
Around 1985, Bari moved north with her husband and two children to the vicinity of Redwood Valley in Mendocino County, California. In 1988, as she was divorcing her husband, she met Darryl Cherney and began a romantic relationship with him based partly on mutual political beliefs.
In 1988, Bari joined Earth First! and began organizing protests against over-cutting old growth redwoods.
Bari's first forest blockade site was on behalf of expanding the B.L.M.'s Cahto Wilderness Area. Also in 1988, Bari organized one demonstration to protect an abortion clinic.
Bari's actions were seen by many timber workers as threatening their livelihoods. At this time, environmentalists were backing their legal suits by lobbying against perceived timber overcutting with blockades of job sites in the woods and tree sitting. In turn, loggers punched and shot at demonstrators, and ran demonstrators' vehicles including Bari's station wagon off the road with a lumber truck. Timber cutters were known to fell trees in the direction of demonstrators.
To counter the loggers' tactics, and to widen the scope of its demonstrations against timber harvesting, Earth First! came up with the idea of Redwood Summer, protests inspired by Freedom Summer, and by the Freedom Riders of the civil rights movement. Bari was instrumental in the process of calling in demonstrators from college campuses across the United States. Reactions to her lobbying tactics were severe, including a purported ramming of her car by a logging truck in 1989, as well as death threats.
In 1986, Houston millionaire Charles Hurwitz had acquired Pacific Lumber Company and doubled its rate of timber harvesting as a means of paying off the acquisition cost. This enraged environmentalists and drew attention from government agencies because of the use of junk bonds.
On 8 May 1987, a sawmill accident occurred at the Louisiana Pacific mill in Cloverdale, California. Mill worker George Alexander nearly died of injuries suffered when the mill's saw blade struck a spike in a log being milled. The spike turned the whirling blade into a storm of tensile shrapnel. A fallout of publicity resulted. Earth First! was blamed for the spike, but cleared by police investigators.
In 1988, Bari used her labor organizing background to run a workshop on the International Workers of the World at an Earth First! rendezvous in California. The formation of IWW-Local 1 union brought together environmentalists and timber workers who were concerned about the rate the timber industry was harvesting timber,
In line with her beliefs in nonviolent action, she harnessed the power of music as part of her demonstrations. She played the violin and sang original compositions by Darryl Cherney and occasionally her own. Their song titles and lyrics aroused controversy by usage of loaded language. Cherney's song about tree spiking, "Spike a Tree for Jesus" is one example; "Will This Fetus Be Aborted", sung as a counter-protest to an anti-abortion rally, was another. The resulting publicity tended to create perceptions about Earth First! among the public contrary to her commitment to non-violence; despite her disavowal of tree spiking and her espousal of civil disobedience, media portrayed her as an obstructionist saboteur. Bari's activism made her seem egocentric, humorless, and strident to some; and her tactics often rankled not only the timber industry and political establishment, but fellow environmental activists.
In August 1989, environmentalist protester Mem Hill suffered a broken nose in a protest confrontation with loggers in the woods. A subsequent legal suit accused a logger of assault, and claimed law enforcement did not protect her from attack.
By the following year, Mendocino County had been convinced that the public interest was best served by reclaiming for the public domain 300,000 acres of timber land from Louisiana Pacific. Ballot proposition 130, dubbed "Forests Forever", was submitted to California's voters in November 1990. It was designed to prevent over-harvesting of the state's timber. The logging corporations were strongly opposed to it. In response, environmentalists began organizing Redwood Summer, a campaign of nonviolent protests focused on saving redwood forests in Northern California. On 6 November 1990, Proposition 130 was defeated by California voters.
On 9 May 1990, a failed pipe bomb was discovered in the Louisiana Pacific saw mill in Cloverdale.
On 22 May 1990, Bari met quietly with local loggers to agree on ground rules for nonviolence during the Redwood Summer demonstrations.
The car bombing attempt on Bari's life.
Summary.
On 24 May 1990, in Oakland, California, the vehicle used by Bari and Darryl Cherney was blown up by a pipe bomb in it. Bari was severely injured by the blast, as the bomb had been under her seat; Cherney suffered minor injuries. Bari was arrested for transporting explosives while she was still in critical condition with a fractured pelvis and other major injuries.
The FBI took jurisdiction of the case away from the Bureau of Alcohol, Tobacco, Firearms and Explosives, alleging it was an eco-terrorism case. The Oakland Police Department was the local agency on the case. Bari's wounds disabled her to the extent she had to curtail her activities. While she lay convalescing, Redwood Summer took place, turning into a series of demonstrations by thousands of ecologists and counter-demonstrations by roughly equal numbers of timber workers and their families.
In late July 1990, the Oakland district attorney declined to press charges against Bari and Cherney, claiming insufficient evidence. The false arrests and illegal search warrants became the basis of Bari's civil rights suit (discussed below), filed the following year but not decided until 2002, five years after her death.
The bombing.
Bari and Cherney went on an organizing tour for Redwood Summer. On May 24, the bomb exploded in her car as she and Cherney traveled through Oakland on their way to Santa Cruz. Although Bureau of Alcohol, Tobacco, Firearms and Explosives is mandated to investigate use of explosives, the FBI claimed jurisdiction of the crime on grounds that it was terrorism.
When the Oakland police and the FBI immediately accused Bari and Cherney of knowingly carrying a bomb for use in an act of terrorism, the story made headlines nationwide. By 3:00 p.m. of the day of the bombing, Bari was placed under arrest for transportation of illegal explosives while being treated in Highland Hospital. The police actions shaped media response. For example, a KQED (TV) news report entitled "Focus: Logjam" used the term "radical" to describe Earth First!, blamed them for sabotaging logger's equipment and tree spiking, and tied in Bari's bombing with these actions.
Based on his personal observations, finding in the destroyed car a bag of broad-headed roofing nails he considered similar to nearly headless finishing nails used as shrapnel in the bomb, FBI Special Agent Frank Doyle filed a public affidavit that the bomb had been carried on the back seat floorboard of Bari's vehicle. The FBI was granted a search warrant on May 25 at 2:21 a.m., and agents subsequently took a helicopter to search Bari's home. Agents also searched the premises of Seeds of Peace, where Bari and Cherney had slept the night before the explosion, at the "Seeds House" in Berkeley. Members of Seeds of Peace were repeatedly interviewed, and repeatedly informed police of Bari's and Cherney's commitment to nonviolence.
Within a week, supporters of Bari and Cherney were petitioning for an investigation of the FBI's investigative methods; there were already complaints by Daniel Hamburg and others that the investigation was focused solely on charging the two environmentalists. At the same time, legislation governing the size of protest sign staffs was under consideration by the Mendocino County Board of Supervisors, as a means of curbing violence by demonstrators. Meanwhile, the remaining Redwood Summer organizers debated whether to cancel demonstrations in the woods as being too dangerous.
On 29 May, representatives of small local logging companies and of Redwood Summer signed an agreement for nonviolent and non-destructive protests of timber harvesting. Redwood Summer eventually continued, though as a series of both demonstrations and counter-demonstrations. The latter were organized by loggers' families, who felt their employment was in jeopardy.
On 6 July, a new search warrant for Bari's home, granted largely on information given in the first one, was executed with exemplars of typewriting the target of the search.
FBI laboratory analysis discovered that the explosive was a pipe bomb packed with nails for shrapnel effect, and that it was equipped with a motion trigger to ensure that it would explode only when the car was driven. The bomb was also placed directly under the driver's seat, not in the back seat or luggage area as it presumably would have been if Bari had been transporting it knowingly. After seven weeks of continual news stories citing repeated police claims that all evidence pointed to Bari and Cherney as culprits, the Oakland District Attorney announced that he would not file any formal charges against the pair due to insufficient evidence against them. The crime would go unsolved.
Theories of the bombing.
The Lord's Avenger.
Just five days after the bombing, on 29 May, while Bari was still in hospital, Mike Geniella of the Santa Rosa "Press Democrat" received a letter claiming responsibility for placing the bomb in Bari's car and at the Cloverdale mill. It was written in a high-flown, biblical style with heavily misogynistic language and signed "The Lord's Avenger," who stated further that the letter writer's motivation was Bari's defense of a Planned Parenthood clinic in Ukiah, California, during an anti-abortion protest. The letter also described the construction of the two bombs in great detail. The bomb in the Cloverdale sawmill included a pipe bomb and a can of gasoline, but it failed to ignite and did no damage. The other bomb was in Bari's vehicle.
The FBI.
As Bari discovered through the depositions for her civil rights trial, the May 24 bomb in Oakland also closely resembled "crime scenes" fabricated by the FBI in a "bomb school" held in redwood country earlier that year. The FBI school was intended to train local and state police officers on how to investigate bomb scenes. The school taught that bomb explosions inside a vehicle were not likely to involve targets of bombing but indicated the knowing, criminal transportation of homemade bombs. This was said to be because it was difficult to break into a locked car to plant a bomb. Nevertheless, two of the three bombs set off as a practicum for the school were placed inside automobiles.
According to Bari, FBI Special Agent Frank Doyle was the bomb school instructor, and at least four of the law enforcement respondents to the bombing were his students at the school.
Bari had received numerous death threats citing her anti-logging activism in the weeks before the bombing. She had reported them to local police, and after the bombing Bari's attorney turned written threats over to the FBI for investigation. The local police and the FBI never investigated, court evidence later showed.
Aftermath of bombing.
Redwood Summer ended with a fractionating Earth First! claiming success because they had trained so many volunteers in nonviolent resistance. Nevertheless, Proposition 130 went down to defeat on 6 November 1990.
Writing and public service career.
Bari became a political writer as part of her interests in feminism, class struggle, and ecology. In May 1992, in her writing, she claimed to have feminized Earth First!,a radical environmentalist group founded by men. While making this claim, she admitted blocking loggers from their work.
By the end of 1996, Bari was working as a para-legal and hosting a weekly public radio show. She also headed the congressional committee that wrote a compensation clause for lumber workers laid off because of the establishment of the Headwaters Forest Reserve; the resultant bill establishing the reserve passed on 14 November 1997, shortly after Bari's death.
Death and posthumous civil rights trial.
On 2 March 1997, Bari died of breast cancer at her home near Willits.
Bari and Cherney had filed a federal civil rights suit claiming that the FBI and police officers falsely arrested the pair and attempted to frame them as terrorists so as to discredit their political organizing in defense of the redwood forests.
In 1997, the law enforcement officers named in the civil rights suit were sued for conspiracy to violate Bari and Cherney's First and Fourth Amendment rights. On 15 October that year, the agents lost their bid for immunity from prosecution.
Also on 15 October, federal judge Claudia Wilken dismissed from the case FBI supervisor Richard Wallace Held, who had been prominent in the agency's COINTELPRO effort, on the grounds that he had no duty to oversee the daily duties of his subordinate agents.
In 2002, a jury in Bari's and Cherney's federal civil lawsuit found that their civil rights had been violated.
As part of the jury's verdict, the judge ordered three FBI agents and three Oakland police officers to pay a total of $4.4 million to Cherney and to Bari's estate. The award was a response to the defendants' violation of the plaintiffs' First Amendment rights to freedom of speech and freedom of assembly, and for the defendants' various unlawful acts, including unlawful search and seizure in violation of the plaintiff's Fourth Amendment rights. At trial the FBI and the Oakland Police pointed fingers at each other.
While neither agency would admit wrongdoing, the jury held both liable finding, "[B]oth agencies admitted they had amassed intelligence on the couple before the bombing." This evidence supported the jury's finding that both the FBI and the Oakland police persecuted Bari and Cherney for being bombed instead of trying to find the true perpetrators in order to discredit and sabotage Earth First! and the upcoming Redwood Summer, thereby violating their First Amendment rights and justifying the large award. Simply, instead of looking for the actual terrorists, they persecuted the victims of that terror because of their political activism.
After the trial's gag order was lifted, jurors made it clear they believed the agents were blatant liars.
Legacy.
Judi Bari Day.
On May 20, 2003, the Oakland City Council unanimously voted a resolution saying: "Whereas, Judi Bari was a dedicated activist, who worked for many social and environmental causes, the most prominent being the protection and stewardship of California's ancient redwood forests. ... Now therefore be it resolved that the City of Oakland shall designate May 24 as Judi Bari Day ...
Biography (book).
In early 2005, a critical biography of Bari titled "The Secret Wars of Judi Bari", by Kate Coleman, drew fierce condemnation from Cherney, Bari's estate, and their friends and supporters, who claimed hundreds of factual errors and a bias against Bari and Earth First! They also pointed out that the book was published by Encounter Books, a non-profit publishing house founded by neoconservative Peter Collier and funded primarily by arch-conservative foundations not sympathetic to Bari's causes. In the book Coleman speculated that Bari's ex-husband had planted the bomb in hopes of killing her and Cherney. A review of the book in the LA Times by Mark Hertsgaard entitled, "Too many rumors, too few facts to examine eco-activism case", said, "the reporting is thin and sloppy, and the humdrum prose is marred by dubious speculation." However, the Times review was said to contain its own errors .
Movie.
The story of the case and the trial inspired an award winning documentary movie, "The Forest For The Trees". The film, which aired on PBS and the Sundance Channel, follows the case through the lead attorney, civil rights legend Dennis Cunningham, and is told by his daughter, Bernadine Mellis. Among the awards the film received was the Grand Prize at the Green Film Festival in Seoul.
Book.
IWW member Steve Ongerth has written a book, Redwood Uprising, which is being made available online at judibari.info which explores the motivation behind the bombing and argues that it was likely a collaboration between COINTELPRO operatives, representatives of the timber corporations, and anti-environmental extremists active in the old growth redwood forest region of northwestern California in response to Bari's efforts to build alliances between radical environmentalists and rank and file timber workers opposing the corporations.

</doc>
<doc id="56509" url="http://en.wikipedia.org/wiki?curid=56509" title="Potash">
Potash

Potash is any of various mined and manufactured salts that contain potassium in water-soluble form. The name derives from "pot ash", which refers to plant ashes soaked in water in a pot, the primary means of manufacturing the product before the industrial era. The word "potassium" is derived from potash.
Today, potash is produced worldwide at amounts exceeding 30 million tonnes per year, mostly for use in fertilizers. Various types of fertilizer-potash thus constitute the single largest global industrial use of the element potassium. Potassium was first derived by electrolysis of caustic potash (aka potassium hydroxide), in 1808.
Terminology.
Potash refers to potassium compounds and potassium-bearing materials, the most common being potassium chloride (KCl). The term "potash" comes from the Old Dutch word "potaschen" ("pot ashes", 16th century). The old method of making potassium carbonate (K2CO3) was by collecting or producing wood ash (an occupation carried out by ash burners), leaching the ashes and then evaporating the resulting solution in large iron pots, leaving a white residue called "pot ash". Approximately 10% by weight of common wood ash can be recovered as pot ash. Later, "potash" became the term widely applied to naturally occurring potassium salts and the commercial product derived from them.
The following table lists a number of potassium compounds which use the word "potash" in their traditional names:
Production.
All commercial potash deposits come originally from marine deposits and are often buried deep in the earth. Potash ores are typically rich in potassium chloride (KCl) and sodium chloride (NaCl) and are obtained by conventional shaft mining with the extracted ore ground into a powder. For deep potash deposits hot water is injected into the potash which is dissolved and then pumped to the surface where it is concentrated by solar induced evaporation. Amine reagents are then added to either the mined or evaporated solutions. The amine coats the KCl but not NaCl. Air bubbles cling to the amine + KCl and float it to the surface while the NaCl and clay sink to the bottom. The surface is skimmed for the amine + KCl which is then dried and packaged for use as a K rich fertilizer—KCl dissolves readily in water and is available quickly for plant nutrition.
History of production.
Potash (especially potassium carbonate) has been used since the dawn of history in bleaching textiles, making glass, and, from about AD 500, in making soap. Potash was principally obtained by leaching the ashes of land and sea plants. Beginning in the 14th century potash was mined in Ethiopia. One of the world's largest deposits, 140 to 150 million tons, is located in the Tigray's Dallol area. Potash was one of the most important industrial chemicals in Canada. It was refined from the ashes of broadleaved trees and produced primarily in the forested areas of Europe, Russia, and North America. The first U.S. patent of any kind was issued in 1790 to Samuel Hopkins for an improvement "in the making of Pot ash and Pearl ash by a new Apparatus and Process". "Pearl ash" was a purer quality made by the ignition of cream of tartar. Potash pits were once used in England to produce potash that was used in making soap for the preparation of wool for yarn production.
As early as 1767, potash from wood ashes was exported from Canada, and exports of potash and pearl ash (potash and lime) reached 43,958 barrels in 1865. There were 519 asheries in operation in 1871. The industry declined in the late 19th century when large-scale production of potash from mineral salts was established in Germany. In 1943, potash was discovered in Saskatchewan, Canada, in the process of drilling for oil. Active exploration began in 1951. In 1958, the Potash Company of America became the first potash producer in Canada with the commissioning of an underground potash mine at Patience Lake; however, due to water seepage in its shaft, production stopped late in 1959 but following extensive grouting and repairs, resumed in 1965. The underground mine was flooded in 1987 and was reactivated for commercial production as a solution mine in 1989.
In the late 18th and early 19th centuries, potash production provided settlers in North America a way to obtain badly needed cash and credit as they cleared wooded land for crops. To make full use of their land, settlers needed to dispose of excess wood. The easiest way to accomplish this was to burn any wood not needed for fuel or construction. Ashes from hardwood trees could then be used to make lye, which could either be used to make soap or boiled down to produce valuable potash. Hardwood could generate ashes at the rate of 60 to 100 bushels per acre (500 to 900 m3/km2). In 1790, ashes could be sold for $3.25 to $6.25 per acre ($800 to $1,500/km2) in rural New York State – nearly the same rate as hiring a laborer to clear the same area. Potash making became a major industry in British North America. Great Britain was always the most important market. The American potash industry followed the woodsman's ax across the country. After about 1820, New York replaced New England as the most important source; by 1840 the center was in Ohio. Potash production was always a by-product industry, following from the need to clear land for agriculture.
Most of the world reserves of potassium (K) were deposited as sea water in ancient inland oceans. After the water evaporated, the potassium salts crystallized into beds of potash ore. These are the locations where potash is being mined today. The deposits are a naturally occurring mixture of potassium chloride (KCl) and sodium chloride (NaCl), better known as common table salt. Over time, as the surface of the earth changed, these deposits were covered by thousands of feet of earth.
Most potash mines today are deep shaft mines as much as 4,400 feet (1,400 m) underground. Others are mined as strip mines, having been laid down in horizontal layers as sedimentary rock. In above-ground processing plants, the KCl is separated from the mixture to produce a high-analysis potassium fertilizer. Other potassium salts can be separated by various procedures, resulting in potassium sulfate and potassium-magnesium sulfate.
Today some of the world's largest known potash deposits are spread all over the world from Saskatchewan, Canada, to Brazil, Belarus, Germany, and more notably the Permian Basin. The Permian basin deposit includes the major mines outside of Carlsbad, New Mexico, to the world's purest potash deposit in Lea County, New Mexico (not far from the Carlsbad deposits), which is believed to be roughly 80% pure. (Osceola County, Michigan has deposits 90+% pure, however, the only mine there was recently converted to salt production.) Canada is the largest producer, followed by Russia and Belarus. The most significant reserve of Canada's potash is located in the province of Saskatchewan and controlled by the Potash Corporation of Saskatchewan.
In the beginning of the 20th century, potash deposits were found in the Dallol Depression in Musely and Crescent localities near the Ethiopean-Eritrean border. The estimated reserves are 173 and 12 million tonnes for the Musely and Crescent, respectively. The latter is particularly suitable for surface mining; it was explored in the 1960s but the works stopped due to the flood in 1967. Attempts to continue mining in the 1990s were halted by the Eritrean–Ethiopian War and have not resumed as of 2009.
Recently, recovery of potassium fertilizer salts from sea water has been studied in India. During extraction of salt from seawater by evaporation, potassium salts get concentrated in bittern, an effluent from the salt industry.
In 2013, almost 70% of potash production was controlled by two cartels, Canpotex and the Belarusian Potash Company. The latter was a joint venture between Belaruskali and Uralkali, but on July 30, 2013 Uralkali announced that it had ended the venture.
Consumption.
Fertilizers.
Potassium is the third major plant and crop nutrient after nitrogen and phosphorus. It has been used since antiquity as a soil fertilizer (about 90% of current use). Elemental potassium does not occur in nature because it reacts violently with water. As part of various compounds, potassium makes up about 2.6% of the weight of the Earth's crust and is the seventh most abundant element, similar in abundance to sodium at approximately 1.8% of the crust. Potash is important for agriculture because it improves water retention, yield, nutrient value, taste, colour, texture and disease resistance of food crops. It has wide application to fruit and vegetables, rice, wheat and other grains, sugar, corn, soybeans, palm oil and cotton, all of which benefit from the nutrient’s quality enhancing properties.
Demand for food and animal feed has been on the rise since 2000. The United States Department of Agriculture’s Economic Research Service (ERS) attributes the trend to average annual population increases of 75 million people around the world. Geographically, economic growth in Asia and Latin America greatly contributed to the increased use of potash-based fertilizer. Rising incomes in developing countries also was a factor in the growing potash and fertilizer use. With more money in the household budget, consumers added more meat and dairy products to their diets. This shift in eating patterns required more acres to be planted, more fertilizer to be applied and more animals to be fed—all requiring more potash.
After years of trending upward, fertilizer use slowed in 2008. The worldwide economic downturn is the primary reason for the declining fertilizer use, dropping prices, and mounting inventories.
The world's largest consumers of potash are China, the United States, Brazil, and India. Brazil imports 90% of the potash it needs.
Potash imports and exports are often reported in "K2O equivalent", although fertilizer never contains potassium oxide, per se, because potassium oxide is caustic and hygroscopic.
Pricing.
At the beginning of 2008, Potash prices started a meteoric climb from less than $200 a tonne to a high of $875 in Feb 2009. These subsequently dropped dramatically to an April 2010 low of $310 level, before recovering in 2011–12, and relapsing again in 2013. For reference, prices in November 2011 were about $470 per tonne, but as of May 2013 were stable at $393. After the surprise breakup of the world's largest potash cartel at the end of July 2013, potash prices are poised to drop some 20 percent. At the end of Feb 2015, Potash traded for $310 a tonne. .
Other uses.
In addition to its use as a fertilizer, potassium chloride is important in many industrialized economies, where it is used in aluminium recycling, by the chloralkali industry to produce potassium hydroxide, in metal electroplating, oil-well drilling fluid, snow and ice melting, steel heat-treating, in medicine as a treatment for hypokalemia, and water softening. Potassium hydroxide is used for industrial water treatment and is the precursor of potassium carbonate, several forms of potassium phosphate, many other potassic chemicals, and soap manufacturing. Potassium carbonate is used to produce animal feed supplements, cement, fire extinguishers, food products, photographic chemicals, and textiles. It is also used in brewing beer, pharmaceutical preparations, and as a catalyst for synthetic rubber manufacturing. These non-fertilizer uses have accounted for about 15% of annual potash consumption in the United States.
Potash (potassium carbonate) along with hartshorn was also used as a baking aid similar to baking soda in old German baked goods such as "lebkuchen", or gingerbread.
References.
 This article incorporates  from websites or documents of the .

</doc>
<doc id="56510" url="http://en.wikipedia.org/wiki?curid=56510" title="Angiopathy">
Angiopathy

Angiopathy is the generic term for a disease of the blood vessels (arteries, veins, and capillaries). The best known and most prevalent angiopathy is diabetic angiopathy, a common complication of chronic diabetes.
Classification.
By caliber.
There are two types of angiopathy: macroangiopathy and microangiopathy.
In macroangiopathy, atherosclerosis and a resultant blood clot forms on the large blood vessels, sticks to the vessel walls, and blocks the flow of blood. Macroangiopathy may cause other complications, such as ischemic heart disease, stroke and peripheral vascular disease which contributes to the diabetic foot ulcers and the risk of amputation.
In microangiopathy, the walls of the smaller blood vessels become so thick and weak that they bleed, leak protein, and slow the flow of blood through the body. The decrease of blood flow through stenosis or clot formation impairs the flow of oxygen to cells and biological tissues (called ischemia) and leads to cellular death (necrosis and gangrene, which in turn may require amputation). Thus, tissues which are very sensitive to oxygen levels, such as the retina, develop microangiopathy and may cause blindness (so-called proliferative diabetic retinopathy). Damage to nerve cells may cause peripheral neuropathy, and to kidney cells, diabetic nephropathy (Kimmelstiel-Wilson syndrome).
By condition.
It is also possible to classify angiopathy by the associated condition:

</doc>
<doc id="56511" url="http://en.wikipedia.org/wiki?curid=56511" title="Dialysis">
Dialysis

In medicine, dialysis (from Greek dialusis,"διάλυσις", meaning "dissolution", dia, meaning "through", and lysis, meaning "loosening or splitting") is a process for removing waste and excess water from the blood, and is used primarily as an artificial replacement for lost kidney function in people with kidney failure. Dialysis may be used for those with an acute disturbance in kidney function (acute kidney injury, previously acute renal failure), or progressive but chronically worsening kidney function—a state known as chronic kidney disease stage 5 (previously chronic renal failure or end-stage renal disease). The latter form may develop over months or years, but in contrast to acute kidney injury is not usually reversible, and dialysis is regarded as a "holding measure" until a kidney transplant can be performed, or sometimes as the only supportive measure in those for whom a transplant would be inappropriate.
The kidneys have important roles in maintaining health. When healthy, the kidneys maintain the body's internal equilibrium of water and minerals (sodium, potassium, chloride, calcium, phosphorus, magnesium, sulfate). The acidic metabolism end-products that the body cannot get rid of via respiration are also excreted through the kidneys. The kidneys also function as a part of the endocrine system, producing erythropoietin and calcitriol. Erythropoietin is involved in the production of red blood cells and calcitriol plays a role in bone formation. Dialysis is an imperfect treatment to replace kidney function because it does not correct the compromised endocrine functions of the kidney. Dialysis treatments replace some of these functions through diffusion (waste removal) and ultrafiltration (fluid removal).
History.
A Dutch physician, Willem Johan Kolff, constructed the first working dialyzer in 1943 during 
the Nazi occupation of the Netherlands. Due to the scarcity of available resources, Kolff had to improvise and build the initial machine using sausage casings, beverage cans, a washing machine, and various other items that were available at the time. Over the following two years, [1943-1945] Kolff used his machine to treat 16 patients suffering from acute kidney failure, but the results were unsuccessful. Then, in 1945, a 67-year-old comatose woman regained consciousness following 11 hours of hemodialysis with the dialyzer, and lived for another seven years before dying from an unrelated condition. She was the first-ever patient successfully treated with dialysis.
Dr. Nils Alwall modified a similar construction to the Kolff kidney by enclosing it inside a stainless steel canister. This allowed the removal of fluids, by applying a negative pressure to the outside canister, thus making it the first truly practical device for hemodialysis. Alwall treated his first patient in acute kidney failure on September 3, 1946.
Principle.
Dialysis works on the principles of the diffusion of solutes and ultrafiltration of fluid across a semi-permeable membrane. Diffusion is a property of substances in water; substances in water tend to move from an area of high concentration to an area of low concentration. Blood flows by one side of a semi-permeable membrane, and a dialysate, or special dialysis fluid, flows by the opposite side. A semipermeable membrane is a thin layer of material that contains holes of various sizes, or pores. Smaller solutes and fluid pass through the membrane, but the membrane blocks the passage of larger substances (for example, red blood cells, large proteins). This replicates the filtering process that takes place in the kidneys, when the blood enters the kidneys and the larger substances are separated from the smaller ones in the glomerulus.
The two main types of dialysis, hemodialysis and peritoneal dialysis, remove wastes and excess water from the blood in different ways. Hemodialysis removes wastes and water by circulating blood outside the body through an external filter, called a dialyzer, that contains a semipermeable membrane. The blood flows in one direction and the dialysate flows in the opposite. The counter-current flow of the blood and dialysate maximizes the concentration gradient of solutes between the blood and dialysate, which helps to remove more urea and creatinine from the blood. The concentrations of solutes (for example potassium, phosphorus, and urea) are undesirably high in the blood, but low or absent in the dialysis solution, and constant replacement of the dialysate ensures that the concentration of undesired solutes is kept low on this side of the membrane. The dialysis solution has levels of minerals like potassium and calcium that are similar to their natural concentration in healthy blood. For another solute, bicarbonate, dialysis solution level is set at a slightly higher level than in normal blood, to encourage diffusion of bicarbonate into the blood, to act as a pH buffer to neutralize the metabolic acidosis that is often present in these patients. The levels of the components of dialysate are typically prescribed by a nephrologist according to the needs of the individual patient.
In peritoneal dialysis, wastes and water are removed from the blood inside the body using the peritoneum as a natural semipermeable membrane. Wastes and excess water move from the blood, across the peritoneal membrane, and into a special dialysis solution, called dialysate, in the abdominal cavity.
Types.
There are three primary and two secondary types of dialysis: hemodialysis (primary), peritoneal dialysis (primary), hemofiltration (primary), hemodiafiltration (secondary), and intestinal dialysis (secondary).
Hemodialysis.
In hemodialysis, the patient's blood is pumped through the blood compartment of a dialyzer, exposing it to a partially permeable membrane. The dialyzer is composed of thousands of tiny hollow synthetic fibers. The fiber wall acts as the semipermeable membrane. Blood flows through the fibers, dialysis solution flows around the outside of the fibers, and water and wastes move between these two solutions. The cleansed blood is then returned via the circuit back to the body. Ultrafiltration occurs by increasing the hydrostatic pressure across the dialyzer membrane. This usually is done by applying a negative pressure to the dialysate compartment of the dialyzer. This pressure gradient causes water and dissolved solutes to move from blood to dialysate, and allows the removal of several litres of excess fluid during a typical 4-hour treatment.
In the United States, hemodialysis treatments are typically given in a dialysis center three times per week (due in the United States to Medicare reimbursement rules); however, as of 2007 over 2,500 people in the United States are dialyzing at home more frequently for various treatment lengths. Studies have demonstrated the clinical benefits of dialyzing 5 to 7 times a week, for 6 to 8 hours. This type of hemodialysis is usually called "nocturnal daily hemodialysis", which a study has shown a significant improvement in both small and large molecular weight clearance and decrease the requirement of taking phosphate binders. These frequent long treatments are often done at home while sleeping, but home dialysis is a flexible modality and schedules can be changed day to day, week to week. In general, studies have shown that both increased treatment length and frequency are clinically beneficial.
Hemo-dialysis was one of the most common procedures performed in U.S. hospitals in 2011, occurring in 909,000 stays (a rate of 29 stays per 10,000 population).
Peritoneal dialysis.
In peritoneal dialysis, a sterile solution containing glucose (called dialysate) is run through a tube into the peritoneal cavity, the abdominal body cavity around the intestine, where the peritoneal membrane acts as a partially permeable membrane. The peritoneal membrane or peritoneum is a layer of tissue containing blood vessels that lines and surrounds the peritoneal, or abdominal, cavity and the internal abdominal organs (stomach, spleen, liver, and intestines). Diffusion and osmosis drive waste products and excess fluid through the peritoneum into the dialysate until the dialysate approaches equilibrium with the body's fluids. Then the dialysate is drained, discarded, and replaced with fresh dialysate.
This exchange is repeated 4-5 times per day; automatic systems can run more frequent exchange cycles overnight. Peritoneal dialysis is less efficient than hemodialysis, but because it is carried out for a longer period of time the net effect in terms of removal of waste products and of salt and water are similar to hemodialysis. Peritoneal dialysis is carried out at home by the patient, often without help. This frees patients from the routine of having to go to a dialysis clinic on a fixed schedule multiple times per week. Peritoneal dialysis can be performed with little to no specialized equipment (other than bags of fresh dialysate).
Hemofiltration.
Hemofiltration is a similar treatment to hemodialysis, but it makes use of a different principle. The blood is pumped through a dialyzer or "hemofilter" as in dialysis, but no dialysate is used. A pressure gradient is applied; as a result, water moves across the very permeable membrane rapidly, "dragging" along with it many dissolved substances, including ones with large molecular weights, which are not cleared as well by hemodialysis. Salts and water lost from the blood during this process are replaced with a "substitution fluid" that is infused into the extracorporeal circuit during the treatment. Hemodiafiltration is the combining of hemodialysis and hemofiltration in one process.
Hemodiafiltration.
Hemodiafiltration is a combination of hemodialysis and hemofiltration.
Intestinal dialysis.
In intestinal dialysis, the diet is supplemented with soluble fibres such as acacia fibre, which is digested by bacteria in the colon. This bacterial growth increases the amount of nitrogen that is eliminated in fecal waste. An alternative approach utilizes the ingestion of 1 to 1.5 liters of non-absorbable solutions of polyethylene glycol or mannitol every fourth hour.
Starting indications.
The decision to initiate dialysis or hemofiltration in patients with kidney failure depends on several factors. These can be divided into acute or chronic indications.
Indications for chronic dialysis:
Chronic dialysis may be indicated when a patient has symptomatic kidney failure and low glomerular filtration rate (GFR).
Between 1996 to 2008 there was a trend to initiate dialysis at progressively higher estimated GFR, eGFR. 
A review of the evidence shows no benefit or potential harm with early dialysis initiation, which has been defined by start of dialysis at an estimated GFR of greater than 10ml/min/1.732.Observational data from large registries of dialysis patients suggests that early start of dialysis may be harmful.
The most recent published guidelines from Canada, for when to initiate dialysis, recommend an intent to defer dialysis until a patient has definite kidney failure symptoms, which may occur at an estimated GFR of 5-9ml/min/1.732.
Some reason for dialysis initiation include difficulty in medically controlling fluid overload or serum potassium. If a patient has intractable kidney failure symptoms or signs, start of dialysis may be recommended at eGFR levels above 10ml/min/1.732
Dialyzable substances.
Characteristics.
Dialyzable substances have following properties:
Dialysis provision in the United Kingdom.
The National Health Service provides dialysis in the United Kingdom. In England the service is commissioned by NHS England. About 23,000 patients use the service each year.

</doc>
<doc id="56512" url="http://en.wikipedia.org/wiki?curid=56512" title="Capillary">
Capillary

Capillaries ( in US; in UK) are the smallest of a body's blood vessels (and lymph vessels) that make up the microcirculation. Their endothelial linings are only one cell layer thick. These microvessels, measuring around 5 to 10 micrometres (µm) in diameter, connect arterioles and venules, and they help to enable the exchange of water, oxygen, carbon dioxide, and many other nutrients and waste substances between the blood and the tissues surrounding them. Lymph capillaries connect with larger lymph vessels to drain lymph collected in the microcirculation.
During early embryonic development new capillaries are formed through vasculogenesis, the process of blood vessel formation that occurs through a "de novo" production of endothelial cells which then form vascular tubes. The term angiogenesis denotes the formation of new capillaries from pre-existing blood vessels and already present endothelium which divides.
Structure.
Blood flows from the heart through arteries, which branch and narrow into arterioles, and then branch further into capillaries. After the tissues have been perfused, the capillaries then join and widen to become venules, which in turn widen and converge to become veins, which then return blood back to the heart through the great veins.
Capillaries do not function on their own, but instead in a "capillary bed", an interweaving network of capillaries supplying organs and tissues. The more metabolically active a cell or environment is, the more capillaries are required to supply nutrients and carry away waste products. Capillary beds can consist of two types of vessels: true capillaries, which branch from arterioles and provide exchange between cells and the blood, and metarterioles, which are short vessels that directly connect the arterioles and venules at opposite ends of the bed.
Metarterioles provide direct communication between arterioles and venules, and are important in bypassing the bloodflow through the capillaries via precapillary sphincters. They are found primarily in mesenteric microcirculation and were previously thought to be found in the entire capillary system. The physiological mechanisms underlying precapillary resistance is no longer considered to be a result of precapillary sphincters outside of the mesentery organ.
Lymphatic capillaries are slightly larger in diameter than blood capillaries, and have closed ends (unlike the loop structure of blood capillaries). This structure permits interstitial fluid to flow into them but not out. Lymph capillaries have a greater internal oncotic pressure than blood capillaries, due to the greater concentration of plasma proteins in the lymph.
Types.
There are three main types of blood capillaries:
Continuous.
Continuous capillaries are continuous in the sense that the endothelial cells provide an uninterrupted lining, and they only allow smaller molecules, such as water and ions to pass through their intercellular clefts. However lipid-soluble molecules can passively diffuse through the endothelial cell membranes along concentration gradients. Tight junctions can be further divided into two subtypes:
Fenestrated.
Fenestrated capillaries (derived from "fenestra", Latin for "window") have pores in the endothelial cells (60-80 nm in diameter) that are spanned by a diaphragm of radially oriented fibrils and allow small molecules and limited amounts of protein to diffuse. In the renal glomerulus there are cells with no diaphragms, called podocyte foot processes or pedicels, which have slit pores with a function analogous to the diaphragm of the capillaries. Both of these types of blood vessels have continuous basal laminae and are primarily located in the endocrine glands, intestines, pancreas, and the glomeruli of the kidney.
Sinusoidal.
Sinusoidal capillaries are a special type of open-pore capillary also known as a discontinuous capillary, that have larger openings (30-40 µm in diameter) in the endothelium. These types of blood vessels allow red and white blood cells (7.5 µm - 25 µm diameter) and various serum proteins to pass, aided by a discontinuous basal lamina. These capillaries lack pinocytotic vesicles, and therefore utilize gaps present in cell junctions to permit transfer between endothelial cells, and hence across the membrane. Sinusoid blood vessels are primarily located in the bone marrow, lymph nodes, and adrenal glands. Some sinusoids are distinctive in that they do not have the tight junctions between cells. They are called "discontinuous sinusoidal capillaries", and are present in the liver and spleen, where greater movement of cells and materials is necessary.
A capillary wall is only 1 cell thick and is simple squamous epithelium.
Function.
The capillary wall performs an important function by allowing nutrients and waste substances to pass across it. Molecules larger than 3 nm such as albumin and other large proteins pass through transcellular transport carried inside vesicles, a process which requires them to go through the cells that form the wall. Molecules smaller than 3 nm such as water, ions and gases cross the capillary wall through the space between cells in a process known as paracellular transport. These transport mechanisms allow bidirectional exchange of substances depending on osmotic gradients and can be further quantified by the Starling equation. Capillaries that form part of the blood–brain barrier however only allow for transcellular transport as tight junctions between endothelial cells seal the paracellular space.
Capillary beds may control their blood flow via autoregulation. This allows an organ to maintain constant flow despite a change in central blood pressure. This is achieved by myogenic response, and in the kidney by tubuloglomerular feedback. When blood pressure increases, arterioles are stretched and subsequently constrict (a phenomenon known as the Bayliss effect) to counteract the increased tendency for high pressure to increase blood flow.
In the lungs special mechanisms have been adapted to meet the needs of increased necessity of blood flow during exercise. When the heart rate increases and more blood must flow through the lungs, capillaries are recruited and are also distended to make room for increased blood flow. This allows blood flow to increase while resistance decreases.
Capillary permeability can be increased by the release of certain cytokines, anaphylatoxins, or other mediators (such as leukotrienes, prostaglandins, histamine, bradykinin, etc.) highly influenced by the immune system.
The Starling equation defines the forces across a semipermeable membrane and allows calculation of the net flux:
where:
By convention, outward force is defined as positive, and inward force is defined as negative. The solution to the equation is known as the net filtration or net fluid movement ("J""v"). If positive, fluid will tend to "leave" the capillary (filtration). If negative, fluid will tend to "enter" the capillary (absorption). This equation has a number of important physiologic implications, especially when pathologic processes grossly alter one or more of the variables.
Variables.
According to Starling's equation, the movement of fluid depends on six variables:
Clinical significance.
Disorders of capillary formation as a developmental defect or acquired disorder are a feature in many common and serious disorders. Within a wide range of cellular factors and cytokines, issues with normal genetic expression and bioactivity of the vascular growth and permeability factor vascular endothelial growth factor (VEGF) appear to play a major role in many of the disorders. Cellular factors include reduced number and function of bone-marrow derived endothelial progenitor cells. and reduced ability of those cells to form blood vessels.
Therapeutics.
Major diseases where altering capillary formation could be helpful include conditions where there is excessive or abnormal capillary formation such as cancer and disorders harming eyesight; and medical conditions in which there is reduced capillary formation either for familial or genetic reasons, or as an acquired problem.
Blood sampling.
Capillary blood sampling can be used to test for, for example, blood glucose (such as in blood glucose monitoring), hemoglobin, pH and lactate (the two latter can be quantified in fetal scalp blood testing to check the acid base status of a fetus during childbirth).
Capillary blood sampling is generally performed by creating a small cut using a blood lancet, followed by sampling by capillary action on the cut with a test strip or small pipe.
History.
Ibn al-Nafis theorized a "premonition of the capillary circulation in his assertion that the pulmonary vein receives what exits the pulmonary artery, explaining the existence of perceptible passages between the two."
Marcello Malpighi was the first to observe and correctly describe capillaries, discovering them in a frog's lung in 1661.

</doc>
<doc id="56517" url="http://en.wikipedia.org/wiki?curid=56517" title="Raymond Smullyan">
Raymond Smullyan

Raymond Merrill Smullyan (; born May 25, 1919) is an American mathematician, concert pianist, logician, Taoist philosopher, and magician.
Born in Far Rockaway, New York, his first career was stage magic. He then earned a BSc from the University of Chicago in 1955 and his Ph.D. from Princeton University in 1959. He is one of many logicians to have studied under Alonzo Church.
Life.
Born in Far Rockaway, New York, he showed musical talent, winning a gold medal in a piano competition when he was aged 12. The following year, his family moved to Manhattan and he attended Theodore Roosevelt High School in The Bronx as this school offered courses suited to his musical talents, but he left to study on his own as the school did not offer similar courses in mathematics. He attended several colleges, studying mathematics and music.
While a Ph.D. student, Smullyan published a paper in the 1957 "Journal of Symbolic Logic" showing that Gödelian incompleteness held for formal systems considerably more elementary than that of Gödel's 1931 landmark paper. The contemporary understanding of Gödel's theorem dates from this paper. Smullyan later made a compelling case that much of the fascination with Gödel's theorem should be directed at Tarski's theorem, which is much easier to prove and equally disturbing philosophically.
Smullyan is the author of many books on recreational mathematics and recreational logic. Most notably, one is titled "What Is the Name of This Book?" ISBN 0139550623.
He was a professor of philosophy at Lehman College and the Graduate Center, City University of New York, and at Indiana University. He is also an amateur astronomer, using a six inch reflecting telescope for which he ground the mirror.
Logic problems.
Many of his logic problems are extensions of classic puzzles. Knights and Knaves involves knights (who always tell the truth) and knaves (who always lie). This is based on a story of two doors and two guards, one who lies and one who tells the truth. One door leads to heaven and one to hell, and the puzzle is to find out which door leads to heaven by asking one of the guards a question. One way to do this is to ask "Which door would the other guard say leads to hell?". This idea was famously used in the 1986 film "Labyrinth".
In more complex puzzles, he introduces characters who may lie or tell the truth (referred to as "normals"), and furthermore instead of answering "yes" or "no", use words which mean "yes" or "no", but the reader does not know which word means which. The puzzle known as "the hardest logic puzzle ever" is based on these characters and themes. In his Transylvania puzzles, half of the inhabitants are insane, and believe only false things, whereas the other half are sane and believe only true things. In addition, humans always tell the truth, and vampires always lie. For example, an insane vampire will believe a false thing (2 + 2 is not 4) but will then lie about it, and say that it is. A sane vampire knows 2 + 2 is 4, but will lie and say it is not. And "mutatis mutandis" for humans. Thus everything said by a sane human or an insane vampire is true, while everything said by an insane human or a sane vampire is false.
His book "Forever Undecided" popularizes Gödel's incompleteness theorems by phrasing them in terms of reasoners and their beliefs, rather than formal systems and what can be proved in them. For example, if a native of a knight/knave island says to a sufficiently self-aware reasoner, "You will never believe that I am a knight", the reasoner cannot believe either that the native is a knight or that he is a knave without becoming inconsistent (i.e., holding two contradictory beliefs). The equivalent theorem is that for any formal system S, there exists a mathematical statement that can be interpreted as "This statement is not provable in formal system S". If the system S is consistent, neither the statement nor its opposite will be provable in it. See also Doxastic logic.
Inspector Craig is a frequent character in Smullyan's "puzzle-novellas." He is generally called into a scene of a crime that has a solution that is mathematical in nature. Then, through a series of increasingly harder challenges, he (and the reader) begin to understand the principles in question. Finally the novella culminates in Inspector Craig (and the reader) solving the crime, utilizing the mathematical and logical principles learned. Inspector Craig generally does not learn the formal theory in question, and Smullyan usually reserves a few chapters after the Inspector Craig adventure to illuminate the analogy for the reader. Inspector Craig gets his name from William Craig.
His book "To Mock a Mockingbird" (1985) is a recreational introduction to the subject of combinatory logic.
Apart from writing about and teaching logic, Smullyan has recently released a recording of his favorite classical piano pieces by composers such as Bach, Scarlatti, and Schubert. Some recordings are available on the Piano Society website, along with the video "Rambles, Reflections, Music and Readings". He has also written an autobiography titled "Some Interesting Memories: A Paradoxical Life" (ISBN 1-888710-10-1).
In 2001, documentary filmmaker Tao Ruspoli made a film about Smullyan called "".
Philosophy.
Smullyan has written several books about Taoist philosophy, which he believes neatly solves most or all traditional philosophical problems as well as integrating mathematics, logic, and philosophy into a cohesive whole.

</doc>
<doc id="56518" url="http://en.wikipedia.org/wiki?curid=56518" title="Wilderness area">
Wilderness area

A wilderness area is a region where the land is in a natural state; where impacts from human activities are minimal—that is, as a wilderness. It might also be called a "wild" or "natural" area. Especially in wealthier, industrialized nations, it has a specific legal meaning as well: as land where development is prohibited by law. Many nations have designated Wilderness Areas, including Australia, Canada, New Zealand, South Africa and the United States.
The WILD Foundation states that wilderness areas have two dimensions: they must be and . The World Conservation Union (IUCN) classifies wilderness at two levels, Ia (Strict Nature Preserves) and Ib (Wilderness areas). 
Most scientists and conservationists agree that no place on earth is completely untouched by humanity, either due to past occupation by indigenous people, or through global processes such as climate change. Activities on the margins of specific wilderness areas, such as fire suppression and the interruption of animal migration also affect the interior of wildernesses.
Wilderness areas by country.
Finland.
There are twelve wilderness areas in the Sami native region in northern Finnish Lapland. They are intended both to preserve the wilderness character of the areas and further the traditional livelihood of the Sami people. This means e.g. that reindeer husbandry, hunting and taking wood for use in the household is permitted. As population is very sparse, this is generally no big threat to the nature. Large scale reindeer husbandry has influence on the ecosystem, but no change is introduced by the act on wilderness areas. The World Commission on Protected Areas (WCPA) classifies the areas as "VI Protected area with sustainable use of natural resources".
New Zealand.
There are seven wilderness areas in New Zealand as defined by the National Parks Act 1980 and the Conservation Act 1987 that fall well within the IUCN definition. Wilderness areas cannot have any human intervention and can only have indigenous species re-introduced into the area if it is compatible with conservation management strategies.
United States.
In the United States, a Wilderness Area is an area of federal land set aside by an act of Congress. Human activities in wilderness areas are restricted to scientific study and non-mechanized recreation; horses are permitted but motorized vehicles and equipment are not.
International.
For a comprehensive review of wilderness areas by country, reference 

</doc>
<doc id="56519" url="http://en.wikipedia.org/wiki?curid=56519" title="Riding (country subdivision)">
Riding (country subdivision)

A riding is an administrative jurisdiction or electoral district, particularly in several current or former Commonwealth countries.
Etymology.
The word "riding" is descended from late Old English *"þriðing" or *"þriding" (recorded only in Latin contexts or forms, e.g., "trehing", "treding", "trithing", with Latin initial "t" here representing the Old English letter thorn). It came into Old English as a loanword from Old Norse "þriðjungr", meaning a third part (especially of a county), cf. farthing. The modern form "riding" was the result of initial "th" being absorbed in the final "th" or "t" of the words "north", "south", "east" and "west", by which it was normally preceded.
A common misconception holds that the term arose from some association between the size of the district and the distance that can be covered or encircled on horseback in a certain amount of time (cf. the Walking Purchase).
Norse states.
Ridings are originally Scandinavian institutions.
In Iceland the third part of a "thing" which corresponded roughly to an English county was called "þrithjungr". The island of Gotland and the Swedish province Närke were also divided into "þrithjungar" instead of hundreds.
In Norway (excluding Iceland) the "þrithjungr" seems to have been an ecclesiastical division.
England.
Yorkshire.
The ancient county of Yorkshire had three ridings, 
North, West and East, originally each subdivided into wapentakes.
The Yorkshire ridings were in many ways treated as separate administrative counties, having had separate quarter sessions and also separate lieutenancies since the Restoration. This practice was followed by the Local Government Act 1888, which made each of the three ridings an administrative county with an elected county council. These county councils, along with the ancient lieutenancies, were abolished in 1974 under the Local Government Act 1972.
A local government area East Riding of Yorkshire was created in 1996, but this does not cover the entire area of the former East Riding and includes areas from the historical West Riding.
According to the 12th century compilation known as the "Leges Edwardi Confessoris", the riding was the third part of a county ("provincia"); to it causes were brought which could not be determined in the wapentake, and a matter which could not be determined in the riding was brought into the court of the shire.
There is abundant evidence that riding courts were held after the Norman Conquest. A charter which Henry I granted to the Church of St Peters at York mentions "wapentacmot, tridingmot" and "shiresmot" (-mot designates popular assemblies), and exemptions from suit to the thriding or riding may be noticed frequently in the charters of the Norman kings. As yet, however, the jurisdiction and functions of these courts have not been ascertained. It seems probable from the silence of the records that they had already fallen into disuse early in the 13th century.
Although no longer having any administrative role the ridings of Yorkshire still play a part as cultural entities – they are used for the names of a number of groups and organisations and some people in Yorkshire associate themselves with one riding or another (see West Riding of Yorkshire#Current usage and Yorkshire Ridings Society). Winifred Holtby's 1936 novel "South Riding" and its adaptations were set in a fictional fourth riding. The title of the novel trilogy "Red Riding" by David Peace, set in Yorkshire, is a play on the word.
Elsewhere.
The Parts of Lindsey, one of the Parts of Lincolnshire, also possessed ridings, in this case the North, West, and South ridings.
Ireland.
County Tipperary in Ireland was divided in 1838 into two ridings, Tipperary North Riding and Tipperary South Riding – the divisions remained as local government counties, but were renamed simply 'North Tipperary' and 'South Tipperary' in 2002. They ceased to exist with the 2014 reforms of local government.
County Cork was divided into East and West Ridings in 1823. The ridings still exist for judicial purposes, and Garda (police) divisions are based on them. County Cork is divided for some purposes into the two ridings, with county councillors for the ridings meeting separately to perform certain functions. County Galway was also divided into east and west ridings.
Canada.
The term was used in 19th century Canada to refer to subdivisions of counties.
In Canadian politics, "riding" is a colloquial term for a constituency or electoral district. Officially, "electoral district" is generally used, although government documents sometimes use the colloquial term. In colloquial Canadian French, a riding is known as "comté", i.e., "county", as the electoral districts in Quebec were historically identical to its counties; the official French term is "circonscription".
The Canadian use of "riding" is derived from the English local government term, which was widely used in Canada in the 19th century. Most Canadian counties never had sufficient population to justify administrative subdivisions. Nonetheless, it was common, especially in Ontario, to divide counties with sufficient population into multiple electoral districts, which thus became known as "ridings" in official documents. The term was used in the legal description of the electoral districts of Canada West, which were grandfathered, by means of a schedule to the new constitution, as the electoral districts for the first elections to the new Canadian House of Commons, immediately following Confederation. Soon after Confederation, the urban population grew (and more importantly, most city dwellers gained the franchise after property ownership was no longer required to gain the vote). Rural constituencies therefore became geographically larger through the 20th century and generally encompassed one or more counties each, and the word "riding" was then used to refer to any electoral division.
The local association for a political party, which legally is known as an "electoral district association", is often referred to as a riding association.
Australia.
The term was used in Australia as a division of some Shire Councils, similar to a Ward in City, Borough, Town and many Shire councils.
New Zealand.
Ridings existed in rural New Zealand in the late 19th and early to mid 20th century as part of larger county councils in the area. For example, The Taranaki County Council was divided into three separate ridings: Moa (south), Omata (west) and Waitara (east).
As use of the automobile became more popular with the improvement of roads, combined with the concurrent trend of urban drift (c. 1950s), the ridings were either merged back into their parent councils or separated off into county councils in their own right. The Taranaki Country Council's three ridings eventually split, with the Omata Riding remaining part of the Taranaki County Council, the Moa riding merging with the Inglewood Borough Council and the Waitara Riding becoming part of the Clifton County Council.
In 1989 these were again merged reorganised into district and/or city councils. For example, the above three all merged with the New Plymouth Council and Waitara Borough Councils to form the New Plymouth District Council.
Examples:
See also.
The term farthing is analogous for quarters of a county. Gloucestershire was once divided into Farthings. In Tolkien's fictional world of Middle-earth, the Shire is divided into four Farthings, into the Fourth Age.

</doc>
<doc id="56520" url="http://en.wikipedia.org/wiki?curid=56520" title="Conservation easement">
Conservation easement

In the United States, a conservation easement (also called conservation covenant, conservation restriction or conservation servitude) is a power invested in a qualified private land conservation organization (often called a "land trust") or government (municipal, county, state or federal) to constrain, as to a specified land area, the exercise of rights otherwise held by a landowner so as to achieve certain conservation purposes. It is an interest in real property established by agreement between a landowner and land trust or unit of government. The conservation easement "runs with the land," meaning it is applicable to both present and future owners of the land. As with other real property interests, the grant of conservation easement is recorded in the local land records; the grant becomes a part of the chain of title for the property.
The conservation easement's purposes will vary depending on the character of the particular property, the goals of the land trust or government unit, and the needs of the landowners. For example, an easement’s purposes (often called "conservation objectives") might include any one or more of the following:
The conservation easement’s administrative terms for advancing the conservation objectives also vary but typically forbid or substantially constrain subdivision and other real estate development. 
The most distinguishing feature of the conservation easement as a conservation tool is that it enables users to achieve specific conservation objectives on the land while keeping the land in the ownership and control of landowners for uses consistent with the conservation objectives. 
The decision to place a conservation easement on a property is strictly a voluntary one whether the easement is sold or donated. The restrictions of the easement, once set in place, are perpetual (and potentially reduce the resale value of the associated property). Appraisals of the value of the easement, and financial arrangements between the parties (land owner and land trust), generally are kept private.
The landowner who grants a conservation easement continues to privately own and manage the land and may receive significant state and federal tax advantages for having donated and/or sold the conservation easement. Perhaps more importantly, the landowner has contributed to the public good by preserving the conservation values associated with their land for future generations. In accepting the conservation easement, the easement holder has a responsibility to monitor future uses of the land to ensure compliance with the terms of the easement and to enforce the terms if a violation occurs.
Although a conservation easement prohibits certain uses by the landowner, such an easement does not make the land public. On the contrary, many conservation easements confer no use of the land either to the easement holder or to the public. Furthermore, many conservation easements reserve to the landowner specific uses which if not reserved would be prohibited. Some conservation easements confer specific uses to the easement holder or to the public. These details are spelled out in the legal document that creates the conservation easement.
Income tax deductions.
Landowners in the United States who donate a "qualifying" conservation easement to a "qualified" land protection organization under the regulations set forth in 170(h) of the Internal Revenue Code may be eligible for a federal income tax deduction equal to the value of their donation. The value of the easement donation, as determined by a qualified appraiser, equals the difference between the fair market value of the property before and after the easement takes effect. 
To qualify for this income tax deduction, the easement must be: a) perpetual; b) held by a qualified governmental or non-profit organization; and, c) serve a valid "conservation purpose", meaning the property must have an appreciable natural, scenic, historic, scientific, recreational, or open space value. As a result of legislation signed by President George W. Bush on August 17, 2006 (H.R. 4 The Pensions Protection Act of 2006), in 2006 and 2007, conservation easement donors were able to deduct the value of their gift at the rate of 50% of their adjusted gross income (AGI) per year. Further, landowners with 50% or more of their income from agriculture were able to deduct the donation at a rate of 100% of their AGI. Any amount of the donation remaining after the first year could be carried forward for fifteen additional years (allowing a maximum of sixteen years within which the deduction may be utilized), or until the amount of the deduction has been used up, whichever comes first. With the passage of the Farm Bill in the summer of 2008 these expanded federal income tax incentives were extended such that they also apply to all conservation easements donated in 2008 and 2009 and then this provision was extended again to apply to donations in 2010 and 2011. The provision has since expired and currently for 2012, conservation easement donations may only be deducted at the rate of 30% of the donor's AGI and after the first year the donor has a five year carryforward.
Income tax credits (states).
Land conservation advocates have long tried to enact additional tax incentives for landowners to donate easements, above the federal charitable deduction (and state tax deduction in states that conform to federal tax process). There has been discussion of creating a federal income tax credit for easement donors since around 1980. However, no federal tax credit has been enacted. States, however, have moved ahead to grant credits that can be used to pay state income tax to donors of qualified conservation easements. In 1983, North Carolina became the first state to establish such a program.
Attorney Philip Tabas of The Nature Conservancy promoted the state tax credit idea widely in the 1990s. In 1999 four state legislatures enacted state tax credit programs (Virginia, Delaware, Colorado, and Connecticut, in that order). South Carolina and California followed in 2000. Several other states have followed since. 
For landowners with little income subject to state taxation, a tax credit is a hollow reward for reducing the value of real property by donating a conservation easement. To respond to this, Colorado conservationists made their state tax credit transferable in 2000—that is, the donor/landowner can sell her/his credit to other parties; the buyers then use the purchased tax credit to pay their Colorado income tax. This is appealing to buyers because the credit is sold at a discount from face value. Virginia followed by enacting transferability in 2002. Delegate Bill Howell (now Speaker of the Virginia House of Delegates) introduced HB1322, which had been suggested to him by conservationists Charles Davenport and Phil Hocker. HB1322 was enacted, effective retroactively to 1Jan2002. Other states have followed since. However, "caps" on the amount of credit an easement can generate, and other restrictions, limit the scope of the different state tax credit programs in varying manners.
In the states where credit for conservation land donations is transferable, free markets have arisen. Brokers assist landowners with excess credit to contact buyers, and the brokers often handle payments and paperwork to protect the principals, and to ensure that transfers are fully reported to the state tax authorities. The federal and state tax treatment of profits from sale and use of transferable tax credit have been the subject of extensive discussion and the issuance of several guidance documents by the Internal Revenue Service.
The New Mexico state income tax credit was originated in 2003.[SB 581] New transferability legislation, effective January 1, 2008, applies retroactively to conservation easements effected from January 1, 2004.
The Virginia transferable credit program is far the largest among the States in dollar value of property conserved. By the end of 2010, $2,512,000,000 of property value had been donated as easements in Virginia for which tax credit was claimed. The qualifying easements cover over 516,000 acre of Virginia landscape. The Virginia program now (2011) grants about $110 million of new tax credit each year. The credit allowance is 40% of the appraised value of the easement donation, so this equates to $275 million of property value donated per year for protection of wildlife habitat, farmland and woodland, and scenic open space—in perpetuity. The other state tax credit programs are smaller in dollar measurement, but are very significant in the area and the conservation values that they cause to be protected. The concept of state tax credit action (in the absence of a federal tax credit) that Philip Tabas and The Nature Conservancy promoted in the 1990s has borne remarkable fruit, and continues to expand today.
Estate tax reductions and exclusions.
For landowners who will leave sizable estates upon their death, the most important financial impact of a conservation easement may be a significant reduction in estate taxes. Estate taxes often make it difficult for heirs to keep land intact and in the family because of high estate tax rates and high development value of land. It may be necessary to subdivide or sell land for development in order to pay these taxes which may not be the desire of the landowner or their heirs. A conservation easement can often provide significant help with this problem in three important ways:
In Pennsylvania, conservation restrictions on land included in the estate can reduce the inheritance tax owed.
State and property tax incentives.
Some states (Colorado, Virginia, Maryland, and North Carolina) offer a state income tax incentive and many states offer property tax incentives to conservation easement donors. In Pennsylvania, conservation restrictions on land included in the estate can reduce the inheritance tax owed.
Purchase of Agricultural Conservation Easement programs.
In 1974, Suffolk County in New York enacted the first PACE (also known as purchase of development rights or PDR) program. King County in Washington and the states of Maryland, Massachusetts, and Connecticut quickly followed suit. As of 2003, the PACE program operates in 23 states, including 19 statewide and more than 45 local programs.

</doc>
<doc id="56522" url="http://en.wikipedia.org/wiki?curid=56522" title="Right-wing politics">
Right-wing politics

Right-wing politics are political positions or activities that view some forms of social stratification or social inequality as either inevitable, natural, normal, or desirable, typically justifying this position on the basis of natural law or tradition. Within the right-wing spectrum, views differ on whether hierarchy and inequality stem from traditional social differences or from competition in market economies. 
The term "right wing" has been used to refer to a number of different political positions through history. The political terms "Right" and "Left" were first used during the French Revolution (1789–99), and referred to where politicians sat in the French parliament; those who sat to the right of the chair of the parliamentary president were broadly supportive of the institutions of the monarchist "Ancien Régime". The original Right in France was formed as a reaction against the Left, and comprised those politicians supporting hierarchy, tradition, and clericalism. The use of the expression "la droite" ("the right") became prominent in France after the restoration of the monarchy in 1815, when "le droit" was applied to describe the Ultra-royalists. In English-speaking countries it was not until the 20th century that people applied the terms "right" and "left" to their own politics. From the 1830s to the 1880s, there was a shift in the Western world of social class structure and the economy, moving away from nobility and aristocracy, and moving towards the bourgeoisie and capitalism. This general economic shift towards capitalism affected centre right movements such as the British Conservative Party that responded by becoming supportive of capitalism.
Although the term 'right-wing' originally designated traditional conservatives and reactionaries, it has also been used to describe neo-conservatives, nationalists, racial supremacists, Christian democrats, religious fundamentalists, and classical liberals.
History.
The political term "right-wing" was first used during the French Revolution, when liberal deputies from the Third Estate generally sat to the left of the president's chair, a habit which began in the Estates General of 1789. The nobility, members of the Second Estate, generally sat to the right. In the successive legislative assemblies, monarchists who supported the Ancien Régime were commonly referred to as rightists, because they sat on the right side. A major figure on the right was Joseph de Maistre, who argued for an authoritarian form of conservatism. Throughout the 19th century, the main line dividing Left and Right in France was between supporters of the Republic and supporters of the Monarchy. On the right, the Legitimists and Ultra-royalists held counter-revolutionary views, while the Orléanists hoped to create a constitutional monarchy under their preferred branch of the royal family, a brief reality after the 1830 July Revolution. The centre-right Gaullists in post-World War II France advocated considerable social spending on education and infrastructure development, as well as extensive economic regulation, but limited the wealth redistribution measures characteristic of social democracy.
In British politics the terms 'right' and 'left' came into common use for the first time in the late 1930s in debates over the Spanish Civil War. In the United States "right wing" has quite a different history and meaning. For the most part the American right wing is an integral part of the conservative "movement" in the U.S. The right has been a major factor—and often dominant—in American politics in the Age of Reagan since 1980. There are also fringe "extremist" elements who reject key elements of the American consensus, are vehemently opposed to the nation's political leadership, and try to exclude groups they hate, sometimes by using violence.
The Right has gone through five distinct historical stages: (i) the reactionary right, which sought a return to aristocracy and established religion; (ii) the moderate right, who sought limited government and distrusted intellectuals; (iii) the radical right, who favored a romantic and aggressive nationalism; (iv) the extreme right, who proposed anti-immigration policies and implicit racism; and (v) the neo-liberal right, who sought to combine a belief in a market economy and economic deregulation with the traditional Right-wing beliefs in patriotism, élitism, and law and order.
Positions.
The meaning of right-wing "varies across societies, historical epochs, and political systems and ideologies." According to "The Concise Oxford Dictionary of Politics", in liberal democracies, the political Right opposes socialism and social democracy. Right-wing parties include conservatives, Christian democrats, classical liberals, nationalists and, on the far Right, racists and fascists.
Roger Eatwell and O'Sullivan divide the Right into five types: 'reactionary', 'moderate', 'radical', 'extreme', and 'new'. Chip Berlet argues that each of these "styles of thought" are "responses to the left", including liberalism and socialism, that have arisen since the 1789 French Revolution. The 'reactionary right' looks toward the past and is "aristocratic, religious and authoritarian". The 'moderate right', typified by the writings of Edmund Burke, is tolerant of change, provided it is gradual, and accepts some aspects of liberalism, including the rule of law and capitalism, although it sees radical laissez-faire and individualism as harmful to society. Often the moderate right promotes nationalism and social welfare policies. 'Radical right' is a term developed after World War II to describe groups and ideologies such as McCarthyism, the John Birch Society, Thatcherism, and the Republikaner Party. Eatwell stresses that this use has "major typological problems" and that the term "has also been applied to clearly democratic developments." The radical right includes right-wing populism and various other subtypes. Eatwell argues that the 'extreme right' has four traits: "1)anti-democracy; 2) nationalism; 3) racism; and 4) the strong state". The 'New Right' consists of the liberal conservatives, who stress small government, free markets, and individual initiative.
Other authors make a distinction between the centre-right and the far right. Parties of the centre-right generally support liberal democracy, capitalism, the market economy (though they may accept government regulation to control monopolies), private property rights, and a limited welfare state (for example government provision of education and medical care). They support conservatism and economic liberalism, and oppose socialism and communism. The phrase "far right", by contrast, is used to describe those who favor an absolutist government, which uses the power of the state to support the dominant ethnic group or religion and often to criminalize other ethnic groups or religions. Typical examples of leaders to whom the "far right" label is often applied are Francisco Franco in Spain and Augusto Pinochet in Chile. The US Department of Homeland Security defines right-wing extremism as hate groups who target racial, ethnic or religious minorities and may be dedicated to a single issue. The phrase is also used to describe support for ethnic nationalism.
Anti-communism.
The original use of "right-wing" in reference to communism had the conservatives on the Right, the liberals in the center, and the communists on the Left. Both the conservatives and the liberals were strongly anti-communist. As time went on, however, conservatives accused liberals of being "soft on communism", and using freedom of speech and freedom of religion as a cover for their hidden communist sympathies. The history of the use of the term "right-wing" to mean anti-communist is a complicated one.
Early Marxist movements were at odds with the traditional monarchies that ruled over much of the European continent at the time. Many European monarchies outlawed the public expression of communist views, and the Communist Manifesto, which began "A spectre is haunting Europe," stated that monarchs feared for their thrones. Advocacy of communism was illegal in the Russian Empire, the German Empire and Austria-Hungary, the three most powerful monarchies in continental Europe prior to World War I. Many Monarchists (except Constitutional Monarchists) viewed inequality in wealth and political power as resulting from a divine natural order. The struggle between monarchists and communists was often described as a struggle between the Right and the Left.
By World War I however, in most European monarchies, the Divine Right of Kings had become discredited and replaced by liberal and nationalist movements. Most European monarchs became figureheads; elected governments held the real power. The most conservative European monarchy, the Russian Empire, was replaced by the communist Soviet Union. The Russian Revolution inspired a series of other communist revolutions across Europe in the years 1917–1922. Many of these, such as the German Revolution, were defeated by nationalist and monarchist military units. In this period, nationalism began to be considered right-wing, especially when it opposed the internationalism of the communists.
The 1920s and 1930s saw the fading of traditional right-wing politics. The mantle of conservative anti-communism was taken up by the rising fascist movements on the one hand, and by American-inspired liberal conservatives on the other. When communist groups and political parties began appearing around the world, as in the Republic of China in the 1920s, their opponents were usually colonial authorities, and the term right-wing came to be applied to colonialism.
After World War II, communism became a global phenomenon, and anti-communism became an integral part of the domestic and foreign policies of the United States and its NATO allies. Conservatism in the post-war era abandoned its monarchist and aristocratic roots, focusing instead on patriotism, religion, and nationalism. Throughout the Cold War, colonial governments in Asia, Africa, and Latin America turned to the United States for political and economic support. Communists were also enemies of capitalism, portraying Wall Street as the oppressor of the masses. The United States made anti-communism the top priority of its foreign policy, and many American conservatives sought to combat what they saw as communist influence at home. This led to the adoption of a number of domestic policies that are collectively known under the term "McCarthyism". While both liberals and conservatives were anti-communist, the followers of Senator McCarthy were called right-wing, and those on the Right called liberals who favored free speech, even for communists, leftist.
Economics.
In France after the French Revolution, the Right fought against the rising power of those who had grown rich through commerce, and sought to preserve the rights of the hereditary nobility. They were uncomfortable with capitalism, with the Enlightenment, with individualism, and with industrialism and fought to retain traditional social hierarchies and institutions.
In the 19th century, the Right had shifted to support the newly rich in some European countries, particularly England, and instead of favouring the nobility over industrialists, favoured capitalists over the working class. Other right-wing currents on the Continent, such as Carlism in Spain and nationalist movements in France, Germany, and Russia, remained hostile to capitalism and industrialism. There are, however, still a few right-wing movements today, notably the French Nouvelle Droite, CasaPound, and American paleoconservatives, that are often in opposition to capitalist ethics and the effects they have on society as a whole, which they see as infringing upon or causing the decay of social traditions or hierarchies that they see as essential for social order.
In modern times, "right-wing" is sometimes used to describe laissez-faire capitalism. In Europe, capitalists formed alliances with the Right during their conflicts with workers after 1848. In France, the Right's support of capitalism can be traced to the late 19th century. The so-called neoliberal Right, popularized by Ronald Reagan and Margaret Thatcher, combines support for free markets, privatisation, and deregulation with traditional right-wing support for social conformity. Right-wing libertarianism (sometimes known as libertarian conservatism or conservative libertarianism) supports a decentralized economy based on economic freedom, and holds property rights, free markets and free trade to be the most important kinds of freedom. Russell Kirk believed that freedom and property rights were interlinked. Anthony Gregory has written that right-wing libertarianism, "can refer to any number of varying and at times mutually exclusive political orientations." He holds that the issue is not right or left but "whether a person sees the state as a major hazard or just another institution to be reformed and directed toward a political goal."
Conservative authoritarians and those on the far right have supported fascism and corporatism.
Nationalism.
In France, nationalism was originally a left-wing and Republican ideology. After the period of "boulangisme" and the Dreyfus Affair nationalism became a trait of the right-wing . Right-wing nationalists sought to define and defend a "true" national identity from elements deemed to be corrupting that identity. Some were supremacists who, in accordance with Social Darwinism, applied the concept of "survival of the fittest" to nations and races. Right-wing nationalism was influenced by romantic nationalism, in which the state derives its political legitimacy from the organic unity of those it governs. This generally includes, the language, race, culture, religion and customs of the "nation", all of which were "born" within its culture. Linked with right-wing nationalism is cultural conservatism, which supports the preservation of the heritage of a nation or culture, and often sees deviations from cultural norms as an existential threat.
Natural law and traditionalism.
Right-wing politics typically justifies a hierarchical society on the basis of natural law or tradition.
Traditionalism was advocated by a group of U.S. university professors (labeled the "New Conservatives" by the popular press) who rejected the concepts of individualism, liberalism, modernity, and social progress, and sought instead to promote what they identify as cultural and educational renewal, and a revived interest in what T. S. Eliot referred to as "the permanent things" (concepts perceived by traditionalists as truths that endure from age to age alongside basic institutions of western society such as the church, the family, the state, and business.)
Populism.
Right-wing populism is a combination of ethno-nationalism with anti-elitism, using populist rhetoric to provide a radical critique of existing political institutions. According to Margaret Canovan, a right-wing populist is "...a charismatic leader, using the tactics of politicians’ populism to go past the politicians and intellectual elite and appeal to the reactionary sentiments of the populace, often buttressing his claim to speak for the people by the use of referendums."
In Europe, right-wing populism often takes the form of distrust of the European Union, and of politicians in general, combined with anti-immigrant rhetoric, and a call for a return to traditional, national values.
Religion.
Government support for an established religion was associated with the original French "right wing." Joseph de Maistre argued for the indirect authority of the Pope over temporal matters. According to Maistre, only governments founded upon a Christian constitution, implicit in the customs and institutions of all European societies but especially in Catholic European monarchies, could avoid the disorder and bloodshed that followed the implementation of rationalist political programs, as in the French Revolution. The Church of England was established by Henry VIII. Some churchmen are given seats in the House of Lords but are considered politically neutral, rather than right or left wing.
Religious fundamentalists frequently feel that governments should enact laws supporting their religious tenets. The Christian right is a major force in North America. They generally support laws upholding what they consider religious values, such as opposition to abortion, contraception, sex outside marriage, and to same-sex marriage, and reject scientific positions on evolution and other matters where science disagrees with the Bible. Outside the West, other religious and ethnic groups are considered right-wing. In India, Hindu nationalism is sometimes considered a part of the Right. The Hindu nationalist movement has attracted privileged groups fearing encroachment on their dominant positions, and also "plebeian" and impoverished groups seeking recognition around a majoritarian rhetoric of cultural pride, order, and national strength. Many Islamist groups have been called "right wing" including the Great Union Party, and the Combatant Clergy Association/Association of Militant Clergy and the Islamic Society of Engineers of Iran.
The term "family values" has been used as a buzzword by right-wing parties such as the Republican Party in the United States, the Family First Party in Australia, the Conservative party in the United Kingdom and the Bharatiya Janata Party in India to describe support for traditional families, and opposition to the changes the modern world has made in how families live. Right-wing supporters of "family values" may oppose abortion, euthanasia, homosexuality, and adultery.
Social stratification.
Right-wing politics involves in varying degrees the rejection of some egalitarian objectives of left-wing politics, claiming either that economic inequality is natural and inevitable or that it is beneficial to society.
Right-wing ideologies and movements support social order. The original French right-wing was called "the party of order" and held that France needed a strong political leader to keep order. In Europe's history, there have been strong collectivist right-wing movements, such as in the social Catholic Right that has exhibited hostility to all forms of liberalism, including economic liberalism, and has historically advocated for paternalist class harmony involving an organic-hierarchical society where workers are protected while hierarchy of classes remain.
British conservative scholar R. J. White, who rejects egalitarianism, wrote: "Men are equal before God and the laws, but unequal in all else; hierarchy is the order of nature, and privilege is the reward of honourable service". American conservative Russell Kirk also rejected egalitarianism as imposing sameness, stating: "Men are created different; and a government that ignores this law becomes an unjust government for it sacrifices nobility to mediocrity". He took as one of the "canons" of conservatism the principle that "civilized society requires orders and classes".
Right libertarians reject collective or state-imposed equality as undermining reward for personal merit, initiative, and enterprise. In their view, it is unjust, limits personal freedom, and leads to social uniformity and mediocrity. Left-libertarians, however, argue that "equality does not mean an equal amount but equal opportunity... Free opportunity and acting out your individuality means development of natural dissimilarities and variations". In their view, freedom without equality gives more freedom to those at a higher social status, and equality without freedom is a form of oppression.

</doc>
<doc id="56524" url="http://en.wikipedia.org/wiki?curid=56524" title="Fats">
Fats

Fats or FATS may refer to:
Persons with the nickname:
FATS:

</doc>
<doc id="56525" url="http://en.wikipedia.org/wiki?curid=56525" title="Triglyceride">
Triglyceride

A triglyceride (TG, triacylglycerol, TAG, or triacylglyceride) is an ester derived from glycerol and three fatty acids. As a blood lipid, it helps enable the bidirectional transference of adipose fat and blood glucose from the liver. There are many triglycerides: depending on the oil source, some are highly unsaturated, some less so.
Saturated compounds are "saturated" with hydrogen — all available places where hydrogen atoms could be bonded to carbon atoms are occupied. Unsaturated compounds have double bonds (C=C) between carbon atoms, reducing the number of places where hydrogen atoms can bond to carbon atoms. Saturated compounds have single bonds (C-C) between the carbon atoms, and the other bond is bound to hydrogen atoms (for example =CH-CH=, -CH2-CH2-, etc.).
Unsaturated fats have a lower melting point and are more likely to be liquid at room temperature. Saturated fats have a higher melting point and are more likely to be solid at room temperature.
Triglycerides are the main constituents of vegetable oil (typically more unsaturated) and animal fats (typically more saturated). Triglycerides are a major component of human skin oils.
Chemical structure.
Triglycerides are formed by combining glycerol with three fatty acid molecules. Alcohols have a hydroxyl (HO-) group. Organic acids have a carboxyl (-COOH) group. Alcohols and organic acids join to form esters. The glycerol molecule has three hydroxyl (HO-) groups. Each fatty acid has a carboxyl group (-COOH). In triglycerides, the hydroxyl groups of the glycerol join the carboxyl groups of the fatty acid to form ester bonds:
The three fatty acids (RCO2H, R'CO2H, R"CO2H in the above equation) are usually different, but many kinds of triglycerides are known. The chain lengths of the fatty acids in naturally occurring triglycerides vary, but most contain 16, 18, or 20 carbon atoms. Natural fatty acids found in plants and animals are typically composed of only even numbers of carbon atoms, reflecting the pathway for their biosynthesis from the two-carbon building-block acetyl CoA. Bacteria, however, possess the ability to synthesise odd- and branched-chain fatty acids. As a result, ruminant animal fat contains odd-numbered fatty acids, such as 15, due to the action of bacteria in the rumen. Many fatty acids are unsaturated, some are polyunsaturated, e.g., those derived from linoleic acid.
Most natural fats contain a complex mixture of individual triglycerides. Because of this, they melt over a broad range of temperatures. Cocoa butter is unusual in that it is composed of only a few triglycerides, derived from palmitic, oleic, and stearic acids.
Metabolism.
The
pancreatic lipase acts at the ester bond, hydrolysing the bond and "releasing" the fatty acid. In triglyceride form, lipids cannot be absorbed by the duodenum. Fatty acids, monoglycerides (one glycerol, one fatty acid), and some diglycerides are absorbed by the duodenum, once the triglycerides have been broken down.
In the intestine, following the secretion of lipases and bile, triglycerides are split into monoacylglycerol and free fatty acids in a process called lipolysis. They are subsequently moved to absorptive enterocyte cells lining the intestines. The triglycerides are rebuilt in the enterocytes from their fragments and packaged together with cholesterol and proteins to form chylomicrons. These are excreted from the cells and collected by the lymph system and transported to the large vessels near the heart before being mixed into the blood. Various tissues can capture the chylomicrons, releasing the triglycerides to be used as a source of energy. Liver cells can synthesize and store triglycerides. When the body requires fatty acids as an energy source, the hormone glucagon signals the breakdown of the triglycerides by hormone-sensitive lipase to release free fatty acids. As the brain cannot utilize fatty acids as an energy source (unless converted to a ketone), the glycerol component of triglycerides can be converted into glucose, via gluconeogenesis by conversion into Dihydroxyacetone phosphate and then into Glyceraldehyde 3-phosphate, for brain fuel when it is broken down. Fat cells may also be broken down for that reason, if the brain's needs ever outweigh the body's.
Triglycerides cannot pass through cell membranes freely. Special enzymes on the walls of blood vessels called lipoprotein lipases must break down triglycerides into free fatty acids and glycerol. Fatty acids can then be taken up by cells via the fatty acid transporter (FAT).
Triglycerides, as major components of very-low-density lipoprotein (VLDL) and chylomicrons, play an important role in metabolism as energy sources and transporters of dietary fat. They contain more than twice as much energy (approximately 9 kcal/g or 38 kJ/g ) as carbohydrates (approximately 4 kcal/g or 17 kJ/g ).
Role in disease.
In the human body, high levels of triglycerides in the bloodstream have been linked to atherosclerosis and, by extension, the risk of heart disease and stroke. However, the relative negative impact of raised levels of triglycerides compared to that of LDL:HDL ratios is as yet unknown. The risk can be partly accounted for by a strong inverse relationship between triglyceride level and HDL-cholesterol level.
Guidelines.
The National Cholesterol Education Program has set guidelines for triglyceride levels:
These levels are tested after fasting 8 to 12 hours. Triglyceride levels remain temporarily higher for a period of time after eating.
The American Heart Association recommends an optimal triglyceride level of 100 mg/dL (1.1 mmol/L) or lower to improve heart health.
Reducing triglyceride levels.
Diets high in refined carbohydrates, with carbohydrates accounting for more than 60% of the total energy intake, can increase triglyceride levels. Of note is how the correlation is stronger for those with higher BMI (28+) and insulin resistance (more common among overweight and obese) is a primary suspect cause of this phenomenon of carbohydrate-induced hypertriglyceridemia.
There is evidence that carbohydrate consumption causing a high glycemic index can cause insulin overproduction and increase triglyceride levels in women.
Adverse changes associated with carbohydrate intake, including triglyceride levels, are stronger risk factors for heart disease in women than in men.
Triglyceride levels are also reduced by moderate exercise and by consuming omega-3 fatty acids from fish, flax seed oil, and other sources.
Carnitine has the ability to lower blood triglyceride levels. In some cases, fibrates have been used to bring down triglycerides substantially. AstraZeneca has developed Epanova (omega-3-carboxylic acids) to treat high triglycerides.
Heavy alcohol consumption can elevate triglycerides levels.
Industrial uses.
Linseed oil and related oils are important components of useful products used in oil paints and related coatings. Linseed oil is rich in di- and triunsaturated fatty acid components, which tend to harden in the presence of oxygen. This heat-producing hardening process is peculiar to these so-called "drying oils". It is caused by a polymerization process that begins with oxygen molecules attacking the carbon backbone.
Triglycerides are also split into their components via transesterification during the manufacture of biodiesel. The resulting fatty acid esters can be used as fuel in diesel engines. The glycerin has many uses, such as in the manufacture of food and in the production of pharmaceuticals.
Staining.
Staining for fatty acids, triglycerides, lipoproteins, and other lipids is done through the use of lysochromes (fat-soluble dyes). These dyes can allow the qualification of a certain fat of interest by staining the material a specific color. Some examples: Sudan IV, Oil Red O, and Sudan Black B.
Interactive pathway map.
"Click on genes, proteins and metabolites below to link to respective articles." 
Statin Pathway 

</doc>
<doc id="56526" url="http://en.wikipedia.org/wiki?curid=56526" title="Diabetic ketoacidosis">
Diabetic ketoacidosis

Diabetic ketoacidosis (DKA) is a potentially life-threatening complication in patients with diabetes mellitus. It happens predominantly in those with type 1 diabetes, but it can occur in those with type 2 diabetes under certain circumstances. DKA results from a shortage of insulin; in response the body switches to burning fatty acids and producing acidic ketone bodies that cause most of the symptoms and complications.
DKA may be the first symptom of previously undiagnosed diabetes, but it may also occur in people known to have diabetes as a result of a variety of causes, such as intercurrent illness or poor compliance with insulin therapy. Vomiting, dehydration, deep gasping breathing, confusion and occasionally coma are typical symptoms. DKA is diagnosed with blood and urine tests; it is distinguished from other, rarer forms of ketoacidosis by the presence of high blood sugar levels. Treatment involves intravenous fluids to correct dehydration, insulin to suppress the production of ketone bodies, treatment for any underlying causes such as infections, and close observation to prevent and identify complications.
DKA is a medical emergency, and without treatment it can lead to death. DKA was first described in 1886; until the introduction of insulin therapy in the 1920s it was almost universally fatal. It now carries a mortality of less than 1% with adequate and timely treatment.
Signs and symptoms.
The symptoms of an episode of diabetic ketoacidosis usually evolve over the period of about 24 hours. Predominant symptoms are nausea and vomiting, pronounced thirst, excessive urine production and abdominal pain that may be severe. Those who measure their glucose levels themselves may notice hyperglycemia (high blood sugar levels). In severe DKA, breathing becomes labored and of a deep, gasping character (a state referred to as "Kussmaul respiration"). The abdomen may be tender to the point that an acute abdomen may be suspected, such as acute pancreatitis, appendicitis or gastrointestinal perforation. Coffee ground vomiting (vomiting of altered blood) occurs in a minority of patients; this tends to originate from erosion of the esophagus. In severe DKA, there may be confusion, lethargy, stupor or even coma (a marked decrease in the level of consciousness).
On physical examination there is usually clinical evidence of dehydration, such as a dry mouth and decreased skin turgor. If the dehydration is profound enough to cause a decrease in the circulating blood volume, tachycardia (a fast heart rate) and low blood pressure may be observed. Often, a "ketotic" odor is present, which is often described as "fruity". If Kussmaul respiration is present, this is reflected in an increased respiratory rate.
Small children with DKA are relatively prone to cerebral edema (swelling of the brain tissue), which may cause headache, coma, loss of the pupillary light reflex, and progress to death. It occurs in 0.3–1.0% of children with DKA, and has been described in young adults, but is overall very rare in adults. It carries a 20–50% mortality.
Cause.
DKA most frequently occurs in those who already have diabetes, but it may also be the first presentation in someone who had not previously been known to be diabetic. There is often a particular underlying problem that has led to the DKA episode; this may be intercurrent illness (pneumonia, influenza, gastroenteritis, a urinary tract infection), pregnancy, inadequate insulin administration (e.g. defective insulin pen device), myocardial infarction (heart attack), stroke or the use of cocaine. Young patients with recurrent episodes of DKA may have an underlying eating disorder, or may be using insufficient insulin for fear that it will cause weight gain.
Diabetic ketoacidosis may occur in those previously known to have diabetes mellitus type 2 or in those who on further investigations turn out to have features of type 2 diabetes (e.g. obesity, strong family history); this is more common in African, African-American and Hispanic people. Their condition is then labeled "ketosis-prone type 2 diabetes".
Mechanism.
Diabetic ketoacidosis arises because of a lack of insulin in the body. The lack of insulin and corresponding elevation of glucagon leads to increased release of glucose by the liver (a process that is normally suppressed by insulin) from glycogen via glycogenolysis and also through gluconeogenesis. High glucose levels spill over into the urine, taking water and solutes (such as sodium and potassium) along with it in a process known as osmotic diuresis. This leads to polyuria, dehydration, and compensatory thirst and polydipsia. The absence of insulin also leads to the release of free fatty acids from adipose tissue (lipolysis), which are converted, again in the liver, into ketone bodies (acetoacetate and β-hydroxybutyrate). β-Hydroxybutyrate can serve as an energy source in the absence of insulin-mediated glucose delivery, and is a protective mechanism in case of starvation. The ketone bodies, however, have a low pKa and therefore turn the blood acidic (metabolic acidosis). The body initially buffers the change with the bicarbonate buffering system, but this system is quickly overwhelmed and other mechanisms must work to compensate for the acidosis. One such mechanism is hyperventilation to lower the blood carbon dioxide levels (a form of compensatory respiratory alkalosis). This hyperventilation, in its extreme form, may be observed as Kussmaul respiration.
In various situations such as infection, insulin demands rise but are not matched by the failing pancreas. Blood sugars rise, dehydration ensues, and resistance to the normal effects of insulin increases further by way of a vicious circle.
As a result of the above mechanisms, the average adult DKA patient has a total body water shortage of about 6 liters (or 100 mL/kg), in addition to substantial shortages in sodium, potassium, chloride, phosphate, magnesium and calcium. Glucose levels usually exceed 13.8 mmol/L or 250 mg/dL.
DKA is common in type 1 diabetes as this form of diabetes is associated with an absolute lack of insulin production by the islets of Langerhans. In type 2 diabetes, insulin production is present but is insufficient to meet the body's requirements as a result of end-organ insulin resistance. Usually, these amounts of insulin are sufficient to suppress ketogenesis. If DKA occurs in someone with type 2 diabetes, their condition is called "ketosis-prone type 2 diabetes". The exact mechanism for this phenomenon is unclear, but there is evidence both of impaired insulin secretion and insulin action. Once the condition has been treated, insulin production resumes and often the patient may be able to resume diet or tablet treatment as normally recommended in type 2 diabetes.
The clinical state of DKA is associated, in addition to the above, with the release of various counterregulatory hormones such as glucagon and adrenaline as well as cytokines, the latter of which leads to increased markers of inflammation, even in the absence of infection.
Cerebral edema, which is the most dangerous DKA complication, is probably the result of a number of factors. Some authorities suggest that it is the result from overvigorous fluid replacement, but the complication may develop before treatment has been commenced. It is more likely in those with more severe DKA, and in the first episode of DKA. Likely factors in the development of cerebral edema are dehydration, acidosis and low carbon dioxide levels; in addition, the increased level of inflammation and coagulation may, together with these factors, lead to decreased blood flow to parts of the brain, which then swells up once fluid replacement has been commenced. The swelling of brain tissue leads to raised intracranial pressure ultimately leading to death.
Diagnosis.
Investigations.
Diabetic ketoacidosis may be diagnosed when the combination of hyperglycemia (high blood sugars), ketones in the blood or on urinalysis and acidosis are demonstrated. Arterial blood gas measurement is usually performed to demonstrate the acidosis; this requires taking a blood sample from an artery. Subsequent measurements (to ensure treatment is effective), may be taken from a normal blood test taken from a vein, as there is little difference between the arterial and the venous pH. Ketones can be measured in the urine (acetoacetate) and blood (β-hydroxybutyrate). When compared with urine acetoacetate testing, blood β-hydroxybutyrate determination can reduce the need of admission, shorten the duration of hospital admission and potentially reduce the costs of hospital care.
In addition to the above, blood samples are usually taken to measure urea and creatinine (measures of kidney function, which may be impaired in DKA as a result of dehydration) and electrolytes. Furthermore, markers of infection (complete blood count, C-reactive protein) and acute pancreatitis (amylase and lipase) may be measured. Given the need to exclude infection, chest radiography and urinalysis are usually performed.
If cerebral edema is suspected because of confusion, recurrent vomiting or other symptoms, computed tomography may be performed to assess its severity and to exclude other causes such as stroke.
Criteria.
Diabetic ketoacidosis is distinguished from other diabetic emergencies by the presence of large amounts of ketones in blood and urine, and marked metabolic acidosis. Hyperosmolar hyperglycemic state (HHS, sometimes labeled "hyperosmolar non-ketotic state" or HONK) is much more common in type 2 diabetes and features increased plasma osmolarity (above 320 mosm/kg) due to profound dehydration and concentration of the blood; mild acidosis and ketonemia may occur in this state, but not to the extent observed in DKA. There is a degree of overlap between DKA and HHS, as in DKA the osmolarity may also be increased.
Ketoacidosis is not always the result of diabetes. It may also result from alcohol excess and from starvation; in both states the glucose level is normal or low. Metabolic acidosis may occur in people with diabetes for other reasons, such as poisoning with ethylene glycol or paraldehyde.
The American Diabetes Association categorizes DKA in adults into one of three stages of severity:
A 2004 statement by the European Society for Paediatric Endocrinology and the Lawson Wilkins Pediatric Endocrine Society (for children) uses slightly different cutoffs, where mild DKA is defined by pH 7.20–7.30 (bicarbonate 10–15 mmol/l), moderate DKA by pH 7.1–7.2 (bicarbonate 5–10) and severe DKA by pH<7.1 (bicarbonate below 5).
Prevention.
Attacks of DKA can be prevented in those known to have diabetes to an extent by adherence to "sick day rules"; these are clear-cut instructions to patients on how to treat themselves when unwell. Instructions include advice on how much extra insulin to take when sugar levels appear uncontrolled, an easily digestible diet rich in salt and carbohydrates, means to suppress fever and treat infection, and recommendations when to call for medical help.
Management.
The main aims in the treatment of diabetic ketoacidosis are replacing the lost fluids and electrolytes while suppressing the high blood sugars and ketone production with insulin. Admission to an intensive care unit or similar high-dependency area or ward for close observation may be necessary.
Fluid replacement.
The amount of fluid replaced depends on the estimated degree of dehydration. If dehydration is so severe as to cause shock (severely decreased blood pressure with insufficient blood supply to the body's organs), or a depressed level of consciousness, rapid infusion of saline (1 liter for adults, 10 ml/kg in repeated doses for children) is recommended to restore circulating volume. Slower rehydration based on calculated water and sodium shortage may be possible if the dehydration is moderate, and again saline is the recommended fluid. Very mild ketoacidosis with no associated vomiting and mild dehydration may be treated with oral rehydration and subcutaneous rather than intravenous insulin under observation for signs of deterioration.
A special but unusual consideration is cardiogenic shock, where the blood pressure is decreased not due to dehydration but due to inability of the heart to pump blood through the blood vessels. This situation requires ICU admission, monitoring of the central venous pressure (which requires the insertion of a central venous catheter in a large upper body vein), and the administration of medication that increases the heart pumping action and blood pressure.
Insulin.
Some guidelines recommend a bolus (initial large dose) of insulin of 0.1 unit of insulin per kilogram of body weight. This can be administered immediately after the potassium level is known to be higher than 3.3 mmol/l; if the level is any lower, administering insulin could lead to a dangerously low potassium level (see below). Other guidelines recommend delaying the initiation of insulin until fluids have been administered.
In general, insulin is given at 0.1 unit/kg per hour to reduce the blood sugars and suppress ketone production. Guidelines differ as to which dose to use when blood sugar levels start falling; some recommend reducing the dose of insulin once glucose falls below 16.6 mmol/l (300 mg/dl) but other recommend infusing glucose in addition to saline to allow for ongoing infusion of higher doses of insulin.
Potassium.
Potassium levels can fluctuate severely during the treatment of DKA, because insulin decreases potassium levels in the blood by redistributing it into cells. A large part of the shifted extracellular potassium would have been lost in urine because of osmotic diuresis. Hypokalemia (low blood potassium concentration) often follows treatment. This increases the risk of dangerous irregularities in the heart rate. Therefore, continuous observation of the heart rate is recommended, as well as repeated measurement of the potassium levels and addition of potassium to the intravenous fluids once levels fall below 5.3 mmol/l. If potassium levels fall below 3.3 mmol/l, insulin administration may need to be interrupted to allow correction of the hypokalemia.
Bicarbonate.
The administration of sodium bicarbonate solution to rapidly improve the acid levels in the blood is controversial. There is little evidence that it improves outcomes beyond standard therapy, and indeed some evidence that while it may improve the acidity of the blood, it may actually worsen acidity inside the body's cells and increase the risk of certain complications. Its use is therefore discouraged, although some guidelines recommend it for extreme acidosis (pH<6.9), and smaller amounts for severe acidosis (pH 6.9–7.0).
Cerebral edema.
Cerebral edema, if associated with coma, often necessitates admission to intensive care, artificial ventilation, and close observation. The administration of fluids is slowed. The ideal treatment of cerebral edema in DKA is not established, but intravenous mannitol and hypertonic saline (3%) are used—as in some other forms of cerebral edema—in an attempt to reduce the swelling.
Resolution.
Resolution of DKA is defined as general improvement in the symptoms, such as the ability to tolerate oral nutrition and fluids, normalization of blood acidity (pH>7.3), and absence of ketones in blood (<1 mmol/l) or urine. Once this has been achieved, insulin may be switched to the usual subcutaneously administrered regimen, one hour after which the intravenous administration can be discontinued.
In patients with suspected ketosis-prone type 2 diabetes, determination of antibodies against glutamic acid decarboxylase and islet cells may aid in the decision whether to continue insulin administration long-term (if antibodies are detected), or whether to withdraw insulin and attempt treatment with oral medication as in type 2 diabetes.
Epidemiology.
Diabetic ketoacidosis occurs in 4.6–8.0 per 1000 people with type 1 diabetes annually. In the United States, 135,000 hospital admissions occur annually as a result of DKA, at an estimated cost of $2.4 billion or a quarter to a half the total cost of caring for people with type 1 diabetes. There has been a documented increasing trend to hospital admissions. The risk is increased in those with an ongoing risk factor, such as an eating disorder, and those who cannot afford insulin. About 30% of children with type 1 diabetes receive their diagnosis after an episode of DKA.
History.
The first full description of diabetic ketoacidosis is attributed to Julius Dreschfeld, a German pathologist working in Manchester, United Kingdom. In his description, which he gave in an 1886 lecture at the Royal College of Physicians in London, he drew on reports by Adolph Kussmaul as well as describing the main ketones, acetoacetate and β-hydroxybutyrate, and their chemical determination. The condition remained almost universally fatal until the discovery of insulin in the 1920s; by the 1930s, mortality had fallen to 29%, and by the 1950s it had become less than 10%. The entity of cerebral edema due to DKA was described in 1936 by a team of doctors from Philadelphia.
Numerous research studies since the 1950s have focused on the ideal treatment for diabetic ketoacidosis. A significant proportion of these studies have been conducted at the University of Tennessee Health Science Center and Emory University School of Medicine. Treatment options studied have included high- or low-dose intravenous, subcutaneous or intramuscular (e.g. the "Alberti regime") insulin, phosphate supplementation, need for a loading dose of insulin, and appropriateness of using bicarbonate therapy in moderate DKA. Various questions remain unanswered, such as whether bicarbonate administration in severe DKA makes any real difference to the clinical course, and whether an insulin loading dose is needed in adults.
The entity of ketosis-prone type 2 diabetes was first fully described in 1987 after several preceding case reports. It was initially thought to be a form of maturity onset diabetes of the young, and went through several other descriptive names (such as "idiopathic type 1 diabetes", "Flatbush diabetes", "atypical diabetes" and "type 1.5 diabetes") before the current terminology of "ketosis-prone type 2 diabetes" was adopted.

</doc>
<doc id="56527" url="http://en.wikipedia.org/wiki?curid=56527" title="Galactose">
Galactose

Galactose (from the Greek stem γάλακτ– "galakt–", "milk"), sometimes abbreviated Gal, is a monosaccharide sugar that is less sweet than glucose and fructose. It is a C-4 epimer of glucose.
Galactan is a polymer of the sugar galactose found in hemicellulose. Galactan can be converted to galactose by hydrolysis.
Structure and isomerism.
Galactose exists in both open-chain and cyclic form. The open-chain form has a carbonyl at the end of the chain. In the open-chain form D- and L- isomers cannot be separated, but the cyclic forms can be crystallized and isolated.
Four isomers are cyclic, two of them with a pyranose (six-membered) ring, two with a furanose (five-membered) ring. Galactofuranose occurs in bacteria, fungi and protozoa.
 In the cyclic form there are two anomers, named alpha and beta, since the transition from the open-chain form to the cyclic form involves the creation of a new stereocenter at the site of the open-chain carbonyl. In the beta form, the alcohol group is in the equatorial position, whereas in the alpha form, the alcohol group is in the axial position.
Relationship to lactose.
Galactose is a monosaccharide. When combined with glucose (monosaccharide), through a condensation reaction, the result is the disaccharide lactose. The hydrolysis of lactose to glucose and galactose is catalyzed by the enzymes lactase and β-galactosidase. The latter is produced by the "lac" operon in "Escherichia coli".
In nature, lactose is found primarily in milk and milk products. Consequently, various food products made with dairy-derived ingredients, e.g. breads and cereals, can contain lactose. Galactose metabolism, which converts galactose into glucose, is carried out by the three principal enzymes in a mechanism known as the Leloir pathway. The enzymes are listed in the order of the metabolic pathway: galactokinase (GALK), galactose-1-phosphate uridyltransferase (GALT), and UDP-galactose-4’-epimerase (GALE).
In the human body, glucose is changed into galactose via hexoneogenesis to enable the mammary glands to secrete lactose. However, most lactose in breast milk is synthesized from galactose taken up from the blood, and only 35±6% is made from galactose from "de novo" synthesis.
 Glycerol also contributes some to the mammary galactose production.
Metabolism.
Glucose is the primary metabolic fuel for humans. It is more stable than galactose and is less susceptible to the formation of nonspecific glycoconjugates, molecules with at least one sugar attached to a protein or lipid. Many speculate that it is for this reason that a pathway for rapid conversion from galactose to glucose has been highly conserved among many species.
The main pathway of galactose metabolism is the Leloir pathway; humans and other species, however, have been noted to contain several alternate pathways, such as the De Ley Doudoroff pathway. The Leloir pathway consists of the latter stage of a two-part process that converts β-D-galactose to UDP-glucose. The initial stage is the conversion of β-D-galactose to α-D-galactose by the enzyme, mutarotase (GALM). The Leloir pathway then carries out the conversion of α-D-galactose to UDP-glucose via three principle enzymes. Galactokinase (GALK) phosphorylates α-D-galactose to galactose-1-phosphate, or Gal-1-P. Galactose-1-phosphate uridyltransferase (GALT) then transfers a UMP group from UDP-glucose to Gal-1-P to form UDP-galactose. Finally, UDP galactose-4’-epimerase (GALE) interconverts UDP-galactose and UDP-glucose, thereby completing the pathway.
However, those suffering from galactosemia cannot properly break down galactose as the result of a genetically inherited mutation in one of the enzymes in the Leloir pathway. These individuals cannot break down galactose properly, so the consumption of even small amounts of galactose is harmful to galactosemics.
Sources.
Galactose is found in dairy products, sugar beets, other gums and mucilages. It is also synthesized by the body, where it forms part of glycolipids and glycoproteins in several tissues; and is a by-product from the third-generation ethanol production process (from macroalgae).
Clinical significance.
Chronic systemic exposure of mice, rats, and "Drosophila" to D-galactose causes the acceleration of senescence (aging) and has been used as an aging model.
Two studies have suggested a possible link between galactose in milk and ovarian cancer. Other studies show no correlation, even in the presence of defective galactose metabolism. More recently, pooled analysis done by the Harvard School of Public Health showed no specific correlation between lactose-containing foods and ovarian cancer, and showed statistically insignificant increases in risk for consumption of lactose at ≥30 g/d. More research is necessary to ascertain possible risks.
Some ongoing studies suggest galactose may have a role in treatment of focal segmental glomerulosclerosis (a kidney disease resulting in kidney failure and proteinuria). This effect is likely to be a result of binding of galactose to FSGS factor.
Galactose is a component of the antigens present on blood cells that determine blood type within the ABO blood group system. In O and A antigens, there are two monomers of galactose on the antigens, whereas in the B antigens there are three monomers of glucose.
A disaccharide composed of two units of galactose, galactose-alpha-1,3-galactose (alpha-gal), has been recognized as a potential allergen present in mammal meat. Alpha-gal allergy may be triggered by lone star tick bites.
History.
In 1855, E. O. Erdmann noted that hydrolysis of lactose produced a substance besides glucose. Galactose was first isolated and studied by Louis Pasteur in 1856. He called it "lactose". In 1860, Berthelot renamed it "galactose" or "glucose lactique". In 1894, Emil Fischer and Robert Morrell determined the configuration of galactose.

</doc>
<doc id="56531" url="http://en.wikipedia.org/wiki?curid=56531" title="Retinopathy">
Retinopathy

Retinopathy is due to persistent or acute damage to the retina of the eye. Ongoing inflammation and vascular remodeling may occur over periods of time where the patient is not fully aware of the extent of the disease. Frequently, retinopathy is an ocular manifestation of systemic disease as seen in diabetes or hypertension. Diabetic retinopathy is the leading cause of blindness in working-aged people.
Pathophysiology.
Causes of retinopathy include but are not limited to: 
Many types of retinopathy are proliferative, most often resulting from neovascularization or blood vessel overgrowth. Angiogenesis is the hallmark precursor that may result in blindness or severe vision loss, particularly if the macula becomes affected.
Retinopathy may more rarely be due to ciliopathic genetic disorders, such as Alström syndrome or Bardet–Biedl syndrome.
Retinopathy is diagnosed by an ophthalmologist during eye examination. Treatment depends on the cause of the disease.
Remote Screening.
Telemedicine programs are available that allow primary care clinics to take images using specially designed retinal imaging equipment which can then be shared electronically with specialists at other locations for review. In 2009, Community Health Center, Inc. implemented a telemedicine retinal screening program for low-income patients with diabetes as part of those patients annual visits at the Federally Qualified Health Center.
Treatment.
Treatment is based on the cause of the retinopathy and may include laser therapy to the retina. In recent years targeting the pathway controlling vessel growth or angiogenesis has been promising. Vascular endothelial growth factor (VEGF) seems to play a vital role in promoting neovascularization. Using anti-VEGF drugs (antibodies to sequester the growth factor), researches have shown significant reduction in the extent of vessel outgrowth. Several anti-VEGF treatments are currently under review in both clinical trials and in preclinical labs.

</doc>
<doc id="56533" url="http://en.wikipedia.org/wiki?curid=56533" title="Diabetic retinopathy">
Diabetic retinopathy

Diabetic retinopathy ([ˌrɛtnˈɑpəθi]) is retinopathy (damage to the retina) caused by complications of diabetes, which can eventually lead to blindness.
It is an ocular manifestation of diabetes, a systemic disease, which affects up to 80 percent of all patients who have had diabetes for 10 years or more. Despite these intimidating statistics, research indicates that at least 90% of these new cases could be reduced if there were proper and vigilant treatment and monitoring of the eyes. The longer a person has diabetes, the higher his or her chances of developing diabetic retinopathy. Each year in the United States, diabetic retinopathy accounts for 12% of all new cases of blindness. It is also the leading cause of blindness for people aged 20 to 64 years.
Signs and symptoms.
Diabetic retinopathy often has no early warning signs. Even macular edema, which may cause vision loss more rapidly, may not have any warning signs for some time. In general, however, a person with macular edema is likely to have blurred vision, making it hard to do things like read or drive. In some cases, the vision will get better or worse during the day.
In the first stage which is called non-proliferative diabetic retinopathy (NPDR) there are no symptoms, it is not visible to the naked eye and patients will have 20/20 vision. The only way to detect NPDR is by fundus photography, in which microaneurysms (microscopic blood-filled bulges in the artery walls) can be seen. If there is reduced vision, fluorescein angiography can be done to see the back of the eye. Narrowing or blocked retinal blood vessels can be seen clearly and this is called retinal ischemia (lack of blood flow).
Macular edema may occur in which blood vessels leak contents into the macular region can happen at all stages of NPDR. The macular edema symptoms are blurring, darkening or distorted images with not the same between two eyes. 10 percent of diabetic patients will get vision loss related with macular edema. Optical Coherence Tomography can show areas of 
retinal thickening (fluid accumulation) of macular edema.
On the second stage, as abnormal new blood vessels (neovascularisation) form at the back of the eye as a part of "proliferative diabetic retinopathy" (PDR), they can burst and bleed (vitreous hemorrhage) and blur vision, because the new blood vessels are weak. The first time this happens, it may not be very severe. In most cases, it will leave just a few specks of blood, or spots, floating in a person's visual field, though the spots often go away after a few hours.
These spots are often followed within a few days or weeks by a much greater leakage of blood, which blurs vision. In extreme cases, a person will only be able to tell light from dark in that eye. It may take the blood anywhere from a few days to months or even years to clear from the inside of the eye, and in some cases the blood will not clear. These types of large hemorrhages tend to happen more than once, often during sleep.
On funduscopic exam, a doctor will see cotton wool spots, flame hemorrhages (similar lesions are also caused by the alpha-toxin of "Clostridium novyi"), and dot-blot hemorrhages.
Pathogenesis.
Diabetic retinopathy is the result of microvascular retinal changes. Hyperglycemia-induced intramural pericyte death and thickening of the basement membrane lead to incompetence of the vascular walls. These damages change the formation of the blood-retinal barrier and also make the retinal blood vessels become more permeable.
The pericyte death is caused when "hyperglycemia persistently activates protein kinase C-δ (PKC-δ, encoded by Prkcd) and p38 mitogen-activated protein kinase (MAPK) to increase the expression of a previously unknown target of PKC-δ signaling, Src homology-2 domain–containing phosphatase-1 (SHP-1), a protein tyrosine phosphatase. This signaling cascade leads to PDGF receptor- dephosphorylation and a reduction in downstream signaling from this receptor, resulting in pericyte apoptosis…"
Small blood vessels – such as those in the eye – are especially vulnerable to poor blood sugar (blood glucose) control. An overaccumulation of glucose and/or fructose damages the tiny blood vessels in the retina. During the initial stage, called nonproliferative diabetic retinopathy (NPDR), most people do not notice any change in their vision. Early changes that are reversible and do not threaten central vision are sometimes termed "simplex retinopathy" or "background retinopathy".
Some people develop a condition called macular edema. It occurs when the damaged blood vessels leak fluid and lipids onto the macula, the part of the retina that lets us see detail. The fluid makes the macula swell, which blurs vision.
Proliferative diabetic retinopathy.
As the disease progresses, severe nonproliferative diabetic retinopathy enters an advanced, or proliferative (PDR), stage when blood vessels proliferate (i.e. grow). The lack of oxygen in the retina causes fragile, new, blood vessels to grow along the retina and in the clear, gel-like vitreous humour that fills the inside of the eye. Without timely treatment, these new blood vessels can bleed, cloud vision, and destroy the retina. Fibrovascular proliferation can also cause tractional retinal detachment. The new blood vessels can also grow into the angle of the anterior chamber of the eye and cause neovascular glaucoma.
Nonproliferative diabetic retinopathy shows up as cotton wool spots, or microvascular abnormalities or as superficial retinal hemorrhages. Even so, the advanced proliferative diabetic retinopathy (PDR) can remain asymptomatic for a very long time, and so should be monitored closely with regular checkups.
Risk factors.
All people with "diabetes mellitus" are at risk – those with Type I diabetes and those with Type II diabetes. The longer a person has diabetes, the higher the risk of developing some ocular problem. Between 40 to 45 percent of Americans diagnosed with diabetes have some stage of diabetic retinopathy. After 20 years of diabetes, nearly all patients with Type I diabetes and >60% of patients with Type II diabetes have some degree of retinopathy; however, these statistics were published in 2002 using data from four years earlier, limiting the usefulness of the research. The subjects would have been diagnosed with diabetes in the late 1970s, before modern fast acting insulin and home glucose testing.
Prior studies had also assumed a clear glycemic threshold between people at high and low risk of diabetic retinopathy.
However, it has been shown that the widely accepted WHO and American Diabetes Association diagnostic cutoff for diabetes of a fasting plasma glucose ≥ 7.0 mmol/l (126 mg/dl) does not accurately identify diabetic retinopathy among patients. The cohort study included a multi-ethnic, cross-sectional adult population sample in the US, as well as two cross-sectional adult populations in Australia. For the US-based component of the study, the sensitivity was 34.7% and specificity was 86.6%. For patients at similar risk to those in this study (15.8% had diabetic retinopathy), this leads to a positive predictive value of 32.7% and negative predictive value of 87.6%.
Published rates vary between trials, the proposed explanation being differences in study methods and reporting of prevalence rather than incidence values.
During pregnancy, diabetic retinopathy may also be a problem for women with diabetes.
It is recommended that all pregnant women with diabetes have dilated eye examinations each trimester to protect their vision.
People with Down's syndrome, who have three copies of chromosome 21, almost never acquire diabetic retinopathy. This protection appears to be due to the elevated levels of endostatin, an anti-angiogenic protein, derived from collagen XVIII. The collagen XVIII gene is located on chromosome 21.
Diagnosis.
Diabetic retinopathy is detected during an eye examination that includes:
The eye care professional will look at the retina for early signs of the disease, such as:
If macular edema is suspected, FFA and sometimes OCT may be performed.
According to a DRSS user manual, poor quality images (which may apply to other methods) may be caused by cataract, poor dilation, ptosis, external ocular condition, or learning difficulties. There may be artefacts caused by dust, dirt, condensation, or smudge.
Management.
There are three major treatments for diabetic retinopathy, which are very effective in reducing vision loss from this disease. In fact, even people with advanced retinopathy have a 90 percent chance of keeping their vision when they get treatment before the retina is severely damaged. These three treatments are laser surgery, injection of corticosteroids or Anti-VEGF into the eye, and vitrectomy.
Although these treatments are very successful (in slowing or stopping further vision loss), they do not cure diabetic retinopathy. Caution should be exercised in treatment with laser surgery since it causes a loss of retinal tissue. It is often more prudent to inject triamcinolone or Anti-VEGF. In some patients it results in a marked increase of vision, especially if there is an edema of the macula.
Avoiding tobacco use and correction of associated hypertension are important therapeutic measures in the management of diabetic retinopathy.
The best way of addressing diabetic retinopathy is to monitor it vigilantly and achieve euglycemia.
Since 2008 there have been other drugs (e.g. kinase inhibitors and anti-VEGF) available.
Laser photocoagulation.
Laser photocoagulation can be used in two scenarios for the treatment of diabetic retinopathy. It can be used to treat macular edema by creating a Modified Grid at the posterior pole and it can be used for panretinal coagulation for controlling neovascularization. It is widely used for early stages of proliferative retinopathy.
Modified Grid Laser photocoagulation.
A 'C' shaped area around the macula is treated with low intensity small burns. This helps in clearing the macular edema.
Panretinal photocoagulation.
Panretinal photocoagulation, or PRP (also called scatter laser treatment), is used to treat proliferative diabetic retinopathy (PDR). The goal is to create 1,600 - 2,000 burns in the retina with the hope of reducing the retina's oxygen demand, and hence the possibility of ischemia. It is done in multiple sittings.
In treating advanced diabetic retinopathy, the burns are used to destroy the abnormal blood vessels that form in the retina. This has been shown to reduce the risk of severe vision loss for eyes at risk by 50%.
Before using the laser, the ophthalmologist dilates the pupil and applies anaesthetic drops to numb the eye. In some cases, the doctor also may numb the area behind the eye to reduce discomfort. The patient sits facing the laser machine while the doctor holds a special lens on the eye. The physician can use a single spot laser or a pattern scan laser for two dimensional patterns such as squares, rings and arcs. During the procedure, the patient will see flashes of light. These flashes often create an uncomfortable stinging sensation for the patient. After the laser treatment, patients should be advised not to drive for a few hours while the pupils are still dilated. Vision will most likely remain blurry for the rest of the day. Though there should not be much pain in the eye itself, an ice-cream headache like pain may last for hours afterwards.
Patients will lose some of their peripheral vision after this surgery although it may be barely noticeable by the patient. The procedure does however save the center of the patient's sight. Laser surgery may also slightly reduce colour and night vision.
A person with proliferative retinopathy will always be at risk for new bleeding, as well as glaucoma, a complication from the new blood vessels. This means that multiple treatments may be required to protect vision.
Intravitreal triamcinolone acetonide.
Triamcinolone is a long acting steroid preparation. When injected in the vitreous cavity, it decreases the macular edema (thickening of the retina at the macula) caused due to diabetic maculopathy, and results in an increase in visual acuity. The effect of triamcinolone is transient, lasting up to three months, which necessitates repeated injections for maintaining the beneficial effect. Best results of intravitreal Triamcinolone have been found in eyes that have already undergone cataract surgery. Complications of intravitreal injection of triamcinolone include cataract, steroid-induced glaucoma and endophthalmitis.
Intravitreal Anti-VEGF.
There are good results from multiple doses of intravitreal injections of Anti-VEGF drugs such as bevacizumab. Present recommended treatment for diabetic macular edema is Modified Grid laser photocoagulation combined with multiple injections of Anti-VEGF.
Vitrectomy.
Instead of laser surgery, some people require a vitrectomy to restore vision. A vitrectomy is performed when there is a lot of blood in the vitreous. It involves removing the cloudy vitreous and replacing it with a saline solution.
Studies show that people who have a vitrectomy soon after a large hemorrhage are more likely to protect their vision than someone who waits to have the operation. Early vitrectomy is especially effective in people with insulin-dependent diabetes, who may be at greater risk of blindness from a hemorrhage into the eye.
Vitrectomy is often done under local anesthesia. The doctor makes a tiny incision in the sclera, or white of the eye. Next, a small instrument is placed into the eye to remove the vitreous and insert the saline solution into the eye.
Patients may be able to return home soon after the vitrectomy, or may be asked to stay in the hospital overnight. After the operation, the eye will be red and sensitive, and patients usually need to wear an eyepatch for a few days or weeks to protect the eye. Medicated eye drops are also prescribed to protect against infection.
Vitrectomy is frequently combined with other modalities of treatment.
Experimental treatments.
C-peptide.
Though not yet commercially available, c-peptide has shown promising results in treatment of diabetic complications incidental to vascular degeneration. Once thought to be a useless byproduct of insulin production, it helps to ameliorate and reverse many symptoms of diabetes.
Pine bark extract.
In a small clinical trial of 24 patients pine bark extract of oligomeric proanthocyanidins improved some measures of eye damage and visual acuity in the early stages of diabetic retinopathy.
Stem cell therapy.
Clinical trials are under way or are being populated in preparation for study at medical 
centers in Brazil, Iran and the United States. Current trials involve using the patients 
own stem cells derived from bone marrow and injected into the degenerated areas in an effort 
to regenerate the vascular system.

</doc>
<doc id="56538" url="http://en.wikipedia.org/wiki?curid=56538" title="Rule of thumb">
Rule of thumb

A rule of thumb is a principle with broad application that is not intended to be strictly accurate or reliable for every situation. It is an easily learned and easily applied procedure for approximately calculating or recalling some value, or for making some determination. Compare this to heuristic, a similar concept used in mathematical discourse, psychology, and computer science, particularly in algorithm design.
Origin of the phrase.
The exact origin of the phrase is uncertain. The earliest known citation comes from J. Durham’s "Heaven upon Earth", 1685, ii. 217: "Many profest Christians are like to foolish builders, who build by guess, and by rule of thumb." The phrase also exists in other languages, for example Italian "Regola del pollice", Swedish "tumregel", Norwegian and Danish "tommelfingerregel", sometimes in the variant "rule of fist", for example Finnish "nyrkkisääntö", Estonian "rusikareegel", German "Faustregel" and "Pi mal Daumen", Hungarian "ökölszabály" or Dutch "vuistregel", as well as in Turkish "parmak hesabı", and in Hebrew "כלל אצבע" (rule of finger) and in Persian "قاعده سرانگشتی," which is translated as finger tip's rule. This suggests that it has some antiquity, and does not originate in specifically Germanic language culture.
Thumb as measurement device.
The term is thought to originate with carpenters who used the width of their thumbs (i.e., inches) rather than rulers for measuring things, cementing its modern use as an imprecise yet reliable and convenient standard. This sense of thumb as a unit of measure also appears in Dutch, in which the word for thumb, "duim", also means inch. The use of a single word or cognate for "inch" and "thumb" is common in many Indo-European languages, for example, French: "pouce" inch/thumb; Italian: "pollice" inch/thumb; Spanish: "pulgada" inch, "pulgar" thumb; Portuguese: "polegada" inch, "polegar" thumb; Swedish: "tum" inch, "tumme" thumb; Sanskrit: "angulam" inch, "anguli" finger; Slovak: "palec", Slovene: "palec" inch/thumb, #REdirect inch/thumb, Hungarian: "hüvelyk" inch/thumb. Also in some other languages such as Thai: nîw inch/finger.
Another possible origin of the phrase comes from measurement, in particular in agricultural fields. The plants need a fairly precise depth to seed properly, whether planted from seed or being replanted, but the depth can sometimes be estimated using the thumb. That is, a "rule (measurement) of thumb". According to Gary Martin, "The origin of the phrase remains unknown. It is likely that it refers to one of the numerous ways that thumbs have been used to estimate things—judging the alignment or distance of an object by holding the thumb in one's eye-line, the temperature of brews of beer, measurement of an inch from the joint to the nail to the tip, or across the thumb, etc. The phrase joins the whole nine yards as one that probably derives from some form of measurement but which is unlikely ever to be definitively pinned down."
Thumb used for abuse.
It is often claimed that the term's etymological origin lies in a law that limited the maximum thickness of a stick with which it was permissible for a man to beat his wife. English common law before the reign of Charles II permitted a man to give his wife "moderate correction", but no "rule of thumb" (whether called by this name or not) has ever been the law in
England. Such "moderate correction" specifically excluded beatings, allowing the husband only to confine a wife to the household.
Nonetheless, belief in the existence of a "rule of thumb" law to excuse spousal abuse can be traced as far back as 1782, the year that James Gillray published his satirical cartoon "Judge Thumb". The cartoon lambastes Sir Francis Buller, an English judge, for allegedly ruling that a man may legally beat his wife, provided that he used a stick no thicker than his thumb, although it is questionable whether Buller ever made such a pronouncement. The Massachusetts Body of Liberties adopted in 1641 by the Massachusetts Bay colonists states, “Every married woman shall be free from bodily correction or stripes by her husband, unless it be in his own defense from her assault.” In the United States, legal decisions in Mississippi (1824) and North Carolina (1868 and 1874) make reference to—and reject—an unnamed "old doctrine" or "ancient law" by which a man was allowed to beat his wife with a stick no wider than his thumb.
For example, the 1874 case "State v. Oliver" (North Carolina Reports, Vol. 70, Sec. 60, p. 44) states: "We assume that the old doctrine that a husband had the right to whip his wife, provided that he used a switch no larger than his thumb, is not the law in North Carolina."
In 1976, feminist Del Martin used the phrase "rule of thumb" as a metaphorical reference to describe such a doctrine. She was misinterpreted by many as claiming the doctrine as a direct origin of the phrase and the connection gained currency in 1982, when the U.S. Commission on Civil Rights issued a report on wife abuse, titled "Under the Rule of Thumb".
References.
</dl>

</doc>
<doc id="56542" url="http://en.wikipedia.org/wiki?curid=56542" title="Hanna-Barbera">
Hanna-Barbera

Hanna-Barbera Productions, Inc. (also known at various times as H-B Enterprises, H-B Production Company and Hanna-Barbera Cartoons) was an American animation studio that dominated American television animation for nearly three decades in the mid-to-late 20th century. It was formed in 1957 by former Metro Goldwyn Mayer animation directors William Hanna and Joseph Barbera (creators of "Tom and Jerry") and live-action director George Sidney in partnership with Columbia Pictures' Screen Gems television division. The company was sold to Taft Broadcasting in late 1966, and spent the next two decades as a subsidiary of the parent and its successors.
For thirty years, Hanna-Barbera produced many successful animated shows, including "The Flintstones", "Yogi Bear", "The Jetsons", "Scooby-Doo", and "The Smurfs", earning eight Emmy Awards, a Golden Globe Award, and a star on the Hollywood Walk of Fame, among other merits. The company's fortunes declined in the mid-eighties after the profitability of Saturday morning cartoons was eclipsed by weekday afternoon syndication. Hanna-Barbera was purchased from Taft (by then named Great American Broadcasting) in late 1991 by Turner Broadcasting System, who used much of its back catalog to program its new channel, Cartoon Network.
After Turner purchased the company, both Hanna and Barbera continued to serve as mentors and creative consultants. In 1996, Turner merged with Time Warner, and Hanna-Barbera became a subsidiary of Warner Bros. Animation. With Hanna's death in 2001, it was absorbed into its parent, and Cartoon Network Studios continued the projects for the channel's output. Barbera continued to work for Warner Bros. Animation until his death in 2006. The studio now exists as an in-name-only company used to market properties and productions associated with the Hanna-Barbera library, specifically its "classic" works.
In 2005, the Academy of Television Arts & Sciences honored Hanna and Barbera with a bronze wall sculpture of them and the characters they created. Hanna-Barbera was known not only for its vast variety of series and characters, but for building upon and popularizing the concepts and uses of limited animation.
History.
Melrose, New Mexico native William Hanna and New York City-born Joseph Barbera first teamed together while working at the Metro-Goldwyn-Mayer cartoon studio in 1939. Their first directorial animated project together was "Puss Gets the Boot" (1940), which served as the genesis of the popular "Tom and Jerry" series of theatricals. Hanna and Barbera served as the directors and story men of the shorts for eighteen years. Seven of the cartoons won seven Oscars for Best Short Subject (Cartoons) between 1943 and 1953, though the trophies were awarded to their producer Fred Quimby, who was not involved in the creative development of the shorts.:83–84 With Quimby's retirement in 1955, Hanna and Barbera became the producers in charge of the MGM animation studio's output.
Outside of their work on the MGM shorts, the two men moonlighted on outside projects, including the original title sequences and commercials for the hit television series "I Love Lucy". MGM decided in early 1957 to close its cartoon studio, as it felt it had acquired a reasonable backlog of shorts for re-release. Hanna and Barbera, contemplating their future while completing the final "Tom and Jerry" and "Droopy" cartoons, began producing animated television commercials. During their last year at MGM, they developed a concept for an animated television program about a dog and cat pair who found themselves in various misadventures. After they failed to convince MGM to back their venture, live-action director George Sidney, who'd worked with Hanna and Barbera on several of his features – most notably "Anchors Aweigh" in 1945 – offered to serve as their business partner and convinced Screen Gems, the television subsidiary of Columbia Pictures, to make a deal with the animation producers.
Harry Cohn, head of Columbia Pictures, took an 18% ownership in Hanna and Barbera's new company, "H-B Enterprises", and provided working capital to produce. Screen Gems became the new studio's distributor and its licensing agent, handling merchandizing of the characters from the animated programs. H-B Enterprises opened for business in rented offices on the lot of Kling Studios (formerly Charlie Chaplin Studios) on July 7, 1957, two months after the MGM animation studio closed down. Sidney and several Screen Gems alumni became members of H-B's original board of directors, and much of the former MGM animation staff – including animators Carlo Vinci, Kenneth Muse, Lewis Marshall, Michael Lah, and Ed Barge and layout artists Ed Benedict and Richard Bickenbach – as its production staff.
1957–69: Television cartoons.
Hanna-Barbera was one of the first animation studios to successfully produce cartoons especially for television. Previously, animated programming on television had consisted primarily of rebroadcasts of theatrical cartoons. Their first animated series for television "The Ruff & Reddy Show", featuring live-action host Jimmy Blaine and several older Columbia-owned cartoons as filler, premiered on NBC in December 1957. The studio had its first big success with "The Huckleberry Hound Show" in 1958, a syndicated series aired in most markets just before primetime. The program was a ratings success, and introduced a new crop of cartoon stars to audiences, in particular Huckleberry Hound and Yogi Bear. The show won an Emmy for Outstanding Achievement in the Field of Children's Programming. The studio began to expand rapidly following the success of "Huckleberry Hound", and several animation industry alumni – in particular former Warner Bros. Cartoons storymen Michael Maltese and Warren Foster, who became H-B's new head writers – joined the staff at this time.
By 1959, H-B Enterprises was reincorporated as "Hanna-Barbera Productions", and was slowly becoming a leader in television animation production. After introducing a second syndicated series, "The Quick Draw McGraw Show", in 1959, Hanna-Barbera migrated into network primetime production with the animated ABC sitcom "The Flintstones" in 1960. Loosely based upon the popular live-action sitcom "The Honeymooners", yet set in a fictionalized stone age of cavemen and dinosaurs, the show ran for six seasons in prime time on ABC, becoming a ratings and merchandising success. It was the longest-running animated show in American prime time television history until being beaten out by "The Simpsons" in 1996. During the early and mid-sixties, the studio debuted several new successful programs, among them prime time ABC series such as "Top Cat", "The Jetsons" and "Jonny Quest".
New shows produced for syndication and Saturday mornings included "The Yogi Bear Show" – a syndicated spinoff from "The Huckleberry Hound Show", "The Hanna-Barbera New Cartoon Series" featuring "Wally Gator", "The Magilla Gorilla Show", "The Peter Potamus Show" and "The Atom Ant/Secret Squirrel Show". Hanna-Barbera also produced several television commercials, often starring its own characters, and animated the opening credits for the ABC sitcom "Bewitched" (the "Bewitched" characters would also appear as guest stars in a season six episode of "The Flintstones"). Hanna-Barbera also produced "Loopy De Loop", a series of theatrical cartoon shorts. It was the studio's first and only series for theaters. The studio moved off of the Kling lot in 1963 (by then renamed the Red Skelton Studios) when it located at 3400 Cahuenga Blvd. West in Hollywood, California, was opened.
This California contemporary office building was designed by architect Arthur Froehlich. Its ultra-modern design included a sculpted latticework exterior, moat, fountains, and after later additions, a Jetsons-like tower. After the success of "The Atom Ant/Secret Squirrel Show" in 1965, two new Saturday morning series debuted the following year, "Space Ghost", which featured action-adventure and "Frankenstein, Jr. and The Impossibles", which blended action-adventure with the earlier Hanna-Barbera humor style. A number of the company's action cartoons followed in 1967, among them are "Shazzan", "Birdman and the Galaxy Trio", "Moby Dick and the Mighty Mightor", "Young Samson and Goliath", "The Herculoids" and an adaptation of Marvel Comics' "Fantastic Four" along with new syndicated shows based on famous celebrities, such as "The Abbott and Costello Cartoon Show" and "Laurel and Hardy".
The Hanna-Barbera and Screen Gems partnership lasted until 1965, when Hanna and Barbera announced the sale of the studio to Taft Broadcasting. Its acquisition of Hanna-Barbera was delayed for a year by a lawsuit from Joan Perry, John Cohn, and Harrison Cohn - the widow and sons of former Columbia head Harry Cohn - who felt that Hanna-Barbera had undervalued the Cohns' 18% share in the company when it was sold a few years prior. By December 1966, the litigation had been settled and the company was finally acquired for $12 million by Taft, who spent 1967 and 1968 folding Hanna-Barbera into its corporate sctructure. Hanna and Barbera stayed on to run the company, and Taft became Hanna-Barbera's new distributor. 
Screen Gems retained licensing and distribution rights to the previous cartoon series, as well as the trademarks to the characters from those series ("The Flintstones" and "Yogi Bear" in particular) into the 1970s and early 1980s. In 1968, the studio mixed live-action and animated comedy-action for its new anthology series for NBC, "The Banana Splits Adventure Hour", while the successful "Wacky Races", and its spinoffs "The Perils of Penelope Pitstop" and "Dastardly and Muttley in Their Flying Machines", aired on CBS, returning Hanna-Barbera to straight animated slapstick humor. ABC would air "Cattanooga Cats", which debuted the following year. The studio tried its hand at being a record label for a short time when Danny Hutton was hired to become the head of Hanna Barbera Records (HBR) from 1965 to 1966. It was distributed by Columbia Records, with artists such as Louis Prima, Five Americans, Scatman Crothers and the 13th Floor Elevators. Previously, children's records with Hanna-Barbera characters were released by Colpix Records.
Next came "Scooby-Doo, Where Are You!" in 1969, a CBS program which blended elements of H-B's comedy programs, action shows, the live-action sitcom "The Many Loves of Dobie Gillis" and the old time radio show "I Love a Mystery". The series centered on four teenagers and a dog solving supernatural mysteries, and was so popular that the company made more new Saturday morning cartoons featuring mystery-solving, crime-fighting teenagers with comical pets and mascots during the 1970s. These series included "Josie and the Pussycats", "The Funky Phantom", "The Amazing Chan and the Chan Clan", "Speed Buggy", "Butch Cassidy & The Sundance Kids", "Goober and the Ghost Chasers", "Clue Club", "Jabberjaw", "Captain Caveman and the Teen Angels" and "The New Shmoo". By 1977, "Scooby-Doo" was the centerpiece of a two-hour ABC program block titled "Scooby's All-Star Laff-a-Lympics", which also included "Dynomutt, Dog Wonder", "Captain Caveman" and "Laff-a-Lympics".
The 1970s.
During the seventies in particular, the majority of American television animation was produced by Hanna-Barbera. The only competition came from Filmation, DePatie-Freleng and a few other companies that specialized primarily in prime time specials, such as Rankin-Bass, Chuck Jones Enterprises and Lee Mendelson-Bill Meléndez. Filmation, in particular, lost ground to Hanna-Barbera when the failure of its show "Uncle Croc's Block" led ABC president Fred Silverman to drop Filmation and give Hanna and Barbera the majority of the network's Saturday morning cartoon time. Besides "Scooby-Doo" and the programs derived from it, the studio also found success with new programs such as "Harlem Globetrotters", "Where's Huddles", "The Addams Family", "These Are The Days", "Partridge Family 2200 A.D.", "Hong Kong Phooey" and "Jeannie". The syndicated "Wait Till Your Father Gets Home" returned Hanna-Barbera to adult-oriented comedy, although the show was more provocative than "The Flintstones" or "The Jetsons" had been.
The studio revisited its 1960s hits starting with the "Flintstones" spin-offs "The Pebbles and Bamm-Bamm Show", "The Flintstone Comedy Hour", "The New Fred and Barney Show" and "The Flintstone Comedy Show". In 1980, four new "Flintstones" specials aired in prime time on NBC as a limited-run revival of the original series. "All-star" shows featuring Yogi Bear, Huckleberry Hound and others included "Yogi's Gang" and "Yogi's Space Race" and the "Scooby-Doo" spin-offs, "The New Scooby-Doo Movies", "The Scooby-Doo Show", and "Scooby-Doo and Scrappy-Doo", followed by new shows, "The All-New Popeye Hour", "Casper and the Angels" and "The New Tom and Jerry/Grape Ape Show". "Super Friends", a Hanna-Barbera produced adaptation of DC Comics' "Justice League of America" comic book, remained on ABC Saturday mornings from 1973 to 1986. "The Kwicky Koala Show", the first and only project of Tex Avery for Hanna-Barbera, first aired in 1981.
Hanna-Barbera also tried its hand at live-action projects, though its success in selling such programming was limited by its track record as an animation studio. The first fully live action film was "Hardcase" one of the ABC Movie of the Week television movies. Their most notable production out of the many of its non-animated specials is the Emmy-winning favorite "The Gathering". Its live-action department spun off into Solow Production Company, founded by Herbert F. Solow, which immediately following the name change was able to sell the series "Man from Atlantis" to NBC.
Production process changes.
From 1957 to 1995, Hanna-Barbera produced prime-time, weekday afternoon, and Saturday morning cartoons for all three major networks and syndication in the United States. The small budgets that television animation producers had to work within prevented them, and most other producers of American television animation, from working with the full theatrical-quality animation the duo had been known for at MGM. While the budget for a seven-minute "Tom and Jerry" entry of the 1950s was about $35,000, Hanna-Barbera was required to produce five-minute "Ruff and Reddy" episodes for no more than $3,000 a piece. To keep within these tighter budgets, Hanna-Barbera modified the concept of limited animation (also called semi-animation) practiced and popularized by the United Productions of America (UPA) studio, which also once had a partnership with Columbia Pictures.
Character designs were simplified, and backgrounds and animation cycles (walks, runs, etc.) were regularly re-purposed. Characters were often broken up into a handful of levels, so that only the parts of the body that needed to be moved at a given time (i.e. a mouth, an arm, a head) would be animated. The rest of the figure would remain on a held animation cel. This allowed a typical 10-minute short to be done with only 1,200 drawings instead of the usual 26,000. Dialogue, music, and sound effects were emphasized over action, leading Chuck Jones – a contemporary who worked for Hanna and Barbera's rivals at Warner Bros. Cartoons when the duo was at MGM, and one who, with his short "The Dover Boys" practically invented many of the concepts in limited animation – to disparagingly refer to the limited TV cartoons produced by Hanna-Barbera and others as "illustrated radio".
In a story published by "The Saturday Evening Post" in 1961, critics stated that Hanna-Barbera was taking on more work than it could handle and was resorting to shortcuts only a television audience would tolerate. An executive who worked for Walt Disney Productions said, "We don't even consider [them] competition". Ironically, during the late 1950s and early 1960s, Hanna-Barbera was the only animation studio in Hollywood that was actively hiring, and it picked up a number of Disney artists who were laid off during this period. The studio's solution to the criticism over its quality was to go into features. The studio produced six theatrical features, among them higher-quality versions of its hit television cartoons and adaptations of other material. Hanna-Barbera was also the first animation studio to have their animation work produced overseas. One of these production companies was a subsidiary started by Hanna-Barbera called PhilToons in the Philippines.
1981–91: Rise and fall.
Competing studios, such as Sunbow/Marvel, Filmation and Rankin/Bass began to introduce successful syndicated cartoons of ', "Transformers", "He-Man", ' and "Thundercats", based upon characters from popular toy lines and action figures. Hanna-Barbera continued to produce for Saturday mornings but no longer dominated the market. In 1981, Taft purchased Ruby-Spears Enterprises from Filmways, founded in 1977 by former H-B employees Joe Ruby and Ken Spears. It would often pair their shows with Hanna-Barbera's programs. Then in 1979, the parent bought Worldvision Enterprises, which then throughout the eighties, became the syndication distributor for most of the cartoons. It was also during this time the studio switched from cel animation to digital ink and paint for some of their shows.
Both Hanna-Barbera and Worldvision had their own home video labels (Worldvision Home Video and Hanna-Barbera Home Video) while many of its productions were released by other VHS distributors. "The Smurfs" debuted in 1981 on NBC, based on Belgian cartoonist and creator Pierre Culliford's popular comics and stories. It centers around the society of tiny, blue creatures lead by Papa Smurf. It began when Hanna and Barbera were called by Fred Silverman in 1979, offering an "on the air" commitment if they could secure the television rights to the property, which had caught the attention of Silverman's young daughter. It ran for nine seasons and won two Daytime Emmys and a Humanitas Prize. A ratings success and the top rated program in eight years, it was the longest-running Saturday morning cartoon and the highest for an NBC program since 1970.
Some of their shows were produced at their Australian-based studio, a partnership with Australian media company Southern Star Entertainment, including "Drak Pack", "The Berenstain Bears" and "Teen Wolf". "Trollkins" made its premiere on CBS in 1981, then "The Biskitts" in 1983. Next was "", a Hanna-Barbera produced series for direct-to-video about three young adventurers traveling back in time to watch biblical events take place in the past. After the success of the smash hit CBS Saturday morning cartoon series "Muppet Babies", which featured toddler versions of Jim Henson's popular Muppet characters, Hanna-Barbera began producing shows featuring "kid" versions of popular characters, such as "The Flintstone Kids", "A Pup Named Scooby-Doo", "Pink Panther and Sons" and "Popeye and Son".
"Yogi's Treasure Hunt" and a 1986 revival of "Jonny Quest", along with new series originals "Galtar and the Golden Lance", "Paw Paws", "Sky Commanders", "Fantastic Max", "The Further Adventures of Superted" and "Paddington Bear" were introduced for the new weekly syndicated block "The Funtastic World of Hanna-Barbera". Meanwhile, DC Comics named Hanna-Barbera as one of the honorees in its 50th anniversary publication "Fifty Who Made DC Great" for its work on the "Super Friends" cartoon series. More new shows were introduced, featuring "Yogi Bear" ("The New Yogi Bear Show") and "Scooby-Doo" ("The New Scooby and Scrappy-Doo Show" and "The 13 Ghosts of Scooby-Doo") along with "The Completely Mental Misadventures of Ed Grimley", "Wildfire" and "Foofur".
Following its original newtork run, two decades earlier, "The Jetsons" returned for new episodes, premiering in 1985 syndicated. The studio followed the lead of its competitors by introducing new shows based on familiar licensed properties, such as "Pac-Man", "Mork and Mindy", "Snorks", "The Fonz and the Happy Days Gang", "Pound Puppies", "The Gary Coleman Show", "Challenge of the GoBots", "Laverne & Shirley in the Army", "Shirt Tales", "The Little Rascals", "Richie Rich", "The Dukes" and "Monchhichis". Throughout all of this, both Hanna-Barbera and Ruby-Spears were affected by the financial troubles of Taft, which had just been acquired by the American Financial Corporation in 1987 and had its name changed to "Great American Broadcasting" the following year.
Many of the business deals were overseen by Taft CEO, Charles Mechem. Along with the rest of the American animation industry, the company had gradually begun to move away from producing everything in-house in the late seventies and early eighties. Much of its product was outsourced to studios in Australia and Asia, including Wang Film Productions, Cuckoo's Nest Studios, Mr. Big Cartoons, Mook Co., Ltd., Toei Animation, and its own Philippines-based studio Fil-Cartoons. In 1989, much of its staff responded to a call from Warner Bros. to resurrect their animation department. Tom Ruegger and a number of his colleagues left the studio, moving to Warners to develop hit programs, such as "Tiny Toon Adventures", "" and "Animaniacs".
The rights to the Hanna-Barbera properties were licensed to Universal Studios while David Kirschner was appointed as the head of the studio in 1989, with Hanna and Barbera remaining as co-chairmen and launched new programs, such as "Yo Yogi!" and "The Pirates of Dark Water". Less than successful and burdened with debt, Carl Lindner, Jr.'s Great American put both Hanna-Barbera and Ruby-Spears up for sale in 1990. The Smurfs appeared in the drug prevention special "Cartoon All-Stars to the Rescue", produced by the Academy of Television Arts & Sciences Foundation.
Turner rebound.
In November 1991, the Hanna-Barbera studio and library, as well as much of the original Ruby-Spears library, were acquired by a 50-50 joint venture between Turner Broadcasting – which by that time had also bought the pre-May 1986 MGM library – and Apollo Investment Fund for $320 million. This was with the intention of launching an all animation based network aimed at children and younger audiences. Turner's president of entertainment Scott Sassa hired Fred Seibert, a former executive for MTV Networks, to head the Hanna-Barbera studio.
He immediately filled the gap left by the departure of most of their creative crew during the Great American years with a new crop of animators, writers, and producers, including Pat Ventura, Craig McCracken, Donovan Cook, Genndy Tartakovsky, David Feiss, Seth MacFarlane, Van Partible, Stewart St. John, and Butch Hartman with new production head Buzz Potamkin. In 1992, the studio was renamed "H-B Productions Company", changing its name once again to "Hanna-Barbera Cartoons, Inc." a year later, the same year that Turner acquired the remaining interests of Hanna-Barbera from Apollo Investment Fund for $255 million. New programs of "Tom & Jerry Kids" and "" made their premieres on FOX in 1990 and 1994.
Production assumed on "Captain Planet and the Planeteers" for TBS in 1993, renaming it "The New Adventures of Captain Planet". More new Hanna-Barbera programs were introduced, that were quite different from its old classics, including "Wake, Rattle, and Roll", "Young Robin Hood" (which was a co-production with the Canadian animation firm Cinar), ', "The Adventures of Don Coyote and Sancho Panda", ', "Dumb and Dumber" (which was the last Hanna-Barbera series to be aired on broadcast television, as well as co-produced with eventual corporate sibling New Line Cinema), "2 Stupid Dogs", "Bill and Ted's Excellent Adventures", "Fish Police", "Gravedale High" and "Capitol Critters".
1992–2001: Partnership with Cartoon Network, dissolution.
In 1992, Turner launched Cartoon Network, to showcase its huge library of animated programs, of which Hanna-Barbera was the core contributor. As a result, many classic cartoons, especially the Hanna-Barbera ones, were introduced to a new audience. Following a 1987 popularity wane and program length decrease, "The Funtastic World of Hanna-Barbera" ended permanently in 1994, so that Turner could refocus the studio to produce new shows exclusively for the Turner-owned networks. In 1995, Hanna-Barbera produced "What a Cartoon!" (also known as "World Premiere Toons") for Cartoon Network, an animation showcase series guided by Fred Seibert, founder of Frederator Studios. The program featured forty-eight new creator driven cartoon shorts developed by its in-house staff. Several original series emerged from the project, giving the company their first hits since "The Smurfs". The first series based on a "What a Cartoon" short was Genndy Tartakovsky's "Dexter's Laboratory". This spawned a multitude of original series for the network known as "Cartoon Cartoons".
In 2001, the Hanna-Barbera name began to disappear from newer shows by the studio in favor of the Cartoon Network Studios label. This came in handy with shows that were produced outside the company, but Cartoon Network had a hand in producing (ex.: "Ed, Edd n Eddy" and "") as well as shows the studio continued to produce (ex.: "Adventure Time", "Regular Show", "Camp Lazlo" and "Ben 10"). Hanna passed away of throat cancer on March 22, 2001, ending his sixty-year partnership in animation with Barbera. Since his partner's death, Barbera went solo and moved on to work for Warner Bros. Animation on new projects relating to the Hanna-Barbera and "Tom and Jerry" properties until his passing on December 18, 2006. Today, Hanna-Barbera Productions is an in-name-only unit of Warner Bros. Animation, which administers the rights to its catalog and characters.
Sound effects.
Besides their cartoons and characters, Hanna-Barbera was also noted for their large library of sound effects. Besides cartoon-style sound effects (such as ricochets, slide whistles and more), they also had familiar sounds used for transportation, household items, the elements, and more. When Hanna and Barbera started their own cartoon studio in 1957, they created a handful of sound effects, and had limited choices. They also took some sounds from the then-defunct MGM animation studios. By 1958, they began to expand and began adding more sound effects to their library.
Besides creating a lot of their own effects, they also collected sound effects from other movie and cartoon studios, such as Universal Pictures, Warner Bros. Animation, and even Walt Disney Productions. Some of their famous sound effects included a rapid bongo drum take used for when a character's feet were scrambling before taking off, a "KaBONG" sound produced on a guitar for when Quick Draw McGraw, in his Zorro-style "El Kabong" crime fighting guise, would smash a guitar over a villain's head, the sound of a car's brake drum combined with a bulb horn for when Fred Flintstone would drop his bowling ball onto his foot, an automobile's tires squealing with a "skipping" effect added for when someone would slide to a sudden stop, a bass-drum-and-cymbal combination called the "Boom Crash" for when someone would fall down or smack into an object, a xylophone being struck rapidly on the same note for a tip-toeing effect, and a violin being plucked with the tuning pegs being raised to simulate something like pulling out a cat's whisker.
The cartoons also used Castle Thunder, a thunderclap sound effect that was commonly used in movies and TV shows from the 1940s to the 1970s. Other common sounds such as Peeong (a frying pan hitting sound with a doppler effect) and Bilp were used regularly in all of its cartoons. Starting in the 1960s, other cartoon studios began using the sound effects, including Nickelodeon Animation Studio, Universal Animation Studios, Disney Television Animation, Film Roman, MGM Animation, Cartoon Network Studios, DiC Entertainment, Hasbro Studios, Warner Bros. Animation and many others. By the 21st century, almost every animation studio was using the sound effects. Today, like Hanna-Barbera, they are used sparingly, while some cartoons and non-animated series like Warner Bros. Animation's "Krypto the Superdog", Nelvana's "The Magic School Bus", A&E's "Parking Wars", Disney's "Bonkers" and Spümcø's "Ren & Stimpy "Adult Party Cartoon"" make heavy use of the classic sound effects, mostly for a retro feel.
Some Hanna-Barbera sounds show up in various sound libraries such as Valentino and Audio Network. Hanna-Barbera Records (the studio's short-lived record division) released a set of LP records in the late 1960s entitled Hanna-Barbera's Drop-Ins, which contained quite a few of the classic sound effects. This LP set was only available for radio and TV stations and other production studios. In 1973, and again in 1986, H-B released a second sound effect record set; a seven-LP set entitled The Hanna-Barbera Library of Sounds, which, like the previous set, contained several of the classic sound effects. Like the previous set, this was only available to production companies and radio/TV stations. The 1986 version was also available as a two compact-disc set.
In 1993, the last president of the studio, Fred Seibert recalled his early production experiences with early LP releases of the studio's effects, and commissioned Sound Ideas to release a four-CD set entitled The Hanna-Barbera Sound FX Library, featuring nearly all of the original H-B sound effects used from 1957 to 1992, a more vast collection compared to the early LP releases (including the sounds H-B had borrowed from other studios). The sound effects were digitally remastered, so they would sound better on new digital soundtracks. A fifth CD was added in 1996, entitled Hanna-Barbera Lost Treasures, and featured more sound effects, including sounds from Space Ghost and The Impossibles.
Also in 1994, Rhino Records released a CD containing some of Hanna-Barbera's famous sound effects, titled simply as Hanna-Barbera Cartoon Sound FX, and also included some answering-machine messages and birthday greetings and short stories starring classic Hanna-Barbera characters, and was hosted by Fred Flintstone. In 1996, it was reissued with the Hanna-Barbera's Pic-A-Nic Basket of Cartoon Classics CD set, which also contained three other CDs of Hanna-Barbera TV theme songs and background music and songs from The Flintstones. Here, the CD was relabeled as The Greatest Cartoon Sound Effects Ever.
In the 1980s, Hanna-Barbera slowly began to cease using their trademark sound effects. This was especially true with the action cartoons of the time such as "Sky Commanders". By the 1990s, with cartoons shows, such as "Fish Police", "" and the animated specials "The Halloween Tree" and "Arabian Nights", the sound effects were virtually nonexistent, being replaced with newer, digitally recorded sounds (mostly from Sound Ideas), as well as the Looney Tunes sound library by Treg Brown. A few early 1990s cartoons continued to use the sound effects, such as "Tom & Jerry Kids" and "The Addams Family".
By 1996, each TV series from the studio typically had its own set of sound effects, including some selected from the classic Hanna-Barbera sound library, as well as some new ones and various sounds from Disney and Warner Bros. cartoons (this was especially true of "Dexter's Laboratory" and "Cow and Chicken"). Several of the classic H-B sound effects still pop up from time to time in many of Cartoon Network Studios' productions. However, on the recent Warner Bros. produced Scooby-Doo shows ("What's New, Scooby-Doo?", "Shaggy & Scooby-Doo Get a Clue!", "Scooby-Doo! Mystery Incorporated") and direct-to-video movies, the Hanna-Barbera sound effects are very rarely used.
References.
Notes
Bibliography

</doc>
<doc id="56549" url="http://en.wikipedia.org/wiki?curid=56549" title="Beta cell">
Beta cell

Beta cells (β cells) are a type of cell in the pancreas located in the islets of Langerhans. They make up 65-80% of the cells in the islets.
Function.
The primary function of a beta cell is to store and release insulin. Insulin is a hormone that brings about effects which reduce blood glucose concentration. Beta cells can respond quickly to spikes in blood glucose concentrations by secreting some of their stored insulin while simultaneously producing more.
Control of Insulin Secretion.
Voltage gated calcium ion channels and ATP-sensitive potassium ion channels are embedded in the cell surface membrane of beta cells. These ATP-sensitive potassium ion channels are normally open and the calcium ion channels are normally closed. Potassium ions diffuse out of the cell, down their concentration gradient, making the inside of the cell more negative with respect to the outside (as potassium ions carry a positive charge). At rest, this creates a potential difference across the cell surface membrane of -70mV.
When the glucose concentration outside the cell is high, glucose molecules move into the cell by facilitated diffusion, down its concentration gradient through the GLUT2 transporter. Since beta cells use glucokinase to catalyze the first step of glycolysis, metabolism only occurs around physiological blood glucose levels and above. Metabolism of the glucose produces ATP, which increases the ATP to ADP ratio.
The ATP-sensitive potassium ion channels close when this ratio rises. This means that potassium ions can no longer diffuse out of the cell. As a result, the potential difference across the membrane becomes more positive (as potassium ions accumulate inside the cell). This change in potential difference opens the voltage-gated calcium channels, which allows calcium ions from outside the cell to diffuse in down their concentration gradient. When the calcium ions enter the cell, they cause vesicles containing insulin to move to, and fuse with, the cell surface membrane, releasing insulin by exocytosis.
Pathology.
Diabetes mellitus can be experimentally induced for research purposes by streptozotocin or alloxan, which are specifically toxic to beta cells.

</doc>
<doc id="56551" url="http://en.wikipedia.org/wiki?curid=56551" title="Vocational education">
Vocational education

 
Vocational education is education within vocational schools that prepares people for a specific trade. It directly develops expertise in techniques related to technology, skill and scientific technique to span all aspects of the trade. Vocational education is classified as using procedural knowledge.
Generally known as career and technical education (CTE) or technical and vocational education and training (TVET) it prepares people for specific trades, crafts and careers at various levels from a trade, a craft, technician, or a high professional practitioner position in careers such as engineering, accountancy, nursing, medicine, architecture, law etc. Craft vocations are usually based on manual or practical activities and are traditionally non-academic but related to a specific trade, occupation . It is sometimes referred to as "technical education" as the trainee directly develops expertise in a particular group of techniques.
Vocational education can be at the secondary, post-secondary level, further education, and higher education level and can interact with the apprenticeship system. Increasingly, vocational education can be recognized in terms of recognition of prior learning and partial academic credit towards tertiary education (e.g., at a university) as credit.
Vocational education is related to the apprenticeship system of learning.
As the labour market becomes more specialized and require higher levels of skill, governments and businesses are increasingly investing in the future of vocational education through publicly funded training organizations and subsidized apprenticeship or traineeship initiatives for businesses. At the post-secondary level vocational education is typically provided by an institute of technology/polytechnic, university, or by a local community college.
Vocational education has diversified over the 20th century and now exists in industries such as retail, tourism, information technology, funeral services and cosmetics, as well as in the traditional crafts and cottage industries.
VET internationally.
Australia.
In Australia vocational education and training is mostly post-secondary and provided through the vocational education and training (VET) system by registered training organisations. However some senior schools do offer school-based apprenticeships and traineeships for students in years 10, 11 and 12. There were 24 Technical Colleges in Australia but now only 4 independent Trade Colleges remain with two in Queensland; one in Brisbane (Australian Trade College) and one on the Gold Coast (Australian Industry Trade College) and one in Adelaide and Perth. This system encompasses both public, TAFE, and private providers in a national training framework consisting of the , Australian Qualifications Framework and which define the assessment standards for the different vocational qualifications.
Australia’s apprenticeship system includes both traditional apprenticeships in traditional trades and "traineeships" in other more service-oriented occupations. Both involve a legal contract between the employer and the apprentice and provide a combination of school-based and workplace training. Apprenticeships typically last three to four years, traineeships only one to two years. Apprentices and trainees receive a wage which increases as they progress.
Since the states and territories are responsible for most public delivery and all regulation of providers, a central concept of the system is "national recognition" whereby the assessments and awards of any one registered training organisation must be recognised by all others and the decisions of any state or territory training authority must be recognised by the other states and territories. This allows national portability of qualifications and units of competency.
A crucial feature of the training package (which accounts for about 60% of publicly funded training and almost all apprenticeship training) is that the content of the vocational qualifications is theoretically defined by industry and not by government or training providers. A Training Package is "owned" by one of 11 Industry Skills Councils which are responsible for developing and reviewing the qualifications.
The National Centre for Vocational Education Research or NCVER is a not-for-profit company owned by the federal, state and territory ministers responsible for training. It is responsible for collecting, managing, analysing, evaluating and communicating research and statistics about vocational education and training (VET).
The boundaries between Vocational education and tertiary education are becoming more blurred. A number of vocational training providers such as NMIT, BHI and WAI are now offering specialised Bachelor degrees in specific areas not being adequately provided by Universities. Such Applied Courses include in the areas of Equine studies, Winemaking and viticulture, aquaculture, Information Technology, Music, Illustration, Culinary Management and many more.
Commonwealth of Independent States.
The largest and the most unified system of vocational education was created in the Soviet Union with the Professional`no-tehnicheskoye uchilische and, Tehnikum. But it became less effective with the transition of the economies of post-Soviet countries to a market economy.
European Union.
Education and training is the responsibility of Member States, but the single European labour market makes some cooperation on education imperative, including on vocational education and training. The 'Copenhagen process', based on the open method of cooperation between Member States, was launched in 2002 in order to help make vocational education and training better and more attractive to learners throughout Europe. The process is based on mutually agreed priorities that are reviewed periodically. Much of the activity is monitored by Cedefop, the European Centre for the Development of Vocational Training
Finland.
In Finland, vocational education belongs to secondary education. After the nine-year comprehensive school, almost all students choose to go to either a "lukio" (high school), which is an institution preparing students for tertiary education, or to a vocational school. Both forms of secondary education last three years, and give a formal qualification to enter university or "ammattikorkeakoulu", i.e. Finnish polytechnics. In certain fields (e.g. the police school, air traffic control personnel training), the entrance requirements of vocational schools include completion of the "lukio", thus causing the students to complete their secondary education twice.
The education in vocational school is free, and the students from low-income families are eligible for a state student grant. The curriculum is primarily vocational, and the academic part of the curriculum is adapted to the needs of a given course. The vocational schools are mostly maintained by municipalities.
After completing secondary education, one can enter higher vocational schools ("ammattikorkeakoulu", or "AMK") or universities.
It is also possible for a student to choose both lukio and vocational schooling. The education in such cases last usually from 3 to 4 years.
German-language areas.
Vocational education is an important part of the education systems in Austria, Germany, Liechtenstein and Switzerland (including the French and the Italian speaking parts of the country) and one element of the German model.
For example, in Germany a law (the "Berufsausbildungsgesetz") was passed in 1969 which regulated and unified the vocational training system and codified the shared responsibility of the state, the unions, associations and chambers of trade and industry. The system is very popular in modern Germany: in 2001, two thirds of young people aged under 22 began an apprenticeship, and 78% of them completed it, meaning that approximately 51% of all young people under 22 have completed an apprenticeship. One in three companies offered apprenticeships in 2003; in 2004 the government signed a pledge with industrial unions that all companies except very small ones must take on apprentices.
The vocational education systems in the other German speaking countries are very similar to the German system and a vocational qualification from one country is generally also recognized in the other states within this area.
Hong Kong.
In Hong Kong, vocational education is usually for post-secondary 6 students. The Hong Kong Institute of Vocational Education (IVE) provides training in nine different vocational fields, namely: Applied Science; Business Administration; Child Education and Community Services; Construction; Design; Printing, Textiles and Clothing; Hotel, Service and Tourism Studies; Information Technology; Electrical and Electronic Engineering; and Mechanical, Manufacturing and Industrial Engineering.
Hungary.
Normally at the end of elementary school (at age 14) students are directed to one of three types of upper secondary education: one academic track (gymnasium) and two vocational tracks. Vocational secondary schools (szakközépiskola) provide four years of general education and also prepare students for the maturata. These schools combine general education with some specific subjects, referred to as pre-vocational education and career orientation. At that point many students enrol in a post-secondary VET programme often at the same institution, to obtain a vocational qualification, although they may also seek entry to tertiary education.
Vocational training schools (szakiskola) initially provide two years of general education, combined with some pre-vocational education and career orientation, they then choose an occupation, and then receive two or three years of vocational education and training focusing on that occupation – such as bricklayer. Students do not obtain the maturata but a vocational qualification at the end of a successfully completed programme. Demand for vocational training schools, both from the labour market and among students, has declined while it has increased for upper secondary schools delivering the maturata.
India.
Vocational training in India is provided on a full-time as well as part-time basis. Full-time programs are generally offered through I.T.I.s Industrial training institutes. The nodal agency for granting the recognition to the I.T.I.s is NCVT, which is under the Min. of labour, Govt. of India. Part-time programs are offered through state technical education boards or universities who also offer full-time courses. Vocational training has been successful in India only in industrial training institutes and that too in engineering trades. There are many private institutes in India which offer courses in vocational training and finishing, but most of them have not been recognized by the Government. India is a pioneer in vocational training in Film & Television, and Information Technology.AAFT, Audio Production & Recording ILM Academy. Maharashtra State Government also offers vocational Diplomas in various Trades .
Vocational Higher Secondary schools are under MHRD in India. All the state governments runs vocational schools. In Kerala, 389 vocational schools are there with 42 different courses. Commerce & Business, Tourism, Agriculture, Automobile, Air conditioning, Live stock management, Lab Technician, Agriculture are some prominent courses. The students get reservation and preference in PSC appointments
Japan.
Japanese vocational schools are known as "senmon gakkō". They are part of Japan's higher education system. They are two-year schools that many students study at after finishing high school (although it is not always required that students graduate from high school). Some have a wide range of majors, others only a few majors. Some examples are computer technology, fashion, and English.
South Korea.
Vocational high schools offer programmes in five fields: agriculture, technology/engineering, commerce/business, maritime/fishery, and home economics. In principle, all students in the first year of high school (10th grade) follow a common national curriculum, In the second and third years (11th and 12th grades) students are offered courses relevant to their specialisation. In some programmes, students may participate in workplace training through co-operation between schools and local employers. The government is now piloting Vocational Meister Schools in which workplace training is an important part of the programme. Around half of all vocational high schools are private. Private and public schools operate according to similar rules; for example, they charge the same fees for high school education, with an exemption for poorer families.
The number of students in vocational high schools has decreased, from about half of students in 1995 down to about one-quarter today. To make vocational high schools more attractive, in April 2007 the Korean government changed the name of vocational high schools into professional high schools. With the change of the name the government also facilitated the entry of vocational high school graduates to colleges and universities.
Most vocational high school students continue into tertiary education; in 2007 43% transferred to junior colleges and 25% to university. At tertiary level, vocational education and training is provided in junior colleges (two- and three-year programmes) and at polytechnic colleges. Education at junior colleges and in two-year programmes in polytechnic colleges leads to an Industrial Associate degree. Polytechnics also provide one-year programmes for craftsmen and master craftsmen and short programmes for employed workers. The requirements for admission to these institutions are in principle the same as those in the rest of tertiary sector (on the basis of the College Scholastic Aptitude Test) but candidates with vocational qualifications are given priority in the admission process. Junior colleges have expanded rapidly in response to demand and in 2006 enrolled around 27% of all tertiary students.
95% of junior college students are in private institutions. Fees charged by private colleges are approximately twice those of public institutions. Polytechnic colleges are state-run institutions under the responsibility of the Ministry of Labour; government funding keeps student fees much lower than those charged by other tertiary institutions. Around 5% of students are enrolled in polytechnic colleges.
Malaysia.
Skills training are no longer depicted as second-class education in Malaysia. There are numerous vocational education centres here including vocational schools (high schools to train skilled students), technic schools (high schools to train future engineers) and vocational colleges all of them under the Ministry of Education. Then there are 33 polytechnics and 86 community colleges under the Ministry of Higher Education; 10 MARA Advanced Skills Colleges, 13 MARA Skills Institutes, 286 GIATMARAs under Majlis Amanah Rakyat (MARA) and 15 National Youth Skills Institutes under Ministry of Youth and Sports. The first vocational institute in Malaysia is the Industrial Training Institute of Kuala Lumpur established in 1964 under the Manpower Department. Other institutes under the same department including 8 Advanced Technology Training Centres, one Centre for Instructor and Advanced Skill Training, one Japan-Malaysia Technical Institute and the other 21 ITIs.
Mexico.
In Mexico, both federal and state governments are responsible for the administration of vocational education. Federal schools are funded by the federal budget, in addition to their own funding sources. The state governments are responsible for the management of decentralised institutions, such as the State Centres for Scientific and Technological Studies (CECyTE) and Institutes of Training for Work (ICAT). These institutions are funded 50% from the federal budget and 50% from the state budget. The state governments also manage and fund "decentralised institutions of the federation", such as CONALEP schools.
Compulsory education (including primary and lower secondary education) finishes at the age of 15 and about half of those aged 15-to-19 are enrolled full-time or part-time in education. All programmes at upper secondary level require the payment of a tuition fee.
The upper secondary vocational education system in Mexico includes over a dozen subsystems (administrative units within the Upper Secondary Education Undersecretariat of the Ministry of Public Education, responsible for vocational programmes) which differ from each other to varying degrees in content, administration, and target group. The large number of school types and corresponding administrative units within the Ministry of Public Education makes the institutional landscape of vocational education and training complex by international standards.
Vocational education and training provided under the Upper Secondary Education Under secretariat includes three main types of programme:
The Netherlands.
Nearly all of those leaving lower secondary school enter upper secondary education, and around 50% of them follow one of four vocational programmes; technology, economics, agricultural, personal/social services & health care. These programmes vary from 1 to 4 years (by level; only level 2, 3 and 4 diplomas are considered formal ‘start qualifications’ for successfully entering the labour market). The programmes can be attended in either of two pathways. One either involving a minimum of 20% of school time (apprenticeship pathway; BBL-BeroepsBegeleidende Leerweg) or the other, involving a maximum of 80% schooltime (BOL -BeroepsOpleidende Leerweg). The remaining time in both cases is apprenticeship/work in a company. So in effect, students have a choice out of 32 trajectories, leading to over 600 professional qualifications.
BBL-Apprentices usually receive a wage negotiated in collective agreements. Employers taking on these apprentices receive a subsidy in the form of a tax reduction on the wages of the apprentice. (WVA-Wet vermindering afdracht).
Level 4 graduates of senior secondary VET may go directly to institutes for Higher Profession Education and Training (HBO-Hoger beroepsonderwijs), after which entering university is a possibility.
The social partners participate actively in the development of policy. As of January 1, 2012 they formed a foundation for Co operation Vocational Education and Entrepreneurship (St. SBB – stichting Samenwerking Beroepsonderwijs Bedrijfsleven; www.s-bb.nl). Its responsibility is to advise the Minister on the development of the national vocational education and training system, based on the full consensus of the constituent members (the representative organisations of schools and of entrepreneurship and their centres of expertise). Special topics are Qualification & Examination, Apprenticeships (BPV-Beroepspraktijkvorming) and (labourmarket) Efficiency of VET.
The Centres of Expertices are linked to the four vocational education programmes provided in senior secondary VET on the content of VET programmes and on trends and future skill needs.
The Local County Vocational Training (MBO Raad www.mboraad.nl) represents the VET schools in this foundation and advise on the quality, operations and provision of VET.
Source: Dutch vocational education in a nutshell www.expatica.com/nl/education/courses_workshops/Dutch-vocational-education-and-training-in-a-nutshell_14318.html
New Zealand.
New Zealand is served by 39 Industry Training Organisations (ITO). The unique element is that ITOs purchase training as well as set standards and aggregate industry opinion about skills in the labour market. Industry Training, as organised by ITOs, has expanded from apprenticeships to a more true lifelong learning situation with, for example, over 10% of trainees aged 50 or over. Moreover much of the training is generic. This challenges the prevailing idea of vocational education and the standard layperson view that it focuses on apprenticeships.
One source for information in New Zealand is the Industry Training Federation.. Another is the Ministry of Education ..
Polytechnics, Private Training Establishments, Wananga and others also deliver vocational training, amongst other areas.
Norway.
Nearly all those leaving lower secondary school enter upper secondary education, and around half follow one of 9 vocational programmes. These programmes typically involve two years in school followed by two years of apprenticeship in a company. The first year provides general education alongside introductory knowledge of the vocational area. During the second year, courses become more trade-specific.
Apprentices receive a wage negotiated in collective agreements ranging between 30% and 80% of the wage of a qualified worker; the percentage increasing over the apprenticeship period. Employers taking on apprentices receive a subsidy, equivalent to the cost of one year in school.
After the two years vocational school programme some students opt for a third year in the ‘general’ programme as an alternative to an apprenticeship. Both apprenticeship and a third year of practical training in school lead to the same vocational qualifications. Upper secondary VET graduates may go directly to Vocational Technical Colleges, while those who wish to enter university need to take a supplementary year of education.
The social partners participate actively in the development of policy. The National Council for Vocational Education and Training advises the Minister on the development of the national vocational education and training system. The Advisory Councils for Vocational Education and Training are linked to the nine vocational education programmes provided in upper secondary education and advise on the content of VET programmes and on trends and future skill needs. The National Curriculum groups assist in deciding the contents of the vocational training within the specific occupations. The Local County Vocational Training Committees advise on the quality, provision of VET and career guidance.
Paraguay.
In Paraguay, vocational education is known as "Bachillerato Técnico" and is part of the secondary education system. These schools combine general education with some specific subjects, referred to as pre-vocational education and career orientation. After nine years of "Educación Escolar Básica" (Primary School), the student can choose to go to either a "Bachillerato Técnico" (Vocational School) or a "Bachillerato Científico" (High School). Both forms of secondary education last three years, and are usually located in the same campus called "Colegio".
After completing secondary education, one can enter to the universities. It is also possible for a student to choose both Técnico and Científico schooling.
Sri Lanka.
Vocational training from Agricultural subjects to ICT related subjects are available in Sri Lanka. 
In 2005 the Ministry of Vocational and Technical Training (MVTT) introduced the National Vocational Qualifications (NVQ) framework which was an important milestone for the education, economic and social development of Sri Lanka. The NVQ framework consists of seven levels of instruction. NVQ levels 1 to 4 are for craftsmen designation and successful candidates are issued with National certificates. NVQ levels 5 and 6 are Diploma level, whereas Level 7 is for degree equivalent qualification.
Training courses are provided by many institutions island wide. All training providers (public and private) must obtain institutional registration and course accreditation from the Tertiary and Vocational Education Commission (TVEC).In order to obtain registration institutions must satisfy specific criteria: infrastructure, basic services, tools and equipment, quality of instruction and staff, based on curriculum and syllabus, and quality of management and monitoring systems.
Government Ministries and Agencies involved in Vocational Training are The Ministry of Vocational and Technical Training (MVTT), The Tertiary and Vocational Education Commission (TVEC), The National Apprentice and Industrial Training Authority (NAITA), The Department of Technical Education and Training (DTET), The Vocational Training Authority (VTA) and the National Youth Services Council (NYSC).
Sweden.
Nearly all of those leaving compulsory schooling immediately enter upper secondary schools, and most complete their upper secondary education in three years. Upper secondary education is divided into 13 vocationally oriented and 4 academic national programmes. Slightly more than half of all students follow vocational programmes. All programmes offer broad general education and basic eligibility to continue studies at the post-secondary level. In addition, there are local programmes specially designed to meet local needs and ‘individual’ programmes.
A 1992 school reform extended vocational upper secondary programmes by one year, aligning them with three years of general upper secondary education, increasing their general education content, and making core subjects compulsory in all programmes. The core subjects (which occupy around one-third of total teaching time in both vocational and academic programmes) include English, artistic activities, physical education and health, mathematics, natural science, social studies, Swedish or Swedish as a second language, and religious studies. In addition to the core subjects, students pursue optional courses, subjects which are specific to each programme and a special project.
Vocational programmes include 15 weeks of workplace training (Arbetsplatsförlagd utbildning – APU) over the three-year period. Schools are responsible for arranging workplace training and verifying its quality. Most municipalities have advisory bodies: programme councils (programmråd) and vocational councils (yrkesråd) composed of employers’ and employees’ representatives from the locality. The councils advise schools on matters such as provision of workplace training courses, equipment purchase and training of supervisors in APU.
Switzerland.
Nearly two thirds of those entering upper secondary education enter the vocational education and training system. At this level, vocational education and training is mainly provided through the ‘dual system’. Students spend some of their time in a vocational school; some of their time doing an apprenticeship at a host company; and for most programmes, students attend industry courses at an industry training centre to develop complementary practical skills relating to the occupation at hand. Common patterns are for students to spend one- two days per week at the vocational school and three-four days doing the apprenticeship at the host company; alternatively they alternate between some weeks attending classes at the vocational school and some weeks attending industry courses at an industry training centre. A different pattern is to begin the programme with most of the time devoted to in-school education and gradually diminishing the amount of in-school education in favour of more in-company training.
Switzerland draws a distinction between vocational education and training (VET) programmes at upper-secondary level, and professional education and training (PET) programmes, which take place at tertiary B level. In 2007, more than half of the population aged 25–64 had a VET or PET qualification as their highest level of education. In addition, universities of applied sciences (Fachhochschulen) offer vocational education at tertiary A level. Pathways enable people to shift from one part of the education system to another.
Turkey.
Students in Turkey may choose vocational high schools after completing the 8-year-long compulsory primary education. Vocational high school graduates may pursue 2 year-long polytechnics or may continue with a related tertiary degree.
Municipalities in Turkey also offer vocational training. The metropolitan municipality of Istanbul, the most populous city in Turkey, offers year long free vocational programs in a wide range of topics through ISMEK, an umbrella organization formed under the municipality.
United Kingdom.
The first "Trades School" in the UK was "Stanley Technical Trades School" (now Harris Academy South Norwood) which was designed, built and set up by William Stanley. The initial idea was thought of in 1901, and the school opened in 1907.
The system of vocational education in the UK initially developed independently of the state, with bodies such as the RSA and City & Guilds setting examinations for technical subjects. The Education Act 1944 made provision for a Tripartite System of grammar schools, secondary technical schools and secondary modern schools, but by 1975 only 0.5% of British senior pupils were in technical schools, compared to two-thirds of the equivalent German age group.
Successive recent British Governments have made attempts to promote and expand vocational education. In the 1970s, the Business And Technology Education Council was founded to confer further and higher education awards, particularly to further education colleges in the United Kingdom. In the 1980s and 1990s, the Conservative Government promoted the Youth Training Scheme, National Vocational Qualifications and General National Vocational Qualifications. However, youth training was marginalised as the proportion of young people staying on in full-time education increased.
In 1994, publicly funded Modern Apprenticeships were introduced to provide "quality training on a work-based (educational) route". Numbers of apprentices have grown in recent years and the Department for Children, Schools and Families has stated its intention to make apprenticeships a "mainstream" part of England's education system.
In the UK some higher technician engineering positions that require 4-5 year apprenticeship require academic study to HNC / HND or higher City & Guilds level. Apprenticeships are increasingly recognised as the gold standard for work-based training. There are three levels of Apprenticeship available for those aged 16 and over:
Apprentices work towards work-based learning qualifications such as a Level 2 Competence Qualification, Functional Skills and, in most cases, a relevant knowledge-based qualification.
Apprentices work towards work-based learning such as a Level 3 Competence Qualification, Functional Skills and, in most cases, a relevant knowledgebased qualification.
Apprentices work towards work-based learning qualifications such as a Level 4 and 5 Competence Qualification, Functional Skills and, in some cases, a knowledge-based qualification such as a Foundation Degree.
References.
14 Prof. Dr. Philipp Gonon, Professor für Berufsbildung, Institut für Erziehungswissenschaft, Universität Zürich

</doc>
<doc id="56552" url="http://en.wikipedia.org/wiki?curid=56552" title="Jet lag">
Jet lag

Jet lag, medically referred to as desynchronosis and rarely as circadian dysrhythmia, is a physiological condition which results from alterations to the body's circadian rhythms resulting from rapid long-distance transmeridian (east–west or west–east) travel on high-speed aircraft. For example, someone traveling from New York to California feels as if the time were three hours later. It was previously classified as one of the circadian rhythm sleep disorders. 
The condition of jet lag may last several days until one is fully adjusted to the new time zone, and a recovery rate of one day per time zone crossed is a suggested guideline. The issue of jet lag is especially pronounced for airline pilots, crew, and frequent travelers. Airlines have regulations aimed at combating pilot fatigue caused by jet lag.
The common term jet lag is used, because before the arrival of passenger jet aircraft, it was generally uncommon to travel far and fast enough to cause jet lag. Trips in propeller-driven aircraft and trains were slower and of more limited distance than jet flights, and thus did not contribute as widely to the problem.
Cause.
Jet lag is a chronobiological problem, similar to issues often induced by shift work and the circadian rhythm sleep disorders. When travelling across a number of time zones, the body clock (circadian rhythm) will be out of synchronization with the destination time, as it experiences daylight and darkness contrary to the rhythms to which it has grown accustomed. The body's natural pattern is upset, as the rhythms that dictate times for eating, sleeping, hormone regulation and body temperature variations no longer correspond to the environment nor to each other in some cases. To the degree that the body cannot immediately realign these rhythms, it is jet lagged.
The speed at which the body adjusts to the new schedule depends on the individual; some people may require several days to adjust to a new time zone, while others experience little disruption. Crossing one or two time zones does not typically cause jet lag.
The condition is not linked to the length of flight, but to the trans-meridian (west–east) distance traveled. A ten-hour flight from Europe to southern Africa does not cause jet lag, as travel is primarily north–south. A five-hour flight from the east to the west coast of the United States may well result in jet lag.
Crossing the International Date Line does not contribute to jet lag, as the guide for calculating jet lag is the number of time zones crossed, and the maximum possible disruption is plus or minus 12 hours. If the time difference between two locations is greater than 12 hours, subtract that number from 24. Note, for example, that the time zone GMT+14 will be at the same time of day as GMT−10, though the former is one day ahead of the latter.
Symptoms.
The symptoms of jet lag can be quite varied, depending on the amount of time zone alteration, time of day and the susceptibility of individual differences. Sleep disturbance occurs, with poor sleep upon arrival, sleep disruption including trouble falling asleep (if flying east), early awakening (if flying west) and interrupted sleep with multiple awakenings and trouble remaining asleep. Cognitive effects include poorer performance on mental tasks and concentration, increased fatigue, headaches, and irritability, and problems with digestion including indigestion, changes in the frequency of defecation and consistency of feces and reduced interest in and enjoyment of food. Symptoms are caused by a circadian rhythm that is out of sync with the day-night cycle of the destination. Jet lag has been measured with simple analogue scales but a study has shown that these are relatively blunt for assessing all the problems associated with jet lag. The Liverpool Jet lag Questionnaire was developed to measure all the symptoms of jet lag at several times of day, and this dedicated measurement tool has been used to assess jet lag in athletes.
Jet lag usually requires a change of three time zones or more to occur, though some individuals can be affected by as little as a single time zone or the single-hour shift of daylight saving time. Symptoms and consequences of jet lag can be a significant area of concern for athletes traveling east or west to competitions as performance is often dependent on a combination of physical and mental characteristics that are impacted by jet lag.
Travel fatigue.
Travel fatigue is general fatigue, disorientation and headache caused by a disruption in routine, time spent in a cramped space with little chance to move around, a low-oxygen environment, and dehydration caused by limited food and dry air. It does not necessarily have the shift in circadian rhythms that cause jet lag. Travel fatigue can occur without crossing time zones, and it often disappears after a single day accompanied by a night of high-quality sleep.
Management.
Light is the strongest stimulus for re-aligning a person's sleep-wake schedule and careful control of exposure to and avoidance of bright lights can speed adjustment to a new time zone.
Management after travelling east.
Traveling east causes more problems than traveling west, because the body clock has to be advanced, which is harder than delaying it, and the necessary exposure to light to realign the body clock does not tie in with the day/night cycle at the destination.
Traveling east by six to nine time zones causes the biggest problems, as it is desirable to avoid light in the mornings.
Waterhouse et al. recommend:
Traveling by 10 hours or more is usually best managed by assuming it is a 14h westward transition and delaying the body clock. A customized jet lag program can be obtained from an online jet lag calculator. These programs consider the sleep pattern of the user, as well as the number of time zones crossed and direction of travel (east or west). The efficacy of these jet lag calculators has not been documented.
Management when travelling west.
Travelling west causes fewer problems than travelling east, and it is usually sufficient to seek exposure to light during the day and avoid it at night.
Other management methods.
Light therapy is a popular method used by professional athletes to reduce jet lag. Commonly referred to as sleep glasses, these devices inhibit the production of melatonin and advance or delay the circadian rhythm. Worn at the correct times sleep glasses can adjust the circadian rhythm closer to the destination time even before the user leaves their departure city.
The benefit of using the hormone melatonin is likely to be greater the more time zones are crossed, and less for westward flights than for eastward ones. There remain issues regarding the appropriate dosage and dosage timing of melatonin, in addition to the legality of the substance in certain countries. In addition, there are questions regarding how effective it may actually be. For athletes, anti-doping agencies may prohibit or limit its use.
Timing of exercise and food consumption have also been suggested as remedies, though their applicability in humans and practicality for most travellers are not certain and no firm guidelines exist. There is very little data supporting the use of diet to adjust to jet lag. While there are data supporting the use of exercise, the intensity of exercise that may be required is significant, and possibly difficult to maintain for non-athletes. These strategies may be used both before departure and after landing. Individuals may differ in their susceptibility to jet lag and ability to quickly adjust to new sleep-wake schedules.
Short-acting sleep medications can be used to improve sleep quality and timing, and stimulants can be used to promote wakefulness, though both these interventions are not generally used in non-military situations and research results on their success at adapting to jet lag are inconsistent. Among the stimulants, only caffeine may be readily available to the public.
For time changes of fewer than three hours, jet lag is unlikely to be a concern, and if travel is for short periods (three days or fewer) retaining a "home schedule" may be better for most people. Sleeping on the plane is only advised if it is within the destination's normal sleep time.
Direction of travel.
North–south flights that do not cross time zones do not cause jet lag. However, crossing of the Arctic Ocean or even the North Pole (often the shortest route between N.E. Europe and Alaska or the Canadian West Coast and East Asia) does cause a significant time change. The jet travel from Alaska to N.E. Europe causes a pattern of a jet lag very similar to an eastward flight at lower latitudes.
In general, adjustment to the new time zone is easier for east-to-west travel than west-to-east. A westward adjustment takes, in days, approximately half the number of time zones crossed. For eastward travel, adjusting to the new time zone takes, in days, approximately two-thirds the number of time zones crossed.

</doc>
<doc id="56556" url="http://en.wikipedia.org/wiki?curid=56556" title="Ketone bodies">
Ketone bodies

Ketone bodies are three water-soluble molecules that are produced by the liver from fatty acids during periods of low food intake (fasting) or carbohydrate restriction for cells of the body to use as energy instead of glucose. Two of the three are used as a source of energy in the heart and brain while the third (acetone) is a degradation breakdown product of acetoacetic acid. Radioactive tracing of acetone determines that between 2% and 30% is excreted from the body. Ketone bodies are picked up by cells and converted back into acetyl-CoA which then enters the citric acid cycle and is oxidized in the mitochondria for energy. In the brain, ketone bodies are also used to make acetyl-CoA into long chain fatty acids, which cannot pass through the blood-brain barrier. The liver additionally produces glucose from non-carbohydrate sources other than fatty acids by a process called gluconeogenesis during starvation. In the brain, ketone bodies are a vital source of energy during fasting or strenuous exercise. Although termed "bodies", they are molecules, not particles.
The three endogenous ketone bodies are acetone, acetoacetic acid, and "beta"-hydroxybutyric acid. Other ketone bodies like "beta"-ketopentanoate and "beta"-hydroxypentanoate may be created as a result of the metabolism of synthetic triglycerides, such as triheptanoin.
Uses in the heart, brain and muscle (but not the liver).
Ketone bodies can be used for energy. Ketone bodies are transported from the liver to other tissues, where acetoacetate and "beta"-hydroxybutyrate can be reconverted to acetyl-CoA to produce energy, via the citric acid cycle. Ketone bodies cannot be used by the liver for energy, because the liver lacks the enzyme β-ketoacyl-CoA transferase, also called thiophorase. Acetone in low concentrations is taken up by the liver and undergoes detoxification through the methylglyoxal pathway which ends with lactate. Acetone in high concentrations due to prolonged fasting or a ketogenic diet is absorbed by cells other than those in the liver and enters a different pathway via 1,2-propanediol. Though the pathway follows a different series of steps requiring ATP, 1,2-propanediol can be turned into pyruvate.
The heart preferentially utilizes fatty acids for energy under normal physiologic conditions. However, under ketotic conditions, the heart can effectively utilize ketone bodies for energy.
The brain gets a portion of its energy from ketone bodies when glucose is less available (e.g., during fasting, strenuous exercise, low carbohydrate, ketogenic diet and in neonates). In the event of low blood glucose, most other tissues have additional energy sources besides ketone bodies (such as fatty acids), but the brain has an obligatory requirement for some glucose. After the diet has been changed to lower blood glucose for 3 days, the brain gets 25% of its energy from ketone bodies. After about 4 days, this goes up to 70% (during the initial stages the brain does not burn ketones, since they are an important substrate for lipid synthesis in the brain). Furthermore, ketones produced from omega-3 fatty acids may reduce cognitive deterioration in old age.
Production.
Ketone bodies are produced from acetyl-CoA (see ketogenesis) mainly in the mitochondrial matrix of hepatocytes (liver tissue) when carbohydrates are so scarce that energy must be obtained from breaking down fatty acids. Because of the high level of acetyl CoA present in the cell, the pyruvate dehydrogenase complex is inhibited, whereas pyruvate carboxylase becomes activated. High levels of ATP and NADH inhibit the enzyme isocitrate dehydrogenase in the TCA cycle (tricarboxylic acid cycle or the Krebs cycle) and as a result cause an increase in the concentration of malate (due to the equilibrium between itself and oxaloacetate). The malate then leaves the mitochondrion and undergoes gluconeogenesis. The elevated level of NADH and ATP result from β-oxidation of fatty acids. Unable to be used in the citric acid cycle, the excess acetyl-CoA is therefore rerouted to ketogenesis. Such a state in humans is referred to as the fasted state.
Acetone is produced by spontaneous decarboxylation of acetoacetate, meaning this ketone body will break down if it is not used for energy and be removed as waste or converted to pyruvate. This "use it or lose it" factor may contribute to the weight loss found in ketogenic diets. Acetone cannot be converted back to acetyl-CoA, so it is excreted in the urine, or (as a consequence of its high vapor pressure) exhaled unless first converted to Pyruvate. Acetone is responsible for the characteristic "Sweet & fruity" odor of the breath of persons in ketoacidosis.
Ketosis and ketoacidosis.
In normal individuals, there is a constant production of ketone bodies by the liver and their utilization by extrahepatic tissues. The concentration of ketone bodies in blood is maintained around 1 mg/dl. Their excretion in urine is very low and undetectable by routine urine tests (Rothera's test).
When the rate of synthesis of ketone bodies exceeds the rate of utilization, their concentration in blood increases; this is known as "ketonemia". This is followed by "ketonuria" – excretion of ketone bodies in urine. The overall picture of ketonemia and ketonuria is commonly referred as ketosis. Smell of acetone in breath is a common feature in ketosis.
When a type 1 diabetic suffers a biological stress event (sepsis, heart attack, infection) or fails to administer enough insulin they may suffer the pathological condition ketoacidosis. Liver cells increase metabolism of fatty acids into ketones in an attempt to supply energy to peripheral cells which are unable to transport glucose in the absence of insulin. The resulting very high levels of blood glucose and ketone bodies lower the pH of the blood and trigger the kidneys to attempt to excrete the glucose and ketones. Osmotic diuresis of glucose will cause further removal of water and electrolytes from the blood resulting in potentially fatal dehydration, tachycardia and hypotension.
Individuals who follow a low-carbohydrate diet will also develop ketosis, this induced ketosis is sometimes called nutritional ketosis, but the level of ketone body concentrations are on the order of 0.5-5 mM whereas the pathological ketoacidosis is 15-25 mM.
As the mainstream diet of diabetic patients is so high in carbohydrate, ketosis is rarely seen without ketoacidosis resulting from low serum insulin levels. Many medical practitioners mistake well regulated nutritional ketosis for pathological ketoacidosis.
Impact upon pH.
Both acetoacetic acid and "beta"-hydroxybutyric acid are acidic, and, if levels of these ketone bodies are too high, the pH of the blood drops, resulting in ketoacidosis, a complication of untreated Type I diabetes, and sometimes in end stage Type II (see diabetic ketoacidosis).

</doc>
<doc id="56557" url="http://en.wikipedia.org/wiki?curid=56557" title="Blood glucose monitoring">
Blood glucose monitoring

Blood glucose monitoring is a way of testing the concentration of glucose in the blood (glycemia). Particularly important in the care of diabetes mellitus, a blood glucose test is performed by piercing the skin (typically, on the finger) to draw blood, then applying the blood to a chemically active disposable 'test-strip'. Different manufacturers use different technology, but most systems measure an electrical characteristic, and use this to determine the glucose level in the blood. The test is usually referred to as capillary blood glucose.
Healthcare professionals advise patients with diabetes on the appropriate monitoring regime for their condition. Most people with Type 2 diabetes test at least once per day. Diabetics who use insulin (all Type 1 diabetes and many Type 2s) usually test their blood sugar more often (3 to 10 times per day), both to assess the effectiveness of their prior insulin dose and to help determine their next insulin dose.
Improved technology for measuring blood glucose is rapidly changing the standards of care for all diabetic people.
Purpose.
Blood glucose monitoring reveals individual patterns of blood glucose changes, and helps in the planning of meals, activities, and at what time of day to take medications.
Also, testing allows for quick response to high blood sugar (hyperglycemia) or low blood sugar (hypoglycemia). This might include diet adjustments, exercise, and insulin (as instructed by the health care provider).
Blood glucose meters.
A blood glucose meter is an electronic device for measuring the blood glucose level. A relatively small drop of blood is placed on a disposable test strip which interfaces with a digital meter. Within several seconds, the level of blood glucose will be shown on the digital display.
Needing only a small drop of blood for the meter means that the time and effort required for testing is reduced and the compliance of diabetic people to their testing regimens is improved. Although the cost of using blood glucose meters seems high, it is believed to be a cost benefit relative to the avoided medical costs of the complications of diabetes.
Recent advances include:
Continuous glucose monitoring.
A continuous glucose monitor (CGM) determines glucose levels on a continuous basis (every few minutes). A typical system consists of:
Continuous glucose monitors measure the glucose level of interstitial fluid. Shortcomings of CGM systems due to this fact are:
Patients therefore require traditional fingerstick measurements for calibration (typically twice per day) and are often advised to use fingerstick measurements to confirm hypo- or hyperglycemia before taking corrective action.
The lag time discussed above has been reported to be about 5 minutes. Anecdotally, some users of the various systems report lag times of up to 10–15 minutes. This lag time is insignificant when blood sugar levels are relatively consistent. However, blood sugar levels, when changing rapidly, may read in the normal range on a CGM system while in reality the patient is already experiencing symptoms of an out-of-range blood glucose value and may require treatment. Patients using CGM are therefore advised to consider both the absolute value of the blood glucose level given by the system as well as any trend in the blood glucose levels. For example, a patient using CGM with a blood glucose of 100 mg/dl on their CGM system might take no action if their blood glucose has been consistent for several readings, while a patient with the same blood glucose level but whose blood glucose has been dropping steeply in a short period of time might be advised to perform a fingerstick test to check for hypoglycemia.
Continuous monitoring allows examination of how the blood glucose level reacts to insulin, exercise, food, and other factors. The additional data can be useful for setting correct insulin dosing ratios for food intake and correction of hyperglycemia. Monitoring during periods when blood glucose levels are not typically checked (e.g. overnight) can help to identify problems in insulin dosing (such as basal levels for insulin pump users or long-acting insulin levels for patients taking injections). Monitors may also be equipped with alarms to alert patients of hyperglycemia or hypoglycemia so that a patient can take corrective action(s) (after fingerstick testing, if necessary) even in cases where they do not feel symptoms of either condition. While the technology has its limitations, studies have demonstrated that patients with continuous sensors experience less hyperglycemia and also reduce their glycosylated hemoglobin levels.
Currently, continuous blood glucose monitoring is not automatically covered by health insurance in the United States in the same way that most other diabetic supplies are covered (e.g. standard glucose testing supplies, insulin, and even insulin pumps). However, an increasing number of insurance companies do cover continuous glucose monitoring supplies (both the receiver and disposable sensors) on a case-by-case basis if the patient and doctor show a specific need. The lack of insurance coverage is exacerbated by the fact that disposable sensors must be frequently replaced. Some sensors have been U.S. Food and Drug Administration (FDA) approved for 7- and 3-day use, though some patients wear sensors for longer than the recommended period) and the receiving meters likewise have finite lifetimes (less than 2 years and as little as 6 months). This is one factor in the slow uptake in the use of sensors that have been marketed in the United States.
The principles, history and recent developments of operation of electrochemical glucose biosensors are discussed in a chemical review by Joseph Wang.
Glucose sensing bio-implants.
Investigations on the use of test strips have shown that the required self-injury acts as a psychological barrier restraining the patients from sufficient glucose control. As a result, secondary diseases are caused by excessive glucose levels. A significant improvement of diabetes therapy might be achieved with an implantable sensor that would continuously monitor blood sugar levels within the body and transmit the measured data outside. The burden of regular blood testing would be taken from the patient, who would instead follow the course of their glucose levels on an intelligent device like a laptop or a smart phone.
Glucose concentrations do not necessarily have to be measured in blood vessels, but may also be determined in the interstitial fluid, where the same levels prevail – with a time lag of a few minutes – due to its connection with the capillary system. However, the enzymatic glucose detection scheme used in single-use test strips is not directly suitable for implants. One main problem is caused by the varying supply of oxygen, by which glucose is converted to glucono lactone and H2O2 by glucose oxidase. Since the implantation of a sensor into the body is accompanied by growth of encapsulation tissue, the diffusion of oxygen to the reaction zone is continuously diminished. This decreasing oxygen availability causes the sensor reading to drift, requiring frequent re-calibration using finger-sticks and test strips.
One approach to achieving long-term glucose sensing is to measure and compensate for the changing local oxygen concentration. Other approaches replace the troublesome glucose oxidase reaction with a reversible sensing reaction, known as an affinity assay. This scheme was originally put forward by Schultz & Sims in 1978. A number of different affinity assays have been investigated, with fluorescent assays proving most common. MEMS technology has recently allowed for smaller and more convenient alternatives to fluorescent detection, via measurement of viscosity. Investigation of affinity-based sensors has shown that encapsulation by body tissue does not cause a drift of the sensor signal, but only a time lag of the signal compared to the direct measurement in blood.
Non-invasive technologies.
Some new technologies to monitor blood glucose levels will not require access to blood to read the glucose level. Non-invasive technologies include near IR detection, ultrasound and dielectric spectroscopy. These will free the person with diabetes from finger sticks to supply the drop of blood for blood glucose analysis.
Most of the non-invasive methods under development are continuous glucose monitoring methods and offer the advantage of providing additional information to the subject between the conventional finger stick, blood glucose measurements and over time periods where no finger stick measurements are available (i.e. while the subject is sleeping).
Effectiveness.
For patients with diabetes mellitus type 2, the importance of monitoring and the optimal frequency of monitoring are not clear. A 2011 study found no evidence that blood glucose monitoring leads to better patient outcomes in actual practice. One randomized controlled trial found that self-monitoring of blood glucose did not improve glycosylated hemoglobin (HbA1c) among "reasonably well controlled non-insulin treated patients with type 2 diabetes". However a recent meta-analysis of 47 randomized controlled trials encompassing 7677 patients showed that self-care management intervention improves glycemic control in diabetics, with an estimated 0.36% (95% CI, 0.21-0.51) reduction in their glycosylated hemoglobin values. Furthermore, a recent study showed that patients described as being "Uncontrolled Diabetics" (defined in this study by HbA1C levels >8%) showed a statistically significant decrease in the HbA1C levels after a 90-day period of seven-point self-monitoring of blood glucose (SMBG) with a relative risk reduction (RRR) of 0.18% (95% CI, 0.86-2.64%, p<.001). Regardless of lab values or other numerical parameters, the purpose of the clinician is to improve quality of life and patient outcomes in diabetic patients. A recent study included 12 randomized controlled trials and evaluated outcomes in 3259 patients. The authors concluded through a qualitative analysis that SMBG on quality of life showed no effect on patient satisfaction or the patients' health-related quality of life. Furthermore, the same study identified that patients with type 2 diabetes mellitus diagnosed greater than one year prior to initiation of SMBG, who were not on insulin, experienced a statistically significant reduction in their HbA1C of 0.3% (95% CI, -0.4 - -0.1) at six months follow up, but a statistically insignificant reduction of 0.1% (95% CI, -0.3 – 0.04) at twelve months follow up. Conversely, newly diagnosed patients experienced a statistically significant reduction of 0.5% (95% CI, -0.9 – -0.1) at 12 months follow up. A recent study found that a treatment strategy of intensively lowering blood sugar levels (below 6%) in patients with additional cardiovascular disease risk factors poses more harm than benefit. For type 2 diabetics who are not on insulin, exercise and diet are the best tools. Blood glucose monitoring is, in that case, simply a tool to evaluate the success of diet and exercise. Insulin-dependent type 2 diabetics need to monitor their blood sugar as frequently as type 1 diabetics.
Blood glucose monitoring recommendations.
The National Institute for Health and Clinical Excellence (NICE), UK released updated diabetes recommendations on the 30th May 2008, which recommend that self-monitoring of plasma glucose levels for people with newly diagnosed type 2 diabetes must be integrated into a structured self-management education process.

</doc>
<doc id="56558" url="http://en.wikipedia.org/wiki?curid=56558" title="Blood pressure">
Blood pressure

Blood pressure (BP) is the pressure exerted by circulating blood upon the walls of blood vessels and is one of the principal vital signs. When used without further specification, "blood pressure" usually refers to the arterial pressure of the systemic circulation, usually measured at a person's upper arm. A person’s blood pressure is usually expressed in terms of the systolic (maximum) pressure over diastolic (minimum) pressure and is measured in millimeters of mercury (mm Hg). Normal resting blood pressure for an adult is approximately 120/80 mm Hg.
Blood pressure varies depending on situation, activity, and disease states, and is regulated by the nervous and endocrine systems. Blood pressure that is pathologically low is called hypotension, and pressure that is pathologically high is hypertension. Both have many causes and can range from mild to severe, with both acute and chronic forms. Chronic hypertension is a risk factor for many diseases, including kidney failure, heart attack, and stroke. Chronic hypertension is more common than chronic hypotension in Western countries. Chronic hypertension often goes undetected because of infrequent monitoring and the absence of obvious symptoms.
Classification.
Systemic arterial pressure.
The table on the right shows the classification of blood pressure adopted by the American Heart Association for adults who are 18 years and older. It assumes the values are a result of averaging blood pressure readings measured at two or more visits to the doctor.
In the UK, clinic blood pressures are usually categorised into three groups; low (90/60 or lower), normal (between 90/60 and 139/80), and high (140/90 or higher).
Blood pressure fluctuates from minute to minute and normally shows a circadian rhythm over a 24-hour period, with highest readings in the afternoons and lowest readings at night. Loss of the normal fall in blood pressure at night is associated with a greater future risk of cardiovascular disease and there is evidence that night-time blood pressure is a stronger predictor of cardiovascular events than day-time blood pressure.
Various factors, such as age and sex, influence a person's blood pressure and variations in it. In children, the normal ranges are lower than for adults and depend on height. Reference blood pressure values have been developed for children in different countries, based on the distribution of blood pressure in children of these countries. As adults age, systolic pressure tends to rise and diastolic tends to fall. In the elderly, blood pressure tends to be above the normal adult range, largely because of reduced flexibility of the arteries. Also, an individual's blood pressure varies with exercise, emotional reactions, sleep, digestion, time of day and circadian rhythm.
Differences between left and right arm blood pressure measurements tend to be random and average to nearly zero if enough measurements are taken. However, in a small percentage of cases there is a consistent difference greater than 10 mm Hg which may need further investigation, e.g. for obstructive arterial disease.
The risk of cardiovascular disease increases progressively above 115/75 mm Hg. In the past, hypertension was only diagnosed if secondary signs of high arterial pressure were present, along with a prolonged high systolic pressure reading over several visits. Regarding hypotension, in practice blood pressure is considered too low only if noticeable symptoms are present.
Clinical trials demonstrate that people who maintain arterial pressures at the low end of these pressure ranges have much better long term cardiovascular health. The principal medical debate concerns the aggressiveness and relative value of methods used to lower pressures into this range for those who do not maintain such pressure on their own. Elevations, more commonly seen in older people, though often considered normal, are associated with increased morbidity and mortality.
Mean arterial pressure.
The mean arterial pressure (MAP) is the average over a cardiac cycle and is determined by the cardiac output (CO), systemic vascular resistance (SVR), and central venous pressure (CVP),
MAP can be approximately determined from measurements of the systolic pressure formula_2  and the diastolic pressure formula_3 
Pulse pressure.
The pulse pressure is the difference between the measured systolic and diastolic pressures,
The up and down fluctuation of the arterial pressure results from the pulsatile nature of the cardiac output, i.e. the heartbeat. Pulse pressure is determined by the interaction of the stroke volume of the heart, the compliance (ability to expand) of the arterial system—largely attributable to the aorta and large elastic arteries—, and the resistance to flow in the arterial tree. By expanding under pressure, the aorta absorbs some of the force of the blood surge from the heart during a heartbeat. In this way, the pulse pressure is reduced from what it would be if the aorta were not compliant. The loss of arterial compliance that occurs with aging explains the elevated pulse pressures found in elderly patients.
Systemic venous pressure.
Blood pressure generally refers to the arterial pressure in the systemic circulation. However, measurement of pressures in the venous system and the pulmonary vessels plays an important role in intensive care medicine but requires invasive measurement of pressure using a catheter.
Venous pressure is the vascular pressure in a vein or in the atria of the heart. It is much less than arterial pressure, with common values of 5 mm Hg in the right atrium and 8 mm Hg in the left atrium.
Variants of venous pressure include:
Pulmonary pressure.
Normally, the pressure in the pulmonary artery is about 15 mm Hg at rest.
Increased blood pressure in the capillaries of the lung cause pulmonary hypertension, with interstitial edema if the pressure increases to above 20 mm Hg, and to pulmonary edema at pressures above 25 mm Hg.
Disorders.
Disorders of blood pressure control include: high blood pressure, low blood pressure, and blood pressure that shows excessive or maladaptive fluctuation.
High.
Arterial hypertension can be an indicator of other problems and may have long-term adverse effects. Sometimes it can be an acute problem, for example hypertensive emergency.
Levels of arterial pressure put mechanical stress on the arterial walls. Higher pressures increase heart workload and progression of unhealthy tissue growth (atheroma) that develops within the walls of arteries. The higher the pressure, the more stress that is present and the more atheroma tend to progress and the heart muscle tends to thicken, enlarge and become weaker over time.
Persistent hypertension is one of the risk factors for strokes, heart attacks, heart failure and arterial aneurysms, and is the leading cause of chronic kidney failure. Even moderate elevation of arterial pressure leads to shortened life expectancy. At severely high pressures, mean arterial pressures 50% or more above average, a person can expect to live no more than a few years unless appropriately treated.
In the past, most attention was paid to diastolic pressure; but nowadays it is recognised that both high systolic pressure and high pulse pressure (the numerical difference between systolic and diastolic pressures) are also risk factors. In some cases, it appears that a decrease in excessive diastolic pressure can actually increase risk, due probably to the increased difference between systolic and diastolic pressures (see the article on pulse pressure). If systolic blood pressure is elevated (>140) with a normal diastolic blood pressure (<90), it is called "isolated systolic hypertension" and may present a health concern.
For those with heart valve regurgitation, a change in its severity may be associated with a change in diastolic pressure. In a study of people with heart valve regurgitation that compared measurements 2 weeks apart for each person, there was an increased severity of aortic and mitral regurgitation when diastolic blood pressure increased, whereas when diastolic blood pressure decreased, there was a decreased severity.
Low.
Blood pressure that is too low is known as hypotension. Hypotension is a medical concern if it causes signs or symptoms, such as dizziness, fainting, or in extreme cases, shock.
When arterial pressure and blood flow decrease beyond a certain point, the perfusion of the brain becomes critically decreased (i.e., the blood supply is not sufficient), causing lightheadedness, dizziness, weakness or fainting.
Sometimes the arterial pressure drops significantly when a patient stands up from sitting. This is known as orthostatic hypotension (postural hypotension); gravity reduces the rate of blood return from the body veins below the heart back to the heart, thus reducing stroke volume and cardiac output.
When people are healthy, the veins below their heart quickly constrict and the heart rate increases to minimize and compensate for the gravity effect. This is carried out involuntarily by the autonomic nervous system. The system usually requires a few seconds to fully adjust and if the compensations are too slow or inadequate, the individual will suffer reduced blood flow to the brain, dizziness and potential blackout. Increases in G-loading, such as routinely experienced by aerobatic or combat pilots 'pulling Gs', greatly increases this effect. Repositioning the body perpendicular to gravity largely eliminates the problem.
Other causes of low arterial pressure include:
Shock is a complex condition which leads to critically decreased perfusion. The usual mechanisms are loss of blood volume, pooling of blood within the veins reducing adequate return to the heart and/or low effective heart pumping. Low arterial pressure, especially low pulse pressure, is a sign of shock and contributes to and reflects decreased perfusion.
If there is a significant difference in the pressure from one arm to the other, that may indicate a narrowing (for example, due to aortic coarctation, aortic dissection, thrombosis or embolism) of an artery.
Fluctuating blood pressure.
Normal fluctuation in blood pressure is adaptive and necessary. Fluctuations in pressure that are significantly greater than the norm are associated with greater white matter hyperintensity, a finding consistent with reduced local cerebral blood flow and a heightened risk of cerebrovascular disease. Within both high and low blood pressure groups, a greater degree of fluctuation was found to correlate with an increase in cerebrovascular disease compared to those with less variability, suggesting the consideration of the clinical management of blood pressure fluctuations, even among normotensive older adults. Older individuals and those who had received blood pressure medications were more likely to exhibit larger fluctuations in pressure.
Physiology.
During each heartbeat, blood pressure varies between a maximum (systolic) and a minimum (diastolic) pressure. The blood pressure in the circulation is principally due to the pumping action of the heart. Differences in mean blood pressure are responsible for blood flow from one location to another in the circulation. The rate of mean blood flow depends on both blood pressure and the resistance to flow presented by the blood vessels. Mean blood pressure decreases as the circulating blood moves away from the heart through arteries and capillaries due to viscous losses of energy. Mean blood pressure drops over the whole circulation, although most of the fall occurs along the small arteries and arterioles. Gravity affects blood pressure via hydrostatic forces (e.g., during standing), and valves in veins, breathing, and pumping from contraction of skeletal muscles also influence blood pressure in veins.
Hemodynamics.
There are many physical factors that influence arterial pressure. Each of these may in turn be influenced by physiological factors, such as: diet, exercise, disease, drugs or alcohol, stress, and obesity.
Some physical factors are:
In practice, each individual's autonomic nervous system responds to and regulates all these interacting factors so that, although the above issues are important, the actual arterial pressure response of a given individual varies widely because of both split-second and slow-moving responses of the nervous system and end organs. These responses are very effective in changing the variables and resulting blood pressure from moment to moment.
Moreover, blood pressure is the result of cardiac output increased by peripheral resistance: "blood pressure = cardiac output X peripheral resistance". As a result, an abnormal change in blood pressure is often an indication of a problem affecting the heart's output, the blood vessels' resistance, or both. Thus, knowing the patient's blood pressure is critical to assess any pathology related to output and resistance.
Regulation.
The endogenous regulation of arterial pressure is not completely understood, but the following mechanisms of regulating arterial pressure have been well-characterized:
These different mechanisms are not necessarily independent of each other, as indicated by the link between the RAS and aldosterone release. When blood pressure falls many physiological cascades commence in order to return the blood pressure to a more appropriate level.
Currently, the RAS is targeted pharmacologically by ACE inhibitors and angiotensin II receptor antagonists. The aldosterone system is directly targeted by spironolactone, an aldosterone antagonist. The fluid retention may be targeted by diuretics; the antihypertensive effect of diuretics is due to its effect on blood volume. Generally, the baroreceptor reflex is not targeted in hypertension because if blocked, individuals may suffer from orthostatic hypotension and fainting.
Measurement.
Arterial pressure is most commonly measured via a sphygmomanometer, which historically used the height of a column of mercury to reflect the circulating pressure. Blood pressure values are generally reported in millimetres of mercury (mm Hg), though aneroid and electronic devices do not contain mercury.
For each heartbeat, blood pressure varies between systolic and diastolic pressures. Systolic pressure is peak pressure in the arteries, which occurs near the end of the cardiac cycle when the ventricles are contracting. Diastolic pressure is minimum pressure in the arteries, which occurs near the beginning of the cardiac cycle when the ventricles are filled with blood. An example of normal measured values for a resting, healthy adult human is 120 mm Hg systolic and 80 mm Hg diastolic (written as 120/80 mm Hg, and spoken as "one-twenty over eighty").
Systolic and diastolic arterial blood pressures are not static but undergo natural variations from one heartbeat to another and throughout the day (in a circadian rhythm). They also change in response to stress, nutritional factors, drugs, disease, exercise, and momentarily from standing up. Sometimes the variations are large. Hypertension refers to arterial pressure being abnormally high, as opposed to hypotension, when it is abnormally low. Along with body temperature, respiratory rate, and pulse rate, blood pressure is one of the four main vital signs routinely monitored by medical professionals and healthcare providers.
Measuring pressure invasively, by penetrating the arterial wall to take the measurement, is much less common and usually restricted to a hospital setting.
Noninvasive.
The noninvasive auscultatory and oscillometric measurements are simpler and quicker than invasive measurements, require less expertise, have virtually no complications, are less unpleasant and less painful for the patient. However, noninvasive methods may yield somewhat lower accuracy and small systematic differences in numerical results. Noninvasive measurement methods are more commonly used for routine examinations and monitoring.
Palpation.
A minimum systolic value can be roughly estimated by palpation, most often used in emergency situations, but should be used with caution. It has been estimated that, using 50% percentiles, carotid, femoral and radial pulses are present in patients with a systolic blood pressure > 70 mm Hg, carotid and femoral pulses alone in patients with systolic blood pressure of > 50 mm Hg, and only a carotid pulse in patients with a systolic blood pressure of > 40 mm Hg.
A more accurate value of systolic blood pressure can be obtained with a sphygmomanometer and palpating the radial pulse. The diastolic blood pressure cannot be estimated by this method. The American Heart Association recommends that palpation be used to get an estimate before using the auscultatory method.
Auscultatory.
The auscultatory method (from the Latin word for "listening") uses a stethoscope and a sphygmomanometer. This comprises an inflatable ("Riva-Rocci") cuff placed around the upper arm at roughly the same vertical height as the heart, attached to a mercury or aneroid manometer. The mercury manometer, considered the gold standard, measures the height of a column of mercury, giving an absolute result without need for calibration and, consequently, not subject to the errors and drift of calibration which affect other methods. The use of mercury manometers is often required in clinical trials and for the clinical measurement of hypertension in high-risk patients, such as pregnant women.
A cuff of appropriate size is fitted smoothly and also snugly, then inflated manually by repeatedly squeezing a rubber bulb until the artery is completely occluded. Listening with the stethoscope to the brachial artery at the antecubital area of the elbow, the examiner slowly releases the pressure in the cuff. When blood just starts to flow in the artery, the turbulent flow creates a "whooshing" or pounding (first Korotkoff sound). The pressure at which this sound is first heard is the systolic blood pressure. The cuff pressure is further released until no sound can be heard (fifth Korotkoff sound), at the diastolic arterial pressure.
The auscultatory method is the predominant method of clinical measurement.
Oscillometric.
The oscillometric method was first demonstrated in 1876 and involves the observation of oscillations in the sphygmomanometer cuff pressure which are caused by the oscillations of blood flow, i.e., the pulse. The electronic version of this method is sometimes used in long-term measurements and general practice. It uses a sphygmomanometer cuff, like the auscultatory method, but with an electronic pressure sensor (transducer) to observe cuff pressure oscillations, electronics to automatically interpret them, and automatic inflation and deflation of the cuff. The pressure sensor should be calibrated periodically to maintain accuracy.
Oscillometric measurement requires less skill than the auscultatory technique and may be suitable for use by untrained staff and for automated patient home monitoring.
The cuff is inflated to a pressure initially in excess of the systolic arterial pressure and then reduced to below diastolic pressure over a period of about 30 seconds. When blood flow is nil (cuff pressure exceeding systolic pressure) or unimpeded (cuff pressure below diastolic pressure), cuff pressure will be essentially constant. It is essential that the cuff size is correct: undersized cuffs may yield too high a pressure; oversized cuffs yield too low a pressure. When blood flow is present, but restricted, the cuff pressure, which is monitored by the pressure sensor, will vary periodically in synchrony with the cyclic expansion and contraction of the brachial artery, i.e., it will oscillate.
Over the deflation period, the recorded pressure waveform forms a signal known as the cuff deflation curve. A bandpass filter is utilized to extract the oscillometric pulses from the cuff deflation curve. Over the deflation period, the extracted oscillometric pulses form a signal known as the oscillometric waveform (OMW). The amplitude of the oscillometric pulses increases to a maximum and then decreases with further deflation. A variety of analysis algorithms can be employed in order to estimate the systolic, diastolic, and mean arterial pressure.
Oscillometric monitors may produce inaccurate readings in patients with heart and circulation problems, which include arterial sclerosis, arrhythmia, preeclampsia, pulsus alternans, and pulsus paradoxus .
In practice the different methods do not give identical results; an algorithm and experimentally obtained coefficients are used to adjust the oscillometric results to give readings which match the auscultatory results as well as possible. Some equipment uses computer-aided analysis of the instantaneous arterial pressure waveform to determine the systolic, mean, and diastolic points. Since many oscillometric devices have not been validated, caution must be given as most are not suitable in clinical and acute care settings.
Recently, several coefficient-free oscillometric algorithms have developed for estimation of blood pressure. These algorithms do not rely on experimentally obtained coefficients and have been shown to provide more accurate and robust estimation of blood pressure,
The term NIBP, for non-invasive blood pressure, is often used to describe oscillometric monitoring equipment.
Continuous noninvasive techniques (CNAP).
Continuous Noninvasive Arterial Pressure (CNAP) is the method of measuring arterial blood pressure in real-time without any interruptions and without cannulating the human body. CNAP combines the advantages of the following two clinical “gold standards”: it measures blood pressure continuously in real-time like the invasive arterial catheter system and it is noninvasive like the standard upper arm sphygmomanometer. Latest developments in this field show promising results in terms of accuracy, ease of use and clinical acceptance.
Non-occlusive techniques: The Pulse Wave Velocity (PWV) principle.
Since the 1990s a novel family of techniques based on the so-called pulse wave velocity (PWV) principle have been developed. These techniques rely on the fact that the velocity at which an arterial pressure pulse travels along the arterial tree depends, among others, on the underlying blood pressure. Accordingly, after a calibration maneuver, these techniques provide indirect estimates of blood pressure by translating PWV values into blood pressure values.
The main advantage of these techniques is that it is possible to measure PWV values of a subject continuously (beat-by-beat), without medical supervision, and without the need of inflating brachial cuffs. PWV-based techniques are still in the research domain and are not adapted to clinical settings.
Home monitoring.
Ambulatory blood pressure devices that take readings every half hour throughout the day and night have been used for identifying and mitigating measurement problems like white-coat hypertension. Except for sleep, home monitoring could be used for these purposes instead of ambulatory blood pressure monitoring. Home monitoring may be used to improve hypertension management and to monitor the effects of lifestyle changes and medication related to blood pressure. Compared to ambulatory blood pressure measurements, home monitoring has been found to be an effective and lower cost alternative, but ambulatory monitoring is more accurate than both clinic and home monitoring in diagnosing hypertension. Ambulatory monitoring is recommended for most patients before the start of antihypertensive drugs.
Aside from the white-coat effect, blood pressure readings outside of a clinical setting are usually slightly lower in the majority of people. The studies that looked into the risks from hypertension and the benefits of lowering blood pressure in affected patients were based on readings in a clinical environment.
When measuring blood pressure, an accurate reading requires that one not drink coffee, smoke cigarettes, or engage in strenuous exercise for 30 minutes before taking the reading. A full bladder may have a small effect on blood pressure readings; if the urge to urinate arises, one should do so before the reading. For 5 minutes before the reading, one should sit upright in a chair with one's feet flat on the floor and with limbs uncrossed. The blood pressure cuff should always be against bare skin, as readings taken over a shirt sleeve are less accurate. During the reading, the arm that is used should be relaxed and kept at heart level, for example by resting it on a table.
Since blood pressure varies throughout the day, measurements intended to monitor changes over longer time frames should be taken at the same time of day to ensure that the readings are comparable. Suitable times are:
Automatic self-contained blood pressure monitors are available at reasonable prices, some of which are capable of Korotkoff's measurement in addition to oscillometric methods, enabling irregular heartbeat patients to accurately measure their blood pressure at home.
White-coat hypertension.
For some patients, blood pressure measurements taken in a doctor's office may not correctly characterize their typical blood pressure. In up to 25% of patients, the office measurement is higher than their typical blood pressure. This type of error is called white-coat hypertension (WCH) and can result from anxiety related to an examination by a health care professional. The misdiagnosis of hypertension for these patients can result in needless and possibly harmful medication. WCH can be reduced (but not eliminated) with automated blood pressure measurements over 15 to 20 minutes in a quiet part of the office or clinic. In some cases a lower blood pressure reading occurs at the doctor's.
Invasive.
Arterial blood pressure (BP) is most accurately measured invasively through an arterial line. Invasive arterial pressure measurement with intravascular cannulae involves direct measurement of arterial pressure by placing a cannula needle in an artery (usually radial, femoral, dorsalis pedis or brachial).
The cannula must be connected to a sterile, fluid-filled system, which is connected to an electronic pressure transducer. The advantage of this system is that pressure is constantly monitored beat-by-beat, and a waveform (a graph of pressure against time) can be displayed. This invasive technique is regularly employed in human and veterinary intensive care medicine, anesthesiology, and for research purposes.
Cannulation for invasive vascular pressure monitoring is infrequently associated with complications such as thrombosis, infection, and bleeding. Patients with invasive arterial monitoring require very close supervision, as there is a danger of severe bleeding if the line becomes disconnected. It is generally reserved for patients where rapid variations in arterial pressure are anticipated.
Invasive vascular pressure monitors are pressure monitoring systems designed to acquire pressure information for display and processing. There are a variety of invasive vascular pressure monitors for trauma, critical care, and operating room applications. These include single pressure, dual pressure, and multi-parameter (i.e. pressure / temperature). The monitors can be used for measurement and follow-up of arterial, central venous, pulmonary arterial, left atrial, right atrial, femoral arterial, umbilical venous, umbilical arterial, and intracranial pressures.
Fetal blood pressure.
In pregnancy, it is the fetal heart and not the mother's heart that builds up the fetal blood pressure to drive its blood through the fetal circulation.
The blood pressure in the fetal aorta is approximately 30 mm Hg at 20 weeks of gestation, and increases to approximately 45 mm Hg at 40 weeks of gestation.<br>
The average blood pressure for full-term infants:<br>
Systolic 65–95 mm Hg<br>Diastolic 30–60 mm Hg

</doc>
<doc id="56561" url="http://en.wikipedia.org/wiki?curid=56561" title="Anesthesia">
Anesthesia

Anesthesia, or anaesthesia (from Greek ἀν-, "an-", "without"; and αἴσθησις, "aisthēsis", "sensation", see spelling differences) is a temporary state consisting of unconsciousness, loss of memory, lack of pain, and muscle relaxation. A patient under the effects of anesthesia is said to be anesthetized.
Anesthesia enables the performance of other medical interventions. The best anesthetic is therefore one with the lowest risk to the patient that still achieves the end points required to complete the other intervention. There are many different needs and goals of anesthesia. The goals (end points) are traditionally described as unconsciousness and amnesia, analgesia, and muscle relaxation. To reach multiple end points one or more drugs are commonly used (such as general anesthetics, hypnotics, sedatives, paralytics, narcotics, and analgesics), each of which serves a specific purpose in creating a safe anesthetic.
The types of anesthesia are broadly classified into general anesthesia, sedation and regional anesthesia. General anesthesia refers to the suppression of activity in the central nervous system, resulting in unconsciousness and total lack of sensation. Sedation (or dissociative anesthesia) uses agents that inhibit transmission of nerve impulses between higher and lower centers of the brain inhibiting anxiety and the creation of long-term memories. Regional anesthesia renders a larger area of the body insensate by blocking transmission of nerve impulses between a part of the body and the spinal cord. It is divided into peripheral and central blockades. Peripheral blockade inhibits sensory perception within a specific location on the body, such as when a tooth is "numbed" or when a nerve block is given to stop sensation from an entire limb. Central blockades place the local anesthetic around the spinal cord (such as with spinal and epidural anesthesia) removing sensation from any area below the level of the block.
There are both major and minor risks of anesthesia. Examples of major risks include death, heart attack and pulmonary embolism whereas minor risks can include postoperative nausea and vomiting and readmission to hospital. The likelihood of a complication occurring is proportional to the relative risk of a variety of factors related to the patient's health, the complexity of the surgery being performed and the type of anesthetic. Of these factors, the person's health prior to surgery (stratified by the ASA physical status classification system) has the greatest bearing on the probability of a complication occurring. Patients typically wake within minutes of an anesthetic being terminated and regain their senses within hours. One exception is a condition called long-term post-operative cognitive dysfunction, characterized by persistent confusion lasting weeks or months, which is more common in those undergoing cardiac surgery and in the elderly.
The first documented general anesthetic was performed by Crawford W. Long in 1842. Unfortunately for Long, he did not publish his successes with ether for general anesthesia until 1849. The first public demonstration of general anesthesia was in 1846 by a Boston dentist named William T.G. Morton at the Massachusetts General Hospital. Dr. Morton gave an ether anesthetic for the removal of a neck tumor by surgeon John Collins Warren (the first editor of the New England Journal of Medicine and dean of Harvard Medical School). About a decade later, cocaine was introduced as the first viable local anesthetic. John H. Packard, of Philadelphia, published the first notice of using ether for general anesthesia in 1872. It wasn't until the 1930s that Dr. Harvey Cushing tied the stress response to higher mortality rates and began using local anesthetic for hernia repairs in addition to general anesthesia.
Medical uses.
The purpose of anesthesia can be distilled down to three basic goals or end points::236
Different types of anesthesia (which are discussed in the following sections) affect the endpoints in different ways. Regional anesthesia, for instance affects analgesia, benzodiazepine type sedatives (used in twilight sleep) favor amnesia and general anesthetics can affect all of the endpoints. The goal of anesthesia is to achieve the necessary endpoints with the least amount of risk possible to the patient. 
To achieve the goals of anesthesia, drugs act on different but interconnected parts of the nervous system. Hypnosis, for instance, is generated through actions on the nuclei in the brain and is similar to the activation of sleep. The effect is to make people less aware and less reactive to non-noxious stimuli.:245
Loss of memory (amnesia) is created by action of drugs on multiple (but specific) regions of the brain. Memories are created as either declarative or non-declarative memories in several stages (short-term, long-term, long-lasting) the strength of which is determined by the strength of connections between neurons termed synaptic plasticity.:246 Each anesthetic produces amnesia through unique effects on memory formation at variable doses. Inhalational anesthetics will reliably produce amnesia through general suppression of the nuclei at doses below those required for loss of consciousness. Drugs like midazolam produce amnesia through different pathways by blocking the formation of long-term memories.:249
Tied closely to the concepts of amnesia and hypnosis is the concept of consciousness. Consciousness is the higher order process that synthesizes information. For instance, the “sun” conjures up feelings, memories and a sensation of warmth rather than a description of a round, orange warm ball seen in the sky for part of a 24‑hour cycle. Likewise, a person can have dreams (a state of subjective consciousness) during anesthetic or have consciousness of the procedure despite having no indication of it under anesthetic. It is estimated that 22% of people dream during general anesthesia and 1 or 2 cases per 1000 have some consciousness termed “awareness during general anesthesia”.:253
Techniques.
Anesthesia is unique, in that it does not offer any particular benefit, rather it allows others to do things that might be beneficial. The best anesthetic, therefore is the one with the lowest risk to the patient that still achieves the endpoints required to complete the procedure. The first stage of an anesthetic is the pre-operative risk assessment made up of the medical history, physical examination and lab tests. Diagnosing a person's pre-operative physical status allows the clinician to minimize anesthetic risks. A well completed medical history will arrive at the correct diagnosis 56% of the time which increases to 73% with a physical examination. Lab tests help in diagnosis but only in 3% of cases, underscoring the need for a full history and physical examination prior to anesthetics. Incorrect pre-operative assessments or preparations are the root cause of 11% of all adverse anesthetic events.:1003
One part of the risk assessment is based on the patients' health. The American Society of Anesthesiologists have developed a six-tier scale which stratifies the pre-operative physical state of the patient called the ASA physical status. The scale assesses a high-order of risk as the patient's general health relates to an anesthetic.
The more detailed pre-operative medical history aims to discover genetic disorders (such as malignant hyperthermia or pseudocholinesterase deficiency), habits (tobacco, drug and alcohol use), physical attributes (such as obesity or a difficult airway) and any coexisting diseases (especially cardiac and respiratory diseases) that might impact the anesthetic. The physical examination helps quantify the impact of anything found in the medical history in addition to lab tests.:1003–1009
Aside from the generalities of the patients health assessment, an evaluation of the specific factors as they relate to the surgery also need to be considered for anesthesia. For instance, anesthesia during childbirth must consider not only the mother but the baby. Cancers and tumors that occupy the lungs or throat create special challenges to general anesthesia. After determining the health of the person undergoing anesthetic and the endpoints that are required to complete the procedure, the type of anesthetic can be selected. Choice of surgical method and anaesthetic technique aims to reduce risk of complications, shorten time needed for recovery and minimise the surgical stress response.
General anesthesia.
Anesthesia is the combination of the endpoints (discussed above) which are reached by drugs acting on different but overlapping sites in the central nervous system. General anesthesia (as opposed to sedation or regional anesthesia) has three main goals: lack of movement (paralysis), unconsciousness, and blunting of the stress response. In the early days of anesthesia, anesthetics could reliably achieve the first two, allowing surgeons to perform necessary procedures, but many patients died because the extremes of blood pressure and pulse caused by the surgical insult were ultimately harmful. Eventually, the need for blunting of the surgical stress response was identified by Harvey Cushing, who injected local anesthetic prior to hernia repairs.:30 This led to the development of other drugs that could blunt the response leading to lower surgical mortality rates.
The most common approach to reach the endpoints of general anesthesia is through the use of inhaled general anesthetics. Each has its own potency which is correlated to its solubility in oil. This relationship exists because the drugs bind directly to cavities in proteins of the central nervous system, although several theories of general anaesthetic action have been described. Inhalational anesthetics are thought to exact their effects on different parts of the central nervous system. For instance, the immobilizing effect of inhaled anesthetics results from an effect on the spinal cord whereas sedation, hypnosis and amnesia involve sites in the brain.:515 The potency of an inhalational anesthetic is quantified by its minimum alveolar concentration or MAC. The MAC is the percentage dose of anaesthetic that will prevent a response to painful stimulus in 50% of subjects. The higher the MAC, generally, the less potent the anesthetic.
The ideal anesthetic drug would provide hypnosis, amnesia, analgesia, and muscle relaxation without undesirable changes in blood pressure, pulse or breathing. In the 1930s, physicians started to augment inhaled general anesthetics with intravenous general anesthetics. The drugs used in combination offered a better risk profile to the person under anesthetic and a quicker recovery. A combination of drugs was later shown to result in lower odds of dying in the first 7 days after anesthetic. For instance, propofol (injection) might be used to start the anesthetic, fentanyl (injection) used to blunt the stress response, midazolam (injection) given to ensure amnesia and sevoflurane (inhaled) during the procedure to maintain the effects. More recently, several intravenous drugs have been developed which, if desired, allow inhaled general anesthetics to be avoided completely.:720
Equipment.
The core instrument in an inhalational anesthetic delivery system is an anesthetic machine. It has vaporizers, ventilators, an anesthetic breathing circuit, waste gas scavenging system and pressure gauges. The purpose of the anesthetic machine is to provide anesthetic gas at a constant pressure, oxygen for breathing and to remove carbon dioxide or other waste anesthetic gases. Since inhalational aenesthetics are inflammable, various checklists have been developed to confirm that the machine is ready for use, that the safety features are active and the electrical hazards are removed. Intravenous anesthetic is delivered either by bolus doses or an infusion pump. There are also many smaller instruments used in airway management and monitoring the patient. The common thread to modern machinery in this field is the use of fail-safe systems that decrease the odds of catastrophic misuse of the machine.
Monitoring.
Patients under general anesthesia must undergo continuous physiological monitoring to ensure safety. In the US, the American Society of Anesthesiologists (ASA) have established minimum monitoring guidelines for patients receiving general anesthesia, regional anesthesia, or sedation. This includes electrocardiography (ECG), heart rate, blood pressure, inspired and expired gases, oxygen saturation of the blood (pulse oximetry), and temperature. In the UK the Association of Anaesthetists (AAGBI) have set minimum monitoring guidelines for general and regional anesthesia. For minor surgery, this generally includes monitoring of heart rate, oxygen saturation, blood pressure, and inspired and expired concentrations for oxygen, carbon dioxide, and inhalational anesthetic agents. For more invasive surgery, monitoring may also include temperature, urine output, blood pressure, central venous pressure, pulmonary artery pressure and pulmonary artery occlusion pressure, cardiac output, cerebral activity, and neuromuscular function. In addition, the operating room environment must be monitored for ambient temperature and humidity, as well as for accumulation of exhaled inhalational anesthetic agents, which might be deleterious to the health of operating room personnel.
Sedation.
Sedation (also referred to as "dissociative anesthesia" or "twilight anesthesia") creates hypnotic, sedative, anxiolytic, amnesic, anticonvulsant, and centrally produced muscle-relaxing properties. From the perspective of the person giving the sedation, the patient will appear sleepy, relaxed and forgetful, allowing unpleasant procedures to be more easily completed. Sedatives such as benzodiazepines are usually given with pain relievers (such as narcotics, or local anesthetics or both) because they don't, by themselves, provide significant pain relief.
From the perspective of the person receiving sedative, the effect is a feeling of general relaxation, amnesia (loss of memory) and time passing quickly. Many drugs can produce a sedative effect including benzodiazepines, propofol, thiopental, ketamine and inhaled general anesthetics. The advantage of sedation over a general anesethetic is that it generally doesn't require support of the airway or breathing (no tracheal intubation or mechanical ventilation) and can have less of an effect on the cardiovascular system which may add to a greater margin of safety in some patients.:736
Regional anesthesia.
When pain is blocked from a part of the body using local anesthetics, it is generally referred to as regional anesthesia. There are many types of regional anesthesia either by injecting into the tissue itself, a vein that feeds the area or around a nerve trunk that supplies sensation to the area. The latter are called nerve blocks and are divided into peripheral or central nerve blocks.
The following are the types of regional anesthesia::926–931
Nerve blocks.
When local anesthetic is injected around a larger diameter nerve that transmits sensation from an entire region it is referred to as a nerve block. Nerve blocks are commonly used in dentistry, when the mandibular nerve is blocked for procedures on the lower teeth. With larger diameter nerves (such as the interscalene block for upper limbs or psoas compartment block for lower limbs) the nerve and position of the needle is localized with ultrasound or electrical stimulation. The use of ultrasound may reduce complication rates and improve quality, performance time, and time to onset of blocks. Because of the large amount of local anesthetic required to affect the nerve, the maximum dose of local anesethetic has to be considered. Nerve blocks are also used as a continuous infusion, following major surgery such as knee, hip and shoulder replacement surgery, and may be associated with lower complications. Nerve blocks are also associated with a lower risk of neurologic complications when compared to neuraxial blocks.:1639–1641
Spinal, epidural and caudal anesthesia.
Central neuraxial anesthesia is the injection of local anesthetic around the spinal cord to provide analgesia in the abdomen, pelvis or lower extremities. It is divided into either spinal (injection into the subarachnoid space), epidural (injection outside of the subarachnoid space into the epidural space) and caudal (injection into the cauda equina or tail end of the spinal cord). Spinal and epidural are the most commonly used forms of central neuraxial blockade.
Spinal anesthesia is a "one-shot" injection that provides rapid onset and profound sensory anesthesia with lower doses of anesethetic, and is usually associated with neuromuscular blockade (loss of muscle control). Epidural anesthesia uses larger doses of anesthetic infused through an indwelling catheter which allows the anesthetic to be augmented should the effects begin to dissipate. Epidural anesethesia does not typically affect muscle control.
Because central neuraxial blockade causes arterial and vasodilation, a drop in blood pressure is common. This drop is largely dictated by the venous side of the circulatory system which holds 75% of the circulating blood volume. The physiologic effects are much greater when the block is placed above the 5th thoracic vertebra. An ineffective block is most often due to inadequate anxiolysis or sedation rather than a failure of the block itself.:1611
Acute pain management.
Pain that is well managed during and immediately after surgery improves the health of patients (by decreasing physiologic stress) and the potential for chronic pain. Nociception (pain sensation) is not hard-wired into the body. Instead, it is a dynamic process wherein persistent painful stimuli can sensitize the system and either make pain management difficult or promote the development of chronic pain. For this reason, preemptive acute pain management may reduce both acute and chronic pain and is tailored to the surgery, the environment in which it is given (in-patient/out-patient) and the individual patient.:2757
Pain management is classified into either pre-emptive or on-demand. On-demand pain medications typically include either opioid or non-steroidal anti-inflammatory drugs but can also make use of novel approaches such as inhaled nitrous oxide or ketamine. On demand drugs can be administered by a clinician ("as needed drug orders") or by the patient using patient-controlled analgesia (PCA). PCA has been shown to provide slightly better pain control and increased patient satisfaction when compared with conventional methods. Common preemptive approaches include epidural neuraxial blockade or nerve blocks. One review which looked at pain control after abdominal aortic surgery found that epidural blockade provides better pain relief (especially during movement) in the period up to three postoperative days. It reduces the duration of postoperative tracheal intubation by roughly half. The occurrence of prolonged postoperative mechanical ventilation and myocardial infarction is also reduced by epidural analgesia.
Risks and complications.
Risks and complications as they relate to anesthesia are classified as either morbidity (a disease or disorder that results from anesthesia) or mortality (death that results from anesthesia). Attempting to quantify how anesthesia contributes to morbidity and mortality can be difficult because a person's health prior to surgery and the complexity of the surgical procedure can also contribute to the risks.
Prior to anesthetic in the early 19th century, the physiologic stress from surgery caused significant complications and many deaths from shock. The faster the surgery was, the lower the rate of complications (leading to reports of very quick amputations). The advent of anesthesia allowed more complicated and life-saving surgery to be completed, decreased the physiologic stress of the surgery, but added an element of risk. It was two years after the introduction of ether anesthetics that the first death directly related to anesthetic was reported.
Morbidity can be major (myocardial infarction, pneumonia, pulmonary embolism, renal failure/insufficiency, postoperative cognitive dysfunction and allergy) or minor (minor nausea, vomiting, readmission). There is usually overlap in the contributing factors that lead to morbidity and mortality between the health of the patient, the surgery being performed and the anesthetic. To understand the relative risk of each contributing factor, consider that the rate of deaths totally attributed to the patient's health is 1:870. Compare that to the rate of deaths totally attributed to surgical factors (1:2860) or anesthesia alone (1:185,056) illustrating that the single greatest factor in anesthetic mortality is the health of the patient. These statistics can also be compared to the first such study on mortality in anesthesia from 1954, which reported a rate of death from all causes at 1:75 and a rate attributed to anesthesia alone at 1:2680.:993 Direct comparisons between mortality statistics cannot reliably be made over time and across countries because of differences in the stratification of risk factors, however, there is evidence that anesthetics have made a significant improvement in safety but to what degree is uncertain.
Rather than stating a flat rate of morbidity or mortality, many factors are reported as contributing to the relative risk of the procedure and anesthetic combined. For instance, an operation on a person who is between the ages of 60–79 years old places the patient at 2.32 times greater risk than someone less than 60 years old. Having an ASA score of 3, 4 or 5 places the person at 10.65 times greater risk than someone with an ASA score of 1 or 2. Other variables include age greater than 80 (3.29 times risk compared to those under 60), gender (females have a lower risk of 0.77), urgency of the procedure (emergencies have a 4.44 times greater risk), experience of the person completing the procedure (less than 8 years experience and/or less than 600 cases have a 1.06 times greater risk) and the type of anesthetic (regional anesthetics are lower risk than general anesthetics).:984 Obstetrical, the very young and the very old are all at greater risk of complication so extra precautions may need to be taken.:969–986
Recovery.
The immediate time after anesthesia is called emergence. Emergence from general anesthesia or sedation requires careful monitoring because there is still a risk of complication. Nausea and vomiting are reported at 9.8% but will vary with the type of anesthetic and procedure. There is a need for airway support in 6.8%, there can be urinary retention (more common in those over 50 years of age) and hypotension in 2.7%. Hypothermia, shivering and confusion are also common in the immediate post-operative period because of the lack of muscle movement (and subsequent lack of heat production) during the procedure.:2707
Postoperative cognitive dysfunction (also known as "POCD" and post-anesthetic confusion) is a disturbance in cognition after surgery. It may also be variably used to describe emergence delirium (immediate post-operative confusion) and early cognitive dysfunction (diminished cognitive function in the first post-operative week). Although the three entities (delirium, early POCD and long-term POCD) are separate, the presence of delirium post-operatively predicts the presence of early POCD. There does not appear to be an association between delirium or early POCD and long-term POCD. According to a recent study conducted at the David Geffen School of Medicine at UCLA, the brain navigates its way through a series of activity clusters, or "hubs" on its way back to consciousness. Dr. Andrew Hudson, an assistant professor in anesthesiology states, "Recovery from anesthesia is not simply the result of the anesthetic 'wearing off,' but also of the brain finding its way back through a maze of possible activity states to those that allow conscious experience. Put simply, the brain reboots itself."
Long-term postoperative cognitive dysfunction is a subtle deterioration in cognitive function, that can last for weeks, months, or longer. Most commonly, relatives of the person report a lack of attention, memory and loss of interest in activities previously dear to the person (such as crosswords). In a similar way, people in the workforce may report an inability to complete tasks at the same speed they could previously. There is good evidence that POCD occurs after cardiac surgery and the major reason for its occurrence is the formation of microemboli. POCD also appears to occur in non-cardiac surgery. Its causes in non-cardiac surgery are less clear but older age is a risk factor for its occurrence.:2805–2816
History.
The first attempts at general anesthesia were probably herbal remedies administered in prehistory. Alcohol is one of the oldest known sedatives and it was used in ancient Mesopotamia thousands of years ago. The Sumerians are said to have cultivated and harvested the opium poppy ("Papaver somniferum") in lower Mesopotamia as early as 3400 BC.
The ancient Egyptians had some surgical instruments, as well as crude analgesics and sedatives, including possibly an extract prepared from the mandrake fruit. Bian Que (Chinese: 扁鹊, Wade–Giles: "Pien Ch'iao", c. 300 BC) was a legendary Chinese internist and surgeon who reportedly used general anesthesia for surgical procedures.
Throughout Europe, Asia, and the Americas a variety of "Solanum" species containing potent tropane alkaloids were used for anesthesia. In 13th century Italy, Theodoric Borgognoni used similar mixtures along with opiates to induce unconsciousness, and treatment with the combined alkaloids proved a mainstay of anesthesia until the nineteenth century. Local anesthetics were used in Inca civilization where shamans chewed coca leaves and performed operations on the skull while spitting into the wounds they had inflicted to anesthetize. Cocaine was later isolated and became the first effective local anesthetic. It was first used in 1859 by Karl Koller, at the suggestion of Sigmund Freud, in eye surgery in 1884. German surgeon August Bier (1861–1949) was the first to use cocaine for intrathecal anesthesia in 1898. Romanian surgeon Nicolae Racoviceanu-Piteşti (1860–1942) was the first to use opioids for intrathecal analgesia; he presented his experience in Paris in 1901.
Early Arab writings mention anesthesia by inhalation. This idea was the basis of the "soporific sponge" ("sleep sponge"), introduced by the Salerno school of medicine in the late twelfth century and by Ugo Borgognoni (1180–1258) in the thirteenth century. The sponge was promoted and described by Ugo's son and fellow surgeon, Theodoric Borgognoni (1205–1298). In this anesthetic method, a sponge was soaked in a dissolved solution of opium, mandragora, hemlock juice, and other substances. The sponge was then dried and stored; just before surgery the sponge was moistened and then held under the patient's nose. When all went well, the fumes rendered the patient unconscious.
The most famous anesthetic, ether, may have been synthesized as early as the 8th century, but it took many centuries for its anesthetic importance to be appreciated, even though the 16th century physician and polymath Paracelsus noted that chickens made to breathe it not only fell asleep but also felt no pain. By the early 19th century, ether was being used by humans, but only as a recreational drug.
Meanwhile, in 1772, English scientist Joseph Priestley discovered the gas nitrous oxide. Initially, people thought this gas to be lethal, even in small doses, like some other nitrogen oxides. However, in 1799, British chemist and inventor Humphry Davy decided to find out by experimenting on himself. To his astonishment he found that nitrous oxide made him laugh, so he nicknamed it laughing gas. Davy wrote about the potential anesthetic properties of nitrous oxide, but nobody at that time pursued the matter any further.
American physician Crawford W. Long noticed that his friends felt no pain when they injured themselves while staggering around under the influence of ether. He immediately thought of its potential in surgery. Conveniently, a participant in one of those “ether frolics", a student named James Venable, had two small tumors he wanted excised. But fearing the pain of surgery, Venable kept putting the operation off. Hence, Long suggested that he have his operation while under the influence of ether. Venable agreed, and on 30 March 1842 he underwent a painless operation. However, Long did not announce his discovery until 1849.
On October 16, 1846, Boston dentist William Thomas Green Morton conducted the first public demonstration of the inhalational anesthetic. Morton, who was unaware of Long's previous work, was invited to the Massachusetts General Hospital to demonstrate his new technique for painless surgery. After Morton had induced anesthesia, surgeon John Collins Warren removed a tumor from the neck of Edward Gilbert Abbott. This occurred in the surgical amphitheater now called the Ether Dome. The previously skeptical Warren was impressed and stated, "Gentlemen, this is no humbug." In a letter to Morton shortly thereafter, physician and writer Oliver Wendell Holmes, Sr. proposed naming the state produced "anesthesia", and the procedure an "anesthetic".
Morton at first attempted to hide the actual nature of his anesthetic substance, referring to it as Letheon. He received a US patent for his substance, but news of the successful anesthetic spread quickly by late 1846. Respected surgeons in Europe including Liston, Dieffenbach, Pirogov, and Syme quickly undertook numerous operations with ether. An American-born physician, Boott, encouraged London dentist James Robinson to perform a dental procedure on a Miss Lonsdale. This was the first case of an operator-anesthetist. On the same day, 19 December 1846, in Dumfries Royal Infirmary, Scotland, a Dr. Scott used ether for a surgical procedure. The first use of anesthesia in the Southern Hemisphere took place in Launceston, Tasmania, that same year. Drawbacks with ether such as excessive vomiting and its flammability led to its replacement in England with chloroform.
Discovered in 1831 by an American physician Samuel Guthrie (1782–1848), and independently a few months later by Frenchman Eugène Soubeiran (1797-1859) and Justus von Liebig (1803–73) in Germany, chloroform was named and chemically characterised in 1834 by Jean-Baptiste Dumas (1800–84). Its anaesthetic properties were noted early in 1847 by Marie-Jean-Pierre Flourens (1794–1867). The use of chloroform in anesthesia is linked to James Young Simpson, who, in a wide-ranging study of organic compounds, found chloroform's efficacy on 4 November 1847. Its use spread quickly and gained royal approval in 1853 when John Snow gave it to Queen Victoria during the birth of Prince Leopold. Unfortunately, though free of ether's flammability and consequent explosion hazard, chloroform is not as safe pharmacologically, especially when administered by an untrained practitioner (medical students, nurses, and occasionally members of the public were often pressed into giving anesthetics at this time). This led to many deaths from the use of chloroform that (with hindsight) might have been preventable. The first fatality directly attributed to chloroform anesthesia was recorded on 28 January 1848 after the death of Hannah Greener.
John Snow of London published articles from May 1848 onwards "On Narcotism by the Inhalation of Vapours" in the London Medical Gazette. Snow also involved himself in the production of equipment needed for the administration of inhalational anesthetics, the forerunner of today's anesthesia machines.
Of these first famous anesthetics, only nitrous oxide is still widely used today, with chloroform and ether having been replaced by safer but sometimes more expensive general anesthetics, and cocaine by more effective local anesthetics with less abuse potential.
Society and culture.
Almost all healthcare providers use anesthesia to some degree, however most health professions have their own field of specialists in the field including medicine, nursing and dentistry.
Doctors specializing in perioperative care, development of an anesthetic plan, and the administration of anesthetics are known in the US as "anesthesiologists" and in the UK, Canada, Australia, and NZ as "anaesthetists" or "anaesthesiologists". All anesthetics in the UK, Australia, New Zealand, Hong Kong and Japan are administered by doctors. Nurse anesthetists also administer anesthesia in 109 nations. In the US, 35% of anesthetics are provided by physicians in solo practice, about 55% are provided by anesthesia care teams (ACTs) with anesthesiologists medically directing anesthesiologist assistants or certified registered nurse anesthetists (CRNAs), and about 10% are provided by CRNAs in solo practice. There can also be anesthesiologist assistants (US) or physician assistant (anaesthesia) (UK) who assist with anesthesia
Special populations.
There are many circumstances when anesthesia needs to be altered for special circumstances due to the procedure (such as in cardiac surgery, cardiothoracic anesthesiology or neurosurgery), the patient (such as in pediatric anesthesia, geriatric, bariatric or obstetrical anesthesia) or special circumstances (such as in trauma, prehospital care, robotic surgery or extreme environments).

</doc>
<doc id="56565" url="http://en.wikipedia.org/wiki?curid=56565" title="Circadian rhythm">
Circadian rhythm

A circadian rhythm is any biological process that displays an endogenous, entrainable oscillation of about 24 hours. These 24-hour rhythms are driven by a circadian clock, and they have been widely observed in plants, animals, fungi, and cyanobacteria. The term "circadian" comes from the Latin "circa", meaning "around" (or "approximately"), and "diēs", meaning "day". The formal study of biological temporal rhythms, such as daily, tidal, weekly, seasonal, and annual rhythms, is called chronobiology. Although circadian rhythms are endogenous ("built-in", self-sustained), they are adjusted (entrained) to the local environment by external cues called zeitgebers, commonly the most important of which is daylight.
History.
The earliest recorded account of a circadian process dates from the 4th century B.C.E., when Androsthenes, a ship captain serving under Alexander the Great, described diurnal leaf movements of the tamarind tree. The observation of a circadian or diurnal process in humans is mentioned in Chinese medical texts dated to around the 13th century, including the "Noon and Midnight Manual" and the "Mnemonic Rhyme to Aid in the Selection of Acu-points According to the Diurnal Cycle, the Day of the Month and the Season of the Year".
The first recorded observation of an endogenous circadian oscillation was by the French scientist Jean-Jacques d'Ortous de Mairan in 1729. He noted that 24-hour patterns in the movement of the leaves of the plant "Mimosa pudica" continued even when the plants were kept in constant darkness, in the first experiment to attempt to distinguish an endogenous clock from responses to daily stimuli.
In 1896, Patrick and Gilbert observed that during a prolonged period of sleep deprivation, sleepiness increases and decreases with a period of approximately 24 hours. In 1918, J.S. Szymanski showed that animals are capable of maintaining 24-hour activity patterns in the absence of external cues such as light and changes in temperature. In the early 20th century, circadian rhythms were noticed in the rhythmic feeding times of bees. Extensive experiments were done by Auguste Forel, Ingeborg Beling, and Oskar Wahl to see whether this rhythm was due to an endogenous clock. Ron Konopka and Seymour Benzer isolated the first clock mutant in "Drosophila" in the early 1970s and mapped the "period" gene, the first discovered genetic component of a circadian clock. Joseph Takahashi discovered the first mammalian 'clock gene' (CLOCK) using mice in 1994.
The term "circadian" was coined by Franz Halberg in the 1950s.
Criteria.
To be called circadian, a biological rhythm must meet these three general criteria: 
Origin.
Photosensitive proteins and circadian rhythms are believed to have originated in the earliest cells, with the purpose of protecting the replicating DNA from high ultraviolet radiation during the daytime. As a result, replication was relegated to the dark. The fungus "Neurospora", which exists today, retains this clock-regulated mechanism.
Circadian rhythms allow organisms to anticipate and prepare for precise and regular environmental changes; they have great value in relation to the outside world. The rhythmicity appears to be as important in regulating and coordinating internal metabolic processes, as in coordinating with the environment. This is suggested by the maintenance (heritability) of circadian rhythms in fruit flies after several hundred generations in constant laboratory conditions, as well as in creatures in constant darkness in the wild, and by the experimental elimination of behavioural but not physiological circadian rhythms in quail.
The simplest known circadian clock is that of the prokaryotic cyanobacteria. Recent research has demonstrated that the circadian clock of "Synechococcus elongatus" can be reconstituted "in vitro" with just the three proteins (KaiA, KaiB, KaiC) of their central oscillator. This clock has been shown to sustain a 22-hour rhythm over several days upon the addition of ATP. Previous explanations of the prokaryotic circadian timekeeper were dependent upon a DNA transcription/translation feedback mechanism.
A defect in the human homologue of the "Drosophila" "period" gene was identified as a cause of the sleep disorder FASPS (Familial advanced sleep phase syndrome), underscoring the conserved nature of the molecular circadian clock through evolution. Many more genetic components of the biological clock are now known. Their interactions result in an interlocked feedback loop of gene products resulting in periodic fluctuations that the cells of the body interpret as a specific time of the day.
It is now known that the molecular circadian clock can function within a single cell; i.e., it is cell-autonomous. This was shown by Gene Block in isolated mollusk BRNs. At the same time, different cells may communicate with each other resulting in a synchronised output of electrical signaling. These may interface with endocrine glands of the brain to result in periodic release of hormones. The receptors for these hormones may be located far across the body and synchronise the peripheral clocks of various organs. Thus, the information of the time of the day as relayed by the eyes travels to the clock in the brain, and, through that, clocks in the rest of the body may be synchronised. This is how the timing of, for example, sleep/wake, body temperature, thirst, and appetite are coordinately controlled by the biological clock.
Importance in animals.
Circadian rhythmicity is present in the sleeping and feeding patterns of animals, including human beings. There are also clear patterns of core body temperature, brain wave activity, hormone production, cell regeneration, and other biological activities. In addition, photoperiodism, the physiological reaction of organisms to the length of day or night, is vital to both plants and animals, and the circadian system plays a role in the measurement and interpretation of day length.
Impact of circadian disruption.
Mutations or deletions of clock gene in mice have demonstrated the importance of body clocks to ensure the proper timing of cellular/metabolic events; clock-mutant mice are hyperphagic and obese, and have altered glucose metabolism. In mice, deletion of the Rev-ErbA alpha clock gene facilitates diet-induced obesity and changes the balance between glucose and lipid utilization predisposing to diabetes. However, it is not clear whether there is a strong association between clock gene polymorphisms in humans and the susceptibility to develop the metabolic syndrome.
Impact of light–dark cycle.
The rhythm is linked to the light–dark cycle. Animals, including humans, kept in total darkness for extended periods eventually function with a free-running rhythm. Their sleep cycle is pushed back or forward each "day", depending on whether their "day", their endogenous period, is shorter or longer than 24 hours. The environmental cues that reset the rhythms each day are called "zeitgebers" (from the German, "time-givers"). Totally blind subterranean mammals (e.g., blind mole rat "Spalax" sp.) are able to maintain their endogenous clocks in the apparent absence of external stimuli. Although they lack image-forming eyes, their photoreceptors (which detect light) are still functional; they do surface periodically as well.
Free-running organisms that normally have one or two consolidated sleep episodes will still have them when in an environment shielded from external cues, but the rhythm is, of course, not entrained to the 24-hour light–dark cycle in nature. The sleep–wake rhythm may, in these circumstances, become out of phase with other circadian or ultradian rhythms such as metabolic, hormonal, CNS electrical, or neurotransmitter rhythms.
Recent research has influenced the design of spacecraft environments, as systems that mimic the light–dark cycle have been found to be highly beneficial to astronauts.
Arctic animals.
Norwegian researchers at the University of Tromsø have shown that some Arctic animals (ptarmigan, reindeer) show circadian rhythms only in the parts of the year that have daily sunrises and sunsets. In one study of reindeer, animals at 70 degrees North showed circadian rhythms in the autumn, winter and spring, but not in the summer. Reindeer on Svalbard at 78 degrees North showed such rhythms only in autumn and spring. The researchers suspect that other Arctic animals as well may not show circadian rhythms in the constant light of summer and the constant dark of winter.
A 2006 study in northern Alaska found that day-living ground squirrels and nocturnal porcupines strictly maintain their circadian rhythms through 82 days and nights of sunshine. The researchers speculate that these two rodents notice that the apparent distance between the sun and the horizon is shortest once a day, and, thus, a sufficient signal to entrain (adjust) by.
Butterfly migration.
The navigation of the fall migration of the Eastern North American monarch butterfly ("Danaus plexippus") to their overwintering grounds in central Mexico uses a time-compensated sun compass that depends upon a circadian clock in their antennae.
In plants.
Plant circadian rhythms tell the plant what season it is and when to flower for the best chance of attracting pollinators. Behaviors showing rhythms include leaf movement, growth, germination, stomatal/gas exchange, enzyme activity, photosynthetic activity, and fragrance emission, among others. Circadian rhythms occur as a plant entrains to synchronize with the light cycle of its surrounding environment. These rhythms are endogenously generated and self-sustaining and are relatively constant over a range of ambient temperatures. Important features include two interacting transcription-translation feedback loops: proteins containing PAS domains, which facilitate protein-protein interactions; and several photoreceptors that fine-tune the clock to different light conditions. Anticipation of changes in the environment allows appropriate changes in a plant's physiological state, conferring an adaptive advantage. A better understanding of plant circadian rhythms has applications in agriculture, such as helping farmers stagger crop harvests to extend crop availability and securing against massive losses due to weather.
Light is the signal by which plants synchronize their internal clocks to their environment and is sensed by a wide variety of photoreceptors. Red and blue light are absorbed through several phytochromes and cryptochromes. One phytochrome, phyA, is the main phytochrome in seedlings grown in the dark but rapidly degrades in light to produce Cry1. Phytochromes B–E are more stable with phyB, the main phytochrome in seedlings grown in the light. The cryptochrome (cry) gene is also a light-sensitive component of the circadian clock and is thought to be involved both as a photoreceptor and as part of the clock's endogenous pacemaker mechanism. Cryptochromes 1–2 (involved in blue–UVA) help to maintain the period length in the clock through a whole range of light conditions.
The central oscillator generates a self-sustaining rhythm and is driven by two interacting feedback loops that are active at different times of day. The morning loop consists of CCA1 (Circadian and Clock-Associated 1) and LHY (Late Elongated Hypocotyl), which encode closely related MYB transcription factors that regulate circadian rhythms in "Arabidopsis", as well as PRR 7 and 9 (Pseudo-Response Regulators.) The evening loop consists of GI (Gigantea) and ELF4, both involved in regulation of flowering time genes. When CCA1 and LHY are overexpressed (under constant light or dark conditions), plants become arrhythmic, and mRNA signals reduce, contributing to a negative feedback loop. Gene expression of CCA1 and LHY oscillates and peaks in the early morning, whereas TOC1 gene expression oscillates and peaks in the early evening. While it was previously hypothesised that these three genes model a negative feedback loop in which over-expressed CCA1 and LHY repress TOC1 and over-expressed TOC1 is a positive regulator of CCA1 and LHY, it was shown in 2012 by Andrew Millar and others that TOC1 in fact serves as a repressor not only of CCA1, LHY, and PRR7 and 9 in the morning loop but also of GI and ELF4 in the evening loop. This finding and further computational modeling of TOC1 gene functions and interactions suggest a reframing of the plant circadian clock as a triple negative-component repressilator model rather than the positive/negative-element feedback loop characterizing the clock in mammals.
Biological clock in mammals.
The primary circadian "clock" in mammals is located in the suprachiasmatic nucleus (or nuclei) (SCN), a pair of distinct groups of cells located in the hypothalamus. Destruction of the SCN results in the complete absence of a regular sleep–wake rhythm. The SCN receives information about illumination through the eyes. The retina of the eye contains "classical" photoreceptors ("rods" and "cones"), which are used for conventional vision. But the retina also contains specialized ganglion cells that are directly photosensitive, and project directly to the SCN, where they help in the entrainment (synchronization) of this master circadian clock.
These cells contain the photopigment melanopsin and their signals follow a pathway called the retinohypothalamic tract, leading to the SCN. If cells from the SCN are removed and cultured, they maintain their own rhythm in the absence of external cues.
The SCN takes the information on the lengths of the day and night from the retina, interprets it, and passes it on to the pineal gland, a tiny structure shaped like a pine cone and located on the epithalamus. In response, the pineal secretes the hormone melatonin. Secretion of melatonin peaks at night and ebbs during the day and its presence provides information about night-length.
Several studies have indicated that pineal melatonin feeds back on SCN rhythmicity to modulate circadian patterns of activity and other processes. However, the nature and system-level significance of this feedback are unknown.
The circadian rhythms of humans can be entrained to slightly shorter and longer periods than the Earth's 24 hours. Researchers at Harvard have shown that human subjects can at least be entrained to a 23.5-hour cycle and a 24.65-hour cycle (the latter being the natural solar day-night cycle on the planet Mars).
Humans.
Early research into circadian rhythms suggested that most people preferred a day closer to 25 hours when isolated from external stimuli like daylight and timekeeping. However, this research was faulty because it failed to shield the participants from artificial light. Although subjects were shielded from time cues (like clocks) and daylight, the researchers were not aware of the phase-delaying effects of indoor electric lights. The subjects were allowed to turn on light when they were awake and to turn it off when they wanted to sleep. Electric light in the evening delayed their circadian phase.
Biological markers and effects.
The classic phase markers for measuring the timing of a mammal's circadian rhythm are:
For temperature studies, subjects must remain awake but calm and semi-reclined in near darkness while their rectal temperatures are taken continuously. Though variation is great among normal chronotypes, the average human adult's temperature reaches its minimum at about 05:00 (5 a.m.), about two hours before habitual wake time. Baehr et al. found that, in young adults, the daily body temperature minimum occurred at about 04:00 (4 a.m.) for morning types but at about 06:00 (6 a.m.) for evening types. This minimum occurred at approximately the middle of the eight hour sleep period for morning types, but closer to waking in evening types.
Melatonin is absent from the system or undetectably low during daytime. Its onset in dim light, "dim-light melatonin onset" (DLMO), at roughly 21:00 (9 p.m.) can be measured in the blood or the saliva. Its major metabolite can also be measured in morning urine. Both DLMO and the midpoint (in time) of the presence of the hormone in the blood or saliva have been used as circadian markers. However, newer research indicates that the melatonin "offset" may be the more reliable marker. Benloucif et al. found that melatonin phase markers were more stable and more highly correlated with the timing of sleep than the core temperature minimum. They found that both sleep offset and melatonin offset are more strongly correlated with phase markers than the onset of sleep. In addition, the declining phase of the melatonin levels is more reliable and stable than the termination of melatonin synthesis.
Other physiological changes that occur according to a circadian rhythm include heart rate and many cellular processes "including oxidative stress, cell metabolism, immune and inflammatory responses, epigenetic modification, hypoxia/hyperoxia response pathways, endoplasmic reticular stress, autophagy, and regulation of the stem cell environment."
In contradiction to previous studies, it has been found that there is no effect of body temperature on performance on psychological tests. This is likely due to evolutionary pressures for higher cognitive function compared to the other areas of function examined in previous studies.
Outside the "master clock".
More-or-less independent circadian rhythms are found in many organs and cells in the body outside the suprachiasmatic nuclei (SCN), the "master clock". These clocks, called peripheral oscillators, are found in the adrenal gland, oesophagus, lungs, liver, pancreas, spleen, thymus, and skin. Though oscillators in the skin respond to light, a systemic influence has not been proven. There is also some evidence that the olfactory bulb and prostate may experience oscillations when cultured, suggesting that these structures may also be weak oscillators.
Furthermore, liver cells, for example, appear to respond to feeding rather than to light. Cells from many parts of the body appear to have free-running rhythms.
Light and the biological clock.
Light resets the biological clock in accordance with the phase response curve (PRC). Depending on the timing, light can advance or delay the circadian rhythm. Both the PRC and the required illuminance vary from species to species and lower light levels are required to reset the clocks in nocturnal rodents than in humans.
Enforced longer cycles.
Studies by Nathaniel Kleitman in 1938 and by Derk-Jan Dijk and Charles Czeisler in the 1990s put human subjects on enforced 28-hour sleep–wake cycles, in constant dim light and with other time cues suppressed, for over a month. Because normal people cannot entrain to a 28-hour day in dim light if at all, this is referred to as a forced desynchrony protocol. Sleep and wake episodes are uncoupled from the endogenous circadian period of about 24.18 hours and researchers are allowed to assess the effects of circadian phase on aspects of sleep and wakefulness including sleep latency and other functions.
Human health.
Timing of medical treatment in coordination with the body clock may significantly increase efficacy and reduce drug toxicity or adverse reactions.
A number of studies have concluded that a short period of sleep during the day, a power-nap, does not have any measurable effect on normal circadian rhythms but can decrease stress and improve productivity.
Health problems can result from a disturbance to the circadian rhythm. Circadian rhythms also play a part in the reticular activating system, which is crucial for maintaining a state of consciousness. A reversal in the sleep–wake cycle may be a sign or complication of uremia, azotemia or acute renal failure.
Studies have also shown that light has a direct effect on human health because of the way it influences the circadian rhythms.
Obesity and diabetes.
Obesity and diabetes are associated with lifestyle and genetic factors. Among those factors, disruption of the circadian clockwork and/or misalignment of the circadian timing system with the external environment (e.g., light-dark cycle) might play a role in the development of metabolic disorders.
Shift-work or chronic jet-lag have profound consequences on circadian and metabolic events in the body. Animals that are forced to eat during their resting period show increased body mass and altered expression of clock and metabolic genes. In humans, shift-work that favors irregular eating times is associated with altered insulin sensitivity and higher body mass. Shift-work also leads to increased metabolic risks for cardio-metabolic syndrome, hypertension, inflammation.
Airline pilots.
Due to the work nature of airline pilots, who often cross several timezones and regions of sunlight and darkness in one day, and spend many hours awake both day and night, they are often unable to maintain sleep patterns that correspond to the natural human circadian rhythm; this situation can easily lead to fatigue. The NTSB cites this as contributing to many accidents and has conducted several research studies in order to find methods of combating fatigue in pilots.
Disruption.
Disruption to rhythms usually has a negative effect. Many travellers have experienced the condition known as jet lag, with its associated symptoms of fatigue, disorientation, and insomnia.
A number of other disorders, for example bipolar disorder and some sleep disorders such as delayed sleep phase disorder (DSPD), are associated with irregular or pathological functioning of circadian rhythms.
Disruption to rhythms in the longer term is believed to have significant adverse health consequences on peripheral organs outside the brain, in particular in the development or exacerbation of cardiovascular disease. LED lighting suppresses melatonin production five times more than a high-pressure sodium light. Depression symptoms from long term nighttime light exposure can be undone by returning to a normal cycle.
Effect of drugs.
Studies conducted on both animals and humans show major bidirectional relationships between the circadian system and abusive drugs. It is indicated that these abusive drugs affect the central circadian pacemaker. Individuals suffering from substance abuse display disrupted rhythms. These disrupted rhythms can increase the risk for substance abuse and relapse. It is possible that genetic and/or environmental disturbances to the normal sleep and wake cycle can increase the susceptibility to addiction.
It is difficult to determine if a disturbance in the circadian rhythm is at fault for an increase in prevalence for substance abuse or if other environmental factors such as stress are to blame.
Changes to the circadian rhythm and sleep occur once an individual begins abusing drugs and alcohol. Once an individual chooses to stop using drugs and alcohol, the circadian rhythm continues to be disrupted.
The stabilization of sleep and the circadian rhythm might possibly help to reduce the vulnerability to addiction and reduce the chances of relapse.
Circadian rhythms and clock genes expressed in brain regions outside the suprachiasmatic nucleus may significantly influence the effects produced by drugs such as cocaine. Moreover, genetic manipulations of clock genes profoundly affect cocaine's actions.
Further reading.
</dl>

</doc>
<doc id="56566" url="http://en.wikipedia.org/wiki?curid=56566" title="Chronobiology">
Chronobiology

Chronobiology is a field of biology that examines periodic (cyclic) phenomena in living organisms and their adaptation to solar- and lunar-related rhythms. These cycles are known as biological rhythms. Chronobiology comes from the ancient Greek χρόνος ("chrónos", meaning "time"), and biology, which pertains to the study, or science, of life. The related terms "chronomics" and "chronome" have been used in some cases to describe either the molecular mechanisms involved in chronobiological phenomena or the more quantitative aspects of chronobiology, particularly where comparison of cycles between organisms is required.
Chronobiological studies include but are not limited to comparative anatomy, physiology, genetics, molecular biology and behavior of organisms within biological rhythms mechanics. Other aspects include development, reproduction, ecology and evolution.
Description.
The variations of the timing and duration of biological activity in living organisms occur for many essential biological processes. These occur (a) in animals (eating, sleeping, mating, hibernating, migration, cellular regeneration, etc.), (b) in plants (leaf movements, photosynthetic reactions, etc.), and in microbial organisms such as fungi and protozoa. They have even been found in bacteria, especially among the cyanobacteria (aka blue-green algae, see bacterial circadian rhythms). The most important rhythm in chronobiology is the circadian rhythm, a roughly 24-hour cycle shown by physiological processes in all these organisms. The term "circadian" comes from the Latin "circa", meaning "around" and "dies", "day", meaning "approximately a day." It is regulated by circadian clocks.
The circadian rhythm can further be broken down into routine cycles during the 24-hour day:
While circadian rhythms are defined as endogenously regulated, other biological cycles may be regulated by exogenous signals. In some cases, multi-trophic systems may exhibit rhythms driven by the circadian clock of one of the members (which may also be influenced or reset by external factors). The endogenous plant cycles may regulate the activity of the bacterium by controlling availability of plant-produced photosynthate.
Many other important cycles are also studied, including:
Within each cycle, the time period during which the process is more active is called the "acrophase". When the process is less active, the cycle is in its "bathyphase" or "trough" phase. The particular moment of highest activity is the "peak" or "maximum"; the lowest point is the "nadir". How high (or low) the process gets is measured by the "amplitude".
History.
A circadian cycle was first observed in the 18th century in the movement of plant leaves by the French scientist Jean-Jacques d'Ortous de Mairan (for a description of circadian rhythms in plants by de Mairan, Linnaeus, and Darwin see ). In 1751 Swedish botanist and naturalist Carolus Linnaeus (Carl von Linné) designed a flower clock using certain species of flowering plants. By arranging the selected species in a circular pattern, he designed a clock that indicated the time of day by the flowers that were open at each given hour. For example, among members of the daisy family, he used the hawk's beard plant which opened its flowers at 6:30 am and the hawkbit which did not open its flowers until 7 am. 
The 1960 symposium at Cold Spring Harbor Laboratory laid the groundwork for the field of chronobiology.
It was also in 1960 that Patricia DeCoursey invented the phase response curve, one of the major tools used in the field since.
Franz Halberg of the University of Minnesota, who coined the word "circadian", is widely considered the "father of American chronobiology." However, it was Colin Pittendrigh and not Halberg who was elected to lead the "Society for Research in Biological Rhythms" in the 1970s. Halberg wanted more emphasis on the human and medical issues while Pittendrigh had his background more in evolution and ecology. With Pittendrigh as leader, the Society members did basic research on all types of organisms, plants as well as animals. More recently it has been difficult to get funding for such research on any other organisms than mice, rats, humans and fruit flies.
Recent developments.
More recently, light therapy and melatonin administration have been explored by Dr. Alfred J. Lewy (OHSU), Dr. Josephine Arendt (University of Surrey, UK) and other researchers as a means to reset animal and human circadian rhythms. Additionally, the presence of low-level light at night accelerates circadian re-entrainment of hamsters of all ages by 50%; this is thought to be related to simulation of moonlight.
Humans can be morning people or evening people; these variations are called chronotypes for which there are various assessment tools and biological markers.
In the second half of 20th century, substantial contributions and formalizations have been made by Europeans such as Jürgen Aschoff and Colin Pittendrigh, who pursued different but complementary views on the phenomenon of entrainment of the circadian system by light (parametric, continuous, tonic, gradual vs. nonparametric, discrete, phasic, instantaneous, respectively; see , subscription required).
There is also a food-entrainable biological clock, which is not confined to the suprachiasmatic nucleus. The location of this clock has been disputed. Working with mice, however, Fuller "et al." concluded that the food-entrainable clock seems to be located in the dorsomedial hypothalamus. During restricted feeding, it takes over control of such functions as activity timing, increasing the chances of the animal successfully locating food resources.
Other fields.
Chronobiology is an interdisciplinary field of investigation. It interacts with medical and other research fields such as sleep medicine, endocrinology, geriatrics, sports medicine, space medicine and photoperiodism.
The notion of biorhythms, a classic example of pseudoscience, which attempts to describe a set of cyclic variations in human behavior based on physiological and emotional cycles, is not a part of chronobiology.
Further reading.
</dl>
External articles.
</dl>

</doc>
<doc id="56567" url="http://en.wikipedia.org/wiki?curid=56567" title="Hyperbolic function">
Hyperbolic function

In mathematics, hyperbolic functions are analogs of the ordinary trigonometric, or circular functions. The basic hyperbolic functions are the hyperbolic sine "sinh" ( or ), and the hyperbolic cosine "cosh" (), from which are derived the hyperbolic tangent "tanh" ( or ), hyperbolic cosecant "csch" or "cosech" ( or ), hyperbolic secant "sech" ( or ), and hyperbolic cotangent "coth" ( or ), corresponding to the derived trigonometric functions. The inverse hyperbolic functions are the area hyperbolic sine "arsinh" (also called "asinh" or sometimes "arcsinh") and so on.
Just as the points (cos "t", sin "t") form a circle with a unit radius, the points (cosh "t", sinh "t") form the right half of the equilateral hyperbola. The hyperbolic functions take a real argument called a hyperbolic angle. The size of a hyperbolic angle is the area of its hyperbolic sector. The hyperbolic functions may be defined in terms of the legs of a right triangle covering this sector.
Hyperbolic functions occur in the solutions of some important linear differential equations, for example the equation defining a catenary, of some cubic equations, and of Laplace's equation in Cartesian coordinates. The latter is important in many areas of physics, including electromagnetic theory, heat transfer, fluid dynamics, and special relativity.
In complex analysis, the hyperbolic functions arise as the imaginary parts of sine and cosine. When considered defined by a complex variable, the hyperbolic functions are rational functions of exponentials, and are hence meromorphic.
Hyperbolic functions were introduced in the 1760s independently by Vincenzo Riccati and Johann Heinrich Lambert. Riccati used "Sc." and "Cc." ("[co]sinus circulare") to refer to circular functions and "Sh." and "Ch." ("[co]sinus hyperbolico") to refer to hyperbolic functions. Lambert adopted the names but altered the abbreviations to what they are today. The abbreviations "sh" and "ch" are still used in some other languages, like French and Russian.
Standard algebraic expressions.
The hyperbolic functions are:
Hyperbolic functions can be introduced via imaginary circular angles:
where "i" is the imaginary unit with the property that "i"2 = −1.
The complex forms in the definitions above derive from Euler's formula.
Useful relations.
Odd and even functions:
Hence:
It can be seen that cosh "x" and sech "x" are even functions; the others are odd functions.
Hyperbolic sine and cosine satisfy the identity
which is similar to the Pythagorean trigonometric identity. One also has
for the other functions.
The hyperbolic tangent is the solution to the differential equation formula_22 with f(0)=0 and the nonlinear boundary value problem:
It can be shown that the area under the curve of cosh ("x") over a finite interval is always equal to the arc length corresponding to that interval:
Sums of arguments:
particularly
Sum and difference of cosh and sinh:
Second derivatives.
The second derivatives of sinh and cosh are the same function: 
The only other functions for which this is the case are the exponential functions formula_43 and formula_44, and the zero function formula_45 (and linear combinations of these).
Standard integrals.
formula_46
The following integrals can be proved using hyperbolic substitution.
formula_47
where "C" is the constant of integration.
Taylor series expressions.
It is possible to express the above functions as Taylor series:
The function sinh "x" has a Taylor series expression with only odd exponents for "x". Thus it is an odd function, that is, −sinh "x" = sinh(−"x"), and sinh 0 = 0.
The function cosh "x" has a Taylor series expression with only even exponents for "x". Thus it is an even function, that is, symmetric with respect to the "y"-axis. The sum of the sinh and cosh series is the infinite series expression of the exponential function.
where
Comparison with circular functions.
The hyperbolic functions represent an expansion of trigonometry beyond the circular functions. Both types depend on an argument, either circular angle or hyperbolic angle.
Since the area of a circular sector is formula_53 it will be equal to "u" when "r" = square root of 2. In the diagram such a circle is tangent to the hyperbola "x y" = 1 at (1,1). The yellow sector depicts an area and angle magnitude. Similarly, the red augmentation depicts an area and magnitude as hyperbolic angle.
The legs of the two right triangles with hypotenuse on the ray defining the angles are of length √2 times the circular and hyperbolic functions.
Mellon Haskell of University of California, Berkeley described the basis of hyperbolic functions in areas of hyperbolic sectors in an 1895 article in Bulletin of the American Mathematical Society (see External links). He refers to the hyperbolic angle as an invariant measure with respect to the squeeze mapping just as circular angle is invariant under rotation.
Identities.
The hyperbolic functions satisfy many identities, all of them similar in form to the trigonometric identities. In fact, Osborn's rule states that one can convert any trigonometric identity into a hyperbolic identity by expanding it completely in terms of integral powers of sines and cosines, changing sine to sinh and cosine to cosh, and switching the sign of every term which contains a product of 2, 6, 10, 14, ... sinhs. This yields for example the addition theorems
the "double argument formulas"
and the "half-argument formulas"
The derivative of sinh "x" is cosh "x" and the derivative of cosh "x" is sinh "x"; this is similar to trigonometric functions, albeit the sign is different (i.e., the derivative of cos "x" is −sin "x").
The Gudermannian function gives a direct relationship between the circular functions and the hyperbolic ones that does not involve complex numbers.
The graph of the function "a" cosh("x"/"a") is the catenary, the curve formed by a uniform flexible chain hanging freely between two fixed points under uniform gravity.
Relationship to the exponential function.
From the definitions of the hyperbolic sine and cosine, we can derive the following identities:
and
These expressions are analogous to the expressions for sine and cosine, based on Euler's formula, as sums of complex exponentials.
Hyperbolic functions for complex numbers.
Since the exponential function can be defined for any complex argument, we can extend the definitions of the hyperbolic functions also to complex arguments. The functions sinh "z" and cosh "z" are then holomorphic.
Relationships to ordinary trigonometric functions are given by Euler's formula for complex numbers:
so:
Thus, hyperbolic functions are periodic with respect to the imaginary component, with period formula_64 (formula_65 for hyperbolic tangent and cotangent).

</doc>
<doc id="56568" url="http://en.wikipedia.org/wiki?curid=56568" title="Pleiades">
Pleiades

In astronomy, the Pleiades ( or ), or Seven Sisters (Messier 45 or M45), is an open star cluster containing middle-aged hot B-type stars located in the constellation of Taurus. It is among the nearest star clusters to Earth and is the cluster most obvious to the naked eye in the night sky. The celestial entity has several meanings in different cultures and traditions.
The cluster is dominated by hot blue and extremely luminous stars that have formed within the last 100 million years. Dust that forms a faint reflection nebulosity around the brightest stars was thought at first to be left over from the formation of the cluster (hence the alternative name Maia Nebula after the star Maia), but is now known to be an unrelated dust cloud in the interstellar medium, through which the stars are currently passing. Computer simulations have shown that the Pleiades was probably formed from a compact configuration that resembled the Orion Nebula. Astronomers estimate that the cluster will survive for about another 250 million years, after which it will disperse due to gravitational interactions with its galactic neighborhood.
Origin of name.
The name of the Pleiades comes from Ancient Greek. It probably derives from "plein" ('to sail') because of the cluster's importance in delimiting the sailing season in the Mediterranean Sea: 'the season of navigation began with their heliacal rising'. However, the name was later mythologised as the name of seven divine sisters, whose name was imagined to derive from that of their mother Pleione, effectively meaning 'daughters of Pleione'. However, in reality the name of the star-cluster almost certainly came first, and Pleione was invented to explain it.
Observational history.
The Pleiades are a prominent sight in winter in the Northern Hemisphere, and have been known since antiquity to cultures all around the world, including the Celts, Māori, Aboriginal Australians, the Persians, the Arabs (known as "Thurayya"), the Chinese, the Japanese, the Maya, the Aztec, and the Sioux and Cherokee. In Hinduism, the Pleiades are known as Krittika and are associated with the war-god Kartikeya (Murugan, Skanda), who derives his name from them. The god is raised by the six Krittika sisters, also known as the Matrikas. He is said to have developed a face for each of them.
The Babylonian star catalogues name the Pleiades MUL.MUL or "star of stars", and they head the list of stars along the ecliptic, reflecting the fact that they were close to the point of vernal equinox around the 23rd century BC. The earliest known depiction of the Pleiades is likely a bronze age artifact known as the Nebra sky disk, dated to approximately 1600 BC. Some Greek astronomers considered them to be a distinct constellation, and they are mentioned by Hesiod, and in Homer's "Iliad" and "Odyssey". They are also mentioned three times in the Bible (Job 9:9 and 38:31, as well as Amos 5:8). Some scholars of Islam suggested that the Pleiades (ath-thurayya) are the star mentioned in the sura (chapter) Najm of the Quran.
In Japan, the constellation is mentioned under the name Mutsuraboshi ("six stars") in the 8th century Kojiki and Manyosyu documents. The constellation is also known in Japan as Subaru (“unite”) and is depicted in the logo and name of the Subaru automobile company. The Persian equivalent is Nahid (pronounced "Naheed").
The rising of the Pleiades is mentioned in the Ancient Greek text "Geoponica". The Greeks oriented the Hecatompedon temple of 550 BC and the Parthenon of 438 BC to their rising. The rising of the Pleiades before dawn (usually at the beginning of June) has long been regarded as the start of the new year in Māori culture, with the star group being known as "Matariki". The rising of Matariki is celebrated as a midwinter festival in New Zealand. In Hawaiian culture the cluster is known as the Makali'i and their rising shortly after sunset marks the beginning of Makahiki, a 4 month time of peace in honor of the god Lono.
Galileo Galilei was the first astronomer to view the Pleiades through a telescope. He thereby discovered that the cluster contains many stars too dim to be seen with the naked eye. He published his observations, including a sketch of the Pleiades showing 36 stars, in his treatise "Sidereus Nuncius" in March 1610.
The Pleiades have long been known to be a physically related group of stars rather than any chance alignment. The Reverend John Michell calculated in 1767 that the probability of a chance alignment of so many bright stars was only 1 in 500,000, and so correctly surmised that the Pleiades and many other clusters of stars must be physically related. When studies were first made of the stars' proper motions, it was found that they are all moving in the same direction across the sky, at the same rate, further demonstrating that they were related.
Charles Messier measured the position of the cluster and included it as M45 in his catalogue of comet-like objects, published in 1771. Along with the Orion Nebula and the Praesepe cluster, Messier's inclusion of the Pleiades has been noted as curious, as most of Messier's objects were much fainter and more easily confused with comets—something that seems scarcely possible for the Pleiades. One possibility is that Messier simply wanted to have a larger catalogue than his scientific rival Lacaille, whose 1755 catalogue contained 42 objects, and so he added some bright, well-known objects to boost his list.
Edme-Sébastien Jeaurat then drew in 1782 a map of 64 stars of the Pleiades from his observations in 1779, which he published in 1786.
Distance.
The distance to the Pleiades can be used as an important first step to calibrate the cosmic distance ladder. As the cluster is so close to the Earth, its distance is relatively easy to measure and has been estimated by many methods. Accurate knowledge of the distance allows astronomers to plot a Hertzsprung-Russell diagram for the cluster, which, when compared to those plotted for clusters whose distance is not known, allows their distances to be estimated. Other methods can then extend the distance scale from open clusters to galaxies and clusters of galaxies, and a cosmic distance ladder can be constructed. Ultimately astronomers' understanding of the age and future evolution of the universe is influenced by their knowledge of the distance to the Pleiades. Yet some authors argue that the controversy over the distance to the Pleiades discussed below is a red herring, since the cosmic distance ladder can (presently) rely on a suite of other nearby clusters where consensus exists regarding the distances as established by Hipparcos and independent means (e.g., the Hyades, Coma Berenices cluster, etc.).
Measurements of the distance have elicited much controversy. Results prior to the launch of the Hipparcos satellite generally found that the Pleiades were about 135 parsecs away from Earth. Data from Hipparcos yielded a surprising result, namely a distance of only 118 parsecs by measuring the parallax of stars in the cluster—a technique that should yield the most direct and accurate results. Later work consistently argued that the Hipparcos distance measurement for the Pleiades was erroneous. In particular, distances derived to the cluster via the Hubble Space Telescope and infrared color-magnitude diagram fitting favor a distance between 135–140 pc; a dynamical distance from optical interferometric observations of the Pleiad double Atlas favors a distance of 133-137 pc. However, the author of the 2007–2009 catalog of revised Hipparcos parallaxes reasserted that the distance to the Pleiades is ~120 pc, and challenged the dissenting evidence. Recently, Francis and Anderson proposed that a systematic effect on Hipparcos parallax errors for stars in clusters biases calculation using the weighted mean, and gave a Hipparcos parallax distance of 126 pc, and photometric distance 132 pc based on stars in the AB Doradus, Tucana-Horologium moving group and Beta Pictoris moving groups, which are similar in age and composition to the Pleiades. Those authors note that the difference between these results can be attributed to random error.
The latest result (August, 2014) used very long baseline radio interferometry (VLBI) to determine a distance of 136.2 ± 1.2 pc, conclusively showing "that the "Hipparcos" measured distance to the Pleiades cluster is in error."
Composition.
The cluster core radius is about 8 light years and tidal radius is about 43 light years. The cluster contains over 1,000 statistically confirmed members, although this figure excludes unresolved binary stars. It is dominated by young, hot blue stars, up to 14 of which can be seen with the naked eye depending on local observing conditions. The arrangement of the brightest stars is somewhat similar to Ursa Major and Ursa Minor. The total mass contained in the cluster is estimated to be about 800 solar masses.
The cluster contains many brown dwarfs, which are objects with less than about 8% of the Sun's mass, not heavy enough for nuclear fusion reactions to start in their cores and become proper stars. They may constitute up to 25% of the total population of the cluster, although they contribute less than 2% of the total mass. Astronomers have made great efforts to find and analyse brown dwarfs in the Pleiades and other young clusters, because they are still relatively bright and observable, while brown dwarfs in older clusters have faded and are much more difficult to study.
Age and future evolution.
Ages for star clusters can be estimated by comparing the Hertzsprung-Russell diagram for the cluster with theoretical models of stellar evolution. Using this technique, ages for the Pleiades of between 75 and 150 million years have been estimated. The wide spread in estimated ages is a result of uncertainties in stellar evolution models, which include factors such as convective overshoot, in which a convective zone within a star penetrates an otherwise non-convective zone, resulting in higher apparent ages.
Another way of estimating the age of the cluster is by looking at the lowest-mass objects. In normal main sequence stars, lithium is rapidly destroyed in nuclear fusion reactions. Brown dwarfs can retain their lithium, however. Due to lithium's very low ignition temperature of 2.5 million kelvin, the highest-mass brown dwarfs will burn it eventually, and so determining the highest mass of brown dwarfs still containing lithium in the cluster can give an idea of its age. Applying this technique to the Pleiades gives an age of about 115 million years.
The cluster is slowly moving in the direction of the feet of what is currently the constellation of Orion. Like most open clusters, the Pleiades will not stay gravitationally bound forever. Some component stars will be ejected after close encounters with other stars; others will be stripped by tidal gravitational fields. Calculations suggest that the cluster will take about 250 million years to disperse, with gravitational interactions with giant molecular clouds and the spiral arms of our galaxy also hastening its demise.
Reflection nebulosity.
Under ideal observing conditions, some hint of nebulosity may be seen around the cluster, and this shows up in long-exposure photographs. It is a reflection nebula, caused by dust reflecting the blue light of the hot, young stars.
It was formerly thought that the dust was left over from the formation of the cluster, but at the age of about 100 million years generally accepted for the cluster, almost all the dust originally present would have been dispersed by radiation pressure. Instead, it seems that the cluster is simply passing through a particularly dusty region of the interstellar medium.
Studies show that the dust responsible for the nebulosity is not uniformly distributed, but is concentrated mainly in two layers along the line of sight to the cluster. These layers may have been formed by deceleration due to radiation pressure as the dust has moved towards the stars.
Brightest stars.
The nine brightest stars of the Pleiades are named for the Seven Sisters of Greek mythology: Sterope, Merope, Electra, Maia, Taygeta, Celaeno, and Alcyone, along with their parents Atlas and Pleione. As daughters of Atlas, the Hyades were sisters of the Pleiades. The English name of the cluster itself is of Greek origin (Πλειάδες), though of uncertain etymology. Suggested derivations include: from πλεῖν "plein", "to sail," making the Pleiades the "sailing ones"; from πλέος "pleos", "full, many"; or from πελειάδες "peleiades", "flock of doves." The following table gives details of the brightest stars in the cluster:
Possible planets.
Analyzing deep-infrared images obtained by the Spitzer Space Telescope and Gemini North telescope, astronomers discovered that one of the cluster's stars – HD 23514, which has a mass and luminosity a bit greater than that of the Sun, is surrounded by an extraordinary number of hot dust particles. This could be evidence for planet formation around HD 23514.
External links.
Coordinates: 

</doc>
<doc id="56569" url="http://en.wikipedia.org/wiki?curid=56569" title="Ashgabat">
Ashgabat

Ashgabat (Turkmen: "Aşgabat", ]; Persian: اشک آباد‎; Russian: Ашхаба́д, "Ashkhabad"; ]), known as Poltoratsk (Russian: Полтора́цк; ]) between 1919 and 1927, is the capital and the largest city of Turkmenistan in Central Asia, situated between the Karakum Desert and the Kopet Dag mountain range. The 2001 census estimated a population of 695,300, while the 2009 census estimated a population of 1 million, primarily Turkmen people, with ethnic minorities of Russians, Armenians, and Azerbaijanis.
The Karakum Canal runs through the city, carrying waters from the Amu Darya from east to west.
Names.
Ashgabat is called "Aşgabat" in Turkmen, Ашхабад ("Ashkhabad") in Russian, and "Ešq-ābād" (عشق‌آباد) in Persian. Before 1991, the city was usually spelled Ashkabad in English, a transliteration of the Russian form, which was itself from the original Persian form. It has also been variously spelled Ashkhabat and Ashgabad. From 1919 until 1927 the city was renamed Poltoratsk after a local revolutionary.
The name in Persian means "city of love" or "city of devotion". Modern linguists insist that the name goes back to the Parthian era, 3rd century BC, deriving from the name of the founder of the Parthian Empire, Arsaces I of Parthia, modified by Turkish pronunciation to Ashk-Abad (the city of "Ashk"/Arsaces).
History.
Ashgabat is a relatively young city, having been founded in 1881 as a fortification and named after the nearby settlement of Askhabad (lit. "beloved city" in Turkmen). Located not far from the site of Nisa, the ancient capital of the Parthian Empire, it grew on the ruins of the Silk Road city of Konjikala, first mentioned as a wine-producing village in the 2nd century BC and leveled by an earthquake in the 1st century BC (a precursor of the 1948 Ashgabat earthquake). Konjikala was rebuilt because of its advantageous location on the Silk Road and it flourished until its destruction by Mongols in the 13th century. After that it survived as a small village until Russians took over in the 19th century.
A part of Persia until the Battle of Geok Tepe, Askhabad was ceded to the Russian Empire under the terms of the Akhal Treaty. Russia developed the area as it was close to the border of British-influenced Persia. It was regarded as a pleasant town with European style buildings, shops, and hotels. In 1908, the first Bahá'í House of Worship was built in Askhabat. It was badly damaged in the 1948 earthquake and finally demolished in 1963. The community of the Bahá'í Faith in Turkmenistan was largely based in Ashgabat.
Soviet rule was established in Ashgabat in December 1917. However, in July 1918, a coalition of Mensheviks, Social Revolutionaries, and Tsarist former officers of the Imperial Russian Army revolted against the Bolshevik rule emanating from Tashkent and established the Ashkhabad Executive Committee. After receiving some support (but even more promises) from General Malleson, the British withdrew in April 1919 and the Tashkent Soviet resumed control of the city.
In 1919, the city was renamed Poltoratsk (Полторацк), after Pavel Poltoratsky, the Chairman of the Soviet of National Economy of the Turkestan Autonomous Soviet Socialist Republic. When the Turkmen SSR was established in 1924, Poltoratsk became its capital; original name (in the form of "Ashkhabad") was restored in 1927. From this period onward, the city experienced rapid growth and industrialisation, although severely disrupted by a major earthquake on October 6, 1948. An estimated 7.3 on the Richter scale, the earthquake killed 110-176,000 (⅔ of the population of the city), although the official number announced by Soviet news was only 40,000.
In July 2003, all the names of streets in Ashgabat were replaced by serial numbers except nine major highways, some named after Saparmurat Niyazov, his father and mother. The Central Palace area is designated 2000 to symbolize the beginning of the 21st century. The rest of the streets have larger or smaller four-digit numerical names.
In 2013, the city was included in the "Guinness Book of Records" as the world's highest concentration of white marble buildings.
Ashgabat milestones:
First Baha'i Temple in the world.
When Ashgabat was under the rule of Russia, it was known as Ishqábád and at that time the Bahá'í Faith was under the protection and freedom of the Russian authorities. The number of Bahá'ís of Ishqábád rose to over 1,000 and for the first time anywhere in the world a true Bahá'í community was established, with its own schools, medical facilities, cemetery, etc. They elected one of the first Bahá'í local administrative institutions. In 1908 the Bahá'í community completed construction of the first Bahá'í House of Worship, the spiritual and social heart of the Bahá'í community. The House of Worship, sometimes referred to by its Arabic name of mašriqu-l-'aḏkār (Arabic: مشرق اﻻذكار‎), was a gathering place where people of all religions may worship God without denominational restrictions. The building was designed under the guidance of `Abdu'l-Bahá by Ustad' Ali-Akbar Banna Yazdi who also wrote a history of the Baha'is in Ashgabat.
The House of Worship itself was surrounded by gardens with four buildings at the four corners of the gardens: a school, a hostel where travelling Bahá'ís were entertained, a small hospital, and a building for groundskeepers. The House of Worship in 'Ishqábád has been the only house of worship thus far to have the humanitarian subsidiaries associated with the institution built alongside it.
During the period of the Soviet Union Russia adopted the Soviet policy of oppression of religion, so the Bahá'ís, strictly adhering to their principle of obedience to legal government, abandoned these properties in 1928. For the decade between 1938 and 1948, when it was seriously damaged by the earthquake, it was an art gallery. It was demolished in 1963.
Districts.
Ashgabat is divided into the following districts:
In 2013, in the city of Ashgabat formed districts:
Architecture.
After 1991.
After exiting the Soviet Union, the city gained many high-rise residential buildings. Ashgabat has adopted modern construction techniques has become a high-rise infill development (mainly 12-storeyed). Primarily consisting of residential towers, the first floor is given a shopping area and the service department, many of the buildings are made of marble. The Arch of Neutrality was dismantled and re-erected in its original form in the south of the capital. Turkmenistan Tower, at a height of 211 meters, is the tallest building in the country.
Ashgabat is primarily a government and administrative centre. The business centre of Ashgabat is on the Archabil highway. Construction of several ministries and departments, teaching and research and cultural centres is complete. Development of office buildings and public spaces along the avenue continues.
Panorama of Ashgabat
Economy.
The principal industries are cotton textiles and metal working. It is a major stop on the Trans-Caspian railway. A large percentage of the employment in Ashgabat is provided by the state institutions; such as the ministries, undersecretariats, and other administrative bodies of the Turkmenistan government. There are also many foreign citizens working as diplomats or clerks in the embassies of their respective countries.
Industry.
Over 43 large and 128 medium industrial enterprises along with over 1,700 small industrial facilities are located on the territory of Ashgabat and its suburbs. The most important are “Ashneftemash”, “Turkmenkabel”, “Turkmenbashi Textile Complex” etc.
Shopping.
Foreign visitors to Ashgabat usually like to visit Altyn Asyr Bazaar in Choganly, where myriad things ranging from traditional fabrics, hand-woven carpets and massive range of commodities can be found at bargain prices. Modern shopping areas are mostly found in central streets, including the modern Turkish mall Ýimpaş, just a popular shopping centers are Paýtagt and Aşgabat. The local residents like traditional bazaars: Russian bazaar, Teke bazaar, Daşoguz bazaar, Mir bazaar, Jennet bazaar, etc.
Transportation.
The city is served by the Ashgabat International Airport. Turkmenistan Airlines has its headquarters in the city. Ashgabat offers air service to and from the major cities of the Turkmenistan, as well as Asia, Europe and the CIS. Ashgabat is served by the following foreign airlines: Belavia, Lufthansa, Turkish Airlines, S7 Airlines, flydubai, China Southern Airlines and Uzbekistan Airways.
Through the city from east to west is a Trans-Caspian Railway Turkmenbashi - Balkanabat - Bereket - Ashgabat - Mary - Türkmenabat. Also from Ashgabat to the north-east departs new Trans Karakum railway (Ashgabat-Karakum-Dashoguz), on which the movement is open from February 2006. In May 2009, the city municipality has completed the reconstruction of the Ashgabat railway station.
In Ashgabat there are two intercity bus stations, one located near the Teke Bazaar, the second at the old airport. There are daily buses to Archman, Dashoguz and Turkmenabat. The new International Passenger Bus Terminal of Ashgabat was commissioned in September 5, 2014.
Public transport in the city consists mainly of buses. More than 60 bus lines cover a total range of over 2230 km with 700 buses running on urban routes. Currently the city primarily uses Mercedes-Benz and Hyunda buses. Bus timetables and detailed schematic map of the route are at every stop. Distances between stops are about 300–500 meters. From October 19, 1964 to December 31, 2011 the city also had the Ashgabat trolleybus system. At the beginning of the twentieth century narrow-gauge railway operated by steam-power, connecting the city with the suburbs Firyuza.
On 18 October 2006, the Ashgabat Cable Car opened, connecting the city with the foothills of the Kopetdag.
Science and education.
Ashgabat is the most important educational center of Turkmenistan with a large number of places of education. Turkmen State University was founded in 1950: the main university building is located in Saparmurat Turkmenbashi Avenue. The Turkmen State Medical University is situated in Ashgabat also: it reports to the Ministry of Health and the medical industry of Turkmenistan. Other prominent institutions are the Turkmen State Institute of Economics and Management, a main business school founded in 1980, as well as the Turkmen State Institute of Architecture and Construction and the The National Institute of Sports and Tourism of Turkmenistan. There is only one foreign university - International Turkmen-Turkish University.
Climate.
The Kopet-Dag mountain range is about 25 km to the south, and Ashgabat's northern boundary touches the Kara-Kum desert. Because of this Ashgabat has an arid climate with hot, dry summers and cool, short winters. The average high temperature in July is 38.3 °C. Nighttimes in the summer are warm, with an average minimum temperature in July of 23.8 °C. The average January high temperature is 8.6 C, and the average low temperature is -0.4 C. The highest temperature ever recorded in Ashgabat is 46.7 °C, recorded in June 1995. A low temperature of -24.1 °C was recorded in January 1969. Snow is infrequent in the area. Annual precipitation is only 201 mm; March and April are the wettest months.
Notable buildings.
Museums include the Turkmen Fine Arts Museum and Turkmen Carpet Museum, noted for their impressive collection of woven carpets as well as a Turkmen history museum and the Ashgabat National Museum of History, which displays artifacts dating back to the Parthian and Persian civilizations. The Academy of Sciences of Turkmenistan is an important institute of higher learning. Ashgabat was also home to the Arch of Neutrality, a 250-foot-tall tripod crowned by a golden statue of late president Saparmurat Niyazov (also known as Turkmenbashi, or leader of all Turkmen). The 50-foot-high statue, which rotated in order to always face the sun during daylight hours, was removed on August 26, 2010 after Niyazov’s successor, current President Gurbanguly Berdimuhamedov, made it clear earlier in the year that the statue was going to be taken out of Ashgabat’s parliament square. In 2011 a Monument to the Constitution was built, the total height - 185 meters, makes it the second tallest building in Turkmenistan.
Alem Cultural and Entertainment Center was recognised by "Guinness World Records" as the world's tallest Ferris wheel in an enclosed space. The Ashgabat Flagpole is the fourth tallest free-standing flagpole in the world, standing at 133 m tall. The Ashgabat Fountain is the worlds greatest number of fountain pools in a public place. Ashgabat also features Turkmenistan Tower which is the tallest tower in Turkmenistan, the decorative octagonal Star of Oguzkhan is recognized as the world's largest architectural image of the star and entered in the Guinness World Records.
Parks and squares.
Ashgabat has many parks and open spaces mainly established in the early years of the Independence and well maintained and expanded thereafter. The most important of these parks are: the Botanical Garden, Güneş, Turkmen-Turkish friendship, Independence. The oldest city park - Ashgabat, founded in 1887. In the center of town is the Inspiration Alley, art-park complex, which is a favorite place for townspeople. Amusement park World of Turkmenbashi Tales - a local version of Disneyland. Squares: 10 years of independence of Turkmenistan, Magtymguly, Eternal Flame, Zelili, Chyrchyk, Garashsyzlyk, March 8, Gerogly, Dolphin, 15 years of Independence, Ruhyýet, 10 ýyl Abadançylyk.
Cinemas.
Ashgabat has several cinemas. In 2011, Aşgabat Cinema, the first 3D cinema in Turkmenistan, opened in Ashgabat. The Watan and Turkmenistan theaters were reconstructed.
Sports.
The main sporting venues in Ashgabat are the Olympic Stadium, Ashgabat Stadium, the National Olympic ice rink, Sports complex for winter sports and the Olympic water sports complex.
Ashgabat has been chosen as the host city of the V Asian Indoor Games and Martial Arts, and was also the first city in Central Asia to host the Asian Indoor Games. In 2010, an Olympic Village was built in the south of the city. It is aimed to be completed by 2015, at a cost of $5 billion.
The city's professional football clubs Altyn Asyr, FC Ashgabat, HTTU Aşgabat and FC Talyp Sporty play in the Ýokary Liga, the top flight of Turkmenistan.
International relations.
Twin towns and sister cities.
Ashgabat is twinned with:

</doc>
<doc id="56571" url="http://en.wikipedia.org/wiki?curid=56571" title="Guignol">
Guignol

Guignol is the main character in a French puppet show which has come to bear his name. 
Although often thought of as children's entertainment, Guignol's sharp wit and linguistic verve have always been appreciated by adults as well, as shown by the motto of a prominent Lyon troupe: "Guignol amuses children… and witty adults".
Laurent Mourguet, Guignol's creator, was born into a family of modest silk weavers on March 3, 1769. The certificate of his marriage to Jeanne Esterle in 1788 shows he was unable to read. When hard times fell on the silk trade during the French Revolution, he became a peddler, and in 1797 started to practice dentistry, which in those days was simply the pulling of teeth. The service was free; the money was made from the medicines sold afterward to ease the pain. To attract patients, he started setting up a puppet show in front of his dentist's chair.
His first shows featured Polichinelle, a character borrowed from the Italian commedia dell'arte who in England would become Punch. By 1804 the success was such that he gave up dentistry altogether and became a professional puppeteer, creating his own scenarios drawing on the concerns of his working-class audience and improvising references to the news of the day. He developed characters closer to the daily lives of his Lyon audience, first Gnafron, a wine-loving cobbler, and in 1808 Guignol. Other characters, including Guignol's wife Madelon and the gendarme Flagéolet soon followed, but these are never much more than foils for the two heroes.
Although nominally a silkweaver like much of his original audience, Guignol's profession changes, as does his marital status; he can be in turn valet, peddler, carpenter, shoemaker, or unemployed; at times he is Madelon's husband, at times her smitten suitor according to requirements of the scenario. What remain constant are his poverty, but more importantly his good humor and his sense of justice. The use in French of "guignol" as an insult meaning "buffoon" is a curious misnomer, as Guignol is clever, courageous and generous; his inevitable victory is always the triumph of good over evil. 
Sixteen of Mourguet's children and grandchildren continued his tradition, and many of the companies performing today can trace their heritage back to him. According to the era, the region, or the performers, Guignol's original caustic satire has often been watered down to simple children's fare, and has even been used to parody grand opera, but his original spirit still survives in his hometown of Lyon, where both traditional and original contemporary performances are an integral part of local culture. In addition to his social satire, Guignol has become an important protector of the local dialect, the "parler lyonnais".

</doc>
<doc id="56573" url="http://en.wikipedia.org/wiki?curid=56573" title="Messier">
Messier

Messier can refer to:

</doc>
<doc id="56574" url="http://en.wikipedia.org/wiki?curid=56574" title="Maria Edgeworth">
Maria Edgeworth

Maria Edgeworth (1 January 1768 – 22 May 1849) was a prolific Anglo-Irish writer of adults' and children's literature. She was one of the first realist writers in children's literature and was a significant figure in the evolution of the novel in Europe. She held advanced views, for a woman of her time, on estate management, politics and education, and corresponded with some of the leading literary and economic writers, including Sir Walter Scott and David Ricardo.
Life.
Early life.
Maria Edgeworth was born at Black Bourton, Oxfordshire. She was the second child of Richard Lovell Edgeworth (who eventually fathered 22 children by four wives) and Anna Maria Edgeworth ("née" Elers); Maria was thus an aunt of Francis Ysidro Edgeworth. She spent her early years with her mother's family in England, until her mother's death when Maria was five. When her father married his second wife Honora Sneyd in 1773, she went with him to his estate, Edgeworthstown, in County Longford, Ireland.
Maria was sent to Mrs. Lattafière's school in Derby after Honora fell ill in 1775. When Honora died in 1780 and Maria's father married Honora's sister Elizabeth (considered somewhat shocking in that time's moral climate), Maria transferred to Mrs. Devis's school in London. Her father's attention became fully focused on her in 1781 when she nearly lost her sight to an eye infection. Returning home at the age of 14, she took charge of her many younger siblings and was home-tutored in law, Irish economics and politics, science, and literature by her father. She also started her lifelong correspondences with learned men, mainly members of the Lunar Society.
She became her father's assistant in managing the Edgeworthtown estate, which had become run-down during the family's 1777–1782 absence; she would live and write there for the rest of her life. With their bond strengthened, Maria and her father began a lifelong academic collaboration "of which she was the more able and nimble mind." Present at Edgeworthstown was an extended family, servants and tenants. She observed and recorded the details of daily Irish life, later drawing on this experience for her novels about the Irish. She also mixed with the Anglo-Irish gentry, particularly Kitty Pakenham (later the wife of Arthur Wellesley, 1st Duke of Wellington), Lady Moira, and her aunt Margaret Ruxton of Black Castle. Margaret supplied her with the novels of Anne Radcliffe and William Godwin and encouraged her in her writing.
Travels.
In 1798 Richard married Frances Beaufort, daughter of Daniel Augustus Beaufort, who instigated the idea of travelling to England and the European continent. Frances, a year younger than Maria, became her lifelong confidante. The family travelled first to London in 1800.
In 1802 the Edgeworths toured the English midlands. They then travelled to the continent, first to Brussels and then to Consulate France (during the Peace of Amiens, a brief lull in the Napoleonic Wars). They met all the notables, and Maria received a marriage proposal from a Swedish courtier, Count Edelcrantz. Her letter on the subject seems very cool, but her stepmother assures us in the Augustus Hare "Life and Letters" that Maria loved him very much and did not get over the affair quickly. They came home to Ireland in 1803 on the eve of the resumption of the wars and Maria returned to writing. "Tales of Fashionable Life", "The Absentee" and "Ormond" are novels of Irish life. Edgeworth was an extremely popular author who was compared with her contemporary writers Jane Austen and Sir Walter Scott. She initially earned more than them, and used her income to help her siblings.
On a visit to London in 1813, where she was received as a literary lion, Maria met Lord Byron (whom she disliked) and Humphry Davy. She entered into a long correspondence with the ultra-Tory Sir Walter Scott after the publication of "Waverley" in 1814, in which he gratefully acknowledged her influence, and they formed a lasting friendship. She visited him in Scotland at Abbotsford House in 1823, where he took her on a tour of the area. The next year, Sir Walter visited Edgeworthstown. When passing through the village, one of the party wrote, "We found neither mud hovels nor naked peasantry, but snug cottages and smiles all about." A counterview was provided by another visitor who stated that the residents of Edgeworthstown treated Edgeworth with contempt, refusing even to feign politeness.
Later life.
Richard Edgeworth was comparatively fair and forgiving in his dealings with his tenants and was actively involved in the estate's management. After debating the issue with the economist David Ricardo, Maria came to believe that better management and the further application of science to agriculture would raise food production and lower prices. Both Richard and Maria were also in favour of Catholic Emancipation, enfranchisement for Catholics without property restrictions (although he admitted it was against his own interest), agricultural reform and increased educational opportunities for women. She particularly worked hard to improve the living standards of the poor in Edgeworthstown. In trying to improve conditions in the village she provided schools for the local children of all denominations.
After her father's death in 1817 she edited his memoirs, and extended them with her biographical comments. She was an active writer to the last.
She worked for the relief of the famine-stricken Irish peasants during the Irish Potato Famine. She wrote "Orlandino" for the benefit of the Relieve Fund. Her letters to the Quaker Relief Committee provide a vivid account of the desperate plight facing the tenants in Edgeworthstown, the extreme conditions under which they lived, and the struggle to obtain whatever aid and assistance she could to alleviate their plight. Through her efforts she received gifts for the poor from America.
During the Irish Famine Edgeworth insisted that only those of her tenants who had paid their rent in full would receive relief. Edgeworth also punished those of her tenants who voted against her Tory preferences.
With the election of William Rowan Hamilton to president of the Royal Irish Academy, Maria became a dominant source of advice for Hamilton, particularly on the issue of literature in Ireland. She suggested that women should be allowed to participate in events held by the academy. For her guidance and help, Hamilton made Edgeworth an honorary member of the Royal Irish Academy in 1837, following in the footsteps of Louisa Beaufort, a former member of the academy and a relative of hers.
After a visit to see her relations in Trim, Maria, now in her eighties, began to feel heart pains and died suddenly of a heart attack in Edgeworthstown on 22 May 1849.
Views.
Though Maria Edgeworth spent most of her childhood in England, her life in Ireland had a profound impact on both her thinking and views surrounding her Irish culture. Fauske and Kaufman conclude, "[She] used her fiction to address the inherent problems of acts delineated by religious, national, racial, class based, sexual, and gendered identities." Edgeworth used works such "Castle Rackrent" and "Harrington" to express her feelings on controversial issues.
Ireland.
In her works, Edgeworth created a nostalgic past of Ireland in an attempt to celebrate Irish culture.
Suvendrini Perera said Edgeworth's novels traced "the gradual anglicanization of feudal Irish society." Edgeworth's goal in her works was to show the Irish as equal to the English, and therefore warranting equal, though not separate, status.
"Essay on Irish Bulls" rejects an English stereotype of Irishmen and portrays them accurately in realistic, everyday settings. This is a common theme in her Irish works, combating the caricatured Irish with accurate representations. In her work Edgeworth also places focus on the linguistic differences between Irish and English societies, as a foil to how dynamic and intricate Irish society was in spite of English stereotypes.
Edgeworth's writing of Ireland, especially her early Irish tales, offer an important rearticulation of Burkean local attachment and philosophical cosmopolitanism to produce an understanding of the nation as neither tightly bordered (like nations based on historical premises such as blood or inheritance) or not borderless (like those based on rational notions of universal inclusion). Edgeworth used her writing to reconsider the meaning of the denomination "Anglo-Irish", and through her interrogation she reinterpreted both cosmopolitan and national definitions of belonging so as to reconstitute "Anglo-Irish" less as a category than as an ongoing mediation between borders. In Edgeworth's Irish novels, education is the key to both individual and national improvement, according to Edgeworth, "it is the foundation of the well-governed estate and the foundation of the well-governed nation". More specifically, a slow process of education instills transnational understanding in the Irish people while retaining the bonds of local attachment by which the nation is secured. The centrality of education not only suggests Edgeworth's wish for a rooted yet cosmopolitan or transnational judgment, but also distinguishes her writing from constructions of national identity as national character, linking her through to earlier cosmopolitan constructions of universal human subjects. By claiming national difference as anchored in education, culture rather than nature, Edgeworth gives to national identity a sociocultural foundation, and thereby opens a space in which change can happen.
Social.
Maria agreed with the Act of Union, but thought that it should not be passed against the wishes of the Irish people. Concerning education, she thought boys and girls should be educated equally and together, drawing upon Rousseau's ideas.
She believed a woman should only marry someone who suits her in "character, temper, and understanding." Becoming an old maid was preferable to an incompatible union.
The story "Vivian" from "Tales of Fashionable Life" and "Patronage" attack eighteenth-century English Whig governance of Ireland as corrupt and unrepresentative.
Edgeworth strove for the self-realization of women and stressed the importance of the individual. She also wanted greater participation in politics by middle class women. Her work "Helen" clearly demonstrates this point in the passage:
"Women are now so highly cultivated, and political subjects are at present of so much importance, of such high interest, to all human creatures who live together in society, you can hardly expect, Helen, that you, as a rational being, can go through the world as it now is, without forming any opinion on points of public importance. You cannot, I conceive, satisfy yourself with the common namby-pamby little missy phrase, 'ladies have nothing to do with politics'."
She sympathised with Catholics and supported gradual, though not immediate, Catholic Emancipation.
Education.
To help illustrate the care that must be taken in teaching children and to emphasise the necessity of properly directing and managing their attentiveness, Maria Edgeworth drew several comparisons with non-European peoples. In her 1798 book Practical Education she maintained that unnecessarily causing fatigue should be a great concern of educators. In making the point that any mode of instruction that tired the attention was hurtful to children, her reasoning was that people can pay attention only to one thing at a time, and because children can appear resistant to repetition, teachers naturally should vary things. However, educators should always be mindful of the fact that, "while variety relieves the mind, the objects which are varied must not all be entirely new, for novelty and variety when joined, fatigue the mind" as Edgeworth states. The teaching of children needed to follow carefully considered methods, needed to evidence concern for appropriateness and proper sequencing, and needed to be guided by consideration from forms of teaching that would be empowering and enabling, not fatiguing or disabling. In Edgeworth's work, the attention of the child appears as a key site for pedagogical work and interventions.
Work.
Edgeworth's early literary efforts have often been considered melodramatic rather than realistic. Recent scholarship, however, has uncovered the importance of Edgeworth's previously unpublished juvenilia manuscript, "The Double Disguise" (1786). In particular, "The Double Disguise" signals Edgeworth's turn toward realism and is now considered a seminal regional narrative predating "Castle Rackrent" (1800). In addition, Edgeworth wrote many children's novels that conveyed moral lessons to their audience. One of her schoolgirl novels features a villain who wore a mask made from the skin of a dead man's face. Edgeworth's first published work was "Letters for Literary Ladies" in 1795. Her work, "An Essay on the Noble Science of Self-Justification" (1795) is written for a female audience in which she convinces women that the fair sex is endowed with an art of self-justification and women should use their gifts to continually challenge the force and power of men, especially their husbands, with wit and intelligence. It humorously and satirically explores the feminine argumentative method. This was followed in 1796 by her first children's book, "The Parent's Assistant", which included Edgeworth's celebrated short story "The Purple Jar". "The Parent's Assistant" was influenced by her father's work and perspectives on children's education.
Mr. Edgeworth, a well-known author and inventor, encouraged his daughter's career. At the height of her creative endeavours, Maria wrote, "Seriously it was to please my Father I first exerted myself to write, to please him I continued." Though the impetus for Maria's works, Mr. Edgeworth has been criticised for his insistence on approving and editing her work. The tales in "The Parent's Assistant" were approved by her father before he would allow them to be read to her younger siblings. It is speculated that her stepmother and siblings also helped in the editing process of Edgeworth's work.
"Practical Education" (1798) is a progressive work on education that combines the ideas of Locke and Rousseau with scientific inquiry. Edgeworth asserts that "learning should be a positive experience and that the discipline of education is more important during the formative years than the acquisition of knowledge." The system attempted to "adapt both the curriculum and methods of teaching to the needs of the child; the endeavour to explain moral habits and the learning process through associationism; and most important, the effort to entrust the child with the responsibility for his own mental culture." The ultimate goal of Edgeworth's system was to create an independent thinker who understands the consequences of their actions.
Her first novel, "Castle Rackrent" (1800) was written and submitted for anonymous publication in 1800 without her father's knowledge. It was an immediate success and firmly established Edgeworth's appeal. The book is a satire on Anglo-Irish landlords, before the year 1782, showing the need for more responsible management by the Irish landowning class. The story follows four generations of an Irish landholding family, the Rackrents. It is narrated by an Irish catholic worker on the estate, named Thady Quirk, and portrayed the rise of the catholic-Irish middle class.
"Belinda" (1801), a 3-volume work published in London, was Maria Edgeworth's first full-length novel. It dealt with love, courtship, and marriage, dramatising the conflicts within her "own personality and environment; conflicts between reason and feeling, restraint and individual freedom, and society and free spirit." "Belinda" was also notable for its controversial depiction of interracial marriage between an African servant and an English farm-girl. Later editions of the novel, however, removed these sections.
"Tales of Fashionable Life" (1809 and 1812) is a 2-series collection of short stories which often focus on the life of a woman. The second series was particularly well received in England, making her the most commercially successful novelist of her age. After this, Edgeworth was regarded as the preeminent woman writer in England alongside Jane Austen.
Following an anti-Semitic remark in "The Absentee", Edgeworth received a letter from an American Jewish woman named Rachel Mordecai in 1815 complaining about Edgeworth's depiction of Jews. In response, "Harrington" (1817) was written as an apology to the Jewish community. The novel was a fictitious autobiography about overcoming antisemitism and includes one of the first sympathetic Jewish characters in an English novel.
"Helen" (1834) is Maria Edgeworth's final novel, the only one she wrote after her father's death. She chose to write a novel focused on the characters and situation, rather than moral lessons. In a letter to her publisher, Maria wrote, "I have been reproached for making "my moral" in some stories too prominent. I am sensible of the inconvenience of this both to reader and writer & have taken much pains to avoid it in "Helen"." Her novel is also set in England, a conscious choice as Edgeworth found Ireland too troubling for a fictitious work in the political climate of the 1830s.
Style and purpose.
Having come to her literary maturity at a time when the ubiquitous and unvarying stated defence of the novel was its educative power, Maria Edgeworth was among the few authors who truly espoused the educator's role. Her novels are morally and socially didactic in the extreme. A close analysis of the alterations which Edgeworth's style underwent when it was pressed into the service of overt didacticism should serve to illuminate the relationship between prose technique and didactic purpose in her work. The convention which Maria Edgeworth has adopted and worked to death is basic to the eighteenth-century novel, but its roots like in the drama, tracing at least to the Renaissance separation of high and low characters by their forms of speech. Throughout the eighteenth-century drama, and most noticeably in the sentimental comedy, the separation becomes more and more a means of moral judgment as well as social identification. The only coherent reason for Edgeworth's acceptance is the appeal of didactic moralism. In the first place, she is willing to suspend judgment wherever the service of the moral is the result. Everything else may go, so long as the lesson is enforced. the lesson might be a warning against moral impropriety, as in Miss Milner's story, or against social injustice, as in "The Absentee". Furthermore, the whole reliance on positive exemplars had been justified long before by Steele, who argued that the stage must supply perfect heroes since its examples are imitated and since simple natures are incapable of making the necessary deductions from the negative exemplars of satire.
The characteristic of Edgeworth is to connect an identifiable strain of formal realism, both philosophical and rhetorical, and therefore display an objective interest in human nature and the way it manifests itself in social custom. One would expect this from Edgeworth, an author whose didacticism often has struck modern readers as either gendered liability, technical regression, or familial obligation. Critics have responded to Edgeworth's eccentricities by attributing them to something more deep-seated, temperamental, and psychological. In their various, often insightful representation, Edgeworth's fondness for the real, the strange, and the pedagogically useful verges on the relentless, the obsessive, and the instinctive. There is an alternative literary answer to explain Edgeworth's cultural roots and ideological aims which shifts focus away from Edgeworth's familial, psychological, and cultural predicaments to the formal paradigms by which her work has been judged. Rather than locating Edgeworth's early romances of real life exclusively within the traditions of eighteenth-century children's literature or domestic realism, they can be read primarily as responses to late eighteenth-century debates over the relation between history and romance, because the genre attempts to mediate between the two differentiating itself from other kinds of factual fiction. Edgeworth's romances of real life operate in the same discursive field but do not attempt to traverse between self-denied antinomies. In fact, they usually make the opposite claim.
Edgeworth's repeated self-effacement needs to be seen in the context of the times, where learning in women was often disapproved of and even riduculed, such as the satirical poem of the Rev. Richard Polwhele, "The Unsex'd Females" (1798).
Legacy.
During the period 1800–1814 (when Walter Scott's "Waverley" was published) Edgeworth was the most celebrated and successful living English novelist. Her reputation equalled that of Fanny Burney (Madame d'Arblay) (1752–1840) earlier, in a time that saw a number of other women writers including Elizabeth Hamilton, Amelia Opie, Hannah More, Elizabeth Inchbald. Her only potential male competitor prior to Scott was William Godwin. She was certainly well received by the critics and literary figures of her time. Croker (1780–1857) compared her work to "Don Quixote" and "Gil Blas" and to the work of Henry Fielding, while Francis Jeffrey (1773–1850) called her work 'perfect'.
Bibliography.
Reference materials.
</dl>

</doc>
<doc id="56575" url="http://en.wikipedia.org/wiki?curid=56575" title="Castle Rackrent">
Castle Rackrent

Castle Rackrent, a short novel by Maria Edgeworth published in 1800, is often regarded as the first historical novel, the first regional novel in English, the first Anglo-Irish novel, the first Big House novel and the first saga novel. 
It is also widely regarded as the first novel to use the device of a narrator who is both unreliable and an observer of, rather than a player in, the actions he chronicles. Kirkpatrick suggests that it "both borrows from and originates a variety of literary genres and subgenres without neatly fitting into any one of them". William Butler Yeats pronounced "Castle Rackrent" "one of the most inspired chronicles written in English".
Shortly before its publication, an introduction, glossary and footnotes, written in the voice of an English narrator, were added to the original text to blunt the negative impact the Edgeworths feared the book might have on English enthusiasm for the Act of Union 1800. 
The novel is one of the few of Miss Edgeworth's novels which her father did not 'edit'.
Plot summary.
The novel is set prior to the Constitution of 1782 and tells the story of four generations of Rackrent heirs through their steward, Thady Quirk. The heirs are: the dissipated spendthrift Sir Patrick O'Shaughlin, the litigious Sir Murtagh Rackrent, the cruel husband and gambling absentee Sir Kit Rackrent, and the generous but improvident Sir Condy Rackrent. Their sequential mismanagement of the estate is resolved through the machinations—and to the benefit—of the narrator's astute son, Jason Quirk.
Themes and style.
It satirises Anglo-Irish landlords and their overall mismanagement of the estates they owned at a time when the English and Irish parliaments were working towards formalising their union through the Acts of Union. Through this and other works, Edgeworth is credited with serving the political, national interests of Ireland and the United Kingdom the way Sir Walter Scott did for Scotland.
It is a dialogic novel, comprising a preface and conclusion by an editor bookending a first person narrative proper. It also has a glossary (which was a last-minute addition).

</doc>
<doc id="56576" url="http://en.wikipedia.org/wiki?curid=56576" title="Humphrey B. Bear">
Humphrey B. Bear

Humphrey B. Bear is an Australian children's television series and its fictional character namesake is an icon of Australian children's television. "Humphrey B. Bear" was first broadcast on Adelaide's NWS-9 on Monday, 24 May 1965. The show became one of the most successful programs for pre-schoolers in Australia. The part of Humphrey was played by Edwin Duryea, an actor, singer and dancer whose human identity was never revealed.
The character of Humphrey is a tall, shaggy brown bear with a large, glossy nose, straw boater, tartan waist-coat and oversized yellow bow-tie. His television show always features a companion who assists and narrates Humphrey's various adventures in the "magic forest" including his brightly coloured tree house. The show is shot on television studio set. In the early days the character was known as Bear Bear and was named Humphrey B. Bear as the result of an on air competition. The 'B' in Humphrey B Bear stands for Bear, but this has rarely been acknowledged on air.
Television show.
The show has won Logies for Best Children's Series and the character of Humphrey has received a number of National Awards and Commendations, including a special "Citizen of the Year" Award at the 1994 Australia Day celebrations. "Humphrey B. Bear" has viewers all over the world thanks to the United States version of his show shown on PBS in America and the Spanish version shown on Galavision.
Each episode of Humphrey is designed to entertain and educate its audience as they join in the fun with the character of Humphrey B. Bear. Humphrey enjoys exploring and pretending. He likes playing, singing, dancing and being with his friends.
The writers of "Humphrey" including Anthony O'Donohue (also long time and favourite host of the show) attempt to set up each show as a new adventure for Humphrey that parallels the needs, fears and fun of the average four-year-old child. The character of Humphrey Bear explores life as they do, trying to reinforce their self-esteem and showing them it's all right to make mistakes (after all everyone does). The series attempts to show that it is not always necessary to be the best at everything, but that it's more important to simply take part.
On 14 February 2007 it was reported that the Nine Network would record a new "Here's Humphrey" series for the first time since 2003.
In April 2009, Banksia Productions, the company that owned the rights to the character, was wound up by the Supreme Court over a $50,000 debt.
In February 2012, Imagination Ventures, the philanthropic enterprise of media company Imagination Entertainment, purchased the assets of Banksia Productions and the rights to the character from the administrator.
In May 2012 Humphrey was announced as the official 'Ambassabear' for the Women & Children's Hospital Foundation and he was introduced to a new generation of children. His first major fundraising effort saw the release of a limited edition gift set featuring a Humphrey plush doll & DVD with all proceeds supporting the hospitals Kids FUNd program. Since then, Humphrey has reappeared across Australia featuring in live shows including school performances, community events and birthday parties.
In July 2013 Humphrey returned to national TV screens on Community Television stations in Sydney, Melbourne, Brisbane, Adelaide & Perth.
Humphrey B Bear celebrates his 50th Anniversary in 2015.

</doc>
<doc id="56577" url="http://en.wikipedia.org/wiki?curid=56577" title="The Absentee">
The Absentee

The Absentee is a novel by Maria Edgeworth, published in 1812 in "Tales of Fashionable Life", that expresses the systemic evils of the absentee landlord class of Anglo-Irish and the desperate condition of the Irish peasantry. 
Just before coming of age, Lord Colambre, the sensitive hero of the novel, finds that his mother Lady Clonbrony's attempts to buy her way into the high society of London are only ridiculed, while his father, Lord Clonbrony, is in serious debt as a result of his wife's lifestyle. His mother wishes him to marry an heiress, Miss Broadhurst, who is a friend of Grace Nugent. However, Colambre has already fallen in love with his cousin, Grace Nugent, who lives with the family as a companion to Lady Clonbrony. Worried that his mother will pressure him into a marriage with someone he does not love, Colambre decides to leave the London social scene and visit his ancestral home in Ireland.
Upon arriving in Dublin, Colambre becomes good friends with Sir James Brooke, who is a good influence on Colambre and warns him against the schemes of some new arrivals on the Dublin social scene: Lady Dashfort and her widowed daughter, Lady Isobel. It is generally known that Lady Dashfort is looking to ensnare a new, rich Irish peer for her equally unscrupulous daughter, and by any means necessary. Despite a pointed warning from Sir James, Colambre falls under the influence of the persuasive Lady Dashfort, who wishes to secure him as the next husband for Lady Isobel. Chance intelligence from a former maid in the Clonbrony household reveals to Lady Dashfort that Lord Colambre is, in fact, in love with his cousin, Grace Nugent. To discourage the match, Lady Dashfort slyly lets slip that Grace was born out of wedlock, and is therefore illegitimate. This is confirmed by letter by his mother, who while a social climber and generally frivolous, is very loving to Grace and has never told her about her parentage. Colambre is heart broken and feels he can never love a woman with such a heritage. 
He visits his family estate and discovers that his father's agents are oppressing the local peasantry and probably cheating his father as well. He reveals himself to the evil agents, and there is a race back to London, Colambre trying to stop his father from signing documents that would ruin some of the good peasants, the agent's agent trying to get the papers signed.
Colambre makes it back just in time to stop his father from ruining the people, and he then assists his father in paying off his debts, on condition that the Clonbrony family return to live in Ireland. 
The final section concerns Colambre's love for Grace and how it is discovered that she is both legitimate and an heiress. 
There are many turns of plot and lots of information about Ireland as well as Irish dialect and details of shallow London fashionable life, and the egregious results of the propertied classes treating their Irish lands as a resource to be exploited rather than as a relationship among classes and with the land.

</doc>
