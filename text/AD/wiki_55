<doc id="52447" url="http://en.wikipedia.org/wiki?curid=52447" title="European colonization of the Americas">
European colonization of the Americas

European colonization of the Americas began as early as the 10th century, when Norse sailors explored and settled limited areas on the shores of present-day Greenland and Canada. According to Norse folklore, violent conflicts with the indigenous population ultimately made the Norse abandon those settlements.
Extensive European colonization began in 1492, when a Spanish expedition headed by Genoese Christopher Columbus sailed west to find a new trade route to the Far East but inadvertently found the Americas. European conquest, large-scale exploration, colonization and industrial development soon followed. Columbus's first two voyages (1492–93) reached the Bahamas and various Caribbean islands, including Hispaniola, Puerto Rico and Cuba. In 1497, sailing from Bristol on behalf of England, John Cabot landed on the North American coast, and a year later, Columbus's third voyage reached the South American coast. As the sponsor of Christopher Columbus's voyages, Spain was the first European power to settle and colonize the largest areas, from North America and the Caribbean to the southern tip of South America. Spanish cities were founded as early as 1496 with Santo Domingo in today's Dominican Republic.
Other powers such as France also founded colonies in the Americas: in eastern North America, a number of Caribbean islands, and small coastal parts of South America. Portugal colonized Brazil, tried early (since 1499) colonizing of the coasts of present-day Canada, and sat for extended periods on the northwest bank of the River Plate (including in the Brazilian region). This was the beginning of territorial expansion for several European countries. Europe had been preoccupied with internal wars, and was slowly recovering from the loss of population caused by the bubonic plague; thus the rapid rate at which it grew in wealth and power was unforeseeable in the early 1400s.
Eventually, the entire Western Hemisphere came under the ostensible control of European governments, leading to profound changes to its landscape, population, and plant and animal life. In the 19th century alone over 50 million people left Europe for the Americas. The post-1492 era is known as the period of the Columbian Exchange, a dramatically widespread exchange of animals, plants, culture, human populations (including slaves), communicable disease, and ideas between the American and Afro-Eurasian hemispheres following Columbus's voyages to the Americas.
Early conquests, claims, and colonies.
Early explorations and conquests were made by the Spanish and the Portuguese immediately following their own final reconquest of Iberia in 1492. In the 1494 Treaty of Tordesillas, ratified by the Pope, these two kingdoms divided the entire non-European world into two areas of exploration and colonization, with a north to south boundary that cut through the Atlantic Ocean and the eastern part of present-day Brazil. Based on this treaty and on early claims by Spanish explorer Vasco Núñez de Balboa, discoverer of the Pacific Ocean in 1513, the Spanish conquered large territories in North, Central and South America.
Spanish conquistador Hernán Cortés took over the Aztec Kingdom and Francisco Pizarro conquered the Inca Empire. As a result, by the mid-16th century, the Spanish Crown had gained control of much of western South America, Central America and southern North America, in addition to its earlier Caribbean territories. Over this same timeframe, Portugal claimed lands in North America (Canada) and colonized much of eastern South America, naming it Santa Cruz and Brazil.
Other European nations soon disputed the terms of the Treaty of Tordesillas. England and France attempted to plant colonies in the Americas in the 16th century, but these failed. England and France succeeded in establishing permanent colonies in the following century, along with the Dutch Republic. Some of these were on Caribbean islands, which had often already been conquered by the Spanish or depopulated by disease, while others were in eastern North America, which had not been colonized by Spain north of Florida.
Early European possessions in North America included Spanish Florida, Spanish New Mexico, the English colonies of Virginia (with its North Atlantic off-shoot, Bermuda) and New England, the French colonies of Acadia and Canada, the Swedish colony of New Sweden, and the Dutch New Netherland. In the 18th century, Denmark–Norway revived its former colonies in Greenland, while the Russian Empire gained a foothold in Alaska.
As more nations gained an interest in the colonization of the Americas, competition for territory became increasingly fierce. Colonists often faced the threat of attacks from neighboring colonies, as well as from indigenous tribes and pirates.
Early state-sponsored colonists.
The first phase of well-financed European activity in the Americas began with the Atlantic Ocean crossings of Christopher Columbus (1492–1504), sponsored by Spain, whose original attempt was to find a new route to India and China, known as "the Indies". He was followed by other explorers such as John Cabot, who was sponsored by England and reached Newfoundland. Pedro Álvares Cabral reached Brazil and claimed it for Portugal.
Amerigo Vespucci, working for Portugal in voyages from 1497 to 1513, established that Columbus had reached a new set of continents. Cartographers still use a Latinized version of his first name, "America", for the two continents. Other explorers included Giovanni da Verrazzano, sponsored by France in 1524; the Portuguese João Vaz Corte-Real in Newfoundland; João Fernandes Lavrador, Gaspar and Miguel Corte-Real and João Álvares Fagundes, in Newfoundland, Greenland, Labrador, and Nova Scotia (from 1498 to 1502, and in 1520); Jacques Cartier (1491–1557), Henry Hudson (1560s-1611), and Samuel de Champlain (1567–1635), who explored Canada.
In 1513, Vasco Núñez de Balboa crossed the Isthmus of Panama and led the first European expedition to see the Pacific Ocean from the west coast of the New World. In an action with enduring historical import, Balboa claimed the Pacific Ocean and all the lands adjoining it for the Spanish Crown. It was 1517 before another expedition, from Cuba, visited Central America, landing on the coast of Yucatán in search of slaves.
These explorations were followed, notably in the case of Spain, by a phase of conquest: The Spaniards, having just finished the "Reconquista" of Spain from Muslim rule, were the first to colonize the Americas, applying the same model of governing to the former "Al-Andalus" as to their territories of the New World.
Ten years after Columbus's discovery, the administration of Hispaniola was given to Nicolás de Ovando of the Order of Alcántara, founded during the "Reconquista". As in the Iberian Peninsula, the inhabitants of Hispaniola were given new landmasters, while religious orders handled the local administration. Progressively the "encomienda" system, which granted tribute (access to indigenous labor and taxation) to European settlers, was set in place.
A relatively common misconception is that a small number of "conquistadores" conquered vast territories, aided only by disease epidemics and their powerful caballeros. In fact, recent archaeological excavations have suggested a vast Spanish-Indian alliance numbering in the hundreds of thousands. Hernán Cortés eventually conquered Mexico and the Tlaxcala in 1519-1521, while the conquest of the Inca was carried out by some 40,000 Incan renegades led by Francisco Pizarro in between 1532 and 1535.
Over the first century and a half after Columbus's voyages, the native population of the Americas plummeted by an estimated 80% (from around 50 million in 1492 to eight million in 1650), mostly by outbreaks of Old World diseases.
In 1532, Charles V, Holy Roman Emperor sent a vice-king to Mexico, Antonio de Mendoza, in order to prevent Cortes' independentist drives, who definitively returned to Spain in 1540. Two years later, Charles V signed the New Laws (which replaced the Laws of Burgos of 1512) prohibiting slavery and the "repartimientos", but also claiming as his own all the American lands and all of the indigenous people as his own subjects.
When in May 1493, the Pope Alexander VI issued the "Inter caetera" bull granting the new lands to the Kingdom of Spain, he requested in exchange an evangelization of the people. Thus, during Columbus's second voyage, Benedictine friars accompanied him, along with twelve other priests. As slavery was prohibited between Christians, and could only be imposed in non-Christian prisoners of war or on men already sold as slaves, the debate on Christianization was particularly acute during the 16th century. In 1537, the papal bull "Sublimis Deus" definitively recognized that Native Americans possessed souls, thus prohibiting their enslavement, without putting an end to the debate. Some claimed that a native who had rebelled and then been captured could be enslaved nonetheless.
Later, the Valladolid controversy opposed the Dominican priest Bartolomé de Las Casas to another Dominican philosopher Juan Ginés de Sepúlveda, the first one arguing that Native Americans were beings doted with souls, as all other human beings, while the latter argued to the contrary and justified their enslavement.
The process of Christianization was at first violent: when the first Franciscans arrived in Mexico in 1524, they burned the places dedicated to pagan cult, alienating much of the local population. In the 1530s, they began to adapt Christian practices to local customs, including the building of new churches on the sites of ancient places of worship, leading to a mix of Old World Christianity with local religions. The Spanish Roman Catholic Church, needing the natives' labor and cooperation, evangelized in Quechua, Nahuatl, Guaraní and other Native American languages, contributing to the expansion of these indigenous languages and equipping some of them with writing systems. One of the first primitive schools for Native Americans was founded by Fray Pedro de Gante in 1523.
To reward their troops, the "Conquistadores" often allotted Indian towns to their troops and officers. Black African slaves were introduced to substitute for Native American labor in some locations—including the West Indies, where the indigenous population was nearing extinction on many islands.
During this time, the Portuguese gradually switched from an initial plan of establishing trading posts to extensive colonization of what is now Brazil. They imported millions of slaves to run their plantations. The Portuguese and Spanish royal governments expected to rule these settlements and collect at least 20% of all treasure found (the "Quinto Real" collected by the "Casa de Contratación"), in addition to collecting all the taxes they could. By the late 16th century American silver accounted for one-fifth of Spain's total budget. In the 16th century perhaps 240,000 Europeans entered American ports.
The search for riches.
Inspired by the Spanish riches from colonies founded upon the conquest of the Aztecs, Incas, and other large Native American populations in the 16th century, the first Englishmen to settle permanently in America hoped for some of the same rich discoveries when they established their first permanent settlement in Jamestown, Virginia in 1607. They were sponsored by common stock companies such as the chartered Virginia Company financed by wealthy Englishmen who exaggerated the economic potential of this new land. The main purpose of this colony was the hope of finding gold.
It took strong leaders, like John Smith, to convince the colonists of Jamestown that searching for gold was not taking care of their immediate needs for food and shelter and the biblical principle that "he who will not work shall not eat" (see 2 Thessalonians 3). The extremely high mortality rate was quite distressing and cause for despair among the colonists. Tobacco later became a cash crop, with the work of John Rolfe and others, for export and the sustaining economic driver of Virginia and the neighboring colony of Maryland.
From the beginning of Virginia's settlements in 1587 until the 1680s, the main source of labor and a large portion of the immigrants were indentured servants looking for new life in the overseas colonies. During the 17th century, indentured servants constituted three-quarters of all European immigrants to the Chesapeake region. Most of the indentured servants were teenagers from England with poor economic prospects at home. Their fathers signed the papers that gave them free passage to America and an unpaid job until they became of age. They were given food, clothing, housing and taught farming or household skills. American landowners were in need of laborers and were willing to pay for a laborer’s passage to America if they served them for several years. By selling passage for five to seven years worth of work they could then start out on their own in America. Many of the migrants from England died in the first few years.
Economic advantage also prompted the Darien Scheme, an ill-fated venture by the Kingdom of Scotland to settle the Isthmus of Panama in the late 1690s. The Darien Scheme aimed to control trade through that part of the world and thereby promote Scotland into a world trading power. However, it was doomed by poor planning, short provisions, weak leadership, lack of demand for trade goods, and devastating disease. The failure of the Darien Scheme was one of the factors that led the Kingdom of Scotland into the Act of Union 1707 with the Kingdom of England creating the united Kingdom of Great Britain and giving Scotland commercial access to English, now British, colonies.
In the French colonial regions, the focus of economy was on sugar plantations in Caribbean. In Canada the fur trade with the natives was important. About 16,000 French men and women became colonizers. The great majority became subsistence farmers along the St. Lawrence River. With a favorable disease environment and plenty of land and food, their numbers grew exponentially to 65,000 by 1760. Their colony was taken over by Britain in 1760, but social, religious, legal, cultural and economic changes were few in a society that clung tightly to its recently formed traditions.
Religious immigration.
Roman Catholics were the first major religious group to immigrate to the New World, as settlers in the colonies of Portugal and Spain (and later, France) were required to belong to that faith. English and Dutch colonies, on the other hand, tended to be more religiously diverse. Settlers to these colonies included Anglicans, Dutch Calvinists, English Puritans, English Catholics, Scottish Presbyterians, French Huguenots, German and Swedish Lutherans, as well as Quakers, Mennonites, Amish, Moravians and Jews of various nationalities.
Many groups of colonists went to the Americas searching for the right to practice their religion without persecution. The Protestant Reformation of the 16th century broke the unity of Western Christendom and led to the formation of numerous new religious sects, which often faced persecution by governmental authorities. In England, many people came to question the organization of the Church of England by the end of the 16th century. One of the primary manifestations of this was the Puritan movement, which sought to "purify" the existing Church of England of its many residual Catholic rites that they believed had no mention in the Bible.
A strong believer in the notion of rule by divine right, Charles I, King of England and Scotland, persecuted religious dissenters. Waves of repression led to the migration of about 20,000 Puritans to New England between 1629 and 1642, where they founded multiple colonies. Later in the century, the new Pennsylvania colony was given to William Penn in settlement of a debt the king owed his father. Its government was set up by William Penn in about 1682 to become primarily a refuge for persecuted English Quakers; but others were welcomed. Baptists, Quakers and German and Swiss Protestants flocked to Pennsylvania. The lure of cheap land, religious freedom and the right to improve themselves with their own hand was very attractive.
Forced immigration and enslavement.
Slavery existed in the Americas, prior to the arrival of Europeans, as the Natives often captured and held other tribes' members as captives. Some of these captives were even forced to undergo human sacrifice under some tribes, such as the Aztecs. The Spanish followed with the enslavement of local aborigines in the Caribbean. As the native populations declined (mostly from European diseases, but also and significantly from forced exploitation and careless murder), they were often replaced by Africans imported through a large commercial slave trade.
By the 18th century, the overwhelming number of black slaves was such that Native American slavery was less commonly used. Africans, who were taken aboard slave ships to the Americas, were primarily obtained from their African homelands by coastal tribes who captured and sold them. The high incidence of disease nearly always fatal to Europeans kept nearly all the slave capture activities confined to native African tribes. Rum, guns and gunpowder were some of the major trade items exchanged for slaves.
The great majority went to sugar colonies in the Caribbean and to Brazil, where life expectancy was short and the numbers had to be continually replenished.
The total slave trade to islands in the Caribbean, Brazil, Mexico and to the United States is estimated to have involved 12 million Africans.
Slavery.
Slaves imported to American colonies
About 600,000 slaves were imported into the U.S., or 5% of the 12 million slaves brought across from Africa. Life expectancy was much higher in the U.S. (because of better food, less disease, lighter work loads, and better medical care) so the numbers grew rapidly by excesses of births over deaths, reaching 4 million by the 1860 Census. From 1770 until 1860, the rate of natural growth of North American slaves was much greater than for the population of any nation in Europe, and was nearly twice as rapid as that of England.
Disease and indigenous population loss.
The European lifestyle included a long history of sharing close quarters with domesticated animals such as cows, pigs, sheep, goats, horses, and various domesticated fowl, which had resulted in epidemic diseases unknown in the Americas. Thus the large-scale contact with Europeans after 1492 introduced novel germs to the indigenous people of the Americas.
Epidemics of smallpox (1518, 1521, 1525, 1558, 1589), typhus (1546), influenza (1558), diphtheria (1614) and measles (1618) swept ahead of initial European contact, killing between 10 million and 20 million people, up to 95% of the indigenous population of the Americas. The cultural and political instability attending these losses appears to have been of substantial aid in the efforts of various colonists to seize the great wealth in land and resources of which indigenous societies had customarily made use.
Such diseases yielded human mortality of an unquestionably enormous gravity and scale – and this has profoundly confused efforts to determine its full extent with any true precision. Estimates of the pre-Columbian population of the Americas vary tremendously.
Others have argued that significant variations in population size over pre-Columbian history are reason to view higher-end estimates with caution. Such estimates may reflect historical population maxima, while indigenous populations may have been at a level somewhat below these maxima or in a moment of decline in the period just prior to contact with Europeans. Indigenous populations hit their ultimate lows in most areas of the Americas in the early 20th century; in a number of cases, growth has returned.
Exhibitions and collections.
In 2007, the Smithsonian Institution National Museum of American History and the Virginia Historical Society (VHS) co-organized a traveling exhibition to recount the strategic alliances and violent conflict between European empires (English, Spanish, French) and the Native people living in North America. The exhibition was presented in three languages and with multiple perspectives. Artifacts on display included rare surviving Native and European artifacts, maps, documents, and ceremonial objects from museums and royal collections on both sides of the Atlantic. The exhibition opened in Richmond, Virginia on March 17, 2007, and closed at the Smithsonian International Gallery on October 31, 2009.
The related online exhibition explores the international origins of the societies of Canada and the United States and commemorates the 400th anniversary of three lasting settlements in Jamestown (1607), Québec (1608), and Santa Fe (1609). The site is accessible in three languages.

</doc>
<doc id="52448" url="http://en.wikipedia.org/wiki?curid=52448" title="883">
883

Year 883 (DCCCLXXXIII) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="52449" url="http://en.wikipedia.org/wiki?curid=52449" title="933">
933

Year 933 (CMXXXIII) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="52450" url="http://en.wikipedia.org/wiki?curid=52450" title="936">
936

Year 936 (CMXXXVI) was a leap year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="52451" url="http://en.wikipedia.org/wiki?curid=52451" title="Russian colonization of the Americas">
Russian colonization of the Americas

The Russian colonization of the Americas covers the period from 1732 to 1867, when the Russian Empire laid claim to northern Pacific Coast territories in the Americas. Russian colonial possessions in the Americas are collectively known as Russian America. Russian expansion eastward began in 1552, and in 1639 Russian explorers reached the Pacific Ocean. In 1725, Emperor Peter the Great ordered navigator Vitus Bering to explore the North Pacific for potential colonization. The Russians were primarily interested in the abundance of fur-bearing mammals on Alaska's coast, as stocks had been depleted by overhunting in Siberia. Bering's first voyage was foiled by thick fog and ice, but in 1741 a second voyage by Bering and Aleksei Chirikov made sight of the North American mainland.
Russian "promyshlenniki" (trappers and hunters) quickly developed the maritime fur trade, which instigated several conflicts between the Aleuts and Russians in the 1760s. The fur trade proved to be a lucrative enterprise, capturing the attention of other European nations. In response to potential competitors, the Russians extended their claims eastward from the Commander Islands to the shores of Alaska. In 1784, with encouragement from Empress Catherine the Great, explorer Grigory Shelekhov founded Russia's first permanent settlement in Alaska at Three Saints Bay. Ten years later, the first group of Orthodox Christian missionaries began to arrive, evangelizing thousands of Indians, many of whose descendents continue to maintain the religion. By the late 1780s, trade relations had opened with the Tlingits, and in 1799 the Russian-American Company (RAC) was formed in order to monopolize the fur trade, also serving as an imperialist vehicle for the Russification of Alaska Natives.
Angered by encroachment on their land and other grievances, the indigenous peoples' relations with the Russians deteriorated. In 1802, Tlingit warriors destroyed several Russian settlements, most notably Redoubt Saint Michael (Old Sitka), leaving New Russia as the only remaining outpost on mainland Alaska. This failed to expel the Russians, who reestablished their presence two years later following the Battle of Sitka. (Peace negotiations between the Russians and Indians would later establish a "modus vivendi", a situation that, with few interruptions, lasted for the duration of Russian presence in Alaska.) In 1808, Redoubt Saint Michael was rebuilt as New Archangel and became the capital of Russian America after the previous colonial headquarters were moved from Kodiak. A year later, the RAC began expanding its operations to more abundant sea otter grounds in Northern California, where Fort Ross was built in 1812.
By the middle of the 19th century, profits from Russia's American colonies were in steep decline. Competition with the British Hudson's Bay Company had brought the sea otter to near extinction, while the population of bears, wolves, and foxes on land was also nearing depletion. Faced with the reality of periodic Indian revolts, the political ramifications of the Crimean War, and unable to fully colonize the Americas to their satisfaction, the Russians concluded that their American colonies were too expensive to retain. Eager to release themselves of the burden, the Russians sold Fort Ross in 1842, and in 1867, after less than a month of negotiations, the United States accepted Emperor Alexander II's offer to sell Alaska. The purchase of Alaska for $7.2 million ended Imperial Russia's colonial presence in the Americas. Many indigenous peoples protested the sale, arguing that they were the rightful owners of the land and that Russia had no right to sell Alaska.
Exploration.
Europeans first sighted the Alaskan coastline in 1732. Captain Sterling Romanov and his wife Annan Romanov founded the first colony. It was made by the Russian maritime explorer and navigator Ivan Fedorov from sea near present day Cape Prince of Wales on the eastern boundary of the Bering Strait opposite Russian Cape Dezhnev. He did not land. The first European landfall took place in southern Alaska in 1741 during the Russian exploration by Vitus Bering and Aleksei Chirikov. Between 1774 and 1800 Spain also led several expeditions to Alaska in order to assert its claim over the Pacific Northwest. These claims were later abandoned at the turn of the 19th century. Count Nikolay Rumyantsev funded Russia's first naval circumnavigation under the joint command of Adam Johann von Krusenstern and Nikolai Rezanov in 1803–1806, and was instrumental in the outfitting of the voyage of the "Riurik's" circumnavigation of 1814–1816, which provided substantial scientific information on Alaska's and California's flora and fauna, and important ethnographic information on Alaskan and Californian (among others) natives.
Trading company.
Imperial Russia was unique among European empires for having no state sponsorship of foreign expeditions or territorial (conquest) settlement. The first state-protected trading company for sponsoring such activities in the Americas was the Shelikhov-Golikov Company of Grigory Shelikhov and Ivan Larionovich Golikov. A number of other companies were operating in Russian America during the 1780s. Shelikhov petitioned the government for exclusive control, but in 1788 Catherine II decided to grant his company a monopoly only over the area it had already occupied. Other traders were free to compete elsewhere. Catherine's decision was issued as the imperial "ukase" (proclamation) of September 28, 1788.
The Shelikhov-Golikov Company formed the basis for the Russian-American Company (RAC). Its charter was laid out in a 1799, by the new Tsar Paul I, which granted the company monopolistic control over trade in the Aleutian Islands and the North America mainland, south to 55° north latitude. The RAC was Russia's first joint stock company, and came under the direct authority of the Ministry of Commerce of Imperial Russia. Siberian merchants based in Irkutsk were initial major stockholders, but soon replaced by Russia's nobility and aristocracy based in Saint Petersburg. The company constructed settlements in what is today Alaska, Hawaii, and California.
Colonies.
The first Russian colony in Alaska was founded in 1784 by Grigory Shelikhov. Subsequently, Russian explorers and settlers continued to establish trading posts in mainland Alaska, on the Aleutian Islands, Hawaii, and Northern California.
Alaska.
The Russian-American Company was formed in 1799 with the influence of Nikolay Rezanov for the purpose of hunting sea otters for their fur. The peak population of the Russian colonies was about 4,000,000, although almost all of these were Aleuts, Tlingits and other Native Alaskans. The number of Russians rarely exceeded 500 at any one time.
California.
The Russians established their outpost of Fort Ross in 1812 near Bodega Bay in Northern California,
north of San Francisco Bay.
The Fort Ross colony included a sealing station on the Farallon Islands off San Francisco.
By 1818 Fort Ross had a population of 128, consisting of 26 Russians and of 102 Native Americans. The Russians maintained it until 1841, when they left the region. s of 2015[ [update]] Fort Ross is a Federal National Historical Landmark on the National Register of Historic Places. It is preserved—restored in California's Fort Ross State Historic Park 50 miles north of San Francisco.
Spanish concern about Russian colonial intrusion prompted the authorities in New Spain to initiate the upper Las Californias Province settlement, with presidios (forts), pueblos (towns), and the California missions. After declaring their independence in 1821 the Mexicans also asserted themselves in opposition to the Russians: the Mission San Francisco de Solano (Sonoma Mission-1823) specifically responded to the presence of the Russians at Fort Ross; and Mexico established the El Presidio Real de Sonoma or "Sonoma Barracks" in 1836, with General Mariano Guadalupe Vallejo as the 'Commandant of the Northern Frontier' of the Alta California Province. The fort was the northernmost Mexican outpost to halt any further Russian settlement southward. The restored Presidio and mission are in the present day city of Sonoma, California.
In 1920 a one-hundred pound bronze church bell was unearthed in an orange grove near Mission San Fernando Rey de España in the San Fernando Valley of Southern California. It has an inscription in the Russian language (translated here): "In the Year 1796, in the month of January, this bell was cast on the Island of Kodiak by the blessing of Juvenaly of Alaska, during the sojourn of Alexander Andreyevich Baranov." How this Russian Orthodox Kodiak church artifact from Kodiak Island in Alaska arrived at a Roman Catholic Mission Church in Southern California remains unknown.
Seward Purchase.
The Russian colonies were rarely profitable, primarily due to transportation costs for supplies. In addition, Russia was in a difficult financial position and feared losing Russian Alaska without compensation in some future conflict, especially to the British. The Russians believed that in a dispute with Britain, their hard-to-defend region might become a prime target for British aggression from British Columbia, and would be easily captured. So following the Union victory in the American Civil War, Tsar Alexander II instructed the Russian minister to the United States, Eduard de Stoeckl, to enter into negotiations with the United States Secretary of State William H. Seward in the beginning of March 1867. At the instigation of Seward the United States Senate approved the purchase, known as the Alaska Purchase, from the Russian Empire. The cost was set at 2 cents an acre, which came to a total of $7,200,000 on 9 April 1867. The canceled check is in the present day United States National Archives.
Legacy.
Russian Orthodox Church.
Saint Herman of Alaska, Saint Innocent of Alaska and Saint Peter the Aleut have contributed historically to the strong Russian Orthodox Church community in Alaska. The Orthodox Church in America, which was formerly a missionary diocese of the Russian Orthodox Church, traces its history back to the early Russian missionaries in 'Russian America'.
In present-day Russian Federation and its predecessor the Soviet Union (USSR) there are periodic mass media stories that Alaska was not sold to the United States in the 1867 Alaska Purchase, but only leased for 99 years (= to 1966), or 150 years (= to 2017)—and will be returned to Russia. However, the Alaska Purchase Treaty is absolutely clear that the agreement was for a complete Russian cession of the territory.
The Soviet Union (USSR) released a series of commemorative coins in 1990 and 1991 to commemorate the 250th anniversary of the first sighting of and claiming domain over Alaska–Russian America. The commemoration consisted of a silver coin, a platinum coin and two palladium coins in both years.
References.
</dl>
Further reading.
</dl>

</doc>
<doc id="52452" url="http://en.wikipedia.org/wiki?curid=52452" title="John Gorton">
John Gorton

Sir John Grey Gorton, GCMG, AC, CH (9 September 1911 – 19 May 2002), Australian politician, was the 19th Prime Minister of Australia. Gorton is the only Australian Senator to have become Prime Minister.
Early life.
John Grey Gorton was born in Melbourne, Victoria, the illegitimate son of Alice Sinn, the daughter of a railway worker, and English orange orchardist John Rose Gorton. The older Gorton and his wife Kathleen had emigrated to Australia by way of South Africa, where they had prospered during the Boer War. They separated in Australia, and Gorton established a de facto relationship with Sinn, who died of tuberculosis in 1920. Gorton the younger went to live with his father's estranged wife and his half-sister Ruth, in Sydney.
He was educated at Sydney Church of England Grammar School (where he was a classmate of Errol Flynn) and Geelong Grammar School, and then travelled to England to attend Brasenose College, Oxford. While in England, he undertook flying lessons and was awarded a British pilot's licence in 1932. He studied history, politics and economics at Oxford and graduated with an upper second undergraduate degree.
During a holiday in Spain while still an undergraduate, Gorton met Bettina Brown of Bangor, Maine, United States. She was a language student at the Sorbonne. This meeting came about through Gorton's friend from Oxford, Arthur Brown, who was Bettina's brother. Arthur Brown was later revealed to be a card-carrying member of the Communist Party. In 1935, Gorton and Bettina Brown were married in Oxford. After his studies were finished, they settled in Australia, taking over his father's orchard, "Mystic Park", at Lake Kangaroo near Kerang, Victoria. They had three children: Joanna, Michael and Robin.
War service.
1940–42.
On 31 May 1940, following the outbreak of World War II, Gorton enlisted in the Royal Australian Air Force Reserve. At the age of 29, Gorton was considered too old for pilot training, but he re-applied in September after this rule was relaxed. Gorton was accepted and commissioned into the RAAF on 8 November 1940. He trained as a fighter pilot at Somers, Victoria and Wagga Wagga, New South Wales, before being sent to the UK. Gorton completed his training at RAF Heston and RAF Honiley, with No. 61 Operational Training Unit RAF, flying Supermarine Spitfires. He was disappointed when his first operational posting was No. 135 Squadron RAF, a Hawker Hurricane unit, as he considered the type greatly inferior to Spitfires.
During late 1941, Gorton and other members of his squadron became part of the cadre of a Hurricane wing being formed for service in the Middle East. They were sent by sea, with 50 Hurricanes in crates, travelling around Africa to reduce the risk of attack. In December, when the ship was at Durban, South Africa, it was diverted to Singapore, after Japan entered the war. As it approached its destination in mid-January, Japanese forces were advancing down the Malayan Peninsula. The ship was attacked on at least one occasion by Japanese aircraft, but arrived and unloaded safely after tropical storms made enemy air raids impossible. As the Hurricanes were assembled, the pilots were formed into a composite operational squadron, No. 232 Squadron RAF.
In late January 1942, the squadron became operational and joined the remnants of several others that had been in Malaya, operating out of RAF Seletar and RAF Kallang. During one of his first sorties, Gorton was involved in a brief dogfight over the South China Sea, after which he suffered engine failure and was forced to land on Bintan island, 40 km (25 mi) south east of Singapore. As he landed, one of the Hurricane's wheels hit an embankment and flipped over. Gorton was not properly strapped in and his face hit the gun sight and windscreen, mutilating his nose and breaking both cheekbones. He also suffered severe lacerations to both arms. He made his way out of the wreck and was rescued by members of the Royal Dutch East Indies Army, who provided some medical treatment. Gorton later claimed that his face was so badly cut and bruised, that a member of the RAF sent to collect him assumed he was near death, collected his personal effects and returned to Singapore without him. By chance, one week later, Sgt Matt O'Mara of No. 453 Squadron RAAF also crash landed on Bintan, and arranged for them to be collected.
They arrived back in Singapore, on 11 February, three days after the island had been invaded. As the Allied air force units on Singapore had been destroyed or evacuated by this stage, Gorton was put on the "Derrymore", an ammunition ship bound for Batavia (Jakarta). On 13 February, as it neared its destination, the ship was torpedoed by Japanese submarine I-55 Kaidai class submarine and the "Derrymore" was abandoned. Gorton then spent almost a day on a crowded liferaft, in shark-infested waters, with little drinking water, until the raft was spotted by HMAS "Ballarat", which picked up the passengers and took them to Batavia.
Two schoolfriends, who had also been evacuated from Singapore to Batavia, heard that Gorton was in hospital, arranged for them to be put on a ship for Fremantle, which left on 23 February and treated Gorton's wounds. When the ship arrived in Fremantle, on 3 March, one of Gorton's arm wounds had become septic and needed extensive treatment. However, he was more concerned about the effect that the sight of his mutilated face would have on his wife. It is reported that Betty Gorton, who had been running the farm in his absence, was relieved to see Gorton alive.
1942–44.
After arriving in Australia he was posted to Darwin, Northern Territory on 12 August 1942 with No. 77 Squadron RAAF (Kittyhawks), during this time he was involved in his second air accident. While flying P-40E A29-60 on 7 September 1942, he was forced to land due to an incorrectly set fuel cock. Both Gorton and his aircraft were recovered several days later after spending time in the bush. On 21 February 1943 the squadron was relocated to Milne Bay, New Guinea.
John Gorton's final air incident came on 18 March 1943. His A29-192 Kittyhawk's engine failed on take off, causing the aircraft to flip at the end of the strip. Gorton was unhurt. In March 1944, Gorton was sent back to Australia with the rank of Flight Lieutenant. His final posting was as a Flying Instructor with No. 2 Operational Training Unit at Mildura, Victoria. He was then discharged from the RAAF on 5 December 1944.
During late 1944 Gorton went to Heidelberg hospital for surgery which could not fully repair his facial injuries.
Political career.
Although Gorton had been a member of the Country Party before the war, in 1949 he was elected to the Senate for the Liberal Party, his term commencing on 22 February 1950. From 1958 onward, he served in various positions under Robert Menzies and Harold Holt, including Minister for the Navy from 1958–63, Minister for Works, Minister for the Interior and Minister for Education as well as Leader of the Government in the Senate. Gorton was an energetic and capable minister, and began to be considered leadership material once he moderated his early extremely right-wing views.
Prime minister.
Harold Holt disappeared while swimming on 17 December 1967 and was declared presumed drowned two days later. His presumed successor was Liberal deputy leader William McMahon. However, on 18 December, the Country Party leader and Deputy Prime Minister John McEwen announced that if McMahon were named the new Liberal leader, he and his party would not serve under him. His reasons were never stated publicly, but in a private meeting with McMahon, he said "I will not serve under you because I do not trust you". McEwen's shock declaration triggered a leadership crisis within the Liberal Party; even more significantly, it raised the threat of a possible breaking of the Coalition, which would spell electoral disaster for the Liberals. The Liberals had never won enough seats in any House of Representatives election to be able to govern without Country Party support (although they would have been able to do so after the 1975 election). Indeed, since the Coalition's formation in 1923, the major non-Labor party had only been able to govern alone once, during Joseph Lyons' first ministry—and even then, Lyons' United Australia Party had come up four seats short of a majority and needed confidence and supply support from the Country Party to govern.
The Governor-General Lord Casey swore McEwen in as Prime Minister, on an interim basis pending the Liberal Party electing its new leader. McEwen agreed to accept an interim appointment provided there was no formal statement of time limit. This appointment was in keeping with previous occasions when a conservative Coalition government had been deprived of its leader. Casey also concurred in the view put to him by McEwen that to commission a Liberal temporarily as Prime Minister would give that person an unfair advantage in the forthcoming party room ballot for the permanent leader.
In the subsequent leadership struggle, Gorton was championed by Army Minister Malcolm Fraser and Liberal Party Whip Dudley Erwin, and with their support he was able to defeat his main rival, External Affairs Minister Paul Hasluck, to become Liberal leader even though he was a member of the Senate. He was elected party leader on 9 January 1968, and appointed Prime Minister on 10 January, replacing McEwen. He was the only Senator in Australia's history to be Prime Minister and the only Prime Minister to have ever served in the Senate. He remained a Senator until, in accordance with the Westminster tradition that the Prime Minister is a member of the lower house of parliament, he resigned on 1 February 1968 in order to contest the by-election for Holt's old House of Representatives seat of Higgins in south Melbourne. The by-election in this comfortably safe Liberal seat was held on 24 February; there were three other candidates, but Gorton achieved a massive 68% of the formal vote. He visited all the polling booths during the day, but was unable to vote for himself as he was still enrolled in Mallee, in rural western Victoria. Between 2 and 23 February (both dates inclusive) he was a member of neither house of parliament.
Gorton was initially a very popular Prime Minister. He carved out a style quite distinct from those of his predecessors – the aloof Menzies and the affable, sporty Holt. Gorton liked to portray himself as a man of the people who enjoyed a beer and a gamble, with a bit of a "larrikin" streak about him. Unfortunately for him, this reputation later came back to haunt him.
He also began to follow new policies, pursuing independent defence and foreign policies and distancing Australia from its traditional ties to Britain. But he continued to support Australia's involvement in the Vietnam War, a position he had reluctantly inherited from Holt, which became increasingly unpopular after 1968. On domestic issues, he favoured centralist policies at the expense of the states, which alienated powerful Liberal state leaders like Sir Henry Bolte of Victoria and Bob Askin of New South Wales. He also fostered an independent Australian film industry and increased government funding for the arts.
Gorton proved to be a surprisingly poor media performer and public speaker, and was portrayed by the media as a foolish and incompetent administrator. He was unlucky to come up against a new and formidable Labor Opposition Leader in Gough Whitlam. Also, he was subjected to media speculation about his drinking habits and his involvements with women. He generated great resentment within his party, and his opponents became increasingly critical of his reliance on an inner circle of advisers – most notably his private secretary Ainsley Gotto.
The Coalition suffered a 7% swing against it at the 1969 election, and Labor outpolled it on the two-party-preferred vote. During the close election Groton promised to waive all future government rent on residential leaseholders in Canberra. After surviving the election Groton came through on his promise, giving away an estimated $100 million in equity to leaseholders and abandoning future government rent revenue. Still, Gorton saw the sizeable 45-seat majority he'd inherited from Holt cut down to only seven. Indeed, the Coalition might have lost government had it not been for the Democratic Labor Party's longstanding practice of preferencing against Labor. The Coalition was only assured of an eighth term in government when DLP preferences tipped four marginal seats in Melbourne —the DLP's heartland—to the Liberals. Had those preferences gone the other way, Whitlam would have become Prime Minister.
Leadership challenge.
After the election, Gorton was challenged for the Liberal leadership by McMahon and David Fairbairn, but so long as McEwen's veto on McMahon remained in place, he was fairly safe. McEwen retired in January 1971, and his successor, Doug Anthony, told the Liberals that the veto no longer applied. With the Liberals falling further behind Labor in the polls, a challenge was launched in March when Defence Minister Fraser resigned. Fraser had strongly supported Gorton for the leadership two years earlier, but now attacked Gorton on the floor of Parliament in his resignation speech, saying that Gorton was "not fit to hold the great office of Prime Minister."
Gorton called a Liberal caucus meeting to settle the matter. A motion of confidence in his leadership was tied. Under Liberal caucus rules of the time, a tied vote meant the motion was lost, and hence Gorton could have remained as party leader and Prime Minister without further ado. However, he took it upon himself to resign, saying "Well, that is not a vote of confidence, so the party will have to elect a new leader." A ballot was held and McMahon was elected leader and thus Prime Minister. Australian television marked the end of Gorton's stormy premiership with a newsreel montage appropriately accompanied by Sinatra's anthem "My Way".
In a surprise move, Gorton contested and won the position of Deputy Leader, forcing McMahon to make him Defence Minister. This farcical situation ended within five months when McMahon sacked him for disloyalty.
After 1972.
After Labor won the 1972 election, Gorton served in the Shadow Ministry of Billy Snedden until after the 1974 election, when he was dropped. In 1973, Gorton moved a motion in Parliament calling for the decriminalisation of homosexual acts between consenting adults in Australia. The motion was successful following a conscience vote.
When Fraser became Liberal leader in 1975, Gorton resigned from the party, sat as an independent, and openly campaigned against Fraser, whom he detested. He denounced the dismissal of the Whitlam government by Sir John Kerr, and unsuccessfully stood for an Australian Capital Territory Senate seat at the 1975 election as an independent. He achieved 11 per cent of the vote, coming third behind the major parties.
In 1977, he became a public supporter of Don Chipp's new centre-line Australian Democrats party.
Retirement.
Gorton retired to Canberra, where he kept out of the political limelight. However, in March 1983, he congratulated Bob Hawke "for rolling that bastard Fraser" at that year's election. Bettina Gorton died aged about 67 on 2 October 1983, and in 1993 he married Nancy Home. He quietly rejoined the Liberal Party in the 1990s. John Hewson credited himself with "returning Gorton to the fold." In his old age he was rehabilitated by the Liberals; his 90th birthday party was attended by Prime Minister John Howard. However, he never forgave Fraser; as late as 2002 he told his biographer Ian Hancock that he still could not tolerate being in the same room as Fraser. He died at the age of 90 in Sydney in May 2002.
He was a freemason.
Honours.
Gorton was appointed a Privy Counsellor in 1968, a Companion of Honour in 1971, a Knight Grand Cross of the Order of St Michael and St George in 1977 and a Companion of the Order of Australia in 1988. He was awarded the Centenary Medal in 2001.
1. (GCMG) - Knight Grand Cross in The Most Distinguished Order of Saint Michael and Saint George2. (AC) - Companion in the Order of Australia3. (CH) - Companion in the Order of the Companions of Honour4. 1939–45 Star5. Pacific Star6. War Medal7. Australia Service Medal 1939-458. Centenary Medal9. Australian Defence Medal

</doc>
<doc id="52453" url="http://en.wikipedia.org/wiki?curid=52453" title="Tetum language">
Tetum language

Tetum , also Tetun, is an Austronesian language spoken on the island of Timor. It is spoken in Belu Regency in Indonesian West Timor, and across the border in East Timor, where it is one of the two official languages. In East Timor a creolized form, Tetun Dili, is widely spoken fluently as a second language; without previous contact, Tetum and Tetun Dili are not mutually intelligible. Besides the grammatical simplification involved in creolization, Tetun Dili has been greatly influenced by the vocabulary of Portuguese, the other official language of East Timor.
History and dialects.
Tetum has four dialects:
"Tetun-Belu" and "Tetun-Terik" are not spoken or well understood outside their home territories. "Tetun-Prasa" is the form of Tetum that is spoken throughout East Timor. Although Portuguese was the official language of Portuguese Timor until 1975, "Tetun-Prasa" has always been the predominant "lingua franca" in the eastern part of the island.
In the fifteenth century, before the arrival of the Portuguese, Tetum had spread through central and eastern Timor as a contact language under the aegis of the Belunese-speaking Kingdom of Wehali, at that time the most powerful kingdom in the island. The Portuguese (present in Timor from c. 1556) made most of their settlements in the west, where Dawan was spoken, and it was not until 1769, when the capital was moved from Lifau (Oecussi) to Dili that they began to promote Tetum as an inter-regional language in their colony. Timor was one of the few Portuguese colonies where a local language, and not a form of Portuguese, became the lingua franca: this is because Portuguese rule was indirect rather than direct, the Europeans governing through local kings who embraced Catholicism and became vassals of the King of Portugal.
When Indonesia occupied East Timor between 1975 and 1999, declaring it "the Republic's 27th Province", the use of Portuguese was banned, and Indonesian was declared the sole official language, but the Roman Catholic Church adopted Tetum as its liturgical language, making it a focus for cultural and national identity. When East Timor gained its independence on 20 May 2002, Tetum and Portuguese were declared as official languages.
In addition to regional varieties of Tetum in East Timor, there are variations in vocabulary and pronunciation, partly due to Portuguese and Indonesian influence. The Tetum spoken by East Timorese migrants in Portugal and Australia is more Portuguese-influenced, as many of those speakers were not educated in Indonesian.
Vocabulary.
Indigenous.
The Tetum name for East Timor is "Timór Lorosa'e", which means "Timor of the rising sun", or, less poetically, "East Timor"; "lorosa'e" comes from "loro" "sun" and "sa'e" "to rise, to go up". The noun for "word" is "liafuan", from "lia" "voice" and "fuan" "fruit". Some more words in Tetum:
From Portuguese.
Words derived from Portuguese:
From Malay.
As a result of Bazaar Malay being a regional lingua franca, many words are derived from Malay, including:
In addition, as a legacy of Indonesian rule, other words of Malay origin have entered Tetum, through Indonesian.
Numerals.
However, Tetum speakers often use Malay/Indonesian or Portuguese numbers instead, such as
"delapan" or "oito" "eight" instead of "ualu" (just like "eight" in Javanese: "wolu"), especially for numbers over one thousand.
Combinations.
Tetum has many hybrid words, which are combinations of indigenous and Portuguese words. These often include an indigenous Tetum verb, with a Portuguese suffix "-dór" (similar to '-er'). For example:
Grammar.
Morphology.
Personal pronouns.
Examples:
A common occurrence is to use titles such as" Senhora" for a woman or names rather than pronouns when addressing people.
Example:
The tetun first person singular pronoun "Ó" is used generously with children or if the speaker intends to address someone of high social status.
Example:
Nouns and pronouns.
Plural.
The plural is not normally marked on nouns, but the word "sira" "they" can express it when necessary.
However, the plural ending "-(e)s" of nouns of Portuguese origin is retained.
Definiteness.
Tetum has an indefinite article "ida" ("one"), used after nouns:
There is no definite article, but the demonstratives "ida-ne'e" ("this one") and "ida-ne'ebá" ("that one") may be used to express definiteness:
In the plural, "sira-ne'e" ("these") or "sira-ne'ebá" ("those") are used:
Possessive and genitive.
The particle "nia" forms the possessive, and can be used in a similar way to the Saxon genitive in English, e.g.:
The genitive is formed with "nian", so that:
Inclusive and exclusive "we".
Like other Austronesian languages, Tetum has two forms of "we", "ami" (equivalent to Indonesian and Malay "kami") which is exclusive, e.g. "I and they", and "ita" (equivalent to Indonesian and Malay "kita"), which is inclusive, e.g. "you, I, and they".
Nominalization.
Nouns derived from verbs or adjectives are usually formed with affixes, for example the suffix "-na'in", similar to "-er" in English.
The suffix "-na'in" can also be used with nouns, in the sense of "owner".
In more traditional forms of Tetum, the circumfix "ma(k)- -k" is used instead of "-na'in". For example, the nouns "sinner" or "wrongdoer" can be derived from the word "sala" as either "maksalak", or "sala-na'in". Only the prefix "ma(k)-" is used when the root word ends with a consonant; for example, the noun "cook" or "chef" can be derived from the word "te'in" as "makte'in" as well as "te'in-na'in".
The suffix "-teen" (from the word for "dirt" or "excrement") can be used with adjectives to form derogatory terms:
Adjectives.
Derivation from nouns.
To turn a noun into an adjective, the particle "oan" is added to it.
Thus, "Timorese" is "Timor-oan", as opposed to the country of Timor, "rai-Timor".
To form adjectives from verbs, the suffix "-dór" (derived from Portuguese) can be added:
Gender.
Tetum does not have separate masculine and feminine forms of the third person singular, hence "nia" (similar to "dia" in Indonesian and Malay) can mean either "he", "she" or "it".
Different forms for the genders only occur in Portuguese-derived adjectives, hence "obrigadu" ("thank you") is used by males, and "obrigada" by females. The masculine and feminine forms of other adjectives derived from Portuguese are sometimes used with Portuguese loanwords, particularly by Portuguese-educated speakers of Tetum.
In some instances, the different gender forms have distinct translations into English:
In indigenous Tetum words, the suffixes "-mane" ("male") and "-feto" ("female") are sometimes used to differentiate between the genders:
Comparatives and superlatives.
Superlatives can be formed from adjectives by reduplication:
When making comparisons, the word "liu" ("more") is used after the adjective, followed by "duké" ("than" from Portuguese "do que"):
To describe something as the most or least, the word "hotu" ("all") is added:
Adverbs.
Adverbs can be formed from adjectives or nouns by reduplication:
Prepositions and circumpositions.
The most commonly used prepositions in Tetum are "iha" ("in") and "ba" ("to" or "for") while circumpositions are widely used. These are formed by using "iha", the object and the position.
Verbs.
Copula and negation.
There is no verb "to be" as such, but the word "la'ós", which translates as "not to be", is used for negation:
The word "maka", which roughly translates as "who is" or "what is", can be used with an adjective for emphasis:
Interrogation.
The interrogative is formed by using the words "ka" ("or") or "ka lae" ("or not").
Derivation from nouns and adjectives.
Transitive verbs are formed by adding the prefix "ha-" or "hak-" to a noun or adjective:
Intransitive verbs are formed by adding the prefix "na-" or "nak-" to a noun or adjective:
Conjugations and inflections (in Tetun-Terik).
In "Tetun-Terik", verbs inflect when they begin with a vowel or consonant h. In this case mutation of the first consonant occurs. For example, the verb "haree" (to see) in "Tetun-Terik" would be conjugated as follows:
Tenses.
Past.
Whenever possible, the past tense is simply inferred from the context, for example:
However, it can be expressed by placing the adverb "ona" ("already") at the end of a sentence.
When "ona" is used with "la" ("not") this means "no more" or "no longer", rather than "have not":
In order to convey that an action has not occurred, the word "seidauk" ("not yet") is used:
When relating an action that occurred in the past, the word "tiha" ("finally" or "well and truly") is used with the verb.
Future.
The future tense is formed by placing the word "sei" ("will") before a verb:
The negative is formed by adding "la" ("not") between "sei" and the verb:
Aspects.
Perfect.
The perfect aspect can be formed by using "tiha ona".
When negated, "tiha ona" indicates that an action ceased to occur:
In order to convey that a past action had not or never occurred, the word "ladauk" ("not yet" or "never") is used:
Progressive.
The progressive aspect can be obtained by placing the word "hela" ("stay") after a verb:
Imperative.
The imperative mood is formed using the word "ba" ("go") at the end of a sentence, hence:
The word "lai" ("just" or "a bit") may also be used when making a request rather than a command:
When forbidding an action "labele" ("cannot") or "keta" ("do not") are used:
Orthography and phonology.
The influence of Portuguese and to a lesser extent Malay/Indonesian on the phonology of Tetun has been extensive.
In the tetun language, /a/ /i/ and /u/ tend to have relatively fixed sounds. However /e/ and /o/ vary according to the environment they are placed in, for instance the sound is slightly higher if the proceeding syllable is /u/ or /i/.
Stops: All stops in tetun are un-aspirated, meaning an expulsion of breath is absent. In contrast, English stops namely ‘p’ ‘t’ and ‘k’ are generally aspirated. 
Fricatives: 
 /v/ is an unstable voiced labio-dental fricative and tends to alternate with or is replaced by /b/; e.g. [a’vo:] – [a’bo:] meaning" grandparent.
As Tetum did not have any official recognition or support under either Portuguese or Indonesian rule, it is only recently that a standardised orthography has been established by the National Institute of Linguistics (INL). However, there are still widespread variations in spelling, one example being the word "bainhira" or "when", which has also been written as "bain-hira", "wainhira", "waihira", "uaihira". The use of "w" or "u" is a reflection of the pronunciation in some rural dialects of "Tetun-Terik".
The current orthography originates from the spelling reforms undertaken by Fretilin in 1974, when it launched literacy campaigns across East Timor, and also from the system used by the Catholic Church when it adopted Tetum as its liturgical language during the Indonesian occupation. These involved the transcription of many Portuguese words that were formerly written in their original spelling, for example, "educação" → "edukasaun" "education", and "colonialismo" → "kolonializmu" "colonialism".
More recent reforms by the INL include the replacement of the digraphs "nh" and "lh" (borrowed from Portuguese, where they stand for the phonemes /ɲ/ and /ʎ/) by "ñ" and "ll", respectively (as in Spanish), to avoid confusion with the consonant clusters /nh/ and /lh/, which also occur in Tetum. Thus, "senhor" "sir" became "señór", and "trabalhador" "worker" became "traballadór". Some linguists favoured using "ny" (as in Catalan and Filipino) and "ly" for these sounds, but the latter spellings were rejected for being similar to the Indonesian system. However, most speakers actually pronounce "ñ" and "ll" as [i̯n] and [i̯l], respectively, with a semivowel [i̯] which forms a diphthong with the preceding vowel (but reduced to [n], [l] after /i/), not as the palatal consonants of Portuguese and Spanish. Thus, "señór", "traballadór" are pronounced [sei̯ˈnoɾ], [tɾabai̯laˈdoɾ], and "liña", "kartilla" are pronounced [ˈlina], [kaɾˈtila]. As a result, some writers use "in" and "il" instead, for example "Juinu" and "Juilu" for June and July ("Junho" and "Julho" in Portuguese).
As well as variations in the transliteration of Portuguese loanwords, there are also variations in the spelling of indigenous words. These include the use of double vowels and the apostrophe for the glottal stop, for example "boot" → "bot" "large" and "ki'ik" → "kiik" "small".
The sound [z], which is not indigenous to Tetum but appears in many loanwords from Portuguese and Malay, often changed to [s] in old Tetum and to [ʒ] (written "j") in the speech of young speakers: for example, "meja" "table" from Portuguese "mesa", and "kamija" "shirt" from Portuguese "camisa". In the sociolect of Tetum that is still used by the generation educated during the Indonesian occupation, [z] and [ʒ] may occur in free variation. For instance, the Portuguese-derived word "ezemplu" "example" is pronounced [eˈʒemplu] by some speakers, and conversely "Janeiru" "January" is pronounced [zanˈeiru]. The sound [v], also not native to the language, often shifted to [b], as in "serbisu" "work" from Portuguese "serviço" (also note that a modern INL convention promotes the use of "serbisu" for "work" and "servisu" for "service").
Name.
The English spelling "Tetum" is derived from Portuguese, rather than from modern Tetum orthography. Consequently, some people regard "Tetun" as more appropriate. Although this coincides with the favoured Indonesian spelling, and the spelling with "m" has a longer history in English, "Tetun" has also been used by some Portuguese-educated Timorese, such as José Ramos-Horta and Carlos Filipe Ximenes Belo.
Similar disagreements over nomenclature have emerged regarding the names of other languages, such as Swahili/Kiswahili and Punjabi/Panjabi.
External links.
Institute of Technology website

</doc>
<doc id="52454" url="http://en.wikipedia.org/wiki?curid=52454" title="945">
945

Year 945 (CMXLV) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="52455" url="http://en.wikipedia.org/wiki?curid=52455" title="448">
448

Year 448 (CDXLVIII) was a leap year starting on Thursday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Praetextatus and Zeno (or, less frequently, year 1201 "Ab urbe condita"). The denomination 448 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years. 
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="52456" url="http://en.wikipedia.org/wiki?curid=52456" title="Dwarf (Germanic mythology)">
Dwarf (Germanic mythology)

In Germanic mythology, a dwarf is a being that dwells in mountains and in the earth, and is variously associated with wisdom, smithing, mining, and crafting. Dwarfs are often also described as short and ugly, although some scholars have questioned whether this is a later development stemming from comical portrayals of the beings.
Etymology and usage.
The modern English noun "dwarf" descends from the Old English "dweorg". It has a variety of cognates in other Germanic languages, including Old Norse "dvergr" and Old High German "twerg". According to Vladimir Orel, the English noun and its cognates ultimately descend from Proto-Germanic *"đwerȝaz".
Beyond the Proto-Germanic reconstruction, the etymology of the word "dwarf" is highly contested. By way of historical linguistics and comparative mythology, scholars have proposed theories about the origins of the being, including that dwarfs may have originated as nature spirits, as beings associated with death, or as a mixture of concepts. Competing etymologies include a basis in the Indo-European root "*dheur-" (meaning 'damage'), the Indo-European root "*dhreugh" (whence, for example, modern English "dream" and German "Trug" 'deception'), and comparisons have been made with Sanskrit "dhvaras" (a type of "demonic being").
Modern English has two plurals for the word "dwarf"; "dwarfs" and "dwarves". "Dwarfs" remains the most commonly employed plural. While recorded as early as 1818, the minority plural "dwarves" was popularized by the fiction of philologist and author J. R. R. Tolkien, originating as a mistake (hypercorrection) and employed by Tolkien since some time before 1917 (for Tolkien's beings, see Dwarf (Middle-earth)). Regarding the plural, Tolkien wrote in 1937 that "I am afraid it is just a piece of private bad grammar, rather shocking in a philologist; but I shall have to go with it".
Norse mythology and folklore.
Norse mythology, as recorded in the "Poetic Edda" (compiled in the 13th century from earlier traditional sources) and the "Prose Edda" (written by Snorri Sturluson in the 13th century) provide different mythical origins for the beings. The "Poetic Edda" poem "Völuspá" details that the dwarfs were the product of the primordial blood of the being Brimir and the bones of Bláinn (generally considered to be different names for the primordial being Ymir). The "Prose Edda", however, describes dwarfs as beings similar to maggots that festered in the flesh of Ymir before being gifted with reason by the gods. The "Poetic Edda" and "Prose Edda" contain over 100 dwarf names, while the "Prose Edda" gives the four dwarfs Norðri, Suðri, Austri and Vestri (Old Norse 'North, South, East, and West') a cosmological role – they hold up the sky. In addition, scholars have noted that the Svartálfar (Old Norse 'black elves') appear to be the same beings as dwarfs, given that both are described in the "Prose Edda" as the denizens of Svartálfaheimr.
Very few beings explicitly identifiable as dwarfs appear in the "Poetic Edda" and "Prose Edda" and have quite diverse roles: murderous creators who create the mead of poetry, 'reluctant donors' of important artifacts with magical qualities, or sexual predators who lust after goddesses. They are primarily associated with metalsmithing, and also with death; as in the story of King Sveigðir in "Ynglinga saga", the first segment of the "Heimskringla", the doorways in the mountains that they guard may be regarded as doors between worlds. One dwarf, Alvíss, claimed the hand of the god Thor's daughter Þrúðr in marriage, but when kept talking until daybreak, turned to stone much like some accounts of trolls.
After the Christianization of the Germanic peoples, tales of dwarfs continued to be told in the folklore of areas of Europe where Germanic languages were (and are) spoken. In the late legendary sagas, they demonstrate skill in healing as well as in smithing. Whereas in the early Norse sources there is no mention of their being short, in the legendary sagas they are "small and usually ugly". Anatoly Liberman suggests that dwarfs may have originally been thought of as lesser supernatural beings, which after Christianization became literal smallness. Whereas Old Norse dwarf-names include "Fullangr" ('tall enough') and "Hár" ('high'), Anglo-Saxon glosses use "dweorg" to render Latin terms such as "nanus" and "pygmaeus" ('pygmy').
Dwarfs in folklore are usually described as old men with long beards. Female dwarfs are hardly ever mentioned. The dwarf Dvalinn has daughters and a 14th-century romantic saga, "Þjalar Jóns saga", gives a feminine form, Old Norse "dyrgja", but the few folklore examples cited by Grimm in "Teutonic Mythology" may be identified as other beings. However, in one Swedish ballad, "Herr Peder och Dvärgens Dotter" (Swedish 'Sir Peder and the Dwarf's Daughter'), the role of supernatural temptress is played by a dwarf's daughter.
Anglo-Saxon medicine.
The Anglo-Saxon charm "Wið Dweorh", "Against a Dwarf", appears to relate to sleep disturbances. This may indicate that the dwarf antagonist is similar to the oppressive supernatural figure, the "mare", that is the etymological source of the word "nightmare", or possibly that the word had come to be used to mean "fever". In the Old English "Herbal", it translates Latin "verrucas"; warts.
Scholarly interpretations.
Lotte Motz theorized that the Germanic dwarfs, particularly as smiths and gatekeepers, constituted a reminiscence of the Megalithic culture in Northern Europe.
John Lindow noted that stanza 10 of the "Poetic Edda" poem "Völuspá" can be read as describing the creation of human forms from the earth and follows a catalog of dwarf names; he suggests that the poem may present Ask and Embla as having been created by dwarfs, with the three gods then giving them life.
In popular culture.
In the Brothers Grimm's fairy tale "Snow White", there were seven dwarfs. The Walt Disney Company's 1937 film based on the story, the first feature-length animated film, is the best known adaptation today. 
In the "Prose Edda", the dwarfs are equated with the svartálfar and dökkálfar ("dark elves"); in J. R. R. Tolkien's "The Lord of the Rings", the dwarves (Tolkien's spelling) and the Elves of Darkness or Moriquendi are distinct.
Most modern fantasy media, beginning with TSR's "Dungeons and Dragons", have continued this distinction; "Dungeons and Dragons" calls the dwarfs "dwarves" and the dark elves drow, which according to Gary Gygax derives from the Scottish being, the trow.
Games including "Warhammer", "", and the "Warcraft" franchise feature dwarfs, again largely patterned after Tolkien's.
The dwarfs in Terry Pratchett's "Discworld" universe are also derived from Tolkien's. 
The ASCII game Dwarf Fortress involves building an underground home for dwarfs.
In Terry Brooks' Shannara Series dwarves are an offshoot race created after the Great Wars. The Dwarves, who live in the Eastland, were one of the races that evolved from Humans. During the time of the Great Wars, the Humans who would later become Dwarves hid underground to avoid the devastation above the ground.
In Eoin Colfer's Artemis Fowl novels, dwarves tunnel through dirt by ingesting and then expelling it through the rear end, similar to earthworms. Mulch Diggums is a kleptomaniac dwarf who helps Artemis on many occasions.
References.
</dl>

</doc>
<doc id="52457" url="http://en.wikipedia.org/wiki?curid=52457" title="934">
934

Year 934 (CMXXXIV) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="52458" url="http://en.wikipedia.org/wiki?curid=52458" title="937">
937

Year 937 (CMXXXVII) was a common year starting on Sunday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="52459" url="http://en.wikipedia.org/wiki?curid=52459" title="Counter-Earth">
Counter-Earth

The Counter-Earth is a hypothesized by the pre-Socratic philosopher Philolaus (c. 470 – c. 385 BCE) to support his non-geocentric cosmology, in which all objects in the universe revolve around an unseen "Central Fire" (distinct from the Sun which also revolves around it). The Greek word Antichthon (Greek: Ἀντίχθων) means "Counter-Earth."
In modern times a hypothetical planet always on the other side of the Sun from the Earth has been called a "Counter-Earth", and has been a recurring theme in fiction, science fiction and UFO claims.
Greek Pythagorean universe.
In the 5th century BC an astronomical system positing that the Earth, Moon, Sun and planets revolve around an unseen "Central Fire" was developed, attributed to the Pythagorean philosopher Philolaus. Philolaus' universe had the Sun revolving around the Central Fire, and included a nonexistent "Counter-Earth" in his system, moving "the earth from the center of the cosmos", and provided the insight that "the apparent motion of the heavenly bodies" was (in large part) due to "the real motion of the observer"—i.e. Earth.
In Philolaus's system, the Earth did not rotate and its inhabited surface faced away from the Central Fire—possibly because it was flat. The revolution of the Earth around the Central Fire was not yearly but daily, while the Moon's revolution was monthly, and the sun's yearly. It was the Earth's speedy travel past the slower moving Sun that resulted in the appearance on Earth of the Sun rising and setting. Further from the Central Fire, the Planets' movement was slower still, and the outermost "sky" (i.e. stars) probably fixed.
Counter-Earth.
Along with the Central Fire, the "mysterious" Counter-Earth ("Antichthon") was the other heavenly body not visible from Earth. We know that Aristotle described it as "another Earth", from which Greek scholar George Burch infers that it must be similar in size, shape and constitution to Earth. Some (astronomer John Louis Emil Dreyer) think Philolaus had it following an orbit so that it was always located between Earth and Central Fire, and a tale of Greek mythology may have placed it in that location to stop man from looking at the throne of Zeus directly. However, Burch argues Philolaus must have thought it orbited on the other side of the Fire from Earth. Since "counter" means "opposite", and opposite can only be in respect to the Central Fire, it follows that the Counter-Earth must be orbiting 180 degrees from Earth.
According to Aristotle — a critic of the Pythagoreans — the function of the Counter-Earth was to explain "eclipses of the moon and their frequency", which could not be explained by Earth blocking the light of the sun if the Earth did not revolve around the sun. Aristotle suggests that it was also introduced "to raise the number of heavenly bodies around the central fire from nine to ten, which the Pythagoreans regarded as the perfect number" 
However Burch believes Aristotle was having a joke "at the expense of Pythagorean number theory", and that the true purpose of the Counter-Earth was to "balance" Philolaus's cosmos—balance being needed because without a counter there would be only one dense, massive object in the system—Earth. Although his system had both the Earth and the Planets orbiting a single point, the ancient Greeks did not consider Earth a "Planet". In the time before Galileo could observe from his telescope that Planets were spheres like Earth, they were thought to be different from stars only in brightness and in their motion, and like stars composed of a fiery or ethereal matter having little or no density. However, the Earth was obviously made of the dense elements of earth and water. According to Burch,
"If there was a single Earth revolving at some distance from the center of space, then the universe's center of gravity, located in the Earth as its only dense body, would not coincide with its spatial center ... The universe, consequently, would be off center, so to speak—lopsided and asymmetric—a notion repugnant to any Greek, and doubly so to a Pythagorean." This could be corrected by another body with the same mass as Earth, orbiting the same central point but 180 degrees from Earth—the Counter-Earth.
Later.
In the 1st century A.D., after the idea of a spherical Earth gained more general acceptance, Pomponius Mela, a Latin cosmographer, developed an updated version of the idea, wherein a spherical Earth must have a more or less balanced distribution of land and water. Mela drew the first map on which the mysterious continent of Earth appears in the unknown half of Earth—our antipodes. This continent he inscribed with the name Antichthones.
Modern era.
The idea of a Counter-Earth did not have significant currency at least since the introduction of the heliocentric model in the 16th century. Nevertheless, as late as 1968, the "Scientific Study of Unidentified Flying Objects" headed by Edward Condon at the University of Colorado included a "Numerical Experiment on the Possible Existence of an 'Anti-Earth'" as an appendix. A Counter-Earth would have gravitational influence (perturbation) upon the other planets, comets and man-made probes of the Solar System. No such influence has been detected, and indeed space probes sent to Venus, Mars and other places could not have successfully flown by or landed on their targets if a Counter-Earth existed, as it was not accounted for in navigational calculation. Roughly speaking, anything larger than 100 mi in diameter should have been detected. 
The gravitational forces of the other planets on a Counter-Earth would make "its" orbit unstable. Venus has 82% of the mass of Earth and would come within 0.3 Astronomical unit of the location of a Counter Earth every 20 months, providing considerable gravitational pull that over the years would move its orbit into sight of observers on Earth. If a Counter-Earth was much smaller than Earth, its location at the "Sun–Earth L3" Lagrangian point (see diagram), would mean the combined gravitational pull of the two large masses of Earth and Sun would provide "precisely the centripetal force required to orbit with them". But a small planet would be even more influenced by the orbit of Venus, Mars and Jupiter, making it even more unstable.
Any planetary sized body 180 degrees from Earth should also have been visible to some space probes, such as NASA's STEREO coronagraph probes (two spacecraft launched into orbits around the Sun in 2006, one farther ahead of and one behind the Earth's orbit) which would have seen the Counter-Earth during the first half of 2007. The separation of the STEREO spacecraft from Earth would give them a view of the L3 point during the early phase of the mission.
For a Counter-Earth orbiting the same path as Earth to always stay 180 degrees from Earth, the two planets would have to have circular orbits, but Earth's orbit is elliptical. Following Kepler's second law, a planet revolves faster when it is close to the star, so a Counter-Earth following the Earth on the same orbit with half a year of delay would sometimes not be exactly 180 degrees from Earth. To be hidden from Earth, the Counter-Earth would have an orbit symmetrical to Earth's, not sharing the second focus or orbit path.
References in culture.
The idea of a Counter-Earth has been a recurring motif in science fiction, fiction—often serving as an allegory for the real Earth—and UFO claims.

</doc>
<doc id="52460" url="http://en.wikipedia.org/wiki?curid=52460" title="French colonization of the Americas">
French colonization of the Americas

The French colonization of the Americas began in the 16th century, and continued on into the following centuries as France established a colonial empire in the Western Hemisphere. France founded colonies in much of eastern North America, on a number of Caribbean islands, and in South America. Most colonies were developed to export products such as fish, sugar, and furs.
As they colonized the New World, the French established forts and settlements that would become such cities as Quebec and Montreal in Canada; Detroit, Green Bay, St. Louis, Cape Girardeau, Mobile, Biloxi, Baton Rouge and New Orleans in the United States; and Port-au-Prince, Cap-Haïtien (founded as "Cap-Français") in Haiti, Cayenne in French Guiana and São Luís (founded as "Saint-Louis de Maragnan") in Brazil.
North America.
Background.
The French first came to the New World as explorers, seeking a route to the Pacific Ocean and wealth. Major French exploration of North America began under the rule of Francis I, King of France. In 1524, Francis sent Italian-born Giovanni da Verrazzano to explore the region between Florida and Newfoundland for a route to the Pacific Ocean. Verrazzano gave the names "Francesca" and "Nova Gallia" to that land between New Spain and English Newfoundland, thus promoting French interests.
Colonization.
In 1534, Francis I of France sent Jacques Cartier on the first of three voyages to explore the coast of Newfoundland and the St. Lawrence River. He founded New France by planting a cross on the shore of the Gaspé Peninsula. The French subsequently tried to establish several colonies throughout North America that failed, due to weather, disease, or conflict with other European powers. Cartier attempted to create the first permanent European settlement in North America at Cap-Rouge (Quebec City) in 1541 with 400 settlers but the settlement was abandoned the next year after bad weather and first nations attacks. A small group of French troops were left on Parris Island, South Carolina in 1562 to build Charlesfort, but left after a year when they were not resupplied by France. Fort Caroline established in present-day Jacksonville, Florida in 1564, lasted only a year before being destroyed by the Spanish from St. Augustine. An attempt to settle convicts on Sable Island off Nova Scotia in 1598 failed after a short time. In 1599, a sixteen-person trading post was established in Tadoussac (in present-day Quebec), of which only five men survived the first winter. In 1604, Saint Croix Island in Acadia was the site of a short-lived French colony, much plagued by illness, perhaps scurvy. The following year the settlement was moved to Port Royal. Samuel de Champlain founded Quebec (1608) and explored the Great Lakes. In 1634, Jean Nicolet founded "La Baye des Puants" (present-day Green Bay), which is one of the oldest permanent European settlements in America. In 1634, Sieur de Laviolette founded Trois-Rivières. In 1642, Paul de Chomedey, Sieur de Maisonneuve, founded Ville-Marie which is now known as Montreal. Louis Jolliet and Jacques Marquette founded Sault Sainte Marie (1668) and Saint Ignace (1671) and explored the Mississippi River. At the end of the 17th century, René-Robert Cavelier, Sieur de La Salle established a network of forts going from the Gulf of Mexico to the Great Lakes and the Saint Lawrence River. Fort Saint Louis was established in Texas in 1685, but was gone by 1688. Antoine de la Mothe Cadillac founded "Fort Pontchartrain du Détroit" (modern-day Detroit) in 1701 and Jean-Baptiste Le Moyne, Sieur de Bienville founded "La Nouvelle Orléans" (New Orleans) in 1718. Pierre Le Moyne d'Iberville founded Baton Rouge in 1719.
The French were eager to explore North America but New France remained largely unpopulated. Due to the lack of women, intermarriages between French and Indians were frequent, giving rise to the Métis people. Relations between the French and Indians were usually peaceful. As the 19th-century historian Francis Parkman stated:
"Spanish civilization crushed the Indian; English civilization scorned and neglected him; French civilization embraced and cherished him"—Francis Parkman.
To boost the French population, Cardinal Richelieu issued an act declaring that Indians converted to Catholicism were considered as "natural Frenchmen" by the Ordonnance of 1627:
"The descendants of the French who are accustomed to this country [New France], together with all the Indians who will be brought to the knowledge of the faith and will profess it, shall be deemed and renowned natural Frenchmen, and as such may come to live in France when they want, and acquire, donate, and succeed and accept donations and legacies, just as true French subjects, without being required to take no letters of declaration of naturalization."
Louis XIV also tried to increased the population by sending approximately 800 young women nicknamed the "King's Daughters". However, the low density of population in New France remained a very persistent problem. At the beginning of the French and Indian War (1754–1763), the British population in North America outnumbered the French 20 to 1. France fought a total of six colonial wars in North America (see the four French and Indian Wars as well as Father Rale's War and Father Le Loutre's War).
Canada and Acadia.
The French interest in Canada focuses first on the fishing off the Grand Banks of Newfoundland. However, at the beginning of XVIIth century, France was more interested in fur from North America. The fur trading post of Tadoussac was founded in 1600. Four years later, Champlain made his first trip to Canada in a trade mission for fur. Although he had no formal mandate on this trip, he sketched a map of the St. Lawrence River and in writing, on his return to France, a report entitled "Savages" (Relation of his stay in a tribe of Montagnais near Tadoussac).
Champlain needed to report his findings to Henry IV. He participated in another expedition to New France in the spring of 1604, conducted by Pierre Du Gua de Monts. It helped the foundation a settlement on Saint Croix Island, the first French settlement in the New World, which will be given up the following winter. The expedition then founded the colony of Port-Royal.
In 1608, Champlain founded a fur post that will become the city of Quebec, which will become the capital of New France. In Quebec, Champlain forged alliances between France and the Huron and Ottawa against their traditional enemies, the Iroquois. Champlain and other French travelers then continued to explore North America, with the canoe made from the bark of Birch, to move quickly through the Great Lakes and their tributaries. In 1634, the Normand explorer Jean Nicolet pushed his exploration to the West up to the state of Wisconsin.
Following the capitulation of Quebec by the Kirke brothers, the British occupied the city of Quebec and that of Canada from 1629 to 1632. Samuel de Champlain was taken prisoner and there followed the bankruptcy of Company of One Hundred Associates. Following the Treaty of Saint-Germain-en-Laye, France took possession of the colony in 1632. The city of Trois-Rivières was founded in 1634. In 1642, the Angevin Jérôme le Royer de la Dauversière founded Ville-Marie (later Montreal) which was at that time, a fort as protection against Iroquois attacks (the first great Iroquois war lasted from 1642 to 1667).
Despite this rapid expansion, the colony developed very slowly. The Iroquois wars and diseases were the leading causes of death in the French colony. In 1663 when Louis XIV provided the "Royal Government", the population of New France was only 2500 European inhabitants. That year, to increase the population, Louis XIV sent between 800 and 900 'King's Daughters' to become the wives of French settlers. The population of New France reached subsequently 7000 in 1674 and 15000 in 1689.
From 1689 to 1713, the French settlers were faced with almost incessant war during the French and Indian Wars. From 1689 to 1697, they fought the British in the Nine Years' War. The war against the Iroquois continued even after the Treaty of Rijswijk until 1701, when the two parties agreed on peace. Then, the war against the English took over in the War of the Spanish Succession. In 1690 and 1711, Quebec City had successfully resisted the attacks of the English navy and then British army. Nevertheless, the British took advantage of the second war. With the signing of the Treaty of Utrecht in 1713, France ceded to Britain Acadia (with a population of 1700 people), Newfoundland and Hudson Bay.
Under the Sovereign Council, the population of the colony grew faster. However, the population rate was far from being equivalent to what was happening in the British Thirteen Colonies to the south. In the middle of the XVIII century, New France accounted for 60,000 people while the British colonies had more than one million people. This placed the colony at a great military disadvantage against the British. The war between the colonies resumed in 1744, lasting until 1748. A final and decisive war began in 1754. The Canadiens and the French were helped by numerous alliances with Native Americans, but they were usually outnumbered on the battlefield.
French Florida.
In 1562, Charles IX, under the leadership of Admiral Gaspard de Coligny sends Jean Ribault and a group of Huguenot settlers in an attempt to colonize the Atlantic coast and found a colony on a territory which will take the name of the French Florida. They discover the probe and Port Royal Island, which will be called by Parris Island in South Carolina, on which he built a fort named
Charlesfort. The group, led by René Goulaine de Laudonnière, moved to the south where they founded the Fort Caroline on the Saint John's river in Florida on June 22 1564. This irritated the Spanish who claimed Florida and oppose the Protestant settlers for religious reasons. In 1565, Pedro Menéndez de Avilés led a group of Spaniards and founded Saint Augustine, 60 kilometers south of Fort Caroline. Fearing a Spanish attack, Ribault planned to move the colony but a storm suddenly destroyed his fleet. On 20 September 1565 the Spaniards, commanded by Menéndez de Avilés, attacked and massacre all the Carolina occupants including Jean Ribaut.
Louisiana.
On May 17, 1673, explorers Louis Jolliet and Jacques Marquette began exploring the Mississippi River, known to the Sioux as "does Tongo," or to the Miami-Illinois as " missisipioui" ("the great river"). They reached the mouth of the Arkansas and then up the river, after learning that it flowed into the Gulf of Mexico and not to the California Sea (Pacific Ocean).
In 1682, the Normand Cavelier de la Salle and the Italian Henri de Tonti came down the Mississippi to its Delta. They left from Fort Crevecoeur on the Illinois River, along with 23 French and 18 Native Americans. In April 1682, they arrived at the mouth of the Mississippi; they planted a cross and a column bearing the arms of the king of France. Going back through the same route to Canada, La Salle returned to Versailles. There he wins over the Minister of the Navy to give him the command of Louisiana. He does believe that it is close to the New Spain by drawing a map on which the Mississippi seemed much further west than its actual rate. He set up a maritime expedition with four ships and 320 emigrants, but it ended in disaster when he failed to find the Mississippi Delta and was killed in 1687.
Dissolution.
The last French and Indian War resulted in the dissolution of New France, with Canada going to Great Britain and Louisiana going to Spain. Only the islands of Saint-Pierre-et-Miquelon have remained in French hands until today.
In 1802 Spain returned Louisiana to France, but Napoleon sold it to the United States in 1803. The French left many toponyms (Illinois, Vermont, Bayous...) and ethnonyms (Sioux, Coeur d'Alene, Nez Percé...) in North America.
West Indies.
A major French settlement lay on the island of Hispaniola, where France established the colony of Saint-Domingue on the western third of the island in 1664. Nicknamed the "Pearl of the Antilles", Saint-Domingue became the richest colony in the Caribbean due to slave plantation production of sugar cane. It had the highest slave mortality rate in the western hemisphere. A 1791 slave revolt, the only ever successful slave revolt, began the Haitian Revolution, led to freedom for the colony's slaves in 1794 and, a decade later, complete independence for the country, which renamed itself Haiti. France briefly also ruled the eastern portion of the island, which is now the Dominican Republic.
During the 17th and 18th centuries, France ruled much of the Lesser Antilles at various times. Islands that came under French rule during part or all of this time include Dominica, Grenada, Guadeloupe, Marie-Galante, Martinique, St. Barthélemy, St. Croix, St. Kitts, St. Lucia, St. Martin, St. Vincent and Tobago. Control of many of these islands was contested between the French, the British and the Dutch; in the case of St. Martin, the island was divided in two, a situation that persists to this day. Great Britain captured some of France's islands during the Seven Years' War and the Napoleonic Wars. Following the latter conflict, France retained control of Guadeloupe, Martinique, Marie-Galante, St. Barthélemy, and its portion of St. Martin; all remain part of France today. Guadeloupe (including Marie-Galante and other nearby islands) and Martinique each is an overseas department of France, while St. Barthélemy and St. Martin each became an overseas collectivity of France in 2007.
South America.
From 1555 to 1567, French Huguenots, under the leadership of vice-admiral Nicolas Durand de Villegaignon, made an attempt to establish the colony of France Antarctique in what is now Brazil, but were expelled. From 1612 to 1615, a second failed attempt ("France Équinoxiale") was made in present-day São Luís, Brazil.
French Guiana was first settled by the French in 1604, although its earliest settlements were abandoned in the face of hostilities from the indigenous population and tropical diseases. The settlement of Cayenne was established in 1643, but was abandoned. It was re-established in the 1660s. Except for brief occupations by the English and Dutch in the 17th century, and by the Portuguese in the 19th century, Guiana has remained under French rule ever since. From 1851 to 1951 it was the site of a notorious penal colony, Devil's Island ("Île du Diable"). Since 1946, French Guiana has been an overseas department of France.
In 1860, a French adventurer, Orelie-Antoine de Tounens proclaimed himself king of Araucania and Patagonia. His claim was not accepted by foreign powers and Chile and Argentina took firm control over the regions, treating him as insane.

</doc>
<doc id="52461" url="http://en.wikipedia.org/wiki?curid=52461" title="938">
938

Year 938 (CMXXXVIII) was a common year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="52462" url="http://en.wikipedia.org/wiki?curid=52462" title="Observational learning">
Observational learning

Observational learning is learning that occurs through observing the behavior of others. Albert Bandura, who is known for the classic Bobo doll experiment, identified this basic form of learning in 1961. The importance of observational learning because it may help, especially children, acquire new responses by observing others' behavior.
This form of learning does not need reinforcement to occur, but instead, requires a model. A social model can be a parent, sibling, friend, or teacher, but—particularly in childhood—a model is someone of authority or higher status. A social model is significantly important in observational learning because it facilitates cognitive process behavior. It helps the learner encode what they observe and store it in memory for later imitation.
While the model may not intentionally try to instill a particular behavior, many behaviors the learner observes, remembers, and imitates are actions that models display. A child may learn to swear, smack, smoke, and deem other inappropriate behavior acceptable through poor modeling. Bandura claims that children continually learn desirable and undesirable behavior through observational learning. Observational learning suggests that an individual's environment, cognition, and behavior all integrate and ultimately determine how the individual functions.
Through observational learning, individual behaviors can spread across a culture through a process called "diffusion chain" This basically occurs when an individual first learns a behavior by observing another individual and that individual serves as a model through whom other individuals learn the behavior, and so on.
Culture plays a role in whether observational learning is the dominant learning style in a person or community. Some cultures expect children to actively participate in their communities and are therefore exposed to different trades and roles on a daily basis. This exposure allows children to observe and learn the different skills and practices that are valued in their communities.
Albert Bandura states that people’s behavior could be determined by their environment. Observational learning occurs through observing negative and positive behaviors. Bandura believes in reciprocal determinism in which the environment can influence in people’s behavior and vice versa. For instance, the Bobo doll experiment shows that model in a determined environment impact children’s behavior. In this experiment Bandura demonstrates that one group of children placed in an aggressive environment would act the same way. While, the control group and the other group of children placed in a passive role model environment hardly shows any type of aggressions.
In communities where children's primary mode of learning is through observation, the children are rarely separated from adult activities. This incorporation into the adult world at an early age allows children to use observational learning skills in multiple spheres of life. This learning through observation requires keen attentive abilities. Culturally, they learn that their participation and contributions are valued in their communities. This teaches children that it is their duty, as members of the community, to observe others' contributions so they gradually become involved and participate further in the community.
Stages.
Bandura's social cognitive learning theory states that there are four stages involved in observational learning:
Bandura clearly distinguishes between learning and performance. Unless motivated, a person does not produce learned behavior. This motivation can come from external reinforcement, such as the experimenter's promise of reward in some of Bandura's studies, or the bribe of a parent. Or it can come to vicarious reinforcement, based on the observation that models are rewarded. High-status models can affect performance through motivation. For example, girls aged 11 to 14 performed better on a motor performance task when they thought it was demonstrated by a high-status cheerleader than by a low-status model.
Some have even added a step of encoding a behavior between attention and retention.
Observational learning leads to a change in an individual's behavior along three dimensions:
Effect on behavior.
According to Bandura's social cognitive learning theory, observational learning can affect behavior in many ways, with both positive and negative consequences. It can teach completely new behaviors, for one. It can also increase or decrease the frequency of behaviors that have previously been learned. Observational learning can even encourage behaviors that were previously forbidden (for example, the violent behavior towards the Bobo doll that children imitated in Albert Bandura's study). Observational learning can also have an impact on behaviors that are similar to, but not identical to, the ones being modeled. For example, seeing a model excel at playing the piano may motivate an observer to play the saxophone.
Age difference.
Albert Bandura stressed that developing children learn from different social models, meaning that no two children are exposed to exactly the same modeling influence. From infancy to adolescence, they are exposed to various social models. A 2013 study found that a toddlers' previous social familiarity with a model was not always necessary for learning and that they were also able to learn from observing a stranger demonstrating or modeling a new action to another stranger.
It was once believed that babies could not imitate actions until the latter half of the first year. However a number of studies now report that infants as young as seven days can imitate simple facial expressions. By the latter half of their first year, 9-month-old babies can imitate actions hours after they first see them. As they continue to develop, toddlers around age two can acquire important personal and social skills by imitating a social model.
Deferred imitation is an important developmental milestone in a two-year-old, in which children not only construct symbolic representations, but can also remember information. Unlike toddlers, children of elementary school age are less likely to rely on imagination to represent an experience. Instead, they can verbally describe the model's behavior. Since this form of learning does not need reinforcement, it is more likely to occur regularly.
As age increases, age-related observational learning motor skills may decreases in athletes and golfers. Younger and skilled golfers have higher observational learning compared to older golfers and less skilled golfers.
Observational causal learning.
Humans use observational causal learning to watch what other people’s actions and use that information to find out how something works and how we can do it ourselves.
A study of 25-month-old infants found that they can learn causal relations from observing human interventions. They also learn by observing normal actions not created by intentional human action.
Comparisons with imitation.
Observational learning is presumed to have occurred when an organism copies an improbable action or action outcome that it has observed and the matching behavior cannot be explained by an alternative mechanism. Psychologists have been particularly interested in the form of observational learning known as imitation and in how to distinguish imitation from other processes. To successfully make this distinction, one must separate the degree to which behavioral similarity results from (a) predisposed behavior, (b) increased motivation resulting from the presence of another animal, (c) attention drawn to a place or object, (d) learning about the way the environment works, as distinguished from what we think of as (e) imitation (the copying of the demonstrated behavior) .
Observational learning differs from imitative learning in that it does not require a duplication of the behavior exhibited by the model. For example, the learner may observe an unwanted behavior and the subsequent consequences, and thus learn to refrain from that behavior. For example, Riopelle, A.J. (1960) found that monkeys did better with observational learning if they saw the "tutor" monkey make a mistake before making the right choice. Heyes (1993) distinguished imitation and non-imitative social learning in the following way: imitation occurs when animals learn about behavior from observing conspecifics, whereas non-imitative social learning occurs when animals learn about the environment from observing others.
Not all imitation and learning through observing is the same, and they often differ in the degree to which they take on an active or passive form. John Dewey describes an important distinction between two different forms of imitation: imitation as an end in itself and imitation with a purpose. Imitation as an end is more akin to mimicry, in which a person copies another’s act to repeat that action again. This kind of imitation is often observed in animals. Imitation with a purpose utilizes the imitative act as a means to accomplish something more significant. Whereas the more passive form of imitation as an end has been documented in some European American communities, the other kind of more active, purposeful imitation has been documented in other communities around the world.
Observation may take on a more active form in children’s learning in multiple Indigenous American communities. Ethnographic anthropological studies in Yucatec Mayan and Quechua Peruvian communities provide evidence that the home or community-centered economic systems of these cultures allow children to witness first-hand, activities that are meaningful to their own livelihoods and the overall well-being of the community. These children have the opportunity to observe activities that are relevant within the context of that community, which gives them a reason to sharpen their attention to the practical knowledge they are exposed to. This does not mean that they have to observe the activities even though they are present. The children often make an active decision to stay in attendance while a community activity is taking place to observe and learn. This decision underscores the significance of this learning style in many indigenous American communities. It goes far beyond learning mundane tasks through rote imitation; it is central to children’s gradual transformation into informed members of their communities’ unique practices. There was also a study, done with children, that concluded that Imitated behavior can be recalled and used in another situation or the same.
Apprenticeship.
Apprenticeship can involve both observational learning and modelling. Apprentices gain their skills in part through working with masters in their profession and through observing and evaluating the work of their fellow apprentices.Examples include renaissance inventor/painter Leonardo da Vinci and Michelangelo, before succeeding in their profession they were apprentices.
Learning without imitation.
Michael Tomasello described various ways of observational learning without the process of imitation in animals (ethology):
Exposure- Individuals learn about their environment with a close proximity to other individuals that have more experience. For example, a young dolphin learning the location of a plethora of fish by staying near its mother.
Peer model influences.
Observational learning is very beneficial when there are positive, reinforcing peer models involved. Although individuals go through four different stages for observational learning: attention; retention; production; and motivation, this does not simply mean that when an individual's attention is captured that it automatically sets the process in that exact order. One of the most important ongoing stages for observational learning, especially among children, is motivation and positive reinforcement.
Performance is enhanced when children are positively instructed on how they can improve a situation and where children actively participate alongside a more skilled person. Examples of this are scaffolding and guided participation. Scaffolding refers to an expert responding contingently to a novice so the novice gradually increases their understanding of a problem. Guided participation refers to an expert actively engaging in a situation with a novice so the novice participates with or observes the adult to understand how to resolve a problem.
Cultural variation.
Cultural variation can be seen in the extent of information learned or absorbed by children through the use of observation and more specifically the use of observation without verbal requests for further information. For example, children from Mexican heritage families tend to learn and make better use of information observed during classroom demonstration then children of European heritage. Children of European heritage experience the type of learning that separates them from their family and community activities. They instead participate in lessons and other exercises in special settings such as school. Cultural backgrounds differ from each other in which children display certain characteristics in regards to learning an activity. Another example is seen in the immersion, of children in some Indigenous communities of the Americas, into the adult world and the effects it has on observational learning and the ability to complete multiple tasks simultaneously. This might be due to children in these communities having the opportunity to see a task being completed by their elders or peers and then trying to emulate the task. In doing so they learn to value observation and the skill-building it affords them because of the value it holds within their community. This type of observation is not passive, but reflects the child's intent to participate or learn within a community.
Observational learning can be seen taking place in many domains of Indigenous communities. The classroom setting is one significant example, and it functions differently for these communities in comparison to what is commonly present in Western schooling. The emphasis of keen observation in favor of supporting participation in ongoing activities strives to aid children to learn the important tools and ways of their community). Engaging in shared endeavors - with both the experienced and inexperienced - allows for the experienced to understand what the inexperienced need in order to grow in regards to the assessment of observational learning. The involvement of the inexperienced, or the children in this matter, can either be furthered by the children’s learning or advancing into the activity performed by the assessment of observational learning. For the Indigenous communities to rely on observational learning is a way allowing for their children to be a part of ongoing activities in the community (Tharp, 2006).
Although learning in the IAC is not always the central focus when participating in an activity studies have shown that attention in intentional observation differs from accidental observation. Intentional participation is “keen observation and listening in anticipation of, or in the process of engaging in endeavors”. This means that when they have the intention of participating in an event, their attention is more focused on the details, compared to when they are accidentally observing.
Observational learning can be an active process in many Indigenous American communities. The learner must take initiative to attend to activities going on around them. Children in these communities also take initiative to contribute their knowledge in ways that will benefit their community. For example, in many Indigenous American cultures, children perform household chores without being instructed to do so by adults. Instead, they observe a need for their contributions and take initiative to accomplish the tasks based on
observations of others having done them. The learner's intrinsic motivations play an important role in the child's understanding and construction of meaning in these educational experiences. The independence and responsibility associated with observational learning in many Indigenous American communities are significant reasons why this method of learning can involve more than just watching and imitating. A learner must be actively engaged with their demonstrations and experiences in order to fully comprehend and apply the knowledge they obtain.
Indigenous communities of the Americas.
Children from indigenous heritage communities of the Americas often learn through observation, a strategy that can carry over into adulthood. The heightened value towards observation allows children to multi-task and actively engage in simultaneous activities. The exposure to an uncensored adult lifestyle allows children to observe and learn the skills and practices that are valued in their communities. Children observe elders, parents, and siblings complete tasks and learn to participate in them. They are seen as contributors and learn to observe multiple tasks being completed at once and can learn to complete a task, while still engaging with other community members without being distracted.
Indigenous communities provide more opportunities to incorporate children in everyday life. This can be seen in some Mayan communities where children are given full access to community events, which allows observational learning to occur more often. Other children in Mazahua, Mexico are known to intensely observe ongoing activities. In native northern Canadian and indigenous Mayan communities children often learn as third-party observers from stories and conversations by others. Most young Mayan children are carried on their mother's back, allowing them to observe their mother's work and see the world as their mother sees it. Children are often allowed to learn without restrictions and with minimal guidance. They are self-motivated to learn and finish their chores. These children act as a second set of eyes and ears for their parents updating them about the community.
Children aged 6 to 8 in an indigenous heritage community in Guadalajara, Mexico participated in hard work, such as cooking or running errands, to benefit the whole family, while those in the city of Guadalajara rarely did so. These children participated more in adult regulated activities and had little time to play, while those from the indigenous-heritage community had more time to play and initiate in their own after-school activities.
Within certain indigenous communities people do not typically seek out explanation beyond basic observation. This is because they are competent in learning through astute observation. In a Guatemalan footloom factory amateur adult weavers observed skilled weavers over the course of weeks without questioning or being given explanations; the amateur weaver moved at their own pace and began when they felt confident. The framework of learning how to weave through observation can serve as a model that groups within a society use as a reference to guide their actions in particular domains of life. Communities that participate in observational learning promote tolerance and mutual understand of those coming from different cultural backgrounds.
Other human and animal behavior experiments.
When an animal is given a task to complete, they are almost always more successful after observing another animal doing the same task before them. Experiments have been conducted on several different species with the same effect: animals can learn behaviors from peers. However, there is a need to distinguish the propagation of behavior and the stability of behavior. Research has shown that social learning can spread a behavior, but there are more factors regarding how a behavior carries across generations of an animal culture.
Learning in fish.
Experiments with ninespine sticklebacks showed that individuals will use social learning to locate food.
Social learning in pigeons.
A study in 1996 at the University of Kentucky used a foraging device to test social learning in pigeons. A pigeon could access the food reward by either pecking at a treadle or stepping on it. Significant correspondence was found between the methods of how the observers accessed their food and the methods the initial model used in accessing the food.
Acquiring foraging niches.
Studies have been conducted at the University of Oslo and University of Saskatchewan regarding the possibility of social learning in birds, delineating the difference between cultural and genetic acquisition. Strong evidence already exists for mate choice, bird song, predator recognition, and foraging.
Researchers cross-fostered eggs between nests of blue tits and great tits and observed the resulting behavior through audio-visual recording. Tits raised in the foster family learned their foster family's foraging sites early. This shift—from the sites the tits would among their own kind and the sites they learned from the foster parents—lasted for life. What young birds learn from foster parents, they eventually transmitted to their own offspring. This suggests cultural transmissions of foraging behavior over generations in the wild.
Social learning in crows.
The University of Washington studied this phenomenon with crows, acknowledging the evolutionary tradeoff between acquiring costly information firsthand and learning that information socially with less cost to the individual but at the risk of inaccuracy. The experimenters exposed wild crows to a unique “dangerous face” mask as they trapped, banded, and released 7-15 birds at five different study places around Seattle, WA. An immediate scolding response to the mask after trapping by previously captured crows illustrates that the individual crow learned the danger of that mask. There was a scolding from crows that were captured that had not been captured initially. That response indicates conditioning from the mob of birds that assembled during the capture.
Horizontal social learning (learning from peers) is consistent with the lone crows that recognized the dangerous face without ever being captured. Children of captured crow parents were conditioned to scold the dangerous mask, which demonstrates vertical social learning (learning from parents). The crows that were captured directly had the most precise discrimination between dangerous and neutral masks than the crows that learned from the experience of their peers. The ability of crows to learn doubled the frequency of scolding, which spread at least 1.2 km from where the experiment started to over a 5 year period at one site.
Propagation of animal culture.
Researchers at the Département d’Etudes Cognitives, Institut Jean Nicod, Ecole Normale Supérieure acknowledged a difficulty with research in social learning. To count acquired behavior as cultural, two conditions need must be met: the behavior must spread in a social group, and that behavior must be stable across generations. Research has provided evidence that imitation may play a role in the propagation of a behavior, but these researchers believe the fidelity of this evidence is not sufficient to prove stability of animal culture.
Other factors like ecological availability, reward-based factors, content-based factors, and source-based factors might explain the stability of animal culture in a wild rather than just imitation. As an example of ecological availability, chimps may learn how to fish for ants with a stick from their peers, but that behavior is also influenced by the particular type of ants as well as the condition. A behavior may be learned socially, but the fact that it was learned socially does not necessarily mean it will last. The fact that the behavior is rewarding has a role in cultural stability as well. The ability for socially-learned behaviors to stabilize across generations is also mitigated by the complexity of the behavior. Different individuals of a species, like crows, vary in their ability to use a complex tool. Finally, a behavior’s stability in animal culture depends on the context in which they learn a behavior. If a behavior has already been adopted by a majority, then the behavior is more likely to carry across generations out of a need for conforming.
Animals are able to acquire behaviors from social learning, but whether or not that behavior carries across generations requires more investigation.
Hummingbird experiment.
Experiments with hummingbirds provided one example of apparent observational learning in a non-human organism. Hummingbirds were divided into two groups. Birds in one group were exposed to the feeding of a knowledgeable "tutor" bird; hummingbirds in the other group did not have this exposure. In subsequent tests the birds that had seen a tutor were more efficient feeders than the others.
Bottlenose dolphin.
Herman (2002) suggested that bottlenose dolphins produce goal-emulated behaviors rather than imitative ones. A dolphin that watches a model place a ball in a basket might place the ball in the basket when asked to mimic the behavior, but it may do so in a different manner seen.
Rhesus monkey.
Kinnaman (1902) reported that one rhesus monkey learned to pull a plug from a box with its teeth to obtain food after watching another monkey succeed at this task.
Fredman (2012) also performed an experiment on observational behavior. In experiment 1, human-raised monkeys observed a familiar human model open a foraging box using a tool in one of two alternate ways: levering or poking. In experiment 2, mother-raised monkeys viewed similar techniques demonstrated by monkey models. A control group in each population saw no model. In both experiments, independent coders detected which technique experimental subjects had seen, thus confirming social learning. Further analyses examined copying at three levels of resolution.
The human-raised monkeys exhibited the greatest learning with the specific tool use technique they saw. Only monkeys who saw the levering model used the lever technique, by contrast with controls and those who witnessed poking. Mother-reared monkeys instead typically ignored the tool and exhibited fidelity at a lower level, tending only to re-create whichever result the model had achieved by either levering or poking.
Nevertheless, this level of social learning was associated with significantly greater levels of success in monkeys witnessing a model than in controls, an effect absent in the human-reared population. Results in both populations are consistent with a process of canalization of the repertoire in the direction of the approach witnessed, producing a narrower, socially shaped behavioral profile than among controls who saw no model.
Light box experiment.
Pinkham and Jaswal (2011) did an experiment to see if a child would learn how to turn on a light box by watching a parent. They found that children who saw a parent use their head to turn on the light box tended to do the task in that manner, but children who had not seen the parent chose a more efficient way, using their hands.
Swimming skill performance.
When adequate practice and appropriate feedback follow demonstrations, increased skill performance and learning occurs. Lewis (1974) did a study of children who had a fear of swimming and observed how modelling and going over swimming practices affected their overall performance. The experiment spanned nine days, and included many steps. The children were first assessed on their anxiety and swimming skills. Then they were placed into one of three conditional groups and exposed to these conditions over a few days.
At the end of each day, all children participated in a group lesson. The first group was a control group where the children watched a short cartoon video unrelated to swimming. The second group was a peer mastery group, which watched a short video of similar-aged children who had very good task performances and high confidence. Lastly, the third group was a peer coping group, whose subjects watched a video of similar-aged children who progressed from low task performances and low confidence statements to high task performances and high confidence statements.
The day following the exposures to each condition, the children were reassessed. Finally, the children were also assessed a few days later for a follow up assessment. Upon reassessment, it was shown that the two model groups who watched videos of children similar in age had successful rates on the skills assessed because they perceived the models as informational and motivational.
Neuroscience.
Recent research in neuroscience has implicated mirror neurons as a neurophysiological basis for observational learning. These specialized visuomotor neurons fire action potentials when an individual performs a motor task and also fire when an individual passively observes another individual performing the same motor task. In observational motor learning, the process begins with a visual presentation of another individual performing a motor task, this acts as a model. The learner then needs to transform the observed visual information into internal motor commands that will allow them to perform the motor task, this is known as visuomotor transformation. Mirror neuron networks provide a mechanism for visuo-motor and motor-visual transformation and interaction. Similar networks of mirror neurons have also been implicated in social learning, motor cognition and social cognition.

</doc>
<doc id="52463" url="http://en.wikipedia.org/wiki?curid=52463" title="942">
942

Year 942 (CMXLII) was a common year starting on Saturday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="52464" url="http://en.wikipedia.org/wiki?curid=52464" title="445">
445

Year 445 (CDXLV) was a common year starting on Monday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Valentinianus and Nomus (or, less frequently, year 1198 "Ab urbe condita"). The denomination 445 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="52465" url="http://en.wikipedia.org/wiki?curid=52465" title="444">
444

Year 444 (CDXLIV) was a leap year starting on Saturday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Theodosius and Aginatius (or, less frequently, year 1197 "Ab urbe condita"). The denomination 444 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="52467" url="http://en.wikipedia.org/wiki?curid=52467" title="446">
446

Year 446 (CDXLVI) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Aetius and Symmachus (or, less frequently, year 1199 "Ab urbe condita"). The denomination 446 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="52468" url="http://en.wikipedia.org/wiki?curid=52468" title="442">
442

Year 442 (CDXLII) was a common year starting on Thursday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Dioscorus and Eudoxius (or, less frequently, year 1195 "Ab urbe condita"). The denomination 442 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="52469" url="http://en.wikipedia.org/wiki?curid=52469" title="Stephen Wolfram">
Stephen Wolfram

Stephen Wolfram (born 29 August 1959) is a British computer scientist, entrepreneur and former physicist known for his contributions to theoretical physics; his pioneering work on knowledge-based programming; as the CEO of Wolfram Research and chief designer of Mathematica and the Wolfram Alpha answer engine; and as the author of the book "A New Kind of Science".
Background.
Wolfram's parents were Jewish refugees who emigrated from Germany to England in the 1930s. Wolfram's father Hugo was a textile manufacturer and novelist ("Into a Neutral Country") and his mother Sybil was a professor of philosophy at the University of Oxford. He has a younger brother, Conrad Wolfram. Wolfram is married to a mathematician and has four children.
Education.
Wolfram was educated at Eton College, but left prematurely in 1976. He entered St John's College, Oxford at age 17 but found lectures "awful", and left in 1978 without graduating. He received a PhD in particle physics from the California Institute of Technology at age 20. Wolfram's thesis committee included Richard Feynman, Peter Goldreich and Steven Frautschi while the thesis research was supervised by Geoffrey C. Fox and Hugh David Politzer.
Career.
Following his PhD, Wolfram joined the faculty at Caltech and received one of the first MacArthur Fellowships in 1981, at age 21.
Wolfram presented a talk at the TED conference in 2010, and he was named Speaker of the Event for his 2012 talk at SXSW. In 2012 he became a fellow of the American Mathematical Society.
Research.
According to Google Scholar, Stephen Wolfram is cited by over 30,000 publications (up to April 2012) and has an h-index of 58. He has an Erdős number of 2.
Unpublished works.
At the age of 12, he wrote a dictionary on physics, and soon by ages 13 and 14 he wrote three books on particle physics. They were not published.
Particle physics.
By the time he was 15 he began to research in applied quantum field theory and particle physics and publish his first scientific papers. Topics included matter creation and annihilation, the fundamental interactions, elementary particles and their currents, hadronic and leptonic physics, and the parton model, published in professional peer-reviewed scientific journals including "Nuclear Physics B", "Australian Journal of Physics", "Nuovo Cimento", and "Physical Review D". Working independently, Wolfram published a widely cited paper on heavy quark production at age 18 and nine other papers, and continued to research and publish on particle physics into his early twenties. Wolfram's work with Geoffrey C. Fox on the theory of the strong interaction is still used today in experimental particle physics.
Symbolic Manipulation Program.
Wolfram led the development of the computer algebra system SMP ("Symbolic Manipulation Program") in the Caltech physics department during 1979–1981. A dispute with the administration over the intellectual property rights regarding SMP—patents, copyright, and faculty involvement in commercial ventures—eventually caused him to resign from Caltech. SMP was further developed and marketed commercially by Inference Corp. of Los Angeles during 1983–1988.
Complex systems and cellular automata.
In 1983, Wolfram left for the School of Natural Sciences of the Institute for Advanced Study in Princeton, where he conducted research into cellular automata, mainly with computer simulations. He produced a series of papers systematically investigating the class of elementary cellular automata, conceiving the Wolfram code, a naming system for one-dimensional cellular automata, and a classification scheme for the complexity of their behaviour. He conjectured that the Rule 110 cellular automaton might be Turing complete. In the middle 1980s Wolfram worked on simulations of physical processes (such as turbulent fluid flow) with cellular automata on the Connection Machine alongside Richard Feynman and helped ignite the field of complex systems founding the first institute devoted to this subject, The Center for Complex Systems Research (CCSR) at the University of Illinois at Urbana–Champaign and the journal "Complex Systems" in 1987.
Mathematica.
In 1986 Wolfram left the Institute for Advanced Study for the University of Illinois at Urbana–Champaign where he founded their Center for Complex Systems Research and started to develop the computer algebra system Mathematica, which was first released in 1988, when he left academia. In 1987 he co-founded a company called Wolfram Research which continues to develop and market the program.
"A New Kind of Science".
From 1992 to 2002, he worked on his controversial book "A New Kind of Science", which presents an empirical study of very simple computational systems. Additionally, it argues that for fundamental reasons these types of systems, rather than traditional mathematics, are needed to model and understand complexity in nature. Wolfram's conclusion is that the universe is digital in its nature, and runs on fundamental laws which can be described as simple programs. He predicts that a realisation of this within the scientific communities will have a major and revolutionary influence on physics, chemistry and biology and the majority of the scientific areas in general, which is the reason for the book's title.
Since the release of the book in 2002, Wolfram has split his time between developing Mathematica and encouraging people to get involved with the subject matter of "A New Kind of Science" by giving talks, holding conferences, and starting a summer school devoted to the topic.
Computational knowledge engine.
In March 2009, Wolfram announced Wolfram|Alpha, an answer engine with a new approach to knowledge extraction and an easy-to-use interface, launched in May 2009 and a Pro version launched on February 2012. The engine is based on natural language processing and a large library of algorithms, and answers queries using the approach described in "A New Kind of Science". The application programming interface (API) allows other applications to extend and enhance Alpha. Wolfram|Alpha is one of the answer engines behind Microsoft's Bing and Apple's Siri (along with Google and Yelp!) answering factual questions.
Wolfram Language.
In June 2014, Wolfram officially announced the Wolfram Language as a new general multi-paradigm programming language. The documentation for the language was pre-released in October 2013 to coincide with the bundling of Mathematica and the Wolfram Language on every Raspberry Pi computer. While the Wolfram Language has existed for over 25 years as the primary programming language used in Mathematica, it was not officially named until 2014.

</doc>
<doc id="52476" url="http://en.wikipedia.org/wiki?curid=52476" title="History of Greenland">
History of Greenland

The history of Greenland is a history of life under extreme Arctic conditions: currently, an ice cap covers about 80 percent of the island, restricting human activity largely to the coasts.
The first humans are thought to have arrived in Greenland around 2500 BC. Their descendants apparently died out and were succeeded by several other groups migrating from continental North America. There is no evidence that Greenland was known to Europeans until the 10th century, when Icelandic Vikings settled on its southwestern coast, which seems to have been uninhabited when they arrived. The ancestors of the Inuit Greenlanders who live there today appear to have migrated there later, around 1200 AD, from northwestern Greenland. While the Inuit survived in the icy world of the Little Ice Age, the early Norse settlements along the southwestern coast disappeared, leaving the Inuit as the only inhabitants of the island for several centuries. During this time, Denmark-Norway, apparently believing the Norse settlements had survived, continued to claim sovereignty over the island despite the lack of any contact between the Norse Greenlanders and their Scandinavian brethren. In 1721, aspiring to become a colonial power, Denmark-Norway sent a missionary expedition to Greenland with the stated aim of reinstating Christianity among descendants of the Norse Greenlanders who may have reverted to paganism. When the missionaries found no descendants of the Norse Greenlanders, they baptized the Inuit Greenlanders they found living there instead. Denmark-Norway then developed trading colonies along the coast and imposed a trade monopoly and other colonial privileges on the area.
During World War II, when Germany invaded Denmark, Greenlanders became socially and economically less connected to Denmark and more connected to the United States and Canada. After the war, Denmark resumed control of Greenland and in 1953, converted its status from colony to overseas "amt" (county). Although Greenland is still a part of the Kingdom of Denmark, it has enjoyed home rule since 1979. In 1985, the island became the only territory to leave the European Union, which it had joined as a part of Denmark in 1973; the Faroes had never joined.
Early Paleo-Eskimo cultures.
The prehistory of Greenland is a story of repeated waves of Paleo-Eskimo immigration from the islands north of the North American mainland. (The peoples of those islands are thought to have descended, in turn, from inhabitants of Siberia who migrated into Canada thousands of years ago.) Because of Greenland's remoteness and climate, survival there was difficult. Over the course of centuries, one culture succeeded another as groups died out and were replaced by new immigrants. Archaeology can give only approximate dates for the cultures that flourished before the Norse exploration of Greenland in the 10th century.
The earliest known cultures in Greenland are the Saqqaq culture (2500-800 BC) and the Independence I culture in northern Greenland (2400-1300 BCE). The practitioners of these two cultures are thought to have descended from separate groups that came to Greenland from northern Canada. Around 800 BCE, the so-called Independence II culture arose in the region where the Independence I culture had previously existed. it was originally thought that Independence II was succeeded by Dorset culture (700 BC - 200 AD), but some Independence II artefacts date from as recently as the 1st century BCE. Recent studies suggest that, in Greenland at least, the Dorset culture may be better understood as a continuation of Independence II culture; the two cultures have therefore been designated "Greenlandic Dorset". Artefacts associated with early Dorset culture in Greenland have been found as far north as Inglefield Land on the west coast and the Dove Bugt area on the east coast.
After the Early Dorset culture disappeared around 200 AD, the island was uninhabited for several centuries. The next immigrants to arrive from Canada, perhaps as early as 800 AD, settled the northwest part of the island, bringing with them the so-called Late Dorset culture, which survived until about 1300 AD. The Norse arrived and settled in the southern part of the island in 980 AD.
Norse settlement.
Europeans became aware of Greenland's existence, probably in the early 10th century, when Gunnbjörn Ulfsson, sailing from Norway to Iceland, was blown off course by a storm, and happened to sight some islands off Greenland. During the 980s, explorers from Iceland and Norway reached the southwest coast of Greenland, found the region uninhabited, and settled there. The settlers named the island Greenland ("Grænland" in Old Norse and modern Icelandic, "Grønland" in modern Danish and Norwegian). Tradition has it that Erik the Red coined the name—in effect as a marketing device. In both the "Book of Icelanders" ("Íslendingabók")—a medieval account of Icelandic history from the 12th century onward—and the Icelandic saga, "The Saga of Eric the Red" ("Eiríks saga rauða")—a medieval account of his life and of the Norse settlement of Greenland—it is written, ""He named the land Greenland, saying that people would be eager to go there if it had a good name"." (Although there is no particular reason to doubt this information, sagas often reflect oral traditions which may or may not be historically accurate.)
According to the sagas, Erik the Red was exiled from Iceland for a period of three years for committing a murder. He sailed to Greenland, where he explored the coastline and claimed certain regions as his own. He then returned to Iceland to persuade people to join him in establishing a settlement on Greenland. The Icelandic sagas say that 25 ships left Iceland with Erik the Red in 985 AD, and that only 14 of them arrived safely in Greenland. This date has been approximately confirmed by radiocarbon dating of some remains at the first settlement at Brattahlid (now Qassiarsuk), which yielded a date of about 1000. According to the sagas, it was also in the year 1000 that Erik's son, Leif Eirikson, left the settlement to explore the surrounding waters, and came across what he called Vinland, which is generally assumed to have been located in what is now Newfoundland.
The Norse settled in three separate locations: the larger Eastern settlement, the smaller Western settlement, and the still smaller Middle Settlement (sometimes considered part of the Eastern one). The settlements at their height are estimated to have had a population of between 2,000 and 10,000 people. More recent estimates (such as that of Professor Niels Lynnerup, in "Vikings: The North Atlantic Saga," edited by William W. Fitzhugh and Elisabeth I. Ward) have tended toward the lower figure. Ruins of approximately 620 farms have been identified: 500 in the Eastern settlement, 95 in the Western settlement, and 20 in the Middle. The settlements carried on a trade in ivory from walrus tusks with Europe, as well as exporting rope, sheep, seals and cattle hides according to one 13th-century account. They depended on Iceland and Norway for iron tools, wood (especially for boat building, although they also may have obtained some wood from coastal Labrador), supplemental foodstuffs, and religious and social contacts. Trade ships from Iceland and Norway traveled to Greenland every year and would sometimes overwinter in Greenland. Beginning in the late 13th century, all ships from Greenland were required by law to sail directly to Norway.
In 1126, a diocese was founded at Garðar (now Igaliku). It was subject to the Norwegian archdiocese of Nidaros (now Trondheim); at least five churches in Norse Greenland are known from archeological remains. In 1261, the population accepted the overlordship of the Norwegian King as well, although it continued to have its own law. In 1380 the Norwegian kingdom entered into a personal union with the Kingdom of Denmark. After initially thriving, the Norse settlements declined in the 14th century. The Western Settlement was abandoned around 1350. In 1378, there was no longer a bishop at Garðar. After 1408, when a marriage was recorded, not many written records mention the settlers. There are correspondence between the Pope and the Biskop Bertold af Garde from same year. The Danish Cartographer Claudius Clavus seems to have visited Greenland in 1420 from documents written by Nicolas Germanus and Henricus Martellus who had access to original cartographic notes and map by Clavus. Two mathematical manuscripts containing the second chart of the Claudius Clavus map from his travel to Greenland where he himself mapped the area were found during the late 20th century by the Danish scholar Bjönbo and Petersen. (Originals in Hofbibliothek at Vienna. A Greenlander in Norway, on visit; it is also mentioned in a Norwegian Diploma from 1426, [Peder Grønlendiger])
In a letter dated 1448 from Rome, the Pope Nicholas V prescribe the bishops of Skálholt and Hólar (the two Icelandic episcopal sees) to ensure to provide the inhabitants of Greenland with priests and a bishop, the latter of which they hadn't had in the 30 years since the apparent coming of the heathens when most churches were destroyed and the people taken away as prisoners.
It is probable that the Eastern Settlement was defunct by the middle of the 15th century although no exact date has been established.
Norse failure.
There are many theories as to why the Norse settlements collapsed in Greenland after surviving for some 450–500 years (AD 985 to 1450–1500). It has been suggested that some or all of five factors contributed to the demise of the Greenland colony: cumulative environmental damage, gradual climate change, conflicts with hostile neighbors, the loss of contact and support from Europe, and, perhaps most crucial, cultural conservatism and failure to adapt to an increasingly harsh natural environment. Numerous studies have tested these hypotheses and some have led to significant discoveries. On the other hand there are dissenters: In "The Frozen Echo," Kirsten Seaver contests some of the more generally accepted theories about the demise of the Greenland colony, and asserts that the colony, towards the end, was healthier than Diamond and others have thought. Seaver believes that the Greenlanders cannot have starved to death, but rather may have been wiped out by Inuit or unrecorded European attacks, or they may have abandoned the colony to return to Iceland or to seek out new homes in Vinland. However, the physical evidence from archeological studies of the ancient farm sites does not show evidence of attack. The paucity of personal belongings at these sites is typical of North Atlantic Norse sites that were abandoned in an orderly fashion, with any useful items being deliberately removed; but to others it suggests a gradual but devastating impoverishment. Midden heaps at these sites do show an increasingly impoverished diet for humans and livestock.
Greenland was always colder in winter than Iceland and Norway, and its terrain less hospitable to agriculture. Erosion of the soil was a danger from the beginning, one that the Greenland settlements may not have recognized until it was too late. For an extended time, nonetheless, the relatively warm West Greenland current flowing northwards along the southwestern coast of Greenland made it feasible for the Norse to farm much as their relatives did in Iceland or northern Norway. Palynologists' tests on pollen counts and fossilized plants prove that the Greenlanders must have struggled with soil erosion and deforestation. As the unsuitability of the land for agriculture became more and more patent, the Greenlanders resorted first to pastoralism and then to hunting for their food. But they never learned to use the hunting techniques of the Inuit, one being a farming culture, the other living on hunting in more northern areas with pack ice.
To investigate the possibility of climatic cooling, scientists drilled into the Greenland ice caps to obtain core samples. The oxygen isotopes from the ice caps suggested that the Medieval Warm Period had caused a relatively milder climate in Greenland, lasting from roughly 800 to 1200. However from 1300 or so the climate began to cool. By 1420, we know that the "Little Ice Age" had reached intense levels in Greenland. Excavations of midden or garbage heaps from the Viking farms in both Greenland and Iceland show the shift from the bones of cows and pigs to those of sheep and goats. As the winters lengthened, and the springs and summers shortened, there must have been less and less time for Greenlanders to grow hay. A study of North Atlantic seasonal temperature variability showed a significant decrease in maximum summer temperatures beginning in the late 1200s to early 1300s--as much as 6-8°C lower than modern summer temperatures. The study also found that the lowest winter temperatures of the last 2000 years occurred in the late 1300s and early 1400s. By the mid-14th century deposits from a chieftain’s farm showed a large number of cattle and caribou remains, whereas, a poorer farm only several kilometers away had no trace of domestic animal remains, only seal. Bone samples from Greenland Norse cemeteries confirm that the typical Greenlander diet had increased by this time from 20% sea animals to 80%.
Although Greenland seems to have been uninhabited at the time of initial Norse settlement, after a couple of centuries the Norse in Greenland had to deal with the Inuit. The Thule-Inuit were the successors of the Dorset who migrated south and finally came into contact with the Norse in the 12th century. There are limited sources showing the two cultures interacting; however, scholars know that the Norse referred to the Inuit (and Vinland natives) as skraeling. The "Icelandic Annals" are among the few existing sources that confirm contact between the Norse and the Inuit. They report an instance of hostility initiated by the Inuit against the Norse, leaving eighteen Greenlanders dead and two boys carried into slavery. Archaeological evidence seems to show that the Inuit traded with the Norse. On the other hand, the evidence shows many Norse artefacts at Inuit sites throughout Greenland and on the Canadian Arctic islands but very few Inuit artefacts in the Norse settlements. This may indicate either European indifference—an instance of cultural resistance to Inuit crafts among them—or perhaps hostile raiding by the Inuit. It is also quite possible that the Norse were trading for perishable items such as meat and furs and had little interest in other Inuit items, much as later Europeans who traded with Native Americans.
We know that the Norse never learned the Inuit techniques of kayak navigation or ring seal hunting. Indeed, they never learned to adjust to the cold winters as the Inuit did. Archaeological evidence plainly establishes that by 1300 or so the Inuit had successfully expanded their winter settlements as close to the Europeans as the outer fjords of the Western Settlement. Yet by 1350, the Norse, for whatever reasons, had completely deserted their Western Settlement. The Inuit, being a hunting society, may have hunted the Norse livestock, forcing the Norse into conflict or abandonment of their settlements.
In mild weather conditions, a ship could make the 900-mile (1400 kilometers) trip from Iceland to Eastern Settlement within a couple of weeks. Greenlanders had to keep in contact with Iceland and Norway in order to trade. Little is known about any distinctive shipbuilding techniques among the Greenlanders. Greenland lacks a supply of lumber, so was completely dependent on Icelandic merchants or, possibly, logging expeditions to the Canadian coast.
The sagas mention Icelanders traveling to Greenland to trade. But the settlement chieftains and large farm owners controlled this trade. The chieftains would trade with the foreign ships and then disperse the goods by trading with the surrounding farmers. The Greenlanders' main commodity was the walrus tusk, which was used primarily in Europe as a substitute for elephant ivory for art décor, whose trade had been blocked by conflict with the Islamic world. Professor Gudmundsson also suggests a very valuable narwhal tusk trade, through a smuggling route via western Iceland (where the Greenlanders came from) to the Orkney islands (where Western Icelanders came from).
Many scholars believe that the royal Norwegian monopoly on shipping contributed to the end of trade and contact. However, Christianity and European customs continued to hold sway among the Greenlanders for the greater part of the 14th and 15th centuries. In 1921, a Danish historian, Paul Norland, found human remains from the Eastern Settlement in the Herjolfsnes church courtyard. The bodies were dressed in 15th century medieval clothing with no indications of malnutrition or genetic deterioration. Most had crucifixes around their necks with their arms crossed as in a stance of prayer. Perhaps the buried were sailors having died en route or while over wintering. It is known from Roman papal records that the Greenlanders were excused from paying their tithes in 1345 because the colony was suffering from poverty. The last reported ship to reach Greenland was a private ship that was "blown off course", reaching Greenland in 1406, and departing in 1410 with the last news of Greenland: the burning at the stake of a condemned witch, the insanity and death of the woman this witch was accused of attempting to seduce through witchcraft, and the marriage of the ship's captain, Thorsteinn Ólafsson, to another Icelander, Sigridur Björnsdóttir. However, there are some suggestions of much later unreported voyages from Europe to Greenland, possibly as late as the 1480s.
The last of the five factors points to the failure of the Norse to adapt to the changing conditions of Greenland. The Norse struggled to adapt, as the excavations show plainly. Some of the Norse, perhaps most, dramatically changed their folkways. But it is not known whether they adopted the ways of the Inuit, even, it seems, when faced with extinction. Most likely no single factor brought about their extinction. What is plain is that the settlement died out once and for all.
One intriguing fact is that very few fish remains are found among their middens. This has led to much speculation and argument. Most archaeologists reject any decisive judgment based on this one fact, however, as fish bones decompose more quickly than other remains, and may have been disposed of in a different manner. Isotope analysis of the bones of inhabitants shows that marine food sources in fact supplied more and more of the diet of the Norse Greenlanders, making up between 50% and 80% of their diet by the 14th century.
One Inuit story recorded in the 18th century tells that raiding expeditions by European ships over the course of three years destroyed the settlement, after which many of the Norse sailed away south and the Inuit took in some of the remaining women and children before the final attack.
Late Dorset and Thule cultures.
The Norse may not have been alone on the island when they arrived; a new influx of Arctic people from the west, the Late Dorset culture, may predate them. However, this culture was limited to the extreme northwest of Greenland, far from the Norse who lived around the southern coasts. Some archaeological evidence may point to this culture slightly predating the Norse settlement. It disappeared around 1300, around the same time as the westernmost of the Norse settlements disappeared. In the region of this culture, there is archaeological evidence of gathering sites for around four to thirty families, living together for a short time during their movement cycle.
Around 1200, another Arctic culture, the Thule, arrived from the west, having emerged 200 years earlier in Alaska. They settled south of the Late Dorset culture and ranged over vast areas of Greenland's west and east coasts. These people, the ancestors of the modern Inuit, were flexible and engaged in the hunting of almost all animals on land and in the ocean, including big whales. They had dogs, which the Dorset did not, and used them to pull the dog sledges; they also used bows and arrows, contrary to the Dorset. Increasingly settled, they had large food storages to avoid winter famine. The early Thule avoided the highest latitudes, which only became populated again after renewed immigration from Canada in the 19th century.
The nature of the contacts between the Thule, Dorset and Norse cultures is not clear, but may have included trade elements. The level of contact is currently the subject of widespread debate, possibly including Norse trade with Thule or Dorsets in Canada or possible scavenging of abandoned Norse sites (see also Maine penny). No Norse trade goods are known in Dorset archaeological sites in Greenland; the only Norse items found have been characterized as "exotic items". Carved screw threads on tools and carvings with beards found in settlements on the Canadian Arctic islands show contact with the Norse. Some stories tell of armed conflicts between, and kidnappings by, both Inuit and Norse groups. The Inuit may have reduced Norse food sources by displacing them on hunting grounds along the central west coast. These conflicts can be one contributing factor to the disappearance of the Norse culture as well as for the Late Dorset, but few see it as the main reason.
Danish recolonization.
Most of the old Norse records concerning Greenland were removed from Trondheim to Copenhagen in 1664 and subsequently lost, probably in the 1728 fire there. The precise rediscovery is uncertain because south-drifting icebergs during the Little Ice Age long made the eastern coast unreachable, leading to general confusion between Baffin Island, Greenland, and Spitsbergen as seen, for example, in the difficulty locating the Frobisher "Strait", which was not confirmed to be a bay until 1861. Nonetheless, interest in discovering a Northwest Passage to Asia led to repeated expeditions in the area, though none were successful until Roald Amundsen in 1906 and even that success involved his being iced in for two years. Christian I of Denmark purportedly sent an expedition to the region under Pothorst and Pining to Greenland in 1472 or 1473; Henry VII of England sent another under Cabot in 1497 and 1498; Manuel I of Portugal sent a third under Corte-Real in 1500 and 1501. It had certainly been generally charted by the 1502 Cantino map, which includes the southern coastline. The island was "rediscovered" yet again by Martin Frobisher in 1578, prompting the Danish king Frederick II to outfit a new expedition of his own the next year under the Englishman James Alday; this proved a costly failure. The influence of English and Dutch whalers became so pronounced that for a time the western shore of the island itself became known as "Davis Strait" (Dutch: "Straat Davis") after John Davis's 1585 and 1586 expeditions, which charted the western coast as far north as Disko Bay.
Meanwhile, following Sweden's exit from the Kalmar Union, the remaining states in the personal union were reorganized into Denmark-Norway in 1536. In protest against foreign involvement in the region, the Greenlandic polar bear was included in the state's coat of arms in the 1660s (It was removed in 1958). In the second half of the 17th century Dutch, German, French, Basque, and Dano-Norwegian ships hunted bowhead whales in the pack ice off the east coast of Greenland, regularly coming to shore to trade and replenish drinking water. Foreign trade was later forbidden by Danish monopoly merchants.
From 1711 to 1721, the Norwegian cleric Hans Egede petitioned King Frederick IV for funding to travel to Greenland and re-establish contact with the Norse settlers there. Presumably, such settlers would still be Catholic or even pagan and he desired to establish a mission among them to spread the Reformation. Frederick permitted Egede and some Norwegian merchants to establish the Bergen Greenland Company to revive trade with the island but refused to grant them a monopoly over it for fear of antagonizing Dutch whalers in the area. The Royal Mission College assumed superintendency over the mission and provided the company with a small stipend. Egede found but misidentified the ruins of the Norse colony, went bankrupt amid repeated attacks by the Dutch, and found lasting conversion of the migrant Inuit exceedingly difficult. An attempt to found a royal colony under Major Claus Paarss established the settlement of Godthåb ("Good Hope") in 1728 but was a costly debacle which saw most of his soldiers mutiny and his settlers killed by scurvy. Two child converts sent to Copenhagen for the coronation of Christian VI returned in 1733 with smallpox, devastating the island. The same ship that returned them, however, also brought the first Moravian missionaries, who in time would convert a former angekok (Inuit shaman), experience a revival at their mission of New Herrnhut, and establish a string of mission houses along the southwest coast. Around the same time, the merchant Jacob Severin took over administration of the colony and its trade and, having secured a large royal stipend and full monopoly from the king, successfully repulsed the Dutch in a series of skirmishes in 1738 and 1739. Egede himself quit the colony on the death of his wife, leaving the Lutheran mission to his son Poul. Both of them had studied the Kalaallisut language extensively and published works on it; as well, Poul and some of the other clergy sent by the Mission College such as Otto Fabricius began wide-ranging study of Greenland's flora, fauna, and meteorology. However, though kale, lettuce, and other herbs were successfully introduced, repeated attempts to cultivate wheat or clover failed throughout Greenland, limiting the ability to raise European livestock.
As a result of the Napoleonic Wars, Norway was ceded to Sweden at the 1814 Treaty of Kiel. The colonies, including Greenland, remained in Danish possession. The 19th century saw increased interest in the region on the part of polar explorers and scientists like William Scoresby and Greenland-born Knud Rasmussen. At the same time, the colonial elements of the earlier trade-oriented Danish presence in Greenland expanded. In 1861, the first Greenlandic-language journal was founded. Danish law still applied only to the Danish settlers, though. At the turn of the 19th century, the northern part of Greenland was still sparsely populated; only scattered hunting inhabitants were found there. During that century, however, Inuit families immigrated from British North America to settle in these areas. The last group from what later became Canada arrived in 1864. During the same time, the Northeastern part of the coast became depopulated following the violent 1783 Lakagígar eruption in Iceland.
Democratic elections for the district assemblies of Greenland were held for the first time in 1862–1863, although no assembly for the land as a whole was allowed. In 1888, a party of six led by Fridtjof Nansen accomplished the first land crossing of Greenland. The men took 41 days to make the crossing on skis, at approximately 64°N latitude. In 1911, two Landstings were introduced, one for northern Greenland and one for southern Greenland, not to be finally merged until 1951. All this time, most decisions were made in Copenhagen, where the Greenlanders had no representation. Towards the end of the 19th century, traders criticized the Danish trade monopoly. It was argued that it kept the natives in non-profitable ways of life, holding back the potentially large fishing industry. Many Greenlanders however were satisfied with the "status quo", as they felt the monopoly would secure the future of commercial whaling. It probably did not help that the only contact the local population had with the outside world was with Danish settlers. Nonetheless, the Danes gradually moved over their investments to the fishing industry.
Polar exploration.
At the end of the 19th century and beginning of the 20th century, American explorers, including Robert Peary, explored the northern sections of Greenland, which up to that time had been a mystery and were often shown on maps as extending over the North Pole. Peary discovered that Greenland's northern coast in fact stopped well short of the pole. These discoveries were considered to be the basis of an American territorial claim in the area. But after the United States purchased the Virgin Islands from Denmark in 1917, it agreed to relinquish all claims on Greenland.
Strategic importance.
After Norway regained full independence in 1905, it argued that Danish claims to Greenland were invalid since the island had been a Norwegian possession prior to 1815. In 1931, Norwegian whaler Hallvard Devold occupied uninhabited eastern Greenland, on his own initiative. After the fact, the occupation was supported by the Norwegian government, who claimed the area as Erik the Red's Land. Two years later, the Permanent Court of International Justice ruled in favor of Denmark.
During World War II, when Nazi Germany extended its war operations to Greenland, Henrik Kauffmann, the Danish Minister to the United States — who had already refused to recognize the German occupation of Denmark — signed a treaty with the United States on April 9, 1941, granting the US Armed Forces permission to establish stations in Greenland. Because of the difficulties for the Danish government to govern the island during the war, and because of successful export, especially of cryolite, Greenland came to enjoy a rather independent status. Its supplies were guaranteed by the United States and Canada.
During the Cold War, Greenland had a strategic importance, controlling parts of the passage between the Soviet Arctic harbours and the Atlantic, as well as being a good base for observing any use of intercontinental ballistic missiles, typically planned to pass over the Arctic. The United States therefore had a geopolitical interest in Greenland, and in 1946, the United States offered to buy Greenland from Denmark for $100,000,000 but Denmark did not agree to sell. In 1951, the Kauffman treaty was replaced by another one. The Thule Air Base at Thule (now Qaanaaq) in the northwest was made a permanent air force base. In 1953, some Inuit families were forced by Denmark to move from their homes to provide space for extension of the base. For this reason, the base has been a source of friction between the Danish government and the Greenlandic people. Tensions mounted when, on January 21, 1968, there was a nuclear accident — a B-52 Stratofortress carrying four hydrogen bombs crashed near the base, contaminating the area with radioactive debris. Although most of the contaminated ice was cleaned up, controversy currently surrounds recently declassified information indicating that one of the bombs was not accounted for. A 1995 Danish parliamentary scandal, dubbed Thulegate, highlighted that nuclear weapons were routinely present in Greenland's airspace in the years leading up to the accident, and that Denmark had tacitly given the go-ahead for this activity despite its official nuclear free policy.
Another recent controversy surrounds the Ballistic Missile Early Warning System (BMEWS), which the United States Air Force upgraded in recent years to a phased array radar. Opponents argue that the system presents a threat to the local population, as it would be targeted in the event of nuclear war.
Home rule.
From 1948 to 1950, the Greenland Commission studied the conditions on the island, seeking to address its isolation, unequal laws, and economic stagnation. In the end, the Royal Greenland Trading Department's monopolies were finally removed. In 1953, Greenland was raised from the status of colony to that of an autonomous province or constituent country of the Danish Realm. Despite its small population, it was provided nominal representation in the Danish Folketing.
Denmark also began a number of reforms aimed at urbanizing the Greenlanders, principally to replace their dependence on (then) dwindling seal populations and provide workers for the (then) swelling cod fisheries, but also to provide improved social services such as health care, education, and transportation. These well-meaning reforms have led to a number of problems, particularly modern unemployment and the infamous Blok P housing project. The attempt to introduce European-style urban housing suffered from such inattention to local detail that Inuit could not fit through the doors in their winter clothing and fire escapes were constantly blocked by fishing gear too bulky to fit into the cramped apartments. Television broadcasts began in 1982. The collapse of the cod fisheries and mines in the late 1980s and early 1990s greatly damaged the economy, which now principally depends on Danish aid and cold-water shrimp exports. Large sectors of the economy remain controlled by state-owned corporations, with Air Greenland and the Arctic Umiaq ferry heavily subsidized to provide access to remote settlements. The major airport remains the former US air base at Kangerlussuaq well north of Nuuk, with the capital unable to accept international flights on its own, owing to concerns about expense and noise pollution.
Greenland's minimal representation in the Folketing meant that despite 70.3% of Greenlanders rejecting entry into the European Common Market (EEC), it was pulled in along with Denmark in 1973. Fears that the customs union would allow foreign firms to compete and overfish its waters were quickly realized and the local parties began to push strongly for increased autonomy. The Folketing approved devolution in 1978 and the next year enacted home rule under a local Landsting. On 23 February 1982, a bare majority (53%) of Greenland's population voted to leave the EEC, a process which lasted until 1985.
Greenland Home Rule has become increasingly Greenlandized, rejecting Danish and avoiding regional dialects to standardize the country under the language and culture of the Kalaallit (West Greenland Inuit). The capital Godthåb was renamed Nuuk in 1979; a local flag was adopted in 1985; the Danish KGH became the locally administered Kalaallit Niuerfiat (now KNI A/S) in 1986. Following a successful referendum on self-government in 2008, the local parliament's powers were expanded and Danish was removed as an official language in 2009.
International relations are now largely, but not entirely, also left to the discretion of the home rule government. After leaving the EEC, Greenland signed a special treaty with it, granting it special access to the market as a constituent country of Denmark, which remains a member. Greenland is also a member of several small organizations along with Iceland, the Faroes, and the Inuit populations of Canada and Russia. It was one of the founders of the environmental Arctic Council in 1996. The US military bases on the island remain a major issue, with some politicians pushing for renegotiation of the 1951 US–Denmark treaty by the Home Rule government. The 1999–2003 Commission on Self-Governance even proposed that Greenland should aim at Thule Air Base's removal from American authority and operation under the aegis of the United Nations.

</doc>
<doc id="52477" url="http://en.wikipedia.org/wiki?curid=52477" title="History of Canada">
History of Canada

The history of Canada covers the period from the arrival of Paleo-Indians thousands of years ago to the present day. Canada has been inhabited for millennia by distinctive groups of Aboriginal peoples, with distinct trade networks, spiritual beliefs, and social hierarchies. Some of these civilizations had long faded by the time of the first European arrivals and have been discovered through archaeological investigations. Various treaties and laws have been enacted between European settlers and the Aboriginal populations.
Beginning in the late 15th century French and British expeditions explored, and later settled, along the Atlantic Coast. France ceded nearly all of its colonies in North America to Britain in 1763 after the Seven Years' War. In 1867, with the union of three British North American colonies through Confederation, Canada was formed as a federal dominion of four provinces. This began an accretion of provinces and territories and a process of increasing autonomy from the British Empire, which became official with the Statute of Westminster of 1931 and completed in the Canada Act of 1982, which severed the vestiges of legal dependence on the British parliament.
Over centuries, elements of Aboriginal, French, British and more recent immigrant customs have combined to form a Canadian culture. Canadian culture has also been strongly influenced by that of its linguistic, geographic and economic neighbour, the United States. Since the conclusion of the Second World War, Canadians have supported multilateralism abroad and socioeconomic development domestically. Canada currently consists of ten provinces and three territories and is governed as a parliamentary democracy and a constitutional monarchy with Queen Elizabeth II as its head of state.
Pre-colonization.
Aboriginals.
According to the North American archeological and Aboriginal genetic evidence, North and South America were the last continents in the world to have human habitation. During the Wisconsin glaciation, 50,000 – 17,000 years ago, falling sea levels allowed people to move across the Bering land bridge (Beringia) that joined Siberia to northwest North America (Alaska). At that point, they were blocked by the Laurentide ice sheet that covered most of Canada, confining them to Alaska for thousands of years.
Around 16,000 years ago, the glaciers began melting, allowing people to move south and east into Canada. The exact dates and routes of the peopling of the Americas are the subject of an ongoing debate. The Queen Charlotte Islands, Old Crow Flats, and Bluefish Caves are some of the earliest archaeological sites of Paleo-Indians in Canada. Ice Age hunter-gatherers left lithic flake fluted stone tools and the remains of large butchered mammals.
The North American climate stabilized around 8000 BCE (10,000 years ago). Climatic conditions were similar to modern patterns; however, the receding glacial ice sheets still covered large portions of the land, creating lakes of meltwater. Most population groups during the Archaic periods were still highly mobile hunter-gatherers. However, individual groups started to focus on resources available to them locally; thus with the passage of time, there is a pattern of increasing regional generalization (i.e.: Paleo-Arctic, Plano and Maritime Archaic traditions).
PP
S
L
Great Lakes area of the Hopewell Interaction Area 
The Woodland cultural period dates from about 2000 BCE to 1000 CE and includes the Ontario, Quebec, and Maritime regions. The introduction of pottery distinguishes the Woodland culture from the previous Archaic-stage inhabitants. The Laurentian-related people of Ontario manufactured the oldest pottery excavated to date in Canada.
The Hopewell tradition is an Aboriginal culture that flourished along American rivers from 300 BCE to 500 CE. At its greatest extent, the Hopewell Exchange System connected cultures and societies to the peoples on the Canadian shores of Lake Ontario. Canadian expression of the Hopewellian peoples encompasses the Point Peninsula, Saugeen, and Laurel complexes.
The eastern woodland areas of what became Canada were home to the Algonquian and Iroquoian peoples. The Algonquian language is believed to have originated in the western plateau of Idaho or the plains of Montana and moved eastward, eventually extending all the way from Hudson Bay to what is today Nova Scotia in the east and as far south as the Tidewater region of Virginia.
Speakers of eastern Algonquian languages included the Mi'kmaq and Abenaki of the Maritime region of Canada and likely the extinct Beothuk of Newfoundland. The Ojibwa and other Anishinaabe speakers of the central Algonquian languages retain an oral tradition of having moved to their lands around the western and central Great Lakes from the sea, likely the east coast. According to oral tradition, the Ojibwa formed the Council of Three Fires in 796 CE with the Odawa and the Potawatomi.
The Iroquois (Haudenosaunee) were centred from at least 1000 CE in northern New York, but their influence extended into what is now southern Ontario and the Montreal area of modern Quebec. The Iroquois Confederacy, according to oral tradition, was formed in 1142 CE. On the Great Plains the Cree or "Nēhilawē" (who spoke a closely related Central Algonquian language, the plains Cree language) depended on the vast herds of bison to supply food and many of their other needs. To the northwest were the peoples of the Na-Dene languages, which include the Athapaskan-speaking peoples and the Tlingit, who lived on the islands of southern Alaska and northern British Columbia. The Na-Dene language group is believed to be linked to the Yeniseian languages of Siberia. The Dene of the western Arctic may represent a distinct wave of migration from Asia to North America.
The Interior of British Columbia was home to the Salishan language groups such as the Shuswap (Secwepemc), Okanagan and southern Athabaskan language groups, primarily the Dakelh (Carrier) and the Tsilhqot'in. The inlets and valleys of the British Columbia Coast sheltered large, distinctive populations, such as the Haida, Kwakwaka'wakw and Nuu-chah-nulth, sustained by the region's abundant salmon and shellfish. These peoples developed complex cultures dependent on the western red cedar that included wooden houses, seagoing whaling and war canoes and elaborately carved potlatch items and totem poles.
In the Arctic archipelago, the distinctive Paleo-Eskimos known as Dorset peoples, whose culture has been traced back to around 500 BCE, were replaced by the ancestors of today's Inuit by 1500 CE. This transition is supported by archaeological records and Inuit mythology that tells of having driven off the "Tuniit" or 'first inhabitants'. Inuit traditional laws are anthropologically different from Western law. "Customary law" was non-existent in Inuit society before the introduction of the Canadian legal system.
European contact.
There are reports of contact made before the 1492 voyages of Christopher Columbus and the age of discovery between First Nations, Inuit and those from other continents.
The earliest known documented European exploration of Canada is described in the Icelandic Sagas, which recount the attempted Norse colonization of the Americas. According to the Sagas, the first European to see Canada was Bjarni Herjólfsson, who was blown off course en route from Iceland to Greenland in the summer of 985 or 986 CE. Around the year 1001 CE, the Sagas then refer to Leif Ericson's landing in three places to the west, the first two being Helluland (possibly Baffin Island) and Markland (possibly Labrador). Leif's third landing was at a place he called Vinland (possibly Newfoundland). Norsemen (often referred to as Vikings) attempted to colonize the new land; they were driven out by the local climate and harassment by the Indigenous populace. Archaeological evidence of a short-lived Norse settlement was found in L'Anse aux Meadows, Newfoundland (carbon dating estimate 990 – 1050 CE).
Based on the Treaty of Tordesillas, the Portuguese Crown claimed it had territorial rights in the area visited by John Cabot in 1497 and 1498 CE. To that end, in 1499 and 1500, the Portuguese mariner João Fernandes Lavrador visited the north Atlantic coast, which accounts for the appearance of "Labrador" on topographical maps of the period. Subsequently, in 1501 and 1502 the Corte-Real brothers explored Newfoundland (Terra Nova) and Labrador claiming these lands as part of the Portuguese Empire. In 1506, King Manuel I of Portugal created taxes for the cod fisheries in Newfoundland waters. João Álvares Fagundes and Pêro de Barcelos established fishing outposts in Newfoundland and Nova Scotia around 1521 CE; however, these were later abandoned, with the Portuguese colonizers focusing their efforts on South America. The extent and nature of Portuguese activity on the Canadian mainland during the 16th century remains unclear and controversial.
English America, New France and colonization 1534–1763.
French interest in the New World began with Francis I of France, who in 1524 sponsored Giovanni da Verrazzano to navigate the region between Florida and Newfoundland in hopes of finding a route to the Pacific Ocean. In 1534, Jacques Cartier planted a cross in the Gaspé Peninsula and claimed the land in the name of Francis I. Earlier colonization attempts by Cartier at Charlesbourg-Royal in 1541, at Sable Island in 1598 by Marquis de La Roche-Mesgouez, and at Tadoussac, Quebec in 1600 by François Gravé Du Pont had failed. Despite these initial failures, French fishing fleets began to sail to the Atlantic coast and into the St. Lawrence River, trading and making alliances with First Nations.
In 1604, a North American fur trade monopoly was granted to Pierre Dugua Sieur de Monts. The fur trade became one of the main economic ventures in North America. Dugua led his first colonization expedition to an island located near the mouth of the St. Croix River. Among his lieutenants was a geographer named Samuel de Champlain, who promptly carried out a major exploration of the northeastern coastline of what is now the United States. In the spring of 1605, under Samuel de Champlain, the new St. Croix settlement was moved to Port Royal (today's Annapolis Royal, Nova Scotia).
In 1608, Champlain founded what is now Quebec City, which would become the first permanent settlement and the capital of New France. He took personal administration over the city and its affairs, and sent out expeditions to explore the interior. Champlain himself discovered Lake Champlain in 1609. By 1615, he had travelled by canoe up the Ottawa River through Lake Nipissing and Georgian Bay to the centre of Huron country near Lake Simcoe. During these voyages, Champlain aided the Wendat (aka 'Hurons') in their battles against the Iroquois Confederacy. As a result, the Iroquois would become enemies of the French and be involved in multiple conflicts (known as the French and Iroquois Wars) until the signing of the Great Peace of Montreal in 1701.
The English, led by Humphrey Gilbert, had claimed St. John's, Newfoundland, in 1583 as the first North American English colony by royal prerogative of Queen Elizabeth I. In the reign of King James I, the English established additional colonies in Cupids and Ferryland, Newfoundland, and soon after established the first successful permanent settlements of Virginia to the south. On September 29, 1621, a charter for the foundation of a New World Scottish colony was granted by King James to Sir William Alexander. In 1622, the first settlers left Scotland. They initially failed and permanent Nova Scotian settlements were not firmly established until 1629 during the end of the Anglo-French War. These colonies did not last long: in 1631, under Charles I of England, the Treaty of Suza was signed, ending the war and returning Nova Scotia to the French. New France was not fully restored to French rule until the 1632 Treaty of Saint-Germain-en-Laye. This led to new French immigrants and the founding of Trois-Rivières in 1634, the second permanent settlement in New France.
During this period, in contrast to the higher density and slower moving agricultural settlement development by the English inward from the east coast of the colonies, New France's interior frontier would eventually cover an immense area with a thin network centred on fur trade, conversion efforts by missionaries, establishing and claiming an empire, and military efforts to protect and further those efforts. The largest of these canoe networks covered much of present-day Canada and central present-day United States.
After Champlain’s death in 1635, the Roman Catholic Church and the Jesuit establishment became the most dominant force in New France and hoped to establish a utopian European and Aboriginal Christian community. In 1642, the Sulpicians sponsored a group of settlers led by Paul Chomedey de Maisonneuve, who founded Ville-Marie, precursor to present-day Montreal. In 1663 the French crown took direct control of the colonies from the Company of New France.
Although immigration rates to New France remained very low under direct French control, most of the people were farmers, and the rate of population growth among the settlers themselves had been very high. The women had about 30 per cent more children than comparable women who remained in France. Yves Landry says, "Canadians had an exceptional diet for their time. This was due to the natural abundance of meat, fish, and pure water; the good food conservation conditions during the winter; and an adequate wheat supply in most years. The 1666 census of New France was conducted by France's intendant, Jean Talon, in the winter of 1665–1666. The census showed a population count of 3,215 "Acadians" and "habitants" (French-Canadian farmers) in the administrative districts of Acadia and Canada. The census also revealed a great difference in the number of men at 2,034 versus 1,181 women.
Wars during the colonial era.
By the early 1700s the New France settlers were well established along the shores of the Saint Lawrence River and parts of Nova Scotia, with a population around 16,000. However new arrivals stopped coming from France in the proceeding decades, resulting in the English and Scottish settlers in Newfoundland, Nova Scotia, and the southern Thirteen Colonies to vastly outnumber the French population approximately ten to one by the 1750s. From 1670, through the Hudson's Bay Company, the English also laid claim to Hudson Bay and its drainage basin known as Rupert's Land establishing new trading posts and forts, while continued to operate fishing settlements in Newfoundland. French expansion along the Canadian canoe routes challenged the Hudson's Bay Company claims, and in 1686, Pierre Troyes led an overland expedition from Montreal to the shore of the bay, where they managed to capture a handful of outposts. La Salle's explorations gave France a claim to the Mississippi River Valley, where fur trappers and a few settlers set up scattered forts and settlements.
There were four French and Indian Wars and two additional wars in Acadia and Nova Scotia between the Thirteen American Colonies and New France from 1689 to 1763. During King William's War (1689 to 1697), military conflicts in Acadia included: Battle of Port Royal (1690); a naval battle in the Bay of Fundy (Action of July 14, 1696); and the Raid on Chignecto (1696) . The Treaty of Ryswick in 1697 ended the war between the two colonial powers of England and France for a brief time. During Queen Anne's War (1702 to 1713), the British Conquest of Acadia occurred in 1710, resulting in Nova Scotia, other than Cape Breton, being officially ceded to the British by the Treaty of Utrecht including Rupert's Land, which France had conquered in the late 17th century (Battle of Hudson's Bay). As an immediate result of this setback, France founded the powerful Fortress of Louisbourg on Cape Breton Island.
Louisbourg was intended to serve as a year-round military and naval base for France's remaining North American empire and to protect the entrance to the St. Lawrence River. Father Rale's War resulted in both the fall of New France influence in present-day Maine and the British recognition of having to negotiate with the Mi'kmaq in Nova Scotia. During King George's War (1744 to 1748), an army of New Englanders led by William Pepperrell mounted an expedition of 90 vessels and 4,000 men against Louisbourg in 1745. Within three months the fortress surrendered. The return of Louisbourg to French control by the peace treaty prompted the British to found Halifax in 1749 under Edward Cornwallis. Despite the official cessation of war between the British and French empires with the Treaty of Aix-la-Chapelle; the conflict in Acadia and Nova Scotia continued on as the Father Le Loutre's War.
The British ordered the Acadians expelled from their lands in 1755 during the French and Indian War, an event called the Expulsion of the Acadians or "le Grand Dérangement". The "expulsion" resulted in approximately 12,000 Acadians being shipped to destinations throughout Britain's North American and to France, Quebec and the French Caribbean colony of Saint-Domingue. The first wave of the expulsion of the Acadians began with the Bay of Fundy Campaign (1755) and the second wave began after the final Siege of Louisbourg (1758). Many of the Acadians settled in southern Louisiana, creating the Cajun culture there. Some Acadians managed to hide and others eventually returned to Nova Scotia, but they were far outnumbered by a new migration of New England Planters who were settled on the former lands of the Acadians and transformed Nova Scotia from a colony of occupation for the British to a settled colony with stronger ties to New England. Britain eventually gained control of Quebec City and Montreal after the Battle of the Plains of Abraham and Battle of Fort Niagara in 1759, and the Battle of the Thousand Islands and Battle of Sainte-Foy in 1760.
Canada under British rule (1763–1867).
With the end of the Seven Years' War and the signing of the Treaty of Paris (1763), France ceded almost all of its territory in mainland North America, except for fishing rights off Newfoundland and two small islands where it could dry that fish. In turn France received the return of its sugar colony, Guadeloupe, which it considered more valuable than Canada. As of 2015, Guadeloupe remains apart of the French Republic. The two small fishing islands, named St. Pierre et Miquelon, are less than 10 kilometers from the coast of Newfoundland and Labrador, yet remain under French rule.
The new British rulers retained and protected most of the property, religious, political, and social culture of the French-speaking "habitants", guaranteeing the right of the "Canadiens" to practice the Catholic faith and to the use of French civil law (now Quebec law) through the Quebec Act of 1774. The Royal Proclamation of 1763 had been issued in October, by King George III following Great Britain's acquisition of French territory. The proclamation organized Great Britain's new North American empire and stabilized relations between the British Crown and Aboriginal peoples through regulation of trade, settlement, and land purchases on the western frontier.
American Revolution and the Loyalists.
During the American Revolution, there was some sympathy for the American cause among the Acadians and the New Englanders in Nova Scotia. Neither party joined the rebels, although several hundred individuals joined the revolutionary cause. An invasion of Canada by the Continental Army in 1775, with a goal to take Quebec from British control, was halted at the Battle of Quebec by Guy Carleton, with the assistance of local militias. The defeat of the British army during the Siege of Yorktown in October 1781 signaled the end of Britain's struggle to suppress the American Revolution.
When the British evacuated New York City in 1783, they took many Loyalist refugees to Nova Scotia, while other Loyalists went to southwestern Quebec. So many Loyalists arrived on the shores of the St. John River that a separate colony—New Brunswick—was created in 1784; followed in 1791 by the division of Quebec into the largely French-speaking Lower Canada (French Canada) along the St. Lawrence River and Gaspé Peninsula and an anglophone Loyalist Upper Canada, with its capital settled by 1796 in York, in present-day Toronto. After 1790 most of the new settlers were American farmers searching for new lands; although generally favorable to republicanism, they were relatively non-political and stayed neutral in the War of 1812.
The signing of the Treaty of Paris 1783 formally ended the war. Britain made several concessions to the Americans at the expense of the North American colonies. Notably, the borders between Canada and the United States were officially demarcated; all land south of the Great Lakes, which was formerly a part of the Province of Quebec and included modern day Michigan, Illinois and Ohio, was ceded to the Americans. Fishing rights were also granted to the United States in the Gulf of St. Lawrence and on the coast of Newfoundland and the Grand Banks. The British ignored part of the treaty and maintained their military outposts in the Great Lakes areas it had ceded to the U.S., and they continued to supply their native allies with munitions. The British evacuated the outposts with the Jay Treaty of 1795, but the continued supply of munitions irritated the Americans in the run-up to the War of 1812.
Lower emphasizes the positive benefits of the Revolution for Americans, making them an energetic people, while for English Canada the results were negative:
 To take the place of the internal fire that was urging Americans westward across the continent, there was only melancholy contemplation of things as they might have been and dingy reflection of that ineffably glorious world across the stormy Atlantic. English Canada started its life with as powerful a nostalgic shove backward into the past as the Conquest had given to French Canada: two little peoples officially devoted to counter-revolution, to lost causes, to the tawdry ideals of a society of men and masters, and not to the self-reliant freedom alongside of them."
War of 1812.
The War of 1812 was fought between the United States and the British, with the British North American colonies being heavily involved. Greatly outgunned by the British Royal Navy, the American war plans focused on an invasion of Canada (especially what is today eastern and western Ontario). The American frontier states voted for war to suppress the First Nations raids that frustrated settlement of the frontier. Another goal may have been the annexation of Canada. The war on the border with the United States was characterized by a series of multiple failed invasions and fiascos on both sides. American forces took control of Lake Erie in 1813, driving the British out of western Ontario, killing the Native American leader Tecumseh, and breaking the military power of his confederacy. The war was overseen by British army officers like Isaac Brock and Charles de Salaberry with the assistance of First Nations and loyalist informants, most notably Laura Secord.
The War ended with the Treaty of Ghent of 1814, and the Rush–Bagot Treaty of 1817. A demographic result was the shifting of American migration from Upper Canada to Ohio, Indiana and Michigan. After the war, supporters of Britain tried to repress the republicanism that was common among American immigrants to Canada. The troubling memory of the war and the American invasions etched itself into the consciousness of Canadians as a distrust of the intentions of the United States towards the British presence in North America.pp. 254–255
Rebellions and the Durham Report.
The rebellions of 1837 against the British colonial government took place in both Upper and Lower Canada. In Upper Canada, a band of Reformers under the leadership of William Lyon Mackenzie took up arms in a disorganized and ultimately unsuccessful series of small-scale skirmishes around Toronto, London, and Hamilton.
In Lower Canada, a more substantial rebellion occurred against British rule. Both English- and French-Canadian rebels, sometimes using bases in the neutral United States, fought several skirmishes against the authorities. The towns of Chambly and Sorel were taken by the rebels, and Quebec City was isolated from the rest of the colony. Montreal rebel leader Robert Nelson read the "Declaration of Independence of Lower Canada" to a crowd assembled at the town of Napierville in 1838. The rebellion of the "Patriote movement" was defeated after battles across Quebec. Hundreds were arrested, and several villages were burnt in reprisal.
British Government then sent Lord Durham to examine the situation; he stayed in Canada only five months before returning to Britain and brought with him his Durham Report, which strongly recommended responsible government. A less well-received recommendation was the amalgamation of Upper and Lower Canada for the deliberate assimilation of the French-speaking population. The Canadas were merged into a single colony, the United Province of Canada, by the 1840 Act of Union, and responsible government was achieved in 1848, a few months after it was accomplished in Nova Scotia. The parliament of United Canada in Montreal was set on fire by a mob of Tories in 1849 after the passing of an indemnity bill for the people who suffered losses during the rebellion in Lower Canada.
Between the Napoleonic Wars and 1850, some 800,000 immigrants came to the colonies of British North America, mainly from the British Isles, as part of the great migration of Canada. These included Gaelic-speaking Highland Scots displaced by the Highland Clearances to Nova Scotia and Scottish and English settlers to the Canadas, particularly Upper Canada. The Irish Famine of the 1840s significantly increased the pace of Irish Catholic immigration to British North America, with over 35,000 distressed Irish landing in Toronto alone in 1847 and 1848.
Pacific colonies.
Spanish explorers had taken the lead in the Pacific Northwest coast, with the voyages of Juan José Pérez Hernández in 1774 and 1775. By the time the Spanish determined to build a fort on Vancouver Island, the British navigator James Cook had visited Nootka Sound and charted the coast as far as Alaska, while British and American maritime fur traders had begun a busy era of commerce with the coastal peoples to satisfy the brisk market for sea otter pelts in China, thereby launching what became known as the China Trade.
In 1789 war threatened between Britain and Spain on their respective rights; the Nootka Crisis was resolved peacefully largely in favor of Britain, the much stronger naval power. In 1793 Alexander MacKenzie, a Canadian working for the North West Company, crossed the continent and with his Aboriginal guides and French-Canadian crew, reached the mouth of the Bella Coola River, completing the first continental crossing north of Mexico, missing George Vancouver's charting expedition to the region by only a few weeks. In 1821, the North West Company and Hudson's Bay Company merged, with a combined trading territory that was extended by a licence to the North-Western Territory and the Columbia and New Caledonia fur districts, which reached the Arctic Ocean on the north and the Pacific Ocean on the west.
The Colony of Vancouver Island was chartered in 1849, with the trading post at Fort Victoria as the capital. This was followed by the Colony of the Queen Charlotte Islands in 1853, and by the creation of the Colony of British Columbia in 1858 and the Stikine Territory in 1861, with the latter three being founded expressly to keep those regions from being overrun and annexed by American gold miners. The Colony of the Queen Charlotte Islands and most of the Stikine Territory were merged into the Colony of British Columbia in 1863 (the remainder, north of the 60th Parallel, became part of the North-Western Territory).
Confederation.
The Seventy-Two Resolutions from the 1864 Quebec Conference and Charlottetown Conference laid out the framework for uniting British colonies in North America into a federation. They had been adopted by the majority of the provinces of Canada and became the basis for the London Conference of 1866, which led to the formation of the Dominion of Canada on July 1, 1867. The term "dominion" was chosen to indicate Canada's status as a self-governing colony of the British Empire, the first time it was used about a country. With the coming into force of the British North America Act (enacted by the British Parliament), the Province of Canada, New Brunswick, and Nova Scotia became a federated kingdom in its own right.
Federation emerged from multiple impulses: the British wanted Canada to defend itself; the Maritimes needed railroad connections, which were promised in 1867; British-Canadian nationalism sought to unite the lands into one country, dominated by the English language and British culture; many French-Canadians saw an opportunity to exert political control within a new largely French-speaking Quebecpp. 323–324 and fears of possible U.S. expansion northward. On a political level, there was a desire for the expansion of responsible government and elimination of the legislative deadlock between Upper and Lower Canada, and their replacement with provincial legislatures in a federation. This was especially pushed by the liberal Reform movement of Upper Canada and the French-Canadian "Parti rouge" in Lower Canada who favored a decentralized union in comparison to the Upper Canadian Conservative party and to some degree the French-Canadian "Parti bleu", which favored a centralized union.
Post-Confederation Canada 1867–1914.
In 1866, the Colony of British Columbia and the Colony of Vancouver Island merged into a single Colony of British Columbia, until their incorporation into the Canadian Confederation in 1871. In 1873, Prince Edward Island, the Maritime colony that had opted not to join Confederation in 1867, was admitted into the country. That year, John A. Macdonald (First Prime Minister of Canada) created the North-West Mounted Police (now the Royal Canadian Mounted Police) to help police the Northwest Territories. Specifically the Mounties were to assert Canadian sovereignty over possible American encroachments into the sparsely populated land.
The Mounties' first large-scale mission was to suppress the second independence movement by Manitoba's Métis, a mixed blood people of joint First Nations and European descent, who originated in the mid-17th century. The desire for independence erupted in the Red River Rebellion in 1869 and the later North-West Rebellion in 1885 led by Louis Riel. In 1905 when Saskatchewan and Alberta were admitted as provinces, they were growing rapidly thanks to abundant wheat crops that attracted immigration to the plains by Ukrainians and Northern and Central Europeans and by settlers from the United States, Britain and eastern Canada.
The Alaska boundary dispute, simmering since the Alaska purchase of 1867, became critical when gold was discovered in the Yukon during the late 1890s, with the U.S. controlling all the possible ports of entry. Canada argued its boundary included the port of Skagway. The dispute went to arbitration in 1903, but the British delegate sided with the Americans, angering Canadians who felt the British had betrayed Canadian interests to curry favour with the U.S.
In 1893, legal experts codified a framework of civil and criminal law, culminating in the Criminal Code of Canada. This solidified the liberal ideal of "equality before the law" in a way that made an abstract principle into a tangible reality for every adult Canadian. Wilfrid Laurier who served 1896–1911 as the Seventh Prime Minister of Canada felt Canada was on the verge of becoming a world power, and declared that the 20th century would "belong to Canada"
Laurier signed a reciprocity treaty with the U.S. that would lower tariffs in both directions. Conservatives under Robert Borden denounced it, saying it would integrate Canada's economy into that of the U.S. and loosen ties with Britain. The Conservative party won the Canadian federal election, 1911.
World Wars and Interwar Years 1914–1945.
First World War.
The Canadian Forces and civilian participation in the First World War helped to foster a sense of British-Canadian nationhood. The highpoints of Canadian military achievement during the First World War came during the Somme, Vimy, Passchendaele battles and what later became known as "Canada's Hundred Days". The reputation Canadian troops earned, along with the success of Canadian flying aces including William George Barker and Billy Bishop, helped to give the nation a new sense of identity. The War Office in 1922 reported approximately 67,000 killed and 173,000 wounded during the war. This excludes civilian deaths in war-time incidents like the Halifax Explosion.
Support for Great Britain during the First World War caused a major political crisis over conscription, with Francophones, mainly from Quebec, rejecting national policies. During the crisis, large numbers of enemy aliens (especially Ukrainians and Germans) were put under government controls. The Liberal party was deeply split, with most of its Anglophone leaders joining the unionist government headed by Prime Minister Robert Borden, the leader of the Conservative party. The Liberals regained their influence after the war under the leadership of William Lyon Mackenzie King, who served as prime minister with three separate terms between 1921 and 1949.
Woman suffrage.
Women's political status without the vote was vigorously promoted by the National Council of Women of Canada from 1894 to 1918. It promoted a vision of "transcendent citizenship" for women. The ballot was not needed, for citizenship was to be exercised through personal influence and moral suasion, through the election of men with strong moral character, and through raising public-spirited sons. The National Council position reflected its nation-building program that sought to uphold Canada as a White settler nation. While the woman suffrage movement was important for extending the political rights of White women, it was also authorized through race-based arguments that linked White women's enfranchisement to the need to protect the nation from "racial degeneration."
Women did have a local vote in some provinces, as in Canada West from 1850, where women owning land could vote for school trustees. By 1900 other provinces adopted similar provisions, and in 1916 Manitoba took the lead in extending full woman's suffrage. Simultaneously suffragists gave strong support to the prohibition movement, especially in Ontario and the Western provinces.
The Military Voters Act of 1917 gave the vote to British women who were war widows or had sons or husbands serving overseas. Unionists Prime Minister Borden pledged himself during the 1917 campaign to equal suffrage for women. After his landslide victory, he introduced a bill in 1918 for extending the franchise to women. This passed without division, but did not apply to Quebec provincial and municipal elections. The women of Quebec gained full suffrage in 1940. The first woman elected to Parliament was Agnes Macphail of Ontario in 1921.
Interwar.
On the world stage.
As a result of its contribution to Allied victory in the First World War, Canada became more assertive and less deferential to British authority. Convinced that Canada had proven itself the battlefields of Europe, Prime Minister Sir Robert Borden demanded that it have a separate seat at the Paris Peace Conference in 1919. This was initially opposed not only by Britain but also by the United States, which saw such a delegation as an extra British vote. Borden responded by pointing out that since Canada had lost nearly 60,000 men, a far larger proportion of its men, its right to equal status as a nation had been consecrated on the battlefield. British Prime Minister David Lloyd George eventually relented, and convinced the reluctant Americans to accept the presence of delegations from Canada, India, Australia, Newfoundland, New Zealand and South Africa. These also received their own seats in the League of Nations. Canada asked for neither reparations nor mandates. It played only a modest role at Paris, but just having a seat was a matter of pride. It was cautiously optimistic about the new League of Nations, in which it played an active and independent role.
In 1923 British Prime Minister, David Lloyd George, appealed repeatedly for Canadian support in the Chanak crisis, in which a war threatened between Britain and Turkey. Canada refused. The Department of External Affairs, which had been founded in 1909, was expanded and promoted Canadian autonomy as Canada reduced its reliance on British diplomats and used its own foreign service. Thus began the careers of such important diplomats as Norman Robertson and Hume Wrong, and future prime minister Lester Pearson.
In 1931 the British Parliament passed the Statute of Westminster gave which each dominion the opportunity for almost complete legislative independence from London. While Newfoundland never adopted the statute, for Canada the Statute of Westminster became its declaration of independence.
Domestic affairs.
In 1921 to 1926, William Lyon Mackenzie King's Liberal government pursued a conservative domestic policy with the object of lowering wartime taxes and, especially, cooling wartime ethnic tensions, as well as defusing postwar labour conflicts. The Progressives refused to join the government, but did help the Liberals defeat non-confidence motions. King faced a delicate balancing act of reducing tariffs enough to please the Prairie-based Progressives, but not too much to alienate his vital support in industrial Ontario and Quebec, which needed tariffs to compete with American imports. King and Conservative leader Arthur Meighen sparred constantly and bitterly in Commons debates. The Progressives gradually weakened. Their effective and passionate leader, Thomas Crerar, resigned to return to his grain business, and was replaced by the more placid Robert Forke. The socialist reformer J.S. Woodsworth gradually gained influence and power among the Progressives, and he reached an accommodation with King on policy matters.
In 1926 Prime Minister Mackenzie King advised the Governor General, Lord Byng, to dissolve Parliament and call another election, but Byng refused, the only time that the Governor General has exercised such a power. Instead Byng called upon Meighen, the Conservative Party leader, to form a government. Meighen attempted to do so, but was unable to obtain a majority in the Commons and he, too, advised dissolution, which this time was accepted. The episode, the King-Byng Affair, marks a constitutional crisis that was resolved by a new tradition of complete non-interference in Canadian political affairs on the part of the British government.
Great Depression.
Canada was hard hit by the worldwide Great Depression that began in 1929. Between 1929 and 1933, the gross national product dropped 40% (compared to 37% in the US). Unemployment reached 27% at the depth of the Depression in 1933. Many businesses closed, as corporate profits of $396 million in 1929 turned into losses of $98 million in 1933. Canadian exports shrank by 50% from 1929 to 1933. Construction all but stopped (down 82%, 1929–33), and wholesale prices dropped 30%. Wheat prices plunged from 78c per bushel (1928 crop) to 29c in 1932.
Urban unemployment nationwide was 19%; Toronto's rate was 17%, according to the census of 1931. Farmers who stayed on their farms were not considered unemployed. By 1933, 30% of the labour force was out of work, and one fifth of the population became dependent on government assistance. Wages fell as did prices. Worst hit were areas dependent on primary industries such as farming, mining and logging, as prices fell and there were few alternative jobs. Most families had moderate losses and little hardship, though they too became pessimistic and their debts become heavier as prices fell. Some families saw most or all of their assets disappear, and suffered severely.
In 1930, in the first stage of the long depression, Prime Minister Mackenzie King believed that the crisis was a temporary swing of the business cycle and that the economy would soon recover without government intervention. He refused to provide unemployment relief or federal aid to the provinces, saying that if Conservative provincial governments demanded federal dollars, he would not give them "a five cent piece." His blunt wisecrack was used to defeat the Liberals in the 1930 election. The main issue was the rapid deterioration in the economy and whether the prime minister was out of touch with the hardships of ordinary people. The winner of the 1930 election was Richard Bedford Bennett and the Conservatives. Bennett had promised high tariffs and large-scale spending, but as deficits increased, he became wary and cut back severely on Federal spending. With falling support and the depression getting only worse, Bennett attempted to introduce policies based on the New Deal of President Franklin D. Roosevelt (FDR) in the United States, but he got little passed. Bennett's government became a focus of popular discontent. For example, auto owners saved on gasoline by using horses to pull their cars, dubbing them Bennett Buggies. The Conservative failure to restore prosperity led to the return of Mackenzie King's Liberals in the 1935 election.
In 1935, the Liberals used the slogan "King or Chaos" to win a landslide in the 1935 election. Promising a much-desired trade treaty with the U.S., the Mackenzie King government passed the 1935 Reciprocal Trade Agreement. It marked the turning point in Canadian-American economic relations, reversing the disastrous trade war of 1930–31, lowering tariffs, and yielding a dramatic increase in trade.
The worst of the Depression had passed by 1935, as Ottawa launched relief programs such as the National Housing Act and National Employment Commission. The Canadian Broadcasting Corporation became a crown corporation in 1936. Trans-Canada Airlines (the precursor to Air Canada) was formed in 1937, as was the National Film Board of Canada in 1939. In 1938, Parliament transformed the Bank of Canada from a private entity to a crown corporation.
One political response was a highly restrictive immigration policy and a rise in nativism.
Times were especially hard in western Canada, where a full recovery did not occur until the Second World War began in 1939. One response was the creation of new political parties such as the Social Credit movement and the Cooperative Commonwealth Federation, as well as popular protest in the form of the On-to-Ottawa Trek.
Second World War.
Canada's involvement in the Second World War began when Canada declared war on Nazi Germany on September 10, 1939, delaying it one week after Britain acted to symbolically demonstrate independence. The war restored Canada's economic health and its self-confidence, as it played a major role in the Atlantic and in Europe. During the war, Canada became more closely linked to the U.S. The Americans took virtual control of Yukon in order to build the Alaska Highway, and were a major presence in the British colony of Newfoundland with major airbases.
Mackenzie King — and Canada — were largely ignored by Winston Churchill and the British government despite Canada's major role in supplying food, raw materials, munitions and money to the hard-pressed British economy, training airmen for the Commonwealth, guarding the western half of the North Atlantic Ocean against German U-boats, and providing combat troops for the invasions of Italy, France and Germany in 1943–45. The government successfully mobilized the economy for war, with impressive results in industrial and agricultural output. The depression ended, prosperity returned, and Canada's economy expanded significantly. On the political side, Mackenzie King rejected any notion of a government of national unity. The Canadian federal election, 1940 was held as normally scheduled, producing another majority for the Liberals.
Building up the Royal Canadian Air Force was a high priority; it was kept separate from Britain's Royal Air Force. The British Commonwealth Air Training Plan Agreement, signed in December 1939, bound Canada, Britain, New Zealand, and Australia to a program that eventually trained half the airmen from those four nations in the Second World War.
After the start of war with Japan in December 1941, the government, in cooperation with the U.S., began the Japanese-Canadian internment, which sent 22,000 British Columbia residents of Japanese descent to relocation camps far from the coast. The reason was intense public demand for removal and fears of espionage or sabotage. The government ignored reports from the RCMP and Canadian military that most of the Japanese were law-abiding and not a threat.
The Battle of the Atlantic began immediately, and from 1943 to 1945 was led by Leonard W. Murray, from Nova Scotia. German U-boats operated in Canadian and Newfoundland waters throughout the war, sinking many naval and merchant vessels, as Canada took charge of the defenses of the western Atlantic. The Canadian army was involved in the failed defence of Hong Kong, the unsuccessful Dieppe Raid in August 1942, the Allied invasion of Italy, and the highly successful invasion of France and the Netherlands in 1944–45.
The Conscription Crisis of 1944 greatly affected unity between French and English-speaking Canadians, though was not as politically intrusive as that of the First World War. Of a population of approximately 11.5 million, 1.1 million Canadians served in the armed forces in the Second World War. Many thousands more served with the Canadian Merchant Navy. In all, more than 45,000 died, and another 55,000 were wounded.
Post-war Era 1945–1960.
Prosperity returned to Canada during the Second World War and continued in the proceeding years, with the development of universal health care, old-age pensions, and veterans' pensions. The financial crisis of the Great Depression had led the Dominion of Newfoundland to relinquish responsible government in 1934 and become a crown colony ruled by a British governor. In 1948, the British government gave voters three Newfoundland Referendum choices: remaining a crown colony, returning to Dominion status (that is, independence), or joining Canada. Joining the United States was not made an option. After bitter debate Newfoundlanders voted to join Canada in 1949 as a province.
The foreign policy of Canada during the Cold War was closely tied to that of the United States. Canada was a founding member of NATO (which Canada wanted to be a transatlantic economic and political union as well). In 1950, Canada sent combat troops to Korea during the Korean War as part of the United Nations forces. The federal government's desire to assert its territorial claims in the Arctic during the Cold War manifested with the High Arctic relocation, in which Inuit were moved from Nunavik (the northern third of Quebec) to barren Cornwallis Island; this project was later the subject of a long investigation by the Royal Commission on Aboriginal Peoples.
In 1956, the United Nations responded to the Suez Crisis by convening a United Nations Emergency Force to supervise the withdrawal of invading forces. The peacekeeping force was initially conceptualized by Secretary of External Affairs and future Prime Minister Lester B. Pearson. Pearson was awarded the Nobel Peace Prize in 1957 for his work in establishing the peacekeeping operation. Throughout the mid-1950s, Louis St. Laurent (12th Prime Minister of Canada) and his successor John Diefenbaker attempted to create a new, highly advanced jet fighter, the Avro Arrow. The controversial aircraft was cancelled by Diefenbaker in 1959. Diefenbaker instead purchased the BOMARC missile defense system and American aircraft. In 1958 Canada established (with the United States) the North American Aerospace Defense Command (NORAD).
1960–1981.
In the 1960s, what became known as the Quiet Revolution took place in Quebec, overthrowing the old establishment which centred on the Roman Catholic Archdiocese of Quebec and led to modernizing of the economy and society. Québécois nationalists demanded independence, and tensions rose until violence erupted during the 1970 October Crisis. In 1976 the Parti Québécois was elected to power in Quebec, with a nationalist vision that included securing French linguistic rights in the province and the pursuit of some form of sovereignty for Quebec. This culminated in the 1980 referendum in Quebec on the question of sovereignty-association, which was turned down by 59% of the voters.
In 1965, Canada adopted the maple leaf flag, although not without considerable debate and misgivings among large number of English Canadians. The World's Fair titled Expo 67 came to Montreal, coinciding with the Canadian Centennial that year. The fair opened April 28, 1967, with the theme "Man and his World" and became the best attended of all BIE-sanctioned world expositions until that time.
Legislative restrictions on Canadian immigration that had favoured British and other European immigrants were amended in the 1960s, opening the doors to immigrants from all parts of the world. While the 1950s had seen high levels of immigration from Britain, Ireland, Italy, and northern continental Europe, by the 1970s immigrants increasingly came from India, China, Vietnam, Jamaica and Haiti. Immigrants of all backgrounds tended to settle in the major urban centres, particularly Toronto, Montreal and Vancouver.
During his long tenure in the office (1968–79, 1980–84), Prime Minister Pierre Trudeau made social and cultural change his political goals, including the pursuit of official bilingualism in Canada and plans for significant constitutional change. The west, particularly the petroleum-producing provinces like Alberta, opposed many of the policies emanating from central Canada, with the National Energy Program creating considerable antagonism and growing western alienation. Multiculturalism in Canada was adopted as the official policy of the Canadian government during the prime ministership of Pierre Trudeau.
1982–1992.
In 1982, the Canada Act was passed by the British parliament and granted Royal Assent by Queen Elizabeth II on March 29, while the Constitution Act was passed by the Canadian parliament and granted Royal Assent by the Queen on April 17, thus patriating the Constitution of Canada. Previously, the constitution has existed only as an act passed of the British parliament, and was not even physically located in Canada, though it could not be altered without Canadian consent. At the same time, the Charter of Rights and Freedoms was added in place of the previous Bill of Rights. The patriation of the constitution was Trudeau's last major act as Prime Minister; he resigned in 1984.
On June 23, 1985, Air India Flight 182 was destroyed above the Atlantic Ocean by a bomb on board exploding; all 329 on board were killed, of whom 280 were Canadian citizens. The Air India attack is the largest mass murder in Canadian history.
The Progressive Conservative (PC) government of Brian Mulroney began efforts to gain Quebec's support for the Constitution Act 1982 and end western alienation. In 1987 the Meech Lake Accord talks began between the provincial and federal governments, seeking constitutional changes favourable to Quebec. The constitutional reform process under Prime Minister Mulroney culminated in the failure of the Charlottetown Accord which would have recognized Quebec as a "distinct society" but was rejected in 1992 by a narrow margin.
Under Brian Mulroney, relations with the United States began to grow more closely integrated. In 1986, Canada and the U.S. signed the "Acid Rain Treaty" to reduce acid rain. In 1989, the federal government adopted the Free Trade Agreement with the United States despite significant animosity from the Canadian public who were concerned about the economic and cultural impacts of close integration with the United States. On July 11, 1990, the Oka Crisis land dispute began between the Mohawk people of Kanesatake and the adjoining town of Oka, Quebec. The dispute was the first of a number of well-publicized conflicts between First Nations and the Canadian government in the late 20th century. In August 1990, Canada was one of the first nations to condemn Iraq's invasion of Kuwait, and it quickly agreed to join the U.S.-led coalition. Canada deployed destroyers and later a CF-18 Hornet squadron with support personnel, as well as a field hospital to deal with casualties.
Recent history: 1992–present.
Following Mulroney's resignation as prime minister in 1993, Kim Campbell took office and became Canada's first female prime minister. Campbell remained in office for only a few months: the 1993 election saw the collapse of the Progressive Conservative Party from government to two seats, while the Quebec-based sovereigntist Bloc Québécois became the official opposition. Prime Minister Jean Chrétien of the Liberals took office in November 1993 with a majority government and was re-elected with further majorities during the 1997 and 2000 elections.
In 1995, the government of Quebec held a second referendum on sovereignty that was rejected by a margin of 50.6% to 49.4%. In 1998, the Canadian Supreme Court ruled unilateral secession by a province to be unconstitutional, and Parliament passed the Clarity Act outlining the terms of a negotiated departure. Environmental issues increased in importance in Canada during this period, resulting in the signing of the Kyoto Accord on climate change by Canada's Liberal government in 2002. The accord was in 2007 nullified by the present government, which has proposed a "made-in-Canada" solution to climate change.
Canada became the fourth country in the world and the first country in the Americas to legalize same-sex marriage nationwide with the enactment of the Civil Marriage Act. Court decisions, starting in 2003, had already legalized same-sex marriage in eight out of ten provinces and one of three territories. Before the passage of the Act, more than 3,000 same-sex couples had married in these areas.
The Canadian Alliance and PC Party merged into the Conservative Party of Canada in 2003, ending a 13-year division of the conservative vote. The party was elected twice as a minority government under the leadership of Stephen Harper in the 2006 federal election and 2008 federal election. Harper's Conservative Party won a majority in the 2011 federal election with the New Democratic Party forming the Official Opposition for the first time.
Under Harper, Canada and the United States continue to integrate state and provincial agencies to strengthen security along the Canada-United States border through the Western Hemisphere Travel Initiative. From 2002 to 2011, Canada was involved in the Afghanistan War as part of the U.S. stabilization force and the NATO-commanded International Security Assistance Force. In July 2010, the largest purchase in Canadian military history, totalling C$9 billion for the acquisition of 65 F-35 fighters, was announced by the federal government. Canada is one of several nations that assisted in the development of the F-35 and has invested over C$168 million in the program.
See also.
History by province or territory
Further reading.
</dl>
</dl>
External links.
<br>

</doc>
<doc id="52482" url="http://en.wikipedia.org/wiki?curid=52482" title="Dutch colonization of the Americas">
Dutch colonization of the Americas

Dutch trading posts and plantations in the Americas precede the much wider known colonization activities of the Dutch in Asia. When the first Dutch fort in Asia was built in 1600 (in present-day Indonesia), the first forts and settlements on the Essequibo river in Guyana and on the Amazon date from the 1590s. Actual colonization, with Dutch settling in the new lands, was not as common as with other European nations. Many of the Dutch settlements were lost or abandoned by the end of the 17th century, but the Netherlands managed to retain possession of Suriname until it gained independence in 1975, as well as the former Netherlands Antilles, of which the islands remain within the Kingdom of the Netherlands today.
North America.
Netherlands Antilles.
Dutch colonization in the Caribbean started in the 1634 on St. Croix and Tobago (1628), followed in 1631 with settlements on Tortuga (now Île Tortue) and Sint Maarten. When the Dutch lost Sint Maarten (and Anguilla where they had built a fort shortly after arriving in Sint Maarten) to the Spanish, they settled Curaçao and Sint Eustatius. They regained half of Sint Maarten in 1648, from then on sharing the island with France. The border between the two portions of the island continued to be modified periodically, before being set for good in 1816.
Until deep into the 19th century, the now Venezuelan islands of Aves, the Aves archipelago, Los Roques and La Orchila were also considered by the Dutch government to be part of the Dutch West Indies.
The Netherlands Antilles remained an overseas territory of the Netherlands. It was granted self-rule in 1954. In 1986, Aruba was granted autonomy, separately from the other islands. On October 10, 2010 the Netherlands Antilles was dismantled. Like Aruba, the islands Curaçao and Sint Maarten became constituent countries of the Kingdom of the Netherlands. Bonaire, Saba, and Sint Eustatius became special municipalities of the Netherlands.
Tobago.
The Netherlands made numerous attempts to colonize Tobago (Nieuw-Walcheren) in the 17th century. Each time, the settlements were destroyed by rival European powers. Dutch settlements on Tobago:
Virgin Islands.
As a group, the islands are known as the Maagdeneilanden in Dutch. The Dutch established a base on St. Croix ("Sint-Kruis") in 1625, the same year that the British did. French Protestants joined the Dutch but conflict with the British colony led to its abandonment before 1650. The Dutch established a settlement on Tortola ("Ter Tholen") before 1640 and later on Anegada, Saint Thomas ("Sint-Thomas") and Virgin Gorda. The British took Tortola in 1672 and Anegada and Virgin Gorda in 1680.
United States and Canada.
In 1602, the government of the Republic of the Seven United Netherlands chartered the Dutch East India Company ("Vereenigde Oostindische Compagnie"), or VOC with the mission of exploring it for a passage to the Indies and claiming any uncharted areas for the United Provinces, which led to several significant expeditions which led to the creation of the province of New Netherland.
In 1609, the VOC commissioned English explorer Henry Hudson who, in an attempt to find the so-called northwest passage to the Indies, discovered and claimed for the VOC parts of the present-day United States and Canada. In the belief that it was the best route to explore, Hudson entered the Upper New York Bay sailing up the river which now bears his name. In 1614, Adriaen Block led an expedition to the lower Hudson in the "Tyger", and then explored the East River aboard the "Onrust", becoming the first known European to navigate the Hellegat enter Long Island Sound. Block Island and its sound were named after him. Upon returning, Block compiled a map, the first to apply the name "New Netherland" to the area between English Virginia and French Canada, where he was later granted exclusive trading rights by the Dutch government.
After some early trading expeditions, the first Dutch settlement in the Americas was founded in 1615: Fort Nassau, on Castle Island in the Hudson, near present-day Albany. The settlement served mostly as a factorij for fur trade with the natives and was later replaced by Fort Orange. Both forts were named in honor of the House of Orange-Nassau.
In 1621, a new company was established with a trading monopoly in the Americas and West Africa: the Dutch West India Company ("Westindische Compagnie" or WIC). The WIC sought recognition for the area in the New World – which had been called New Netherland – as a province, which was granted in 1623. That year, another Fort Nassau was built on the Delaware River near Gloucester City, New Jersey.
In 1624, the first colonists, mostly Walloons and company-owned slaves, arrived in the new province, landing at Governor's Island and Initially were dispersed to Fort Orange, Fort Wilhelmus and Kievets Hoek. In 1626, Director of the WIC Peter Minuit purchased the island of Manhattan from the Lenape and started the construction of Fort Amsterdam, which grew to become the main port and capital, New Amsterdam The colony expanded to outlying areas at Pavonia, Brooklyn, Bronx, and Long Island.
On the Connecticut River, Fort Huys de Goede Hoop was completed in 1633 at present day Hartford. By 1636, the English from Newtown (now Cambridge, Massachusetts) settled on the north side of the Little River. In the Treaty of Hartford, the border of New Netherland was retracted to western Connecticut and by 1653, the English had overtaken the Dutch trading post.
Expansion along the Delaware River beyond Fort Nassau did not begin until the 1650s, after the takeover of the colony of New Sweden, which had been established at Fort Christina in 1638. Settlements at Fort Nassau and the short-lived Fort Beversreede were abandoned and consolidated at Fort Casimir in 1655. Fort Christina, at today's Wilmington, was renamed Fort Altena.
Not all of the inhabitants of province were ethnically Dutch, but came from a variety of other European countries as well as African, originally brought as slaves. Many New Netherlanders were Walloons, Huguenots, Germans, Scandinavian and English relocated from New England.
In 1664, the English naval expedition ordered by the Prince James, Duke of York and of Albany (later King James II & VII) sailed in the harbor at New Amsterdam, threatening to attack. Being greatly outnumbered, Director-General Peter Stuyvesant surrendered after negotiating favorable articles of capitulation. The province was renamed New York (from James's English title). Fort Orange was renamed Fort Albany (from James's Scottish title). The region between the lower Hudson and the Delaware was deeded to proprietors and called New Jersey.
The loss of New Netherland led to the Second Anglo–Dutch War during 1665–1667. This conflict ended with the Treaty of Breda in which the Dutch gave up their claim to New Netherland in exchange for Suriname.
From 1673 to 1674, the territories were once again briefly captured by the Dutch in the Third Anglo–Dutch War, only to be returned to England at the Treaty of Westminster. In 1674, Dutch navy captain Jurriaen Aernoutsz also briefly captured two forts in the French colony of Acadia, which he claimed as the Dutch territory of New Holland. However, Aernoutsz's appointed administrator, John Rhoades, quickly lost control of the territory after Aernoutsz himself left for Curaçao to seek out new settlers, and with effective control of Acadia remaining in the hands of France, Dutch sovereignty existed only on paper until the Netherlands surrendered their claim in the Treaties of Nijmegen.
South America.
Brazil.
From 1630 onward, the Dutch Republic gained control of a large portion of northeastern Brazil from the Portuguese. The Dutch West India Company set up their headquarters in Recife. The governor, Johan Maurits, invited artists and scientists to the colony to help promote migration to the new South-American colony. However, the Portuguese fought back and won a significant victory at the Second Battle of Guararapes in 1649. On January 26, 1654, the Dutch Republic surrendered and signed a capitulation returning control of all the northeastern Brazil colony to the Portuguese. After the end of the First Anglo–Dutch War in May 1654, the Dutch Republic demanded that New Holland (Dutch Brazil) be returned to Dutch control. Under threat of an occupation of Lisbon and a reoccupation of northeastern Brazil, the Portuguese, already involved in a war against Spain, acceded to the Dutch demand. However, the new Dutch political leader Johan de Witt deemed commerce more important than territory, and saw to it that New Holland was sold back to Portugal on August 6, 1661 through the Treaty of the Hague.
Chile.
In 1600, the Chilean city of Valdivia was conquered by the Dutch pirate Sebastian de Cordes. He left the city after a few months. In 1642, the VOC and WIC sent a fleet to Chile to conquer Valdivia and its supposed gold mines. This expedition was led by Hendrik Brouwer, a Dutch admiral. In 1643, Brouwer died before effecting the conquest of the Chiloé Archipelago; his lieutenant Elias Herkmans succeeded in capturing the ruins of the city, which he refortified and named Brouwershaven. Finding no gold but many hostile natives, the Dutch soon abandoned the outpost.
The second emigration from the Netherlands to Chile was in 1895. Under the so-called "Inspector General of Colonization and Immigration Chilean", a dozen Dutch families settled between 1895 and 1897 in Chiloé, particularly in Mechaico, Huillinco and Chacao. In the same period Hageman Egbert arrived in Chile. with his family, 14 April 1896, settling in Rio Gato, near Puerto Montt. In addition, family Wennekool which inaugurated the Dutch colonization of Villarrica.
In the early twentieth century, there arrived in Chile a large group of Dutch people from South Africa, which had been established where they worked mainly in construction of the railway. When the Boer War, which would eventually lead to the British annexation of both republics in 1902. These emigrants decided to emigrate to Chile with the help of the Chilean government.
On 4 May 1903, a group of over 200 Dutch emigrants sailed on the steamship "Oropesa" shipping company "Pacific Steam Navigation Company, from La Rochelle (La Pallice) in France. The majority of migrants were born in the Netherlands: 35% was from North Holland and South Holland, 13% of North Brabant, 9% of Zeeland and equal number of Gelderland.
On June 5, arrived by train to their final destination, the city of Pitrufquén, located south of Temuco, near the hamlet of Donguil. Another group of Dutchmen arrived shortly after to Talcahuano, in the "Oravi" and the "Orissa". The Netherlands colony in Donguil was christened "New Transvaal Colony. There were established more than 500 families in order to start a new life. Between 7 February 1907 and February 18, 1909 above the last group of families Boers.
It is currently estimated at about 50,000 descendants of Dutch, mostly located in Malleco, Gorbea, Pitrufquén, Faja Maisan and around Temuco and Osorno.
Guyana.
The Dutch West Indian Company built a fort in 1616 on the Essequibo River. The Dutch traded with the Indian peoples and, as in Suriname, established sugar plantations worked by African slaves. While the coast remained under Dutch control, the English established plantations west of the Suriname River. Conflict between the two countries meant parts of the region changed hands a number of times, but by 1796 Britain had control of the region. The Netherlands ceded the colonies of Essequibo, Demerara, and Berbice to Britain in 1814.
Suriname.
The European colony in Suriname was founded in the 1650s by Lord Francis Willoughby, the British governor of Barbados. This colony was captured by the Dutch under Abraham Crijnsen during the Second Anglo–Dutch War. On July 31, 1667, under the Treaty of Breda the Dutch offered New Netherland (including New Amsterdam, modern-day New York City) in exchange for their sugar factories on the coast of Suriname. In 1683 Suriname was sold to the Dutch West India Company. The colony developed an agricultural economy based on African slavery. England controlled Suriname during the Napoleonic Wars from 1799 until 1816, when it was returned to the Dutch. The Netherlands abolished slavery in 1863 and imported indentured labor from the British Indian colonies and from the Dutch East Indies to keep the economy going. Internal self governance was granted in 1954 and full independence in 1975. The prospect of independence prompted many to migrate to the Netherlands, especially from the large Hindustani minority. Political instability and economic decline after independence resulted in even more migration to the Netherlands and also to the USA. The Surinamese community in the Netherlands is now almost as large as the population in the country itself (about 450,000).

</doc>
<doc id="52483" url="http://en.wikipedia.org/wiki?curid=52483" title="Electronic mailing list">
Electronic mailing list

An electronic mailing list or email list is a special use of email that allows for widespread distribution of information to many Internet users. It is similar to a traditional mailing list — a list of names and addresses — as might be kept by an organization for sending publications to its members or customers, but typically refers to four things:
How automated electronic mailing lists work.
Electronic mailing lists usually are fully or partially automated through the use of special mailing list software and a reflector address that are set up on a server capable of receiving email. Incoming messages sent to the reflector address are processed by the software, and, depending on their content, are acted upon internally (in the case of messages containing commands directed at the software itself) or are distributed to all email addresses subscribed to the mailing list. Depending on the software, additional addresses may be set up for the purpose of sending commands.
Many electronic mailing list servers have a special email address in which subscribers (or those who want to be subscribers) may send commands to the server to perform such tasks as subscribing and unsubscribing, temporarily halting the sending of messages to them, or changing available preferences. The common format for sending these commands is to send an email that contains simply, the command followed by the name of the electronic mailing list the command pertains to. Examples: "subscribe anylist" or "subscribe anylist John Doe". Some list servers also allow people to subscribe, unsubscribe, and change preferences through a web-based interface.
Electronic mailing list servers may be set to forward messages to subscribers of a particular mailing list either individually as they are received by the list server, or in digest form in which all messages received on a particular day by the list server are combined into one email that is sent once per day to subscribers. Some mailing lists allow individual subscribers to decide how they prefer to receive messages from the list server (individual or digest).
Types.
Announcement list.
One type of electronic mailing list is an "announcement list", which is used primarily as a one-way conduit of information and may only be "posted to" by selected people. This may also be referred to by the term "newsletter". Newsletter and promotional emailing lists are employed in various sectors as parts of direct marketing campaigns.
Discussion list.
Another type of electronic mailing list is a "discussion list", in which any subscriber may post. On a discussion list, a subscriber uses the mailing list to send messages to all the other subscribers, who may answer in similar fashion. Thus, actual discussion and information exchanges can happen. Mailing lists of this type are usually topic-oriented (for example, politics, scientific discussion, health problems, joke contests), and the topic may range from extremely narrow to "whatever you think could interest us". In this they are similar to Usenet newsgroups, another form of discussion group that may have an aversion to off-topic messages.
List security.
On both discussion lists and newsletter lists precautions are taken to avoid spamming.
Discussion lists often require every message to be approved by a moderator before being sent to the rest of the subscribers (moderated lists), although higher-traffic lists typically only moderate messages from new subscribers. Companies sending out promotional newsletters have the option of working with whitelist mail distributors, which agree to standards and high fines from ISPs should any of the opt-in subscribers complain. In exchange for their compliance and agreement to prohibitive fines, the emails sent by whitelisted companies are not blocked by spam filters, which often can reroute these legitimate, non-spam emails.
Subscription.
Some mailing lists are open to anyone who wants to join them, while others require an approval from the list owner before one may join. Joining a mailing list is called "subscribing" and leaving a list is called "unsubscribing".
Archives.
A mailing list archive is a collection of past messages from one or more electronic mailing lists. Such archives often include searching and indexing functionality. Many archives are directly associated with the mailing list, but some organizations, such as Gmane, collect archives from multiple mailing lists hosted at different organizations; thus, one message sent to one popular mailing list may end up in many different archives. Gmane had archives of more than 9000 mailing lists as of 16 January 2007. Some popular free software programs for collecting mailing list archives are Hypermail, MHonArc, and FUDforum.

</doc>
<doc id="52484" url="http://en.wikipedia.org/wiki?curid=52484" title="Danish colonization of the Americas">
Danish colonization of the Americas

Denmark and the former political union of Denmark–Norway had a colonial empire from the 17th through the 20th centuries, large portions of which were found in the Americas. Denmark and Norway in one form or another also maintained land claims in Greenland since the 13th century.
Greenland.
Greenland, which had been settled by the Norsemen in the 980s, submitted to Norwegian rule in 1261. Norway entered the Kalmar Union with Denmark and Sweden in 1397 and its overseas territories including Greenland became subject to the king in Copenhagen. Scandinavian settlement in Greenland declined over the years and the last written record is a marriage recorded in 1408, although the Norwegian claims to the land remained. Following the establishment of an independent Sweden, Norway and Denmark were reorganized into a polity now known as Denmark–Norway in 1536 and the nominal Norwegian sovereignty over Greenland was taken up by the new kingdom. Despite the decline of European settlement and the loss of contact, Denmark–Norway continued to maintain its claim to lordship of Greenland: in the 1660s, a polar bear was added to the royal coat of arms. Around this same time Dano-Norwegian ships, joined by ships from various other European countries, began journeying to Greenland to hunt bowhead whales, though no formal recolonization was attempted. 
In 1721, Lutheran minister Hans Egede and his Bergen Greenland Company received a royal charter from King Frederick IV granting them broad authority over Greenland and commissioning them to seek out the old Norse colony and spread the Reformation among its inhabitants, who were presumed to still be Catholic or to have reverted to paganism. Egede led three boats to Baal's River (the modern Nuup Kangerlua) and established Hope Colony on Kangeq with his family and a few dozen colonists. Finding no Norse survivors, he started a mission among the Inuit and baptized the first child converts in 1724. Meanwhile, his settlers had been ravaged by scurvy and the Dutch attacked and burnt a whaling station erected on Nipisat. The Bergen company went bankrupt in 1727. King Frederick attempted to replace it with a royal colony by sending Major Claus Paarss and several dozen soldiers and convicts to erect a fortress for the colony in 1728 but this new settlement of Good Hope (Godthaab) failed due to mutiny and scurvy and the retinue was recalled in 1730.
Three Moravian missionaries under Matthias Stach arrived in 1733 and began the first of a series of mission stations at Neu-Herrnhut (which later developed into the modern capital Nuuk), but a returning Inuit child brought smallpox from Denmark and a large proportion of the native population died over the next few years. The death of Egede's wife prompted his return to Denmark, with his son Paul left in charge of the settlement. The Danish merchant Jacob Severin was granted authority over the colony from 1734 to 1740, which was extended until 1749, assisted by royal patronage and Moravian sponsorship of some of Egede's missionary activities. He was succeeded by the General Trade Company ("Det almindelige Handelskompagni"). Both were granted armed ships and full monopolies over trade around their settlements, to prevent better-armed, lower-priced, and better-quality Dutch goods from bankrupting the enterprise. The ranged nature of their monopolies spurred them to found new settlements: Christianshaab (1734), Jakobshavn (1741), Frederikshaab (1742), Claushavn (1752), Fiskenæsset (1754), Ritenbenck and Egedesminde and Sukkertoppen (1755), Holsteinsborg (1756), Umanak (1758), Upernavik (1771), Godhavn (1773), and Julianehaab (1774). The GTC folded in 1774 and was replaced by the Royal Greenland Trade Department ("Kongelige Grønlandske Handel", KGH), which recognized that the island possessed neither fertile farmland nor easily accessible mineral wealth and that income would be dependent on the whaling and seal-hunting trade with the native Inuit. An early attempt to man a government-run Scandinavian whaling fleet was aborted and instead the KGH's Instruction of 1782 banned further attempts to urbanize the Inuit or alter their traditional way of life through improved employment opportunities or sales of luxury items. One effect was that construction of new settlements was effectively suspended after Nennortalik (1797) for a century until the establishment of Ammassalik on the eastern shore in 1894. The 1782 Instructions also established separate governing councils for North and South Greenland.
Danish intervention on France's behalf during the Napoleonic Wars ended with the severing of Denmark-Norway under the 1814 Treaty of Kiel, which granted mainland Norway to Sweden but retained the former Norwegian colonies under the Danish crown. Repeated inquiries into the Greenlandic trade and the end of absolutism in Denmark did not end the KGH's monopolies. In 1857, the administrators did set up "parsissaets", local councils conducted in Kalaallisut with minor control over spending decisions at each station. In 1912, Royal Greenland's independence was ended and its operations were folded into the Ministry of the Interior.
Arctic exploration placed claims of Danish sovereignty over the whole of Greenland in doubt: the principle of "terra nullius" seemed to leave huge tracts of the territory available to new entrants. Denmark responded by slowly acquiring diplomatic agreements recognizing its sovereignty from the parties involved, beginning with the treaty selling the Danish Virgin Islands to the United States in 1917. Norway – which had become independent of Sweden in 1905 – eventually protested and claimed Erik the Red's Land in eastern Greenland in 1931. The Permanent Court of International Justice ruled against Norway two years later, albeit on questionable grounds.
The fall of Denmark in early 1940 increased the power and importance of the governors greatly, but by 1941 the island had become an American protectorate. Following the war, the former corporate policy was discontinued: the North and South Greenland colonies were united and the RGTD's monopoly officially ended. In 1953, Greenland's colonial status was ended and it was made an integral part of the Kingdom of Denmark with representation in the Folketing. In 1979, the Folketing granted the island home rule and, in 2009, all matters other than defense and foreign policy were transferred to the regional parliament.
West Indies.
Explorers (mainly Norwegians), scientists, merchants (mainly Danish) and settlers from Denmark–Norway took possession of the Danish West Indies (present-day U.S. Virgin Islands) in the late 17th and early 18th centuries. 
Denmark started colonies on St. Thomas in 1665 and St. John in 1683 (though control of the latter was disputed with Great Britain until 1718), and purchased St. Croix from France in 1733. During the 18th century, the Virgin Islands in the Caribbean Sea were divided into two territorial units, one British and the other Dano-Norwegian. The Dano-Norwegian islands were run by the Danish West India and Guinea Company until 1755, when the Dano-Norwegian king bought them out. 
Sugar cane, produced by slave labor, drove the islands' economy during the 18th and early 19th centuries. A triangular trade existed with Danish manufactures buying African slaves which in turn were traded for West Indian sugar meant for Denmark. Although the slave trade was abolished in 1803, slavery itself was not abolished until 1848, after several mass slave escapes to the free British islands and an ensuing slave protest. The Danish Virgin Islands were also used as a base for pirates. The British and Dutch settlers became the largest non-slave groups on the islands. Their languages predominated, so much so that the Danish government, in 1839, declared that slave children must attend school in the English language. The colony reached its largest population in the 1840–50s, after which an economic downturn increased emigration and the population dropped, a trend that continued until after the islands' purchase by the United States. The Danish West Indies had 34,000 inhabitants in 1880.
In 1868, the islanders voted to sell the colony to the United States but their offer was rebuffed. In 1902, Denmark rejected an American purchase offer. In 1917, the United States purchased the islands, which had been in economic decline since the abolition of slavery.

</doc>
<doc id="52486" url="http://en.wikipedia.org/wiki?curid=52486" title="History of Suriname">
History of Suriname

The history of Suriname dates from 3000 BC when Native Americans first inhabited the area. Present-day Suriname was the home to many distinct indigenous cultures. The largest tribes were the Arawaks, a nomadic coastal tribe that lived from hunting and fishing, and the Caribs. The Arawaks were the first inhabitants of Suriname; later, the Caribs arrived, and conquered the Arawaks using their sailing ships. They settled in Galibi ("Kupali Yumï", meaning "tree of the forefathers") on the mouth of the Marowijne river. While the larger Arawak and Carib tribes lived off the coast and savanna, smaller groups of indigenous peoples lived in the rainforest inland, such as the Akurio, Trió, Warrau, and Wayana.
Dutch colonization.
The first Europeans who came to Suriname were Dutch traders who visited the area along with other parts of South America's 'Wild Coast.' The first attempts to settle the area by Europeans was in 1630, when English settlers led by Captain Marshall attempted to found a colony. They cultivated crops of tobacco, but the venture failed financially.
In 1650 Lord Willoughby, the governor of Barbados, furnished out a vessel to settle a colony in Suriname. At his own cost he equipped a ship of 20 guns, and two smaller vessels with things necessary for the support of the plantation. Major Anthony Rowse settled there in his name. Two years later, for the better settling of the colony, he went in person, fortified and furnished it with things requisite for defence and trade. 'Willoughbyland' consisted of around 30000 acre and a fort. In 1663 most of the work on the ca. 50 plantations was done by native Indians and 3,000 African slaves. There were around 1,000 whites there, joined by Brazilian Jews, attracted by religious freedom which was granted to all the settlers by the English.
The settlement was invaded by seven Dutch ships (from the Zeeland region), led by Abraham Crijnssen, on 26 February 1667. Fort Willoughby was captured the next day after a three-hour fight and renamed Fort Zeelandia. On 31 July 1667, the English and Dutch signed the Treaty of Breda, in which for the time being the status quo was respected: the Dutch could keep occupying Suriname and the British the formerly Dutch colony New Amsterdam (modern-day New York). Willoughbyland was renamed Suriname. This arrangement was made official in the Treaty of Westminster of 1674, after the British had regained and again lost Suriname in 1667 and the Dutch regained the colony in 1668. In 1683 the Society of Suriname was set up, modelled on the ideas of Jean-Baptiste Colbert to profit from the management and defence of the Dutch Republic's colony. It had three participants, with equal shares in the society's responsibilities and profits—the city of Amsterdam, the family Van Aerssen van Sommelsdijck, and the Dutch West India Company. The Van Aerssen family only managed to sell its share in 1770. The Society came to an end in 1795 when this kind of trade and business was no longer seen as acceptable.
Slavery and emancipation.
In South America, slavery was the norm. The native people proved to be in limited supply and consequently the Atlantic slave trade supplied the workforce for the plantations. The plantations were producing sugar, coffee, cocoa, cotton which were exported for the Amsterdam market. In 1713 for instance most of the work on the 200 plantations was done by 13,000 African slaves. Their treatment was bad, and slaves periodically escaped to the jungle from the start. These "Maroons" (also known as "Djukas" or "Bakabusi Nengre") attacked the plantations in order to acquire goods that were in short supply and to acquire women. Notable leaders of the Surinam Maroons were Alabi, Boni, Joli-coeur and Broos (Captain Broos). In the 18th century, three of the Maroon people signed a peace treaty, similar to the peace treaty ending the First Maroon War in Jamaica, whereby they were recognised as free people and received a yearly tribute that provided them with the goods they used to "liberate" from the plantations. A contemporary description of the war between the Maroons and the plantation owners in Suriname can be found in "Narrative of a Five Years Expedition Against the Revolted Negroes of Surinam" by John Gabriel Stedman.
Suriname was occupied by the British in 1799, after the Netherlands were incorporated by France, and was returned to the Dutch in 1816, after the defeat of Napoleon. The Dutch abolished slavery only in 1863, although the British had already abolished it during their short rule. The slaves were, however, not released until 1873; up to that date they conducted obligatory but paid work at the plantations. In the meantime, many more workers had been imported from the Dutch East Indies, mostly Chinese inhabitants of that colony, creating a Chinese Surinamese population. From 1873 to 1916, many laborers were imported from India, creating the Indo-Surinamese. After 1916, many laborers were again imported from the Dutch East Indies, especially Java, creating the Javanese Surinamese.
Twentieth century.
In the 20th century, the natural resources of Suriname, rubber, gold and bauxite, were exploited. The US company Alcoa had a claim on a large area in Suriname where bauxite, from which aluminum can be made, was found. Given that the peace treaties with the Maroon people granted them title to the lands, there have been international court cases that negated the right of the Surinam government to grant these claims. On November 23, 1941, under an agreement with the Netherlands government-in-exile, the United States occupied Dutch Guiana to protect the bauxite mines.
Decolonization.
In 1945, the first full election was held, with the Netherlands providing aid in health matters.
In 1954, Suriname gained self-government, with the Netherlands retaining control of defence and foreign affairs.
Independence.
In 1973 the Dutch government started independence negotiations with the local government, led by the NPS (a largely Creole party), which was granted on November 25, 1975. The Dutch instituted an aid programme worth US$1.5 billion to last till 1985. The first President of the country was Johan Ferrier, with Henck Arron (leader of the NPS) as Prime Minister. Roughly a third of the population emigrated to the Netherlands prior to independence, fearing that the new country would not be viable. 
In 1980, the government of Henck Arron was overthrown in a military coup led by Sergeant-Major Desi Bouterse. President Ferrier refused to recognise the new government, appointing Henk Chin A Sen (of the Nationalist Republican Party). Another coup followed five months later, with the army replacing Ferrier with Chin A Sen. These developments were largely welcomed by a population that expected the new army-installed government to put an end to corruption and improve the standard of living. This was despite the fact that the new regime banned opposition parties and became increasingly dictatorial. The Dutch initially accepted the new government; however, relations between Suriname and the Netherlands collapsed when 15 members of the political opposition were killed by the army on December 8, 1982, in Fort Zeelandia. This event is also known as the "December killings" ("Decembermoorden" in Dutch). The Dutch and Americans cut off their aid in protest at the move.
In 1985, the ban on opposition parties was lifted, and work began on devising a new constitution. The following year saw the start of an anti-government rebellion of the Maroons in the interior, calling themselves the Jungle Commando and led by Ronnie Brunswijk. The Bouterse government violently tried to suppress the insurgency by burning villages and other similar means. Many Maroons fled to French Guiana.

</doc>
<doc id="52487" url="http://en.wikipedia.org/wiki?curid=52487" title="Ivan Pavlov">
Ivan Pavlov

Ivan Petrovich Pavlov (Russian: Ива́н Петро́вич Па́влов; ]; 26 September [O.S. 14 September] 1849 – 27 February 1936) was a Russian physiologist known primarily for his work in classical conditioning. From his childhood days Pavlov demonstrated intellectual brilliance along with an unusual energy which he named "the instinct for research". Inspired by the progressive ideas which D. I. Pisarev, the most eminent of the Russian literary critics of the 1860s and I. M. Sechenov, the father of Russian physiology, were spreading, Pavlov abandoned his religious career and decided to devote his life to science. In 1870 he enrolled in the physics and mathematics faculty at the University of Saint Petersburg to take the course in natural science. Ivan Pavlov devoted his life to the study of physiology and sciences, making several remarkable discoveries and ideas that were passed on from generation to generation. He won the Nobel Prize for Physiology or Medicine in 1904, becoming the first Russian Nobel laureate.
Early life and schooling.
Ivan Pavlov, the eldest of eleven children, was born in Ryazan (now the Central Federal District) of the Russian Empire. His father, Peter Dmitrievich Pavlov (1823–1899), was a village priest. His mother, Varvara Ivanovna Uspenskaya (1826–1890), was a devoted homemaker. As a child, Pavlov willingly participated in house duties such as doing the dishes and taking care of his siblings. He loved to garden, ride his bicycle, row, swim, and play gorodki; he devoted his summer vacations to these activities. Although able to read by the age of 7, Pavlov was seriously injured when he fell from a high wall onto stone pavement; he did not undergo formal schooling until he was 11 years old as a result of his injuries.
Pavlov attended and graduated from the Ryazaia Church School before entering the local theological seminary. However, in 1870, Pavlov left the seminary without graduating to attend the university at St. Petersburg where he enrolled in the physics and math department and took natural science courses. In his fourth year, his first research project on the physiology of the nerves of the pancreas won him a prestigious university award. In 1875, Pavlov completed his course with an outstanding record and received the degree of Candidate of Natural Sciences. However, impelled by his overwhelming interest in physiology, he decided to continue his studies and proceeded to the Academy of Medical Surgery. While at the Academy of Medical Surgery, Pavlov became an assistant to his former teacher, Tyson, but left the department when Tyson was replaced by another instructor.
After some time, Pavlov obtained a position as a laboratory assistant to Professor Ustimovich at the physiological department of the Veterinary Institute. For two years, Pavlov investigated the circulatory system for his medical dissertation. In 1878, Professor S.P. Botkin, a famous Russian clinician, invited the gifted young physiologist to work in the physiological laboratory as the clinic's chief. In 1879, Pavlov graduated from the Medical Military Academy with a gold medal award for his research work. After a competitive examination, Pavlov won a fellowship at the Academy for postgraduate work. The fellowship and his position as Director of the Physiological Laboratory at the clinic of the famous Russian clinician, S. P. Botkin enabled Pavlov to continue his research work. In 1883, he presented his doctor's thesis on the subject of "The centrifugal nerves of the heart" and posited the idea of "nervism" and the basic principles on the trophic function of the nervous system. Additionally, his collaboration with the Botkin clinic produced evidence of a basic pattern in the regulation of reflexes in the activity of circulatory organs.
Influences.
He was inspired to forsake his Orthodox Christian background and pursue a scientific career by D. I. Pisarev, a literary critique and natural science advocate of the time and I. M. Sechenov, a Russian physiologist, whom Pavlov described as 'The father of physiology'.
Career.
After completing his doctorate, Pavlov went to Germany where he studied in Leipzig with Carl Ludwig in the Heidenhain laboratories in Breslau. He remained there from 1884 to 1886. Heidenhain was studying digestion in dogs, using an exteriorized section of the stomach. However, Pavlov perfected the technique by overcoming the problem of maintaining the external nerve supply. The exteriorized section became known as the Heidenhain or Pavlov pouch. After two years (1884–1886), Pavlov returned from Germany to look for a new position. His application for the chair of physiology at the University of Saint Petersburg was rejected. Eventually, Pavlov was given the chair of pharmacology at Tomsk University and then at the University of Warsaw. However, he went to neither place. In 1890, he was appointed the role of professor of Pharmacology at the Military Medical Academy and occupied the position for 5 years. Pavlov was invited to the in 1891 to organize and direct the Department of Physiology. Over a 45 year period, under his direction it became one of the most important centers of physiological research. While Pavlov directed the Department of Physiology at the Institute, he also transferred to the chair of physiology at the Medical Military Academy. This change in positions at the Academy occurred in 1895. He headed the physiology department at the Academy continuously for three decades. Also, starting in 1901, Pavlov was nominated for the Nobel Prize in Physiology or Medicine for four successive years. However, he did not win because his nominations were not specific to any discovery and were based on a variety of laboratory findings. In 1904, Pavlov was awarded the Nobel laureate "in recognition of his work on the physiology of digestion, through which knowledge on vital aspects of the subject has been transformed and enlarged".
While at the Institute of Experimental Medicine he carried out his classical experiments on the digestive glands which is how he eventually won the Nobel prize mentioned above. Pavlov investigated the gastric function of dogs, and later, children, by externalizing a salivary gland so he could collect, measure, and analyze the saliva and what response it had to food under different conditions. He noticed that the dogs tended to salivate before food was actually delivered to their mouths, and set out to investigate this "psychic secretion", as he called it. Pavlov’s laboratory housed a full-scale kennel for the experimental animals. Pavlov was interested in observing their long-term physiological processes. This required keeping them alive and healthy in order to conduct chronic experiments, as he called them. These were experiments over time, designed to understand the normal functions of animals. This was a new kind of study, because previously experiments had been “acute,” meaning that the dog went through vivisection and was ultimately killed in the process.
A 1921 article by S. Morgulis in the journal "Science", came as a critique of Pavlov's work in that it addressed concerns about the environment in which these experiments had been performed. Based on a report from H. G. Wells, claiming that Pavlov grew potatoes and carrots in his lab, the article stated, "It is gratifying to be assured that Professor Pavlov is raising potatoes only as a pastime and still gives the best of his genius to scientific investigation". Also in 1921, Pavlov began holding laboratory meetings known as the ‘Wednesday meetings’ where he spoke bluntly on many topics, including his views on psychology. These meetings lasted until he died in 1936.
Pavlov was highly regarded by the Soviet government, and he was able to continue his research until he reached a considerable age. He was praised by Lenin. However, despite the praise from the Soviet Union government, the money that poured out to support his laboratory, and the honours he was given, Pavlov made no attempts to conceal the disapproval and contempt in which he held Soviet Communism. For example, in 1923 he claimed that he would not sacrifice even the hind leg of a frog to the type of social experiment that the regime was conducting in Russia. Also, in 1927, he wrote to Stalin protesting at what was being done to Russian intellectuals and saying he was ashamed to be a Russian. After the murder of Sergei Kirov in 1934, Pavlov wrote several letters to Molotov criticizing the mass persecutions which followed and asking for the reconsideration of cases pertaining to several people he knew personally.
Conscious until his very last moment, Pavlov asked one of his students to sit beside his bed and to record the circumstances of his dying. He wanted to create unique evidence of subjective experiences of this terminal phase of life. Pavlov died of double pneumonia at the age of 86. He was given a grandiose funeral, and his study and laboratory were preserved as a museum in his honour.
Marriage and family.
Ivan Pavlov married Seraphima Vasilievna Karchevskaya on 1 May 1881, whom he had met in 1878 or 1879 when she went to St. Petersburg to study at the Pedagogical Institute. Seraphima, called Sara for short, was born in 1855. In her later years, she suffered from ill health and died in 1947. The first nine years of their marriage were marred by financial problems; Pavlov and his wife often had to stay with others in order to have a home, and for a time, the two lived apart so that they could find hospitality. Although their poverty caused despair, material welfare was a secondary consideration. Sara's first pregnancy ended in a miscarriage. When she conceived again, the couple took precautions, and she safely bore their first child, a boy whom they named Mirchik. Because she adored Mirchik, Sara was profoundly depressed following his sudden death in childhood. The family were staying in a country home at the time of his death, which most likely resulted from some type of children's summer disease. Ivan and Sara eventually had four more children: Vladimir, Victor, Vsevolod, and Vera. Their youngest son, Vsevolod, died of pancreatic cancer in 1935, predeceasing his father by one year.
Reflex system research.
Pavlov contributed to many areas of physiology and neurological sciences. Most of his work involved research in temperament, conditioning and involuntary reflex actions.
Pavlov performed and directed experiments on digestion, eventually publishing "The Work of the Digestive Glands" in 1897, after 12 years of research. His experiments earned him the 1904 Nobel Prize in Physiology and Medicine. These experiments included surgically extracting portions of the digestive system from animals, severing nerve bundles to determine the effects, and implanting fistulas between digestive organs and an external pouch to examine the organ's contents. This research served as a base for broad research on the digestive system.
Further work on reflex actions involved involuntary reactions to stress and pain. Pavlov extended the definitions of the four temperament types under study at the time: phlegmatic, choleric, sanguine, and melancholic, updating the names to "the strong and impetuous type, the strong equilibrated and quiet type, the strong equilibrated and lively type, and the weak type." Pavlov and his researchers observed and began the study of transmarginal inhibition (TMI), the body's natural response of shutting down when exposed to overwhelming stress or pain by electric shock. This research showed how all temperament types responded to the stimuli the same way, but different temperaments move through the responses at different times. He commented "that the most basic inherited difference. .. was how soon they reached this shutdown point and that the quick-to-shut-down have a fundamentally different type of nervous system."
Legacy.
The concept for which Pavlov is famous is the "conditioned reflex" (or in his own words the "conditional reflex") he developed jointly with his assistant Ivan Filippovitch Tolochinov in 1901. He had come to learn this concept of conditioned reflex when examining the rates of salivations among dogs. Pavlov had learned that when a buzzer or metronome was sounded in subsequent time with food being presented to the dog in consecutive sequences, the dog would initially salivate when the food was presented. The dog would later come to associate the sound with the presentation of the food and salivate upon the presentation of that stimulus.
Tolochinov, whose own term for the phenomenon had been "reflex at a distance", communicated the results at the Congress of Natural Sciences in Helsinki in 1903. Later the same year Pavlov more fully explained the findings, at the 14th International Medical Congress in Madrid, where he read a paper titled "The Experimental Psychology and Psychopathology of Animals".
As Pavlov's work became known in the West, particularly through the writings of John B. Watson, the idea of "conditioning" as an automatic form of learning became a key concept in the developing specialism of comparative psychology, and the general approach to psychology that underlay it, behaviorism. Pavlov's work with classical conditioning was of huge influence to how humans perceive themselves, their behavior and learning processes and his studies of classical conditioning continue to be central to modern behavior therapy. The British philosopher Bertrand Russell was an enthusiastic advocate of the importance of Pavlov's work for philosophy of mind.
Pavlov's research on conditional reflexes greatly influenced not only science, but also popular culture. Pavlovian conditioning was a major theme in Aldous Huxley's dystopian novel, "Brave New World", and also to a large degree in Thomas Pynchon's "Gravity's Rainbow".
It is popularly believed that Pavlov always signaled the occurrence of food by ringing a bell. However, his writings record the use of a wide variety of stimuli, including electric shocks, whistles, metronomes, tuning forks, and a range of visual stimuli, in addition to the ring of a bell. In 1994, Catania cast doubt on whether Pavlov ever actually used a bell in his famous experiments. Littman tentatively attributed the popular imagery to Pavlov’s contemporaries Vladimir Mikhailovich Bekhterev and John B. Watson. Roger K. Thomas, of the University of Georgia, however, claimed to have found "three additional references to Pavlov's use of a bell that strongly challenge Littman's argument". In reply, Littman suggested that Catania's recollection, that Pavlov did not use a bell in research, was "convincing .. and correct".
In 1964 the eminent psychologist H. J. Eysenck reviewed Pavlov's "Lectures on Conditioned Reflexes" for the British Medical Journal: Volume I – "Twenty-five Years of Objective Study of the Higher Nervous Activity of Animals", Volume II – "Conditioned Reflexes and Psychiatry".
The Pavlov Institute of Physiology of the Russian Academy of Sciences was founded by Pavlov in 1925 and named after him following his death.
Further reading.
</dl>

</doc>
<doc id="52489" url="http://en.wikipedia.org/wiki?curid=52489" title="Pavlov">
Pavlov

Pavlov may refer to:

</doc>
<doc id="52491" url="http://en.wikipedia.org/wiki?curid=52491" title="Non-repudiation">
Non-repudiation

Non-repudiation refers to a state of affairs where the purported maker of a statement will not be able to successfully challenge the validity of the statement or contract. The term is often seen in a legal setting wherein the authenticity of a signature is being challenged. In such an instance, the authenticity is being "repudiated".
In security.
In a general sense "non-repudiation" involves associating actions or changes to a unique individual. For a secure area, for example, it may be desirable to implement a key card access system. Non-repudiation would be violated if it were not also a strictly enforced policy to prohibit sharing of the key cards and to immediately report lost or stolen cards. Otherwise determining who performed the action of opening the door cannot be trivially determined. Similarly, for computer accounts, the individual owner of the account must not allow others to use that account, especially, for instance, by giving away their account's password, and a policy should be implemented to enforce this. This prevents the owner of the account from denying actions performed by the account.
In digital security.
Regarding digital security, the cryptological meaning and application of non-repudiation shifts to mean:
Proof of data integrity is typically the easiest of these requirements to accomplish. A data hash, such as SHA2, is usually sufficient to establish that the likelihood of data being undetectably changed is extremely low. Even with this safeguard, it is still possible to tamper with data in transit, either through a man-in-the-middle attack or phishing. Due to this flaw, data integrity is best asserted when the recipient already possesses the necessary verification information.
The most common method of asserting the digital origin of data is through digital certificates, a form of public key infrastructure, to which digital signatures belong. Note that the public key scheme is not used for encryption in this form, confidentiality is not achieved by signing a message with a private key (since anyone can obtain the public key to reverse the signature). Verifying the digital origin means that the certified/signed data can be, with reasonable certainty, trusted to be from somebody who possesses the private key corresponding to the signing certificate. If the key is not properly safeguarded by the original owner, digital forgery can become a major concern.
Trusted third parties (TTPs).
The ways in which a party may attempt to repudiate a signature present a challenge to the trustworthiness of the signatures themselves. The standard approach to mitigating these risks is to involve a trusted third party.
The two most common TTPs are forensic analysts and notaries. A forensic analyst specializing in handwriting can look at a signature, compare it to a known valid signature, and make a reasonable assessment of the legitimacy of the first signature. A notary provides a witness whose job is to verify the identity of an individual by checking other credentials and affixing their certification that the party signing is who they claim to be. Further, a notary provides the extra benefit of maintaining independent logs of their transactions, complete with the type of credential checked and another signature that can independently be verified by the preceding forensic analyst. For this double security, notaries are the preferred form of verification.
On the digital side, the only TTP is the repository for public key certificates. This provides the recipient with the ability to verify the origin of an item even if no direct exchange of the public information has ever been made. The digital signature, however, is forensically identical in both legitimate and forged uses - if someone possesses the private key they can create a "real" signature. The protection of the private key is the idea behind the United States Department of Defense's Common Access Card (CAC), which never allows the key to leave the card and therefore necessitates the possession of the card in addition to the personal identification number (PIN) code necessary to unlock the card for permission to use it for encryption and digital signatures.

</doc>
<doc id="52495" url="http://en.wikipedia.org/wiki?curid=52495" title="Gor">
Gor

Gor is the parallel universe Counter-Earth setting for an extended series of novels by John Norman that combine philosophy, erotica, and science fiction. The series has been variously referred to by several names including: Chronicles of Counter-Earth, Tarl Cabot Saga, Chronicles of Gor, and Gorean Saga. The customs, terminology and imagery depicted in these books inspired a Gorean subculture, with lifestyle adherents online and off. The science fiction inspired books have taken in influences from alternate genres such as fantasy novels and other works. 
The Gorean fictional universe features numerous elements that are similar to 21st century American and European civilization, examples being in architecture and in language. However, the intervention of extraterrestrials from outside of the solar system have restricted the use of technology to significantly pre-industrial levels, and several other aspects of Gorean society are distinct. The first novel in the series, titled "Tarnsman of Gor", came out through Ballantine Books in 1966. That work received a loose film adaption in 1988 with the Fritz Kiersch directed movie "Gor".
Series description.
Setting.
Gor is described as a habitable planet in the Solar System that shares the same orbit as Earth, but it is linearly opposed to Earth and consequently always hidden by the Sun, making direct observation of it from Earth impossible. The flora, fauna, and customs of Gor are intricately detailed. John Norman—the pseudonym of Dr. John Lange, a professor of philosophy and a classical scholar—often delights in ethnography, populating his planet with the equivalents of Roman, Greek, Native American, Viking, and other cultures. In the novels these various population groups are transplants from Earth brought there by space-craft through the behind the scenes rulers of Gor, the Priest-Kings, an extraterrestrial species of insectoid appearance. The Gorean humans are permitted advanced architectural, agricultural and medical skills (including life extension), but are forced to remain primitive in the fields of transportation, communication and weaponry (at approximately the level of Classical Mediterranean civilization) due to restrictions on technology imposed by the Priest-Kings. This limitation is imposed to ensure the safety of both the Priest-Kings, as well as the other indigenous and transplanted beings on Gor, who would otherwise possibly come to harm due to humans' belligerent tendencies.
The planet Gor has lower gravity than Earth's (which allows for the existence of large flying creatures, and tall towers connected by aerial bridges in the cities), and would have an even lower gravity if not for the technology of the Priest-Kings. The known geography of Gor consists mainly of the western seaboard of a continent that runs from the Arctic in the north to south of the equator, with the Thassa ocean to the west, and the Voltai mountain range forming an eastern boundary at many latitudes. There are also offshore islands in the ocean, and some relatively sparsely settled plains to the east of the Voltai. The word "Gor" itself means "home stone" in the Gorean language (the native language of the "northern civilized cities of known Gor", and a widely spoken lingua franca in many other areas).
Plotlines.
Most of the novels in the series are action and sexual adventures, with many of the military engagements borrowing liberally from historic ones, such as the trireme battles of ancient Greece and the castle sieges of medieval Europe. Ar, the largest city in known Gor, has resemblances to the ancient city of Rome, and its land empire is opposed to the sea-power of the island of Cos.
The series is an overlapping of planetary romance and sword and planet. The first book, "Tarnsman of Gor", opens with scenes reminiscent of scenes in the first book of the Barsoom series by Edgar Rice Burroughs; both feature the protagonist narrating his adventures after being transported to another world. These parallels end after the first few books, when the stories of the books begin to be structured along a loose plot arc involving the struggles of the city-state of Ar and the island of Cos to control the Vosk river area, as well as the struggles at a higher level between non-human Priest-Kings and Kurii (another alien race) to control the solar system.
Most of the books are narrated by transplanted British professor Tarl Cabot, master swordsman, as he engages in adventures involving Priest-Kings, Kurii, and humans. Books 7, 11, 19, 21, 26, 27, 31 and parts of 32 are narrated by abducted Earth women who are made slaves. Books 14, 15, and 16 are narrated by male abductee Jason Marshall. Book 28 is narrated by an unknown Kur, but features Tarl Cabot. Book 30 and parts of 32 are narrated by three Gorean men: a mariner and a scribe and a merchant/slaver.
The series features several sentient alien races. The most important to the books are the insectoid Priest-Kings and the huge sharp-clawed predatory Kurii, both space-farers from foreign star systems. The Priest-Kings rule Gor as disinterested custodians, leaving humans to their own affairs as long as they abide by certain restrictions on technology. The Kurii are an aggressive, invasive race with advanced technology (but less so than that of the Priest-Kings) who wish to colonize Gor and Earth. The power of the Priest-Kings is diminished after the "Nest War" described in the third book, and the Priest-Kings and Kurii struggle against each other via their respective human agents and spies.
Early entries in the series were plot-driven space opera adventures, but later entries grew more philosophical and sexual. Many sub-plots run the course of several books and tie back to the main plot in later books. Some of these plots begin in the first book, but most are underway in the first ten books.
Historical influences.
Many historical cultures of Earth are reflected in the novels of Gor. Although the Greco-Roman is the most often noted of these, this is not the only society presented in some fashion on Gor. There are many similarities to real-life historical civilizations in various regions of Gor (explained in the books by early "voyages of acquisition" the Priest-Kings undertook to populate Gor with humans from different parts of Earth).
The majority of the area of the "northern civilized cities", as the Vosk river region in the temperate north of the continent is referred to, is reminiscent of ancient Greco-Roman city-states in many respects (aside from the delta city of Port Kar, which is a more anarchic and piratical version of Venice). The most common dating system is "Contasta Ar", or years since the founding of Ar (similar to the Roman dating system known as ab urbe condita), and the Viktel Aria road leading to Ar is analogous to the Appian way. In Torvaldsland, inhabitants are similar to Earth's Vikings. The "Red Savage" peoples of the Barrens are populated with a culture based upon Native Americans, especially the Sioux Nations. The "Wagon Peoples" are a blend of the Mongols and the Gauchos of South America. The Alars appear based on the Alans, barbarians who were later conquered by the Huns. The peoples of the Tahari desert correlate to the nomads of Arabia, the Gorean regions around Schendi to Amazon or Congo River valley populations. The peoples of far north Gor, or the "Red Hunters" as Norman sometimes referred to them, are clearly Inuit—in this case to the point of referring to them as such.
In an interview with the speculative fiction anthology "Polygraff", John Norman spoke at length about the creation of the Gor universe and his influences.
"The Counter-Earth, or "Antichthon," is from Greek cosmology. Speculation on such a world, you see, is ancient. One of the premises of the Gorean series is that a race of aliens, whom we might speak of as the Priest-Kings, have a technology at their disposal compared to which ours would be something like that in the Bronze Age." 
"I think, pretty clearly, the three major influences on my work are Homer, Freud, and Nietzsche. Interestingly, however obvious this influence might be, few, if any, critics, commentators, or such, have called attention to it."
In the same interview, he said "one of the pleasures of writing science fiction is the development of, and characterization of, alien life forms."
Criticism.
The "Gor" novels have been criticized for their focus on relationships between dominant men and submissive women, the latter often in positions of slavery. "The Encyclopedia of Fantasy" says, "later volumes degenerate into extremely sexist, sadomasochistic pornography involving the ritual humiliation of women, and as a result have caused widespread offence." Science fiction/fantasy author Michael Moorcock has suggested that the "Gor" novels should be placed on the top shelves of bookstores, saying, "I’m not for censorship but I am for strategies which marginalize stuff that works to objectify women and suggests women enjoy being beaten."
Publication.
DAW Books, which published the Gor series from the 8th volume ("Hunters of Gor") through the 25th volume ("Magicians of Gor"), subsequently decided to cease publication of the books, citing low sales; Norman attributes the decision to feminist influences, saying in 1996:
"Tarnsman of Gor" was published in late 1966. It has been reprinted 22 times... I have recently signed contracts for fresh French and German sales, and have recently been published for the first time in Czechoslovakia. There have been recent Spanish and Italian sales. There's no evidence that my books no longer sell... After DAW refused to buy any more Gor books, I sold a three-part Telnarian series to Brian Thomsen of Warner Books. The first book, "The Chieftain", had a 67 percent sell-through. The second, "The Captain", had a 91 percent sell-through, which is the sort of thing that would make Stephen King rush over to shake your hand... Brian Thomsen, my Warner editor for the Telnarian series... was replaced by an editor from one of the blacklisting presses, one that "explicitly" informed my agent they would not consider anything by John Norman. That new editor canceled the series despite its success and without waiting to see how the third book, "The King", would do. That way things are made nicely clear...
"Unfortunately for me, only about seven or eight publishing houses maintain a mass-market paperback line in science fiction and fantasy; this small, closely-knit group effectively controls the market. With such a group, a blacklist need not be an explicit, formal written or oral agreement subscribed to by a gathered cabal pledged to secrecy. It is an understanding that a certain individual is to be ostracized, excluded, methodologically overlooked or such."
All of John Norman's books are now published by E-Reads as ebooks and print copies. According to their website, "they are among E-Reads’ biggest sellers".
Adaptations.
Two films have been made, "Gor" and "Outlaw of Gor" (also known as "Outlaw"); the latter appeared on "Mystery Science Theater 3000".
While not officially connected to John Norman's work, "Fencer of Minerva" is a Japanese animated series containing many of the elements and ideas discussed in Gorean Philosophy.
During the mid-1990s an attempt was made to publish an authorized graphic novel adaptation of the Gor series under Vision Entertainment. The project collapsed under a combination of financial issues and the nature of the imagery, which violated Canadian law, where the printer was located.

</doc>
<doc id="52497" url="http://en.wikipedia.org/wiki?curid=52497" title="Nobel Prize in Physics">
Nobel Prize in Physics

The Nobel Prize in Physics (Swedish: "Nobelpriset i fysik") is a yearly award given by the Royal Swedish Academy of Sciences for those who conferred the most outstanding contributions for mankind in the field of physics. It is one of the five Nobel Prizes established by the will of Alfred Nobel in 1895 and awarded since 1901; the others being the Nobel Prize in Chemistry, Nobel Prize in Literature, Nobel Peace Prize, and Nobel Prize in Physiology or Medicine.
The first Nobel Prize in Physics was awarded to a German physicist Wilhelm Conrad Röntgen in recognition of the extraordinary services he has rendered by the discovery of the remarkable rays (or x-rays). This award is administered by the Nobel Foundation and widely regarded as the most prestigious award that a scientist can receive in physics. It is presented in Stockholm at an annual ceremony on December 10, the anniversary of Nobel's death. Till 2014, a total of 198 individuals have been awarded the prize.
Background.
Alfred Nobel, in his last will and testament, stated that his wealth be used to create a series of prizes for those who confer the "greatest benefit on mankind" in the fields of physics, chemistry, peace, physiology or medicine, and literature. Though Nobel wrote several wills during his lifetime, the last one was written a year before he died was and signed at the Swedish-Norwegian Club in Paris on 27 November 1895. Nobel bequeathed 94% of his total assets, 31 million Swedish "kronor" (US$186 million in 2008), to establish and endow the five Nobel Prizes. Due to the level of skepticism surrounding the will it was not until April 26, 1897 that it was approved by the Storting (Norwegian Parliament). The executors of his will were Ragnar Sohlman and Rudolf Lilljequist, who formed the Nobel Foundation to take care of Nobel's fortune and organise the prizes.
The members of the Norwegian Nobel Committee who were to award the Peace Prize were appointed shortly after the will was approved. The prize-awarding organisations followed: the Karolinska Institutet on June 7, the Swedish Academy on June 9, and the Royal Swedish Academy of Sciences on June 11. The Nobel Foundation then reached an agreement on guidelines for how the Nobel Prize should be awarded. In 1900, the Nobel Foundation's newly created statutes were promulgated by King Oscar II. According to Nobel's will, The Royal Swedish Academy of sciences were to award the Prize in Physics.
Nomination and selection.
A maximum of three Nobel laureates and two different works may be selected for the Nobel Prize in Physics.Compared with other Nobel Prizes, the nomination and selection process for the prize in Physics is long and rigorous. This is a key reason why it has grown in importance over the years to become the most important prize in Physics.
The Nobel laureates are selected by the Nobel Committee for Physics, a Nobel Committee that consists of five members elected by The Royal Swedish Academy of Sciences. In the first stage, several thousand people are asked to nominate candidates. These names are scrutinized and discussed by experts who narrow it to approximately fifteen names. The committee submits a report with recommendations to the appropriate institution.
The names of the nominees are never publicly announced, and neither are they told that they have been considered for the prize. Nomination records are sealed for fifty years. While posthumous nominations are not permitted, awards can be made if the individual died in the months between the decision of the prize committee (typically in October) and the ceremony in December. Prior to 1974, posthumous awards were permitted if the recipient had died after being nominated.
The rules for the Nobel Prize in Physics require that the significance of achievements being recognized has been "tested by time". In practice it means that the lag between the discovery and the award is typically on the order of 20 years and can be much longer. For example, half of the 1983 Nobel Prize in Physics was awarded to Subrahmanyan Chandrasekhar for his work on stellar structure and evolution that was done during the 1930s. As a downside of this approach, not all scientists live long enough for their work to be recognized. Some important scientific discoveries are never considered for a prize, as the discoverers may have died by the time the impact of their work is appreciated.
Prizes.
A Physics Nobel Prize laureate earns a gold medal, a diploma bearing a citation, and a sum of money. The amount of money awarded depends on the income of the Nobel Foundation that year. If a prize is awarded to more than one laureate, the money is either split evenly among them or, for three laureates, it may be divided into a half and two quarters.
Medals.
The Nobel Prize medals, minted by Myntverket in Sweden and the Mint of Norway since 1902, are registered trademarks of the Nobel Foundation. Each medal has an image of Alfred Nobel in left profile on the obverse. The Nobel Prize medals for Physics, Chemistry, Physiology or Medicine, and Literature have identical obverses, showing the image of Alfred Nobel and the years of his birth and death (1833–1896). Nobel's portrait also appears on the obverse of the Nobel Peace Prize medal and the Medal for the Prize in Economics, but with a slightly different design. The image on the reverse of a medal varies according to the institution awarding the prize. The reverse sides of the Nobel Prize medals for Chemistry and Physics share the same design of Nature, as a Goddess, whose veil is held up by the Genius of Science. These medals and the ones for Physiology/Medicine and Literature were designed by Erik Lindberg in 1902.
Diplomas.
Nobel laureates receive a diploma directly from the hands of the King of Sweden. Each diploma is uniquely designed by the prize-awarding institutions for the laureate that receives it. The diploma contains a picture and text which states the name of the laureate and normally a citation of why they received the prize.
Award money.
The laureate is also given a sum of money when they receive the Nobel Prize in the form of a document confirming the amount awarded; in 2009, the monetary award was 10 million SEK (US$1.4 million). Due to budget cuts, in 2012, the amount for each Nobel prize was 8 million SEK, or US$1.1 million. The amount may differ depending on how much money the Nobel Foundation can award that year. If there are two laureates in a particular category, the award grant is divided equally between the recipients. If there are three, the awarding committee has the option of dividing the grant equally, or awarding one-half to one recipient and one-quarter to each of the others.
Ceremony.
The committee and institution serving as the selection board for the prize typically announce the names of the laureates in October. The prize is then awarded at formal ceremonies held annually in Stockholm Concert Hall on 10 December, the anniversary of Nobel's death. The laureates receive a diploma, a medal and a document confirming the prize amount.

</doc>
<doc id="52501" url="http://en.wikipedia.org/wiki?curid=52501" title="Fork">
Fork

As a piece of cutlery or kitchenware, a fork is a tool consisting of a handle with several narrow tines on one end. The fork is a primarily western utensil, whereas in East Asia chopsticks have been more prevalent. Today, forks are increasingly available throughout East Asia. The usually metal utensil is used to lift food to the mouth or to hold ingredients in place while they are being cut by a knife. Food can be lifted either by spearing it on the tines, or by holding it on top of the tines, which are often curved slightly. A fork is shaped in the form of a trident but curved at the joint of the handle to the points.
Early history of forks is obscure, as a kitchen and dining utensil it's generally believed to have originated in the Roman Empire, or Ancient Greece. The personal table fork most likely originated in the Eastern Roman, or "Byzantine", Empire. Its use spread to what is now the Middle East during the first millennium CE and then spread into southern Europe during the second millennium. It did not become common in northern Europe until the 18th century and was not common in North America until the 19th century.
History.
The word "fork" comes from the Latin "furca", meaning "pitchfork". Some of the earliest known uses of forks with food occurred in Ancient Egypt, where large forks were used as cooking utensils. Bone forks had been found in the burial site of the Bronze Age Qijia culture (2400–1900 BC) as well as later Chinese dynasties' tombs. The Ancient Greeks used the fork as a serving utensil. The Greek name for fork is still used in some European languages, for instance in the Venetian, Greek, and Albanian languages.
In the Roman Empire, bronze and silver forks were used, indeed many examples are displayed in museums around Europe. The use varied according to local customs, social class and the nature of food, but forks of the earlier periods were mostly used as cooking and serving utensils. The personal table fork was most likely invented in the Eastern Roman ("Byzantine") Empire, where they were in common use by the 4th century (its origin may even go back to Ancient Greece, before the Roman period). By the 10th century, the table fork was in common use throughout the Middle East.
The first recorded introduction of the fork to Western Europe was by Theophano Sklereina, the Byzantine wife of Holy Roman Emperor Otto II, who nonchalantly wielded one at an Imperial banquet in AD 972, astonishing her Western hosts. By the 11th century, the table fork had become increasingly prevalent in the Italian peninsula. It gained a following in Italy before any other Western European region because of historical ties with Byzantium, and it continued to gain popularity due to the increased presence of early pasta in the Italian diet. At first, pasta was consumed by using a long wooden spike, but this eventually evolved into three spikes because of how much easier it was to gather the noodles. In Italy, it became commonplace by the 14th century, almost universally used by merchant and upper classes by the year 1600. It was proper for a guest to arrive with his own fork and spoon enclosed in a box called a "cadena"; this usage was introduced to the French court with Catherine de' Medici's entourage.
In Portugal, forks began being used with Infanta Beatrice, Duchess of Viseu, king Manuel I of Portugal's mother. That happened around 1450. Still forks were not commonly used in Western Europe until the 16th century when they became part of the etiquette in Italy. It had also gained some currency in Spain by this time, and its use gradually spread to France. Even at that, though, most of Europe did not adopt use of the fork until the 18th century.
Long after the personal table fork had become commonplace in France, at the supper celebrating the marriage of the duc de Chartres to Louis XIV's natural daughter in 1692, the seating was described in the court memoirs of Saint-Simon: "King James having his Queen on his right hand and the King on his left, and each with their cadenas." In Perrault's contemporaneous fairy tale of "La Belle au bois dormant" (1697), each of the fairies invited for the christening is presented with a splendid "fork holder".
The fork's adoption in northern Europe was slower. Its use was first described in English by Thomas Coryat in a volume of writings on his Italian travels (1611), but for many years it was viewed as an unmanly Italian affectation. Some writers of the Roman Catholic Church expressly disapproved of its use, St. Peter Damian seeing it as "excessive delicacy": It was said that... "God in his wisdom has provided man with natural forks – his fingers. Therefore it is an insult to Him to substitute artificial metallic forks for them when eating." It was not until the 18th century that the fork became commonly used in Great Britain, although some sources say that forks were common in France, England and Sweden already by the early 17th century.
The fork did not become popular in North America until near the time of the American Revolution. The curved fork that is used in most parts of the world today was developed in Germany in the mid 18th century. The standard four-tine design became current in the early 19th century. The fork was very important in Germany because they believed that eating with fingers was very rude and disrespectful. The fork led to family dinners and sit-down meals, which is very important in their culture.
External links.
Listen to this article ()
This audio file was created from a revision of the "Fork" article dated 2006-05-10, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="52502" url="http://en.wikipedia.org/wiki?curid=52502" title="Nobel Prize in Physiology or Medicine">
Nobel Prize in Physiology or Medicine

The Nobel Prize in Physiology or Medicine (Swedish: "Nobelpriset i fysiologi eller medicin") administered by the Nobel Foundation, is awarded once a year for outstanding discoveries in the fields of life sciences and medicine. It is one of five Nobel Prizes established in 1895 by Swedish chemist Alfred Nobel, the inventor of dynamite, in his will. Nobel was personally interested in experimental physiology and wanted to establish a prize for progress through scientific discoveries in laboratories. The Nobel prize is presented to the recipient(s) at an annual ceremony on 10 December, the anniversary of Nobel's death, along with a diploma and a certificate for the monetary award. The front side of the medal provides the same profile of Alfred Nobel as depicted on the medals for Physics, Chemistry, and Literature; its reverse side is unique to this medal.
As of 2014, 105 Nobel Prizes in Physiology or Medicine have been awarded to 206 men and 11 women. The first Nobel Prize in Physiology or Medicine was awarded in 1901 to the German physiologist Emil Adolf von Behring, for his work on serum therapy and the development of a vaccine against diphtheria. The first woman to receive the Nobel Prize in Physiology or Medicine, Gerty Cori, received it in 1947 for her role in elucidating the metabolism of glucose, important in many aspects of medicine, including treatment of diabetes.
Some awards have been controversial. This includes one to António Egas Moniz in 1949 for the prefrontal leucotomy, bestowed despite protests from the medical establishment. Other controversies resulted from disagreements over who was included in the award. The 1952 prize to Selman Waksman was litigated in court, and half the patent rights awarded to his co-discoverer Albert Schatz who was not recognized by the prize. The 1962 prize awarded to James D. Watson, Francis Crick and Maurice Wilkins for their work on DNA structure and properties did not acknowledge the contributing work from others, such as Oswald Avery and Rosalind Franklin who had died by the time of the nomination. Since the Nobel Prize rules forbid nominations of the deceased, longevity is an asset, one prize being awarded as long as 50 years after the discovery. Also forbidden is awarding any one prize to more than three recipients, and since in the last half century there has been an increasing tendency for scientists to work as teams, this rule has resulted in controversial exclusions.
Background.
Alfred Nobel was born on 21 October 1833 in Stockholm, Sweden into a family of engineers. He was a chemist, engineer and inventor who amassed a fortune during his lifetime, most of it from his 355 inventions of which dynamite is the most famous. He was interested in experimental physiology and set up his own labs in France and Italy to conduct experiments in blood transfusions. Keeping abreast of scientific findings, he was generous in his donations to Ivan Pavlov's laboratory in Russia, and was optimistic about the progress resulting from scientific discoveries made in laboratories.
In 1888, Nobel was surprised to read his own obituary, titled "‘The merchant of death is dead’", in a French newspaper. As it happened, it was Nobel's brother Ludvig who had died, but Nobel, unhappy with the content of the obituary and concerned that his legacy would reflect poorly on him, was inspired to change his will. In his last will, Nobel requested that his money be used to create a series of prizes for those who confer the "greatest benefit on mankind" in physics, chemistry, peace, physiology or medicine, and literature. Though Nobel wrote several wills during his lifetime, the last was written a little over a year before he died at the age of 63. Because his will was contested, it was not approved by the Storting (Norwegian Parliament) until 26 April 1897.
After Nobel's death, the Nobel Foundation was set up to manage the assets of the bequest. In 1900, the Nobel Foundation's newly created statutes were promulgated by Swedish King Oscar II. According to Nobel's will, the Karolinska Institutet in Sweden, a medical school and research center, is responsible for the Prize in Physiology or Medicine. Today the prize is commonly referred to as the Nobel Prize in Medicine.
Nomination and selection.
It was important to Nobel that the prize be awarded for a "discovery" and that it was of "greatest benefit on mankind".
Per the provisions of the will, only select persons are eligible to nominate individuals for the award. These include members of academies around the world, professors of medicine in Sweden, Denmark, Norway, Iceland and Finland, as well as professors of selected universities and research institutions in other lands. Past Nobel laureates may also nominate. Until 1977, all professors of Karolinska Institutet together decided on the Nobel Prize in Physiology or Medicine. That year, changes in Swedish law forced the Institute to make any documents pertaining to the Nobel Prize public and it was considered necessary to establish a legally independent body for the Prize work. Therefore, the Nobel Assembly was constituted, consisting of 50 professors at Karolinska Institutet. It elects the Nobel Committee with 5 members who evaluate the nominees, the Secretary who is in charge of the organization, and each year 10 adjunct members to assist in the evaluation of candidates. In 1968, a provision was added that no more than three persons may share a Nobel prize.
True to its mandate, the Committee has selected researchers working in the basic sciences over those who have made applied contributions. Harvey Cushing, a pioneering American neurosurgeon who identified Cushing's syndrome never was awarded the prize, nor was Sigmund Freud, as his psychoanalysis lacks hypotheses that can be tested experimentally. The public expected Jonas Salk or Albert Sabin to receive the prize for their development of the polio vaccines, but instead the award went to John Enders, Thomas Weller, and Frederick Robbins whose basic discovery that the polio virus could reproduce in monkey cells in laboratory preparations was a fundamental finding that led to the elimination of the disease of polio.
Through the 1930s, there were frequent prize laureates in classical physiology, but after that the field began dissolving into specialties. The last classical physiology laureates were John Eccles, Alan Hodgkin and Andrew Huxley in 1963 for their findings regarding "unitary electrical events in the central and peripheral nervous system."
Prizes.
A Medicine or Physiology Nobel Prize laureate, earns a gold medal, a diploma bearing a citation, and a sum of money. These are awarded at the Nobel Banquet.
Medals.
The Nobel Prize medals, minted by Myntverket in Sweden are registered trademarks of the Nobel Foundation. Each medal features an image of Alfred Nobel in left profile on the obverse (front side of the medal). The Nobel Prize medals for Physics, Chemistry, Physiology or Medicine, and Literature have identical obverses, showing the image of Alfred Nobel and the years of his birth and death (1833–1896). Before 1980, the medals were made of 23K gold; since then the medals are of 18K green gold, plated with 23K gold.
The medal awarded by the Karolinska Institute displays an image of "the Genius of Medicine holding an open book in her lap, collecting the water pouring out from a rock in order to quench a sick girl's thirst." The medal is inscribed with words taken from Virgil's Aeneid and reads: "Inventas vitam juvat excoluisse per artes", which translates to "inventions enhance life which is beautified through art."
Diplomas.
Nobel laureates receive a Diploma directly from the King of Sweden. Each Diploma is uniquely designed by the prize-awarding institutions for the laureate that receives it. In the case of the Nobel Prize in Physiology or Medicine, that is the Nobel Assembly at Karolinska Institute. Well-known artists and calligraphers from Sweden are commissioned to create it. The Diploma contains a picture and text which states the name of the laureate and a citation as to why they received the prize.
Award money.
The amount of prize money fluctuates depending on how much money the Nobel Foundation can award that year, and is awarded in Swedish kronor (SEK). The first award in 1901 was for 150,782 kronor (7,872,648 kronor in 2009 value). In 2009, the prize money totaled 10,000,000 kronor. Due to budget cuts, in 2012, the amount for each Nobel prize was 8 million Swedish Krona, or US$1.1 million. If there are two laureates in a particular category, the award grant is divided equally between the recipients. If there are three, the awarding committee has the option of dividing the grant equally, or awarding one-half to one recipient and one-quarter to each of the others.
Ceremony and banquet.
The awards are bestowed at a gala ceremony followed by a banquet. The Nobel Banquet is an extravagant affair with the menu, planned months ahead of time, kept secret until the day of the event. The Nobel Foundation chooses the menu after tasting and testing selections submitted by selected chefs of international repute. Currently it is a three course dinner, although it was originally six courses when it began in 1901. Every Nobel Prize laureate is allowed to bring up to 16 guests, and Sweden's royal family is always there. Typically the Prime Minister and other members of the government attend as well as representatives of the Nobel family.
Laureates.
The first Nobel Prize in Physiology or Medicine was awarded in 1901 to the German physiologist Emil Adolf von Behring. Behring's discovery of serum therapy in the development of the diphtheria and tetanus vaccines put "in the hands of the physician a victorious weapon against illness and deaths". In 1902, the award went to Ronald Ross for his work on malaria, "by which he has shown how it enters the organism and thereby has laid the foundation for successful research on this disease and methods of combating it". He identified the mosquito as the transmitter of malaria, and worked tirelessly on measures to prevent malaria worldwide. The 1903 prize was awarded to Niels Ryberg Finsen, the first Danish laureate, "in recognition of his contribution to the treatment of diseases, especially lupus vulgaris, with concentrated light radiation, whereby he has opened a new avenue for medical science". He died within a year after receiving the prize at the age of 43.
Ivan Pavlov, whose work Nobel admired and supported, received the prize in 1904 for his work on the physiology of digestion.
Subsequently, those selecting the recipients have exercised wide latitude in determining what falls under the umbrella of Physiology or Medicine. The awarding of the prize in 1973 to Nikolaas Tinbergen, Konrad Lorenz and Karl von Frisch for their observations of animal behavioral patterns could be considered a prize in the behavioral sciences rather than medicine or physiology.
Tinbergen expressed surprise in his Nobel Prize acceptance speech at "the unconventional decision of the Nobel Foundation to award this year’s prize ‘for Physiology or Medicine’ to three men who had until recently been regarded as ‘mere animal watchers’".
Laureates have been awarded the Nobel Prize in a wide range of fields that relate to physiology or medicine. s of 2010[ [update]], eight Prizes have been awarded for contributions in the field of signal transduction through G proteins and second messengers. 13 have been awarded for contributions in the field of neurobiology and 13 have been awarded for contributions in Intermediary metabolism. The 100 Nobel Prizes in Physiology or Medicine have been awarded to 195 individuals through 2009. Ten women have received the prize: Gerty Cori (1947), Rosalyn Yalow (1977), Barbara McClintock (1983), Rita Levi-Montalcini (1986), Gertrude B. Elion (1988), Christiane Nüsslein-Volhard (1995), Linda B. Buck (2004), Françoise Barré-Sinoussi (2008), Elizabeth H. Blackburn (2009) and Carol W. Greider (2009). Only one woman, Barbara McClintock, has received an unshared prize in this category, for the discovery of genetic transposition. Mario Capecchi, Martin Evans and Oliver Smithies was awarded the prize in 2007 for the discovery of a gene targeting procedure (a type of genetic recombination) for introducing homologous recombination in mice, employing embryonic stem cells through the development of the knockout mouse. There have been 37 times when the Nobel Prize in Physiology or Medicine was awarded to a single individual, 31 times when it was shared by two, and 33 times there were three laureates (the maximum allowed).
In 2009, the Nobel Prize was awarded to Elizabeth Blackburn, Carol W. Greider and Jack W. Szostak of the United States for discovering the process by which chromosomes are protected by telomeres (regions of repetitive DNA at the ends of chromosomes) and the enzyme telomerase; they shared the prize of 10,000,000 SEK (slightly more than €1 million, or US$1.4 million). Rita Levi-Montalcini, an Italian neurologist, who together with colleague Stanley Cohen, received the 1986 Nobel Prize in Physiology or Medicine for their discovery of Nerve growth factor (NGF), was the first Nobel laureate to reach the 100th birthday.
Time factor and death.
Because of the length of time that may pass before the significance of a discovery becomes apparent, some prizes are awarded many years after the initial discovery. Barbara McClintock made her discoveries in 1944, before the structure of the DNA molecule was known; she was not awarded the prize until 1983. Similarly, in 1916 Peyton Rous discovered the role of tumor viruses in chickens, but was not awarded the prize until 50 years later, in 1966.
Nobel laureate Carol Greider's research leading to the prize was conducted over 20 years before. She noted that the passage of time is an advantage in the medical sciences, as it may take many years for the significance of a discovery to become apparent. The 2009 award in medicine was the first in the Nobel Prize's history that more than one woman has been the recipient of the Nobel Prize in a single year. It is also the first time two women have been awarded the Physiology or Medicine prize.
In 2011, Canadian immunologist Ralph M. Steinman was awarded the prize; however, unknown to the committee, he had died three days before the announcement. The committee decided that since the prize was awarded "in good faith," it would be allowed to stand.
Controversial inclusions and exclusions.
Some of the awards have been controversial. The person who was deserving of the 1923 prize for the discovery of insulin as a central hormone for controlling diabetes (awarded only a year after its discovery) has been heatedly debated. It was shared between Frederick Banting and John Macleod; this infuriated Banting who regarded Macleod's involvement as minimal. Macleod was the department head at the University of Toronto but otherwise was not directly involved in the findings. Banting thought his laboratory partner Charles Best, who had shared in the laboratory work of discovery, should have shared the prize with him as well. In fairness, he decided to give half of his prize money to Best. Macleod on his part felt the biochemist James Collip, who joined the laboratory team later, deserved to be included in the award and shared his prize money with him. Some maintain that Nicolae Paulescu, a Romanian professor of physiology at the University of Medicine and Pharmacy in Bucharest, was the first to isolate insulin, in 1916, although his pancrein was an impure aqueous extract unfit for human treatment similar to the one used previously by Israel Kleiner. In the paper that brought him the Nobel, Paulescu already held a patent for his discovery (10 April 1922, patent no. 6254 (8322) "Pancreina şi procedeul fabricaţiei ei"/"Pancrein and the process of making it", from the Romanian Ministry of Industry and Trade).
In 1949, despite protests from the medical establishment, the Portuguese neurologist António Egas Moniz received the Physiology or Medicine Prize for his development of the prefrontal leucotomy, which he promoted by declaring the procedure's success just 10 days postoperative. Due largely to the publicity surrounding the award, it was prescribed without regard for modern medical ethics. Favorable results were reported by such publications as "The New York Times". It is estimated that around 40,000 lobotomies were performed in the United States before the procedure's popularity faded. Joseph Kennedy, the father of John Kennedy, subjected his daughter, Rosemary, to the procedure which incapacitated her to the degree that she needed to be institutionalized for the rest of her life.
The 1952 prize, awarded solely to Selman Waksman for his discovery of streptomycin, omitted the recognition some felt due to his co-discoverer Albert Schatz. There was litigation brought by Schatz against Waksman over the details and credit of the streptomycin discovery; Schatz was awarded a substantial settlement, and, together with Waksman, Schatz was to be officially recognized as a co-discoverer of streptomycin as concerned patent rights. However, he is not recognized as a Nobel Prize laureate.
The 1962 Prize awarded to James D. Watson, Francis Crick and Maurice Wilkins—for their work on DNA structure and properties—did not recognize contributing work from others, such as Alec Stokes and Herbert Wilson. In addition, Erwin Chargaff, Oswald Avery and Rosalind Franklin (whose key DNA x-ray crystallography work was the most detailed yet least acknowledged among the three) contributed directly to the ability of Watson and Crick to solve the structure of the DNA molecule—but Avery died in 1955, and Franklin in 1958 and posthumous nominations for the Nobel Prize are not permitted. However, recently unsealed files of the Nobel Prize nominations reveal that no one ever nominated Franklin for the prize when she was alive. Wilkins' only contribution was to show Rosalind Franklin's key x-ray photos to Watson. As a result of Watson's misrepresentations of Franklin and her role in the discovery of the double helix in his controversial book "The Double Helix", Franklin has come to be portrayed as a classic victim of sexism in science. Chargaff, for his part, was not quiet about his exclusion from the prize, bitterly writing to other scientists about his disillusionment regarding the field of molecular biology.
The 2008 award went to Harald zur Hausen in recognition of his discovery that human papillomavirus (HPV) can cause cervical cancer, and to Françoise Barré-Sinoussi and Luc Montagnier for discovering the human immunodeficiency virus (HIV). Whether Robert Gallo or Luc Montagnier deserved more credit for the discovery of the virus that causes AIDS has been a matter of considerable controversy. As it was, Gallo was left out and not awarded a prize. Additionally, there was scandal when it was learned that Harald zur Hausen was being investigated for having a financial interest in vaccines for the cervical cancer that HPV can cause. AstraZeneca, who with a stake in two lucrative HPV vaccines could benefit financially from the prize, had agreed to sponsor Nobel Media and Nobel Web. According to Times Online, two senior figures in the selection process that chose zur Hausen also had strong links with AstraZeneca.
Limits on number of awardees.
The provision that restricts the maximum number of nominees to three for any one prize, introduced in 1968, has caused considerable controversy. From the 1950s onward, there has been an increasing trend to award the Nobel Prize in Physiology or Medicine to more than one person. There were 59 people who received the prize in the first 50 years of the last century, while 113 individuals received it between 1951 and 2000. This increase could be attributed to the rise of the international scientific community after World War II, resulting in more persons being responsible for the discovery, and nominated for, a particular prize. Also, current biomedical research is more often carried out by teams rather than by scientists working alone, making it unlikely that any one scientist, or even a few, is primarily responsible for a discovery; this has meant that a prize nomination that would have to include more than three contributors is automatically excluded from consideration. Also, deserving contributors may not be nominated at all because the restriction results in a cut off point of three nominees per prize, leading to controversial exclusions.
Years without awards.
There have been nine years in which the Nobel Prize in Physiology or Medicine was not awarded (1915–1918, 1921, 1925, 1940–1942). Most of these occurred during either World War I (1914–1918) or World War II (1939–1945). In 1939, Adolf Hitler's Third Reich forbade Gerhard Domagk to accept his prize. He was later able to receive the diploma and medal but not the money.

</doc>
<doc id="52504" url="http://en.wikipedia.org/wiki?curid=52504" title="Gwent">
Gwent

Gwent may refer to:

</doc>
<doc id="52507" url="http://en.wikipedia.org/wiki?curid=52507" title="British colonization of the Americas">
British colonization of the Americas

British colonization of the Americas (including colonization by both the Kingdom of England and the Kingdom of Scotland before the Acts of Union, which created the Kingdom of Great Britain in 1707) began in 1607 in Jamestown, Virginia and reached its peak when colonies had been established throughout the Americas. The English, and later the British, were among the most important colonizers of the Americas, and their American empire came to rival the Spanish American colonies in military and economic might.
Three types of colonies existed in the British Empire in America during the height of its power in the eighteenth century. These were charter colonies, proprietary colonies and royal colonies. After the end of the Napoleonic Wars (1803–1815), British territories in the Americas were slowly granted more responsible government. In 1838 the Durham Report recommended full responsible government for Canada but this did not get fully implemented for another decade. Eventually with the Confederation of Canada, the Canadian colonies were granted a significant amount of autonomy and became a self-governing Dominion in 1867. Other colonies in the rest of the Americas followed at a much slower pace. In this way, two countries in North America, ten in the Caribbean, and one in South America have received their independence from the United Kingdom. All of these are members of the Commonwealth of Nations and nine are Commonwealth realms. The eight remaining British overseas territories in the Americas have varying degrees of self-government.
North America.
Pre-British colonization of North America.
English colonies in North America.
A number of English colonies were established under a system of Proprietary Governors, who were appointed under mercantile charters to English joint stock companies to found and run settlements, most notably the Virginia Company, which created the first successful English settlement at Jamestown and the second at St. George's, Bermuda.
In 1664, England also took over the Dutch colony of New Netherland, (including the New Amsterdam settlement), which England renamed the Province of New York. With New Netherland, the English also came to control the former New Sweden (in what is now Delaware), which the Dutch had conquered earlier. This later became part of Pennsylvania after it was established in 1680.
Scottish colonies in North America.
There was also an early unsuccessful attempt by the Kingdom of Scotland to establish a colony at Darién, and the short-lived Scottish colonisation of Nova Scotia (New Scotland) from 1629 to 1632. Thousands of Scotsmen also participated in the English colonisation even before the two countries were united in 1708.
British colonies in North America.
The Kingdom of Great Britain acquired the French colony of Acadia in 1713 and then Canada and the Spanish colony of Florida in 1763. After being renamed the Province of Quebec, the former French Canada was divided in two Provinces, the Canadas, consisting of the old settled country of Lower Canada (today Quebec) and the newly settled Upper Canada (today Ontario).
In the north, the Hudson's Bay Company actively traded for fur with the indigenous peoples, and had competed with French, Aboriginal, and Metis fur traders. The company came to control the entire drainage basin of Hudson Bay called Rupert's Land. The small part of the Hudson Bay drainage south of the 49th parallel went to the United States in the Anglo-American Convention of 1818.
Thirteen of Great Britain's colonies rebelled with the American Revolutionary War, beginning in 1775, primarily over representation, local laws and tax issues, and established the United States of America, which was recognised internationally with the signing of the Treaty of Paris on 3 September 1783.
Great Britain also colonised the west coast of North America, indirectly via the Hudson's Bay Company licenses west of the Rocky Mountains, the Columbia District and New Caledonia fur district, most of which were jointly claimed as the Oregon Country by the United States from 1818 until the 49th parallel was established as the international boundary west of the Rockies by the Oregon Treaty of 1846. The Colony of Vancouver Island, founded in 1849, and the Colony of British Columbia, founded in 1858, were combined in 1866 with the name Colony of British Columbia until joining Confederation in 1871. British Columbia also was expanded with the inclusion of the Stikine Territory in 1863, and upon joining Confederation with the addition of the Peace River Block, formerly part of Rupert's Land.
In 1867, the colonies of New Brunswick, Nova Scotia, and the Province of Canada (the southern portion of modern-day Ontario and Quebec) combined to form a self-governing dominion, named Canada, within the British Empire (the term "kingdom" was avoided so as to not provoke the United States). Quebec (including what is now the southern portion of Ontario) and Nova Scotia (including what is now New Brunswick and Prince Edward Island) had been ceded to Britain by the French. The colonies of Prince Edward Island and British Columbia joined over the next six years, and Newfoundland joined in 1949. Rupert's Land and the North-Western Territory were ceded to Canada in 1870. This area now consists of the provinces of Manitoba (admitted after negotiation between Canada and a Métis provisional government in 1870), Saskatchewan, and Alberta (both created in 1905), as well as the Northwest Territories, the Yukon Territory (created 1898, following the start of the Klondike Gold Rush), and Nunavut (created in 1999).
Central and South America, Caribbean.
English and later British Caribbean colonies.
In order of settlement or founding:

</doc>
<doc id="52508" url="http://en.wikipedia.org/wiki?curid=52508" title="Gwynedd">
Gwynedd

Gwynedd (; ]) is an area in north-west Wales, named after the old Kingdom of Gwynedd. As a local government area it is the second biggest in terms of geographical area and also one of the most sparsely populated. Most of the population is Welsh-speaking. The name Gwynedd is also used for a preserved county, covering the two local government areas of Gwynedd and the Isle of Anglesey. Culturally and historically, the name can also be used for most of North Wales (for instance, the area covered by the Gwynedd Constabulary), corresponding to the approximate territory of the Kingdom of Gwynedd at its greatest extent. The current area is 2,548 square km (983.78 sq miles) (slightly smaller than Luxembourg).
Gwynedd is the home of Bangor University and includes the scenic Llŷn Peninsula, and most of Snowdonia National Park.
History.
Gwynedd was an independent kingdom from the end of the Roman period until the 13th Century when it was conquered and subjugated by England. The modern Gwynedd was one of eight Welsh counties originally created on 1 April 1974 under the Local Government Act 1972, based on the principal territory of the former realm. It covered the entirety of the old counties of Anglesey, and Caernarfonshire along with all of Merionethshire apart from Edeirnion Rural District (which went to Clwyd), and also a few parishes in Denbighshire: Llanrwst, Llansanffraid Glan Conwy, Eglwysbach, Llanddoged, Llanrwst and Tir Ifan.
The county was divided into five districts: Aberconwy, Arfon, Dwyfor, Meirionnydd and Anglesey.
The Local Government (Wales) Act 1994 abolished the 1974 county (and the five districts) on 1 April 1996, and its area was divided: the Isle of Anglesey became an independent unitary authority, and Aberconwy (which included the former Denbighshire parts) passed to the new Conwy County Borough. The remainder of the county was constituted a principal area with the name Caernarfonshire and Merionethshire, reflecting that it covered most of the areas of those two counties. As one of its first actions, the Council renamed itself Gwynedd on 2 April 1996. The present Gwynedd local government area is governed by Gwynedd Council. As a unitary authority the modern entity no longer has any districts, but Arfon, Dwyfor and Meirionnydd remain in use as area committees.
The pre-1996 boundaries were retained as a preserved county for a few purposes such as the Lieutenancy. In 2003 the boundary with Clwyd was adjusted to match the modern local government boundary, so that the preserved county now covers the two local government areas of Gwynedd and Anglesey, and the area of Conwy county borough is now entirely within Clwyd.
A Gwynedd Constabulary was formed in 1950 from the merger of the Anglesey, Caernarfonshire and Merionethshire forces. A further amalgamation took place in the 1960s when Gwynedd Constabulary was merged with the Flintshire and Denbighshire county forces, retaining the name Gwynedd. In one proposal for local government reform in Wales, Gwynedd had been proposed as a name for a local authority covering all of north Wales, but the scheme as enacted divided this area between Gwynedd and Clwyd. To prevent confusion, the Gwynedd Constabulary was therefore renamed the North Wales Police.
The Snowdonia National Park was formed in 1951. After the 1974 local authority reorganisation, the park fell entirely within the boundaries of Gwynedd, and was run as a department of Gwynedd County Council. After the 1996 local government reorganisation, part of the park fell under Conwy County Borough, and the park's administration separated from the Gwynedd council. Gwynedd Council does still appoint 9 of the 18 members of the Snowdonia National Park Authority; Conwy County Borough Council appoints 3; and the National Assembly for Wales appoints the remaining 6.
Welsh language.
In Gwynedd, more than two-thirds of the population reports being able to speak Welsh. The proportion of Welsh speakers in Gwynedd slightly declined from 1991 to 2001, from 72.1% to 68.7%, respectively. This occurred even as the proportion of Welsh speakers in Wales as a whole increased during that decade, to 20.5%. In 2003, however, a survey of schools showed that just over 94% of children between 3 and 15 were able to speak Welsh. Nevertheless, there have been concerns that an influx of English speakers to the area is damaging the standing of Welsh.

</doc>
<doc id="52510" url="http://en.wikipedia.org/wiki?curid=52510" title="Mores">
Mores

Mores (generally pronounced , and often ; from Latin "mōrēs", ], grammatically plural: "habit"; singular form: "mōs") is a term introduced into English by William Graham Sumner (1840–1910), an early U.S. sociologist, to refer to norms that are more widely observed and have greater moral significance than others. Mores include an aversion for societal taboos, such as incest. Consequently, the values and mores of a society predicates legislation prohibiting their taboos.
Folkways, in sociology, are norms for routine or casual interaction. This includes ideas about appropriate greetings and proper dress in different situations.
In short, mores "distinguish the difference between right and wrong, while folkways draw a line between right and rude".
Both "mores" and "folkways" are terms coined by William Graham Sumner in 1906.
Terminology.
The English word morality comes from the same Latin root "mōrēs", as does the English noun "moral". However, mores do not, as is commonly supposed, necessarily carry connotations of morality. Rather, morality can be seen as a subset of mores, held to be of central importance in view of their content, and often formalized in some kind of moral code.
The Greek term equivalent to Latin "mores" is "ethos" (ἔθος, ἦθος). As with the relation of "mores" to "morality", "ethos" is the basis of the term "ethics".
Anthropology.
The meaning of all these terms extend to all customs of proper behavior in a given society, both religious and profane, from more trivial conventional aspects of custom, etiquette or politeness — "folkways" enforced by gentle social pressure, but going beyond mere "folkways" or conventions in including moral codes and notions of justice — down to strict taboos, behavior that is unthinkable within the society in question, very commonly including incest and murder, but also the commitment of outrages specific to the individual society such as blasphemy. Such religious or sacral customs may vary.
While cultural universals are by definition part of the "mores" of every society (hence also called "empty universals"), the customary norms specific to a given society are a defining aspect of the cultural identity of an ethnicity or a nation. Coping with the differences between two sets of cultural conventions is a question of intercultural competence.
Differences in the "mores" of various nations are at the root of ethnic stereotype, or in the case of reflection upon one's own "mores", autostereotypes.

</doc>
<doc id="52517" url="http://en.wikipedia.org/wiki?curid=52517" title="Ulrike Meinhof">
Ulrike Meinhof

Ulrike Marie Meinhof (7 October 1934 – 9 May 1976) was a German left-wing militant. She co-founded the Red Army Faction ("Rote Armee Fraktion") in 1970 after having previously worked as a journalist for the monthly left-wing magazine "konkret". She was arrested in 1972, and eventually charged with numerous murders and the formation of a criminal association. Before the trial concluded, Meinhof was found hanged in her prison cell in 1976.
Early life.
Ulrike Meinhof was born in 1934 in Oldenburg, Germany. In 1936, her family moved to Jena when her father, art historian Dr. Werner Meinhof, became director of the city's museum. Her father died of cancer in 1940, causing her mother to take in a boarder, Renate Riemeck, to make money. In 1946, the family moved back to Oldenburg because Jena fell under Soviet rule as a result of the Yalta agreement. Ulrike's mother, Dr. Ingeborg Meinhof, worked as a teacher after World War II and died 8 years later from cancer. Renate Riemeck took on the role of guardian for Ulrike and her elder sister.
In 1952, she took her "Abitur" at a school in Weilburg. She then studied philosophy, sociology, education and German at Marburg where she became involved with reform movements.
In 1957, she moved to the University of Münster, where she met the Spanish Marxist Manuel Sacristán (who later translated and edited some of her writings) and joined the Socialist German Student Union, participating in the protests against the rearmament of the Bundeswehr and its involvement with nuclear weapons as proposed by Konrad Adenauer's government. She eventually became the spokeswoman of the local "Anti-Atomtod-Ausschuss" ('Anti-Atomic Death Committee'). In 1958, she spent a short time on the AStA (German: "Allgemeiner Studierendenausschuss", or General Committee of Students) of the university and wrote articles for various student newspapers.
In 1959, she joined the banned Communist Party of Germany (KPD) and later began working at the magazine "konkret", serving as chief editor from 1962 until 1964. In 1961, she married the co-founder and publisher of "konkret", Klaus Rainer Röhl. Their marriage produced twins, Regine and Bettina, on 21 September 1962. Meinhof and Röhl separated in 1967 and divorced a year later.
Establishment of the Red Army Faction.
The attempted assassination of student activist Rudi Dutschke on 11 April 1968, provoked Meinhof to write an article in "konkret" demonstrating her increasingly militant attitude and containing perhaps her best-known quote:
Protest is when I say this does not please me.
Resistance is when I ensure what does not please me occurs no more. 
Later that year, her writings on arson attacks in Frankfurt as protests against the Vietnam War resulted in her developing an acquaintance with the perpetrators, most significantly Andreas Baader and Gudrun Ensslin. She stopped writing for "konkret" which had in their opinion evolved into a completely commercial magazine in the early part of 1969, and many other authors followed her. She stated that neither she or her collaborators wanted to give a left-wing alibi to the magazine, that sooner or later "would become part of the counter-revolution, a thing that I cannot gloss over with my co-operation, especially now that it is impossible to deter its course". Later, they organised an occupation at "konkret"‍ '​s office (along with several members of the Außerparlamentarische Opposition), to distribute proclamations to the employees, something that failed since Röhl learned about it, and moved the employees to their homes to continue their work from there. Finally, Röhl's house was vandalised by some of the protesters. Meinhof arrived in Röhl's villa at 11:30, after police and journalists had already arrived. She was accused by Röhl (and subsequently described by the media) as the organizer of the vandalism, even though she was not there when it happened.:352-4
Perhaps her last work as an individual was the writing and production of the film "Bambule" in 1970, where she put focus on a group of borstal girls in West Berlin; by the time it was scheduled to be aired, she had become wanted for the breakout of Andreas Baader, and its broadcast was delayed until 1994.
Meinhof had been approached by Gudrun Ennslin, girlfriend of jailed arsonist Andreas Baader, for her help in securing the release of Baader from police custody. A scheme was developed where Meinhof would approach leftist publisher Klaus Wagenbach, seeking to have him hire Meinhof and the imprisoned Baader in writing a book. After securing a contract from Wagenbach (who was not aware of Meinhof's ulterior motives), Meinhof petitioned authorities to allow Baader to travel from Moabit Prison to an institute for social research in the Dahlem district of Berlin. The plan was for armed guerrillas to enter the institute and secure the release of Baader; it was intended that no shooting was to take place. Meinhof was to stay behind, and have a plausibly deniable explanation that she was not involved in the planning of Baader's escape. Baader arrived with two guards, and set to work with Meinhof in the institute's library. Two women compatriots of Ensslin's, along with a man with a criminal record (hired because of his supposed experience with armed encounters) broke into the institute. The man shot the elderly librarian Georg Linke, severely wounding him in his liver. It was later claimed that the man was holding two weapons, a pistol and a gas canister gun, and accidentally fired the wrong weapon in the confusion.
Because of the shooting of the librarian, it is speculated that Meinhof make a snap decision to join Baader in his escape. Within days wanted posters appeared throughout Berlin offered a 10,000 DM reward for her capture for "Attempted Murder."
In the beginning, Meinhof meant to stay behind to use her power as an influential reporter to help the rest outside, but in the panic after the shooting she joined the others jumping out of the institute's window. Immediately after their escape Meinhof called a friend to pick up her children from school. This call helped illustrate her overall lack of planning. 
Action in the Red Army Faction and arrest.
In the next two years Meinhof participated in the various bank robberies and bombings executed by the group. She and other RAF members attempted to kidnap her children so that they could be sent to a camp for Palestinian orphans and educated there according to her desires; however, the twins were intercepted in Sicily and returned to their father, in part due to the intervention of Stefan Aust.
During this period, Meinhof wrote or recorded many of the manifestos and tracts for the RAF. The most significant of these is probably "The Concept of the Urban Guerrilla", a response to an essay by Horst Mahler, that attempts to set out more correctly their prevailing ideology. It also included the first use of the name "Rote Armee Fraktion" and, in the publications of it, the first use of the RAF insignia. Her practical importance in the group, however, was often overstated by the media, the most obvious example being the common name "Baader-Meinhof gang" for the RAF. (Gudrun Ensslin is often considered to have been the effective female co-leader of the group rather than Meinhof.)
On 14 June 1972, in Langenhagen, Fritz Rodewald, a teacher who had been providing accommodation to deserters from the U.S. Armed Forces, was approached by a stranger asking for an overnighting house the next day for herself and a friend. He agreed but later became suspicious that the woman might be involved with the RAF and eventually decided to call the police. The next day the pair arrived at Rodewald's dwelling while the police watched. The man was followed to a nearby telephone box and was found to be Gerhard Müller who was armed. After arresting Müller, the police then proceeded to arrest the woman – Ulrike Meinhof.
Imprisonment and death.
In December 1972, Meinhof, who was awaiting trial, was called to testify at Horst Mahler's trial where Mahler questioned her about the statement of support the two had issued for the September 1972 massacre of Israeli athletes at the Munich Olympics. His questioning led her to say
How was Auschwitz possible, what was anti-Semitism? It used the hatred of the people of their dependence on money as a medium of exchange, their longing for communism. Auschwitz means that six million Jews were murdered and carted on to the rubbish dumps of Europe for being that which was maintained of them – Money-Jews. What had happened was that finance capital and
banks, the hard core of the system of imperialism and capitalism, had diverted the people's hatred of money and exploitation away from themselves and on to the Jews.
After two years of preliminary hearings, Meinhof was sentenced to 8 years' imprisonment on 29 November 1974. Eventually Meinhof, Baader, Ensslin, and Raspe were jointly charged on 19 August 1975, with four counts of murder, fifty-four of attempted murder, and a single count of forming a criminal association. However before the trial was concluded, Meinhof was found hanged by a rope, fashioned from a towel, in her cell in the Stammheim Prison on 9 May 1976. It is highly probable that, if not for her death, she would have been sentenced to 'life imprisonment plus 15 years'. (The remaining three defendants received such a sentence, designed to minimize the possibility of early parole.)
The official verdict was that Meinhof had committed suicide. It was later discovered that she had become increasingly isolated from other RAF prisoners. Notes exchanged between them in prison included one by Gudrun Ensslin, describing her as "too weak". The official findings were not accepted by many in the RAF and other militant organisations, and there are still some who doubt their accuracy and believe that she was murdered by the authorities. A second investigation was carried out by an international group. The findings of the inquiry were published under the title "Der Tod Ulrike Meinhofs. Bericht der Internationalen Untersuchungskommission" ("The Death of Ulrike Meinhof. Report of the International Investigation Committee") in 1979.
Meinhof's body was buried six days after her death, in Berlin-Mariendorf. Her funeral turned out to be a demonstration of about 4,000 people.
In late 2002, following investigations by her daughter Bettina, it was discovered that Meinhof's brain had been retained (apparently without permission) following the autopsy performed as part of the investigation into Meinhof's death. The original autopsy had found brain injury near the amygdala, resulting from unsuccessful surgery in 1962 to remove a benign brain tumor. The unpublished autopsy results at the time stated that the brain injuries "justified questions as to the culpability" of Meinhof. Bernhard Bogerts, a psychiatrist at Magdeburg university, later re-examined the brain and also doubted that Meinhof was fully criminally responsible. On Bettina's request, the brain was interred in Meinhof's burial place on 19 December 2002.
Last days in prison.
Meinhof's last appearance in court was on 4 May 1976 when the defendants requested to provide evidence about the participation of West Germany in the Vietnam war, claiming that this was the cause of their radicalization, and requesting to be granted the status of prisoners of war (see above). According to Jutta Ditfurth, the last days before Meinhof's death went smoothly. The prisoners (including Meinhof) spent their meeting time (30 minutes, twice per day) discussing various philosophers and political issues. One of the guards noted that they were laughing.:586,592
According to Wienke Zittlaf, during her last visit in prison, Meinhof had told her: "You can stand up and fight only while you are alive. If they say I committed suicide, be sure that it was a murder.":582
In early May, attorney Axel Azzola contacted his client (Meinhof). They were hopeful about the possibilities that the new strategy seemed to offer. They also discussed whether Meinhof could testify as witness in the International Law Conference in Geneva where a delegation of lawyers planned to denounce the measure of detention in solitary confinement. Finally, Meinhof was planning to reveal main witness Gerhard Müller's role in trial.:590 Federal prosecutors had blamed exclusively the four defendants for the murder of policeman Norbert Schmid, who was shot by Müller himself.
During the press conference called by defense attorneys, one of Meinhof's lawyers, Michael Oberwinder, stated that it was less than a week before Meinhof's death that they had a very involved conversation. He claimed that there was not the least sign of depression or disinterest on her part, and that it was an animated discussion in the context of which Meinhof explained the group's point of view.
Meinhof's last visitor was Giovanni Capelli, lawyer of the Red Brigades. He conveyed the desire of the Red Brigades to contact her and described the conditions of detention in Italy where prisoners were not held in isolation (except Renato Curcio) and were politically active. They also discussed the establishment of an international committee of lawyers to defend the RAF. Capelli later said that Meinhof gave him the impression of "a vivid, lifelike woman", "open to all questions". They arranged to meet again soon. "She behaved like a woman who wanted to live".
Autopsy and death investigation.
At 9.20 a.m. on 9 May, the Ministry of Justice of Baden-Württemberg disseminated the information that Meinhof had committed suicide, although the initial post mortem body examination began only after 9:25 AM by professor Joachim Rauschke. At 9:34 a.m. the German news agency (dpa) announced "Suicide by hanging".:594,595. Two hours later professor Rauschke together with Hans Joachim Mallach performed the official autopsy in the general hospital of Stuttgart from 11:45 a.m. until 12:45 p.m., whose outcome was "death by hanging beyond doubt". According to Ditfurth the hasty press releases that followed Meinhof's death, were similar to those of April 1972, when it was incorrectly broadcast that Meinhof had committed suicide.:596. The following days the newspapers reported in detail what supposed to be Meinhof's thoughts, like: "she realised her mistake," "she had become aware of the futility," and that she "resigned to death".
There was a concern of Meinhof supporters about the forensic surgeons chosen by the state to perform the autopsy. Mallach (NSDAP Member No. 9154986) had been a member of the SS. He served in World War II as corporal in a Panzer division. In 1977, he made (without approval) and kept for a long time the death masks of Andreas Baader, Gudrun Ensslin and Jan-Carl Raspe. Professor Rauschke was the one who also performed the autopsy of Siegfried Hausner one year earlier and was accused by fellows and supporters of the RAF for ignoring the injuries to Hausner's head, so as to cover up the true cause of his death.
On 11 May, a second autopsy was performed on demand of Wienke Zitzlaff (Meinhof's sister) by Dr. Werner Janssen and Dr. Jürgen Schröder. There had been removed the brain, a lot of critical organs, and tissue parts. Also her nails had been cut, so the doctors could not determine clearly if there were traces of struggle. Some examinations could not take place since critical time had passed. Janssen concluded that the most probable cause of death was "suicide by hanging", however in order to come to a definite conclusion he insisted to be given access to the report of the first autopsy, something that never happened.:602,603
Finally on demand of Meinhof's attorney Klaus Croissant and the International Committee for Political Prisoners, an international investigation commission was created in order to examine the conditions surrounding Meinhof's death. Once more the German authorities refused to give the complete (first) autopsy report to the commission, hindering their investigation. In 1978 the committee published its report, concluding that: "The formal claim that Ulrike Meinhof committed suicide by hanging is unfounded, given the fact that the investigation results reasonably converge to the conclusion that she could not hang herself. Most probably Ulrike Meinhof was already dead before she was hanged and there are warning signs indicating the involvement of a third party regarding her death."
Suicide disputation.
A lot of Meinhof's relatives, friends, lawyers, comrades, and many other people strongly reject the suicide scenario, presenting various arguments. There are inquiries regarding the procedure followed by the authorities, including the autopsy reports and the findings of the international commission. Some of them are:
Some other questions still remain, like:
Finally there is dispute over the arguments regarding Meinhof's motive. Some of the points usually mentioned are:
Portrayals.
The book "Lieber wütend als traurig" (Better angry than sad) by Alois Prinz was intended as a mainly faithful account of Meinhof's lifestory for adolescents.
Meinhof's life has been the subject, to varying degrees of fictionalisation, of several films and stage productions. Treatment in films include Reinhard Hauff's 1986 "Stammheim", an account of the Stammheim trial, Margarethe von Trotta's 1981 "Marianne and Juliane" and Uli Edel's 2008 film "The Baader Meinhof Complex". Stage treatments include the 1990 opera "Ulrike Meinhof" by Johann Kresnik, the 1993 play "Leviathan" by Dea Loher, the 2005 play "La extraordinaria muerte de Ulrike M." by Spanish playwright Carlos Be and the 2006 play "Ulrike Maria Stuart" by Austrian playwright Elfriede Jelinek. The 1981 French movie "Il faut tuer Birgitt Haas" is inspired by Meinhof's death.
In 1978 Dario Fo and Franca Rame wrote the monologue "Moi, Ulrike, je crie..."
The 2010 feature documentary "Children of the Revolution" tells Meinhof's story from the perspective of her daughter, journalist and historian Bettina Röhl ().
"Subtopia", a novel published in 2005 by Australian author and academic A.L. McCann, is partially set in Berlin and contains a character who is obsessed with Ulrike Meinhof and another that claims to have attended her funeral.
The 2013 book "Revolutionary Brain" by Harold Jaffe features a titular section devoted to the brain of Ulrike Meinhof.
Music.
Marianne Faithfull's album "Broken English" had the title track dedicated to Meinhof.
The anarcho punk band Chumbawamba's 1990 album, "Slap!" featured an opening and closing track, both named after Meinhof. The first track was entitled "Ulrike" and featured lyrics which directly involved Ulrike Meinhof as the protagonist and the final track was purely instrumental (but unrelated to the first track) and was entitled "Meinhof". The album's liner notes included information and an article relating to the song Ulrike.
Electronica act Doris Days created a track entitled "To Ulrike M.", in which there is a passage spoken in German throughout the song, presumably an archived audio file from Ulrike Meinhof herself. This track has since been remixed by other electronica acts like Zero 7, Kruder & Dorfmeister, and The Amalgamation of Soundz.
The German duo Andreas Ammer and F.M. Einheit released an album in 1996 entitled "Deutsche Krieger", a substantial portion of which consists of audio recordings of and about Ulrike Meinhof.
London-based experimental group Cindytalk have an electronic side-project called Bambule, named after the Meinhof film .
The Brazilian Rock band Legião Urbana has a song called "Baader-Meinhof Blues".
The Portland-based Chilean artist Gonzalo Villa has an instrumental song called "Dear Ulrike".
The refrain of the song "Ludvig van Beethoven" from the Finnish popular-music band SIG is "And nobody has heard about rock 'n' roll or Ulrike Meinhof's death".
Powerviolence band The Endless Blockade has a song entitled "Ulrike Meinhof's Brain".
California hardcore band Ghostlimb has a song about Meinhof called "Concrete" on their album "Infrastructure".
The Italian singer-songwriter Giovanna Marini includes a track called "Ulrike Meinhof" on her 2010 album "Correvano Coi Carri".
In the 1995 song "Red Sonja" by the German band FSK, Baader-Meinhof is mentioned.
In 1996, British songwriter Luke Haines released a record under the band's name 'Baader-Meinhof'. This record tells the highlights of the German guerrilla group.
Spanish rapper Pablo Hasél released an album named Escribiendo con Ulrike Meinhof (Writing with Ulrike Meinhof).
Portuguese singer Vitorino dedicated the song 'Sedas Ao Vento', from the 1979 album 'Não Há Terra Que Resista - Contraponto', to Ulrike Meinhof. He mentions her in the liner notes together with a photograph on the back of the cover.
Bibliography.
Works of the Red Army Faction
Further reading.
Books
Films

</doc>
<doc id="52519" url="http://en.wikipedia.org/wiki?curid=52519" title="Vale of Glamorgan">
Vale of Glamorgan

The Vale of Glamorgan (Welsh: "Bro Morgannwg" ]) is a county borough in Wales. The Vale of Glamorgan has a successful agriculture industry and is the most southerly county in Wales. The Vale of Glamorgan, sometimes known locally as the 'Vale,' has a rich history and geography and has a large number of towns, villages and attractions.
The Vale also has a number of notable locations including Barry Island Pleasure Park, known worldwide for the BBC sitcom, "Gavin & Stacey". Other attractions include the Barry Tourist Railway, Porthkerry Park, St Donat's Castle, Cosmeston Lakes Country Park and Cosmeston Medieval Village. It is also the location of Atlantic College, one of the United World Colleges.
The largest town is Barry. Other towns include Penarth, Llantwit Major and Cowbridge. There are many villages in the county borough.
Geography.
It has been a county borough (unitary authority) since 1996, previously being part of South Glamorgan county. The largest centre of population is Barry. Other towns include Cowbridge, Dinas Powys, Llantwit Major and Penarth which is the Vale's first Fairtrade town, but a large proportion of the population inhabits villages, hamlets and individual farms. The area is low-lying, with a greatest height of 137 m above sea level.
The yellow-grey cliffs on the Glamorgan Heritage Coast (which stretches between Llantwit Major to Ogmore-by-Sea) are unique on the Celtic Sea coastline (i.e. Cornwall, Wales, Ireland and Brittany) as they are formed of a combination of liassic limestone, shale and carboniferous sandstone/limestone. They were formed 200 million years ago when Wales (as well as Cornwall, Brittany and Ireland) lay underneath a warm, shallow, equatorial sea during the beginning of the Jurassic age. Today the cliffs contain elements of Jurassic age sea-creatures (although not land dinosaurs – what is now the Celtic Sea coastline was underneath the sea), such as ammonites. The stratification of overlapping shale, sandstone and limestone was caused by a geological upheaval known as the Variscan orogeny, which literally pushed the cliffs out of the sea, contorting them as they did so. (This stratification can also be found on other parts of the Celtic seaboard, such as Bude in Cornwall, across the Bristol Channel). As the cliffs and land contain elements of calcium carbonate found in the limestone, it allows farmers in the vale to grow crops which would be difficult elsewhere in Wales or the West country, such as Devon and Cornwall (whose soil is predominantly acidic as most of the west country is made of poor quality Devonian soils). The liassic limestone and carboniferous sandstone is also used in the vale for building materials; in previous centuries it was taken by sloops across the Bristol Channel to north Cornish ports such as Bude, Boscastle and Port Isaac to fertilise Cornwall's poor slate soils for the farming communities; while the hard Devonian slate of Cornwall was brought back as a roofing material for houses in the Vale.
As the Glamorgan Heritage Coast faces westwards out to the Atlantic, it bears the brunt of brutal on-shore (west, south-westerly) winds; ideal for surfing, but a nightmare for ships trying to sail up the Bristol Channel into Cardiff. Just like North Cornwall or South-West Ireland, the fierce Atlantic gales created ideal conditions for pre-meditated shipwrecking, which up until 100 years was very common along the coast (although shipwrecking was common across all the Celtic Sea). Nash Point, Southerndown and Ogmore-by-Sea have some of the highest shipwreck victims on the coast of Wales; as recently as 1962 an oil tanker, the BP Driver crashed into Nash Point during a violent westerly storm, was torn to shreds by the brutal reefs and eventually sank, although thanks to a courageous effort by various Bristol Channel lifeboats and helicopters the crew were saved.
The district borders Cardiff to the north east, Rhondda Cynon Taf to the north, Bridgend to the north west and the Bristol Channel to the south.
Government.
The region is governed by the Vale of Glamorgan Council which was controlled by the Conservative Party until May 2012. The Vale of Glamorgan parliamentary and assembly constituencies (which do not include Penarth and Sully which are in the constituency of Cardiff South and Penarth) sway between Labour control and Conservative Party control in both the National Assembly for Wales and in Westminster. This is supposedly because of the Labour supporters in the east of the constituency and in the town of Barry and then the Tory supporters in the west due to a large farming population. Since May 2012, the Labour Party leads a coalition with the Llantwit First independent group. 
International links.
The Vale of Glamorgan is twinned with:
and has friendship agreements with:
Once every year, there is a twinning event in one of the Vale of Glamorgan's towns where representatives are invited from each of the twin cities. The event focuses on culture and economic regeneration.
Transport.
Road.
The county borough is served by the M4 Motorway junctions 33 (Cardiff West) and 34 (Llantrisant). However the A48 trunk road cuts right through the Vale of Glamorgan, linking it to Cardiff and Bridgend.
Rail.
The county borough is served by the Vale of Glamorgan Line with services to Bridgend and Cardiff, with stations in Barry, Penarth and Llantwit Major, although the stations serving Pontyclun and Bridgend may be closer to some residents.
Bus.
Barry, Wenvoe, Llantwit Major and Penarth are served by Cardiff Bus, who operate services within the towns and to Cardiff. First Cymru operates the X2 route along the A48 to Cardiff via Cowbridge, Bonvilston and St. Nicholas, however the county borough is well served by rural operators as well.
Air.
Cardiff International Airport, the only international airport in Wales, is located in Rhoose in the south of the county borough.

</doc>
<doc id="52520" url="http://en.wikipedia.org/wiki?curid=52520" title="Glamorgan">
Glamorgan

Glamorgan or, sometimes, Glamorganshire (Welsh: "Morgannwg" ] or "Sir Forgannwg" ]) is one of the thirteen historic counties of Wales and a former administrative county of Wales. It was originally an early medieval petty kingdom of varying boundaries known as Glywysing until taken over by the Normans as a lordship. Glamorgan is latterly represented by the three preserved counties of Mid Glamorgan, South Glamorgan and West Glamorgan. The name also survives in that of Vale of Glamorgan, a county borough.
Although initially a rural and pastoral area of little value, the area that became known as Glamorgan was a conflict point between the Norman lords and the Welsh princes, with the area being defined by a large concentration of castles. After falling under English rule in the 16th century, Glamorgan became a more stable county, and exploited its natural resources to become an important part of the Industrial Revolution. Glamorgan was the most populous and industrialised county in Wales, and was once called the "crucible of the Industrial Revolution," as it contained the world centres of three metallurgical industries and its rich resources of coal.
The county of Glamorgan comprised several distinct regions: the industrial valleys, the agricultural Vale of Glamorgan, and the scenic Gower Peninsula. The county was bounded to the north by Brecknockshire, east by Monmouthshire, south by the Bristol Channel, and west by Carmarthenshire and Carmarthen Bay. Its total area was 2100 km2, and the total population of the three preserved counties of Glamorgan in 1991 was 1,288,309. From 1974 Glamorgan contained two cities, Cardiff, the county town and from 1955 the capital city of Wales, and Swansea. The highest point in the county is Craig y Llyn (600 m) which is situated near the village of Rhigos in the Cynon Valley.
History.
Origins.
Glamorgan's terrain has been inhabited by humankind for over 200,000 years. Climate fluctuation caused the formation, disappearance, and reformation of glaciers which, in turn, caused sea levels to rise and fall. At various times life has flourished, at others the area is likely to have been completely uninhabitable. Evidence of the presence of Neanderthals has been discovered on the Gower Peninsula. Whether they remained in the area during periods of extreme cold is unclear. Sea levels have been 150 m lower and 8 m higher than at present, resulting in significant changes to the coastline during this period.
Archaeological evidence shows that humans settled in the area during an interstadial period. The oldest known human burial in Great Britain – the "Red Lady of Paviland" – was discovered in a coastal cave between Port Eynon and Rhossili, on the Gower Peninsula. The 'lady' has been radiocarbon dated to c. 29,000 years before present (BP) – during the Late Pleistocene – at which time the cave overlooked an area of plain, some miles from the sea.
From the end of the last ice age (between 12,000 and 10,000 BP) Mesolithic hunter-gatherers began to migrate to the British Peninsula – through Doggerland – from the European mainland. Archaeologist Stephen Aldhouse-Green notes that while Wales has a "multitude" of Mesolithic sites, their settlements were "focused on the coastal plains", the uplands were "exploited only by specialist hunting groups".
Human lifestyles in North-West Europe changed around 6000 BP; from the Mesolithic nomadic lives of hunting and gathering, to the Neolithic agrarian life of agriculture and settlement. They cleared the forests to establish pasture and to cultivate the land and developed new technologies such as ceramics and textile production. A tradition of long barrow construction began in continental Europe during the 7th millennium BP – the free standing megalithic structures supporting a sloping capstone (known as "dolmens)"; common over Atlantic Europe. Nineteen Neolithic chambered tombs (or "long barrows") and five possible henges have been identified in Glamorgan. These megalithic burial chambers, or "cromlechi", were built between 6000 and 5000 BP, during the early Neolithic period, the first of them about 1500 years before either Stonehenge or the Egyptian Great Pyramid of Giza was completed. Two major groups of Neolithic architectural traditions are represented in the area: portal dolmens (e.g. St Lythans burial chamber (Vale of Glamorgan), and Cae'rarfau (near Creigiau)); and Severn-Cotswold chamber tombs (e.g. "Parc Cwm" long cairn, ("Parc le Breos Cwm", Gower Peninsula), and Tinkinswood burial chamber (Vale of Glamorgan)), as well as tombs that do not fall easily into either group. Such massive constructions would have needed a large labour force – up to 200 men – suggestive of large communities nearby. Archaeological evidence from some Neolithic sites (e.g. Tinkinswood) has shown the continued use of cromlechi in the Bronze Age.
The Bronze Age – defined by the use of metal – has made a lasting impression on the area. Over six hundred Bronze Age barrows and cairns, of various types, have been identified all over Glamorgan. Other technological innovations – including the wheel; harnessing oxen; weaving textiles; brewing alcohol; and skillful metalworking (producing new weapons and tools, and fine gold decoration and jewellery, such as brooches and torcs) – changed people's everyday lives during this period. Deforestation continued to the more remote areas as a warmer climate allowed the cultivation even of upland areas.By 4000 BP people had begun to bury, or cremate their dead in individual cists, beneath a mound of earth known as a round barrow; sometimes with a distinctive style of finely decorated pottery – like those at Llanharry (discovered 1929) and at Llandaff (1991) – that gave rise to the Early Bronze Age being described as "Beaker culture". From c. 3350 BP, a worsening climate began to make agriculture unsustainable in upland areas. The resulting population pressures appear to have led to conflict. Hill forts began to be built from the Late Bronze Age (and throughout the Iron Age (3150–1900 BP)) and the amount and quality of weapons increased noticeably – along the regionally distinctive tribal lines of the Iron Age.
Archaeological evidence from two sites in Glamorgan shows Bronze Age practices and settlements continued into the Iron Age. Finds from "Llyn Fawr", thought to be votive offerings, include weapons and tools from the Late Bronze Age and the Early Iron Age. The hoard has given its name to the Llyn Fawr Phase, the last Bronze Age phase in Britain. Excavations at Llanmaes, Vale of Glamorgan, indicate a settlement and "feasting site" occupied from the Late Bronze Age until the Roman occupation. Until the Roman conquest of Britain, the area that would become known as Glamorgan was part of the territory of the Silures – a Celtic British tribe that flourished in the Iron Age – whose territory also included the areas that would become known as Breconshire and Monmouthshire. The Silures had hill forts throughout the area – e.g., Caerau (Cardiff), Caerau hill fort, Rhiwsaeson (Llantrisant), and Y Bwlwarcau [Mynydd Margam, south west of Maesteg – and cliff castles along the Glamorgan coast – e.g., Burry Holms (Gower Peninsula). Excavations at one – Dunraven hill fort (Southerndown, Vale of Glamorgan) – revealed the remains of twenty-one roundhouses.
Many other settlements of the Silures were neither hill forts nor castles. For example, the 3.2 ha fort established by the Romans near the mouth of the River Taff in 75 CE (Common Era), in what would become Cardiff, was built over an extensive settlement established by the Silures in the 50s CE.
Morgannwg.
History AD 500–1080.
The region originated as an independent petty kingdom named "Glywysing", believed to be named after a 5th-century Welsh king called Glywys, who is said to have been descended from a Roman Governor in the region. Saint Paul Aurelian was born in Glamorgan in the 6th century. The name "Morgannwg" or "Glamorgan" ('territory of Morgan') reputedly derives from the 8th-century king Morgan ab Athrwys, otherwise known as "Morgan Mwynfawr" ('great in riches') who united "Glywysing" with the neighbouring kingdoms of Gwent and Ergyng, although some have argued for the similar 10th-century ruler Morgan Hen. It is possible it was only the union of Gwent and Glywysing that was referred to as Morgannwg. By virtue of its location and geography, Morgannwg or Glywysing was the second part of Wales, after Gwent, to fall under the control of the Normans and was frequently the scene of fighting between the Marcher Lords and Welsh princes.
Buildings of note, 500–1080.
The earliest buildings of note included earthwork dykes and rudimentary motte-and-bailey hillside defences. All that remains of these fortifications are foundations that leave archaeological evidence of their existence, though many were built upon to create more permanent defensive structures. The earliest surviving structures within the region are early stone monuments, waypoints and grave markers dating between the 5th and 7th century, with many being moved from their original position to sheltered locations for protection. The most notable of the early stone markers still in its original place is on a high mountain ridge at Gelligaer. Of the later plaitwork patterned standing crosses the finest and best preserved is the 9th century 'Houelt' stone at Llantwit Major.
Lordship of Glamorgan.
History, 1080–1536.
The Lordship of Glamorgan was established by Robert Fitzhamon following the defeat of Iestyn ap Gwrgant in the 1080s. The Lordship of Morgannwg was split after it was conquered; the kingdom of Glamorgan had as its caput the town of Cardiff and took in the lands from the River Tawe to the River Rhymney. The Lordship took in four of the Welsh cantrefi, Gorfynydd, Penychen, Senghenydd and Gwynllwg. The area later known as the Gower Peninsula was not under the Lordship of Glamorgan, and became the Gower Lordship which had previously been the cantref of Gŵyr. The lowlands of the Lordship of Glamorgan were manorialized, while much of the sparsely populated uplands were left under Welsh control until the late 13th century. Upon the death of William, Lord of Glamorgan, his extensive holdings were eventually granted to Gilbert de Clare in 1217. The subjugation of Glamorgan, begun by Fitzhamon, was finally completed by the powerful De Clare family, and in 1486 the kingdom was granted to Jasper Tudor.
Buildings of note, 1080–1536.
The legacy of the Marcher Lords left the area scattered with historic buildings including Norman castles, Cistercian Abbeys, churches and medieval monuments.
The kingdom of Glamorgan was also notable for the number of castles built during the time of the Marcher Lords, many surviving to the present day though many are now ruinous. Of the castles built during the medieval period, those still standing above foundation level include, Caerphilly Castle, Cardiff Castle, Ogmore Castle, St Quintins Castle, Coity Castle, Neath Castle and Oystermouth Castle. Many of the castles within Morgannwg were attacked by forces led by Owain Glyndŵr during the Welsh Revolt of 1400–1415. Some were captured, and several were damaged to such an extent they were never maintained as defences again.
When the Diocese of Llandaff became incorporated into the Province of Canterbury, the Bishop of Llandaff rebuilt over the small church with the beginnings of Llandaff Cathedral in 1120. In the western region of Morgannwg two monastic foundations were sited, a Savigniac house in Neath in 1130 and the Cistercian Margam Abbey in 1147. In the Vale a Benedictine monastery was founded in 1141, Ewenny Priory, a community under the patronage of St. Peter's Gloucester. The building of parish churches also began in the 12th century, densely in the Vale, but very sparsely in the upland and northern areas.
County of Glamorgan.
History 1536–1750.
The Laws in Wales Acts of 1535 established the County of Glamorgan through the amalgamation of the Lordship of Glamorgan with the lordships of Gower and Kilvey; the area that had previously been the cantref of Gwynllwg was lost to Monmouthshire. With Wales finally incorporated with the English dominions, the administration of justice passed into the hands of the crown. The Lordship became a shire and was awarded its first Parliamentary representative with the creation of the Glamorganshire constituency in 1536. The Reformation, which was closely followed by the Dissolution of the Monasteries, led to vast social changes across Britain. These events, along with the Act of Union, allowed the leading Welsh families to gain in wealth and prosperity, allowing equal footing to those families of English extraction. Old monasteries, with their lands, were acquired by the wealthy and turned into country houses; their notable residents preferring to live in gentry houses rather than the fortified castles of the past. Major families in Glamorgan included the Carnes at Ewenny, the Mansels at Margam, Williams of Neath, the Herberts at Cardiff and Swansea and the Stradlings of St Donats.
The main industry of Glamorgan during this period was agriculture. In the upland, or "Blaenau" area, the hilly terrain along with many areas being densely wooded, made arable farming unprofitable, so the local farming concentrated on the rearing of horses, cattle and sheep. The lowland, or "Bro" was devoted to more general branches of farming, cereal, grass for pasture, hay and stock raising. Non-agricultural industries were generally small scale, with some shallow coal pits, fulling mills, weaving and pottery-making. The main heavy industry of note during this period was copper smelting, and this was centred on the towns of Swansea and Neath. Although copper had been mined in Wales since the Bronze Age, it was not until non-ferrous metalworking became a major industry in the late 17th century that Glamorgan saw a concentration of works appearing in a belt between Kidwelly and Port Talbot. Smelting of copper started around Neath under the Mines Royal Society c. 1584 but the scale of the works increased dramatically from the early 18th century when Swansea displaced Bristol as Britain's copper smelting capital. Easy access to Cornish ores and a local outcropping of coal near the surface, gave Swansea economic advantages in the smelting industry.
Early iron smelting within Glamorgan was a localised and minor industry, with historical evidence pointing to scattered ironworks throughout the county. John Leland mentions a works at Llantrisant in 1539, an operation in Aberdare existed during the reign of Edward VI and two iron furnaces were recorded as being set up by Sir W. Mathew in Radyr during the Elizabethan era. By 1666 a furnace was in operation in Hirwaun and in 1680 a smelting hearth was established in Caerphilly. Despite the existence of these industries, the scale of production was small, and in 1740 the total output of iron from Glamorgan was reported at 400 tons per year.
Glamorgan, now falling under the protection of the crown, was also involved in the conflicts of the crown. With the start of the First English Civil War, there was little support from the Welsh for the Parliamentarians. Glamorgan sent troops to join Charles I at the Battle of Edgehill, and their Member of Parliament Sir Edward Stradling was captured in the conflict. In the Second English Civil War, the war came to Glamorgan at the Battle of St Fagans (1648), where the New Model Army overcame a larger Royalist to prevent a siege of Cardiff.
Buildings of note, 1536–1750.
The period between the Laws in Wales Acts and the industrialisation of Glamorgan saw two distinct periods architecturally. From the 1530s throughout to 1650, the newly empowered gentry attempted to show their status by building stately homes to show their wealth; but the period from 1650 through to the mid-1750s was a fallow time for architectural grandeur, with few new wealthy families moving to the area. Of the eight major gentry houses of the time only St Fagans Castle survives with its interior intact; five, Neath Abbey, Old Beaupre Castle, Oxwich Castle, Llantrithyd and Ruperra Castle are ruinous. Of the remaining two manors, The Van at Caerphilly was reconstructed in 1990 while Cefnmabli was gutted by a fire in 1994. The old castles became abandoned throughout this period due to the new security brought by Glamorgan coming under the protection of the crown, with only the Stradlings of St Donat's Castle electing to remain in their old ancestral home.
By the 17th century, the availability of fine building stone permitted the construction of high-quality lime-washed rural cottages and farmhouses in the Vale of Glamorgan, which drew favourable remarks from travellers. A Glamorgan yeoman of the time generally lived in greater comfort than his contemporaries of the more westerly or upland parts of Wales such as Cardiganshire or north Carmarthenshire.
Industrial Glamorgan, 1750–1920.
Metals industry.
From the mid-18th century onwards, Glamorgan's uplands underwent large-scale industrialisation and several coastal towns, in particular Swansea and later Cardiff, became significant ports. From the late 18th century until the early 20th century Glamorgan produced 70 per cent of the British output of copper. The industry was developed by English entrepreneurs and investors such as John Henry Vivian and largely based in the west of the county, where coal could be purchased cheaply and ores imported from Cornwall, Devon and later much further afield. The industry was of immense importance to Swansea in particular; in 1823 the smelting works on the River Tawe, and the colleries and shipping dependent on them, supported between 8,000 and 10,000 people. Imports of copper ores reached a peak in the 1880s, after which there was a steep fall until the virtual end of the trade in the 1920s. The cost of shipping ores from distant countries, and the growth of foreign competitors, ended Glamorgan's dominance of the industry. Some of the works converted to the production of zinc and the Tawe valley also became a location for the manufacture of nickel after Ludwig Mond established a works at Clydach in 1902.
Even at its peak, copper smelting was never as significant as iron smelting, which was the major industrial employer of men and capital in south Wales before the rise of the sale-coal industry. Ironmaking developed in locations where ironstone, coal and limestone were found in close proximity - primarily the northern and south-western parts of the South Wales coalfield. In the second half of the 18th century four ironworks were built in Merthyr Tydfil. In 1759 the Dowlais Ironworks were established by a partnership of nine men. This was followed by the Plymouth Ironworks in 1763, which was formed by Isaac Wilkinson and John Guest, then in 1765 Anthony Bacon established the Cyfarthfa Ironworks. The fourth of the great ironworks, Penydarren Ironworks was built in 1784. These works made Merthyr Tydfil the main centre of the industry in Wales.
As well as copper and iron, Glamorgan became an important centre for the tinplate industry. Although not as famous as the Llanelli or Pontypool works, a concentrated number of works emerged around Swansea, Aberavon and Neath towards the late 19th century. Glamorgan became the most populous and industrialised county in Wales and was known as the 'crucible of the Industrial Revolution'.
Other areas to house heavy industries include ironworks in Maesteg (1826), tinplate works in Llwydarth and Pontyclun and an iron ore mine in Llanharry.
Alongside the metalworks, industries appeared throughout Glamorgan that made use of the works' output. Pontypridd was well known for the Brown Lenox Chainworks, which during the 19th century was the town's main industrial employer.
Coal industry.
The largest change to industrial Glamorgan was the opening up of the South Wales coalfield, the largest continuous coalfield in Britain, which occupied the greater part of Glamorgan, mostly north of the Vale. The coalfield provided a vast range in quality and type, but prior to 1750 the only real access to the seams was through bell pits or digging horizontally into a level where the seam was exposed at a river bank or mountainside. Although initially excavated for export, coal was soon also needed for the smelting process in Britain's expanding metallurgical industries. Developments in coal mining began in the north-eastern rim of Glamorgan around the ironworks of Merthyr and in the south-west around the copper plants of Swansea. In 1828 the South Wales coalfiled was producing an estimated 3 million tons of coal, by 1840 that had risen to 4.5 million, with about 70 percent consumed by local commercial and domestic usage.
The 1840s saw the start of a dramatic increase in the amount of coal excavated within Glamorgan. Several events took place to precipitate the growth in coal mining, including the discovery of steam coal in the Cynon Valley, the building of a large masonry dock at Cardiff and the construction of the Taff Vale Railway. In 1845, after trials by the British Admiralty, Welsh steam coal replaced coal from Newcastle-upon-Tyne as the preferred fuel for the ships of the Royal Navy. Glamorgan steam coal quickly became a sought-after commodity for navies all over the world and its production increased to meet the demand.
The richest source for steam coal was the Rhondda Valleys, and by 1856 the Taff Vale Railway had reached the heads of both valleys. Over the next fifty years the Rhondda would grow to become the largest producer of coal of the age. In 1874, the Rhondda produced 2.13 million tons of coal, which rose to 5.8 million tons by 1884. The coal now produced in Glamorgan far exceeded the interior demand, and in the later half of the 19th century the area became a mass exporter for its product. In the 1890s the docks of South Wales accounted for 38 percent of British coal exports and a quarter of global trade.
Along with the increase in coal production came a very large increase in the population, as people emigrated to the area to seek employment. In Aberdare the population grew from 6,471 in 1841 to 32,299 in 1851 while the Rhondda grew from 3,035 in 1861 to 55,632 in 1881, peaking in 1921 at 162,729. Much of this population growth was driven by immigration. In the ten years from 1881–1891, net migration to Glamorgan was over 76,000, 63 per cent of which was from the non-border counties of England - a proportion that increased in the following decade.
Agriculture.
Until the beginning of the 18th century, Glamorgan was almost entirely agriculture based. With the industrialisation of the county, farming became of far less importance, with industrial areas encroaching into farming lands. In Glamorgan, from the late 19th century, there was a significant reduction away from arable land towards pasture land. There were two main factors behind this trend; firstly the increase in the population of the county required more milk and other dairy produce, in an age before refrigeration. Secondly there was an employment shortage in farming due to the call of better paid industrial work, and pastoral land was less work intensive. Stock rearing became prominent with breeds such as Hereford, Devon and Shorthorn cattle being bred in the Vale of Glamorgan, while the unenclosed wilds of the Gower saw Welsh Ponies bred on the commons.
Buildings of note 1750–1920.
The industrial period of Glamorgan saw a massive building program throughout the uplands and in the coastal regions, reflecting the increasing population and the need for new cheap housing to accommodate the hundreds of thousands of workers coming into the area. As the towns urbanised and the hamlets became villages, the trappings of modern life were reflected in the buildings required to sustain new and growing communities. The period saw the appearance, not only of the works and pits themselves, but of the terrace house or miners cottage, railway stations, hospitals, churches, chapels, bridges, viaducts, stadiums, schools, universities, museums and workingmen's halls.
As well as the architecture of Glamorgan entering modernity, there was also a reflection to the past, with some individuals who made the most from the booming industrial economy restoring symbols of the past, building follies and commissioning Gothic-style additions to ancient churches. Robert Lugar's Cyfarthfa Castle in Merthyr (1825) and the late 19th century additions to Cardiff Castle, designed by William Burges, exemplify how Gothic was the favoured style for rich industrialists and entrepreneurs. Greek Revival architecture, popularised in France and Germany in the late 18th century, was used for a number of public and educational buildings in Wales including the Royal Institution of South Wales in Swansea (1841) and Bridgend Town Hall (1843).
In 1897, Cardiff Corporation acquired land from the Marquess of Bute with the intention of erecting buildings to meet the administrative, legal and educational needs of Glamorgan's county town. From 1901 onwards, Cathays Park was developed into "possibly the finest... civic centre in Britain" with a range of public buildings including the Baroque City Hall and the rococo-style University College.
The majority of Nonconformist chapels were built in the 19th century. They progressed from simple, single-storey designs to larger and more elaborate structures, most built in the classical style. Perhaps the most ambitious chapel was John Humphrey's Morriston Tabernacle (1872), incorporating Classical, Romanesque and Gothic elements, which has been called the 'Noncomformist Cathedral of Wales'.
Industrial architecture tended to be functional, although some structures, such as the four-storey engine house at Cyfarthfa Ironworks (1836), were built to impress. Coal mining eventually became the dominant industry in Glamorgan and tall winding towers - originally made of timber or cast iron, later steel - became symbolic icons.
Late-period Glamorgan, 1920–1974.
After the First World War, there was an initial drop in coal and iron production, there was still enough demand to push the coalfields to their limits, helped by events such as the American coal miners' strike. Cardiff Docks reached an exporting peak in 1923, but soon production fell and unemployment in the upland valleys began to increase at a dramatic rate. Between April 1924 and August 1925 the unemployment rate amongst South Wales miners jumped from 1.8% to 28.5%. Several factors came together to cause this collapse, including the over-valuation of sterling, the end of the coal subsidy, the growth of electric power, the adoption of oil as the fuel of choice for many industries, and over-expansion of the mines in the late nineteenth century. The Welsh coal owners had failed to invest mechanisation during the good years, and by the 1930s the South Wales Coalfield had the lowest productivity, highest production costs and smallest profits of all Britain's coal-producing regions.
These structural problems were followed by the General Strike of 1926 and then most disastrously the interwar depression of 1929–1931, which changed the face of industrial Glamorgan forever. In 1932, Glamorgan had an unemployment rate of more than 40 per cent, and one of the highest proportions of people receiving poor relief in the United Kingdom. This was a contrast with relatively recent prosperity: for example, in 1913 unemployment in Merthyr was below 2 per cent and the borough had 24,000 miners. By 1921, the number of employed miners had fallen to 16,000, and in 1934, it was down to 8,000.
Steel production was no less depressed than the coal industry. The inter-war years saw the closure of the old Cyfarthfa and Dowlais works, as steel-making became increasingly concentrated in the coastal belt. Both the coal and steel industries were increasingly dominated by large amalgamations, such as Powell Duffryn and Guest, Keen and Nettlefolds. The smaller companies progressively disappeared.
Glamorgan suffered disproportionately during the Great Depression because of the high proportion of its workforce employed in primary production rather than the manufacture of finished products. Other parts of Britain began to recover as domestic demand for consumer products picked up, but unemployment in the South Wales Valleys continued to rise: the jobless rate in Merthyr reached 47.5 per cent in June 1935. However, the coastal ports, Cardiff and Swansea, managed to sustain a "reasonable" level of economic activity, and the anthracite coalfield in western Glamorgan (and eastern Carmarthenshire) also managed to maintain production and exports above pre-war levels.
With the outbreak of World War II the coalfields of Glamorgan saw a sharp rise in trade and employment. Despite the demand the want for the youth to conscript in the war effort in the valley areas meant that there was a shortage of workers to run the mines; this in turn saw the introduction of the Bevin Boys, workers conscripted to work in the mines. During the war both Cardiff and Swansea were targets for German air attacks due to their important docks.
Buildings and structures of note, 1920–1974.
After the First World War, Glamorgan, as was typical for Britain as a whole, entered a period of modernity, which saw buildings built and designed for functionality rather than splendour with period features watered down. As the century progressed, symbols of the past industrial period were torn down and replaced with industrial estates populated by unadorned geometric factories. With concrete becoming the favourite post-war building material, larger office blocks began appearing within the cities, though few were of any architectural significance.
Despite entering a fallow period of architectural design, several structures of note did emerge. Although work began in 1911, The National Museum of Wales (Smith and Brewer) was not completed until 1927 due to the First World War. Designed to reflect sympathetically in dimensions with its neighbouring city hall, the dome-topped museum combines many architectural motifs with Doric columns at its facade, while internally a large entrance hall with stairs, landings and balconies. Percy Thomas' Guildhall in Swansea, an example of the 'stripped modernist' style completed in 1936, was described as "Wales' finest interwar building".
Although functionality often deprived a building of interest, Sully Hospital (Pite, Son & Fairweather) is an example of a building which gained from its functional requirements. Initially built for tubercular patients, whose cure required the maximum amount of light and air, the Functional architecture left a striking glass fronted building, completed in 1936.
Another hospital to which Functionalism was applied was the University Hospital of Wales (S.W. Milburn & Partners). Begun in the 1960s, and completed in 1971, the building is the third largest hospital in the United Kingdom and the largest in Wales. It was designed to bring the care of patients, research and medical teaching together under one roof.
The demands of modern living saw the growth of housing estates throughout Glamorgan, moving away from the Victorian terrace of Cardiff or the ribbon cottages of the valleys. Several of these projects were failures architecturally and socially. Of note were the Billybanks estate in Penarth and Penrhys Estate (Alex Robertson, Peter Francis & Partners) in the Rhondda, both described by Malcolm Parry, the former Head of the School of Architecture at Cardiff University, as "...the worst examples of architecture and planning in Wales."
Geography.
Glamorgan divides into three distinct and contrasting geographical areas. To the south east is a gently undulating limestone plateau, virtually coterminous with the modern county borough of Vale of Glamorgan, mainly comprising farmland and small villages stretching from Porthcawl to Cardiff. The lowlands are geographically the best environment for agriculture of the three areas. Settlements in the area included Cardiff, Barry, Bridgend, Cowbridge, Penarth and Porthcawl.
The northern part of the county is a mountainous area, dissected by deep narrow valleys. At the southern edge of the Brecon Beacons, the simple geological structure of Old Red Sandstone gives way to Carboniferous rocks; limestone, shales and millstone grit. In the 19th century, industrial and population growth in the coal-bearing valleys of the Rhymney, Taff, Dare and Rhondda gave rise to a form of urbanisation characterised as ribbon development. The last deep mine, Tower Colliery at Hirwaun, closed in January 2008. A few small drift mines like Unity Mine (formerly Pentreclwydau South) near Glynneath remain. Towns in the region included Aberdare, Caerphilly, Pontypridd, Maesteg, Merthyr Tydfil and Mountain Ash.
Further west is Swansea Bay and the Gower Peninsula, an Area of Outstanding Natural Beauty. Of all the areas, Gower was the least affected by heavy industry and the ancient landscape was the least impaired. The high ground that runs centrally through the Gower was largely uncultivated common land and its beaches and rocky coastal headlands showed little signs of the tourist trade that played an increasing role on the local economy. The major settlements of the region include Swansea, Neath and Port Talbot.
Coastline.
The coastline of Glamorgan stretches for 88 miles from Trowbridge in the east to Gower in the west. It divides naturally into three distinct sections. The coast of the Vale of Glamorgan is mainly characterised by cliffs, while from Porthcawl to Swansea Bay wide sandy shores prevail. The final section, the Gower coast, is made up of a rugged and serrated peninsula.
From the east the first major coastline feature is the Rhymney River, once seen as the natural border between Glamorgan and Monmouthshire, until the absorption of Trowbridge into the Cardiff district in 1936. Heading west, the coast is an expanse of alluvial deposits stretching to the mouth of Glamorgan's most well known river, the River Taff. Once marshland, the area was consumed by the rapid growth of the Cardiff Docks during the industrial revolution, but with the downturn in Glamorgan's iron and coal industries, the docks declined. Also flowing into Cardiff Docks is the River Ely, which separates Cardiff from the headland and seaside resort of Penarth in the Vale of Glamorgan. Here the coast stretches southwards for two and a half miles from Penarth Head to Lavernock Point, hidden from vessels travelling up the Bristol Channel. South easterly from Lavernock Point, roughly three miles out in the Channel Estuary is Flat Holm, an island which although geographically is within the Vale, is administered as part of the city of Cardiff. Flat Holm is the most southerly point of Glamorgan and Wales.
From Lavernock Point the coast heads sharply west to the town of Barry, a well known seaside resort, Barry is most notable for its rapid expansion during the late 19th century to become an important dock, at one stage surpassing Cardiff Dock for the tonnage of coal exported. Passing the cliffs of Barry Island the coastline becomes a low-lying promontory called the Lays, which continues west taking in the villages of Rhoose and Aberthaw before reaching Breaksea Point, the most southerly point of mainland Wales. Beyond the point is Limpert Bay, which is overlooked by the village of Gileston and the ancient encampment of Summerhouse Point. Here the cliffs rise and run for eleven miles as far as the estuary of the Ogmore. Along this run of cliffs the coast passes Llantwit Major and St Donats, before heading in a rough north west direction at Nash Point.
The coastline remains as steep cliffs until after Dunraven Head, where the cliff face drops away to expose Southerndown Beach. Two miles beyond, the Ogmore River runs out into a sand-locked bay which can been seen as commencing the second section of the Glamorgan coast, as here the scenery undergoes an abrupt change; from a series of unbroken cliffs to vast regions of sandy beaches. The Ogmore Bay at Ogmore-by-Sea is not only floored with sand but is also backed by high and extensive sand dune system, these impressive natural sand features are commonly known as the Merthyr Mawr sand dunes. Beyond the bay the underlying rocks emerge from the sand to form the promontory of Porthcawl Point. Porthcawl town, once possessing a small dock, abandoned the trade in favour of tourism. The coast continues to the north west as a low rocky formation for three miles to Sker Point, after which the sand line begins again, forming an arid wilderness all the way to Port Talbot. Port Talbot was one of the later industrial towns of Glamorgan, and grew out of the medieval village of Aberavon, a settlement built on the banks of the River Afan. To the west of the mouth of the Afan is the new district of Sandfields, built over the holiday dunes of Aberavon beach in the 1950s to house the workforce of Port Talbot Steelworks.
The River Afan commences the wide sweep of Swansea Bay, which from Port Talbot arcs around taking in Baglan Bay, Briton Ferry, Swansea and ending in Mumbles. The whole bay is shut in by high hills and is thickly encircled with sands. Within the bay are two of the major estuaries of Glamorgan; from Port Talbot the first is the River Neath, which is protected by long breakwaters. The second is the Tawe, the central river of Swansea. Beyond the Tawe the bay sweeps for six miles before reaching Mumbles Head, its most westerly point. Mumbles Head is served by Mumbles Lighthouse, which sits on the further of two small islands off the head.
At The Mumbles, the coastline begins its third phase, commencing the wild and rugged cliffs of the Gower. From Mumbles Head to Worm's Head, 20 miles to the west, the coast consists of a series of precipitous cliffs, interrupted by a number of sandy bays. The most notable of the bays include Langland Bay, Caswell Bay, Pwlldu Bay, Three Cliffs Bay and Oxwich Bay. Three Cliffs Bay and the adjoining Oxwich Bay are overlooked by three medieval defences, Pennard Castle, Penrice Castle and Oxwich Castle, all three now ruinous. Oxwich Bay ends in the large wooded promontory of Oxwich Point, which leads west to the beach front villages of Horton and Port Eynon. From Port Eynon Point, a five-mile stretch of wild and impressive cliffs leads to Worm's Head and the western termination of the peninsula. This rock face is pierced in places by caverns, the most notable being Culver Hole a bone cave near Port Eynon Point.
Worm's Head is one of the stand out features of the Glamorgan coastline, a long narrow ledge of limestone, projecting into the sea, ending in a 200 foot high wedge shaped crag; the Head takes its name from its resemblance to a dragon. On the northern side of the Worm's Head is the village and Bay of Rhossili, a westerly facing bay that leads backwards to a series of downs, some of the highest land in the Gower. Rhossili Bay ends in the northern formation of Llangenydd Burrows and the islet of Burry Holms. The final stretch of Glamorgan coastline turns north east to form the Burry Inlet, a shallow and sand-choked estuary which leads to a tract of salt marshes which stretch to the mouth of the River Loughor. The Loughor forming the border between Glamorgan and Carmarthenshire.
Rivers.
The major rivers of Glamorgan include the Taff, the Ely, the Ogmore, the Neath, Dulais, the Tawe, the Rhymney (which forms the historic boundary with Monmouthshire), and the Loughor (which forms the historic boundary with Carmarthenshire).
Administration.
After the fall of the Welsh kingdom of Morgannwg to Robert FitzHamon in 1091, the region became the English Lordship of Glamorgan, sometimes called the Lordship of Glamorgan and Morgan because it was divided into the Norman settled Plain or Vale of Glamorgan and the Welsh upland area called Morgannwg, anglicized to Morgan. Both areas were under the control of the Norman Lords of Glamorgan (often the Earls of Gloucester). As well as building a military and defensive network, the Normans also undertook an ecclesiastical reorganisation on Glamorgan. In Llandaff there was a small monastic community based on a small church; which was made the headquarters of the diocese, incorporated into the Province of Canterbury. The Diocese of Llandaff covered almost the entirety of Glamorgan and continued throughout the history of the county of Glamorgan, and through to modern times.
In 1536, the Laws in Wales Act 1535 attached the Lordship of Gower and Kilvey to Glamorgan and created the historic county of Glamorgan. Along with gaining parliamentary representation in 1536, Glamorgan became part of the King's circuit, with judges from England administering law at the Great Session or Assizes. Local magistrates were appointed to deal with petty sessions while Lords Lieutenant were appointed as the King's representative. Law enforcement within the confines of the shire was the responsibility of the High Sheriff of Glamorgan.
From the 1790s a call was made for parliamentary reform to address the imbalance between the number of Members of Parliament for each Welsh county and the population each seat represented. Radnorshire had only a tenth of the population of Glamorganshire, though Radnorshire had one MP to Glamorganshire's two (Glamorgan and the District of Cardiff). The First Reform Act (1832) gave five more seats to Wales, three went to Glamorganshire. The Act increased the number of MPs for Glamorganshire from one to two, it created the separate District of Swansea and Merthyr Tydfil became a borough constituency. Reflecting the increased importance and wealth of Merthyr the borough was given a second MP after the Reform Act 1867. However, the 1867 Act had only a limited impact in Glamorgan as the majority of the population lived in the county constituency. Out of 162,241 inhabitants of the county in 1880, only 12,785 had the vote. Conversely, the borough electorate, in Cardiff, Swansea and Merthyr Tydfil had been greatly expanded. This was particularly true of Merthyr where the electorate was increased tenfold to 14,577. As a result, the nonconformist radical, Henry Richard, was returned as senior member for Merthyr, an important watershed in Welsh political history.
The next major redistribution of MPs occurred with the Redistribution of Seats Act 1885. Glamorganshire was split from its two Members of Parliament to five, with the creation of constituencies for East, Mid and South Glamorganshire, Gower and Rhondda. An additional Swansea Town constituency was created, distinct from Swansea District but the Cardiff constituency remained unchanged, and with over 85,000 inhabitants became the largest single-member constituency in the United Kingdom. At this election, all ten members returned for Glamorgan were Liberals, an event which marked the ascendancy of the nonconformist middle-class as a powerful political force. Although most of these seats now had the working-class electorate in a majority they were safe for the Liberals as long as the labour element remained in the Liberal fold.
An administrative county of Glamorgan was created under the Local Government Act 1888, excluding Swansea and Cardiff, which became independent county boroughs. In 1908, county borough status was also granted to Merthyr Tydfil, despite protests from the southern part of the borough, where it was claimed that links were stronger with Pontypridd. In 1935, a Royal Commission argued that Merthyr Tydfil County Borough, then heavily burdened by the cost of maintaining many unemployed people, should be abolished and merged with Glamorgan. The county council refused the proposal.
The first chairman of the County Council was Henry Vivian, 1st Baron Swansea. The county council's coat of arms, granted in 1950, was: "Or, three chevronels gules between as many Tudor roses barbed and seeded proper". The red chevronels on a gold shield were the arms of the De Clare Marcher Lords, while the roses recorded the shiring of Glamorgan by Henry VIII. The crest above the shield was a Welsh dragon rising from flames, symbolising the revival of the county's industry following a period of economic depression. The dragon supported a flag bearing a clarion from the arms of the De Granville family, lords of Neath. The supporters of the arms were a coalminer and a steel worker. The motto adopted by the county council: "A Ddioddefws A Orfu" or "He Who suffered, conquered" was that of the lineage of Iestyn ap Gwrgant, and was considered appropriate to an area whose wealth depended on great hardship.
Under the Local Government Act 1972, the county boroughs and administrative county of Glamorgan were abolished on 1 April 1974, with three new counties being established, each containing a former county borough - West Glamorgan, Mid Glamorgan, South Glamorgan. It 1996 these areas were reorganised into several unitary authorities by the Local Government Act of 1994. The South Wales Police force covers an area that is similar to Glamorgan.
Transport.
Roads.
The earliest forms of transport within Glamorgan were mere paths or trackways linking one settlement to another. With continual use the tracks widened to allow different forms of travel, including the use by pack horses; and as the tracks became more recognisable the first primitive roads came into being. The Romans established a route, Via Julia Maritima, to service their garrisons across South Wales and this is followed largely by the present A48. However, for 1,000 years after the Romans there was little need for major roads. Early roads were not systematically managed, and in Glamorgan as in the rest of Wales, they were in a very poor state. Towards Tudor times the upkeep and repair of the roads came under the administration of each parish, with six days of the week during the summer allowed for track repairs. These repairs were rarely completed and the roadways continued to suffer. An Act of 1555 required each landowner to produce a cart, horses or bullocks, and two men to work 4 days on roads. Supervision was by two unpaid surveyors appointed by the parish. By the late 1600s the situation improved as surveyors were appointed by the magistrates, who were allowed to levy a rate to pay for some of the work.
In 1756, after the shire of Glamorgan had come under the rule of the crown, Wales adopted a toll system for the maintenance of the roads; with the governance falling under the control of the turnpike trusts. Further Turnpike Acts came into force in 1799 and 1810, and these Acts allowed trustees to collect a toll for the use of certain roads within a district. In South Wales there were turnpikes along the coast, more or less following the present motorway line, up the Merthyr Valley and across the hills to Abergavenny, Brecon, Llandovery and down to Carmarthen. This system improved travelling conditions, allowing for stage coaches which were then coming into general use. Although the roads improved there were those who felt that the tolls were unjust, and there was a popular uprising between 1839 and 1843 known as the Rebecca Riots where agitators attacked and destroyed the toll houses. Although most of these attacks occurred in Carmarthenshire, there were reports of attacks within Glamorgan, most notably in Swansea. In 1846, County Highway Boards were established in south Wales, to buy out the turnpike trusts and take over their functions. In 1878 all roads that had ceased to be turnpiked after 1870 were deemed as 'main roads' by the Highways and Locomotives Act of 1878. The turnpike system was eventually abolished by the Local Government Act 1888 and the roads were placed under the management of the local county council. County Highway Boards were disbanded. There were, however, a number of urban areas within Glamorgan that retained the right to control their own highways, and the county council never achieved control of the whole highway network.
Proposals for a high-quality new road across South Wales were first made in the 1930s. However, the dualling of the A48 Neath bypass was only completed in 1960, with the A48(M) Port Talbot bypass following in 1966. The latter road, an early example of dual carriageway construction through a built-up area, was the first length of motorway opened to traffic in Wales. The Ministry of Transport initially envisaged that the new M4 motorway would terminate at Tredegar Park near Newport, with a series of bypasses to improve the A48 further west. The creation of the Welsh Office led to a re-appraisal of policy and a decision to extend the M4 further into Glamorgan. By 1970, the Welsh Office was committed to building a new route all the way to Pont Abraham in Carmarthenshire. The 1960s also saw the construction of the first road across the Heads of the Valleys, with the A465 Neath-Abergavenny trunk road opening in 1964. However, even at the outset there were complaints about the capacity and safety of its single carriageway, three-lane design.
Waterways and ports.
Due to Glamorgan's long coastline, several settlements grew and prospered as harbour and port towns. In 1801, Swansea was Glamorgan's largest urban area with a population five times that of Cardiff's. Cowbridge was the capital town of the Vale, and the centre of agricultural trade, with surplus stock being shipped to the coastal village of Aberthaw and to a lesser extent Newton. Where there were breaks in the rocky coastline, small fishing and cockling communities existed, such as Port Eynon and Penclawdd.
The event that changed the face of coastal Glamorgan was the growth of the Merthyr iron industry. Merthyr needed a coastal export point for its iron and Cardiff was the obvious choice being at the mouth of the River Taff. A road was built to connect the two towns, but with only horses to move the cargo, transportation was cumbersome; therefore an alternative was planned. Although Glamorgan had a large number of rivers, few were navigable for any considerable length. Between 1790 and 1794, Acts of Parliament were obtained for the construction of three canals within Glamorgan, the Glamorganshire Canal (1790), Neath Canal (1791) and the Swansea Canal (1794). All three were vital in increasing the transportation of iron, copper, steel and coal from the uplands of the county to the ports at Swansea and Cardiff. Although the first stages of all three canals were completed by 1800 and revolutionised the commercial transportation systems of Glamorgan; in 1804 at Penydarren Ironworks, Richard Trevithick's "Pen-y-Darren" locomotive became the first engine to pull a load along rails; heralding the coming of the railways, which would eventually replace the canals.
The port at Cardiff grew quickly during the 19th century, not as a mass exporter of iron but of coal, transported from Pontypridd and the Cynon and Rhondda Valleys. From 1840 to 1870 Cardiff's export tonnage of coal increased from 44,350 to 2,219,000. By 1871, Cardiff had outgrown all of its Welsh rivals to become the most populous town in the country Swansea Docks continued to be the world's leading exporter of copper, but did not experience the growth of Cardiff due to poor links to the coalfields. Ambitious attempts were made to link Swansea's docks to coal rich areas, such as the Rhondda and Swansea Bay Railway, but these plans were never truly economically successful. The biggest threat to Cardiff's dominance came in the early 20th century at Barry. In 1881, Barry had 484 inhabitants, after an 1884 Parliamentary Act authorising the construction of a docks and railway link, the town grew to over 27,000 by 1901. The chief advocate of Barry's growth as a dock was David Davies, and in 1901 Barry was exporting more coal than Cardiff, peaking in 1913 when it shipped 11.41 million tons.
The interwar depression experienced by Great Britain brought an end to the prosperity of the Glamorgan ports. During the Second World War, the main ports of Glamorgan were heavily targeted by German bombing raids, though exports were not severely disrupted. By the second half of the 20th century none of the county's docks showed any growth, and with the collapse of the coal trade in South Wales Cardiff and Barry Docks became near derelict, shipping mainly general cargo. Swansea also suffered a vast reduction on trade with the end of the area as a world leader in copper smelting. The only dock to remain a viable exporter was the Port of Port Talbot. First built in 1839, the docks at Port Talbot were a minor concern in relation to the more established ports, but exports increased after the 1916 with the completion of the Margam Steelworks. Exports continued strongly when the Abbey Works were built in 1952. Port Talbot would eventually become the biggest exporting port in Glamorgan, and the second largest in Wales, only surpassed by Milford Haven.
Rail.
Before the use of locomotives, railway track was used at various stages of the canal system to link locations to which the waterways could not reach. These wagons on these tramlines would be pulled by horse over wooden rails, which later were replaced by wrought iron. In 1809 Richard Griffiths built a private tram-road to the Glamorganshire Canal from his coal mine in Gyfeillion. The Gyfeillion site was extended further in 1811 to link Walter Coffin's mine at Dinas Rhondda, allowing the first viable transport link from the Rhondda coal fields to the ports of Cardiff.
The first railway network to be built in Glamorgan, the Taff Vale Railway, was also the first in Wales. Linking the ironworks of Merthyr to the ports of Cardiff, the Taff Vale line was given royal assent in 1836, with work commencing the same year. It was completed in 1840, and as well as carrying goods the trains made limited passenger trips from the very beginning. By 1856 the Taff Vale Railway was extended to service the top of the Rhondda Valleys at Treherbert and Maerdy, which allowed the exploitation of the minefields in one of the most coal-rich areas of Britain. The second major railway to open was the South Wales Railway, linking Gloucester in England to Neyland. The line was designed to link the coalfields of Glamorgan to London, and was also part of Isambard Kingdom Brunel's vision of a transport link from London to New York. The South Wales Railway serviced Cardiff, Bridgend, Neath and Swansea, with its final destination within Glamorgan being Loughor, before continuing through Carmarthenshire. Other railway lines that opened during the mid to late 19th century included the Vale of Neath Railway, the Swansea Vale Railway and the Rhymney Railway; all designed with the primary purpose of transporting metals and coal from the uplands of the county to the ever expanding ports. The cargo carried on these lines was of a very high volume, and in 1850 the Taff Vale Railway was transporting 600,000 tons of coal per annum.
Towards the turn of the 19th century, two notable events occurred connected to the Taff Vale Railway. In 1888, the Barry Railway Company was formed as part of David Davies' plan to create an alternative export port in south Wales at Barry Docks. As a threat to the monopoly of the TVR, the plans were heavily contested in Parliament, and more parliamentary time was spent on the Barry bill than on any other railway bill in British history. The second event saw the Taff Vale Railway Strike of 1900, an event that saw the House of Lords, in the Taff Vale Case, deem trade unions accountable for the financial losses caused by strike action. The need to reverse the decision was a central factor in the creation of the British Labour Party.
In the 20th century, the railways saw a gradual drop in usage as the heavy industrial works and mines began to reduce output and close and many stations became redundant. Following the Second World War, the railways were nationalised in 1948. In the 1960s the main line services in Wales underwent dieselisation, but this modernisation failed to save the rail system and by 1968 many passenger lines were discontinued by the Beeching Axe.
Airports.
Glamorgan was served by several airports and airfields, with Cardiff Airport being the county's chief airport. Cardiff Airport grew from a former RAF station built in 1942 at Rhoose, and was originally known as Rhoose Airport. In 1970 it became 'Glamorgan, Rhoose Airport' before becoming 'Cardiff-Wales airport' in the 1980s.
Glamorgan's second commercial airport was Swansea Airport which also began as an RAF station, before being released to commercial usage in 1956. The airport saw varying degrees of success until regular flights ceased in 1969. Several other airports and aerodromes have serviced Glamorgan, but usually for private flights. The most notorious aviation disaster in Wales occurred in Glamorgan in 1950, when a privately hired Avro Tudor crashed at Llandow Aerodrome. The Llandow air disaster was, at the time, the world's worst aviation disaster.
Culture and recreation.
Sport in Glamorgan.
Sport was an important part of life in Glamorgan, and the county produced several individuals and teams of note. One of the first recorded team sports in Wales was bando, a variant of bandy. The game was very popular in Glamorgan between the eighteenth and nineteenth centuries before losing in popularity to rugby football. The most notable team to carry the name Glamorgan, is Glamorgan County Cricket Club. Although cricket had been established in Glamorgan since the creation of Cardiff Cricket Club in 1845; county team Glamorgan CCC did not form until 1888. The team gained first-class status in 1921, and still play under the name of Glamorgan. In the first hundred years, the only Welshman to captain an England major tour abroad was Tony Lewis, Glamorgan captain 1967-72. 
The other bat and ball team sport of note in the area was baseball, which was very popular in Cardiff, reaching its peak in the 1930s.
One of the most popular sports in Glamorgan was rugby union, producing some of the oldest rugby clubs in the world. Swansea RFC, Cardiff RFC and Merthyr RFC were founding members of the Welsh Rugby Union in 1881, and both St. Helen's Rugby and Cricket Ground (Swansea) and the Cardiff Arms Park (Cardiff), have been sporting venues for international rugby. Like cricket, rugby union was also played at county level, with Glamorgan represented by Glamorgan County RFC, an invitational team which faced the likes of the All Blacks and the Springboks in the early part of the 20th century. Other rugby clubs of note from the region include Bridgend RFC, Glamorgan Wanderers RFC, Neath RFC and Pontypridd RFC. Although never finding any lasting appeal within Glamorgan, a number of rugby league teams emerged in the early 1900s; and on 1 January 1908, the first true international rugby league game took place in Aberdare between Wales and New Zealand.
As well as rugby and cricket, association football was a very popular sport in Glamorgan, producing two teams with a long tradition in British football, Swansea Town F.C. (formed 1912) and Cardiff City (formed 1899 as Riverside AFC). Both clubs played in the English football league system, rather than the Welsh leagues, though Cardiff were more successful during this period, spending 15 seasons in the First Division and winning the FA Cup in 1927. Other teams of note include Merthyr Tydfil F.C. (1945), who have won the Welsh Cup on three occasions.
Of all the individual sports, arguably boxing was Glamorgan's most prolific. From the northern coalfields and ironworks a string of world class boxers were produced, which was later matched by notable fighters from Cardiff. Of note were Rhondda's Percy Jones (World Flyweight Champion), Tom Thomas (British Middleweight Champion), Jimmy Wilde (World Flyweight Champion) and Tommy Farr (Empire Heavyweight Champion) ; Merthyr's Eddie Thomas (European Welterweight Champion) and Howard Winstone (European Featherweight Champion); Pontypridd's Freddie Welsh (World Lightweight Champion) and Frank Moody (Empire Middleweight Champion). From Cardiff came 'Peerless' Jim Driscoll (British Featherweight Champion) and Jack Petersen (British Heavyweight Champion). Other fighter of note include Dai Dower (European Flyweight Champion) from Abercynon and Bill Beynon (Empire Bantamweight Champion) from Taibach.
Tourism.
Glamorgan, and Wales, were never exploited as a tourist destination until the late 18th century. The destination of choice for English gentlemen during the period was the Grand Tour, but after conflicts in mainland Europe, British travellers looked for 'wild' destinations within their own country. These first tourists were important archivists in their writings, paintings and sketches but there was no real tourist trade to receive them. The coming of industrialisation in the early 19th century gave rise to a new prosperous middle-class and improved communications; both led to a burgeoning tourist trade. The late 19th century, with improving rail links, saw the coastal areas of Glamorgan that benefited from a beachfront grow as tourist destinations. These towns, most notably Barry Island, Porthcawl, Aberavon and Mumbles, owed their existence as tourist locations to the development of the south Wales coal field and the introduction of the workers' annual holidays. By the mid 20th century these locations improved the number of visitors they could accommodate with the introduction of caravan parks and chalet parks.
As the 20th century progressed, and people's leisure activities extended beyond a once-a-year weeks holiday, the county responded with county parks, museums, art galleries and activity centres.

</doc>
<doc id="52526" url="http://en.wikipedia.org/wiki?curid=52526" title="Bar and Bat Mitzvah">
Bar and Bat Mitzvah

Bar Mitzvah (Hebrew: בַּר מִצְוָה) and Bat Mitzvah (Hebrew: בַּת מִצְוָה) (Ashkanasic: "Bas Mitzvah") (plural: "B'nai mitzvah" (for boys, "B'not Mitzvah", Ashkanasic: "B'nos Mitzvah" for girls) are Jewish coming of age rituals. Bar (בַּר) is a Jewish Babylonian Aramaic word literally meaning 'son' (בֵּן), while bat (בַּת) means 'daughter' in Hebrew, and mitzvah (מִצְוָה) means 'commandment' or 'law'. Thus "bar mitzvah" and "bat mitzvah" literally translate to "son of commandment" and "daughter of commandment". However, in rabbinical usage, the word "bar" means 'under the category of' or 'subject to'. "Bar mitzvah" therefore translates to 'an [agent] who is subject to the law'. Although the term is commonly used to refer to the ritual itself, in fact the phrase originally refers to the person.
According to Jewish law, when Jewish boys become 13 years old, they become accountable for their actions and become a bar mitzvah. A girl becomes a bat mitzvah at the age of 12 according to Orthodox and Conservative Jews, and at the age of 13 according to Reform Jews. Prior to reaching bar mitzvah, the child's parents hold the responsibility for the child's actions. After this age, the boys and girls bear their own responsibility for Jewish ritual law, tradition, and ethics, and are able to participate in all areas of Jewish community life. Traditionally, the father of the bar mitzvah gives thanks to God that he is no longer punished for the child's sins (Genesis Rabba, Toldot 23:11). In addition to being considered accountable for their actions from a religious perspective, b'nai mitzvah may be counted towards a minyan (prayer quorum) and may lead prayer and other religious services in the family and the community.
Bar mitzvah is mentioned in the Mishnah (Ethics of the fathers, 5:21), and in the Talmud. In some classic sources, the age of thirteen appears for instance as the age from which males must fast on the Day of Atonement, while females fast from the age of twelve. In the late Middle Ages this was systematized in Europe into a general rule as to when a young person was obligated to observe the mitzvot. The age of b'nai mitzvah roughly coincides with physical puberty. The bar or bat mitzvah ceremony is usually held on the first Shabbat after a boy's thirteenth and a girl's twelfth birthday.
Significance.
Reaching the age of bar or bat Mitzvah signifies becoming a full-fledged member of the Jewish community with the responsibilities that come with it. These include moral responsibility for own actions, eligibility to be called to read from the Torah and lead or participate in a minyan, may possess personal property, may be legally married according to Jewish law, must follow the 613 laws of the Torah and keep the halakha, may testify as a witness in a Beth Din (Rabbinical court) case.
Many congregations require pre-bar mitzvah children to attend a minimum number of Shabbat prayer services at the synagogue, study at a Hebrew school, take on a charity or community service project, and maintain membership in good standing with the synagogue. In addition to study and preparation offered through the synagogue and Hebrew schools, bar mitzvah tutors may be hired to prepare the child through the study of Hebrew, Torah cantillation and basic Jewish concepts.
Aliyah to the Torah.
The widespread practice is that on a Sabbath early in his thirteenth year, a boy is called up to read from the weekly portion of the Law (five books of Moses), either as one of the first seven men or as the last, in which case he will read the closing verses and the Haftarah (selections from the books of the Prophets); and if he is unable to read, to recite at least the benediction before and after the reading. He may also give a d'var Torah (a discussion of some Torah issue, such as a discussion of that week's Torah portion) and/or lead part or all of the prayer services.
In Orthodox circles, the occasion is sometimes celebrated during a weekday service that includes reading from the Torah, such as a Monday or Thursday morning service, in which case the bar mitzvah will also lay tefillin for the first time.
Some communities or families may delay the celebration for reasons such as availability of a Shabbat during which no other celebration has been scheduled, or due to the desire to permit family to travel to the event. However, this does not delay the onset of rights and responsibilities of being a Jewish adult which comes about strictly by virtue of age.
Tefillin.
The obligation to lay tefillin begins when a boy reaches bar mitzvah age. In some Orthodox circles, however, the custom is for the bar mitzvah boy to begin putting on Tefillin one to three months before his bar mitzvah. This way, by the time he is obligated in the commandment, he will already know how to fulfill it properly.
Parties.
Bar mitzvah festivities typically include a seudat mitzvah, a celebratory meal with family, friends, and members of the community. Others may celebrate in different ways such as taking the bar or bat mitzvah on a special trip or organizing some special event in the celebrant's honor. In many communities, the celebrant is given a certificate. According to the Orthodox view, the bar mitzvah boy is so happy to be commanded to do mitzvah and earn reward in the next world for his efforts, that he throws a party and has a festive meal.
Bar and bat mitzvah parties in America are often lavish affairs held at hotels and country clubs with hundreds of guests. The trend has been mocked, most notably in the movie "Keeping Up With The Steins". Rabbi Shmuley Boteach says that over-the-top bar mitzvah parties were already common when he was growing up in Miami in the 1970s.
Customs.
Today many non-Orthodox Jews celebrate a girl's bat mitzvah in the same way as a boy's bar mitzvah. All Reform and Reconstructionist, and most Conservative synagogues have egalitarian participation, in which women read from the Torah and lead services. In Orthodox communities, a Bat Mitzvah is celebrated when a girl reaches the age of 12.
The majority of Orthodox and some Conservative Jews reject the idea that a woman can publicly read from the Torah or lead prayer services whenever there is a minyan (quorum of 10 males) available to do so. However, the public celebration of a girl becoming bat mitzvah in other ways has made strong inroads into Modern Orthodox Judaism and also into some elements of Haredi Judaism. In these congregations, women do not read from the Torah or lead prayer services, but they occasionally lecture on a Jewish topic to mark their coming of age, learn a book of Tanakh, recite verses from the Book of Esther or the Book of Psalms, or say prayers from the siddur. In some Modern Orthodox circles, bat mitzvah girls will read from the Torah and lead prayer services in a women's tefillah. Rabbi Moshe Feinstein, a prominent Orthodox "posek," has ruled that bat mitzvah celebrations are permissible, but should not be held in a synagogue, because then they would be construed as imitating Reform and Conservative customs; in any case, they do not have the status of seudat mitzvah. Rabbi Ovadiah Yosef holds that it is a seudat mitzvah.
The event is celebrated by joyous festivity, the bat mitzvah girl delivering on this occasion a learned discourse or oration at the table before the invited guests, who offer her presents, while the rabbi or teacher gives her her blessing, accompanying it at times with an address.
There were occasional attempts to recognize a girl's coming of age in eastern Europe in the 19th and 20th centuries, the former in Warsaw (1843) and the latter in Lemberg (1902). The occasion was marked by a party without any ritual in the synagogue.
According to the archivist at the Great Synagogue in Rome, the custom of a young woman being called up in synagogue before the entire community dates back to the early years of the Roman Jewish community approximately 2,300 years ago. The community recognized her as "being of age" and acknowledged her in a public fashion. This would support more modern documents that record an Orthodox Jewish Italian rite for becoming bat mitzvah (which involved an "entrance into the minyan" ceremony, in which boys of thirteen and girls of twelve recited a blessing) since the mid-19th century. There were also bat mitzvahs held in the 19th century in Iraq. All this may have influenced the American rabbi Mordecai M. Kaplan, who held the first public celebration of a bat mitzvah in the United States, for his daughter Judith, on March 18, 1922, at the Society for the Advancement of Judaism, his synagogue in New York City. Judith Kaplan recited the preliminary blessing, read a portion of that week's Torah portion in Hebrew and English, and then intoned the closing blessing. Kaplan, who at that time claimed to be an Orthodox rabbi, joined Conservative Judaism and then became the founder of Reconstructionist Judaism, influenced Jews from all branches of non-Orthodox Judaism, through his position at the Jewish Theological Seminary of America. At the time, most Orthodox rabbis strongly rejected the idea of a bat mitzvah ceremony.
As the ceremony became accepted for females as well as males, many women chose to celebrate the ceremony even though they were much older, as a way of formalizing and celebrating their place in the adult Jewish community.
Alternative ceremonies.
Instead of reading from the Torah, some Humanist Jews prefer a research paper on a topic in Jewish history to mark their coming of age. Secular Jewish Sunday schools and communities—including those affiliated with the Congress of Secular Jewish Organizations and the Arbeiter Ring (Workmen's Circle)—encourage the youngsters to select any topic that interests them and relates to the Jewish part of their identities.
The kibbutz movement in Israel also encouraged the celebration of the bar mitzvah. All those coming of age in the community for that year would take on a project and research in a topic of Jewish or Zionist interest. Today many kibbutz children are opting for a more traditional bar mitzvah celebration.
Among some Jews, a man who has reached the age of 83 will customarily celebrate a second bar mitzvah, under the logic that in the Torah it says that a "normal" lifespan is 70 years, so that an 83-year-old can be considered 13 in a second lifetime. This practice has become increasingly uncommon.
A Bark Mitzvah is a pseudo-traditional observance and celebration of a dog's coming of age, as in the Jewish traditional bar mitzvah and bat mitzvah. The term has been in use since at least as early as 1977, and Bark Mitzvahs are sometimes held as an adjunct to the festival of Purim.
Gifts.
Bar or bat mitzvah celebrations have become an occasion to give the celebrant a commemorative gift. Traditionally, common gifts include books with religious or educational value, religious items, writing implements, savings bonds (to be used for the child's college education), gift certificates, or money. Gifts of cash have become commonplace in recent times. As with charity and all other gifts, it has become common to give in multiples of 18, since the "gematria", or numerical equivalent of the Hebrew word for "life", ("chai"), is the number 18. Monetary gifts in multiples of 18 are considered to be particularly auspicious and have become very common for bar and bat mitzvahs. Many bar and bat mitzvahs also receive their first tallit from their parents to be used for the occasion and tefillin where this is appropriate. Jewelry is a common gift for girls at a bat mitzvah celebration. Another gift for the bat mitzvah girl are Shabbat candlesticks because it is the duty and honour of the woman to light the candles.
History.
The modern method of celebrating becoming a bar mitzvah did not exist in the time of the Hebrew Bible, Mishnah or Talmud. Passages in the books of Exodus and Numbers note the age of majority for army service as twenty. The term "bar mitzvah" appears first in the Talmud, the codification of the Jewish oral Torah compiled in the early first millennium of the common era, to connote "an [agent] who is subject to the law," and the age of thirteen is also mentioned in the Mishnah as the time one is obligated to observe the Torah's commandments: "At five years old a person should study the Scriptures, at ten years for the Mishnah, at 13 for the commandments . . ." The Talmud gives 13 as the age at which a boy's vows are legally binding, and states that this is a result of his being a "man," as required in Numbers . The term "bar mitzvah", in the sense it is now used, cannot be clearly traced earlier than the 14th century, the older rabbinical term being "gadol" (adult) or "bar 'onshin" (legally responsible for own misdoings). Many sources indicate that the ceremonial observation of a bar mitzvah developed in the Middle Ages, however, there are extensive earlier references to thirteen as the age of majority with respect to following the commandments of the Torah, as well as Talmudic references to observing this rite of passage with a religious ceremony, including:
In adults.
While the traditional age to hold a bar or bat mitzvah is 13 (12 for girls), some adults choose to have bar or bat mitzvahs at an older age, some of whom had them as children and some who did not have them as children. Since the 1970s, the "adult bar and bat mitzvah" have been growing in popularity.
Bar and Bat Barakah.
Bar/Bat Barakah means, in Aramaic, "Son/Daughter of the Blessing". In honour and recognition of Jewish traditions, including Zeved habat and Bar and Bat Mitzvah, some Christians have begun to conduct a Bar and Bat Barakah ceremony to pronounce blessings upon their children.

</doc>
<doc id="52533" url="http://en.wikipedia.org/wiki?curid=52533" title="7-Dehydrocholesterol">
7-Dehydrocholesterol

7-Dehydrocholesterol is a zoosterol that functions in the serum as a cholesterol precursor, and is converted to vitamin D3 in the skin, therefore functioning as provitamin-D3. The presence of this compound in human skin enables humans to manufacture vitamin D3 from ultraviolet rays in the sun light, via an intermediate isomer pre-vitamin D3. It is also found in the milk of several mammalian species. In insects it is a precursor for the hormone ecdysone, required for reaching adulthood. It was discovered by Nobel-laureate organic chemist Adolf Windaus.
Location.
The skin consists of two primary layers: an inner layer, the dermis, comprising largely connective tissue, and an outer, thinner epidermis. The thickness of the epidermis ranges from 0.08 mm to greater than 0.6 mm (from 0.003 to 0.024 inches). The epidermis comprises five "strata"; from outer to inner, they are the stratum corneum, stratum lucidum, stratum granulosum, stratum spinosum, and stratum basale. The highest concentrations of 7-dehydrocholesterol are found in the epidermal layer of skin—specifically in the stratum basale and stratum spinosum. The production of pre-vitamin D3 is, therefore, greatest in these two layers.
Radiation.
Synthesis of pre-vitamin D3 in the skin involves UVB radiation, which effectively penetrates only the epidermal layers of skin. 7-Dehydrocholesterol absorbs UV light most effectively at wavelengths between 290 and 320 nm and, thus, the production of vitamin D3 will occur primarily at those wavelengths. The two most important factors that govern the generation of pre-vitamin D3 are the quantity (intensity) and quality (appropriate wavelength) of the UVB irradiation reaching the 7-dehydrocholesterol deep in the stratum basale and stratum spinosum. Another important consideration is the quantity of 7-dehydrocholesterol present in the skin. Under normal circumstances, ample quantities of 7-dehydrocholesterol (about 25–50 mg/cm2 of skin) are available in the stratum spinosum and stratum basale of human skin to meet the body's vitamin D requirements.

</doc>
<doc id="52534" url="http://en.wikipedia.org/wiki?curid=52534" title="Axiom of empty set">
Axiom of empty set

In axiomatic set theory, the axiom of empty set is an axiom of Kripke–Platek set theory and the variant of general set theory that Burgess (2005) calls "ST," and a demonstrable truth in Zermelo set theory and Zermelo–Fraenkel set theory, with or without the axiom of choice.
Formal statement.
In the formal language of the Zermelo–Fraenkel axioms, the axiom reads:
or in words:
Interpretation.
We can use the axiom of extensionality to show that there is only one empty set. Since it is unique we can name it. It is called the "empty set" (denoted by { } or ∅). The axiom, stated in natural language, is in essence:
The axiom of empty set is generally considered uncontroversial, and it or an equivalent appears in just about any alternative axiomatisation of set theory.
In some formulations of ZF, the axiom of empty set is actually repeated in the axiom of infinity. However, there are other formulations of that axiom that do not presuppose the existence of an empty set. The ZF axioms can also be written using a constant symbol representing the empty set; then the axiom of infinity uses this symbol without requiring it to be empty, while the axiom of empty set is needed to state that it is in fact empty.
Furthermore, one sometimes considers set theories in which there are no infinite sets, and then the axiom of empty set may still be required. However, any axiom of set theory or logic that implies the existence of any set will imply the existence of the empty set, if one has the axiom schema of separation. This is true, since the empty set is a subset of any set consisting of those elements that satisfy a contradictory formula.
In many formulations of first-order predicate logic, the existence of at least one object is always guaranteed. If the axiomatization of set theory is formulated in such a logical system with the axiom schema of separation as axioms, and if the theory makes no distinction between sets and other kinds of objects (which holds for ZF, KP, and similar theories), then the existence of the empty set is a theorem.
If separation is not postulated as an axiom schema, but derived as a theorem schema from the schema of replacement (as is sometimes done), the situation is more complicated, and depends on the exact formulation of the replacement schema. The formulation used in the axiom schema of replacement article only allows to construct the image "F"["a"] when "a" is contained in the domain of the class function "F"; then the derivation of separation requires the axiom of empty set. On the other hand, the constraint of totality of "F" is often dropped from the replacement schema, in which case it implies the separation schema without using the axiom of empty set (or any other axiom for that matter).

</doc>
<doc id="52536" url="http://en.wikipedia.org/wiki?curid=52536" title="Nationalist Party of Australia">
Nationalist Party of Australia

The Nationalist Party of Australia was an Australian political party. It was formed on 17 February 1917 from a merger between the conservative Commonwealth Liberal Party and the National Labor Party, the name given to the pro-conscription defectors from the Australian Labor Party led by Prime Minister Billy Hughes. The Nationalist Party held government (at times in coalition) until 1929. From then it was the major opposition to the Labor party until it merged with pro-Joseph Lyons Labor defectors to form the United Australia Party in 1931, which was the predecessor to the 1944 foundation of the Liberal Party of Australia.
History.
In October 1915 Labor Prime Minister Andrew Fisher retired and Hughes was chosen unanimously by the Labor caucus to succeed him. He was a strong supporter of Australia's participation in World War I, and after a visit to Britain in 1916 he became convinced that conscription was necessary if Australia was to sustain its contribution to the war effort. The majority of his party, most notably Roman Catholics and trade union representatives, was bitterly opposed to this, especially in the wake of the British government's reprisals against the Irish Easter Uprising of 1916. In October Hughes held a plebiscite to try to gain approval for conscription, but the plebiscite was narrowly defeated. Melbourne's Catholic Archbishop, Daniel Mannix, was his main opponent on the conscription issue. The defeat, however, did not deter Hughes, who continued to vigorously argue in favour of conscription. This produced a deep and bitter split within the Australian community, as well as within the members of his own party. The extent to which he engineered this has been hotly debated ever since, and was even at the time regarded as ironic by many in the Labor movement given Hughes' violent hostility to earlier Labor "rats" like Joseph Cook.
On 15 September 1916 the NSW executive of the Political Labour League (the Labor Party organisation at the time) expelled Hughes from the Labor Party. When the Federal Parliamentary Labor caucus met on 14 November 1916, lengthy discussions ensued until Hughes walked out with 24 other Labor members. The remaining 43 members of Caucus then passed their motion of no confidence in the leadership, effectively expelling Hughes and the other members.
Hughes and his followers formed a minority Government (briefly using the title "National Labor"), with support from Cook and his Commonwealth Liberal Party. As the war dragged on, Hughes began negotiations with Cook to turn their confidence-and-supply agreement into a formal party. That February, under prodding from the Governor-General, Sir Robert Munro Ferguson, the two groups formally merged to form the Nationalist Party, with Hughes as leader and Cook as deputy leader. The new party was dominated by former Liberals, and as such was basically an upper- and middle-class party. However, the presence of many former Labor men—many of whom had been among early leaders in that party—allowed the Nationalists to project an image of national unity.
In May 1917 the Nationalists won a huge electoral victory--at the time, the biggest majority government since Federation. The size of the landslide was magnified by the large number of Labor MPs who followed Hughes into the Nationalists. At this election Hughes abandoned his working-class seat of West Sydney, and was elected for Bendigo in Victoria. Hughes had promised to resign if his Government did not win the power to conscript. A second plebiscite on conscription was held in December 1917, but was again defeated, this time by a wider margin. Hughes, after receiving a vote of confidence in his leadership by his party, resigned as Prime Minister. However, there were no alternative candidates available. Ferguson used his reserve power to immediately re-commission Hughes as Prime Minister, thus allowing Hughes to remain as Prime Minister while keeping his promise to resign.
Hughes and the Nationalists governed on their own until the elections of 1922, when the newly emerged Country Party gained the balance of power in the House of Representatives. The Nationalists could not govern without Country Party support, and it was obvious that a confidence-and-supply agreement would not be enough to keep the Nationalists in office. However, the Country Party had never liked Hughes' rural policy, and their leader, Earle Page let it be known that he would not serve under him. Several of the more conservative elements of the Nationalist Party had only tolerated Hughes after the war, suspecting he was still a socialist at heart. Page's demand finally gave them an excuse to dump Hughes, and Hughes was forced to resign in January 1923. Former Treasurer Stanley Bruce was chosen as leader, and quickly entered into a coalition with the Country Party. The price, however, was high—five seats in cabinet (out of 11), including the Treasurer's post and the number-two position in the ministry for Page. These kinds of demands were unheard of for such a young party in a Westminster system. However, Bruce agreed rather than force another election. This was the start of the traditional coalition of non-Labor parties.
With the ouster of Hughes, the Nationalists took on a decidedly more conservative hue. Despite initial concerns that Australians wouldn't warm over to the aloof Bruce, the Nationalist-Country coalition won a smashing victory in 1925. It was reelected in 1928, though with a significantly reduced mandate. However, only a year later, the embittered Hughes led a group of backbenchers to cross the floor on a vote on Bruce's plans to reform the industrial arbitration system. In the subsequent election, the Coalition was heavily defeated, suffering what was at the time the second-worst defeat of a sitting government since Federation. Bruce even lost his own seat, and was succeeded as leader by former Attorney-General John Latham.
The Nationalists were never a real force in Australian politics again. The party had spent its entire 12-year existence in government, and was ill-prepared for a role in opposition. In 1931, following negotiations with a group of Labor Party defectors led by Joseph Lyons, the Nationalist Party was absorbed into the new United Australia Party. Although the UAP was dominated by former Nationalists, Lyons was chosen as leader rather than Latham. The UAP replaced the Nationalists as the main conservative anti-Labor Party.
Young Nationalists Organisation.
Around 1929, Robert Menzies, then a member of the Victorian Legislative Council, joined with Wilfrid Kent Hughes to form the Young Nationalists Organisation. Menzies was its first President.
The organisation kept its name when its parent party became part of the UAP. Half the UAP members elected in the 1932 Victorian state election were Young Nationalists, almost trebling their parliamentary representation. The Premier, Sir Stanley Argyle, included three of them in his eight-person cabinet, including Menzies as Deputy Premier.
Later, when Menzies founded the Liberal Party of Australia, he invited delegates from the Young Nationalists to attend. The Young Nationalists followed the UAP into the Liberal Party, and formed the nucleus of the new party's youth wing, the Young Liberals.

</doc>
<doc id="52537" url="http://en.wikipedia.org/wiki?curid=52537" title="54 BC">
54 BC

Year 54 BC was a year of the pre-Julian Roman calendar. At the time, it was known as the Year of the Consulship of Appius and Ahenobarbus (or, less frequently, year 700 "Ab urbe condita"). The denomination 54 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Roman Republic.
</onlyinclude>

</doc>
<doc id="52538" url="http://en.wikipedia.org/wiki?curid=52538" title="55 BC">
55 BC

Year 55 BC was a year of the pre-Julian Roman calendar. At the time, it was known as the Year of the Consulship of Crassus and Pompey (or, less frequently, year 699 "Ab urbe condita"). The denomination 55 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Parthia.
</onlyinclude>

</doc>
<doc id="52541" url="http://en.wikipedia.org/wiki?curid=52541" title="Melanocyte">
Melanocyte

Melanocytes are melanin-producing cells located in the bottom layer (the stratum basale) of the skin's epidermis, the middle layer of the eye (the uvea), the inner ear, meninges, bones, and heart. Melanin is the pigment primarily responsible for skin color. Once synthesised, melanin is contained in a special organelle called a melanosome and moved along arm-like structures called dendrites, so as to reach the keratinocytes.
Melanogenesis.
Through a process called melanogenesis, these cells produce melanin, which is a pigment found in the skin, eyes, and hair. This melanogenesis leads to a long-lasting pigmentation, which is in contrast to the pigmentation that originates from oxidation of already-existing melanin.
There are both basal and activated levels of melanogenesis; in general, lighter-skinned people have low basal levels of melanogenesis. Exposure to UV-B radiation causes an increased melanogenesis. The purpose of the melanogenesis is to protect the hypodermis, the layer under the skin, from the UV-B light that can damage it (DNA photodamage). The color of the melanin is dark, allowing it to absorb a majority of the UV-B light and block it from passing through this skin layer.
Since the action spectrum of sunburn and melanogenesis are virtually identical, they are assumed to be induced by the same mechanism. The agreement of the action spectrum with the absorption spectrum of DNA points towards the formation of cyclobutane pyrimidine dimers (CPDs) - direct DNA damage.
Typically, between 1000 and 2000 melanocytes per square millimeter of skin are found. Melanocytes comprise from 5% to 10% of the cells in the basal layer of epidermis. Although their size can vary, melanocytes are typically 7 μm in length.
The difference in skin color between lightly and darkly pigmented individuals is due not to the number (quantity) of melanocytes in their skin, but to the melanocytes' level of activity (quantity and relative amounts of eumelanin and pheomelanin). This process is under hormonal control, including the MSH and ACTH peptides that are produced from the precursor proopiomelanocortin.
Albinos lack an enzyme called tyrosinase. Tyrosinase is required for melanocytes to produce melanin from the amino acid tyrosine.
Stimulations.
Numerous stimuli are able to alter melanogenesis, or the production of melanin by cultured melanocytes, although the method by which it works is not fully understood. Melanocortins have been discussed to have effect on appetite and sexual activity in mice. Vitamin D metabolites, retinoids, melanocyte-stimulating hormone, forskolin, cholera toxin, isobutylmethylxanthine, diacylglycerol analogues, and UV irradiation all trigger melanogenesis and, in turn, pigmentation. Increased melanin production is seen in conditions where ACTH is elevated, such as Cushing's disease. This is mainly a consequence of alpha-MSH being secreted along with ACTH. Alpha-MSH is a cleavage product of ACTH that has a stronger affinity for the MC1 receptor on melanocytes.
Melanosomes are vesicles that package the chemical inside a plasma membrane. The melanosomes are organized as a cap protecting the nucleus of the keratinocyte.
When ultraviolet rays penetrate the skin and damage DNA, thymidine dinucleotide (pTpT) fragments from damaged DNA will trigger melanogenesis and cause the melanocyte to produce melanosomes, which are then transferred by dendrites to the top layer of keratinocytes.

</doc>
<doc id="52544" url="http://en.wikipedia.org/wiki?curid=52544" title="Aldo Moro">
Aldo Moro

Aldo Romeo Luigi Moro (]; September 23, 1916 – May 9, 1978) was an Italian Christian Democratic politician and the 38th Prime Minister of Italy, from 1963 to 1968, and then from 1974 to 1976. He was one of Italy's longest-serving post-war Prime Ministers, holding power for a combined total of more than six years.
A leader of "Democrazia Cristiana" (Christian Democracy, DC), Moro was considered an intellectual and a patient mediator, especially in the internal life of his party. He was kidnapped on March 16, 1978, by the Red Brigades (BR), a Marxist–Leninist urban guerilla organization, and killed after 55 days of captivity.
Early career.
Moro was born in Maglie, in the province of Lecce (Apulia), into a family from Ugento. At 4, he moved with his family to Milan, but they soon moved back to Apulia, where he gained a classical high school degree at "Archita" lyceum in Taranto. Till 1939 he studied Law at the University of Bari, an institution where he was later to hold the post of ordinary professor of philosophy of Law and Colonial Policy (1941) and of Criminal Law (1942).
In 1935, he joined the Catholic university students' association ("Federazione Universitaria Cattolica Italiana", FUCI) of Bari. In 1939, under approval of Giovanni Battista Montini of whom he had befriended, Moro was chosen as president of the association; he kept the post till 1942, succeeded by Giulio Andreotti. During his university years Italy was under the Fascist government, and he took part in students competitions ("Littoriali della cultura e dell'arte") organised by local fascist students' organisation ("Gioventù Universitaria Fascista", GUF). He then founded the periodical "La Rassegna", published in 1943–1945.
In 1945, he married Eleonora Chiavarelli (1915–2010), with whom he had four children: Maria Fida (born 1946), Agnese (1952), Anna and Giovanni (1958).
Political activities.
Moro developed his interest in politics between 1943 and 1945. Initially, he seemed to be very interested in the social-democratic component of the Italian Socialist Party, but then his Catholic faith moved him towards the newly constituted "Democrazia Cristiana" (DC). In the DC, he took part in the work of the leftist trend, headed by Giuseppe Dossetti. In 1945 he became director of the magazine "Studium" and president of the Graduated Movement of the Azione Cattolica.
In 1946 he was nominated vice-president of the "Democrazia Cristiana" and elected member of the Constitutional Assembly, where he took part in the work to redact the Italian Constitution. In 1948 he was elected to the Italian Parliament and nominated vice-minister of Foreign Affairs in the 5th De Gasperi cabinet (May 23, 1948 – January 27, 1950).
In 1953 Moro was re-elected to the Italian Chamber of Deputies, where he held the position of chairman of the DC parliamentary group. He was chosen as Minister of Grace and Justice in the Antonio Segni 1st cabinet in 1955.
Minister of Education in the following Adone Zoli and Amintore Fanfani-II cabinets, he introduced civic education into the national curriculum. In 1959, at the 6th party's congress he gained the post of National Secretary of the DC.
In 1963 he was nominated Prime Minister of Italy for the first time. His government was unevenly supported by the DC, but also by the Italian Socialist Party, along with the minor Italian Republican Party and Italian Democratic Socialist Party. The centre-left coalition, a first for the Italian post-war political panorama, stayed in power until the 1968 general elections. His 3rd cabinet (1966–68) stayed in power for 833 days, a record for Italy's so-called "First Republic".
In the 1968 DC's congress, Moro yielded the Secretariat and passed to internal opposition, while serving as Foreign Minister between 1969 and 1974. In 1974–1976 he re-gained the post of Prime Minister, and concluded the Osimo Treaty with Yugoslavia, defining the official partition of the Free Territory of Trieste. In 1976 he was elected President of the DC National Council.
A wide range of social reforms were carried out during Moro's periods as prime minister. The 1967 Ponte Law ("Legge Ponte") introduced urgent housing provisions as part of an envisioned reform of the entire sector, such as the introduction of minimum standards for housing and environment. A law promulgated on 14 December 1963 introduced an annual allowance for university students with income below a given level. Another law, promulgated on 10 March 1968, introduced voluntary public pre-elementary education for children aged three to five years. A law promulgated on 21 July 1965 introduced new pension provisions under the general scheme. The legal minima was raised, all current pensions were revalued, seniority pensions (pensioni d’anzianità) were introduced (after 35 years of contributions workers could retire even before attaining the pensionable age), and within the national social security institution ("Istituto nazionale della previdenza sociale", INPS), a Social Fund (Fondo Sociale) was established, ensuring to all members pensioners a basic uniform pension largely financed by state, known as the social pension (not related to the later social pension introduced in 1968). A law of 22 July 1966 extended pension insurance to small traders. A law of 22 July 1966 extended health insurance to retired traders, and a law of 29 May 1967 extended compulsory health insurance to retired farmers, tenant farmers, and sharecroppers, and extended health insurance to the unemployed in receipt of unemployment benefits. A law of 18 March 1968 introduced the principle of earnings-related pensions within the general scheme, with the pension formula to equal 1.626% of average earnings in the last 3 years of work multiplied by the number of contribution years (maximum pension: 65% of previous earnings) up to 40. A law of 5 November 1968 extended family allowances to the unemployed in receipt of unemployment benefits.
A law of 9 June 1975 increased the number of eligible occupational diseases and extended the duration of benefits. A law of 3 June 1975 introduced various benefit improvements for pensioners. The multiplying coefficient was raised to 2% and applied to average earnings of the best 3 years in the last 10 years of work, and automatic annual adjustment of minimum pensions to increase of the minimum contractual wage in the industrial sector (with a smaller adjustment made for pensions higher than the minima). A law of 27 December 1975 introduced "ad hoc" upgrading of cash benefits for certain diseases and f all flat-rate allowances. A law of 14 July 1967 extended family allowances to self-employed farmers, sharecroppers, and tenant farmers. In 29 April 1976, pension linkage to the industrial wage was extended to civil servants.
Historic Compromise.
Moro was considered a very tenacious mediator, particularly skilled in coordinating the different internal trends of DC.
At the beginning of the 1960s, Moro was one of the most convinced supporters of an alliance between the DC and the Italian Socialist Party, in order to widen the majority and integrate the socialists in the government system. In the 1963 party congress in Naples, he was able to convince the whole party directive of the strategy. The same happened in 1978, when he supported a "national solidarity" government with the backing of the Italian Communist Party.
Moro's main aim was to widen the democratic base of the government: the cabinets should have been able to represent a bigger number of voters and parties. He thought of the DC as the fulcrum of a coalition system, on the principles of consociative democracy.
Moro faced big challenges: especially, the necessity to conciliate the Christian and popular mission of the "Democrazia Cristiana" with the rising laicist and liberal values of the Italian society in the 1960s, and the necessity to integrate new important social groups (youth, women, workers) in the democratic system. DC's mission, in Moro's vision, was intended to recover the popular class that supported Fascism and ferry them in the democratic system. The contradiction of Moro's political stance was in trying to reconcile the extreme mobility of social transformations with the continuity of the institutions of representative democracy, and the integration the masses in the State, without falling into autocracy.
Following the Hungarian Revolution of 1956, the Italian Socialist Party (PSI) had taken a definitive distance from the Italian Communist Party (PCI), and Pietro Nenni had collaborated with the DC in the early 1960s. After the rise of the PCI of Enrico Berlinguer at the 1976 general elections, when the Communists scored 34,4% of the votes, Moro conceived the idea of a "national solidarity" cabinet, whose parliamentary base should include the PCI as well. Moro's idea was openly criticised, as such an "Historic Compromise" would have involved a PCI which was still under direct influence from Moscow. Berlinguer openly defused the proposition.
In 1976–1977, Berlinguer's PCI broke up with Moscow, and convened with the Spanish and French parties to draw the lines of Eurocommunism. Such a move made an eventual collaboration more acceptable for DC voters, and the two parties began an intense parliamentary debate, in a moment of deep social crises.
In 1977, Moro had been personally involved in international disputes. He strongly defended Mariano Rumor during the parliamentary debate on the Lockheed scandal, and some in the press reported that he might have been "Antelope Cobbler", an alleged bribe recipient. The accusation, aimed at politically destroying Moro and avoiding the risk of a "Historic Compromise" cabinet, failed when Moro was cleared on March 3, 1978, 13 days before his kidnapping.
The early-1978 proposition by Moro of a DC-PSI cabinet supported also by the PCI was strongly opposed by both super-powers: the USA feared that the collaboration of an Italian government with the Communists might have allowed these later to gain information on strategic NATO military plans and installations, and pass them to Soviet agents. Moreover, the participation in government of the Communists in a Western country would have represented a cultural failure for the USA. The USSR considered potential participation by the PCI in a cabinet a form of emancipation from Moscow and rapprochement to the Americans, therefore also opposing it.
Kidnapping and death.
Kidnapping.
On March 16, 1978, on Via Fani, a street in Rome, a unit of the militant Communist organisation known as the Red Brigades (Italian: "Brigate Rosse") blocked the two-car convoy transporting Moro and kidnapped him, murdering his five bodyguards. At the time, all of the founding members of the Red Brigades were in jail; the organisation led by Mario Moretti that kidnapped Moro, therefore, is said to be the "Second Red Brigades".
On the day of his kidnapping, Moro was on his way to a session of the Chamber of Deputies, where a discussion was to take place regarding a vote of confidence for a new government led by Giulio Andreotti (DC) that would have, for the first time, the support of the Communist Party. It was to be the first implementation of Moro's strategic political vision as defined by the "Compromesso storico" (historic compromise).
In the following days, trade unions called for a general strike, while security forces made hundreds of raids in Rome, Milan, Turin and other cities searching for Moro's location. Held for two months, he was allowed to send letters to his family and politicians. The government refused to negotiate, despite demands by family, friends and Pope Paul VI. In fact, Paul VI "offered himself in exchange … for Aldo Moro …"
During the investigation of Moro's kidnapping, General Carlo Alberto Dalla Chiesa reportedly responded to a member of the security services who suggested torturing a suspected "brigatista", "Italy can survive the loss of Aldo Moro. It would not survive the introduction of torture." The Red Brigades initiated a secret trial where Moro was found guilty and sentenced to death. Then they sent demands to the Italian authorities, stating that unless 16 Red Guard prisoners were released, Moro would be killed. The Italian authorities responded with a large-scale manhunt.
Negotiations.
The Red Brigades (BR) proposed to exchange Moro's life for the freedom of several prisoners. There has been speculation that during his detention many knew where he was (in an apartment in Rome). When Moro was abducted, the government immediately took a hard line position: the "State must not bend" on 'terrorist demands'. Some contrasted this with the kidnapping of Ciro Cirillo in 1981, a minor political figure for whom the government negotiated. However, Cirillo was released for a monetary ransom, rather than the release of the imprisoned extremists.
Romano Prodi, Mario Baldassarri, and Alberto Clò, of the faculty of the University of Bologna passed on a tip about a safe-house where the BR might have been holding Moro on April 2. Prodi claimed he had been given the tip by the founders of the Christian Democrats, from beyond the grave in a séance and a Ouija board, which gave the names of Viterbo, Bolsena and Gradoli.
Captivity letters.
During this period, Moro wrote several letters to the leaders of the Christian Democrats and to Pope Paul VI (who later personally officiated in Moro's Funeral Mass). Those letters, at times very critical of Andreotti, were kept secret for more than a decade, and published only in the early 1990s. In his letters, Moro said that the state's primary objective should be saving lives, and that the government should comply with his kidnappers' demands. Most of the Christian Democrat leaders argued that the letters did not express Moro's genuine wishes, claiming they were written under duress, and thus refused all negotiation. This was in stark contrast to the requests of Moro's family. In his appeal to the terrorists, Pope Paul asked them to release Moro "without conditions".
Murder.
When the Red Brigades decided to kill Moro, they placed him in a car and told him to cover himself with a blanket saying that they were going to transport him to another location. After Moro was covered, they killed him by shooting ten rounds into him. According to the official reconstruction after a series of trials, the killer was Mario Moretti. Moro's body was left in the trunk of a red Renault 4 on Via Michelangelo Caetani towards the Tiber River near the Roman Ghetto.
After the recovery of Moro's body, the Minister of the Interior Francesco Cossiga resigned.
Antonio Negri's 1979 arrest and release.
On April 7, 1979, Marxist philosopher Antonio Negri was arrested along with other leaders of "Autonomia Operaia" (Oreste Scalzone, E. Vesce, A. Del Re, L. Ferrari Bravo, Franco Piperno and others). Pietro Calogero, an attorney close to the PCI, accused the Autonomia group of masterminding left-wing "terrorism" in Italy. Negri was charged with a number of offences including leadership of the Red Brigades, being behind Moro's kidnapping and murder and plotting to overthrow the government. A year later, he was found innocent of Moro's assassination.
In the "New York Review of Books", Thomas Sheehan wrote at the time in Negri's defense, "Negri is a figure of some stature in Italy, and his arrest might be compared, imperfectly, to jailing Herbert Marcuse a decade ago on suspicion of being the brains behind the Weathermen."
In the same journal in 2003, Alexander Stille accused Negri of bearing moral but not legal responsibility for the crimes, citing Negri's words from one year later:
Every action of destruction and sabotage seems to me a manifestation of class solidarity... Nor does the pain of my adversary affect me: proletarian justice has the productive force of self-affirmation and the faculty of logical conviction.
and
The antagonistic process tends toward hegemony, toward the destruction and the annihilation of the adversary... The adversary must be destroyed.
Alternative points of view about Moro's death.
Many other points of views have been advanced about Moro's death. The "Gladio network", directed by NATO, has also been accused.
Historian Sergio Flamigni, member of the Communist Refoundation Party, believes Moretti was used by Gladio in Italy to take over the Red Brigades and pursue a strategy of tension.
In BR member Alberto Franceschini's book, Aldo Moro is described as one of Gladio's founders. Evidence has emerged to support this view of American involvement in overarching the strategy of tension and of known strong American foreign policies against the then looming historic (unprecedented in post war times) coalition that would have admitted the eurocommunist PCI into a government of national unity, the fear on the US side being that Italy thereafter might withdraw from NATO and that the US would then lose access to vital Mediterranean ports.
Moro's widow later recounted Moro's meeting with U.S. President Nixon's advisor, Henry Kissinger, and an unidentified American intelligence official, who warned him not to pursue the strategy of bringing the Communist Party into his cabinet, telling him "You must abandon your policy of bringing all the political forces in your country into direct collaboration...or you will pay dearly for it." Moro was allegedly so shaken by the comment that he became ill and threatened to quit politics.
But finally Aldo Moro did not quit politics; in the month following the Kissinger/Moro meeting, he was heading to the Italian Parliament for the crucial vote he had proposed when he was kidnapped and subsequently murdered.
Mino Pecorelli's May 1978 article.
Investigative journalist Mino Pecorelli thought that Aldo Moro's kidnapping had been organised by a "lucid superpower" and was inspired by the "logic of Yalta". He painted the figure of General Carlo Alberto Dalla Chiesa as "general Amen", explaining in his review, the "Osservatorio politico", in an article titled "Vergogna, buffoni!" ("Shame on you, buffoons!"), that it was Dalla Chiesa that, during Aldo Moro's kidnapping, had informed the then Interior Minister Francesco Cossiga of the location of the cave where Moro was detained. But he would have been ordered not to act on his information because of the opposition of a "lodge of the Christ in Paradise", referring to Propaganda Due masonic lodge. Pecorelli then wrote that Dalla Chiesa was also in danger and would be assassinated (Dalla Chiesa was murdered four years later). After Aldo Moro's assassination, Mino Pecorelli published some confidential documents, mainly Moro's letters to his family. In a cryptic article published in May 1978 Pecorelli drew a connection between Moro's death and Gladio, NATO's stay-behind anti-communist organisation whose existence was publicly acknowledged by Prime Minister Giulio Andreotti only in October 1990. During his interrogation, Aldo Moro had referred to "NATO's anti-guerrilla activities." Mino Pecorelli, who was on Licio Gelli's list of P2 members discovered in 1980, was assassinated on March 20, 1979. The ammunitions used for Pecorelli's assassination, a very rare type, were the same as those discovered in the "Banda della Magliana" 's weapons stock hidden in the Health Minister's basement. Pecorelli's assassination has been thought to be directly related to Giulio Andreotti, who was first condemned to 24 years of prison for homicide in 2002 and finally acquitted by the Supreme Court of Cassation in 2003.
Carlos "the Jackal"'s declarations.
In a 2008 interview with the Italian news network ANSA (news agency), Venezuelan revolutionary Carlos the Jackal stated from his cell in the prison at Poissy that there had been a deal to exchange Aldo Moro for several imprisoned members of the Red Brigades. Under the terms of the deal struck with "patriotic" members of the Italian military intelligence agency SISMI (Carlos' words), several Italian servicemen and members of a Palestinian resistance group would escort the prisoners to an Arab country. The deal fell through while the plane sat on a runway in Beirut, perhaps because a PLO official's loose tongue alarmed a pro-NATO faction within SISMI. (Carlos maintains that NATO wanted Moro dead, while the Soviets wanted him alive.) The officials in charge of the operation were subsequently purged or forced to resign.
Carlos also claimed that the plotters originally planned to kidnap, along with Moro, the industrialist Gianni Agnelli and a judge of the Italian Supreme Court. He expressed surprise to learn that the Catholic Church was ready to pay a huge ransom for Moro's release.
"Sacrifice Aldo Moro to maintain the stability of Italy".
Steve Pieczenik, a former member of the U.S. State Department sent by President Jimmy Carter as a "psychological expert" to integrate the Interior Minister Francesco Cossiga's "crisis committee", was interviewed by Emmanuel Amara in his 2006 documentary "Les derniers jours d'Aldo Moro" ("The Last Days of Aldo Moro"), in which he alleged that: "We had to sacrifice Aldo Moro to maintain the stability of Italy."
He alleged that the U.S. had to "instrumentalize the Red Brigades," and that the decision to have him killed was taken during the fourth week of Moro's detention, when he started revealing state secrets through his letters (allegedly the existence of Gladio). Francesco Cossiga also said the "crisis committee" also leaked a false statement, attributed to the Red Brigades, saying that Moro was dead.
Possible beatification.
According to media reports on September 26, 2012, the Holy See has received a file on beatification for Moro. Beatification is the first step to becoming a saint in the Roman Catholic Church. Nicola Giampaolo serves as the postulator for the cause.
In April 2015 it was reported that controversies around Moro could cause the suspension or closing of the cause. The postulator has stated the cause will continue when the discrepancies are cleared up.
Cinematic adaptations.
A number of films have portrayed the events of Moro's kidnapping and murder with varying degrees of fictionalization including the following:
External links.
<br>

</doc>
<doc id="52545" url="http://en.wikipedia.org/wiki?curid=52545" title="Semiology (Gregorian Chant)">
Semiology (Gregorian Chant)

Semiology (from Greek σημεῖον "sēmeion", "a sign, a mark") is a branch of Gregorian Chant research. Semiology refers specifically to the study of the neumes as found in the earliest fully notated manuscripts of Gregorian Chant, the oldest of which have been dated to the 9th century. The first application of the term 'semiology' (which first appeared in the 1960s) for the study of Latin chant was made by Dom Eugene Cardine (1905–1988), a monk of the Abbey of Solesmes. In this context, 'semiology' is understood as 'the study of musical signs'. Text and neumatic notation, together with significative letters adjoined to the neumes, presents an effective and integrated mnemonic for melody.
History of Gregorian chant semiology.
In the 19th century, palaeographical work relating to chant was done in various places in Europe against the background of a performance style based on proportional durational values that were assigned to various deteriorated forms of chant used in various locales.
The main player in the history of Gregorian chant semiology in the 19th century is the Benedictine community of the Abbey of St Peter in Solesmes, which was established in 1833 by Fr Prosper Guéranger, who wished to create single authoritative editions of chant via paleographical study. This led to the scholarly monks of the abbey, chief among whom was Dom Paul Jausions, spending over half a century finding and copying the most ancient chant manuscripts. Under Guéranger, the monks of Solesmes advocated singing Gregorian chant in a free musical metre giving the majority of sung notes the same durational length. This interpretation was contrary to much contemporary practice elsewhere and at odds with scholars who backed the use of long and short notes related in strict durational proportion as per polyphonic singing.
The publication of Gontiér's "Méthode Raisonée de plain-chant" (1859) was followed by Dom Pothier's "Mélodie Grégorienne d'après la tradition" (1880) in which he advocated singing the chant in 'rythme oratoire' (oratorical rhythm), which still involved giving the majority of sung notes the same durational length. In 1889, Dom André Mocquereau initiated the "Paleographie Musicale" periodicals which saw the publication of facsimiles of most ancient chant manuscripts to make them more accessible to scholars. Dom Pothier disapproved of this initiative.
In his third volume of "Études de science musicale", published in 1898, Antoine Dechevrens laid out a comprehensive system of interpreting the neumes of Sankt Gallen style in proportional note lengths. Peter Wagner's "Neumenkunde" (1905) volume set out the various musical signs of all the most ancient notational styles historically and paleographically, including Jewish and Byzantine neumes, while providing a number of facsimile illustrations, giving rhythmically proportional values for the musical signs along with a few examples of proportional interpretations of certain chants in modern Western European notation.
The Holy See set up a commission which ran from 1904 till 1913, headed by Pothier, and an editorial team, run by Mocquereau, to create official chant editions for the Vatican. Mocquereau's editorial team only lasted a year: owing to editorial disagreements with Mocquereau, Pothier ended up in charge of the editing which, amongst other things, led to the production of a revised Graduale Romanum in 1908. Mocquereau published "Le nombre musical grégorienne ou rhythmique grégorienne" (two volumes) in 1908 & 1927, in which he presented his own understanding of Gregorian rhythm, several elements of which have since been generally discredited. Two elements which have not been discredited are the recognition of the existence of note lengthening, and the notion of 'nuancing', i.e., altering note durations by very small, non-proportional values. One-note syllables were declared to be normally short in duration, their written length being interpreted as 'graphic licence'.
In 1934, Dom Gregory Murray's anti-proportionalist "A Pilgrim's Progress" was published. In the same year, a series of articles on the subject of the rhythmic quantities of Gregorian musical signs began to be published, entitled 'La Question Rhythmique Grégorienne' by the Abbé G Delorme. This work concluded that certain notational styles contained two distinct signs for any single note and that this difference must be related to rhythm rather than pitch.
The next person to work out a comprehensively coherent analysis of the various neumes and their rhythmic durations was Dr Jan Vollaerts. Using comparative analysis of all the material available to him, Vollaerts was able to show the internal logic and coherence in the neumatic notation with regard to a proper articulation of the verbal-melodic line. In his posthumously published book, 'Rhythmic Proportions in Early Medieval Ecclesiastical Chant' (Brill, 1958), where the term 'semiotic' is used, tables are presented of neumes of different notational styles once used in various parts of Europe (e.g., Nonantola, Laon, Brittany, Aquitaine, Switzerland). One-note, two-note, three-note neumes as found in the various notations are dealt with chapter by chapter. The neumes of one-note syllables were declared to be generally long in duration, as marked in Nonantola and Laon notation.
In the book, singing chant to proportional durations is advocated. This is supported in the book by the evidence of Latin medieval theoretical writings which overwhelmingly advocate singing note lengths according to long and short notes bearing durations defined by simple ratios. Certain of the same writings criticise any lengthening or shortening of these ratios, although certain writings also recognise that such practice existed.
In a volte face, Dom Gregory Murray published two booklets, presenting the same views as Vollaerts. In 1957, he published "Gregorian Rhythm in the Gregorian Centuries; the Literary Evidence" which presented excerpts from the medieval theoretical writings in English and Latin. In 1959, he published "The Authentic Rhythm of Gregorian Chant" which statedly presented, in edited fashion,
Delorme's and Vollaerts' arguments.
This work was followed in 1968 by the book 'Semiologia Gregoriana' by Dom Eugène Cardine. In this book, a fairly comprehensive table of the neumes used by the school of Sankt Gallen is presented. Unlike Fr. Vollaerts, Dom Cardine did not view the musical signs as representing proportional note values, and he viewed one-note syllables in Sankt Gallen notation as normally representing a short duration. Unlike Vollaerts, Cardine did not present all the styles of notation to the reader for examination, which means that the reader had no access to certain notations, such as those of Nonantola and Laon, which mark most one-note syllables with a sign indicating a lengthening of duration.
Vertical, from top to bottom, in the first column, Cardine starts off with neumes representing a single note, then two-, three- and four-note groups and many compound neumes and ornamental neumes. Horizontally, Cardine enters all the variations of the main neume. The system of neumes used in most of the earliest notational styles is rhythmically complex and sophisticated, particularly the styles of Laon and Einsiedeln Abbey.
Cardine states that natural speech-rhythms provide a rhythmic basis for the declamation of Gregorian chant. He divides syllabic time into three categories: "normal" "enlarged, more heavy" and "light, more liquid". Under this interpretation, a one-note syllable would not be considered usually "long" or "longer".
Cardine was employed as a teacher of palaeography and semiology by the Vatican from 1952 to 1984 at the Pontifical Institute of Sacred Music in Rome. His work in the field of semiology was recognized and supported by commissions and led to the publication of the 'Graduale Triplex' in 1979, which was based on Cardine's personal Roman Gradual in which, over the years, he had copied many neumes from Sankt Gallen school manuscripts. Two students of Cardine, Rupert Fischer and M.C. Billecocq, undertook the strenuous task to manually copy the neumes of two schools of generally concordant rhythmic manuscripts (Einsiedeln/Sankt Gallen and Laon) into the new type-set Roman Gradual of 1974. In hindsight, the 'Graduale Triplex' proved a great stimulus for self-study as it made important material available in a handy book. The momentum of its publication has created a demand for a new Gradual as the 1974 Gradual contains many incidental or structural melodic errors.
The relative small but growing number of choirs or small groups that perform Gregorian Chant according to these recent developments are thus said to follow the 'semiological approach'.
Other students of Cardine, who, like Fischer and Billecocg, held a professorate at the Pontifical Institute in Rome, include Marie-Noel Colette, Luigi Augustoni and Godehard Joppich.
The even smaller school of singing chant using proportional durations, as per Fr Vollaerts, has continued in the hands of Jan van Biesen in the Netherlands, R John Blackley in Maine, USA, and Luca Ricossa in Switzerland.
In the 1983 "Liber Hymnarius" from Solesmes, it is stated that, "When an ordinary syllable is set to one note, this represents the fundamental rhythmic value used in Gregorian chant (i.e. valor syllabicus medius)." This implies that the one-note syllable (and thus the fundamental rhythmic value of chant) is no longer interpreted by Solesmes as being normally short in duration.

</doc>
<doc id="52546" url="http://en.wikipedia.org/wiki?curid=52546" title="Genesis (band)">
Genesis (band)

Genesis are an English rock band formed in Godalming, Surrey in 1967, with Peter Gabriel, Tony Banks, Mike Rutherford, Anthony Phillips and Chris Stewart as founding members. The band has had numerous line-ups throughout its history, of which eleven musicians became full time members. Its most recent formation comprised two founding members — keyboardist Tony Banks and bassist/guitarist Mike Rutherford — and drummer/singer Phil Collins, who joined in 1970. Genesis are one of the best selling music artists of all time with approximately 130 million records sold worldwide. They were inducted into the Rock and Roll Hall of Fame in 2010.
Formed by five pupils at Charterhouse School, Genesis were initially regarded as a "pop experiment" as evident by their debut album, "From Genesis to Revelation" (1969). They evolved into a progressive rock band with "Trespass" (1970) and "Nursery Cryme" (1971), which showcased longer tracks, fantasy inspired lyrics, and complex song structures and instrumentation. Their success continued with "Foxtrot" (1972), which features the 23-minute track "Supper's Ready", and "Selling England by the Pound" (1973). Genesis concerts during this time became theatrical experiences with stage design, pyrotechnics, story telling, and singer Peter Gabriel wearing make-up and costumes. In 1975, after touring in support of their double concept album "The Lamb Lies Down on Broadway" (1974), Gabriel left the band. Collins would handle drums and lead vocals on their subsequent studio albums, of which three more were released in the 1970s: "A Trick of the Tail" (1976), "Wind & Wuthering" (1976), and "...And Then There Were Three..." (1978). The single "Follow You Follow Me" from the latter was a major international success and represented a change in their musical direction, becoming more pop-oriented and commercially accessible.
In 1980, Genesis scored their first UK No. 1 album with "Duke" (1980). Their commercial success grew with further UK No. 1 albums "Abacab" (1981) and "Genesis" (1983), which coincided with Collins's increasing popularity as a solo artist. The band peaked with "Invisible Touch" (1986), their best-selling album, from which all five singles released entered the top five on the U.S. "Billboard" Hot 100 chart, with "Invisible Touch" reaching the No. 1 spot. In 1991, after a five-year break, Genesis continued their mainstream success with "We Can't Dance" (1991), which contained the worldwide hit single "I Can't Dance". In 1996, Collins departed the band, which led to Ray Wilson taking his place on vocals. Wilson, Banks and Rutherford released "Calling All Stations" (1997), which sold well in Europe but peaked at No. 53 in the U.S., their lowest charting album since 1974. Following a European tour in 1998, the band went on hiatus.
In 2006, Banks, Rutherford and Collins reunited for the 2007 , which included a free concert in Rome that was attended by 500,000 people. The future of the band remains uncertain; Collins stated that he was retiring from the music industry in 2011 but has since indicated he is considering a return, whilst Banks indicated that Genesis had come to an end during an interview in 2012. In 2014, Gabriel, Banks, Rutherford, Collins, and Hackett reunited for a BBC documentary, "".
History.
1967–70: Formation, "From Genesis to Revelation", and "Trespass".
The founding members of Genesis, Peter Gabriel, Tony Banks, Mike Rutherford and Anthony Phillips all met at Charterhouse School in Godalming, Surrey. Gabriel and Banks had arrived at the school in September 1963, Rutherford in September 1964 and Phillips in April 1965. All four found the environment of Charterhouse restrictive, as it favoured activities such as team sports, which they disliked. Banks had been taking piano lessons since he started prep school aged 7, while Rutherford had been playing guitar since he was 7 and Phillips had already played in a band, the Spiders, before arriving at the school. The group evolved from earlier school bands the Anon and the Garden Wall, and joined forces in Easter 1967, in order to record a demo tape. The first line-up consisted of Gabriel on vocals, Phillips on guitar, Banks on keyboards, Rutherford on bass and rhythm guitar and Chris Stewart (drums).
Having recorded a demo containing "Don't Want You Back", "Try A Little Sadness", "She's Beautiful", "That's me", "Listen on Five" and an instrumental "Patricia", the group wanted to get the songs professionally published and recorded. Charterhouse alumnus Jonathan King had left in 1965 and achieved immediate success in the pop world with "Everyone's Gone to the Moon", so he seemed a natural choice as a publisher and producer. The group got a friend to give the tape to King, who was immediately enthusiastic, later saying "I thought it was fabulous". Under King's advice, the group recorded another demo, which led to a recording contract with him.
The group recorded another session at Regent Sound Studio in Denmark Street, London, where they attempted a number of longer and more complex songs, but King was unhappy with these, and advised that the group should stick to straightforward pop. In response, Banks and Gabriel wrote "The Silent Sun", a pastiche of the Bee Gees, one of King's favourite bands. The song was chosen to be their first single and it was recorded at Regent in December 1967. The group suggested a number of names, including King's suggestion of Gabriel's Angels and Champagne Meadow from Phillips, before taking King's suggestion of Genesis, indicating the start of his production career. The single achieved airplay on BBC Radio One and Radio Caroline, but the record didn't sell. A further single, "A Winter's Tale" was recorded and released in 1968, but it also failed to chart. Shortly afterwards, Stewart left the group as he lacked the dedication and drive of the others, and had no input into songwriting. He was replaced by John Silver.
Though the singles did not sell, King felt that the group's songwriting and sound might be better suited to an album. The result, "From Genesis to Revelation", was recorded over a 10-day period in August 1968 and released in March 1969 on Decca Records. King assembled the tracks as a concept album, which he produced, while Arther Greenslade added string arrangements. The band were unhappy with the presence of the strings, which they felt swamped the rest of the instruments. The album omitted the group's name as Decca noticed there was another group in the U.S. named Genesis, and simply listed the title on a black cover. The album sold a minimal 649 copies and Genesis split with both Decca and King, who continues to hold the rights to the album, reissuing it several times under a variety of names. The band have since given a negative view of the album and have been embarrassed by its re-releases.
Following the recording of "From Genesis to Revelation", the band went their separate ways. Gabriel and Phillips stayed at Charterhouse, while Banks started a maths, physics and philosophy degree at Sussex University and Rutherford moved to Farnborough College of Technology. They regrouped in the summer of 1969 to discuss what future the group held, given they had offers of further education that would have led to the group splitting up. Phillips and Rutherford decided they would turn professional and make music a full-time career, as they were starting to write music that was more complex and advanced than the earlier work with King. Silver decided to leave the group to study in the U.S., and was replaced by John Mayhew, who had been recruited by an advertisement in "Melody Maker".
The group relocated to Dorking, Surrey and lived in a cottage owned by the parents of Richard MacPhail, a friend from Charterhouse. They played their first gig in September 1969, and continued to write and rehearse in the cottage until April 1970, by which time they had enough material for an album. The band developed a strong working ethic, playing together for as much as 11 hours a day. Banks later said they were "trying to do something adventurous musically". Gabriel managed to book the band for a gig at Brunel University, which won them several fans and allowed them to secure a six-week residency at Ronnie Scotts during March and April. The group were spotted by Charisma Records' producer John Anthony, who enjoyed the performance and persuaded his boss, label owner Tony Stratton-Smith to sign the group. They would remain at Charisma until the label's demise in 1986.
Recording for the band's second album, "Trespass", began in June 1970 at Trident Studios with Anthony producing. The album was produced from many of the songs the band had written in Dorking, and included folk influences and progressive rock elements, such as complex arrangements and time signature changes used in the closing song "The Knife". The album's cover was designed by Paul Whitehead, who would illustrate the covers for the band's next two albums.
Shortly after recording "Trespass", Phillips decided to leave the group. He had felt that the increased workload of gigs had stopped the band from being creative as it had been previously, and that a number of acoustic pieces he wrote were dropped from the live set and not considered for recording. He had contracted bronchial pneumonia and became isolated from the rest of the band, feeling that it had too many songwriters in it. Phillips had been an important member of the band, being the most encouraging and instrumental in encouraging them to turn professional, and his departure has since been described by the rest of the band as the greatest threat to the band and the biggest to overcome. Driving home from Phillips' last gig, the rest of the band discussed their future. Gabriel and Rutherford decided they would continue, while Banks agreed on the condition that they also find a new drummer that was of equal stature to the rest of the group. Mayhew was therefore fired, though Phillips later thought Mayhew's working-class background clashed with the rest of the band and damaged his confidence at drumming. "Trespass" was released in October 1970, and though commercially unsuccessful in the UK, topped the charts in Belgium. Initial sales of the album, though far greater than those of "From Genesis to Revelation" were minimal at around 6,000 copies worldwide. It peaked at No. 98 in the UK when reissued by Virgin Records in 1985.
In August 1970, Stratton-Smith advertised in "Melody Maker" for a replacement guitarist and drummer. Gabriel, Banks and Rutherford auditioned 15 drummers, but were particularly keen on Phil Collins, partly due to his playing skill, but also because of his sense of humour. Collins had stage school experience, and had played in a number of bands, including Flaming Youth. Though he was friends with Stratton-Smith, he was still required to audition for Genesis.
The group did not find a suitable replacement for Phillips, so Banks learned how to play two keyboard parts simultaneously to cover for the lack of lead guitar and they resumed gigging as a four-piece. Mick Barnard briefly joined the band in November 1970 as the new guitarist, but they quickly discovered his playing expertise and experience was not up to the same standard as the rest of the group. In December, Gabriel spotted an advert in "Melody Maker" from Steve Hackett, who was looking for a band of "receptive musicians, determined to drive beyond existing stagnant music forms". Gabriel phoned former Quiet World guitarist Steve Hackett, asking him to listen to "Trespass" and attend a gig at the Lyceum. Hackett realised his guitar playing style would improve the band's sound and formed an immediate rapport with them, joining the band in January 1971.
1971–75: "Nursery Cryme", "Foxtrot", "Selling England by the Pound", and "The Lamb".
Following the addition of Hackett, the band went on the "Six Bob Tour" with two other Charisma acts, Lindisfarne and Van der Graaf Generator. Those groups had had commercial success, but Genesis had a positive reception, with "Melody Maker"‍‍ '​‍s Michael Watts saying they "emerged with the greatest honours and audience acclaim". With no commercial success and little interest in hit singles, Genesis began to commit themselves to regular touring to build a live following, feeling it was the only way they would become successful.
The band started recording their third album "Nursery Cryme" in August 1971. The album includes "The Musical Box", which had been worked on with Phillips and Mayhew, but Hackett created new lead guitar parts. "For Absent Friends", written by Collins and Hackett and produced by John Anthony, is the first track to feature Collins on lead vocals. On "Seven Stones" and "The Fountain of Salmacis", a song based on Hermaphroditus, Banks used the same Mellotron used on "In the Court of the Crimson King" by King Crimson. "Nursery Cryme" was released on 12 November 1971 and would belatedly peak at number 39 in the UK in spring 1974. It continued the band's success in Italy after it reached No. 4. Genesis resumed touring to support "Nursery Cryme" in November 1971, including their first dates outside of the UK, including dates in Belgium and Italy. Their performance at the year's Reading Festival was well received by the music press.
In August 1972, the band recorded "Foxtrot" at Island Studios. During the album's production two producers were used before John Burns took over which began a successful three-album collaboration. The album features what music critic and author Chris Welch described as "one of the group's most accomplished works", the 23-minute track "Supper's Ready". It remains the band's longest track recorded. Songs such as the Arthur C. Clarke-inspired "Watcher of the Skies" solidified their reputation as songwriters and performers. Gabriel's flamboyant and theatrical stage presence, which involved numerous and elaborate costumes and surreal spoken song introductions, made the band a popular live act. "Foxtrot" was released in October 1972. It reached No. 1 in Italy and No. 12 in the UK, but and failed to chart in the U.S. The "Foxtrot" tour began in September 1972 and lasted for one year, which included the band's first North American dates. The tour spawned the band's first live album, "Genesis Live", which became the band's highest UK chart position since its formation at No. 9. It is their first album to break into the U.S. charts, reaching No. 105.
During summer 1973, Collins, Rutherford and Phillips started work on Phillips' "The Geese and the Ghost" album with songs, "Only Your Love", Silver Song" and "Master of Time", with Collins on lead vocals, Rutherford on bass and rhythm guitars. The album would not be released until 1977.
In August 1973, Genesis returned to the studio to record "Selling England by the Pound". The album's title refers to a UK Labour Party slogan in an effort to counter the impression that Genesis were becoming too U.S.-oriented. On the opening track, "Dancing with the Moonlit Knight", Hackett became an early user of tapping and sweep-picking, two guitar techniques later popularised by Eddie Van Halen and Yngwie Malmsteen, respectively.
"Selling England By the Pound" was released in October 1973 to a positive critical reception. The album reached No. 3 in the UK and No. 70 in the U.S. The track "I Know What I Like (In Your Wardrobe)" was released as a single in the UK that peaked at No. 17 and "Firth of Fifth" was a staple of album oriented FM stations. By 1973, the band signed Tony Smith as their new manager who published all subsequent Genesis songs through his company, Hit & Run Music Publishing.
In 1974, Genesis retreated to Headley Grange in Headley, East Hampshire to write and rehearse material for their double concept album, "The Lamb Lies Down on Broadway". In contrast to the longer tracks featured on earlier albums, the album is a collection of shorter tracks connected by a number of segues. It tells the story of Rael, a Puerto Rican youth living in New York City, and his spiritual quest to establish his freedom and identity. Rael encounters several bizarre characters including the "Slippermen" and a Lamia. Influences for the story include Greek mythology, works by Keats, and Alejandro Jodorowsky's philosophical film "El Topo". Recording began in August 1974 at Island Mobile Studios in Wales and lasted for three months. Gabriel was absent for a considerable amount of sessions due to his wife's problems with her first pregnancy. He proceeded to write the album's story and lyrics himself, which caused some friction with the rest of the group. English musician Brian Eno contributed synthesizers and sound effects to the album that were later known as "Enossifications"; Gabriel was pleased with Eno's contributions but Banks was not enthusiastic. Eno's work was done in exchange for Collins' percussion work on "Mother Whale Eyeless" from Eno's album "Taking Tiger Mountain (By Strategy)".
"The Lamb Lies Down on Broadway" was released on 18 November 1974. It reached No. 10 in the UK and No. 41 in the U.S. "The Lamb Lies Down on Broadway" tour ran from October 1974 to May 1975, covering Europe and North America across 102 dates. The show included "The Lamb" performed in its entirety with an encore, a choice that the band later regretted as it compelled them to play songs that failed to come off well on stage. The tour's stage design included elaborate costumes and theatrical performances from Gabriel, slide projections, and an elaborate laser lighting display developed by Dutch technician Theo Botschuijver. Genesis were voted as "Top Stage Band" by readers of "NME".
During "The Lamb" tour, Gabriel announced his intention to leave Genesis at its conclusion to the group. He cited estrangement from his bandmates and the strains of the difficult birth of his first child. He wrote a statement to the British music press that was published in August 1975, explaining: "...the vehicle we had built as a co-op to serve our songwriting became our master and had cooped us up inside the success we had wanted. It affected the attitudes and the spirit of the whole band. The music had not dried up and I still respect the other musicians, but our roles had set in hard." Banks later stated, "Although I did spend a long time trying to persuade Pete not to leave, in a way it was absolutely the right thing to happen. He wanted to move into slightly different areas, and Pete was also getting too big for the group. He was being portrayed as if he was 'the man' and it really wasn't like that. It was a very difficult thing to accommodate. So it was actually a bit of a relief."
1975–77: Collins on lead vocals, "A Trick of the Tail," and "Wind & Wuthering".
The group auditioned lead singers to find a replacement for Gabriel. Phil Collins, who had provided backing vocals, coached prospective replacements. When the band was about to record the vocals for the album, the members came to the realisation that Gabriel's possible replacement just was not the voice they needed. Collins asked the other members if he could give it a try. As his voice fit the already-completed music, Collins quickly completed the vocals and the band was left with the decision about what to do for live shows. Even though he had successfully completed the singing for the album, he still was unsure about leaving his drum kit and coming out front to sing for concert performances for 1976's "A Trick of the Tail". New producer David Hentschel, who engineered "Nursery Cryme", gave the album a clearer-sounding production. One music historian later opined that Collins sounded "more like Gabriel than Gabriel did". Collins joined jazz fusion group Brand X on their debut album "Unorthodox Behaviour", which would have an influence on Genesis songs "Los Endos" and "Wot Gorilla?".
Despite the success of the album, the group remained concerned with their live shows, which now lacked Gabriel's elaborate costume changes and dramatic behaviour. Yes and King Crimson drummer Bill Bruford was brought in to fill the vacated drum kit necessitated by Collins new role as frontman for the 1976 tour. Their first live performance without Gabriel, and the first with Collins as lead singer, was on 26 March 1976, in London, Ontario, Canada. Concert footage of this tour appears in the 1977 concert film, "".
Later that year, Genesis recorded "Wind & Wuthering", the first of two albums recorded at the Relight Studios in Hilvarenbeek in the Netherlands. Released in December 1976, the album took its title from Emily Brontë's novel "Wuthering Heights", whose last lines — "listened to the soft wind breathing through the grass; and wondered how any one could ever imagine unquiet slumbers for the sleepers in that quiet earth" — inspired the titles of the seventh and eighth tracks.
For the 1977 Genesis tour, the jazz fusion-trained Chester Thompson—a veteran of Weather Report and Frank Zappa—took on live drumming duties. In a lengthy interview with Robin Tolleson, Collins described the selection of Thompson to partake in the role as drummer for the band:
The thing that clinched me with Chester was a song called "More Trouble Every Day" (by Zappa, on "Roxy & Elsewhere"), which he and Ralph Humphrey play, and I heard that drum fill, which we actually do at the end of "Afterglow". They did that fill on the Zappa song and it floored me completely. I saw what two drummers could do. It could be like a machine. I play flams quite a lot, and with my flams and another drummer you get this huge, sort of solid, thick, backbeat. So one of the first things we did when I met Chester was get him to teach me that lick, and we always put it in the show somewhere. But that was really just listening to him. I had never met him. I rang him up and said, "Hi Chester, I've heard your stuff, would you like to play with Genesis?" He came over as a member. He didn't even audition. He just came over and set up his drums and we started rehearsing.
Collins's approach to Genesis shows differed from the theatrical performances of Gabriel, and his interpretations of older songs were lighter and more subtle. At the 1982 Milton Keynes reunion show, Gabriel admitted that Collins sang the songs "better", though never "quite like" him.
Hackett had become increasingly disenchanted with the band by the time of "Wind & Wuthering"'s release, and he felt confined. He was the first member of the band to record a solo album, 1975's "Voyage of the Acolyte", (with the assistance of Collins and Rutherford) and greatly enjoyed the feelings of control over the recording process that working within a group could not provide. Hackett's album featured Collins on drums, who did the lead vocal on "Star of Sirius", Rutherford on bass, and a Hackett/Rutherford track "Shadow of the Hierophant"; a track that Genesis rehearsed in 1972. Banks' reaction to Hackett's album was not enthusiastic. Hackett had asked that a quarter of "Wind & Wuthering" be allocated to his songs, which Collins described as "a dumb way to work in a band context". While Hackett was given songwriting credits on the instrumental track "Unquiet Slumbers for the Sleepers..."/"...In That Quiet Earth", "Eleventh Earl of Mar", and "Inside and Out" (which was omitted from the album) the Hackett and Collins co-written "Blood on the Rooftops" was never performed live, and his song "Please Don't Touch" (the title track to his 1978 solo album "Please Don't Touch", featuring Thompson) was rejected after rehearsing the track, whom then opted for the shorter and catchier instrumental "Wot Gorilla?". Hackett left the band in summer 1977, phoning in his resignation at the studio while the band were mixing the live album "Seconds Out"; recorded during the 1976 and 1977 tours. Hackett's last studio performance with Genesis was on the "Spot the Pigeon" EP.
1978–79: Three-man era and "...And Then There Were Three...".
Following the departure of Hackett, Rutherford assumed all guitar duties in the studio and the band were getting closer to a balance of what each member provided from a creative standpoint. The group decided to continue as a trio, a fact they acknowledged in the title of the 1978 album "...And Then There Were Three...". The album was a further move away from lengthy progressive epics (as explained in the lyrics on the song "Down and Out"), and yielded their first U.S.radio hit, "Follow You Follow Me", whose popularity led to "…And Then There Were Three…" being the band's first U.S. Platinum-certified album.
For live performances that year, Rutherford alternated again between guitar and bass with American Daryl Stuermer, formerly guitarist with French born violinist Jean-Luc Ponty's instrumental jazz fusion/jazz rock band. Generally, Rutherford played the guitar pieces he composed during the most recent album, but stuck with bass for all material recorded prior to 1978 with Stuermer performing Hackett's guitar part.
Their 1978 world tour took them across North America, over to Europe, back to North America, and, eventually, to their first performances in Japan at the end of 1978. As the headline act, Genesis performed their first concert at Knebworth in Hertfordshire on 24 June 1978. On 29 July 1978, the band made their second appearance at Madison Square Garden, New York. Gabriel and Genesis did an encore of "I Know What I Like" at the end of the show. Genesis would play this venue again on all subsequent U.S. tours except for the 1992 We Can't Dance tour (where they played Giants Stadium).
As the band had been recording and touring constantly since the winter of 1977–78, it was decided by Banks, Collins, and Rutherford to take the majority of 1979 off. Collins had previously informed his bandmates that he needed to attempt to save his marriage by following his wife to her new home in Vancouver. If they planned to go back into the studio, they were going to have to count him out. Banks and Rutherford responded by proposing that the band go into hiatus while he sorted out his family issues and record solo material in the meantime.
1980–84: "Duke", "Abacab", and "Genesis".
At the end of the "...And Then There Were Three..." tour in December 1978, Collins proceeded to try and save his now-failing marriage. He explained, "I went off to Vancouver for two months to try and sort things out ... I was never going to leave the band. It was just that if I was going to be living in Vancouver then we'd have had to organise ourselves differently." After his marriage collapsed, Collins returned to the UK in April 1979 while Banks and Rutherford had begun work on their respective solo albums, "A Curious Feeling" and "Smallcreep's Day". During the making of "Smallcreep's Day", Rutherford finished writing a side B single track "Compression" that Genesis had originally rehearsed in 1973 With time to spare before Genesis reconvened to work on a new album, Collins returned to Brand X, worked with Peter Gabriel and Robert Fripp, and started writing his first solo album, "Face Value". The release of Phillips' "Sides", Hackett's "Spectral Mornings" and "Defector", and Gabriel's third album all signified that all current and former members of Genesis remained active.
Banks, Collins and Rutherford recorded their tenth studio album, "Duke", in late 1979 at Polar Studios in Stockholm, Sweden. More of Collins' R&B-based pop writing was permitted in the song writing where it was absent from previous Genesis albums. Rutherford said their time recording "Duke" was "getting back to the basic stage of ideas being worked on jointly". Banks reasoned much of the band's refreshed attitude was "down to not having worked together in a while ... Good ideas are coming out ... which hasn't happened for some time." "Duke" showcased the band moving further into commercial rock. "Duchess" is the first Genesis track that utilised a drum machine, specifically the Roland CR-78 imported from Japan. Upon its release in March 1980, "Duke" was the band's biggest commercial success to date. It topped the UK charts for two weeks and peaked at No. 11 in the U.S. where it sold over one million copies. "Turn It On Again" was released as a single in the UK and reached No. 8. In the U.S., "Misunderstanding" reached number 14. The "Duke" tour ran from March to June 1980, beginning with a 40-date tour of the UK where all 106,000 tickets sold out within hours of going on sale.
In 1981, Genesis started work on the self-produced "Abacab". It was their first album recorded in The Farm, a remodelled studio in Chiddingfold, Surrey that has since been the band's main recording studio. "No Reply at All" features the Phenix Horns, the horn section of American band Earth, Wind & Fire. The album featured drums with a gated reverb effect which combines strong reverb and a noise gate that rapidly cuts off when a particular volume threshold is reached, resulting in a clean but and punchy drum sound. "Abacab" was released in September 1981 to commercial success. It reached No. 1 in the UK for two weeks and peaked at No. 7 in the U.S., selling two million copies. The album spawned four singles; three reached the U.S. top 40 and "Abacab" reached No. 9 in the UK. The "Abacab" tour covered Europe and North America from September to December 1981. The tour marked the band's first use of the Vari-Lite, a computer controlled intelligent lighting system.
In May 1982, three tracks recorded during the "Abacab" sessions were released as an EP titled "3X3" which peaked at No. 10 in the UK. The lead single, "Paperlate", features the Phenix Horns. "3X3" was followed by the release of the double live album, "Three Sides Live", in June 1982, formed of recordings from the "Duke" and "Abacab" tours. The North American edition contains three sides of live recordings with the fourth comprising the "3X3" tracks and two from the "Duke" sessions. The European version contains a fourth side of live performances. The album reached No. 2 in the UK and No. 10 in the U.S. A tour of North America and Europe followed ran from August to September 1982 and included an unadvertised show at the Marquee Club in Soho, London. The album coincided with the release of the "Three Sides Live" concert film, recorded during the "Abacab" tour.
On 2 October 1982, Genesis performed a one-off concert with Gabriel and Hackett at the Milton Keynes Bowl under the name Six of the Best. The concert was organised to raise money for Gabriel's World of Music, Arts and Dance project which was suffering from considerable debts. Hackett, who flew in from South America, arrived in time to perform the last two songs.
1982 signified solo releases of Rutherford's "Acting Very Strange", Collins' "Hello, I Must Be Going!", and Banks' "The Fugitive". Recording for the band's next album, "Genesis", began in May 1983. The band decided on its eponymous title as each track was written as a group rather than individually. Its opening track, "Mama", concerns a man's obsession with a prostitute. Collins's maniacal laugh developed from the "The Message" by Grandmaster Flash and the Furious Five. "That's All" was the band's attempt to create a pop song with a melody in the style of The Beatles with Collins attempting a "Ringo Starr drum part". "Genesis" was released in October 1983 and continued the band's growing commercial success. The album topped the UK charts for one week and peaked at No. 9 in the U.S., selling over four million copies. Five tracks were released as singles; "Mama" reached No. 4 in the UK, their highest charting UK single to date, and "That's All" reached No. 6 in the U.S. The Mama Tour ran from November 1983 to February 1984, covering North America and five shows in Birmingham. The latter shows were filmed and released as "Genesis Live – The Mama Tour". In 1985, "Genesis" was nominated for a Best Rock Performance by a Duo or Group with Vocal and "Second Home by the Sea" was nominated for Best Rock Instrumental Performance.
1985–96: "Invisible Touch", "We Can't Dance", and Collins's departure.
Banks, Collins and Rutherford planned to work on more solo material following the end of the Mama Tour. In 1984 Rutherford, Collins and Gabriel contributed solo work on "Against All Odds", and in 1985, Rutherford recorded an album with his side project Mike + The Mechanics, Banks worked on his second solo soundtrack album "Soundtracks". Collins released his third solo album, "No Jacket Required" which catapulted him to super stardom. The trio then reconvened at The Farm to write and record "Invisible Touch".
"Invisible Touch" was released in June 1986 and remains the band's most commercially successful album. It reached No. 1 in the UK for two weeks and peaked at No. 3 in the U.S., where it sold over six million copies. The album's five singles reached the top five in the U.S. chart: "Throwing It All Away", "In Too Deep", "Tonight, Tonight, Tonight", "Land of Confusion" and "Invisible Touch". The title track reached No. 1 in the U.S. for three weeks, the only song in the band's history to do so. In September 1986, the band performed "Throwing It All Away" at the 1986 MTV Video Music Awards in Los Angeles. Earlier that year, Collins viewed a spoof of himself on "Spitting Image", a satirical British television show that used puppets to lampoon politicians and celebrities. He was impressed with the representation, and commissioned the show's creators, Peter Fluck and Roger Law, to work on the video for the "Land of Confusion" single. The video was formed as an ironic commentary on the Cold War, and played on the perception that the coalition's leaders were "trigger happy" with the nuclear "button". At the 1987 MTV Video Music Awards it was nominated for the MTV Video of the Year, losing to Gabriel's "Sledgehammer". At the 1988 Grammy Awards it won the award for Best Concept Music Video.
The Invisible Touch Tour ran from September 1986 to July 1987. It was the band's longest and highest-attended tour in its history. The tour concluded with four sold out shows at Wembley Stadium, the first time a band achieved this feat. The shows were recorded and released on video as "The Invisible Touch Tour" in 1988.
After Banks released "Bankstatement", Collins released "...But Seriously", and Rutherford released "The Living Years", the trio reconvened for the 1991 album release "We Can't Dance", Collins' last studio album with the group. The album featured the hit singles "Jesus He Knows Me", "I Can't Dance", "No Son of Mine", "Hold on My Heart", "Tell Me Why" and "Never a Time" (a U.S. release only), as well as lengthy pieces such as "Driving the Last Spike" and "Fading Lights". The album, produced by Nick Davis who had previously produced Marillion, includes "Since I Lost You", which Collins wrote in memory of Eric Clapton's son Conor. In 1993 it was nominated for the Brit Award for Best British Album. At the 1993 American Music Awards on 25 January, the trio won the award for Favorite Pop/Rock Band, Duo, or Group. Once again the trio went off to record solo albums; Banks', 'Still" Rutherford's, "Word of Mouth", and Collins' "Both Sides".
Collins was expected to return to the band to record a new album in March 1996 but instead announced his resignation. He reasoned that he "felt it time to change direction in my musical life. For me now, it will be music for movies, some jazz projects, and of course my solo career. I wish the guys in Genesis all the very best in their future. We remain the best of friends."
1996–2000: Wilson replaces Collins, hiatus.
Rutherford and Banks decided to continue as Genesis. However, they required more than one new member, because the band had lost not only Collins, but also live musicians Stuermer]] and Thompson. Stuermer was approached, but was working with Collins on his "Dance into the Light" album and touring with Collins at the time. Stuermer's last studio performance with Banks would be on Banks' "Strictly Inc" album, playing the guitar solo on the album's most notable 17 minute track "An Island In the Darkness". Thompson inquired regarding the vacant drum stool, but after being refused full-band membership, he ended his 19-year association with Genesis. However, Thompson did work with Hackett on his "Genesis Revisited" album as well as toured with Hackett for the album "The Tokyo Tapes". During the recording of "Genesis Revisited", Hackett finished a 1973 Gabriel track "Deja Vu", while Rutherford released "Beggar on a Beach of Gold". Eventually drumming duties were shared between Nir Zidkyahu, an Israeli session drummer, who had played with Hidden Persuaders, and Nick D'Virgilio, from the American progressive rock band Spock's Beard. The difference in their playing styles was marked; D'Virgilio played softer, more subtle rhythms in comparison to Zidkyahu's bombastic technique. Two singers made the final vocal auditions, ex-Stiltskin singer Ray Wilson and David Longdon. Wilson was appointed as the new lead singer of Genesis in June 1997. On the band's criteria in the search for a singer, Banks noted: "We needed someone who fits as many of the things you require as possible — being able to improvise with the kind of music we write and also someone capable of jumping in at the deep end and fronting a band." Wilson was immediately incorporated into the songwriting process, being given six songs to work on and ending up with three co-writing credits on the final album.
1997's album "Calling All Stations" sold well in Europe, while the track "Congo" reached No. 29 in the UK. The album was not as successful in America, where it failed to reach the Billboard Top 50. During 1997 and 1998, Genesis toured across Europe; Banks, Rutherford, and Wilson were joined live by Zidkyahu and the guitarist Anthony Drennan, who previously had worked with Paul Brady and The Corrs. A concert of this tour was featured in Genesis's "Live in Poland" DVD. However, a planned American tour was cancelled due to the album's poor sales performance. Following the truncation of the "Calling All Stations" tour, Genesis dismissed Wilson and went on an extended hiatus, although the members remained in regular contact. In an April 2007 interview, Wilson expressed his disgust at how his dismissal was handled, saying "it was like death by silence."
In 1998, Banks, Collins, Gabriel, Hackett, Phillips, Rutherford, and Silver gathered for a photo session and dinner to celebrate the release of a new box set, "Genesis Archive 1967–75". In 1999, Genesis with Hackett and Gabriel released a new version of "The Carpet Crawlers" for the "" compilation. On 21 September 2000, Collins, Banks, and Rutherford along with Daryl Stuermer performed acoustic renditions of "I Can't Dance", "Invisible Touch", "Follow You, Follow Me", and "Turn It On Again" at the Music Managers Forum, in honour of their manager Tony Smith. Gabriel attended but did not perform. Most of the original members were involved in compiling the two "Archive" boxed-sets. Acoustic versions of "Afterglow", "No Son of Mine" and "Follow You, Follow Me" were recorded in 1999 for the documentary film "The Genesis Songbook".
2006–09: Reunion tour and discography remasters.
In November 2006, Banks, Rutherford, and Collins announced their reunion for their . An early idea for the project was to have Gabriel and Hackett join for live performances of "The Lamb Lies Down on Broadway", but Gabriel was unable to commit. Hackett decided not to participate without Gabriel. The Turn It On Again Tour included 48 shows covering Europe and North America from June to October 2007. Thompson and Stuermer reprised their roles on drums and guitars, respectively. During the UK leg, Banks Collins and Rutherford opened the London concert of Live Earth at Wembley Stadium on 7 July. The European leg ended with a free concert at Circus Maximus in Rome that was attended by approximately 500,000 people. The show was filmed for DVD titled "When in Rome 2007". Recordings from various locations on the European leg were used for the live album "Live over Europe 2007", released in November 2007. Soundboard recordings of each show on the tour were released by The Music.
On 12 May 2007, the band was honoured at the second annual VH1 Rock Honors where Collins, Banks, and Rutherford performed "Turn It On Again", "No Son of Mine", and "Los Endos".
In 2007, the first two of three box sets were released containing remastered editions of the band's studio albums released from 1970 to 1997 in new stereo and 5.1 surround sound mixes by producer Nick Davis. Each album is presented as a two-disc set containing a CD/Super Audio CD and a DVD with DTS 24bit/96K and Dolby Digital 24bit/48K 5.1 mixes with bonus features including previously unreleased live performances, interviews, and concert programs. "Genesis 1976–1982" was released in May 2007, "Genesis 1983–1998" in October 2007, and "Genesis 1970–1975" in November 2008. Each album was also reissued individually. In 2009, the DVD box set "Genesis Live 1973–2007" containing new editions of the first four live albums was released. This was followed by the DVD box set "Genesis Movie Box 1981–2007", containing their concert films filmed between 1981 and 1992.
2010–present: Hall of Fame induction, reunion speculations, Genesis Revisited II, and BBC documentary.
On 15 March 2010, Genesis were inducted into the Rock and Roll Hall of Fame by Phish guitarist Trey Anastasio. Collins, Banks, Rutherford, and Hackett appeared at the ceremony.
Since 2010, the band have expressed their feelings about a Genesis reunion. Collins said, "I think Genesis are no longer. I don't foresee me doing any more Genesis shows. Not because I don't like it or don't want to. But it doesn't fit in with my life ... I can't physically play the drums. I don't want to sound like a spoiled kid, like I've had my stuff and I don't want to do it any more. But I have done it all my life, and now I'm enjoying another side of life." In 2011 he announced that he ended his music career citing family commitments. In September 2011, Gabriel said that a reunion is a possibility but hopes remain very slim: "I won't say never ever, but it's in the outside department of the betting shop ... if you stick with the stuff that nourishes you the most then you'll probably be the happiest." In May 2012, Banks said "I think we probably won't do it. Phil, particularly, has sort of moved on somewhat. We did do that last tour three or four years ago as a sort of goodbye. That was the idea of it." Hackett stated, "It has been discussed and I'm always up for it" and said "I would say it's possible, but highly improbable. I've always been open to it. I'm not the guy who says no." Gabriel addressed the possibility of a reunion: "It's never been ruled out. I'm trying to picture a time when it would top my priorities list." In April 2014, he was asked again about a possible Genesis reunion saying, "I never say never. It really didn't happen last time. I think there's a small chance, but I don't think it's very high."
In September 2012, Genesis won the Lifetime Achievement Award at the inaugural Progressive Music Awards.
In 2012 Hackett's Genesis Revisited II album was released featuring many Genesis classic tracks, as well as a two year world tour that followed in Genesis Revisited: Live at Hammersmith and Genesis Revisited: Live At the Royal Albert Hall. Hackett has delivered a Genesis show that features many of the band's classic tracks that Hackett and Gabriel worked on, something the other members failed to deliver for one reason or another.
In 2014, Gabriel, Banks, Rutherford, Collins, and Hackett reunited for "", a BBC documentary about the band history and the various solo albums the members have released. Hackett was critical about the documentary, claiming its bias and completely ignored his solo work as well as his enormous writing contribution to Genesis. The documentary does not feature Ray Wilson or his time in the group.
Inspiration and influences.
Throughout their career, Genesis has primarily been a vehicle for songwriting, with individual instruments and styles merely serving the song in question. Though the group have been labelled as Progressive Rock and Arena Rock, Rutherford stated "we've never been worried about technique. We're much more concerned with feel." Band biographers Dave Bowler and Bryan Dray believe the emphasis on songs provides the common link between "Trespass" and "We Can't Dance" despite their apparent musical differences.
Genesis has taken influence from a wide range of music, ranging from classical music to mainstream rock and jazz. The group's public school background meant they took equal influence from classical and church music as well as the contemporary rock music of the 1960s. Classical music was an influence on Tony Banks, Anthony Phillips and Steve Hackett in particular. Gabriel and Banks were big fans of Simon and Garfunkel. Banks also drew influence from Alan Price of The Animals, whom he regarded as "[t]he first person who made me aware of the organ in a rock context". Collins has cited Buddy Rich and the jazz-rock outfits The Mahavishnu Orchestra and Weather Report. He was heavily influenced by The Beatles, the band he cited as the reason he started making music, The Action ("They were big heroes of mine, especially their drummer, who I copied all the time") and the soul music of Motown, Stax Records and Atlantic Records. Hackett's formative years were also influenced by The Beatles, and he has cited "I Feel Fine" as one of the records he learned to play guitar from. Gabriel's early career with Genesis took influence from Nina Simone and King Crimson.
Legacy.
As a group that influenced the growth of the progressive rock genre, Genesis has been cited as an influence on a number of bands including Rush, Marillion, IQ, Pendragon, Pallas, Iron Maiden, Sound of Contact, Spock's Beard, and Dream Theater. Simple Minds singer Jim Kerr's first concert was on the band's "Foxtrot" tour, which he described as "just the most terrific gig and in a way my life was never quite the same again." They have also been cited as an influence by alternative rock bands Elbow and Coheed and Cambria. Several Genesis tribute bands, including ReGenesis, The Musical Box and the Italian progressive rock band The Watch routinely perform material from the Peter Gabriel and Phil Collins eras.
Collins became the first artist to cover a Genesis song in a studio release, "Behind the Lines"', which he included on "Face Value" one year after its original release. Other former members previously and subsequently performed the band's material live during their solo shows—Gabriel played "The Lamb Lies Down on Broadway" and "Back in NYC", while Hackett has performed "In That Quiet Earth", "Los Endos", "Horizons", "Firth of Fifth" and "Blood on the Rooftops", among others. Hackett has performed "I Know What I Like (In Your Wardrobe)" on his own solo tours, and on a 1986 tour with his short lived supergroup GTR. Rutherford has performed "I Can't Dance" during his tours with the Mechanics. Collins also later formed The Phil Collins Big Band, which played jazz arrangements of Genesis songs, which were "That's All", "Invisible Touch", "Hold on My Heart" and "Los Endos" (renamed "The Los Endos Suite"), during its 1998 world tour. Ray Wilson has covered the most Genesis songs during his solo concerts. His two solo live albums, "Live" and "Life and Acoustic", feature the Genesis songs "The Carpet Crawlers", "Follow You Follow Me", "I Can't Dance", "The Lamb Lies Down on Broadway", "No Son of Mine", "Shipwrecked", and "Mama". He has interpreted two songs from the solo careers of his two predecessors – "In the Air Tonight" (Collins) and "Biko" (Gabriel).
Jeff Buckley reworked "Back in NYC" for the posthumously released 1998 "Sketches for My Sweetheart the Drunk"; And You Will Know Us by the Trail of Dead also covered "Back in NYC" as a B-side in 2005. The Brazilian power metal band Angra covered "Mama" in 2002. The Swedish melodic death metal band In Flames covered "Land of Confusion" on "Trigger", as did Disturbed on their 2005 album "Ten Thousand Fists". Disco-pop band "Alcazar", also from Sweden, has covered parts of "Land of Confusion" on their song "This is the World We Live in". Dream Theater covered "Turn It On Again" as part of their song "The Big Medley". In 2007, Simon Collins recorded his own version of "Keep It Dark" with the assistance of sound designer and future bandmate Dave Kerzner as a tribute to the 40th anniversary of his father's band. Collins and Kerzner met at rehearsals for Genesis's tour. The duo would later form their own progressive rock band, Sound of Contact, inspired by Collins' experiences on tour with Genesis in his youth as well as Kerzner's appreciation for the band. Collins and Kerzner also provided vocals and keyboards, respectively, on Steve Hackett's 2012 album, "Genesis Revisited II".
Inducting the band into the Rock and Roll Hall of Fame in 2010, Trey Anastasio of Phish acclaimed Genesis as "rebellious, restless and constantly striving for something more … Every musical rule and boundary was questioned and broken … It's impossible to overstate what impact this band and musical philosophy had on me as a young musician. I'm forever in their debt."
Beyond purely musical ventures, the theatrical style of Genesis's 1970s concerts with Gabriel and advanced lighting of their 1980s shows have provided inspiration for Cirque du Soleil's productions: the 2004 anniversary show "Midnight Sun" and the arena-based touring show "Delirium" trace their musical and multimedia elements back to these concerts. According to Victor Pilon, co-creator and co-director of both shows, "We're not inventing anything. Genesis did it years ago. We're just using new technology."
Album cover art.
The band's album covers often incorporate complex and intricate art intended to reflect the themes explored in the music. The initial release of the band's first album, "From Genesis to Revelation", used a plain black sleeve with the album title written in a golden gothic typeface. The three subsequent album covers were developed by the popular Charisma Records graphic artist Paul Whitehead. The "Foxtrot" sleeve depicts a feminine figure in a red dress with the head of a fox. Whitehead has said in an interview that Jimi Hendrix's "Foxy Lady" was an inspiration for the character.
The cover art for "Selling England by the Pound" was painted by Betty Swanwick. Peter Gabriel saw the original drawing, called "The Dream", at an exhibition and asked Swanwick to modify it for use as the album cover. Most notably, Swanwick added a lawnmower to the image to tie the painting to the lyrics of "I Know What I Like (In Your Wardrobe)".
After Whitehead moved to Los Angeles, Genesis signed with the art collective Hipgnosis, whose artists had created high profile album covers for Pink Floyd's "The Dark Side of the Moon" and Led Zeppelin's "Houses of the Holy". Hipgnosis's first Genesis album cover was for "The Lamb Lies Down on Broadway", which featured a male model, credited simply as "Omar", portraying the album's protagonist "Rael". Peter Gabriel has said in an interview for the 2008 box-set release of "The Lamb" that he was not happy about the choice of model as he had vividly imagined Rael as being Puerto Rican.
Through the rest of the 1970s, various Hipgnosis artists designed Genesis' studio album covers. The "Trick of the Tail" cover depicts the characters from the album songs, including the robber from "Robbery, Assault and Battery", the beast from the title track, and a metaphoric image of old age reminiscing on youth from the song "Ripples..." and a squonk (from the song of the same name) is also featured on the rear of the cover. Beginning with "Duke", Genesis albums have featured artwork designed by Bill Smith Studios. The band's highest-selling album "Invisible Touch", features the artwork of Assorted Images, which had previously designed sleeves for Simple Minds, Duran Duran and Culture Club. The "We Can't Dance" cover art features the work of Felicity Roma Bowers, and is reminiscent of "Wind & Wuthering", now presented in hazy watercolour. The "Calling All Stations" and the compilation "Turn It On Again: The Hits" sleeves were designed by Wherefore Art?.
Criticism.
Early incarnations of Genesis were often targets for criticism during the 1970s. An article in "Q Magazine" describes a 1977 Ray Lowry cartoon, which depicted an arena of "either asleep, moribund, [or] comatose" fans watching a live Genesis performance, with the band's name emblazoned on a banner above the stage reading "GENESNOOZE".
More specifically, some in Britain – especially supporters of the punk movement – regarded Genesis in particular, but also the progressive rock genre more generally, as overtly middle class (paying particular attention to Gabriel, Banks and Rutherford's private education), and claimed that rock music was being taken away from the working class, whom they regarded as its core audience. Peter Gabriel claimed that their audience was a "mixture of social classes" and that such a suggestion was a fabrication of the critics. In 2013, Gabriel told "Mojo": "To this day, we’ve never outgrown the snotty rich-kid thing. It used to piss me off seeing all these 'people's hero' musicians – like Joe Strummer – who’d come from a similar background to mine, but were keeping it quiet. In Genesis we were always very straight about where we came from, and we were middle-class, not aristocratic."
Gabriel's theatrics were unpalatable to some of the mainstream rock audience, resulting in a cult following rather than mainstream. This was exemplified during live performances of Gabriel's last Genesis album, "The Lamb Lies Down on Broadway", during which he appeared on stage as various characters in the album's lyrics. The elaborate storyline for "The Lamb" proved difficult to understand and accept, and caused a bit of friction within the band. Collins later recalled that Gabriel would "be in a Slipperman costume trying to get a mic anywhere near his throat, and be out of breath—all twisted up. Towards the end I felt the singing wasn't really being heard; the songs weren't really being heard".
BBC Radio 1 DJ John Peel championed the band in their early years and they performed three sessions for him between 1970 and 1972, but "he grew disillusioned with their later excesses". Peel was quoted: "I used to go and see Genesis and after about three minutes I'd think, oh, I wish this would stop!"
Conversely, the band's transition from lengthy, complex songs to more compact, simplistic, radio-friendly material was not welcomed by critics; "Rolling Stone""s review of "...And Then There Were Three..." read: "...this contemptible opus is but the palest shadow of the group's earlier accomplishments." "I don't feel we've bastardised the way we were", Collins remarked in an interview with "Music Express": "on a generous day I'll blame me for the change, but I just think it is us growing up, listening to different things".
In a 1982 interview in "Sounds", Collins talked about the band's reputation in the music press and said that he only knew of one music journalist, Hugh Fielder, who openly liked Genesis.
In 1987, "Los Angeles Times" critic Robert Hilburn stated: "There's something flabbergastingly insignificant about Genesis. Its themes touch on the usual subjects – various desires and disappointments in love and life – but there is scant discovery. That isn't music that documents our times or questions our assumptions, the way involving art does. Rather than bite, probe or surprise, Genesis' music just lulls. No wonder it fits so perfectly into beer commercials." Hilburn expressed more admiration for the earlier version of the band, describing it as "a promising, if often overly ambitious progressive-rock entry, highlighted by expert musicianship and the showmanship/imagination of lead singer Peter Gabriel."
Reviewing "Genesis 1976–1982" in "Q", Andy Fyfe wrote: "... in spite of 150 ["sic"] million album sales the bottom line is that little of the band’s output has aged well ... There are moments of impressive songwriting, such as the tender "Many Too Many", the darkly tragic "Duchess" and epic "One for the Vine", but little of Genesis's music transcends in the way real classics do, and that is why they will remain perennial whipping boys for decades to come."
Music critic J. D. Considine wrote of the band:
Genesis has had a hard time getting respect. In the early '70s, when the group specialised in ambitious, theatrical story-songs, it attracted an avid cult following but was largely ignored by the rock press and public at large. Later in the decade, lead singer Peter Gabriel was finally recognised as a major talent – but only after he'd left the band, who were at this point being derided as middlebrow throwbacks still in thrall to the pomposities of art rock. Even in the early '80s, when Genesis did finally shed its art-rock inclinations and move toward pop, becoming international stars in the process, the press was unimpressed, dismissing the group as easy-listening lightweights. By the '90s, even the solo success of members Phil Collins and Mike Rutherford was being held against the group, by then one of the best-known rock acts in the world. All of which, to be honest, has been grossly unfair to the group. Granted, Genesis has made its share of mediocre albums – perhaps even more than its share, considering how long the band has been around. But bad albums? None to speak of.
References.
</dl>

</doc>
<doc id="52547" url="http://en.wikipedia.org/wiki?curid=52547" title="Jehovah's Witnesses">
Jehovah's Witnesses

Jehovah's Witnesses is a millenarian restorationist Christian denomination with nontrinitarian beliefs distinct from mainstream Christianity. According to August 2014 organizational statistics published in the 2015 Yearbook of Jehovah's Witnesses, worldwide membership exceeded 8.2 million adherents involved in evangelism, convention attendance exceeded 15 million, and annual Memorial attendance exceeded 19.9 million. Jehovah's Witnesses are directed by the Governing Body of Jehovah's Witnesses, a group of elders in Brooklyn, New York, which establishes all doctrines based on its interpretations of the Bible; they prefer to use their own translation, the "New World Translation of the Holy Scriptures". They believe that the destruction of the present world system at Armageddon is imminent, and that the establishment of God's kingdom over the earth is the only solution for all problems faced by humanity.
The group emerged from the Bible Student movement, founded in the late 1870s by Charles Taze Russell with the formation of Zion's Watch Tower Tract Society, with significant organizational and doctrinal changes under the leadership of Joseph Franklin Rutherford. The name "Jehovah's witnesses" was adopted in 1931 to distinguish themselves from other Bible Student groups and symbolize a break with the legacy of Russell's traditions.
Jehovah's Witnesses are best known for their door-to-door preaching, distributing literature such as "The Watchtower" and "Awake!", and refusing military service and blood transfusions. They consider use of the name "Jehovah" vital for proper worship. They reject Trinitarianism, inherent immortality of the soul, and hellfire, which they consider to be unscriptural doctrines. They do not observe Christmas, Easter, birthdays, or other holidays and customs they consider to have pagan origins incompatible with Christianity. Adherents commonly refer to their body of beliefs as "the truth" and consider themselves to be "in the truth". They consider secular society to be morally corrupt and under the influence of Satan, and most limit their social interaction with non-Witnesses. Congregational disciplinary actions include "disfellowshipping", their term for formal expulsion and shunning. Baptized individuals who formally leave are considered "disassociated" and are also shunned. Disfellowshipped and disassociated individuals may eventually be reinstated if deemed repentant.
The religion's position regarding conscientious objection to military service and refusal to salute national flags has brought it into conflict with some governments. Consequently, some Jehovah's Witnesses have been persecuted and their activities are banned or restricted in some countries. Persistent legal challenges by Jehovah's Witnesses have influenced legislation related to civil rights in several countries.
The organization has attracted criticism over issues surrounding biblical translation, doctrines, handling of sexual abuse cases, and alleged coercion of its members. The claims are rejected by adherents, and some have been disputed by courts and religious scholars.
History.
Background (1870–1916).
In 1870, Charles Taze Russell and others formed a group in Pittsburgh, Pennsylvania, to study the Bible. During the course of his ministry, Russell disputed many beliefs of mainstream Christianity including immortality of the soul, hellfire, predestination, the fleshly return of Jesus Christ, the Trinity, and the burning up of the world. In 1876, Russell met Nelson H. Barbour; later that year they jointly produced the book "Three Worlds," which combined restitutionist views with end time prophecy. The book taught that God's dealings with humanity were divided dispensationally, each ending with a "harvest," that Christ had returned as an invisible spirit being in 1874 inaugurating the "harvest of the Gospel age," and that 1914 would mark the end of a 2520-year period called "the Gentile Times," at which time world society would be replaced by the full establishment of God's kingdom on earth. Beginning in 1878 Russell and Barbour jointly edited a religious journal, "Herald of the Morning". In June 1879 the two split over doctrinal differences, and in July, Russell began publishing the magazine "Zion's Watch Tower and Herald of Christ's Presence", stating that its purpose was to demonstrate that the world was in "the last days," and that a new age of earthly and human restitution under the reign of Christ was imminent.
From 1879, "Watch Tower" supporters gathered as autonomous congregations to study the Bible topically. Thirty congregations were founded, and during 1879 and 1880, Russell visited each to provide the format he recommended for conducting meetings. As congregations continued to form during Russell's ministry, they each remained self-administrative, functioning under the congregationalist style of church governance. In 1881, "Zion's Watch Tower Tract Society" was presided over by William Henry Conley, and in 1884, Charles Taze Russell incorporated the society as a non-profit business to distribute tracts and Bibles. By about 1900, Russell had organized thousands of part- and full-time colporteurs, and was appointing foreign missionaries and establishing branch offices. By the 1910s, Russell's organization maintained nearly a hundred "pilgrims," or traveling preachers. Russell engaged in significant global publishing efforts during his ministry, and by 1912, he was the most distributed Christian author in the United States.
Russell moved the Watch Tower Society's headquarters to Brooklyn, New York, in 1909, combining printing and corporate offices with a house of worship; volunteers were housed in a nearby residence he named "Bethel". He identified the religious movement as "Bible Students," and more formally as the International Bible Students Association. By 1910, about 50,000 people worldwide were associated with the movement and congregations re-elected him annually as their "pastor." Russell died October 31, 1916, at the age of 64 while returning from a ministerial speaking tour.
Reorganization (1917–1942).
In January 1917, the Watch Tower Society's legal representative, Joseph Franklin Rutherford, was elected as its next president. His election was disputed, and members of the Board of Directors accused him of acting in an autocratic and secretive manner. The divisions between his supporters and opponents triggered a major turnover of members over the next decade. In June 1917, he released "The Finished Mystery" as a seventh volume of Russell's Studies in the Scriptures series. The book, published as the posthumous work of Russell, was a compilation of his commentaries on the Bible books of Ezekiel and Revelation, plus numerous additions by Bible Students Clayton Woodworth and George Fisher. It strongly criticized Catholic and Protestant clergy and Christian involvement in the Great War. As a result, Watch Tower Society directors were jailed for sedition under the "Espionage Act" in 1918 and members were subjected to mob violence; charges against the directors were dropped in 1920.
Rutherford centralized organizational control of the Watch Tower Society. In 1919, he instituted the appointment of a director in each congregation, and a year later all members were instructed to report their weekly preaching activity to the Brooklyn headquarters. At an international convention held at Cedar Point, Ohio, in September 1922, a new emphasis was made on house-to-house preaching. Significant changes in doctrine and administration were regularly introduced during Rutherford's twenty-five years as president, including the 1920 announcement that the Jewish patriarchs (such as Abraham and Isaac) would be resurrected in 1925, marking the beginning of Christ's thousand-year Kingdom. Disappointed by the changes, tens of thousands of defections occurred during the first half of Rutherford's tenure, leading to the formation of several Bible Student organizations independent of the Watch Tower Society, most of which still exist. By mid-1919, as many as one in seven of Russell-era Bible Students had ceased their association with the Society, and as many as two-thirds by the end of the 1920s.
On July 26, 1931, at a convention in Columbus, Ohio, Rutherford introduced the new name—"Jehovah's witnesses"—based on Isaiah 43:10: "Ye are my witnesses, saith Jehovah, and my servant whom I have chosen"—which was adopted by resolution. The name was chosen to distinguish his group of Bible Students from other independent groups that had severed ties with the Society, as well as symbolize the instigation of new outlooks and the promotion of fresh evangelizing methods. In 1932, Rutherford eliminated the system of locally elected elders and in 1938, introduced what he called a "theocratic" (literally, "God-ruled") organizational system, under which appointments in congregations worldwide were made from the Brooklyn headquarters.
From 1932, it was taught that the "little flock" of 144,000 would not be the only people to survive Armageddon. Rutherford explained that in addition to the 144,000 "anointed" who would be resurrected—or transferred at death—to live in heaven to rule over earth with Christ, a separate class of members, the "great multitude," would live in a paradise restored on earth; from 1935, new converts to the movement were considered part of that class. By the mid-1930s, the timing of the beginning of Christ's presence (Greek: "parousía"), his enthronement as king, and the start of the "last days" were each moved to 1914.
As their interpretations of the Bible developed, Witness publications decreed that saluting national flags is a form of idolatry, which led to a new outbreak of mob violence and government opposition in the United States, Canada, Germany, and other countries.
Worldwide membership of Jehovah's Witnesses reached 113,624 in 5,323 congregations by the time of Rutherford's death in January 1942.
Continued development (1942–present).
Nathan Knorr was appointed as third president of the Watch Tower Bible and Tract Society in 1942. Knorr commissioned a new translation of the Bible, the "New World Translation of the Holy Scriptures", the full version of which was released in 1961. He organized large international assemblies, instituted new training programs for members, and expanded missionary activity and branch offices throughout the world. Knorr's presidency was also marked by an increasing use of explicit instructions guiding Witnesses in their lifestyle and conduct, and a greater use of congregational judicial procedures to enforce a strict moral code.
From 1966, Witness publications and convention talks built anticipation of the possibility that Christ's thousand-year reign might begin in late 1975 or shortly thereafter. The number of baptisms increased significantly, from about 59,000 in 1966 to more than 297,000 in 1974. By 1975, the number of active members exceeded two million. Membership declined during the late 1970s after expectations for 1975 were proved wrong. Watch Tower Society literature did not state dogmatically that 1975 would definitely mark the end, but in 1980 the Watch Tower Society admitted its responsibility in building up hope regarding that year.
The offices of elder and ministerial servant were restored to Witness congregations in 1972, with appointments made from headquarters (and later, also by branch committees). It has been announced that starting in September 2014, appointments will be made by traveling overseers. In a major organizational overhaul in 1976, the power of the Watch Tower Society president was diminished, with authority for doctrinal and organizational decisions passed to the Governing Body. Since Knorr's death in 1977, the position of president has been occupied by Frederick Franz (1977–1992) and Milton Henschel (1992–2000), both members of the Governing Body, and since 2000 by Don A. Adams, not a member of the Governing Body. In 1995, Jehovah's Witnesses abandoned the idea that Armageddon must occur during the lives of the generation that was alive in 1914 and in 2013 changed their teaching on the "generation".
Organization.
Jehovah's Witnesses are organized hierarchically, in what the leadership calls a "theocratic organization", reflecting their belief that it is God's "visible organization" on earth. The organization is led by the Governing Body—an all-male group that varies in size, but since early 2014 has comprised seven members, all of whom profess to be of the "anointed" class with a hope of heavenly life—based in the Watch Tower Society's Brooklyn headquarters. There is no election for membership; new members are selected by the existing body. Until late 2012, the Governing Body described itself as the representative and "spokesman" for God's "faithful and discreet slave class" (approximately 10,000 self-professed "anointed" Jehovah's Witnesses). At the 2012 Annual Meeting of the Watch Tower Society, the "faithful and discreet slave" was defined as referring to the Governing Body only. The Governing Body directs several committees that are responsible for administrative functions, including publishing, assembly programs and evangelizing activities. It appoints all branch committee members and "traveling overseers", after they have been recommended by local branches, with traveling overseers supervising "circuits" of congregations within their jurisdictions. Traveling overseers appoint local elders and ministerial servants, and while branch offices may appoint regional committees for matters such as Kingdom Hall construction or disaster relief.
Each congregation has a body of appointed unpaid male elders and ministerial servants. Elders maintain general responsibility for congregational governance, setting meeting times, selecting speakers and conducting meetings, directing the public preaching work, and creating "judicial committees" to investigate and decide disciplinary action for cases involving sexual misconduct or doctrinal breaches. New elders are appointed by a traveling overseer after recommendation by the existing body of elders. Ministerial servants—appointed in a similar manner to elders—fulfill clerical and attendant duties, but may also teach and conduct meetings. Witnesses do not use "elder" as a title to signify a formal clergy-laity division, though elders may employ ecclesiastical privilege such as confession of sins.
Baptism is a requirement for being considered a member of Jehovah's Witnesses. Jehovah's Witnesses do not practice infant baptism, and previous baptisms performed by other denominations are not considered valid. Individuals undergoing baptism must affirm publicly that dedication and baptism identify them "as one of Jehovah’s Witnesses in association with God's spirit-directed organization," though Witness publications say baptism symbolizes personal dedication to God and not "to a man, work or organization." Watch Tower Society publications emphasize the need for members to be obedient and loyal to Jehovah and to "his organization," stating that individuals must remain part of it to receive God's favor and to survive Armageddon.
Funding.
Much of their funding is provided by donations, primarily from members. There is no tithing or collection. In 2001 "Newsday" listed the Watch Tower Society as one of New York's forty richest corporations, with revenues exceeding $950 million. The organization reported for the same year that it "spent over 70.9 million dollars in caring for special pioneers, missionaries, and traveling overseers in their field service assignments."
Beliefs.
Sources of doctrine.
Jehovah's Witnesses believe their religion is a restoration of first-century Christianity. Doctrines of Jehovah's Witnesses are established by the Governing Body, which assumes responsibility for interpreting and applying scripture. The Watch Tower Society does not issue any single, comprehensive "statement of faith", but prefers to express its doctrinal position in a variety of ways in its publications. Its publications teach that doctrinal changes and refinements result from a process of progressive revelation, in which God gradually reveals his will and purpose, and that such enlightenment results from the application of reason and study, the guidance of the holy spirit, and direction from Jesus Christ and angels. The Society also teaches that members of the Governing Body are helped by the holy spirit to discern "deep truths", which are then considered by the entire Governing Body before it makes doctrinal decisions. The religion's leadership, while disclaiming divine inspiration and infallibility, is said to provide "divine guidance" through its teachings described as "based on God's Word thus ... not from men, but from Jehovah."
The entire Protestant canon of scripture is considered the inspired, inerrant word of God. Jehovah's Witnesses consider the Bible to be scientifically and historically accurate and reliable and interpret much of it literally, but accept parts of it as symbolic. They consider the Bible to be the final authority for all their beliefs, although sociologist Andrew Holden's ethnographic study of the religion concluded that pronouncements of the Governing Body, through Watch Tower Society publications, carry almost as much weight as the Bible. Regular personal Bible reading is frequently recommended; Witnesses are discouraged from formulating doctrines and "private ideas" reached through Bible research independent of Watch Tower Society publications, and are cautioned against reading other religious literature. Adherents are told to have "complete confidence" in the leadership, avoid skepticism about what is taught in the Watch Tower Society's literature, and "not advocate or insist on personal opinions or harbor private ideas when it comes to Bible understanding." The religion makes no provision for members to criticize or contribute to official teachings and all Witnesses must abide by its doctrines and organizational requirements.
Jehovah and Jesus Christ.
Jehovah's Witnesses emphasize the use of what they consider to be God's name, represented in the Old Testament by the Tetragrammaton. In English they prefer to use the name "Jehovah". They believe that Jehovah is the only true God, the creator of all things, and the "Universal Sovereign". They believe that all worship should be directed toward him, and that he is not part of a Trinity; consequently, the religion places more emphasis on God than on Christ. They believe that the holy spirit is God's applied power or "active force", rather than a person.
Jehovah's Witnesses believe that Jesus is God's only direct creation, that everything else was created by means of Christ, and that the initial unassisted act of creation uniquely identifies Jesus as God's "only-begotten Son". Jesus served as a redeemer and a ransom sacrifice to pay for the sins of humanity. They believe Jesus died on a single upright post rather than the traditional cross. They believe that references in the Bible to the Archangel Michael, Abaddon (Apollyon), and the Word all refer to Jesus. Jesus is considered to be the only intercessor and high priest between God and humanity, and appointed by God as the king and judge of his kingdom. His role as a mediator (referred to in 1 Timothy 2:5) is applied to the 'anointed' class, though the 'other sheep' are said to also benefit from the arrangement.
Satan.
Jehovah's Witnesses believe that Satan was originally a perfect angel who developed feelings of self-importance and craved worship. Satan influenced Adam and Eve to disobey God, and humanity subsequently became participants in a challenge involving the competing claims of Jehovah and Satan to universal sovereignty. Other angels who sided with Satan became demons.
Jehovah's Witnesses teach that Satan and his demons were cast down to earth from heaven after October 1, 1914, at which point the end times began. Witnesses believe that Satan is the ruler of the current world order, that human society is influenced and misled by Satan and his demons, and that they are a cause of human suffering. They believe that human governments are controlled by Satan, but that he does not directly control each human ruler.
Life after death.
Jehovah's Witnesses believe death is a state of non-existence with no consciousness. There is no Hell of fiery torment; Hades and Sheol are understood to refer to the condition of death, termed the "common grave". Jehovah's Witnesses consider the soul to be a life or a living body that can die. Watch Tower Society publications teach that humanity is in a sinful state, from which release is only possible by means of Jesus' shed blood as a ransom, or atonement, for the sins of humankind.
Witnesses believe that a "little flock" go to heaven, but that the hope for life after death for the majority of "other sheep" involves being resurrected by God to a cleansed earth after Armageddon. They interpret Revelation 14:1–5 to mean that the number of Christians going to heaven is limited to exactly 144,000, who will rule with Jesus as kings and priests over earth. Jehovah's Witnesses teach that only they meet scriptural requirements for surviving Armageddon, but that God is the final judge. During Christ's millennial reign, most people who died prior to Armageddon will be resurrected with the prospect of living forever; they will be taught the proper way to worship God to prepare them for their final test at the end of the millennium.
God's kingdom.
Watch Tower Society publications teach that God's kingdom is a literal government in heaven, ruled by Jesus Christ and 144,000 Christians drawn from the earth. The kingdom is viewed as the means by which God will accomplish his original purpose for the earth, transforming it into a paradise without sickness or death. It is said to have been the focal point of Jesus' ministry on earth. They believe the kingdom was established in heaven in 1914, and that Jehovah's Witnesses serve as representatives of the kingdom on earth.
Eschatology.
A central teaching of Jehovah's Witnesses is that the current world era, or "system of things", entered the "last days" in 1914 and faces imminent destruction through intervention by God and Jesus Christ, leading to deliverance for those who worship God acceptably. They consider all other present-day religions to be false, identifying them with "Babylon the Great", or the "harlot", of Revelation 17, and believe that they will soon be destroyed by the United Nations, which they believe is represented in scripture by the scarlet-colored wild beast of Revelation chapter 17. This development will mark the beginning of the "great tribulation". Satan will subsequently attack Jehovah's Witnesses, an action that will prompt God to begin the war of Armageddon, during which all forms of government and all people not counted as Christ's "sheep", or true followers, will be destroyed. After Armageddon, God will extend his heavenly kingdom to include earth, which will be transformed into a paradise similar to the Garden of Eden. After Armageddon, most of those who had died before God's intervention will gradually be resurrected during "judgment day" lasting for one thousand years. This judgment will be based on their actions after resurrection rather than past deeds. At the end of the thousand years, a final test will take place when Satan is released to mislead perfect mankind. Those who fail will be destroyed, along with Satan and his demons. The end result will be a fully tested, glorified human race. Christ will then hand all authority back to God.
Watch Tower Society publications teach that Jesus Christ began to rule in heaven as king of God's kingdom in October 1914, and that Satan was subsequently ousted from heaven to the earth, resulting in "woe" to humanity. They believe that Jesus rules invisibly, from heaven, perceived only as a series of "signs". They base this belief on a rendering of the Greek word "parousia"—usually translated as "coming" when referring to Christ—as "presence". They believe Jesus' presence includes an unknown period beginning with his inauguration as king in heaven in 1914, and ending when he comes to bring a final judgment against humans on earth. They thus depart from the mainstream Christian belief that the "second coming" of Matthew 24 refers to a single moment of arrival on earth to judge humans.
Practices.
Worship.
Meetings for worship and study are held at Kingdom Halls, which are typically functional in character, and do not contain religious symbols. Witnesses are assigned to a congregation in whose "territory" they usually reside and attend weekly services they refer to as "meetings" as scheduled by congregation elders. The meetings are largely devoted to study of Watch Tower Society literature and the Bible. The format of the meetings is established by the religion's headquarters, and the subject matter for most meetings is the same worldwide. Congregations meet for two sessions each week comprising five distinct meetings that total about three-and-a-half hours, typically gathering mid-week (three meetings) and on the weekend (two meetings). Prior to 2009, congregations met three times each week; these meetings were condensed, with the intention that members dedicate an evening for "family worship". Gatherings are opened and closed with kingdom songs (hymns) and brief prayers. Twice each year, Witnesses from a number of congregations that form a "circuit" gather for a one-day assembly. Larger groups of congregations meet once a year for a three-day "regional convention", usually at rented stadiums or auditoriums. Their most important and solemn event is the commemoration of the "Lord's Evening Meal", or "Memorial of Christ's Death" on the date of the Jewish Passover.
Evangelism.
Jehovah's Witnesses are perhaps best known for their efforts to spread their beliefs, most notably by visiting people from house to house, distributing literature published by the Watch Tower Society in 700 languages. The objective is to start a regular "Bible study" with any person who is not already a member, with the intention that the student be baptized as a member of the group; if the student does not show an interest in becoming a member, the study is terminated. Witnesses are told they are under a biblical command to engage in public preaching. They are instructed to devote as much time as possible to their ministry and are required to submit an individual monthly "Field Service Report". Baptized members who fail to submit a report every month are termed "irregular" and may be counseled by elders; those who do not submit a report for six consecutive months are termed "inactive".
Ethics and morality.
All sexual relations outside of marriage are grounds for expulsion if the individual is not deemed repentant; homosexual activity is considered a serious sin, and same-sex marriages are forbidden. Abortion is considered murder. Suicide is considered to be "self-inflicted murder" and a sin against God. Modesty in dress and grooming is frequently emphasized. Gambling, drunkenness, illegal drugs, and tobacco use are forbidden. Drinking of alcoholic beverages is permitted in moderation.
The family structure is patriarchal. The husband is considered to have authority on family decisions, but is encouraged to solicit his wife's thoughts and feelings, as well as those of his children. Marriages are required to be monogamous and legally registered. Marrying a non-believer, or endorsing such a union, is strongly discouraged and carries religious sanctions. Divorce is discouraged, and remarriage is forbidden unless a divorce is obtained on the grounds of adultery, which they refer to as "a scriptural divorce".
If a divorce is obtained for any other reason, remarriage is considered adulterous unless the prior spouse has died or is since considered to have committed sexual immorality. Extreme physical abuse, willful non-support of one's family, and what the religion terms "absolute endangerment of spirituality" are considered grounds for legal separation.
Disciplinary action.
Formal discipline is administered by congregation elders. When a baptized member is accused of committing a serious sin—usually cases of sexual misconduct or charges of apostasy for disputing the Watch Tower Society's doctrines—a judicial committee is formed to determine guilt, provide help and possibly administer discipline. Disfellowshipping, a form of shunning, is the strongest form of discipline, administered to an offender deemed unrepentant. Contact with disfellowshipped individuals is limited to direct family members living in the same home, and with congregation elders who may invite disfellowshipped persons to apply for reinstatement; formal business dealings may continue if contractually or financially obliged. Witnesses are taught that avoiding social and spiritual interaction with disfellowshipped individuals keeps the congregation free from immoral influence and that "losing precious fellowship with loved ones may help [the shunned individual] to come 'to his senses,' see the seriousness of his wrong, and take steps to return to Jehovah." The practice of shunning may also serve to deter other members from dissident behavior. Members who disassociate (formally resign) are described in Watch Tower Society literature as wicked and are also shunned. Expelled individuals may eventually be reinstated to the congregation if deemed repentant by elders in the congregation in which the disfellowshipping was enforced. Reproof is a lesser form of discipline given formally by a judicial committee to a baptized Witness who is considered repentant of serious sin; the reproved person temporarily loses conspicuous privileges of service, but suffers no restriction of social or spiritual fellowship. Marking, a curtailing of social but not spiritual fellowship, is practiced if a baptized member persists in a course of action regarded as a violation of Bible principles but not a serious sin.
Separateness.
Jehovah's Witnesses believe that the Bible condemns the mixing of religions, on the basis that there can only be one truth from God, and therefore reject interfaith and ecumenical movements. They believe that only their religion represents true Christianity, and that other religions fail to meet all the requirements set by God and will soon be destroyed. Jehovah's Witnesses are taught that it is vital to remain "separate from the world." Watch Tower Society publications define the "world" as "the mass of mankind apart from Jehovah's approved servants" and teach that it is morally contaminated and ruled by Satan. Witnesses are taught that association with "worldly" people presents a "danger" to their faith, and are instructed to minimize social contact with non-members to better maintain their own standards of morality.
Jehovah's Witnesses believe their highest allegiance belongs to God's kingdom, which is viewed as an actual government in heaven, with Christ as king. They remain politically neutral, do not seek public office, and are discouraged from voting, though individual members may participate in uncontroversial community improvement issues. Although they do not take part in politics, they respect the authority of the governments under which they live. They do not celebrate religious holidays such as Christmas and Easter, nor do they observe birthdays, nationalistic holidays, or other celebrations they consider to honor people other than Jesus. They feel that these and many other customs have pagan origins or reflect a nationalistic or political spirit. Their position is that these traditional holidays reflect Satan's control over the world. Witnesses are told that spontaneous giving at other times can help their children to not feel deprived of birthdays or other celebrations.
They do not work in industries associated with the military, do not serve in the armed services, and refuse national military service, which in some countries may result in their arrest and imprisonment. They do not salute or pledge allegiance to flags or sing national anthems or patriotic songs. Jehovah's Witnesses see themselves as a worldwide brotherhood that transcends national boundaries and ethnic loyalties. Sociologist Ronald Lawson has suggested the religion's intellectual and organizational isolation, coupled with the intense indoctrination of adherents, rigid internal discipline and considerable persecution, has contributed to the consistency of its sense of urgency in its apocalyptic message.
Rejection of blood transfusions.
Jehovah's Witnesses refuse blood transfusions, which they consider a violation of God's law based on their interpretation of Acts 15:28, 29 and other scriptures. Since 1961 the willing acceptance of a blood transfusion by an unrepentant member has been grounds for expulsion from the religion. Watch Tower Society literature directs Witnesses to refuse blood transfusions, even in "a life-or-death situation". Jehovah's Witnesses accept non-blood alternatives and other medical procedures in lieu of blood transfusions, and the Watch Tower Society provides information about current non-blood medical procedures.
Though Jehovah's Witnesses do not accept blood transfusions of whole blood, they may accept some blood plasma fractions at their own discretion. The Watch Tower Society provides pre-formatted Durable Power of Attorney documents prohibiting major blood components, in which members can specify which allowable fractions and treatments they will personally accept. Jehovah's Witnesses have established Hospital Liaison Committees as a cooperative arrangement between individual Jehovah's Witnesses and medical professionals and hospitals.
Demographics.
Jehovah's Witnesses have an active presence in most countries, but do not form a large part of the population of any country.
As of August 2014, Jehovah's Witnesses report an average of 8.2 million "publishers"—the term they use for members actively involved in preaching—in 115,416 congregations. In 2014, these reports indicated over 1.94 billion hours spent in preaching and "Bible study" activity. Since the mid-1990s, the number of peak publishers has increased from 4.5 million to 8.2 million. In the same year, they conducted "Bible studies" with over 9.2 million individuals, including those conducted by Witness parents with their children. Jehovah's Witnesses estimate their current worldwide growth rate to be 2.2% per year.
The official published membership statistics, such as those mentioned above, include only those who submit reports for their personal ministry; official statistics do not include "inactive" and "disfellowshipped" individuals or others who might attend their meetings. As a result, only about half of those who self-identified as Jehovah's Witnesses in independent demographic studies are considered "active" by the faith itself. The 2008 US Pew Forum on Religion & Public Life survey found a low retention rate among members of the religion: about 37% of people raised in the religion continued to identify themselves as Jehovah's Witnesses.
Sociological analysis.
Sociologist James A. Beckford, in his 1975 study of Jehovah's Witnesses, classified the religion's organizational structure as "Totalizing", characterized by an assertive leadership, specific and narrow objectives, control over competing demands on members' time and energy, and control over the quality of new members. Other characteristics of the classification include likelihood of friction with secular authorities, reluctance to co-operate with other religious organizations, a high rate of membership turnover, a low rate of doctrinal change, and strict uniformity of beliefs among members. Beckford identified the religion's chief characteristics as "historicism" (identifying historical events as relating to the outworking of God's purpose), "absolutism" (conviction that the Watch Tower Society dispenses absolute truth), "activism" (capacity to motivate members to perform missionary tasks), "rationalism" (conviction that Witness doctrines have a rational basis devoid of mystery), "authoritarianism" (rigid presentation of regulations without the opportunity for criticism) and "world indifference" (rejection of certain secular requirements and medical treatments).
Sociologist Bryan R. Wilson, in his consideration of five religions including Jehovah's Witnesses, noted that each of the religions:
A sociological comparative study by the Pew Research Center found that Jehovah's Witnesses in the United States ranked highest in statistics for getting no further than high school graduation, belief in God, importance of religion in one's life, frequency of religious attendance, frequency of prayers, frequency of Bible reading outside of religious services, belief their prayers are answered, belief that their religion can only be interpreted one way, belief that theirs is the only one true faith leading to eternal life, opposition to abortion, and opposition to homosexuality. In the study, Jehovah's Witnesses ranked lowest in statistics for having earned a graduate degree and interest in politics.
Opposition.
Controversy surrounding various beliefs, doctrines and practices of Jehovah's Witnesses has led to opposition from local governments, communities, and religious groups. Religious commentator Ken Jubber wrote that "Viewed globally, this persecution has been so persistent and of such intensity that it would not be inaccurate to regard Jehovah's Witnesses as the most persecuted group of Christians of the twentieth century."
Persecution.
Political and religious animosity against Jehovah's Witnesses has at times led to mob action and government oppression in various countries. Their doctrine of political neutrality and their refusal to serve in the military has led to imprisonment of members who refused conscription during World War II and at other times where national service has been compulsory. In 1933, there were approximately 20,000 Jehovah's Witnesses in Germany, of whom about 10,000 were imprisoned. Of those, 2000 were sent to Nazi concentration camps, where they were identified by purple triangles; as many as 1200 died, including 250 who were executed. In Canada, Jehovah's Witnesses were interned in camps along with political dissidents and people of Chinese and Japanese descent. In the former Soviet Union, about 9,300 Jehovah's Witnesses were deported to Siberia as part of Operation North in April 1951. Their religious activities are currently banned or restricted in some countries, including China, Vietnam and some Islamic states.
Authors including William Whalen, Shawn Francis Peters and former Witnesses Barbara Grizzuti Harrison, Alan Rogerson and William Schnell, have claimed the religion incited opposition to pursue a course of martyrdom under Rutherford's leadership during the 1930s, in a bid to attract dispossessed members of society, and to convince members that persecution from the outside world was evidence of the truth of their struggle to serve God. Watch Tower Society literature of the period directed Witnesses to "avoid unnecessary opposition or prejudice", stating that their purpose is not to get arrested.
Legal challenges.
Several cases involving Jehovah's Witnesses have been heard by Supreme Courts throughout the world. The cases generally relate to their right to practice their religion, displays of patriotism and military service, and blood transfusions.
In the United States, their persistent legal challenges prompted a series of state and federal court rulings that reinforced judicial protections for civil liberties. Among the rights strengthened by Witness court victories in the United States are the protection of religious conduct from federal and state interference, the right to abstain from patriotic rituals and military service, the right of patients to refuse medical treatment, and the right to engage in public discourse. Similar cases in their favor have been heard in Canada.
Criticism.
Jehovah's Witnesses have attracted criticism over issues surrounding their Bible translation, doctrines, their handling of sexual abuse cases, and alleged coercion of members. Many of the claims are denied by Jehovah's Witnesses and some have also been disputed by religious scholars.
Free speech and thought.
Doctrines of Jehovah's Witnesses are established by the Governing Body, without consultation with other members. The religion does not tolerate dissidence about doctrines and practices; members who openly disagree with the religion's teachings are shunned. Watch Tower Society publications strongly discourage followers from questioning its doctrines and counsel, reasoning that the Society is to be trusted as "God's organization". It also warns members to "avoid independent thinking", claiming such thinking "was introduced by Satan the Devil" and would "cause division". Those who openly disagree with official teachings are condemned as "apostates" who are "mentally diseased".
Former members Heather and Gary Botting compare the cultural paradigms of the religion to George Orwell's "Nineteen Eighty-four", and Alan Rogerson describes the religion's leadership as totalitarian. Other critics charge that by disparaging individual decision-making, the Watch Tower Society cultivates a system of unquestioning obedience in which Witnesses abrogate all responsibility and rights over their personal lives. Critics also accuse the Watch Tower Society of exercising "intellectual dominance" over Witnesses, controlling information and creating "mental isolation", which former Governing Body member Raymond Franz argued were all elements of mind control.
Watch Tower Society publications state that consensus of faith aids unity, and deny that unity restricts individuality or imagination. Historian James Irvin Lichti has rejected the description of the religion as "totalitarian".
Sociologist Rodney Stark states that while Jehovah's Witness leaders are "not always very democratic" and members are expected to conform to "rather strict standards," enforcement tends to be informal, sustained by close bonds of friendship and that Jehovah's Witnesses see themselves as "part of the power structure rather than subject to it." Sociologist Andrew Holden states that most members who join millenarian movements such as Jehovah's Witnesses have made an informed choice. However, he also states that defectors "are seldom allowed a dignified exit", and describes the administration as autocratic.
New World Translation.
Some Bible scholars including Bruce M. Metzger, former Professor and Bible editor at Princeton Theological Seminary, have said that the translation of certain texts in its "New World Translation" of the Bible is biased in favor of Witness practices and doctrines. The Bible editor Harold H. Rowley criticized the pre-release edition of the first volume ("Genesis to Ruth") published in 1953 as "a shining example of how the Bible should not be translated."
On the other hand, in his study on nine of "the Bibles most widely in use in the English-speaking world", Bible scholar Jason BeDuhn, Professor of Religious Studies at the Northern Arizona University, wrote: “The NW [New World Translation] emerges as the most accurate of the translations compared.” Although the general public and many Bible scholars assume that the differences in the New World Translation are the result of religious bias on the part of its translators, BeDuhn stated: “Most of the differences are due to the greater accuracy of the NW as a literal, conservative translation of the original expressions of the New Testament writers.” He added however that the insertion of the name "Jehovah" in the New Testament "violate[s] accuracy in favor of denominationally preferred expressions for God".
Failed predictions.
Watch Tower Society publications have claimed that God has used Jehovah's Witnesses (and formerly, the International Bible Students) to declare his will and has provided advance knowledge about Armageddon and the establishment of God's kingdom. Some publications also claimed that God has used Jehovah's Witnesses and the International Bible Students as a modern-day prophet. Jehovah's Witnesses' publications have made various predictions about world events they believe were prophesied in the Bible. Failed predictions have led to the alteration or abandonment of some doctrines. Some failed predictions that the Watch Tower Society had claimed were presented as "beyond doubt" or "approved by God".
The Watch Tower Society rejects accusations that it is a false prophet, stating that its teachings are not inspired or infallible, and that it has not claimed its predictions were "the words of Jehovah." George D. Chryssides has suggested that with the exception of statements about 1914, 1925 and 1975, the changing views and dates of the Jehovah's Witnesses are largely attributable to changed understandings of biblical chronology than to failed predictions. Chryssides further states, "it is therefore simplistic and naïve to view the Witnesses as a group that continues to set a single end-date that fails and then devise a new one, as many counter-cultists do." However, sociologist Andrew Holden states that since the foundation of the movement around 140 years ago, "Witnesses have maintained that we are living on the precipice of the end of time."
Handling of sexual abuse cases.
Critics have accused Jehovah's Witnesses of employing organizational policies that make the reporting of sexual abuse difficult for members. Some victims of sexual abuse have asserted that they were ordered by certain local elders to maintain silence so as to avoid embarrassment to both the accused and the organization. Jehovah's Witnesses maintain that they have no policy of silence, and that elders are directed to report abuse to authorities when there is evidence of abuse, and when required to by law. In 1997, Jehovah's Witnesses' Office of Public Information published their policy for elders to report allegations of child abuse to the authorities where required by law to do so, even if there was only one witness. An individual known to have sexually abused a child is generally prohibited from holding any position of responsibility inside the organization. Unless considered by the congregation elders to have demonstrated repentance, such a person is typically disfellowshipped.
In California in June 2012, Alameda County Superior Court ordered the Watch Tower Society to pay $21 million in punitive damages, in addition to compensatory damages, after finding that the Society's policy to not disclose the child abuse history of a member to parents in the congregation or to report abuse to authorities contributed to the sexual abuse of a nine-year-old girl. The Watchtower Society appealed the ruling, and in April 2015 the court of appeal concluded that the Watchtower Society was negligent in preventing child abuse committed by a member while engaged in organization-sponsored preaching. The appeal court upheld the trial court's verdict regarding compensatory damages, awarding $7 million to the plaintiff, of which the Watchtower Society and the congregation were ordered to pay $2.8 million, but found that the Watchtower Society had no legal duty to warn the parents or members in the congregation about the child abuse history of other members. 

</doc>
<doc id="52548" url="http://en.wikipedia.org/wiki?curid=52548" title="Carl Bildt">
Carl Bildt

Nils Daniel Carl Bildt (born 15 July 1949) is a Swedish politician and diplomat who was Prime Minister of Sweden from 1991 to 1994. He was the leader of the liberal conservative Moderate Party from 1986 to 1999. Bildt served as Sweden's Minister for Foreign Affairs from 2006 to 2014.
Bildt has been noted internationally as a mediator in the Balkan conflict, serving as the European Union's Special Envoy to the Former Yugoslavia from June 1995, co-chairman of the Dayton Peace Conference in November 1995 and High Representative for Bosnia and Herzegovina from December 1995 to June 1997, immediately after the Bosnian War. From 1999 to 2001, he served as the United Nations Secretary-General's Special Envoy for the Balkans.
Background.
Bildt was born on 15 July 1949 in Halmstad, Halland, to an old Norwegian-Danish-Swedish noble family traditionally domiciled in Bohus county. Colonel Bildt and his family were neighbours to the Palme family. Bildt's father Daniel Bildt (1920–2010) was a former major in the reserves of the now defunct Halland Regiment and a former bureau director in the now defunct Civil Defense Board's Education Bureau. Daniel Bildt married Kerstin Andersson-Alwå in 1947.
Bildt's brother, Nils, was born in 1952. Bildt was married to Kerstin Zetterberg from 1974 to 1975, Mia Bohman (daughter of former Moderate party leader and Minister of Economy, Gösta Bohman) from 1984 to 1997 and, since 1998, has been married to Anna Maria Corazza. Bildt has two children from his second marriage, Gunnel (born 1989) and Nils (born 1991). From his third marriage is Bildt's son Gustaf (born 2004).
Early career.
Bildt attended Stockholm University but never graduated. In 1968, while studying at Stockholm University, Bildt opposed the occupation of the Student Union Building and co-founded the Borgerliga Studenter – Opposition '68 group. He served as chairman of the FMSF Confederation of Swedish Conservative and Liberal Students, a centre-right student organisation, in the early 1970s. Bildt displayed his commitment to the European Union project through joining the Young European Federalists and later becoming vice president of the Swedish section. In 2012, he stated, through his Twitter account, "I still believe that we must continue building federation of nation states. Necessary evolution to meet new challenges."
When the non-socialist formed government in 1976, Bildt served as the Moderate Party coordinator as close collaborator of the party leader and Minister of Economy Gösta Bohman. Bildt became a Member of Parliament in 1979, although he instead served as State Secretary for Policy Coordination in the reformed non-socialist government after that election. As an MP in the early eighties, he became noted as an incisive and combative debater on foreign affairs, and found himself pitted against prime minister Olof Palme. Bildt was elected leader of the Moderate Party in 1986, succeeding Ulf Adelsohn. In 1991, the Social Democrats were defeated by a four-party coalition led by Bildt's Moderate Party.
Prime Minister.
On 4 October 1991, Bildt became the first conservative prime minister in Sweden in 61 years. His government policies focused on liberalizing and reforming the Swedish economy and making Sweden a member of the European Union. It initiated negotiations for Sweden's accession to the European Union, though the work to prepare the ground, at home and versus the EEC/EU, had already started during the final year of the Social Democratic government. The Social Democrats' volte face on possible accession to the EEC was most likely a prerequisite for the positive referendum result. Bildt signed the accession treaty at the European Union summit of Corfu, Greece, on 23 June 1994.
Economic reforms were enacted, including voucher schools, liberalizing markets for telecommunications and energy, privatizing publicly owned companies and health care, contributing to liberalizing the Swedish economy. Arguably, the subsequent budget cut-backs agreement with the Social Democrats and the continued spending cuts by the Social Democratic government following 1994 did more to reform the Swedish economy and the Swedish model than Bildt's government's program. The government's effectiveness was hampered by in-fighting, most memorably over the construction of the Oresund Bridge.
The period was marked by a severe economic crisis. In November 1992, the crisis reached its climax when Sweden left the European Exchange Rate Mechanism and let the Krona float, after having defended the fixed exchange rate at tremendous cost. In some people's opinion, single-minded defense of the Krona led to and continues to draw heavy criticism. Emergency cut-backs were negotiated with the Social Democrats during the crisis. The measures helped reduce the public deficit in 1994 and 1995, and allegedly revived growth in subsequent years. There is debate on whether the economic growth of 2006 were due to the devaluation of the Krona. Some see the increased importance of the export industry as testament to this.
Although Bildt's Moderate Party scored a slight gain in the 1994 election, the Social Democrats gained slightly more ground, enough to unseat him after only one term. Bildt served as leader of the opposition until 1999, when he was succeeded as party leader by Bo Lundgren.
Balkan conflict.
After his term as prime minister, Bildt was active as a mediator in the Balkans conflict, serving as the European Union Special Envoy to Former Yugoslavia from June 1995, co-chairman of the Dayton Peace Conference in November 1995, and High Representative for Bosnia and Herzegovina from December 1995 to June 1997 immediately after the Bosnian War. From 1999 to 2001, he served as the United Nations Secretary General's Special Envoy for the Balkans.
Bildt has been considered persona non-grata in several countries for remarks he has made against various governments. These remarks included one made in Croatia, where he "lost the credibility necessary for the role of a peace mediator" by suggesting that the former President of Croatia, Franjo Tuđman, was as guilty of war crimes as the Krajina Serb leader Milan Martić.
Kosovo unilaterally declared its independence from Serbia on 17 February 2008, without the approval of the UN Security Council, and Sweden recognised it on 4 March 2008. On 8 March 2008, Carl Bildt became the first foreign minister to officially visit Kosovo since it declared its independence.
Minister for Foreign Affairs.
On 6 October 2006, Bildt was appointed as Minister of Foreign Affairs in the newly formed cabinet of Fredrik Reinfeldt. This was seen by many as a surprising move. Not only had Bildt already served both as prime minister and as leader of the Moderate Party, but he and Reinfeldt had previously not gotten along very well. He retained this post following the 2010 general election.
He lost his post after the 2014 general election, and moved on to become a board member of the International Crisis Group.
Controversies and criticisms.
Opposition parties, politicians and journalists have questioned Carl Bildt's suitability as Sweden's Foreign Minister for his private stance on international issues and his private affairs as a businessman with interest in Russian gas giant Gazprom and Lundin Petroleum, an oil company with activities in war-torn Sudan.
Lundin Oil operations in Sudan.
Carl Bildt joined the board of directors of Lundin Oil AB in 2000. Lundin Oil was the lead operator of a consortium that worked in the area that had become the center stage of Sudan's civil war. Bildt won the public debate in Sweden, allowing Lundin Oil to pursue its activities in Sudan. In June 2010, the European Coalition on Oil in Sudan published the report , saying why Lundin may have been complicit in war crimes and crimes against humanity. The company has denied any wrongdoing. The Swedish public prosecutor opened a criminal investigation. Human Rights Watch says blame for the activities in Block 5A in Sudan is held by Lundin Oil, saying that "no war-related displacement at all took place there until 1998", the year when Lundin Oil established themselves in Sudan.
Personal interests.
After leaving his position as leader of the Moderate Party in 1999, other than engaging in international issues, Bildt took positions in the private sector and positions with international think tanks.
His positions in think tanks included serving as the first non-US member on the Board of Trustees of the RAND Corporation in Santa Monica, and on the Advisory Board of the Centre for European Reform in London. He was a member of the board of the European Policy Centre in Brussels, the International Institute for Strategic Studies in London, and the International Advisory Board of the Council on Foreign Affairs in New York.
Bildt served as non-executive director of the Baltimore-based US assets management company Legg Mason, Inc. He served as chairman of the board of Teleopti and chairman of the public affairs consultancy Kreab AB, and board member of the IT consultancy HiQ AB. He was chairman of Nordic Venture Network, which brought Nordic high-tech VC firms together in an informal network. In 2002, Bildt joined the board of directors of Vostok Nafta, a financial company primarily with holdings in Gazprom. Bildt was a member of the board of independent oil company Lundin Petroleum. He left his positions on the boards upon becoming Foreign Minister in October 2006.
Bildt has been criticized for the potential conflict of interest due to his previous position in Vostok Nafta, although he could not divest his stock options until the first two weeks of December 2006. The conflict of interest has the potential to affect Sweden's relations with other European Union countries and Russia, since many EU countries are dependent on Russian oil and gas for their energy needs. On 20 October 2006, Ulf Holm, a member of parliament for the Green Party, reported the Foreign Minister to the Riksdag Constitutional Committee to determine whether Bildt's private economic affairs might represent a conflict of interest. Carl Söderbergh, Secretary General for the Swedish section of Amnesty International, has criticized Bildt since Human Rights issues are within the portfolio of the Minister for Foreign Affairs. The criticism of Bildt for his interests subsided after he announced his intentions of divesting himself of all financial ties with the company. The work by the Constitutional Committee of the Parliament could not find any grounds for questioning the activities of Bildt in these regards. It was revealed that Swedish state pension funds (Swedish: "AP-fonderna") had invested over one billion Swedish krona (140 million US$ or 75 million GBP) in Vostok Nafta.
Bosnian war mediator criticisms.
While prime minister, he was accused of indifference to the ethnic cleansing and genocide committed by the Bosnian Serb forces against Muslim and Croat civilians. Bildt opposed any military intervention and criticized the former British prime minister Margaret Thatcher in 1993 for calling NATO to intervene against the Bosnian Serb forces, which led to the "Sunday Times" describing Bildt and other EU leaders as "robotic political pygmies" and their acceptance of the ongoing genocide as "shameful".
Following Bildt's appointment as the EU special envoy to Yugoslavia, Tom Warrick from the Coalition for International Justice described Bildt as "dangerously misinformed about his own job description" and largely ignorant about the region. "The New York Times" criticized Bildt for a nonchalant attitude towards the Srebrenica massacre when over 8,000 Bosniaks were killed, and described him as being burdened with a reputation for accepting Bosnian Serb claims of good behavior at face value and overlooking evidence of atrocities against civilians. 
Following the early release of convicted war criminal Biljana Plavšić from Swedish prison in 2009, Bildt was reported to Sweden's Committee on the Constitution for being disqualified to take part in such a decision. Bildt was accused of being personally involved in the case and being personally close to Plavšić. Bildt testified at Plavšićs trial in 2002 at the Hague praising her, calling her post-war actions "brave" and "courageous".
Middle East.
Bildt has been questioned for his role as a member of the International Advisory Council of the Committee for the Liberation of Iraq, a group with ties to the Bush administration pushing for an invasion of Iraq in 2003.
On 8 April 2008, during his visit in Israel and Palestinian Authority, Bildt gave an interview to Swedish state radio, where he responded to a question on whether it would be possible to strike a peace deal without the involvement of the Palestinian group Hamas, which remained under international boycott. He responded that the Palestinian Fatah-backed government could deal with Israel, in the same way that it was possible for the Israeli government to make peace with Fatah over the objections of the former Israeli prime minister Benjamin Netanyahu, who, similarly to Hamas opposed a two-state deal. Israeli officials issued very strongly worded condemnations of this, describing it as "horrible and stupid" and an example of "chutzpah" and "complete ignorance of the Middle East", on the grounds that they saw it as comparing Hamas and Netanyahu as equals.
South Ossetian conflict.
After the 2008 South Ossetia war, Bildt wrote on his blog that the Russian rationale for its intervention, concern for the welfare of its expatriates in the Near Abroad, had similarities with the rationale for the annexation of Sudetenland. The Russian reaction was strong, and the Russian Foreign Ministry announced that Bildt was no longer considered welcome in Moscow. Bildt called South Ossetian independence "a joke", and said it would be supported only by a "miserable" lot of countries.
He became considered unwelcome in Russia after comparing its handling of the 2008 South Ossetia War to Nazi Germany under Hitler, and was prevented from visiting Sri Lanka.
WikiLeaks.
Bildt was described in leaked United States documents as thinking he has more power and influence than he really has and was called a "medium size dog with big dog attitude". The US president George W. Bush was advised before a meeting to "play on Bildt's desire to operate at a high level" and to pretend to be impressed by his previous international assignments.
Crisis in Ukraine.
Bildt, together with Polish Foreign Minister Radosław Sikorski, is one of the main architects of the Eastern policy of the EU.
During the 2014 unrest in Ukraine, Carl Bildt has been criticized in Swedish media for ignoring and downplaying the issues with fascism and right-wing extremism in the Ukrainian Svoboda party. Johan Croneman at Dagens Nyheter has also condemned Bildt for pushing Prime Minister Fredrik Reinfeldt to rephrase himself after having expressed understanding of the Russians' concerns about the situation.
In a public message on Twitter, Bildt compared Viktor Yanukovych to Vidkun Quisling, writing that he was "sitting on foreign soil begging a foreign army to give his country to him". This has been described as "undiplomatic" by Christer Jönsson, professor in Political Science at the Lund University. Norwegian politician Anniken Huitfeldt also criticized Bildt's statement, saying that it showed "ignorance of history" and that it "does not contribute to solving the conflict". Torsten Kälvemark from Aftonbladet has criticized Bildt's statement as well. "Our Foreign Minister is ignorant, because it was actually Norway's legal head of state, Haakon VII, that during the war sat on foreign soil and hoped that he would with help from the British get back his country", he remarked.
Stefan Hedlund, professor at Uppsala University, stated that "Carl Bildt's threatening rhetoric should in this context be regarded as extremely destructive", in an article about the Ukrainian crisis. Hedlund also suggested that Bildt should take a "time-out", and that progress can only be made through dialogue with Russia.
In a radio interview with channel SR P1 on March 15, Bildt stated that he considers the Crimean referendum illegal, and "invalid, no matter which way people vote". He continued his refusal to answer questions about Svoboda, saying that he "won't describe what that party is". His overall comment on the new regime in Kiev was that it's a "reasonable and democratic government" and that he does not want to "play along with Russian propaganda".
Mikael Nyberg, author and journalist for Aftonbladet, has criticized Bildt for describing the Russian annexation of Crimea as "the law of the jungle", when Sweden at the same time provides navigational support for U.S. drone warfare in Pakistan, something which Nyberg argues has been done with low respect for international laws and civilian collateral damage.
In early 2015, a study made at the Swedish Defence Research Agency stated that Bildt had been a target of information warfare and that he was "regularly smeared in Russian state-controlled media". The reason was described to be Bildt's involvement in the Eastern Partnership program and that the project was perceived as a threat by the Russian government.
Reaction to Edward Snowden's Right Livelihood Award.
About a week after it became known that Edward Snowden was going to be one of the recipients of the 2014 Right Livelihood Award, Carl Bildt made sure that the organization was banned from the Swedish Ministry for Foreign Affairs, according to the public news broadcaster Sveriges Television which had been in touch with numerous involved people that didn't want to comment on the affair in public. Bildt later rejected the claims, stating that a re-categorization of the security level for the press room was the real reason. Because of this, the 2014 announcement ceremony became the first one in 18 years that was held in another location than the Ministry for Foreign Affairs.
Internet activities.
Bildt was an early pioneer among politicians of using the Internet for communicating. On 4 February 1994, he sent an email message to US president Bill Clinton, which was the first publicly known electronic message sent between two heads of government. In the message he praised Clinton's decision to end the trade embargo on Vietnam. In the same year, he also started a weekly electronic newsletter which was active until 2005. He is an active blogger, starting his first blog in February 2005. His current blog, started in January 2007, is one of the most widely read political blogs in Sweden.
On 30 May 2007, he officially opened a "Swedish embassy" in the virtual world "Second Life". The embassy, called "Second House of Sweden", is a virtual replica of House of Sweden, the Swedish embassy building in Washington, D.C.. During Bildt's time as Foreign Minister, the Ministry of Foreign Affairs has opened a channel on YouTube which has been active since early 2008. Bildt maintains a personal Twitter feed in English with approximately 250,000 subscribed followers. As of 2014, Bildt has served as Chair of the Global Commission on Internet Governance.

</doc>
<doc id="52549" url="http://en.wikipedia.org/wiki?curid=52549" title="Star Wars (film)">
Star Wars (film)

Star Wars (later retitled Star Wars Episode IV: A New Hope) is a 1977 American epic space opera film written and directed by George Lucas. The first release in the "Star Wars" saga, the film stars Mark Hamill, Harrison Ford, Carrie Fisher, Peter Cushing, and Alec Guinness.
The plot focuses on the Rebel Alliance, led by Princess Leia (Fisher), and its attempt to destroy the Galactic Empire's space station, the Death Star. This conflict disrupts the isolated life of ambitious farmhand Luke Skywalker (Hamill) when he inadvertently acquires a pair of droids that possess stolen architectural plans for the Death Star. After the Empire begins a destructive search for the missing droids, Skywalker agrees to accompany Jedi Master Obi-Wan Kenobi (Guinness) on a mission to return the Death Star plans to the Rebel Alliance and save the galaxy from the tyranny of the Galactic Empire.
Lucas began writing the script to "Star Wars" after completing "American Graffiti". He based the plot outline on the 1936 "Flash Gordon" serials and the 1958 Akira Kurosawa film "The Hidden Fortress". After United Artists and Universal Pictures rejected Lucas' script, Alan Ladd, Jr. of 20th Century Fox accepted it and agreed to finance and distribute the film. Shot mostly in Tunisia, England, and Guatemala, the film was met with numerous problems during production, including bad weather conditions, malfunctioning equipment, and financial difficulties. The script underwent numerous changes, and Lucas founded Industrial Light & Magic specifically to create the groundbreaking visual effects needed for the film.
"Star Wars" was released theatrically in the United States on May 25, 1977. It earned $461 million in the United States and $314 million overseas, totaling $775 million. It surpassed "Jaws" (1975) to become the highest-grossing film until "E.T. the Extra-Terrestrial" in 1983. When adjusted for inflation as of 2013, "Star Wars" was the second-highest-grossing film in the United States and Canada, and the third-highest-grossing film in the world. It received 10 Academy Award nominations (including Best Picture), winning six; it is often regarded as one of the best films of all time. It was selected to become part of the United States National Film Registry by the Library of Congress in its first year of opening as being "culturally, historically, or aesthetically significant"; at the time, it was the newest film to be selected, and it was the only film from the 1970s to be chosen. The film's soundtrack was added to the United States National Recording Registry 15 years later.
Lucas has re-released "Star Wars" a number of times, incorporating many changes including modified computer-generated effects, altered dialogue, re-edited shots, remixed soundtracks, and added scenes. The film's massive success led to the production of two sequels: "The Empire Strikes Back" (1980) and "Return of the Jedi" (1983), both of which became critically and commercially successful. A prequel trilogy was later released between 1999 and 2005; all three films were again commercially successful, but did not match the level of critical and fanatical acclaim of the original trilogy. In early 2014, a sequel trilogy began production with a majority of the cast members from the original trilogy returning for the seventh installment, "", which is scheduled for release in 2015.
Plot.
The galaxy is in a civil war, and spies for the Rebel Alliance have stolen plans to the Galactic Empire's Death Star, a heavily armed and armored space station capable of destroying an entire planet. Rebel leader Princess Leia is in possession of the plans, but her ship is captured by Imperial forces under the command of the evil Lord Darth Vader. Before she is captured, Leia hides the plans in the memory of an astromech droid called R2-D2, along with a holographic recording. The droid, accompanied by fellow protocol droid C-3PO, escape from the captured ship to the desert planet Tatooine.
The droids are captured by Jawa traders, who sell the pair to moisture farmers Owen and Beru Lars and their nephew, Luke Skywalker. While cleaning R2-D2, Luke accidentally triggers part of Leia's message, in which she requests help from Obi-Wan Kenobi. After wondering if she is referring to Ben Kenobi, a hermit living nearby, Luke retires for the evening. The next morning, Luke finds R2-D2 searching for Obi-Wan, and meets Ben, who reveals himself to be Obi-Wan. Obi-Wan tells Luke of his days as a Jedi Knight, who were a faction of former galactic peacekeepers with supernatural powers derived from an energy field called the Force, and who were conquered by the Empire. Contrary to his uncle's assertions, Luke learns that his father fought alongside Obi-Wan as a Jedi Knight before he was betrayed and killed by Vader, Obi-Wan's former pupil who turned to the dark side of the Force. Obi-Wan then offers Luke his father's lightsaber.
Obi-Wan views Leia's complete message in which she begs him to take the Death Star plans to her home planet of Alderaan and give them to her father for analysis. Obi-Wan invites Luke to accompany him to Alderaan and become a student of the Force. Luke initially declines, but changes his mind after discovering that Imperial stormtroopers searching for C-3PO and R2-D2 have destroyed his home and killed his aunt and uncle. Obi-Wan and Luke visit the Mos Eisley Cantina, and hire smuggler Han Solo and his Wookiee first mate Chewbacca to transport them to Alderaan on their ship, the "Millennium Falcon".
Arriving at their destination, they find only debris; Alderaan has been destroyed by order of the Death Star's commanding officer, Grand Moff Tarkin, as a demonstration of the Death Star's power. The "Falcon" is captured by the Death Star's tractor beam and brought into its hangar bay. While Obi-Wan attempts to disable the tractor beam, Luke discovers that Leia is imprisoned aboard. With the help of Han and Chewbacca, he rescues her. After several harrowing escapes, the group makes its way back to the "Falcon". Obi-Wan engages in a lightsaber duel with Darth Vader and is killed. The "Falcon" escapes the Death Star, but carries a homing device that enables Tarkin and Vader to track it to the rebels' hidden base on Yavin 4.
The rebels' analysis of the Death Star plans reveals a vulnerable exhaust port that connects to the station's main reactor; they plan a mission to attack it. Luke joins the rebel assault squadron while Han collects his payment for the transport and intends to leave despite Luke's request that he stay and help. In the subsequent battle, the rebels suffer heavy losses after several unsuccessful attack runs, leaving Luke one of the few surviving pilots. Vader leads a squad of TIE fighters and prepares to attack Luke's X-wing ship, but Han returns and fires on the Imperials, sending Vader spiraling away. Helped by spiritual advice from Obi-Wan instructing him to use the Force, Luke successfully destroys the Death Star, killing Tarkin seconds before he can fire on the rebel base. Leia later awards Luke and Han medals for their heroism.
Cast.
Other characters include: Owen and Beru, Luke's uncle and aunt, were portrayed by Phil Brown and Shelagh Fraser, respectively; Jack Purvis, Kenny Baker's partner in his London comedy act, portrayed the Chief Jawa in the film; Eddie Byrne performed the role of General Vanden Willard, a general during the Galactic Civil War; actors Denis Lawson and Garrick Hagon were cast as rebel pilots Wedge Antilles and Biggs Darklighter (also Luke's childhood friend), respectively; and Don Henderson and Leslie Schofield play Imperial Generals Cassio Tagge and Moradmin Bast, respectively.
Production.
Development.
Elements of the history of "Star Wars" are commonly disputed, as George Lucas's statements about it have changed over time. Lucas has said that it was early as 1971—after he completed directing his first full-length feature, "THX 1138"—that he first had an idea for a space fantasy film, though he has also claimed to have had the idea long before then. Originally, Lucas wanted to adapt the "Flash Gordon" space adventure comics and serials into his own films, having been fascinated by it since he was young. In 1979, he said, "I especially loved the "Flash Gordon" serials... Of course I realize now how crude and badly done they were... loving them that much when they were so awful, I began to wonder what would happen if they were done really well."
At the Cannes Film Festival in May following the completion of "THX 1138", Lucas was granted a two-film development deal with United Artists; the two films were "American Graffiti", and an untitled "Flash Gordon"-esque space fantasy film. He pushed towards buying the "Flash Gordon" rights. He said:
I wanted to make a "Flash Gordon" movie, with all the trimmings, but I couldn't obtain the rights to the characters. So I began researching and went right back and found where Alex Raymond (who had done the original "Flash Gordon" comic strips in newspapers) had got his idea from. I discovered that he'd got his inspiration from the works of Edgar Rice Burroughs (author of "Tarzan") and especially from his "John Carter of Mars" series books. I read through that series, then found that what had sparked Burroughs off was a science-fantasy called "", written by Edwin Arnold and published in 1905. That was the first story in this genre that I have been able to trace. Jules Verne had got pretty close, I suppose, but he never had a hero battling against space creatures or having adventures on another planet. A whole new genre developed from that idea.
Director Francis Ford Coppola, who accompanied Lucas in buying the "Flash Gordon" rights, recounted in 1999, "[George] was very depressed because he had just come back and they wouldn't sell him "Flash Gordon". And he says, 'Well, I'll just invent my own.'" Lucas envisioned his own space opera and called it "The Star Wars". After his failed attempt to gain the rights, Lucas went to United Artists and showed the script for "American Graffiti", but they passed on the film, which was then picked up by Universal Pictures. United Artists also passed on Lucas's "The Star Wars" concept, which he shelved for the time being. After spending the next two years completing "American Graffiti", Lucas turned his attention to "The Star Wars".
Lucas began writing in January 1973, "eight hours a day, five days a week", by taking small notes, inventing odd names and assigning them possible characterizations. Lucas would discard many of these by the time the final script was written, but he included several names and places in the final script or its sequels. He revived others decades later when he wrote his prequel trilogy. He used these initial names and ideas to compile a two-page synopsis titled "Journal of the Whills", which told the tale of the training of apprentice CJ Thorpe as a "Jedi-Bendu" space commando by the legendary Mace Windu. Frustrated that his story was too difficult to understand, Lucas then began writing a 13-page treatment called "The Star Wars" on April 17, 1973, which had thematic parallels with Akira Kurosawa's 1958 film "The Hidden Fortress".
After United Artists declined to budget the film, Lucas and producer Gary Kurtz presented the film treatment to Universal Pictures, the studio that financed "American Graffiti"; however, it rejected its options for the film because the concept was "a little strange", and it said that Lucas should follow "American Graffiti" with more consequential themes. Lucas said, "I've always been an outsider to Hollywood types. They think I do weirdo films." According to Kurtz, Lew Wasserman, the studio's head, "just didn't think much of science fiction at that time, didn't think it had much of a future then, with that particular audience." He said that "science fiction wasn't popular in the mid-'70s ... what seems to be the case generally is that the studio executives are looking for what was popular last year, rather than trying to look forward to what might be popular next year." Lucas explained in 1977 that the film is not "about the future" and that it "is a fantasy much closer to the Brothers Grimm than it is to ". He added: "My main reason for making it was to give young people an honest, wholesome fantasy life, the kind my generation had. We had westerns, pirate movies, all kinds of great things. Now they have "The Six Million Dollar Man" and "Kojak". Where are the romance, the adventure, and the fun that used to be in practically every movie made?" Kurtz said, "Although "Star Wars" wasn't like that at all, it was just sort of lumped into that same kind of [science fiction] category."
There were also concerns regarding the project's potentially high budget. Lucas and Kurtz, in pitching the film, said that it would be "low-budget, Roger Corman style, and the budget was never going to be more than—well, originally we had proposed about 8 million, it ended up being about 10. Both of those figures are very low budget by Hollywood standards at the time." After Walt Disney Productions rejected the project, Lucas and Kurtz persisted in securing a studio to support the film because "other people had read it and said, 'Yeah, it could be a good idea...'" Lucas pursued Alan Ladd, Jr., the head of 20th Century Fox, and in June 1973 completed a deal to write and direct the film. Although Ladd did not grasp the technical side of the project, he believed that Lucas was talented. Lucas later stated that Ladd "invested in me, he did not invest in the movie." The deal gave Lucas $150,000 to write and direct the film.
Writing.
"It's the flotsam and jetsam from the period when I was twelve years old. All the books and films and comics that I liked when I was a child. The plot is simple—good against evil—and the film is designed to be all the fun things and fantasy things I remember. The word for this movie is fun."
—George Lucas
Since commencing his writing process in January 1973, Lucas had done "various rewrites in the evenings after the day's work." He would write four different screenplays for "Star Wars", "searching for just the right ingredients, characters and storyline. It's always been what you might call a good idea in search of a story." By May 1974, he had expanded the film treatment into a rough draft screenplay, adding elements such as the Sith, the Death Star, and a protagonist named Annikin Starkiller. He changed the protagonist, who had been a mature general in the treatment, to an adolescent boy, and he shifted the general into a supporting role as a member of a family of dwarfs. Lucas envisioned the Corellian smuggler, Han Solo, as a large, green-skinned monster with gills. He based Chewbacca on his Alaskan Malamute dog, Indiana (whom he would later use as namesake for his character Indiana Jones), who often acted as the director's "co-pilot" by sitting in the passenger seat of his car.
Lucas began researching the science fiction genre by watching films and reading books and comics. His first script incorporated ideas from many new sources. The script would also introduce the concept of a Jedi Master father and his son, who trains to be a Jedi under his father's friend; this would ultimately form the basis for the film and, later, the trilogy. However, in this draft, the father is a hero who is still alive at the start of the film.
Lucas completed a second draft of "The Star Wars" in January 1975, making heavy simplifications and introducing the young hero on a farm as Luke Starkiller. Annikin became Luke's father, a wise Jedi knight. "The Force" was also introduced as a mystical energy field. This second draft still had some differences from the final version in the characters and relationships. For example, the protagonist Luke had several brothers, as well as his father, who appears in a minor role at the end of the film. The script became more of a fairy tale quest as opposed to the action-adventure of the previous versions. This version ended with another text crawl, previewing the next story in the series. This draft was also the first to introduce the concept of a Jedi turning to the dark side: the draft included a historical Jedi who became the first to ever fall to the dark side, and then trained the Sith to use it. Impressed with his works, Lucas hired conceptual artist Ralph McQuarrie to create paintings of certain scenes around this time. When Lucas delivered his screenplay to the studio, he included several of McQuarrie's paintings.
A third draft, dated August 1, 1975, was titled "The Star Wars: From the Adventures of Luke Starkiller". This third draft had most of the elements of the final plot, with only some differences in the characters and settings. The draft characterized Luke as an only child, with his father already dead, replacing him with a substitute named Ben Kenobi. This script would be re-written for the fourth and final draft, dated January 1, 1976, as "The Adventures of Luke Starkiller as taken from the Journal of the Whills, Saga I: The Star Wars". Lucas worked with his friends Gloria Katz and Willard Huyck to revise the fourth draft into the final pre-production script. 20th Century Fox approved a budget of $8.25 million; "American Graffiti"‍ '​s positive reception afforded Lucas the leverage necessary to renegotiate his deal with Alan Ladd, Jr. and request the sequel rights to the film. For Lucas, this deal protected "Star Wars"‍ '​ unwritten segments and most of the merchandising profits.
Lucas finished writing his script in March 1976, when the crew started filming. He said, "What finally emerged through the many drafts of the script has obviously been influenced by science-fiction and action-adventure I've read and seen. And I've seen a lot of it. I'm trying to make a classic sort of genre picture, a classic space fantasy in which all the influences are working together. There are certain traditional aspects of the genre I wanted to keep and help perpetuate in "Star Wars"." During production, he changed Luke's name from Starkiller to Skywalker and altered the title to "The Star Wars" and later "Star Wars". He would also continue to tweak the script during filming, including adding the death of Obi-Wan after realizing he served no purpose in the ending of the film.
For the film's opening crawl, Lucas originally wrote a composition consisting of six paragraphs with four sentences each. He said, "The crawl is such a hard thing because you have to be careful that you're not using too many words that people don't understand. It's like a poem." Lucas showed his draft to his friends. Director Brian De Palma, who was there, described it: "The crawl at the beginning looks like it was written on a driveway. It goes on forever. It's gibberish." Lucas recounted what De Palma said the first time he saw it: "George, you're out of your mind! Let me sit down and write this for you." De Palma helped to edit the text into the form used in the film.
Design.
George Lucas recruited many conceptual designers, including: Colin Cantwell, who worked on "" (1968), to conceptualize the initial spacecraft models; Alex Tavoularis to create the preliminary conceptual storyboard sketches of early scripts; and Ralph McQuarrie to visualize the characters, costumes, props and scenery. McQuarrie's pre-production paintings of certain scenes from Lucas's early screenplay drafts helped 20th Century Fox visualize the film, which positively influenced their decision to fund the project. After McQuarrie's drawings for Lucas's colleagues Hal Barwood and Matthew Robbins (who were collaborating for a film) caught his interest, Lucas met with McQuarrie to discuss his plans for the then-untitled space fantasy film he wanted to make. Two years later, after completing "American Graffiti", Lucas approached McQuarrie and asked him if he would be interested "in doing something for "Star Wars"." McQuarrie produced a series of artworks from simple sketches; these set a visual tone for the film, and for the rest of the original trilogy.
""Star Wars" has no points of reference to Earth time or space, with which we are familiar, and it is not about the future but some galactic past or some extra-temporal present, it is a decidedly inhabited and used place where the hardware is taken for granted."
—Lucas on his "used future" backdrop
The film was ambitious as Lucas wanted to create fresh prop prototypes and sets (based on McQuarrie's paintings) that had never been realized before in science fiction films. He commissioned production designers John Barry and Roger Christian, who were working on the sets of the film "Lucky Lady" (1975) when Lucas first approached them, to work on the production sets. Christian recounted in 2014: "George came to the set I was doing, it was an old salt factory design and he helped me shovel salt, just like two students in plaid shirts and sneakers. And we spoke and he looked at the set and couldn't believe it wasn't real." They had a conversation with Lucas on what he would like the film to appear like, with them creating the desired sets. Christian said that Lucas "didn't want anything [in "Star Wars"] to stand out, he wanted it [to look] all real and used. And I said, 'Finally somebody's doing it the right way.'"
Lucas described a "used future" concept to the production designers in which all devices, ships, and buildings looked aged and dirty. Instead of following the traditional sleekness and futuristic architecture of science fiction films that came before, the "Star Wars" sets were designed to look inhabited and used. Barry said that the director "wants to make it look like its shot on location on your average everyday Death Star or Mos Eisly Spaceport or local cantina." Lucas believed that "what is required for true credibility is a used future", opposing the interpretation of "future in most futurist movies" that "always looks new and clean and shiny." Christian supported Lucas's vision, saying "All science fiction before was very plastic and stupid uniforms and "Flash Gordon" stuff. Nothing was new. George was going right against that."
The designers started working with the director before "Star Wars" was approved by 20th Century Fox. For four to five months, in a studio in Kensal Rise, England, they attempted to plan the creation of the props and sets with "no money". Although Lucas initially provided funds using his earnings from "American Graffiti", it was inadequate. As they could not afford to dress the sets, Christian was forced to use unconventional methods and materials to achieve the desired look. He suggested that Lucas use scrap in making the dressings, and the director agreed. Christian said, "I've always had this idea. I used to do it with models when I was a kid. I'd stick things on them and we'd make things look old." Barry, Christian, and their team began designing the props and sets at Elstree Studios.
According to Christian, the "Millennium Falcon" set was the most difficult to build. Christian wanted the interior of the "Falcon" to look like that of a submarine. He found scrap airplane metal "that no one wanted in those days and bought them". He began his creation process by breaking down jet engines into scrap pieces, giving him the chance to "stick it in the sets in specific ways". It took him several weeks to finish the chess set (which he described as "the most encrusted set") in the hold of the "Falcon". The garbage compactor set "was also pretty hard, because I knew I had actors in there and the walls had to come in, and they had to be in dirty water and I had to get stuff that would be light enough so it wouldn't hurt them but also not bobbing around". A total of 30 sets consisting of planets, starships, caves, control rooms, cantinas, and the Death Star corridors were created; all of the nine sound stages at Elstree were used to accommodate them. The massive rebel hangar set was housed at a second sound stage at Shepperton Studios; the stage is the largest in Europe.
Filming.
In 1975, Lucas formed his own visual effects company Industrial Light & Magic (ILM) after discovering that 20th Century Fox's visual effects department had been disbanded. ILM began its work on "Star Wars" in a warehouse in Van Nuys, California. Most of the visual effects used pioneering digital motion control photography developed by John Dykstra and his team, which created the illusion of size by employing small models and slowly moving cameras.
George Lucas tried "to get a cohesive reality" for his feature. However, since the film is a fairy tale, as he had described, "I still wanted it to have an ethereal quality, yet be well composed and, also, have an alien look." He designed the film to have an "extremely bizarre, Gregg Toland-like surreal look with strange over-exposed colors, a lot of shadows, a lot of hot areas." Lucas wanted "Star Wars" to embrace the combination of "strange graphics of fantasy" and "the feel of a documentary" to impress a distinct look. To achieve this, he hired the British cinematographer Gilbert Taylor. Originally, Lucas's first choice for the position was Geoffrey Unsworth, who also provided the cinematography for Stanley Kubrick's "2001: A Space Odyssey". Unsworth was interested in working with the director, and initially accepted the job when it was offered to him by Lucas and Kurtz. However, he eventually withdrew to work on the Vincente Minnelli-directed "A Matter of Time" (1976) instead, which "really annoy[ed]" Kurtz. Lucas called up for other cinematographers, and eventually chose Taylor, basing his choice on Taylor's cinematography for "Dr. Strangelove" and "A Hard Day's Night" (1964). On his decision, Lucas said: "I thought they were good, eccentrically photographed pictures with a strong documentary flavor."
Taylor said that Lucas, who was consumed by the details of the complicated production, "avoided all meetings and contact with me from day one, so I read the extra-long script many times and made my own decisions as to how I would shoot the picture." He also "took it upon myself to experiment with photographing the lightsabers and other things onstage before we moved on to our two weeks of location work in Tunisia." During production, Lucas and Taylor—whom Kurtz called "old-school" and "crotchety"—had disputes over filming. With a background in independent filmmaking, Lucas was accustomed to creating most of the elements of the film himself. His lighting suggestions were rejected by an offended Taylor, who felt that Lucas was overstepping his boundaries by giving specific instructions, sometimes even moving lights and cameras himself. Taylor refused to use the soft-focus lenses and gauze Lucas wanted after Fox executives complained about the look. Kurtz stated that "In a couple of scenes [...] rather than saying, 'It looks a bit over lit, can you fix that?', [Lucas would] say, 'turn off this light, and turn off that light.' And Gil would say, 'No, I won't do that, I've lit it the way I think it should be—tell me what's the effect that you want, and I'll make a judgment about what to do with my lights.'"
Originally, Lucas envisioned the planet of Tatooine, where much of the film would take place, as a jungle planet. Gary Kurtz traveled to the Philippines to scout locations; however, because of the idea of spending months filming in the jungle would make Lucas "itchy", the director refined his vision and made Tatooine a desert planet instead. Kurtz then researched all American, North African, and Middle Eastern deserts, and found Tunisia, near the Sahara desert, as the ideal location.
When principal photography began on March 22, 1976 in the Tunisian desert for the scenes on Tatooine, the project faced several problems. Lucas fell behind schedule in the first week of shooting due to malfunctioning props and electronic breakdowns. Moreover, a rare Tunisian rainstorm struck the country, which further disrupted filming. Taylor said, "you couldn't really see where the land ended and the sky began. It was all a gray mess, and the robots were just a blur." Given this situation, Lucas requested for heavy filtration, which confused Taylor, who said: "I thought the look of the film should be absolutely clean ... But George saw it differently, so we tried using nets and other diffusion. He asked to set up one shot on the robots with a 300mm, and the sand and sky just mushed together. I told him it wouldn't work, but he said that was the way he wanted to do the entire film, all diffused." This difference was later settled by 20th Century Fox executives, who backed Taylor's suggestion.
Filming began in Chott el Djerid, while a construction crew in Tozeur took eight weeks to transform the desert into the desired setting. Other locations included the sand dunes of the Tunisian desert near Nafta, where a scene featuring a giant skeleton of a creature lying in the background as R2-D2 and C-3PO make their way across the sands was filmed. When actor Anthony Daniels wore the C-3PO outfit for the first time in Tunisia, the left leg piece shattered down through the plastic covering his left foot, stabbing him. He also could not see through his costume's eyes, which was covered with gold to prevent corrosion. Abnormal radio signals caused by the Tunisian sands made the radio-controlled R2-D2 models run out of control. Kenny Baker, who portrayed R2-D2, said: "I was incredibly grateful each time an [R2] would actually work right." After several scenes were filmed against the volcanic canyons outside Tozeur, production moved to Matmata to film Luke's home on Tatooine. Lucas chose Hotel Sidi Driss, which is larger than the typical underground dwellings, to shoot the interior of Luke's homestead. Additional scenes for Tatooine were filmed at Death Valley in North America.
After completing two and a half weeks of filming in Tunisia, the cast and crew moved into the more controlled environment of Elstree Studios, near London. Difficulties encountered in Tunisia were assumed to cease; however, due to strict British working conditions adhered to on set, a new problem arose: filming had to finish by 5:30 pm, unless Lucas was in the middle of a scene. The interiors were shot in London due to its proximity to North Africa and because of the availability of top technical crew at Elstree Studios. The film studio was the only one of its kind in England or America that could cater nine large stages at the same time and allow the company complete freedom to use its own personnel. Despite Lucas' efforts, his crew had little interest in the film and did not take the project seriously. Most of the crew considered the project a "children's film", rarely took their work seriously, and often found it unintentionally humorous. Actor Baker later confessed that he thought the film would be a failure. Harrison Ford found strange that "there's a princess with weird buns in her hair", and he called Chewbacca a "giant in a monkey suit".
Filming at Elstree Studios became another problem for Taylor; the sets John Barry made "were like a coal mine", as the cinematographer described. He said that "they were all black and gray, with really no opportunities for lighting at all." To resolve the problem, he worked the lighting into the sets by chopping in its walls, ceiling and floors. This would result in "a 'cut-out' system of panel lighting", with quartz lamps that could be placed in the holes in the walls, ceiling and floors. His idea was supported by the Fox studio, which agreed that "we couldn't have this 'black hole of Calcutta'". The lighting approach Taylor devised "allowed George to shoot in almost any direction without extensive relighting, which gave him more freedom." In total, filming the scenes in England took 14 and a half weeks.
The moon Yavin 4, which acted as the rebel base in the film, was filmed in the Mayan temples at Tikal, Guatemala. Lucas selected the location as a potential filming site after seeing a poster of it hanging at a travel agency while he was filming in England. This inspired him to send a film crew to Guatemala in March 1977 to shoot scenes. While filming in Tikal, the crew paid locals with a six pack of beer to watch over the camera equipment for several days.
Lucas rarely spoke to the actors, who felt that he expected too much of them while providing little direction. His directions to the actors usually consisted of the words "faster" and "more intense". Kurtz stated that "it happened a lot where he would just say, 'Let's try it again a little bit faster.' That was about the only instruction he'd give anybody. A lot of actors don't mind—they don't care, they just get on with it. But some actors really need a lot of pampering and a lot of feedback, and if they don't get it, they get paranoid that they might not be doing a good job." Kurtz has said that Lucas "wasn't gregarious, he's very much a loner and very shy, so he didn't like large groups of people, he didn't like working with a large crew, he didn't like working with a lot of actors."
Ladd offered Lucas some of the only support from the studio; he dealt with scrutiny from board members over the rising budget and complex screenplay drafts. Initially, Fox approved $8 million for the project; Gary Kurtz said: "we proceeded to pick a production plan and do a more final budget with a British art department and look for locations in North Africa, and kind of pulled together some things. Then, it was obvious that 8 million wasn't going to do it—they had approved 8 million." After requests from the team that "it had to be more", the executives "got a bit scared". For two weeks, Lucas and his crew "didn't really do anything except kind of pull together new budget figures". At the same time, after production fell behind schedule, Ladd told Lucas he had to finish production within a week or he would be forced to shut down production. Kurtz said that "it came out to be like 9.8 or .9 or something like that, and in the end they just said, 'Yes, that's okay, we'll go ahead.'" The crew split into three units, with those units led by Lucas, Kurtz, and production supervisor Robert Watts. Under the new system, the project met the studio's deadline.
During production, the cast attempted to make Lucas laugh or smile, as he often appeared depressed. At one point, the project became so demanding that Lucas was diagnosed with hypertension and exhaustion and was warned to reduce his stress level. Post-production was equally stressful due to increasing pressure from 20th Century Fox. Moreover, Mark Hamill's car accident left his face visibly scarred, which restricted re-shoots.
Post-production.
"Star Wars" was originally slated for release on Christmas 1976; however, its production delays pushed the film's release to summer 1977. Already anxious about meeting his deadline, Lucas was shocked when editor John Jympson's first cut of the film was a "complete disaster". According to an article in "Star Wars Insider" No. 41 by David West Reynolds, this first edit of "Star Wars" contained about 30–40% different footage from the final version. After attempting to persuade Jympson to cut the film his way, Lucas replaced him with Paul Hirsch and Richard Chew. He also allowed his then-wife, Marcia Lucas, to aid the editing process while she was cutting the film "New York, New York" (1977) with Lucas's friend Martin Scorsese. Richard Chew found the film to have a lethargic pace and to have been cut in a by-the-book manner: scenes were played out in master shots that flowed into close-up coverage. He found that the pace was dictated by the actors instead of the cuts. Hirsch and Chew worked on two reels simultaneously.
Jympson's original assembly contained a large amount of footage which differed from the final cut of the film, including several alternate takes and a number of scenes which were subsequently deleted to improve the narrative pace. The most significant material cut was a series of scenes from the first part of the film which served to introduce the character of Luke Skywalker. These early scenes, set in Anchorhead on the planet Tatooine, presented the audience with Luke's everyday life among his friends as it is affected by the space battle above the planet; they also introduced the character of Biggs Darklighter, Luke's closest friend who departs to join the Rebellion. Chew explained the rationale behind removing these scenes as a narrative decision: "In the first five minutes, we were hitting everybody with more information than they could handle. There were too many story lines to keep straight: the robots and the Princess, Vader, Luke. So we simplified it by taking out Luke and Biggs". After viewing a rough cut, Alan Ladd likened these Anchorhead scenes to ""American Graffiti" in outer space", referring to Lucas's 1973 coming of age film. Lucas was looking for a way of accelerating the storytelling, and removing Luke's early scenes would distinguish "Star Wars" from his earlier teenage drama and "get that "American Graffiti" feel out of it". Lucas also stated that he wanted to move the narrative focus to C-3PO and R2-D2: "At the time, to have the first half-hour of the film be mainly about robots was a bold idea."
Meanwhile, Industrial Light & Magic was struggling to achieve unprecedented special effects. The company had spent half of its budget on four shots that Lucas deemed unacceptable. Moreover, theories surfaced that the workers at ILM lacked discipline, forcing Lucas to intervene frequently to ensure that they were on schedule. With hundreds of uncompleted shots remaining, ILM was forced to finish a year's work in six months. Lucas inspired ILM by editing together aerial dogfights from old war films, which enhanced the pacing of the scenes.
During the chaos of production and post-production, the team made decisions about character voicing and sound effects. Sound designer Ben Burtt had created a library of sounds that Lucas referred to as an "organic soundtrack". Blaster sounds were a modified recording of a steel cable, under tension, being struck. The lightsaber sound effect was developed by Burtt as a combination of the hum of idling interlock motors in aged movie projectors and interference caused by a television set on a shieldless microphone. Burtt discovered the latter accidentally as he was looking for a buzzing, sparking sound to add to the projector-motor hum. For Chewbacca's growls, Burtt recorded and combined sounds made by dogs, bears, lions, tigers, and walruses to create phrases and sentences. Lucas and Burtt created the robotic voice of R2-D2 by filtering their voices through an electronic synthesizer. Darth Vader's breathing was achieved by Burtt breathing through the mask of a scuba regulator implanted with a microphone.
In February 1977, Lucas screened an early cut of the film for Fox executives, several director friends, along with Roy Thomas and Howard Chaykin of Marvel Comics who were preparing a "Star Wars" comic book. The cut had a different crawl from the finished version and used Prowse's voice for Darth Vader. It also lacked most special effects; hand-drawn arrows took the place of blaster beams, and when the "Millennium Falcon" fought TIE fighters, the film cut to footage of World War II dogfights. The reactions of the directors present, such as Brian De Palma, John Milius, and Steven Spielberg, disappointed Lucas. Spielberg, who claimed to have been the only person in the audience to have enjoyed the film, believed that the lack of enthusiasm was due to the absence of finished special effects. Lucas later said that the group was honest and seemed bemused by the film. In contrast, Ladd and the other studio executives loved the film; Gareth Wigan told Lucas: "This is the greatest film I've ever seen" and cried during the screening. Lucas found the experience shocking and rewarding, having never gained any approval from studio executives before. The delays increased the budget from $8 million to $11 million.
With the project $2 million over budget, Lucas was forced to make numerous artistic compromises to complete "Star Wars". Ladd reluctantly agreed to release an extra $20,000 funding and in early 1977 second unit filming completed a number of sequences including exterior desert shots for Tatooine in Death Valley and China Lake Acres in California, and exterior Yavin jungle shots in Guatemala, along with additional studio footage to complete the Mos Eisley Cantina sequence. Lucas had planned to rework a confrontation scene between Han Solo and Jabba the Hutt in Mos Eisley Spaceport by compositing a stop-motion animated model of Jabba to replace the actor Declan Mulholland, but with time and money running out, Lucas reluctantly decided to cut the scene entirely. The sequence was later re-instated in the 1997 Special Edition with a computer-generated version of Jabba.
Soundtrack.
On the recommendation of his friend Steven Spielberg, Lucas hired composer John Williams. Williams had worked with Spielberg on the film "Jaws", for which he won an Academy Award. Lucas felt that the film would portray visually foreign worlds, but that the musical score would give the audience an emotional familiarity; he wanted a grand musical sound for "Star Wars", with leitmotifs to provide distinction. Therefore, he assembled his favorite orchestral pieces for the soundtrack, until Williams convinced him that an original score would be unique and more unified. However, a few of Williams' pieces were influenced by the tracks given to him by Lucas: the "Main Title Theme" was inspired by the theme from the 1942 film "Kings Row", scored by Erich Wolfgang Korngold; and the track "Dune Sea of Tatooine" drew from the soundtrack of "Bicycle Thieves", scored by Alessandro Cicognini.
In March 1977, Williams conducted the London Symphony Orchestra to record the "Star Wars" soundtrack in 12 days. The original soundtrack was released as a double LP in 1977 by 20th Century Records. 20th Century Fox released "The Story of Star Wars" that same year, which adapted the film and presented it as a narrated story with music, dialogue, and sound effects from the original film. The American Film Institute's list of best film scores ranks the "Star Wars" soundtrack at number one.
Cinematic and literary allusions.
According to Lucas, different concepts of the film were inspired by numerous sources, such as Beowulf and King Arthur for the origins of myth and religion. Lucas originally intended to rely heavily on the 1930s "Flash Gordon" film serials; however, he resorted to Akira Kurosawa's film "The Hidden Fortress", and Joseph Campbell's "The Hero with a Thousand Faces", because of copyright issues with "Flash Gordon". "Star Wars" features several parallels to "Flash Gordon", such as the conflict between Rebels and Imperial Forces, the wipes between scenes, the fusion of futuristic technology and tradition magic, and the famous opening crawl that begins each film. The film has also been compared to "The Wizard of Oz".
The influence of Kurosawa's 1958 film can be seen in the relationship between C-3PO and R2-D2, which evolved from the two bickering peasants in "The Hidden Fortress", and a Japanese family crest seen in the earlier film is similar to the Imperial Crest. "Star Wars" also borrows heavily from another Kurosawa film, "Yojimbo". In both films, several men threaten the hero, bragging about how wanted they are by the authorities, and have an arm being cut off by a blade; Kuwabatake Sanjuro (portrayed by Toshiro Mifune) is offered "... twenty-five ryo now, twenty-five when you complete the mission ...", whereas Han Solo is offered "Two thousand now, plus fifteen when we reach Alderaan."
Tatooine is similar to Arrakis from Frank Herbert's "Dune" series. Arrakis is the only known source of a longevity spice called Melange. References to "spice", various illegal stimulant drugs, occur throughout the last three films of the "Star Wars" saga. In the original film, Han Solo is a spice smuggler who has been through the spice mines of Kessel. In the conversation at Obi-Wan Kenobi's home, between Obi-Wan and Luke, Luke expresses a belief that his father was a navigator on a spice freighter. Other similarities include those between Princess Leia and Princess Alia, and between Jedi mind tricks and "The Voice", a controlling ability used by Bene Gesserit. In passing, Uncle Owen and Aunt Beru are "moisture farmers"; in "Dune", dew collectors are used by Fremen to "... provide a small but reliable source of water." Frank Herbert reported that "David Lynch, [director of the 1984 film "Dune"] had trouble with the fact that "Star Wars" used up so much of "Dune"." The pair found "... sixteen points of identity ..." and they calculated that, "... the odds against coincidence produced a number larger than the number of stars in the universe."
The Death Star assault scene was modeled after the film "The Dam Busters" (1955), in which Royal Air Force Lancaster bombers fly along heavily defended reservoirs and aim bouncing bombs at dams, in order to cripple the heavy industry of the Ruhr. Some of the dialogue in "The Dam Busters" is repeated in the "Star Wars" climax; Gilbert Taylor also filmed the special effects sequences in "The Dam Busters". In addition, the sequence was partially inspired by the climax of the film "633 Squadron" (1964), directed by Walter Grauman, in which RAF de Havilland Mosquitos attack a German heavy water plant by flying down a narrow fjord to drop special bombs at a precise point, while avoiding anti-aircraft guns and German fighters. Clips from both films were included in Lucas's temporary dogfight footage version of the sequence.
The opening shot of "Star Wars", in which a detailed spaceship fills the screen overhead, is a reference to the scene introducing the interplanetary spacecraft "Discovery One" in Stanley Kubrick's seminal 1968 film "". The earlier big-budget science fiction film influenced the look of "Star Wars" in many other ways, including the use of EVA pods and hexagonal corridors. The Death Star has a docking bay reminiscent of the one on the orbiting space station in "2001". Although golden and male, C-3PO was inspired by the robot Maria, the "Maschinenmensch" from Fritz Lang's 1927 film "Metropolis".
Release.
Premiere and initial release.
Lucasfilm hired Charles Lippincott as marketing director for "Star Wars". As 20th Century Fox gave little support for marketing beyond licensing T-shirts and posters, Lippincott was forced to look elsewhere. He secured deals with Marvel Comics for a comic book adaptation, and with Del Rey Books for a novelization. A fan of science fiction, he used his contacts to promote the film at the San Diego Comic-Con and elsewhere within science fiction fandom. Worried that "Star Wars" would be beaten out by other summer films, such as "Smokey and the Bandit", 20th Century Fox moved the release date to May 25, the Wednesday before Memorial Day. However, fewer than 40 theaters ordered the film to be shown. In response, 20th Century Fox demanded that theaters order "Star Wars" if they wanted an eagerly anticipated film based on the best-selling novel "The Other Side of Midnight".
"On opening day I ... did a radio call-in show ... this caller, was really enthusiastic and talking about the movie in really deep detail. I said, 'You know a lot about the film.' He said, 'Yeah, yeah, I've seen it four times already.'"
—Producer Gary Kurtz, on when he realized "Star Wars" had become a cultural phenomenon
"Star Wars" debuted on Wednesday, May 25, 1977, in fewer than 32 theaters, and eight more on Thursday and Friday. Kurtz said in 2002, "That would be laughable today." It immediately broke box office records, effectively becoming one of the first blockbuster films, and Fox accelerated plans to broaden its release. Lucas himself was not able to predict how successful "Star Wars" would be. After visiting the set of the Steven Spielberg–directed "Close Encounters of the Third Kind", Lucas was sure "Close Encounters" would outperform the yet-to-be-released "Star Wars" at the box office. Spielberg disagreed, and felt Lucas's "Star Wars" would be the bigger hit. Lucas proposed they trade 2.5% of the profit on each other's films; Spielberg took the trade, and still receives 2.5% of the profits from "Star Wars".
Fearing that "Star Wars" would fail, Lucas had made plans to be in Hawaii with his wife Marcia. Having forgotten that the film would open that day, he spent most of Wednesday in a sound studio in Los Angeles. When Lucas went out for lunch with Marcia, they encountered a long line of people along the sidewalks leading to Mann's Chinese Theatre, waiting to see "Star Wars". He was still skeptical of the film's success despite Ladd and the studio's enthusiastic reports. While in Hawaii, it was not until he watched Walter Cronkite discuss the gigantic crowds for "Star Wars" on the "CBS Evening News" that Lucas realized he had become very wealthy (Francis Ford Coppola, who needed money to finish "Apocalypse Now", sent a telegram to Lucas's hotel asking for funding). Even technical crew members, such as model makers, were asked for autographs, and cast members became instant household names; when Ford visited a record store to buy an album, enthusiastic fans tore half his shirt off.
The film was a huge success for the studio, and was credited for reinvigorating it. Within three weeks of its release, 20th Century Fox's stock price had doubled to a record high. Prior to 1977, 20th Century Fox's greatest annual profits were $37 million, while in 1977, the company broke that record by posting a profit of $79 million. Although the film's cultural neutrality helped it to gain international success, Ladd became anxious during the premiere in Japan. After the screening, the audience was silent, leading him to fear that the film would be unsuccessful. Ladd was later told by his local contacts that, in Japan, silence was the greatest honor to a film, and the subsequent strong box office returns confirmed its popularity.
When "Star Wars" made an unprecedented second opening at Mann's Chinese Theatre on August 3, 1977, after William Friedkin's "Sorcerer" failed, thousands of people attended a ceremony in which C-3PO, R2-D2 and Darth Vader placed their footprints in the theater's forecourt. At that time "Star Wars" was playing in 1,096 theaters in the United States. Approximately 60 theaters played the film continuously for over a year; in 1978, Lucasfilm distributed "Birthday Cake" posters to those theaters for special events on May 25, the one-year anniversary of the film's release.
Later releases.
The film was originally released as "Star Wars", without "Episode IV" or the subtitle "A New Hope". The subtitles were added starting with the film's theatrical re-release on April 10, 1981. "Star Wars" was re-released theatrically in 1978; 1979; 1981; 1982; and, with additional scenes and enhanced special effects (further subtitled as the "Special Edition"), in 1997. After ILM used computer-generated effects for Steven Spielberg's 1993 film "Jurassic Park", Lucas concluded that digital technology had caught up to his original vision for "Star Wars". For the film's 20th anniversary in 1997, "Star Wars" was digitally remastered and re-released to movie theaters, along with "The Empire Strikes Back" and "Return of the Jedi", under the campaign title "Star Wars Trilogy: Special Edition".
The "Special Edition" contained visual shots and scenes that were unachievable in the original release due to financial, technological, and time constraints; one such scene involved a meeting between Han Solo and Jabba the Hutt. The process of creating the new visual effects for "Star Wars" was featured in the Academy Award-nominated IMAX documentary film, "", directed by "Star Wars" sound designer, Ben Burtt. Although most changes were minor or cosmetic in nature, some fans believe that Lucas degraded the film with the additions. A particularly controversial change in which a bounty hunter named Greedo shoots first when confronting Han Solo has inspired T-shirts brandishing the phrase "Han Shot First".
"Star Wars" required extensive restoration before Lucas's "Special Edition" modifications could be attempted. It was discovered that in addition to the negative motion picture stocks commonly used on feature films, Lucas had also used internegative film, a reversal stock which deteriorated faster than negative stocks did. This meant that the entire printing negative had to be disassembled, and the CRI (color reversal internegative) portions cleaned separately from the negative portions. Once the cleaning was complete, the film was scanned into the computer for restoration. In many cases, entire scenes had to be reconstructed from their individual elements. Fortunately, digital compositing technology allowed them to correct for problems such as alignment of mattes, "blue-spill", and so forth.
Though the original "Star Wars" was selected by the National Film Registry of the United States Library of Congress in 1989, it is unclear whether a copy of the 1977 theatrical sequence or the 1997 "Special Edition" has been archived by the NFR, or indeed if any copy has been provided by Lucasfilm and accepted by the Registry. While the agency has a mandate to register films for preservation, it has no authority to secure its selections from authors or copyright holders.
Home media.
"Star Wars" debuted on Betamax, LaserDisc, Video 2000, and VHS between the 1980s and 1990s by CBS/Fox Video. The final issue of the original theatrical release (pre-"Special Edition") to VHS format occurred in 1995, as part of "Last Chance to Own the Original" campaign, available as part of a trilogy set and as a standalone purchase. The film was released for the first time on DVD on September 21, 2004, in a box set with "The Empire Strikes Back", "Return of the Jedi", and a bonus disc of supplementary material. The films were digitally restored and remastered, and more changes were made by George Lucas. The DVD features a commentary track from Lucas, Ben Burtt, Dennis Muren, and Carrie Fisher. The bonus disc contains the documentary "Empire of Dreams: The Story of the Star Wars Trilogy", three featurettes, teasers, theatrical trailers, TV spots, still galleries, an exclusive preview of ', a playable Xbox demo of the LucasArts game ', and a "Making Of" documentary on . The set was reissued in December 2005 as part of a three-disc limited edition boxed set without the bonus disc.
The trilogy was re-released on separate two-disc limited edition DVD sets from September 12 to December 31, 2006, and again in a limited edition tin box set on November 4, 2008; the original versions of the films were added as bonus material. The release was met with criticism as the unaltered versions were from the 1993 non-anamorphic LaserDisc masters and were not re-transferred using modern video standards. The transfer led to problems with colors and digital image jarring.
All six "Star Wars" films were released by 20th Century Fox Home Entertainment on Blu-ray Disc on September 16, 2011 in three different editions, with "A New Hope" available in both a box set of the original trilogy and with the other five films on "Star Wars: The Complete Saga", which includes nine discs and over 40 hours of special features. The original theatrical versions of the films were not included in the box set; however, the new 2011 revisions of the trilogy were leaked a month prior to release, inciting controversy the new changes made to these movies and causing an online uproar against Lucas.
20th Century Fox owned full rights to the original film until they sold it to Lucas in 1998 in exchange for a lower distribution fee for the prequels and broadcast rights to "Episode I". In late 2012, The Walt Disney Company announced a deal to acquire Lucasfilm for $4.05 billion, with approximately half in cash and half in shares of Disney stock. Although Disney will now possess the ownership rights to all six "Star Wars" films, under a previous deal with Lucasfilm, the full distribution rights to "A New Hope" will remain with Fox in perpetuity, while the physical distribution arrangements for the remaining films are set to expire in 2020 (Lucasfilm had retained the television and digital distribution rights to all Star Wars films produced after the original).
On April 7, 2015, the Walt Disney Studios, 20th Century Fox, and Lucasfilm jointly announced the digital releases of the six released "Star Wars" films. Fox released "A New Hope" for digital download on April 10, 2015 (while Disney released the other five films).
Reception.
Box office.
"Star Wars" remains one of the most financially successful films of all time. The film earned $1,554,475 through its opening weekend ($ in 2014 dollars), building up to $7 million weekends as it entered wide release ($ in 2014 dollars). It replaced "Jaws" as the highest-earning film in North America just six months into release, eventually earning over $220 million during its initial theatrical run ($ in 2014 dollars). "Star Wars" entered international release towards the end of the year, and in 1978 added the worldwide record to its domestic one, earning $410 million in total. Reissues in 1978, 1979, 1981, and 1982 brought its cumulative gross in Canada and the U.S. to $323 million, and extended its global earnings to $530 million. The film remained the highest-grossing film of all time until "E.T. the Extra-Terrestrial" broke that record in 1983.
Following the release of the "Special Edition" in 1997, "Star Wars" briefly reclaimed the North American record before losing it again the following year to "Titanic". In total, the film has earned $775,398,007 worldwide (including $460,998,007 in North America alone). Adjusted for inflation, it has earned over $2.5 billion worldwide at 2011 prices, making it the most successful franchise film of all time. According to "Guinness World Records", the film ranks as the third-highest-grossing film when adjusting for inflation; at the North American box office, it ranks second behind "Gone with the Wind" on the inflation-adjusted list.
Critical response.
"What makes the "Star War" experience unique, though, is that it happens on such an innocent and often funny level. It's usually violence that draws me so deeply into a movie — violence ranging from the psychological torment of a Bergman character to the mindless crunch of a shark's jaws. Maybe movies that scare us find the most direct route to our imaginations. But there's hardly any violence at all in "Star Wars" (and even then it's presented as essentially bloodless swashbuckling). Instead, there's entertainment so direct and simple that all of the complications of the modern movie seem to vaporize."
—Roger Ebert, in his review for the "Chicago Sun-Times"
The film was met with positive reviews upon its release. In his 1977 review, Roger Ebert of the "Chicago Sun-Times" called the film "an out-of-body experience", compared its special effects to those of "", and opined that the true strength of the film was its "pure narrative". Vincent Canby of "The New York Times" called the film "the movie that's going to entertain a lot of contemporary folk who have a soft spot for the virtually ritualized manners of comic-book adventure" and "the most elaborate, most expensive, most beautiful movie serial ever made." A.D. Murphy of "Variety" described the film as "magnificent" and claimed George Lucas had succeeded in his attempt to create the "biggest possible adventure fantasy" based on the serials and older action epics from his childhood. Writing for "The Washington Post", Gary Arnold gave the film a positive review, writing that the film "is a new classic in a rousing movie tradition: a space swashbuckler." However, the film was not without its detractors: Pauline Kael of "The New Yorker" criticized "Star Wars", stating that "there's no breather in the picture, no lyricism", and that it had no "emotional grip".
British press for the film was positive. Derek Malcolm of "The Guardian" concluded that the film "plays enough games to satisfy the most sophisticated." "The Daily Telegraph"‍ '​s Adrian Berry said that "Star Wars" "is the best such film since "2001" and in certain respects it is one of the most exciting ever made." He described the plot as "unpretentious and pleasantly devoid of any 'message.'" In his review for BBC, Matt Ford awarded the film five out of five stars and wrote, ""Star Wars" isn't the best film ever made, but it is universally loved."
The film continues to receive critical acclaim from modern critics. The film review aggregator website Rotten Tomatoes sampled 71 reviews and judged 93% of them to be positive. Its consensus states in summary, "A legendary expansive and ambitious start to the sci-fi saga, George Lucas opens our eyes to the possibilities of blockbuster film-making and things have never been the same." Metacritic reports an aggregate score of 91 out of 100 (based on 13 reviews), indicating "universal acclaim". In his 1997 review of the film's 20th anniversary release, Michael Wilmington of the "Chicago Tribune" gave the film four out of four stars, saying, "A grandiose and violent epic with a simple and whimsical heart." A "San Francisco Chronicle" staff member described the film as "a thrilling experience."
Gene Siskel, writing for the "Chicago Tribune" in 1999, said, "What places it a sizable cut about the routine is its spectacular visual effects, the best since Stanley Kubrick's "2001"." Andrew Collins of "Empire" magazine awarded the film five out of five and said, ""Star Wars"‍ '​ timeless appeal lies in its easily identified, universal archetypes—goodies to root for, baddies to boo, a princess to be rescued and so on—and if it is most obviously dated to the 70s by the special effects, so be it." In his 2009 review, Robert Hatch of "The Nation" called the film "an outrageously successful, what will be called a 'classic,' compilation of nonsense, largely derived but thoroughly reconditioned. I doubt that anyone will ever match it, though the imitations must already be on the drawing boards." In a more critical review, Jonathan Rosenbaum of the "Chicago Reader" stated, "None of these characters has any depth, and they're all treated like the fanciful props and settings." Peter Keough of the "Boston Phoenix" said, ""Star Wars" is a junkyard of cinematic gimcracks not unlike the Jawas' heap of purloined, discarded, barely functioning droids."
Accolades.
The film garnered numerous accolades after its release. "Star Wars" won six competitive Academy Awards at the 50th Academy Awards: Best Art Direction, Best Costume Design, Best Film Editing, Best Original Score, Best Sound and Best Visual Effects. A Special Achievement for Sound Effects Editing went to sound designer Ben Burtt. Additional nominations included Alec Guinness for Best Actor in a Supporting Role and George Lucas for Best Original Screenplay, Best Director, and Best Picture, which were instead awarded to Woody Allen's "Annie Hall".
At the 35th Golden Globe Awards, the film was nominated for Best Motion Picture – Drama, Best Director, Best Supporting Actor (Alec Guinness), and it won the award for Best Score. It received six British Academy Film Awards nominations: Best Film, Best Editing, Best Costume Design, Best Production/Art Design, Best Sound, and Best Score; the film won in the latter two categories. John Williams' soundtrack album won the Grammy Award for Best Album of Original Score for a Motion Picture or Television Program, and the film attained the Hugo Award for Best Dramatic Presentation.
The film also received twelve nominations at the Saturn Awards, winning nine: Best Science Fiction Film, Best Direction and Best Writing for George Lucas, Best Supporting Actor for Alec Guinness, Best Music for John Williams, Best Costume for John Mollo, Best Make-up for Rick Baker and Stuart Freeborn, Best Special Effects for John Dykstra and John Stears, and Outstanding Editing for Paul Hirsch, Marcia Lucas and Richard Chew.
Legacy.
The original "Star Wars" trilogy is considered one of the best film trilogies in history. Lucas has often stated that the entire trilogy was intended to be considered one film. However, he said that his story material for "Star Wars" was too long for a single film, prompting Lucas to split the story into multiple films. Lucas also stated that the story evolved over time and that "There was never a script completed that had the entire story as it exists now [in 1983] ... As the stories unfolded, I would take certain ideas and save them ... I kept taking out all the good parts, and I just kept telling myself I would make other movies someday." In early interviews, it was suggested the series might comprise nine or twelve films.
"Star Wars" launched the careers of Mark Hamill, Harrison Ford, and Carrie Fisher. Ford, who subsequently starred in the "Indiana Jones" series (1981–2008), "Blade Runner" (1982), and "Witness" (1985) after working on the film, told the Daily Mirror that "Star Wars" "boosted my career", and said, "I think the great luck of my career is that I've made these family movies which are introduced to succeeding generations of kids by their families at the time it seems appropriate."
The film has spawned a series of films consisting of two trilogies (including the original film), and an extensive media franchise called the Expanded Universe including books, television series, computer and video games, and comic books. All of the main films have been box office successes, with the overall box office revenue generated by the "Star Wars" films (including the theatrical "") totaling $4.38 billion, making it the fifth highest-grossing film series.
The film also spawned the "Star Wars Holiday Special", which debuted on CBS on November 17, 1978 and is often considered a failure; Lucas himself disowned it. The special has never been aired after its original broadcast, and it has never been officially released on home video. However, many bootleg copies exist, and the special has consequently become something of an underground legend.
In popular culture.
"Star Wars" and its ensuing film installments have been explicitly referenced and satirized across a wide range of media. "Hardware Wars", released in 1978, was one of the first fan films to parody "Star Wars". It received positive critical reaction, went to earn over $1 million, and is one of Lucas's favorite "Star Wars" spoofs. Writing for "The New York Times", Frank DeCaro said, ""Star Wars" littered pop culture of the late 1970s with a galaxy of space junk." He cited "Quark" (a short-lived 1977 sitcom that parodied the science fiction genre) and "Donny & Marie" (a 1970s variety show that produced a 10-minute musical adaptation of "Star Wars" guest starring Anthony Daniels and Peter Mayhew) as "television's two most infamous examples". Mel Brooks's "Spaceballs", a satirical comic science fiction parody, later came out in 1987 to mixed reviews. Lucas permitted Brooks to make a spoof of the film under "one incredibly big restriction: no action figures."
Contemporary animated comedy TV series "Family Guy", "Robot Chicken", and "The Simpsons" have produced episodes satirizing the film series. "Star Wars", together with Lucas, was also the subject of the 2010 documentary film "The People vs. George Lucas" that details the issues of filmmaking and fanaticism pertaining to the film franchise and its creator. Many elements of the film have also endured presence in popular culture. The iconic weapon of choice of the Jedi, the lightsaber, was voted as the most popular weapon in film history in a survey of approximately 2,000 film fans. The expressions "Evil empire" and "May the Force be with you" have become part of the popular lexicon. To commemorate the film's 30th anniversary in May 2007, the United States Postal Service issued a set of 15 stamps depicting the characters of the franchise. Approximately 400 mailboxes across the country were also designed to look like R2-D2.
Cinematic influence.
Film critic Roger Ebert wrote in his book "The Great Movies", "Like "The Birth of a Nation" and "Citizen Kane", "Star Wars" was a technical watershed that influenced many of the movies that came after." It began a new generation of special effects and high-energy motion pictures. The film was one of the first films to link genres together to invent a new, high-concept genre for filmmakers to build upon. Finally, along with Steven Spielberg's "Jaws", it shifted the film industry's focus away from personal filmmaking of the 1970s and towards fast-paced, big-budget blockbusters for younger audiences.
Filmmakers who have said to have been influenced by "Star Wars" include James Cameron, Dean Devlin, Gareth Edwards, Roland Emmerich, John Lasseter, David Fincher, Peter Jackson, Joss Whedon, Christopher Nolan, Ridley Scott, John Singleton, and Kevin Smith. Scott, Cameron, and Jackson were influenced by Lucas's concept of the "used future" (where vehicles and culture are obviously dated) and extended the concept for their films, such as Scott's science fiction films "Alien" (1979) and "Blade Runner" (1982), and Cameron's "The Terminator" (1984). Jackson used the concept for his production of "The Lord of the Rings" trilogy to add a sense of realism and believability. Christopher Nolan cited "Star Wars" as an influence when making the 2010 blockbuster film, "Inception".
Some critics have blamed "Star Wars", as well as "Jaws", for ruining Hollywood by shifting its focus from "sophisticated" films such as "The Godfather", "Taxi Driver", and "Annie Hall" to films about spectacle and juvenile fantasy. One such critic, Peter Biskind, complained, "When all was said and done, Lucas and Spielberg returned the 1970s audience, grown sophisticated on a diet of European and New Hollywood films, to the simplicities of the pre-1960s Golden Age of movies... They marched backward through the looking-glass." In an opposing view, Tom Shone wrote that through "Star Wars" and "Jaws", Lucas and Spielberg "didn't betray cinema at all: they plugged it back into the grid, returning the medium to its roots as a carnival sideshow, a magic act, one big special effect", which was "a kind of rebirth".
Recognition.
In its May 30, 1977 issue, the film's year of release, "Time" magazine named "Star Wars" the "Movie of the Year". The publication claimed it was a "big early supporter" of the vision which would become "Star Wars". In an article intended for the cover of the issue, "Time"‍ '​s Gerald Clarke wrote that "Star Wars" is "a grand and glorious film that may well be the smash hit of 1977, and certainly is the best movie of the year so far. The result is a remarkable confection: a subliminal history of the movies, wrapped in a riveting tale of suspense and adventure, ornamented with some of the most ingenious special effects ever contrived for film." Each of the subsequent films of the "Star Wars" saga has appeared on the magazine's cover.
AFI 100 Years... series
American Film Institute
"Star Wars" was voted the second most popular film by Americans in a 2008 nationwide poll conducted by the market research firm, Harris Interactive. "Star Wars" has also been featured in several high-profile audience polls: in 1997, it ranked as the 10th Greatest American Film on the "Los Angeles Daily News" Readers' Poll; in 2002, the film and its sequel "The Empire Strikes Back" were voted as the greatest films ever made in Channel 4's 100 Greatest Films poll; in 2011, it ranked as Best Sci-Fi Film on "", a primetime special aired by ABC that counted down the best films as chosen by fans, based on results of a poll conducted by ABC and "People" magazine; in 2014 the film placed 11th in a poll undertaken by "The Hollywood Reporter", which balloted every studio, agency, publicity firm, and production house in the Hollywood region.
Reputable publications also have included "Star Wars" in their best films lists: in 2008, "Empire" magazine ranked "Star Wars" at No. 22 on its list of the "500 Greatest Movies of All Time"; in 2010, the film ranked among the "All-Time 100" list of the greatest films as chosen by "Time" magazine film critic Richard Schickel; the film was also placed on a similar list created by "The New York Times", "The Best 1,000 Movies Ever Made"; in 2012, the film was included in "Sight & Sound"‍ '​s prestigious decennial critics poll "Critics' Top 250 Films", ranking at 171st on the list, and in their directors poll at 224th.
Lucas's original screenplay was selected by the Writers Guild of America as the 68th greatest of all time. In 1989, the Library of Congress selected "Star Wars" for preservation in the United States National Film Registry, as being "culturally, historically, or aesthetically significant" (though it remains unclear which edition, if any, the NFR has succeeded in acquiring from Lucasfilm); its soundtrack was added to the United States National Recording Registry 15 years later (in 2004).
In addition to the film's multiple awards and nominations, "Star Wars" has also been recognized by the American Film Institute on several of its lists. The film ranks first on 100 Years of Film Scores, second on Top 10 Sci-Fi Films, 15th on 100 Years...100 Movies (ranked 13th on the updated 10th anniversary edition), 27th on 100 Years...100 Thrills, and 39th on 100 Years...100 Cheers. In addition, the quote "May the Force be with you" is ranked eighth on 100 Years...100 Movie Quotes, and Han Solo and Obi-Wan Kenobi are ranked as the 14th and 37th greatest heroes respectively on 100 Years...100 Heroes & Villains.
Merchandising.
Little "Star Wars" merchandise was available for several months after the film's debut, as only Kenner Products had accepted marketing director Charles Lippincott's licensing offers. Kenner responded to the sudden demand for toys by selling boxed vouchers in its "empty box" Christmas campaign. Television commercials told children and parents that vouchers within a "Star Wars Early Bird Certificate Package" could be redeemed for four action figures between February and June 1978. Jay West of the "Los Angeles Times" said that the boxes in the campaign "became the most coveted empty box[es] in the history of retail." In 2012, the "Star Wars" action figures were inducted into the National Toy Hall of Fame.
The was published in December 1976, six months before the film was released. The credited author was George Lucas, but the book was revealed to have been ghostwritten by Alan Dean Foster, who later wrote the first Expanded Universe novel, "Splinter of the Mind's Eye" (1978). The book was first published as "Star Wars: From the Adventures of Luke Skywalker"; later editions were titled simply "Star Wars" (1995) and, later, "Star Wars: A New Hope" (1997), to reflect the retitling of the film. Marketing director Charles Lippincott secured the deal with Del Rey Books to publish the novelization in November 1976. By February 1977, a half-million copies had been sold.
Marvel Comics also adapted the film as the first six issues of its licensed "Star Wars" comic book, with the first issue dated May 1977. Roy Thomas was the writer and Howard Chaykin was the artist of the adaptation. Like the novelization, it contained certain elements, such as the scene with Luke and Biggs, that appeared in the screenplay but not in the finished film. The series was so successful that, according to Jim Shooter, it "single-handedly saved Marvel". In 2013, Dark Horse Comics published a comic adaption of the original screenplay's plot.
Lucasfilm adapted the story for a children's book-and-record set. Released in 1979, the 24-page "Star Wars" read-along book was accompanied by a 33⅓ rpm 7-inch phonograph record. Each page of the book contained a cropped frame from the movie with an abridged and condensed version of the story. The record was produced by Buena Vista Records, and its content was copyrighted by Black Falcon, Ltd., a subsidiary of Lucasfilm "formed to handle the merchandising for "Star Wars"". "The Story of Star Wars" was a 1977 record album presenting an abridged version of the events depicted in "Star Wars", using dialogue and sound effects from the original film. The recording was produced by George Lucas and Alan Livingston, and was narrated by Roscoe Lee Browne. The script was adapted by E. Jack Kaplan and Cheryl Gard.
A radio drama adaptation of the film was written by Brian Daley, directed by John Madden, and produced for and broadcast on the American National Public Radio network in 1981. The adaptation received cooperation from George Lucas, who donated the rights to NPR. John Williams' music and Ben Burtt's sound design were retained for the show; Mark Hamill (Luke Skywalker) and Anthony Daniels (C-3PO) reprised their roles as well. The radio drama featured scenes not seen in the final cut of the film, such as Luke Skywalker's observation of the space battle above Tatooine through binoculars, a skyhopper race, and Darth Vader's interrogation of Princess Leia. In terms of "Star Wars" canon, the radio drama is given the highest designation (like the screenplay and novelization), G-canon.
Footnotes.
</dl>
Annotations
References.
Bibliography

</doc>
<doc id="52552" url="http://en.wikipedia.org/wiki?curid=52552" title="Axiom of power set">
Axiom of power set

In mathematics, the axiom of power set is one of the Zermelo–Fraenkel axioms of axiomatic set theory.
In the formal language of the Zermelo–Fraenkel axioms, the axiom reads:
where "P" stands for the Power set of "A", formula_2. In English, this says:
More succinctly: "for every set formula_5, there is a set formula_2 consisting precisely of the subsets of formula_5."
Note the subset relation formula_8 is not used in the formal definition as subset is not a primitive relation in formal set theory; rather, subset is defined in terms of set membership, formula_9. By the axiom of extensionality, the set formula_2 is unique.
The axiom of power set appears in most axiomatizations of set theory. It is generally considered uncontroversial, although constructive set theory prefers a weaker version to resolve concerns about predicativity.
Consequences.
The Power Set Axiom allows a simple definition of the Cartesian product of two sets formula_11 and formula_12: 
Notice that
and thus the Cartesian product is a set since 
One may define the Cartesian product of any finite collection of sets recursively: 
Note that the existence of the Cartesian product can be proved without using the power set axiom, as in the case of the Kripke–Platek set theory.
References.
"This article incorporates material from on PlanetMath, which is licensed under the ."

</doc>
<doc id="52553" url="http://en.wikipedia.org/wiki?curid=52553" title="Axiom of union">
Axiom of union

In axiomatic set theory and the branches of logic, mathematics, and computer science that use it, the axiom of union is one of the axioms of Zermelo–Fraenkel set theory, stating that, for any set "x" there is a set "y" whose elements are precisely the elements of the elements of "x". Together with the axiom of pairing this implies that for any two sets, there is a set that contains exactly the elements of both.
Formal statement.
In the formal language of the Zermelo–Fraenkel axioms, the axiom reads:
or in words:
Interpretation.
What the axiom is really saying is that, given a set "A", we can find a set "B" whose members are precisely the members of the members of "A". By the axiom of extensionality this set "B" is unique and it is called the "union" of "A", and denoted formula_2. Thus the essence of the axiom is:
The axiom of union is generally considered uncontroversial, and it or an equivalent appears in just about any alternative axiomatization of set theory.
Note that there is no corresponding axiom of intersection. If "A" is a "nonempty" set containing "E", then we can form the intersection formula_3 using the axiom schema of specification as
so no separate axiom of intersection is necessary. (If "A" is the empty set, then trying to form the intersection of "A" as
is not permitted by the axioms. Moreover, if such a set existed, then it would contain every set in the "universe", but the notion of a universal set is antithetical to Zermelo–Fraenkel set theory.)

</doc>
<doc id="52555" url="http://en.wikipedia.org/wiki?curid=52555" title="Defense Information Systems Agency">
Defense Information Systems Agency

The Defense Information Systems Agency (DISA), known as the Defense Communications Agency (DCA) until 1991, is a United States Department of Defense (DoD) combat support agency composed of military, federal civilians, and contractors. DISA provides information technology (IT) and communications support to the President, Vice President, Secretary of Defense, the military services, the combatant commands, and any individual or system contributing to the defense of the United States.
According to the mission statement on the agency website, DISA “provides, operates, and assures command and control, information sharing capabilities, and a globally accessible enterprise information infrastructure in direct support to joint warfighters, National level leaders, and other mission and coalition partners across the full spectrum of operations.” DISA’s vision is “Information superiority in defense of our Nation.”
Headquarters.
From January to July 2011, DISA relocated more than 4,500 military and civilian employees and supporting onsite contractors, 700 workstation suites with 11,000 pieces of advanced IT equipment, and 58,000 square feet of lab equipment in accordance with the Base Realignment and Closure legislation of 2005. The relocation to Fort George G. Meade, Md., consolidated DISA headquarters elements that were housed in multiple locations in Arlington and Falls Church, Va. In April 2011, DISA held a ribbon cutting ceremony officially opening the new headquarters complex.
During the relocation DISA maintained its pace of operations and continued to deploy critical warfighting capabilities with no disruption of service and support to its mission partners.
As it enters the second decade of the new century, DISA continues to engineer, develop, maintain, and operate a global net-centric enterprise in direct support to joint and coalition warfighters, national-level leaders, and other mission partners across the full spectrum of operations.
Services.
DISA offers the following services to its mission partners.
Command and Control.
Command and Control (C2) systems provide the U.S. military commander with the information to make effective decisions and provide the warfighter the capability to access the information necessary to complete their mission. The C2 portfolio contains the Global Combat Support System - Joint (GCSS-J), Global Command and Control System - Joint (GCCS-J), Multinational Information Sharing (MNIS), and Joint Planning and Execution Services (JPES).
Computing.
DISA's computing services portfolio includes mainframe hosting, application monitoring, and server hosting and virtualization. DISA manages all the partner data, hardware components, software, and labor.
Contracting.
DISA purchases telecommunications and information technology (IT) products and services for the U.S. military using a variety of contract vehicles.
Enterprise Engineering.
Enterprise Engineering refers to the Global Information Grid (a.k.a. the GIG). DISA plans, designs, constructs, and analyzes the effectiveness of the U.S. military's cyberspace and establishes the technological standards to make the GIG secure and reliable. The enterprise engineering portfolio includes the Joint Communication Simulation System (JCSS), GIG Technical Guidance for Information Technology Standards, and Interoperability Enhancement Process/iSmart (IEP/iSmart).
Enterprise Services.
Enterprise services provided by DISA to its mission partners fall under three categories: Applications, Infrastructure, and Identity and Access Management.
Applications
Infrastructure
Identity and Access Management
Information Assurance.
DISA's Information Assurance services serve the purpose of:
Network Services.
The Defense Information Systems Network (DISN) is a worldwide-protected telecommunications network that enables the exchange of information in an interoperable and global space, partitioned by security demands, transmission requirements, and geographic needs of targeted end-user communities.
Nowadays, DISA maintains the following network services, to support diverse telecommunication requirements for organizations focused on, but not limited to, the Department of Defense (DoD):
Data:
Voice:
Video:
Messaging:
Wireless:
Satellite:<br>
Providing access to DISN through
Spectrum.
Through the Defense Spectrum Organization (DSO), DISA provides commanders direct operational support, including electromagnetic battlespace planning, deconfliction, and joint spectrum interference resolution. DSO services include:
Testing.
DISA's Joint Interoperability Test Command (JITC) provides testing and joint certification for the net-centric systems employed by U.S. armed forces.
History.
1960s: The Defense Communications Agency.
DCA was established May 12, 1960, with the primary mission of operational control and management of the Defense Communications System (DCS).
The initial headquarters for 34 DCA members was Wake Hall, one of a complex of three buildings (which included Midway Hall and Guam Hall) on the site where the parking lot of the Robert F. Kennedy Stadium in Washington, D.C., stands today. Navy Rear Admiral William D. Irvin became the first DCA director in July. In September, Rear Admiral Irvin moved his staff to office space in Building 12 at the Naval Services Center, 701 Courthouse Road, Arlington, Va., the site of the U.S. Navy’s old Radio Arlington Station.
DCA’s first major tasks were to identify the DCS elements and develop an implementation and management plan. The DCS was essentially a collection of communications systems turned over by the military departments with considerable restrictions. Key among these responsibilities was the establishment of three common-user, defense-wide networks that would be known as the Automatic Voice Network (AUTOVON), the Automatic Digital Network (AUTODIN), and the Automatic Secure Voice Communications Network (AUTOSEVOCOM). For each, DCA sought to determine its overall system configuration and prepare the technical specifications necessary for the equipment for switching centers, interconnecting transmission media, and subscriber terminals.
With the arrival of the space-age, DCA was designated as the “strong focal point” for development, integration, and operation of the space and ground elements of a number of satellite-based communications initiatives. The most important of these would be the DCA-managed Defense Satellite Communications System (DSCS).
The Cuban Missile Crisis of October 1962 showed the need for direct, timely, and private communications between the leaders of the world’s two superpowers, the United States and the Soviet Union. A duplex cable circuit (later augmented by a satellite hookup) between the two capitals known as the Moscow–Washington hotline or "Red Telephone", became operational August 30, 1963. Program management and engineering for the “Hotline” was assigned to DCA. The system continues intact today with direct links to more than 40 foreign leaders. Another direct result of the Cuban Missile Crisis was the creation of the Worldwide Military Command and Control System (WWMCCS) to enable national command authorities to exercise effective command and control of their widely dispersed forces.
While DCA dealt with the communication crises of the Cold War, a “hot war” was waging in Southeast Asia. America’s commitment to South Vietnam led to the creation of a DCA Southeast Asia Region unit in 1964. DCA developed a plan to integrate the region’s communication systems into a single modern network. The system would extend the commercial-quality communications provided by satellites and cables to the battlefield.
1970s.
DCA assumed responsibility for the Minimum Essential Emergency Communications Network (MEECN), a subsystem of WWMCCS, in December 1971. The MEECN was developed to assure the timely receipt of emergency action messages by worldwide U.S. nuclear forces under nuclear attack by the Soviet Union. DCA served as the MEECN system engineer and provided the broad engineering necessary to ensure a more survivable future network with compatible, interoperable, and secure subsystems.
A DoD directive issued in the early 1970s appointed DCA as the system architect for all defense satellite communications. A major new DCA headquarters staff directorate, the Military Satellite Communications (MILSATCOM) System Office, was created to discharge the new role. As the system architect, DCA coordinated all defense satellite communications planning and programs to avoid duplication and ensure communications interoperability among the diverse systems serving the complete spectrum of defense needs.
1980s.
The momentum of major improvements in national security telecommunications accelerated rapidly in the 1980s. Along with the unprecedented peacetime military build-up under the Reagan Administration came the proliferation of government-owned and government-leased networks and a high emphasis on interoperability among the military services. The pace of technological advancement brought with it new opportunities for system improvements.
The desire for interoperability in military communications did not originate in the 1980s. The need for communications systems that talked to each other within an individual military service and among the services together went back to the needs generated by the global proportions of WWII. Indeed, it was the lack of interoperability that drove the Eisenhower administration to seek one organization to pull together the services’ disparate systems to speak with one voice – that organization was DCA. But interoperability still had yet to be achieved by the 1980s.
In April 1986, the assistant secretary of defense for command and control, communications and intelligence proposed the consolidation of DCA and the Joint Tactical Command, Control, and Communications Agency (JTC3A) in view of the “climate within DoD of streamlining and reducing overhead functions.” The Joint Staff endorsed the proposal because it also provided some operational efficiency.
In January 1987, the secretary of defense approved the consolidation of DCA and JTC3A. A year later, DCA absorbed the Tri-Service Tactical Communications Joint Test Element and JTC3A Joint Operability Test Facility. DCA consolidated these organizations into a new organization in 1989, establishing the Joint Interoperability Test Command (JITC) at Fort Huachuca, Arizona. JITC provided the facility for DoD and private-sector interoperability compliance testing and certification.
In October 1989, the deputy secretary of defense established a DoD Corporate Information Management (CIM) Initiative to identify and implement management efficiencies in DoD information systems. DCA was given responsibility for implementing the CIM initiative, and its mission was expanded to include information support to the JCS and Office of the Secretary of Defense, tactical information system standards and interoperability, and White House information systems.
1990s.
In 1990 and 1991, during Operations Desert Shield and Desert Storm, a team of planners, engineers, and operators from DCA’s Defense Network Systems Organization (DNSO) assisted in the design of a semi-fixed telecommunications system, the Southwest Asia Telecommunications (SATS) for use in support of the theater commander’s operations. SATS included satellite, microwave, copper cable, and fiber optic links; Defense Data Network packet-switching nodes; Defense Switched Network (DSN) multi-function voice switches; and technical control facilities. At their peak, these systems included more than 100 satellite links.
On June 25, 1991, DCA underwent a major reorganization and was renamed the Defense Information Systems Agency (DISA) to reflect its expanded role in implementing the DoD’s CIM (Corporate Information Management) initiative and to clearly identify DISA as a combat support agency. DISA established the Center for Information Management to provide technical and program execution assistance to the assistant secretary of defense (C3I) and technical products and services to DoD and military components.
DISA’s role in DoD information management continued to expand with implementation of several Defense Management Report Decisions (DMRD ), most notably DMRD 918, in September 1992. DMRD 918 created the Defense Information Infrastructure (DII) and directed DISA to manage and consolidate the Services’ and DoD’s information processing centers into 16 mega-centers. During the 1990s, DISA fielded new systems to support the combatant commands. The Global Command and Control System (GCCS) and the Joint Chiefs’ C4I (Command, Control, Communications, Computers, and Intelligence) for the Warrior, and the Defense Message System were among the critical systems. GCCS was developed to replace WWMCCS, which had been in existence since the early 1960s.
2000s.
With the new century, DISA faced even greater challenges as a DoD service provider. Preserving radio spectrum, information assurance, ensuring interoperability, and establishing secure wireless links were just some of the tasks performed by the agency. Perhaps the most significant achievement of the agency in 2001 was its immediate response in the aftermath of the attacks of Sept. 11, 2001. DISA justified $300 million in supplemental funds to support the Global War on Terrorism by providing critical communications paths and command and control enhancements for warfighters.
In the 18 months between September 2001 and April 2003, DISA supported the exponential use and increased capacity of information systems. The Defense Switched Network (DSN) infrastructure increased 400 percent. The Secret Internet Protocol (IP) Data Service (formerly known as the SIPRNet) capacity increased 292 percent. Sensitive but Unclassified Internet Protocol (IP) Data Service (formerly known as NIPRNet) capacity increased 509 percent. The Defense Video System Global (Secure) increased 1,150 percent. Satellite bandwidth increased 800 percent. The Enhanced Mobile Satellite Service (EMSS) capacity increased 300 percent, and usage increased 3,000 percent. EMSS allowed Special Operations forces to even call in air strikes from horseback in Afghanistan by permitting instantaneous communications in areas without any infrastructure whatsoever.
For Operation Iraqi Freedom in 2003, DISA provided 30 times more bandwidth to a 45-percent smaller force than in Operation Desert Storm in 1991. DISA facilitated multiple enhancements to the nation’s preeminent joint command-and-control system and provided a real-time battle space picture.
After the previous consolidation of 194 data-processing centers in the 1990s into 16 computing mega-centers, DISA further reduced the number of mega-centers from 16 to six.
Starting in 2003, DISA managed the six-year, $326 million effort to completely modernize presidential communications — the largest such initiative in the 61-year history of the White House Communications Agency. The “Pioneer Program” transformed presidential communications by employing net-centric concepts to put voice, video, and data at the president’s fingertips on an around-the-clock basis.
The Global Information Grid Bandwidth Expansion (GIG-BE) Program was a major DoD net-centric transformational initiative executed by DISA. The $877 million program was the largest DoD information technology transport structure ever built. GIG-BE created a ubiquitous "bandwidth-available" environment to improve national security intelligence, surveillance, reconnaissance, information assurance, and command and control at locations worldwide. On Dec. 20, 2005, the GIG-BE program achieved the milestone of full operational capability at all of the almost 100 Joint Staff-approved sites.
2010s.
DISA’s 50 years of service as the Defense Communications Agency and later the Defense Information Systems Agency was recognized May 12, 2010, during an anniversary celebration at Seven Skyline Place, Falls Church, Va. Army LTG Carroll F. Pollett, the DISA director at the time, led the celebration of the agency’s storied past.
From 2008 through 2010, DISA worked directly with the commander, United States Central Command (USCENTCOM), to design and implement a high-capacity, strategic communication network into an active Theater of Operations, ensuring reliable communications for intra-theater mission partners and to national leadership. Prior to this installation, the coalition forces in Afghanistan were dependent on satellite communications and tactical microwave links, which had limited bandwidth capacity and induced significant delay.
DISA operated and defended the Global Information Grid (GIG), providing information capabilities with a reach from the White House to forces at the tactical edge. DISA supported execution of military operations while simultaneously supporting peacekeeping, humanitarian assistance, and disaster-relief missions in multiple theaters around the globe. During a 4-month period in 2011, DISA provided support to an unprecedented six simultaneous operations: Operation NEW DAWN in Iraq; Operation ENDURING FREEDOM in Afghanistan; Operation UNIFIED RESPONSE in Haiti; Operation ODYSSEY DAWN and NATO Operation UNIFIED PROTECTOR in Libya, Operation TOMODACHI in Japan; and DISA’s global cyber operations in support of United States Cyber Command (USCYBERCOM).

</doc>
<doc id="52563" url="http://en.wikipedia.org/wiki?curid=52563" title="United States Department of Justice">
United States Department of Justice

The U.S. Department of Justice (DOJ), also known as the U.S. Justice Department, is a federal executive department of the U.S. government, responsible for the enforcement of the law and administration of justice in the United States, equivalent to the justice or interior ministries of other countries.
The Department is headed by the Attorney General, who is nominated by the President and confirmed by the Senate and is a member of the Cabinet. The current Attorney General is Loretta Lynch.
History.
The U.S. Attorney General was initially a one-person, part-time job. It was established by the Judiciary Act of 1789, but this grew with the bureaucracy. At one time the Attorney General gave legal advice to the U.S. Congress as well as the President, but this Congressional advice-giving had stopped by 1819 on account of the workload involved. To supplement their salaries, which until March 3, 1853, were set by statute at less than the amounts paid to other members of the Cabinet, early Attorneys General, while in office, engaged in extensive private practice of law, often arguing cases before the courts in their private capacities, as attorneys for private (paying) litigants.
Following unsuccessful efforts (in 1830 and 1846) to put the Attorney General's Office on a full-time footing, in 1869, the U.S. House Committee on the Judiciary, led by Congressman William Lawrence, conducted an inquiry into the creation of a "Law department" headed by the Attorney General and also composed of the various department solicitors and United States attorneys. On February 19, 1868, Lawrence introduced a bill in Congress to create the Department of Justice. This first bill was unsuccessful, however, as Lawrence could not devote enough time to ensure its passage owing to his occupation with the Impeachment of President Andrew Johnson.
A second bill was introduced to Congress by Rhode Island Representative Thomas Jenckes on February 25, 1870, and both the Senate and House passed the bill. President Ulysses S. Grant then signed the bill into law on June 22, 1870. The Department of Justice officially began operations on July 1, 1870.
The "Act to Establish the Department of Justice" drastically increased the Attorney General's responsibilities to include the supervision of all United States Attorneys, formerly under the department of the interior, the prosecution of all federal crimes, and the representation of the United States in all court actions, barring the use of private attorneys by the federal government. The law did create a new office, that of Solicitor General, to supervise and conduct government litigation in the Supreme Court of the United States.
With the passage of the Interstate Commerce Act in 1887, the federal government began to take on some law enforcement responsibilities, with the Department of Justice tasked to carry out these duties.
In 1884, control of federal prisons was transferred to the new department, from the Department of Interior. New facilities were built, including the penitentiary at Leavenworth in 1895, and a facility for women located in West Virginia, at Alderson was established in 1924.
In 1933, President Franklin D. Roosevelt issued an executive order which conveyed, to the Department of Justice, the responsibility for the "functions of prosecuting in the courts of the United States claims and demands by, and offsenses [sic] against, the Government of the United States, and of defending claims and demands against the Government, and of supervising the work of United States attorneys, marshals, and clerks in connection therewith, now exercised by any agency or officer...".
Headquarters.
The U.S. Department of Justice building was completed in 1935 from a design by Milton Bennett Medary. Upon Medary's death in 1929, the other partners of his Philadelphia firm Zantzinger, Borie and Medary took over the project. On a lot bordered by Constitution and Pennsylvania Avenues and Ninth and Tenth Streets, Northwest, it holds over one million square feet of space. The sculptor C. Paul Jennewein served as overall design consultant for the entire building, contributing more than 50 separate sculptural elements inside and outside.
Various efforts, none entirely successful, have been made to determine the meaning of the Latin motto appearing on the Department of Justice seal, "Qui Pro Domina Justitia Sequitur". It is not even known exactly when the original version of the DOJ seal itself was adopted, or when the motto first appeared on the seal. The most authoritative opinion of the DOJ suggests that the motto refers to the Attorney General (and thus, by extension, to the Department of Justice) "who prosecutes on behalf of justice (or the Lady Justice)." The motto’s conception of the prosecutor (or government attorney) as being the servant of justice itself finds concrete expression in a similarly-ordered English-language inscription ("THE UNITED STATES WINS ITS POINT WHENEVER JUSTICE IS DONE ITS CITIZENS IN THE COURTS") in the above-door paneling in the ceremonial rotunda anteroom just outside the Attorney General’s office in the Department of Justice Main Building in Washington, D.C.
The building was renamed in honor of former Attorney General Robert F. Kennedy in 2001. It is sometimes referred to as "Main Justice."
Organization.
Law enforcement agencies.
Several federal law enforcement agencies are administered by the Department of Justice:
Other offices and programs.
In March 2003, the United States Immigration and Naturalization Service was abolished and its functions transferred to the United States Department of Homeland Security. The Executive Office for Immigration Review and the Board of Immigration Appeals, which review decisions made by government officials under Immigration and Nationality law, remain under jurisdiction of the Department of Justice. Similarly the Office of Domestic Preparedness left the Justice Department for the Department of Homeland Security, but only for executive purposes. The Office of Domestic Preparedness is still centralized within the Department of Justice, since its personnel are still officially employed within the Department of Justice.
In 2003, the Department of Justice created LifeAndLiberty.gov, a website that supported the PATRIOT Act. It was criticized by government watchdog groups.
Finances and budget.
The Justice Department was authorized a budget for Fiscal Year 2015 of approximately $21 billion. The budget authorization is broken down as follows:

</doc>
<doc id="52564" url="http://en.wikipedia.org/wiki?curid=52564" title="Partial differential equation">
Partial differential equation

In mathematics, a partial differential equation (PDE) is a differential equation that contains unknown multivariable functions and their partial derivatives. (This is in contrast to ordinary differential equations (ODEs), which deal with functions of a single variable and their derivatives.) PDEs are used to formulate problems involving functions of several variables, and are either solved by hand, or used to create a relevant computer model.
PDEs can be used to describe a wide variety of phenomena such as sound, heat, electrostatics, electrodynamics, fluid flow, elasticity, or quantum mechanics. These seemingly distinct physical phenomena can be formalised similarly in terms of PDEs. Just as ordinary differential equations often model one-dimensional dynamical systems, partial differential equations often model multidimensional systems. PDEs find their generalisation in stochastic partial differential equations.
Introduction.
Partial differential equations (PDEs) are equations that involve rates of change with respect to continuous variables. The position of a rigid body is specified by six numbers, but the configuration of a fluid is given by the continuous distribution of several parameters, such as the temperature, pressure, and so forth. The dynamics for the rigid body take place in a finite-dimensional configuration space; the dynamics for the ﬂuid occur in an infinite-dimensional conﬁguration space. This distinction usually makes PDEs much harder to solve than ordinary differential equations (ODEs), but here again there will be simple solutions for linear problems. Classic domains where PDEs are used include acoustics, fluid flow, electrodynamics, and heat transfer.
A partial differential equation (PDE) for the function formula_1 is an equation of the form
If "f" is a linear function of "u" and its derivatives, then the PDE is called linear. Common examples of linear PDEs include the heat equation, the wave equation, Laplace's equation, Helmholtz equation, Klein–Gordon equation, and Poisson's equation.
A relatively simple PDE is
This relation implies that the function "u"("x","y") is independent of "x". However, the equation gives no information on the function's dependence on the variable "y". Hence the general solution of this equation is
where "f" is an arbitrary function of "y". The analogous ordinary differential equation is
which has the solution
where "c" is any constant value. These two examples illustrate that general solutions of ordinary differential equations (ODEs) involve arbitrary constants, but solutions of PDEs involve arbitrary functions. A solution of a PDE is generally not unique; additional conditions must generally be specified on the boundary of the region where the solution is defined. For instance, in the simple example above, the function "f(y)" can be determined if "u" is specified on the line "x" = 0.
Existence and uniqueness.
Although the issue of existence and uniqueness of solutions of ordinary differential equations has a very satisfactory answer with the Picard–Lindelöf theorem, that is far from the case for partial differential equations. The Cauchy–Kowalevski theorem states that the Cauchy problem for any partial differential equation whose coefficients are analytic in the unknown function and its derivatives, has a locally unique analytic solution. Although this result might appear to settle the existence and uniqueness of solutions, there are examples of linear partial differential equations whose coefficients have derivatives of all orders (which are nevertheless not analytic) but which have no solutions at all: see Lewy (1957). Even if the solution of a partial differential equation exists and is unique, it may nevertheless have undesirable properties. The mathematical study of these questions is usually in the more powerful context of weak solutions.
An example of pathological behavior is the sequence (depending upon "n") of Cauchy problems for the Laplace equation
with boundary conditions
where "n" is an integer. The derivative of "u" with respect to "y" approaches 0 uniformly in "x" as "n" increases, but the solution is
This solution approaches infinity if "nx" is not an integer multiple of π for any non-zero value of "y". The Cauchy problem for the Laplace equation is called "ill-posed" or "not well posed", since the solution does not depend continuously upon the data of the problem. Such ill-posed problems are not usually satisfactory for physical applications.
Notation.
In PDEs, it is common to denote partial derivatives using subscripts. That is:
Especially in physics, del or Nabla (∇) is often used to denote spatial derivatives, and formula_14 for time derivatives. For example, the wave equation (described below) can be written as
or
where Δ is the Laplace operator.
Examples.
Heat equation in one space dimension.
The equation for conduction of heat in one dimension for a homogeneous body has
where "u"("t","x") is temperature, and α is a positive constant that describes the rate of diffusion. The Cauchy problem for this equation consists in specifying "u"(0, "x")= "f"("x"), where "f"("x") is an arbitrary function.
General solutions of the heat equation can be found by the method of separation of variables. Some examples appear in the heat equation article. They are examples of Fourier series for periodic "f" and Fourier transforms for non-periodic "f". Using the Fourier transform, a general solution of the heat equation has the form
where "F" is an arbitrary function. To satisfy the initial condition, "F" is given by the Fourier transform of "f", that is
If "f" represents a very small but intense source of heat, then the preceding integral can be approximated by the delta distribution, multiplied by the strength of the source. For a source whose strength is normalized to 1, the result is
and the resulting solution of the heat equation is
This is a Gaussian integral. It may be evaluated to obtain
This result corresponds to the normal probability density for "x" with mean 0 and variance 2α"t". The heat equation and similar diffusion equations are useful tools to study random phenomena.
Wave equation in one spatial dimension.
The wave equation is an equation for an unknown function "u"("t", "x") of the form
Here "u" might describe the displacement of a stretched string from equilibrium, or the difference in air pressure in a tube, or the magnitude of an electromagnetic field in a tube, and "c" is a number that corresponds to the velocity of the wave. The Cauchy problem for this equation consists in prescribing the initial displacement and velocity of a string or other medium:
where "f" and "g" are arbitrary given functions. The solution of this problem is given by d'Alembert's formula:
This formula implies that the solution at ("t","x") depends only upon the data on the segment of the initial line that is cut out by the characteristic curves
that are drawn backwards from that point. These curves correspond to signals that propagate with velocity "c" forward and backward. Conversely, the influence of the data at any given point on the initial line propagates with the finite velocity "c": there is no effect outside a triangle through that point whose sides are characteristic curves. This behavior is very different from the solution for the heat equation, where the effect of a point source appears (with small amplitude) instantaneously at every point in space. The solution given above is also valid if "t" < 0, and the explicit formula shows that the solution depends smoothly upon the data: both the forward and backward Cauchy problems for the wave equation are well-posed.
Generalised heat-like equation in one space dimension.
Where heat-like equation means equations of the form:
where formula_29 is a Sturm–Liouville operator subject to the boundary conditions:
Then:
If:
where
Spherical waves.
Spherical waves are waves whose amplitude depends only upon the radial distance "r" from a central point source. For such waves, the three-dimensional wave equation takes the form
This is equivalent to
and hence the quantity "ru" satisfies the one-dimensional wave equation. Therefore a general solution for spherical waves has the form
where "F" and "G" are completely arbitrary functions. Radiation from an antenna corresponds to the case where "G" is identically zero. Thus the wave form transmitted from an antenna has no distortion in time: the only distorting factor is 1/"r". This feature of undistorted propagation of waves is not present if there are two spatial dimensions.
Laplace equation in two dimensions.
The Laplace equation for an unknown function of two variables φ has the form
Solutions of Laplace's equation are called harmonic functions.
Connection with holomorphic functions.
Solutions of the Laplace equation in two dimensions are intimately connected with analytic functions of a complex variable (a.k.a. holomorphic functions): the real and imaginary parts of any analytic function are conjugate harmonic functions: they both satisfy the Laplace equation, and their gradients are orthogonal. If "f"="u"+"iv", then the Cauchy–Riemann equations state that
and it follows that
Conversely, given any harmonic function in two dimensions, it is the real part of an analytic function, at least locally. Details are given in Laplace equation.
A typical boundary value problem.
A typical problem for Laplace's equation is to find a solution that satisfies arbitrary values on the boundary of a domain. For example, we may seek a harmonic function that takes on the values "u"(θ) on a circle of radius one. The solution was given by Poisson:
Petrovsky (1967, p. 248) shows how this formula can be obtained by summing a Fourier series for φ. If "r" < 1, the derivatives of φ may be computed by differentiating under the integral sign, and one can verify that φ is analytic, even if "u" is continuous but not necessarily differentiable. This behavior is typical for solutions of elliptic partial differential equations: the solutions may be much more smooth than the boundary data. This is in contrast to solutions of the wave equation, and more general hyperbolic partial differential equations, which typically have no more derivatives than the data.
Euler–Tricomi equation.
The Euler–Tricomi equation is used in the investigation of transonic flow.
Advection equation.
The advection equation describes the transport of a conserved scalar ψ in a velocity field u = ("u", "v", "w"). It is:
If the velocity field is solenoidal (that is, ∇⋅u = 0), then the equation may be simplified to
In the one-dimensional case where "u" is not constant and is equal to ψ, the equation is referred to as Burgers' equation.
Ginzburg–Landau equation.
The Ginzburg–Landau equation is used in modelling superconductivity. It is
where "p","q" ∈ C and γ ∈ R are constants and "i" is the imaginary unit.
The Dym equation.
The Dym equation is named for Harry Dym and occurs in the study of solitons. It is
Initial-boundary value problems.
Many problems of mathematical physics are formulated as initial-boundary value problems.
Vibrating string.
If the string is stretched between two points where "x"=0 and "x"="L" and "u" denotes the amplitude of the displacement of the string, then "u" satisfies the one-dimensional wave equation in the region where 0 < "x" < "L" and "t" is unlimited. Since the string is tied down at the ends, "u" must also satisfy the boundary conditions
as well as the initial conditions
The method of separation of variables for the wave equation
leads to solutions of the form
where
where the constant "k" must be determined. The boundary conditions then imply that "X" is a multiple of sin "kx", and "k" must have the form
where "n" is an integer. Each term in the sum corresponds to a mode of vibration of the string. The mode with "n" = 1 is called the fundamental mode, and the frequencies of the other modes are all multiples of this frequency. They form the overtone series of the string, and they are the basis for musical acoustics. The initial conditions may then be satisfied by representing "f" and "g" as infinite sums of these modes. Wind instruments typically correspond to vibrations of an air column with one end open and one end closed. The corresponding boundary conditions are
The method of separation of variables can also be applied in this case, and it leads to a series of odd overtones.
The general problem of this type is solved in Sturm–Liouville theory.
Vibrating membrane.
If a membrane is stretched over a curve "C" that forms the boundary of a domain "D" in the plane, its vibrations are governed by the wave equation
if "t">0 and ("x","y") is in "D". The boundary condition is "u(t,x,y)" = 0 if "(x,y)" is on "C". The method of separation of variables leads to the form
which in turn must satisfy
The latter equation is called the Helmholtz Equation. The constant "k" must be determined to allow a non-trivial "v" to satisfy the boundary condition on "C". Such values of "k"2 are called the eigenvalues of the Laplacian in "D", and the associated solutions are the eigenfunctions of the Laplacian in "D". The Sturm–Liouville theory may be extended to this elliptic eigenvalue problem (Jost, 2002).
Other examples.
The Schrödinger equation is a PDE at the heart of non-relativistic quantum mechanics. In the WKB approximation it is the Hamilton–Jacobi equation.
Except for the Dym equation and the Ginzburg–Landau equation, the above equations are linear in the sense that they can be written in the form "Au" = "f" for a given linear operator "A" and a given function "f". Other important non-linear equations include the Navier–Stokes equations describing the flow of fluids, and Einstein's field equations of general relativity.
Also see the list of non-linear partial differential equations.
Classification.
Some linear, second-order partial differential equations can be classified as parabolic, hyperbolic and elliptic. Others such as the Euler–Tricomi equation have different types in different regions. The classification provides a guide to appropriate initial and boundary conditions, and to smoothness of the solutions.
Equations of second order.
Assuming formula_60, the general second-order PDE in two independent variables has the form
where the coefficients "A", "B", "C" etc. may depend upon "x" and "y". If formula_62 over a region of the xy plane, the PDE is second-order in that region. This form is analogous to the equation for a conic section:
More precisely, replacing ∂"x" by "X", and likewise for other variables (formally this is done by a Fourier transform), converts a constant-coefficient PDE into a polynomial of the same degree, with the top degree (a homogeneous polynomial, here a quadratic form) being most significant for the classification.
Just as one classifies conic sections and quadratic forms into parabolic, hyperbolic, and elliptic based on the discriminant formula_64, the same can be done for a second-order PDE at a given point. However, the discriminant in a PDE is given by formula_65 due to the convention of the "xy" term being 2"B" rather than "B"; formally, the discriminant (of the associated quadratic form) is formula_66 with the factor of 4 dropped for simplicity.
If there are "n" independent variables "x"1, "x"2 , ..., "x""n", a general linear partial differential equation of second order has the form
The classification depends upon the signature of the eigenvalues of the coefficient matrix "ai,j"..
Systems of first-order equations and characteristic surfaces.
The classification of partial differential equations can be extended to systems of first-order equations, where the unknown "u" is now a vector with "m" components, and the coefficient matrices "A"ν are "m" by "m" matrices for ν = 1, ..., "n". The partial differential equation takes the form
where the coefficient matrices "A"ν and the vector "B" may depend upon "x" and "u". If a hypersurface "S" is given in the implicit form
where φ has a non-zero gradient, then "S" is a characteristic surface for the operator "L" at a given point if the characteristic form vanishes:
The geometric interpretation of this condition is as follows: if data for "u" are prescribed on the surface "S", then it may be possible to determine the normal derivative of "u" on "S" from the differential equation. If the data on "S" and the differential equation determine the normal derivative of "u" on "S", then "S" is non-characteristic. If the data on "S" and the differential equation "do not" determine the normal derivative of "u" on "S", then the surface is characteristic, and the differential equation restricts the data on "S": the differential equation is "internal" to "S".
has "m" real roots λ1, λ2, ..., λ"m". The system is strictly hyperbolic if these roots are always distinct. The geometrical interpretation of this condition is as follows: the characteristic form "Q"(ζ) = 0 defines a cone (the normal cone) with homogeneous coordinates ζ. In the hyperbolic case, this cone has "m" sheets, and the axis ζ = λ ξ runs inside these sheets: it does not intersect any of them. But when displaced from the origin by η, this axis intersects every sheet. In the elliptic case, the normal cone has no real sheets.
Equations of mixed type.
If a PDE has coefficients that are not constant, it is possible that it will not belong to any of these categories but rather be of mixed type. A simple but important example is the Euler–Tricomi equation
which is called elliptic-hyperbolic because it is elliptic in the region "x" < 0, hyperbolic in the region "x" > 0, and degenerate parabolic on the line "x" = 0.
Infinite-order PDEs in quantum mechanics.
Weyl quantization in phase space leads to quantum Hamilton's equations for trajectories of quantum particles. Those equations are infinite-order PDEs. However, in the semiclassical expansion one has a finite system of ODEs at any fixed order of formula_76. The equation of evolution of the Wigner function is infinite-order PDE also. The quantum trajectories are quantum characteristics with the use of which one can calculate the evolution of the Wigner function.
Analytical methods to solve PDEs.
Separation of variables.
Linear PDEs can be reduced to systems of ordinary differential equations by the important technique of separation of variables. This technique rests on a characteristic of solutions to differential equations: if one can ﬁnd any solution that solves the equation and satisﬁes the boundary conditions, then it is "the" solution (this also applies to ODEs). We assume as an ansatz that the dependence of a solution on the parameters space and time can be written as a product of terms that each depend on a single parameter, and then see if this can be made to solve the problem.
In the method of separation of variables, one reduces a PDE to a PDE in fewer variables, which is an ordinary differential equation if in one variable – these are in turn easier to solve.
This is possible for simple PDEs, which are called separable partial differential equations, and the domain is generally a rectangle (a product of intervals). Separable PDEs correspond to diagonal matrices – thinking of "the value for fixed "x"" as a coordinate, each coordinate can be understood separately.
This generalizes to the method of characteristics, and is also used in integral transforms.
Method of characteristics.
In special cases, one can find characteristic curves on which the equation reduces to an ODE – changing coordinates in the domain to straighten these curves allows separation of variables, and is called the method of characteristics.
More generally, one may find characteristic surfaces.
Integral transform.
An integral transform may transform the PDE to a simpler one, in particular a separable PDE. This corresponds to diagonalizing an operator.
An important example of this is Fourier analysis, which diagonalizes the heat equation using the eigenbasis of sinusoidal waves.
If the domain is finite or periodic, an infinite sum of solutions such as a Fourier series is appropriate, but an integral of solutions such as a Fourier integral is generally required for infinite domains. The solution for a point source for the heat equation given above is an example for use of a Fourier integral.
Change of variables.
Often a PDE can be reduced to a simpler form with a known solution by a suitable change of variables. For example the Black–Scholes PDE
is reducible to the heat equation
by the change of variables (for complete details see at the Wayback Machine (archived ))
Fundamental solution.
Inhomogeneous equations can often be solved (for constant coefficient PDEs, always be solved) by finding the fundamental solution (the solution for a point source), then taking the convolution with the boundary conditions to get the solution.
This is analogous in signal processing to understanding a filter by its impulse response.
Superposition principle.
Because any superposition of solutions of a linear, homogeneous PDE is again a solution, the particular solutions may then be combined to obtain more general solutions.
if u1 and u2 are solutions of a homogeneous linear pde in same region R, then u= c1u1+c2u2
with any constants c1 and c2 is also a solution of that pde in that same region...
Methods for non-linear equations.
There are no generally applicable methods to solve non-linear PDEs. Still, existence and uniqueness results (such as the Cauchy–Kowalevski theorem) are often possible, as are proofs of important qualitative and quantitative properties of solutions (getting these results is a major part of analysis). Computational solution to the nonlinear PDEs, the split-step method, exist for specific equations like nonlinear Schrödinger equation.
Nevertheless, some techniques can be used for several types of equations. The h-principle is the most powerful method to solve underdetermined equations. The Riquier–Janet theory is an effective method for obtaining information about many analytic overdetermined systems.
The method of characteristics (similarity transformation method) can be used in some very special cases to solve partial differential equations.
In some cases, a PDE can be solved via perturbation analysis in which the solution is considered to be a correction to an equation with a known solution. Alternatives are numerical analysis techniques from simple finite difference schemes to the more mature multigrid and finite element methods. Many interesting problems in science and engineering are solved in this way using computers, sometimes high performance supercomputers.
Lie group method.
From 1870 Sophus Lie's work put the theory of differential equations on a more satisfactory foundation. He showed that the integration theories of the older mathematicians can, by the introduction of what are now called Lie groups, be referred to a common source; and that ordinary differential equations which admit the same infinitesimal transformations present comparable difficulties of integration. He also emphasized the subject of transformations of contact.
A general approach to solve PDE's uses the symmetry property of differential equations, the continuous infinitesimal transformations of solutions to solutions (Lie theory). Continuous group theory, Lie algebras and differential geometry are used to understand the structure of linear and nonlinear partial differential equations for generating integrable equations, to find its Lax pairs, recursion operators, Bäcklund transform and finally finding exact analytic solutions to the PDE.
Symmetry methods have been recognized to study differential equations arising in mathematics, physics, engineering, and many other disciplines.
Semianalytical methods.
The adomian decomposition method, the Lyapunov artificial small parameter method, and He's homotopy perturbation method are all special cases of the more general homotopy analysis method. These are series expansion methods, and except for the Lyapunov method, are independent of small physical parameters as compared to the well known perturbation theory, thus giving these methods greater flexibility and solution generality.
Numerical methods to solve PDEs.
The three most widely used numerical methods to solve PDEs are the finite element method (FEM), finite volume methods (FVM) and finite difference methods (FDM). The FEM has a prominent position among these methods and especially its exceptionally efficient higher-order version hp-FEM. Other versions of FEM include the generalized finite element method (GFEM), extended finite element method (XFEM), spectral finite element method (SFEM), meshfree finite element method, discontinuous Galerkin finite element method (DGFEM), Element-Free Galerkin Method (EFGM), Interpolating Element-Free Galerkin Method (IEFGM), etc.
Finite element method.
The finite element method (FEM) (its practical application often known as finite element analysis (FEA)) is a numerical technique for finding approximate solutions of partial differential equations (PDE) as well as of integral equations. The solution approach is based either on eliminating the differential equation completely (steady state problems), or rendering the PDE into an approximating system of ordinary differential equations, which are then numerically integrated using standard techniques such as Euler's method, Runge–Kutta, etc.
Finite difference method.
Finite-difference methods are numerical methods for approximating the solutions to differential equations using finite difference equations to approximate derivatives.
Finite volume method.
Similar to the finite difference method or finite element method, values are calculated at discrete places on a meshed geometry. "Finite volume" refers to the small volume surrounding each node point on a mesh. In the finite volume method, surface integrals in a partial differential equation that contain a divergence term are converted to volume integrals, using the Divergence theorem. These terms are then evaluated as fluxes at the surfaces of each finite volume. Because the flux entering a given volume is identical to that leaving the adjacent volume, these methods are conservative.

</doc>
<doc id="52565" url="http://en.wikipedia.org/wiki?curid=52565" title="Partial derivative">
Partial derivative

In mathematics, a partial derivative of a function of several variables is its derivative with respect to one of those variables, with the others held constant (as opposed to the total derivative, in which all variables are allowed to vary). Partial derivatives are used in vector calculus and differential geometry.
The partial derivative of a function "f"("x", "y", ...) with respect to the variable "x" is variously denoted by
Since in general a partial derivative is a function of the same arguments as was the original function, this functional dependence is sometimes explicitly included in the notation, as in
The partial-derivative symbol is ∂. One of the first known uses of the symbol in mathematics is by Marquis de Condorcet from 1770, who used it for partial differences. The modern partial derivative notation is by Adrien-Marie Legendre (1786), though he later abandoned it; Carl Gustav Jacob Jacobi re-introduced the symbol in 1841.
Introduction.
Suppose that "ƒ" is a function of more than one variable. For instance,
The graph of this function defines a surface in Euclidean space. To every point on this surface, there are an infinite number of tangent lines. Partial differentiation is the act of choosing one of these lines and finding its slope. Usually, the lines of most interest are those that are parallel to the "xz"-plane, and those that are parallel to the "yz"-plane (which result from holding either y or x constant, respectively.)
To find the slope of the line tangent to the function at P(1, 1, 3) that is parallel to the "xz"-plane, the "y" variable is treated as constant. The graph and this plane are shown on the right. On the graph below it, we see the way the function looks on the plane . By finding the derivative of the equation while assuming that "y" is a constant, the slope of "ƒ" at the point ("x", "y", "z") is found to be:
So at (1, 1, 3), by substitution, the slope is 3. Therefore
at the point (1, 1, 3). That is, the partial derivative of "z" with respect to "x" at (1, 1, 3) is 3, as shown in the graph.
Definition.
Basic definition.
The function "f" can be reinterpreted as a family of functions of one variable indexed by the other variables:
In other words, every value of "y" defines a function, denoted "fy", which is a function of one variable "x". That is,
Once a value of "y" is chosen, say "a", then "f"("x","y") determines a function "fa" which traces a curve "x"2 + "ax" + "a"2 on the xz plane:
In this expression, "a" is a "constant", not a "variable", so "fa" is a function of only one real variable, that being "x". Consequently, the definition of the derivative for a function of one variable applies:
The above procedure can be performed for any choice of "a". Assembling the derivatives together into a function gives a function which describes the variation of "f" in the "x" direction:
This is the partial derivative of "f" with respect to "x". Here ∂ is a rounded "d" called the partial derivative symbol. To distinguish it from the letter "d", ∂ is sometimes pronounced "del" or "partial" instead of "dee".
In general, the partial derivative of a function "f"("x"1...,"x""n") in the direction "xi" at the point ("a"1...,"an") is defined to be:
In the above difference quotient, all the variables except "xi" are held fixed. That choice of fixed values determines a function of one variable formula_12, and by definition,
In other words, the different choices of "a" index a family of one-variable functions just as in the example above. This expression also shows that the computation of partial derivatives reduces to the computation of one-variable derivatives.
An important example of a function of several variables is the case of a scalar-valued function "f"("x"1..."x""n") on a domain in Euclidean space formula_14 (e.g., on formula_15 or formula_16). In this case "f" has a partial derivative ∂"f"/∂"x""j" with respect to each variable "x""j". At the point "a", these partial derivatives define the vector
This vector is called the gradient of "f" at "a". If "f" is differentiable at every point in some domain, then the gradient is a vector-valued function ∇"f" which takes the point "a" to the vector ∇"f"("a"). Consequently, the gradient produces a vector field.
A common abuse of notation is to define the del operator (∇) as follows in three-dimensional Euclidean space formula_16 with unit vectors formula_19:
Or, more generally, for "n"-dimensional Euclidean space formula_14 with coordinates (x1, x2, x3...,x"n") and unit vectors (formula_22):
Formal definition.
Like ordinary derivatives, the partial derivative is defined as a limit. Let "U" be an open subset of R"n" and "f" : "U" → R a function. The partial derivative of "f" at the point a = ("a"1, ..., "a""n") ∈ "U" with respect to the "i"-th variable "a""i" is defined as
Even if all partial derivatives ∂"f"/∂"a""i"("a") exist at a given point "a", the function need not be continuous there. However, if all partial derivatives exist in a neighborhood of "a" and are continuous there, then "f" is totally differentiable in that neighborhood and the total derivative is continuous. In this case, it is said that "f" is a C1 function. This can be used to generalize for vector valued functions ("f" : "U" → "R"'"m") by carefully using a componentwise argument.
The partial derivative formula_25 can be seen as another function defined on "U" and can again be partially differentiated. If all mixed second order partial derivatives are continuous at a point (or on a set), "f" is termed a C2 function at that point (or on that set); in this case, the partial derivatives can be exchanged by Clairaut's theorem:
Examples.
Geometry.
The volume "V" of a cone depends on the cone's height "h" and its radius "r" according to the formula
The partial derivative of "V" with respect to "r" is
which represents the rate with which a cone's volume changes if its radius is varied and its height is kept constant. The partial derivative with respect to "h" is
which represents the rate with which the volume changes if its height is varied and its radius is kept constant.
By contrast, the "total" derivative of "V" with respect to "r" and "h" are respectively
and
The difference between the total and partial derivative is the elimination of indirect dependencies between variables in partial derivatives.
If (for some arbitrary reason) the cone's proportions have to stay the same, and the height and radius are in a fixed ratio "k",
This gives the total derivative with respect to "r":
which simplifies to:
Similarly, the total derivative with respect to "h" is:
The total derivative with respect to "both" r and h of the volume intended as scalar function of these two variables is given by the gradient vector formula_36.
Optimization.
Partial derivatives appear in any calculus-based optimization problem with more than one choice variable. For example, in economics a firm may wish to maximize profit π("x", "y") with respect to the choice of the quantities "x" and "y" of two different types of output. The first order conditions for this optimization are π"x" = 0 = π"y". Since both partial derivatives π"x" and π"y" will generally themselves be functions of both arguments "x" and "y", these two first order conditions form a system of two equations in two unknowns.
Science and engineering.
Equations involving an unknown function's partial derivatives are called partial differential equations. These equations are used to mathematically approximate many physical phenomena like fluid flows, force in a spring, nerve conduction and are frequently encountered in physics, engineering, and other sciences and applied disciplines.
Economics.
Partial derivatives play a prominent role in economics, in which most functions describing economic behavior posit that the behavior depends on more than one variable. For example, a societal consumption function may describe the amount spent on consumer goods as depending on both income and wealth; the marginal propensity to consume is then the partial derivative of the consumption function with respect to income.
Notation.
For the following examples, let "f" be a function in "x", "y" and "z".
First-order partial derivatives:
Second-order partial derivatives:
Second-order mixed derivatives:
Higher-order partial and mixed derivatives:
When dealing with functions of multiple variables, some of these variables may be related to each other, and it may be necessary to specify explicitly which variables are being held constant. In fields such as statistical mechanics, the partial derivative of "f" with respect to "x", holding "y" and "z" constant, is often expressed as
Antiderivative analogue.
There is a concept for partial derivatives that is analogous to antiderivatives for regular derivatives. Given a partial derivative, it allows for the partial recovery of the original function.
Consider the example of formula_4. The "partial" integral can be taken with respect to "x" (treating "y" as constant, in a similar manner to partial differentiation):
Here, the "constant" of integration is no longer a constant, but instead a function of all the variables of the original function except "x". The reason for this is that all the other variables are treated as constant when taking the partial derivative, so any function which does not involve formula_44 will disappear when taking the partial derivative, and we have to account for this when we take the antiderivative. The most general way to represent this is to have the "constant" represent an unknown function of all the other variables.
Thus the set of functions formula_45, where "g" is any one-argument function, represents the entire set of functions in variables "x","y" that could have produced the "x"-partial derivative 2"x"+"y".
If all the partial derivatives of a function are known (for example, with the gradient), then the antiderivatives can be matched via the above process to reconstruct the original function up to a constant.
Higher order partial derivatives.
Second and higher order partial derivatives are defined analogously to the higher order derivatives of univariate functions. For the function formula_46 the "own" second partial derivative with respect to "x" is simply the partial derivative of the partial derivative (both with respect to "x")::316–318
The cross partial derivative with respect to "x" and "y" is obtained by taking the partial derivative of "f" with respect to "x", and then taking the partial derivative of the result with respect to "y", to obtain
Schwarz' theorem states that if the second derivatives are continuous the expression for the cross partial derivative is unaffected by which variable the partial derivative is taken with respect to first and which is taken second. That is,
or equivalently formula_50
Own and cross partial derivatives appear in the Hessian matrix which is used in the second order conditions in optimization problems.

</doc>
<doc id="52566" url="http://en.wikipedia.org/wiki?curid=52566" title="John Goldsmith">
John Goldsmith

John Anton Goldsmith (born 1951) is the Edward Carson Waller Distinguished Service Professor at the University of Chicago, with appointments in Linguistics and Computer Science. He was educated at Swarthmore College, where he obtained his B.A. in 1972, and at MIT, where he completed his Ph.D. in Linguistics under Morris Halle in 1976. He was on the faculty at the Department of Linguistics at Indiana University, before joining the University of Chicago in 1984. He has also taught at the LSA Linguistic Institutes and has held visiting appointments at McGill, Harvard, and UCSD, among others. In 2007, Goldsmith was elected a Fellow of the American Academy of Arts and Sciences.
Goldsmith's research ranges from phonology to computational linguistics. His Ph.D thesis introduced autosegmental phonology, which regards phonological phenomena as a collection of parallel tiers with individual segments representing certain features of speech. His recent research deals with unsupervised learning of linguistic structure (particularly exemplified by his Linguistica project, a body of software which attempts to automatically analyze the morphology of a language), as well as in extending computational linguistics algorithms to bioinformatics. Programs that implement his research in CL include 'SweetTalker', a rule-based intonation system, 'Babylon', a trainable language identification system, and 'AutoMorphology'/'WinAutomorphology', an automatic morphological analyzer.

</doc>
<doc id="52567" url="http://en.wikipedia.org/wiki?curid=52567" title="Autosegmental phonology">
Autosegmental phonology

Autosegmental phonology is the name of a framework of phonological analysis proposed by John Goldsmith in his PhD thesis in 1976 at the Massachusetts Institute of Technology 
(MIT).
As a theory of phonological representation, autosegmental phonology developed a formal account of ideas that had been sketched in earlier work by several linguists, notably Bernard Bloch (1948), Charles Hockett (1955) and J. R. Firth (1948). On such a view, phonological representations consist of more than one linear sequence of segments; each linear sequence constitutes a separate tier. The co-registration of elements (or "autosegments") on one tier with those on another is represented by association lines. There is a close relationship between analysis of segments into distinctive features and an autosegmental analysis; each feature in a language appears on exactly one tier. 
The working hypothesis of autosegmental analysis is that a large part of phonological generalizations can be interpreted as a restructuring or reorganization of the autosegments in a representation. Clear examples of the usefulness of autosegmental analysis came in early work from the detailed study of African tone languages, as well as the study of vowel and nasal harmony systems. A few years later, John McCarthy proposed an important development by showing that the derivation of words from consonantal roots in Arabic could be analyzed autosegmentally.
In the first decade of the development of the theory, G. N. Clements developed a number of influential aspects of the theory involving harmonic processes, especially vowel harmony and nasal harmony, and John McCarthy generalized the theory to deal with the conjugational system of classical Arabic, on the basis of an autosegmental account of vowel and consonant slots on a central timing tier (see also nonconcatenative morphology).
Structure of autosegmental rules.
The autosegmental formalism departs from the depiction of segments as matrices of features in order to show segments as connected groups of individual features. Segments are depicted through vertical listings of features connected by lines. These sets can also underspecify in order to indicate a class rather than a single segment. Environments can be shown by placing other connected sets of features around that which is the focus of the rule. Feature changes are shown by striking through the lines that connect a feature that is lost to the rest of the segment and drawing dotted lines to features that are gained.
Distinctive features.
Rather than classify segments using the categories given in the International Phonetic Alphabet, the autosegmental formalism makes use of distinctive features, which provide greater granularity and make identification of natural classes easier. A segment is identified by a +/- dichotomy of a series of binary features, some of which are subfeatures of unary features (place of articulation, in particular, is identified by unary features indicating the active articulator, and binary subfeatures that distinguish further). For example, [p], the voiceless bilabial stop, is indicated [-sonorant, -continuant, -voice, labial], and the set of voiced coronal stops can be indicated [-sonorant, -continuant, +voice, coronal].
Feature dependencies.
For unary features to be fully specified, it is necessary to include binary subfeatures that correspond to them. In the autosegmental formalism, this is depicted by placing the binary subfeature at a horizontal offset from the unary feature and connecting them with a line. The next top-level feature in the segment would then be connected to the unary feature as well as opposed to the subfeature.
Functional groupings.
There are situations in which the rule applies not to a particular value of a feature, but to whatever value the feature has. In these situations, it is necessary to include the presence of the feature, but not to specify its value. This can be done by including a placeholder feature composed of ellipses, with an indication of the type of feature. For example, a generic place feature can be indicated [...]P.
Tiers.
The autosegmental formalism deals with several separate linear sequences; because of this, a phonological representation is depicted on several distinct tiers. Each of these tiers shows a different language feature.
Segmental tier.
The segmental tier contains the features that define the segments articulated in the phonological representation. The descriptions given in the previous section deal with the segmental tier. In the segmental tier, features are assigned to segments.
Timing tier.
The timing tier contains timing units that define the lengths of segments in the phonological representation. These timing units are commonly depicted as X's, and are assigned to segments.
Stress tier.
The stress tier contains the features that show the distribution of stress in the phonological representation. The features in the stress tier are [+/– stress] and [+/– main], and they are assigned to the stress-bearing units of the language (syllables or moras).
Tone tier.
The tone tier contains the features that show the distribution of tones in the phonological representation. The features in the tone tier are [+/– high pitch] and [+/– low pitch], and they are assigned to the tone-bearing units of the language (syllables or moras).
Well-Formedness Condition.
As a theory of the dynamic of phonological representations, autosegmental phonology includes a Well-formedness Condition on association lines (each element on one tier that "may" be associated to an element on another tier "must" be associated to such an element, and association lines do not cross) plus an instruction as to what to do in case of a violation of the Well-formedness Condition: add or delete the minimum number of association lines in order to maximally satisfy it. Many of the most interesting predictions of the autosegmental model derive from the automatic effects of the Well-formedness Condition and their independence of language-particular rules.
Examples.
Place assimilation in nasals.
The autosegmental formalism can be especially useful in describing assimilation rules. Using it for such rules makes the relationship between the result of the rule and the environment obvious. It also makes it possible to concisely describe rules that apply to different environments in different ways.
The phenomenon whereby /ɪn/ goes to [ɪn] in such words as <intractable> and <indestructible>, [ɪŋ] in such words as <ingrate> and <incapacitate>, and [ɪm] in such words as <impossible> and <implausible> can be represented in the autosegmental formalism. The rule is that a coronal nasal will assimilate to the place of the following consonant. The nasal is depicted by [+nasal] connected to a [coronal]P, and the consonant is depicted to the nasal's right as [...]P. No more specification is necessary because place is the only feature of the following segment that factors into the rule. The assimilation is shown by striking through the line to [coronal]P on the left and drawing a dotted line to the [...]P on the right.

</doc>
<doc id="52568" url="http://en.wikipedia.org/wiki?curid=52568" title="Agent">
Agent

Agent may refer to:

</doc>
<doc id="52569" url="http://en.wikipedia.org/wiki?curid=52569" title="Lamp (electrical component)">
Lamp (electrical component)

A lamp is a replaceable component that produces light from electricity. Compact lamps are commonly called light bulbs, for example the incandescent light bulb. Lamps usually have a base made of ceramic, metal, glass or plastic, which secures the lamp in the socket of a light fixture. The electrical connection to the socket may be made with a screw-thread base, two metal pins, two metal caps or a bayonet cap.
Types.
There are several types of lamp:
Uses other than illumination.
Lamps can be used as heat sources, for example in incubators and toys such as the Easy-Bake Oven.
Filament lamps have long been used as fast acting thermistors in electronic circuits. The filaments are most likely made out of tungsten. Popular uses have included:
Lamp circuit symbols.
In circuit diagrams lamps usually are shown as symbols. There are two main types of symbols, these are:

</doc>
<doc id="52570" url="http://en.wikipedia.org/wiki?curid=52570" title="Igbo language">
Igbo language

Igbo (; archaically Ibo ) (Igbo: "Asụsụ Igbo"), is the principal native language of the Igbo people, an ethnic group of southeastern Nigeria. There are approximately 24 million speakers, who live mostly in Nigeria and are primarily of Igbo descent. Igbo is written in the Latin script, which was introduced by British colonialists.
There are over 20 Igbo dialects. There is apparently a degree of dialect leveling occurring. A standard literary language was developed in 1972 based on the Owerri (Isuama) and Umuahia (such as Ohuhu) dialects, though it omits the nasalization and aspiration of those varieties. There are related Igboid languages as well that are sometimes considered dialects of Igbo, the most divergent being Ekpeye. Some of these, such as Ika, have separate standard forms. Igbo is also a recognised minority language of Equatorial Guinea.
History.
The first book to publish Igbo words was "History of the Mission of the Evangelical Brothers in the Caribbean" (German: "Geschichte der Mission der Evangelischen Brüder auf den Carabischen Inseln"), published in 1777.  Shortly afterwards in 1789, "The Interesting Narrative of the Life of Olaudah Equiano" was published in London, England, written by Olaudah Equiano, a former slave, featuring 79 Igbo words.  The narrative also illustrated various aspects of Igbo life based in detail, based on Olaudah Equiano's experiences in his hometown of Essaka.
Central Igbo, the dialect form gaining widest acceptance, is based on the dialects of two members of the Ezinihitte group of Igbo in Central Owerri Province between the towns of Owerri and Umuahia, Eastern Nigeria. From its proposal as a literary form in 1939 by Dr. Ida C. Ward, it was gradually accepted by missionaries, writers, and publishers across the region. In 1972, the Society for Promoting Igbo Language and Culture (SPILC), a nationalist organisation which saw Central Igbo as an imperialist exercise, set up a Standardisation Committee to extend Central Igbo to be a more inclusive language. Standard Igbo aims to cross-pollinate Central Igbo with words from Igbo dialects from outside the "Central" areas, and with the adoption of loan words.
Vocabulary.
Igbo has an extremely limited number of adjectives in a closed class. Emenanjo (1978) counts just eight: "ukwu" 'big', "nta" 'small'; "oji" 'dark', "ọcha" 'light'; "ọhụrụ" 'new', "ochie" 'old'; "ọma" 'good'; "ọjọọ" 'bad'. (Payne 1990)
Many names in Igbo are actually fusions of older original words and phrases. For example, one Igbo word for vegetable leaves is "akwụkwọ nri", which literally means "leaves for eating" or "vegetables". Green leaves are called "akwụkwọ ndụ", because "ndụ" means "life". Another example is train ("ụgbọ igwe"), which comes from the words "ụgbọ" (vehicle, craft) and "igwe" (iron, metal); thus a locomotive train is vehicle via iron (rails); a car, "ụgbọ ala"; vehicle via land and an aeroplane "ụgbọ elu"; "vehicle via air".
Words may also take on multiple meanings. Take for example the word "akwụkwọ". "Akwụkwọ" originally means "leaf" (as on a tree), but during and after the colonization period, "akwụkwọ" also came to be linked to "paper," "book," "school," and "education", to become respectively "akwụkwọ édémédé", "akwụkwọ ọgụgụ", "ụlọ akwụkwọ", "mmụta akwụkwọ". This is because printed paper can be first linked to an organic leaf, and then the paper to a book, the book to a school, and so on. Combined with other words, "akwụkwọ" can take on many forms; for example, "akwụkwọ ego" means "printed money" or "bank notes," and "akwụkwọ ejị éjé njem" means "passport."
Proverbs.
Proverbs and idiomatic (ilu in Igbo) expressions are highly valued by the Igbo people and proficiency in the language means knowing how to intersperse speech with a good dose of proverbs. Chinua Achebe (in "Things Fall Apart") describes proverbs as "the palm oil with which words are eaten". Proverbs are widely used in the traditional society to describe, in very few words, what could have otherwise required a thousand words. Proverbs may also become euphemistic means of making certain expressions in the Igbo society, thus the Igbo have come to typically rely on this as avenues of certain expressions.
Phonology.
Igbo is a tonal language with two distinctive tones, high and low. In some cases a third, downstepped high tone is recognized. The language's tone system was given by John Goldsmith as an example of suprasegmental phenomena that go beyond the linear model of phonology laid out in "The Sound Pattern of English". Igbo words may differ only in tone. An example is "ákwá" "cry", "àkwà" "bed", "àkwá" "egg", and "ákwà" "cloth". As tone is not normally written, these all appear as ⟨akwa⟩ in print.
The language features vowel harmony with two sets of oral vowels distinguished by pharyngeal cavity size described in terms of retracted tongue root (RTR). These vowels also occupy different places in vowel space: [i ɪ̙ e a u ʊ̙ o ɒ̙] (the last commonly transcribed [ɔ̙], in keeping with neighboring languages). For simplicity, phonemic transcriptions typically choose only one of these parameters to be distinctive, either RTR as in the chart at right and Igbo orthography (that is, as /i i̙ e a u u̙ o o̙/), or vowel space as in the alphabetic chart below (that is, as /i ɪ e a u ʊ o ɔ/). There are also nasal vowels.
Adjacent vowels usually undergo assimilation during speech. The sound of a preceding vowel, usually at the end of one word, merges in a rapid transition to the sound of the following vowel, particularly at the start of another word, giving the second vowel greater prominence in speech. Usually the first vowel (in the first word) is only slightly identifiable to listeners, usually undergoing centralisation. /Kà ó mésyá/, for example, becomes /kòó mésyá/ "goodbye". An exception to this assimilation may be with words ending in /a/ such as /nà/ in /nà àlà/, "on the ground", which could be completely assimilated leaving /n/ in rapid speech, as in "nàlà" or "n'àlà". In other dialects however, the instance of /a/ such as in "nà" in /ọ́ nà èrí ńrí/, "he/she/it is eating", results in a long vowel, /ọ́ nèèrí ńrí/.
Igbo does not have a contrast among voiced occlusives (between voiced stops and nasals): the one precedes oral vowels, and the other nasal vowels. Only a limited number of consonants occur before nasal vowels, including /f, z, s/.
In some dialects, such as Enu-Onitsha Igbo, the doubly articulated /ɡ͡b/ and /k͡p/ are realized as a voiced/devoiced bilabial implosive. The approximant /ɹ/ is realized as an alveolar tap [ɾ] between vowels as in "árá". The Enu-Onitsha Igbo dialect is very much similar to Enuani spoken among the Igbo-Anioma people in Delta State.
To illustrate the effect of phonological analysis, the following inventory of a typical Central dialect is taken from Clark (1990). Nasality has been analyzed as a feature of consonants, rather than vowels, avoiding the problem of why so few consonants occur before nasal vowels; [CjV] has also been analyzed as /CʲV/.
Syllables are of the form (C)V (optional consonant, vowel) or N (a syllabic nasal). CV is the most common syllable type. Every syllable bears a tone. Consonant clusters do not occur. The semivowels /j/ and /w/ can occur between consonant and vowel in some syllables. The semi-vowel in /CjV/ is analyzed as an underlying vowel "ị", so that "-bịa" is the phonemic form of "bjá" 'come'. On the other hand, "w" in /CwV/ is analyzed as an instance of labialization; so the phonemic form of the verb "-gwá" "tell" is /-ɡʷá/.
Writing system.
The Igbo people have long used Nsibidi ideograms, invented by the neighboring Ekoi people, for basic written communication. They have been used since at least the 16th century, but died out publicly after they became popular amongst secret societies such as the Ekpe, who used them as a secret form of communication. Nsibidi, however, is not a full writing system, because it cannot transcribe the Igbo language specifically. In 1960 a rural land owner and dibia named Nwagu Aneke developed a syllabary for the Umuleri dialect of Igbo, the script, named after him as the Nwagu Aneke script, was used to write hundred of diary entires until Aneke's death in 1991. The Nwagu Aneke Project is working on translating Nwagu's commentary and diary.
The wide variety of spoken dialects has made agreement on a standardize orthography of Igbo difficult. The current "Ọ́nwụ́" (/oŋwu/) alphabet, a compromise between the older Lepsius alphabet and a newer alphabet advocated by the International Institute of African Languages and Cultures (IIALC), was agreed to in 1962. It is presented in the following table, with the International Phonetic Alphabet equivalents for the characters:
The graphemes ⟨gb⟩ and ⟨kp⟩ are described both as coarticulated /ɡ͡b/ and /k͡p/ and as implosives, so both values are included in the table.
⟨m⟩ and ⟨n⟩ each represent two phonemes: a nasal consonant and a syllabic nasal.
Tones are sometimes indicated in writing, and sometimes not. When tone is indicated, low tones are shown with a grave accent over the vowel, for example ⟨a⟩ → ⟨à⟩, and high tones with an acute accent over the vowel, for example ⟨a⟩ → ⟨á⟩.
Usage in the diaspora.
As a consequence of the Atlantic slave trade, the Igbo language was spread by enslaved Igbo people throughout slave colonies in the Americas. These colonies include the United States, Dominican Republic, Jamaica, Belize, Barbados, and the Bahamas. Examples can be found in Jamaican Patois: the pronoun /unu/, used for 'you (plural)', is taken from Igbo, "Red eboe" refers to a fair-skinned black person because of the reported account of a fair or yellowish skin tone among the Igbo. "Soso" meaning "only" comes from Igbo.
The word "Bim", a name for Barbados, was commonly used by enslaved Barbadians (Bajans). This word is said to derive from the Igbo language, derived from "bi mu" (or either "bem", "Ndi bem", "Nwanyi ibem" or "Nwoke ibem") (English: My people), but it may have other origins (see: Barbados etymology).

</doc>
<doc id="52571" url="http://en.wikipedia.org/wiki?curid=52571" title="Halogen lamp">
Halogen lamp

A halogen lamp, also known as a tungsten halogen, quartz-halogen or quartz iodine lamp, is an incandescent lamp that has a small amount of a halogen such as iodine or bromine added. The combination of the halogen gas and the tungsten filament produces a halogen cycle chemical reaction which redeposits evaporated tungsten back onto the filament, increasing its life and maintaining the clarity of the envelope. Because of this, a halogen lamp can be operated at a higher temperature than a standard gas-filled lamp of similar power and operating life, producing light of a higher luminous efficacy and color temperature. The small size of halogen lamps permits their use in compact optical systems for projectors and illumination.
History.
A carbon filament lamp using chlorine to prevent darkening of the envelope was patented in 1882, and chlorine-filled "NoVak" lamps were marketed in 1892. The use of iodine was proposed in a 1933 patent, which also described the cyclic redeposition of tungsten back onto the filament. In 1959, General Electric patented a practical lamp using iodine.
Halogen cycle.
In ordinary incandescent lamps, evaporated tungsten mostly deposits onto the inner surface of the bulb, causing the bulb to blacken and the filament to grow increasingly weak until it eventually breaks. The halogen, however, sets up a reversible chemical reaction cycle with this evaporated tungsten. The halogen cycle keeps the bulb clean and causes the light output to remain almost constant throughout the bulb's life. At moderate temperatures the halogen reacts with the evaporating tungsten, the halide formed being moved around in the inert gas filling. At some point, however, it will reach higher temperature regions within the bulb where it then dissociates, releasing tungsten back onto the filament and freeing the halogen to repeat the process. The overall bulb envelope temperature must be significantly higher than in conventional incandescent lamps for this reaction to succeed, however.
The bulb must be made of fused silica (quartz) or a high-melting-point glass (such as aluminosilicate glass). Since quartz is very strong, the gas pressure can be higher, which reduces the rate of evaporation of the filament, permitting it to run a higher temperature (and so luminous efficacy) for the same average life. The tungsten released in hotter regions does not generally redeposit where it came from, so the hotter parts of the filament eventually thin out and fail.
Quartz iodine lamps, using elemental iodine, were the first commercial halogen lamps launched by GE in 1959. Quite soon, bromine was found to have advantages, but was not used in elemental form. Certain hydrocarbon bromine compounds gave good results. Regeneration of the filament is also possible with fluorine, but its chemical reactivity is so great that other parts of the lamp are attacked. The halogen is normally mixed with a noble gas, often krypton or xenon. The first lamps used only tungsten for filament supports, but some designs use molybdenum — an example being the molybdenum shield in the H4 twin filament headlight for the European Asymmetric Passing Beam.
For a fixed power and life, the luminous efficacy of all incandescent lamps is greatest at a particular design voltage. Halogen lamps made for 12 to 24 volt operation have good light outputs, and the very compact filaments are particularly beneficial for optical control (see picture). The range of multifaceted reflector "MR" lamps of 20-50 watts were originally conceived for the projection of 8 mm film, but are now widely used for display lighting and in the home. More recently, wider beam versions have become available designed for direct use on supply voltages of 120 or 230 V.
Effect of voltage on performance.
Tungsten halogen lamps behave in a similar manner to other incandescent lamps when run on a different voltage. However the light output is reported as proportional to formula_1, and the luminous efficacy proportional to formula_2. The normal relationship regarding the lifetime is that it is proportional to formula_3. For example, a bulb operated at 5% higher than its design voltage would produce about 15% more light, and the luminous efficacy would be about 6.5% higher, but would be expected to have only half the rated life.
Halogen lamps are manufactured with enough halogen to match the rate of tungsten evaporation at their design voltage. Increasing the applied voltage increases the rate of evaporation, so at some point there may be insufficient halogen and the lamp goes black. Over-voltage operation is not generally recommended. With a reduced voltage the evaporation is lower and there may be too much halogen, which can lead to abnormal failure. At much lower voltages, the bulb temperature may be too low to support the halogen cycle, but by this time the evaporation rate is too low for the bulb to blacken significantly. There are many situations where halogen lamps are dimmed successfully. However, lamp life may not be extended as much as predicted. The life span on dimming depends on lamp construction, the halogen additive used and whether dimming is normally expected for this type.
Spectrum.
Like all incandescent light bulbs, a halogen lamp produces a continuous spectrum of light, from near ultraviolet to deep into the infrared. Since the lamp filament can operate at a higher temperature than a non-halogen lamp, the spectrum is shifted toward blue, producing light with a higher effective color temperature. 
High temperature filaments emit some energy in the UV region. Small amounts of other elements can be mixed into the quartz, so that the "doped" quartz (or selective optical coating) blocks harmful UV radiation. Hard glass blocks UV and has been used extensively for the bulbs of car headlights. Alternatively, the halogen lamp can be mounted inside an outer bulb, similar to an ordinary incandescent lamp, which also reduces the risks from the high bulb temperature. Undoped quartz halogen lamps are used in some scientific, medical and dental instruments as a UV-B source.
Safety.
Halogen lamps get hotter than regular incandescent lamps because the heat is concentrated on a smaller envelope surface, and because the surface is closer to the filament. This high temperature is essential to their operation. Because the halogen lamp operates at very high temperatures, it can pose fire and burn hazards. In Australia, numerous house fires each year are attributed to ceiling-mounted halogen downlights. The Western Australia Department of Fire and Emergency Services recommends that home owners consider instead using compact fluorescent lamps or light emitting diode lamps because they produce less heat. Some safety codes now require halogen bulbs to be protected by a grid or grille, especially for high power (1–2 kW) bulbs used in theatre, or by the glass and metal housing of the fixture to prevent ignition of draperies or flammable objects in contact with the lamp.
To reduce unintentional ultraviolet (UV) exposure, and to contain hot bulb fragments in the event of explosive bulb failure, general-purpose lamps usually have a UV-absorbing glass filter over or around the bulb. Alternatively, lamp bulbs may be doped or coated to filter out the UV radiation. With adequate filtering, a halogen lamp exposes users to less UV than a standard incandescent lamp producing the same effective level of illumination without filtering.
Handling precautions.
Any surface contamination, notably the oil from human fingertips, can damage the quartz envelope when it is heated. Contaminants will create a hot spot on the bulb surface when the lamp is turned on. This extreme, localized heat causes the quartz to change from its vitreous form into a weaker, crystalline form that leaks gas. This weakening may also cause the bulb to form a bubble, weakening it and leading to its explosion. Consequently, manufacturers recommend that quartz lamps should be handled without touching the clear quartz, either by using a clean paper towel or carefully holding the porcelain base. If the quartz is contaminated in any way, it must be thoroughly cleaned with denatured alcohol and dried before use.
Applications.
Halogen headlamps are used in many automobiles. Halogen floodlights for outdoor lighting systems as well as for watercraft are also manufactured for commercial and recreational use. They are now also used in desktop lamps.
Tungsten-halogen lamps are frequently used as a near-infrared light source in Infrared spectroscopy.
Halogen lamps were used on the Times Square Ball from 1999 to 2006. However, from 2007 onwards, the halogen lamps were replaced with LED lights, both to reduce electrical costs, and due to the much longer potential lifespan (about ten times longer for LED over incandescent). The year numerals that light up when the ball reaches the bottom used halogen lighting for the last time for the 2009 ball drop. It was announced on the Times Square website that the year numerals for the 2010 ball drop would use LED lights.
Automotive.
Tungsten-halogen lamps have been commonly used as the light sources in automobile headlamps, but are increasing being replaced by Xenon and LED lights.
Cooking.
Halogen lamps are used as the heating element in a halogen oven.
Home use.
Halogen multifaceted reflector bulbs are widely available. The most common format is MR16, which is available in 10–50 W power ratings (150–800 lumens).
Low voltage lamps use the MR16 and similar bi-pin bases, whereas mains voltage lamps use the same caps as normal mains tungsten filament lamps, or a special GU10/GZ10 base. The GU10/GZ10 bases are shaped to prevent dichroic reflector lamps being used in luminaires intended for aluminised reflector lamps, which could cause overheating of the fitting. Higher efficiency LED versions of all of these lamps are now available, but these have widely varying light output and quality.
With the help of some companies such as Philips and Osram Sylvania, halogen bulbs have been made for standard household fittings, and can replace banned incandescent light bulbs of low luminous efficacy.
Tubular lamps with electrical contacts at each end are now being used in standalone lamps and household fixtures. These come in various lengths and wattages (50–300 W).
Stage lighting.
Tungsten halogen lamps are used in the majority of theatrical and studio (film and television) fixtures, including Ellipsoidal Reflector Spotlights and Fresnels. PAR Cans are also predominately tungsten halogen.
Specialized.
Projection lamps are used in motion-picture and slide projectors for homes and small office or school use. The compact size of the halogen lamp permits a reasonable size for portable projectors, although heat-absorbing filters must be placed between the lamp and the film to prevent melting. Halogen lamps are sometimes used for inspection lights and microscope stage illuminators. Halogen lamps were used for early flat-screen LCD backlighting, but other types of lamps are now used.
Disposal.
Halogen lamps do not contain any mercury. General Electric claims that none of the materials making up their halogen lamps would cause the lamps to be classified as hazardous waste.

</doc>
<doc id="52572" url="http://en.wikipedia.org/wiki?curid=52572" title="The Sound Pattern of English">
The Sound Pattern of English

The Sound Pattern of English (frequently referred to as SPE) is a 1968 work on phonology (a branch of linguistics) by Noam Chomsky and Morris Halle. It presents a view of the phonology of English, and has been very influential in both the field of phonology and in the analysis of the English language. Chomsky and Halle present a view of phonology as a linguistic subsystem, separate from other components of the grammar, that transforms an underlying phonemic sequence according to rules and produces as its output the phonetic form that is uttered by a speaker. The theory fits with the rest of Chomsky's early theories of language in the sense that it is transformational; as such it serves as a landmark in Chomsky's theories by adding a clearly articulated theory of phonology to his previous work which focused on syntax.
"The Sound Pattern of English" has had some influence on subsequent work. Derivatives of the theory have made modifications by changing the inventory of segmental features, considering some to be absent rather than having a positive or negative value, or adding complexity to the linear, segmental structure assumed by Chomsky and Halle. Its treatment of phonology as rules that operate on features, as well as its particular feature scheme, survive in various altered forms in many current theories of phonology. Some major successor theories include autosegmental phonology, lexical phonology and optimality theory.
Chomsky and Halle represent speech sounds as bundles of plus-or-minus valued features (e.g. vocalic, high, back, anterior, nasal, etc.) The phonological component of each lexical entry is considered to be a linear sequence of these feature bundles. A number of context-sensitive rules transform the underlying form of a sequence of words into the final phonetic form that is uttered by the speaker. These rules are allowed access to the tree structure that the syntax is said to output. This access allows rules that apply, for example, only at the end of a word, or only at the end of a noun phrase.
However, one of the most serious criticisms of "SPE" is that the so-called phonological processes alleged to be part of a speaker's competence are really only the successive phonetic transformations of the original historical lexical items. Chomsky and Halle appear to have replaced diachronic processes with purely synchronic ones.

</doc>
<doc id="52580" url="http://en.wikipedia.org/wiki?curid=52580" title="Real line">
Real line

In mathematics, the real line, or real number line is the line whose points are the real numbers. That is, the real line is the set R of all real numbers, viewed as a geometric space, namely the Euclidean space of dimension one. It can be thought of as a vector space (or affine space), a metric space, a topological space, a measure space, or a linear continuum.
Just like the set of real numbers, the real line is usually denoted by the symbol R (or alternatively, formula_1, the letter “R” in blackboard bold). However, it is sometimes denoted R1 in order to emphasize its role as the first Euclidean space.
This article focuses on the aspects of R as a geometric space in topology, geometry, and real analysis. The real numbers also play an important role in algebra as a field, but in this context R is rarely referred to as a line. For more information on R in all of its guises, see real number.
As a linear continuum.
The real line is a linear continuum under the standard < ordering. Specifically, the real line is linearly ordered by <, and this ordering is dense and has the least-upper-bound property.
In addition to the above properties, the real line has no maximum or minimum element. It also has a countable dense subset, namely the set of rational numbers. It is a theorem that any linear continuum with a countable dense subset and no maximum or minimum element is order-isomorphic to the real line.
The real line also satisfies the countable chain condition: every collection of mutually disjoint, nonempty open intervals in R is countable. In order theory, the famous Suslin problem asks whether every linear continuum satisfying the countable chain condition that has no maximum or minimum element is necessarily order-isomorphic to R. This statement has been shown to be independent of the standard axiomatic system of set theory known as ZFC.
As a metric space.
The real line forms a metric space, with the distance function given by absolute difference:
The metric tensor is clearly the 1-dimensional Euclidean metric. Since the" n"-dimensional Euclidean metric can be represented in matrix form as the "n "by " n" identity matrix, the metric on the real line is simply the 1 by 1 identity matrix, i.e. 1.
If "p" ∈ R and "ε" > 0, then the "ε"-ball in R centered at "p" is simply the open interval ("p" − "ε", "p" + "ε").
This real line has several important properties as a metric space:
As a topological space.
The real line carries a standard topology which can be introduced in two different, equivalent ways.
First, since the real numbers are totally ordered, they carry an order topology. Second, the real numbers inherit a metric topology from the metric defined above. The order topology and metric topology on R are the same. As a topological space, the real line is homeomorphic to the open interval (0, 1).
The real line is trivially a topological manifold of dimension 1. Up to homeomorphism, it is one of only two different 1-manifolds without boundary, the other being the circle. It also has a standard differentiable structure on it, making it a differentiable manifold. (Up to diffeomorphism, there is only one differentiable structure that the topological space supports.)
The real line is locally compact and paracompact, as well as second-countable and normal. It is also path-connected, and is therefore connected as well, though it can be disconnected by removing any one point. The real line is also contractible, and as such all of its homotopy groups and reduced homology groups are zero.
As a locally compact space, the real line can be compactified in several different ways. The one-point compactification of R is a circle (namely the real projective line), and the extra point can be thought of as an unsigned infinity. Alternatively, the real line has two ends, and the resulting end compactification is the extended real line [−∞, +∞]. There is also the Stone–Čech compactification of the real line, which involves adding an infinite number of additional points.
In some contexts, it is helpful to place other topologies on the set of real numbers, such as the lower limit topology or the Zariski topology. For the real numbers, the latter is the same as the finite complement topology.
As a vector space.
The real line is a vector space over the field R of real numbers (that is, over itself) of dimension 1. It has a standard inner product, making it a Euclidean space. (The inner product is simply ordinary multiplication of real numbers.) The standard norm on R is simply the absolute value function.
As a measure space.
The real line carries a canonical measure, namely the Lebesgue measure. This measure can be defined as the completion of a Borel measure defined on R, where the measure of any interval is the length of the interval.
Lebesgue measure on the real line is one of the simplest examples of a Haar measure on a locally compact group.
In real algebras.
The real line is a one-dimensional subspace of a real algebra "A" where R ⊂ "A". For example, in the complex plane "z" = "x" + i"y", the subspace {"z" : "y" = 0} is a real line. Similarly, the algebra of quaternions
has a real line in the subspace {"q" : "x" = "y" = "z" = 0 }.
When the real algebra is a direct sum formula_2 then a conjugation on "A" is introduced by the mapping formula_3 of subspace "V". In this way the real line consists of the fixed points of the conjugation.

</doc>
<doc id="52581" url="http://en.wikipedia.org/wiki?curid=52581" title="The Smiths">
The Smiths

The Smiths were an English rock band formed in Manchester in 1982. The band consisted of vocalist Morrissey, guitarist Johnny Marr, bassist Andy Rourke and drummer Mike Joyce. Critics have called them the most important alternative rock band to emerge from the British independent music scene of the 1980s." Q" magazine's Simon Goddard argued in 2007 that The Smiths were "the one truly vital voice of the '80s", "the most influential British guitar group of the decade" and the "first indie outsiders to achieve mainstream success on their own terms".
The "NME" named the Smiths the "most influential artist ever" in a 2002 poll, even topping the Beatles.
Based on the songwriting partnership of Morrissey and Marr, the group signed to the independent record label Rough Trade Records, on which they released four studio albums, "The Smiths" (1984), "Meat Is Murder" (1985), "The Queen Is Dead" (1986) and "Strangeways, Here We Come" (1987). Four of their albums (including three studio albums) appeared on "Rolling Stone's" list of the 500 Greatest Albums of All Time. They have also released several compilations, and numerous non-LP singles.
The Smiths had several singles reach the UK top twenty and all four of their studio albums reached the UK top five, including one which topped the charts. They won a significant following and remain cult favourites, although they had limited commercial success outside the UK while they were still together. The band broke up in 1987 and have turned down several offers to reunite.
The band's focus on a guitar, bass, and drum sound, and their fusion of 1960s rock and post-punk, were a repudiation of synthesizer-based contemporary dance-pop – the style popular in the early 1980s. Marr's guitar-playing on his Rickenbacker often had a jangly sound reminiscent of Roger McGuinn of the Byrds. Marr's guitar-playing influenced later Manchester bands, including The Stone Roses and Oasis. Morrissey's lyrics combined themes about ordinary people with a mordant sense of humour.
History.
Formation and early singles.
The Smiths were formed in early 1982 by Steven Patrick Morrissey, a writer who had briefly fronted punk rock band The Nosebleeds (which included guitarist Billy Duffy, who later was a member of The Cult); and John Maher, a guitarist and songwriter. Maher changed his name to Johnny Marr to avoid confusion with Buzzcocks drummer John Maher, and Morrissey performed under his surname alone. After recording several demo tapes with Simon Wolstencroft (later of The Fall) on drums, Morrissey and Marr recruited drummer Mike Joyce in the autumn of 1982. Joyce had formerly been a member of punk bands The Hoax and Victim. They also added bass player Dale Hibbert, who provided the group with demo recording facilities at the studio where he worked as a recording engineer. Hibbert was replaced after one gig by Marr's friend Andy Rourke, because Marr felt that neither Hibbert's bass playing nor his personality fitted the group.
The band picked their name in part as a reaction against those used by synthpop bands of the early 1980s, such as Orchestral Manoeuvres in the Dark and Spandau Ballet, which they considered pretentious. In a 1984 interview Morrissey said that he chose The Smiths "because it was the most ordinary name" and because he thought that it was "time that the ordinary folk of the world showed their faces." Signing to indie label Rough Trade Records, they released their first single, "Hand in Glove", in May 1983. The record was championed by DJ John Peel, as were all of their later singles, but failed to chart. The follow-up singles "This Charming Man" and "What Difference Does It Make?" fared better when they reached numbers 25 and 12 respectively on the UK Singles Chart.
"The Smiths".
In February 1984, the group released their debut album "The Smiths", which reached number two on the UK Albums Chart. Both "Reel Around the Fountain" and "The Hand That Rocks the Cradle" met with controversy, with some tabloid newspapers alleging the songs were suggestive of paedophilia, a claim strongly denied by the group.
The album was followed the same year by the non-album singles "Heaven Knows I'm Miserable Now" and "William, It Was Really Nothing", which featured "How Soon Is Now?" on its B-side. Securing the band's first top ten placing, "Heaven Knows I'm Miserable Now" was also significant for marking the beginning of engineer and producer Stephen Street's long-term working relationship with the band.
More controversy followed when "Suffer Little Children", the B-side to "Heaven Knows I'm Miserable Now", touched on the theme of the Moors murders. This caused an uproar after the grandfather of one of the murdered children heard the song on a pub jukebox and felt the band was trying to commercialise the murders. After meeting with Morrissey, he accepted that the song was a sincere exploration of the impact of the murders. Morrissey subsequently established a friendship with Ann West, the mother of victim Lesley Ann Downey, who is mentioned by name in the song.
The year ended with the compilation album "Hatful of Hollow". This collected singles, B-sides and the versions of songs that had been recorded throughout the previous year for the Peel and Jensen shows.
"Meat Is Murder".
Early in 1985 the band released their second album, "Meat Is Murder". This album was more strident and political than its predecessor, including the pro-vegetarian title track (Morrissey forbade the rest of the group from being photographed eating meat), the light-hearted republicanism of "Nowhere Fast", and the anti-corporal punishment "The Headmaster Ritual" and "Barbarism Begins at Home". The band had also grown more diverse musically, with Marr adding rockabilly riffs to "Rusholme Ruffians" and Rourke playing a funk bass solo on "Barbarism Begins at Home". The album was preceded by the re-release of the B-side "How Soon Is Now?" as a single, and although that song was not on the original LP, it has been added to subsequent releases. "Meat Is Murder" was the band's only album (barring compilations) to reach number one in the UK charts. In 2003, the album was ranked number 295 on "Rolling Stone" magazine's list of the 500 greatest albums of all time.
Morrissey brought a political stance to many of his interviews, courting further controversy. Among his targets were the Thatcher government, the British monarchy, and the famine relief project Band Aid. Morrissey famously quipped of the last, "One can have great concern for the people of Ethiopia, but it's another thing to inflict daily torture on the people of England" ("torture" being a reference to the music that resulted from the project). The subsequent single-only release "Shakespeare's Sister" reached number 26 on the UK Singles Chart, although the only single taken from the album, "That Joke Isn't Funny Anymore", was less successful, barely making the top 50.
"The Queen Is Dead".
During 1985 the band completed lengthy tours of the UK and the US while recording their next studio record, "The Queen Is Dead". The album was released in June 1986, shortly after the single "Bigmouth Strikes Again". The single again featured Marr's strident acoustic guitar rhythms and lead melody guitar lines with wide leaps. "The Queen Is Dead" reached number two in the UK charts, and consisted of a mixture of mordant bleakness (e.g. "Never Had No One Ever", which seemed to play up to stereotypes of the band), dry humour (e.g. "Frankly, Mr. Shankly", allegedly a message to Rough Trade boss Geoff Travis disguised as a letter of resignation from a worker to his superior), and synthesis of both, such as in "There Is a Light That Never Goes Out" and "Cemetry Gates".
However, all was not well within the group. A legal dispute with Rough Trade had delayed the album by almost seven months (it had been completed in November 1985), and Marr was beginning to feel the stress of the band's exhausting touring and recording schedule. He later told "NME", "'Worse for wear' wasn't the half of it: I was extremely ill. By the time the tour actually finished it was all getting a little bit ... dangerous. I was just drinking more than I could handle." Meanwhile, Rourke was fired from the band in early 1986 due to his use of heroin. He allegedly received notice of his dismissal via a Post-it note stuck to the windscreen of his car. It read, "Andy – you have left The Smiths. Goodbye and good luck, Morrissey." Morrissey himself, however, denies this.
Rourke was replaced on bass by Craig Gannon (formerly a member of Scottish new wave band Aztec Camera), but was reinstated two weeks later. Gannon stayed in the band, switching to rhythm guitar. This five-piece recorded the singles "Panic" and "Ask" (the latter with Kirsty MacColl on backing vocals) which reached numbers 11 and 14 respectively on the UK Singles Chart, and toured the UK. After the tour ended in October 1986, Gannon left the band, having played on six studio tracks and was thereafter regularly referred to as 'The Fifth Smith'.
The group had become frustrated with Rough Trade and sought a record deal with a major label. Marr told "NME" in early 1987, "Every single label came to see us. It was small-talk, bribes, the whole number. I really enjoyed it." The band ultimately signed with EMI, which drew criticism from their fanbase and from elements of the music press.
"Strangeways, Here We Come" and break-up.
In early 1987 the single "Shoplifters of the World Unite" was released and reached number 12 on the UK Singles Chart. It was followed by a second compilation, "The World Won't Listen" – the title was Morrissey's comment on his frustration with the band's lack of mainstream recognition, although the album reached number two in the charts – and the single "Sheila Take a Bow", the band's second (and last during the band's lifetime) UK top-10 hit. Another compilation, "Louder Than Bombs", was intended for the overseas market and covered much the same material as "The World Won't Listen", with the addition of "Sheila Take a Bow" and material from "Hatful of Hollow", as that compilation was yet to be released in the US
Despite their continued success, a variety of tensions emerged within the band to threaten their split. Johnny Marr was exhausted and took a break from the band in June 1987, which he felt was negatively perceived by the other Smiths. In July 1987, Marr left the group permanently because he thought an "NME" article entitled "Smiths to Split" was planted by Morrissey, when in fact it was not. That article, written by Danny Kelly, alleged that Morrissey disliked Marr working with other musicians, and that Marr and Morrissey's personal relationship had reached breaking point. Marr contacted "NME" to explain that he did not leave the band due to personal tensions but because he wanted wider musical scope.
Former Easterhouse guitarist Ivor Perry was brought in to replace Marr, and the band recorded some new material with him which was never completed, including an early version of "Bengali in Platforms" that was originally intended as the B-side of "Stop Me If You Think You've Heard This One Before". Perry was uncomfortable with the situation, stating "it was like they wanted another Johnny Marr", and the sessions ended with (according to Perry) "Morrissey running out of the studio". By the time the group's fourth album "Strangeways, Here We Come" was released in September, the band had split up.
The breakdown in the relationship has been primarily attributed to Morrissey becoming annoyed by Marr's work with other artists and Marr growing frustrated by Morrissey's musical inflexibility. Marr particularly hated Morrissey's obsession with covering 1960s pop artists such as Twinkle and Cilla Black. Marr recalled in 1992, "That was the last straw, really. I didn't form a group to perform Cilla Black songs." In a 1989 interview, Morrissey cited the lack of a managerial figure and business problems as reasons for the band's split.
"Strangeways, Here We Come" peaked at number two in the UK and was their most successful album in the US, reaching number 55 on the "Billboard" 200. It received a lukewarm reception from critics, but both Morrissey and Marr name it as their favourite Smiths album. A couple of further singles from "Strangeways" were released with earlier live, session and demo tracks as B-sides, and the following year the live recording "Rank" (recorded in 1986 while Gannon was in the band) repeated the UK chart success of previous albums.
Post-Smiths careers.
The Smiths were the subject of a "South Bank Show" documentary produced by LWT and broadcast by ITV on 18 October 1987, four months after their break-up and three weeks after the release of "Strangeways".
Following the group's demise, Morrissey began work on a solo recording, collaborating with producer Stephen Street and fellow Mancunian Vini Reilly, guitarist for The Durutti Column. The resulting album, "Viva Hate" (a reference to the end of the Smiths), was released in March 1988, reaching number one in the UK charts. Morrissey continues to perform and record as a solo artist.
Johnny Marr returned to the music scene in 1989 with New Order's Bernard Sumner and Pet Shop Boy Neil Tennant in the supergroup Electronic. Electronic released three albums over the next decade. Marr was also a member of The The, recording two albums with the group between 1989 and 1993. He has worked as a session musician and writing collaborator with artists including The Pretenders, Bryan Ferry, Pet Shop Boys, Billy Bragg, Black Grape, Talking Heads, Crowded House, and Beck.
In 2000 he started another band, Johnny Marr and the Healers, which enjoyed moderate success, and later worked as a guest musician on the Oasis album "Heathen Chemistry" (2002). In 2006 he began work with Modest Mouse's Isaac Brock on songs that eventually featured on the band's 2007 release, "We Were Dead Before the Ship Even Sank". Modest Mouse subsequently announced that Marr was a fully fledged member, and the reformed line-up toured extensively in 2006–07. Marr also recorded with Liam Gallagher of Oasis. In January 2008, it was reported that Marr had taken part in a week-long songwriting session at Moolah Rouge recording studio in Stockport with Wakefield indie group The Cribs. Marr's association with the band lasted three years and included an appearance on its fourth album, "Ignore the Ignorant" (2009). His departure from the group was announced in April 2011. He is now working on solo material. In addition to his activities as a musician and songwriter, Marr produced Haven's debut album, "Between the Senses" (2002).
Andy Rourke and Mike Joyce have continued working together. They toured with Sinéad O'Connor in the first half of 1988 (Rourke also appeared on her 1990 album, "I Do Not Want What I Haven't Got"). Still in 1988, they were recruited (with Craig Gannon) to Adult Net, but left the band soon afterwards. In 1988 and 1989, they recorded singles with Morrissey. In 1998 they toured and recorded with Aziz Ibrahim (ex-The Stone Roses). In 2001 they formed Specter with Jason Specter and others. The band played in the United Kingdom and the United States, but did not prosper. Part of its 27 May 2001 show in New York can be seen at YouTube.
In the same year they recorded demos with Paul Arthurs (ex-Oasis), Aziz Ibrahim, and Rowetta Idah (ex-Happy Mondays) under the name Moondog One, but the project went no further. Towards the end of 2001, they played together in the veteran Manchester band Jeep. In 2005 they played with Vinny Peculiar, recording the single "Two Fat Lovers" (Joyce also appeared on the 2006 album, "The Fall and Rise of Vinny Peculiar"). In 2007 they released the documentary DVD "Inside the Smiths", a surprisingly affectionate memoir of their time with the band, notable for the absence of Marr, Morrissey, and their music.
Rourke and Joyce have also pursued their own projects. Joyce has recorded with Suede (1990); toured and recorded with Buzzcocks (1990–1991); toured with Julian Cope (1992); toured with John Lydon and Public Image Ltd (1992); recorded with P.P. Arnold (1995); toured and recorded with Pete Wylie (ex-The Mighty Wah!) (1996–1998); toured with Vinny Peculiar and Paul Arthurs (2007); and toured with Autokat (2008–2009). Joyce presented the "Alternative Therapy" radio show on Revolution 96.2 FM until the station changed format in 2008, later reviving it on Manchester Radio Online and Tin Can Media. He now hosts "The Coalition Chart Show" on East Village Radio, which streams from New York, and works as a club DJ.
Rourke wrote the music for three Morrissey B-sides released in 1989 and 1990 ("Yes, I Am Blind", "Girl Least Likely To", and "Get Off the Stage"). He has played and recorded with Killing Joke (for three days in 1988); The Pretenders (featuring on "Last of the Independents", 1994); Badly Drawn Boy (with whom he played for two years); Proud Mary (featuring on "Love and Light", 2004); and Ian Brown (featuring on "The World Is Yours", 2007). In 2007 he formed Freebass with fellow bassists Peter Hook (ex-New Order and Joy Division) and Mani (The Stone Roses and Primal Scream); he remained active in the group until 2010 and appears on its only album, "It's A Beautiful Life" (2010).
Rourke co-founded the Manchester v Cancer concert series, later known as Versus Cancer, to raise money for cancer research. Concerts took place in January 2006, March 2007, February 2008, and December 2009. He has since concentrated on his radio career, beginning with a Saturday-evening show on XFM Manchester. More recently he has been a regular on East Village Radio, where his colleagues include Mike Joyce. Rourke relocated to New York in early 2009. Soon after arriving there, he formed Jetlag – a "DJ and audio production outfit" – with Olé Koretsky. The pair DJ at venues around the city; a selection of their remixes can be heard at Soundcloud.
Later controversies.
Royalties dispute.
Morrissey and Marr each took 40 per cent of The Smiths' recording and performance royalties, allowing 10 per cent each to Joyce and Rourke. As Joyce's barrister would later argue in court, the bassist and drummer were treated as "mere session musicians, as readily replaceable as the parts in a lawnmower".
In March 1989, Joyce and Rourke started legal proceedings against their former bandmates, arguing that they were equal partners in The Smiths and each entitled to a 25 per cent share of the band's profits on all activities other than songwriting and publishing. Rourke, who was in debt, settled almost immediately for a lump sum of £83,000 and 10 per cent of royalties, renouncing all further claims.
Joyce continued with the action, which eventually reached the High Court of Justice (Chancery Division) in December 1996. Morrissey and Marr had accepted the previous year that Joyce and Rourke were partners. "The only contentious issue was whether Mr Joyce was an equal partner entitled to ¼ of the profits arising out of the activities (other than songwriting or publishing) of 'The Smiths'." Joyce's barrister, Nigel Davis QC, asserted that "it was not until after the bestselling band split up in 1987 that his client discovered he was getting only 10 per cent of the profits". Davis continued: "Mr Joyce never agreed to ten per cent, he never assumed he was getting ten per cent. On the contrary he thought he was getting 25 per cent."
Morrissey and Marr – who were represented separately at the trial – insisted that the royalty split had been explained to Rourke and Joyce, even if they were no longer sure when. As Marr's counsel, Robert Englehart QC, explained, "Some 13 years on it is extremely difficult to pinpoint the moment when the 40:40:10:10 profit split came into being ... But Morrissey and Marr acted throughout on the basis that they would be getting 40 per cent each of the net profits from The Smiths earnings."
After a seven-day hearing, Judge Weeks found in favour of Joyce, ordering that he receive around £1 million in back-royalties and 25 per cent henceforth. The judge also volunteered character assessments of the four antagonists, which were highly favourable to Joyce and Rourke (who gave evidence in Joyce's support):
The judge also ranked the band members by IQ, with Marr "probably the more intelligent of the four", Rourke and Joyce "unintellectual", and Morrissey presumably somewhere in between.
Morrissey offered a different interpretation in an interview eight months later:
Asked some time before the trial whether he thought Rourke and Joyce had been short-changed, Morrissey responded: "They were lucky. If they'd had another singer they'd never have got further than Salford shopping centre." Morrissey's counsel, Ian Mill QC, conceded that his client's attitude "betrayed a degree of arrogance". Morrissey appealed against the verdict; Marr did not. The appeal was heard by the Court of Appeal (Civil Division) in November 1998 and dismissed. Inspired by Joyce's success, Rourke sought legal advice on his own options. No further action appears to have been taken since that time. Rourke was declared bankrupt in 1999.
In November 2005, Mike Joyce told Marc Riley on BBC Radio 6 Music that financial hardship had reduced him to selling rare Smiths' recordings on eBay. By way of illustration, Riley played part of an unfinished instrumental known as the "Click Track" (or "Cowbell Track"). Morrissey responded with a statement three days later revealing that Joyce had received £215,000 each from Marr and Morrissey in 1997, along with Marr's final back-payment of £260,000 in 2001. Morrissey failed to make his final payment because, he said, he was overseas in 2001 and did not receive the paperwork. Joyce obtained a default judgement against Morrissey, revised his outstanding claim to £688,000, and secured orders garnishing much of the singer's income. This was a source of ongoing inconvenience and grievance to Morrissey, who estimated that Joyce had cost him at least £1,515,000 in recovered royalties and legal fees up to 30 November 2005.
Reunion speculation.
Both Johnny Marr and Morrissey have repeatedly said that they will not reunite the band. In 2006, Morrissey declared, "I would rather eat my own testicles than reform The Smiths, and that's saying something for a vegetarian." When asked why in another interview the same year, he responded, "I feel as if I've worked very hard since the demise of the Smiths and the others haven't, so why hand them attention that they haven't earned? We are not friends, we don't see each other. Why on earth would we be on a stage together?" In a February 2009 interview on BBC Radio 2, he said, "People always ask me about reunions and I can't imagine why ... the past seems like a distant place, and I'm pleased with that."
In November 2004, VH1 screened a "Backstage Pass Special" episode of "Bands Reunited" showing host Aamer Haleem trying and failing to corner Morrissey before a show at the Apollo Theater. In March 2006, Morrissey revealed that The Smiths had been offered $5 million for a performance at the Coachella Valley Music and Arts Festival, which he turned down, saying, "No, because money doesn't come into it." He further explained, "It was a fantastic journey. And then it ended. I didn't feel we should have ended. I wanted to continue. [Marr] wanted to end it. And that was that."
In August 2007, it was widely reported that Morrissey had that summer declined an offer of $75 million – nearly £40 million at the time – from a "consortium of promoters" to reunite with Marr for a fifty-date world tour under the Smiths' name in 2008 and 2009. "NME" gave Morrissey as its source for the story. "Rolling Stone" cited his publicist. The offer was also reported at true-to-you.net, an unofficial fan site tacitly supported by Morrissey. It was later described as a "hoax", although it is unclear who was hoaxing whom.
In October the same year, Marr reignited speculation when he hinted on BBC Radio 5 Live at a potential reunion in the future, saying that "stranger things have happened so, you know, who knows?" Marr went on to say that "It's no biggy. Maybe we will in 10 or 15 years' time when we all need to for whatever reasons, but right now Morrissey is doing his thing and I'm doing mine, so that's the answer really." This suggested a change of heart, given that Marr had previously said reforming the band would be a bad idea.
In October 2008, "The Sun", citing "sources close to the band", reported that the Smiths would reform to play at the Coachella in 2009. Soon afterwards, "NME" scotched the story, also citing "sources close to the band", and quoting Johnny Marr's manager to the effect that it was "rubbish".
In June 2009, Marr told an interviewer on London's XFM, "I think we were offered 50 million dollars for three ... possibly five shows." He said that the chances of a reunion were "nothing to do with money", and that the reasons were "really abstract".
The closest Marr or Morrissey has come to any kind of reunion was in January 2006 when Johnny Marr and The Healers played at Andy Rourke's Manchester v Cancer benefit concert. There were suggestions leading up to the show that Morrissey might also be involved. Marr made it clear that this would not happen, but did perform "How Soon Is Now?" with Rourke. Marr and Rourke played the same music again at the Loolapalloza Brazil 2014 festival.
Repackaging.
Since the band split, its members have sanctioned the release of a live album ("Rank", 1988), four greatest-hits collections ("Best ... I", 1992; "... Best II", 1992; "Singles", 1995; and "The Sound of The Smiths", 2008), one miscellaneous compilation ("Stop Me", 1988), and two box-sets ("The Smiths Singles Box", 2008; and "Complete", 2011). There has also been an unsanctioned greatest-hits collection ("The Very Best of The Smiths", 2001). This is in addition to the compilations released during the band's lifetime ("Hatful of Hollow", 1984; "The World Won't Listen", 1987; and "Louder Than Bombs", 1987).
As critic Stephen Thomas Erlewine has pointed out, "Several months after releasing their first album, the Smiths issued the singles and rarities collection "Hatful of Hollow", establishing a tradition of repackaging their material as many times and as quickly as possible." Erlewine elsewhere observes that, "the anti-record company "Paint a Vulgar Picture" – on "Strangeways, Here We Come" – "has grown increasingly ironic in the wake of the Smiths' and Morrissey's love of repackaging the same material in new compilations."
Musical style.
Morrissey and Johnny Marr dictated the musical direction of The Smiths. Marr said in 1990 that it "was a 50/50 thing between Morrissey and me. We were completely in sync about which way we should go for each record". The band's "non-rhythm-and-blues, whiter-than-white fusion of 1960s rock and postpunk was a repudiation of contemporary dance pop" – the style popular in the early 1980s. The band purposely rejected synthesisers and dance music. They sometimes used Sergei Prokofiev's "Montagues and Capulets" as entrance music at live shows.
Marr's jangly Rickenbacker guitar-playing was influenced by Roger McGuinn of The Byrds, Neil Young's work with Crazy Horse, George Harrison (with The Beatles) and James Honeyman-Scott of The Pretenders. Marr often tuned his guitar up a full step to F-sharp to accommodate Morrissey's vocal range, and also used open tunings. Citing producer Phil Spector as an influence, Marr said, "I like the idea of records, even those with plenty of space, that sound 'symphonic'. I like the idea of all the players merging into one atmosphere". Marr's other favourite guitarists are James Williamson of The Stooges, Rory Gallagher, Pete Townshend of The Who, Jimi Hendrix, Marc Bolan of T. Rex, Keith Richards of The Rolling Stones and John McGeoch of Magazine and Siouxsie and the Banshees.
Morrissey's role was to create vocal melodies and lyrics. Morrissey's songwriting was influenced by punk rock and post-punk bands such as the New York Dolls, The Cramps, The Specials and The Cult, along with 1960s girl groups, and singers such as Dusty Springfield, Sandie Shaw, Marianne Faithfull, and Timi Yuro. Morrissey's lyrics, while superficially depressing, were often full of mordant humour; John Peel remarked that The Smiths were one of the few bands capable of making him laugh out loud. Influenced by his childhood interest in the social realism of 1960s "kitchen sink" television plays, Morrissey wrote about ordinary people and their experiences with despair, rejection and death. While "songs such as 'Still Ill' sealed his role as spokesman for disaffected youth", Morrissey's "manic-depressive rants" and his "'woe-is-me' posture inspired some hostile critics to dismiss the Smiths as 'miserabilists.'"
A study has found that The Smiths employed the greatest vocabulary range of all bands to emerge from Manchester, using more than 1,100 different words in their first three albums.
Visual imagery.
The group's cover artwork had a distinctive visual style and often featured images of film and pop stars, usually in duotone. Design was by Morrissey and Rough Trade art coordinator Jo Slee. The covers of singles rarely featured any text other than the band name, and the band itself did not appear on the cover of any UK release. (Morrissey did, however, appear on an alternative cover for "What Difference Does It Make?", mimicking the pose of the original subject, British actor Terence Stamp, after the latter objected to his picture being used.) The choice of cover subjects reflected Morrissey's interest in cult film stars (Stamp, Alain Delon, Jean Marais, Warhol protégé Joe Dallesandro, James Dean); figures from sixties British popular culture (Viv Nicholson, Pat Phoenix, Yootha Joyce, Shelagh Delaney); and anonymous images from old films and magazines.
The Smiths dressed mainly in ordinary clothes – jeans and plain shirts – in keeping with the back-to-basics, guitar-and-drums style of the music. This contrasted with the exotic high-fashion image cultivated by New Romantic pop groups such as Spandau Ballet and Duran Duran and highlighted in magazines such as "The Face" and "i-D". In 1986, when The Smiths performed on the British music programme "The Old Grey Whistle Test", Morrissey wore a fake hearing-aid to support a hearing-impaired fan who was ashamed of using one, and also frequently wore thick-rimmed National Health Service-style glasses.
Legacy.
The Smiths have been widely influential. Marr's guitar playing "was a huge building block for more Manchester legends that followed The Smiths", including The Stone Roses, whose guitarist John Squire has said Marr was an influence. Oasis guitarist Noel Gallagher also cites The Smiths as an influence, especially Marr. Gallagher has said that "When The Jam split, The Smiths started, and I totally went for them." Singer Davey Havok of the band AFI cites The Smiths as an influence. The BBC described The Smiths as "the band that inspired deeper devotion than any British group since The Beatles".
"Q" magazine's Simon Goddard argued in 2007 that The Smiths were "the one truly vital voice of the '80s" and "the most influential British guitar group of the decade". He continued: "As the first indie outsiders to achieve mainstream success on their own terms (their second album proper, 1985's Meat Is Murder, made Number 1 in the UK), they elevated rock's standard four-piece formula to new heights of magic and poetry. Their legacy can be traced down through The Stone Roses, Oasis and The Libertines to today's crop of artful young guitar bands."
"Uncut" magazine's Simon Reynolds wrote of the band: "Once upon a time, a band from the North came with a sound so fresh and vigorous it took the nation by storm. The sound was rock, but crucially it was pop, too: concise, punchy, melodic, shiny without being "plastic". The singer was a true original, delivering a blend of sensitivity and strength, defiance and tenderness, via a regionally inflected voice. The young man's lips spilled forth words that were realistic without being dour, full of sly humour and beautifully observed detail. Most recognised their debut album as a landmark, an instant classic."
The "Britpop movement pre-empted by The Stone Roses and spearheaded by groups like Oasis, Suede and Blur, drew heavily from Morrissey's portrayal of and nostalgia for a bleak urban England of the past." Blur formed as a result of seeing The Smiths on "The South Bank Show" in 1987. Yet even while leading bands from the Britpop movement were influenced by The Smiths, they were at odds with the "basic anti-establishment philosophies of Morrissey and The Smiths", since Britpop "was an entirely commercial construct." Mark Simpson has suggested that "the whole point of Britpop was to airbrush Morrissey out of the picture ... Morrissey had to become an 'unperson' so that the Nineties and its centrally-planned and coordinated pop economy could happen."
Playwright Shaun Duggan's stage drama "William", Alex Broun's one-man show "Half a Person: My Life as Told by The Smiths", Douglas Coupland's 1998 novel "Girlfriend in a Coma", Andrew Collins' autobiography "Heaven Knows I'm Miserable Now", Marc Spitz's novel "How Soon is Never?", the pop band Shakespears Sister, the defunct art-punk group Pretty Girls Make Graves, and the Polish filmmaker Przemysław Wojcieszek's short fictional film about two Polish fans of The Smiths, "Louder Than Bombs", are all inspired by or named after songs or albums by The Smiths.
In 2014, The Smiths were announced as nominees to be inducted into the Rock and Roll Hall of Fame.

</doc>
<doc id="52583" url="http://en.wikipedia.org/wiki?curid=52583" title="441">
441

Year 441 (CDXLI) was a common year starting on Wednesday (link will display the full calendar) of the Julian calendar. At the time, it was known as the Year of the Consulship of Seleucus without colleague (or, less frequently, year 1194 "Ab urbe condita"). The denomination 441 for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="52584" url="http://en.wikipedia.org/wiki?curid=52584" title="941">
941

Year 941 (CMXLI) was a common year starting on Friday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By topic.
Religion.
</onlyinclude>

</doc>
<doc id="52585" url="http://en.wikipedia.org/wiki?curid=52585" title="Thespis">
Thespis

Thespis (; Greek: Θέσπις; fl. 6th century BC) of Icaria (present-day Dionysos, Greece), according to certain Ancient Greek sources and especially Aristotle, was the first person ever to appear on stage as an actor playing a character in a play (instead of speaking as him or herself). In other sources, he is said to have introduced the first principal actor in addition to the chorus.
Thespis was a singer of dithyrambs (songs about stories from mythology with choric refrains). He is credited with introducing a new style in which one singer or actor performed the words of individual characters in the stories, distinguishing between the characters with the aid of different masks.
This new style was called tragedy, and Thespis was the most popular exponent of it. Eventually, in 534 BC competitions to find the best tragedy were instituted at the City Dionysia in Athens, and Thespis won the first documented competition. Capitalising on his success, Thespis also invented theatrical touring; he would tour various cities while carrying his costumes, masks and other props in a horse-drawn wagon.
Alleged works.
Titles of some plays have been attributed to Thespis. But most modern scholars, following the suggestion of Diogenes Laërtius, consider them to be forgeries, some forged by the philosopher Heraclides Ponticus, others by or altered by Christian writers:
Fragments (probably spurious) in A Nauck, "Tragicorum graecorum fragmenta" (1887).
Legacy.
It is implied that Thespis invented acting in the Western world, and that prior to his performances, no one had ever assumed the resemblance of another person for the purpose of storytelling. In fact, Thespis is the first known actor in "written" plays. He may thus have had a substantial role in changing the way stories were told and inventing theater as we know it today. In reverence to Thespis, actors in the English-speaking part of the world have been referred to as thespians.
A branch of the National Theater of Greece expressly instituted in 1939 to tour the country is named "The Wagon of Thespis" (Greek: Άρμα Θέσπιδος, "Árma Théspidos") in his honour.
A first season episode of the TV series "" was named "Thespis" and referenced him.

</doc>
<doc id="52586" url="http://en.wikipedia.org/wiki?curid=52586" title="940">
940

Year 940 (CMXL) was a leap year starting on Wednesday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="52587" url="http://en.wikipedia.org/wiki?curid=52587" title="944">
944

Year 944 (CMXLIV) was a leap year starting on Monday (link will display the full calendar) of the Julian calendar.
Events.
<onlyinclude>
By place.
Europe.
</onlyinclude>

</doc>
<doc id="52588" url="http://en.wikipedia.org/wiki?curid=52588" title="56 BC">
56 BC

Year 56 BC was a year of the pre-Julian Roman calendar. At the time, it was known as the Year of the Consulship of Lentulus and Philippus (or, less frequently, year 698 "Ab urbe condita"). The denomination 56 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Roman Republic.
</onlyinclude>

</doc>
<doc id="52589" url="http://en.wikipedia.org/wiki?curid=52589" title="57 BC">
57 BC

Year 57 BC was a year of the pre-Julian Roman calendar. At the time, it was known as the Year of the Consulship of Lentulus and Metellus (or, less frequently, year 697 "Ab urbe condita"). The denomination 57 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="52590" url="http://en.wikipedia.org/wiki?curid=52590" title="The Population Bomb">
The Population Bomb

The Population Bomb is a best-selling book written by Stanford University Professor Paul R. Ehrlich and his wife, Anne Ehrlich (who was uncredited), in 1968. It warned of the mass starvation of humans in the 1970s and 1980s due to overpopulation, as well as other major societal upheavals, and advocated immediate action to limit population growth. Fears of a "population explosion" were widespread in the 1950s and 60s, but the book and its author brought the idea to an even wider audience. The book has been criticized since its publishing for its alarmist tone, and in recent decades for its inaccurate predictions. The Ehrlichs stand by the basic ideas in the book, stating in 2009 that "perhaps the most serious flaw in "The Bomb" was that it was much too optimistic about the future" and believe that it achieved their goals because "it alerted people to the importance of environmental issues and brought human numbers into the debate on the human future."
General description of the book.
"The Population Bomb" was written at the suggestion of David Brower the executive director of the environmentalist Sierra Club, and Ian Ballantine of Ballantine Books following various public appearances Ehrlich had made regarding population issues and their relation to the environment. Although the Ehrlichs collaborated on the book, the publisher insisted that a single author be credited, and also asked to change their preferred title: "Population, Resources, and Environment." The title "Population Bomb" was taken (with permission) from General William H. Draper, founder of the Population Crisis Committee and a pamphlet issued in 1954 by the Hugh Moore Fund. The Ehrlichs regret the choice of title, which they admit was a perfect choice from a marketing perspective, but think that "it led Paul to be miscategorized as solely focused on human numbers, despite our interest in all the factors affecting the human trajectory."
Early editions of "The Population Bomb" began with the statement:
"The battle to feed all of humanity is over. In the 1970s hundreds of millions of people will starve to death in spite of any crash programs embarked upon now. At this late date nothing can prevent a substantial increase in the world death rate..."
Much of the book is spent describing the state of the environment and the food security situation, which is described as increasingly dire. Ehrlich argues that as the existing population was not being fed adequately, and as it was growing rapidly it was unreasonable to expect sufficient improvements in food production to feed everyone. He further argued that the growing population placed escalating strains on all aspects of the natural world.
In answer to the question, "what needs to be done?" he wrote, "We must rapidly bring the world population under control, reducing the growth rate to zero or making it negative. Conscious regulation of human numbers must be achieved. Simultaneously we must, at least temporarily, greatly increase our food production." Ehrlich described a number of "ideas on how these goals "might" be reached." He believed that the United States should take a leading role in population control, both because it was already consuming much more than the rest of the world, and therefore had a moral duty to reduce its impact, and because the US would have to lead international efforts due to its prominence in the world. In order to avoid charges of hypocrisy or racism it would have to take the lead in population reduction efforts. Ehrlich floats the idea of adding "temporary sterilants" to the water supply or staple foods. However, he rejects the idea as unpractical due to "criminal inadequacy of biomedical research in this area." He suggests a tax scheme in which additional children would add to a family's tax burden at increasing rates for more children, as well as luxury taxes on childcare goods. He suggests incentives for men who agree to permanent sterilization before they have two children, as well as a variety of other monetary incentives. He proposes a powerful Department of Population and Environment which "should be set up with the power to take whatever steps are necessary to establish a reasonable population size in the United States and to put an end to the steady deterioration of our environment." The department should support research into population control, such as better contraceptives, mass sterilizing agents, and prenatal sex discernment (because families often continue to have children until a male is born. Ehrlich suggested that if they could choose a male child this would reduce the birthrate). Legislation should be enacted guaranteeing the right to an abortion, and sex education should be expanded.
After explaining the domestic policies the US should pursue, he discusses foreign policy. He advocates a system of "triage," such as that suggested by William and Paul Paddock in "Famine 1975!". Under this system countries would be divided into categories based on their abilities to feed themselves going forward. Countries with sufficient programmes in place to limit population growth, and the ability to become self-sufficient in the future would continue to receive food aid. Countries, for example India, which "were far behind in the population-food game that there is no hope that our food aid will see them through to self-sufficiency" would have their food aid eliminated. Ehrlich argued that this was the only realistic strategy in the long-term. Ehrlich applauds the Paddocks' "courage and foresight" in proposing such a solution. Ehrlich further discusses the need to set up public education programs and agricultural development schemes in developing countries. He argues that the scheme would likely have to be implemented outside the framework of the United Nations due to the necessity of being selective regarding the targeted regions and countries, and suggests that within countries certain regions should be prioritized to the extent that cooperative separatist movements should be encouraged if they are an improvement over the existing authority. He mentions his support for government mandated sterilization of Indian males with three or more children.
In the rest of the book Ehrlich discusses things which readers can do to help. This is focused primarily on changing public opinion to create pressure on politicians to enact the policies he suggests, which he believed were not politically possible in 1968. At the end of the book he discusses the possibility that his forecasts may be wrong, a fact which he felt he must acknowledge as a scientist. However, he believes that humanity will only be better off if it follows his prescriptions, so that even if he is incorrect it is the right course of action.
The book sold over two million copies, raised the general awareness of population and environmental issues, and influenced 1960s and 1970s public policy.
Context.
In 1948 two widely read books were published that would inspire a "neo-Malthusian" debate on population and the environment: Fairfield Osborn’s "Our Plundered Planet" and William Vogt’s "Road to Survival". Although, they are now much less well known than "Population Bomb", they inspired many works such as the original "Population Bomb" pamphlet by Hugh Everett Moore in 1954 that inspired the name of Ehrlich's book, as well as some of the original societies concerned with population and environmental matters. D.B. Luten has said that although the book is often seen as a seminal work in the field, the "Population Bomb" is actually best understood as "climaxing and in a sense terminating the debate of the 1950s and 1960s.” Ehrlich has said that he traced his own Malthusian beliefs to a lecture he heard Vogt give when he was attending university in the early 1950s. For Ehrlich, these writers provided “a global framework for things he had observed as a young naturalist."
Criticisms.
Restatement of Malthusian theory.
The "Population Bomb" has been characterized by critics as primarily a repetition of the Malthusian catastrophe argument that population growth will outpace agricultural growth unless controlled. Ehrlich observed that since about 1930 the population of the world had doubled within a single generation, from 2 billion to nearly 4 billion, and was on track to do so again. He assumed that available resources on the other hand, and in particular food, were nearly at their limits. Some critics compare Ehrlich unfavorably to Malthus, saying that although Thomas Malthus did not make a firm prediction of imminent catastrophe, Ehrlich warned of a potential massive disaster within the next decade or two. In addition, critics state that unlike Malthus, Ehrlich did not see any means of avoiding the disaster entirely (although some mitigation was possible), and proposed solutions that were much more radical than those discussed by Malthus, such as starving whole countries that refused to implement population control measures.
Ehrlich was certainly not unique in his neo-Malthusian predictions, and there was a widespread belief in the 1960s and 70s that increasingly catastrophic famines were on their way.
Predictions.
The Ehrlichs made a number of specific predictions that did not come to pass, for which they have received criticism. They have acknowledged that some predictions were incorrect. However, they maintain that their general argument remains intact, that their predictions were merely illustrative, that their and others' warnings caused preventive action, or that many of their predictions may yet come true (see Ehrlich's response below). Still other commentators have criticized the Ehrlichs' perceived inability to acknowledge mistakes, evasiveness, and refusal to alter their arguments in the face of contrary evidence.
In "The Population Bomb's" opening lines the authors state that nothing can prevent famines in which hundreds of millions of people will die during the 1970s (amended to 1970s and 80s in later editions), and that there would be "a substantial increase in the world death rate." Although many lives could be saved through dramatic action, it was already too late to prevent a substantial increase in the global death rate. However, in reality the global death rate has continued to decline substantially since then, from 13/1000 in 1965–74 to 10/1000 from 1985–1990. Meanwhile the population of the world has more than doubled, while calories consumed/person have increased 24%. The UN does not keep official death-by-hunger statistics so it is hard to measure whether the "hundreds of millions of deaths" number is correct. Ehrlich himself suggested in 2009 that between 200-300 million had died of hunger since 1968. However, that is measured over 40 years rather than the ten to twenty foreseen in the book, so it can be seen as significantly fewer than predicted.
Famine has not been eliminated, but its root cause has been political instability, not global food shortage. The Indian economist and Nobel Prize winner, Amartya Sen, has argued that nations with democracy and a free press have virtually never suffered from extended famines. Nevertheless, in 2010 the UN reported that 925 million of the world's population of nearly seven billion people were in a constant state of hunger. The UN report notes that the percentage of the world's population who qualify as "undernourished" has fallen by more than half, from 33 percent to about 16 percent, since Ehrlich published "The Population Bomb."
Ehrlich writes: "I don't see how India could possibly feed two hundred million more people by 1980." This view was widely held at the time, as another statement of his, later in the book: "I have yet to meet anyone familiar with the situation who thinks that India will be self-sufficient in food by 1971." In the book's 1971 edition, the latter prediction was removed, as the food situation in India suddenly improved.
As of 2010, India had almost 1.2 billion people, having nearly tripled its population from around 400 million in 1960. India's Total Fertility Rate in 2008 was calculated to be 2.6. While the absolute numbers of malnourished children in India is high, the rates of malnutrition and poverty in India have declined from approximately 90% at the time of India's independence, to less than 40% today. Ehrlich's prediction about famines were found to be false, although food security is an issue in India. However, most epidemiologists, public health physicians and demographers identify corruption as the chief cause of malnutrition, not "overpopulation". As Nobel Prize–winning economist Amartya Sen noted, India frequently had famines during British colonial rule. However, when India became a democracy, there have been no recorded famines.
Journalist Dan Gardner has criticized Ehrlich both for his overconfident predictions and his refusal to acknowledge his errors. "In two lengthy interviews, Ehrlich admitted making not a single major error in the popular works he published in the late 1960s and early 1970s … the only flat-out mistake Ehrlich acknowledges is missing the destruction of the rain forests, which happens to be a point that supports and strengthens his world view—and is therefore, in cognitive dissonance terms, not a mistake at all. Beyond that, he was by his account, off a little here and there, but only because the information he got from others was wrong. Basically, he was right across the board."
Jonathan Last called it "one of the most spectacularly foolish books ever published".
Showmanship.
One frequent criticism of "The Population Bomb" is that it focused on spectacle and exaggeration at the expense of accuracy. Pierre Desrochers and Christine Hoffbauer remark that "at the time of writing "The Population Bomb", Paul and Anne Ehrlich should have been more cautious and revised their tone and rhetoric, in light of the undeniable and already apparent errors and shortcomings of Osborn and Vogt’s analyses." Charles Rubin has written that it was precisely because Ehrlich was largely unoriginal and wrote in a clear emotionally gripping style that it became so popular. He quotes a review from "Natural History" noting that Ehrlich does not try to "convince intellectually by mind dulling statistics," but rather roars "like an Old Testament Prophet." Gardner says, "as much as the events and culture of the era, Paul Ehrlich's style explain the enormous audience he attracted." Indeed, an appearance on The Tonight Show Starring Johnny Carson helped to propel the success of the book, as well as Ehrlich's celebrity. Desrochers and Hoffbauer go on to conclude that it seems hard to deny that using an alarmist tone and emotional appeal were the main lessons that the present generation of environmentalists learned from Ehrlich's success.
Criticism by Marxists.
On the political left the book received criticism that it was focusing on "the wrong problem", and that the real issue was distribution of resources rather than of overpopulation. Marxists worried that Ehrlich's work could be used to justify genocide and imperial control, as well as oppression of minorities and disadvantaged groups or even a return to eugenics. Barry Commoner argued that the Ehrlichs were too focused on overpopulation as the source of environmental problems, and that their proposed solutions were politically unacceptable because of the coercion that they implied, and because the cost would fall disproportionately on the poor. He argued that technological, and above all social development would lead to a natural decrease in both population growth and environmental damage.
Ehrlich's response.
In a 2004 "Grist Magazine" interview, Ehrlich acknowledged some specific predictions he had made, in the years around the time "The Population Bomb" was published, that had "not" come to pass. However, as to a number of his fundamental ideas and assertions he maintained that facts and science proved them correct.
In answer to the question: "Were your predictions in The Population Bomb right?", Ehrlich responded:
"Anne and I have always followed UN population projections as modified by the Population Reference Bureau -- so we never made "predictions," even though idiots think we have. When I wrote The Population Bomb in 1968, there were 3.5 billion people. Since then we've added another 2.8 billion -- many more than the total population (2 billion) when I was born in 1932. If that's not a population explosion, what is? My basic claims (and those of the many scientific colleagues who reviewed my work) were that population growth was a major problem. Fifty-eight academies of science said that same thing in 1994, as did the world scientists' warning to humanity in the same year. My view has become depressingly mainline!
In another retrospective article published in 2009, Ehrlich said, in response to criticism that many of his predictions had not come to pass:
"the biggest tactical error in "The Bomb" was the use of scenarios, stories designed to help one think about the future. Although we clearly stated that they were not predictions and that “we can be sure that none of them will come true as stated,’ (p. 72)—their failure to occur is often cited as a failure of prediction. In honesty, the scenarios were way off, especially in their timing (we underestimated the resilience of the world system). But they did deal with future issues that people in 1968 should have been thinking about – famines, plagues, water shortages, armed international interventions by the United States, and nuclear winter (e.g., Ehrlich et al. 1983, Toon et al. 2007)—all events that have occurred or now still threaten

</doc>
<doc id="52591" url="http://en.wikipedia.org/wiki?curid=52591" title="58 BC">
58 BC

Year 58 BC was a year of the pre-Julian Roman calendar. At the time, it was known as the Year of the Consulship of Piso and Gabinius (or, less frequently, year 696 "Ab urbe condita"). The denomination 58 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Asia.
</onlyinclude>

</doc>
<doc id="52592" url="http://en.wikipedia.org/wiki?curid=52592" title="George Sand">
George Sand

Amantine-Lucile-Aurore Dupin (]; 1 July 1804 – 8 June 1876), best known by her pseudonym George Sand (; ]), was a French novelist and memoirist. She is equally well known for her much publicized romantic affairs with a number of artists, including the composer and pianist Frédéric Chopin and the writer Alfred de Musset.
Life.
Sand wrote: "My name is not Marie-Aurore de Saxe, Marquise of Dudevant, as several of my biographers have asserted, but Amantine-Lucile-Aurore Dupin, and my husband, M. François Dudevant, claims no title: the highest rank he ever reached was that of infantry second lieutenant."
Always known simply as "Aurore" she was born in Paris, but raised for much of her childhood by her grandmother, Marie-Aurore de Saxe, Madame Dupin de Francueil, at her grandmother's estate, Nohant, in the French province of Berry (see House of George Sand). Sand later used the setting in many of her novels. It has been said[] that her upbringing was quite liberal. Her father, Maurice Dupin, was the grandson of the Marshal General of France, Maurice, Comte de Saxe, and an illegitimate son of Augustus II the Strong, King of Poland and a Saxon elector, and a cousin to the sixth degree to the kings of France Louis XVI, Louis XVIII and Charles X. Sand's mother, Sophie-Victoire Delaborde, was a commoner.
In 1822, at the age of eighteen, Sand married Casimir Dudevant (1795–1871; first name "François"), illegitimate son of Baron Jean-François Dudevant. She and Dudevant had two children: Maurice (1823–1889) and Solange (1828–1899). In early 1831, she left her husband and entered upon a four- or five-year period of "romantic rebellion." In 1835, she was legally separated from Dudevant and took her children with her.
Sand conducted affairs of varying duration with Jules Sandeau (1831), Prosper Mérimée, Alfred de Musset (summer 1833 – March 1835), Louis-Chrysostome Michel, Pierre-François Bocage, Félicien Mallefille, Louis Blanc, and Frédéric Chopin (1837–1847). Later in life, she corresponded with Gustave Flaubert. Despite their obvious differences in temperament and aesthetic preference, they eventually became close friends. She engaged in an intimate friendship with actress Marie Dorval, which led to widespread but unconfirmed rumours of a lesbian affair. Letters written by Sand to Dorval made such references as "wanting you either in your dressing room or in your bed."
In Majorca one can still visit the (then-abandoned) Carthusian monastery of Valldemossa, where she spent the winter of 1838–1839 with Chopin and her children. This trip to Majorca was described by her in "" ("A Winter in Majorca"), first published in 1841. Chopin was already ill with incipient tuberculosis (or, as has recently been suggested, cystic fibrosis) at the beginning of their relationship, and spending a winter in Majorca—where Sand and Chopin did not realize that winter was a time of rain and cold, and where they could not get proper lodgings—exacerbated his symptoms. They separated two years before his death for a variety of reasons (some of which are explained below).
In her novel "Lucrezia Floriani", Sand used Chopin as a model for a sickly Eastern European prince named Karol. He is cared for by a middle-aged actress past her prime, Lucrezia, who suffers a great deal through her affection for Karol. Though Sand claimed not to have made a cartoon out of Chopin, the book's publication and widespread readership may have exacerbated their antipathy to each other. However, the tipping point in their relationship involved her daughter Solange.
Chopin continued to be cordial to Solange after she and her husband, Auguste Clésinger, had a vicious falling out with Sand over money. Sand took Chopin's support of Solange as outright treachery and confirmation that Chopin had always "loved" Solange. Sand's son Maurice also disliked Chopin. Maurice wanted to establish himself as the "man of the estate" and did not wish to have Chopin as a rival for that role. Chopin was never asked back to Nohant. In 1848, he returned to Paris from a tour of the United Kingdom, to die at the Place Vendôme in the following year. Chopin was penniless at that time; his friends had to pay for his stay there, as well as his funeral at the Madeleine. The funeral was attended by over 3,000 people, including Eugène Delacroix, Franz Liszt, Victor Hugo and other famous people. George Sand, however, was notable by her absence.
Sand was also known for her implication and writings during the Paris Commune, where she took a position for the Versailles assembly against the "communards", urging them to take violent action against the "rebels".
Writing.
A liaison with the writer Jules Sandeau heralded her literary debut. They published a few stories in collaboration, signing them "Jules Sand". Her first published novel, "Rose et Blanche" (1831), was written in collaboration with Sandeau. She subsequently adopted, for her first independent novel, "Indiana" (1832), the pen name that made her famous – George Sand.
Drawing from her childhood experiences of the countryside, she wrote the pastoral novels "La Mare au Diable" (1846), "François le Champi" (1847–1848), "La Petite Fadette" (1849), and "Les Beaux Messieurs Bois-Doré" (1857). "A Winter in Majorca" described the period that she and Chopin spent on that island from 1838 to 1839. Her other novels include "Indiana" (1832), "Lélia" (1833), "Mauprat" (1837), "Le Compagnon du Tour de France" (1840), "Consuelo" (1842–1843), and "Le Meunier d'Angibault" (1845). Theatre pieces and autobiographical pieces include "Histoire de ma vie" (1855), "Elle et Lui" (1859, about her affair with Musset), "Journal Intime" (posthumously published in 1926), and "Correspondence". Sand often performed her theatrical works in her small private theatre at the Nohant estate.
In addition, Sand authored literary criticism and political texts. She wrote many essays and published works establishing her socialist position. Because of her early life, she sided with the poor and working class. When the 1848 Revolution began, Sand started her own newspaper, which was published in a workers' co-operative. This allowed her to publish more political essays. She wrote: "I cannot believe in any republic that starts a revolution by killing its own proletariat."
She was known well in far reaches of the world, and her social practices, her writings and her beliefs prompted much commentary, often by other luminaries in the world of arts and letters. A few excerpts demonstrate much of what was often said about George Sand:
She was a thinking bosom and one who overpowered her young lovers, all Sybil—a Romantic.—V. S. Pritchett
What a brave man she was, and what a good woman.—Ivan Turgenev
The most womanly woman.—Alfred de Musset
The most widely used quote of her own is: "There is only one happiness in life, to love and be loved."
Death.
George Sand died at Nohant, near Châteauroux, in France's Indre "département" on 8 June 1876, at the age of 71 and was buried in the grounds of her home there. In 2003, plans that her remains be moved to the Panthéon in Paris resulted in controversy.
Contemporary views.
Sand's reputation came into question when she began sporting men's clothing in public, which she justified by the clothes being far sturdier and less expensive than the typical dress of a noblewoman at the time. In addition to being comfortable, Sand's male dress enabled her to circulate more freely in Paris than most of her female contemporaries, and gave her increased access to venues from which women were often barred, even women of her social standing. Also scandalous was Sand's smoking tobacco in public; neither peerage nor gentry had yet sanctioned the free indulgence of women in such a habit, especially in public (though Franz Liszt's paramour Marie d'Agoult affected this as well, smoking large cigars).
These and other behaviors were exceptional for a woman of the early and mid-19th century, when social codes—especially in the upper classes—were of the utmost importance. As a consequence of many unorthodox aspects of her lifestyle, Sand was obliged to relinquish some of the privileges appertaining to a baroness, though the mores of the period did permit upper-class wives to live physically separate from their husbands, without losing face, provided the estranged couple exhibited no blatant irregularity to the outside world.
Poet Charles Baudelaire was a contemporary critic of George Sand: "She is stupid, heavy and garrulous. Her ideas on morals have the same depth of judgment and delicacy of feeling as those of janitresses and kept women ... The fact that there are men who could become enamoured of this slut is indeed a proof of the abasement of the men of this generation." Other writers of the period, however, differed in their assessment. Flaubert, by no means an indulgent or forbearing critic, was an unabashed admirer. Honoré de Balzac, who knew Sand personally, once said that if someone thought George Sand wrote badly, it was because their own standards of criticism were inadequate. He also noted that her treatment of imagery in her works showed that her writing had an exceptional subtlety, having the ability to 'virtually put the image in the word'.
In literature.
Frequent literary references to George Sand can be found in "" (1990) by A. S. Byatt. The American poet Walt Whitman cited Sand's novel "Consuelo" as a personal favorite, and the sequel to this novel, "La Comtesse de Rudolstadt", contains at least a couple of passages that appear to have had a very direct influence on him. Elizabeth Barrett Browning (1806–61), the English poet, produced two poems: "To George Sand: A Desire" and "To George Sand: A Recognition". The character of Stepan Verkhovensky in Fyodor Dostoevsky's novel "Demons" took to translating the works of George Sand in his periodical, before the periodical was subsequently seized by the ever-cautious Russian government of the 1840s. (Dostoevsky himself "read widely in the numerous novels of George Sand" and translated her "La dernière Aldini" in 1844 but "discovered to his dismay that the work had already appeared in Russian".) Sand is also referred to in Virginia Woolf's book-length essay "A Room of One's Own" along with George Eliot and Currer Bell as "all victims of inner strife as their writings prove, sought ineffectively to veil themselves by using the name of a man".
George Sand is referenced a number of times in the play "Voyage", the first part of Tom Stoppard's "The Coast of Utopia" trilogy. And in the first episode of the "Overture" to "Swann's Way" – the first novel in Marcel Proust's "In Search of Lost Time" sequence – a young, distraught Marcel is calmed by his mother as she reads from "François le Champi", a novel which (it is explained) was part of a gift from his grandmother, which also included "La Mare au Diable", "La Petite Fadette", and "Les Maîtres Sonneurs". As with many episodes involving art in "À la recherche du temps perdu", this reminiscence includes commentary on the work. George Sand also makes an appearance in Isabel Allende's "Zorro", going still by her given name, as a young girl in love with Diego de la Vega, "i.e.", Zorro.
Works.
Plays.
</dl>

</doc>
<doc id="52593" url="http://en.wikipedia.org/wiki?curid=52593" title="Addis Ababa">
Addis Ababa

 
Addis Ababa (Amharic: አዲስ አበባ "Addis Abäba", ], “new flower”; Oromo: "Finfinne", ] "Natural Spring(s)"), sometimes spelled Addis Abeba (the spelling used by the official Ethiopian Mapping Authority), is the capital city of Ethiopia. Founded in 1886, it is the largest city in Ethiopia, with a population of 3,384,569 according to the 2007 population census with annual growth rate of 3.8%. This number has been increased from the originally published 2,738,248 figure and appears to be still largely underestimated.
As a chartered city ("ras gez astedader"), Addis Ababa has the status of both a city and a state. It is where the African Union and its predecessor the OAU are based. It also hosts the headquarters of the United Nations Economic Commission for Africa (UNECA) and numerous other continental and international organizations. Addis Ababa is therefore often referred to as "the political capital of Africa" due to its historical, diplomatic and political significance for the continent.
The city is populated by people from different regions of Ethiopia – the country has as many as 80 nationalities speaking 80 languages and belonging to a wide variety of religious communities. It is home to Addis Ababa University. The Federation of African Societies of Chemistry (FASC) and Horn of Africa Press Institute (HAPI) are also headquartered in Addis Ababa.
History.
The site of Addis Ababa was the chosen by Empress Taytu Betul and the city was founded in 1886 by Emperor Menelik II. Menelik, as initially a King of the Shewa province, had found Mount Entoto a useful base for military operations in the south of his realm, and in 1879 visited the reputed ruins of a medieval town, and an unfinished rock church that showed proof of an Ethiopian presence in the area before the campaigns of Ahmad ibn Ibrihim. His interest in the area grew when his wife Taytu began work on a church on Mount Entoto, and Menelik endowed a second church in the area.
However, the immediate area did not encourage the founding of a town due to the lack of firewood and water, so settlement actually began in the valley south of the mountain in 1886. Initially, Taytu built a house for herself near the "Filwoha" hot mineral springs, where she and members of the Showan Royal Court liked to take mineral baths. Other nobility and their staffs and households settled in the vicinity, and Menelik expanded his wife's house to become the Imperial Palace which remains the seat of government in Addis Ababa today. The name changed to Addis Ababa and became Ethiopia's capital when Menelik II became Emperor of Ethiopia. The town grew by leaps and bounds. One of Emperor Menelik's contributions that is still visible today is the planting of numerous eucalyptus trees along the city streets.
Following all the major engagements of their invasion, Italian troops from the colony of Eritrea entered Addis Ababa on 5 May 1936. Along with Dire Dawa, the city had been spared the aerial bombardment (including the use of chemical weapons such as mustard gas) practiced elsewhere and its railway to Djibouti remained intact. Under its Italian spelling "Addis Abeba", the city served as the Duke of Aosta's capital for the unified colony of Italian East Africa until 1941, when it was abandoned in favor of Amba Alagi and other redoubts during the Second World War's East African Campaign. The city was liberated by Major Orde Wingate's Sudanese and Ethiopian Gideon Force in time to permit Emperor Haile Selassie's return on 5 May 1941, five years to the day after he had left.
Following reconstruction, Haile Selassie helped form the Organisation of African Unity in 1963 and invited the new organization to keep its headquarters in the city. The OAU was dissolved in 2002 and replaced by the African Union (AU), also headquartered in Addis Ababa. The United Nations Economic Commission for Africa also has its headquarters in Addis Ababa. Addis Ababa was also the site of the Council of the Oriental Orthodox Churches in 1965.
Ethiopia has often been called the original home of mankind due to various humanoid fossil discoveries like the Australopithecine Lucy. North eastern Africa, and the Afar region in particular was the central focus of these claims until recent DNA evidence suggested origins in south central Ethiopian regions like present-day Addis Ababa. After analysing the DNA of almost 1,000 people around the world, geneticists and other scientists claimed people spread from what is now Addis Ababa 100,000 years ago. The research indicated that genetic diversity declines steadily the farther one's ancestors traveled from Addis Ababa, Ethiopia.
Geography.
Overview.
Addis Ababa lies at an altitude of 7,546 feet (2,300 metres) and is a grassland biome, located at . The city lies at the foot of Mount Entoto and forms part of the watershed for the Awash. From its lowest point, around Bole International Airport, at 2326 m above sea level in the southern periphery, the city rises to over 3000 m in the Entoto Mountains to the north.
Subdivision.
The city is divided into 10 boroughs named subcities (Amharic: ክፍለ ከተማ) and 99 wards (Amharic: ቀበሌ). The 10 subcities are:
Climate.
Addis Ababa has a subtropical highland climate (Köppen: Cwb). The city has a complex mix of highland climate zones, with temperature differences of up to 10 C-change, depending on elevation and prevailing wind patterns. The high elevation moderates temperatures year-round, and the city's position near the equator means that temperatures are very constant from month to month.
Mid-November to January is a season for occasional rain. The highland climate regions are characterized by dry winters, and this is the dry season in Addis Ababa. During this season the daily maximum temperatures are usually not more that 23 °C, and the night-time minimum temperatures can drop to freezing. The short rainy season is from February to May. During this period, the difference between the daytime maximum temperatures and the night-time minimum temperatures is not as great as during other times of the year, with minimum temperatures in the range of 10 -. At this time of the year the city experiences warm temperatures and a pleasant rainfall. The long wet season is from June to mid-September; it is the major winter season of the country. This period coincides with summer, but the temperatures are much lower than at other times of year due to the frequent rain and hail and the abundance of cloud cover and fewer hours of sunshine. This time of the year is characterized by dark, chilly and wet days and nights. The autumn which follows is a transitional period between the wet and dry seasons.
The highest record temperature was 32 C August 27, 1996, while the lowest record temperature was 0 C on November 23, 1999.
Demographics.
Based on the 2007 census conducted by the Ethiopian national statistics authorities the population of Addis Ababa is 3,384,569 million; all of the population are urban inhabitants. For the capital city 662,728 households were counted living in 628,984 housing units, which results in an average of 5.3 persons to a household. Although all Ethiopian ethnic groups are represented in Addis Ababa due to its position as capital of the country, the largest groups include the Amhara (47.04%), Oromo (19.51%), Gurage (16.34%), Tigray (6.18%), Silt'e (2.94%), and Gamo (1.68%). Languages spoken include Amharic (71.0%), Oromiffa (10.7%), Gurage (8.37%), Tigrinya (3.60%), Silt'e (1.82%) and Gamo (1.03%). The religion with the most believers in Addis Ababa is Ethiopian Orthodox with 74.7% of the population, while 16.2% are Muslim, 7.77% Protestant, and 0.48% Catholic.
In the previous census, conducted in 1994, the city's population was reported to be 2,112,737, of whom 1,023,452 were men and 1,089,285 were women. At that time not all of the population were urban inhabitants; only 2,084,588 or 98.7% were. For the entire administrative council there were 404,783 households in 376,568 housing units with an average of 5.2 persons per household. The major ethnic groups included the Amhara (48.3%), Oromo (19.2%), Gurage (13.5%; 2.3% Sebat Bet, and 0.8% Sodo), Tigray 7.64%, Silt'e 3.98%, and foreigners from Eritrea 1.33%. Languages spoken included Amharic (72.6%), Oromiffa (10.0%), Gurage (6.54%), Tigrinya (5.41%), and Silt'e 2.29%. In 1994 the predominant religion was also Ethiopian Orthodox with 82.0% of the population, while 12.7% were Muslim, 3.87% Protestant, and 0.78% Catholic.
According to the 2007 national census, 98.64% of the housing units of Addis Ababa had access to safe drinking water, while 14.9% had flush toilets, 70.7% pit toilets (both ventilated and unventilated), and 14.3% had no toilet facilities. Values for other reported common indicators of the standard of living for Addis Ababa as of 2005[ [update]] include the following: 0.1% of the inhabitants fall into the lowest wealth quintile; adult literacy for men is 93.6% and for women 79.95%, the highest in the nation for both sexes; and the civic infant mortality rate is 45 infant deaths per 1,000 live births, which is less than the nationwide average of 77; at least half of these deaths occurred in the infants’ first month of life.
The City is partially powered by water at the Koka Reservoir.
Economy.
The economic activities in Addis Ababa are diverse. According to official statistics from the federal government, some 119,197 people in the city are engaged in trade and commerce; 113,977 in manufacturing and industry; 80,391 homemakers of different variety; 71,186 in civil administration; 50,538 in transport and communication; 42,514 in education, health and social services; 32,685 in hotel and catering services; and 16,602 in agriculture. In addition to the residents of rural parts of Addis Ababa, the city dwellers also participate in animal husbandry and cultivation of gardens. 677 ha of land is irrigated annually, on which 129,880 quintals of vegetables are cultivated. It is a relatively clean and safe city, with the most common crimes being pickpocketing, scams and minor burglary. The city has recently been in a construction boom with tall buildings rising in many places. Various luxury services have also become available and the construction of shopping malls has recently increased. According to Tia Goldenberg of "IOL", area spa professionals said that some people have labelled the city, "the spa capital of Africa."
Ethiopian Airlines has its headquarters on the grounds of Bole International Airport in Addis Ababa.
Government.
Pursuant to the Ethiopian Constitution of 1995, the city of Addis Ababa is one of the two federal cities that are accountable to the Federal Government of Ethiopia. The other city with the same status is Dire Dawa in the east of the country and both federal cities are located within the State of Oromia. Earlier, following the establishment of the federal structure in 1991 under the Transitional Charter of Ethiopia, the City Government of Addis Ababa was one of the then new 14 regional governments. However, that structure was changed by the federal constitution in 1995 and as a result Addis Ababa does not have statehood status.
The administration of Addis Ababa city consists of the Mayor, who leads the executive branch, and the City Council, which enacts city regulations. However, as part of the Federal Government, the federal legislature enacts laws that are binding in Addis Ababa. Members of the City Council are directly elected by the residents of the city and the Council, in turn, elects the Mayor among its members. Term of office for elected officials is five years. However, the Federal Government, when it deems necessary, can dissolve the City Council and the entire administration and replace it by a temporary administration until elections take place next. Residents of Addis Ababa are represented in the federal legislature, the House of Peoples' Representatives. However, the city is not represented in the House of Federation, which is the federal upper house constituted by the representatives of the member states. The executive branch under the Mayor comprises the City Manager and various branches of civil service offices.
The current Mayor of Addis Ababa is Mr. Diriba Kuma from the Oromo People Democratic Organisation (OPDO), which is member of the ruling coalition Ethiopian Peoples Revolutionary Democratic Front (EPRDF). Mr. Diriba Kuma took office on 9 July 2013. His predecessor, Mr. Kuma Demeksa (also from the OPDO party), served a five-year term from 30 October 2008. Before that, the Federal Government appointed Mr. Berhane Deressa to lead the temporary caretaker administration that served from 9 May 2006 to 30 October 2008 following the 2005 election crisis. In the 2005 national election, the ruling EPRDF party suffered a major defeat in Addis Ababa. However, the opposition who won in Addis Ababa did not take part in the government both on regional and federal level. This situation forced the EPRDF-led Federal Government to assign a temporary administration until a new election was carried out. As a result, Mr. Berhane Deressa, an independent citizen, was appointed.
Some of the notable past mayors of Addis Ababa are Arkabe Oqubay (2003–06), Zewde Teklu (1985–89), Alemu Abebe (1977–85) and Zewde Gebrehiwot (1960–69).
Landmarks.
High rise, architecture and skyline.
Mayor Kuma Demeksa embarked on a quest to improve investment for the buildings in the city. Addis Ababa is the headquarters of the United Nations Economic Commission for Africa and the African Union.
The fossilized skeleton, and a plaster replica of the early hominid Lucy (known in Ethiopia as "Dinkinesh") is preserved at the Ethiopian National Museum in Addis Ababa. Meskel Square is one of the noted squares in the city and is the site for the annual Meskel at the end of September annually when thousands gather in celebration.
The city is home to the Ethiopian National Library, the Ethiopian Ethnological Museum (and former Guenete Leul Palace), the Addis Ababa Museum, the Ethiopian Natural History Museum, the Ethiopian Railway Museum and National Postal Museum.
Notable taller architecture in Addis Ababa includes the Huda Tower, Nani Tower, Bank Misr Building, as well as the approved Angola World Trade Center Tower, Abyssinia Bank Tower, Mexico Square Tower and the 200 million dollar AU Conference Center and Office Complex.
Culture.
Notable buildings include St George's Cathedral (founded in 1896 and also home to a museum), Holy Trinity Cathedral (once the largest Ethiopian Orthodox Cathedral and the location of Sylvia Pankhurst's tomb) as well as the burial place of Emperor Haile Selassie and the Imperial family, and those who fought the Italians during the war. There is also Menelik's old Imperial palace which remains the official seat of government, and the National Palace formerly known as the Jubilee Palace (built to mark Emperor Haile Selassie's Silver Jubilee in 1955) which is the residence of the President of Ethiopia. Africa Hall is located across Menelik II avenue from this Palace and is where the United Nations Economic Commission for Africa is headquartered as well as most UN offices in Ethiopia. It is also the site of the founding of the Organisation of African Unity (OAU) which eventually became the African Union. The African Union is now housed in a new headquarters built on the site of the demolished Akaki Prison, on land donated by Ethiopia for this purpose in the south western part of the city. The Hager Fikir Theatre, the oldest theatre in Ethiopia, is located at the Piazza district. Near Holy Trinity Cathedral is the art deco Parliament building, built during the reign of Emperor Haile Selassie, with its clock tower. It continues to serve as the seat of Parliament today. Across from the Parliament is the Shengo Hall, built by the Derg regime of Mengistu Haile Mariam as its new parliament hall. The Shengo Hall was the world's largest pre-fabricated building, which was constructed in Finland before being assembled in Addis Ababa. It is used for large meetings and conventions. Itegue Taitu Hotel, built in 1898 (Ethiopian Calendar) in the middle of the city (Piazza), was the first hotel in Ethiopia.
In the Merkato district, which happens to be the largest open market in Africa, is the impressive Grand Anwar Mosque, the biggest mosque in Ethiopia built during the Italian occupation. A few metres to the southwest of the Anwar Mosque is the Raguel Church built after the liberation by Empress Menen. The proximity of the mosque and the church has symbolised the long peaceful relations between Christianity and Islam in Ethiopia. The Roman Catholic Cathedral of the Holy Family is also in the Merkato district. Near Bole International Airport is the new Medhane Alem (Savior of the World) Orthodox Cathedral, which is the second largest in Africa.
Other features of the city include the large Mercato market, the Jan Meda racecourse, Bihere Tsige Recreation Centre and a railway line to Djibouti. Sport facilities include Addis Ababa and Nyala Stadiums. The 2008 African Championships in Athletics were held in Addis Ababa.
The Entoto Mountains start among the northern suburbs. Suburbs of the city include Shiro Meda and Entoto in the north, Urael and Bole (home to Bole International Airport) in the east, Nifas Silk in the south-east, Mekanisa in the south, and Keraniyo and Kolfe in the west. Kolfe was mentioned in Nelson Mandela's Autobiography "A Long Walk to Freedom", as the place he got military training.
Parks include Africa Park, situated along Menelik II Avenue.
Development.
The city hosts the We Are the Future centre, a child care centre that provides children with a higher standard of living. The centre is managed under the direction of the mayor’s office, and the international NGO Glocal Forum serves as the fundraiser and programme planner and coordinator for the WAF child centre in each city. Each WAF city is linked to several peer cities and public and private partners to create a unique international coalition.
Launched in 2004, the programme is the result of a strategic partnership between the Glocal Forum, the Quincy Jones Listen Up Foundation and Mr. Hani Masri, with the support of the World Bank, UN agencies and major companies.
Education.
Addis Ababa University was founded in 1950 and was originally named "University College of Addis Ababa", then renamed in 1962 for the former Ethiopian emperor Haile Selassie I who had donated his Genete Leul Palace to be the university's main campus in the previous year. It received its current name in 1975 after the Emperor was deposed. Although the university has six of its seven campuses within Addis Ababa (the seventh is located in Debre Zeit, about 45 km away), it also maintains branches in many cities throughout Ethiopia. It is the home of the Institute of Ethiopian Studies and the Ethnological Museum. The city also has numerous public universities and private colleges including Ethiopian Civil Service University, Admas University College and Unity University. A massive new university solely dedicated to science and technology is under construction in the east of the city.
Transport.
Public transport is through public buses from Anbessa City Bus Service Enterprise or blue and white share taxis. The taxis are usually minibuses that can seat at most twelve people. Two people are responsible for each taxi, the driver and a "weyala" who collects fares and calls out the taxi's destination.
Road.
The construction of the Addis Ababa Ring Road was initiated in 1998 to implement the city master plan and enhance peripheral development. The Ring Road was divided into three major phases that connect all the five main gates in and out of Addis Ababa with all other regions (Jimma, Debre Zeit, Mekelle, Gojjam and Ambo). For this project, China Road and Bridge Corporation (CRBC) was the partner of Addis Ababa City Roads Authority (AACRA). The Ring Road has greatly helped to decongest and alleviate city traffic.
Intercity bus service is provided by the Selam Bus Line Share Company.
Air.
The city is served by Addis Ababa Bole International Airport, where a new terminal opened in 2003. The old Lideta Airport in the western "Old Airport" district is used mostly by small craft and military planes and helicopters.
Railway.
Addis Ababa also has had a railway connection with Djibouti City, with a picturesque French style railway station, but the railway no longer operates; a new modern rail line is to be built in the near future.
Light Rail.
A light rail system is complete; in September 2010, Ethiopian Railway Corporation reached a funding agreement with Export and Import Bank of China and the light rail project was completed in January 2015. The route is a 34.25 km network with two lines; an east-west line from Ayat to the Torhailoch ringroad, and from Menelik Square to Merkato Bus Station, Meskel Square and Akaki which is currently in testing and will open in June 2015.

</doc>
<doc id="52594" url="http://en.wikipedia.org/wiki?curid=52594" title="60 BC">
60 BC

Year 60 BC was a year of the pre-Julian Roman calendar. At the time, it was known as the Year of the Consulship of Metellus and Afranius (or, less frequently, year 694 "Ab urbe condita"). The denomination 60 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
China.
</onlyinclude>

</doc>
<doc id="52595" url="http://en.wikipedia.org/wiki?curid=52595" title="61 BC">
61 BC

Year 61 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Calpurnianus and Messalla (or, less frequently, year 693 "Ab urbe condita"). The denomination 61 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Roman Republic.
</onlyinclude>

</doc>
<doc id="52596" url="http://en.wikipedia.org/wiki?curid=52596" title="62 BC">
62 BC

Year 62 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Silanus and Murena (or, less frequently, year 692 "Ab urbe condita"). The denomination 62 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Commagene.
</onlyinclude>

</doc>
<doc id="52598" url="http://en.wikipedia.org/wiki?curid=52598" title="63 BC">
63 BC

Year 63 BC was a year of the pre-Julian Roman calendar. At the time it was known as the Year of the Consulship of Cicero and Hybrida (or, less frequently, year 691 "Ab urbe condita"). The denomination 63 BC for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.
Events.
<onlyinclude>
By place.
Pontus.
</onlyinclude>

</doc>
<doc id="52599" url="http://en.wikipedia.org/wiki?curid=52599" title="Monoculture">
Monoculture

Monoculture is the agricultural practice of producing or growing a single crop or plant species in a field at a time. Polyculture, where more than one crop is grown in the same space at the same time, is the alternative to monoculture. Monoculture is widely used in modern industrial agriculture and its implementation has allowed for increased efficiencies in planting and harvest.
Continuous monoculture, or monocropping, where the same species is grown year after year, can lead to the quicker buildup of pests and diseases, and then rapid spread where a uniform crop is susceptible to a pathogen. This is in contrast to crop rotation, where monocultures of various crops are rotated on a field over time. Oligoculture has been suggested to describe a crop rotation of just a few crops, as is practiced by several regions of the world.
The term is frequently applied for other uses to describe any group dominated by a single variety, e.g. social Monoculturalism, or in the field of musicology to describe the dominance of the American and British music-industries in Western pop music, or in the field of computer science to describe a group of computers all running identical software.
Land use.
The term is mostly used in agriculture and describes the practice of planting crops with the same patterns of growth resulting from genetic similarity. Examples include wheat fields or apple orchards or grape vineyards. These cultivars have uniform growing requirements and habits, resulting in greater yields on less land because planting, maintenance (including pest control), and harvesting can be standardized. This standardization results in less waste and loss from inefficient harvesting and planting. It also is beneficial because a crop can be tailor-planted for a location that has special problems – like soil salt or drought or a short growing season.
Monoculture produces great yields by utilizing plants' abilities to maximize growth under less pressure from other species and more uniform plant structure. Uniform cultivars are able to better use available light and space, but also have a greater drain on soil nutrients. In the last 40
years, modern practices such as monoculture planting and the use of synthesized fertilizers have greatly reduced the amount of land needed to produce much higher yielding crops. A huge problem with growing any crop in a monoculture is that once the land has been used to agriculture for a single species, soil fertility diminishes greatly.
Forestry.
In forestry, monoculture refers to the planting of one species of tree. Monoculture plantings provide great yields and more efficient harvesting than natural stands of trees. Single-species stands of trees are often the natural way trees grow, but the stands show a diversity in tree sizes, with dead trees mixed with mature and young trees. In forestry, monoculture stands that are planted and harvested as a unit provide limited resources for wildlife that depend on dead trees and openings, since all the trees are the same size; they are most often harvested by clearcutting, which drastically alters the habitat. The mechanical harvesting of trees can compact soils, which can adversely affect understory growth. Single-species planting of trees also are more vulnerable when infected with a pathogen, or are attacked by insects, and by adverse environmental conditions.
Lawns and animals.
Examples of monoculture include lawns and most field crops, such as wheat or corn. The term is also used where a single species of farm animal is raised in large-scale concentrated animal feeding operations (CAFOs).
Disease.
Monocultures used in agriculture are usually single strains that have been bred for high yield and resistant to certain common diseases. Since all plants in a monoculture are genetically similar, if a disease strikes to which they have no resistance, it can destroy entire populations of crops. Polyculture, which is the mixing of different crops, has natural variation and a likelihood that one or more of the crops will be resistant to any particular pathogen. Studies have shown planting a mixture of crop strains in the same field to be effective at combating disease. Ending monocultures grown under disease conditions by introducing crop diversity has greatly increased yields. In one study in China, the planting of several varieties of rice in the same field increased yields of non-resistant strains by 89% compared to non-resistant strains grown in monoculture, largely because of a dramatic (94%) decrease in the incidence of disease, making pesticides less necessary. There is currently a great deal of international worry about the wheat leaf rust fungus, that has already decimated wheat crops in Uganda and Kenya, and is starting to make inroads into Asia as well. As much of the world's wheat crops are very genetically similar following the Green Revolution, the impacts of such diseases threaten agricultural production worldwide.
Polyculture.
The environmental movement seeks to change popular culture by redefining the "perfect lawn" to be something other than a turf monoculture, and seeks agricultural policy that provides greater encouragement for more diverse cropping systems. Local food systems may also encourage growing multiple species and a wide variety of crops at the same time and same place. Heirloom gardening has come about largely as a reaction against monocultures in agriculture.

</doc>
<doc id="52605" url="http://en.wikipedia.org/wiki?curid=52605" title="Port Talbot">
Port Talbot

Port Talbot ( or ) is a town in the county borough of Neath Port Talbot, Wales. It had a population of 37,276 in 2011.
History.
The earliest evidence of humans in Port Talbot has been found on the side of Mynydd Margam where farming ditches can be found at an age of 4,000 BC during the Bronze Age. There were Iron Age hill forts on Mynydd Dinas, Mynydd Margam, Mynydd Emroch and other mountains. Mynydd Hawdef contains remains of an ancient Iron Age village. The Margam deer herd was first introduced by the Romans.
Historically in Glamorgan, Port Talbot grew out of the original small port and market town of Aberafan, which belonged to the medieval Lords of Afan.
Aberafan was first established by Caradoc ap Iestyn (son of Iestyn ap Gwrgant), on the instructions of Robert Fitzhamon, after the Normans' conquest of south Wales by the end of the eleventh century. The town grew up with and around the castle which Fitzhamon ordered to be built (where Castle, Norman and Bailey streets are situated near to Saint Mary's Church in modern-day Port Talbot). The first recorded name of Aberafan was the French Norman 'Avene' which is likely to be an interpretation of the Welsh 'a-bhan' meaning 'from the heights' meaning the hills of the Afan Valley, from whence flowed the River Afan. 'Afan' is always pronounced 'Avan'. Margam Abbey was founded in 1147 as a daughter house of Clairvaux, a Cistercian foundation, by Robert, 1st Earl of Gloucester. Local landowner John Talbot, fought at the Battle of Crécy, and bred the Talbot dog, a breed of small white dog, an ancestor of the modern Beagle.
The English antiquarian John Leland made an extensive journey through Wales c.1536-39 of which he recorded an itinerary. He passed through Aberafan, which he describes as a "poor village" surrounded by barren ground, though he also describes the area as heavily wooded, not much of which remains today. He mentions the use of the river mouth as a port, a "haven for ships" as he puts it. His portrayal of Aberafan as a small, struggling village however suggests that the port was not in great use, especially as traffic to and from Margam Abbey would have ceased following its dissolution in 1536.
The area of the parish of Margam lying on the west bank of the lower Afan became industrialised following the establishment of a copperworks in 1770. The Afan was diverted and a dock was opened in 1839 named for the Talbot family, local landowners who were related to the pioneer photographer, William Henry Fox Talbot. The Talbots were patrons of Margam Abbey, and also built Margam Castle. Christopher Rice Mansel Talbot (1803–1890) (Liberal Member of Parliament for Glamorgan from 1830 until his death) saw the potential of his property as a site for an extensive ironworks, which opened in early 1831.
CRM Talbot's daughter Emily Charlotte Talbot (1840–1918) inherited her father's fortune and became just as notable in the development of ports and railways. With assistance from engineers Charles Meik and Patrick Meik, she set about creating a port and railway system to attract business away from Cardiff and Swansea. The Port Talbot Railway and Docks Company opened a dock at Port Talbot and the Llyfni Railway in 1897, followed by the Ogmore Valley Extension and the South Wales Mineral Junction Railway (almost all these lines were closed as part of the Beeching Axe cuts in the mid-1960s, but some bridges and viaducts remain and many of these railway routes have re-emerged as recreational cycle tracks). By 1900, the dock was exporting over 500,000 tons of coal; it reached a peak of over three million tons in 1923.
In 1952 the completion of the Abbey Works by the Steel Company of Wales made Port Talbot the home of one of Europe's largest integrated steelworks and (with 18,000 employees) the largest employer in Wales. This was followed by the establishment of a chemical plant at Baglan Bay by British Petroleum (now BP) in the 1960s. In 1970 a new deep-water harbour was opened by Queen Elizabeth II and the Duke of Edinburgh. This harbour was capable of discharging iron ore vessels of 100,000 deadweight, a tenfold improvement on the old dock. By the early 21st century, due to further modification and dredging, the harbour is capable of harbouring vessels of over 170,000 tons deadweight.
Around 400 years ago the Welsh and English border ran through Kenfig. Wales was on the West and the English side was East of Kenfig castle which was on the border between the two nations, the castle was attacked and eventually defeated by the Welsh. Incoming sand caused the residents of Kenfig to move and build a new town now called Pyle.
Governance.
In November 1921, the borough of Port Talbot was created, incorporating Margam, Cwmafan and the older town of Aberafan. It was therefore 85 years after the phrase 'Port Talbot' was first used, that the town's name was officially and legally recognised. Historically, Port Talbot is part of the historic county of Glamorgan. The 1974 county council re-organisation split Glamorgan into three new counties, and Port Talbot was one of four districts of West Glamorgan.
Following the demise of the West Glamorgan County Council, the Port Talbot borough council was merged with Neath and part of Lliw Valley Districts to create the new unitary authority of Neath Port Talbot County Borough in 1996. The Civic Centre is located in Port Talbot, and the town is represented by three of the 64 councillors that make up the county council.
Physical geography.
The town is built along the eastern rim of Swansea Bay in a narrow strip of coastal plain surrounding the River Afan estuary. Swansea is visible on the opposite side of Swansea Bay. The local beach is known as Aberafan Sands and is situated along the edge of the bay between the River Afan and the River Neath. The other beach in Port Talbot is Margam Sands, popularly known as Morfa Beach. The north-eastern edge of the town is marked by the River Neath. A significant landmark in the town is the Port Talbot Steelworks.
Human geography.
The town is still said to be the most polluted place in Wales and the most polluted in the United Kingdom outside of London. However, air quality in the Port Talbot area has improved.
63% of Port Talbot population in 2000 was between the ages of 15-64. Male unemployment in 2000 was around 9%, with female unemployment around 45% in 2000.
Geology.
Port Talbot has a variety of bedrock and drift types.
Bedrock geology.
South East of Port Talbot is dominated by Pennant sandstone which forms this high relief area including Mynydd Margam, Mynydd Dinas and the other mountains. The pennant sandstone is made up of two formations which are the Rhondda Member and Brithdir Member. The sandstone formed in Carboniferous swamps 300 million years ago. Pennant sandstone is a micacous sandstone which has a brown colouration with areas of red staining where iron from pyrite in coal has weathered creating a rust colouration.
Lower land areas are predominantly Pennant sandstone within the South Wales Middle Coal Measures Formation, South Wales Upper Coal Measures Formation and South Wales Lower Coal Measures Formation.
Drift geology.
There is a variety of drift deposits in Port Talbot. Sandfields area of Port Talbot is built upon blown sand and tidal flat deposits. These were deposited by alluvial processes (wind) and fluvial processes (water). Velindre area of Port Talbot is built upon an alluvial fan deposit. This deposit formed during the last glacial period 14,000 years ago. Baglan Road in Port Talbot is built upon glacial till from the Devensian period. Till, also known as boulder clay, is a mix of unconsolidated sediment with a range of grain sizes (clay-boulder). This forms as the fronts of glaciers rapidly deposit material due to melting. Cwmafan in Port Talbot is built upon alluvial and glaciofluvial deposits, formed from glacial melt water. Baglan Moors, Fairfield and Port Talbot town centre are built upon tidal flat deposits (tides were higher 12,000 years ago allowing sandy deposits to accumulate).
Economic geology.
Coal seams within the Pennant sandstone run North West-South East and East-West. The coal seams arise from the South Wales Middle Coal Measures Formation, South Wales Upper Coal Measures Formation, South Wales Lower Coal Measures Formation, Rhondda Member and Brithdir Member. Pennant sandstone is an excellent construction rock and road stone.
Structural geology.
Faults have an orientation of North West-South East, Eas-West and North-South. All are normal faults which form extension processes. There are also many marine fossils bands.
Bio-stratigraphy/palaeontology.
Marine fossils found in Port Talbot region include species of bivalves, gastropods and brachiopods. Terrestrial fossils include fern tree branches, trunks, leaves and roots. Traces of organism footprints can also be found.
Engineering geology.
Drift geology average thickness is between 3 metres to 20 metres. Several landslips occur in the highlands including many bole holes historically made for the construction of the M4 motorway, steelworks and coal mines.
Hydro-geology.
Rivers in the region are fault guided meaning that they flow is highly influenced by a structural weakness called a fault. Several natural springs occur in the highland regions with a neutral to slightly acidic ph values. Natural ground water levels varies from 10 metres below the Tiabach area of Port Talbot to over 20 metres. Rivers in the region including the River Afan (Aberafan), River Neath (Baglan Bay), Ffrwd wyllt (Tibach), Arnallt Brook (Tiabach), Baglan Brook (Baglan) and other rivers are fast flowing and are highly influenced by their mouths (end of the rivers, tidal region). A spout can be found in Baglan Park in the Baglan region of Port Talbot. Many open and uncovered reservoirs exist in the region. Water has been channelled into ditches in industrial areas of Port Talbot.
Marine geo-science and oceanography.
Port Talbot sea floor topography ranges from 0m to 15m within Swansea Bay. There are many patches within the bay including the North Kenfig patches, green grounds, outer green grounds, madjoe and stalheim. These patches are created from faults, hollows, general topography and other factors. Sea depth around Port Talbot is 10m-50m with increasing depth with increasing distance from the coast. There are two beaches within Port Talbot: Aberafan and Morfa. Sand at both beaches are yellow and semi-shell rich. Tide in the area has a harmonic prediction which means it can be predicted easy and has repeatable tide heights every year. The outer bay area and sea area near Port Talbot Pier has a tidal stream with no harmonic prediction. A tidal stream (or tidal current) is an alternating horizontal movement of water associated with the rise and fall of the tide caused by tide-producing forces. This means that the tide can not be accurately predicted due to additional factors like currents, rip current, river mouths and precipitation. There are also two major dumping grounds within the bay. These are areas were sand is collected for construction industry. Port Talbot docks is a deep water harbour which allows large cargo shape to dock into the area.
Sport.
Sporting teams in Port Talbot include:
The town is part of the Ospreys rugby union region, by which it is represented at the top level of the sport.
Margam Forest to the northeast of the Port Talbot is used as a venue for a stage of the annual Wales Rally GB. In the past, the rally route has traversed Margam Country Park.
Afan Forest Park to the north of the town has a number of dedicated mountain biking trails including the 'Penhydd', 'Y Wâl', 'Skyline', 'White's Level' and 'W²'.
Port Talbot has an array of higher level football. With two historically dominant football teams in the town (Port Talbot Town F.C. and Afan Lido F.C.), also Welsh Football League First Division high-flyers Goytre United F.C. are based just outside of Port Talbot. The town's nearest Welsh Premier League team Port Talbot and Afan Lido A.F.C, who are located in Port Talbot. Swansea City A.F.C. and Cardiff City F.C. are also premier league clubs which are in close vicinity of Port Talbot.
Education.
There are five comprehensive schools situated within the Port Talbot area:
A campus of Neath Port Talbot College is located in the Margam area. The Margam campus was previously called Afan College.
South Wales Miners' Museum.
The South Wales Miners' Museum is located in Cynonville, Cymmer.
Margam Stones Museum.
The nearby Margam Stones Museum has early Christian inscribed stones and Celtic crosses, including four from the area now under the Steelworks. A Roman milestone, an 8th-century pillar, and two Celtic crosses from the 10th century were all rescued from the steelworks site by the Talbot family and taken to Margam, where they are now in the museum, in the care of Cadw.
Port Talbot Historical Society.
Port Talbot Historical Society was founded in 1954 and is based in Carmel Chapel, in the town centre. The group is dedicated to the research and recording of local history and has published a number of books over the years. Their website is www.historicalporttalbot.com
Media.
The area is served by several radio stations: The Wave (96.4FM), Swansea Sound (1170MW), Nation Hits (102.1FM), Real Radio (106.0FM) and Nation Radio (107.3FM), all of which are available on DAB. Radio Phoenix also operates a 24-hour hospital radio service for the patients & staff of Neath Port Talbot Hospital in Baglan Moors.
In 2005 the area was granted its first radio station when Afan FM, the inspiration of a group of local young people headed by 19-year-old Craig Williams, was awarded a five-year licence by Ofcom to serve Port Talbot and neighbouring Neath. Afan FM transmitted on 107.9FM and online via its website, broadcasting from the AquaDome leisure complex on Aberafan Seafront. Following a December 2009 fire at the AquaDome, Afan FM moved to Aberafan House, adjacent to the town's shopping centre. In late 2011 Afan FM was shut down after an unexpected tax bill; it ceased live broadcasting at 2pm on 13 December 2011.
The town is served by several newspapers. The Port Talbot Guardian was a weekly paper published by Media Wales, part of the Trinity Mirror group, but ceased publication in October 2009. The Swansea-based daily South Wales Evening Post and the weekly Courier and Tribune are also distributed in the town and are published by South West Wales Publications, part of the Northcliffe Media group.
Neath Port Talbot Council publish a quarterly newsletter entitled "Pride" - which is delivered to every home in the Neath Port Talbot area.
The is a hyperlocal online website that publishes local news and events from the Neath and Port Talbot area. Port Talbot Magnet started as a free printed issue in September 2013 distributed to Port Talbot postcodes SA12 and SA13.
"Cân i Gymru" is usually filmed in Port Talbot. TV programmes such as "Doctor Who" and "The Sarah Jane Adventures" have filmed in this town.
The Passion in Port Talbot.
In April 2011, actor Michael Sheen led a 72-hour National Theatre Wales production of a modern retelling of The Passion. The play began at 0530 BST on Good Friday with a seafront scene, inspired by John the Baptist's baptism of Jesus, which was watched by hundreds who had heard about it by word of mouth.
By the time the first main part of the play was performed on Aberafan Beach at 1500 BST, organisers estimated up to 6,000 people had gathered to watch.
On Saturday, there were sequences in Llewellyn Street, the Castle Street underpass, Aberafan Shopping Centre, the Seaside Social and Labour Club in Sandfields and nearby Abbeyville Court.
On Easter Sunday, the production returned to Aberafan Beach as part of the finale. A trial was performed on Civic Square before a procession from Station Road, with the final scene, "the cross", at Aberafan seafront. By the time the procession had reached the seafront close to where it had begun 72 hours earlier, organisers estimate over 13,000 people had come to watch on the small roundabout.
In April 2012, Michael Sheen returned to attend the world premiere of a two-hour feature-length film "The Gospel of Us" based on The Passion. The premiere was held at the Apollo Cinema (now the Reel Cinema) on the Aberafan seafront close to where The Passion took place. Tickets for the premiere sold out weeks before the showing; all six screens showed the film simultaneously. The film was also shown daily from Easter Sunday to the following Thursday prior to its UK-wide release the next day, 13 April 2012.
Transport.
Railways.
Port Talbot is served by the South Wales Main Line at Port Talbot Parkway railway station. First Great Western and Arriva Trains Wales serve the station with services westbound to Neath and Swansea and West Wales Line and eastbound to Bridgend, Cardiff Central, Newport, Bristol Parkway, Swindon, Didcot Parkway, Reading and London Paddington. Trains also run via Hereford and Shrewsbury to Crewe and Manchester Piccadilly.
Other.
Port Talbot bus station, located adjacent to the Aberafan Centre in the centre of the town is the main bus transport hub, it is a National Express stop. Local bus services are provided by First Cymru, South Wales Transport & Veolia Transport Cymru. The bus station's layout is very distinctive for the fact that buses always have to perform a 270° clockwise turn to exit the station. A Sustrans cycle route has recently been constructed at this bus station as part of the connect2 scheme connecting the Afan Valley with Aberafan beach.
The M4 motorway cuts through the town from southeast to northwest, crossing a central area on a concrete viaduct, junctions 38 to 41 serve Port Talbot, with junctions 40 and 41 being in the commercial heart of the town. This busy urban stretch of the M4, with tight bends, 2-lane carriageways, short narrow slip roads and concrete walls on both sides, was the first length of motorway in Wales when it opened to traffic in 1966. The road has a speed limit of 50 mi/h enforced with a speed camera in the eastbound direction. The stretch through Port Talbot town centre is a particular traffic congestion blackspot and there have been calls to close the slip roads at junctions 40 and 41 to improve traffic flow. However some commuters oppose this plan since it would add more time to their journey. A new dual carriageway relief road, the Port Talbot Peripheral Distribution Road (PDR), is planned for completion in 2012. The new carriageway will serve as a distributor road to the southwest of Port Talbot, beginning at M4 Junction 38 ending near Junction 41.
The Port Talbot Docks complex consist of an inner set of floating docks and an outer tidal basin. Construction of the tidal basin began in 1964 and the whole basin covers about 500 acre. The tidal basin is capable of handling ships of up to 170,000 dwt and is used mostly for the import of iron ore and coal for use by nearby Port Talbot Steelworks. The inner floating docks were constructed in 1898 and were closed in 1959. They were re-opened in 1998 for commercial shipping and in March 2007 for the import of some steel products and are capable of handling ships of up to 8,000 dwt. There have been proposals for the development of an intermodal freight terminal at the port.
Economy.
Heavy industry is a visible feature of Port Talbot's economy. The coastal strip of the town features Port Talbot Steelworks, a large BOC Industrial Gases plant, a biomass power station and a gas-fired power station. Further power plants are being planned or commissioned: at Margam adjacent to the BOC plant, at Aberafan Beach sea front and a recently announced £60m project within Corus to utilise by-product gases. 
On 20 November 2007, the Department for Business, Enterprise and Regulatory Reform (BERR) granted consent for the world's largest biomass power station to be built at Port Talbot. This is expected to provide enough electricity (from wood from environmentally-managed forests, mostly in North America) to supply half the homes in Wales with electricity.
Potential future development currently centres around the peripheral distributor road to the south (the dual carriageway road in the Margam and Tiabach areas was finished in 2013), Baglan Industrial Park and Baglan Energy Park to the west, Port Talbot Docks to the southwest, Margam Country Park to the east and the Afan Valley to the north. In March 2009 Neath Port Talbot County Borough Council announced a regeneration project for Port Talbot town centre and docks, with a masterplan for new homes, offices, light industry, retail developments and improvements to the railway station.
Economic factors.
A recent local council research project into industry revealed that 37.4% of Port Talbot's workforce belong in the public sector, notably Health and Social Care. Port Talbot is also the site for Neath Port Talbot General Hospital, which houses a psychiatric ward and drug rehabilitation centre, including a Juvenile wing which provides temporary emergency care for 15-18 year olds lasting up to seven days before being placed in a secure psychiatric unit. According to the office of national statics between April 2012 to March 2013 25,400 (7.8%) between the ages of 16-64 were economically inactive, 60,100 (70.3%) between the ages of 16-64 were economically active, Unemployment rate was 7.8% and employment rate was 64.9%.
Youth organisations.
Port Talbot is home to a number of youth organisations. They are operated by Neath Port Talbot County Borough Council, the Ministry of Defence and a range of other charitable organisations.
Council youth groups.
Neath Port Talbot County Borough Council operates youth clubs in Blaengwynfi, Bryn, Bryncoch, Cimla, Croeserw, Crynant, Cwmafan, Cwmllynfell, Cymmer, Glyncorrwg, Glynneath, Hengwrt, Neath, Sandfields, Seven Sisters, Taibach and Ystalyfera.
Cadet organisations.
Port Talbot Detachment, Dyfed and Glamorgan Army Cadet Force
Sea rescue.
Port Talbot coastguard celebrated its centenary in 2008 with a history of rescues in the last 100 years. The crew are now the mud rescue team for the Swansea Bay area. Port Talbot Coastguard are one of the seven rescue teams that make up the Gower Sector.
Port Talbot also has an Inshore Lifeboat, which is part of the RNLI (Royal National Lifeboat Institution). Set about making sure the Inwater docks, Aberafan Beach and rivers along the route are safe.
Both sea rescue organisations, are opposite each other, and are used to working in partnership for effective beach and sea safety.

</doc>
<doc id="52606" url="http://en.wikipedia.org/wiki?curid=52606" title="River Afan">
River Afan

The River Afan (generally anglicized as "Avon", and sometimes historically as "Avan") is a river in southwest Wales whose river valley formed the territory of the medieval Lords of Afan. The Afan Valley encompasses the upper reaches of the river. The valley is traversed by the A4107 Afan Valley Road. Settlements in the area include Cwmafan, Pwll-y-glaw and Cymmer. The town of Aberavon grew up on the banks of the river, and was later subsumed by the larger centre of population known as Port Talbot. The political constituency still retains the name Aberavon (aber meaning mouth of a river).
Etymology.
The river's name is old and there is no definite agreement on its origin. One suggestion is that it is from "A-Ban" meaning "from the heights" due to its comparatively quick descent from hills to the sea. (Compare to the 'Ban' in "Bannau Brycheiniog", the Brecon Beacons).
Course.
The river Afan begins its journey at the village of Cymmer (meaning confluence) where the rivers Corrwg and Gwynfi join. The river runs in a more or less south-westerly direction parallel to the River Neath with which it shares its western watershed. It converges with the Afon Pelenna at Pontrhydyfen. From here it turns southward towards Port Talbot. To aid the construction of the docks at Port Talbot, the river was diverted away slightly. Before it reaches the sea, the river drops over a 12-foot high vertical weir called the Slaughterhouse Falls. 
The River passes the Afan Argoed Country Park in its middle reaches.
A motte and bailey castle stood on the banks of the river as it passed through Aberavon during the medieval period. No remains are now visible above ground, but the site of the castle is commemorated in local street names.
Geography.
The river is about 11 miles long. In the east it borders the River Kenfig and then the River Llynfi, a tributary of the River Ogmore. The river Gwynfi, one of the tributaries that form the river, shares a watershed with the Rhondda Fawr, a tributary of the River Taff.
Industrial past.
For much of the 19th century and the first half of the 20th century, the River Afan was severely polluted by the coal and iron industry. With the decline in the coal mining industry, the quality of the river improved in the 1960s and 1970s so that some salmon and sea-trout started to return to the river to spawn. A number of weirs on the river had to be made passable to allow fish to ascend the river. This required the creation of fish passes on some weirs such as on the Dock feeder weir and the demolition of others such as at Corlannau weir.
Tributaries.
Afon Corrwg.
The river Corrwg is one of the two rivers to form the Afan. Its length is approximately 7 miles, and its source lies in the hills south of Glyn-neath. It has one major tributary called the Afon Corrwg Fechan, as well as other numerous streams. The river is known for the numerous waterfalls along its length. Although the water is clear today, discharge from the many collieries along its lower reaches led to noticeable pollution. Minor discharge sometimes leaks from the Glyncorrwg colliery, although its effects do not have a noticeably detrimental effect on the river.
Afon Gwynfi.
The Afon Gwynfi joins the Corrwg at Cymer. It is 5 miles long, and starts at Blaengwynfi, where two small rivers join. Its source is only a couple of miles away from that of the rivers Rhondda and Ogmore. Strangely, there seems to be some confusion between the Gwynfi and the Afan itself; one of the two streams that form the river is named the Nant Gwynfi, while the other appears not to have a name, but is labelled on the Ordnance Survey map of the area as "River Afan" (as is the entire length of the Gwynfi). This is likely a mistake, but the spring from which this river comes is called Blwch-yr-Afan, meaning "Source of the Afan River".
The river is slightly alkaline due to continuing, albeit minor, pollution discharge from the Corrwg Rhondda and Glyncorrwg collieries.
River Pelenna.
A major tributary, the River Pelenna,which meets the Afan at Pontrhydyfen, suffered more severely from pollution than the main river because of the sulphur-rich coal produced by the mines in that area. As a result, the abandoned coal mines continued to discharge acid mine drainage rich in iron and highly acidic. This turned much of the river orange down to the confluence of the Pelena with the main river Afan. The Orange colour could often be seen as far down stream as Pontrhydyfen. There were a number of collieries contributing to the pollution although the major source was the Whitworth Colliery. At the height of coal extraction in the valley, there were several deep pits and numerous levels. This pollution is now much mitigated
following extensive work promoted by the Environment Agency in the creation of engineered reed beds to treat the mine drainage.
Nant Ffrwdwyllt.
With a length of just under 5 miles, this was a small tributary of the Afan shortly before it entered the sea. The Nant Ffrwdwyllt was diverted in the 18th century into the ironworks at what was to become Port Talbot to provide a source of water. It remains diverted flowing into the Port Talbot Docks.

</doc>
<doc id="52608" url="http://en.wikipedia.org/wiki?curid=52608" title="Sigismund III Vasa">
Sigismund III Vasa

Sigismund III Vasa (also known as Sigismund III of Poland, Polish: "Zygmunt III Waza", Lithuanian: "Žygimantas Vaza", English exonym: "Sigmund"; 20 June 1566 – 30 April 1632 ) was King of Poland and Grand Duke of Lithuania, a monarch of the united Polish–Lithuanian Commonwealth from 1587 to 1632, and King of Sweden (where he is known simply as "Sigismund") from 1592 until he was deposed in 1599. He was the son of King John III of Sweden and his first wife, Catherine Jagellonica of Poland.
Elected to the throne of the Polish–Lithuanian Commonwealth, Sigismund sought to create a personal union between the Commonwealth and Sweden (Polish–Swedish union), and succeeded for a time in 1592. After he had been deposed in 1599 from the Swedish throne by his uncle, Charles IX of Sweden, and a meeting of the Riksens ständer ("Swedish Riksdag"), he spent much of the rest of his life attempting to reclaim it.
Shortly after his victory over his internal enemies, Sigismund took advantage of a period of civil unrest in Muscovy (known as the Time of Troubles) and invaded Russia, holding Moscow for two years (1610–12) and Smolensk thereafter. In 1617 the Polish-Swedish conflict, which had been interrupted by an armistice in 1611, broke out again. While Sigismund’s army was also fighting Ottoman forces in Moldavia (1617–21), King Gustavus II Adolphus of Sweden (Charles IX’s son) invaded Sigismund’s lands, capturing Riga (1621) and seizing almost all of Polish Livonia. Sigismund, who concluded the Truce of Altmark with Sweden in 1629, never regained the Swedish crown. His Swedish wars resulted, moreover, in Poland’s loss of Livonia and in a diminution of the kingdom’s international prestige.
Sigismund remains a highly controversial figure in Poland. His long reign coincided with the apex of the Polish–Lithuanian Commonwealth's prestige, power and economic influence. On the other hand, it was during his reign that the symptoms of decline leading to the Commonwealth's eventual demise surfaced. Popular histories, such as the books of Paweł Jasienica, tend to present Sigismund as the principal source of these destructive processes; whereas academic histories are usually not as damning of him. However, the question of whether the Commonwealth's decline was caused by Sigismund's decisions or had its roots in historical processes beyond his personal control, remains a highly debated topic.
He was commemorated in Warsaw with Sigismund's Column, commissioned by his son and successor, Władysław IV.
Royal titles.
Sigismund was elected King of Poland and reigned 1587–1632. By paternal inheritance, he also succeeded in 1592 as King of Sweden but was deposed in 1599. His successor, Charles IX of Sweden, officially gained the Swedish throne in 1604. From his grandmother Bona Sforza he inherited the title of King of Jerusalem.
Biography.
Early life and coronation.
Sigismund was born on 20 June 1566 to Catherine Jagiellon of Poland and King John III of Sweden at Gripsholm. His parents, at the time, were being held prisoner by King Eric XIV, but despite the Protestant domination of Sweden young Sigismund was raised as a Roman Catholic. Regaining the throne of Sweden would be one of the primary driving forces in his life. His Polish connection came through his mother who was the daughter of Sigismund I the Old and the Jagiellonian family had been the royal family of the Kingdom of Poland and the Polish-Lithuanian Commonwealth since King Władysław II Jagiełło (Jogaila) obtained the crown in 1386 through his Angevin wife, Saint Queen Jadwiga. In 1587 Sigismund stood for election to the Polish throne after the death of King Stephen Bathory. He was supported by Chancellor and Hetman Jan Zamoyski, the dowager Queen Anna and the nobles loyal to the Zborowski family. With this network behind him he was duly elected King of the Polish-Lithuanian Commonwealth on 19 August 1587 with the blessings of the primate of Poland Stanisław Karnkowski. From that time his official name and title became Sigismund III, by the grace of God, king of Poland, grand duke of Lithuania, Ruthenia, Prussia, Masovia, Samogitia, Livonia and also hereditary king of the Swedes, Goths and Wends; the later titles being in reference to the claims of his father to the Swedish throne.
Opposition to the throne.
However, as was often the case with the Polish electoral monarchy, the outcome was strongly contested by the "losers" and the greedy and stubborn Polish nobility who backed the Archduke Maximilian III of Further Austria for King of Poland. Upon hearing of his election King Sigismund slipped through the clutches of the Protestants in Sweden and landed in Poland on 7 October and immediately agreed to give up several royal privileges to the parliament (Sejm) of the Commonwealth in the hope of winning over some of his enemies and settling the disputed election. He was proclaimed by the Lesser Prussian Treasurer Jan Dulski as king on behalf of the Crown Marshal Andrzej Opaliński and after arriving in the Royal Capital City of Kraków he was crowned on 27 December inside the Wawel Cathedral. It seemed that the issue of who would be King of Poland had been settled when Maximilian III invaded at the head of his army to claim his crown. The hostilities did not last long as Hetman Jan Zamoyski at the head of a Polish army loyal to King Sigismund met and successfully defeated the Austrian troops at the Battle of Byczyna and took Maximilian III as prisoner of war. However, at the request of Pope Sixtus V, King Sigismund III released Maximilian who surrendered his claim to the Polish Commonwealth in 1589. King Sigismund also tried to maintain peace with his powerful neighbor by marrying Archduchess Anna of Austria in 1592. His was always his intention to be allied with Catholic Austria against the Protestant forces that were tearing Christendom apart.
When his father died King Sigismund III requested from his parliament that he be allowed to claim his inheritance as the rightful King of Sweden. The Poles had no objection and when he promised to respect Lutheranism as the official religion of Sweden; the Swedes agreed to the proposition and Sigismund was crowned King of Sweden in 1594. He appointed his uncle, Duke Charles, to rule as regent on his behalf in Sweden while he remained in Poland since the Swedes and the Commonwealth were not united politically but simply had a personal union by sharing one monarch. However, tensions grew quickly with Sweden as despite the legal guarantees, King Sigismund was a devout and ultra-Catholic person and this made the Swedes nervous and somewhat cynical. The Protestant firebrands warned that Sigismund had the ultimate goal of making Sweden Catholic again. As proof they pointed to the Union of Brest set up in 1596 which brought many Eastern Orthodox into the Catholic fold and led to the modern day Ukrainian Catholic Church, to his friendship with Catholic Austria and his support for the Catholic Reformation, particularly the Jesuit order, which was spreading out to refute Protestantism and regain lost spiritual ground for Rome.
Internal and external affairs of the Commonwealth.
Combating heresy and giving Poland a strong and stable government were the primary goals of King Sigismund. Toward this end he moved the royal court from Kraków to Warsaw and oversaw the arrival of the Jesuits who established new schools throughout Poland and became chaplains and confessors to many families. The Catholic Church in Poland rebounded strongly during the early years of the reign of King Sigismund III. Their preaching was very well received by the public and along with their staunch defense of the faith they also reminded Poles of their crucial role as the first line of defense for Catholic Christendom against the Orthodox Russians and the Ottoman Turks. However, trouble was never far away for King Sigismund and 1598 was a particularly painful year. His wife, Anna, suddenly died (he later married her sister Constance of Austria in 1605) and he experienced the outbreak of a rebellion in Sweden (known as "War against Sigismund") led by his own uncle and regent who portrayed himself as the Protestant champion of Sweden fighting against their Polish Catholic monarch. King Sigismund moved against him which a combined the Swedish and Polish forces. He won some early victories but the climax came at the Battle of Stangebro in which his 8,000 strong army was defeated by the 12,000 men of Duke Charles. The Swedish loyalists were executed by the Protestant government and after the King returned to Poland he was declared deposed and his uncle was proclaimed King Charles IX of Sweden in 1600. A number of Swedish-Polish wars resulted but the personal union was never to be recovered despite the many persistent efforts of King Sigismund.
Trouble was also plentiful on the southern border where Poland was drawn into the wars of local nobles and the Austrian Habsburgs against the Muslim Tartars and Ottoman Turks. King Sigismund was anxious to help Austria and was promised territorial gains for Poland in return for his assistance. He sent in an army consisting of mercenaries from the wars in Russia to the Principality of Moldavia, but in 1620 the Polish forces were defeated and Sigismund was forced to renounce his claim to the principality. It was a setback but resulted in a negotiated peace and was no stunning victory for the Muslims who had vowed to destroy the Polish-Lithuanian Commonwealth and in this aim they certainly failed. Almost at the same time as these troubles, and those with Sweden, Sigismund was fighting a war with the Grand Duchy of Muscovy. In the time of the Polish-Lithuanian Commonwealth it was the Poles that were a force to be reckoned with, especially their elite heavy, winged, hussars. The Russians had been fighting amongst themselves and King Sigismund got involved, as did Sweden though they were never firmly on one side or the other. At one point the Russians invited the son of King Sigismund, Prince Władysław to become their Tsar, but Sigismund would not allow it. He though he himself might become the master of Russia and though this did not happen the Polish-Lithuanian Commonwealth did win a number of victories and gained more territory. At one point Polish troops, under the command of the great general Stanisław Żółkiewski, even captured Moscow and the Kremlin. On the downside the whole conflict meant that any lasting union between the Commonwealth and Russia was impossible and any plans concerning the final destruction of the Russian state were unsuccessful.
Religious issues, withdrawal from politics and death.
Throughout all of these constant wars King Sigismund also tried to stabilize and streamline the Commonwealth government. The electoral monarchy in Poland had created a nobility with rather too extensive powers and a great deal of division. Sigismund worked to gain more power for the king as well as to allow government business to pass with a majority of votes of the parliament rather than unanimity which was extremely hard to achieve and meant that things often did not get done. All these actions led to a rebellion but the King was ultimately victorious and despite what his many detractors might say his reign marked a period of Polish greatness the likes of which has not often been seen. He made the Commonwealth very much the dominant power of Central and Eastern Europe and just as importantly ensured that Poland remained a solidly Catholic country in the face of Protestant incursions. He was considered a brave man, a talented monarch and something of a renaissance man as is evidenced by his devout faith and his artistic talent. If the reforms he planned were successful and if he would create a personal union with Poland's neighbours, Sigismund might have been the father of a Catholic dynasty that stretched across Poland, Sweden, Finland, Lithuania, Moldavia, Turkey and Russia. It did not happen, but that should not detract from his greatness as one of the royal champions of the Catholic Reformation period. Sigismund was a gifted artist, painter and goldsmith; only one of his three paintings survived, one was for centuries erroneously attributed to Tintoretto; and from his own, personal workshop came the main part of the famous silver coffin of St. Adalbert of Prague at the Cathedral in Gniezno.
Towards the end of his reign, Sigismund III withdrew altogether from politics and devoted himself exclusively to family matters and his interests in performing arts. Shortly after the sudden death of his second wife, Constance of Austria, Sigismund fell dangerously ill and experienced severe mental and psychological problems. He died of a stroke on 30 April 1632 at the age of 65 in the Royal Castle in Warsaw and was interred inside Wawel Cathedral in Kraków. He was succeeded by his son, King Władysław IV.
Sigismund's politics.
Many historians believe that Sigismund viewed Poland only as a tool that would allow him to eventually regain the throne of Sweden. To this end he tried to strengthen his royal power and allied himself with Habsburgs and Counter-Reformation forces. His policies were opposed by many within the circles of the wealthy Polish nobility (the szlachta), most notably the chancellor Jan Zamoyski. This led to a semi-legal rebellion against the king (rokosz), known as Zebrzydowski Rebellion (1606–1608), which was a response to Sigismund's attempt to introduce majority voting in place of unanimity in the Sejm. Eventually Sigismund's forces were victorious, but the rebels went unpunished. Partially in order to pacify the restless szlachta, Sigismund supported war with Muscovy (the Dimitriads, 1608–1618). Although Commonwealth forces were almost constantly shuffled between wars in the East (with Muscovy), north (with Sweden) and South (with Ottomans – the Polish-Ottoman wars), Sigismund took advantage of the civil war in Russia (the Time of Troubles) and secured temporary territorial gains for the Commonwealth.
While Sigismund never managed to regain the Swedish throne, his personal ambition to do so did succeed in provoking a long series of conflicts between the Commonwealth and Sweden temporarily allied with Muscovy. While the Commonwealth's Royal Parliament managed to thwart many of the plans of Sigismund (and later of his son, Władysław), the Vasa dynasty nonetheless succeeded in partially drawing the Commonwealth into the Thirty Years' War. The conflict with Sweden, combined with wars against Ottomans and Muscovy, culminated well after Sigismund's death in the series of events known as The Swedish Deluge, which ended the Golden Age of the Polish-Lithuanian Commonwealth that spanned for almost a century.
During his reign Sigismund permitted the Brandenburg Hohenzollerns to inherit Ducal Prussia. This decision later greatly strengthened the Duchy and following the Commonwealth's major military defeat in the Second Northern War during the reign of Sigismund's younger son, John II Casimir, under the terms and conditions of the Treaty of Oliva, Prussia became a sovereign state and country that eventually Partition Poland together with Austria and the Russian Empire in the late 18th century.
Early conflicts with Hetman Jan Zamoyski.
The contest between the King and the Chancellor began during Sigismund’s first Sejm sitting, the so-called "Pacification Sejm," which met at Warsaw in March 1589. Zamoyski presented the project of a political combination between Poland, Moscovy, and Bohemia, coupled with a suggestion that in case the present King should die without issue (a somewhat premature and gratuitous assumption in the circumstances) none but a Prince of some Slavonic stock should henceforth be eligible to the Polish throne. The extravagance of a project which could even imagine the possibility of any sort of union between Catholic Poland, Orthodox Moscovy, and semi-Protestant Bohemia struck even the majority of the Sejm with amazement. It was only explicable at all as a circuitous and clumsy attempt to traverse the Habsburg influence. The Parliament promptly rejected it, accepting instead the royal proposition of a marriage between Sigismund and the Archduchess Anne. The way had already been opened for this rapprochement with Austria by the Treaty of Bytom and Będzin (March 1589), negotiated by the Nuncio Ippolito Aldobrandini, afterwards Pope Clement VIII, whereby the Emperor resigned all his claims to the Polish Crown. At the succeeding Sejm, which assembled in March 1590, Zamoyski succeeded in persuading the deputies to exclude at any rate the Archduke Maximilian from the succession to the throne. But he had only gained his ends by skilfully frightening them with the bugbears of Austrian intrigues and Turkish threats; and his opponents, headed by the Primate Kamkowski, immediately after the Diet rose, formed a Confederation to protest against its decrees, and a second extraordinary Sejm, dominated by the enemies of Zamoyski, met at the end of the same year. It at once proceeded to reverse all the decrees of its predecessor and strike blow after blow at the Chancellor of the Crown. Thus the Grand-Hetmanship was placed in commission, the party of Maximilian was amnestied, the Zborowskis were rehabilitated, Zamoyski’s friends and supporters were removed from Court, and the chief pillars of the Catholic party in the Grand Duchy of Lithuania, the wealthy Cardinal Radziwiłł and the newly converted and highly popular Prince Ostrogski, were appointed Bishop of Kraków and Castellan of Kraków respectively. Zamoyski naturally retaliated by means of the same double-edged constitutional weapon which his opponent had used.
On 1 June 1592, he formed a Confederation at Jędrzejów, which was more numerously attended than the wedding feast in honour of Sigismund’s young Austrian bride the Archduchess Anne, who made her state entry into Kraków, amidst great rejoicings, at the end of May. All the Polish nobility, nearly all the senators of Greater and Lesser Poland, and the majority of the orthodox Lithuanians acceded to the Chancellor, so that, at the meeting of the "Inquisition Sejm" at Warsaw (7 August) summoned by the King to inquire into all grievances and thoroughly sift the so-called "Austrian cabals", Zamoyski was once more formidable. Sigismund, supported by the Primate of Poland, had still enough authority to stop the inquisition half-way, but the young Queen’s mother, the shrewd and sensible Archduchess Maria, who had accompanied her daughter to Kraków, had made up her mind that Zamoyski was too strong to be set aside, and that therefore the interests of Austria demanded a reconciliation between the King and the Chancellor. This reconciliation was accomplished quietly by Mikołaj Firlej, Palatine of Kraków, and included all the leading men of both parties. The rival cardinals Bathory and Radziwiłł adjusted all their past differences; Zamoyski was fully reinstated in the Grand-Hetmanship, and as Grand Chancellor of the Crown, to the general astonishment, presented to the Sejm and eloquently defended all the royal propositions, including Sigismund’s request for leave to proceed to Sweden to occupy the throne left vacant by the death of his father John III, on 17 November 1592. This reconciliation lasted for a long period of time, with the happiest results for Poland. Zamoyski, no longer distracted by personal considerations, gave his whole attention to public affairs, and, from 1595 to 1602, achieved some of his most brilliant military and political triumphs.
Gentry, nobility and privileges.
The "Szlachta" (Polish nobility) of the Commonwealth had become dominant, and its one exclusive idea was to remain dominant. From the middle and lower classes, whom it had crushed beneath its feet, nothing was to be feared. But the King, as the nominal head of the State, as the controller of foreign affairs through his official counselors, the Senate and the Chancellors, and, as the head of the army, through the Hetmans, whom he appointed, was still a potential menace to individual liberty as the nobility understood it. Henceforth, therefore, an unreasonable, incur-able suspicion of the Crown, and all the executive instruments of the Crown, is the characteristic, or rather the mania, of every Polish Sejm. For its country, as a State, the nobles had no thought at all. As long as every nobleman, or squire, was lord paramount in his own parish he cared little for anything beyond it. And what, after all, was the Sejm, or Diet, but a collection of some 600 of such squires who met annually at Warsaw or elsewhere, in order to contribute as little as possible to public needs and protest vehemently against everything they did not like or could not understand. So far as they can be said to have had any policy at all, the nobility was in favour of absolute non-intervention in foreign affairs, as being the cheapest and least troublesome policy to pursue. The unwillingness with which the gentry of Poland parted with their money, especially for armaments, however necessary, was entirely due to the fear lest a popular monarch, at the head of a victorious army, might curtail their privileges. Rather than run such a risk as this, they were ready to avoid every advantageous alliance, forgo every political opportunity, stint their armies, starve and abandon their generals, and even leave the territories of the Commonwealth unguarded and undefended. Then, if ever, Polish statesmen had the opportunity of realising the Jagiellonic dream of an Empire, the political situation everywhere favoured them. Livonia, with its fine seaboard and its hundreds of towns and fortresses, had literally fallen into the lap of Poland. Her one serious rival in the north was the rude young Swedish monarchy, for Moscovy, after the death of Ivan IV (1584), had ceased to be dangerous. The Turks, unless violently shaken, was inclined to slumber. The Emperor and the Western Powers were more or less involved in the Spanish and, subsequently, in the Thirty Years’ War. The regular army, if small, was good, while in the Polish occupied Ukraine (Ruthenia) had an almost unlimited reserve of the best raw military material. The country had Zamoyski, Żółkiewski, Chodkiewicz and Stanisław Koniecpolski, four of the greatest generals and military commanders of the age.
Brief conflict with England.
The Muslim Ottoman Empire of the Turks and the Christian England were allies of convenience against Spain. Elizabeth's armies fighting Catholic forces in the Low Countries to prevent Spain from gaining secure harbors on the Channel coast to stage an invasion England also served the Turk's interest by diverting Spain from focusing on domination of the Mediterranean. In 1580, the Turks threatened to invade Poland from lands north of the Black Sea. The good will of Poland was crucial to England because trade with countries bordering the Baltic was the source of grain and the all important forest products needed to maintain the navy. English merchants enjoyed preferential trading privileges in Poland. Elizabeth's intercession with the Caliphate was credited with cancelling the invasion, and she received letters of praise from then reigning Polish king, Stephen Bathory.
After Sigismund III was elected in 1587, Elizabeth's intelligence service gave notice that an ambassador is in transit and that the embassage was one of amity. On 23 July 1587, the Privy Council instructs the Lord Mayor of London to arrange housing for the diplomat, preferably with a merchant prominent in the Baltic trade. To insure Elizabeth will not find fault with the preparations, the Lord Mayor is to report the arrangements made. Two days later Ambassador Paweł Działyński arrived at the palace in Greenwich. Brought to the reception hall, he found Elizabeth sitting on the throne under the canopy of state with all her nobles in attendance. The ambassador presented his credentials, and kissed the Queen's hand extended to him―a gesture of royal favor. He then strode to the center of the chamber without any forewarning of what he was about to say, and instead of the oration of a legate that everyone anticipated―couched in respectful words to flatter the monarch being addressed―he spoke as a herald. In Latin, he hectored, admonished and criticized the queen, and declared an ultimatum of capitulation to terms or hostile action.
Działyński indormed the queen that Sigismund married into the Catholic royalty of Austria and was sympathetic to Catholic Spain. The reason for his mission was to complain about Elizabeth's policy of having her navy capture ships of Polish and Hanseatic League merchants trading with Spain. This was intolerable to his sovereign. Hostilities would commence if Elizabeth did not rescind her orders to interdict trade, release the captured ships, and restore the confiscated cargoes or make restitution.
War against Sigismund in Sweden.
After Sigismund had been crowned King of Sweden 19 February 1594, he decided that no Parliaments ("riksdagar") could be summoned without the King’s consent. Despite this, Charles summoned a Parliament at Söderköping in autumn 1595, at which he managed to get his will through. The Duke was appointed Regent with "the advice of the Council", meaning that he was to govern Sweden together with the Privy Council during the King’s absence from the Realm. Soon afterwards, the nobility of Finland, led by the Sigismund-appointed Governor, Klaus Fleming, rejected these decisions. They sympathised with the King and considered Charles a rebel. As a counterattack, Charles instigated a rebellion against Fleming, the Cudgel War, among the farmers in Ostrobothnia.
Fleming managed to quell the revolt but died in April 1597. Roughly at the same time, a letter arrived from Sigismund’s headquarters in Poland stating that he would not accept Charles as regent. The Duke then used a tactic which his father had employed, namely to resign from office. However, the response was not what Charles had been hoping for: the King accepted Charles’s resignation and invested complete power in the Privy Council. Despite the difficult situation, Charles summoned another illegal Parliament the same year, this time in Arboga. Only one of the Privy Councillors showed up. The reason was that Charles’s goal of deposing Sigismund had now been revealed, and the men understood that a serious revolt was brewing. When Duke Charles threatened the absent men with severe punishment some of them lost courage. Erik Gustavsson Stenbock, Arvid Gustavsson Stenbock, , and fled immediately to Sigismund.
Thus, in 1597, civil war erupted, and Duke Charles was able to assume control over a large share of the powerful castles in the country, and in this manner achieved control over almost all the Realm. The problem was Finland, where Klaus Fleming’s widow guarded Åbo castle. But after psychological warfare, Charles and his followers managed to take the castle in Turku (Swedish: "Åbo"). It is said that when the Duke entered the castle chapel he saw Klaus Fleming’s body lying in a coffin. He is said to have said: "Hadst thou now been alive, thy head would not have been in great safety." Then Fleming’s widow Ebba Stenbock is said to have approached the Duke and responded: "If my late husband had been alive, Your Grace would never have entered herein."
When Sigismund found out about what had happened in Finland he lost his patience. The King could not accept Duke Charles’s disrespectful actions and decided to use force. This decision eventually would cost him the Swedish crown. In February 1598 Sigismund assembled an army consisting of merely 5,000 men, mostly Hungarian and German mercenaries. A larger army had been proposed, but had been dismissed since Sigismund expected Swedish forces to join him, and also did not want to come into conflict with them. The advisers and the King expected military support from Finland and Estonia (homes of the Swedish gentry formerly commanded by baron Klaus Fleming). They also wanted help from Denmark–Norway and pro-Sigismund parts of Sweden. The diplomat Laski was dispatched, but Denmark did not show any interest. In May, Sigismund’s men started to advance northwards. The army gathered in Marienburg (Malbork), where the Livonian Jürgen Farensbach was appointed commander. The army was to be transported from Danzig (Gdańsk) to Sweden on Swedish ships, but the Swedish Estates declined. They refused to lend him ships as long as he stayed with a foreign army. There was widespread suspicion against Sigismund and his Catholic warriors. Thus the Estates promised to protect Duke Charles and the others who rebelled against the King.
At the end of May 1598 Sigismund landed on Swedish soil at Avaskär. The King opened peacefully by sending the diplomat Samuel Łaski to Kalmar for negotiations. His task was to convince the city’s commanders to open the gates. However, the negotiations led nowhere. Instead, the King took his soldiers and marched on Kalmar. The army halted just outside of the city. The plan was to frighten the commanders into opening the gates. To make his message even more terrifying, Sigismund threatened the city with severe punishments and to withdraw the nobility of all children in the city. The propaganda worked well and Sigismund was able to make his long-desired entry on 1 August. After the fall of Kalmar, Duke Charles found himself with major trouble on his hands. The Polish Crown army attracted Swedish followers and Stockholm, lacking military defence, was easily taken with the help of the nobility and officers of Götaland. After this event, the cavalry of Uppland joined up, and new forces were mobilised in Finland and Estonia.
The morning of 25 September 1598 the armies clashed in a major engagement at the Battle of Stångebro. Charles offered talks again but attacked in a mist while Sigismund's men were withdrawing to their camp, which resulted in only the mercenaries fighting since his Swedes refused to fight. Duke Charles won a decisive victory which forced Sigismund to agree to harsh terms. Charles demanded that the King send home his entire army, but that he himself was to stay and await a Parliament. Also, a number of Swedes who had sided with Sigismund, including his Council supporters, were captured. These were later executed in the Linköping Bloodbath of 1600. The peace agreement was sealed with a dinner between Charles and Sigismund on Linköping Castle. The King, who was under pressure, fearing for his life without his army and having realised that he had lost the political battle, fled during the coming days to Poland in late 1598. At the same time as the peace treaty was being signed in Linköping, conflicts were taking place in Dalarna. There, a pro-Sigismund bailiff, , had tried to raise up the Dalecarlians against Duke Charles. Chaos ensued. Näf was executed, and the Dalecarlians set out on the so-called Neaf Campaign (1598), burning and killing down to Brunnbäck ferry. In Västergötland, Carl Carlsson Gyllenhielm, illegitimate son of Duke Charles, defeated the rebellion.
Sigismund was officially deposed from the throne of Sweden by a Parliament, Riksdag, held in Stockholm on 24 July 1599. He was given six months to say whether he wanted to send his son. Prince Władysław Vasa, to Sweden as his successor, under the condition that the boy would be brought up in the Evangelical faith. Otherwise the Estates would look for a new king. In February 1600, Duke Charles summoned the Estates of the Realm to Linköping. Since Sigismund had not provided a reply, the Estates elected Duke Charles as King Charles IX of Sweden. The consequences for those who had supported Sigismund were devastating. The most prominent among them were killed by the new King, in what was called the "Linköping Bloodbath". During the winter and spring of 1600, Charles also occupied the Swedish part of Estonia, as the castle commanders had shown sympathies towards Sigismund. Charles' invasion of Livonia led to a series of wars with Poland, starting with the Second Polish-Swedish War. Charles accepted the crown as Charles IX in 1604.
Zebrzydowski Rebellion.
The infamous Zebrzydowski's Rebellion or the Sandomierz Rebellion was a semi-legal rebellion against King Sigismund, formed on 5 August 1606 by Hetman Mikołaj Zebrzydowski, Jan Szczęsny Herburt, Stanisław Stadnicki, Aleksander Józef Lisowski and Janusz Radziwiłł in Stężyca and Lublin. It was primarily caused by the growing dissatisfaction with the King among the Polish nobility and wealthy magnates. In particular, the rebels disapproved of the King's efforts to limit the power of the nobles, his attempts to weaken the Sejm (the Polish parliament) and to introduce a hereditary monarchy in place of the elective one. The rebellion (1606–08) ended in the defeat of the rebels. Despite the failure to overthrow the King, the rebellion firmly established the dominance of the nobility over the monarch in the Polish political system.
The Polish nobles gathered at the rebellion-formed a council and outlined their demands in 67 articles. They demanded Sigismund III's dethronement for breaching the Henrician Articles, and the expulsion of the Jesuits from the Polish-Lithuanian Commonwealth. They further demanded that the Sejm was appoint state officials instead of the king; that local officials should be elected and not appointed and that Protestant's rights should be expanded and protected. The 1607 Parliament sitting rejected the demands. Meanwhile, the rebel nobles gathered in the town of Guzów. In 1607 the Polish Royal Army, led by Hetman Jan Karol Chodkiewicz was sent to pacify the rebels. A full-scale battle ensued on 5 July, with 200 casualties, which resulted in the victory of the Royalist forces. By 1609, the rebellion was over. Two years after the start of the revolt, the rebellious nobles formally surrendered to the king at the 1609 meeting of the Sejm, which became known as the Pacification Sejm. In return for their surrender the rebels were granted leniency. Many royal supporters, including Hetman Chodkiewicz, had successfully argued for amnesty for the rebels. Despite the failure of the rebellion, it nevertheless ruined any chance that Sigismund III had to strengthen his role in the government.
After the rebellion, King Sigismund attempted to funnel the nobles' restless energy into external wars. This, combined with other factors, led to the official Commonwealth involvement in the Polish-Muscovite War (1609–1618), which followed the Dimitriads (1605–1609).
"The first rebellion in Polish history had sinister consequences. Royalty lost, to great extent, the moral prestige it had enjoyed... The Polish constitution was henceforth regarded as sacrosanct and the king had to renounce not only the idea of making any far-reaching changes in it, but even any reform."—Oskar Halecki
Piotr Skarga and Sigismund, "King of the Jesuits".
The election of Sigismund III to the throne proved to be the greatest blow it was possible to inflict upon Protestanism in Poland. Brought up by his mother, Catherine Jagiellon, in the strictest Roman Catholic doctrines, he made the promotion of the interests of Rome the guiding motive of all his actions. This zeal for Rome outweighed all considerations of prudence or policy; through it he lost two hereditary thrones, and brought innumerable calamities on the country which election had handed over to him, "In order to make sure of heaven", said the Emperor Ferdinand, "he has renounced earth". The Protestants called him the "King of the Jesuits", and Sigismund gloried in the appellation. This feeble imitation of Philip II of Spain possessed all the bigotry and zeal of his model without his abilities or strength of character. In all that he did he was ruled by the Jesuits; he bestowed honours only on those whom they favoured, and preferred their advice to that of his wisest counselors. By private interviews, wrote a Roman Catholic historian who was also bishop of Przemyśl, which they could always command, the Jesuits so bound the king by their solicitations, that he did everything according to their counsel, and the hopes and cares of courtiers had no weight except by their favour. Chief among these advisers of the king was Piotr Skarga, one of the most eminent of Polish Jesuits. Born in Mazovia in 1536, he was educated at the Jagiellonian University, where he distinguished himself by winning the "prima Laurea". He then proceeded to Rome, where he entered the society in 1568. He began his preaching at Pułtusk, and visited the colleges which Stephen Bathory had founded at Riga, Dorpat and Połock; his eloquence was very successful, and even now his sermons are thought highly of in Poland. On the accession of Sigismund he became royal chaplain and he founded a confraternity of St. Lazarus at Warsaw, and many other establishments elsewhere in the country.
Relationship with the Mennonites.
Sigismund confirmed the contracts of lease made with the Mennonites and on 20 October 1623, accorded special privileges to the lace-makers of Schottland, most of whom were Mennonites. But he refused to grant them any new rights or liberties. Upon the complaint of the city council of Elbing (Elbląg) that the Mennonites broke up marriages without having previously informed the authorities, married one another, and divided property at their pleasure, he forbade the Mennonites, upon penalty of a fine of 100 guilders, to marry without the foreknowledge of the authorities, and ordered that the Mennonites should be given no special rights. When the Mennonites nevertheless requested release from all civil handicaps, especially from military defense of the city and the court oath, he decreed on 26 April 1615, that they should do their duty like others. But the ruling was not enforced. On 26 April 1626, the king sent the following orders to the magistrate of Elbing, because he had heard that they had accepted Anabaptists and Mennonites and given them liberties, so that they, without swearing to him and the city, carried on trade and crafts, bought properties and food from the citizens, and tolerated them free of all that citizens must assume, and, what was not the least, their testimony at court was counted as valid as an oath, all of which is contrary to the public and special laws and offended his royal regard sorely and threatened to do harm, therefore these people were held to sworn obligations to the king and the city, to take up all civil burdens. Sigismund placed wild hordes of Poles and German mercenaries at the disposal of his brother-in-law, Ferdinand II of Austria, which burned and sacked the Hutterite villages at Schädowitz, Watznobis, and Goding, killing thousands.
Assassination attempt in Warsaw.
An unsuccessful attempt on the life of the king was made on 15 November 1620. It occurred on Sunday, at 9 am, when the monarch was to attend Mass in St. John's Archcathedral in Warsaw. Sigismund was to arrive by walking on a wooden bridge-looking construction that connected the Royal Castle with the temple. When the royal procession already reached the end of the bridge, hidden in a nearby window was nobleman Michał Piekarski. The assassin previously killed a Hungarian mercenary that was protecting the post. When the monarch reached the final steps, Piekarski instantly jumped out and threw himself on the king, stabbing him twice, firstly in the back and then in the cheek, another hit was in the arm, however, the assassin was not able to cause any deadly harm because of the royal guards that were initially standing to the right of the king and Piekarski attacked from the left. Shortly after this, Sigismund fell flat on the ground, pale and lifeless, and from the church Priest Kobierzycki started to groan and shout - he has seen the attack from the temple's stained glass window or from the belfry. A group of local civilians and citizens surrounded the procession, the king quickly fainted and his clothes were stained in blood, however, the guards were able to revive the monarch. Eventually after medical examinations the wounds proved to be harmless. Few minutes later, panic erupted in the crowd and the air filled with the atmosphere of terror. Most of the people gathered in the church, that have arrived before the royal procession, believed that the king was already dead. Initially it was thought that the capital was invaded by the Muslim Tatars or, at least, by their spies.
The circumstances of this attack and the assassin were known exceptionally well after the attempt, as soon pamphlets appeared on the Market Square, reporting three different viewpoints on the subject, published in a total of five editions. The assassin was indeed Michał Piekarski, always regarded by the society as a freak, a melancholic, unrestrained in deeds (as a child he suffered head and brain damage - this may have been the cause of his mental illness). Earlier, he murdered the royal cook and killed, and wounded several people from the royal court. Piekarski, after hearing the news of the successful assassination of Henry IV in Paris (1610), decided to assassinate Sigismund, simply for fame. For the appropriate moment he waited patiently for 10 years. At trial he did not deny the crime he committed and heavily insulted both the jury, the Court Marshal and the monarch. He was executed in exactly the same way as Francois Ravaillac (the killer of the French king) on 26 November 1620 in Warsaw, in a torture area called "Piekiełko" (Devil's den or Devil's place).
Thirty Years' War.
Sigismund III would have intervened in the Thirty Years’ War, on the Catholic side, but for the determined opposition of the Parliament (Sejm), expressing itself in fresh insurrections and the refusal of supplies. His intervention would have taken the form of an invasion and, possibly, an occupation of Transylvania, which, under the energetic and ambitious Princes of the Protestant Houses of Bethlen and Rakoczy was the active ally of the Sultan and equally dangerous to Habsburg Austria and Poland. This would result in a war that would devastate the eastern borderlands of the Polish-Lithuanian Commonwealth, known as the "Kresy", and Sigismund was aware that he would not stand a chance against the mighty Sultan and the entire, great Ottoman Empire stretching from the Middle East all the way to the Balkans. The best heads in Poland, including Hetman Stanisław Żółkiewski, warmly approved of the King’s policy in this respect, but it proved to be impracticable. The Parliament's mania for non-intervention went so far that it refused to grant any subsidies for the Swedish War with the disastrous consequences already recorded. Sigismund eventually decided that joining the Thirty Years' War would diminish the country's national prestige and power in the region. This, however, weakened the alliance between the Habsburg states and the Polish-Lithuanian Commonwealth.
Opinion of reign and legacy.
The reign of King Sigismund III of Poland is often spoken of as the beginning of the end of Polish greatness. In terms of worldly success he certainly met with many defeats and setbacks. Yet, he was also one of the great Catholic champions of Europe and his reign can also be seen as one of many opportunities for an even greater Poland. He was stubborn, but a man of principle who would follow the hard but upright path rather than compromise his values for a more sure chance at success. As a monarch who reigned during the Catholic Reformation (also called the counter-reformation) he constantly worked to see the restoration of all of his subjects to the true faith embodied in the Church of Rome headed by the Pope of the Roman Catholic Church. Oddly enough for such a staunchly Catholic monarch his story begins in the staunchly Protestant Kingdom of Sweden. Sigismund's rule is often criticized in Poland for his unsuccessful decisions that negatively affected the diplomatic and financial situation of the country, however, especially by the nationalists, he is widely praised for conquering the eastern empires and gaining territories for the Polish-Lithuanian Commonwealth, thus creating the largest country in Europe of the 16th and 17th century that lasted until the final partition in 1795. 
Sigismund III Vasa is one of the personages in a famous painting by Jan Matejko, depicting the preaching of Piotr Skarga.
Ancestry.
Marriages and descendants.
Sigismund married twice. Firstly, on 31 May 1592, to Anna of Austria (1573–1598), daughter of Archduke Charles II of Austria (1540–1590) and his wife Maria Anna of Bavaria (1551-1608). They had five children:
And secondly, on 11 December 1605, to his first wife's sister, Constance of Austria (1588–1631). They had seven children:
References.
Bibliography.
</dl>

</doc>
<doc id="52612" url="http://en.wikipedia.org/wiki?curid=52612" title="Ancona">
Ancona

Ancona (], from Greek: Ἀγκών - Ankon) is a city and a seaport in the Marche region, in central Italy, with a population of 102,997 (2010). Ancona is the capital of the province of Ancona and of the region.
The city is located 280 km northeast of Rome, on the Adriatic Sea, between the slopes of the two extremities of the promontory of Monte Conero, Monte Astagno and Monte Guasco.
Ancona is one of the main ports on the Adriatic Sea, especially for passenger traffic, and is the main economic and demographic centre of the region.
History.
Ancona was founded by Greek settlers from Syracuse about 387 BC, who gave it its name: "Ancona" is a very slightly modified transliteration of the Greek Αγκων, meaning "elbow"; the harbour to the east of the town was originally protected only by the promontory on the north, shaped like an elbow. Greek merchants established a Tyrian purple dye factory here. In Roman times it kept its own coinage with the punning device of the bent arm holding a palm branch, and the head of Aphrodite on the reverse, and continued the use of the Greek language.
When it became a Roman colony is uncertain. It was occupied as a naval station in the Illyrian War of 178 BC. Julius Caesar took possession of it immediately after crossing the Rubicon. Its harbour was of considerable importance in imperial times, as the nearest to Dalmatia, and was enlarged by Trajan, who constructed the north quay with his Syrian architect Apollodorus of Damascus. At the beginning of it stands the marble triumphal arch with a single archway, and without bas-reliefs, erected in his honour in 115 by the Senate and Roman people.
Ancona was successively attacked by the Goths, Lombards and Saracens between the 3rd and 5th centuries, but recovered its strength and importance. It was one of the cities of the Pentapolis of the Roman Exarchate of Ravenna in the 7th and 8th centuries. In 840, Saracen raiders sacked and burned the city. After Charlesmagne's conquest of northern Italy, it became the capital of the Marca di Ancona, whence the name of the modern region. After 1000, Ancona became increasingly independent, eventually turning into an important maritime republic (together with Gaeta, Trani and Ragusa, it is one of those not appearing on the Italian naval flag), often clashing against the nearby power of Venice. An oligarchic republic, Ancona was ruled by six Elders, elected by the three "terzieri" into which the city was divided: S. Pietro, Porto and Capodimonte. It had a coin of its own, the agontano, and a series of laws known as "Statuti del mare e del Terzenale" and "Statuti della Dogana". Ancona was usually allied with Ragusa and the Byzantine Empire. In 1137, 1167 and 1174 it was strong enough to push back the forces of the Holy Roman Empire. Anconitan ships took part in the Crusades, and their navigators included Cyriac of Ancona. In the struggle between the Popes and the Holy Roman Emperors that troubled Italy from the 12th century onwards, Ancona sided with the Guelphs.
Differently from other cities of northern Italy, Ancona never became a seignory. The sole exception was the rule of the Malatesta, who took the city in 1348 taking advantage of the black death and of a fire that had destroyed many of its important buildings. The Malatesta were ousted in 1383. In 1532 it definitively lost its freedom and became part of the Papal States, under Pope Clement VII. Symbol of the papal authority was the massive Citadel. Together with Rome, and Avignon in southern France, Ancona was the sole city in the Papal States in which the Jews were allowed to stay after 1569, living in the ghetto built after 1555.
In 1733 Pope Clement XII extended the quay, and an inferior imitation of Trajan's arch was set up; he also erected a Lazaretto at the south end of the harbour, Luigi Vanvitelli being the architect-in-chief. The southern quay was built in 1880, and the harbour was protected by forts on the heights. From 1797 onwards, when the French took it, it frequently appears in history as an important fortress. Ancona entered in the Kingdom of Italy when Christophe Léon Louis Juchault de Lamoricière surrendered here on 29 September 1860, eleven days after his defeat at Castelfidardo.
During World War II, in July 1944, the city was taken by the Polish II Corps as part of an Allied operation to gain access to a seaport closer to the Gothic Line in order to shorten their lines of communication for the advance into northern Italy.
The Greek community of Ancona in the 16th century.
Ancona, as well as Venice, became a very important destination for merchants from the Ottoman Empire during the 16th century. The Greeks formed the largest of the communities of foreign merchants. They were refugees from former Byzantine or Venetian territories that were occupied by the Ottomans in the late 15th and 16th centuries. The first Greek community was established in Ancona early in the 16th century. Natalucci, the 17th-century historian of the city, notes the existence of 200 Greek families in Ancona at the opening of the 16th century. Most of them came from northwestern Greece, i.e. the Ionian islands and Epirus. In 1514, Dimitri Caloiri of Ioannina obtained reduced custom duties for Greek merchants coming from the towns of Ioannina, Arta and Avlona in Epirus. In 1518 a Jewish merchant of Avlona succeeded in lowering the duties paid in Ancona for all “the Levantine merchants, subjects to the Turk”.
In 1531 the Confraternity of the Greeks ("Confraternita dei Greci") was established which included Orthodox and Catholic Greeks. They secured the use of the Church of St. Anna dei Greci and were granted permission to hold services according to the Greek and the Latin rite. The church of St. Anna had existed since the 13th century, initially as "Santa Maria in Porta Cipriana," on ruins of the ancient Greek walls of Ancona.
In 1534 a decision by Pope Paul III favoured the activity of merchants of all nationalities and religions from the Levant and allowed them to settle in Ancona with their families. A Venetian travelling through Ancona in 1535 recorded that the city was "full of merchants from every nation and mostly Greeks and Turks." In the second half of the 16th century, the presence of Greek and other merchants from the Ottoman Empire declined after a series of restrictive measures taken by the Italian authorities and the pope.
Disputes between the Orthodox and Catholic Greeks of the community were frequent and persisted until 1797 when the city was occupied by France who closed all the religious confraternities and confiscated the archive of the Greek community. The church of St. Anna dei Greci was re-opened to services in 1822. In 1835, in the absence of a Greek community in Ancona, it passed to the Latin Church.
Jewish history.
Jews began to live in Ancona in 967 A.D. In 1270, Jewish resident of Ancona, Jacob of Ancona travelled to China, four years before Marco Polo and documented his impressions in a book called "The City of Lights". From 1300 and on, the Jewish community of Ancona grew steadily, most due to the city importance and it being a center of trade with the Levant. In that year, Jewish poet Immanuel the Roman tried to lower high taxation taken from the Jewish community of the city. over the next 200 years, Jews from Germany, Spain, Sicily and Portugal immigrated to Ancona, due to persecutions in their homeland and thanks to the pro-Jewish attitude taken towards Ancona Jews due to their importance in the trade and banking business, making Ancona a trade center. In 1550, the Jewish population of Ancona numbered about 2700 individuals.
In 1555, pope Paul IV forced the Crypto-Judaism community of the city to convert to Christianity, as part of his Papal Bull of 1555. While some did, others refused to do so and thus were hanged and then burnt in the town square. In response, Jewish merchants boycotted Ancona for a short while. The boycott was led by Dona Gracia Mendes Nasi.
Though emancipated by Napoleon I for several years, in 1843 Pope Gregory XVI revived an , forbidding Jews from living outside the ghetto, wearing identification sign on their clothes and other religious and financial restrictions, though public opinion did not approved these restrictions and thus cancelled a short while after
The Jews of Ancona received full emancipation in 1848. In 1938, 1177 lived in Ancona. 53 Jews were sent away to Germany, 15 of them survived and returned to the town after World War II. The majority of the Jewish community stayed in town or immigrated due to high ransoms paid to the fascist regime. In 2004, about 200 Jews lived in Ancona.
Two synagogues and two cemeteries still exist in the city. The ancient Monte-Cardeto cemetery is one of the biggest Jewish cemeteris in Europe and tombstones are dated to 1552 and on. It can still be visited and it resides within the .
The Great War.
Ancona was an important city during the Great War and in 1915, following Italy's entry, the battleship division of the Austro-Hungarian Navy carried out extensive bombardments causing great damage to all installations.
WW II.
The Battle of Ancona was a battle involving Free Polish forces serving as part of the British Army and German forces that took place from 16 June–18 July 1944 during the Italian campaign in World War II. The battle was the result of an Allied plan to capture the city of Ancona in Italy in order to gain possession of a seaport closer to the fighting so that they could shorten their lines of communication. The Polish 2nd Corps was tasked with capture of the city on 16 June 1944, accomplishing the task a month later on 18 July 1944.
Climate.
The climate of Ancona is humid subtropical (Cfa in the Koeppen climate classification). Winters are cool (Jan mean temp. +5 °C), with frequent rain and fog. Lows can reach -10 °C -or below- outside the city centre, during the most intense cold waves from the north or from the east. Snow is not unusual when there are air masses coming from Northern Europe, the Balkans or Russia, and can be heavy at times, especially in the hills surrounding the city centre. Summers are usually warm and humid (July mean temp. +22.5 °C). Highs sometimes reach values between 35 and, especially if the wind is blowing from the south or from the west (föhn effect). Thunderstorms are quite common, particularly in August and September, when can be severe with flash floods. Spring and autumn are changeable seasons, but generally mild. Extreme temperatures have been -15.4 C (in 1967) and 40.8 C (in 1968) / 40.5 C (in 1983).
Demographics.
In 2007, there were 101,480 people residing in Ancona (the greater area has a population more than four times its size), located in the province of Ancona, Marche, of whom 47.6% were male and 52.4% were female. Minors (children ages 18 and younger) totalled 15.54 percent of the population compared to pensioners who number 24.06 percent. This compares with the Italian average of 18.06 percent (minors) and 19.94 percent (pensioners). The average age of Ancona resident is 48 compared to the Italian average of 42. In the five years between 2002 and 2007, the population of Ancona grew by 1.48 percent, while Italy as a whole grew by 3.56 percent. The current birth rate of Ancona is 8.14 births per 1,000 inhabitants compared to the Italian average of 9.45 births.
As of 2006, 92.77% of the population was Italian. The largest immigrant group came from other European nations (particularly those from Albania, Romania and Ukraine): 3.14%, followed by the Americas: 0.93%, East Asia: 0.83%, and North Africa: 0.80%.
Main sights.
Ancona Cathedral.
Ancona Cathedral, dedicated to Judas Cyriacus, was consecrated at the beginning of the 11th century and completed in 1189. Some writers suppose that the original church was in the form of a basilica and belonged to the 7th century. An early restoration was completed in 1234. It is a fine Romanesque building in grey stone, built in the form of a Greek cross, and other elements of Byzantine art. It has a dodecagonal dome over the centre slightly altered by Margaritone d'Arezzo in 1270. The façade has a Gothic portal, ascribed to Giorgio da Como (1228), which was intended to have a lateral arch on each side.
The interior, which has a crypt under each transept, in the main preserves its original character. It has ten columns which are attributed to the temple of Venus. The church was restored in the 1980s.
Other sights.
There are also several fine late Gothic buildings, including the "Palazzo Benincasa", the "Palazzo del Senato" and the "Loggia dei Mercanti", all by Giorgio da Sebenico, and the prefecture, which has Renaissance additions.
The National Archaeological Museum (Museo Archeologico Nazionale) is housed in the Palazzo Ferretti, built in the late Renaissance by Pellegrino Tibaldi; it preserves frescoes by Federico Zuccari. The Museum is divided into several sections:
The Municipal Art Gallery (Pinacoteca Civica) "Francesco Podesti" is housed in the Palazzo Bosdari, reconstructed in 1558 - 1561 by Pellegrino Tibaldi. Works in the gallery include:
Other artists present include Ciro Ferri and Arcangelo di Cola (flourished 1416-1429). Modern artists featured are Bartolini, Bucci, Campigli, Bruno Cassinari, Cucchi, Levi, Sassu, Orfeo Tamburi, Trubbiani, Francesco Podesti and others.
Angelo Messi, ancestor of famous football star Lionel Messi, emigrated from Ancona to Rosario, Argentina in the 1880s.
Ancona is also the birth city of Italian opera superstar, Franco Corelli.
Transportation.
Shipping.
The Port has regular ferry links to the following cities with the following operators:
Airport.
Ancona is served by Ancona Airport (IATA: AOI, ICAO: LIPY), an airport located in Falconara Marittima and named after Raffaello Sanzio.
Railways.
The Ancona railway station is the main railway station of the city and is served by regional and long distance trains. The other stations are Ancona Marittima, Ancona Torrette, Ancona Stadio, Palombina and Varano. Nuovo Trasporto Viaggiatori plans to run services between Milan and Ancona starting in summer 2013.
Roads.
The A14 motorway serves the city with the exits "Ancona Nord" ("An. North") and "Ancona Sud" ("An. South").
Urban public transportation.
The Ancona trolleybus system has been in operation since 1949. Ancona is also served by an urban bus network.
International relations.
Twin towns – Sister cities.
Ancona is twinned with:

</doc>
<doc id="52613" url="http://en.wikipedia.org/wiki?curid=52613" title="London boroughs">
London boroughs

London boroughs are 32 of the 33 principal subdivisions of the administrative area of Greater London (the 33rd is the City of London) and are each governed by a London borough council. The London boroughs were all created at the same time as Greater London on 1 April 1965 by the London Government Act 1963 and are a type of local government district. Twelve were designated as Inner London boroughs and twenty as Outer London boroughs. 
London boroughs have populations of around 150,000 to 300,000. Inner London boroughs tend to be smaller, in both population and area, and more densely populated than Outer London boroughs. The London boroughs were created by combining groups of former local government units. A review undertaken between 1987 and 1992 led to a number of relatively small alterations in borough boundaries. 
The smaller populations of inner London boroughs are to a large extent due to the shift in population out of inner London since the 1960s.
London borough councils provide the majority of local government services, in contrast to the strategic Greater London Authority, which has limited authority over all of Greater London. The councils were first elected in 1964 and acted as shadow authorities until 1 April 1965. Each borough is divided into electoral wards, subject to periodic review, for the purpose of electing councillors. Council elections take place every four years, with the most recent elections in 2014 and the next elections due in 2018. 
The political make-up of London borough councils is dominated by the Conservative, Labour and Liberal Democrat parties. Twenty-eight councils follow the leader and cabinet model of executive governance, with directly elected mayors in Hackney, Lewisham, Newham, and Tower Hamlets. The City of London is instead governed by the City of London Corporation and the Inner and Middle Temples.
History.
Creation.
From the mid-1930s, the Greater London area comprised four types of local government authorities. There were county boroughs, municipal boroughs, urban districts and metropolitan boroughs. The large county boroughs provided all local government services and held the powers usually invested in county councils. The municipal borough and urban district authorities had fewer powers. The situation was made more complex because county councils could delegate functions such as elementary education and library provision to the municipal borough and district councils, and this was implemented piecemeal. Reform of London local government sought to regularise this arrangement.
The Royal Commission on Local Government in Greater London was established in 1957 and the report was published on 19 October 1960. It proposed 52 "Greater London Boroughs" with a population range of 100,000 to 250,000. This was made up of a mixture of whole existing units, mergers of two or three areas, and two boroughs formed as the result of a split. In December 1961 the government proposed that there would be 34 boroughs rather than 52, and detailed their boundaries. The proposed number was further reduced to 32 in 1962.
On 1 April 1965, the 32 London boroughs and Greater London were created by the London Government Act 1963. 12 boroughs in the former County of London area were designated Inner London boroughs and the 20 others were designated Outer London boroughs. Outer London borough councils were local education authorities, but Inner London borough councils were so designated primarily to continue the existence of an Inner London Education Authority, praised by official Opposition and government who further noted that unusually the former County of London's many small local authorities had no history of providing education. The City of London continued to be administered by the City of London Corporation and the Inner and Middle Temples.
Elections were held on 7 May 1964, with the new councils acting as shadow authorities before coming into their powers the following year.
Former authorities.
The boroughs were created as follows. Some relatively minor changes have been made to the boundaries of boroughs since 1965, and two have changed their names.
Greater London Council.
Between 1965 and 1986 the boroughs were part of a two-tier system of government and shared power with the Greater London Council (GLC). The split of powers and functions meant that the Greater London Council was responsible for "wide area" services such as fire, ambulance, flood prevention, and refuse disposal; with the London borough councils responsible for "personal" services such as social care, libraries, cemeteries and refuse collection. Several London borough councils and the GLC were involved in the rate-capping rebellion of 1985. On 1 April 1986 the GLC was abolished and the borough councils gained responsibility for some services that had been provided by the Greater London Council, such as waste disposal. The Inner London Education Authority continued to exist as an ad hoc authority. In 1990 it was abolished and the Inner London borough councils also became local education authorities.
Name and boundary changes.
The Local Government Act 1972 provided a mechanism for the name of a London borough and its council to be changed. This was used by the London Borough of Hammersmith (changed to Hammersmith and Fulham) on 1 April 1979 and the London Borough of Barking (changed to Barking and Dagenham) on 1 January 1980. Borough names formed by combining two locality names had been discouraged when the boroughs were created.
The London boroughs were created by combining whole existing units of local government and it was realised that this might provide arbitrary boundaries in some places. The London Government Act 1963 provided a mechanism for communities on the edge of Greater London to petition for transfer from London boroughs to a neighbouring county district. This was used in 1969 in the transfers of Knockholt in Bromley to Kent, and of Farleigh and Hooley in Croydon to Surrey. The Act also provided for transfers between London boroughs and neighbouring counties where there was consensus for the change between all the relevant local authorities. This provision was used to exchange two islands on the River Thames between Richmond upon Thames and Surrey. (See List of Greater London boundary changes.)
The Local Government Boundary Commission for England was established by the Local Government Act 1972 to review periodically the boundaries of Greater London and the London boroughs. The first review of boundaries commenced on 1 April 1987 and reported in 1992. Following the review a series of relatively minor adjustments were made to borough boundaries, for example uniting the whole of the Becontree estate in Barking and Dagenham. The commission noted that many of its recommendations were strongly opposed and were not implemented. The boundary of the City of London with adjacent boroughs was adjusted to remove some anomalies.
Greater London Authority.
In 2000 the Greater London Authority was created, comprising the Mayor of London and the London Assembly. As a strategic authority, it absorbed only limited powers, such as major highways and planning strategy, from the borough councils.
London borough councils.
The London boroughs are administered by London borough councils (sometimes abbreviated LBCs) which are elected every four years. They are the principal local authorities in London and are responsible for running most local services, such as schools, social services, waste collection and roads. Some London-wide services are run by the Greater London Authority, and some services and lobbying of government are pooled within London Councils. Some councils group together for services such as waste collection and disposal (e.g., the West London Waste Authority). The boroughs are local government districts and have similar functions to metropolitan boroughs. Each borough council is a local education authority.
Shared services.
Shared services are borough council services shared between two or more boroughs. Shared services were previously resisted due to councils jealously guarding their authority. However, as the need for budget cuts in the late 2000s became apparent some councils have sought service mergers. Westminster and Hammersmith & Fulham were due to merge their education services, including school admissions and transport, by 2011. In October 2010, Hammersmith & Fulham, Kensington & Chelsea and Westminster announced plans to merge all their services to create a "super-council". Each would retain its own political identity, leadership and councillors but staff and budgets would be combined for cost savings. Lambeth and Southwark likewise expressed an interest in sharing services.
Critics of shared services.
The management thinker and inventor of the Vanguard Method, Professor John Seddon, claims that shared service projects based on attempts to achieve economies of scale are a mix of a) the plausibly obvious and b) a little hard data, brought together to produce two broad assertions, for which there is little hard factual evidence. He argues that shared service projects fail (and often end up costing more than they hoped to save) because they cause a disruption to the service flow by moving the work to a central location, creating waste in handoffs, rework and duplication, lengthening the time it takes to deliver a service and consequently creating failure demand (demand caused by a failure to do something or do something right for a customer).
Seddon referred directly to the so-called tri-borough shared services in an article in 2012.
List of boroughs.
There are four boroughs that do not have "London Borough" in their names: the City of Westminster, and the Royal Boroughs of Kingston upon Thames, Kensington and Chelsea, and (since 2012) Greenwich.

</doc>
<doc id="52616" url="http://en.wikipedia.org/wiki?curid=52616" title="Delaware River">
Delaware River

The Delaware River is a major river on the Atlantic coast of the United States. Its watershed drains an area of 14119 sqmi in five U.S. states—New York, New Jersey, Pennsylvania, Maryland and Delaware. Rising in two branches in New York state's Catskill Mountains, the river flows 419 mi into Delaware Bay where its waters enter the Atlantic Ocean near Cape May in New Jersey and Cape Henlopen in Delaware. Not including Delaware Bay, the river's length including its two branches is 388 mi.
The Delaware River is one of nineteen "Great Waters" recognized by the America's Great Waters Coalition.
The Delaware River rises in two main branches that descend from the western flank of the Catskill Mountains in New York. The West Branch begins near Mount Jefferson in the Town of Jefferson in Schoharie County. The river's East Branch begins at Grand Gorge near Roxbury
Delaware County. These two branches flow west and merge near Hancock in Delaware County and the combined waters flow as the Delaware River south. Through its course, the Delaware River forms the boundaries between Pennsylvania and New York, the entire boundary between New Jersey and Pennsylvania, and most of the boundary between Delaware and New Jersey. The river meets tide-water at the junction of Morrisville, Pennsylvania and Trenton, New Jersey at the Falls of the Delaware. The river's navigable, tidal section served as a conduit for shipping and transportation that aided the development of the industrial cities of Trenton, Camden, and Philadelphia. The mean freshwater discharge of the Delaware River into the estuary of Delaware Bay is 11,550 cubic feet (330 m³) per second.
In 1609, the river was first visited by a Dutch East India Company expedition led by Henry Hudson. Hudson, an English navigator, was hired to find a western route to Cathay (present-day China), but his discoveries set the stage for Dutch colonization of North America in the seventeenth-century. Early Dutch and Swedish settlements were established along the lower section of river and Delaware Bay. Both colonial powers called the river the "South River" compared to the Hudson River which was known as the "North River". After the English expelled the Dutch and took control of the New Netherland colony in 1664, the river was renamed "Delaware" after Sir Thomas West 3rd Baron De La Warr, an English nobleman and the Virginia colony's first royal governor who defended the colony during the First Anglo-Powhatan War.
Origin of the name.
The Delaware River is named in honor of Thomas West, 3rd Baron De La Warr (1577–1618), an English nobleman and the Virginia colony's first royal governor who defended the colony during the First Anglo-Powhatan War. Lord de la Warr waged a punitive campaign to subdue the Powhatan after they had killed the colony’s council president, John Ratcliffe, and attacked the colony’s fledgling settlements. Lord de la Warr arrived 150 soldiers in time to prevent colony’s original settlers at Jamestown from giving up and returning to England and is credited with saving the Virginia colony. The name of barony (later an earldom) is pronounced as in the current spelling form "Delaware" ( ) and is thought to derive from French "de la Guerre".
It has often been reported that the river and bay received the name "Delaware" after English forces under Richard Nicolls expelled the Dutch and took control of the New Netherland colony in 1664. However, the river and bay were known by the name "Delaware" as early as 1641. The state of Delaware was originally part of the William Penn's Pennsylvania colony. In 1682, the Duke of York granted Penn's request for access to the sea and leased him the territory along the western shore of Delaware Bay which became known as the "Lower Counties on the Delaware." In 1704, these three lower counties were given political autonomy to form a separate provincial assembly, but shared its provincial governor with Pennsylvania until the two colonies separated on 15 June 1776 and remained separate as states after the establishment of the United States. The name also became used as a collective name for the Lenape, a Native American people (and their language) who inhabited an area of the basins of the Susquehanna River, Delaware River, and lower Hudson River in the northeastern United States at the time of European settlement. As a result of disruption following the French & Indian War, American Revolutionary War and later Indian removals from the eastern United States, the name "Delaware" has been spread with the Lenape's diaspora to municipalities, counties and other geographical features in the American Midwest and Canada.
Watershed.
The Delaware River's watershed drains an area of 14119 sqmi and encompasses 42 counties and 838 municipalities in five U.S. states—New York, New Jersey, Pennsylvania, Maryland, and Delaware.:p.9 This total area constitutes approximately 0.4% of the land mass in the United States.:p.9 In 2001, the watershed was 18% agricultural land, 14% developed land, and 68% forested land.
There are 216 tributary streams and creeks—an estimated 14,057 miles of streams and creeks—in the watershed.:p.11,25 While the watershed is home to 4.17 million people according to the 2000 Federal Census, these bodies of water provide drinking water to 17 million people—roughly 6% of the population of the United States.:p.vi,9 The waters of the Delaware River's basin are used to sustain "fishing, transportation, power, cooling, recreation, and other industrial and residential purposes.":p.9 It is the 33rd largest river in the United States in terms of flow, but the nation's most heavily used rivers in daily volume of tonnage.:p.11 The average annual flow rate of the Delaware is 11,700 cubic feet per second at Trenton, New Jersey.:p.9 With no dams or impediments on the river's main stem, the Delaware is one of the few remaining large free-flowing rivers in the United States.:p.11
Course.
West Branch of the Delaware.
The West Branch of the Delaware River (also called the "Mohawk Branch") spans approximately 90 mi from the northern Catskill Mountains to where it joins in confluence with the Delaware River's East Branch at Hancock, New York. The last 6 mi forms part of the boundary between New York and Pennsylvania.
The West Branch rises in Schoharie County, New York at 1886 ft above sea level, near Mount Jefferson, and flows tortuously through the plateau in a deep trough. The branch flows generally southwest, entering Delaware County and flowing through the towns of Stamford and Delhi. In southwestern Delaware County it flows in an increasingly winding course through the mountains, generally southwest. At Stilesville the West Branch was impounded in the 1960s to form the Cannonsville Reservoir, the westernmost of the reservoirs in the New York City water system. It is the most recently constructed New York City reservoir and began serving the city in 1964. Draining a large watershed of 455 sqmi, the reservoir's capacity is 95.7 e9USgal. This water flows over halfway through the reservoir to enter the 44 mi West Delaware Tunnel in Tompkins, New York. Then it flows through the aqueduct into the Rondout Reservoir, where the water enters the 85 mi Delaware Aqueduct, that contributes to roughly 50% of the city's drinking water supply. At Deposit, on the border between Broome and Delaware counties, it turns sharply to the southeast and is paralleled by New York State Route 17. It joins the East Branch at 880 ft above sea level at Hancock to form the Delaware.
East Branch of the Delaware.
Similarly, the East Branch begins from a small pond south of Grand Gorge in the town of Roxbury in Delaware County, flowing southwest toward its impoundment by New York City to create the Pepacton Reservoir, the largest reservoir in the New York City water supply system. Its tributaries are the Beaver Kill River and the Willowemoc Creek which enter into the river ten miles (16 km) before the West Branch meets the East Branch. The confluence of the two branches is just south of Hancock.
Both the East Branch and West Branch of the Delaware River parallel each other, both flowing in a southwesterly direction.
Upper Delaware Valley.
From Hancock, New York, the river flows between the northern Pocono Mountains in Pennsylvania, and the lowered shale beds north of the Catskills. The river flows down a broad Appalachian valley, passing Hawk's Nest overlook on the Upper Delaware Scenic Byway. The river flows southeast for 78 miles through rural regions along the New York-Pennsylvania border to
Port Jervis and the Shawangunk Mountains.
The Minisink.
At Port Jervis, New York, it enters the Port Jervis trough. At this point, the Walpack Ridge deflects the Delaware into the Minisink Valley, where it follows the southwest strike of the eroded Marcellus Formation beds along the Pennsylvania–New Jersey state line for 25 mi to the end of the ridge at Walpack Bend in the Delaware Water Gap National Recreation Area.
The Minisink is a buried valley where the Delaware flows in a bed of glacial till that buried the eroded bedrock during the last glacial period. It then skirts the Kittatinny ridge, which it crosses at the Delaware Water Gap, between nearly vertical walls of sandstone, quartzite, and conglomerate, and then passes through a quiet and charming country of farm and forest, diversified with plateaus and escarpments, until it crosses the Appalachian plain and enters the hills again at Easton, Pennsylvania. From this point it is flanked at intervals by fine hills, and in places by cliffs, of which the finest are the Nockamixon Rocks, 3 mi long and above 200 ft high.
The Appalachian Trail, which traverses the ridge of Kittatinny Mountain in New Jersey, and Blue Mountain in Pennsylvania, crosses the Delaware River at the Delaware Water Gap near Columbia, New Jersey.
Central Delaware Valley.
At Easton, Pennsylvania, the Lehigh River enters the Delaware. At Trenton there is a fall of 8 ft.
The Lower Delaware and Tide-Water.
Below Trenton the river flows between Philadelphia and New Jersey before becoming a broad, sluggish inlet of the sea, with many marshes along its side, widening steadily into its great estuary, Delaware Bay.
The Delaware River constitutes part of the boundary. The Delaware-New Jersey border is actually at the easternmost river shoreline within the Twelve-Mile Circle of New Castle, rather than mid-river or mid-channel borders, causing small portions of land lying west of the shoreline, but on the New Jersey side of the river, to fall under the jurisdiction of Delaware. The rest of the borders follow a mid-channel approach.
History.
The Delaware River played a key factor in the economic and social development of the Mid-Atlantic region. In the seventeenth century it provided the conduit for colonial settlement by the Dutch (New Netherland), the Swedish (New Sweden). Beginning in 1664, the region became an English possession as settlement by Quakers established the colonies of Pennsylvania (including present-day Delaware) and West Jersey. In the eighteenth century, cities like Philadelphia, Camden (then Cooper's Ferry), Trenton, and Wilmington, and New Castle were established upon the Delaware and their continued commercial success into the present day has been dependent on access to the river for trade and power. The river provided the path for the settlement of northeastern Pennsylvania's Lehigh Valley, and northwestern New Jersey by German Palatine immigrants—a population that became key in the agricultural development of the region.
Washington's crossing of the Delaware.
Perhaps the most famous “Delaware Crossing” involved the improvised boat crossing undertaken by George Washington’s army during the American Revolution on the night of December 25–26, 1776. This led to a successful surprise attack on the Hessian troops occupying Trenton, New Jersey.
Canals.
The magnitude of the commerce of Philadelphia has made the improvements of the river below that port of great importance. Small improvements were attempted by Pennsylvania as early as 1771. Commerce was once important on the upper river, primarily prior to railway competition (1857).
In the "project of 1885" the U.S. government undertook systematically the formation of a 26 ft channel 600 ft wide from Philadelphia to deep water in Delaware Bay. The River and Harbor Act of 1899 provided for a 30 ft channel 600 ft wide from Philadelphia to the deep water of the bay.
Delaware Water Gap National Recreation Area.
The Delaware Water Gap National Recreation Area came about as a result of the failure of a controversial plan to build a dam on the Delaware River at Tocks Island, just north of the Delaware Water Gap to control water levels for flood control and hydroelectric power generation. The dam would have created a 37 mi lake in the center of present park for use as a reservoir. Starting in 1960, the present day area of the Recreation Area was acquired for the Army Corps of Engineers through eminent domain. Between 3,000 and 5,000 dwellings were demolished, including historical sites, and about 15,000 people were displaced by the project.
Because of massive environmental opposition, dwindling funds, and an unacceptable geological assessment of the dam's safety, the government transferred the property to the National Park Service in 1978. The National Park Service found itself as the caretaker of the previously endangered territory, and with the help of the federal government and surrounding communities, developed recreational facilities and worked to preserve the remaining historical structures.
Commerce.
Wine regions.
In 1984, the U.S. Department of the Treasury authorized the creation of a wine region or "American Viticultural Area" called the Central Delaware Valley AVA located in southeastern Pennsylvania and New Jersey. The wine appellation includes 96000 acre surrounding the Delaware River north of Philadelphia and Trenton, New Jersey. In Pennsylvania, it consists of the territory along the Delaware River in Bucks County; in New Jersey, the AVA spans along the river in Hunterdon County and Mercer County from Titusville, New Jersey, just north of Trenton, northward to Musconetcong Mountain. As of 2013, there are no New Jersey wineries in the Central Delaware Valley AVA.
Shipping.
Since 1941, the Delaware River Main Channel has been maintained at a depth of 40 ft. A 102.5-mile stretch of this federal navigation channel, from Philadelphia, Pa. and Camden, N.J. to the mouth of the Delaware Bay, is being deepened to 45 ft., with a 2017 projected completion date.
As of 2011, crude oil was the largest single commodity transported on the Delaware River, accounting for half of all annual cargo tonnage. Major ports and facilities along the river are the Port of Philadelphia, the Port of Camden-Gloucester, the Port of Paulsboro, the Port of Wilmington, and Delaware City Refinery.
Bridge crossings.
The Delaware River is a major barrier to travel between New Jersey and Pennsylvania. Most of the larger bridges are tolled only westbound, and are owned by the Delaware River and Bay Authority, Delaware River Port Authority, Burlington County Bridge Commission or Delaware River Joint Toll Bridge Commission.
Environmental issues.
New York City water supply.
After New York City had built 15 reservoirs to supply water to the city's growing population, it was unable to obtain permission to build an additional five reservoirs along the Delaware River's tributaries. As a result, in 1928 the city decided to draw water from the Delaware River, putting them in direct conflict with villages and towns across the river in Pennsylvania which were already using the Delaware for their water supply. The two sides eventually took their case to the U.S. Supreme Court, and in 1931, New York City was allowed to draw 440 e6USgal of water a day from the Delaware and its upstream tributaries.
Flooding.
With the failure of the dam project to come to fruition, the lack of flood control on the river left it vulnerable, and it has experienced a number of serious flooding events as the result of snow melt or rain run-off from heavy rainstorms. Record flooding occurred in August 1955, in the aftermath of the passing of the remnants of two separate hurricanes over the area within less than a week: first Hurricane Connie and then Hurricane Diane, which was, and still is, the wettest tropical cyclone to have hit the northeastern United States. The river gauge at Riegelsville, Pennsylvania recorded an all time record crest of 38.85 ft on August 19, 1955.
More recently, moderate to severe flooding has occurred along the river. The same gauge at Riegelsville recorded a peak of 30.95 ft on September 23, 2004, 34.07 ft on April 4, 2005, and 33.62 ft on June 28, 2006, all considerably higher than the flood stage of 22 ft.
Since the upper Delaware basin has few population centers along its banks, flooding in this area mainly affects natural unpopulated flood plains. Residents in the middle part of the Delaware basin experience flooding, including three major floods in the three years (2004–2006) that have severely damaged their homes and land. The lower part of the Delaware basin from Philadelphia southward to the Delaware Bay is tidal and much wider than portions further north, and is not prone to river-related flooding (although tidal surges can cause minor flooding in this area).
The Delaware River Basin Commission, along with local governments, is working to try to address the issue of flooding along the river. As the past few years have seen a rise in catastrophic floods, most residents of the river basin feel that something must be done. The local governments have worked in association with FEMA to address many of these problems, however, due to insufficient federal funds, progress is slow.
Major oil spills.
A number of oil spills have taken place in the Delaware over the years.
References.
Attribution
External links.
Historical content

</doc>
<doc id="52619" url="http://en.wikipedia.org/wiki?curid=52619" title="United Kingdom of the Netherlands">
United Kingdom of the Netherlands

 |style="width:1.0em; padding:0 0 0 0.6em;"| - 
 |style="padding-left:0;text-align:left;"| 1815–1839
The United Kingdom of the Netherlands (1815–1839) (Dutch: "Verenigd Koninkrijk der Nederlanden", French: "Royaume uni des Pays-Bas") was the Kingdom of the Netherlands (Dutch: "Koninkrijk der Nederlanden", French: "Royaume des Belgiques") during the period after it was first created from part of the First French Empire and before the new Kingdom of Belgium split off from it in 1830.
This state, a large part of which still exists today as the Kingdom of the Netherlands, was made up of the former Dutch Republic (Republic of the Seven United Netherlands) to the north, the former Austrian Netherlands to the south, and the former Prince-Bishopric of Liège. The House of Orange-Nassau came to be the monarchs of this new state.
The United Kingdom of the Netherlands collapsed after the 1830 Belgian Revolution. William I, King of the Netherlands, would refuse to recognize a Belgian state until 1839, when he had to yield under pressure by the Treaty of London. Only at this time were exact borders agreed upon.
Nowadays, the Benelux Union (created in 1944 between Netherlands, Belgium and Luxembourg) is in some ways a "distant heir" of the former United Kingdom of the Netherlands. Their respective political systems are very similar and Dutch is the official and vernacular language of 83% of its total population.
Prince William of Orange-Nassau, the new sovereign of the Netherlands.
After the liberation of the Netherlands in 1813 by Prussian and Russian troops, it was taken for granted that any new regime would have to be headed by William Frederik of Orange-Nassau, the son of the last stadtholder William V of Orange-Nassau and Princess Wilhelmina of Prussia. William returned to The Hague, where on 6 December he was offered the title of King. He refused, instead proclaiming himself "Sovereign Prince" of the Principality of the United Netherlands.
Unification under William I.
During the Congress of Vienna in 1815 France had to give up its rule of the Southern Netherlands. These negotiations were not made easy, because William tried to get as much out of it as he could. His ideas of a United Netherlands were based upon the actions of Hendrik van der Noot, a lawyer and politician and one of the main players in the Revolution of the Southern Netherlands against the Austrian Emperor (1789–1790). In 1789, after the Southern Netherlands declared themselves independent, Hendrik knew this was a fragile state and he tried to be reunited with the Republic of the Seven United Netherlands. Since then William had never forgotten this and after the fall of Napoleon he saw a chance.
Three different scenarios were made:
The first two scenarios came from "Memorandum of Holland" made in 1813 after the Battle of Leipzig. The last scenario came from William himself. The first scenario never made it because the Great Powers (Great Britain, Prussia, Austria and Russia) thought an independent Southern Netherlands/Belgium under an Austrian Prince was too weak and Austria was not interested in getting it back.
The Dutch question became a problem. The Great Powers of Europe chose the last scenario, but didn't want to go as far in enlarging the Netherlands as William.
In the end, the Eight Articles of London granted William sovereignty over the following lands:
The Duchy of Luxembourg was not fully granted to William, because it was a member of the German Confederation. William however demanded that Luxembourg become a part of the Netherlands, as a unified Netherlands was stronger as a buffer for France. Historically it had been a part of the Seventeen Provinces or Burgundian Netherlands up to 1648, but Luxembourg was still a part of the discussions.
On 1 March 1815, while the Congress of Vienna was still going on, Napoleon escaped from Elba and he created a large army against the Great Powers of Europe. He was defeated at the Battle of Waterloo (at that time within the kingdom) by Prussian, British, Belgian, Dutch and Nassau (under the prince of Orange) troops.
In response, on 16 March 1815, William proclaimed the Netherlands a kingdom, with himself as King William I.
Furthermore, on 31 May 1815, William concluded a treaty at the Congress of Vienna whereby he ceded the Principality of Orange-Nassau to the Kingdom of Prussia in exchange for the Duchy of Luxembourg. As William ceased to be reigning Prince of Orange-Nassau and became Grand Duke Guillaume I of Luxembourg the Duchy was elevated to a Grand Duchy in a personal and political (until 1839) union with the Netherlands - albeit remaining within the German Confederation, being garrisoned by Prussian troops on behalf of the Dutch king.
With the unification William completed the three-century dream of his family (started by his ancestor William the Silent in 1579) of uniting the Low Countries under a single rule.
Terminology.
"Royaume uni des Pays-Bas" never was the French official name of this short-lived kingdom. This French unofficial name stayed in the common language to avoid any confusion with the rest of the Netherlands after the Belgian Revolution and secession (1830-1839). Both in international treaties and national legislation was the country indifferently referred in French to "" ("Belgiques" in the plural) and "Royaume des Pays-Bas".
From the 17th century until the revolution of 1830 were the English "Netherlands", Dutch "Nederlanden", Latin "Belgium" (or "Belgica") and French "Pays-Bas" or "Belgique" (in the singular) more or less interchangeable. For example, the Dutch colony of New Netherlands (North America) was called in Latin "Nova Belgica" or "Novum Belgium", in Dutch "Nieuw-Nederland" and in French... "Nouvelle-Hollande". Likewise, the United States of Belgium (the first independent and short-lived Belgian state, 1789-1790) were called in French "États belgiques unis", in Dutch "Verenigde Nederlandse Staten" and in Latin "Status Belgii Fœderati" or "Belgium Fœderatum".
At the start of the Orange regime, harsh discussions arose - especially in the Southern provinces - about the way to "qualify" the inhabitants of the new kingdom and the latter itself. In common language (in Flemish as in French), it wasn't a problem to talk about "de Nederlanden" or "les Pays-Bas". For the Flemings, it was uneasy but not totally irrelevant to be referred to "Nederlanders" (adj. "Nederlands"), even if they now preferred to be called "Belgen" (adj. "Belgisch"). Contrariwise was it absolutely irrelevant for the Frenchspeaking elites to be called "Néerlandais" (King William furthermore wanted to create the French neologism ...) and they demanded to be named "Belges". So, confronted to a wide protest in the elite circles from the South, the regime decided to translate the Dutch "Nederlanden", "Het Nederlandse volk", "Nederlanders" and "Nederlands" by the French "Belgiques", "Le peuple belge", "Belges" and "belge". Moreover, in French, it wasn't referred to a "langue néerlandaise" but to a "langue belgique" 
But even the latter decision also caused turmoil in the South: some Walloons and Flemings (French speakers as Flemish speakers) petitioned vehemently, arguing they didn't want to share "their" name with the "Hollanders". To illustrate the complexity of this "terminological mess", one among the most radical and republican opposition newspapers published in the South was named... "Le Courrier des Pays-Bas".
After the Belgian secession, the Southern provinces choose as an official name "Kingdom of Belgium". In French, the new state was called "Royaume de Belgique" ("Belgique" in the singular), while it was necessary to find a neologism for the Dutch official name to be used by the Flemings: "Koninkrijk België". Finally, to establish a clear distinction with the Northern provinces, the official Latin name became "Regnum Belgicæ" or "Belgica" (and no more "Regnum Belgii" or "Belgium", both reserved to the North until the eve of de 20th century). Since then, the Latin (mostly honorific) names for the North are "Nederlandia" and sometimes "Batavia".
Power of the King.
The newly formed kingdom was not like the Netherlands or Belgium today. Under the constitution, King William was both head of state and head of government, and had considerably more power than a King or Queen in a modern constitutional monarchy.
The Second Chamber of the States General of the Netherlands had 110 members. Despite the south's far greater population, both halves of the kingdom each elected 55 members--a source of considerable resentment in the south. The First Chamber was appointed by the king and consisted of old and new noblemen.
The Netherlands had eight ministers, who were responsible only to the King himself. In fact, they followed his demands. The King also could rule by "Royal Order".
Provinces.
The Kingdom consisted of 17 provinces (BE means currently part of Belgium, NL means currently part of the Netherlands).
In the North, the provinces kept the former administrative boundaries of the French departments, themselves shaped according the former seven United Provinces of the Netherlands.
In the South, the provinces were "grosso modo" shaped according to the former French departments but - in a "Restoration" spirit - they were renamed to refer to the former principalities of the pre-revolutionary Southern Netherlands and Prince-Bishopric of Liège.
Economic and social development.
Economically the new state prospered, although many people in the north were unemployed and lived in poverty because a lot of British goods had destabilised the Dutch trade market.
Although financially stable, the south also had the burden of the nation's debt, but gained new trade markets in the Dutch colonies. Many people's welfare improved in the south lived in poverty because the profits of trade were used for big projects.
William tried to divide the nation's wealth more equally through, among others, the following actions:
Through these actions export of cotton, sheets, weapons and steel products increased. The fleet of Antwerp grew to 117 ships. Many of these projects were funded by King William himself.
The educational system was extended. Under William's rule the number of school-going children doubled from 150,000 to 300,000 by opening 1,500 new public schools. The south especially needed schools because many people could not read or write.
In 1825 William founded the Dutch Trading Company (Dutch: Nederlandse Handels Maatschappij), to boost trade with the colonies.
The way to separation.
Social differences
Socially the unification created many problems. Although William set out from the start to create a single people, it soon became apparent that the north and south had drifted far apart culturally in the 200 years since the south was reconquered by the Habsburgs. In particular, the mentalities of the Burgundian south and Calvinistic north did not tolerate each other very well. Both the north and the south had a different historical background and the Dutch and French speaking people both were afraid of being overruled by each other. France played a role in this by the "Légion belge et parisienne", financed with private funds but with permission of the French government, to make a unification with France possible.
The north had built up an independent history, and had experienced a golden age. William and his northern subjects saw the south more as a territorial gain than a partner. Although 62% of the population lived in the South, they were assigned the same number of representatives in the States General as the North. This was exacerbated by the fact that the north had more representation in the Second Chamber, since it was divided into more provinces than the south. Therefore the more populous Belgians felt significantly under-represented.
A linguistic reform in 1823 intended to make Dutch the official language in the Flemish provinces, since it was the language of most of the Flemish population. This reform met with strong opposition from the Flemish upper and middle classes who at the time were mostly French speaking.
Religious and political differences
Religion was also a reason for separation. While the north was dominantly Protestant, the south was Catholic. The Catholic Church saw its influence declining in favour of the king. He built over 1,500 state schools where the Church was no longer the provider of education.

</doc>
<doc id="52620" url="http://en.wikipedia.org/wiki?curid=52620" title="Gower Peninsula">
Gower Peninsula

Gower or the Gower Peninsula (Welsh: "Gŵyr" or "Penrhyn Gŵyr") is a peninsula in South Wales, projecting westwards into the Bristol Channel, and administratively part of the City and County of Swansea. In 1956, Gower became the first area in the United Kingdom to be designated an Area of Outstanding Natural Beauty.
Geography.
About 70 sqmi in area, Gower is known for its coastline, popular with walkers and outdoor enthusiasts, especially surfers. Gower has many caves, including Paviland Cave and Minchin Hole Cave. The peninsula is bounded by the Loughor Estuary to the north and Swansea Bay to the east. Gower Area of Outstanding Natural Beauty covers 188 km², including most of the peninsula west of Crofty, Three Crosses, Upper Killay, Blackpill and Bishopston. The highest point of Gower is The Beacon at Rhossili Down at 193 metres (633 ft) overlooking Rhossili Bay. Pwll Du and the Bishopton Valley form a statutory Local Nature Reserve.
The interior of Gower consists mainly of farmland and common land. The population resides mainly in villages and small communities, though suburban development has made a number of communities in eastern Gower part of the Swansea Urban Area.
The southern coast consists of a series of small, rocky or sandy bays, such as Langland and Three Cliffs, and larger beaches such as Port Eynon, Rhossili and Oxwich Bay. The north of the peninsula has fewer beaches, and is home to the cockle-beds of Penclawdd.
History.
Stone Age.
Wales is known to have been inhabited since at least the Upper Paleolithic period, and the Gower Peninsula has been the scene of several important archaeological discoveries. In 1823 Victorian-era archaeologists discovered a fairly complete Upper Paleolithic-era human male skeleton in Paviland Cave. They named their find the "Red Lady of Paviland" because the skeleton is dyed in red ochre, though later investigators determined it was actually a male. This was the first human fossil to have been found anywhere in the world, and is still the oldest ceremonial burial anywhere in Western Europe. The most recent re-calibrated radiocarbon dating in 2009 indicates that the skeleton can be dated to around 33,000 Before Present (BP). In 1937 the Parc Cwm long cairn was identified as a Severn-Cotswold type of chambered long barrow. Also known as Parc le Breos burial chamber, it is a partly restored Neolithic chambered tomb. The megalithic burial chamber, or "cromlech", was built around 6,000 BP. In the 1950s, Cambridge University excavating in a cave on the peninsula found 300–400 pieces of flint related to toolmaking, and dated it to between 12,000–14,000 BC. In 2010 an instructor from Bristol University, exploring caves in the same area, discovered a rock drawing of a red deer from the same period, which may be the oldest cave art found in Great Britain.
Bronze Age.
Gower is also home to menhirs or standing stones from the Bronze Age. Of the nine stones, eight remain today. One of the most notable of the stones is Arthur's stone near Cefn Bryn. Its twenty-five ton capstone was most likely a glacial erratic (a piece of rock/conglomerate carried by glacial ice some distance from the rock outcrop from which it came), which the builders dug beneath and supported with upright stones to create a burial chamber. The remains of Sweyne Howes on Rhossili Down, Penmaen Burrows Tomb (Pen-y-Crug) and Nicholaston Long Cairn are three other well-known Neolithic chambered tombs. During the Bronze Age, people continued to use local caves as a source of shelter and for burying their dead. Bronze Age evidence, such as funeral urns, pottery and human remains have been found in Tooth Cave at Llethryd, Culver Hole (Port Eynon) and Cat Hole Cave. With the transition into the Iron Age, hill forts (timber fortifications on hill tops and coastal promontories) and earthworks began to appear. The largest example of this type of Iron Age settlement on the Gower Peninsula is Cilifor Top near Llanrhidian.
Roman era.
Roman occupation brought new settlement. The Romans built Leucarum, a rectangular or trapezoidal fort at the mouth of the River Loughor in the late 1st century to house a regiment of Roman auxiliary troops. Its remains are located beneath the town of Loughor. Stone defences were added to the earthen ditch and rampart by 110 and the fort was occupied until the middle or end of that century. However, it was later abandoned for a time and in the early 3rd century the ditch naturally silted up. It appears to have been brought back into use during the rule of Carausius who was worried about Irish raids, but was abandoned again before the 4th century. A Norman castle was later built on the site.
Anglo-Normans.
Following the Norman invasion of Wales the commote of Gwyr passed into the hands of English-speaking Britons and its southern part soon became Anglicised. In 1203 King John (1199–1216) granted the Lordship of Gower to William III de Braose (d.1211) for the service of one knight's fee. It remained with the Braose family until the death of William de Braose, 2nd Baron Braose in 1326, when it passed from the family to the husband of one of his two daughters and co-heiresses, Aline and Joan. In 1215 a local lord, Rhys Gryg of Deheubarth claimed control of the peninsula, but in 1220 he ceded control to the Anglo-Norman lords, perhaps on the orders of his overlord, Llywelyn ap Iorwerth. Thereafter Gower remained beyond the reach of Llewelyn's successors as Prince of Wales; but its population suffered at the hands of Rhys ap Maredudd during his revolt of 1287–8.
Tudor era.
In 1535 the Act of Union made the Lordship of Gower part of the historic county of Glamorgan, and its south-western section became the hundred of Swansea.
Modern era.
In modern times Gower was administered as a Rural District of Glamorgan. In 1974 it was merged with the county borough of Swansea, to form the Swansea district. Since 1996 Gower has been part of the City and County of Swansea.
Governance.
The Gower constituency has elected only Labour members of Parliament since 1906, the longest run (with Normanton and Makerfield) of any UK constituency. The constituency encompasses the old Lordship of Gower (less the city of Swansea) and covers the peninsula and outer Gower areas including Clydach, Gowerton, Gorseinon, Felindre and Garnswllt. A Conservative Party MP was elected to represent the area in the 2015 election.
Economy.
Agriculture remains important to the area, but tourism plays an increasing role in the local economy. The peninsula has a Championship status golf course at Fairwood Park just off Fairwood Common, having twice held the Welsh PGA Championships in the 1990s. Meanwhile, the Gower Golf Club at Three Crosses hosts the West Wales Open, a two-day tournament on Wales' professional golf tour, the Dragon Tour. Gower is part of the Swansea Travel to Work Area (see Economy of Swansea).
Landmarks.
There are six castles on the Gower Peninsula: (also known as Landimore Castle), Oystermouth Castle, Oxwich Castle, Pennard Castle, Penrice Castle and Weobley Castle.
Four of Gower's beaches have Blue Flag beach and Seaside (2006) awards for their high standards: Bracelet Bay, Caswell Bay, Langland Bay and Port Eynon Bay. Five other beaches have been given the Green Coast Award 2005 for "natural, unspoiled environment": Rhossili Bay, Mewslade Bay, Tor Bay, Pwll Du Bay, and Limeslade Bay.
Other beaches include:
Llethryd Tooth Cave.
The Llethryd Tooth Cave, or Tooth Hole cave, is a Bronze Age ossuary site in a limestone cave, about 1,500 yards (1.4 km) north, north west of the Parc Cwm long cairn cromlech, on private land along the "Parc Cwm" valley, near the village of Llethryd. The cave was rediscovered by cavers in 1961, who found human bones. An excavation was carried out by D.P. Webley & J. Harvey in 1962 revealing the "disarticulated remains" (i.e. not complete skeletons) of six adults and two children, dated to the Early Bronze Age or Beaker culture. Other finds are now held at the Amgueddfa Cymru–National Museum Wales, Cardiff: Early Bronze Age, or Beaker, collared urn pottery; flaked knives; a scraper; flint flakes; a bone spatula; a needle & bead; and animal bones – the remains of domesticated animals, cat and dog. Archaeologists Alasdair Whittle and Michael Wysocki note that this period of occupation may be "significant", with respect to "Parc Cwm" long cairn, as it is "broadly contemporary with the secondary use of the tomb". In their article published in The Proceedings of the Prehistoric Society (vol.64 (1998), pp. 139–82) Whittle and Wysocki suggest corpses may have been placed in caves near the cromlech until they decomposed, when the bones were moved to the tomb – a process known as "excarnation".
At nearly a mile (1,525 m) long, the Tooth Cave is the longest cave in Gower. It has tight and flooded sections, and so is kept locked for safety.
Representation in the media.
The village of Mumbles set the scene for a six-part drama "Ennals Point" featuring Welsh actor Philip Madoc. The series focused on the local lifeboat crew and first aired in January 1982.
A film, "Gower Boy", made by artist Gee Vaucher and musician Huw Warren, described as a "gentle, contemplative exploration of the Gower Peninsula in Wales", debuted at the 14th Raindance Film Festival in October 2006 .
The village of Rhossili appeared as a location in the 2006 "Doctor Who" episode "New Earth", in which Worm's Head could also be seen.

</doc>
<doc id="52621" url="http://en.wikipedia.org/wiki?curid=52621" title="Gower (electoral ward)">
Gower (electoral ward)

Gower (Welsh: "Gŵyr") electoral ward is an electoral ward in Britain. It is a ward of the City and County of Swansea, and comprises the western part of the Gower Peninsula. It lies within the UK Parliamentary constituency of Gower. 
The electoral ward consists of some or all of the following villages and areas: Cheriton, Horton, Ilston, Knelston, Landimore, Llandewi, Llangennith, Llanmadoc, Llanrhidian, Middleton, Nicholaston, Oldwalls, Overton, Oxwich Green, Oxwich, Parkmill, Penmaen, Penrice, Port Eynon, Reynoldston, Rhossili, Slade, Scurlage.
It also includes the communities of Ilston, "Llangennith, Llanmadoc and Cheriton", Llanrhidian Lower, Penrice, Swansea, Port Eynon, Reynoldston and Rhossili.
Neighbouring wards are Penclawdd to the north east, Fairwood to the east and Pennard to the south east.
2012 local council elections.
Local council elections for Gower were held on 3 May 2012, along with wards in 21/22 local authorities in Wales. The turn-out for Gower was 47.51%. The results were:
National Assembly for Wales.
Gower returns one constituency member to the National Assembly for Wales - currently Edwina Hart.
It votes in the South Wales West region, which elects four list members.
Swansea Airport.
Swansea Airport is based in the district of "Fairwood" in Gower, about 6.5 miles west of Swansea city centre.

</doc>
