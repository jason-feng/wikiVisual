<doc id="36791" url="http://en.wikipedia.org/wiki?curid=36791" title="Todd Rundgren">
Todd Rundgren

Todd Harry Rundgren (born June 22, 1948) is an American multi-instrumentalist, songwriter, and record producer. Hailed in the early stage of his career as a pop wunderkind for both his own material and for his production of other artists, supported by the certified gold solo double LP "Something/Anything?" in 1972, his career has produced a diverse and eclectic range of recordings often both as a solo artist and as a member of the band Utopia. Rundgren has often been at the forefront as a promoter of cutting edge recording technologies. 
During the 1970s and 1980s, Rundgren prolifically engineered and/or produced many notable albums for other acts, including "Straight Up" by Badfinger, "Stage Fright" by the Band, "We're an American Band" by Grand Funk Railroad, "Bat Out of Hell" by Meat Loaf, "New York Dolls" by the New York Dolls, "War Babies" by Hall & Oates, and "Skylarking" by XTC. In the 1980s and 1990s his interest in video and computers led to his "Time Heals" being the eighth video played on MTV, and "Change Myself" was animated by Rundgren on commercially available Amiga computers.
His best-known songs include "Hello It's Me" and "I Saw the Light", which have heavy rotation on classic rock radio stations, and "Bang the Drum All Day", which is featured in many sports arenas, commercials, and movie trailers. Although lesser known, "Couldn't I Just Tell You" has had a major influence on artists in the power pop musical genre.
Early career.
Rundgren was born in Upper Darby, at the western city limits of Philadelphia, Pennsylvania, the son of Ruth (née Fleck; b. 1922) and Harry W. Rundgren (1917–1996). His father was of half Swedish and half Austrian descent. Todd's grandfather Johan Sigfrid Rundgren (1882–1951) was born and raised in Norrtälje, Sweden, and his grandmother Sophie Brandweis Rundgren was born and raised in Austria. Both immigrated to America in the 1900s.
He began his career in Woody's Truck Stop, a Philadelphia-based group in the style of Paul Butterfield Blues Band. However, Rundgren and bassist Carson Van Osten left the band to form the garage rock group Nazz in 1967 with Thom Mooney (drums) and Robert "Stewkey" Antoni (vocals and keyboards). The group gained minor recognition with the Rundgren-penned songs "Open My Eyes" and "Hello It's Me". (He later recorded a solo, uptempo version of "Hello It's Me"; it became one of his signature songs.)
Nazz released three albums during this time – "Nazz" (1968), "Nazz Nazz" (1969), and "Nazz III" (1971). "Open My Eyes" gained belated recognition thanks to its inclusion in "" (1972), the genre-defining anthology of American 1960s garage punk and psychedelia compiled by musician Lenny Kaye. The group's second LP was originally intended as double album (titled "Fungo Bat"), but instead a truncated version was released as "Nazz Nazz" in April 1969. Rundgren and Van Osten left the band shortly after. Under Stewkey's leadership the band continued (with new members) until 1970, and their label released a third LP "Nazz III", on which most of Rundgren's vocals on the unreleased songs from the "Fungo Bat" sessions were replaced by Stewkey's.
Rundgren's distinctive style was inspired by a wide variety of musical influences—British pop-rock (notably Pink Floyd, the Beatles, the Who, The Yardbirds, Cream and the Move), the intricate vocal harmonies of the Beach Boys, classic American rock'n'roll, Broadway musicals, the operettas of Gilbert & Sullivan and American soul and R&B, but as his music evolved he demonstrated an increasing interest in other genres as well, such as hard rock and the guitar work of Robert Jay Bruner experimental music.
Particularly during the early years of his career, Rundgren's songwriting was heavily influenced by the music of singer-songwriter Laura Nyro:
Rundgren's debut solo album "Runt" (1970) includes the strongly Nyro-influenced "Baby Let's Swing", which was written about her and mentions her by name.
Nazz manager Michael Friedman, who had joined Albert Grossman management brought Rundgren to the firm where he became both a solo artist and producer for many artists in the Grossman stable.
Career.
Production work, 1970–75.
Rundgren's unhappiness with the production on the Nazz recordings prompted him to educate himself in audio engineering and production, and after leaving the Nazz in 1969, he relocated to New York, signed with Albert Grossman and began working as a producer for other groups, as well as recording his own material, which was initially released through the Ampex Records label (a short-lived joint venture between Grossman and the Ampex company). He also apparently considered working as a computer programmer. Subsequently, he became one of the first artists signed to Grossman's Bearsville Records label (distributed through Warner Bros. Records).
After signing with Bearsville, Rundgren worked almost constantly on production projects through the early 1970s and he rapidly became one of the most sought-after and acclaimed producer-engineers of the period. He quickly gained a high reputation for his creative approach, his no-nonsense, "can-do" approach, and for his ability to solve problems, work very rapidly and bring projects to completion on time and on budget – although he did occasionally come into conflict with some of the performers with whom he worked, due to his intense work ethic and his rather sarcastic, aloof manner in the studio. Rundgren's first project for Bearsville was a Philadelphia band called the American Dream, followed by a trip to Nashville to produce Ian and Sylvia Tyson's group Great Speckled Bird, with a backing band featuring guitarist Amos Garrett, pedal steel player Buddy Cage, pianist David Briggs and bassist Norbert Puttnam and drummer N.D. Smart, with whom Rundgren worked on several later projects. During this period Rundgren also made an abortive attempt to record with Janis Joplin and her band for Joplin's next studio album, but the sessions came to nothing and the project was eventually taken over by Paul A. Rothchild; the result was Joplin's swansong LP "Pearl", which Rothchild pieced together from the incomplete session tapes, following the singer's untimely death from a heroin overdose.
Albert Grossman recommended Rundgren to Robbie Robertson of the Band as the engineer for an album Robertson was producing, by singer-songwriter Jesse Winchester, who was at the time living in exile in Canada to avoid the draft. This was followed by a live album for the Paul Butterfield Blues Band. Having impressed Robertson with his work on the Winchester LP, Rundgren was then asked to engineer The Band's third album, "Stage Fright", which was recorded in an often fraught series of sessions at the Woodstock Playhouse. One of these was attended by a budding New York writer called Patti Smith, and their chance meeting led to an enduring friendship. Smith became an ardent champion of Rundgren's early solo work through her reviews in the rock press, and the friendship came full-circle in 1979 when Rundgren produced the final Patti Smith Group album, "Wave".
His work for The Band was followed by a second album for Winchester (which was then shelved for two years) and the album "Taking Care of Business" by the James Cotton Blues Band. This project resulted in another fortuitous meeting for Rundgren, introducing him to Cotton's keyboard player Mark "Moogy" Klingman, who in turn introduced Rundgren to keyboard player Ralph Schuckett, and both would work extensively with Todd over the next few years.
Runt and solo career, 1970-1972.
Although he had originally intended to concentrate on production rather than his own music, in 1970 Todd formed the 'band' Runt, consisting of himself, teenagers Hunt Sales on drums, and his brother Tony Sales on bass (the Sales brothers are the sons of US comedian Soupy Sales, were in a short lived band called Tony and the Tigers and went on to play with Iggy Pop, David Bowie, and Tin Machine). Rundgren himself wrote, produced, sang and played guitars, keyboards and other instruments. Whether Runt is best described as a band or simply as a pseudonym for Rundgren as a solo artist is unclear—for the album "Runt" (1970) the group appeared to be a "bona fide" trio, but on their second album "" (1971), Hunt Sales plays only on two tracks and is replaced by N.D. Smart on the rest of the album. Furthermore, only Rundgren is pictured on the covers of both albums, and both albums have been subsequently reissued with the same titles and cover art, but bearing the artist credit "Todd Rundgren". Whether a solo project or a band, Runt had a No. 20 hit in the U.S. with "We Gotta Get You a Woman" in 1970, and two other Runt songs placed in the lower reaches of the Hot 100.
By this time Rundgren had effectively moved his base to Los Angeles. As he prepared for his second solo album, he was introduced to aspiring L.A. band Halfnelson, led by brothers Ron Mael and Russell Mael and guitarist Earle Mankey. After attending an elaborate, self-staged 'showcase' performance by the group at their L.A. rehearsal space, Rundgren became intrigued by their music and agreed to produce their debut album, originally released as "Halfnelson" and later retitled "Sparks". The brothers later credited Rundgren as being instrumental in launching their career and in 2010 Russell Mael commented that when reviewing the album in 2008 they were still "... really happy with the way it sounded. There's nothing there that really sounds 'of an era' because it didn't exactly sound 'of an era' at the time."
By 1972, the Runt persona/band identity had been abandoned, and Rundgren's next project, the ambitious double LP "Something/Anything?" (1972) was credited simply to Rundgren, who wrote, played, sang, engineered, and produced everything on three of the four sides of the album. "Something/Anything?" featured the Top 20 U.S. hits "I Saw the Light" (#16; not to be confused with the Hank Williams song of the same name), and a remake of the Nazz near-hit "Hello It's Me", which reached No. 5 in the U.S. and is Rundgren's biggest hit. The former song featured Rundgren on all vocals and instruments. On his ensuing concert tour, his backing band was the Hello People, whose own album he later produced.
Changing style, 1973-1975.
The "Something/Anything?" period marked a significant change in Rundgren's lifestyle. Up until that time he neither drank nor took any drugs:
However, he began to change his views after a visit to Philadelphia to see Randy Reed, his closest friend from his school days. Reed introduced Todd to cannabis, and he credited this with having a big effect on his songwriting for his second solo album, "The Ballad of Todd Rundgren". In the lead-up to his third album, "Something/Anything?", he was experimenting with various mind-altering substances including cannabis, and a range of psychedelics including DMT, psilocybin mushrooms, and peyote – although he says he never (to his knowledge) took LSD. During the recording of "Something/Anything?", he began using the stimulant Ritalin and he later said that it had a marked effect both on the style of his music and on his productivity:
Speaking of the effect on "A Wizard, A True Star" (1973), Rundgren commented:
Though he often revisited the classic popular song format, during the early 1970s Rundgren's music began to incorporate elements of progressive rock. 1973's transitional "A Wizard, a True Star" marked the beginning of this trend, which came to fruition with his next two solo albums "Todd" (1974) and "Initiation" (1975) and the early recordings under the aegis of his new group project Utopia.
Shortly after he had completed work on "Something/Anything?", Los Angeles was struck by a strong earthquake, and Rundgren was sufficiently unnerved by this to move back to New York. His return east led to a long and fruitful working relationship with Moogy Klingman and the pair collaborated extensively over the next few years. They built a recording facility in Manhattan which they dubbed Secret Sound Studios, and a large proportion of Rundgren's solo and production work was done there, until his relocation to Woodstock in the mid-70s.
"A Wizard, A True Star" (1973), which was sequenced as a continuous medley, featured a wildly eclectic range of songs set in dazzling arrangements and production, with Rundgren experimenting with the synthesizer and exploiting virtually every studio effect and technique then available. Backing musicians included renowned horn players Michael Brecker and Randy Brecker, guitarist Rick Derringer and several other musicians, who subsequently joined the original incarnation of Utopia. Although it featured predominantly original material (including the anthemic "Just One Victory", which became a concert favorite), the album set a pattern followed on subsequent solo albums, with Rundgren recording cover versions of his favorite songs – in this case, "Never Never Land", from the Broadway musical version of "Peter Pan", and a medley of soul classics, including a unique version of the Capitols' "Cool Jerk" played in the 7/8 time signature. The album was also notable for its extended running time – over 55 minutes in length, compared to around 40–45 minutes for a typical pop-rock LP of the period. This reflected Rundgren's skills as a mastering engineer, since this extended running time took the album close to the practical maximum for an LP. Due to the inherent physical limitations of the vinyl LP medium, on records with running times over 45 minutes there is an unfavorable trade-off between duration and the audio quality and volume. On the album cover, packed with his handwritten notes, he advised listeners to crank up their Victrolas accordingly.
"Todd" (1974) continued in this vein and featured similarly diverse material. Alongside originals such as "A Dream Goes on Forever" and "Heavy Metal Kids", both of which became concert staples, Rundgren also satirized his chosen profession with the song "An Elpees' Worth of Tunes" and revisited his teenage obsession with the music of Gilbert & Sullivan in a rendition of "The Lord Chancellor's Nightmare Song" (from "Iolanthe"). "Izzat Love?" was sampled by Indie artist Neon Indian on their song, "Deadbeat Summer" in 2010.
By contrast, Rundgren's work with Utopia (see below) and his next solo album took him decisively into progressive rock. "Initiation" (1975) addressed cosmic themes, showed a strong interest in spirituality (particularly Far Eastern religion and philosophy), and displayed the musical influence of psychedelic rock, as well as the avant-garde jazz fusion of contemporary acts such as the Mahavishnu Orchestra and Frank Zappa. Once again the original LP issue saw Rundgren pushing the medium to its physical limits, with the side-long suite "A Treatise on Cosmic Fire" clocking in at over 35 minutes.
Touring and equipment.
When touring, Rundgren presented the music in a lavish stage setting that echoed the ambitious space-themed shows of acts like Parliament/Funkadelic and he adopted an outlandish space-rock image on stage, including multi-colored dyed hair.
During 1977 and 1978, Rundgren attempted to tour with a true quadraphonic sound system, however it proved ultimately unworkable – despite successfully delivering high-quality sound in a concert setting – due to the enormous technical requirements involved. Since most concert arenas of the day were ill-equipped to host large towers of sound equipment in the rear of the halls, the speakers often had to be hung from the ceiling rigging. This installation could take up to two days to complete, meaning that it was necessary to send two separate sound systems, each with its own, complete set-up crew, out on the road, so that they could "leapfrog" and allow Rundgren to play dates on consecutive days, which would have otherwise been impossible. The system featured a then-new technology called "signal analysis", which required white and pink noise to be pumped through the speakers, in order to set the active equalizers so as to minimize feedback and distortion. The pink and white noise analysis had to be performed twice: once with the hall empty, and then again with the audience present, which many concertgoers found annoying. Additionally, Rundgren's insistence on personally overseeing the acoustic set-up of the system left him exhausted and unable to continue, and he pulled the plug on the experiment.
During the mid-to-late 1970s, Rundgren regularly played the eye-catching psychedelic Gibson SG (known variously as "Sunny" or "The Fool"), which Eric Clapton had played in Cream. After he had stopped using it ca. 1968, Clapton gave the guitar to George Harrison, who subsequently 'loaned' it to British singer Jackie Lomax. In 1972, after meeting at a recording session, Lomax sold the guitar to Rundgren for $500 with an option to buy it back, which he never took up. Rundgren played it extensively during the early years of Utopia before retiring the instrument for a short time in the mid to late 70's, which in that time he had the guitar restored having a lacquer finish applied to protect the paint and replaced the talpiece and bridge to stabilize tuning, bringing the guitar back out on tour during the 1980 Deface the Music tour and using it on and off throughout the 80's until 1993 when he permanently retired the guitar, eventually auctioning it off in 1999; he now uses a reproduction given to him in 1988 by a Japanese fan.
"NME"—September 1974
"Faithful", "Hermit of Mink Hollow" and "Back to the Bars", 1976-1979.
The 1976 album "Faithful" saw Rundgren marking his tenth year as a professional musician by return to the pop/rock genre, featuring one side of original songs and one side of covers of significant songs from 1966, including the Yardbirds' "Happening Ten Years Time Ago" (the B-side of that Yardbirds single gave Nazz its name) and a nearly identical re-creation of the Beach Boys' "Good Vibrations".
In the latter half of the 1970s Rundgren moved to Woodstock, where Bearsville Records established a studio under Rundgren's direction. He bought a home nearby and a property adjoining the studio was taken over as accommodation for artists who used the studio. The Woodstock complex became Rundgren's base until his eventual relocation to the Hawaiian island of Kauai in the 1990s. That move was in part prompted by a violent home invasion at Woodstock in the late 1970s, in which Rundgren and girlfriend (who was pregnant at the time) were tied up while the house was ransacked by a group of armed men. According to Rundgren's account, the men appeared to believe that he possessed a large quantity of cocaine (which he never used); although the family was unharmed, the men stole some valuable items including a custom-made Alembic bass guitar. Todd recovered it years later after Alembic staff spotted it for sale on Ebay and it was returned to him, but was by then so badly damaged that it could not be restored.
"Faithful" was followed by "Hermit of Mink Hollow" (1978); this included the hit ballad "Can We Still Be Friends" (covered a year later by Robert Palmer), which reached No. 29 in the U.S. (Palmer's version reached No. 52) and was accompanied by an innovative self-produced music video, and the album became the second most successful of his career (after "Something/Anything?"), reaching No. 36 in the U.S. During 1978 Rundgren undertook an American tour playing at smaller venues including The Bottom Line in New York and the Roxy in Los Angeles; this resulted in the double live album "Back to the Bars", which featured a mixture of material from his solo work and Utopia, performed with backing musicians including Utopia, Edgar Winter, Spencer Davis, Daryl Hall and John Oates and Stevie Nicks.
1980-1991.
Subsequent solo releases included the album-long concept work "Healing" (1981) and the new wave-tinged "The Ever Popular Tortured Artist Effect" (1982), which included a cover of the Small Faces' hit "Tin Soldier". The latter album also marked the end of Rundgren's tenure with Bearsville Records. He then signed with Warner Bros. Records, who issued his next album, "A Cappella" (1985), which was recorded using Rundgren's multi-tracked voice, accompanied by arrangements constructed entirely from programmed vocal samples. "Bang the Drum All Day", from "The Ever Popular Tortured Artist Effect" was a minor chart hit, which has become more prominent in subsequent years, having been adopted as an unofficial theme by several professional sports franchises, notably the Green Bay Packers, and becoming popular on radio, where it was often featured on Friday afternoons. "Bang..." was also used prominently in a Carnival Cruises television advertising campaign. It is now considered one of Rundgren's most popular songs. In 1986, Rundgren scored four episodes of the popular children's television show Pee Wee's Playhouse.
"Nearly Human" (1989) and "2nd Wind" (1991) were both recorded live—the former in the studio, the latter in a theater before a live audience, whom were instructed to remain silent. Each song on these albums was recorded as a complete single take with no later overdubbing. Both albums marked, in part, a return to his Philly soul roots. "2nd Wind" also included several excerpts from Rundgren's musical "Up Against It", which was adapted from the screenplay (originally titled "Prick Up Your Ears"), that British playwright Joe Orton had originally offered to the Beatles for their never-made follow-up to "Help!". "2nd Wind" was Rundgren's last release through a major label and all his subsequent recordings have been self-released.
After a long absence from touring, Rundgren hit the road with "Nearly Human—2nd Wind" band, which included brass and a trio of slinky backup singers (one of whom, Michele Gray, Rundgren married). He also toured during this period with Ringo Starr's All-Starr band.
1993-present.
The next few years saw Rundgren recording under the pseudonym TR-i ("Todd Rundgren interactive") for two albums. The first of these, 1993's "No World Order", consisted of hundreds of seconds-long snippets of music, that could be combined in various ways to suit the listener. Initially targeted for the Philips CD-i platform, "No World Order" featured interactive controls for tempo, mood, and other parameters, along with pre-programmed mixes by Rundgren himself, Bob Clearmountain, Don Was, and Jerry Harrison. The disc was also released for PC and Macintosh and in two versions on standard audio CD, the continuous mix disc "No World Order" and, later, the more song-oriented "No World Order Lite". The music itself was quite a departure from Rundgren's previous work, with a dance/techno feel and much rapping by Rundgren. The follow-up, 1995's "The Individualist", featured interactive video content, that could be viewed or in one case, played; it was a simple video game along with the music, which was more rock-oriented than "No World Order".
Rundgren returned to recording under his own name for "With a Twist..." (1997), an album of bossa-nova covers of his older material. His Patronet work, which trickled out to subscribers over more than a year, was released in 2000 as "One Long Year". In 2004, Rundgren released "Liars", a concept album about "paucity of truth", that features a mixture of his older and newer sounds.
In early 2008, Rundgren launched his official MySpace page. Later that year, he released the rock album "Arena". In concert, he had been performing the album in full and in sequence before its release.
Rundgren released the live compilation album, "For Lack of Honest Work", in 2010. The album was advertised as a collection of bootleg recordings, that were approved by Rundgren himself.
April 2011 saw the release of "Todd Rundgren's Johnson", a collection of Robert Johnson covers, which had been recorded more than a year earlier. On another 2011 release, scheduled for September 13, a further album of covers entitled "" sees him performing tracks he had previously produced for other acts, including Grand Funk Railroad's "Walk Like a Man" and XTC's "Dear God."
In April 2013, Rundgren released his 24th solo album, "State".
On April 7, 2015, Todd released his 25th solo album, "Global" with a vinyl release of the album on April 27. He started a US tour to promote the album on April 10th and is planned to continue through June including an appearance on The Late Show with David Letterman on April 27. 
Utopia.
Rundgren's back-up band for "A Wizard, a True Star" (1973) evolved into the first version of Utopia, a larger prog-rock ensemble, which included multiple keyboards, synthesizers and brass and featured a character completely disguised in a silver suit, "M. Frog Labat" (Jean-Yves Labat de Rossi) on synthesizers, who also put out his own electronics/keyboards-based solo album. This incarnation premiered on 1974's "Todd Rundgren's Utopia", which was book-ended by the 14-minute "Utopia Theme" (recorded live in concert) and the 30-minute suite "The Ikon", which occupied the whole of Side 2 of the album. Like "Wizard", the album also showcased Rundgren's skills as a recording and mastering engineer, clocking in at over 30 minutes per side.
A slightly altered version of this group performed on the eclectic 1975 live album "Another Live". It featured three new extended progressive tracks (which appear only on this LP), a version of "Heavy Metal Kids" (from "Todd") and covers of "Something's Coming" (from "West Side Story") and "Do Ya" by the Move. By the time this album was recorded the Utopia lineup included keyboard player/trumpeter/vocalist Roger Powell and drummer John "Willie" Wilcox.
In 1976 Siegler left Utopia and was replaced by Kasim Sulton (bass, keyboards, vocals), who had previously played with New York singer-poetess Cherry Vanilla. This formidable ensemble was widely regarded as one of the best live acts of its day—all four members were highly accomplished on their main instrument as well as being able to play multiple other instruments, and all four could sing lead vocals.
After 1977's prog-rock fusion homage, "Ra", Utopia moved toward a more concise pop-oriented style with 1977's "Oops! Wrong Planet", which included "Love Is the Answer", later a hit for England Dan & John Ford Coley, followed by the more successful "Adventures in Utopia" in 1980, which spawned the hits "Road to Utopia", "Set Me Free" and "Caravan". During that year Utopia also acted as the backing band for the Rundgren-produced Shaun Cassidy solo album "Wasp".
Other releases include "Deface the Music" (also 1980), an uncanny Beatles homage, that borders on parody; the more politicised "Swing to the Right" (1982), incorporating more new wave elements; their pop-referenced, self-titled album "Utopia" (1982), as well as "Oblivion" (1984), which showed a cynical side of Utopia, sporting a black cover. 1985's "P.O.V." includes "Mated", later a staple of Rundgren solo tours. Rundgren eventually disbanded Utopia in the mid-1980s; they released "Trivia" (1986) as their "swan song" effort. However, in 1992 a brief tour of Japan reunited the Rundgren/Powell/Sulton/Wilcox lineup, and "" was released on Rhino Records.
Eventually, the compilation "Oblivion", "P.O.V." and "Some Trivia" was released in 1996, an effort by Rhino Records to re-release selections from the Todd/Utopia discography. In addition, many Utopia concerts from the mid-1970s onwards were taped (e.g. their 1975 London debut, recorded by BBC Radio) and these were widely bootlegged by fans, although some have since gained an official release and can now be obtained as commercial digital downloads from iTunes.
Production, video and other work.
In addition to his own recordings, Rundgren has engineered and/or produced albums for many notable acts. Sparked by his dissatisfaction with the sound quality of the Nazz albums, Rundgren learned how to engineer and master his own records and since 1970 he has overseen production of all his solo recordings and those by Utopia. His earliest outside credits were as producer on a long-unreleased Janis Joplin track (recorded with the Paul Butterfield Blues Band) and as recording engineer for the LP "Stage Fright" by the Band (1970). Other notable production credits include Halfnelson (first incarnation of Sparks), New York Dolls, Badfinger, Grand Funk Railroad, Hall & Oates, Ian and Sylvia (on their "Great Speckled Bird" album), Meat Loaf, Patti Smith, Shaun Cassidy, the Tubes, Tom Robinson Band, XTC, Bad Religion, John Sloman, Cheap Trick, Hello People, Hiroshi Takano, Bourgeois Tagg, Dragon (aka Hunter), 12 Rods, the Pursuit of Happiness, the Psychedelic Furs, Steve Hillage, the American Dream, and many others.
The difficult XTC sessions produced the album "Skylarking" (1986), now considered a high point for band and producer despite its acrimonious origin. Rundgren's production of Meat Loaf's "Bat out of Hell" (1977) (on which he also played lead guitar) helped that album become one of the top selling LPs released in the 1970s. The industry regard for Rundgren's production work has been a lofty one: Jim Steinman, with whom Rundgren worked on "Bat Out of Hell", has said in interviews, that "Todd Rundgren is a genius and I don't use that word a lot."
Rundgren has long been on the cutting edge of music and video technologies. His music video for the song "Time Heals" was among the first videos aired on MTV, and a video he produced for RCA, accompanied by Gustav Holst's "The Planets", was used as a demo for their videodisc players. His experience with computer graphics dates back to 1981, when he developed one of the first computer paint programs, dubbed the Utopia Graphics System; it ran on an Apple II with Apple's digitizer tablet. He is also the co-developer of the computer screensaver system Flowfazer.
In the 1990s, Rundgren was an early adopter of the NewTek Video Toaster and made several videos with it. The first, for "Change Myself" from "2nd Wind", was widely distributed as a demo reel for the Toaster; he also used the system for videos from "No World Order" (songs "Fascist Christ" and "Property"). Later, he set up a company to produce 3D animation using the Toaster; this company's first demo, "Theology" (a look at religious architecture through the ages featuring music by former Utopia bandmate Roger Powell) also became a widely circulated item among Toaster users. Most of Rundgren's Toaster work is available on the video compilation "The Desktop Collection."
Rundgren composed music for the 1986 TV series "Pee-wee's Playhouse" and "Crime Story" as well as the movies "Undercover" (a/k/a "Under Cover") (1987), and "Dumb and Dumber" (1994), plus background cues for several other TV shows. He hosted a syndicated radio show called "The Difference" in the early 1990s.
In 1986 he sang a duet with Bonnie Tyler: "Loving You's a Dirty Job but Somebody's Gotta Do It", released (also as a single) on Bonnie's album "Secret Dreams and Forbidden Fire".
As the Internet gained mass acceptance in the mid-1990s Rundgren, along with longtime manager Eric Gardner and Apple digital music exec Kelli Richards, started Patronet, which offered fans (patrons) access to his works-in-progress and new unreleased tracks in exchange for a subscription fee, cutting out record labels. The songs from Rundgren's first Patronet run were later released as the album "One Long Year". Since then, Rundgren has severed his connections with major record labels and continues to offer new music direct to subscribers via his website, although he also continues to record and release CDs through independent labels. (However, as of November 2007, the PatroNet.com website offers the following message: "PatroNet is undergoing a major software revision and is not accepting memberships at this time.")
Rundgren produced the 1999 debut album for the band Splender, entitled "Halfway to the Sky".
In the summer of 2001, Rundgren joined artists such as Alan Parsons, the Who's John Entwistle, Heart's Ann Wilson and Ambrosia's David Pack for the tour "A Walk Down Abbey Road", in which the musicians played their own hits alongside Beatles favorites. They also did a short tour of Japan in the winter of 2001, and another the following year, which included Jack Bruce of Cream, Mark Farner of Grand Funk Railroad, Christopher Cross and Eric Carmen.
In the aftermath of the September 11 attacks Rundgren created the score for the film 'A Face to a Name', directed by Douglas Sloan. The film depicted the many photographs of NY's missing, that were displayed on Bellevue Hospital's 'wall of prayers' following the attacks. The film was part of a special screening at the Woodstock Film Festival in 2002.
Rundgren toured the US and Europe in 2004 with Joe Jackson and the string quartet Ethel, appearing on "Late Night with Conan O'Brien" performing their collaborative cover of the Beatles song "While My Guitar Gently Weeps".
In 2009, Rundgren produced "Cause I Sez So" by the New York Dolls. In October, in one of the last concerts at the famed Wachovia Spectrum, Rundgren and Philadelphia area musicians the Hooters and Hall & Oates headlined a concert titled "Last Call". Tickets were as low as $6.00, the deep discount reflected ticket prices in 1967, when the Spectrum first staged concerts.
The year also included a lecture at DePauw University in Indiana, in which he discussed "Music, Technology and Risk-Taking".
In late-October to early-November 2010, Rundgren was the IU Class of 1963 Wells Scholars Professor at Indiana University. He taught a course with IU Professor Glenn Gass entitled 'The Ballad of Todd Rundgren'.
The New Cars.
In late 2005, the Boston-based band the Cars were planning to re-form despite bassist Benjamin Orr's death and lack of interest on the part of former lead singer Ric Ocasek. Rumors followed that Rundgren had joined Elliot Easton and Greg Hawkes in rehearsals for a possible new Cars lineup. Initial speculation pointed to the New Cars being fleshed out with Clem Burke of Blondie and Art Alexakis of Everclear. Eventually it was revealed that The New Cars were to complete their lineup with veteran bass player and former Rundgren bandmate Kasim Sulton and studio drummer Prairie Prince of the Tubes, who had played on XTC's Rundgren-produced "Skylarking" and who has recorded and toured with Rundgren.
In early 2006, the new lineup played a few private shows for industry professionals, played live on "The Tonight Show with Jay Leno" and made other media appearances before commencing a 2006 summer tour with the re-formed Blondie.
Rundgren has referred to the project as "an opportunity ... for me to pay my bills, play to a larger audience, work with musicians I know and like, and ideally have some fun for a year."
The New Cars' first single, "Not Tonight", was released on March 20, 2006. A live album/greatest hits collection, "The New Cars: It's Alive", was released in June 2006. The album includes classic Cars songs (and two Rundgren hits) recorded live plus three new studio tracks ("Not Tonight", "Warm", and "More").
Tours from 2009–13.
In April 2009, Rundgren discussed his career during an Ubben Lecture at Indiana's DePauw University.
In September 2009, Rundgren assembled a very limited-engagement tour with Jesse Gress, Kasim Sulton, Prairie Prince, Greg Hawkes, Bobby Strickland, and Roger Powell (and his wife Michele as costume designer and back-up singer for the concerts finale'), covering his 1973 album, "A Wizard, A True Star". The shows included a complete, start-to-finish rendition of the album, with multiple costume changes and theatrical props to accent the songs. The opening band for the shows was Utopia, with Roger Powell, Kasim Sulton, and Prairie Prince.
In December 2009, Rundgren once again took the AWATS Live show on the road with four shows in California. Roger Powell returned to his real job in the computer/software industry and was replaced by Ralph Schuckett, who played keyboards on the studio recording of the original album.
The A Wizard a True Star show has had two European dates as well; playing in London, England at the Hammersmith Apollo on February 6, 2010, and the Paradiso in Amsterdam, Holland on February 8, 2010. Rundgren opened the London and Amsterdam shows by showcasing his new project, entitled 'Todd Rundgren's Johnson'; consisting of Rundgren, Jesse Gress (guitar), Prairie Prince (drums) and Kasim Sulton (bass) reworking Robert Johnson songs.
In January 2010 Rundgren gave his first ever concert performance in Australia as a participant in the "Rogue's Gallery" show, produced by Hal Willner for the 2010 Sydney Festival. In October 2010 Rundgren returned for a three-date tour of Australia performing his 'Johnson' project, with concerts at The Basement, Sydney, the Great Southern Blues Festival at Bateman's Bay and the Corner Hotel in Melbourne. The band consisted of Todd, guitarist Jesse Gress, Australian bassplayer Damien Steele Scott and Australian drummer Mick Skelton of Baby Animals.
A Photographic Journal of each American show was created by rock photographer J Bloomrosen.
Rundgren participated in the Hollywood Bowl's "Beatles Celebration" concert held July 9–11, 2010 along with the Hollywood Bowl Orchestra conducted by Thomas Wilkins. Featured guests over the three nights also included Patti Austin, Bettye LaVette, Rob Laufer and Brian Stokes Mitchell. He performed "Being for the Benefit of Mr. Kite," outfitted in an outsized top hat, fake walrus mustache, black waistcoat, white gloves and white spats. He amped up the show's rock quotient with "Everybody's Got Something to Hide Except for Me and My Monkey," and took over the guitar solo in "While My Guitar Gently Weeps," which he preceded with a nod to Ringo Starr's 70th birthday (which had been just two nights earlier). Finally, his performance of "A Day in the Life" concluded his set.
In October 2010, Rundgren was selected as the Class of 1963 Wells Scholars Professor at Indiana University. In that capacity, he taught two weeks of a four-week, one-credit hour honors seminar designed for 22 Wells Scholars (HON-H300: The Ballad of Todd Rundgren). Co-teaching the class was IU Professor of Music Glenn Gass—whose relationship with Rundgren helped make the professorship possible—and IU Distinguished Professor of Sociology Bernice Pescosolido, who was instrumental in helping to plan the course.
In September 2010, Rundgren performed his "Todd" and "Healing" albums live for the first time ever in Akron, OH and followed that up with five more of the album concerts in Muskegon MI, Indianapolis IN, St. Louis MO, Glenside PA, and Morristown NJ. A large LED display and lasers were on display throughout the shows with Rundgren and the band dressed in extravagant costumes. Rundgren brought out his SG Gibson "The Fool" replica guitar and also performed a few songs on the piano. The band consisted of Jesse Gress, Greg Hawkes, Prairie Prince, Bobby Strickland, and Kasim Sulton. Led by Choir Master Dirk Hillyer, local choirs from near each venue joined the band during parts of the "Healing" album set, which added a brand new element to the music for fans, that had only heard it by listening to the album. The shows closed with the song, "Sons of 1984", which included fan participation even after the band left the stage. In March 2011, Rundgren took the "Todd" and "Healing" albums live concerts back on the road for a mini-tour and included stops in Hartford CT, Boston MA, Red Bank NJ, Toledo OH, and Columbus OH.
In January 2011, a reunion of the most of the members of the 1974 Utopia personnel (Rundgren, Klingman, Schuckett, Siegler, and Ellman) was held for two nights in New York City, with proceeds to defray medical treatment for Klingman, who was battling with cancer. Material was drawn from the 1972–1975 catalogs of Rundgren and Todd Rundgren's Utopia. Both shows sold out in just three days, which may have influenced the idea for a full tour, that took place in November 2011 as "Todd Rundgren's Utopia". The original plan for the tour included Moogy Klingman but his health condition worsened during rehearsals and he died before the 12 concert tour was finished.
In September 2011, for the first time ever with a symphony orchestra, Rundgren performed two concerts in the Netherlands (Amsterdam and Groningen) backed by the Dutch Metropole Orchestra. On June 1–2, 2012, he performed in two concerts accompanied by the Rockford Symphony Orchestra at the historic Coronado Performing Arts Center in Rockford, IL. The concerts were Rundgren's first ever symphonic shows in North America.
Rundgren toured with Ringo Starr & His All-Starr Band for the third time and for the first time in 13 years, starting in the summer of 2012, and continuing into 2013 and 2014.
In November 2012 Rundgren again collaborated with the Dutch Metropole Orchestra. At the Paradiso venue in Amsterdam he was also backed by three backing vocalist, including Dutch singer Mathilde Santing with whom he sang a duet that night. This concert was released as a bonus cd with his cd State.
In August 2013 Rundgren performed with the Akron Symphony Orchestra and Akron Youth Symphony at the Akron Civic Theatre under the baton of conductor Levi Hammer. This was his first concert with a youth symphony orchestra.
Personal life.
Rundgren has three sons; Rex (born 1980) and Randy (born 1985) with his long-term girlfriend Karen Darvin, and Rebop with current wife Michele. Rex is a minor league baseball player (Infield position), who, as of 2012, plays for the Tulsa (Oklahoma) Drillers.
From 1972 to 1979, Rundgren had a longtime relationship with model Bebe Buell. During their cohabitation, sometimes they were on-and-off. In 1976, Buell became unexpectedly pregnant from her brief relationship with Steven Tyler. On July 1, 1977, Buell gave birth to future actress/model Liv Tyler. But Buell initially named the daughter "Liv Rundgren" and claimed that Todd Rundgren was the biological father to protect the child from Tyler's drug addiction. Rundgren and Buell ended their romantic relationship shortly after Liv's birth, but Rundgren put his heart and soul into the "white lie". At age nine, Liv was made aware of her real parentage, that she is in fact Steven Tyler's biological daughter.
According to Tyler "...Todd basically decided when I was born that I needed a father so he signed my birth certificate. He knew that there was a chance that I might not be his but…" He paid to put her through private school, and she visited him several times a year.
Tyler maintains a close relationship with Rundgren. "I'm so grateful to him, I have so much love for him. You know, when he holds me it feels like Daddy. And he's very protective and strong."
In 1998 Rundgren married Michele Gray (Michele Rundgren), who had been a dancer with the Tubes, performed with Rundgren as a backup singer on the tour for his "Nearly Human" album which led to a number of appearances on the David Letterman Show as one of "The World's Most Dangerous Backup Singers".
In October 2013, along with his fans, Rundgren founded the Spirit of Harmony Foundation, to provide opportunities for personal development and self-expression through the support of music and music education.

</doc>
<doc id="36795" url="http://en.wikipedia.org/wiki?curid=36795" title="Medieval Warm Period">
Medieval Warm Period

The Medieval Warm Period (MWP), Medieval Climate Optimum, or Medieval Climatic Anomaly was a time of warm climate in the North Atlantic region that may also have been related to other climate events around the world during that time, including China and other areas, lasting from about AD 950 to 1250. It was followed by a cooler period in the North Atlantic termed the Little Ice Age. Some refer to the event as the Medieval Climatic Anomaly as this term emphasizes that effects other than temperature were important.
Despite substantial uncertainties, especially for the period prior to 1600 for which data are scarce, the warmest period of the last 2,000 years prior to the 20th century very likely occurred between 950 and 1100, but temperatures were probably between 0.1 °C and 0.2 °C below the 1961 to 1990 mean and significantly below the level shown by instrumental data after 1980. Proxy records from different regions show peak warmth at different times during the Medieval Warm Period, indicating the heterogeneous nature of climate at the time. Temperatures in some regions matched or exceeded recent temperatures in these regions, but globally the Medieval Warm Period was cooler than recent global temperatures.
Causes of MWP include increased solar acitivity, decreased volcanic acitivity and ocean circulation.
Initial research.
The Medieval Warm Period (MWP) is generally thought to have occurred from about AD 950–1250, during the European Middle Ages. In 1965 Hubert Lamb, one of the first paleoclimatologists, published research based on data from botany, historical document research and meteorology combined with records indicating prevailing temperature and rainfall in England around 1200 and around 1600. He proposed that "Evidence has been accumulating in many fields of investigation pointing to a notably warm climate in many parts of the world, that lasted a few centuries around A.D. 1000–1200, and was followed by a decline of temperature levels till between 1500 and 1700 the coldest phase since the last ice age occurred."
The warm period became known as the MWP, and the cold period was called the Little Ice Age (LIA). However, this view was questioned by other researchers; the IPCC First Assessment Report of 1990 discussed the "Medieval Warm Period around 1000 AD (which may not have been global) and the Little Ice Age which ended only in the middle to late nineteenth century." The IPCC Third Assessment Report from 2001 summarised research at that time, saying "…current evidence does not support globally synchronous periods of anomalous cold or warmth over this time frame, and the conventional terms of 'Little Ice Age' and 'Medieval Warm Period' appear to have limited utility in describing trends in hemispheric or global mean temperature changes in past centuries". Global temperature records taken from ice cores, tree rings, and lake deposits, have shown that, taken globally, the Earth may have been slightly cooler (by 0.03 degrees Celsius) during the 'Medieval Warm Period' than in the early and mid-20th century.
Palaeoclimatologists developing region-specific climate reconstructions of past centuries conventionally label their coldest interval as "LIA" and their warmest interval as the "MWP". Others follow the convention and when a significant climate event is found in the "LIA" or "MWP" time frames, associate their events to the period. Some "MWP" events are thus wet events or cold events rather than strictly warm events, particularly in central Antarctica where climate patterns opposite to the North Atlantic area have been noticed.
By world region.
Evidence exists across the world, often very sparsely, for changes in climatic conditions over time. Some of the "warm period" events documented below are actually "dry periods" or "wet periods."
Globally.
A 2009 study by Michael Mann "et al." examining spatial patterns of surface temperatures shown in multi-proxy reconstructions finds that the MWP shows "warmth that matches or exceeds that of the past decade in some regions, but which falls well below recent levels globally." Their reconstruction of MWP pattern is characterised by warmth over large part of North Atlantic, Southern Greenland, the Eurasian Arctic, and parts of North America which appears to substantially exceed that of the late 20th century (1961–1990) baseline and is comparable or exceeds that of the past one-to-two decades in some regions. Certain regions such as central Eurasia, northwestern North America, and (with less confidence) parts of the South Atlantic, exhibit anomalous coolness.
North Atlantic.
A radiocarbon-dated box core in the Sargasso Sea shows that the sea surface temperature was approximately 1 C-change cooler than today approximately 400 years ago (the Little Ice Age) and 1700 years ago, and approximately 1 °C warmer than today 1000 years ago (the Medieval Warm Period).
Using sediment samples from Puerto Rico, the Gulf Coast and the Atlantic Coast from Florida to New England, Mann "et al." (2009) found consistent evidence of a peak in North Atlantic tropical cyclone activity during the Medieval Warm Period followed by a subsequent lull in activity.
Through retrieval and isotope analysis of marine cores and examination of mollusc growth patterns from Iceland, Patterson "et al" were able to reconstruct a mollusc growth record at a decadal resolution from the Roman Warm Period through the Medieval Warm Period and into the Little Ice Age.
North America.
The 2009 Mann et al. study found warmth exceeding 1961–1990 levels in Southern Greenland and parts of North America during the Medieval climate anomaly (defined for this purpose as 950 to 1250) with warmth in some regions exceeding temperatures of the 1990–2010 period. Much of the Northern hemisphere showed significant cooling during the Little Ice Age (defined for the purpose as 1400 to 1700) but Labrador and isolated parts of the United States appeared to be approximately as warm as during the 1961–1990 period.
Norse colonization of the Americas has been associated with warmer periods. The Vikings took advantage of ice-free seas to colonize areas in Greenland and other outlying lands of the far north.
From around 1000 AD Vikings formed settlements in two areas located near the southern tip of Greenland at a similar latitude to Iceland, the Eastern Settlement at the southern tip, and the Western Settlement to its north. A smaller group of stations between them has been identified by archaeologists as the "Middle Settlement". At that time they kept a few cattle and sheep, with around a quarter of their diet from seafood, but after the climate became colder and stormier around 1250 smaller homesteads gradually dropped cows. Around 1300 seal hunting provided over three quarters of their food. While there are no signs that this adversely affected their health, by mid century trade with Europe fell away and there was little demand for their exports of hunted produce. One of the last documents of their occupation dates from 1412, and over the remainder of that century the remaining Europeans left in what seems to have been a withdrawal, largely due to social factors such as increased availability of farms in Scandinavian countries.
Around 1000 AD the climate was sufficiently warm for the north of Newfoundland to support a European outpost and led to the descriptor "Vinland." An extensive settlement at L'Anse aux Meadows was found and originally excavated by Helge Ingstad.
In Chesapeake Bay (modern day Maryland and Virginia in the United States), researchers found large temperature excursions (changes from the mean temperature of that time) during the Medieval Warm Period (about 950–1250) and the Little Ice Age (about 1400–1700, with cold periods persisting into the early 20th century), possibly related to changes in the strength of North Atlantic thermohaline circulation. Sediments in Piermont Marsh of the lower Hudson Valley show a dry Medieval Warm period from AD 800–1300.
Prolonged droughts affected many parts of the western United States and especially eastern California and the west of Great Basin. Alaska experienced three time intervals of comparable warmth: AD 1–300, 850–1200, and post-1800. Knowledge of the North American Medieval Warm Period has been useful in dating occupancy periods of certain Native American habitation sites, especially in arid parts of the western U.S. Review of more recent archaeological research shows that as the search for signs of unusual cultural changes during the MWP has broadened, some of these early patterns (for example, violence and health problems) have been found to be more complicated and regionally varied than previously thought while others (for example, settlement disruption, deterioration of long distance trade, and population movements) have been further corroborated.
Other regions.
The climate in equatorial east Africa has alternated between drier than today, and relatively wet. The drier climate took place during the Medieval Warm Period (~AD 1000–1270).
A sediment core from the eastern Bransfield Basin, Antarctic Peninsula, preserves climatic events in the Little Ice Age and Medieval Warm Period. The core shows a distinctly cold period about AD 1000–1100, illustrating that during the "warm" period there were, regionally, periods of both warmth and cold.
Corals in the tropical Pacific Ocean suggest that relatively cool, dry conditions may have persisted early in the millennium, consistent with a La Niña-like configuration of the El Niño-Southern Oscillation patterns. Although there is an extreme scarcity of data from Australia (for both the Medieval Warm Period and Little Ice Age) evidence from wave-built shingle terraces for a permanently full Lake Eyre during the 9th and 10th centuries is consistent with this La Niña-like configuration, though of itself inadequate to show how lake levels varied from year to year or what climatic conditions elsewhere in Australia were like.
The MWP has been noted in Chile in a 1500-year lake bed sediment core, as well as in the Eastern Cordillera of Ecuador.
Adhikari and Kumon (2001), whilst investigating sediments in Lake Nakatsuna in central Japan, finding a warm period from AD 900 to 1200 that corresponded to the Medieval Warm Period and three cool phases, of which two could be related to the Little Ice Age. Another research in northeastern Japan shows that there is one warm/humid interval from AD 750 to 1200, and two cold/dry intervals from AD 1 to 750 and 1200 to present. Ge "et al." studied temperatures in China during the past 2000 years; they found high uncertainty prior to the 16th century but good consistency over the last 500 years, "highlighted by the two cold periods 1620s–1710s and 1800s–1860s, and the warming during the 20th century". They also found that the warming during the 10–14th centuries in some regions might be comparable in magnitude to the warming of the last few decades of the 20th century which was unprecedented within the past 500 years.
A 1979 study from the University of Waikato found that "Temperatures derived from an 18O/16O profile through a stalagmite found in a New Zealand cave (40.67°S, 172.43°E) suggested the Medieval Warm Period to have occurred between AD 1050 and 1400 and to have been 0.75 °C warmer than the Current Warm Period." The MWP has also been evidenced in New Zealand by an 1100-year tree-ring record.
A reconstruction based on ice cores found the Medieval Warm Period could be distinguished in tropical South America from about 1050 to 1300, followed in the 15th century by the Little Ice Age. Peak temperatures did not rise as high as those from the late 20th century, which were unprecedented in the area during the study period going back around 1600 years.

</doc>
<doc id="36796" url="http://en.wikipedia.org/wiki?curid=36796" title="Paclitaxel">
Paclitaxel

Paclitaxel is a medication used to treat a number of types of cancer including: ovarian cancer, breast cancer, lung cancer and pancreatic cancer among others. It and docetaxel represent the taxane family of drugs. Paclitaxel's mechanism of action involves interference with the normal breakdown of microtubules during cell division.
Common side effects include: hair loss, muscle and joint pains, and diarrhea, among others. It results in a greater risk of infections which can be potentially serious. Use during pregnancy often results in problems in the infant.
Paclitaxel was discovered in 1962 as a result of a U.S. National Cancer Institute-funded screening program; being isolated from the bark of the Pacific yew, "Taxus brevifolia", thus its name "taxol". Developed commercially by Bristol-Myers Squibb, the generic name has changed to "paclitaxel" with a trademark becoming "Taxol". Other trademarks include Abraxane. Clinicians sometimes use the abbreviation "PTX" for paclitaxel, which is discouraged, because it is not a unique identifier.
Paclitaxel is on the World Health Organization's List of Essential Medicines, a list of the most important medication needed in a basic health system. There was initially concern over the environmental impact of its initial sourcing from the slow growing Pacific yew. In addition, both the assignment of rights to Bristol-Myers Squibb and the product name were subject to public debate and Congressional hearings.
Medical use.
Paclitaxel is approved in the UK for ovarian, breast and lung, bladder, prostate, melanoma, esophageal, and other types of solid tumor cancers as well as Kaposi's sarcoma.
It is recommended in NICE guidance of June 2001 that it should be used for nonsmall cell lung cancer in patients unsuitable for curative treatment, and in first-line and second-line treatment of ovarian cancer. In September 2001, NICE recommended paclitaxel should be available for the treatment of advanced breast cancer after the failure of anthracyclic chemotherapy, but that its first-line use should be limited to clinical trials. In September 2006, NICE recommended paclitaxel should "not" be used in the adjuvant treatment of early node-positive breast cancer. In 2005, its use in the United States for the treatment of breast, pancreatic, and non-small cell lung cancers was approved by the FDA.
Similar compounds.
Albumin-bound paclitaxel (trade name Abraxane, also called nab-paclitaxel) is an alternative formulation where paclitaxel is bound to albumin nano-particles. Much of the clinical toxicity of paclitaxel is associated with the solvent Cremophor EL in which it is dissolved for delivery.
Abraxis BioScience developed Abraxane, in which paclitaxel is bonded to albumin as an alternative delivery agent to the often toxic solvent delivery method. This was approved by the U.S. Food and Drug Administration in January 2005 for the treatment of breast cancer after failure of combination chemotherapy for metastatic disease or relapse within six months of adjuvant chemotherapy.
Synthetic approaches to paclitaxel production led to the development of docetaxel. Docetaxel has a similar set of clinical uses to paclitaxel and is marketed under the name of Taxotere.
Recently the presence of taxanes including paclitaxel, 10-deacetylbaccatin III, baccatin III, paclitaxel C, and 7-epipaclitaxel in the shells and leaves of hazel plants has been reported. The finding of these compounds in shells, which are considered discarded material and are mass-produced by many food industries, is of interest for the future availability of paclitaxel.
Restenosis.
Paclitaxel is used as an antiproliferative agent for the prevention of restenosis (recurrent narrowing) of coronary and peripheral stents; locally delivered to the wall of the artery, a paclitaxel coating limits the growth of neointima (scar tissue) within stents. Paclitaxel drug eluting coated stents for coronary artery placement are sold under the trade name Taxus by Boston Scientific in the United States. Paclitaxel drug eluting coated stents for femoropopliteal artery placement are sold under the trade name Zilver PTX by Cook Medical, Inc.
Side effects.
Common side effects include nausea and vomiting, loss of appetite, change in taste, thinned or brittle hair, pain in the joints of the arms or legs lasting two to three days, changes in the color of the nails, and tingling in the hands or toes. More serious side effects such as unusual bruising or bleeding, pain/redness/swelling at the injection site, Hand-foot syndrome, change in normal bowel habits for more than two days, fever, chills, cough, sore throat, difficulty swallowing, dizziness, shortness of breath, severe exhaustion, skin rash, facial flushing, female infertility by ovarian damage and chest pain can also occur. A number of these side effects are associated with the excipient used, Cremophor EL, a polyoxyethylated castor oil. Allergies to drugs such as cyclosporine, teniposide and drugs containing polyoxyethylated castor oil may indicate increased risk of adverse reactions to paclitaxel. Dexamethasone is given prior to beginning paclitaxel treatment to mitigate some of the side effects. Leuprolide, a GnRH analog may prevent ovarian damage, according to mice studies.
Mechanism of action.
Paclitaxel is one of several cytoskeletal drugs that target tubulin. Paclitaxel-treated cells have defects in mitotic spindle assembly, chromosome segregation, and cell division. Unlike other tubulin-targeting drugs such as colchicine that inhibit microtubule assembly, paclitaxel stabilizes the microtubule polymer and protects it from disassembly. Chromosomes are thus unable to achieve a metaphase spindle configuration. This blocks progression of mitosis, and prolonged activation of the mitotic checkpoint triggers apoptosis or reversion to the G-phase of the cell cycle without cell division.
The ability of paclitaxel to inhibit spindle function is generally attributed to its suppression of microtubule dynamics, but recent studies have demonstrated that suppression of dynamics occurs at concentrations lower than those needed to block mitosis. At the higher therapeutic concentrations, paclitaxel appears to suppress microtubule detachment from centrosomes, a process normally activated during mitosis. Paclitaxel binds to beta-tubulin subunits of microtubules.
Research use.
Aside from its direct clinical use, paclitaxel is used extensively in biological and biomedical research as a microtubule stabilizer. In general, in vitro assays involving microtubules, such as motility assays, rely on paclitaxel to maintain microtubule integrity in the absence of the various nucleating factors and other stabilizing elements found in the cell. For example, it is used for in vitro tests of drugs that aim to alter the behavior of microtubule motor proteins, or for studies of mutant motor proteins. Paclitaxel is sometimes used for in vivo studies as well; it can be fed to test organisms, such as fruit flies, or injected into individual cells, to inhibit microtubule disassembly or to increase the number of microtubules in the cell. Paclitaxel induces remyelination in a demyelinating mouse in vivo and inhibits hPAD2 in vitro though its methyl ester side chain did not. Angiotech Pharmaceuticals Inc. began phase II clinical trials in 1999 as a multiple sclerosis treatment but in 2002, reported that the results showed no statistical significance.
Delivery-related paclitaxel derivatives.
In recent years, extensive research has been done to find a way to mitigate the side effects of paclitaxel, by altering its administration. DHA-paclitaxel, PG-paclitaxel, and tumor-activated taxol prodrugs are undergoing continued testing, and are actually on the way to being introduced into widespread clinical use.
Protarga has linked paclitaxel to docosahexaenoic acid (DHA), a fatty acid easily taken up by tumor cells; the DHA-paclitaxel “appears not to be cytotoxic until the bond with DHA is cleaved within the cell.” The advantage of DHA-paclitaxel over paclitaxel is DHA-paclitaxel’s ability to carry much higher concentrations of paclitaxel to the cells, which are maintained for longer periods in the tumor cells, thus increasing their action. With increased activity, DHA-paclitaxel, also known as Taxoprexin, may have a more successful response in cancer patients than paclitaxel, and it may be able to treat more types of cancer than paclitaxel has been able to treat.
Cell Therapeutics has formulated PG-paclitaxel, which is paclitaxel bonded to a polyglutamate polymer; tumor cells are significantly more porous to polyglutamate polymers than normal cells, due to the leaky endothelial membranes of tumor cells. PG-paclitaxel has been introduced into clinical use, and has proven to initiate very mild side effects and to effectively treat many patients who were not responsive to the action of Taxol. The PG-paclitaxel may be a very promising anticancer drug, as it is much more selective than paclitaxel for which cells it targets.
ImmunoGen has been introducing tumor-activated prodrug (TAP) technology in recent years, and is now working to apply this technology to paclitaxel. Tumor-activated paclitaxel prodrugs are designed for accurate targeting, by the action of a monoclonal antibody that is very specific to certain cells. Tumor-activated Taxol prodrugs research is progressing, and, in mice, the “taxane-based TAP completely eradicated human tumour xenografts at non-toxic doses.”
ANG1005 is made up of one molecule of a peptide called angiopep-2 joined with three molecules of paclitaxel. It is in phase I clinical trials for some types of cancer.
Production.
From 1967 to 1993, almost all paclitaxel produced was derived from bark from the Pacific yew, the harvesting of which kills the tree in the process. The processes used were descendants of the original isolation method of Wall and Wani; by 1987, the NCI had contracted Hauser Chemical Research of Boulder, Colorado, to handle bark on the scale needed for Phase II and III trials. While both the size of the wild population of "Taxus brevifola" and the magnitude of the eventual demand for taxol were uncertain, it was clear for many years that an alternative, sustainable source of supply of the natural product would be needed. Initial attempts to broaden its sourcing used needles from the tree, or material from other related "Taxus" species, including cultivated ones, but these attempts were challenged by the relatively low and often highly variable yields obtained. Early in the 1990s, coincident with increased sensitivity to the ecology of the forests of the Pacific Northwest, taxol was successfully extracted on a clinically useful scale from these sources.
Concurrently, synthetic chemists in the US and France had been interested in taxol, beginning in the late 1970s. As noted, by 1992 extensive efforts were underway to accomplish the total synthesis of paclitaxel, efforts motivated by the desire to generate new chemical understanding rather than to achieve practical commercial production. In contrast, the French group of Pierre Potier at the Centre national de la recherche scientifique (CNRS) addressed the matter of overall process yield, showing that it was feasible to isolate relatively large quantities of the compound 10-deacetylbaccatin from yew, "Taxus baccata", which grew on the CNRS campus and whose needles were available in large quantity. By virtue of its structure, 10-deacetylbaccatin was seen as a viable starting material for a short semisynthesis to produce taxol. By 1988 Poitier and collaborators had published a semisynthetic route from needles of "T. baccata" to taxol.
The view of the NCI, however, was even this route was not practical. The group of Robert A. Holton had also pursued a practical semisynthetic production route; by late 1989, Holton's group had developed a semisynthetic route to paclitaxel with twice the yield of the Potier process. Florida State University, where Holton worked, signed a deal with Bristol-Myers Squibb to license their semisynthesis and future patents. In 1992, Holton patented an improved process with an 80% yield, and BMS took the process in-house and started to manufacture paclitaxel in Ireland from 10-deacetylbaccatin isolated from the needles of the European yew. In early 1993, BMS was able to announce that it would cease reliance on Pacific yew bark by the end of 1995, effectively terminating ecological controversy over its use. This announcement also made good their commitment to develop an alternative supply route, made to the NCI in their CRADA application of 1989.
Currently, all paclitaxel production for BMS uses plant cell fermentation (PCF) technology developed by the Ithaca, New York biotechnology company Phyton Biotech, Inc. and carried out at their plant in Germany. PCF uses a specific "Taxus" cell line propagated in aqueous medium in large fermentation tanks with the endophytic fungus "Penicillium raistrickii". Paclitaxel is then extracted directly, purified by chromatography and isolated by crystallization. Compared to the semisynthesis, PCF eliminates the need for many hazardous chemicals and saves a considerable amount of energy.
In 1993, taxol was discovered as a natural product in a newly described endophytic fungus living in the yew tree. It has since been reported in a number of other endophytic fungi, including "Nodulisporium sylviforme", "Alternaria taxi", "Cladosporium cladosporioides MD2", "Metarhizium anisopliae", "Aspergillus candidus MD3", "Mucor rouxianus sp.", "Chaetomella raphigera", "Phyllosticta tabernaemontanae", "Phomopsis", "Pestalotiopsis pauciseta", "Phyllosticta citricarpa", "Podocarpus","Fusarium solani", "Pestalotiopsis terminaliae", "Pestalotiopsis breviseta", "Botryodiplodia theobromae Pat.", "Gliocladium sp.", "Alternaria alternata var. monosporus", "Cladosporium cladosporioides", "Nigrospora sp.", "Pestalotiopsis versicolor", and "Taxomyces andreanae". However, there has been contradictory evidence for its production by endophytes, with other studies finding independent production is unlikely.
Biosynthesis.
The core synthetic route is via a terpenoid pathway, parts of which having been successfully transplanted into production strains of E.coli and yeast.
Synthesis.
By 1992, at least thirty academic research teams globally were working to achieve a total synthesis of this natural product, with the synthesis proceeding from simple natural products and other readily available starting materials. This total synthesis effort was motivated primarily by the desire to generate new chemical understanding, rather than with an expectation of the practical commercial production of paclitaxel. The first laboratories to complete the total synthesis from much less complex starting materials were the research groups of Robert A. Holton, who had the first article to be accepted for publication, and of K. C. Nicolaou who had the first article to appear in print (by a week, on 7 February 1994). Though the Holton submission preceded the Nicolaou by a month (21 December 1993 versus 24 January 1994), the near coincidence of the publications arising from each of these massive, multiyear efforts—11-18 authors appearing on each of the February 1994 publications—has led the ending of the race to be termed a "tie" or a "photo finish", though each group has argued that their synthetic strategy and tactics were superior.
As of 2007, five additional research groups have joined the initial two in successful total syntheses: Wender et al. in 1997, and Kuwajima et al. and Mukaiyama et al. in 1998 with further linear syntheses, and Danishefsky et al. in 1996 and Takahashi et al. in 2006 with further convergent syntheses. All strategies aim to prepare a 10-Deacetylbaccatin-type core containing the ABCD ring system, followed generally by last stage addition of the "tail" to the 13-hydroxyl group.
While the "political climate surrounding taxol and "Taxus brevifolia" in the early 1990s… helped bolster [a] link between total synthesis and the [taxol] supply problem", and though total synthesis activities were a requisite to explore the structure-activity relationships of taxol via generation of analogs for testing, the total synthesis efforts were never seen "as a serious commercial route" to provide significant quantities of the natural product for medical testing or therapeutic use.
History.
Paclitaxel was discovered as a part of a U.S. National Cancer Institute screening program, by Monroe E. Wall and Mansukh C. Wani at the Research Triangle Institute, Research Triangle Park, North Carolina, in 1967. These scientists isolated the natural product from the bark of the Pacific yew tree, "Taxus brevifolia", determined its structure and named it "taxol", and arranged for its first biological testing. The compound was then developed commercially by Bristol-Myers Squibb (BMS), who had the generic name assigned as "paclitaxel".
Plant screening program.
In 1955, the National Cancer Institute (NCI) in the United States set up the Cancer Chemotherapy National Service Center (CCNSC) to act as a public screening center for anticancer activity in compounds submitted by external institutions and companies. Although the majority of compounds screened were of synthetic origin, one chemist, Jonathan Hartwell, who was employed there from 1958 onwards, had had experience with natural product derived compounds, and began a plant screening operation. After some years of informal arrangements, in July 1960, the NCI commissioned USDA botanists to collect samples from about 1000 plant species per year. On 21 August 1962, one of those botanists, Arthur S. Barclay, collected bark from a single Pacific yew tree, "Taxus brevifolia", in a forest north of the town of Packwood, Washington as part of a four-month trip to collect material from over 200 different species. The material was then processed by a number of specialist CCNSC subcontractors, and one of the "Taxus" samples was found to be cytotoxic in a cellular assay on 22 May 1964.
Accordingly, in late 1964 or early 1965, the fractionation and isolation laboratory run by Monroe E. Wall in Research Triangle Park, North Carolina, began work on fresh "Taxus" samples, isolating the active ingredient in September 1966 and announcing their findings at an April 1967 American Chemical Society meeting in Miami Beach. They named the pure compound taxol in June 1967.
Wall and his colleague Wani published their results, including the chemical structure, in 1971.
The NCI continued to commission work to collect more "Taxus" bark and to isolate increasing quantities of taxol. By 1969, 28 kg of crude extract had been isolated from almost 1,200 kg of bark, although this ultimately yielded only 10g of pure material, but for several years, no use was made of the compound by the NCI. In 1975, it was shown to be active in another "in vitro" system; two years later, a new department head reviewed the data and finally recommended taxol be moved on to the next stage in the discovery process. This required increasing quantities of purified taxol, up to 600 g, and in 1977 a further request for 7,000 lbs of bark was made.
In 1978, two NCI researchers published a report showing taxol was mildly effective in leukaemic mice.
In November 1978, taxol was shown to be effective in xenograft studies.
Meanwhile, taxol began to be well known in the cell biology, as well as the cancer community, with a publication in early 1979 by Susan B. Horwitz, a molecular pharmacologist at Albert Einstein College of Medicine, showing taxol had a previously unknown mechanism of action involving the stabilization of microtubules. Together with formulation problems, this increased interest from researchers meant that, by 1980, the NCI envisaged needing to collect 20,000 lbs of bark.
Animal toxicology studies were complete by June 1982, and in November NCI applied for the IND necessary to begin clinical trials in humans.
Early clinical trials, supply and the transfer to BMS.
Phase I clinical trials began in April 1984, and the decision to start Phase II trials was made a year later. These larger trials needed more bark and collection of a further 12,000 pounds was commissioned, which enabled some phase II trials to begin by the end of 1986. But by then it was recognized that the demand for taxol might be substantial and that more than 60,000 pounds of bark might be needed as a minimum. This unprecedentedly large amount brought ecological concerns about the impact on yew populations into focus for the first time, as local politicians and foresters expressed unease at the program.
The first public report from a phase II trial in May 1988 showed an effect in melanoma patients and a remarkable response rate of 30% in patients with refractory ovarian cancer. At this point, Gordon Cragg of the NCI's Natural Product Branch calculated the synthesis of enough taxol to treat all the ovarian cancer and melanoma cases in the US would require the destruction of 360,000 trees annually. For the first time, serious consideration was given to the problem of supply.
Because of the practical and, in particular, the financial scale of the program needed, the NCI decided to seek association with a pharmaceutical company, and in August 1989, it published a Cooperative Research and Development Agreement (CRADA) offering its current stock and supply from current bark stocks, and proprietary access to the data so far collected, to a company willing to commit to providing the funds to collect further raw material, isolate taxol, and fund a large proportion of clinical trials. In the words of Goodman and Welsh, authors of a substantial scholarly book on taxol, "The NCI] was thinking, not of collaboration, ... but of a hand-over of taxol (and its problems)".
Although the offer was widely advertised, only four companies responded to the CRADA, including the American firm Bristol-Myers Squibb (BMS),
which was selected as the partner in December 1989. The choice of BMS later became controversial and was the subject of Congressional hearings in 1991 and 1992. While it seems clear the NCI had little choice but to seek a commercial partner, there was also controversy about the terms of the deal, eventually leading to a report by the General Accounting Office in 2003, which concluded the NIH had failed to ensure value for money. In related CRADAs with the USDA and Department of the Interior, Bristol-Myers Squibb was given exclusive first refusal on all Federal supplies of "Taxus brevifolia".
This exclusive contract lead to some criticism for giving BMS a "cancer monopoly".
Eighteen months after the CRADA, BMS filed a new drug application (NDA), which was given FDA approval at the very end of 1992.
Although there was no patent on the compound, the provisions of the Waxman-Hatch Act gave Bristol-Myers Squibb five years exclusive marketing rights.
In 1990, BMS applied to trademark the name taxol as "Taxol(R)". This was controversially approved in 1992. At the same time, paclitaxel replaced taxol as the generic (INN) name of the compound. Critics, including the journal "Nature", argued the name taxol had been used for more than two decades and in more than 600 scientific articles and suggested the trademark should not have been awarded and the BMS should renounce its rights to it. BMS argued changing the name would cause confusion among oncologists and possibly endanger the health of patients. BMS has continued to defend its rights to the name in the courts.
BMS has also been criticized for misrepresentation by Goodman and Walsh, who quote from a company report saying "It was not until 1971 that ... testing ... enabled the isolation of paclitaxel, initially described as 'compound 17". This quote is, strictly speaking, accurate: the objection seems to be that this misleadingly neglects to explain that it was the scientist doing the isolation who named the compound taxol and it was not referred to in any other way for more than twenty years.
Annual sales peaked in 2000, reaching US$1.6 billion; paclitaxel is now available in generic form.
Nomenclature.
The nomenclature for paclitaxel is structured on a tetracyclic 17-carbon (heptadecane) skeleton. There are a total of 11 stereocenters. The active stereoisomer is (−)-paclitaxel (shown here).
Cost.
The cost to the NHS per patient in early breast cancer, assuming four cycles of treatment, is about £4000 (approx. $6000).
Research.
A recent study suggested that caffeine may act inhibitory on paclitaxels' pro-apoptotic effect in colorectal cancer cells.

</doc>
<doc id="36797" url="http://en.wikipedia.org/wiki?curid=36797" title="Occam's razor">
Occam's razor

Occam's razor (also written as Ockham's razor and in Latin "lex parsimoniae", which means 'law of parsimony') is a problem-solving principle devised by William of Ockham (c. 1287–1347), who was an English Franciscan friar and scholastic philosopher and theologian. The principle states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected. Other, more complicated solutions may ultimately prove to provide better predictions, but—in the absence of differences in predictive ability—the fewer assumptions that are made, the better.
The application of the principle can be used to shift the burden of proof in a discussion. However, Alan Baker, who suggests this in the online Stanford Encyclopedia of Philosophy, is careful to point out that his suggestion should not be taken generally, but only as it applies in a particular context, that is: philosophers who argue in opposition to metaphysical theories that involve allegedly "superfluous ontological apparatus". Baker then notices that principles, including Occam's razor, are often expressed in a way that is not clear regarding which facet of "simplicity"—parsimony or elegance—is being referred to, and that in a hypothetical formulation the facets of simplicity may work in different directions: a simpler description may refer to a more complex hypothesis, and a more complex description may refer to a simpler hypothesis.
Solomonoff's theory of inductive inference is a mathematically formalized Occam's razor: shorter computable theories have more weight when calculating the probability of the next observation, using all computable theories which perfectly describe previous observations.
In science, Occam's razor is used as a heuristic technique (discovery tool) to guide scientists in the development of theoretical models rather than as an arbiter between published models. In the scientific method, Occam's razor is not considered an irrefutable principle of logic or a scientific result; the preference for simplicity in the scientific method is based on the falsifiability criterion. For each accepted explanation of a phenomenon, there is always an infinite number of possible and more complex alternatives, because one can always burden failing explanations with ad hoc hypothesis to prevent them from being falsified; therefore, simpler theories are preferable to more complex ones because they are better testable and falsifiable.
History.
The term "Occam's Razor" first appeared in 1852 in the works of Sir William Hamilton, 9th Baronet (1788–1856), centuries after William of Ockham's death in 1347. Ockham did not invent this "razor"; its association with him may be due to the frequency and effectiveness with which he used it (Ariew 1976). Ockham stated the principle in various ways, but the most popular version "entities must not be multiplied beyond necessity" "(Non sunt multiplicanda entia sine necessitate)" was formulated by the Irish Franciscan philosopher John Punch in his 1639 commentary on the works of Duns Scotus.
Formulations before Ockham.
The origins of what has come to be known as Occam's Razor are traceable to the works of earlier philosophers such as John Duns Scotus (1265–1308), Robert Grosseteste (1175-1253), Maimonides (Moses ben-Maimon, 1138–1204), and even Aristotle (384–322 BC). Aristotle writes in his "Posterior Analytics", "we may assume the superiority "ceteris paribus" [other things being equal] of the demonstration which derives from fewer postulates or hypotheses." Ptolemy (c. AD 90 – c. AD 168) stated, "We consider it a good principle to explain the phenomena by the simplest hypothesis possible."
Phrases such as "It is vain to do with more what can be done with fewer" and "A plurality is not to be posited without necessity" were commonplace in 13th-century scholastic writing. Robert Grosseteste, in "Commentary on" [Aristotle's] "the Posterior Analytics Books" ("Commentarius in Posteriorum Analyticorum Libros") (c. 1217–1220), declares: "That is better and more valuable which requires fewer, other circumstances being equal... For if one thing were demonstrated from many and another thing from fewer equally known premises, clearly that is better which is from fewer because it makes us know quickly, just as a universal demonstration is better than particular because it produces knowledge from fewer premises. Similarly in natural science, in moral science, and in metaphysics the best is that which needs no premises and the better that which needs the fewer, other circumstances being equal." The "Summa Theologica" of Thomas Aquinas (1225–1274) states that "it is superfluous to suppose that what can be accounted for by a few principles has been produced by many". Aquinas uses this principle to construct an objection to God's existence, an objection that he in turn answers and refutes generally (cf. "quinque viae"), and specifically, through an argument based on causality. Hence, Aquinas acknowledges the principle that today is known as Occam's Razor, but prefers causal explanations to other simple explanations (cf. also Correlation does not imply causation).
The Indian Hindu philosopher Madhva in verse 400 of his "Vishnu-Tattva-Nirnaya" says: "dvidhAkalpane kalpanAgauravamiti" (To make two suppositions when one is enough is to err by way of excessive supposition).
Ockham.
William of Ockham ("c". 1287–1347) was an English Franciscan friar and theologian, an influential medieval philosopher and a nominalist. His popular fame as a great logician rests chiefly on the maxim attributed to him and known as Ockham's razor. The term "razor" refers to distinguishing between two hypotheses either by "shaving away" unnecessary assumptions or cutting apart two similar conclusions.
While it has been claimed that Ockham's razor is not found in any of his writings, one can cite statements such as "" [Plurality must never be posited without necessity], which occurs in his theological work on the 'Sentences of Peter Lombard' ("Quaestiones et decisiones in quattuor libros Sententiarum Petri Lombardi" (ed. Lugd., 1495), i, dist. 27, qu. 2, K).
Nevertheless, the precise words sometimes attributed to Ockham, "entia non sunt multiplicanda praeter necessitatem" (entities must not be multiplied beyond necessity), are absent in his extant works; this particular phrasing owes more to John Punch, who described the principle as a "common axiom" "(axioma vulgare)" of the Scholastics. Indeed, Ockham's contribution seems to be to restrict the operation of this principle in matters pertaining to miracles and God's power: so, in the Eucharist, a plurality of miracles is possible, simply because it pleases God.
This principle is sometimes phrased as "pluralitas non est ponenda sine necessitate" ("plurality should not be posited without necessity"). In his "Summa Totius Logicae", i. 12, Ockham cites the principle of economy, "Frustra fit per plura quod potest fieri per pauciora" [It is futile to do with more things that which can be done with fewer]. (Thorburn, 1918, pp. 352–3; Kneale and Kneale, 1962, p. 243.)
Later formulations.
To quote Isaac Newton, "We are to admit no more causes of natural things than such as are both true and sufficient to explain their appearances. Therefore, to the same natural effects we must, so far as possible, assign the same causes."
Bertrand Russell offers a particular version of Occam's Razor: "Whenever possible, substitute constructions out of known entities for inferences to unknown entities."
Around 1960, Ray Solomonoff founded the theory of universal inductive inference, the theory of prediction based on observations; for example, predicting the next symbol based upon a given series of symbols. The only assumption is that the environment follows some unknown but computable probability distribution. This theory is a mathematical formalization of Occam's Razor.
Another technical approach to Occam's Razor is ontological parsimony.
The widespread layperson's formulation that "the simplest explanation is usually the correct one" appears to have been derived from Occam's Razor.
Justifications.
Beginning in the 20th century, epistemological justifications based on induction, logic, pragmatism, and especially probability theory have become more popular among philosophers.
Aesthetic.
Prior to the 20th century, it was a commonly held belief that nature itself was simple and that simpler hypotheses about nature were thus more likely to be true. This notion was deeply rooted in the aesthetic value simplicity holds for human thought and the justifications presented for it often drew from theology. Thomas Aquinas made this argument in the 13th century, writing, "If a thing can be done adequately by means of one, it is superfluous to do it by means of several; for we observe that nature does not employ two instruments [if] one suffices."
Empirical.
Occam's Razor has gained strong empirical support as far as helping to converge on better theories (see "Applications" section below for some examples).
In the related concept of overfitting, excessively complex models are affected by statistical noise (a problem also known as the bias-variance trade-off), whereas simpler models may capture the underlying structure better and may thus have better predictive performance. It is, however, often difficult to deduce which part of the data is noise (cf. model selection, test set, minimum description length, Bayesian inference, etc.).
Testing the razor.
The razor's statement that "other things being equal, simpler explanations are generally better than more complex ones" is amenable to empirical testing. Another interpretation of the razor's statement would be that "simpler hypotheses (not conclusions, i.e. explanations) are generally better than the complex ones". The procedure to test the former interpretation would compare the track records of simple and comparatively complex explanations. If you accept the first interpretation, the validity of Occam's Razor as a tool would then have to be rejected if the more complex explanations were more often correct than the less complex ones (while the converse would lend support to its use). If the latter interpretation is accepted, the validity of Occam's Razor as a tool could possibly be accepted if the simpler hypotheses led to correct conclusions more often than not.
In the history of competing hypotheses, the simpler hypotheses have led to mathematically rigorous and empirically verifiable theories. In the history of competing explanations, this is not the case—at least not generally. Some increases in complexity are sometimes necessary. So there remains a justified general bias toward the simpler of two competing explanations. To understand why, consider that for each accepted explanation of a phenomenon, there is always an infinite number of possible, more complex, and ultimately incorrect, alternatives. This is so because one can always burden failing explanations with ad hoc hypothesis. Ad hoc hypotheses are justifications that prevent theories from being falsified. Even other empirical criteria, such as consilience, can never truly eliminate such explanations as competition. Each true explanation, then, may have had many alternatives that were simpler and false, but also an infinite number of alternatives that were more complex and false. But if an alternate ad hoc hypothesis were indeed justifiable, its implicit conclusions would be empirically verifiable. On a commonly accepted repeatability principle, these alternate theories have never been observed and continue to escape observation. In addition, we do not say an explanation is true if it has not withstood this principle.
Put another way, any new, and even more complex, theory can still possibly be true. For example, if an individual makes supernatural claims that Leprechauns were responsible for breaking a vase, the simpler explanation would be that he is mistaken, but ongoing ad hoc justifications (e.g. "and that's not me on the film; they tampered with that, too") successfully prevent outright falsification. This endless supply of elaborate competing explanations, called saving hypotheses, cannot be ruled out—but by using Occam's Razor.
Practical considerations and pragmatism.
The common form of the razor, used to distinguish between equally explanatory hypotheses, may be supported by the practical fact that simpler theories are easier to understand.
Some argue that Occam's Razor is not an inference-driven model, but a heuristic maxim for choosing "among" other models and instead" underlies" induction.
Alternatively, if we want to have reasonable discussion we may be practically forced to accept Occam's Razor in the same way we are simply forced to accept the laws of thought and inductive reasoning (given the problem of induction). Philosopher Elliott Sober states that not even reason itself can be justified on any reasonable grounds, and that we must start with first principles of some kind (otherwise an infinite regress occurs).
The pragmatist may go on, as David Hume did on the topic of induction, that there is no satisfying alternative to granting this premise. Though one may "claim" that Occam's Razor is invalid as a premise helping to regulate theories, putting this doubt into practice would mean doubting whether every step forward will result in locomotion or a nuclear explosion. In other words still: "What's the alternative?"
Mathematical.
One justification of Occam's Razor is a direct result of basic probability theory. By definition, all assumptions introduce possibilities for error; if an assumption does not improve the accuracy of a theory, its only effect is to increase the probability that the overall theory is wrong.
There have also been other attempts to derive Occam's Razor from probability theory, including notable attempts made by Harold Jeffreys and E. T. Jaynes. The probabilistic (Bayesian) basis for Occam's Razor is elaborated by David J. C. MacKay in chapter 28 of his book "Information Theory, Inference, and Learning Algorithms", where he emphasises that a prior bias in favour of simpler models is not required.
William H. Jefferys (no relation to Harold Jeffreys) and James O. Berger (1991) generalize and quantify the original formulation's "assumptions" concept as the degree to which a proposition is unnecessarily accommodating to possible observable data. They state "a hypothesis with fewer adjustable parameters will automatically have an enhanced posterior probability, due to the fact that the predictions it makes are sharp". The model they propose balances the precision of a theory's predictions against their sharpness; theories which sharply made their correct predictions are preferred over theories which would have accommodated a wide range of other possible results. This, again, reflects the mathematical relationship between key concepts in Bayesian inference (namely marginal probability, conditional probability, and posterior probability).
Other philosophers.
Karl Popper.
Karl Popper argues that a preference for simple theories need not appeal to practical or aesthetic considerations. Our preference for simplicity may be justified by its falsifiability criterion: we prefer simpler theories to more complex ones "because their empirical content is greater; and because they are better testable" (Popper 1992). The idea here is that a simple theory applies to more cases than a more complex one, and is thus more easily falsifiable. This is again comparing a simple theory to a more complex theory where both explain the data equally well.
Elliott Sober.
The philosopher of science Elliott Sober once argued along the same lines as Popper, tying simplicity with "informativeness": The simplest theory is the more informative one, in the sense that less information is required in order to answer one's questions. He has since rejected this account of simplicity, purportedly because it fails to provide an epistemic justification for simplicity. He now believes that simplicity considerations (and considerations of parsimony in particular) do not count unless they reflect something more fundamental. Philosophers, he suggests, may have made the error of hypostatizing simplicity (i.e. endowed it with a "sui generis" existence), when it has meaning only when embedded in a specific context (Sober 1992). If we fail to justify simplicity considerations on the basis of the context in which we make use of them, we may have no non-circular justification: "just as the question 'why be rational?' may have no non-circular answer, the same may be true of the question 'why should simplicity be considered in evaluating the plausibility of hypotheses?'".
Richard Swinburne.
Richard Swinburne argues for simplicity on logical grounds:
... the simplest hypothesis proposed as an explanation of phenomena is more likely to be the true one than is any other available hypothesis, that its predictions are more likely to be true than those of any other available hypothesis, and that it is an ultimate a priori epistemic principle that simplicity is evidence for truth.—Swinburne 1997
According to Swinburne, since our choice of theory cannot be determined by data (see Underdetermination and Quine-Duhem thesis), we must rely on some criterion to determine which theory to use. Since it is absurd to have no logical method by which to settle on one hypothesis amongst an infinite number of equally data-compliant hypotheses, we should choose the simplest theory: "either science is irrational [in the way it judges theories and predictions probable] or the principle of simplicity is a fundamental synthetic a priori truth" (Swinburne 1997).
Ludwig Wittgenstein.
From the "Tractatus Logico-Philosophicus":
and on the related concept of "simplicity":
Applications.
Science and the scientific method.
In science, Occam's Razor is used as a heuristic (rule of thumb) to guide scientists in developing theoretical models rather than as an arbiter between published models. In physics, parsimony was an important heuristic in Albert Einstein's formulation of special relativity, in the development and application of the principle of least action by Pierre Louis Maupertuis and Leonhard Euler, and in the development of quantum mechanics by Max Planck, Werner Heisenberg and Louis de Broglie.
In chemistry, Occam's Razor is often an important heuristic when developing a model of a reaction mechanism. Although it is useful as a heuristic in developing models of reaction mechanisms, it has been shown to fail as a criterion for selecting among some selected published models. In this context, Einstein himself expressed caution when he formulated Einstein's Constraint: "It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience". An often-quoted version of this constraint (which cannot be verified as posited by Einstein himself) says "Everything should be kept as simple as possible, but no simpler."
In the scientific method, parsimony is an epistemological, metaphysical or heuristic preference, not an irrefutable principle of logic or a scientific result. As a logical principle, Occam's Razor would demand that scientists accept the simplest possible theoretical explanation for existing data. However, science has shown repeatedly that future data often support more complex theories than do existing data. Science prefers the simplest explanation that is consistent with the data available at a given time, but the simplest explanation may be ruled out as new data become available. That is, science is open to the possibility that future experiments might support more complex theories than demanded by current data and is more interested in designing experiments to discriminate between competing theories than favoring one theory over another based merely on philosophical principles.
When scientists use the idea of parsimony, it has meaning only in a very specific context of inquiry. Several background assumptions are required for parsimony to connect with plausibility in a particular research problem. The reasonableness of parsimony in one research context may have nothing to do with its reasonableness in another. It is a mistake to think that there is a single global principle that spans diverse subject matter.
It has been suggested that Occam's Razor is a widely accepted example of extraevidential consideration, even though it is entirely a metaphysical assumption. There is little empirical evidence that the world is actually simple or that simple accounts are more likely to be true than complex ones.
Most of the time, Occam's Razor is a conservative tool, cutting out crazy, complicated constructions and assuring that hypotheses are grounded in the science of the day, thus yielding "normal" science: models of explanation and prediction. There are, however, notable exceptions where Occam's Razor turns a conservative scientist into a reluctant revolutionary. For example, Max Planck interpolated between the Wien and Jeans radiation laws and used Occam's Razor logic to formulate the quantum hypothesis, even resisting that hypothesis as it became more obvious that it was correct.
Appeals to simplicity were used to argue against the phenomena of meteorites, ball lightning, continental drift, and reverse transcriptase. One can argue for atomic building blocks for matter, because it provides a simpler explanation for the observed reversibility of both mixing and chemical reactions as simple separation and rearrangements of atomic building blocks. At the time, however, the atomic theory was considered more complex because it implied the existence of invisible particles which had not been directly detected. Ernst Mach and the logical positivists rejected the atomic theory of John Dalton until the reality of atoms was more evident in Brownian motion, as shown by Albert Einstein. In the same way, postulating the aether is more complex than transmission of light through a vacuum. At the time, however, all known waves propagated through a physical medium, and it seemed simpler to postulate the existence of a medium than to theorize about wave propagation without a medium. Likewise, Newton's idea of light particles seemed simpler than Christiaan Huygens's idea of waves, so many favored it. In this case, as it turned out, neither the wave—nor the particle—explanation alone suffices, as light behaves like waves and like particles.
Three axioms presupposed by the scientific method are realism (the existence of objective reality), the existence of natural laws, and the constancy of natural law. Rather than depend on provability of these axioms, science depends on the fact that they have not been objectively falsified. Occam's Razor and parsimony support, but do not prove, these axioms of science. The general principle of science is that theories (or models) of natural law must be consistent with repeatable experimental observations. This ultimate arbiter (selection criterion) rests upon the axioms mentioned above.
There are examples where Occam's Razor would have favored the wrong theory given the available data. Simplicity principles are useful philosophical preferences for choosing a more likely theory from among several possibilities that are all consistent with available data. A single instance of Occam's Razor favoring a wrong theory falsifies the razor as a general principle. Michael Lee and others provide cases in which a parsimonious approach does not guarantee a correct conclusion and, if based on incorrect working hypotheses or interpretations of incomplete data, may even strongly support a false conclusion. Lee states, "When parsimony ceases to be a guideline and is instead elevated to an "ex cathedra" pronouncement, parsimony analysis ceases to be science."
If multiple models of natural law make exactly the same testable predictions, they are equivalent and there is no need for parsimony to choose a preferred one. For example, Newtonian, Hamiltonian and Lagrangian classical mechanics are equivalent. Physicists have no interest in using Occam's Razor to say the other two are wrong. Likewise, there is no demand for simplicity principles to arbitrate between wave and matrix formulations of quantum mechanics. Science often does not demand arbitration or selection criteria between models that make the same testable predictions.
Biology.
Biologists or philosophers of biology use Occam's Razor in either of two contexts both in evolutionary biology: the units of selection controversy and systematics. George C. Williams in his book "Adaptation and Natural Selection" (1966) argues that the best way to explain altruism among animals is based on low level (i.e. individual) selection as opposed to high level group selection. Altruism is defined by some evolutionary biologists (e.g. R. Alexander, 1987; W. D. Hamilton, 1964) as behavior that is beneficial to others (or to the group) at a cost to the individual, and many posit individual selection as the mechanism which explains altruism solely in terms of the behaviors of individual organisms acting in their own self-interest (or in the interest of their genes, via kin selection). Williams was arguing against the perspective of others who propose selection at the level of the group as an evolutionary mechanism that selects for altruistic traits (e.g. D. S. Wilson & E. O. Wilson, 2007). The basis for Williams' contention is that of the two, individual selection is the more parsimonious theory. In doing so he is invoking a variant of Occam's Razor known as Morgan's Canon: "In no case is an animal activity to be interpreted in terms of higher psychological processes, if it can be fairly interpreted in terms of processes which stand lower in the scale of psychological evolution and development" (Morgan 1903).
However, more recent biological analyses, such as Richard Dawkins' "The Selfish Gene", have contended that Morgan's Canon is not the simplest and most basic explanation. Dawkins argues the way evolution works is that the genes propagated in most copies will end up determining the development of that particular species, i.e., natural selection turns out to select specific genes, and this is really the fundamental underlying principle, that automatically gives individual and group selection as emergent features of evolution.
Zoology provides an example. Muskoxen, when threatened by wolves, will form a circle with the males on the outside and the females and young on the inside. This is an example of a behavior by the males that seems to be altruistic. The behavior is disadvantageous to them individually but beneficial to the group as a whole and was thus seen by some to support the group selection theory.
However, a much better explanation immediately offers itself once one considers that natural selection works on genes. If the male musk ox runs off, leaving his offspring to the wolves, his genes will not be propagated. If however he takes up the fight his genes will live on in his offspring. And thus the "stay-and-fight" gene prevails. This is an example of kin selection. An underlying general principle thus offers a much simpler explanation, without retreating to special principles as group selection.
Systematics is the branch of biology that attempts to establish genealogical relationships among organisms. It is also concerned with their classification. There are three primary camps in systematics; cladists, pheneticists, and evolutionary taxonomists. The cladists hold that genealogy alone should determine classification and pheneticists contend that similarity over propinquity of descent is the determining criterion while evolutionary taxonomists say that both genealogy and similarity count in classification.
It is among the cladists that Occam's Razor is to be found, although their term for it is cladistic parsimony. Cladistic parsimony (or maximum parsimony) is a method of phylogenetic inference in the construction of types of phylogenetic trees (more specifically, cladograms). Cladograms are branching, tree-like structures used to represent lines of descent based on one or more evolutionary changes. Cladistic parsimony is used to support the hypotheses that require the fewest evolutionary changes. For some types of tree, it will consistently produce the wrong results regardless of how much data is collected (this is called long branch attraction). For a full treatment of cladistic parsimony, see Elliott Sober's "Reconstructing the Past: Parsimony, Evolution, and Inference" (1988). For a discussion of both uses of Occam's Razor in biology, see Sober's article "Let's Razor Ockham's Razor" (1990).
Other methods for inferring evolutionary relationships use parsimony in a more traditional way. Likelihood methods for phylogeny use parsimony as they do for all likelihood tests, with hypotheses requiring few differing parameters (i.e., numbers of different rates of character change or different frequencies of character state transitions) being treated as null hypotheses relative to hypotheses requiring many differing parameters. Thus, complex hypotheses must predict data much better than do simple hypotheses before researchers reject the simple hypotheses. Recent advances employ information theory, a close cousin of likelihood, which uses Occam's Razor in the same way.
Francis Crick has commented on potential limitations of Occam's Razor in biology. He advances the argument that because biological systems are the products of (an ongoing) natural selection, the mechanisms are not necessarily optimal in an obvious sense. He cautions: "While Ockham's razor is a useful tool in the physical sciences, it can be a very dangerous implement in biology. It is thus very rash to use simplicity and elegance as a guide in biological research."
In biogeography, parsimony is used to infer ancient migrations of species or populations by observing the geographic distribution and relationships of existing organisms. Given the phylogenetic tree, ancestral migrations are inferred to be those that require the minimum amount of total movement.
Medicine.
When discussing Occam's Razor in contemporary medicine, doctors and philosophers of medicine speak of diagnostic parsimony. Diagnostic parsimony advocates that when diagnosing a given injury, ailment, illness, or disease a doctor should strive to look for the fewest possible causes that will account for all the symptoms. This philosophy is one of several demonstrated in the popular medical adage "when you hear hoofbeats behind you, think horses, not zebras". While diagnostic parsimony might often be beneficial, credence should also be given to the counter-argument modernly known as Hickam's dictum, which succinctly states that "patients can have as many diseases as they damn well please". It is often statistically more likely that a patient has several common diseases, rather than having a single rarer disease which explains their myriad symptoms. Also, independently of statistical likelihood, some patients do in fact turn out to have multiple diseases, which by common sense nullifies the approach of insisting to explain any given collection of symptoms with one disease. These misgivings emerge from simple probability theory—which is already taken into account in many modern variations of the razor—and from the fact that the loss function is much greater in medicine than in most of general science. Because misdiagnosis can result in the loss of a person's health and potentially life, it is considered better to test and pursue all reasonable theories even if there is some theory that appears the most likely.
Diagnostic parsimony and the counterbalance it finds in Hickam's dictum have very important implications in medical practice. Any set of symptoms could be indicative of a range of possible diseases and disease combinations; though at no point is a diagnosis rejected or accepted just on the basis of one disease appearing more likely than another, the continuous flow of hypothesis formulation, testing and modification benefits greatly from estimates regarding which diseases (or sets of diseases) are relatively more likely to be responsible for a set of symptoms, given the patient's environment, habits, medical history and so on. For example, if a hypothetical patient's immediately apparent symptoms include fatigue and cirrhosis and they test negative for Hepatitis C, their doctor might formulate a working hypothesis that the cirrhosis was caused by their drinking problem, and then seek symptoms and perform tests to formulate and rule out hypotheses as to what has been causing the fatigue; but if the doctor were to further discover that the patient's breath inexplicably smells of garlic and they are suffering from pulmonary edema, they might decide to test for the relatively rare condition of selenium poisoning.
Religion.
In the philosophy of religion, Occam's Razor is sometimes applied to the existence of God. William of Ockham himself was a Christian. He believed in God, and in the authority of Scripture; he writes that "nothing ought to be posited without a reason given, unless it is self-evident (literally, known through itself) or known by experience or proved by the authority of Sacred Scripture." Ockham believed that an explanation has no sufficient basis in reality when it does not harmonize with reason, experience, or the Bible. However, unlike many theologians of his time, Ockham did not believe God could be logically proven with arguments. To Ockham, science was a matter of discovery, but theology was a matter of revelation and faith. He states: "only faith gives us access to theological truths. The ways of God are not open to reason, for God has freely chosen to create a world and establish a way of salvation within it apart from any necessary laws that human logic or rationality can uncover."
St. Thomas Aquinas, in the "Summa Theologica", uses a formulation of Occam's Razor to construct an objection to the idea that God exists, which he refutes directly with a counterargument:
Further, it is superfluous to suppose that what can be accounted for by a few principles has been produced by many. But it seems that everything we see in the world can be accounted for by other principles, supposing God did not exist. For all natural things can be reduced to one principle which is nature; and all voluntary things can be reduced to one principle which is human reason, or will. Therefore there is no need to suppose God's existence.
In turn, Aquinas answers this with the "quinque viae", and addresses the particular objection above with the following answer:
Since nature works for a determinate end under the direction of a higher agent, whatever is done by nature must needs be traced back to God, as to its first cause. So also whatever is done voluntarily must also be traced back to some higher cause other than human reason or will, since these can change or fail; for all things that are changeable and capable of defect must be traced back to an immovable and self-necessary first principle, as was shown in the body of the Article.
Rather than argue for the necessity of a god, some theists base their belief upon grounds independent of, or prior to, reason, making Occam's Razor irrelevant. This was the stance of Søren Kierkegaard, who viewed belief in God as a leap of faith which sometimes directly opposed reason. This is also the doctrine of Gordon Clark's Presuppositional apologetics, with the exception that Clark never thought the leap of faith was contrary to reason. (See also Fideism).
There are various arguments in favour of God which establish God as a useful or even necessary assumption. Contrastingly, atheists hold firmly to the belief that assuming the existence of God would introduce unnecessary complexity (Schmitt 2005, e.g. the Ultimate Boeing 747 gambit). Taking a nuanced position, philosopher Del Ratzsch suggests that the application of the razor to God may not be so simple, least of all when we are comparing that hypothesis with theories postulating multiple invisible universes.
Another application of the principle is to be found in the work of George Berkeley (1685–1753). Berkeley was an idealist who believed that all of reality could be explained in terms of the mind alone. He invoked Occam's Razor against materialism, stating that matter was not required by his metaphysic and was thus eliminable. One potential problem with this belief is that it's possible, given Berkeley's position, to find solipsism itself more in line with the razor than a God-mediated world beyond a single thinker.
In his article "Sensations and Brain Processes" (1959), J. J. C. Smart invoked Occam's Razor with the aim to justify his preference of the mind-brain identity theory over spirit-body dualism. Dualists state that there are two kinds of substances in the universe: physical (including the body) and spiritual, which is non-physical. In contrast, identity theorists state that everything is physical, including consciousness, and that there is nothing nonphysical. Despite the fact that it is impossible to appreciate the spiritual when limiting oneself to the physical, Smart maintained that identity theory explains all phenomena by assuming only a physical reality. Subsequently, Smart has been severely criticized for his (mis)use of Occam's Razor and ultimately retracted his advocacy of it in this context. Paul Churchland (1984) states that by itself Occam's Razor is inconclusive regarding duality. In a similar way, Dale Jacquette (1994) stated that Occam's Razor has been used in attempts to justify eliminativism and reductionism in the philosophy of mind. Eliminativism is the thesis that the ontology of folk psychology including such entities as "pain", "joy", "desire", "fear", etc., are eliminable in favor of an ontology of a completed neuroscience.
Penal ethics.
In penal theory and the philosophy of punishment, parsimony refers specifically to taking care in the distribution of punishment in order to avoid excessive punishment. In the utilitarian approach to the philosophy of punishment, Jeremy Bentham's "parsimony principle" states that any punishment greater than is required to achieve its end is unjust. The concept is related but not identical to the legal concept of proportionality. Parsimony is a key consideration of the modern restorative justice, and is a component of utilitarian approaches to punishment, as well as the prison abolition movement. Bentham believed that true parsimony would require punishment to be individualised to take account of the sensibility of the individual—an individual more sensitive to punishment should be given a proportionately lesser one, since otherwise needless pain would be inflicted. Later utilitarian writers have tended to abandon this idea, in large part due to the impracticality of determining each alleged criminal's relative sensitivity to specific punishments.
Probability theory and statistics.
Marcus Hutter's universal artificial intelligence builds upon Solomonoff's mathematical formalization of the razor to calculate the expected value of an action.
There are various papers in scholarly journals deriving formal versions of Occam's Razor from probability theory, applying it in statistical inference, and using it to come up with criteria for penalizing complexity in statistical inference. Recent papers have suggested a connection between Occam's Razor and Kolmogorov complexity.
One of the problems with the original formulation of the razor is that it only applies to models with the same explanatory power (i.e. it only tells us to prefer the simplest of equally good models). A more general form of the razor can be derived from Bayesian model comparison, which is based on Bayes factors and can be used to compare models that don't fit the data equally well. These methods can sometimes optimally balance the complexity and power of a model. Generally, the exact Occam factor is intractable, but approximations such as Akaike information criterion, Bayesian information criterion, Variational Bayesian methods, false discovery rate, and Laplace's method are used. Many artificial intelligence researchers are now employing such techniques, for instance through work on Occam Learning.
Statistical versions of Occam's razor have a more rigorous formulation than that which came of previous philosophical discussions. In particular, they must have a specific definition of the term 'simplicity', and that definition can vary. For example, in the Kolmogorov-Chaitin minimum description length approach, the subject must pick a Turing machine whose operations describe the basic operations "believed" to represent "simplicity" by the subject. However, one could always choose a Turing machine with a simple operation that happened to construct one's entire theory and would hence score highly under the razor. This has led to two opposing camps- one which believes that Occam's razor is objective, and the other which believes that Occam's razor is subjective.
Objective razor.
The minimum instruction set of a universal Turing machine requires approximately the same length description across different formulations, and is small compared to the Kolmogorov complexity of most practical theories. Marcus Hutter has used this consistency to define a "natural" Turing machine of small size as the proper basis for excluding arbitrarily complex instruction sets in the formulation of razors. Describing the program for the universal program as the "hypothesis", and the representation of the evidence as program data, it has been formally proven under Zermelo–Fraenkel set theory that "the sum of the log universal probability of the model plus the log of the probability of the data given the model should be minimized." Interpreting this as minimising the total length of a two-part message encoding model followed by data given model gives us the minimum message length (MML) principle.
One possible conclusion from mixing the concepts of Kolmogorov complexity and Occam's Razor is that an ideal data compressor would also be a scientific explanation/formulation generator. Some attempts have been made to re-derive known laws from considerations of simplicity or compressibility.
According to Jürgen Schmidhuber, the appropriate mathematical theory of Occam's Razor already exists, namely, Solomonoff's theory of optimal inductive inference and its extensions. See discussions in David L. Dowe's "Foreword re C. S. Wallace" for the subtle distinctions between the algorithmic probability work of Solomonoff and the MML work of Chris Wallace, and see Dowe's "MML, hybrid Bayesian network graphical models, statistical consistency, invariance and uniqueness" both for such discussions and for (in section 4) discussions of MML and Occam's Razor. For a specific example of MML as Occam's Razor in the problem of decision tree induction, see Dowe and Needham's "Message Length as an Effective Ockham's Razor in Decision Tree Induction".
Controversial aspects of the razor.
Occam's Razor is not an embargo against the positing of any kind of entity, or a recommendation of the simplest theory come what may. Occam's Razor is used to adjudicate between theories that have already passed "theoretical scrutiny" tests, and which are equally well-supported by the evidence. Furthermore, it may be used to prioritize empirical testing between two equally plausible but unequally testable hypotheses; thereby minimizing costs and wastes while increasing chances of falsification of the simpler-to-test hypothesis.
Another contentious aspect of the razor is that a theory can become more complex in terms of its structure (or syntax), while its ontology (or semantics) becomes simpler, or vice versa. Quine, in a discussion on definition, referred to these two perspectives as "economy of practical expression" and "economy in grammar and vocabulary", respectively. The theory of relativity is often given as an example of the proliferation of complex words to describe a simple concept.
Galileo Galilei lampooned the "misuse" of Occam's Razor in his "Dialogue". The principle is represented in the dialogue by Simplicio. The telling point that Galileo presented ironically was that if you really wanted to start from a small number of entities, you could always consider the letters of the alphabet as the fundamental entities, since you could construct the whole of human knowledge out of them.
Anti-razors.
Occam's Razor has met some opposition from people who have considered it too extreme or rash. Walter Chatton (c. 1290–1343) was a contemporary of William of Ockham (c. 1287–1347) who took exception to Occam's Razor and Ockham's use of it. In response he devised his own "anti-razor:" "If three things are not enough to verify an affirmative proposition about things, a fourth must be added, and so on." Although there have been a number of philosophers who have formulated similar anti-razors since Chatton's time, no one anti-razor has perpetuated in as much notability as Chatton's anti-razor, although this could be the case of the Late Renaissance Italian motto of unknown attribution "Se non è vero, è ben trovato" ("Even if it is not true, it is well conceived") when referred to a particularly artful explanation. For further information, see "Ockham's Razor and Chatton's Anti-Razor" (1984) by Armand Maurer.
Anti-razors have also been created by Gottfried Wilhelm Leibniz (1646–1716), Immanuel Kant (1724–1804), and Karl Menger (1902–1985). Leibniz's version took the form of a principle of plenitude, as Arthur Lovejoy has called it: the idea being that God created the most varied and populous of possible worlds. Kant felt a need to moderate the effects of Occam's Razor and thus created his own counter-razor: "The variety of beings should not rashly be diminished."
Karl Menger found mathematicians to be too parsimonious with regard to variables, so he formulated his Law Against Miserliness, which took one of two forms: "Entities must not be reduced to the point of inadequacy" and "It is vain to do with fewer what requires more." A less serious, but (some might say) even more extremist anti-razor is 'Pataphysics, the "science of imaginary solutions" developed by Alfred Jarry (1873–1907). Perhaps the ultimate in anti-reductionism, "'Pataphysics seeks no less than to view each event in the universe as completely unique, subject to no laws but its own." Variations on this theme were subsequently explored by the Argentine writer Jorge Luis Borges in his story/mock-essay "Tlön, Uqbar, Orbis Tertius". There is also Crabtree's Bludgeon, which cynically states that "[n]o set of mutually inconsistent observations can exist for which some human intellect cannot conceive a coherent explanation, however complicated."
Further reading.
</dl>

</doc>
<doc id="36806" url="http://en.wikipedia.org/wiki?curid=36806" title="Cotton">
Cotton

Cotton is a soft, fluffy staple fiber that grows in a boll, or protective capsule, around the seeds of cotton plants of the genus "Gossypium" in the family of "Malvaceae". The fiber is almost pure cellulose. Under natural conditions, the cotton bolls will tend to increase the dispersion of the seeds.
The plant is a shrub native to tropical and subtropical regions around the world, including the Americas, Africa, and India. The greatest diversity of wild cotton species is found in Mexico, followed by Australia and Africa. Cotton was independently domesticated in the Old and New Worlds. The English name derives from the Arabic "(al) quṭn" قُطْن, which began to be used circa 1400 AD.
The fiber is most often spun into yarn or thread and used to make a soft, breathable textile. The use of cotton for fabric is known to date to prehistoric times; fragments of cotton fabric dated from 5000 BC have been excavated in Mexico and the Indus Valley Civilization (modern-day Pakistan and some parts of India). Although cultivated since antiquity, it was the invention of the cotton gin that lowered the cost of production that led to its widespread use, and it is the most widely used natural fiber cloth in clothing today.
Current estimates for world production are about 25 million tonnes or 110 million bales annually, accounting for 2.5% of the world's arable land. China is the world's largest producer of cotton, but most of this is used domestically. The United States has been the largest exporter for many years. In the United States, cotton is usually measured in bales, which measure approximately 0.48 m3 and weigh 226.8 kg.
Types.
There are four commercially grown species of cotton, all domesticated in antiquity:
The two New World cotton species account for the vast majority of modern cotton production, but the two Old World species were widely used before the 1900s. While cotton fibers occur naturally in colors of white, brown, pink and green, fears of contaminating the genetics of white cotton have led many cotton-growing locations to ban the growing of colored cotton varieties, which remain a specialty product.
History.
Cotton was used in the Old World at least 7,000 years ago (5th millennium BC). Evidence of cotton use has been found at the site of Mehrgarh, where early cotton threads have been preserved in copper beads. Cotton cultivation became more widespread during the Indus Valley Civilization, which covered parts of modern eastern Pakistan and northwestern India. The Indus cotton industry was well-developed and some methods used in cotton spinning and fabrication continued to be used until the industrialization of India. Between 2000 and 1000 BC cotton became widespread across much of India. For example, it has been found at the site of Hallus in Karnataka dating from around 1000 BC. Cotton fabrics discovered in a cave near Tehuacán, Mexico have been dated to around 5800 BC, although it is difficult to know for certain due to fiber decay. Other sources date the domestication of cotton in Mexico to approximately 5000 to 3000 BC.
The Greeks and the Arabs were not familiar with cotton until the Wars of Alexander the Great, as his contemporary Megasthenes told Seleucus I Nicator of "there being trees on which wool grows" in "Indica". This might actually be a reference to 
"tree cotton", Gossypium arboreum, which is a native of the Indian subcontinent.
According to the "Columbia Encyclopedia":
Cotton has been spun, woven, and dyed since prehistoric times. It clothed the people of ancient India, Egypt, and China. Hundreds of years before the Christian era, cotton textiles were woven in India with matchless skill, and their use spread to the Mediterranean countries.
In Iran (Persia), the history of cotton dates back to the Achaemenid era (5th century BC); however, there are few sources about the planting of cotton in pre-Islamic Iran. The planting of cotton was common in Merv, Ray and Pars of Iran. In Persian poets' poems, especially Ferdowsi's Shahname, there are references to cotton ("panbe" in Persian). Marco Polo (13th century) refers to the major products of Persia, including cotton. John Chardin, a French traveler of the 17th century who visited the Safavid Persia, spoke approvingly of the vast cotton farms of Persia.
During the Han dynasty, cotton was grown by non-Chinese peoples in the southern Chinese province of Yunnan.
In Peru, cultivation of the indigenous cotton species "Gossypium barbadense" was the backbone of the development of coastal cultures such as the Norte Chico, Moche, and Nazca. Cotton was grown upriver, made into nets, and traded with fishing villages along the coast for large supplies of fish. The Spanish who came to Mexico and Peru in the early 16th century found the people growing cotton and wearing clothing made of it.
During the late medieval period, cotton became known as an imported fiber in northern Europe, without any knowledge of how it was derived, other than that it was a plant. Because Herodotus had written in his "Histories", Book III, 106, that in India trees grew in the wild producing wool, it was assumed that the plant was a tree, rather than a shrub. This aspect is retained in the name for cotton in several Germanic languages, such as German "Baumwolle", which translates as "tree wool" ("Baum" means "tree"; "Wolle" means "wool"). Noting its similarities to wool, people in the region could only imagine that cotton must be produced by plant-borne sheep. John Mandeville, writing in 1350, stated as fact the now-preposterous belief: "There grew there [India] a wonderful tree which bore tiny lambs on the endes of its branches. These branches were so pliable that they bent down to allow the lambs to feed when they are hungrie ["sic"]." (See Vegetable Lamb of Tartary.) By the end of the 16th century, cotton was cultivated throughout the warmer regions in Asia and the Americas.
India's cotton-processing sector gradually declined during British expansion in India and the establishment of colonial rule during the late 18th and early 19th centuries. This was largely due to aggressive colonialist mercantile policies of the British East India Company, which made cotton processing and manufacturing workshops in India uncompetitive. Indian markets were increasingly forced to supply only raw cotton and were forced, by British-imposed law, to purchase manufactured textiles from Britain.
Industrial Revolution in Britain.
The advent of the Industrial Revolution in Britain provided a great boost to cotton manufacture, as textiles emerged as Britain's leading export. In 1738, Lewis Paul and John Wyatt, of Birmingham, England, patented the roller spinning machine, as well as the flyer-and-bobbin system for drawing cotton to a more even thickness using two sets of rollers that traveled at different speeds. Later, the invention of the James Hargreaves' spinning jenny in 1764, Richard Arkwright's spinning frame in 1769 and Samuel Crompton's spinning mule in 1775 enabled British spinners to produce cotton yarn at much higher rates. From the late 18th century on, the British city of Manchester acquired the nickname "Cottonopolis" due to the cotton industry's omnipresence within the city, and Manchester's role as the heart of the global cotton trade.
Production capacity in Britain and the United States was improved by the invention of the cotton gin by the American Eli Whitney in 1793. Before the development of cotton gins, the cotton fibers had to be pulled from the seeds tediously by hand. By the late 1700s a number of crude ginning machines had been developed. However, to produce a bale of cotton required over 600 hours of human labor, making large-scale production uneconomical in the United States, even with the use of humans as slave labor. The gin that Whitney manufactured (the Holmes design) reduced the hours down to just a dozen or so per bale. Although Whitney patented his own design for a cotton gin, he manufactured a prior design from Henry Odgen Holmes, for which Holmes filed a patent in 1796. Improving technology and increasing control of world markets allowed British traders to develop a commercial chain in which raw cotton fibers were (at first) purchased from colonial plantations, processed into cotton cloth in the mills of Lancashire, and then exported on British ships to captive colonial markets in West Africa, India, and China (via Shanghai and Hong Kong).
By the 1840s, India was no longer capable of supplying the vast quantities of cotton fibers needed by mechanized British factories, while shipping bulky, low-price cotton from India to Britain was time-consuming and expensive. This, coupled with the emergence of American cotton as a superior type (due to the longer, stronger fibers of the two domesticated native American species, "Gossypium hirsutum" and "Gossypium barbadense"), encouraged British traders to purchase cotton from plantations in the United States and plantations in the Caribbean. By the mid-19th century, "King Cotton" had become the backbone of the southern American economy. In the United States, cultivating and harvesting cotton became the leading occupation of slaves.
During the American Civil War, American cotton exports slumped due to a Union blockade on Southern ports, and also because of a strategic decision by the Confederate government to cut exports, hoping to force Britain to recognize the Confederacy or enter the war. This prompted the main purchasers of cotton, Britain and France, to turn to Egyptian cotton. British and French traders invested heavily in cotton plantations. The Egyptian government of Viceroy Isma'il took out substantial loans from European bankers and stock exchanges. After the American Civil War ended in 1865, British and French traders abandoned Egyptian cotton and returned to cheap American exports, sending Egypt into a deficit spiral that led to the country declaring bankruptcy in 1876, a key factor behind Egypt's occupation by the British Empire in 1882.
During this time, cotton cultivation in the British Empire, especially India, greatly increased to replace the lost production of the American South. Through tariffs and other restrictions, the British government discouraged the production of cotton cloth in India; rather, the raw fiber was sent to England for processing. The Indian Mahatma Gandhi described the process:
In the United States, Southern cotton provided capital for the continuing development of the North. The cotton produced by enslaved African Americans not only helped the South, but also enriched Northern merchants. Much of the Southern cotton was trans-shipped through northern ports.
Cotton remained a key crop in the Southern economy after emancipation and the end of the Civil War in 1865. Across the South, sharecropping evolved, in which free black farmers and landless white farmers worked on white-owned cotton plantations of the wealthy in return for a share of the profits. Cotton plantations required vast labor forces to hand-pick cotton.
It was not until the 1950s that reliable harvesting machinery was introduced (prior to this, cotton-harvesting machinery had been too clumsy to pick cotton without shredding the fibers). During the first half of the 20th century, employment in the cotton industry fell, as machines began to replace laborers and the South's rural labor force dwindled during the World Wars.
Cotton remains a major export of the southern United States, and a majority of the world's annual cotton crop is of the long-staple American variety.
Cultivation.
Successful cultivation of cotton requires a long frost-free period, plenty of sunshine, and a moderate rainfall, usually from 600 to. Soils usually need to be fairly heavy, although the level of nutrients does not need to be exceptional. In general, these conditions are met within the seasonally dry tropics and subtropics in the Northern and Southern hemispheres, but a large proportion of the cotton grown today is cultivated in areas with less rainfall that obtain the water from irrigation. Production of the crop for a given year usually starts soon after harvesting the preceding autumn. Cotton is naturally a perennial but is grown as an annual to help control pests.Planting time in spring in the Northern hemisphere varies from the beginning of February to the beginning of June. The area of the United States known as the South Plains is the largest contiguous cotton-growing region in the world. While dryland (non-irrigated) cotton is successfully grown in this region, consistent yields are only produced with heavy reliance on irrigation water drawn from the Ogallala Aquifer.
Since cotton is somewhat salt and drought tolerant, this makes it an attractive crop for arid and semiarid regions. As water resources get tighter around the world, economies that rely on it face difficulties and conflict, as well as potential environmental problems. For example, improper cropping and irrigation practices have led to desertification in areas of Uzbekistan, where cotton is a major export. In the days of the Soviet Union, the Aral Sea was tapped for agricultural irrigation, largely of cotton, and now salination is widespread.
Cotton can also be cultivated to have colors other than the yellowish off-white typical of modern commercial cotton fibers. Naturally colored cotton can come in red, green, and several shades of brown.
Genetic modification.
Genetically modified (GM) cotton was developed to reduce the heavy reliance on pesticides. The bacterium "Bacillus thuringiensis" (Bt) naturally produces a chemical harmful only to a small fraction of insects, most notably the larvae of moths and butterflies, beetles, and flies, and harmless to other forms of life. The gene coding for Bt toxin has been inserted into cotton, causing cotton, called Bt cotton, to produce this natural insecticide in its tissues. In many regions, the main pests in commercial cotton are lepidopteran larvae, which are killed by the Bt protein in the transgenic cotton they eat. This eliminates the need to use large amounts of broad-spectrum insecticides to kill lepidopteran pests (some of which have developed pyrethroid resistance). This spares natural insect predators in the farm ecology and further contributes to noninsecticide pest management.
But Bt cotton is ineffective against many cotton pests, however, such as plant bugs, stink bugs, and aphids; depending on circumstances it may still be desirable to use insecticides against these. A 2006 study done by Cornell researchers, the Center for Chinese Agricultural Policy and the Chinese Academy of Science on Bt cotton farming in China found that after seven years these secondary pests that were normally controlled by pesticide had increased, necessitating the use of pesticides at similar levels to non-Bt cotton and causing less profit for farmers because of the extra expense of GM seeds. However, a 2009 study by the Chinese Academy of Sciences, Stanford University and Rutgers University refuted this. They concluded that the GM cotton effectively controlled bollworm. The secondary pests were mostly miridae (plant bugs) whose increase was related to local temperature and rainfall and only continued to increase in half the villages studied. Moreover, the increase in insecticide use for the control of these secondary insects was far smaller than the reduction in total insecticide use due to Bt cotton adoption. A 2012 Chinese study concluded that Bt cotton halved the use of pesticides and doubled the level of ladybirds, lacewings and spiders. The International Service for the Acquisition of Agri-biotech Applications (ISAAA) said that, worldwide, GM cotton was planted on an area of 25 million hectares in 2011. This was 69% of the worldwide total area planted in cotton.
GM cotton acreage in India grew at a rapid rate, increasing from 50,000 hectares in 2002 to 10.6 million hectares in 2011. The total cotton area in India was 12.1 million hectares in 2011, so GM cotton was grown on 88% of the cotton area. This made India the country with the largest area of GM cotton in the world. A long-term study on the economic impacts of Bt cotton in India, published in the Journal PNAS in 2012, showed that Bt cotton has increased yields, profits, and living standards of smallholder farmers. The U.S. GM cotton crop was 4.0 million hectares in 2011 the second largest area in the world, the Chinese GM cotton crop was third largest by area with 3.9 million hectares and Pakistan had the fourth largest GM cotton crop area of 2.6 million hectares in 2011. The initial introduction of GM cotton proved to be a success in Australia – the yields were equivalent to the non-transgenic varieties and the crop used much less pesticide to produce (85% reduction). The subsequent introduction of a second variety of GM cotton led to increases in GM cotton production until 95% of the Australian cotton crop was GM in 2009 making Australia the country with the fifth largest GM cotton crop in the world. Other GM cotton growing countries in 2011 were Argentina, Myanmar, Burkina Faso, Brazil, Mexico, Colombia, South Africa and Costa Rica.
Cotton has been genetically modified for resistance to glyphosate a broad-spectrum herbicide discovered by Monsanto which also sells some of the Bt cotton seeds to farmers. There are also a number of other cotton seed companies selling GM cotton around the world. About 62% of the GM cotton grown from 1996 to 2011 was insect resistant, 24% stacked product and 14% herbicide resistant.
Cotton has gossypol, a toxin that makes it inedible. However, scientists have silenced the gene that produces the toxin, making it a potential food crop.
Organic production.
Organic cotton is generally understood as cotton from plants not genetically modified and that is certified to be grown without the use of any synthetic agricultural chemicals, such as fertilizers or pesticides. Its production also promotes and enhances biodiversity and biological cycles. United States cotton plantations are required to enforce the National Organic Program (NOP). This institution determines the allowed practices for pest control, growing, fertilizing, and handling of organic crops. As of 2007, 265,517 bales of organic cotton were produced in 24 countries, and worldwide production was growing at a rate of more than 50% per year.
Pests and weeds.
The cotton industry relies heavily on chemicals, such as herbicides, fertilizers and insecticides, although a very small number of farmers are moving toward an organic model of production, and organic cotton products are now available for purchase at limited locations. These are popular for baby clothes and diapers. Under most definitions, organic products do not use genetic engineering. All natural cotton products are known to be both sustainable and hypoallergenic.
Historically, in North America, one of the most economically destructive pests in cotton production has been the boll weevil. Due to the US Department of Agriculture's highly successful Boll Weevil Eradication Program (BWEP), this pest has been eliminated from cotton in most of the United States. This program, along with the introduction of genetically engineered Bt cotton (which contains a bacterial gene that codes for a plant-produced protein that is toxic to a number of pests such as cotton bollworm and pink bollworm), has allowed a reduction in the use of synthetic insecticides.
Other significant global pests of cotton include the pink bollworm, "Pectinophora gossypiella"; the chili thrips, "Scirtothrips dorsalis"; the cotton seed bug, "Oxycarenus hyalinipennis"; the tarnish plant bug, "Lygus lineolaris"; and the fall armyworm, "Spodoptera frugiperda", "Xanthomonas citri subsp. malvacearum".
Harvesting.
Most cotton in the United States, Europe, and Australia is harvested mechanically, either by a cotton picker, a machine that removes the cotton from the boll without damaging the cotton plant, or by a cotton stripper, which strips the entire boll off the plant. Cotton strippers are used in regions where it is too windy to grow picker varieties of cotton, and usually after application of a chemical defoliant or the natural defoliation that occurs after a freeze. Cotton is a perennial crop in the tropics, and without defoliation or freezing, the plant will continue to grow.
Cotton continues to be picked by hand in developing countries.
Competition from synthetic fibers.
The era of manufactured fibers began with the development of rayon in France in the 1890s. Rayon is derived from a natural cellulose and cannot be considered synthetic, but requires extensive processing in a manufacturing process, and led the less expensive replacement of more naturally derived materials. A succession of new synthetic fibers were introduced by the chemicals industry in the following decades. Acetate in fiber form was developed in 1924. Nylon, the first fiber synthesized entirely from petrochemicals, was introduced as a sewing thread by DuPont in 1936, followed by DuPont's acrylic in 1944. Some garments were created from fabrics based on these fibers, such as women's hosiery from nylon, but it was not until the introduction of polyester into the fiber marketplace in the early 1950s that the market for cotton came under threat. The rapid uptake of polyester garments in the 1960s caused economic hardship in cotton-exporting economies, especially in Central American countries, such as Nicaragua, where cotton production had boomed tenfold between 1950 and 1965 with the advent of cheap chemical pesticides. Cotton production recovered in the 1970s, but crashed to pre-1960 levels in the early 1990s.
Beginning as a self-help program in the mid-1960s, the Cotton Research and Promotion Program (CRPP) was organized by U.S. cotton producers in response to cotton's steady decline in market share. At that time, producers voted to set up a per-bale assessment system to fund the program, with built-in safeguards to protect their investments. With the passage of the Cotton Research and Promotion Act of 1966, the program joined forces and began battling synthetic competitors and re-establishing markets for cotton. Today, the success of this program has made cotton the best-selling fiber in the U.S. and one of the best-selling fibers in the world.
Administered by the Cotton Board and conducted by Cotton Incorporated, the CRPP works to greatly increase the demand for and profitability of cotton through various research and promotion activities. It is funded by U.S. cotton producers and importers.
Uses.
Cotton is used to make a number of textile products. These include terrycloth for highly absorbent bath towels and robes; denim for blue jeans; cambric, popularly used in the manufacture of blue work shirts (from which we get the term "blue-collar"); and corduroy, seersucker, and cotton twill. Socks, underwear, and most T-shirts are made from cotton. Bed sheets often are made from cotton. Cotton also is used to make yarn used in crochet and knitting. Fabric also can be made from recycled or recovered cotton that otherwise would be thrown away during the spinning, weaving, or cutting process. While many fabrics are made completely of cotton, some materials blend cotton with other fibers, including rayon and synthetic fibers such as polyester. It can either be used in knitted or woven fabrics, as it can be blended with elastine to make a stretchier thread for knitted fabrics, and apparel such as stretch jeans.
In addition to the textile industry, cotton is used in fishing nets, coffee filters, tents, explosives manufacture (see nitrocellulose), cotton paper, and in bookbinding. The first Chinese paper was made of cotton fiber. Fire hoses were once made of cotton.
The cottonseed which remains after the cotton is ginned is used to produce cottonseed oil, which, after refining, can be consumed by humans like any other vegetable oil. The cottonseed meal that is left generally is fed to ruminant livestock; the gossypol remaining in the meal is toxic to monogastric animals. Cottonseed hulls can be added to dairy cattle rations for roughage. During the American slavery period, cotton root bark was used in folk remedies as an abortifacient, that is, to induce a miscarriage. Gossypol was one of the many substances found in all parts of the cotton plant and it was described by the scientists as 'poisonous pigment'. It also appears to inhibit the development of sperm or even restrict the mobility of the sperm. Also, it is thought to interfere with the menstrual cycle by restricting the release of certain hormones.
Cotton linters are fine, silky fibers which adhere to the seeds of the cotton plant after ginning. These curly fibers typically are less than 1/8 in long. The term also may apply to the longer textile fiber staple lint as well as the shorter fuzzy fibers from some upland species. Linters are traditionally used in the manufacture of paper and as a raw material in the manufacture of cellulose. In the UK, linters are referred to as "cotton wool". This can also be a refined product ("absorbent cotton" in U.S. usage) which has medical, cosmetic and many other practical uses. The first medical use of cotton wool was by Sampson Gamgee at the Queen's Hospital (later the General Hospital) in Birmingham, England.
Shiny cotton is a processed version of the fiber that can be made into cloth resembling satin for shirts and suits. However, it is hydrophobic (does not absorb water easily), which makes it unfit for use in bath and dish towels (although examples of these made from shiny cotton are seen).
The name Egyptian cotton is broadly associated with quality products, however only a small percentage of Egyptian cotton production is actually of superior quality. Most products bearing the name are not made with the finest cottons from Egypt.
Pima cotton is often compared to Egyptian cotton, as both are used in high quality bed sheets and other cotton products. It is considered the next best quality after high quality Egyptian cotton by some authorities. Pima cotton is grown in the American southwest. Not all products bearing the Pima name are made with the finest cotton. The Pima name is now used by cotton-producing nations such as Peru, Australia and Israel.
International trade.
The largest producers of cotton, currently (2009), are China and India, with annual production of about 34 million bales and 27 million bales, respectively; most of this production is consumed by their respective textile industries. The largest exporters of raw cotton are the United States, with sales of $4.9 billion, and Africa, with sales of $2.1 billion. The total international trade is estimated to be $12 billion. Africa's share of the cotton trade has doubled since 1980. Neither area has a significant domestic textile industry, textile manufacturing having moved to developing nations in Eastern and South Asia such as India and China. In Africa, cotton is grown by numerous small holders. Dunavant Enterprises, based in Memphis, Tennessee, is the leading cotton broker in Africa, with hundreds of purchasing agents. It operates cotton gins in Uganda, Mozambique, and Zambia. In Zambia, it often offers loans for seed and expenses to the 180,000 small farmers who grow cotton for it, as well as advice on farming methods. Cargill also purchases cotton in Africa for export.
The 25,000 cotton growers in the United States of America are heavily subsidized at the rate of $2 billion per year although China now provides the highest overall level of cotton sector support. The future of these subsidies is uncertain and has led to anticipatory expansion of cotton brokers' operations in Africa. Dunavant expanded in Africa by buying out local operations. This is only possible in former British colonies and Mozambique; former French colonies continue to maintain tight monopolies, inherited from their former colonialist masters, on cotton purchases at low fixed prices.
Leading producer countries.
The five leading exporters of cotton in 2011 are (1) the United States, (2) India, (3) Brazil, (4) Australia, and (5) Uzbekistan. The largest nonproducing importers are Korea, Taiwan, Russia, and Japan.
In India, the states of Maharashtra (26.63%), Gujarat (17.96%) and Andhra Pradesh (13.75%) and also Madhya Pradesh are the leading cotton producing states, these states have a predominantly tropical wet and dry climate.
In Pakistan, cotton is grown predominantly in the provinces of Punjab, and Sindh. The leading area of cotton production is the south Punjab, comprising the areas around Rahim Yar Khan, Bahawalpur, Bahawalnagar, Multan, Dera Ghazi Khan, Muzaffargarh, Vehari, and Khanewal. In Sindh Sanghar is the most important cotton producing district. Faisalabad is a leader in textiles within Pakistan. Punjab has a tropical wet and dry climate throughout the year therefore enhancing the growth of cotton.
In the United States, the state of Texas led in total production as of 2004, while the state of California had the highest yield per acre.
Fair trade.
Cotton is an enormously important commodity throughout the world. However, many farmers in developing countries receive a low price for their produce, or find it difficult to compete with developed countries.
This has led to an international dispute (see United States – Brazil cotton dispute):
On 27 September 2002, Brazil requested consultations with the US regarding prohibited and actionable subsidies provided to US producers, users and/or exporters of upland cotton, as well as legislation, regulations, statutory instruments and amendments thereto providing such subsidies (including export credits), grants, and any other assistance to the US producers, users and exporters of upland cotton.
On 8 September 2004, the Panel Report recommended that the United States "withdraw" export credit guarantees and payments to domestic users and exporters, and "take appropriate steps to remove the adverse effects or withdraw" the mandatory price-contingent subsidy measures.
While Brazil was fighting the US through the WTO's Dispute Settlement Mechanism against a heavily subsidized cotton industry, a group of four least-developed African countries – Benin, Burkina Faso, Chad, and Mali – also known as "Cotton-4" have been the leading protagonist for the reduction of US cotton subsidies through negotiations. The four introduced a "Sectoral Initiative in Favour of Cotton", presented by Burkina Faso's President Blaise Compaoré during the Trade Negotiations Committee on 10 June 2003.
In addition to concerns over subsidies, the cotton industries of some countries are criticized for employing child labor and damaging workers' health by exposure to pesticides used in production. The Environmental Justice Foundation has campaigned against the prevalent use of forced child and adult labor in cotton production in Uzbekistan, the world's third largest cotton exporter. The international production and trade situation has led to "fair trade" cotton clothing and footwear, joining a rapidly growing market for organic clothing, fair fashion or "ethical fashion". The fair trade system was initiated in 2005 with producers from Cameroon, Mali and Senegal.
Trade.
Cotton is bought and sold by investors and price speculators as a tradable commodity on 2 different stock exchanges in the United States of America.
Critical temperatures.
A temperature range of 25 to is the optimal range for mold development. At temperatures below 0 °C, rotting of wet cotton stops. Damaged cotton is sometimes stored at these temperatures to prevent further deterioration.
Fiber properties.
The chemical composition of cotton is as follows:
Cotton genome.
A public genome sequencing effort of cotton was initiated in 2007 by a consortium of public researchers. They agreed on a strategy to sequence the genome of cultivated, tetraploid cotton. "Tetraploid" means that cultivated cotton actually has two separate genomes within its nucleus, referred to as the A and D genomes. The sequencing consortium first agreed to sequence the D-genome relative of cultivated cotton ("G. raimondii", a wild Central American cotton species) because of its small size and limited number of repetitive elements. It is nearly one-third the number of bases of tetraploid cotton (AD), and each chromosome is only present once. The A genome of "G. arboreum" would be sequenced next. Its genome is roughly twice the size of "G. raimondii"'s. Part of the difference in size between the two genomes is the amplification of "retrotransposons" (GORGE). Once both diploid genomes are assembled, then research could begin sequencing the actual genomes of cultivated cotton varieties. This strategy is out of necessity; if one were to sequence the tetraploid genome without model diploid genomes, the euchromatic DNA sequences of the AD genomes would co-assemble and the repetitive elements of AD genomes would assembly independently into A and D sequences respectively. Then there would be no way to untangle the mess of AD sequences without comparing them to their diploid counterparts.
The public sector effort continues with the goal to create a high-quality, draft genome sequence from reads generated by all sources. The public-sector effort has generated Sanger reads of BACs, fosmids, and plasmids as well as 454 reads. These later types of reads will be instrumental in assembling an initial draft of the D genome. In 2010, two companies (Monsanto and Illumina), completed enough Illumina sequencing to cover the D genome of "G. raimondii" about 50x. They announced that they would donate their raw reads to the public. This public relations effort gave them some recognition for sequencing the cotton genome. Once the D genome is assembled from all of this raw material, it will undoubtedly assist in the assembly of the AD genomes of cultivated varieties of cotton, but a lot of hard work remains.

</doc>
<doc id="36807" url="http://en.wikipedia.org/wiki?curid=36807" title="Football Hall of Fame">
Football Hall of Fame

A Football Hall of Fame may refer to:

</doc>
<doc id="36808" url="http://en.wikipedia.org/wiki?curid=36808" title="Heart">
Heart

The heart is a muscular organ in humans and other animals, which pumps blood through the blood vessels of the circulatory system. Blood provides the body with oxygen and nutrients, and also assists in the removal of metabolic wastes. The heart is located in the middle compartment of the mediastinum in the chest.
In humans, other mammals and birds the heart is divided into four chambers: upper left and right atria; and lower left and right ventricles. Commonly the right atrium and ventricle are referred together as the "right heart" and their left counterparts as the "left heart". Fish in contrast have two chambers, an atrium and a ventricle, while reptiles have three chambers. In a healthy heart blood flows one way through the heart due to heart valves, which prevent backflow. The heart is enclosed in a protective sac, the pericardium, which also contains a small amount of fluid. The wall of the heart is made up of three layers: epicardium, myocardium, and endocardium.
The heart pumps blood through both circulatory systems. Blood low in oxygen from the systemic circulation enters the right atrium from the superior and inferior vena cavae and passes to the right ventricle. From here it is pumped into the pulmonary circulation, through the lungs where it receives oxygen and gives off carbon dioxide. Oxygenated blood then returns to the left atrium, passes through the left ventricle and is pumped out through the aorta to the systemic circulation−where the oxygen is used and metabolized to carbon dioxide. In addition the blood carries nutrients from the liver and gastrointestinal tract to various organs of the body, while transporting waste to the liver and kidneys. Normally with each heartbeat, the right ventricle pumps the same amount of blood into the lungs as the left ventricle pumps out into the body. Veins transport blood to the heart, while arteries transport blood away from the heart. Arteries always carries oxygenated blood except the pulmonary artery while Veins always carries deoxygenated blood except the pulmonary vein. Veins normally have lower pressures than arteries. The heart contracts at a rate of around 72 beats per minute, at rest. Exercise temporarily increases this rate, but lowers resting heart rate in the long term, and is good for heart health.
Cardiovascular diseases (CVD) were the most common cause of death globally in 2008, accounting for 30% of cases. Of these deaths more than three quarters were due to coronary artery disease and stroke. Risk factors include: smoking, being overweight, not enough exercise, high cholesterol, high blood pressure, and poorly controlled diabetes among others. Diagnosis of CVD is often done by listening to the heart-sounds with a stethoscope, ECG or by ultrasound. Diseases of the heart are primarily treated by cardiologists, although many specialties of medicine may be involved.
Structure.
The heart is situated in the middle of the mediastinum behind the breastbone in the chest, at the level of thoracic vertebrae T5-T8. The largest part of the heart is usually slightly offset to the left (though occasionally it may be offset to the right) and is felt to be on the left because the left heart is stronger, since it pumps to all body parts. The left lung in turn is smaller than the right lung because it has to accommodate the heart.
The heart is supplied by the coronary circulation and is enclosed in a double-membraned sac–the pericardium. This attaches to the mediastinum, providing anchorage for the heart. The back surface of the heart lies near to the vertebral column, and the front surface sits deep to the sternum and costal cartilages. Two of the great veins – the venae cavae, and the great arteries, the aorta and pulmonary artery, are attached to the upper part of the heart, called the base, which is located at the level of the third costal cartilage. The lower tip of the heart, the apex, lies just to the left of the sternum between the junction of the fourth and fifth ribs near their articulation with the costal cartilages. The right side of the heart is deflected forwards, and the left deflected to the back.
The heart is cone-shaped, with its base positioned upwards and tapering down to the apex. A stethoscope can be placed directly over the apex so that the beats can be counted. An adult heart has a mass of 250–350 grams (9–12 oz). The heart is typically the size of a fist: 12 cm (5 in) in length, 8 cm (3.5 in) wide, and 6 cm (2.5 in) in thickness. Well-trained athletes can have much larger hearts due to the effects of exercise on the heart muscle, similar to the response of skeletal muscle.
Heart wall.
The heart wall is made up of the inner endocardium, middle myocardium and outer epicardium. These are surrounded by a double-membraned sac called the pericardium.
The innermost layer of the heart is called the endocardium. It is made up of a lining of simple squamous epithelium, and covers heart chambers and valves. It is continuous with the endothelium of the veins and arteries of the heart, and is joined to the myocardium with a thin layer of connective tissue.The endocardium, by secreting endothelins, may also play a role in regulating the contraction of the myocardium. 
The middle layer of the heart wall is the myocardium, which is a layer of involuntary striated muscle tissue surrounded by a framework of collagen. It is also supplied with blood vessels, and nerve fibers by way of the epicardium that help to regulate the heartrate.
The pericardium surrounds the heart. It consists of two membranes: an inner serous membrane called the epicardium, and an outer fibrous membrane. These enclose the pericardial cavity. The pericardial cavity contains fluid which lubricates the surface of the heart.
Chambers.
The heart has four chambers, two upper atria, the receiving chambers, and two lower ventricles, the discharging chambers. The atria are connected to the ventricles by the atrioventricular valves and separated from the ventricles by the coronary sulcus. There is an ear-shaped structure in the upper right atrium called the right atrial appendage, or auricle, and another in the upper left atrium, the left atrial appendage. The right atrium and the right ventricle together are sometimes referred to as the "right heart" and this sometimes includes the pulmonary artery. Similarly, the left atrium and the left ventricle together are sometimes referred to as the "left heart". The ventricles are separated by the anterior longitudinal sulcus and the posterior interventricular sulcus.
The cardiac skeleton is made of dense connective tissue and this gives structure to the heart. It forms the atrioventricular septum which separates the atria from the ventricles, and the fibrous rings which serve as bases for the four heart valves. The cardiac skeleton also provides an important boundary in the heart’s electrical conduction system since collagen cannot conduct electricity. The interatrial septum separates the atria and the interventricular septum separates the ventricles. The interventricular septum is much thicker than the interatrial septum, since the ventricles need to generate greater pressure when they contract.
Valves.
All four heart valves lie along the same plane. The valves ensure unidirectional blood flow through the heart and prevent backflow. Between the right atrium and the right ventricle is the tricuspid valve. This consists of three cusps (flaps or leaflets), made of endocardium reinforced with additional connective tissue. Each of the three valve-cusps is attached to several strands of connective tissue, the chordae tendineae (tendinous cords), sometimes referred to as the "heart strings". They are composed of approximately 80 percent collagenous fibers with the remainder consisting of elastic fibers and endothelium. They connect each of the cusps to a papillary muscle that extends from the lower ventricular surface. These muscles control the opening and closing of the valves. The three papillary muscles in the right ventricle are called the anterior, posterior, and septal muscles, which correspond to the three positions of the valve cusps.
Between the left atrium and left ventricle is the mitral valve, also known as the bicuspid valve due to its having two cusps, an anterior and a posterior medial cusp. These cusps are also attached via chordae tendinae to two papillary muscles projecting from the ventricular wall.
The tricuspid and the mitral valves are the atrioventricular valves. During the relaxation phase of the cardiac cycle, the papillary muscles are also relaxed and the tension on the chordae tendineae is slight. However, as the ventricle contracts, so do the papillary muscles. This creates tension on the chordae tendineae, helping to hold the cusps of the atrioventricular valves in place and preventing them from being blown back into the atria.
The semilunar pulmonary valve is located at the base of the pulmonary artery. This has three cusps which are not attached to any papillary muscles. When the ventricle relaxes blood flows back into the ventricle from the artery and this flow of blood fills the pocket-like valve, pressing against the cusps which close to seal the valve. The semilunar aortic valve is at the base of the aorta and also is not attached to papillary muscles. This too has three cusps which close with the pressure of the blood flowing back from the aorta.
Right heart.
The two major systemic veins, the superior and inferior venae cavae, and the collection of veins that make up the coronary sinus which drains the myocardium, empty into the right atrium. The superior vena cava drains blood from above the diaphragm and empties into the upper back part of the right atrium. The inferior vena cava drains the blood from below the diaphragm and empties into the back part of the atrium below the opening for the superior vena cava. Immediately above and to the middle of the opening of the inferior vena cava is the opening of the thin-walled coronary sinus.
In the wall of the right atrium is an oval-shaped depression known as the fossa ovalis, which is a remnant of an opening in the fetal heart known as the foramen ovale. The foramen ovale allowed blood in the fetal heart to pass directly from the right atrium to the left atrium, allowing some blood to bypass the pulmonary circuit. Within seconds after birth, a flap of tissue known as the septum primum that previously acted as a valve closes the foramen ovale and establishes the typical cardiac circulation pattern. Most of the internal surface of the right atrium is smooth, the depression of the fossa ovalis is medial, and the anterior surface has prominent ridges of pectinate muscles, which are also present in the right atrial appendage.
The atria receive venous blood on a nearly continuous basis, preventing venous flow from stopping while the ventricles are contracting. While most ventricular filling occurs while the atria are relaxed, they do demonstrate a contractile phase when they actively pump blood into the ventricles just prior to ventricular contraction. The right atrium is connected to the right ventricle by the tricuspid valve.
When the myocardium of the ventricle contracts, pressure within the ventricular chamber rises. Blood, like any fluid, flows from higher pressure to lower pressure areas, in this case, toward the pulmonary artery and the atrium. To prevent any potential backflow, the papillary muscles also contract, generating tension on the chordae tendineae. This prevents the flaps of the valves from being forced into the atria and regurgitation of the blood back into the atria during ventricular contraction.
The walls of the right ventricle are lined with trabeculae carneae, ridges of cardiac muscle covered by endocardium. In addition to these muscular ridges, a band of cardiac muscle, also covered by endocardium, known as the moderator band reinforces the thin walls of the right ventricle and plays a crucial role in cardiac conduction. It arises from the lower part of the interventricular septum and crosses the interior space of the right ventricle to connect with the inferior papillary muscle.
When the right ventricle contracts, it ejects blood into the pulmonary artery, which branches into the left and right pulmonary arteries that carry it to each lung. The upper surface of the right ventricle begins to taper as it approaches the pulmonary artery. At the base of the pulmonary artery is the pulmonary semilunar valve that prevents backflow from the pulmonary artery.
Left heart.
After gas exchange in the pulmonary capillaries, blood returns to the left atrium high in oxygen via one of the four pulmonary veins. Only the left atrial appendage contains pectinate muscles. Blood flows nearly continuously from the pulmonary veins back into the atrium, which acts as the receiving chamber, and from here through an opening into the left ventricle. Most blood flows passively into the heart while both the atria and ventricles are relaxed, but toward the end of the ventricular relaxation period, the left atrium will contract, pumping blood into the ventricle. This atrial contraction accounts for approximately 20 percent of ventricular filling. The left atrium is connected to the left ventricle by the mitral valve.
Although both sides of the heart will pump the same amount of blood, the muscular layer is much thicker in the left ventricle compared to the right, due to the greater force needed here. Like the right ventricle, the left also has trabeculae carneae, but there is no moderator band. The left ventricle is the major pumping chamber for the systemic circuit; it ejects blood into the aorta through the aortic semilunar valve.
Cardiac muscle.
Cardiac muscle tissue has autorhythmicity, the unique ability to initiate a cardiac action potential at a fixed rate – spreading the impulse rapidly from cell to cell to trigger the contraction of the entire heart. This autorhythmicity is still modulated by the endocrine and nervous systems.
There are two types of cardiac muscle cell: cardiomyocytes which have the ability to contract easily, and modified cardiomyocytes the pacemaker cells of the conducting system. The cardiomyocytes make up the bulk (99%) of cells in the atria and ventricles. These contractile cells respond to impulses of action potential from the pacemaker cells and are responsible for the contractions that pump blood through the body. The pacemaker cells make up just (1% of cells) and form the conduction system of the heart. They are generally much smaller than the contractile cells and have few of the myofibrils or myofilaments which means that have limited contractibility. Their function is similar in many respects to neurons.
It is the contraction of the myocardium that pumps blood through the heart and into the major arteries. The muscle pattern is elegant and complex, as the muscle cells swirl and spiral around the chambers of the heart. They form a figure 8 pattern around the atria and around the bases of the great vessels. Deeper ventricular muscles also form a figure 8 around the two ventricles and proceed toward the apex. More superficial layers of ventricular muscle wrap around both ventricles. This complex swirling pattern allows the heart to pump blood more effectively than a simple linear pattern would.
As with skeletal muscles the heart can increase in size and efficiency with exercise. Thus endurance athletes such as marathon runners may have a heart that has hypertrophied by up to 40%.
Coronary circulation.
Cardiomyocytes like all other cells need to be supplied with oxygen, nutrients and a way of removing metabolic wastes. This is achieved by the coronary circulation. The coronary circulation cycles in peaks and troughs relating to the heart muscle relaxing or contracting.
Coronary arteries supply blood to the heart and the coronary veins remove the deoxygenated blood. There is a left and a right coronary artery supplying the left and right hearts respectively, and the septa. Smaller branches of these arteries anastomose, which in other parts of the body serve to divert blood due to a blockage. In the heart these are very small and cannot form other interconnections with the result that a coronary artery blockage can cause a myocardial infarction and with it, tissue damage.
The great cardiac vein receives the major branches of the posterior, middle, and small cardiac veins and drains into the coronary sinus a large vein that empties into the right atrium. The anterior cardiac veins drain the front of the right ventricle and drain directly into the right atrium.
Development.
The heart is the first functional organ to develop and starts to beat and pump blood at about three weeks into embryogenesis. This early start is crucial for subsequent embryonic and prenatal development.
The heart derives from splanchnopleuric mesenchyme in the neural plate which forms the cardiogenic region. Two endocardial tubes form here that fuse to form a primitive heart tube known as the tubular heart. Between the third and fourth week, the heart tube lengthens, and begins to fold to form an S-shape within the pericardium. This places the chambers and major vessels into the correct alignment for the developed heart. Further development will include the septa and valves formation and remodelling of the heart chambers. By the end of the fifth week the septa are complete and the heart valves are completed by the ninth week.
The embryonic heart begins beating at around 22 days after conception (5 weeks after the last normal menstrual period, LMP). It starts to beat at a rate near to the mother’s which is about 75–80 beats per minute (bpm). The embryonic heart rate then accelerates and reaches a peak rate of 165–185 bpm early in the early 7th week (early 9th week after the LMP).<ref name="DuBose, Miller , Moutos /us/cotm/0001/ehr2000"></ref> After 9 weeks (start of the fetal stage) it starts to decelerate, slowing to around 145 (±25) bpm at birth. There is no difference in female and male heart rates before birth.
Physiology.
Blood flow.
The heart functions as a pump in the circulatory system to provide a continuous circulation of blood throughout the body. This circulation includes the systemic circulation and the pulmonary circulation of the lungs. Blood in the pulmonary circulation collects oxygen from the lungs and delivers carbon dioxide for exhalation. Blood in the systemic circuit transports oxygen to the body and returns relatively deoxygenated blood and carbon dioxide to the lungs.
Blood flows through the heart in one direction, from the atria to the venricles, and to either the pulmonary circulation by the pulmonary artery on the right side, or the systemic circulation by the aorta on the left side. Blood is prevented from flowing backwards (regurgitation) by the heart valves.
The right heart collects deoxygenated blood from two large veins, the superior and inferior venae cavae. The blood collects in the right atrium and is pumped through the tricuspid valve into the right ventricle, where it is pumped into the pulmonary artery through the pulmonary valve. Here the blood enters the pulmonary circulation where carbon dioxide can be exchanged for oxygen in the lungs. This happens through the passive process of diffusion.
In the left heart, oxygenated blood is returned to the left atrium via the pulmonary vein. It is then pumped into the left ventricle through the bicuspid valve and into the aorta for systemic circulation. The aorta is a large artery that branches into many smaller arteries, arterioles, and ultimately capillaries. In the capillaries, oxygen and nutrients from blood are supplied to body cells for metabolism, and exchanged for carbon dioxide and waste products
Cardiac cycle.
The cardiac cycle refers to a complete heartbeat which includes systole and diastole and the intervening pause. The cycle begins with contraction of the atria and ends with relaxation of the ventricles. Systole is when the ventricles of the heart contract to pump blood to the body. Diastole is when the ventricles relax and fill with blood. The atria and ventricles work in concert, so in systole when the ventricles are contracting, the atria are relaxed and collecting blood. When the ventricles are relaxed in diastole, the atria contract to pump blood to the ventricles. This coordination ensures blood is pumped efficiently to the body.
At the beginning of the cardiac cycle, in early diastole, both the atria and ventricles are relaxed. Since blood moves from areas of high pressure to areas of low pressure, when the chambers are relaxed, blood will flow into the atria (through the coronary sinus and the pulmonary veins). As the atria begin to fill, the pressure will rise so that the blood will move from the atria into the ventricles. In late diastole the atria contract pumping more blood into the ventricles. This causes a rise in pressure in the ventricles, and in ventricular systole blood will be pumped into the pulmonary artery. 
When the atrioventricular valves (tricuspid and mitral) are open, during blood flow to the ventricles, the semilunar valves are closed to prevent backflow into the ventricles. When the ventricular pressure is greater than the atrial pressure the tricuspid and mitral valves will shut. When the ventricles contract the pressure forces the semilunar aortic and pulmonary valves open. As the ventricles relax the semilunar valves will close in response to decreased pressure.
Cardiac output.
Cardiac output (CO) is a measurement of the amount of blood pumped by each ventricle in one minute. To calculate this, multiply the amount pumped out by each ventricle, the stroke volume (SV), by the heart rate (HR), in beats per minute. Cardiac output can be represented by the equation: CO = HR x SV
The average cardiac output, using an average SV of about 70mL, is 5.25 L/min, with a range of 4.0–8.0 L/min. The stroke volume is normally measured using an echocardiogram and can be influenced by the size of the heart, physical and mental condition of the individual, sex, contractility, duration of contraction, preload and afterload.
Preload refers to how much blood is in the ventricles at the end of diastole, at their most full. A main factor is how long it takes the ventricles to fill—if the ventricles contract faster, then there is less time to fill and the preload will be less. Preload can also be affected by a person's hydration status. . It is important because of the Frank-Starling mechanism. This states that the force of contraction is directly proportional to the initial length of muscle fiber. This means that a ventricle will contract more forcefully when it is stretched more.
Afterload, or how much blood is left in the ventricles after systole, is influenced by the resistance of the vascular system. This tension is called afterload. It can be influenced by narrowing of the heart valves (stenosis) or contraction or relaxation of the peripheral blood vessels.
The ability of the heart muscle to contract controls the stroke volume. It can be influenced by inotropes, which are called positive or negative depending on their ability to cause stronger or weaker contractions, respectively. Examples include stimulation by the sympathetic nerves (the "fight or flight" response) which will increase contractility, or the parasympathetic nervous system via the vagus nerve, which will decrease the heart rate. Other things that increase contractility ("positive inotropes") include drugs such as Digoxin and high blood calcium. Things that decrease contractility ("negative inotropes") include drugs such as beta blockers and calcium channel blockers, hypoxia, acidosis, and high blood potassium.
Electrical conduction.
The normal rhythmical heart beat, called sinus rhythm, is established by the sinoatrial node, the heart's pacemaker. Here an electrical signal is created that travels through the heart, causing the heart muscle to contract.
The sinoatrial node is found in the coronary sinus of the right atrium. The electrical signal generated by the sinoatrial node travels through the right atrium in a radial way that is not completely understood. It travels to the left atrium via Bachmann's bundle, such that both left and right atrium contract together. The signal then travels to the atrioventricular node. This is found at the bottom of the right atrium in the atrioventricular septum–the boundary between the right atrium and the left ventricle. The septum is part of the cardiac skeleton, tissue within the heart that the electrical signal cannot pass through, which forces the signal to pass through the atrioventricular node only. The signal then travels along the Bundle of His to left and right bundle branches through to the ventricles of the heart. In the ventricles the signal is carried by specialized tissue called the Purkinje fibers which then transmit the electric charge to the cardiac muscle.
Heart rate.
The resting heart rate of a newborn can be 120 beats per minute (bpm) and this gradually decreases until maturity and then gradually increases again with age. The adult resting heart rate ranges from 60 to 100 bpm. Exercise and fitness levels, age and basal metabolic rate can all affect the heart rate. An athlete’s heart rate can be lower than 60bpm. During exercise the rate can be 150bpm with maximum rates reaching from 200 and 220 bpm. 
Creation.
The sinoatrial node create and sustains its own rhythm. Cells in the sinoatrial node do this by creating an action potential. The cardiac action potential is created by the movement of specific electrolytes into and out of the pacemaker cells. The action potential then spreads to nearby cells. 
When the sinoatrial cells are resting, they have a negative charge on their membranes. However a rapid influx of sodium ions causes the membrane's charge to become positive. This is called depolarisation and occurs spontaneously. Once the cell has a sufficiently high charge, the sodium channels close and calcium ions then begin to enter the cell, shortly after which potassium begins to leave it. All the ions travel through ion channels in the membrane of the sinoatrial cells. The potassium and calcium only start to move out of and into the cell once it has a sufficiently high charge, and so are called voltage-gated. Shortly after this, the calcium channels close and potassium channels open, allowing potassium to leave the cell. This causes the cell to have a negative resting charge and is called repolarization. When the membrane potential reaches approximately −60 mV, the potassium channels close and the process may begin again.
The ions move from areas where they are concentrated to where they are not. For this reason sodium moves into the cell from outside, and potassium moves from within the cell to outside the cell. Calcium also plays a critical role. Their influx through slow channels means that the sinoatrial cells have a prolonged "pleateau" phase when they have a positive charge. A part of this is called the absolute refractory period. Calcium ions also combine with the regulatory protein troponin C in the troponin complex to enable contraction of the cardiac muscle, and separate from the protein to allow relaxation.
Influences.
The normal sinus rhythm of the heart is influenced by several factors. The resting heart rate is influenced by the central nervous system through sympathetic and parasympathetic nerves from two paired cardiovascular centres in the medulla. The parasympathetic nervous system acts by the vagus nerve to decrease heart rate, and the sympathetic nerve system by the sympathetic trunk to increase heart rate. These intermingle in the cardiac plexus near the base of the heart. Normally the parasympathetic stimulation predominates to decrease the heart rate. Without parasympathetic input, the sinoatrial node would beat at approximately 100 bpm.
The sympathetic nerves arise from the sympathetic trunk along the neck and through the T1-T4 ganglia and travel to both the sinoatrial and atrioventricular, as well as the atria and ventricles. The ventricles are more richly innervated by sympathetic fibers than parasympathetic fibers. Sympathetic stimulation causes the release of the neurotransmitter norepinephrine (also known as noradrenaline) at the neuromuscular junction of the cardiac nerves. This shortens the repolarization period, thus speeding the rate of depolarization and contraction, which results in an increased heartrate. It opens chemical or ligand-gated sodium and calcium ion channels, allowing an influx of positively charged ions. Norepinephrine binds to the beta–1 receptor. High blood pressure medications are used to block these receptors and so reduce the heart rate.
The cardiovascular centres receive input from a series of receptors including proprioreceptors, baroreceptors, and chemoreceptors, plus stimuli from the limbic system. Through a series of reflexes these help regulate and sustain blood flow. For example, increased physical activity results in increased rates of firing by various proprioreceptors located in muscles, joint capsules, and tendons. With increased rates of firing, the parasympathetic stimulation may decrease or sympathetic stimulation may increase as needed in order to increase blood flow.
Similarly, baroreceptors are stretch receptors located in the aortic sinus, carotid bodies, the venae cavae, and other locations, including pulmonary vessels and the right side of the heart itself. Rates of firing from the baroreceptors represent blood pressure, level of physical activity, and the relative distribution of blood. The cardiac centers monitor baroreceptor firing to maintain cardiac homeostasis, a mechanism called the baroreceptor reflex. With increased pressure and stretch, the rate of baroreceptor firing increases, and the cardiac centers decrease sympathetic stimulation and increase parasympathetic stimulation. As pressure and stretch decrease, the rate of baroreceptor firing decreases, and the cardiac centers increase sympathetic stimulation and decrease parasympathetic stimulation.
There is a similar reflex, called the atrial reflex or Bainbridge reflex, associated with varying rates of blood flow to the atria. Increased venous return stretches the walls of the atria where specialized baroreceptors are located. However, as the atrial baroreceptors increase their rate of firing and as they stretch due to the increased blood pressure, the cardiac center responds by increasing sympathetic stimulation and inhibiting parasympathetic stimulation to increase HR. The opposite is also true.
In addition to the autonomic nervous system, other factors can impact on this. These include epinephrine, norepinephrine, and thyroid hormones; levels of various ions including calcium, potassium, and sodium; body temperature; hypoxia; and pH balance. Factors that increase the heart rate can include release of norepinephrine, hypoxemia, low blood pressure and dehydration, a strong emotional response, a higher body temperature, and metabolic and hormonal factors such as a low potassium or sodium level or stimulus from thyroid hormones. Decreased body temperature, relaxation, and metabolic factors can also contribute to a decrease in heart rate.
Heart sounds.
One of the simplest methods of assessing the heart's condition is to listen to it using a stethoscope. In a healthy heart, there are only two audible heart sounds, called S1 and S2. The first heart sound S1, is the sound created by the closing of the atrioventricular valves during ventricular contraction and is normally described as "lub". The second heart sound, S2, is the sound of the semilunar valves closing during ventricular diastole and is described as "dub". Each sound consists of two components, reflecting the slight difference in time as the two valves close. S2 may split into two distinct sounds, either as a result of inspiration or different valvular or cardiac problems. Additional heart sounds may also be present and these give rise to gallop rhythms. A third heart sound, S3 usually indicates an increase in ventricular blood volume. A fourth heart sound S4 is referred to as an atrial gallop and is produced by the sound of blood being forced into a stiff ventricle. The combined presence of S3 and S4 give a quadruple gallop.
Heart murmurs are abnormal heart sounds which can be either pathological or benign.One example of a murmur is Still's murmur, which presents a musical sound in children, has no symptoms and disappears in adolescence.
A different type of sound, a pericardial friction rub can be heard in cases of pericarditis where the inflamed membranes can rub together.
Clinical significance.
Being such a complex organ the heart is prone to several cardiovascular diseases some becoming more prevalent with ageing. Heart disease is a major cause of death, accounting for an average of 30% of all deaths in 2008, globally. This rate varies from a lower 28% to a high 40% in high-income countries. Doctors that specialise in the heart are called cardiologists. Many other medical professionals are involved in treating diseases of the heart, including doctors such as general practitioners, cardiothoracic surgeons and intensivists, and allied health practitioners including physiotherapists and dieticians.
Obesity, high blood pressure, and high cholesterol can all increase the risk of developing heart disease. However, half the number of heart attacks occur in people with normal cholesterol levels. It is generally accepted that factors such as exercise or the lack of it, good or poor diet, and overall well-being (including emotional), affect heart health. Exercise results in the addition of protein myofilaments and this can result in hypertrophy where the size of individual cells are increased but not their number. This is a condition known as athletic heart syndrome. The hearts of athletes can pump more efficiently at lower heart rates. However, enlarged hearts can have a pathological cause such as hypertrophic cardiomyopathy, which can result in a heart of 1000 g (2 lb) in mass. The cause of an abnormally enlarged heart muscle is unknown, but the condition is often undiagnosed and can cause sudden death in young athletes.
Coronary artery disease is also known as ischemic heart disease, and atherosclerotic disease and is the most common form of heart disease. The underlying mechanism of this disease is atherosclerosis–a build-up of plaque along the inner walls of the arteries which narrows them, reducing the blood flow to the heart. It is the leading cause of heart attacks and the most common cause of death, globally. It is also the main cause of angina.
Cardiomyopathy and most commonly dilated cardiomyopathy, is a noticeable deterioration of the heart muscle's ability to contract, which can lead to heart failure.Other common causes of heart failure (which can also be congestive), are heart attacks, valve disorders and high blood pressure. This happens happens when the heart is pumping insufficiently and cannot meet the body's blood flow demands. Because the heart is a double pump, each side can fail independently of the other, resulting in heart failure of the right heart or the left heart, either of which through causing strain in the other side can result in the failure of the whole heart. Congestive heart failure results in blood backing up in the systemic circulation. Edema (swelling) of the feet, ankles and fingers is the most noticeable symptom. Pulmonary congestion results from left heart failure. The right side of the heart continues to propel blood to the lungs, but the left side is unable to pump the returning blood into the systemic circulation. As blood vessels within the lungs become swollen with blood, the pressure within them increases, and fluid leaks from the circulation into the lung tissue, causing pulmonary edema. If untreated, the person will suffocate because they are drowning in their own blood.
Heart murmurs are abnormal heart sounds which can be either pathological or benign and there are several kinds. Murmurs are graded by volume, from 1) the quietest, to 6) the loudest, and evaluated by their relationship to the heart sounds and position in the cardiac cycle. Phonocardiograms can record these sounds. Murmurs can result from valvular heart diseases due to narrowing (stenosis), regurgitation or insufficiency of any of the main heart valves but they can also result from a number of other disorders, including atrial and ventricular septal defects.
Abnormalities in the sinus rhythm can prevent the heart from effectively pumping blood and cause both atrial and ventricular fibrillation. Examples of cardiac dysrhythmias are a very rapid heart rate (tachycardia) and a very slow heart rate (brachycardia). Tachycardia is generally defined as a heart rate faster than 100 beats per minute, and bradycardia as a heart rate slower than 60. Asystole is the cessation of heart rhythm which results in cardiac arrest. 
Cardiac tamponade, also known as pericardial tamponade, is the condition of an abnormal build-up of fluid in the pericardium which can adversely affect the function of the heart. The fluid can be removed from the pericardial sac using a syringe in a procedure called pericardiocentesis.
Carditis is inflammation of the heart; this can be specific to regions as in pericarditis, myocarditis, and endocarditis or it can be of the whole heart known as pancarditis.
Assessment.
Examination.
The cardiac examination includes inspection, palpation and auscultation.
Electrocardiogram.
Using surface electrodes on the body, it is possible to record the complex electrical activity of the heart. This tracing of the electrical signal is the electrocardiogram (ECG) or (EKG). An ECG clearly shows normal and abnormal heart function and is an indispensable diagnostic tool.
There are five prominent points on the ECG: the P wave (atrial depolarisation), the QRS complex (atrial repolarisation and ventricular depolarisation) and the T wave (ventricular repolarisation).
Imaging.
Several imaging methods can be used to assess the anatomy and function of the heart, including ultrasound, angiography, PET, CT and MRI. Ultrasound of the heart is called echocardiography. It is used to measure the heart's function, assess for disease of the valves of the heart, and look for any anatomical abnormalities. Echocardiography can be conducted by a probe on the chest ("transthoracic") or by a probe in the esophagus ("transoesophageal"). A typical echocardiography report will include information about the volumes at the end of systole and diastole, how wide the valves are (checking for stenosis), whether there is any backflow of blood through the valves (regurgitation), and an ejection fraction, which describes how much blood is ejected from the left and right ventricles after systole. Ejection fractions range from approximately 55 to 70 percent, with a mean of 58 percent.
Stress tests.
A cardiac stress test uses exercise or drugs to stimulate the heart and provoke a measurable response to the stress in order to gauge the heart's effectiveness.
Treatment.
Angiogenesis represents a therapeutic target for cardiovascular disease.
Defibrillation is used to treat serious arrhythmias. Artificial pacemakers used to regulate the heartbeat can also incorporate a defibrillator.
Surgery.
Coronary artery bypass surgery to improve the blood supply to the heart is often the only treatment option for coronary heart disease.
Heart valve repair or valve replacement are options for valvular heart disease.
History.
Ancient.
The valves of the heart were discovered by a physician of the Hippocratean school around the 4th century BC, although their function was not fully understood. On dissection, arteries are typically empty of blood because blood pools in the veins after death. It was subsequently assumed they were filled with air and served to transport air around the body.
Philosophers distinguished veins from arteries, but thought the pulse was a property of arteries. Erasistratos observed that arteries cut during life bleed. He ascribed the fact to the phenomenon that air escaping from an artery is replaced with blood which entered by very small vessels between veins and arteries. Thus he apparently postulated capillaries, but with reversed flow of blood.
The Greek physician Galen (2nd century AD) knew blood vessels carried blood and identified venous (dark red) and arterial (brighter and thinner) blood, each with distinct and separate functions. Growth and energy were derived from venous blood created in the liver from chyle, while arterial blood gave vitality by containing pneuma (air) and originated in the heart. Blood flowed from both creating organs to all parts of the body, where it was consumed and there was no return of blood to the heart or liver. The heart did not pump blood around, the heart's motion sucked blood in during diastole and the blood moved by the pulsation of the arteries themselves.
Galen believed the arterial blood was created by venous blood passing from the left ventricle to the right through 'pores' in the interventricular septum, while air passed from the lungs via the pulmonary artery to the left side of the heart. As the arterial blood was created, "sooty" vapors were created and passed to the lungs, also via the pulmonary artery, to be exhaled.
Pre-modern.
The earliest descriptions of the coronary and pulmonary circulation systems can be found in the "Commentary on Anatomy in Avicenna's Canon", published in 1242 by Ibn al-Nafis. In his manuscript, al-Nafis wrote that blood passes through the pulmonary circulation instead of moving from the right to the left ventricle as previously believed by Galen. His work was later translated into Latin by Andrea Alpago.
In Europe, the teachings of Galen continued to dominate the academic community and his doctrines were adopted as the official canon of the Church. Andreas Vesalius questioned some of Galen's beliefs of the heart in "De humani corporis fabrica" (1543), but his magnum opus was interpreted as a challenge to the authorities and he was subjected to a number of attacks. Michael Servetus wrote in "Christianismi Restitutio" (1553) that blood flows from one side of the heart to the other via the lungs.
Modern.
The breakthrough came with the publication of "De Motu Cordis" (1628) by the English physician William Harvey. Harvey's book completely describes the systemic circulation and the mechanical force of the heart, leading to an overhaul of the Galenic doctrines. Otto Frank (1865–1944) was a German physiologist; among his many published works are detailed studies of this important heart relationship. Ernest Starling (1866–1927) was an important English physiologist who also studied the heart. Although they worked largely independently, their combined efforts and similar conclusions have been recognized in the name "Frank–Starling mechanism."
Although Purkinje fibers and the bundle of His were discovered as early as the 19th century, their specific role in the electrical conduction system of the heart remained unknown until Sunao Tawara published his monograph, titled "Das Reizleitungssystem des Säugetierherzens", in 1906. Tawara's discovery of the atrioventricular node prompted Arthur Keith and Martin Flack to look for similar structures in the heart, leading to their discovery of the sinoatrial node several months later. These structures form the anatomical basis of the electrocardiogram, whose inventor, Willem Einthoven, was awarded the Nobel Prize in Medicine or Physiology in 1924.
The first successful heart transplantation was performed in 1967 by the South African surgeon Christiaan Barnard at Groote Schuur Hospital in Cape Town. This marked an important milestone in cardiac surgery, capturing the attention of both the medical profession and the world at large. However, long-term survival rates of patients were initially very low. Louis Washkansky, the first recipient of a donated heart, died 18 days after the operation while other patients did not survive for more than a few weeks. The American surgeon Norman Shumway has been credited for his efforts to improve transplantation techniques, along with pioneers Richard Lower, Vladimir Demikhov and Adrian Kantrowitz. As of March 2000, more than 55,000 heart transplantations have been performed worldwide.
By the middle of the 20th century, heart disease had surpassed infectious disease as the leading cause of death in the United States, and it is currently the leading cause of deaths worldwide. Since 1948, the ongoing Framingham Heart Study has shed light on the effects of various influences on the heart, including diet, exercise, and common medications such as aspirin. Although the introduction of ACE inhibitors and beta blockers has improved the management of chronic heart failure, the disease continues to be an enormous medical and societal burden, with 30 to 40% of patients dying within a year of receiving the diagnosis.
Society and culture.
Symbolism.
As one of the vital organs, the heart was long identified as the center of the entire body, the seat of life, or emotion, or reason, will, intellect, purpose or the mind. Thus, in the Hebrew Bible, the word for "heart" לָבַב "lebab" is used in these meanings (paralleling the use of "φρήν" "diaphragm" in Homeric Greek).
An important part of the concept of the soul in Ancient Egyptian religion was thought to be the heart, or "ib". The "ib" or metaphysical heart was believed to be formed from one drop of blood from the child's mother's heart, taken at conception. To ancient Egyptians, the heart was the seat of emotion, thought, will, and intention. This is evidenced by Egyptian expressions which incorporate the word "ib", such as "Awt-ib" for "happiness" (literally, "wideness of heart"), "Xak-ib" for "estranged" (literally, "truncated of heart"). In Egyptian religion, the heart was the key to the afterlife. It was conceived as surviving death in the nether world, where it gave evidence for, or against, its possessor. It was thought that the heart was examined by Anubis and the deities during the "Weighing of the Heart" ceremony. If the heart weighed more than the "feather of Maat", it was immediately consumed by the monster Ammit.
The Chinese character for "heart", 心, derives from a comparatively realistic depiction of a heart (indicating the heart chambers) in seal script. The Chinese word "xīn" also takes the metaphorical meanings of "mind, intelligence", "soul", or "center, core". In Chinese medicine, the heart is seen as the center of 神 "shén" "spirit, soul, consciousness".
The Sanskrit word for heart, hRd (हृद्), dates at least as far back as the Rigveda and is a cognate of the word for heart in Greek, Latin, and English. The same word is used to mean "mind" or "soul" depending on the context.
Many classical philosophers and scientists, including Aristotle, considered the heart the seat of thought, reason, or emotion, often disregarding the brain as contributing to those functions. The identification of the heart as the seat of emotions in particular is due to the Roman physician Galen, who also located the seat of the passions in the liver, and the seat of reason in the brain. However these "emotional properties" of the heart were later discovered to be solely centered in the brain. This tradition influenced the development of the medieval Christian devotion to the Sacred Heart of Jesus and the Immaculate Heart of Mary.
The idiomatic expression of "pierced" or "broken" hearts ultimately derive from devotional Christianity, where the hearts of Mary or Jesus are depicted as suffering various tortures (symbolizing the pain suffered by Christ for the sins of the world, and the pain of Mary at the crucifixion of her son, respectively), but from an early time the metaphor was transferred to unfulfilled romantic love, in late medieval literature dealing with the ideals of courtly love. The notion of "Cupid's arrows" is ancient, due to Ovid, but while Ovid describes Cupid as wounding his victims with his arrows, it is not made explicit that it is the "heart" that is wounded. The familiar iconography of Cupid shooting little heart symbols is Baroque.
Food.
Animal hearts are widely consumed as food. As they are almost entirely muscle, they are high in protein. They are often included in dishes with other offal, for example in the pan-Ottoman kokoretsi.
Chicken hearts are considered to be giblets, and are often grilled on skewers: Japanese "hāto yakitori", Brazilian "churrasco de curacao", Indonesian chicken heart satay. They can also be pan-fried, as in Jerusalem mixed grill. In Egyptian cuisine, they can be used, finely chopped, as part of stuffing for chicken. Many recipes combined them with other giblets, such as the Mexican "pollo en menudencias" and the Russian "ragu iz kurinyikh potrokhov".
The hearts of beef, pork, and mutton can generally be interchanged in recipes. As heart is a hard-working muscle, it makes for "firm and rather dry" meat, so is generally slow-cooked. Another way of dealing with toughness is to julienne the meat, as in Chinese stir-fried heart.
Beef heart may be grilled or braised. In the Peruvian "anticuchos de corazón", barbecued beef hearts are grilled after being tenderized through long marination in a spice and vinegar mixture. An Australian recipe for "mock goose" is actually braised stuffed beef heart.
Pig heart is stewed, poached, braised, or made into sausage. The Balinese "oret" is a sort of blood sausage made with pig heart and blood. A French recipe for "cœur de porc à l'orange" is made of braised heart with an orange sauce.
Other animals.
The structure of the heart can vary among the different animal species. Cephalopods have two "gill hearts" also known as branchial hearts and one "systemic heart". The vertebrate heart lies in the front (ventral) part of the body cavity, dorsal to the gut. It is always surrounded by a pericardium, which is usually a distinct structure, but may be continuous with the peritoneum in jawless and cartilaginous fish.
The SA node is found in all amniotes but not in more primitive vertebrates. In these animals, the muscles of the heart are relatively continuous and the sinus venosus coordinates the beat which passes in a wave through the remaining chambers. Indeed, since the sinus venosus is incorporated into the right atrium in amniotes, it is likely homologous with the SA node. In teleosts, with their vestigial sinus venosus, the main centre of coordination is, instead, in the atrium. The rate of heartbeat varies enormously between different species, ranging from around 20 beats per minute in codfish to around 600 in hummingbirds and up to 1200 bpm in the ruby-throated hummingbird.
Double circulatory systems.
In the heart of lungfish, the septum extends part-way into the ventricle. This allows for some degree of separation between the de-oxygenated bloodstream destined for the lungs and the oxygenated stream that is delivered to the rest of the body. The absence of such a division in living amphibian species may be partly due to the amount of respiration that occurs through the skin; thus, the blood returned to the heart through the vena cavae is already partially oxygenated. As a result, there may be less need for a finer division between the two bloodstreams than in lungfish or other tetrapods. Nonetheless, in at least some species of amphibian, the spongy nature of the ventricle does seem to maintain more of a separation between the bloodstreams. Also, the original valves of the conus arteriosus have been replaced by a spiral valve that divides it into two parallel parts, thereby helping to keep the two bloodstreams separate.
Adult amphibians and most reptiles have a double circulatory system but the heart is not separated into two pumps. The development of the double system is necessitated by the presence of lungs which deliver oxygenated blood directly to the heart.
In amphibians, the atrium is divided into two chambers by a muscular septum but there is only one ventricle. The sinus venosus, which remains large, connects only to the right atrium and receives blood from the venae cavae, with the pulmonary vein by-passing it to enter the left atrium.
The heart of most reptiles is similar in structure to that of lungfish but the septum is generally much larger. This divides the ventricle into two halves but the septum does not reach the whole length of the heart and there is a considerable gap near the pulmonary artery and aorta openings. In most reptilian species, there appears to be little, if any, mixing between the bloodstreams, so the aorta receives, essentially, only oxygenated blood.
The fully divided heart.
Archosaurs (crocodilians and birds) and mammals show complete separation of the heart into two pumps for a total of four heart chambers; it is thought that the four-chambered heart of archosaurs evolved independently from that of mammals. In crocodilians, there is a small opening, the foramen of Panizza, at the base of the arterial trunks and there is some degree of mixing between the blood in each side of the heart, during a dive underwater; thus, only in birds and mammals are the two streams of blood – those to the pulmonary and systemic circulations – permanently kept entirely separate by a physical barrier.
Fish.
Primitive fish have a four-chambered heart, but the chambers are arranged sequentially so that this primitive heart is quite unlike the four-chambered hearts of mammals and birds. The first chamber is the sinus venosus, which collects deoxygenated blood, from the body, through the hepatic and cardinal veins. From here, blood flows into the atrium and then to the powerful muscular ventricle where the main pumping action will take place. The fourth and final chamber is the conus arteriosus which contains several valves and sends blood to the "ventral aorta". The ventral aorta delivers blood to the gills where it is oxygenated and flows, through the dorsal aorta, into the rest of the body. (In tetrapods, the ventral aorta has divided in two; one half forms the ascending aorta, while the other forms the pulmonary artery).
In the adult fish, the four chambers are not arranged in a straight row but, instead form an S-shape with the latter two chambers lying above the former two. This relatively simpler pattern is found in cartilaginous fish and in the ray-finned fish. In teleosts, the conus arteriosus is very small and can more accurately be described as part of the aorta rather than of the heart proper. The conus arteriosus is not present in any amniotes, presumably having been absorbed into the ventricles over the course of evolution. Similarly, while the sinus venosus is present as a vestigial structure in some reptiles and birds, it is otherwise absorbed into the right atrium and is no longer distinguishable.
Invertebrates.
Arthropods have an open circulatory system, and often some short open-ended arteries.The arthropod heart is typically a muscular tube that runs the length of the body, under the back and from the base of the head. Instead of blood the circulatory fluid is haemolymph which carries the most commonly used respiratory pigment, copper-based haemocyanin as the oxygen transporter; iron-based haemoglobin is used by only a few arthropods. The heart contracts in ripples from the rear to the front of the animal transporting water and nutrients. Pairs of valves run alongside the heart, allowing fluid to enter whilst preventing backflow.
In insects, the circulatory system is not used to transport oxygen and so is much reduced, having no veins or arteries and consisting of a single perforated tube running dorsally which pumps peristaltically. The simpler unsegmented invertebrates have no body cavity, and oxygen and nutrients pass through their bodies by diffusion.
References.
"This article incorporates text from the CC-BY book: .."

</doc>
<doc id="36811" url="http://en.wikipedia.org/wiki?curid=36811" title="Subset sum problem">
Subset sum problem

In computer science, the subset sum problem is an important problem in complexity theory and cryptography. The problem is this: given a set (or multiset) of integers, is there a non-empty subset whose sum is zero? For example, given the set {−7, −3, −2, 5, 8}, the answer is "yes" because the subset {−3, −2, 5} sums to zero. The problem is NP-complete.
An equivalent problem is this: given a set of integers and an integer "s", does any non-empty subset sum to "s"? Subset sum can also be thought of as a special case of the knapsack problem. One interesting special case of subset sum is the partition problem, in which "s" is half of the sum of all elements in the set.
Complexity.
The complexity of the subset sum problem can be viewed as depending on two parameters, "N", the number of decision variables, and "P", the precision of the problem (stated as the number of binary place values that it takes to state the problem). (Note: here the letters "N" and "P" mean something different from what they mean in the NP class of problems.)
The complexity of the best known algorithms is exponential in the smaller of the two parameters "N" and "P". Thus, the problem is most difficult if "N" and "P" are of the same order. It only becomes easy if either "N" or "P" becomes very small.
If "N" (the number of variables) is small, then an exhaustive search for the solution is practical. If "P" (the number of place values) is a small fixed number, then there are dynamic programming algorithms that can solve it exactly.
Efficient algorithms for both small "N" and small "P" cases are given below.
Exponential time algorithm.
There are several ways to solve subset sum in time exponential in "N". The most naïve algorithm would be to cycle through all subsets of N numbers and, for every one of them, check if the subset sums to the right number. The running time is of order "O"(2"N""N"), since there are 2"N" subsets and, to check each subset, we need to sum at most "N" elements.
A better exponential time algorithm is known which runs in time "O"(2"N"/2). The algorithm splits arbitrarily the "N" elements into two sets of "N"/2 each. For each of these two sets, it stores a list of the sums of all 2"N"/2 possible subsets of its elements. Each of these two lists is then sorted. Using a standard comparison sorting algorithm for this step would take time "O"(2"N"/2"N"). However, given a sorted list of sums for "k" elements, the list can be expanded to two sorted lists with the introduction of a ("k" + 1)st element, and these two sorted lists can be merged in time "O"(2"k"). Thus, each list can be generated in sorted form in time "O"(2"N"/2). Given the two sorted lists, the algorithm can check if an element of the first array and an element of the second array sum up to "s" in time "O"(2"N"/2). To do that, the algorithm passes through the first array in decreasing order (starting at the largest element) and the second array in increasing order (starting at the smallest element). Whenever the sum of the current element in the first array and the current element in the second array is more than "s", the algorithm moves to the next element in the first array. If it is less than "s", the algorithm moves to the next element in the second array. If two elements with sum "s" are found, it stops. Horowitz and Sahni first published this algorithm in a technical report in 1972.
Pseudo-polynomial time dynamic programming solution.
The problem can be solved in pseudo-polynomial time using dynamic programming. Suppose the sequence is 
and we wish to determine if there is a nonempty subset which sums to zero. Define the boolean-valued function "Q"("i","s") to be the value (true or false) of 
Thus, the solution to the problem is the value of "Q"("N",0).
Let "A" be the sum of the negative values and "B" the sum of the positive values. Clearly, if "s" < "A" or "s" > "B" so these values do not need to be stored or computed. Create an array to hold the values "Q"("i","s") for 1 ≤ "i" ≤ "N" and "A" ≤ "s" ≤ "B".
The array can now be filled in using a simple recursion. Initially, for "A" ≤ "s" ≤ "B", set
Then, for "i" = 2, …, "N", set
For each assignment, the values of "Q" on the right side are already known, either because they were stored in the table for the previous value of "i" or because "Q"("i" − 1,"s" − "xi") = false if "s" − "xi" < "A" or "s" − "xi" > "B". Therefore, the total number of arithmetic operations is "O"("N"("B" − "A")). For example, if all the values are "O"("Nk") for some "k", then the time required is "O"("N""k"+2).
This algorithm is easily modified to return the subset with sum 0 if there is one.
This solution does not count as polynomial time in complexity theory because "B" − "A" is not polynomial in the "size" of the problem, which is the number of bits used to represent it. This algorithm is polynomial in the values of "A" and "B", which are exponential in their numbers of bits.
For the case that each "xi" is positive and bounded by a fixed constant "C", found a linear time algorithm having time complexity "O"("NC"). (Note that this is for the version of the problem where the target sum is not necessarily zero, otherwise the problem would be trivial.)
Polynomial time approximate algorithm.
An approximate version of the subset sum would be: given a set of "N" numbers "x"1, "x"2, ..., "xN" and a number "s", output
If all numbers are non-negative, the approximate subset sum is solvable in time polynomial in "N" and 1/"c".
The solution for subset sum also provides the solution for the original subset sum problem in the case where the numbers are small (again, for nonnegative numbers). If any sum of the numbers can be specified with at most "P" bits, then solving the problem approximately with is equivalent to solving it exactly. Then, the polynomial time algorithm for approximate subset sum becomes an exact algorithm with running time polynomial in "N" and 2"P" (i.e., exponential in "P").
The algorithm for the approximate subset sum problem is as follows:
 initialize a list "S" to contain one element 0.
 for each "i" from 1 to "N" do
 let "T" be a list consisting of "xi" + "y", for all "y" in "S"
 let "U" be the union of "T" and "S"
 sort "U"
 make "S" empty 
 let "y" be the smallest element of "U" 
 add "y" to "S" 
 for each element "z" of "U" in increasing order do
 //trim the list by eliminating numbers close to one another
 //and throw out elements greater than "s"
 if "y" + "cs"/"N" < "z" ≤ "s", set "y" = "z" and add "z" to "S" 
 if "S" contains a number between (1 − "c")"s" and "s", output "yes", otherwise "no"
The algorithm is polynomial time because the lists "S", "T" and "U" always remain of size polynomial in "N" and 1/"c" and, as long as they are of polynomial size, all operations on them can be done in polynomial time. The size of lists is kept polynomial by the trimming step, in which we only include a number "z" into "S" if it is greater than the previous one by "cs"/"N" and not greater than "s".
This step ensures that each element in "S" is smaller than the next one by at least "cs"/"N" and do not contain elements greater than "s". Any list with that property consists of no more than "N"/"c" elements.
The algorithm is correct because each step introduces an additive error of at most "cs"/"N" and "N" steps together introduce the error of at most "cs".

</doc>
<doc id="36812" url="http://en.wikipedia.org/wiki?curid=36812" title="Pericles">
Pericles

Pericles (; Greek: Περικλῆς "Periklēs", ] in Classical Attic; c. 495 – 429 BC) was arguably the most prominent and influential Greek statesman, orator and general of Athens during the Golden Age— specifically the time between the Persian and Peloponnesian wars. He was descended, through his mother, from the powerful and historically influential Alcmaeonid family.
Pericles had such a profound influence on Athenian society that Thucydides, a contemporary historian, acclaimed him as "the first citizen of Athens". Pericles turned the Delian League into an Athenian empire, and led his countrymen during the first two years of the Peloponnesian War. The period during which he led Athens, roughly from 461 to 429 BC, is sometimes known as the "Age of Pericles", though the period thus denoted can include times as early as the Persian Wars, or as late as the next century.
Pericles promoted the arts and literature; it is principally through his efforts that Athens holds the reputation of being the educational and cultural center of the ancient Greek world. He started an ambitious project that generated most of the surviving structures on the Acropolis (including the Parthenon). This project beautified and protected the city, exhibited its glory, and gave work to the people. Pericles also fostered Athenian democracy to such an extent that critics call him a populist.
Early years.
Pericles was born c. 495 BC, in the deme of Cholargos just north of Athens.α[›] He was the son of the politician Xanthippus, who, though ostracized in 485–484 BC, returned to Athens to command the Athenian contingent in the Greek victory at Mycale just five years later. Pericles' mother, Agariste, a member of the powerful and controversial noble family of the Alcmaeonidae, and her familial connections played a crucial role in kickstarting Xanthippus' political career. Agariste was the great-granddaughter of the tyrant of Sicyon, Cleisthenes, and the niece of the Athenian reformer Cleisthenes.β[›]
According to Herodotus and Plutarch, Agariste dreamed, a few nights before Pericles' birth, that she had borne a lion. Interestingly, legends say that Philip II of Macedon had a similar dream before the birth of his son, Alexander the Great. One interpretation of the dream treats the lion as a traditional symbol of greatness, but the story may also allude to the unusually large size of Pericles' skull, which became a popular target of contemporary comedians (who called him "Squill-head", after the Squill or Sea-Onion). (Although Plutarch claims that this deformity was the reason that Pericles was always depicted wearing a helmet, this is not the case; the helmet was actually the symbol of his official rank as strategos (general).
Pericles belonged to the tribe of Acamantis ("Ἀκαμαντὶς φυλή"). His early years were quiet; the introverted young Pericles avoided public appearances, instead preferring to devote his time to his studies.
His family's nobility and wealth allowed him to fully pursue his inclination toward education. He learned music from the masters of the time (Damon or Pythocleides could have been his teacher) and he is considered to have been the first politician to attribute importance to philosophy. He enjoyed the company of the philosophers Protagoras, Zeno of Elea, and Anaxagoras. Anaxagoras, in particular, became a close friend and influenced him greatly.
Pericles' manner of thought and rhetorical charisma may have been in part products of Anaxagoras' emphasis on emotional calm in the face of trouble and skepticism about divine phenomena. His proverbial calmness and self-control are also often regarded as products of Anaxagoras' influence.
Political career until 431 BC.
Entering politics.
In the spring of 472 BC, Pericles presented "The Persians" of Aeschylus at the Greater Dionysia as a liturgy, demonstrating that he was one of the wealthier men of Athens. Simon Hornblower has argued that Pericles' selection of this play, which presents a nostalgic picture of Themistocles' famous victory at Salamis, shows that the young politician was supporting Themistocles against his political opponent Cimon, whose faction succeeded in having Themistocles ostracized shortly afterwards.
Plutarch says that Pericles stood first among the Athenians for forty years. If this was so, Pericles must have taken up a position of leadership by the early 460s BC- in his early or mid-thirties. Throughout these years he endeavored to protect his privacy and to present himself as a model for his fellow citizens. For example, he would often avoid banquets, trying to be frugal.
In 463 BC, Pericles was the leading prosecutor of Cimon, the leader of the conservative faction who was accused of neglecting Athens' vital interests in Macedon. Although Cimon was acquitted, this confrontation proved that Pericles' major political opponent was vulnerable.
Ostracizing Cimon.
Around 461 BC, the leadership of the democratic party decided it was time to take aim at the Areopagus, a traditional council controlled by the Athenian aristocracy, which had once been the most powerful body in the state. The leader of the party and mentor of Pericles, Ephialtes, proposed a reduction of the Areopagus' powers. The Ecclesia (the Athenian Assembly) adopted Ephialtes' proposal without opposition. This reform signaled the beginning of a new era of "radical democracy".
The democratic party gradually became dominant in Athenian politics, and Pericles seemed willing to follow a populist policy in order to cajole the public. According to Aristotle, Pericles' stance can be explained by the fact that his principal political opponent, Cimon, was both rich and generous, and was able to gain public favor by lavishly handing out portions of his sizable personal fortune. The historian Loren J. Samons II argues, however, that Pericles had enough resources to make a political mark by private means, had he so chosen.
In 461 BC, Pericles achieved the political elimination of this opponent using ostracism. The accusation was that Cimon betrayed his city by aiding Sparta.
After Cimon's ostracism, Pericles continued to promote a populist social policy. He first proposed a decree that permitted the poor to watch theatrical plays without paying, with the state covering the cost of their admission. With other decrees he lowered the property requirement for the archonship in 458–457 BC and bestowed generous wages on all citizens who served as jurymen in the Heliaia (the supreme court of Athens) some time just after 454 BC. His most controversial measure, however, was a law of 451 BC limiting Athenian citizenship to those of Athenian parentage on both sides.
Such measures impelled Pericles' critics to hold him responsible for the gradual degeneration of the Athenian democracy. Constantine Paparrigopoulos, a major modern Greek historian, argues that Pericles sought for the expansion and stabilization of all democratic institutions. Hence, he enacted legislation granting the lower classes access to the political system and the public offices, from which they had previously been barred.
According to Samons, Pericles believed that it was necessary to raise the demos, in which he saw an untapped source of Athenian power and the crucial element of Athenian military dominance. (The fleet, backbone of Athenian power since the days of Themistocles, was manned almost entirely by members of the lower classes.)
Cimon, on the other hand, apparently believed that no further free space for democratic evolution existed. He was certain that democracy had reached its peak and Pericles' reforms were leading to the stalemate of populism. According to Paparrigopoulos, history vindicated Cimon, because Athens, after Pericles' death, sank into the abyss of political turmoil and demagogy. Paparrigopoulos maintains that an unprecedented regression descended upon the city, whose glory perished as a result of Pericles' populist policies.
According to another historian, Justin Daniel King, radical democracy benefited people individually, but harmed the state. On the other hand, Donald Kagan asserts that the democratic measures Pericles put into effect provided the basis for an unassailable political strength. After all, Cimon finally accepted the new democracy and did not oppose the citizenship law, after he returned from exile in 451 BC.
Leading Athens.
Ephialtes' murder in 461 BC paved the way for Pericles to consolidate his authority.δ[›] Without opposition after the expulsion of Cimon, the unchallengeable leader of the democratic party became the unchallengeable ruler of Athens. He remained in power until his death in 429 BC.
First Peloponnesian War.
Pericles made his first military excursions during the First Peloponnesian War, which was caused in part by Athens' alliance with Megara and Argos and the subsequent reaction of Sparta. In 454 BC he attacked Sicyon and Acarnania. He then unsuccessfully tried to conquer Oeniadea on the Corinthian gulf, before returning to Athens. In 451 BC, Cimon returned from exile and negotiated a five years' truce with Sparta after a proposal of Pericles, an event which indicates a shift in Pericles' political strategy. Pericles may have realized the importance of Cimon's contribution during the ongoing conflicts against the Peloponnesians and the Persians. Anthony J. Podlecki argues, however, that Pericles' alleged change of position was invented by ancient writers to support "a tendentious view of Pericles' shiftiness".
Plutarch states that Cimon struck a power-sharing deal with his opponents, according to which Pericles would carry through the interior affairs and Cimon would be the leader of the Athenian army, campaigning abroad. If it was actually made, this bargain would constitute a concession on Pericles' part that he was not a great strategist. Kagan believes that Cimon adapted himself to the new conditions and promoted a political marriage between Periclean liberals and Cimonian conservatives.
In the mid-450s the Athenians launched an unsuccessful attempt to aid an Egyptian revolt against Persia, which led to a prolonged siege of a Persian fortress in the Nile Delta. The campaign culminated in disaster; the besieging force was defeated and destroyed. In 451–450 BC the Athenians sent troops to Cyprus. Cimon defeated the Persians in the Battle of Salamis-in-Cyprus, but died of disease in 449 BC. Pericles is said to have initiated both expeditions in Egypt and Cyprus, although some researchers, such as Karl Julius Beloch, argue that the dispatch of such a great fleet conforms with the spirit of Cimon's policy.
Complicating the account of this period is the issue of the Peace of Callias, which allegedly ended hostilities between the Greeks and the Persians. The very existence of the treaty is hotly disputed, and its particulars and negotiation are ambiguous. Ernst Badian believes that a peace between Athens and Persia was first ratified in 463 BC (making the Athenian interventions in Egypt and Cyprus violations of the peace), and renegotiated at the conclusion of the campaign in Cyprus, taking force again by 449–448 BC.
John Fine, on the other hand, suggests that the first peace between Athens and Persia was concluded in 450–449 BC, due to Pericles' calculation that ongoing conflict with Persia was undermining Athens' ability to spread its influence in Greece and the Aegean. Kagan believes that Pericles used Callias, a brother-in-law of Cimon, as a symbol of unity and employed him several times to negotiate important agreements.
In the spring of 449 BC, Pericles proposed the Congress Decree, which led to a meeting ("Congress") of all Greek states in order to consider the question of rebuilding the temples destroyed by the Persians. The Congress failed because of Sparta's stance, but Pericles' intentions remain unclear. Some historians think that he wanted to prompt a confederation with the participation of all the Greek cities; others think he wanted to assert Athenian pre-eminence. According to the historian Terry Buckley the objective of the Congress Decree was a new mandate for the Delian League and for the collection of "phoros" (taxes).
During the Second Sacred War Pericles led the Athenian army against Delphi and reinstated Phocis in its sovereign rights on the oracle. In 447 BC Pericles engaged in his most admired excursion, the expulsion of barbarians from the Thracian peninsula of Gallipoli, in order to establish Athenian colonists in the region. At this time, however, Athens was seriously challenged by a number of revolts among its subjects. In 447 BC the oligarchs of Thebes conspired against the democratic faction. The Athenians demanded their immediate surrender, but after the Battle of Coronea, Pericles was forced to concede the loss of Boeotia in order to recover the prisoners taken in that battle. With Boeotia in hostile hands, Phocis and Locris became untenable and quickly fell under the control of hostile oligarchs.
In 446 BC, a more dangerous uprising erupted. Euboea and Megara revolted. Pericles crossed over to Euboea with his troops, but was forced to return when the Spartan army invaded Attica. Through bribery and negotiations, Pericles defused the imminent threat, and the Spartans returned home. When Pericles was later audited for the handling of public money, an expenditure of 10 talents was not sufficiently justified, since the official documents just referred that the money was spent for a "very serious purpose". Nonetheless, the "serious purpose" (namely the bribery) was so obvious to the auditors that they approved the expenditure without official meddling and without even investigating the mystery.
After the Spartan threat had been removed, Pericles crossed back to Euboea to crush the revolt there. He then punished the landowners of Chalcis, who lost their properties. The residents of Histiaea, meanwhile, who had butchered the crew of an Athenian trireme, were uprooted and replaced by 2,000 Athenian settlers. The crisis was brought to an official end by the Thirty Years' Peace (winter of 446–445 BC), in which Athens relinquished most of the possessions and interests on the Greek mainland which it had acquired since 460 BC, and both Athens and Sparta agreed not to attempt to win over the other state's allies.
Final battle with the conservatives.
In 444 BC, the conservative and the democratic factions confronted each other in a fierce struggle. The ambitious new leader of the conservatives, Thucydides (not to be confused with the historian of the same name), accused Pericles of profligacy, criticizing the way he spent the money for the ongoing building plan. Thucydides managed, initially, to incite the passions of the ecclesia in his favor, but, when Pericles, the leader of the democrats, took the floor, he put the conservatives in the shade. Pericles responded resolutely, proposing to reimburse the city for all the expenses from his private property, under the term that he would make the inscriptions of dedication in his own name.
His stance was greeted with applause, and Thucydides suffered an unexpected defeat. In 442 BC, the Athenian public voted to ostracize Thucydides from the city for 10 years and Pericles was once again the unchallenged ruler of the Athenian political arena.
Athens' rule over its alliance.
Pericles wanted to stabilize Athens' dominance over its alliance and to enforce its pre-eminence in Greece. The process by which the Delian League transformed into an Athenian empire is generally considered to have begun well before Pericles' time, as various allies in the league chose to pay tribute to Athens instead of manning ships for the league's fleet, but the transformation was speeded and brought to its conclusion by Pericles.
The final steps in the shift to empire may have been triggered by Athens' defeat in Egypt, which challenged the city's dominance in the Aegean and led to the revolt of several allies, such as Miletus and Erythrae. Either because of a genuine fear for its safety after the defeat in Egypt and the revolts of the allies, or as a pretext to gain control of the League's finances, Athens transferred the treasury of the alliance from Delos to Athens in 454–453 BC.
By 450–449 BC the revolts in Miletus and Erythrae were quelled and Athens restored its rule over its allies. Around 447 BC Clearchus proposed the Coinage Decree, which imposed Athenian silver coinage, weights and measures on all of the allies. According to one of the decree's most stringent provisions, surplus from a minting operation was to go into a special fund, and anyone proposing to use it otherwise was subject to the death penalty.
It was from the alliance's treasury that Pericles drew the funds necessary to enable his ambitious building plan, centered on the "Periclean Acropolis", which included the Propylaea, the Parthenon and the golden statue of Athena, sculpted by Pericles' friend, Phidias. In 449 BC Pericles proposed a decree allowing the use of 9,000 talents to finance the major rebuilding program of Athenian temples. Angelos Vlachos, a Greek Academician, points out the utilization of the alliance's treasury, initiated and executed by Pericles, as one of the largest embezzlements in human history; this misappropriation financed, however, some of the most marvellous artistic creations of the ancient world.
Samian War.
The Samian War was one of the last significant military events before the Peloponnesian War. After Thucydides' ostracism, Pericles was re-elected yearly to the generalship, the only office he ever officially occupied, although his influence was so great as to make him the "de facto" ruler of the state. In 440 BC Samos went to war against Miletus over control of Priene, an ancient city of Ionia on the foot-hills of Mycale. Worsted in the war, the Milesians came to Athens to plead their case against the Samians.
When the Athenians ordered the two sides to stop fighting and submit the case to arbitration in Athens, the Samians refused. In response, Pericles passed a decree dispatching an expedition to Samos, "alleging against its people that, although they were ordered to break off their war against the Milesians, they were not complying".ε[›]
In a naval battle the Athenians led by Pericles and nine other generals defeated the forces of Samos and imposed on the island an Athenian administration. When the Samians revolted against Athenian rule, Pericles compelled the rebels to capitulate after a tough siege of eight months, which resulted in substantial discontent among the Athenian sailors. Pericles then quelled a revolt in Byzantium and, when he returned to Athens, gave a funeral oration to honor the soldiers who died in the expedition.
Between 438–436 BC Pericles led Athens' fleet in Pontus and established friendly relations with the Greek cities of the region. Pericles focused also on internal projects, such as the fortification of Athens (the building of the "middle wall" about 440 BC), and on the creation of new cleruchies, such as Andros, Naxos and Thurii (444 BC) as well as Amphipolis (437–436 BC).
Personal attacks.
Pericles and his friends were never immune from attack, as preeminence in democratic Athens was not equivalent to absolute rule. Just before the eruption of the Peloponnesian War, Pericles and two of his closest associates, Phidias and his companion, Aspasia, faced a series of personal and judicial attacks.
Phidias, who had been in charge of all building projects, was first accused of embezzling gold meant for the statue of Athena and then of impiety, because, when he wrought the battle of the Amazons on the shield of Athena, he carved out a figure that suggested himself as a bald old man, and also inserted a very fine likeness of Pericles fighting with an Amazon.
Aspasia, who was noted for her ability as a conversationalist and adviser, was accused of corrupting the women of Athens in order to satisfy Pericles' perversions. The accusations against her were probably nothing more than unproven slanders, but the whole experience was very bitter for Pericles. Although Aspasia was acquitted thanks to a rare emotional outburst of Pericles, his friend, Phidias, died in prison and another friend of his, Anaxagoras, was attacked by the ecclesia for his religious beliefs.
Beyond these initial prosecutions, the ecclesia attacked Pericles himself by asking him to justify his ostensible profligacy with, and maladministration of, public money. According to Plutarch, Pericles was so afraid of the oncoming trial that he did not let the Athenians yield to the Lacedaemonians. Beloch also believes that Pericles deliberately brought on the war to protect his political position at home. Thus, at the start of the Peloponnesian War, Athens found itself in the awkward position of entrusting its future to a leader whose pre-eminence had just been seriously shaken for the first time in over a decade.
Peloponnesian War.
The causes of the Peloponnesian War have been much debated, but many ancient historians lay the blame on Pericles and Athens. Plutarch seems to believe that Pericles and the Athenians incited the war, scrambling to implement their belligerent tactics "with a sort of arrogance and a love of strife".στ[›] Thucydides hints at the same thing, believing the reason for the war was Sparta's fear of Athenian power and growth. However, as he is generally regarded as an admirer of Pericles, Thucydides has been criticized for bias towards Sparta.ζ[›]
Prelude to the war.
Pericles was convinced that the war against Sparta, which could not conceal its envy of Athens' pre-eminence, was inevitable if unfortunate. Therefore he did not hesitate to send troops to Corcyra to reinforce the Corcyraean fleet, which was fighting against Corinth. In 433 BC the enemy fleets confronted each other at the Battle of Sybota and a year later the Athenians fought Corinthian colonists at the Battle of Potidaea; these two events contributed greatly to Corinth's lasting hatred of Athens. During the same period, Pericles proposed the Megarian Decree, which resembled a modern trade embargo. According to the provisions of the decree, Megarian merchants were excluded from the market of Athens and the ports in its empire. This ban strangled the Megarian economy and strained the fragile peace between Athens and Sparta, which was allied with Megara. According to George Cawkwell, a praelector in ancient history, with this decree Pericles breached the Thirty Years' Peace "but, perhaps, not without the semblance of an excuse". The Athenians' justification was that the Megarians had cultivated the sacred land consecrated to Demeter and had given refuge to runaway slaves, a behavior which the Athenians considered to be impious.
After consultations with its allies, Sparta sent a deputation to Athens demanding certain concessions, such as the immediate expulsion of the Alcmaeonidae family including Pericles and the retraction of the Megarian Decree, threatening war if the demands were not met. The obvious purpose of these proposals was the instigation of a confrontation between Pericles and the people; this event, indeed, would come about a few years later. At that time, the Athenians unhesitatingly followed Pericles' instructions. In the first legendary oration Thucydides puts in his mouth, Pericles advised the Athenians not to yield to their opponents' demands, since they were militarily stronger. Pericles was not prepared to make unilateral concessions, believing that "if Athens conceded on that issue, then Sparta was sure to come up with further demands". Consequently, Pericles asked the Spartans to offer a "quid pro quo". In exchange for retracting the Megarian Decree, the Athenians demanded from Sparta to abandon their practice of periodic expulsion of foreigners from their territory (xenelasia) and to recognize the autonomy of its allied cities, a request implying that Sparta's hegemony was also ruthless. The terms were rejected by the Spartans, and with neither side willing to back down, the two cities prepared for war. According to Athanasios G. Platias and Constantinos Koliopoulos, professors of strategic studies and international politics, "rather than to submit to coercive demands, Pericles chose war". Another consideration that may well have influenced Pericles' stance was the concern that revolts in the empire might spread if Athens showed herself weak.
First year of the war (431 BC).
In 431 BC, while peace already was precarious, Archidamus II, Sparta's king, sent a new delegation to Athens, demanding that the Athenians submit to Sparta's demands. This deputation was not allowed to enter Athens, as Pericles had already passed a resolution according to which no Spartan deputation would be welcomed if the Spartans had previously initiated any hostile military actions. The Spartan army was at this time gathered at Corinth, and, citing this as a hostile action, the Athenians refused to admit their emissaries. With his last attempt at negotiation thus declined, Archidamus invaded Attica, but found no Athenians there; Pericles, aware that Sparta's strategy would be to invade and ravage Athenian territory, had previously arranged to evacuate the entire population of the region to within the walls of Athens.
No definite record exists of how exactly Pericles managed to convince the residents of Attica to agree to move into the crowded urban areas. For most, the move meant abandoning their land and ancestral shrines and completely changing their lifestyle. Therefore, although they agreed to leave, many rural residents were far from happy with Pericles' decision. Pericles also gave his compatriots some advice on their present affairs and reassured them that, if the enemy did not plunder his farms, he would offer his property to the city. This promise was prompted by his concern that Archidamus, who was a friend of his, might pass by his estate without ravaging it, either as a gesture of friendship or as a calculated political move aimed to alienate Pericles from his constituents.
In any case, seeing the pillage of their farms, the Athenians were outraged, and they soon began to indirectly express their discontent towards their leader, who many of them considered to have drawn them into the war. Even when in the face of mounting pressure, Pericles did not give in to the demands for immediate action against the enemy or revise his initial strategy. He also avoided convening the ecclesia, fearing that the populace, outraged by the unopposed ravaging of their farms, might rashly decide to challenge the vaunted Spartan army in the field. As meetings of the assembly were called at the discretion of its rotating presidents, the "prytanies", Pericles had no formal control over their scheduling; rather, the respect in which Pericles was held by the prytanies was apparently sufficient to persuade them to do as he wished. While the Spartan army remained in Attica, Pericles sent a fleet of 100 ships to loot the coasts of the Peloponnese and charged the cavalry to guard the ravaged farms close to the walls of the city. When the enemy retired and the pillaging came to an end, Pericles proposed a decree according to which the authorities of the city should put aside 1,000 talents and 100 ships, in case Athens was attacked by naval forces. According to the most stringent provision of the decree, even proposing a different use of the money or ships would entail the penalty of death. During the autumn of 431 BC, Pericles led the Athenian forces that invaded Megara and a few months later (winter of 431–430 BC) he delivered his monumental and emotional Funeral Oration, honoring the Athenians who died for their city.
Last military operations and death.
In 430 BC, the army of Sparta looted Attica for a second time, but Pericles was not daunted and refused to revise his initial strategy. Unwilling to engage the Spartan army in battle, he again led a naval expedition to plunder the coasts of the Peloponnese, this time taking 100 Athenian ships with him. According to Plutarch, just before the sailing of the ships an eclipse of the sun frightened the crews, but Pericles used the astronomical knowledge he had acquired from Anaxagoras to calm them. In the summer of the same year an epidemic broke out and devastated the Athenians. The exact identity of the disease is uncertain, and has been the source of much debate.η[›] In any case, the city's plight, caused by the epidemic, triggered a new wave of public uproar, and Pericles was forced to defend himself in an emotional final speech, a rendition of which is presented by Thucydides. This is considered to be a monumental oration, revealing Pericles' virtues but also his bitterness towards his compatriots' ingratitude. Temporarily, he managed to tame the people's resentment and to ride out the storm, but his internal enemies' final bid to undermine him came off; they managed to deprive him of the generalship and to fine him at an amount estimated between 15 and 50 talents. Ancient sources mention Cleon, a rising and dynamic protagonist of the Athenian political scene during the war, as the public prosecutor in Pericles' trial.
Nevertheless, within just a year, in 429 BC, the Athenians not only forgave Pericles but also re-elected him as strategos.θ[›] He was reinstated in command of the Athenian army and led all its military operations during 429 BC, having once again under his control the levers of power. In that year, however, Pericles witnessed the death of both his legitimate sons from his first wife, Paralus and Xanthippus, in the epidemic. His morale undermined, he burst into tears and not even Aspasia's companionship could console him. He himself died of the plague in the autumn of 429 BC.
Just before his death, Pericles' friends were concentrated around his bed, enumerating his virtues during peace and underscoring his nine war trophies. Pericles, though moribund, heard them and interrupted them, pointing out that they forgot to mention his fairest and greatest title to their admiration; "for", said he, "no living Athenian ever put on mourning because of me". Pericles lived during the first two and a half years of the Peloponnesian War and, according to Thucydides, his death was a disaster for Athens, since his successors were inferior to him; they preferred to incite all the bad habits of the rabble and followed an unstable policy, endeavoring to be popular rather than useful. With these bitter comments, Thucydides not only laments the loss of a man he admired, but he also heralds the flickering of Athens' unique glory and grandeur.
Pausanias (c. 150 C.E.) records (I.29) seeing the tomb of Pericles along a road near the Academy.
Personal life.
Pericles, following Athenian custom, was first married to one of his closest relatives, with whom he had two sons, Paralus and Xanthippus, but around 445 BC, Pericles divorced his wife. He offered her to another husband, with the agreement of her male relatives. The name of his first wife is not known; the only information about her is that she was the wife of Hipponicus, before being married to Pericles, and the mother of Callias from this first marriage.
The woman whom he really adored was Aspasia of Miletus. She became Pericles' mistress and they began to live together as if they were married. This relationship aroused many reactions and even Pericles' own son, Xanthippus, who had political ambitions, did not hesitate to slander his father. Nonetheless, these persecutions did not undermine Pericles' morale, although he had to burst into tears in order to protect his beloved Aspasia when she was accused of corrupting Athenian society. His greatest personal tragedy was the death of his sister and of both his legitimate sons, Xanthippus and Paralus, all affected by the epidemic, a calamity he never managed to overcome.
Just before his death, the Athenians allowed a change in the law of 451 BC that made his half-Athenian son with Aspasia, Pericles the Younger, a citizen and legitimate heir, a decision all the more striking in consideration that Pericles himself had proposed the law confining citizenship to those of Athenian parentage on both sides.
Assessments.
Pericles marked a whole era and inspired conflicting judgments about his significant decisions. The fact that he was at the same time a vigorous statesman, general and orator makes more complex the objective assessment of his actions.
Political leadership.
Some contemporary scholars call Pericles a populist, a demagogue and a hawk, while other scholars admire his charismatic leadership. According to Plutarch, after assuming the leadership of Athens, "he was no longer the same man as before, nor alike submissive to the people and ready to yield and give in to the desires of the multitude as a steersman to the breezes". It is told that when his political opponent, Thucydides, was asked by Sparta's king, Archidamus, whether he or Pericles was the better fighter, Thucydides answered without any hesitation that Pericles was better, because even when he was defeated, he managed to convince the audience that he had won. In matters of character, Pericles was above reproach in the eyes of the ancient historians, since "he kept himself untainted by corruption, although he was not altogether indifferent to money-making".
Thucydides, an admirer of Pericles, maintains that Athens was "in name a democracy but, in fact, governed by its first citizen". Through this comment, the historian illustrates what he perceives as Pericles' charisma to lead, convince and, sometimes, to manipulate. Although Thucydides mentions the fining of Pericles, he does not mention the accusations against Pericles but instead focuses on Pericles' integrity.ι[›] On the other hand, in one of his dialogues, Plato rejects the glorification of Pericles and quote as saying: "as I know, Pericles made the Athenians slothful, garrulous and avaricious, by starting the system of public fees".
Plutarch mentions other criticism of Pericles' leadership: "many others say that the people were first led on by him into allotments of public lands, festival-grants, and distributions of fees for public services, thereby falling into bad habits, and becoming luxurious and wanton under the influence of his public measures, instead of frugal and self-sufficing".
Thucydides argues that Pericles "was not carried away by the people, but he was the one guiding the people". His judgement is not unquestioned; some 20th-century critics, such as Malcolm F. McGregor and John S. Morrison, proposed that he may have been a charismatic public face acting as an advocate on the proposals of advisors, or the people themselves. According to King, by increasing the power of the people, the Athenians left themselves with no authoritative leader. During the Peloponnesian War, Pericles' dependence on popular support to govern was obvious.
Military achievements.
For more than 20 years Pericles led many expeditions, mainly naval ones. Being always cautious, he never undertook of his own accord a battle involving much uncertainty and peril and he did not accede to the "vain impulses of the citizens". He based his military policy on Themistocles' principle that Athens' predominance depends on its superior naval power and believed that the Peloponnesians were near-invincible on land. Pericles also tried to minimize the advantages of Sparta by rebuilding the walls of Athens, which, it has been suggested, radically altered the use of force in Greek international relations.
During the Peloponnesian War, Pericles initiated a defensive "grand strategy" whose aim was the exhaustion of the enemy and the preservation of the "status quo". According to Platias and Koliopoulos, Athens as the strongest party did not have to beat Sparta in military terms and "chose to foil the Spartan plan for victory". The two basic principles of the "Periclean Grand Strategy" were the rejection of appeasement (in accordance with which he urged the Athenians not to revoke the Megarian Decree) and the avoidance of overextension.ια[›] According to Kagan, Pericles' vehement insistence that there should be no diversionary expeditions may well have resulted from the bitter memory of the Egyptian campaign, which he had allegedly supported. His strategy is said to have been "inherently unpopular", but Pericles managed to persuade the Athenian public to follow it. It is for that reason that Hans Delbrück called him one of the greatest statesmen and military leaders in history. Although his countrymen engaged in several aggressive actions soon after his death, Platias and Koliopoulos argue that the Athenians remained true to the larger Periclean strategy of seeking to preserve, not expand, the empire, and did not depart from it until the Sicilian Expedition. For his part, Ben X. de Wet concludes his strategy would have succeeded had he lived longer.
Critics of Pericles' strategy, however, have been just as numerous as its supporters. A common criticism is that Pericles was always a better politician and orator than strategist. Donald Kagan called the Periclean strategy "a form of wishful thinking that failed", Barry S. Strauss and Josiah Ober have stated that "as strategist he was a failure and deserves a share of the blame for Athens' great defeat", and Victor Davis Hanson believes that Pericles had not worked out a clear strategy for an effective offensive action that could possibly force Thebes or Sparta to stop the war. Kagan criticizes the Periclean strategy on four counts: first that by rejecting minor concessions it brought about war; second, that it was unforeseen by the enemy and hence lacked credibility; third, that it was too feeble to exploit any opportunities; and fourth, that it depended on Pericles for its execution and thus was bound to be abandoned after his death. Kagan estimates Pericles' expenditure on his military strategy in the Peloponnesian War to be about 2,000 talents annually, and based on this figure concludes that he would only have enough money to keep the war going for three years. He asserts that since Pericles must have known about these limitations he probably planned for a much shorter war. Others, such as Donald W. Knight, conclude that the strategy was too defensive and would not succeed.
On the other hand, Platias and Koliopoulos reject these criticisms and state that "the Athenians lost the war only when they dramatically reversed the Periclean grand strategy that explicitly disdained further conquests". Hanson stresses that the Periclean strategy was not innovative, but could lead to a stagnancy in favor of Athens. It is a popular conclusion that those succeeding him lacked his abilities and character.
Oratorical skill.
Modern commentators of Thucydides, with other modern historians and writers, take varying stances on the issue of how much of the speeches of Pericles, as given by this historian, do actually represent Pericles' own words and how much of them is free literary creation or paraphrase by Thucydides.ιβ[›] Since Pericles never wrote down or distributed his orations,ιγ[›] no historians are able to answer this with certainty; Thucydides recreated three of them from memory and, thereby, it cannot be ascertained that he did not add his own notions and thoughts.ιδ[›]
Although Pericles was a main source of his inspiration, some historians have noted that the passionate and idealistic literary style of the speeches Thucydides attributes to Pericles is completely at odds with Thucydides' own cold and analytical writing style.ιε[›] This might, however, be the result of the incorporation of the genre of rhetoric into the genre of historiography. That is to say, Thucydides could simply have used two different writing styles for two different purposes.
Ioannis Kakridis and Arnold Gomme were two scholars who debated the originality of Pericles’ oratory and last speech. Kakridis believes that Thucydides altered Pericles words. Some of his strongest arguments included in the Introduction of the speech, (Thuc.11.35). Kakridis proposes that it is impossible to imagine Pericles deviating away from the expected funeral orator addressing the mourning audience of 430 after the Peloponnesian war. The two groups addressed were the ones who were prepared to believe him when he praised the dead, and the ones who did not. Gomme rejects Kakridis position, defending the fact that "Nobody of men has ever been so conscious of envy and its workings as the Greeks, and that the Greeks and Thucydides in particular had a passion for covering all ground in their generalizations, not always relevantly.".
Kagan states that Pericles adopted "an elevated mode of speech, free from the vulgar and knavish tricks of mob-orators" and, according to Diodorus Siculus, he "excelled all his fellow citizens in skill of oratory". According to Plutarch, he avoided using gimmicks in his speeches, unlike the passionate Demosthenes, and always spoke in a calm and tranquil manner. The biographer points out, however, that the poet Ion reported that Pericles' speaking style was "a presumptuous and somewhat arrogant manner of address, and that into his haughtiness there entered a good deal of disdain and contempt for others".
Gorgias, in Plato's homonymous dialogue, uses Pericles as an example of powerful oratory. In Menexenus, however, Socrates (through Plato) casts aspersions on Pericles' rhetorical fame, claiming ironically that, since Pericles was educated by Aspasia, a trainer of many orators, he would be superior in rhetoric to someone educated by Antiphon. He also attributes authorship of the Funeral Oration to Aspasia and attacks his contemporaries' veneration of Pericles.
Sir Richard C. Jebb concludes that "unique as an Athenian statesman, Pericles must have been in two respects unique also as an Athenian orator; first, because he occupied such a position of personal ascendancy as no man before or after him attained; secondly, because his thoughts and his moral force won him such renown for eloquence as no one else ever got from Athenians".
Ancient Greek writers call Pericles "Olympian" and extol his talents; referring to him "thundering and lightening and exciting Greece" and carrying the weapons of Zeus when orating. According to Quintilian, Pericles would always prepare assiduously for his orations and, before going on the rostrum, he would always pray to the Gods, so as not to utter any improper word.
Legacy.
Pericles' most visible legacy can be found in the literary and artistic works of the Golden Age, most of which survive to this day. The Acropolis, though in ruins, still stands and is a symbol of modern Athens. Paparrigopoulos wrote that these masterpieces are "sufficient to render the name of Greece immortal in our world".
In politics, Victor L. Ehrenberg argues that a basic element of Pericles' legacy is Athenian imperialism, which denies true democracy and freedom to the people of all but the ruling state. The promotion of such an arrogant imperialism is said to have ruined Athens. Pericles and his "expansionary" policies have been at the center of arguments promoting democracy in oppressed countries.
Other analysts maintain an Athenian humanism illustrated in the Golden Age. The freedom of expression is regarded as the lasting legacy deriving from this period. Pericles is lauded as "the ideal type of the perfect statesman in ancient Greece" and his Funeral Oration is nowadays synonymous with the struggle for participatory democracy and civic pride.
Notes.
^ α: Pericles' date of birth is uncertain; he could not have been born later than 492–1 and been of age to present the Persae in 472. He is not recorded as having taken part in the Persian Wars of 480–79; some historians argue from this that he was unlikely to have been born before 498, but this argument "ex silentio" has also been dismissed.
^ β: Plutarch says "granddaughter" of Cleisthenes, but this is chronologically implausible, and there is consensus that this should be "niece".
^ γ: Thucydides records several speeches which he attributes to Pericles; however, he acknowledges that: "it was in all cases difficult to carry them word for word in one's memory, so my habit has been to make the speakers say what was in my opinion demanded of them by the various occasions, of course adhering as closely as possible to the general sense of what they really said."
^ δ: According to Aristotle, Aristodicus of Tanagra killed Ephialtes. Plutarch cites an Idomeneus as saying that Pericles killed Ephialtes, but does not believe him—he finds it to be out of character for Pericles.
^ ε: According to Plutarch, it was thought that Pericles proceeded against the Samians to gratify Aspasia of Miletus.
^ στ: Plutarch describes these allegations without espousing them. Thucydides insists, however, that the Athenian politician was still powerful. Gomme and Vlachos support Thucydides' view.
^ ζ: Vlachos maintains that Thucydides' narration gives the impression that Athens' alliance had become an authoritarian and oppressive empire, while the historian makes no comment for Sparta's equally harsh rule. Vlachos underlines, however, that the defeat of Athens could entail a much more ruthless Spartan empire, something that did indeed happen. Hence, the historian's hinted assertion that Greek public opinion espoused Sparta's pledges of liberating Greece almost uncomplainingly seems tendentious. Geoffrey Ernest Maurice de Ste Croix, for his part, argues that Athens' imperium was welcomed and valuable for the stability of democracy all over Greece. According to Fornara and Samons, "any view proposing that popularity or its opposite can be inferred simply from narrow ideological considerations is superficial".
^ η: Taking into consideration its symptoms, most researchers and scientists now believe that it was typhus or typhoid fever and not cholera, plague or measles.
^ θ: Pericles held the generalship from 444 BC until 430 BC without interruption.
^ ι: Vlachos criticizes the historian for this omission and maintains that Thucydides' admiration for the Athenian statesman makes him ignore not only the well-grounded accusations against him but also the mere gossips, namely the allegation that Pericles had corrupted the volatile rabble, so as to assert himself.
^ ια: According to Platias and Koliopoulos, the "policy mix" of Pericles was guided by five principles: a) Balance the power of the enemy, b) Exploit competitive advantages and negate those of the enemy, c) Deter the enemy by the denial of his success and by the skillful use of retaliation, d) Erode the international power base of the enemy, e) Shape the domestic environment of the adversary to your own benefit.
^ ιβ: According to Vlachos, Thucydides must have been about 30 years old when Pericles delivered his Funeral Oration and he was probably among the audience.
^ ιγ: Vlachos points out that he does not know who wrote the oration, but "these were the words which should have been spoken at the end of 431 BC". According to Sir Richard C. Jebb, the Thucydidean speeches of Pericles give the general ideas of Pericles with essential fidelity; it is possible, further, that they may contain recorded sayings of his "but it is certain that they cannot be taken as giving the form of the statesman's oratory". John F. Dobson believes that "though the language is that of the historian, some of the thoughts may be those of the statesman". C.M.J. Sicking argues that "we are hearing the voice of real Pericles", while Ioannis T. Kakridis claims that the Funeral Oration is an almost exclusive creation of Thucydides, since "the real audience does not consist of the Athenians of the beginning of the war, but of the generation of 400 BC, which suffers under the repercussions of the defeat". Gomme disagrees with Kakridis, insisting on his belief to the reliability of Thucydides.
^ ιδ: That is what Plutarch predicates. Nonetheless, according to the 10th century encyclopedia Suda, Pericles constituted the first orator who systematically wrote down his orations. Cicero speaks about Pericles' writings, but his remarks are not regarded as credible. Most probably, other writers used his name.
^ ιε: Ioannis Kalitsounakis argues that "no reader can overlook the sumptuous rythme of the Funeral Oration as a whole and the singular correlation between the impetuous emotion and the marvellous style, attributes of speech that Thucydides ascribes to no other orator but Pericles". According to Harvey Ynis, Thucydides created the Pericles' indistinct rhetorical legacy that has dominated ever since.
</dl>
References.
Primary sources (Greek and Roman).
 #if: 
 #if:  
 |, 
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: Athenian Constitution
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: Athenian Constitution
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if:  
 |{{
 #if: Aristotle
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2="  
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Aristotle
 |{{
 #if: 
 #if:
}}{{
 #if: 
 #ifeq: | 
 |{{
 #if: 
 #if: Aristotle
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: Athenian Constitution
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: Athenian Constitution
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if:  
 |, {{
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |journal&rft.genre=article&rft.atitle={{urlencode:  
 |book{{
 #if: 
 |&rft.genre=bookitem&rft.btitle={{urlencode:}}&rft.atitle={{urlencode:  
 |&rft.genre=book&rft.btitle={{urlencode:  
 #if: Aristotle |&rft.aulast={{urlencode:Aristotle}}{{
 }}{{
 #if: Aristotle |&rft.au={{urlencode:Aristotle}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: Athenian Constitution
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: Athenian Constitution
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle = 
 |IncludedWorkURL = 
 |Other = Trans. Frederic George Kenyon
 |Edition = 
 |Place = 
 |PublicationPlace = 
 |Publisher = Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = 
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=
 |Sep = .
 |PS = .
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 8
 |amp = 
}}. See original text in .
 #if: 
 #if:Lives
 }}""{{
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: Lives (Dryden translation)
 #if: 
 #if: Pericles
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: Lives (Dryden translation)
 #if: 
 #if: Pericles
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if: Lives
 #if: Plutarch
 |,
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2="Lives{{
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Plutarch
 |
 #if: 
 #if:
}}{{
 #if: 
 #ifeq: | 
 |{{
 #if: 
 #if: Plutarch
 |, 
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: Lives (Dryden translation)
 #if: 
 #if: Pericles
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: Lives (Dryden translation)
 #if: 
 #if: Pericles
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if: Lives
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |book{{
 #if: 
 }}{{
 #if: Plutarch
 |&rft.aulast={{urlencode: Plutarch
 }}{{
 #if: Plutarch
 |&rft.au={{urlencode: Plutarch
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: Lives (Dryden translation)
 #if: 
 #if: Pericles
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: Lives (Dryden translation)
 #if: 
 #if: Pericles
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle =  
 |IncludedWorkURL = 
 |Other = Trans. John Dryden
 |Edition = 
 |Place = 
 |PublicationPlace = 
 |Publisher = Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = 
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=
 |Sep = .
 |PS = .
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 8
 |amp = 
}}. See original text in 
 #if: 
 #if:  
 |, 
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: History of the Peloponnesian War
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: History of the Peloponnesian War
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if:  
 |{{
 #if: Thucydides
 |,
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2="  
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Thucydides
 |
 #if: 
 #if:
}}{{
 #if: 
 #ifeq: | 
 |{{
 #if: 
 #if: Thucydides
 |, 
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: History of the Peloponnesian War
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: History of the Peloponnesian War
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if:  
 |, {{
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |journal&rft.genre=article&rft.atitle={{urlencode:  
 |book{{
 #if: 
 |&rft.genre=bookitem&rft.btitle={{urlencode:}}&rft.atitle={{urlencode:  
 |&rft.genre=book&rft.btitle={{urlencode:  
 #if: Thucydides
 |&rft.aulast={{urlencode: Thucydides
 }}{{
 #if: Thucydides
 |&rft.au={{urlencode: Thucydides
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: History of the Peloponnesian War
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: History of the Peloponnesian War
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle = 
 |IncludedWorkURL = 
 |Other = Trans. Richard Crawley
 |Edition = 
 |Place = 
 |PublicationPlace = 
 |Publisher = Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = 
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=
 |Sep = .
 |PS = .
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 8
 |amp = 
}}, I-III. See original text in 
</dl>
Secondary sources.
</dl>
Further reading.
</dl>

</doc>
<doc id="36816" url="http://en.wikipedia.org/wiki?curid=36816" title="The Three Stooges">
The Three Stooges

The Three Stooges were an American vaudeville and comedy act of the mid–20th century (1930–1975) best known for their numerous Columbia short subject films, still syndicated to television. Their hallmark was physical farce and slapstick. In films, the Stooges were commonly known by their first names: "Moe, Larry, and Curly" or "Moe, Larry, and Shemp", among other lineups depending on the films; there were six active stooges, five of whom performed in the shorts. Moe and Larry were always present until the very last years of the ensemble's run of more than forty years.
The act began as part of a late-1920s vaudeville comedy act, billed as Ted Healy and his Stooges, consisting of Healy, Moe Howard, his brother Shemp Howard, and Larry Fine. The four made one feature film entitled "Soup to Nuts" before Shemp left to pursue a solo career. He was replaced by his younger brother Jerome (Curly Howard) in 1932, and the trio eventually left Healy to launch their own act, billed as "The Three Stooges".
Curly suffered a debilitating stroke in May 1946, and Shemp returned, reinstating the original lineup until Shemp's death in November 1955. Film actor Joe Palma was used as a temporary stand-in; the maneuver thereafter became known as the term of art Fake Shemp—to complete four Shemp-era shorts under contract. The coining of the term took place before a new contract from Columbia but after comic Joe Besser joined as the third Stooge in a run in '56–57—but he left in 1958 to nurse his ailing spouse. Columbia terminated its shorts division and released its Stooges contractual rights to the Screen Gems production studio. When Screen Gems syndicated the shorts to television, the Stooges became one of the most popular comedy acts of the early 1960s. They also made a cameo appearance in the 1963 comedy classic "It's a Mad Mad Mad Mad World".
Comic actor Joe DeRita became "Curly Joe" in 1958, replacing Besser. With the television exposure, the act regained momentum throughout the 1960s as popular kiddie fare until Larry Fine's paralyzing stroke in January 1970. Fine died in 1975 after a further series of strokes. Moe tried to revive the Stooges with longtime supporting actor Emil Sitka in Larry's role in 1970 and again in 1975, but this attempt was cut short with Moe's death in May 1975.
History.
Ted Healy and his Stooges.
The Three Stooges started in 1925 as part of a raucous vaudeville act called "Ted Healy and His Stooges" (also known as "Ted Healy and His Southern Gentlemen", "Ted Healy and His Three Lost Souls", "Ted Healy and His Racketeers", and "Ted Healy and his Three Stooges"). Moe (Moses Harry Horwitz) joined Healy's act in 1921, and his brother Shemp came aboard in 1923. In 1925 violinist-comedian Larry Fine and xylophonist-comedian Fred Sanborn, also joined the group. In the act, lead comedian Healy would attempt to sing or tell jokes while his noisy assistants would keep "interrupting" him, causing Healy to retaliate with verbal and physical abuse.
In 1930, Ted Healy and His Stooges (including Sanborn) appeared in their first Hollywood feature film, "Soup to Nuts", released by Fox Film Corporation. The film was not a critical success, but the Stooges' performances were singled out as memorable, leading Fox to offer the trio a contract minus Healy. This enraged Healy, who told studio executives that the Stooges were his employees. The offer was withdrawn, and after Howard, Fine and Howard learned of the reason, they left Healy to form their own act, which quickly took off with a tour of the theater circuit. Healy attempted to stop the new act with legal action, claiming they were using his copyrighted material. There are accounts of Healy threatening to bomb theaters if Howard, Fine and Howard ever performed there, which worried Shemp so much that he almost left the act; reportedly, only a pay raise kept him on board. Healy tried to save his act by hiring replacement stooges, but they were inexperienced and not as well-received as their predecessors. In 1932, with Moe now acting as business manager, Healy reached a new agreement with his former Stooges, and they were booked in a production of Jacob J. Shubert's "The Passing Show of 1932". During rehearsals, Healy received a more lucrative offer and found a loophole in his contract allowing him to leave the production. Shemp, fed up with Healy's abrasiveness, decided to quit the act and found work almost immediately, in Vitaphone movie comedies produced in Brooklyn, New York.
With Shemp gone, Healy and the two remaining stooges (Moe and Larry) needed a replacement, so Moe suggested his younger brother Jerry Howard. Healy reportedly took one look at Jerry, who had long chestnut red locks and a handlebar mustache, and remarked that he did not look like he was funny. Jerry left the room and returned a few moments later with his head shaved (though his mustache remained for a time), and then quipped "Boy, do I look girly." Healy heard "Curly", and the name stuck. (There are varying accounts as to how the Curly character actually came about.)
In 1933, Metro-Goldwyn-Mayer (MGM) signed Healy and his Stooges to a movie contract. They appeared in feature films and short subjects, either together, individually, or with various combinations of actors. The trio was featured in a series of musical comedy shorts, beginning with "Nertsery Rhymes". The short was one of a few shorts to be made with an early two-strip Technicolor process, including one featuring Curly without Healy or the other Stooges, "Roast Beef and Movies" (1934). The shorts themselves were built around recycled film footage of production numbers cut from MGM musicals, such as "Children of Pleasure", "Lord Byron of Broadway", and the unfinished "March of Time" (all 1930), which had been filmed in early Technicolor. Soon, additional shorts followed (sans the experimental Technicolor), including "Beer and Pretzels" (1933), "Plane Nuts" (1933), "Jail Birds of Paradise" (1934) and "The Big Idea" (1934).
Healy and company also appeared in several MGM feature films as comic relief, such as "Turn Back the Clock" (1933), "Meet the Baron" (1933), "Dancing Lady" (1933), "Fugitive Lovers" (1934), and "Hollywood Party" (1934). Healy and the Stooges also appeared together in "Myrt and Marge" for Universal Pictures.
In 1934, the team's contract with MGM expired, and the Stooges parted professional company with Healy. According to Moe Howard's autobiography, the Stooges split with Ted Healy in 1934 once and for all because of Healy's alcoholism and abrasiveness. Their final film with Healy was MGM's 1934 film, "Hollywood Party". Both Healy and the Stooges went on to separate successes, with Healy dying under mysterious circumstances in 1937.
The Columbia years.
Moe, Larry and Curly.
In 1934, the trio – now officially named "The Three Stooges" – signed on to appear in two-reel comedy short subjects for Columbia Pictures. In Moe's autobiography, he said they each got $600 per week on a one-year contract with a renewable option; in the Ted Okuda–Edward Watz book "The Columbia Comedy Shorts", the Stooges are said to have received $1,000 among them for their first Columbia effort, "Woman Haters", and then signed a term contract for $7,500 per film (equal to $ today), to be divided among the trio.
Within their first year at Columbia, the Stooges became wildly popular. Realizing this, Columbia Pictures president Harry Cohn used the Stooges as leverage, as the demand for their films was so great that he eventually refused to supply exhibitors with the trio's shorts unless they also agreed to book some of the studio's mediocre B movies. Cohn also saw to it that the Stooges remained ignorant of their popularity. During their 23 years at Columbia, the Stooges were never completely aware of their amazing drawing power at the box office. As their contracts with the studio included an open option that had to be renewed yearly, Cohn would tell the boys that the short subjects were in decline, which was not a complete fabrication (Cohn's yearly mantra was "the market for comedy shorts is dying out, fellas"). Thinking their days were numbered, the Stooges would cruelly sweat it out each and every year, with Cohn renewing their contract at the eleventh hour. This deception kept the insecure Stooges unaware of their true value, resulting in them having second thoughts about asking for a better contract without a yearly option. Cohn's scare tactics worked for all 23 years the Stooges were at Columbia; the team never once asked for – nor were they ever given – a salary increase. It was not until after they stopped making the shorts in December 1957 did Moe learn of Cohn's underhanded tactics, what a valuable commodity the Stooges had been for the ailing studio, and how many millions more the act could have earned. While Columbia offered theater owners an entire program of two-reel comedies (15 to 25 titles annually) featuring such stars as Buster Keaton, Andy Clyde, Charley Chase, and Hugh Herbert, the Stooge shorts were the most popular of all.
The Stooges were required to release up to eight short films per year within a 40-week period; for the remaining 12 or so weeks, they were free to pursue other employment, time which was either spent with their families or touring the country to promote their live act. The Stooges appeared in 190 film shorts and five features while at Columbia, outlasting every one of their contemporaries employed in the short film genre. Del Lord directed more than three dozen Stooge films; Jules White directed dozens more, and his brother Jack White directed several under the pseudonym "Preston Black". Silent film star Charley Chase also shared directorial responsibilities with Lord and White.
The Stooge films made between 1935 and 1941 captured the team at the peak, according to film historians Ted Okuda and Edward Watz, authors of "The Columbia Comedy Shorts". Nearly every film produced became a classic in its own right. 1935's "Hoi Polloi" adapted the premise of "Pygmalion", with a stuffy professor waging a bet that he can transform the uncultured trio into refined gentlemen; the plotline worked so well that it was reused twice, as "Half-Wits Holiday" and "Pies and Guys". "Three Little Beers" featured the team employed at a brewery who then run amuck on a local golf course to win prize money. 1936's "Disorder in the Court" features the team as star witnesses in a murder trial. 1938's "Violent is the Word for Curly" was a quality Chase-directed short that featured the musical interlude "Swinging the Alphabet". In the 1940 film "A Plumbing We Will Go" – one of the team's quintessential comedies – the Stooges are cast as plumbers who nearly destroy a socialite's mansion, causing water to exit every appliance in the home. Other entries of the era, like "Uncivil Warriors", "A Pain in the Pullman", "False Alarms", "Grips, Grunts and Groans", "The Sitter Downers", "Dizzy Doctors", "Tassels in the Air", "We Want Our Mummy", "Nutty but Nice", "An Ache in Every Stake" and "In the Sweet Pie and Pie" are considered among the team's finest work.
With the onset of World War II, the Stooges released several entries that poked fun at the rising Axis powers. "You Nazty Spy!" and its sequel "I'll Never Heil Again" burlesqued Hitler and the Nazis at a time when America was still neutral and resolutely isolationist. Moe is cast as "Moe Hailstone", an Adolf Hitler-like character, with Curly playing a Hermann Göring character (replete with medals), and Larry a Ribbentrop-type ambassador. Though revered by Stooge fans, as well as the Stooges themselves (Moe, Larry and director Jules White considered "You Nazty Spy!" their best film), the efforts indulged in a deliberately formless, non-sequitur style of verbal humor that was not the Stooges' forte, according to Okuda and Watz.
Other wartime entries, like "They Stooge to Conga", "Higher Than a Kite", "Back From the Front", "Gents Without Cents" and the controversial "The Yoke's on Me" have their moments, but taken in bulk, the wartime films are decidedly substandard. "No Dough Boys" ranks as the best of these farces. The team, made up as Japanese soldiers for a photo shoot, is mistaken for genuine saboteurs by a Nazi ringleader (Vernon Dent). The highlight of the film features the Stooges engaging in nonsensical gymnastics (the real spies are renowned acrobats) for a skeptical group of enemy agents.
The World War II era also brought on rising production costs that resulted in a reduced number of elaborate gags and outdoor sequences, Del Lord's stock and trade; as such, the quality of the teams' films (particularly those directed by Lord) began to slip after 1942. According to Okuda and Watz, entries like "Loco Boy Makes Good", "What's the Matador?", "Sock-A-Bye Baby", "I Can Hardly Wait" and "A Gem of a Jam" are considered to be less quality work than previous efforts, and in a different class than their earlier films. The 1943 film "Spook Louder", a remake of Mack Sennett's "The Great Pie Mystery", is often cited as their worst film. The story of a phantom pie-thrower (later revealed to be the detective on the case) is repetitious and relying on the same jokes, which many Stooge fans consider to be far less humorous than their past work. "Three Smart Saps", a film considered to be an improvement, features a reworking of a routine from Harold Lloyd's "The Freshman", in which Curly's loosely basted suit begins to come apart at the seams while he is on the dance floor.
The Stooges made occasional guest appearances in feature films, though generally they were restricted to their short subjects. Even though most of the Stooges' peers had either made the transition from shorts to features films (Laurel and Hardy, The Ritz Brothers) or had been starring their own feature films from the onset (The Marx Brothers, Abbott and Costello), Moe believed the team's firebrand style of humor worked better in short form. In 1935, when Columbia proposed to star them in their own full-length feature, Moe rejected the idea, saying "It's a hard job inventing, rewriting or stealing gags for our two-reel comedies for Columbia Pictures without having to make a seven-reeler (feature film). We can make short films out of material needed for a starring feature and then we wouldn't know whether it would be funny enough to click."
Film critics and stooge fans alike have cited Curly as the most popular member of the team. His childlike mannerisms and natural comedic charm (he had no previous acting experience) made him a hit with audiences, particularly children and women (the latter usually finding the trio's humor juvenile and uncouth). The fact that Curly had to shave his head for the act led him to feel unappealing to women. To mask his insecurities, he ate and drank to excess and caroused whenever the Stooges made personal appearances, which was approximately seven months out of the year. His weight ballooned in the 1940s, and his blood pressure became dangerously high. His wild lifestyle and constant drinking eventually caught up with him in 1945, and his performances suffered. After suffering a minor stroke, Moe felt it best Curly take a leave of absence to recover, but Harry Cohn adamantly refused to allow it, forcing Curly to continue the already-taxing work in his ill-health. In his last dozen shorts (ranging from 1945's "If a Body Meets a Body" through 1947's "Half-Wits Holiday") he was seriously ill, struggling to get through even the most basic scenes, necessitating the use of stock footage from older shorts to make up the slack.
During the final day of filming "Half-Wits Holiday" on May 6, 1946, he suffered a debilitating stroke on the set, ending his 14-year career and temporarily forcing the Stooges into retirement. While they hoped for a full recovery, Curly never appeared in a film again except for a single cameo appearance in the third film after Shemp returned to the trio, "Hold That Lion!" It was the only film that contained all four of the original Stooges (the three Howard brothers and Larry) on screen simultaneously. According to Jules White, this anomaly came about when Curly visited the set one day, and White had him do this bit for fun. (Curly's cameo appearance was recycled in the 1953 remake "Booty and the Beast".) In 1948, Curly was supposed to play a cameo role in "Malice in the Palace" as the chef, but beyond posing in costume for a lobby card photo, there is no evidence of his contribution. Larry played the role of the chef in the final cut. The movie itself came out a year later.
Shemp's return.
Moe asked older brother Shemp to take Curly's place but Shemp was hesitant to rejoin the Stooges, as he was enjoying a successful solo career at the time of Curly's stroke. He realized, however, that not reviving the Stooges would mean the end of Moe's and Larry's film careers. Shemp wanted some kind of assurance that rejoining them would be only temporary, and that he could leave the Stooges once Curly recovered. Curly, however, remained ill until his death of a cerebral hemorrhage from additional strokes on January 18, 1952. Joe DeRita was also starring in his own short subject series at Columbia at the time, and Stooges producer-director Jules White attempted to recruit Joe DeRita for the Three Stooges, because he wanted "another Curly." However, the strong-willed DeRita refused to change his act or imitate another performer, and White eventually gave up on DeRita (DeRita's own short-subject contract was not renewed after four films).
Shemp appeared with the Stooges in 76 shorts and a low-budget Western comedy feature titled "Gold Raiders" in which the screen time was evenly divided with B-picture cowboy hero George O'Brien. Shemp's return improved the quality of the films, as the last few with Curly had been marred by his sluggish performances. Entries like "Out West", "Squareheads of the Round Table", and "Punchy Cowpunchers" proved that there was life after Curly, and that Shemp could easily hold his own. This was due in part to the presence of new director Edward Bernds, who joined the team in 1945 when Curly was failing. Bernds sensed that routines and plotlines that worked well with Curly as the comic focus did not fit Shemp's persona, and decidedly allowed the comedian to develop his own Stooge characterization. Jules White, however, persisted in employing the "living cartoon" style of comedy that reigned during the Curly era. White would force either Shemp or Moe to perform similar gags and mannerisms originated by Curly, resulting in what appeared to be lackluster imitation. Most acutely, it created the "Curly vs. Shemp" debate that overshadowed the act upon the former's departure. Though the Stooges lost some of their charm and inherent appeal to children after Curly retired, some excellent films were produced with Shemp, a comedian who often performed best when allowed to improvise on his own.
Unlike the Curly era, the films from the Shemp era contrast sharply, due to the individual directing styles of Bernds and White. From 1947 to 1952, Bernds hit a string of successes, including "Fright Night", "The Hot Scots", "Mummy's Dummies", "Crime on Their Hands", "A Snitch in Time", "Three Arabian Nuts" and "Gents in a Jam". Two of the team's finest efforts, "Brideless Groom" and "Who Done It?", were directed by Bernds. White also contributed a few par entries, such as "Hold That Lion!", "Hokus Pokus", "Scrambled Brains", "A Missed Fortune" and "Corny Casanovas".
Another benefit from the Shemp era was that Larry was given more time on screen. Throughout most of the Curly era, Larry was relegated to a background role, only being called upon to break up a potential scuffle between Moe and Curly. By the time Shemp rejoined the Stooges, Larry was allotted equal footage, even becoming the focus of several films ("Fuelin' Around", "He Cooked His Goose").
The Shemp years also marked a major milestone: the Stooges' first appearance on television. In 1948, they guest starred on Milton Berle's popular "Texaco Star Theater" and Morey Amsterdam's "The Morey Amsterdam Show". By 1949, the team filmed a pilot for ABC-TV for their own weekly television series, titled "Jerks of All Trades". Though it never sold, their slapstick humor was in great demand on television programs looking to fill air space. The team went on to appear on "Camel Comedy Caravan" (also known as "The Ed Wynn Show"), "The Kate Smith Hour", "The Colgate Comedy Hour", "The Frank Sinatra Show" and "The Eddie Cantor Comedy Theatre", among others.
In 1952, however, the Stooges lost some key players at Columbia. The studio decided to downsize its short subject division, resulting in producer Hugh McCollum being discharged and director Edward Bernds resigning out of loyalty to McCollum. Bernds had been contemplating his resignation for some time, as he and Jules White were often at odds. Screenwriter Elwood Ullman followed suit, leaving only White to both produce and direct the Stooges' remaining Columbia comedies. Not long after, the quality of the Stooge shorts declined with White now assuming complete control over Stooge films. Production was significantly faster, with the former four-day filming schedules now tightened to two or three days. In another cost-cutting measure, White would create a "new" Stooge short by borrowing footage from old ones, setting it in a slightly different storyline, and filming a few new scenes often with the same actors in the same costumes. White was initially very subtle when recycling older footage: he would reuse only a single sequence of old film, re-edited so cleverly that it was not easy to detect. The later shorts were cheaper and the recycling more obvious, with as much as 75% of the running time consisting of old footage. White came to rely so much on older material that he could film the "new" shorts in a single day. Plus, any new footage filmed in order to link older material suffered from White's penchant for telling his actors how to act. Shemp in particular disliked working with White.
Three years after Curly's death, Shemp died of a sudden heart attack at age 60 on November 22, 1955 during a taxi ride home with a friend after attending a boxing match. Moe was stunned and contemplated disbanding the Stooges. However, Cohn reminded him that the team owed Columbia four additional films with Shemp. Recycled footage, combined with new footage utilizing Columbia supporting player Joe Palma as Shemp's double (filmed from the back), were used to complete the last four films originally planned with Shemp: "Rumpus in the Harem", "Hot Stuff", "Scheming Schemers", and "Commotion on the Ocean".
Joe Besser replaces Shemp.
Joe Besser replaced Shemp in 1956, appearing in the final 16 Stooge shorts at Columbia. Besser had earlier starred in his own short-subject comedies for the studio from 1949 to 1956 and appeared in supporting roles in a variety of movies, making his persona sufficiently well known that he was frequently caricatured in "Looney Tunes" animated shorts. Besser, noting how one side of Larry Fine's face appeared "calloused", had a clause in his contract specifically prohibiting him from being smacked beyond an infrequent tap (though this restriction was later lifted). Besser was the only "third" Stooge that dared to hit Moe back in retaliation and get away with it; Larry Fine was also known to hit Moe on occasion, but always with serious repercussions. "I usually played the kind of character who would hit others back", Besser recalled. 
Despite Besser's prolific film and stage career, Stooge entries featuring him have been sometimes tagged as the trio's weakest period. During his time with the act, the team's shorts were being assailed for being questionable models for youth, and in response began to resemble television sitcoms. Sitcoms, however, were available for free on television, making the short film a throwback to a bygone era.
Though Besser was a very funny comic (he was quite popular as spoiled-brat "Stinky" on "The Abbott and Costello Show"), his whining mannerisms ("Not so ha-r-r-d!", "You're m-e-a-n!") did not quite jell with the eye-gouging, hand-biting, belly-punching Stooge antics, though it did create the verbal friction between Moe and Larry that succeeded in making put-down banter. Times had changed, and Besser was not solely to blame for the lackluster quality of these final entries: the scripts were tired rehashes of earlier efforts (seven of the 16 films were edited remakes), the budgets were lower than they had been, and Moe's and Larry's performances were tired. They were growing older, and could no longer perform pratfalls and physical comedy as they once had. Besser also suggested that Moe and Larry comb their hair back and discard their trademark hairstyles to give them a more gentlemanly appearance. Surprisingly, Moe and Jules White approved of the idea, but used it sparingly in order to match the old footage in films that were remakes.
Despite their longstanding reputation, the final Stooge shorts did have their comedic moments. In general, the remakes had the traditional Stooges knockabout look and feel, like "Pies and Guys" (a scene-for-scene remake of "Half-Wits Holiday", which itself was a reworking of the earlier "Hoi Polloi"), "Guns a Poppin", "Rusty Romeos" and "Triple Crossed." In contrast, "Hoofs and Goofs", "Horsing Around" and "Muscle Up a Little Closer" mostly resembled the sitcoms of the era. "A Merry Mix Up" and "Oil's Well That Ends Well" are also amusing, while the musical "Sweet and Hot" (long detested by fans) deserves some credit for straying from the norm. The space craze also took hold of the American public at the time, resulting in three entries focusing on space travel: "Space Ship Sappy", "Outer Space Jitters" and "Flying Saucer Daffy."
The inevitable occurred soon enough. Columbia was the last studio still producing short films, and the market for such films had all but dried up. As a result, the studio opted not to renew the Stooges' contract when it expired in December 1957. The final comedy produced was "Flying Saucer Daffy", filmed on December 19–20, 1957. Several days later, the Stooges were unceremoniously fired from Columbia Pictures after 24 years of making low-budget shorts.
No formal "goodbyes" or congratulatory celebrations occurred in recognition of their many years of dedication and service and the dollars their comedies had earned for the studio. Moe later visited Columbia several weeks after their dismissal to say goodbye to several executives. He was stopped by a guard at the gate (obviously not a Stooges fan) as he did not have the current year's studio pass. Moe was ultimately refused entry, later stating that it was a momentary crushing blow to his pride.
Although no longer working for Columbia, the studio had enough completed films on the shelf to keep releasing new Stooge comedies for another 18 months, though not in the order in which they were produced. The final Stooge release, "Sappy Bull Fighters", did not reach theaters until June 4, 1959. With no active contract in place, Moe and Larry discussed plans for a personal appearance tour. In the meantime, Besser's wife suffered a minor heart attack and he preferred to stay local, leading him to withdraw from the act. For the first time in nearly 30 years, the Stooges were at a dead end.
The comeback: Moe, Larry and Curly Joe.
Seeing the success of how television, in its early years, allowed movie studios to unload a backlog of short films thought unmarketable, the Stooge films seemed perfect for the burgeoning genre. ABC had even expressed interest as far back as 1949, purchasing exclusive rights to 30 of the trio's shorts. However, the success of television revivals for such names as Laurel and Hardy, Woody Woodpecker, Popeye, Tom and Jerry and the "Our Gang" series in the late 1950s led Columbia to cash in again on the Stooges. In January 1958, Columbia's television subsidiary Screen Gems offered a package consisting of 78 Stooge shorts (primarily from the Curly era), which were well received. Almost immediately, an additional 40 shorts hit the market, and by 1959, all 190 Stooge shorts were airing regularly. Due to the massive quantity of Stooge product available for broadcast, the films were broadcast Monday through Friday, leading to heavy exposure aimed squarely at children. This led parents to watch alongside of their offspring, and before long, Howard and Fine found themselves in high demand. Moe quickly signed movie and burlesque comic Joe DeRita (who had starred in four of his own comedy Columbia shorts a decade earlier: "Slappily Married", "The Good Bad Egg", "Wedlock Deadlock" and "Jitter Bughouse") for the "third Stooge" role. DeRita, whose hairstyle while working solo had vaguely resembled Shemp's, adopted first a crew cut and then a completely shaven hairstyle to accentuate his slight resemblance to Curly Howard and became "Curly Joe" (also to make it easier to distinguish him from Joe Besser, the earlier Stooge called Joe).
This Three Stooges lineup appeared in six full-length Stooges movies from 1959 to 1965: "Have Rocket, Will Travel" (1959), "Snow White and the Three Stooges" (1961), "The Three Stooges Meet Hercules" (1962), "The Three Stooges in Orbit" (1962), "The Three Stooges Go Around the World in a Daze" (1963), and "The Outlaws IS Coming!" (1965). The films were aimed at the kiddie-matinee market, and most were black and white farce outings in the Stooge tradition, with the exception of "Snow White and the Three Stooges", a children's fantasy in Technicolor. They also appeared in an extremely brief cameo as firemen (the role that helped make the original Stooges lineup famous in "Soup to Nuts") in the film "It's a Mad, Mad, Mad, Mad World" in 1963, and in a larger capacity that same year in "4 for Texas" starring Frank Sinatra and Dean Martin. Throughout the 1960s, The Three Stooges were one of the most popular and highest-paid live acts in America.
The Stooges also tried their hand at another weekly television series in 1960 titled "The Three Stooges Scrapbook". Filmed in color and with a laugh track, the first episode, "Home Cooking", featured the boys rehearsing for a new television show. Like "Jerks of All Trades", the pilot did not sell. However, Norman Maurer was able to reuse the footage (reprocessed in black and white) for the first 10 minutes of the "The Three Stooges in Orbit".
The trio also filmed 41 short comedy skits for "The New Three Stooges", which features a series of 156 animated cartoons produced for television. The Stooges appeared in live-action color footage, which preceded and followed each animated adventure in which they voiced their respective characters.
Last years.
In late 1969, the Stooges began production on a half-hour pilot episode for a syndicated 39-episode TV series entitled "Kook's Tour", a combination travelogue-sitcom that had the "retired" Stooges traveling vaious parts of the world, with the episodes filmed on location. On January 9, 1970, during production of the pilot, Larry suffered a paralyzing stroke, ending his acting career along with plans for the television series. Though the pilot was unfinished and several key shots were missing, Norman Maurer added nature scenes and made the pilot a 52-minute special that was released to the Super 8 home video market. It is the last film in which the Stooges appeared.
Later that year, Moe Howard's grandson, Jeffrey [Maurer] Scott, wrote a feature film script titled "Make Love, Not War", or "Make Mine Manila". Moe Howard, Joe DeRita, and Emil Sitka were cast as POWs in a World War II Japanese prison camp, plotting an escape with fellow prisoners. The film would have been a departure from typical Stooge fare, with dark-edged humor and scenes of war violence, but production never advanced beyond the script stage.
Three years later, in mid-December 1974, Larry suffered yet another stroke at the age of 72 and four weeks later an even more massive one. Slipping into a coma, he died a week later from a cerebral hemorrhage on January 24, 1975.
The Three Stooges were scheduled to costar in the R-rated film, "Blazing Stewardesses", produced under the title "The Jet Set". According to DVD commentary by producer Sam Sherman, original plans were for Moe and Curly Joe to appear with Larry, who would participate in a wheel chair. When Larry died in January 1975, Moe asked longtime Stooge foil and personal friend Emil Sitka to join the team. Emil agreed, and he stepped into the middle spot as 'Harry,' Larry's brother. The team was signed, publicity shots were taken, but one week prior to the shooting date, Moe fell ill from lung cancer and the Stooges had to back out; he died in May 1975, after production was completed. The surviving Ritz Brothers replaced the Stooges and performed much of their act's schtick, including the precision dance routine, first seen in "Sing, Baby, Sing" (1936) costarring original Stooge leader Ted Healy.
In 1974, Moe gave DeRita permission to form a "new" Three Stooges. He recruited burlesque and vaudeville veterans Mousie Garner and Frank Mitchell to replace Moe and Larry for nightclub engagements. Garner 
had worked with Healy decades earlier in an abortive attempt to replace the Stooges after they had split from Healy. Mitchell had also replaced Shemp as the "third stooge" in a 1929 Broadway play and appeared in two of the Stooges' short subjects in '53. DeRita later said the act fared poorly with minimal bookings.
Joe Besser died of heart failure on March 1, 1988, followed by Joe DeRita of pneumonia on July 3, 1993. Emil Sitka, who was announced as a Stooge but never performed as such, died of a stroke on January 16, 1998.
Legacy and perspective.
Over half a century since their last short film was released, the Three Stooges remain wildly popular with audiences. Their films have never left the television airwaves since first appearing in 1958, and they continue to delight old fans while attracting new legions of fervent admirers. A hard-working group of working-class comedians who were never the critics' darlings, the durable act endured several personnel changes in their careers which would have permanently sidelined a less-persistent act. The Stooges would not have lasted as long as they did as a unit without Moe Howard's guiding hand.
The Ted Okuda/Edward Watz-penned book "The Columbia Comedy Shorts" puts the Stooges' legacy in critical perspective:
Many scholarly studies of motion picture comedy have overlooked the Three Stooges entirely – and not without valid reasoning. Aesthetically, the Stooges violated every rule that constitutes "good" comedic style. Their characters lacked the emotional depth of Charlie Chaplin and Harry Langdon; they were never as witty or subtle as Buster Keaton. They were not disciplined enough to sustain lengthy comic sequences; far too often, they were willing to suspend what little narrative structure their pictures possessed in order to insert a number of gratuitous jokes. Nearly every premise they have employed (spoofs of westerns, horror films, costume melodramas) has been done to better effect by other comedians. And yet, in spite of the overwhelming artistic odds against them, they were responsible for some of the finest comedies ever made. Their humor was the most undistilled form of low comedy; they were not great innovators, but as quick laugh practitioners, they place second to none. If public taste is any criterion, the Stooges have been the reigning kings of comedy for over fifty years.
Beginning in the 1980s, the Stooges finally began to receive critical recognition. The release of nearly all their films on DVD by 2010 has allowed critics of Joe Besser and Joe DeRita – often the recipients of significant fan backlash – to appreciate the unique style of comedy both men brought to the Stooges. In addition, the DVD market in particular has allowed fans to view the entire Stooge film corpus as distinct periods in their long, distinguished career instead of comparing one Stooge to the other (the Curly vs. Shemp debate continues to this day).
The team appeared in 220 films. In the end, it is the durability of the 190 timeless short films the Stooges made at Columbia Pictures that acts as an enduring tribute to the comedy team. Their continued popularity worldwide has proven to even the most skeptical critics that their films are funny. American television personality Steve Allen went on record in the mid-1980s saying "though they never achieved widespread critical acclaim, they achieved exactly what they had always intended to do: they made people laugh."
Lineups on film.
Moe Howard
Real Name: Moses Harry Horwitz
Born: (1897--) 19, 1897
Died: 4, 1975(1975--) (aged 77)
Cause of death: Lung cancer
Stooge years: 1921–1969
Larry Fine
Real Name: Louis Feinberg
Born: (1902--) 5, 1902
Died: 24, 1975(1975--) (aged 72)
Cause of death: Stroke
Stooge years: 1925–1969
Shemp Howard 
Real Name: Samuel Horwitz
Born: (1895--) 11, 1895
Died: 22, 1955(1955--) (aged 60)
Cause of death: Heart attack
Stooge years: 1923–1932, 1946–1955
Curly Howard
Real Name: Jerome Lester Horwitz
Born: (1903--) 22, 1903
Died: 18, 1952(1952--) (aged 48)
Cause of death: Cerebral hemorrhage
Stooge years: 1932–1946
Joe Besser
Born: (1907--) 12, 1907
Died: 1, 1988(1988--) (aged 80)
Cause of death: Heart failure
Stooge years: 1956–1957
Curly Joe DeRita 
Real Name: Joseph Wardell
Born: (1909--) 12, 1909
Died: 3, 1993(1993--) (aged 83)
Cause of death: Pneumonia
Stooge years: 1958–1969
Shorts filmography.
The Three Stooges appeared in 220 films throughout their career. Of those 220, 190 short films were made for Columbia Pictures between 1934 and 1959, for which the trio are best known. Their contract was extended each year from 1934 until the final one expired on December 31, 1957. The last 8 of the 16 shorts with Joe Besser were released soon afterward.
C3 Entertainment, Inc..
Throughout their career, Moe acted as both their main creative force and business manager. Comedy III (C3) was formed by Moe, Larry and Joe DeRita in 1959 to manage all business and merchandise transactions for the team. C3 was basically in the background, with Moe's son-in-law Norman Maurer managing the comedy teams' film interests under Normandy Productions, and merchandising affairs under Norman Maurer Productions (NMP). Norman Maurer died of cancer in 1986.
In 1994, the heirs of Larry Fine and Joe DeRita filed a breach-of-contract lawsuit against Moe's family, particularly Joan Howard Maurer and her son Jeffrey, who had inherited the NMP/Normandy business. The lawsuit alleged that the Howards had cheated the DeRita and Fine families out of their share of royalties. Howard was ordered to pay $2.6 million in damages; $1.6 million was for compensatory damages to Jean DeRita, while the remaining $1 million was divided between four of Fine's grandchildren. The Fine and DeRita families were represented by California attorney Bela G. Lugosi. Jr.
The resulting 1994 lawsuit led to the reestablishment of C3 as a three-way interest of Fine/[Moe]Howard/DeRita. The DeRita heirs received the proxy to the Howard share, giving them majority control on the company's management. Joe DeRita's stepsons, Robert and Earl Benjamin, became the senior management of C3, with Lugosi, Jr. serving as an executive board member for several years. The Benjamins later incorporated the company, and C3 is currently the owner of all Three Stooges trademarks and merchandising. Larry's grandson Eric Lamond is the representative of the Fines' one-third interest in the company.
Since 1995, C3 has authorized and provided the services of veteran actors Jim Skousen, Alan Semok, and Dave Knight (as Moe, Larry, and Curly respectively) for numerous "personal appearances" by the Stooge characters for a variety of merchandising and promotional events. This latter day trio has also provided voices for the characters in a variety of radio spots, merchandising tie-ins, and most recently for the first new Three Stooges short in 50 years. A CGI animation by Famous Frames Mobile Interactive, a first-wave "new media" company, entitled "The Grate Debate", has Moe, Larry and Curly running for President.
Television.
A handful of Three Stooges shorts first aired on television in 1949, on the American Broadcasting Company (ABC) network. It was not until 1958 that Screen Gems packaged 78 shorts for national syndication; the package was gradually enlarged to encompass the entire library of 190 shorts. In 1959, KTTV in Los Angeles purchased the Three Stooges films for air, but by the early 1970s, rival station KTLA began airing the Stooges films, keeping them in the schedule until early 1994. The Family Channel ran the shorts as part of their "Stooge TV" block from February 19, 1996, to January 2, 1998. In the late 1990s, AMC had held the rights to the Three Stooges shorts, originally airing them under a programming block called "Stooges Playhouse". In 1999, it was replaced with a program called "N.Y.U.K. (New Yuk University of Knuckleheads)", which starred actor/comedian Leslie Nielsen. The program would show three random Stooge shorts. Nielsen hosts the program as a college instructor, known as the Professor of Stoogelogy, who teaches to the students lectures on the Three Stooges before the Stooges' shorts air. The block aired several shorts often grouped by a theme, such as similar schtick used in different films. Although the block was discontinued after AMC revamped their format in 2002, the network still ran Stooges shorts occasionally. The AMC run ended when Spike TV picked them up in 2004, airing them in their "Stooges Slap-Happy Hour". By 2007, the network had discontinued the block. Although Spike did air Stooges shorts for a brief period of time after the block was canceled, as of late April 2008, Three Stooges has disappeared from the network's schedule entirely. The Three Stooges returned on December 31, 2009, on AMC, starting with the "Countdown with the Stooges" New Year's Eve marathon. AMC planned to put several episodes on their website in 2010. The "Stooges" shorts were best known in Chicago as a part of a half hour late afternoon show on WGN-TV hosted by Bob Bell as "Andy Starr" in the 1960s.
Since the 1990s Columbia and its television division's successor, Sony Pictures Television, has preferred to license the Stooges shorts to cable networks, precluding the films from being shown on local broadcast TV. Two stations in Chicago and Boston, however, signed long-term syndication contracts with Columbia years ago and have declined to terminate them. Thus, WMEU-CD in Chicago currently airs all 190 Three Stooges shorts on Saturday afternoons from 1-3 pm and Sunday evenings from 9–11 pm. WSBK-TV in Boston airs Stooge shorts and feature films, including an annual New Year's Eve marathon. KTLA in Los Angeles dropped the shorts in 1994, but brought them back in 2007 as part of a special retro-marathon commemorating the station's 60th anniversary. Since that time, the station's original 16mm Stooges film prints have aired occasionally as part of mini-marathons on holidays. Antenna TV, a network broadcasting on the digital subchannels of local broadcast stations (owned by Tribune Broadcasting, who also owns KTLA), began airing the Stooges shorts upon the network's January 1, 2011 launch, which ran in multi-hour blocks on weekends through December 29, 2012; most of the Three Stooges feature films are also broadcast on the network, through Antenna TV's distribution agreement with Sony Pictures Entertainment (whose Columbia Pictures subsidiary released most of the films). Although the network no longer airs Stooges shorts regularly, they are occasionally shown as filler if a movie runs short, as well as in holiday marathons.
Some of the Stooge films have been colorized by two separate companies. The first colorized DVD releases, distributed by Sony Pictures Home Entertainment, were prepared by West Wing Studios in 2004. The following year, Legend Films colorized the public domain shorts "Malice in the Palace", "Sing a Song of Six Pants", "Disorder in the Court" and "Brideless Groom". "Disorder in the Court" and "Brideless Groom" also appears on two of West Wing's colorized releases. In any event, the Columbia-produced shorts (aside from the public domain films) are handled by Sony Pictures Entertainment, while the MGM Stooges shorts are owned by Warner Bros. via their Turner Entertainment division. Sony offers 21 of the shorts on their web platform Crackle, along with eleven Minisodes. Meanwhile, the rights to the Stooges' feature films rests with the studios that originally produced them (Columbia/Sony for the Columbia films, and 20th Century Fox for the Fox films).
Home video.
Between 1980 and 1985, Columbia Pictures Home Entertainment and RCA/Columbia Pictures Home Video released a total of thirteen Three Stooges volumes on VHS, Beta and Laserdisc, each containing three shorts. These titles were later reissued on VHS by its successor, Columbia TriStar Home Video, between 1993 and 1996, with a DVD reissue between 2000 and 2004.
"The Three Stooges Collection".
On October 30, 2007, Sony Pictures Home Entertainment released a two-disc DVD set entitled "The Three Stooges Collection, Volume One: 1934–1936". The set contains shorts from the first three years the Stooges worked at Columbia Pictures, marking the first time ever that all 19 shorts were released in their original theatrical order to DVD. Additionally, every short was remastered in high definition, a first for the Stooge films. Previous DVD releases were based on themes (wartime, history, work, etc.), and sold poorly. Fans and critics alike praised Sony for finally giving the Stooges the proper DVD treatment. One critic states "the Three Stooges on DVD has been a real mix'n match hodgepodge of un-restored titles and illogical entries. This new...boxset...seems to be the first concerted effort to categorize their huge body of work chronologically with many shorts seeing the digital light for the first time." Videolibrarian.com critic added "finally, the studio knuckleheads got it right! The way that the Three Stooges have been presented on home video has been a real slap in the face and poke in the eye to fans. They've been anthologized, colorized, and public domain-ed, as their shorts have been released and re-released in varying degrees of quality. Highly recommended." Critic James Plath of DVDtown.com added, "Thank you, Sony, for finally giving these Columbia Pictures icons the kind of DVD retrospective that they deserve. Remastered in High Definition and presented in chronological order, these short films now give fans the chance to appreciate the development of one of the most successful comedy teams in history."
The chronological series proved very successful and wildly popular, and Sony wasted little time preparing the next set for release. "Volume Two: 1937–1939" was released on May 27, 2008, followed by "Volume Three: 1940–1942" three months later on August 26, 2008. Demand exceeded supply, proving to Sony that they had a hit on their hands. In response, "Volume Four: 1943–1945" was released on October 7, 2008, a mere two months after its predecessor. The global economic crisis slowed down the release schedule after Volume Four, and "Volume Five: 1946–1948" was belatedly released on March 17, 2009. "Volume Five" is the first in the series to feature Shemp Howard with the Stooges and the final volume to feature Curly Howard. "Volume Six: 1949–1951" was released June 16, 2009, and "Volume Seven: 1952–1954" was released on November 10, 2009. "Volume Seven" included 3-D glasses for the two shorts: "Spooks!" and "Pardon My Backfire". As of 2013, the 3-D versions of the two shorts in this volume have been removed. "Volume Eight: 1955-1959" was released on June 1, 2010. This was the final volume of the Stooges collection, bringing the series to a close. Instead of two discs, "Volume Eight" includes three discs. It is also the final volume to feature Shemp Howard and the first and only volume to feature Joe Besser. For the first time in history, all 190 "Three Stooges" short subjects became available to the public, uncut and unedited.
A 20-disc DVD boxed set entitled "The Three Stooges: The Ultimate Collection", including all 190 shorts from volumes 1–8 and additional bonus material, was released on June 5, 2012.
Feature motion pictures.
The Three Stooges also made appearances in many feature-length movies in the course of their careers:
Joe Besser never appeared with the Stooges in a feature film.
Three feature-length Columbia releases were actually packages of older Columbia shorts. "Columbia Laff Hour" (introduced in 1956) was a random assortment that included the Stooges among other Columbia comedians like Andy Clyde, Hugh Herbert, and Vera Vague; the content and length varied from one theater to the next. "Three Stooges Fun-o-Rama" (introduced in 1959) was an all-Stooges show capitalizing on their TV fame, again with shorts chosen at random for individual theaters. "The Three Stooges Follies" (1974) was similar to "Laff Hour", with a trio of Stooge comedies augmented by Buster Keaton and Vera Vague shorts, a Batman serial chapter, and a Kate Smith musical.
Museum.
Gary Lassin, grandnephew-in-law of Larry Fine, opened the Stoogeum in 2004, in a renovated architect's office in Spring House, Pennsylvania, 25 mi north of Philadelphia. The museum-quality exhibits fill three stories 10000 sqft, including an 85-seat theater. Peter Seely, editor of the book "Stoogeology: Essays on the Three Stooges" said that the Stoogeum has ""more stuff than I even imagined existed"." 2,500 people visit it yearly, many during the annual Three Stooges Fan Club gathering in April.
In other media.
Comic books.
Over the years, several Three Stooges comics were produced.
Music.
Beginning in 1959, the Three Stooges began to appear in a series of novelty records. Their first recording was a 45 rpm single of the title song from "Have Rocket, Will Travel." The trio released additional singles and LPs on the Golden and Coral labels, mixing comedy adventure albums and off-beat renditions of children's songs. Their final recording was the 1966 "Yogi Bear and the Three Stooges Meet the Mad, Mad, Mad Dr. No-No", which incorporated the Three Stooges into the cast of the Yogi Bear cartoons.
Radio.
Sirius XM Radio aired a special about the Stooges hosted by Tom Bergeron on Friday, July 31, 2009, at 2:00PM on the Sirius Howard 101 channel. Bergeron had conducted the interviews at the age of 16 back when he was still in high school in 1971. The television host had the tapes in storage for many years and was convinced on-air during an interview with Howard Stern to bring them in and turn it into a special.
After finding "the lost tapes", Bergeron brought them into Stern's production studio. He stated that the tapes were so old that the tapes with the Larry Fine interviews began to shred as Stern's radio engineers ran them through their cart players. They only really had one shot, but fortunately for Stooges fans the tapes were saved.
"The Lost Stooges Tapes" was hosted by Tom Bergeron, with modern commentary on the almost 40-year-old interviews that he had conducted with Larry Fine and Moe Howard. At the times of these interviews, Moe was still living at home and Larry had suffered a stroke and was living in a Senior Citizen's home.
Sports.
Canadian-American professional wrestler Curly Moe, whose "gimmick" was based on Curly Howard, was a popular fan favorite in International World Class Championship Wrestling during the early-1990s. The promotion billed Curly Moe as the real-life nephew of Curly and Moe Howard which attracted some attention from the media.
Television.
In addition to the unsuccessful television series pilots "Jerks of All Trades", "The Three Stooges Scrapbook", and the incomplete "Kook's Tour", the Stooges appeared in a show called "The New Three Stooges" which ran from 1965 to 1966. This series featured a mix of forty-one live-action segments which were used as wraparounds to 156 animated Stooges shorts. "The New Three Stooges" became the only regularly scheduled television show in history for the Stooges. Unlike other films shorts that aired on television, like the "Looney Tunes", "Tom and Jerry", and "Popeye", the film shorts of the Stooges never had a regularly scheduled national television program to air in. When Columbia/Screen Gems licensed the film library to television, the shorts aired in any fashion the local stations chose (examples: late-night "filler" material between the end of the late movie and the channel's sign-off time; in "marathon" sessions running shorts back-to-back for one, one-and-a-half, or two hours; etc.) By the 1970s, some local stations showed a Columbia short and a New Three Stooges cartoon in the same broadcast.
In the October 13, 1967 "Who's Afraid of Mother Goose?" episode of ABC's "World-of-Disney"-like anthology series "Off to See the Wizard", the Three Stooges made a short appearance as "the three men in a tub".
Two episodes of Hanna-Barbera's "The New Scooby-Doo Movies" aired on CBS featuring animated Stooges as guest stars: the premiere, "Ghastly Ghost Town" (September 9, 1972) and "The Ghost of the Red Baron" (November 18, 1972). There also was a short-lived animated series, also produced by Hanna-Barbera, titled "The Robonic Stooges", originally seen as a featured segment on "The Skatebirds" (CBS, 1977–1978), featuring Moe, Larry, and Curly (voiced by Paul Winchell, Joe Baker and Frank Welker, respectively) as bionic cartoon superheroes with extendable limbs, similar to the later "Inspector Gadget". "The Robonic Stooges" later aired as a separate half-hour series, retitled "The Three Robonic Stooges" (each half-hour featured two segments of "The Three Robonic Stooges" and one segment of "Woofer And Whimper, Dog Detectives", the latter re-edited from episodes of "Clue Club", an earlier Hanna-Barbera cartoon series). There are also many "Stooges" references in the sitcom "ALF".
In a 1980 episode of "M*A*S*H", Charles Winchester shows disrespect for three Korean doctors by calling them "Moe, Larry and Curly", and says that they are "highly-respected individuals in the States". After Winchester throws out his back and is unable to relieve the pain through conventional methods (in real life, Winchester would've received an automatic medical discharge from the United States Army), Colonel Potter has the Korean doctors try acupuncture (much to Winchester's dismay), which cures Winchester. After the treatment, one of the doctors tells Winchester "Not bad for Three Stooges, huh?", having caught on to his mistreatment of them.
In the episode "Beware the Creeper" of "The New Batman Adventures", the Joker retreats to his hide-out after a quick fight with Batman. He yells out for his three henchmen "Moe? Larr? Cur?" only to find that they are not there. Shortly after that, Batman comes across these three goons in a pool hall; they have distinctive accents and hairstyles similar to those of Moe, Larry and Curly. These henchmen are briefly seen throughout the rest of the season.
2000 television film.
In spring of 2000, long-time Stooge fan Mel Gibson executive-produced a TV film ("The Three Stooges") about the lives and careers of the comedians. Playing Moe was Paul Ben-Victor, Evan Handler was Larry, John Kassir was Shemp and Michael Chiklis was Curly. It was filmed in Australia and was produced for and broadcast on ABC. It was based on Michael Fleming's authorized biography of the Stooges, "The Three Stooges: From Amalgamated Morons to American Icons". Its unflattering portrayal of Ted Healy led Healy's son to give media interviews calling the film inaccurate. Additional error of fact included the hint that Moe Howard was down on his luck later in life and worked as a gofer at the studio, where he, his brothers and Larry had formerly worked as actors. In reality, Moe was the most careful with his money, which he invested well. He and his wife Helen owned a comfortable house in Toluca Lake, in which they raised their children.
The film regularly runs on the American Movie Classics (AMC) channel.
Feature film revival.
A film about the Three Stooges, titled "The Three Stooges", started production on March 14, 2011, with 20th Century Fox and was directed by the Farrelly brothers. The film had been in what one critic has dubbed "development hell". The Farrellys, who wanted to make the film since 1996, said that they were not going to do a biopic or remake, but instead new Three Stooges episodes set in the present day. The film is broken up into three continuous episodes that revolves around the Stooges characters.
Casting the title characters proved difficult for the studio. Originally slated were Sean Penn to play Larry, Benicio del Toro to play Moe, and Jim Carrey to play Curly. Both Penn and del Toro left the project but returned while no official confirmation had been made about Jim Carrey. When del Toro was interviewed on MTV News for "The Wolfman", he spoke about playing Moe. He was later asked who was going to play Larry and Curly in the film and commented that he still thought that Sean Penn and Jim Carrey were going to play them, though he added, "Nothing is for sure yet."
A story in "The Hollywood Reporter" stated that Will Sasso would play Curly in the upcoming comedy and that Hank Azaria was the front runner to play Moe. Sasso was ultimately cast as Curly; Sean Hayes of "Will & Grace" was cast as Larry Fine, while Chris Diamantopoulos was cast as Moe. Jane Lynch later joined the cast, playing a nun.
The film was released on April 13, 2012, and grossed over $54 million worldwide.
On May 7, 2015, a sequel was announced, with Sean Hayes, Chris Diamantopoulos and Will Sasso all reprising their roles. Cameron Fay has been hired to write the script.
Video games.
In 1984 Gottlieb released an arcade game featuring the Stooges trying to find three kidnapped brides.
Later in 1987, game developers Cinemaware released a successful Three Stooges computer game, available for Apple IIGS, Amiga, Commodore 64, MS-DOS, and Nintendo Entertainment System (NES). Based on the Stooges earning money by doing odd jobs to prevent the foreclosure of an orphanage, it incorporated audio from the original films and was popular enough to be reissued for the Game Boy Advance in 2002, as well as for PlayStation in 2004. The 2012 film used a similar plot.
The Three Stooges also have a slot game adaptation created by Realtime Gaming
VCR game.
A VCR game was released by Pressman Toy Corporation in 1986, which utilized a number of classic Stooges clips.
In foreign languages.
In most other languages, the Three Stooges are known by their English name. In Chinese, however, the trio is known as "Sānge Chòu Píjiàng" () or "Huóbǎo Sānrénzǔ" (活寶三人組). "Sānge Chòu Píjiàng", literally "Three Smelly Shoemakers", which derives from a saying in the "Romance of the Three Kingdoms": "Sāngè chòu píjiàng shèngguò yīgè Zhūgě Liàng" (三個臭皮匠，勝過一個諸葛亮) or "Three smelly shoemakers (are enough to) overcome one Zhuge Liang [a hero of the story]", i.e. three inferior people can overpower a superior person when they combine their strength. "Huóbǎo Sānrénzǔ" translates as "Trio of Buffoons".
In Japanese they are known as "San Baka Taishō" () meaning "Three Idiot Generals" or "Three "Baka" Generals". The Japanese term "baka" (馬鹿, "fool" or "idiot", lit. "horse deer") is associated with the Chinese idiom "zhǐlù wéimǎ" (指鹿為馬; lit. "point at a deer and call it a horse", in Japanese "shika o sashite uma to nasu" [鹿を指して馬と為す]) meaning "deliberate misrepresentation for ulterior purposes". In Spanish they are known as ' or, roughly, "The Three Crackpots". In French and German usage, the name of the trio is partially translated as ' (though the French version of the movie adaptation used a fully translated name, "Les Trois Corniauds") and ' respectively. In Thai, the trio is known as ("3 Samunčhǭmpūan";  ]) or 3 พี่น้องจอมยุ่ง ("Phīnǭngčhǭmyung";  ]). In Portuguese, they are known as ' in Brazil, and "" in Portugal, "estarola" being a direct translation of "stooge", while "pateta" being more related to "goofy". In Persian the trio are dubbed as "سه نخاله". In Turkish, they are dubbed as "Üç Ahbap Çavuş" ("The Three Cronies").

</doc>
<doc id="36819" url="http://en.wikipedia.org/wiki?curid=36819" title="Laetitia Casta">
Laetitia Casta

Laetitia Marie Laure Casta (born 11 May 1978) is a French actress and model. Casta became a "GUESS? Girl" in 1993 and gained further recognition as a Victoria's Secret Angel from 1998 to 2000 and as a spokesperson for cosmetics company L'Oreal. She has appeared on over 100 covers of such popular magazines as "Cosmopolitan", "Vogue", "Rolling Stone", "Elle" and "Glamour", and modeled for designers like Yves Saint Laurent, Jean-Paul Gaultier, Chanel, Ralph Lauren, Tommy Hilfiger, J. Crew, Louis Vuitton, Givenchy, Roberto Cavalli, Lolita Lempicka, and Vivienne Westwood. Casta became an established actress, appearing in the films "Gainsbourg (A Heroic Life)", "Face" and "Blue Bicycle", as well as the play "Ondine" at the theatre Antoine.
Early life.
Casta was born in Pont-Audemer, Normandy, France. Her mother, Line Blin, is from Normandy. Her father, Dominique Casta, is from Corsica. She has an older brother, Jean-Baptiste, and a younger sister, . She spent her childhood in Normandy and Corsica.
Career.
Casta's modeling career reportedly began when she was discovered by the photographer Frederic Cresseaux, during a family holiday in her father's native Corsica, at age 15. After her unexpected registration by "Jeeby", Casta was elected Lumio 93.
Casta has been the L'Oreal Paris brand ambassador since 1998. She has been featured in Guess? Jeans, Tommy Hilfiger, Miu Miu, Pepe Jeans, Alberta Ferretti and XOXO ad campaigns. Casta has appeared on over 100 magazine covers including Victoria's Secret catalogs, Harper's Bazaar, "ELLE" magazine, and "Vogue" magazine. She walked down the annual Victoria's Secret Fashion Show in 1997, 1998, 1999, and 2000. Casta was one of the company's signature Victoria' Secret Angels from 1998 to 2000. She also appeared in three consecutive Sports Illustrated Swimsuit Issues, "Rolling Stone", and the Pirelli Calendar 1999 by Herb Ritts and 2000 by Annie Leibovitz.
In 1999, Casta was ranked first in a national survey ordered by the French Mayors Association to decide who should be the new model for the bust of "Marianne", an allegorical symbol of the French Republic, which stands inside every French town hall.
Casta became the focus of a controversy when, after being selected to be Marianne, newspapers in Britain and France reported that she had relocated to London where taxes on high earners are lower. Casta's father said she went to London for professional reasons; on a TV show, she also said that she rented a flat in London to be near her boyfriend. The French minister of the interior spoke about Casta on the radio; comparing the advantages of living in France with regard to the drawbacks of London after political opponents used Casta's relocation to London as an opportunity to criticise the government.
She is the face of fragrances Chanel's "Allure", Givenchy's "Forbidden flower", Cacharel's "Promise", Bulgari's "BLV II", Ralph Lauren's "Notorious", and in 15 June 2012 D&G's "Pour Femme" shot in Erice by Mario Testino. The Parisians could follow her Adventures in the Galeries Lafayette by Jean-Paul Goude. For Christmas 2011, Peter Lindbergh shot "True Love", the very thought of Casta at the summit of Manhattan and between the snowy lions of marble of the New York Public Library for Tiffany & Co.
On 10 March 2010, in Paris, she opened the Louis Vuitton Fall/Winter 2010 fashion show. On 27 September 2010, she closed the Roberto Cavalli SS 2011 fashion show in Milan.
For her first movie, Casta has made forays into the blockbuster "Asterix & Obelix Take On Caesar" directed by Claude Zidi, a live-action film of the comic book Asterix; in which Obelix, portrayed by Gerard Depardieu, plays a love interest for Falbala. Casta appeared in "Les Ames Fortes", a dramatic film directed by Raul Ruiz. Her interpretation of Brigitte Bardot in the movie "Gainsbourg (Vie heroique)" revealed the actress who received her first nomination at the Cesar Award. Casta served as a jury member at the 69th Venice International Film Festival in 2012.
Political involvement.
On 6 April 2008, Casta demonstrated in a White March of nonviolent protest to ask for the immediate release of Ingrid Betancourt, presidential candidate kidnapped since 2002 by the FARC.
On 30 April 2002, she attended the demonstration "Vive la Republique" after the first round election of the 2002 presidential election.
Personal life.
On 19 October 2001, Casta gave birth to her daughter, Sahteene, by photographer Stephane Sednaoui. Casta is engaged to Italian actor Stefano Accorsi. The couple have two children, a son named Orlando, born on 21 September 2006, and a daughter named Athena, born on 29 August 2009.

</doc>
<doc id="36821" url="http://en.wikipedia.org/wiki?curid=36821" title="Sutter's Mill">
Sutter's Mill

Sutter's Mill was a sawmill owned by 19th-century pioneer John Sutter. It was located in Coloma, California, at the bank of the South Fork American River. Sutter's Mill is most famous for its association with the California Gold Rush.
History.
On January 24, 1848, James W. Marshall found several flakes of gold that began the transformation of the territory to a bustling center of activity. 
On February 2, 1848, the Treaty of Guadalupe Hidalgo was signed in Mexico City which transferred the American Southwest to the United States. During the next seven years, approximately 300,000 people came to California (half by land and half by sea) to seek their fortunes from either mining for gold or selling supplies like picks and shovels to the gold prospectors.
Henry Bigler and Azariah Smith, wrote about their experience in their respective recollection or diary. Like several other people working at the mill, these two workers were discharged veterans of the Mormon Battalion. After this discovery at the mill, the "gold rush" era began and many people came from the east to find fortune. The era helped to transform people like Levi Strauss and Luzena Wilson.
Location.
The site of the mill is located on the South Fork American River. Marshall Gold Discovery State Historic Park is registered as California Historical Landmark #530. The current Sutter's Mill is a replica of the original building. It was built using Marshall's own drawings and an early day photo as reference for the recreation of the mill.
In popular culture.
The mill was also the namesake and inspiration for a song by singer-songwriter Dan Fogelberg. The mill was also the namesake for a song by the New Riders of the Purple Sage, and for Herb Sutter's blog.
Smithsonian.
The original flake of gold discovered at the mill is currently at the Smithsonian Institution.

</doc>
<doc id="36822" url="http://en.wikipedia.org/wiki?curid=36822" title="Sutter's Fort">
Sutter's Fort

Sutter's Fort State Historic Park is a California State Historic Park in Sacramento, California.
Location.
The compound was built near the junction of the American and Sacramento Rivers and is located at what is now the intersection of 27th and L Streets in the Midtown neighborhood of the city of Sacramento, California.
History.
Sutter's Fort was built in 1839 and originally called "New Helvetia" ("New Switzerland") by its builder, John Sutter. The fort was a 19th-century agricultural and trade colony in the Mexican Alta California Province. The fort was the first non-Indigenous community in the California Central Valley. The fort is famous for its association with the Donner Party, the California Gold Rush and the formation of Sacramento. It is notable for its proximity to the end of the California Trail and Siskiyou Trails for which it served as a waystation.
After gold was discovered at Sutter's Mill (also owned by Sutter) in Coloma, the fort was abandoned. The adobe structure has been restored to its original condition and is now administered by California Department of Parks and Recreation, although threatened with closure. It was designated a National Historic Landmark in 1961.
Description.
The Main Building of the fort is a two story adobe structure built between 1841 and 1843. This building is the only original surviving structure at the reconstructed Sutter's Fort State Historic Park. It was in here on January 28, 1848 that James Marshall met privately with Sutter in order to show Sutter the gold that Marshall had found during the construction of Sutter's sawmill along the American River only four days earlier. Sutter built the original fort with walls 2.5 ft thick and 15 to 18 ft high.
Following word of the Gold Rush, the fort was largely deserted by the 1850s and fell into disrepair.
In 1891, the Native Sons of the Golden West, who sought to safeguard many of the landmarks of California's pioneer days, purchased and rehabilitated Sutter's Fort when the City of Sacramento sought to demolish it. Repair efforts were completed in 1893 and the fort was given by the Native Sons of the Golden West to the State of California. In 1947, the fort was transferred to the authority of California State Parks.
Most of the original neighborhood structures were initially built in the late 1930s as residences, many of which have been converted to commercial uses such as private medical practices. The history of the neighborhood is largely residential. Pioneers took residence at Sutter's Fort around 1841.
Geography and geology.
Sutter's Fort is located on level ground at an elevation of approximately 20 ft above mean sea datum. The slope elevation decreases northward toward the American River and westward toward the Sacramento River. Slope elevation gradually increases to the south and east, away from the rivers. All surface drainage flows toward the Sacramento River. Groundwater in the vicinity flows south-southwest toward the Sacramento Delta; however, after peak rainfall, because of the swollen Sacramento River, the groundwater flow can actually reverse and flow away from the river.

</doc>
<doc id="36826" url="http://en.wikipedia.org/wiki?curid=36826" title="Dekker's algorithm">
Dekker's algorithm

Dekker's algorithm is the first known correct solution to the mutual exclusion problem in concurrent programming. The solution is attributed to Dutch mathematician Th. J. Dekker by Edsger W. Dijkstra in an unpublished paper on sequential process descriptions and his manuscript on cooperating sequential processes. It allows two threads to share a single-use resource without conflict, using only shared memory for communication. 
It avoids the strict alternation of a naïve turn-taking algorithm, and was one of the first mutual exclusion algorithms to be invented.
Introduction.
If two processes attempt to enter a critical section at the same time, the algorithm will allow only one process in, based on whose turn it is. If one process is already in the critical section, the other process will busy wait for the first process to exit. This is done by the use of two flags, entrance_intents[0] and entrance_intents[1], which indicate an intention to enter the critical section, and a turn variable that indicates who has priority between the two processes.
Pseudocode.
Processes indicate an intention to enter the critical section which is tested by the outer while loop. If the other process has not flagged intent, the critical section can be entered safely irrespective of the current turn. Mutual exclusion will still be guaranteed as neither process can become critical before setting their flag (implying at least one process will enter the while loop). This also guarantees progress as waiting will not occur on a process which has withdrawn intent to become critical. Alternatively, if the other process's variable was set the while loop is entered and the turn variable will establish who is permitted to become critical. Processes without priority will withdraw their intention to enter the critical section until they are given priority again (the inner while loop). Processes with priority will break from the while loop and enter their critical section. 
Dekker's algorithm guarantees mutual exclusion, freedom from deadlock, and freedom from starvation. Let us see why the last property holds. Suppose p0 is stuck inside the "while entrance_intents[1]" loop forever. There is freedom from deadlock, so eventually p1 will proceed to its critical section and set turn = 0 (and the value of turn will remain unchanged as long as p0 doesn't progress). Eventually p0 will break out of the inner "while turn ≠ 0" loop (if it was ever stuck on it). After that it will set entrance_intents[0] to true and settle down to waiting for entrance_intents[1] to become false (since turn = 0, it will never do the actions in the while loop). The next time p1 tries to enter its critical section, it will be forced to execute the actions in its "while entrance_intents[0]" loop. In particular, it will eventually set entrance_intents[1] to false and get stuck in the "while turn ≠ 1" loop (since turn remains 0). The next time control passes to p0, it will exit the "while entrance_intents[1]" loop and enter its critical section. 
If the algorithm were modified by performing the actions in the "while entrance_intents[1]" loop without checking if turn = 0, then there is a possibility of starvation. Thus all the steps in the algorithm are necessary.
Note.
One advantage of this algorithm is that it doesn't require special Test-and-set (atomic read/modify/write) instructions and is therefore highly portable between languages and machine architectures. One disadvantage is that it is limited to two processes and makes use of busy waiting instead of process suspension. (The use of busy waiting suggests that processes should spend a minimum of time inside the critical section.)
Modern operating systems provide mutual exclusion primitives that are more general and flexible than Dekker's algorithm. However, in the absence of actual contention between the two processes, the entry and exit from critical section is extremely efficient when Dekker's algorithm is used.
Many modern CPUs execute their instructions in an out-of-order fashion; even memory accesses can be reordered (see memory ordering). This algorithm won't work on SMP machines equipped with these CPUs without the use of memory barriers. 
Additionally, many optimizing compilers can perform transformations that will cause this algorithm to fail regardless of the platform. In many languages, it is legal for a compiler to detect that the flag variables "entrance_intents[0]" and "entrance_intents[1]" are never accessed in the loop. It can then remove the writes to those variables from the loop, using a process called Loop-invariant code motion. It would also be possible for many compilers to detect that the "turn" variable is never modified by the inner loop, and perform a similar transformation, resulting in a potential infinite loop. If either of these transformations is performed, the algorithm will fail, regardless of architecture.
To alleviate this problem, volatile variables should be marked as modifiable outside the scope of the currently executing context. For example, in C# or Java, one would annotate these variables as 'volatile'. Note however that the C/C++ "volatile" attribute only guarantees that the compiler generates code with the proper ordering; it does not include the necessary memory barriers to guarantee in-order "execution" of that code. C++11 atomic variables can be used to guarantee the appropriate ordering requirements — by default, operations on atomic variables are sequentially consistent so if the entrance_intents and turn variables are atomic a naive implementation will "just work". Alternatively, ordering can be guaranteed by the explicit use of separate fences, with the load and store operations using a relaxed ordering.

</doc>
<doc id="36827" url="http://en.wikipedia.org/wiki?curid=36827" title="Mutual exclusion">
Mutual exclusion

In computer science, mutual exclusion refers to the requirement of ensuring that no two concurrent processes are in their critical section at the same time; it is a basic requirement in concurrency control, to prevent race conditions. Here, a critical section refers to a period when the process accesses a shared resource, such as shared memory. The requirement of mutual exclusion was first identified and solved by Edsger W. Dijkstra in his seminal 1965 paper titled "Solution of a problem in concurrent programming control", and is credited as the first topic in the study of concurrent algorithms.
A simple example of why mutual exclusion is important in practice can be visualized using a singly linked list (See Figure 1). In such a linked list, the removal of a node is done by changing the “next” pointer of the preceding node to point to the subsequent node (e.g., if node "i" is being removed then the “next” pointer of node "i−1" will be changed to point to node "i+1"). In an execution where such a linked list is being shared between multiple processes, two processes may attempt to remove two different nodes simultaneously, resulting in the following problem: let nodes "i" and "i+1" be the nodes to be removed; furthermore, let neither of them be the head nor the tail; the next pointer of node "i−1" will be changed to point to node "i+1" and the next pointer of node "i" will be changed to point to node "i+2". Although both removal operations complete successfully, node "i+1" remains in the list since "i−1" was made to point to "i+1", skipping node "i" (which was the node that reflected the removal of "i+1" by having its next pointer set to "i+2"). This can be seen in Figure 1. This problem (normally called a race condition) can be avoided by using the requirement of mutual exclusion to ensure that simultaneous updates to the same part of the list cannot occur.
Enforcing mutual exclusion.
There are both software and hardware solutions for enforcing mutual exclusion. Some different solutions are discussed below.
Hardware solutions.
On uniprocessor systems, the simplest solution to achieve mutual exclusion is to disable interrupts during a process's critical section. This will prevent any interrupt service routines from running (effectively preventing a process from being preempted). Although this solution is effective, it leads to many problems. If a critical section is long, then the system clock will drift every time a critical section is executed because the timer interrupt is no longer serviced, so tracking time is impossible during the critical section. Also, if a process halts during its critical section, control will never be returned to another process, effectively halting the entire system. A more elegant method for achieving mutual exclusion is the busy-wait.
Busy-waiting is effective for both uniprocessor and multiprocessor systems. The use of shared memory and an atomic test-and-set instruction provides the mutual exclusion. A process can test-and-set on a location in shared memory, and since the operation is atomic, only one process can set the flag at a time. Any process that is unsuccessful in setting the flag can either go on to do other tasks and try again later, release the processor to another process and try again later, or continue to loop while checking the flag until it is successful in acquiring it. Preemption is still possible, so this method allows the system to continue to function - even if a process halts while holding the lock.
Several other atomic operations can be used to provide mutual exclusion of data structures; most notable of these is compare-and-swap (CAS). CAS can be used to achieve wait-free mutual exclusion for any shared data structure by creating a linked list where each node represents the desired operation to be performed. CAS is then used to change the pointers in the linked list during the insertion of a new node. Only one process can be successful in its CAS; all other processes attempting to add a node at the same time will have to try again. Each process can then keep a local copy of the data structure, and upon traversing the linked list, can perform each operation from the list on its local copy.
Software solutions.
Beside hardware-supported solutions, some software solutions exist that use busy waiting to achieve mutual exclusion. Examples of these include the following:
These algorithms do not work if out-of-order execution is used on the platform that executes them. Programmers have to specify strict ordering on the memory operations within a thread.
It is often preferable to use synchronization facilities provided by an operating system's multithreading library, which will take advantage of hardware solutions if possible but will use software solutions if no hardware solutions exist. For example, when the operating system's lock library is used and a thread tries to acquire an already acquired lock, the operating system could suspend the thread using a context switch and swap it out with another thread that is ready to be run, or could put that processor into a low power state if there is no other thread that can be run. Therefore, most modern mutual exclusion methods attempt to reduce latency and busy-waits by using queuing and context switches. However, if the time that is spent suspending a thread and then restoring it can be proven to be always more than the time that must be waited for a thread to become ready to run after being blocked in a particular situation, then spinlocks are an acceptable solution (for that situation only).
Types of mutual exclusion devices.
The solutions explained above can be used to build the synchronization primitives below:
Many forms of mutual exclusion have side-effects. For example, classic semaphores permit deadlocks, in which one process gets a semaphore, another process gets a second semaphore, and then both wait forever for the other semaphore to be released. Other common side-effects include starvation, in which a process never gets sufficient resources to run to completion; priority inversion, in which a higher priority thread waits for a lower-priority thread; and "high latency", in which response to interrupts is not prompt.
Much research is aimed at eliminating the above effects, often with the goal of guaranteeing non-blocking progress. No perfect scheme is known. Blocking system calls used to sleep an entire process. Until such calls became thread safe, there was no proper mechanism for sleeping a single thread within a process (see polling).

</doc>
<doc id="36832" url="http://en.wikipedia.org/wiki?curid=36832" title="Organisation for the Prohibition of Chemical Weapons">
Organisation for the Prohibition of Chemical Weapons

The Organisation for the Prohibition of Chemical Weapons (OPCW) is an intergovernmental organisation, located in The Hague, Netherlands.
The organisation promotes and verifies the adherence to the Chemical Weapons Convention which prohibits the use of chemical weapons and requires their destruction. The verification consists both of evaluation of declarations by member states and on-site inspections.
The organisation was awarded the 2013 Nobel Peace Prize because it had, with the Chemical Weapons Convention, "defined the use of chemical weapons as a taboo under international law" according to Thorbjørn Jagland, Chairman of the Norwegian Nobel Committee.
Organisational structure.
The activities of the OPCW and its core organisational structure are described in the Chemical Weapons Convention (whose members are all in OPCW). The principal body is the conference of states parties, which normally is convened yearly, and in which all countries participate and have equal voting rights. Countries are generally represented in the Conference by a permanent representative to the organisation, which in most cases is also the ambassador to the Netherlands. The conference decides on all main topics regarding the organisation (for example, taking retaliation measures) and the convention (approving guidelines, imposing retaliating measures against members).
The Executive Council is the executive organ of the organisation and consists of 41 States Parties, which are appointed by the Conference on a 2-year term. The Council amongst others oversees the budget and cooperates with the General Secretariat on all matters related to the convention.
The Technical Secretariat applies most of the activities mandated by the Council and is the body where most of the employees of the organisation work. The main activities of the OPCW are performed by the verification and the inspection division.
All States Parties make contributions to the OPCW budget, based on a modified UN scale of assessments.
Inspections.
Chemical weapons destruction facilities.
At all operational chemical weapons destruction facilities (as of August 2010 only in Russia and the United States), 24/7 inspections by the OPCW take place on site to verify the success of the destruction as well as the amounts of weapons being destroyed. In light of the hazardous environment in which the inspections take place, they are generally performed by evaluation via CCTV-systems.
Industry inspections.
Inspections are designed to verify compliance of States Parties with the requirements imposed on production and use of scheduled chemicals and to verify that industrial activities of member states have been correctly declared according to the obligation set by the CWC. The intensity and frequency of the inspections is dependent on the type of chemical produced (in descending order: Schedule 1, Schedule 2, Schedule 3 or DOC, see Scheduled Chemicals), but is regardless of the standing of the member state.
For Schedule 1 and 2 facilities, a mass balance is prepared to identify whether all produced chemicals can be accounted for and whether the amounts are consistent with the declarations made by member states. Furthermore, at Schedule 2 and 3 facilities clues are investigated whether, contrary to the declaration and to the rules in the convention, Schedule 1 chemicals are produced. At Schedule 3 and DOC, the main aim is to check the declaration and to verify the absence of Schedule 2 and Schedule 1 production units. The time limit Schedule 2 inspections is 96 hours while Schedule 3 and DOC inspections can take a maximum of 24 hours. There is no time limit on Schedule 1 inspections.
Challenge inspections and investigations of alleged use.
In case of allegation of use of chemical weapons or the prohibited production, a fact finding inspection can be employed according to the convention. None of those activities have taken place, although the OPCW contributed to investigations of alleged use of Chemical Weapons in Syria as part of a United Nations mission. The OPCW only undertakes these inspections on request of another member state, after verification of the presented proof. To avoid misuse, a majority of three quarters can block a challenge inspection request. Furthermore, the OPCW can only be involved after bilateral diplomatic solutions have failed.
Relations with the United Nations.
The organisation is not an agency of the United Nations, but cooperates both on policy and practical issues. On 7 September 2000 the OPCW and the United Nations signed a cooperation agreement outlining how they were to coordinate their activities. The inspectors furthermore travel on United Nations Laissez-Passer in which a sticker is placed explaining their position, and privileges and immunities. The United Nations Regional Groups also operate at the OPCW to govern the rotations on the Executive Council and provide informal discussion platform.
Headquarters.
The OPCW headquarters building was designed by American architect Gerhard Kallmann of Kallmann McKinnell & Wood.
The Hague was chosen as the location for the seat of the organisation after a successful lobby of the Dutch government, competing against Vienna and Geneva. The organisation has its headquarters next to the World Forum Convention Centre (where it holds its yearly Conference of States Parties) and storage/laboratory facilities in Rijswijk. The headquarters were officially opened by Queen Beatrix of the Netherlands on 20 May 1998 and consist of an eight-story building built in a semi-circle. A "permanent memorial to all victims" is present at the back of the building and open to the public.
Membership.
All 190 parties to the Chemical Weapons convention are automatically members of the OPCW. Non-members are Israel and Myanmar, which are signatory states that have not ratified the Chemical Weapons Convention, and Angola, Egypt, North Korea and South Sudan, which have neither signed nor acceded to the Chemical Weapons Convention. Syria was the most recent state to submit its instrument of accession to the treaty following the Framework for Elimination of Syrian Chemical Weapons.
Leadership.
The Organisation is led by the Director-General, who is directly appointed by the Conference for a maximum of two four-year terms. An overview of Directors-General is shown below.
The first Director-General only served about one year of his second term, after which he was removed from office on grounds of lack of confidence by the member states. Some suspect that Director-General Bustani was forced out by the U.S. government because Bustani wanted international chemical weapons monitors inside Iraq and thus was seen as impeding the U.S. push for war against Iraq. The US gave three main arguments for the removal of Bustani's from his position: "polarising and confrontational conduct", "mismanagement issues" and "advocacy of inappropriate roles for the OPCW". The removal was subsequently determined to be improper by an Administrative Tribunal of the International Labour Organization and consequently Bustani was awarded €50,000 in moral damages, his pay for the remainder of his second term, and his legal costs.
2013 Nobel Peace Prize.
On 11 October, the Norwegian Nobel Committee announced that the OPCW had been awarded the Nobel Peace Prize for "extensive work to eliminate chemical weapons". In the announcement, the OPCW and the Chemical Weapons Convention were praised. The committee further indicated how "Recent events in Syria, where chemical weapons have again been put to use, have underlined the need to enhance the efforts to do away with such weapons.” In the year ending in September, 2014, OPCW had overseen destruction of some 97 percent of Syria's declared chemical weapons, an extraordinary accomplishment. But now it seems that there are stocks and infrastructure that were undeclared, including a ricin factory. However, OPCW says that the production facility was declared in 2013 and is scheduled for verification and destruction. An OPCW team is currently in Beirut holding consultations with the Syrian authorities for the purpose of destroying the ricin factory and clearing up any further discrepancies.

</doc>
<doc id="36834" url="http://en.wikipedia.org/wiki?curid=36834" title="International Fund for Agricultural Development">
International Fund for Agricultural Development

The International Fund for Agricultural Development (IFAD) (French: "Fonds international de développement agricole"; "FIDA") (Italian: "Fondo Internazionale per lo Sviluppo Agricolo") is a specialized agency of the United Nations dedicated to eradicating rural poverty in developing countries. It was established as an international financial institution in 1977 as one of the major outcomes of the 1974 World Food Conference. Seventy-five percent of the world's poor live in rural areas in developing countries, yet only 4% of official development assistance goes to agriculture.
The strategic policy of IFAD is detailed in Strategic Framework for IFAD 2011–2015: Enabling the Rural Poor to Overcome Poverty. Its headquarters is in Rome, Italy, and is a member of the United Nations Development Group.
The President of the IFAD is Kanayo F. Nwanze from Nigeria, who was elected for a second four-year term in 2013.
Goal.
IFAD's goal is to empower poor rural women and men in developing countries to achieve higher incomes and improved food security.
Objectives.
IFAD seeks to ensure that poor rural people have better access to, and the skills and organization they need to take advantage of:
All of IFAD's decisions – on regional, country and thematic strategies, poverty reduction strategies, policy dialogue and development partners – are made with these principles and objectives in mind. As reflected in the strategic framework, IFAD is committed to achieving the Millennium Development Goals, in particular the target to halve the proportion of hungry and extremely poor people by 2015.
Underlying these objectives is IFAD’s belief that rural poor people must be empowered to lead their own development if poverty is to be eradicated. Poor people must be able to develop and strengthen their own organizations, so they can advance their own interests and dismantle the obstacles that prevent many of them from creating better lives for themselves. They must be able to have a say in the decisions and policies that affect their lives, and they need to strengthen their bargaining power in the marketplace.
Partnerships to eradicate rural poverty.
Through loans and grants, IFAD works with governments to develop and finance programmes and projects that enable rural poor people to overcome poverty themselves.
Since starting operations in 1978, IFAD has invested $12 billion, DM 7.5 billion in 860 projects and programmes that have reached some 370 million poor rural people.
Governments and other financing sources in recipient countries, including project participants, contributed $10.8 billion (€7.5 billion), and multilateral, bilateral and other donors provided approximately another $8.8 billion, €5 billion in cofinancing. This represents a total investment of about $19.6 billion (€15 billion).
IFAD tackles poverty not only as a lender, but also as an advocate for rural poor people. Its multilateral base provides a natural global platform to discuss important policy issues that influence the lives of rural poor people, as well as to draw attention to the centrality of rural development to meeting the Millennium Development Goals.
Membership.
Membership in IFAD is open to all member states of the United Nations or its specialized agencies or the International Atomic Energy Agency. A state becomes a member of IFAD by ratifying the multilateral treaty known as the Agreement establishing the International Fund for Agricultural Development. The Governing Council is IFAD's highest decision-making authority, with the Member States each represented by a governor and alternate governor. The Council meets annually. The Executive Board, responsible for overseeing the general operations of IFAD and approving loans and grants, is composed of 18 members and 18 alternate members. The President, who serves for a four-year term (renewable once), is IFAD's chief executive officer and chair of the Executive Board. The current, and fifth, President of IFAD is Kanayo F. Nwanze, who was elected for a first four-year term in 2009.
As of February 2015, IFAD has 176 member states. This includes 174 UN members states along with the Cook Islands and Niue. The member states are classified as follows: List A (primarily OECD members); List B (primarily OPEC members); and List C (developing countries). List C is further divided into sub-list C1 (countries in Africa); sub-list C2 (countries in Europe, Asia and the Pacific Islands); and sub-list C3 (countries in Latin America and the Caribbean).
The other UN member states that are not IFAD member states are: Andorra, Australia (which joined in 1977 but subsequently denounced the agreement), Bahrain, Belarus, Brunei, Bulgaria, Czech Republic, Latvia, Liechtenstein, Lithuania, Monaco, Poland, San Marino, Serbia, Singapore, Slovakia, Slovenia, Turkmenistan, and Ukraine.
The observers are the Holy See and European Union.
The Governing Council is IFAD's highest decision-making authority. Each Member State is represented in the Governing Council by a Governors, Alternate Governors and any other designated advisers. The Executive Board is responsible for overseeing the general operations of IFAD and for approving its programme of work. Membership on the Executive Board is determined by the Governing Council and is distributed as follows: List A: eight Members and eight Alternate Members; List B: four Members and four Alternate Members; and List C: six Members and six Alternate Members; two each in the three regional subdivisions of List C Member States.
Food prices and the rural poor.
The prices of basic food commodities increased rapidly during the 2007–08 world food price crisis. In only the first quarter of 2008, wheat and maize prices increased by 130% and 30% respectively over 2007 figures. Rice prices, while rising moderately in 2006 and more so in 2007, rose 10% in February 2008 and an additional 10% in March 2008. The threat to food security in developing countries increased in stride. Coordinated action by the international community was essential.
IFAD’s immediate response was to make available up to $200 million, €175 million from existing loans and grants to provide an urgent boost to agricultural production in the developing world, in the face of high food prices and low food stocks. But IFAD would continue to press for rapid and urgent longer-term investment in agriculture, including access to land, water, technology, financial services and markets, to enable the 450 million smallholder farms in developing countries to grow more food, more productively, and thereby increase their incomes and resilience, and respond to the increasing global demand for food.
Status of rural poverty.
Despite improvements over the past ten years that have lifted more than 350 million rural people out of extreme poverty, global poverty remains a massive and predominantly rural phenomenon with 70% of the developing world’s 1.4 billion extremely poor people living in rural areas. IFAD’s 2011 Rural Poverty Report demonstrated that during the past decade, the overall rate of extreme poverty in rural areas of developing countries has dropped from 48% to 34%, led by dramatic gains in East Asia.The report also points to the persistence of poverty in rural areas of sub-Saharan Africa and South Asia.

</doc>
<doc id="36835" url="http://en.wikipedia.org/wiki?curid=36835" title="Auger electron spectroscopy">
Auger electron spectroscopy

Auger electron spectroscopy (AES; pronounced ] in French) is a common analytical technique used specifically in the study of surfaces and, more generally, in the area of materials science. Underlying the spectroscopic technique is the Auger effect, as it has come to be called, which is based on the analysis of energetic electrons emitted from an excited atom after a series of internal relaxation events. The Auger effect was discovered independently by both Lise Meitner and Pierre Auger in the 1920s. Though the discovery was made by Meitner and initially reported in the journal "Zeitschrift für Physik" in 1922, Auger is credited with the discovery in most of the scientific community. Until the early 1950s Auger transitions were considered nuisance effects by spectroscopists, not containing much relevant material information, but studied so as to explain anomalies in x-ray spectroscopy data. Since 1953 however, AES has become a practical and straightforward characterization technique for probing chemical and compositional surface environments and has found applications in metallurgy, gas-phase chemistry, and throughout the microelectronics industry.
Electron transitions and the Auger effect.
The Auger effect is an electronic process at the heart of AES resulting from the inter- and intrastate transitions of electrons in an excited atom. When an atom is probed by an external mechanism, such as a photon or a beam of electrons with energies in the range of several eV to 50 keV, a core state electron can be removed leaving behind a hole. As this is an unstable state, the core hole can be filled by an outer shell electron, whereby the electron moving to the lower energy level loses an amount of energy equal to the difference in orbital energies. The transition energy can be coupled to a second outer shell electron, which will be emitted from the atom if the transferred energy is greater than the orbital binding energy. An emitted electron will have a kinetic energy of:
where formula_2, formula_3, formula_4 are respectively the core level, first outer shell, and second outer shell electron energies, measured from the vacuum level. The apostrophe (tic) denotes a slight modification to the binding energy of the outer shell electrons due to the ionized nature of the atom; often however, this energy modification is ignored in order to ease calculations. Since orbital energies are unique to an atom of a specific element, analysis of the ejected electrons can yield information about the chemical composition of a surface. Figure 1 illustrates two schematic views of the Auger process.
The types of state-to-state transitions available to electrons during an Auger event are dependent on several factors, ranging from initial excitation energy to relative interaction rates, yet are often dominated by a few characteristic transitions. Because of the interaction between an electron's spin and orbital angular momentum (spin-orbit coupling) and the concomitant energy level splitting for various shells in an atom, there are a variety of transition pathways for filling a core hole. Energy levels are labeled using a number of different schemes such as the j-j coupling method for heavy elements ("Z" ≥ 75), the Russell-Saunders L-S method for lighter elements ("Z" < 20), and a combination of both for intermediate elements. The j-j coupling method, which is historically linked to X-ray notation, is almost always used to denote Auger transitions. Thus for a formula_5 transition, "K" represents the core level hole, formula_6 the relaxing electron's initial state, and formula_7 the emitted electron's initial energy state. Figure 1(b) illustrates this transition with the corresponding spectroscopic notation. The energy level of the core hole will often determine which transition types will be favored. For single energy levels, i.e. "K", transitions can occur from the L levels, giving rise to strong KLL type peaks in an Auger spectrum. Higher level transitions can also occur, but are less probable. For multi-level shells, transitions are available from higher energy orbitals (different "n, ℓ" quantum numbers) or energy levels within the same shell (same "n", different "ℓ" number). The result are transitions of the type LMM and KLL along with faster Coster–Kronig transitions such as LLM. While Coster–Kronig transitions are faster, they are also less energetic and thus harder to locate on an Auger spectrum. As the atomic number Z increases, so too does the number of potential Auger transitions. Fortunately, the strongest electron-electron interactions are between levels that are close together, giving rise to characteristic peaks in an Auger spectrum. KLL and LMM peaks are some of the most commonly identified transitions during surface analysis. Finally, valence band electrons can also fill core holes or be emitted during KVV-type transitions.
Several models, both phenomenological and analytical, have been developed to describe the energetics of Auger transitions. One of the most tractable descriptions, put forth by Jenkins and Chung, estimates the energy of Auger transition ABC as:
formula_9 are the binding energies of the formula_10th level in element of atomic number "Z" and formula_11 are the energies of the same levels in the next element up in the periodic table. While useful in practice, a more rigorous model accounting for effects such as screening and relaxation probabilities between energy levels gives the Auger energy as:
where formula_13 is the energy of interaction between the "B" and "C" level holes in a final atomic state "x" and the "R"'s represent intra- and extra-atomic transition energies accounting for electronic screening. Auger electron energies can be calculated based on measured values of the various formula_14 and compared to peaks in the secondary electron spectrum in order to identify chemical species. This technique has been used to compile several reference databases used for analysis in current AES setups.
Experimental setup and quantification.
Instrumentation.
Surface sensitivity in AES arises from the fact that emitted electrons usually have energies ranging from 50 eV to 3 keV and at these values, electrons have a short mean free path in a solid. The escape depth of electrons is therefore localized to within a few nanometers of the target surface, giving AES an extreme sensitivity to surface species. Because of the low energy of Auger electrons, most AES setups are run under ultra-high vacuum (UHV) conditions. Such measures prevent electron scattering off of residual gas atoms as well as the formation of a thin "gas (adsorbate) layer" on the surface of the specimen, which degrades analytical performance. A typical AES setup is shown schematically in figure 2. In this configuration, focused electrons are incident on a sample and emitted electrons are deflected into a cylindrical mirror analyzer (CMA). In the detection unit, Auger electrons are multiplied and the signal sent to data processing electronics. Collected Auger electrons are plotted as a function of energy against the broad secondary electron background spectrum.
Since the intensity of the Auger peaks may be small compared to the noise level of the background, AES is often run in a derivative mode that serves to highlight the peaks by modulating the electron collection current via a small applied AC voltage. Since this formula_15, the collection current becomes formula_16. Taylor expanding gives:
Using the setup in figure 2, detecting the signal at frequency ω will give a value for formula_18 or formula_19. Plotting in derivative mode also emphasizes Auger fine structure, which appear as small secondary peaks surrounding the primary Auger peak. These secondary peaks, not to be confused with high energy satellites, which are discussed later, arise from the presence of the same element in multiple different chemical states on a surface (i.e. Adsorbate layers) or from relaxation transitions involving valence band electrons of the substrate. Figure 3 illustrates a derivative spectrum from a copper nitride film clearly showing the Auger peaks. The peak in derivative mode is not the true Auger peak, but rather the point of maximum slope of "N(E)", but this concern is usually ignored.
Quantitative analysis.
Semi-quantitative compositional and element analysis of a sample using AES is dependent on measuring the yield of Auger electrons during a probing event. Electron yield, in turn, depends on several critical parameters such as electron-impact cross-section and fluorescence yield. Since the Auger effect is not the only mechanism available for atomic relaxation, there is a competition between radiative and non-radiative decay processes to be the primary de-excitation pathway. The total transition rate, ω, is a sum of the non-radiative (Auger) and radiative (photon emission) processes. The Auger yield, formula_20, is thus related to the fluorescence (x-ray) yield, formula_21, by the relation,
where formula_23 is the X-ray transition probability and formula_24 is the Auger transition probability. Attempts to relate the fluorescence and Auger yields to atomic number have resulted in plots similar to figure 4. A clear transition from electron to photon emission is evident in this chart for increasing atomic number. For heavier elements, x-ray yield becomes greater than Auger yield, indicating an increased difficulty in measuring the Auger peaks for large Z-values. Conversely, AES is sensitive to the lighter elements, and unlike X-ray fluorescence, Auger peaks can be detected for elements as light as lithium ("Z" = 3). Lithium represents the lower limit for AES sensitivity since the Auger effect is a "three state" event necessitating at least three electrons. Neither H nor He can be detected with this technique. For K-level based transitions, Auger effects are dominant for "Z" < 15 while for L- and M-level transitions, AES data can be measured for "Z" ≤ 50. The yield limits effectively prescribe a cutoff for AES sensitivity, but complex techniques can be utilized to identify heavier elements, such as uranium and americium, using the Auger effect.
Another critical quantity that determines yield of Auger electrons at a detector is the electron impact cross-section. Early approximations (in cm2) of the cross-section were based on the work of Worthington and Tomlin,
with "b" acting as a scaling factor between 0.25 and 0.35, and "C" a function of the primary electron beam energy, formula_26. While this value of formula_27 is calculated for an isolated atom, a simple modification can be made to account for matrix effects:
where α is the angle to the surface normal of the incident electron beam; "rm" can be established empirically and encompasses electron interactions with the matrix such as ionization due to backscattered electrons. Thus the total yield can be written as:
Here "Nx" is the number of "x" atoms per volume, λ the electron escape depth, θ the analyzer angle, "T" the transmission of the analyzer, "I(t)" the electron excitation flux at depth "t", dΩ the solid angle, and δt is the thickness of the layer being probed. Encompassed in these terms, especially the Auger yield, which is related to the transition probability, is the quantum mechanical overlap of the initial and final state wave functions. Precise expressions for the transition probability, based on first-order perturbation Hamiltonians, can be found in Thompson and Baker. Often, all of these terms are not known, so most analyses compare measured yields with external standards of known composition. Ratios of the acquired data to standards can eliminate common terms, especially experimental setup characteristics and material parameters, and can be used to determine element composition. Comparison techniques work best for samples of homogeneous binary materials or uniform surface layers, while elemental identification is best obtained from comparison of pure samples.
Uses and limitations.
There are a number of electron microscopes that have been specifically designed for use in Auger spectroscopy; these are termed scanning Auger microscopes (SAM) and can produce high resolution, spatially resolved chemical images. SAM images are obtained by stepping a focused electron beam across a sample surface and measuring the intensity of the Auger peak above the background of scattered electrons. The intensity map is correlated to a gray scale on a monitor with whiter areas corresponding to higher element concentration. In addition, sputtering is sometimes used with Auger spectroscopy to perform depth profiling experiments. Sputtering removes thin outer layers of a surface so that AES can be used to determine the underlying composition. Depth profiles are shown as either Auger peak height vs. sputter time or atomic concentration vs. depth. Precise depth milling through sputtering has made profiling an invaluable technique for chemical analysis of nanostructured materials and thin films. AES is also used extensively as an evaluation tool on and off fab lines in the microelectronics industry, while the versatility and sensitivity of the Auger process makes it a standard analytical tool in research labs. Theoretically, Auger spectra can also be utilized to distinguish between protonation states. When a molecule is protonated or deprotonated, the geometry and electronic structure is changed, and AES spectra reflect this. In general, as a molecule becomes more protonated, the ionization potentials increase and the kinetic energy of the emitted outer shell electrons decreases.
Despite the advantages of high spatial resolution and precise chemical sensitivity attributed to AES, there are several factors that can limit the applicability of this technique, especially when evaluating solid specimens. One of the most common limitations encountered with Auger spectroscopy are charging effects in non-conducting samples. Charging results when the number of secondary electrons leaving the sample is different from the number of incident electrons, giving rise to a net positive or negative electric charge at the surface. Both positive and negative surface charges severely alter the yield of electrons emitted from the sample and hence distort the measured Auger peaks. To complicate matters, neutralization methods employed in other surface analysis techniques, such as secondary ion mass spectrometry (SIMS), are not applicable to AES, as these methods usually involve surface bombardment with either electrons or ions (i.e. flood gun). Several processes have been developed to combat the issue of charging, though none of them is ideal and still make quantification of AES data difficult. One such technique involves depositing conductive pads near the analysis area to minimize regional charging. However, this type of approach limits SAM applications as well as the amount of sample material available for probing. A related technique involves thinning or "dimpling" a non-conductive layer with Ar+ ions and then mounting the sample to a conductive backing prior to AES. This method has been debated, with claims that the thinning process leaves elemental artifacts on a surface and/or creates damaged layers that distort bonding and promote chemical mixing in the sample. As a result, the compositional AES data is considered suspect. The most common setup to minimize charging effects includes use of a glancing angle (~10°) electron beam and a carefully tuned bombarding energy (between 1.5 keV and 3 keV). Control of both the angle and energy can subtly alter the number of emitted electrons vis-à-vis the incident electrons and thereby reduce or altogether eliminate sample charging.
In addition to charging effects, AES data can be obscured by the presence of characteristic energy losses in a sample and higher order atomic ionization events. Electrons ejected from a solid will generally undergo multiple scattering events and lose energy in the form of collective electron density oscillations called plasmons. If plasmon losses have energies near that of an Auger peak, the less intense Auger process may become dwarfed by the plasmon peak. As Auger spectra are normally weak and spread over many eV of energy, they are difficult to extract from the background and in the presence of plasmon losses; deconvolution of the two peaks becomes extremely difficult. For such spectra, additional analysis through chemical sensitive surface techniques like x-ray photoelectron spectroscopy (XPS) is often required to disentangle the peaks. Sometimes an Auger spectrum can also exhibit "satellite" peaks at well-defined off-set energies from the parent peak. Origin of the satellites is usually attributed to multiple ionization events in an atom or ionization cascades in which a series of electrons is emitted as relaxation occurs for core holes of multiple levels. The presence of satellites can distort the true Auger peak and/or small peak shift information due to chemical bonding at the surface. Several studies have been undertaken to further quantify satellite peaks.
Despite these sometimes substantial drawbacks, Auger electron spectroscopy is a widely used surface analysis technique that has been successfully applied to many diverse fields ranging from gas phase chemistry to nanostructure characterization. Very new class of high-resolving electrostatic energy analyzers recently developed – the face-field analyzers (FFA) can be used for remote electron spectroscopy of distant surfaces or surfaces with large roughness or even with deep dimples. These instruments are designed as if to be specifically used in combined scanning electron microscopes (SEMs). "FFA" in principle have no perceptible end-fields, which usually distort focusing in most of analysers known, for example, well known CMA.
Sensitivity, quantitative detail, and ease of use have brought AES from an obscure nuisance effect to a functional and practical characterization technique in just over fifty years. With applications both in the research laboratory and industrial settings, AES will continue to be a cornerstone of surface-sensitive electron-based spectroscopies.
Further reading.
</dl>

</doc>
<doc id="36840" url="http://en.wikipedia.org/wiki?curid=36840" title="P. J. O'Rourke">
P. J. O'Rourke

Patrick Jake "P. J." O'Rourke (; born November 14, 1947) is an American political satirist, journalist, writer, and author. O'Rourke is the H. L. Mencken Research Fellow at the Cato Institute and is a regular correspondent for "The Atlantic Monthly", "The American Spectator", and "The Weekly Standard", and frequent panelist on National Public Radio's game show "Wait Wait... Don't Tell Me!". In the United Kingdom, he is known as the face of a long-running series of television advertisements for British Airways in the 1990s.
He is the author of 20 books, of which his latest, "", was released January 2014. This was preceded on September 21, 2010, by "Don't Vote! – It Just Encourages the Bastards", and on September 1, 2009, "Driving Like Crazy" with a reprint edition published on May 11, 2010. According to a "60 Minutes" profile, he is also the most quoted living man in "The Penguin Dictionary of Modern Humorous Quotations".
Life and career.
P. J. O'Rourke was born in Toledo, Ohio, the son of Delphine Loy, a housewife, and Clifford Bronson O'Rourke, a car salesman. He attended Toledo's DeVilbiss High School, graduating in 1965. He did his undergraduate work at Miami University, in Ohio, and earned an M.A. in English at Johns Hopkins University while a brother of the Alpha Delta Phi Literary Society. He recounts that during his student days he was a left-leaning hippie, but that in the 1970s his political views underwent a "volte-face". He emerged as a political observer and humorist with libertarian viewpoints.
O'Rourke wrote articles for several publications, including The Rip Off Review of Western Culture an underground magazine/comic book in 1972, entitled "A.J. at N.Y.U." and also for the Baltimore underground newspaper "Harry" and the "New York Ace", before joining "National Lampoon" in 1973, where he served as managing editor among other roles and authored articles such as "Foreigners Around the World" and "How to Drive Fast on Drugs While Getting Your Wing-Wang Squeezed and Not Spill Your Drink." He received a writing credit for "National Lampoon's Lemmings" which helped launch the careers of John Belushi, Chevy Chase and Christopher Guest. He also co-wrote "National Lampoon's 1964 High School Yearbook" with Douglas Kenney. O'Rourke said later that Kenney brought comedy to the piece and he brought the organization. The "Yearbook" was a bestseller and some themes were later used in the movie "Animal House".
Going freelance in 1981, O'Rourke began publishing in magazines such as "Playboy," "Vanity Fair," "Car and Driver," and "Rolling Stone". He became foreign-affairs desk chief at "Rolling Stone", where he remained until 2001. In 1996, he served as the conservative commentator in the point-counterpoint segment of "60 Minutes."
O'Rourke was married to Amy Lumet, a daughter of movie director Sidney Lumet and a granddaughter of Lena Horne, from 1990 to 1993. Since 1995 he has been married to his second wife, Tina, and they have two daughters, Elizabeth and Olivia, and one son, Clifford. O'Rourke splits his time between the small town of Sharon, New Hampshire, and Washington, D.C.
O'Rourke has published 16 books, including three "New York Times" bestsellers. "Parliament of Whores" and "Give War a Chance" reached #1 on the New York Times Best Seller List. O'Rourke was a "Real Time Real Reporter" for "Real Time with Bill Maher" covering the 2008 Presidential Election.
O'Rourke revealed on September 28, 2008, that he has been diagnosed with treatable anal cancer, from which he can expect "a 95% chance of survival." His announcement is typical of his writing in that it handled a very serious subject within his humorous style.
In 2009, O'Rourke described the Presidency of Barack Obama as "the Carter administration in better sweaters".
Writing.
O'Rourke was a proponent of Gonzo journalism; one of his earliest and best-regarded pieces was "How to Drive Fast on Drugs While Getting Your Wing-Wang Squeezed and Not Spill Your Drink", a "National Lampoon" article in March 1979. The article was republished in two of his books, "Republican Party Reptile" (1987) and "Driving Like Crazy" (2009).
O'Rourke's best-received book is "Parliament of Whores", subtitled "A Lone Humorist Attempts to Explain the Entire U.S. Government", whose main argument, according to the author, "is that politics are boring".
O'Rourke has described himself as a libertarian.
O'Rourke types his manuscripts on an IBM Selectric typewriter, though denies that he is a Luddite, asserting that his short attention span would make focusing on writing on a computer difficult. In a January 2007 interview, O'Rourke gave an example of his view of computers and writing by referencing novelist Stephen King, whom he paraphrased – saying had he a computer, he could have written three times as much in his early days. To which O'Rourke remarked, "Does the world need three times as many "Cujos"? Three times as many Jane Austens, maybe."

</doc>
<doc id="36842" url="http://en.wikipedia.org/wiki?curid=36842" title="Gossypium">
Gossypium

Gossypium is the cotton genus. It belongs to the tribe "Gossypieae", in the mallow family, Malvaceae, native to the tropical and subtropical regions from both the Old and New World. The genus "Gossypium" comprises around 50 species, making it the largest in species number in the tribe "Gossypioieae". New species continue to be discovered. The name of the genus is derived from the Arabic word "goz", which refers to a soft substance. 
Cotton is the primary natural fibre used by modern humans. Cultivated cotton is also a major oilseed crop, as well as a main protein source for animal feed. Cotton plants thus have an enormous weight in the world economy and are of great importance for the agriculture, industry and trade of many tropical and subtropical countries in Africa, South America and Asia. Consequently, the genus "Gossypium" has long attracted the attention of scientists.
The origin of the genus "Gossypium" is dated to around 5-10 million years ago. "Gossypium" species are distributed in arid to semiarid regions of the tropics and subtropics. Generally shrubs or shrub-like plants, the species of this genus are extraordinarily diverse in morphology and adaptation, ranging from fire-adapted, herbaceous perennials in Australia to trees in Mexico. 
Cultivated cottons are perennial shrubs most often grown as annuals. Plants are 1–2 m high in modern cropping systems, sometimes higher in traditional, multiannual cropping systems, now largely disappearing. The leaves are broad and lobed, with three to five (or rarely seven) lobes. The seeds are contained in a capsule called a "boll", each seed surrounded by fibres of two types. These fibres are the more commercially interesting part of the plant and they are separated from the seed by a process called ginning. At the first ginning, the longer fibres, called staples, are removed and these are twisted together to form yarn for making thread and weaving into high quality textiles. At the second ginning, the shorter fibres, called "linters", are removed, and these are woven into lower quality textiles (which include the eponymous Lint). Commercial species of cotton plant are "G. hirsutum" (>90% of world production), "G. barbadense" (3-4%), "G. arboreum" and "G. herbaceum" (together, 2%). Many varieties of cotton have been developed by selective breeding and hybridization of these species. Experiments are ongoing to cross-breed various desirable traits of wild cotton species into the principal commercial species, such as resistance to insects and diseases, and drought tolerance. Cotton fibres occur naturally in colours of white, brown, green, and some mixing of these.
Most wild cottons are diploid, but a group of five species from America and Pacific islands are tetraploid, apparently due to a single hybridization event around 1.5 to 2 million years ago. The tetraploid species are "G. hirsutum", "G. tomentosum", "G. mustelinum", "G. barbadense", and "G. darwinii".
"Gossypium" genome.
A public genome sequencing effort of cotton was initiated in 2007 by a consortium of public researchers. They agreed on a strategy to sequence the genome of cultivated, allotetraploid cotton. "Allotetraploid" means that the genomes of these cotton species comprise two distinct subgenomes, referred to as the At and Dt (the 't' for tetraploid, to distinguish them from the A and D genomes of the related diploid species). The strategy is to sequence first the D-genome relative of allotetraploid cottons, "G. raimondii", a wild South American (Peru, Ecuador) cotton species, because of its smaller size due essentially to less repetitive DNA (retrotransposons mainly). It has nearly one-third the number of bases of tetraploid cotton (AD), and each chromosome is only present once. The A genome of "G. arboreum", the 'Old-World' cotton species (grown in India in particular), would be sequenced next. Its genome is roughly twice the size of "G. raimondii"'s. Once both A and D genome sequences are assembled, then research could begin to sequence the actual genomes of tetraploid cultivated cotton varieties. This strategy is out of necessity; if one were to sequence the tetraploid genome without model diploid genomes, the euchromatic DNA sequences of the AD genomes would co-assemble and the repetitive elements of AD genomes would assembly independently into A and D sequences, respectively. Then there would be no way to untangle the mess of AD sequences without comparing them to their diploid counterparts.
The public sector effort continues with the goal to create a high-quality, draft genome sequence from reads generated by all sources. The public-sector effort has generated Sanger reads of BACs, fosmids, and plasmids, as well as 454 reads. These later types of reads will be instrumental in assembling an initial draft of the D genome. In 2010, two companies (Monsanto and Illumina), completed enough Illumina sequencing to cover the D genome of "G. raimondii" about 50x. They announced they would donate their raw reads to the public. This public relations effort gave them some recognition for sequencing the cotton genome. Once the D genome is assembled from all of this raw material, it will undoubtedly assist in the assembly of the AD genomes of cultivated varieties of cotton, but a lot of hard work remains.

</doc>
<doc id="36843" url="http://en.wikipedia.org/wiki?curid=36843" title="ICRM">
ICRM

ICRM may refer to:

</doc>
<doc id="36845" url="http://en.wikipedia.org/wiki?curid=36845" title="Henry Dunant">
Henry Dunant

Jean Henri Dunant (8 May 1828 – 30 October 1910), also known as Henry Dunant, was a Swiss businessman and social activist. During a business trip in 1859, he was witness to the aftermath of the Battle of Solferino in modern-day Italy. He recorded his memories and experiences in the book "A Memory of Solferino" which inspired the creation of the International Committee of the Red Cross (ICRC) in 1863. The 1864 Geneva Convention was based on Dunant's ideas. In 1901 he received the first Nobel Peace Prize together with Frédéric Passy, making Dunant the first Swiss Nobel laureate.
Early life and education.
Dunant was born in Geneva, Switzerland, the first son of businessman Jean-Jacques Dunant and Antoinette Dunant-Colladon. His family was devoutly Calvinist and had significant influence in Geneva society. His parents stressed the value of social work, and his father was active helping orphans and parolees, while his mother worked with the sick and poor. His father worked in a prison and an orphanage. 
Dunant grew up during the period of religious awakening known as the "Réveil", and at age 18 he joined the Geneva Society for Alms giving. In the following year, together with friends, he founded the so-called "Thursday Association", a loose band of young men that met to study the Bible and help the poor, and he spent much of his free time engaged in prison visits and social work. On 30 November 1852, he founded the Geneva chapter of the YMCA and three years later he took part in the Paris meeting devoted to the founding of its international organization.
In 1849, at age 21, Dunant was forced to leave the Collège Calvin due to poor grades, and he began an apprenticeship with the money-changing firm "Lullin et Sautter". After its successful conclusion, he remained as an employee of the bank.
Algeria.
In 1853, Dunant visited Algeria, Tunisia, and Sicily, on assignment with a company devoted to the "colonies of Setif" ("Compagnie genevoise des Colonies de Sétif"). Despite little experience, he successfully fulfilled the assignment. Inspired by the trip, he wrote his first book with the title "An Account of the Regency in Tunis" ("Notice sur la Régence de Tunis"), published in 1858.
In 1856, he created a business to operate in foreign colonies, and, after being granted a land concession by French-occupied Algeria, a corn-growing and trading company called the Financial and Industrial Company of Mons-Djémila Mills ("Société financière et industrielle des Moulins des Mons-Djémila"). However, the land and water rights were not clearly assigned, and the colonial authorities were not especially cooperative. As a result, Dunant decided to appeal directly to French emperor Napoléon III, who was with his army in Lombardy at the time. France was fighting on the side of Piedmont-Sardinia against Austria, who had occupied much of today's Italy. Napoleon's headquarters were located in the small city of Solferino. Dunant wrote a flattering book full of praise for Napoleon III with the intention to present it to the emperor, and then traveled to Solferino to meet with him personally.
The Battle of Solferino.
Dunant arrived in Solferino on the evening of 24 June 1859, on the same day a battle between the two sides had occurred nearby. Twenty-three thousand wounded, dying and dead remained on the battlefield, and there appeared to be little attempt to provide care. Shocked, Dunant himself took the initiative to organize the civilian population, especially the women and girls, to provide assistance to the injured and sick soldiers. They lacked sufficient materials and supplies, and Dunant himself organized the purchase of needed materials and helped erect makeshift hospitals. He convinced the population to service the wounded without regard to their side in the conflict as per the slogan "Tutti fratelli" (All are brothers) coined by the women of nearby city Castiglione delle Stiviere. He also succeeded in gaining the release of Austrian doctors captured by the French.
The Red Cross.
After returning to Geneva early in July, Dunant decided to write a book about his experiences, which he titled "Un Souvenir de Solferino" ("A Memory of Solferino"). It was published in 1862 in an edition of 1,600 copies and was printed at Dunant's own expense. Within the book, he described the battle, its costs, and the chaotic circumstances afterwards. He also developed the idea that in the future a neutral organization should exist to provide care to wounded soldiers. He distributed the book to many leading political and military figures in Europe.
Dunant also began to travel through Europe to promote his ideas. His book was largely positively received, and the President of the Geneva Society for Public Welfare, jurist Gustave Moynier, made the book and its suggestions the topic of the 9 February 1863 meeting of the organization. Dunant's recommendations were examined and positively assessed by the members. They
created a five-person Committee to further pursue the possibility of their implementation and made Dunant one of the members. The others were Moynier, the Swiss army general Henri Dufour, and doctors Louis Appia and Théodore Maunoir. Their first meeting on 17 February 1863 is now considered the founding date of the International Committee of the Red Cross.
From early on, Moynier and Dunant had increasing disagreements and conflicts regarding their respective visions and plans. Moynier considered Dunant's idea to establish neutrality protections for care providers unfeasible and advised Dunant not to insist upon this concept. However, Dunant continued to advocate this position in his travels and conversations with high-ranking political and military figures. This intensified the personal conflict between Moynier, who took a rather pragmatic approach to the project, and Dunant, who was the visionary idealist among the five, and led to efforts by Moynier to attack Dunant and his bid for leadership.
In October 1863, 14 states took part in a meeting in Geneva organized by the committee to discuss the improvement of care for wounded soldiers. Dunant himself, however, was only a protocol leader because of Moynier's efforts to diminish his role. A year later on 22 August 1864, a diplomatic conference organized by the Swiss Parliament led to the signing of the First Geneva Convention by 12 states. Dunant, again, was only in charge of organizing accommodation for the attendees.
Forgotten period.
Dunant's businesses in Algeria had suffered, partially because of his devotion to his humanistic ideals. In April 1867, the bankruptcy of the financial firm "Crédit Genevois" led to a scandal involving Dunant. He was forced to declare bankruptcy and was condemned by the Geneva Trade Court on 17 August 1868 for deceptive practices in the bankruptcies. Due to their investments in the firm, his family and many of his friends were also heavily affected by the downfall of the company. The social outcry in Geneva, a city deeply rooted in Calvinist traditions, also led to calls for him to separate himself from the International Committee. On 25 August 1868, he resigned as Secretary and, on 8 September, he was fully removed from the Committee. Moynier, who had become President of the Committee in 1864, played a major role in his expulsion.
In February 1868, Dunant's mother died. Later that year he was also expelled from the YMCA. In March 1867, he left his home city Geneva and would not return for the rest of his life. In the following years, Moynier likely used his influence to attempt to ensure that Dunant would not receive assistance and support from his friends. For example, the gold medal prize of "Sciences Morales" at the Paris World's Fair did not go to Dunant as originally planned but to Moynier, Dufour, and Dunant together so that the prize money would only go to the Committee as a whole. Napoléon III's offer to take over half of Dunant's debts if Dunant's friends would secure the other half was also thwarted by Moynier's efforts.
Dunant moved to Paris, where he lived in meager conditions. However, he continued to pursue his humanitarian ideas and plans. During the Franco-Prussian War (1870–1871), he founded the Common Relief Society ("Allgemeine Fürsorgegesellschaft") and soon after the Common Alliance for Order and Civilization ("Allgemeine Allianz für Ordnung und Zivilisation"). He argued for disarmament negotiations and for the erection of an international court to mediate international conflicts. Later he worked for the creation of a world library, an idea which had echoes in future projects such as UNESCO.
In his continued pursuit and advocacy of his ideas, he further neglected his personal situation and income, falling further in debt and being shunned by his acquaintances. Despite being appointed an honorary member of the national Red Cross societies of Austria, the Netherlands, Sweden, Prussia and Spain, he was nearly forgotten in the official discourse of the Red Cross Movement, even as it was rapidly expanding to new countries. He lived in poverty, moving to various places between 1874 and 1886, including Stuttgart, Rome, Corfu, Basel, and Karlsruhe. In Stuttgart he met the Tübingen University student Rudolf Müller with whom he would have a close friendship. In 1881, together with friends from Stuttgart, he went to the small Swiss resort village Heiden for the first time. In 1887 while living in London, he began to receive some monthly financial support from some distant family members. This enabled him to live a somewhat more secure existence, and he moved to Heiden in July. He spent the rest of his life there, and after 30 April 1892 he lived in a hospital and nursing home led by Dr. Hermann Altherr.
In Heiden, he met the young teacher Wilhelm Sonderegger and his wife Susanna; they encouraged him to record his life experiences. Sonderegger's wife founded a branch of the Red Cross in Heiden and in 1890 Dunant became its honorary president. With Sonderegger, Dunant hoped to further promote his ideas, including publishing a new edition of his book. However, their friendship later was strained by Dunant's unjustified accusations that Sonderegger, with Moynier in Geneva, was somehow conspiring against Dunant. Sonderegger died in 1904 at the age of only forty-two. Despite their strained relationship, Dunant was deeply moved by the unexpected death. Wilhelm and Susanna Sonderegger's admiration for Dunant, felt by both even after Dunant's allegations, was passed on to their children. In 1935, their son René published a compilation of letters from Dunant to his father.
Return to public memory.
In September 1895, Georg Baumberger, the chief editor of the St. Gall newspaper "Die Ostschweiz", wrote an article about the Red Cross founder, whom he had met and conversed with during a walk in Heiden a month earlier. The article entitled "Henri Dunant, the founder of the Red Cross", appeared in the German Illustrated Magazine "Über Land und Meer", and the article was soon reprinted in other publications throughout Europe. The article struck a chord, and he received renewed attention and support. He received the Swiss Binet-Fendt Prize and a note from Pope Leo XIII. Because of support from Russian tsarist widow Maria Feodorovna and other donations, his financial situation improved remarkably.
In 1897, Rudolf Müller, who was now working as a teacher in Stuttgart, wrote a book about the origins of the Red Cross, altering the official history to stress Dunant's role. The book also contained the text of "A Memory of Solferino". Dunant began an exchange of correspondence with Bertha von Suttner and wrote numerous articles and writings. He was especially active in writing about women's rights, and in 1897 facilitated the founding of a "Green Cross" women's organization whose only section was briefly active in Brussels.
Nobel Peace Prize.
In 1901, Dunant was awarded the first-ever Nobel Peace Prize for his role in founding the International Red Cross Movement and initiating the Geneva Convention. Norwegian military physician Hans Daae, who had received a copy of Müller's book, advocated Dunant's case on the Nobel committee. The award was jointly given to French pacifist Frédéric Passy, founder of the Peace League and active with Dunant in the Alliance for Order and Civilization. The official congratulations which he received from the International Committee finally represented the rehabilitation of Dunant's reputation:
"There is no man who more deserves this honour, for it was you, forty years ago, who set on foot the international organization for the relief of the wounded on the battlefield. Without you, the Red Cross, the supreme humanitarian achievement of the nineteenth century would probably have never been undertaken."
Moynier and the International Committee as a whole had also been nominated for the prize. Although Dunant was supported by a broad spectrum in the selection process, he was still a controversial candidate. Some argued that the Red Cross and the Geneva Convention had made war more attractive and imaginable by eliminating some of its suffering. Therefore Müller, in a letter to the committee, argued that the prize should be divided between Dunant and Passy, who for some time in the debate had been the leading candidate to be the sole recipient of the prize. Müller also suggested that if a prize were to be warranted for Dunant, it should be given immediately because of his advanced age and ill health.
By dividing the prize between Passy, a pacifist, and Dunant, a humanitarian, the Nobel Committee set a precedent for the conditions of the Nobel Peace Prize selection which would have significant consequences in later years. A section of Nobel's will had indicated that the prize should go to an individual who had worked to reduce or eliminate standing armies, or directly to promote peace conferences, which made Passy a natural choice for his peace work. On the other hand, the arguably distinct bestowal for humanitarian effort alone was seen by some as a wide interpretation of Nobel's will. However, another part of Nobel's testament marked the prize for the individual who had best enhanced the "brotherhood of people," which could be interpreted more generally as seeing humanitarian work like Dunant's as connected to peacemaking as well. Many recipients of the Nobel Peace Prize in later years can be assigned to either of these two categories first roughly established by the Nobel committee's decision in 1901.
Hans Daae succeeded in placing Dunant's part of the prize money, 104,000 Swiss Francs, in a Norwegian Bank and preventing access by his creditors. Dunant himself never spent any of the money during his lifetime.
Death and legacy.
Among several other awards in the following years, in 1903 Dunant was given an honorary doctorate by the medical faculty of the University of Heidelberg. He lived in the nursing home in Heiden until his death. In the final years of his life, he suffered from depression and paranoia about pursuit by his creditors and Moynier. There were even days when Dunant insisted that the cook of the nursing home first taste his food before his eyes to protect him against possible poisoning. In his final years, he spurned and attacked Calvinism and organized religion generally. He was said to be agnostic.
According to his nurses, the final act of his life was to send a copy of Müller's book to the Italian queen with a personal dedication. He died on 30 October 1910, and his final words were "Where has humanity gone?" He outlived his nemesis Moynier by just two months. Despite the ICRC's congratulations at the bestowal of the Nobel prize, the two rivals never reached a reconciliation.
According to his wishes, he was buried without ceremony in the Sihlfeld Cemetery in Zurich. In his will, he donated funds to secure a "free bed" in the Heiden nursing home always to be available for a poor citizen of the region and deeded some money to friends and charitable organizations in Norway and Switzerland. The remaining funds went to his creditors partially relieving his debt; his inability to fully erase his debts was a major burden to him until his death.
His birthday, 8 May, is celebrated as the World Red Cross and Red Crescent Day. The former nursing home in Heiden now houses the Henry Dunant Museum. In Geneva and other places there are numerous streets, squares, and schools named after him. The Henry Dunant Medal, awarded every two years by the standing commission of the International Red Cross and Red Crescent Movement is its highest decoration.
His life is represented, with some fictional elements, in the film "D'homme à hommes" (1948), starring Jean-Louis Barrault, and the period of his life when the Red Cross was founded in the international film coproduction "" (2006). In 2010 the Takarazuka Revue staged a musical based on his time in Solferino and the founding of the Red Cross entitled "ソルフェリーノの夜明け" ("Dawn at Solferino, or Where has Humanity Gone?").
In honour of Henry Dunant, the second highest peak in Switzerland was renamed to Dunantspitze (Peak Dunant) by Swiss Federal President Didier Burkhalter on 6 October 2014. 
References.
 Stanford, Richard (2012) "Searching For Henri", The Ovi, Issue #23/2012, http://ovimagazine.com/pdfs/pdf_76.pdf
German books.
</dl>

</doc>
<doc id="36847" url="http://en.wikipedia.org/wiki?curid=36847" title="Sports governing body">
Sports governing body

A sports governing body is a sports organisation that has a regulatory or sanctioning function. Sports governing bodies come in various forms, and have a variety of regulatory functions. Examples of this can include disciplinary action for rule infractions and deciding on rule changes in the sport that they govern. Governing bodies have different scopes. They may cover a range of sport at an international level, such as the International Olympic Committee and the International Paralympic Committee, or only a single sport at a national level, such as the Rugby Football League. National bodies may or may not be affiliated to international bodies for the same sport. The first international federations were formed at the end of the 19th century.
Types of sports governing bodies.
Every sport has a different governing body that can define the way that the sport operates through its afflicted clubs and societies. This is because sports have different levels of difficulty and skill, so they can try to organise the people playing their sport by ability and by age. The different types of sport governing bodies are all shown below:
International sports federations are responsible for one sport (or a group of similar sport disciplines, such as aquatics or skiing). They create a common set of rules and organise international competitions. The promotion of the sport are also a task of an international federation.
Trusts are organizations or groups that have control over money that will be used to help someone else, such as the Youth Sport Trust.
National federations have the same objectives as an international federation, but within the scope of one country, or even part of a country, as the name implies. They support local clubs and are often responsible for national teams. National Olympic Committees and National Paralympic Committees are both a type of National Federation, as they are responsible for a country's participation in the Olympic Games and in the Paralympic Games respectively. However, a national governing body (NGB) can be different from a national federation due to government recognition requirements. Also, NGBs can be a supraorganization representing a range of unrelated organisations operating in a particular sport as evident in the example of the Northern Ireland Federation of Sub-Aqua Clubs.
Multi-sport event organizers are responsible for the organization of an event that includes more than one sport. The best-known example is the International Olympic Committee (IOC), the organizer of the modern Olympic Games. General sports organisations are responsible for sports related topics, usually for a certain group, such as the Catholic or Jewish sports groups. General sports organisations can also exist for the army and other groups, but they usually are medium-sized, as they do not have that much of a budget to work with.
Professional sports leagues are usually the highest level of play in sport, specifically if they consist of the best players around the world in a certain sport. Because of this, they usually work with national and/or international federations, but there is usually a separation between the different federations. Most North American professional leagues usually do not have amateur divisions, as the amateur divisions are mostly run in separate leagues. In addition, most professional leagues are related to other leagues, as players usually attempt to play in the league with the highest level of play. Because of this, promotion and relegation can occur; or, in league systems without promotion and relegation, clubs in professional leagues can have a team in the minor leagues. This enables them to shuffle players who are not doing well to the minor leagues, which will inspire them to contribute more to the team by playing better.

</doc>
<doc id="36848" url="http://en.wikipedia.org/wiki?curid=36848" title="Economic Community of West African States">
Economic Community of West African States

The Economic Community of West African States (ECOWAS; French: "Communauté économique des États de l'Afrique de l'Ouest", CEDEAO) is a regional group of fifteen West African countries. Founded on 28 May 1975, with the signing of the Treaty of Lagos, its mission is to promote economic integration across the region.
Considered one of the pillars of the African Economic Community, the organization was founded in order to achieve "collective self-sufficiency" for its member states by creating a single large trading bloc through an economic and trading union. It also serves as a peacekeeping force in the region. The organization operates officially in three co-equal languages—French, English, and Portuguese.
The ECOWAS consists of two institutions to implement policies—the ECOWAS Commission and the ECOWAS Bank for Investment and Development, formerly known as the Fund for Cooperation until it was renamed in 2001.
A few members of the organization have come and gone over the years. In 1976 Cape Verde joined ECOWAS, and in December 2000 Mauritania withdrew, having announced its intention to do so in December 1999.
WAMI.
 Benin
 Burkina Faso
 Cape Verde
 Gambia
 Ghana
 Guinea
 Guinea-Bissau
 Ivory Coast
 Liberia
 Mali
 Niger
 Senegal
 Sierra Leone
 Togo
Former members.
 Mauritania, withdrew in December 2000
Structure.
President of the Commission, current and former.
From 1977 to 2006 the post name was Executive Secretary
From the restructuring
Regional security cooperation.
The ECOWAS nations assigned a non-aggression protocol in 1990 along with two earlier agreements in 1978 and 1981. They also signed a Protocol on Mutual Defence Assistance in Freetown, Sierra Leone, on 29 May 1981, that provided for the establishment of an Allied Armed Force of the Community.
Expanded ECOWAS Commission.
For the third time since its inception in 1975, ECOWAS is undergoing institutional reforms. The first was when it revised its treaty on 24 July 1993; the second was in 2007, when the Secretariat was transformed into a Commission. As of July 2013, ECOWAS now has six new departments (Human Resources Management; Education, Science and Culture; Energy and Mines; Telecommunications and IT; Industry and Private Sector Promotion. Finance and Administration to Sierra Leone has been decoupled, to give the incoming Ghana Commissioner the new portfolio of Administration and Conferences)
The Community Court of Justice.
The ECOWAS Community Court of Justice was created by a protocol signed in 1991 and was later included in Article 6 of the Revised Treaty of the Community in 1993. However, the Court did not officially begin operations until the 1991 protocol came into effect on 5 November 1996. The jurisdiction of the court is outlined in Article 9 and Article 76 of the Revised Treaty and allows rulings on disputes between states over interpretations of the Revised Treaty. It also provides the ECOWAS Council with advisory opinions on legal issues (Article 10). Like its companion courts the European Court of Human Rights and East African Court of Justice, it has jurisdiction to rule on fundamental human rights breaches.
Sporting and cultural exchange.
ECOWAS nations organize a broad array of cultural and sports event under the auspices of the body, including the CEDEAO Cup in football, the 2012 ECOWAS Games and the Miss CEDEAO beauty pageant.
Economic integration.
West African Economic and Monetary Union.
The West African Economic and Monetary Union (also known as UEMOA from its name in French, "Union économique et monétaire ouest-africaine") is an organization of eight West African states. It was established to promote economic integration among countries that share the CFA franc as a common currency. UEMOA was created by a Treaty signed at Dakar, Senegal, on 10 January 1994, by the heads of state and governments of Benin, Burkina Faso, Côte d’Ivoire, Mali, Niger, Senegal, and Togo. On 2 May 1997, Guinea-Bissau, a former Portuguese colony, became the organization’s eighth (and only non-Francophone) member state.
UEMOA is a customs union and currency union between the members of ECOWAS. Its objectives include the following:
Among its achievements, the UEMOA has successfully implemented macro-economic convergence criteria and an effective surveillance mechanism. It has adopted a customs union and common external tariff and has combined indirect taxation regulations, in addition to initiating regional structural and sectoral policies. A September 2002 IMF survey cited the UEMOA as "the furthest along the path toward integration" of all the regional groupings in Africa.
ECOWAS and UEMOA have developed a common plan of action on trade liberalization and macroeconomic policy convergence. The organizations have also agreed on common rules of origin to enhance trade, and ECOWAS has agreed to adopt UEMOA’s customs declaration forms and compensation mechanisms.
West African Monetary Zone.
Formed in 2000, the West African Monetary Zone (WAMZ) is a group of six countries within ECOWAS that plan to introduce a common currency, the Eco, by the year 2015. The six member states of WAMZ are Gambia, Ghana, Guinea, Nigeria and Sierra Leone who founded the organisation together in 2000 and Liberia who joined on 16 February 2010. Apart from Guinea, which is Francophone, they are all English speaking countries. Along with Mauritania, Guinea opted out of the CFA franc currency shared by all other former French colonies in West and Central Africa.
The WAMZ attempts to establish a strong stable currency to rival the CFA franc, whose exchange rate is tied to that of the Euro and is guaranteed by the French Treasury. The eventual goal is for the CFA franc and Eco to merge, giving all of West and Central Africa a single, stable currency. The launch of the new currency is being developed by the West African Monetary Institute based in Accra, Ghana.
Transport.
A Trans-ECOWAS project, established in 2007, plans to upgrade railways in this zone.
Controversies.
NSA surveillance.
Documents of Edward Snowden showed in December 2013 that British and American intelligence agencies surveillance targets with America's National Security Agency (NSA) included organisations such as the Economic Community of West African States (ECOWAS), the United Nations Development Programme, the UN's children's charity UNICEF and Médecins Sans Frontières.

</doc>
<doc id="36854" url="http://en.wikipedia.org/wiki?curid=36854" title="Paweł Jasienica">
Paweł Jasienica

Paweł Jasienica was the pen name of Leon Lech Beynar (10 November 1909 – 19 August 1970), a Polish historian, journalist and soldier.
During World War II, Jasienica (then, Leon Beynar) fought in the Polish Army, and later, the Armia Krajowa resistance. Near the end of the war, he was also working with the anti-Soviet resistance, which later led to him taking up a new name, Paweł Jasienica, to hide from the communist government of the People's Republic of Poland. He was associated with the Tygodnik Powszechny weekly and several other newspapers and magazines. He is best known for his 1960s books on Polish history—on the Kingdom of Poland under the Piast Dynasty, the Jagiellon Dynasty, and the elected kings of the Polish-Lithuanian Commonwealth. Those books, still popular, played an important role in popularizing Polish history among several generations of readers.
Jasienica became an outspoken critic of the censorship in the People's Republic of Poland, and as a notable dissident, he was persecuted by the government. He was subject to significant invigilation by the security services, and his second wife was in fact an agent of the communist secret police. For a brief period marking the end of his life, his books were prohibited from being distributed or printed.
Life.
Youth.
Beynar was born on 10 November 1909 in Simbirsk, Russia, to Polish parents, Mikołaj Beynar and Helena Maliszewska. His paternal grandfather, Ludwik Beynar, fought in the January Uprising and married a Spanish woman, Joanna Adela Feugas. His maternal grandfather, Wiktor Maliszewski, fought in the November Uprising. Both of his grandfathers eventually settled in the Russian Empire. His father, Mikołaj, worked as an agronomist. Beynar's family lived in Russia and Ukraine—they moved from Simbirsk to a location near Bila Tserkva and Uman, then to Kiev until the Russian Revolution of 1917, after which they decided to settle in the independent Poland. After brief stay in Warsaw, during the Polish-Soviet War, his family settled in Opatów, and in 1924, moved to Grodno.
Beynar graduated from "gymnasium" (secondary school) in Wilno (Vilnius) and graduated in history from Stefan Batory University in Wilno (his thesis concerned the January Uprising). At the university he was an active member of several organizations including "Klub Intelektualistów" (Intellectuals' Club) and "Akademicki Klub Włóczęgów" (Academic Club of Vagabonds). After graduating, he finished training for the officer cadet ("podchorąży") in the Polish Army. From 1928 to 1937 he lived in Grodno, where he worked as a history teacher in a gymnasium; later he was employed as an announcer for Polish Radio Wilno. Here also, Beynar embarked on his career as author and essayist, writing for a local newspaper, "Słowo Wileńskie" (The Wilno Word). On 11 November 1934 he marred Władysława z Adamowiczów, and in 1938 hs daughter Ewa was born. In 1935 he published his first history book, this one about king Zygmunt August, "Zygmunt August na ziemiach dawnego Wielkiego Księstwa" (Sigismund Augustus on the Lands of the Former Grand Duchy [of Lithuania]).
World War II.
During World War II, Beynar was a soldier in the Polish Army, fighting the German "Wehrmacht" when it invaded Poland in September 1939. He commanded a platoon near Sandomierz and was eventually taken prisoner by the Germans. While in temporary prisoner of war camp in Opatów, he was able to escape from it with the help of some old school friends from the time his family lived there in the early 1920s. He joined the Polish underground organization, "Związek Walki Zbrojnej" (Association for Armed Combat), later transformed into the "Armia Krajowa" ("AK"; the Home Army), and continued the fight against the Germans. In the resistance he had the rank of lieutenant, worked in the local Wilno headquarters and was an editor of an underground newspaper "Pobudka". He was also involved in the underground teaching. In July 1944 he took part in the operation aimed at the liberation of Wilno from the Germans (Operation Ostra Brama). In the aftermath of this operation, around 19–21 August, his partisan unit, like many others, was intercepted and attacked by the Soviets. He was taken prisoner; sources vary as to whether he was to be exiled to Siberia or conscripted into the Polish People's Army. Either way he escaped and rejoined AK partisans (the Home Army 5th Wilno Brigade). For a while, he was an aide to Major Zygmunt Szendzielarz ("Łupaszko") and was member of the anti-Soviet resistance, "Wolność i Niezawisłość" ("WiN", Freedom and Independence). He was promoted to the rank of captain. Wounded in August 1945, he left the Brigade before it was destroyed by the Soviets, and avoided the fate of most of its officers who were sentenced to death. While recovering from his wounds, he found shelter in the village of Jasienica.
Post-war.
After recovering from his wounds in 1945, Beynar decided to leave the resistance, and instead began publishing in an independent Catholic weekly "Tygodnik Powszechny". It was then that he took the pen-name Jasienica (from the name of the place where he had received treatment for his injuries) in order not to endanger his wife, who was still living in Soviet-controlled Vilnius, Lithuania. Soon he became a member of the weekly's staff and then an editor. In 1948 he was arrested by the Polish secret police (Polish: "Urząd Bezpieczeństwa") but after several weeks was released after the intervention of Bolesław Piasecki from the PAX Association. In gratitude to Piasecki, he worked with PAX in the future, leaving "Tygodnik Powszechny" for PAX in 1950. From 1950 he was a director of Polish Caritas charity. His essays were published in "Dziś i Jutro", "Słowo Powszechne", "Życie Warszawy", "Po Prostu". From at least this period till his death he would live in Warsaw. His wife Władysława died 29 March 1965.
Over time he became increasingly involved in various dissident organizations. In December 1959 he became a vice president of the Union of Polish Writers ("Związek Literatów Polskich", ZLP). He also published in the magazine "Świat" (1951–1969). In 1962 he was the last president of the literary discussion society, Klub Krzywego Koła. In 1966 he was a vice president of the PEN Club. While in the late 1940s and 1950s he focused mostly on journalistic activity, later he turned to writing popular history in book format. In the 1960s he wrote his most famous works, historical books about history of Poland - the Kingdom of Poland in the times of the Piast dynasty, the Jagiellonian dynasty, and the era of elected kings (the Polish-Lithuanian Commonwealth). His book on the Jagiellonian Poland was recognized as the best book of the year by the readers.
Jasienica was, however, very outspoken in his criticism of the censorship in the People's Republic of Poland. On 29 February 1968 during a ZLP meeting, Jasienia presented a harsh critique of the government. These acts, and in particular his signing of the dissident Letter of 34 in 1964 against censorship and his involvement in the 1968 protests led to his being labeled a political dissident, for which he suffered government persecution. Partly as a response to government's persecution of Jasienica, in 1968 the satirist Janusz Szpotański dedicated one of his anti-government poems, "Ballada o Łupaszce" (The Ballad of Łupaszko), written while Szpotański was in Mokotów Prison, to the writer. In the aftermath of the 1968 events, Polish communist media, and communist leader, Władysław Gomułka, on 19 March 1968, alleged that in 1948 Jasienica was freed because he collaborated with the communist regime; this allegation caused much controversy and damaged Jasienica's reputation. He was subject to much invigilation by the security services. In December 1969, five years after his first wife's death, he became married again. This marriage, after his death, proven to be highly controversial, as his second wife was in fact a secret police informant before the marriage, and continued to write reports about him throughout their marriage. Since then, till his death, his books were prohibited from being distributed or printed.
Jasienica died from cancer on 19 August 1970 in Warsaw. Some publicists later speculated to what extent his death was caused by "hounding from the party establishment". He is buried in Warsaw's Powązki Cemetery. His funeral was attended by many dissidents and became a political manifestation; Adam Michnik recalls seeing Antoni Słonimski, Stefan Kisielewski, Stanisław Stomma, Jerzy Andrzejewski, Jan Józef Lipski and Władysław Bartoszewski. Bohdan Cywiński read a letter from Antoni Gołubiew.
Work.
Jasienica book publishing begun with a historical book, "Zygmunt August na ziemiach dawnego Wielkiego Księstwa" (Sigismund Augustus in the lands of the former Grand Duchy; 1935). He is best known for his highly acclaimed and popular historical books from the 1960s about Piast Poland, Jagiellon Poland and the Polish-Lithuanian Commonwealth: "Polska Piastów" (Piast Poland, 1960), "Polska Jagiellonów" (Jagiellon Poland, 1963) and the trilogy "Rzeczpospolita Obojga Narodów" (The Commonwealth of Both Nations, 1967–1972). This trilogy made him one of the most popular Polish history writers. Throughout his life he avoided writing about modern history, to minimize the influence that the official, communist Marxist historiography would have on his works. This was also one of the reasons for the popularity of his works, which were seen as a rare, legally obtainable alternative to the official version of history. His books, publication of which resumed once again after his death, were labeled as "best-selling", and became the most reprinted postwar history of Poland.
His "Dwie drogi" (Two ways, 1959) about the January Uprising of the 1860s represent the latest historical period he has tackled. His other popular historical books include "Trzej kronikarze", (Three chroniclers; 1964), a book about three medieval chroniclers of Polish history (Thietmar of Merseburg, Gallus Anonymus and Wincenty Kadłubek), in which he discusses the Polish society through ages; and "Ostatnia z rodu" (Last of the Family; 1965) about the last queen of the Jagiellon dynasty, Anna Jagiellonka. His "Rozważania o wojnie domowej" (1978; Thoughts on Civil War) were the last book he has finished; unlike majority of his other works, this book is ostensibly about the civil war (Chouannerie) in Brittany, France. This work does however contains numerous arguments applicable to more modern Polish history; arguments that Jasienica thought would not be allowed by the censors if the book discussed Polish history.
In addition to historical books, Jasienica, wrote a series of essays about archeology - "Słowiański rodowód" (Slavic genealogy; 1961) and "Archeologia na wyrywki. Reportaże" (Archeological excerpts: reports; 1956), journalistic travel reports ("Wisła pożegna zaścianek", "Kraj Nad Jangtse") and science and technology ("Opowieści o żywej materii", "Zakotwiczeni"). Those works were mostly created around the 1950s and 1960s.
His "Pamiętnik" (Diary) was the work that he begun shortly before his death, and that was never finished.
In 2006, Polish journalist and former dissident Adam Michnik said that:
Polish historian Henryk Samsonowicz echoes Michnik's essay in his introduction to a recent (2008) edition of "Trzej kronikarze", describing Jasienica as a person who did much to popularize Polish history. Hungarian historian Balázs Trencsényi notes that "Jasienica's impact of the formation of the popular interpretation of Polish history is hard to overestimate". British historian Norman Davies, himself an author of a popular account of Polish history ("God's Playground"), notes that Jasienica, while more of "a historical writer than an academic historian", had "formidable talents", gained "much popularity" and that his works would find no equals in the time of communist Poland. Samsonowicz notes that Jasienica "was a brave writer", going against prevailing system, and willing to propose new hypotheses and reinterpret history in innovative ways. Michnik notes how Jasienica was willing to write about Polish mistakes, for example in the treatment of Cossacks. Ukrainian historian Stephen Velychenko also positively commented on Jasienica's extensive coverage of the Polish-Ukrainian history. Both Michnik and Samsonowicz note how Jasienica's works contain hidden messages in which Jasienica discusses more contemporary history, such as in his "Rozważania...".
Bibliography.
Several of Jasienica's books have been translated into English by Alexander Jordan and published by the American Institute of Polish Culture, based in Miami, Florida.
Further reading.
 Polish Wikiquote has quotations related to: 

</doc>
<doc id="36856" url="http://en.wikipedia.org/wiki?curid=36856" title="Vertebrate">
Vertebrate

Vertebrates are animals that are any species of animals within the subphylum Vertebrata (chordates with backbones). Vertebrates represent the overwhelming majority of the phylum Chordata, with currently about 64,000 species described. Vertebrates include the jawless fish and the jawed vertebrates, which includes the cartilaginous fish (sharks and rays) and the bony fish. A bony fish clade known as the lobe-finned fishes includes the tetrapods, which are divided into amphibians, reptiles, mammals, and birds. Extant vertebrates range in size from the frog species "Paedophryne amauensis", at as little as 7.7 mm, to the blue whale, at up to 33 m. Vertebrates make up about 4% of all described animal species; the rest are invertebrates, which lack vertebral columns.
The vertebrates traditionally include the hagfish, which do not have proper vertebrae, though their closest living relatives, the lampreys, do. Hagfish do, however, possess a cranium. For this reason, the vertebrate subphylum is sometimes referred to as "Craniata" when discussing morphology. Molecular analysis since 1992 has suggested that the hagfish are most closely related to lampreys, and so also are vertebrates in a monophyletic sense. Others consider them a sister group of vertebrates in the common taxon of Craniata.
Etymology.
The word "vertebrate" derives from the Latin word "vertebratus" (Pliny), meaning "joint of the spine." It is closely related to the word "vertebra", which refers to any of the bones or segments of the spinal column.
Anatomy and morphology.
All vertebrates are built along the basic chordate body plan: a stiff rod running through the length of the animal (vertebral column or notochord), with a hollow tube of nervous tissue (the spinal cord) above it and the gastrointestinal tract below. In all vertebrates, the mouth is found at, or right below, the anterior end of the animal, while the anus opens to the exterior before the end of the body. The remaining part of the body continuing after of the anus forms a tail with vertebrae and spinal cord, but no gut.
Vertebral column.
The defining characteristic of a vertebrate is the vertebral column, in which the notochord (a stiff rod of uniform composition) found in all chordates has been replaced by a segmented series of stiffer elements (vertebrae) separated by mobile joints (intervertebral discs, derived embryonically and evolutionarily from the notochord). However, a few vertebrates have secondarily lost this anatomy, retaining the notochord into adulthood, such as the sturgeon and the "Latimeria". Jawed vertebrates are typified by paired appendages (fins or legs, which may be secondarily lost), but this is not part of the definition of vertebrates as a whole.
Gills.
All basal vertebrates breathe with gills. The gills are carried right behind the head, bordering the posterior margins of a series of openings from the esophagus to the exterior. Each gill is supported by a cartilagenous or bony gill arch. The bony fish have three pairs of arches, cartilaginous fish have five to seven pairs, while the primitive jawless fish have seven. The vertebrate ancestor no doubt had more arches, as some of their chordate relatives have more than 50 pairs of gills.
In amphibians and some primitive bony fishes, the larvae bear external gills, branching off from the gill arches. These are reduced in adulthood, their function taken over by the gills proper in fishes and by lungs in most amphibians. Some amphibians retain the external larval gills in adulthood, the complex internal gill system as seen in fish apparently being irrevocably lost very early in the evolution of tetrapods.
While the higher vertebrates do not have gills, the gill arches form during fetal development, and lay the basis of essential structures such as jaws, the thyroid gland, the larynx, the "columella" (corresponding to the stapes in mammals) and in mammals the malleus and incus.
Central nervous system.
The central nervous system of vertebrates is based on a hollow nerve cord running along the length of the animal. Of particular importance and unique to vertebrates is the presence of neural crest cells. These are progenitors of stem cells, and critical to coordinating the functions of cellular components. Neural crest cells migrate through the body from the nerve cord during development, and initiate the formation of neural ganglia and structures such as the jaws and skull.
The vertebrates are the only chordate group to exhibit cephalisation, the concentration of brain functions in the head. A slight swelling of the anterior end of the nerve cord is found in the lancelet, though it lacks the eyes and other complex sense organs comparable to those of vertebrates. Other chordates do not show any trends towards cephalisation.
A peripheral nervous system branches out from the nerve cord to innervate the various systems. The front end of the nerve tube is expanded by a thickening of the walls and expansion of the central canal of spinal cord into three primary brain vesicles: The prosencephalon (forebrain), mesencephalon (midbrain) and rhombencephalon (hindbrain), further differentiated in the various vertebrate groups. Two laterally placed eyes form around outgrows from the midbrain, except in hagfish, though this may be a secondary loss. The forebrain is well developed and subdivided in most tetrapods, while the midbrain dominate in many fish and some salamanders. Vesicles of the forebrain are usually paired, giving rise to hemispheres like the cerebral hemispheres in mammals.
The resulting anatomy of the central nervous system, with a single hollow nerve cord topped by a series of (often paired) vesicles, is unique to vertebrates. All invertebrates with well-developed brains, such as insects, spiders and squids, have a ventral rather than dorsal system of ganglions, with a split brain stem running on each side of the mouth or gut.
Evolutionary history.
First vertebrates.
Vertebrates originated about 525 million years ago during the Cambrian explosion, which saw the rise in organism diversity. The earliest known vertebrate is believed to be the "Myllokunmingia". Another early vertebrate is "Haikouichthys ercaicunensis". Unlike the other fauna that dominated the Cambrian, these groups had the basic vertebrate body plan: a notochord, rudimentary vertebrae, and a well-defined head and tail. All of these early vertebrates lacked jaws in the common sense and relied on filter feeding close to the seabed. A vertebrate group of uncertain phylogeny, small-eel-like conodonts, are known from microfossils of their paired tooth segments from the late Cambrian to the end of the Triassic.
From fish to amphibians.
The first jawed vertebrates appeared in the latest Ordovician and became common in the Devonian, often known as the "Age of Fishes". The two groups of bony fishes, the actinopterygii and sarcopterygii, evolved and became common. The Devonian also saw the demise of virtually all jawless fishes, save for lampreys and hagfish, as well as the Placodermi, a group of armoured fish that dominated much of the late Silurian. The Devonian also saw the rise of the first labyrinthodonts, which was a transitional form between fishes and amphibians.
Mesozoic vertebrates.
The reptiles appeared from labyrinthodonts in the subsequent Carboniferous period. The anapsid and synapsid reptiles were common during the late Paleozoic, while the diapsids became dominant during the Mesozoic. In the sea, the bony fishes became dominant. The dinosaurs gave rise to the birds in the Jurassic. The demise of the dinosaurs at the end of the Cretaceous allowed for expansion of the mammals, which had evolved from the therapsids, a group of synapsid reptiles, during the late Triassic Period.
After the Mesozoic.
The Cenozoic world has seen great diversification of bony fishes, frogs, birds and mammals.
Over half of all living vertebrate species (about 32,000 species) are fishes (non-tetrapod craniates), a diverse set of lineages that inhabit all the world's aquatic ecosystems, from snow minnows (Cypriniformes) in Himalayan lakes at elevations over 4,600 m to flatfishes (order Pleuronectiformes) in the Challenger Deep, the deepest ocean trench at about 11,000 m. Fishes of myriad varieties are the main predators in most of the world’s water bodies, both freshwater and marine. The rest of the vertebrate species are tetrapods, a single lineage that includes amphibians (with roughly 7,000 species); mammals (with approximately 5,500 species); and reptiles and birds (with about 20,000 species divided evenly between the two classes). Tetrapods comprise the dominant megafauna of most terrestrial environments and also include many partially or fully aquatic groups (e.g., sea snakes, penguins, cetaceans).
Classification.
There are several ways of classifying animals. Evolutionary systematics relies on anatomy, physiology and evolutionary history, which is determined through similarities in anatomy and, if possible, the genetics of organisms. Phylogenetic classification is based solely on phylogeny. Evolutionary systematics gives an overview; phylogenetic systematics gives detail. The two systems are thus complementary rather than opposed.
Traditional classification.
Conventional classification has living vertebrates grouped into seven classes based on traditional interpretations of gross anatomical and physiological traits. This classification is the one most commonly encountered in school textbooks, overviews, non-specialist, and popular works. The extant vertebrates are:
In addition to these comes two classes of extinct armoured fishes, the Placodermi and the Acanthodii. Other ways of classifying the vertebrates have been devised, particularly with emphasis on the phylogeny on early amphibians and reptiles. An example based on Janvier (1981, 1997), Shu "et al." (2003), and Benton (2004) is given here:
While this traditional classification is orderly, most of the groups are paraphyletic, i.e. do not contain all descendants of the class' common ancestor. For instance, descendants of the first reptiles include modern reptiles as well as mammals and birds. Most of the classes listed are not "complete" (and therefore paraphyletic) taxa, meaning they do not include all the descendants of the first representative of the group. For example, the agnathans have given rise to the jawed vertebrates; the bony fishes have given rise to the land vertebrates; the traditional "amphibians" have given rise to the reptiles (traditionally including the synapsids, or mammal-like "reptiles"), which in turn have given rise to the mammals and birds. Most scientists working with vertebrates use a classification based purely on phylogeny, organized by their known evolutionary history and sometimes disregarding the conventional interpretations of their anatomy and physiology.
Phylogenetic relationships.
In phylogenetic taxonomy, the relationships between animals are not typically divided into ranks, but illustrated as a nested "family tree" known as a cladogram. Phylogenetic groups are given definitions based on their relationship to one another, rather than purely on physical traits, such as the presence of a backbone. This nesting pattern is often combined with traditional taxonomy (as above), in a practice known as evolutionary taxonomy.
The cladogram presented below is based on studies compiled by Philippe Janvier and others for the "Tree of Life Web Project".
Bibliography.
</dl>

</doc>
<doc id="36857" url="http://en.wikipedia.org/wiki?curid=36857" title="Thrace">
Thrace

Thrace (demonym "Thracian" ; Ancient Greek: Θρᾴκη, "Thrāikē"; modern Greek: Θράκη, "Thráki"; Bulgarian: Тракия, "Trakija"; Turkish: "Trakya") is a historical and geographic area in southeast Europe, centered on the modern borders of Bulgaria, Greece, and Turkey. As a geographical concept, Thrace designates a region bounded by the Balkan Mountains on the north, Rhodope Mountains and the Aegean Sea on the south, and by the Black Sea and the Sea of Marmara on the east. The areas it comprises are southeastern Bulgaria (Northern Thrace), northeastern Greece (Western Thrace), and the European part of Turkey (Eastern Thrace). The biggest part of Thrace is part of present-day Bulgaria. In Turkey, it is also called Rumeli. The name comes from the Thracians, an ancient Indo-European people inhabiting Southeastern Europe.
Etymology.
The name appears to derive from an ancient heroine and sorceress Thrace, who was the daughter of Oceanus and Parthenope, and sister of Europa. The word itself derives from the Latin "Thrācia", which comes from Ancient Greek "Thrākē" (Θρᾴκη), descending from "Thrāks" (Θρᾱξ/Θρᾴξ), meaning “Thracian”, ultimately being derived from "thrāssō", meaning “to trouble, stir”.
Geography.
Borders.
The historical boundaries of Thrace have varied. Noteworthy is the fact that, at an early date, the ancient Greeks employed the term "Thrace" to refer to all of the territory which lay north of Thessaly inhabited by the Thracians, a region which "had no definite boundaries" and to which other regions (like Macedonia and even Scythia) were added. In one ancient Greek source, the very Earth is divided into "Asia, Libya, Europa and Thracia". As the knowledge of world geography of the Greeks broadened, the term came to be more restricted in its application: Thrace designated the lands bordered by the Danube on the north, by the Euxine Sea (Black Sea) on the east, by northern Macedonia in the south and by Illyria to the west. This largely coincided with the Thracian Odrysian kingdom, whose borders varied over time. During this time, specifically after the Macedonian conquest, the region's old border with Macedonia was shifted from the Struma River to the Mesta River. This usage lasted until the Roman conquest. Henceforth, (classical) Thrace referred only to the tract of land largely covering the same extent of space as the modern geographical region. In its early period, the Roman province of Thrace was of this extent, but after the administrative reforms of the late 3rd century, Thracia's much reduced territory became the six small provinces which constituted the Diocese of Thrace. The medieval Byzantine theme of Thrace contained only what today is Eastern Thrace.
Cities of Thrace.
The largest cities of Thrace are: Byzantium (İstanbul), Plovdiv, Burgas, Stara Zagora, Haskovo, Komotini, Alexandroupoli, Edirne, Çorlu and Tekirdağ.
Demographics and religion.
Most of the Bulgarian and Greek population are Christians, while most of the Turkish inhabitants of Thrace are Muslims.
Thrace in ancient Greek mythology.
Ancient Greek mythology provides them with a mythical ancestor, named Thrax, son of the war-god Ares, who was said to reside in Thrace. The Thracians appear in Homer's "Iliad" as Trojan allies, led by Acamas and Peiros. Later in the "Iliad", Rhesus, another Thracian king, makes an appearance. Cisseus, father-in-law to the Trojan elder Antenor, is also given as a Thracian king. Homeric Thrace was vaguely defined, and stretched from the River Axios in the west to the Hellespont and Black Sea in the east. The Catalogue of Ships mentions three separate contingents from Thrace: Thracians led by Acamas and Peiros, from Aenus; Cicones led by Euphemus, from southern Thrace, near Ismaros; and from the city of Sestus, on the Thracian (northern) side of the Hellespont, which formed part of the contingent led by Asius. Greek mythology is replete with Thracian kings, including Diomedes, Tereus, Lycurgus, Phineus, Tegyrius, Eumolpus, Polymnestor, Poltys, and Oeagrus (father of Orpheus). In addition to the tribe that Homer calls Thracians, ancient Thrace was home to numerous other tribes, such as the Edones, Bisaltae, Cicones, and Bistones."
Thrace is also mentioned in Ovid's Metamorphoses in the episode of Philomela, Procne, and Tereus. Tereus, the King of Thrace, lusts after his sister-in-law, Philomela. He kidnaps her, holds her captive, rapes her, and cuts out her tongue. Philomela manages to get free, however. She and her sister, Procne, plot to get revenge, by killing Itys (son of Tereus and Procne) and serving him to his father for dinner. At the end of the myth, all three turn into birds—Procne, a swallow; Philomela, a nightingale; and Tereus, a hoopoe.
History.
Ancient and Roman history.
The indigenous population of Thrace was a people called the Thracians, divided into numerous tribal groups. A large part of the region was at times controlled by the Persian Empire at its greatest extent, and Thracian soldiers were known to be used in the Persian armies. Later on, Thracian troops were known to accompany neighboring ruler Alexander the Great when he crossed the Hellespont which abuts Thrace, and took on the Persian Empire itself.
The Thracians did not describe themselves by name; terms such as "Thrace" and "Thracians" are simply the names given them by the Greeks.
Divided into separate tribes, the Thracians did not form any lasting political organizations until the founding of the Odrysian state in the 4th century BC. Like Illyrians, the locally ruled Thracian tribes of the mountainous regions maintained a warrior tradition, while the tribes based in the plains were purportedly more peaceable. Recently discovered funeral mounds in Bulgaria suggest that Thracian kings did rule regions of Thrace with distinct Thracian national identity.
During this period, a subculture of celibate ascetics called the Ctistae lived in Thrace, where they served as philosophers, priests and prophets.
Sections of Thrace particularly in the south started to become hellenized before the Peloponnesian War as a significant amount of Athenian and Ionian colonies were set up in Thrace before the war and Spartan and other Doric colonists followed suit after the war. In 168 BC, after the Third Macedonian war and the subjugation of Macedonia to the Romans, Thrace also lost its independence and became tributary to Rome, while towards the end of the 1st century BC was no longer a client kingdom of the Romans appointed and their kings. And this situation until 46 AD, when the Romans finally turned Thrace into a Roman province (Romana provincia Thracia)
During the Roman domination, within the geographical borders of ancient Thrace, there were two separate Roman provinces, namely Thrace ("provincia Thracia") and Lower Moesia ("Moesia inferior"). Later, in the times of Diocletian, the two provinces were joined and formed the so-called "Dioecesis Thracia". Thanks to the provincial and urban policy of the Romans, the urbanisation of Thrace has large dimensions, so that in the 2nd and 3rd AD century was completed after the establishment of Roman colonies and mostly several Greek cities, as was Nicopolis, Topeiros, Traianoupolis, Plotinoupolis and Hadrianoupolis. It is noteworthy that the Roman provincial policy in Thrace favored mainly not the Romanization but the Hellenization of the country, which had started as early as the Archaic period through the Greek colonisation and was completed by the end of Roman Antiquity. As regards the competition between the Greek and Latin language, the very high rate of Greek inscriptions in Thrace extending south of Haemus mountains proves the complete language Hellenization of this region. The boundaries between the Greek and Latin speaking Thrace are placed just above the northern foothills of Haemus mountains.
Medieval history.
By the mid 5th century, as the Western Roman Empire began to crumble, Thracia fell from the authority of Rome and into the hands of Germanic tribal rulers. With the fall of the Western Roman Empire, Thracia turned into a battleground territory for the better part of the next 1,000 years. The surviving eastern portion of the Roman Empire in the Balkans, later known as the Byzantine Empire, retained control over Thrace until the 8th century when the northern half of the entire region was incorporated into the First Bulgarian Empire and the remainder was reorganized in the Thracian theme. The Empire regained the lost regions in the late 10th century until the Bulgarians regained control of the northern half at the end of the 12th century. Throughout the 13th century and the first half of the 14th century, the region was changing in the hands of the Bulgarian and the Byzantine Empire (excluding Constantinople). In 1265 the area suffered a Mongol raid from the Golden Horde, led by Nogai Khan, and between 1305 and 1307 was raided by the Catalan company.
Ottoman period.
In 1352, the Ottoman Turks conducted their first incursion into the region subduing it completely within a matter of two decades and occupying it for five centuries. In 1821, several parts of Thrace, such as Lavara, Maroneia, Sozopolis, Aenos, Callipolis and Samothraki rebelled during the Greek War of Independence.
Modern history.
With the Congress of Berlin in 1878, Northern Thrace was incorporated into the semi-autonomous Ottoman province of Eastern Rumelia, which united with Bulgaria in 1885. The rest of Thrace was divided among Bulgaria, Greece and Turkey at the beginning of the 20th century, following the Balkan Wars, World War I and the Greco-Turkish War. Today "Thracian" is a geographical term used in Greece, Turkey and Bulgaria.
Honours.
Trakiya Heights in Antarctica "are named after the historical region of Trakiya (Thrace)."

</doc>
<doc id="36858" url="http://en.wikipedia.org/wiki?curid=36858" title="Wheat">
Wheat

Wheat ("Triticum" spp.) is a cereal grain, originally from the Levant region of the Near East but now cultivated worldwide. In 2013, world production of wheat was 713 million tons, making it the third most-produced cereal after maize (1,016 million tons) and rice (745 million tons). Wheat was the second most-produced cereal in 2009; world production in that year was 682 million tons, after maize (817 million tons), and with rice as a close third (679 million tons).
This grain is grown on more land area than any other commercial food. World trade in wheat is greater than for all other crops combined. Globally, wheat is the leading source of vegetable protein in human food, having a higher protein content than other major cereals, maize (corn) or rice. In terms of total production tonnages used for food, it is currently second to rice as the main human food crop and ahead of maize, after allowing for maize's more extensive use in animal feeds.
Wheat was a key factor enabling the emergence of city-based societies at the start of civilization because it was one of the first crops that could be easily cultivated on a large scale, and had the additional advantage of yielding a harvest that provides long-term storage of food. Wheat contributed to the emergence of city-states in the Fertile Crescent, including the Babylonian and Assyrian empires. Wheat grain is a staple food used to make flour for leavened, flat and steamed breads, biscuits, cookies, cakes, breakfast cereal, pasta, noodles, couscous and for fermentation to make beer, other alcoholic beverages, and biofuel.
There are six wheat classifications: 1) hard red winter, 2) hard red spring, 3) soft red winter, 4) durum (hard), 5) Hard white, 6) soft white wheat. 
The hard wheats have the most amount of gluten and are used for making bread, rolls and all-purpose flour. The soft wheats are used for making flat bread, cakes, pastries, crackers, muffins, and 
biscuits. A high percentage of wheat production in the EU is used as animal feed, often surplus to human requirements or low-quality wheat.
Wheat is planted to a limited extent as a forage crop for livestock, although the straw cannot be used as feed. Its straw can be used as a construction material for roofing thatch. The whole grain can be milled to leave just the endosperm for white flour. The by-products of this are bran and germ. The whole grain is a concentrated source of vitamins, minerals, and protein, while the refined grain is mostly starch.
Wheat is one of the first cereals known to have been domesticated, and wheat's ability to self-pollinate greatly facilitated the selection of many distinct domesticated varieties. The archaeological record suggests that this first occurred in the regions known as the Fertile Crescent. Recent findings estimate the first domestication of wheat down to a small region of southeastern Turkey, and domesticated Einkorn wheat at Wadi el Jilat in Jordan—has been dated to 7,500-7,300 BCE.
Origin.
 Cultivation and repeated harvesting and sowing of the grains of wild grasses led to the creation of domestic strains, as mutant forms ('sports') of wheat were preferentially chosen by farmers. In domesticated wheat, grains are larger, and the seeds (inside the spikelets) remain attached to the ear by a toughened rachis during harvesting. In wild strains, a more fragile rachis allows the ear to easily shatter and disperse the spikelets. Selection for these traits by farmers might not have been deliberately intended, but simply have occurred because these traits made gathering the seeds easier; nevertheless such 'incidental' selection was an important part of crop domestication. As the traits that improve wheat as a food source "also" involve the loss of the plant's natural seed dispersal mechanisms, highly domesticated strains of wheat cannot survive in the wild.
Cultivation of wheat began to spread beyond the Fertile Crescent after about 8000 BCE. Jared Diamond traces the spread of cultivated emmer wheat starting in the Fertile Crescent sometime before 8800 BCE. Archaeological analysis of wild "emmer" indicates that it was first cultivated in the southern Levant with finds dating back as far as 9600 BCE. Genetic analysis of wild "einkorn" wheat suggests that it was first grown in the Karacadag Mountains in southeastern Turkey. Dated archeological remains of einkorn wheat in settlement sites near this region, including those at Abu Hureyra in Syria, suggest the domestication of einkorn near the Karacadag Mountain Range. With the anomalous exception of two grains from Iraq ed-Dubb, the earliest carbon-14 date for einkorn wheat remains at Abu Hureyra is 7800 to 7500 years BCE.
Remains of harvested emmer from several sites near the Karacadag Range have been dated to between 8600 (at Cayonu) and 8400 BCE (Abu Hureyra), that is, in the Neolithic period. With the exception of Iraq ed-Dubb, the earliest carbon-14 dated remains of domesticated emmer wheat were found in the earliest levels of Tell Aswad, in the Damascus basin, near Mount Hermon in Syria. These remains were dated by Willem van Zeist and his assistant Johanna Bakker-Heeres to 8800 BCE. They also concluded that the settlers of Tell Aswad did not develop this form of emmer themselves, but brought the domesticated grains with them from an as yet unidentified location elsewhere.
The cultivation of emmer reached Greece, Cyprus and India by 6500 BCE, Egypt shortly after 6000 BCE, and Germany and Spain by 5000 BCE. "The early Egyptians were developers of bread and the use of the oven and developed baking into one of the first large-scale food production industries." By 3000 BCE, wheat had reached England and Scandinavia. A millennium later it reached China. The first identifiable bread wheat ("Triticum aestivum") with sufficient gluten for yeasted breads has been identified using DNA analysis in samples from a granary dating to approximately 1350 BCE at Assiros in Greek Macedonia.
Wheat continued to spread throughout Europe. In England, wheat straw (thatch) was used for roofing in the Bronze Age, and was in common use until the late 19th century.
Farming techniques.
Technological advances in soil preparation and seed placement at planting time, use of crop rotation and fertilizers to improve plant growth, and advances in harvesting methods have all combined to promote wheat as a viable crop. Agricultural cultivation using horse collar leveraged plows (at about 3000 BCE) was one of the first innovations that increased productivity. Much later, when the use of seed drills replaced broadcasting sowing of seed in the 18th century, another great increase in productivity occurred.
Yields of pure wheat per unit area increased as methods of crop rotation were applied to long cultivated land, and the use of fertilizers became widespread. Improved agricultural husbandry has more recently included threshing machines and reaping machines (the 'combine harvester'), tractor-drawn cultivators and planters, and better varieties (see Green Revolution and Norin 10 wheat). Great expansion of wheat production occurred as new arable land was farmed in the Americas and Australia in the 19th and 20th centuries.
Genetics.
Wheat genetics is more complicated than that of most other domesticated species. Some wheat species are diploid, with two sets of chromosomes, but many are stable polyploids, with four sets of chromosomes (tetraploid) or six (hexaploid).
The presence of certain versions of wheat genes has been important for crop yields. Apart from mutant versions of genes selected in antiquity during domestication, there has been more recent deliberate selection of alleles that affect growth characteristics. Genes for the 'dwarfing' trait, first used by Japanese wheat breeders to produce short-stalked wheat, have had a huge effect on wheat yields world-wide, and were major factors in the success of the Green Revolution in Mexico and Asia, an initiative led by Norman Borlaug. Dwarfing genes enable the carbon that is fixed in the plant during photosynthesis to be diverted towards seed production, and they also help prevent the problem of lodging. 'Lodging' occurs when an ear stalk falls over in the wind and rots on the ground, and heavy nitrogenous fertilization of wheat makes the grass grow taller and become more susceptible to this problem. By 1997, 81% of the developing world's wheat area was planted to semi-dwarf wheats, giving both increased yields and better response to nitrogenous fertilizer.
Wild grasses in the genus "Triticum" and related genera, and grasses such as rye have been a source of many disease-resistance traits for cultivated wheat breeding since the 1930s.
Heterosis, or hybrid vigor (as in the familiar F1 hybrids of maize), occurs in common (hexaploid) wheat, but it is difficult to produce seed of hybrid cultivars on a commercial scale (as is done with maize) because wheat flowers are perfect and normally self-pollinate. Commercial hybrid wheat seed has been produced using chemical hybridizing agents; these chemicals selectively interfere with pollen development, or naturally occurring cytoplasmic male sterility systems. Hybrid wheat has been a limited commercial success in Europe (particularly France), the USA and South Africa. F1 hybrid wheat cultivars should not be confused with the standard method of breeding inbred wheat cultivars by crossing two lines using hand emasculation, then selfing or inbreeding the progeny many (ten or more) generations before release selections are identified to be released as a variety or cultivar.
Synthetic hexaploids made by crossing the wild goatgrass wheat ancestor "Aegilops tauschii" and various durum wheats are now being deployed, and these increase the genetic diversity of cultivated wheats.
Stomata (or leaf pores) are involved in both uptake of carbon dioxide gas from the atmosphere and water vapor losses from the leaf due to water transpiration. Basic physiological investigation of these gas exchange processes has yielded valuable carbon isotope based methods that are used for breeding wheat varieties with improved water-use efficiency. These varieties can improve crop productivity in rain-fed dry-land wheat farms.
In 2010, a team of UK scientists funded by BBSRC announced they had decoded the wheat genome for the first time (95% of the genome of a variety of wheat known as Chinese Spring line 42). This genome was released in a basic format for scientists and plant breeders to use but was not a fully annotated sequence which was reported in some of the media.
On 29 November 2012, an essentially complete gene set of bread wheat has been published. Random shotgun libraries of total DNA and cDNA from the "T. aestivum" cv. Chinese Spring (CS42) were sequenced in Roche 454 pyrosequencer using GS FLX Titanium and GS FLX+ platforms to generate 85 Gb of sequence (220 million reads), equivalent to 5X genome coverage and identified between 94,000 and 96,000 genes.
This sequence data provides direct access to about 96,000 genes, relying on orthologous gene sets from
other cereals. and represents an essential step towards a systematic understanding of biology and engineering the cereal crop for valuable traits. Its implications in cereal genetics and breeding includes the examination of genome variation, association mapping using natural populations, performing wide crosses and alien introgression, studying the expression and nucleotide polymorphism in transcriptomes, analyzing population genetics and evolutionary biology, and studying the epigenetic modifications. Moreover, the availability of large-scale genetic markers generated through NGS technology will facilitate trait mapping and make marker-assisted breeding much feasible.
Moreover, the data not only facilitate in deciphering the complex phenomena such as heterosis and epigenetics, it may also enable breeders to predict which fragment of a chromosome is derived from which parent in the progeny line, thereby recognizing crossover events occurring in every progeny line and inserting markers on genetic and physical maps without ambiguity. In due course, this will assist in introducing specific chromosomal segments from one cultivar to another. Besides, the researchers had identified diverse classes of genes participating in energy production, metabolism and growth that were probably linked with crop yield, which can now be utilized for the development of transgenic wheat. Thus whole genome sequence of wheat and the availability of thousands of SNPs will inevitably permit the breeders to stride towards identifying novel traits, providing biological knowledge and empowering biodiversity-based breeding.
Plant breeding.
In traditional agricultural systems wheat populations often consist of landraces, informal farmer-maintained populations that often maintain high levels of morphological diversity. Although landraces of wheat are no longer grown in Europe and North America, they continue to be important elsewhere. The origins of formal wheat breeding lie in the nineteenth century, when single line varieties were created through selection of seed from a single plant noted to have desired properties. Modern wheat breeding developed in the first years of the twentieth century and was closely linked to the development of Mendelian genetics. The standard method of breeding inbred wheat cultivars is by crossing two lines using hand emasculation, then selfing or inbreeding the progeny. Selections are "identified" (shown to have the genes responsible for the varietal differences) ten or more generations before release as a variety or cultivar.
The major breeding objectives include high grain yield, good quality, disease and insect resistance and tolerance to abiotic stresses include mineral, moisture and heat tolerance. The major diseases in temperate environments include the following, arranged in a rough order of their significance from cooler to warmer climates: eyespot, Stagonospora nodorum blotch (also known as glume blotch), yellow or stripe rust, powdery mildew, Septoria tritici blotch (sometimes known as leaf blotch), brown or leaf rust, Fusarium head blight, tan spot and stem rust. In tropical areas, spot blotch (also known as Helminthosporium leaf blight) is also important.
Wheat has also been the subject of mutation breeding, with the use of gamma, x-rays, ultraviolet light, and sometimes harsh chemicals. The varieties of wheat created through this methods are in the hundreds (varieties being as far back as 1960), more of them being created in higher populated countries such as China.
Hybrid wheat.
Because wheat self-pollinates, creating hybrid varieties is extremely labor-intensive; the high cost of hybrid wheat seed relative to its moderate benefits have kept farmers from adopting them widely despite nearly 90 years of effort. F1 hybrid wheat cultivars should not be confused with wheat cultivars deriving from standard plant breeding. Heterosis or hybrid vigor (as in the familiar F1 hybrids of maize) occurs in common (hexaploid) wheat, but it is difficult to produce seed of hybrid cultivars on a commercial scale as is done with maize because wheat flowers are complete and normally self-pollinate. Commercial hybrid wheat seed has been produced using chemical hybridizing agents, plant growth regulators that selectively interfere with pollen development, or naturally occurring cytoplasmic male sterility systems. Hybrid wheat has been a limited commercial success in Europe (particularly France), the United States and South Africa.
Hulled versus free-threshing wheat.
The four wild species of wheat, along with the domesticated varieties einkorn, emmer and spelt, have hulls. This more primitive morphology (in evolutionary terms) consists of toughened glumes that tightly enclose the grains, and (in domesticated wheats) a semi-brittle rachis that breaks easily on threshing. The result is that when threshed, the wheat ear breaks up into spikelets. To obtain the grain, further processing, such as milling or pounding, is needed to remove the hulls or husks. In contrast, in free-threshing (or naked) forms such as durum wheat and common wheat, the glumes are fragile and the rachis tough. On threshing, the chaff breaks up, releasing the grains. Hulled wheats are often stored as spikelets because the toughened glumes give good protection against pests of stored grain.
Naming.
There are many botanical classification systems used for wheat species, discussed in a separate article on Wheat taxonomy. The name of a wheat species from one information source may not be the name of a wheat species in another.
Within a species, wheat cultivars are further classified by wheat breeders and farmers in terms of:
Major cultivated species of wheat.
Hexaploid Species
Tetraploid Species
Diploid Species
Classes used in the United States:
Red wheats may need bleaching; therefore, white wheats usually command higher prices than red wheats on the commodities market.
As a food.
Raw wheat can be ground into flour or, using hard durum wheat only, can be ground into semolina; germinated and dried creating malt; crushed or cut into cracked wheat; parboiled (or steamed), dried, crushed and de-branned into bulgur also known as groats. If the raw wheat is broken into parts at the mill, as is usually done, the outer husk or bran can be used several ways. Wheat is a major ingredient in such foods as bread, porridge, crackers, biscuits, Muesli, pancakes, pies, pastries, cakes, cookies, muffins, rolls, doughnuts, gravy, boza (a fermented beverage), and breakfast cereals (e.g., Wheatena, Cream of Wheat, Shredded Wheat, and Wheaties).
Nutrition.
100 g of hard red winter wheat contain about 12.6 g of protein, 1.5 g of total fat, 71 g of carbohydrate (by difference), 12.2 g of dietary fiber, and 3.2 mg of iron (17% of the daily requirement); the same weight of hard red spring wheat contains about 15.4 g of protein, 1.9 g of total fat, 68 g of carbohydrate (by difference), 12.2 g of dietary fiber, and 3.6 mg of iron (20% of the daily requirement).
Much of the carbohydrate fraction of wheat is starch. Wheat starch is an important commercial product of wheat, but second in economic value to wheat gluten. The principal parts of wheat flour are gluten and starch. These can be separated in a kind of home experiment, by mixing flour and water to form a small ball of dough, and kneading it gently while rinsing it in a bowl of water. The starch falls out of the dough and sinks to the bottom of the bowl, leaving behind a ball of gluten.
In wheat, phenolic compounds are mainly found in the form of insoluble bound ferulic acid and are relevant to resistance to wheat fungal diseases. Alkylresorcinols are phenolic lipids present in high amounts in the bran layer (e.g. pericarp, testa and aleurone layers) of wheat and rye (0.1-0.3% of dry weight).
Worldwide consumption.
Wheat is grown on more than 218000000 ha, larger than for any other crop. World trade in wheat is greater than for all other crops combined. With rice, wheat is the world's most favored staple food. It is a major diet component because of the wheat plant’s agronomic adaptability with the ability to grow from near arctic regions to equator, from sea level to plains of Tibet, approximately 4000 m above sea level. In addition to agronomic adaptability, wheat offers ease of grain storage and ease of converting grain into flour for making edible, palatable, interesting and satisfying foods. Wheat is the most important source of carbohydrate in a majority of countries.
Wheat protein is easily digested by nearly 99% of the human population (all but those with gluten-related disorders), as is its starch. Wheat also contains a diversity of minerals, vitamins and fats (lipids). With a small amount of animal or legume protein added, a wheat-based meal is highly nutritious.
The most common forms of wheat are white and red wheat. However, other natural forms of wheat exist. For example, in the highlands of Ethiopia grows purple wheat, a tetraploid species of wheat that is rich in anti-oxidants. Other commercially minor but nutritionally promising species of naturally evolved wheat species include black, yellow and blue wheat.
Health concerns.
Several screening studies in Europe, South America, Australasia, and the USA suggest that approximately 0.5–1% of these populations may have undetected coeliac disease. Coeliac (also written as celiac) disease is a condition that is caused by an adverse immune system reaction to gliadin, a gluten protein found in wheat (and similar grains of the tribe Triticeae which includes other species such as barley and rye). Upon exposure to gliadin, the enzyme tissue transglutaminase modifies the protein, and the immune system cross-reacts with the bowel tissue, causing an inflammatory reaction. That leads to flattening of the lining of the small intestine, which interferes with the absorption of nutrients. The only effective treatment is a lifelong gluten-free diet.
The estimate for celiac disease among people in the United States is between 0.5 and 1.0 percent of the population.
While gluten sensitivity is caused by a reaction to wheat proteins, it is not the same as a wheat allergy.
Recently non-celiac gluten sensitivity has been identified as a further gluten sensitivity condition that differs from celiac disease and wheat allergy.
Comparison of wheat with other major staple foods.
The following table shows the nutrient content of wheat and other major staple foods in a raw form.
Raw forms of these staples, however, are not edible and cannot be digested. These must be sprouted, or prepared and cooked as appropriate for human consumption. In sprouted or cooked form, the relative nutritional and anti-nutritional contents of each of these grains is remarkably different from that of raw form of these grains reported in this table.
In cooked form, the nutrition value for each staple depends on the cooking method (for example: baking, boiling, steaming, frying, etc.).
Commercial use.
Harvested wheat grain that enters trade is classified according to grain properties for the purposes of the commodity markets. Wheat buyers use these to decide which wheat to buy, as each class has special uses, and producers use them to decide which classes of wheat will be most profitable to cultivate.
Wheat is widely cultivated as a cash crop because it produces a good yield per unit area, grows well in a temperate climate even with a moderately short growing season, and yields a versatile, high-quality flour that is widely used in baking. Most breads are made with wheat flour, including many breads named for the other grains they contain like most rye and oat breads. The popularity of foods made from wheat flour creates a large demand for the grain, even in economies with significant food surpluses.
In recent years, low international wheat prices have often encouraged farmers in the USA to change to more profitable crops. In 1998, the price at harvest was $2.68 per bushel. USDA report revealed that in 1998, average operating costs were $1.43 per bushel and total costs were $3.97 per bushel. In that study, farm wheat yields averaged 41.7 bushels per acre (2.2435 metric ton/hectare), and typical total wheat production value was $31,900 per farm, with total farm production value (including other crops) of $173,681 per farm, plus $17,402 in government payments. There were significant profitability differences between low- and high-cost farms, mainly due to crop yield differences, location, and farm size.
In 2007 there was a dramatic rise in the price of wheat due to freezes and flooding in the northern hemisphere and a drought in Australia. Wheat futures in September, 2007 for December and March delivery had risen above $9.00 a bushel, prices never seen before. There were complaints in Italy about the high price of pasta.
Production and consumption.
In 2011, global per capita wheat consumption was 65 kg, with the highest per capita consumption of 210 kg found in Azerbaijan. In 1997, global wheat consumption was 101 kg per capita, with the highest consumption 623 kg per capita in Denmark, but most of this (81%) was for animal feed. Wheat is the primary food staple in North Africa and the Middle East, and is growing in popularity in Asia. Unlike rice, wheat production is more widespread globally though China's share is almost one-sixth of the world.
"There is a little increase in yearly crop yield comparison to the year 1990. The reason for this is not in development of sowing area, but the slow and successive increasing of the average yield. Average 2.5 tons wheat was produced on one hectare crop land in the world in the first half of 1990s, however this value was about 3 tons in 2009. In the world per capita wheat producing area continuously decreased between 1990 and 2009 considering the change of world population. There was no significant change in wheat producing area in this period. However, due to the improvement of average yields there is some fluctuation in each year considering the per capita production, but there is no considerable decline. In 1990 per capita production was 111.98 kg/capita/year, while it was already 100.62 kg/capita/year in 2009. The decline is evident and the per capita production level of the year 1990 can not be feasible simultaneously with the growth of world population in spite of the increased average yields. In the whole period the lowest per capita production was in 2006."
In the 20th century, global wheat output expanded by about 5-fold, but until about 1955 most of this reflected increases in wheat crop area, with lesser (about 20%) increases in crop yields per unit area. After 1955 however, there was a dramatic ten-fold increase in the rate of wheat yield improvement per year, and this became the major factor allowing global wheat production to increase. Thus technological innovation and scientific crop management with synthetic nitrogen fertilizer, irrigation and wheat breeding were the main drivers of wheat output growth in the second half of the century. There were some significant decreases in wheat crop area, for instance in North America.
Better seed storage and germination ability (and hence a smaller requirement to retain harvested crop for next year's seed) is another 20th century technological innovation. In Medieval England, farmers saved one-quarter of their wheat harvest as seed for the next crop, leaving only three-quarters for food and feed consumption. By 1999, the global average seed use of wheat was about 6% of output.
Several factors are currently slowing the rate of global expansion of wheat production: population growth rates are falling while wheat yields continue to rise, and the better economic profitability of other crops such as soybeans and maize, linked with investment in modern genetic technologies, has promoted shifts to other crops.
Farming systems.
In the Punjab region of India and Pakistan, as well as North China, irrigation has been a major contributor to increased grain output. More widely over the last 40 years, a massive increase in fertilizer use together with the increased availability of semi-dwarf varieties in developing countries, has greatly increased yields per hectare. In developing countries, use of (mainly nitrogenous) fertilizer increased 25-fold in this period. However, farming systems rely on much more than fertilizer and breeding to improve productivity. A good illustration of this is Australian wheat growing in the southern winter cropping zone, where, despite low rainfall (300 mm), wheat cropping is successful even with relatively little use of nitrogenous fertilizer. This is achieved by 'rotation cropping' (traditionally called the ley system) with leguminous pastures and, in the last decade, including a canola crop in the rotations has boosted wheat yields by a further 25%. In these low rainfall areas, better use of available soil-water (and better control of soil erosion) is achieved by retaining the stubble after harvesting and by minimizing tillage.
In 2009, the most productive farms for wheat were in France producing 7.45 metric tonnes per hectare (although French production has low protein content and requires blending with higher protein wheat to meet the specifications required in some countries). The five largest producers of wheat in 2009 were China (115 million metric tonnes), India (81 MMT), Russian Federation (62 MMT), United States (60 MMT) and France (38 MMT). The wheat farm productivity in India and Russia were about 35% of the wheat farm productivity in France. China's farm productivity for wheat, in 2009, was about double that of Russia.
In addition to gaps in farming system technology and knowledge, some large wheat grain producing countries have significant losses after harvest at the farm and because of poor roads, inadequate storage technologies, inefficient supply chains and farmers' inability to bring the produce into retail markets dominated by small shopkeepers. Various studies in India, for example, have concluded that about 10% of total wheat production is lost at farm level, another 10% is lost because of poor storage and road networks, and additional amounts lost at the retail level. One study claims that if these post-harvest wheat grain losses could be eliminated with better infrastructure and retail network, in India alone enough food would be saved every year to feed 70 to 100 million people over a year.
Futures contracts.
Wheat futures are traded on the Chicago Board of Trade, Kansas City Board of Trade, and Minneapolis Grain Exchange, and have delivery dates in March (H), May (K), July (N), September (U), and December (Z).
Geographical variation.
There are substantial differences in wheat farming, trading, policy, sector growth, and wheat uses in different regions of the world. In the EU and Canada for instance, there is significant addition of wheat to animal feeds, but less so in the USA.
The biggest wheat producer in 2010 was EU-27, followed by China, India, USA and Russian Federation.
The largest exporters of wheat in 2009 were, in order of exported quantities: United States, EU-27, Canada, Russian Federation, Australia, Ukraine and Kazakhstan. Upon the results of 2011, Ukraine became the world's sixth wheat exporter as well. The largest importers of wheat in 2009 were, in order of imported quantities: Egypt, EU-27, Brazil, Indonesia, Algeria and Japan. EU-27 was on both export and import list, because EU countries such as Italy and Spain imported wheat, while other EU-27 countries exported their harvest. The Black Sea region – which includes Kazakhstan, the Russian Federation and Ukraine – is amongst the most promising area for grain exporters; it possess significant production potential in terms of both wheat yield and area increases. The Black Sea region is also located close to the traditional grain importers in the Middle East, North Africa and Central Asia.
In the rapidly developing countries of Asia, westernization of diets associated with increasing prosperity is leading to growth in "per capita" demand for wheat at the expense of the other food staples.
In the past, there has been significant governmental intervention in wheat markets, such as price supports in the USA and farm payments in the EU. In the EU these subsidies have encouraged heavy use of fertilizer inputs with resulting high crop yields. In Australia and Argentina direct government subsidies are much lower.
World's most productive wheat farms and farmers.
The average annual world farm yield for wheat was 3.3 tonnes per hectare (330 grams per square meter), in 2013.
New Zealander wheat farms were the most productive in 2013, with a nationwide average of 9.1 tonnes per hectare. Ireland was a close second.
Various regions of the world hold wheat production yield contests every year. Yields above 12 tonnes per hectare are routinely achieved in many parts of the world. Chris Dennison of Oamaru, New Zealand, set a world record for wheat yield in 2003 at 15.015 tonnes per hectare (223 bushels/acre). In 2010, this record was surpassed by another New Zealand farmer, Michael Solari, with 15.636 tonnes per hectare (232.64 bushels/acre) at Otama, Gore.
Agronomy.
Crop development.
Wheat normally needs between 110 and 130 days between sowing and harvest, depending upon climate, seed type, and soil conditions (winter wheat lies dormant during a winter freeze). Optimal crop management requires that the farmer have a detailed understanding of each stage of development in the growing plants. In particular, spring fertilizers, herbicides, fungicides, and growth regulators are typically applied only at specific stages of plant development. For example, it is currently recommended that the second application of nitrogen is best done when the ear (not visible at this stage) is about 1 cm in size (Z31 on Zadoks scale). Knowledge of stages is also important to identify periods of higher risk from the climate. For example, pollen formation from the mother cell, and the stages between anthesis and maturity are susceptible to high temperatures, and this adverse effect is made worse by water stress. Farmers also benefit from knowing when the 'flag leaf' (last leaf) appears, as this leaf represents about 75% of photosynthesis reactions during the grain filling period, and so should be preserved from disease or insect attacks to ensure a good yield.
Several systems exist to identify crop stages, with the Feekes and Zadoks scales being the most widely used. Each scale is a standard system which describes successive stages reached by the crop during the agricultural season.
Diseases.
There are many wheat diseases, mainly caused by fungi, bacteria, and viruses. Plant breeding to develop new disease-resistant varieties, and sound crop management practices are important for preventing disease. Fungicides, used to prevent the significant crop losses from fungal disease, can be a significant variable cost in wheat production. Estimates of the amount of wheat production lost owing to plant diseases vary between 10–25% in Missouri. A wide range of organisms infect wheat, of which the most important are viruses and fungi.
The main wheat-disease categories are:
Pests.
Wheat is used as a food plant by the larvae of some Lepidoptera (butterfly and moth) species including The Flame, Rustic Shoulder-knot, Setaceous Hebrew Character and Turnip Moth.
Early in the season, many species of birds, including the Long-tailed Widowbird, and rodents feed upon wheat crops. These animals can cause significant damage to a crop by digging up and eating newly planted seeds or young plants. They can also damage the crop late in the season by eating the grain from the mature spike. Recent post-harvest losses in cereals amount to billions of dollars per year in the USA alone, and damage to wheat by various borers, beetles and weevils is no exception. Rodents can also cause major losses during storage, and in major grain growing regions, field mice numbers can sometimes build up explosively to plague proportions because of the ready availability of food. To reduce the amount of wheat lost to post-harvest pests, Agricultural Research Service scientists have developed an "insect-o-graph," which can detect insects in wheat that are not visible to the naked eye. The device uses electrical signals to detect the insects as the wheat is being milled. The new technology is so precise that it can detect 5-10 infested seeds out of 300,000 good ones. Tracking insect infestations in stored grain is critical for food safety as well as for the marketing value of the crop.
References.
"This article incorporates material from the Citizendium article "", which is licensed under the but not under the ."
Further reading.
 <span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi/fmt%3Akev%3Amtx%3Abook&rft.genre=book&rft.btitle=%3Cspan%20lang%3D%22de%22%20%20%3EWinterweizen.%20Das%20Handbuch%20f%C3%BCr%20Profis%3C/span%3E&rft.date=2009&rft.pub=DLG-Verlags-GmbH&rft.isbn=978-3-7690-0719-0&rfr_id=info:sid/en.wikipedia.org:"> 

</doc>
<doc id="36859" url="http://en.wikipedia.org/wiki?curid=36859" title="Celtic">
Celtic

The words Celt and Celtic (also Keltic) can refer to:

</doc>
<doc id="36860" url="http://en.wikipedia.org/wiki?curid=36860" title="Zooarchaeology">
Zooarchaeology

Zooarchaeology is the study of faunal remains. Faunal remains are the items left behind when an animal dies. It includes: bones, shells, hair, chitin, scales, hides, proteins and DNA. Of these items, bones and shells are the ones that occur most frequently at archaeological sites where faunal remains can be found. Much of the time, most of the faunal remains do not survive. They often decompose or break because of various circumstances. This can cause difficulties in identifying the remains and interpreting their significance. 
Development.
The development of zooarchaeology in Eastern North America can be broken up into three different periods. The first being the Formative period starting around the 1860s, the second being the Systematization period beginning in the early 1950s, and the Integration period which began about 1969. 
Full-time zooarchaeologists didn’t come about until the Systematization period. Before that it was just a technique that was applied but not specifically studied.
Zooarchaeological specialists started to come about partly because of a new approach to archaeology known as “processual archaeology.” This approach puts more emphasis on explaining why things happened, not just what happened. Archaeologists began to specialize in zooarchaeology, and their numbers increased from there on.
Uses.
Zooarchaeology is primarily used to answer several questions. These include:
Zooarchaeology can also tell us what the environment might have been like in order for the different animals to have survived.
In addition to helping us understand the past, zooarchaeology can also help us to improve the present and the future. Studying how people dealt with animals, and its effects can help us avoid many potential ecological problems. This specifically includes problems involving wildlife management. For example, one of the questions that wildlife preservationists ask is whether they should keep animals facing extinction in several smaller areas, or in one larger area. Based on zooarchaeological evidence, they found that animals that are split up into several smaller areas are more likely to go extinct.
Techniques.
One of the techniques that zooarchaeologists use is close attention to taphonomy. This includes studying how items are buried and deposited at the site in question, what the conditions are that aid in the preservation of these items, and how these items get destroyed. Then they interpret that information. 
Another technique that zooarchaeologists use is lab analysis. This analysis can include comparing the skeletons found on site with already identified animal skeletons. This not only helps to identify what the animal is, but also whether the animal was domesticated or not.
Yet another technique that zooarchaeologists use is quantification. They make interpretations based on the number and size of the bones. These interpretations include how important different animals might have been to the diet. 
Zooarchaeology and related fields.
As can be seen from the discussion about the name that should be given to this discipline, zooarchaeology overlaps significantly with other areas of study. These include:
Wider areas of study.
Such analyses provide the basis by which further interpretations can be made. Topics that have been addressed by zooarchaeologists include:

</doc>
<doc id="36863" url="http://en.wikipedia.org/wiki?curid=36863" title="Lung">
Lung

The lung is the essential respiration organ in many air-breathing animals, including most tetrapods, a few fish and a few snails. In mammals and the more complex life forms, the two lungs are located near the backbone on either side of the heart. Their principal function is to transport oxygen from the atmosphere into the bloodstream, and to release carbon dioxide from the bloodstream into the atmosphere. A large surface area is needed for this exchange of gases which is accomplished by the mosaic of specialized cells that form millions of tiny, exceptionally thin-walled air sacs called alveoli.
To understand the anatomy of the lungs, the passage of air through the nose and mouth to the alveoli must be studied. The progression of air through either the mouth or the nose, travels through the nasopharynx and oropharynx of the pharynx, larynx, and the trachea (windpipe). The air passes down the trachea, which divides into two main bronchi; these branch to the left and right lungs where they progressively subdivide into a system of bronchi and bronchioles until the alveoli are reached. These many alveoli are where the gas exchange of carbon dioxide and oxygen takes place.
Breathing is driven by muscular action; in early tetrapods, air was driven into the lungs by the pharyngeal muscles via buccal pumping, which is still found in amphibians. Reptiles, birds and mammals use their musculoskeletal system to support and foster breathing.
Medical terms related to the lung often begin with "pulmo-", such as in the (adjectival form: pulmonary) or from the Latin "pulmonarius" ("of the lungs"), or with "pneumo-" (from Greek πνεύμων "lung").
Mammalian lungs.
The lungs of mammals including those of humans, have a soft, spongelike texture and are honeycombed with epithelium, having a much larger surface area in total than the outer surface area of the lung itself.
Breathing is largely driven by the muscular diaphragm at the bottom of the thorax. Contraction of the diaphragm pulls the bottom of the cavity in which the lung is enclosed downward, increasing volume and thus decreasing pressure, causing air to flow into the airways. Air enters through the oral and nasal cavities; it flows through the pharynx, then the larynx and into the trachea, which branches out into the main bronchi and then subsequent divisions. During normal breathing, expiration is passive and no muscles are contracted (the diaphragm relaxes). The rib cage itself is also able to expand and contract to some degree through the use of the intercostal muscles, together with the action of other respiratory and accessory respiratory muscles. As a result, air is transported into or expelled out of the lungs. This type of lung is known as a bellows lung as it resembles a blacksmith's bellows.
Anatomy.
In humans, the trachea divides into the two main bronchi that enter the roots of the lungs. The bronchi continue to divide within the lung, and after multiple divisions, give rise to bronchioles. The bronchial tree continues branching until it reaches the level of terminal bronchioles, which lead to alveolar sacs. Alveolar sacs, are made up of clusters of alveoli, like individual grapes within a bunch. The individual alveoli are tightly wrapped in blood vessels and it is here that gas exchange actually occurs. Deoxygenated blood from the heart is pumped through the pulmonary artery to the lungs, where oxygen diffuses into blood and is exchanged for carbon dioxide in the haemoglobin of the erythrocytes. The oxygen-rich blood returns to the heart via the pulmonary veins to be pumped back into systemic circulation. 
Human lungs are located in two cavities on either side of the heart. Though similar in appearance, the two are not identical. Both are separated into lobes by fissures, with three lobes on the right and two on the left. The lobes are further divided into segments and then into lobules, hexagonal divisions of the lungs that are the smallest subdivision visible to the naked eye. The connective tissue that divides lobules is often blackened in smokers. The medial border of the right lung is nearly vertical, while the left lung contains a cardiac notch. The cardiac notch is a concave impression molded to accommodate the shape of the heart.
Each lobe is surrounded by a pleural cavity, which consists of two pleurae. The parietal pleura lies against the rib cage, and the visceral pleura lies on the surface of the lungs. In between the pleura is pleural fluid. The pleural cavity helps to lubricate the lungs, as well as providing surface tension to keep the lung surface in contact with the rib cage.
Lungs are to a certain extent "overbuilt" and have a tremendous reserve volume as compared to the oxygen exchange requirements when at rest. Such excess capacity is one of the reasons that individuals can smoke for years without having a noticeable decrease in lung function while still or moving slowly; in situations like these only a small portion of the lungs are actually perfused with blood for gas exchange. Destruction of too many alveoli over time leads to the condition emphysema, which is associated with extreme shortness of breath. As oxygen requirements increase due to exercise, a greater volume of the lungs is perfused, allowing the body to match its CO2/O2 exchange requirements. Additionally, due to the excess capacity, it is possible for humans to live with only one lung, with the one compensating for the other's loss.
The environment of the lung is very moist, which makes it hospitable for bacteria. Many respiratory illnesses are the result of bacterial or viral infection of the lungs. Inflammation of the lungs is known as pneumonia; inflammation of the pleura surrounding the lungs is known as pleurisy.
Vital capacity is the maximum volume of air that a person can exhale after maximum inhalation; it can be measured with a spirometer. In combination with other physiological measurements, the vital capacity can help make a diagnosis of underlying lung disease.
The "lung parenchyma" is strictly used to refer solely to alveolar tissue with respiratory bronchioles, alveolar ducts and terminal bronchioles. However, it often includes any form of lung tissue, also including bronchioles, bronchi, blood vessels and lung interstitium.
Non respiratory functions.
In addition to their function in respiration, the lungs also:
Avian lungs.
Avian lungs do not have alveoli as mammalian lungs do; birds have honey-comb-like, faveolar lungs, which contain millions of tiny passages called parabronchi. There are air vesicles, called atria, which project radially from the walls of the parabronchi. The gas exchange tissues are set into the walls of the atria and gases travel via diffusion between the gas exchange tissues and the lumen of each parabronchus. There are two categories of parabronchi. The paleopulmonic parabronchi are found in all birds and air flows through them in the same direction—posterior to anterior during inhalation and exhalation. Some bird species also have neopulmonic parabronchi where the air flow is bidirectional. The paleopulmonic unidirectional airflow is in contrast to the mammalian system, in which the direction of airflow in the lung is tidal, reversing between inhalation and exhalation.
By utilizing a unidirectional flow of air, avian lungs are able to extract a greater concentration of oxygen from inhaled air. Birds are thus equipped to fly at altitudes at which mammals would succumb to hypoxia. This also allows them to sustain a higher metabolic rate than most equivalent weight mammals. Note that some species of small bats have a higher mean total morphometric pulmonary diffusing capacity for oxygen than equivalent weight birds but this is the exception and is not the rule.
The lungs of birds are relatively small, but are connected to 8–9 air sacs that extend through much of the body, and are in turn connected to air spaces within the bones. The air sacs, although thin walled, are poorly vascularized, and do not contribute much to gas exchange, but they do act like bellows to ventilate the lungs. The air sacs expand and contract due to changes in the volume of the combined thorax and abdominal cavity. This volume change is caused by the movement of the sternum and ribs and this movement is often synchronized with movement of the flight muscles.
Because of the complexity of the system, misunderstanding is common and it is incorrectly believed that it takes two breathing cycles for air to pass entirely through a bird's respiratory system. Air is not stored in either the posterior or anterior sacs between respiration cycles, air moves continuously from the posterior to the anterior of the lungs throughout respiration. This type of lung construction is called a circulatory lung, as distinct from the bellows lung possessed by other animals.
Reptilian lungs.
Reptilian lungs are typically ventilated by a combination of expansion and contraction of the ribs via axial muscles and buccal pumping. Crocodilians also rely on the hepatic piston method, in which the liver is pulled back by a muscle anchored to the pubic bone (part of the pelvis), which in turn pulls the bottom of the lungs backward, expanding them. Turtles, which are unable to move their ribs, instead use their forelimbs and pectoral girdle to force air in and out of the lungs.
The lung of most reptiles has a single bronchus running down the centre, from which numerous branches reach out to individual pockets throughout the lungs. These pockets are similar to, but much larger and fewer in number than, mammalian alveoli, and give the lung a sponge-like texture. In tuataras, snakes, and some lizards, the lungs are simpler in structure, similar to that of typical amphibians.
Snakes and limbless lizards typically possess only the right lung as a major respiratory organ; the left lung is greatly reduced, or even absent. Amphisbaenians, however, have the opposite arrangement, with a major left lung, and a reduced or absent right lung.
Both crocodilians and monitor lizards have developed lungs similar to those of birds, providing an unidirectional airflow and even possessing air sacs. The now extinct pterosaurs have seemingly even further refined this type of lung, extending the airsacs into the wing membranes and, in the case of Pteranodontia, the hindlimbs.
Amphibian lungs.
The lungs of most frogs and other amphibians are simple balloon-like structures, with gas exchange limited to the outer surface area of the lung. This is not a very efficient arrangement, but amphibians have low metabolic demands and can also quickly dispose of carbon dioxide by diffusion across their skin in water, and supplement their oxygen supply by the same method. Unlike higher vertebrates, who use a breathing system driven by negative pressure where the lungs are inflated by expanding the rib cage, amphibians employ positive pressure system, forcing air down into the lungs by buccal pumping. The floor of the mouth is lowered, filling the mouth cavity with air. The throat muscles then presses the throat against the underside of the skull, forcing the air into the lungs.
Due to the possibility of respiration across the skin combined with small size, all known lungless tetrapods are amphibians. The majority of salamander species are lungless salamanders, which respirate through their skin and tissues lining their mouth. This necessarily restrict their size, all are small and rather thread-like in appearance, maximizing skin surface relative to body volume. The only other known lungless tetrapods are the Bornean Flat-headed Frog ("Barbourula kalimantanensis") and "Atretochoana eiselti", a caecilian.
The lungs of amphibians typically have a few narrow septa of soft tissue around the outer walls, increasing the respiratory surface area and giving the lung a honey-comb appearance. In some salamanders even these are lacking, and the lung has a smooth wall. In caecilians, as in snakes, only the right lung attains any size or development.
Lungfish.
The lungs of lungfish are similar to those of amphibians, with few, if any, internal septa. In the Australian lungfish, there is only a single lung, albeit divided into two lobes. Other lungfish and "Polypterus", however, have two lungs, which are located in the upper part of the body, with the connecting duct curving round and above the esophagus. The blood supply also twists around the esophagus, suggesting that the lungs originally evolved in the ventral part of the body, as in other vertebrates.
Invertebrate lungs.
Some invertebrates have "lungs" that serve a similar respiratory purpose as, but are not evolutionarily related to, vertebrate lungs. Some arachnids have structures called "book lungs" used for atmospheric gas exchange. The Coconut crab uses structures called Branchiostegal lungs to breathe air and indeed will drown in water, hence it breathes on land and holds its breath underwater. The Pulmonata are an order of snails and slugs that have developed "lungs".
Origins of the vertebrate lung.
The lungs of today's terrestrial vertebrates and the gas bladders of today's fish are believed to have evolved from simple sacs (outpocketings) of the esophagus that allowed early fish to gulp air under oxygen-poor conditions. These outpocketings first arose in the bony fish. In most of the ray-finned fish the sacs evolved into closed off gas bladders, while a number of carps, trouts, herrings, catfish, eels has retained the physostome condition with the sack being open to the esophagus. In more basal bony fish, such as the gar, bichir, bowfin and the lobe-finned fish, the bladders have evolved to primarily function as lungs. The lobe-finned fish gave rise to the land-based tetrapods. Thus, the lungs of vertebrates are homologous to the gas bladders of fish (but not to their gills). This is reflected by the fact that the lungs of a fetus also develop from an outpocketing of the esophagus and in the case of the physostome gas bladders, which can serve as both buoyancy organ and with the pneumatic duct to the gut also serve as lungs. This condition is found in more "primitive" teleosts, and is lost in the higher orders. (This is an instance of correlation between ontogeny and phylogeny.) No known animals have both a gas bladder and lungs.
Further reading.
</dl>

</doc>
<doc id="36865" url="http://en.wikipedia.org/wiki?curid=36865" title="Hepburn romanization">
Hepburn romanization

The Hepburn romanization system (ヘボン式ローマ字, Hebon-shiki Rōmaji) is named after James Curtis Hepburn, who used it to transcribe the sounds of the Japanese language into the Latin alphabet in the third edition of his Japanese–English dictionary, published in 1887. The system was originally proposed by the Romanization Club (羅馬字会, Rōmajikai) in 1885. The revised edition by Romaji-Hirome-kai in 1908 is called "standard style romanization" (標準式ローマ字, Hyōjun-shiki Rōmaji) and this system has been used as the Hepburn system in Japan traditionally.
Although not officially approved, the original and revised variants of Hepburn remain the most widely used methods of transcription of Japanese, and are regarded as the best to render Japanese pronunciation for Western speakers. As Hepburn is based on English and Italian phonology, an English or Latin-language speaker unfamiliar with Japanese will generally pronounce a word romanized in Hepburn more accurately than a word romanized in the competing Kunrei-shiki, the official Cabinet-ordered romanization system.
Legal status.
Hepburn is based on English phonology and has competed with the alternative Nihon-shiki romanization, which was developed in Japan as a replacement of Japanese script. In 1930, a Special Romanization Study Commission was appointed to compare the two. The Commission eventually decided in favor of a slightly modified version of Nihon-shiki, which was proclaimed to be Japan's official romanization for all purposes by a September 21, 1937 cabinet ordinance and is now known as Kunrei-shiki. The ordinance was temporarily overturned by the Supreme Commander Allied Powers (SCAP) during the Occupation of Japan, but was reissued (with slight revisions) in 1954.
In 1972, a revised version of Hepburn was codified as ANSI standard Z39.11-1972. It was proposed in 1989 as a draft for ISO 3602, but rejected in favor of Kunrei-shiki. The ANSI Z39.11-1972 standard was consequently deprecated on October 6, 1994.
As of 1978, the Ministry of Foreign Affairs, the Ministry of International Trade and Industry, and many other official organizations used Hepburn instead of Kunrei-shiki. In addition "The Japan Times", the Japan Travel Bureau, and many other private organizations used Hepburn instead of Kunrei-shiki. The National Diet Library used Kunrei-shiki.
Although Hepburn is not a government standard, some government agencies mandate it. For example, the Ministry of Foreign Affairs requires the use of Hepburn on passports, and the Ministry of Land, Infrastructure and Transport requires the use of Hepburn on transport signs, including road signs and railway station signs.
In many other areas where it lacks "de jure" status, Hepburn remains the "de facto" standard. Signs and notices in city offices and police stations, at shrines, temples and attractions also use it. English-language newspapers and media use the simplified form of Hepburn. Cities and prefectures use it in information for English-speaking residents and visitors, and English-language publications by the Japanese Foreign Ministry use simplified Hepburn too. Official tourism information put out by the government uses it, as do guidebooks, local and foreign, on Japan.
Many students of Japanese as a foreign language learn Hepburn.
Variants of Hepburn romanization.
There are many variants of Hepburn romanization. The two most common styles are:
In Japan itself, there are some variants officially mandated for various uses:
Details of these variants can be found below.
Obsolete variants.
The romanizations set out in the first and second versions of Hepburn's dictionary are primarily of historical interest. Notable differences from the third and later versions include:
First version.
The following differences are in addition to those in the second version:
Features of Hepburn romanization.
The main feature of Hepburn is that its spelling is based on English phonology. More technically, where syllables constructed systematically according to the Japanese syllabary contain the "unstable" consonant for the modern spoken language, the orthography is changed to something that, as an English speaker would pronounce it, better matches the real sound, for example し is written "shi" not * "si".
Some linguists such as H.E.Palmer, Daniel Jones and Otto Jespersen object to Hepburn, as the pronunciation-based spellings can obscure the systematic origins of Japanese phonetic structures, inflections, and conjugations. Supporters argue that Hepburn is not intended as a linguistic tool.
Long vowels.
The long vowels are generally indicated by macrons ( ¯ ). Since this diacritical sign is usually missing on typewriter and computer keyboards, the circumflex ( ˆ ) is often used in its place.
The combinations of vowels are written as follows in traditional/modified Hepburn:
A + A.
In traditional and modified:
In traditional Hepburn: 
In modified Hepburn:
I + I.
In traditional and modified:
U + U.
In traditional and modified:
E + E.
In traditional and modified:
In traditional Hepburn:
In modified Hepburn:
O + O.
In traditional and modified:
O + U.
In traditional and modified:
E + I.
In traditional and modified:
Other combination of vowels.
All remaining combinations of two different vowels are written separately:
Loanwords.
The long vowels within loanwords are indicated by macrons (ā, ī, ū, ē, ō) as follows:
Variations.
There are many variations of the Hepburn system for indicating the long vowels. For example, 東京（とうきょう） can be written as:
Particles.
In traditional and modified:
In traditional Hepburn:
In modified Hepburn:
Syllabic "n".
In traditional Hepburn:
In modified Hepburn:
Double consonants.
Double (or "geminate") consonant sounds are marked by doubling the consonant following the sokuon, っ; for consonants that are digraphs in Hepburn ("sh", "ch", "ts"), double only the first consonant of the set, except for "ch" → "tch".
Hepburn romanization charts.
For extended katakana.
These combinations are used mainly to represent the sounds in words in other languages.
Digraphs with orange backgrounds are the general ones used for loanwords or foreign places or names, and the ones with blue backgrounds are used for more accurate transliterations of foreign sounds, both suggested by the Cabinet of Japan's Ministry of Education, Culture, Sports, Science and Technology. Katakana combinations with beige backgrounds are suggested by the American National Standards Institute and the British Standards Institution as possible uses. Ones with purple backgrounds appear on the 1974 version of the Hyōjun-shiki formatting.

</doc>
<doc id="36867" url="http://en.wikipedia.org/wiki?curid=36867" title="Soldier of Fortune (video game)">
Soldier of Fortune (video game)

Soldier of Fortune (also known as SoF) is a first-person shooter video game created by Raven Software and published by Activision on February 29, 2000 for Microsoft Windows. It was later released for the PlayStation 2 as well as the Dreamcast, while Loki Software also made a port for Linux. Two sequels were later made to the game as well.
Plot.
The story involves the theft of nuclear weapons, and the main enemy turns out to be a neo-fascist group based in Germany, led by South African exile Sergei Dekker. At the beginning of the game, terrorists steal four nuclear weapons from a storage facility in Russia, and proceed to sell them to various nations. This is a prelude to the acquisition of advanced weapons of mass destruction by this terrorist group. John Mullins, working for a U.S.-based mercenary ("soldier of fortune") organization known only as "The Shop", and his partner, Aaron "Hawk" Parsons, are assigned to prevent the nukes from falling into the wrong hands, and stop the terrorists in their plans. His missions take him to New York City, Siberia, Tokyo, Kosovo, Iraq, Uganda and finally Germany.
Gameplay.
"Soldier of Fortune" was best known for its graphic depictions of firearms dismembering the human body. This graphic violence is the game's main stylistic attraction, much like the destructible environments of "Red Faction" or bullet time of "Max Payne". The GHOUL engine enables depiction of extreme graphic violence, in which character models are based on body parts that can each independently sustain damage (gore zones). There are 26 zones in total: a shot to the head with a powerful gun will often make the target's head explode, leaving nothing but the bloody stump of the neck remaining; a close-range shot to the stomach with a shotgun will leave an enemy's bowels in a bloody mess, and a shot to the nether regions will cause the victims to clutch their groin in agony for a few seconds before kneeling over dead. It is possible to shoot off an enemy's limbs (head, arms, legs) leaving nothing left but a bloody torso. In the last mission there is also a fictional microwave weapon, causing the enemies to fry or explode, depending on the firing mode. However, nonviolence is a possibility, if the player is a good shot it is possible to shoot an enemy's weapon out of their hand, causing them to cower on the floor to surrender. The game also came with password-protected options to disable all gore and there is even a version of the game with the extreme violence permanently locked-out, titled Soldier of Fortune: Tactical Low-Violence Version. 
Multiplayer.
In multiplayer mode, there are seven gametypes: Arsenal, Assassination, Capture the Flag, Conquer the Bunker, Control, Deathmatch and Realistic Deathmatch.
Development.
"Soldier of Fortune" was built around a modified version of the "Quake II" game engine. It was the first game to utilize the GHOUL damage model engine developed by Raven Software. This introduced the ability to dismember enemies in combat, adding to the realism of the game. Upgraded versions of the GHOUL system was later used in other Raven titles such as ' and '.
The game was originally supposed to be much more realistic, featuring mostly real weapons, and the players taking damage would impede their movement and dexterity, depending on where and how many times they were hit. In 1998 (prior to the Kosovo War) the game was also supposed to be partially based in Bosnia instead of Kosovo.
The game is AMD Eyefinity validated.
Reception.
"Soldier of Fortune" was praised as being a solid and entertaining shooter, with one of the game's greatest praises being its graphic depiction of gore and violence, which both proponents and detractors consider to be more realistic than most first-person shooter games.
Critical reaction was positive, with the GameRankings averaged rating of 82.30% for the PC version. However, the Dreamcast version's reception was less enthusiastic, with the 71.06% average rating (reviewers criticized the loading times, which were both frequent and extremely lengthy).
Violence controversy.
In 2000, after receiving a complaint from a member of the public about the explicit content of the game, the British Columbia Film Classification Office investigated and decided the violence, gore and acts of torture were not suitable for persons under 18 years of age. In a controversial decision, the game was labeled an "adult motion picture" and was rated as a pornographic film. In Germany, the game was placed on the Federal Department for Media Harmful to Young Persons.
Legacy.
Signs of "Soldier of Fortune"'s success are still evident today with still many thousands of active players. 
"Soldier of Fortune" was originally, and only released as physical media. The game is not digitally distributed on the PC, nor on any other platform.
Sequels.
Based on its success, Raven Software and Activision later published "" in 2002, based on the "Quake III: Team Arena" engine. Initially released for Windows, the sequel was later ported to the Xbox.
A third game in the series, "" was made by Cauldron HQ and released on November 14, 2007.
A MMOFPS based on the series, "Soldier of Fortune Online" was published in Korea by Dragonfly and went in Closed Beta on August 12, 2010 and ended on August 16, 2010.

</doc>
<doc id="36868" url="http://en.wikipedia.org/wiki?curid=36868" title="CIS">
CIS

CIS may refer to:

</doc>
<doc id="36869" url="http://en.wikipedia.org/wiki?curid=36869" title="Cell division">
Cell division

Cell division is the process by which a "parent cell" divides into two or more "daughter cells". Cell division usually occurs as part of a larger cell cycle. In eukaryotes, there are two distinct types of cell division: a vegetative division, whereby each daughter cell is genetically identical to the parent cell (mitosis), and a reductive cell division, whereby the number of chromosomes in the daughter cells is reduced by half, to produce haploid gametes (meiosis). Meiosis results in four haploid daughter cells by undergoing one round of DNA replication followed by two divisions: homologous chromosomes are separated in the first division, and sister chromatids are separated in the second division. Both of these cell division cycles are in sexually reproducing organisms at some point in their life cycle, and both are believed to be present in the last eukaryotic common ancestor Prokaryotes also undergo a vegetative cell division known as binary fission, where their genetic material is segregated equally into two daughter cells. All cell divisions, regardless of organism, are preceded by a single round of DNA replication.
For simple unicellular organisms such as the amoeba, one cell division is equivalent to reproduction – an entire new organism is created. On a larger scale, mitotic cell division can create progeny from multicellular organisms, such as plants that grow from cuttings. Cell division also enables sexually reproducing organisms to develop from the one-celled zygote, which itself was produced by cell division from gametes. And after growth, cell division allows for continual construction and repair of the organism. A human being's body experiences about 10,000 trillion cell divisions in a lifetime.
Cell division has been modeled by finite subdivision rules.
The primary concern of cell division is the maintenance of the original cell's genome. Before division can occur, the genomic information that is stored in chromosomes must be replicated, and the duplicated genome must be separated cleanly between cells. A great deal of cellular infrastructure is involved in keeping genomic information consistent between "generations".
Daughter cells of cell divisions, in early embryonic development, contribute unequally to the generation of adult tissues.
Variants.
Cells are classified into two main categories: simple, non-nucleated prokaryotic cells, and complex, nucleated eukaryotic cells. By dint of their structural differences, eukaryotic and prokaryotic cells do not divide in the same way. Also, the pattern of cell division that transforms eukaryotic stem cells into gametes (sperm cells in males or ova – egg cells – in females) is different from that of the somatic cell division in the cells of the body.
Degradation.
Multicellular organisms replace worn-out cells through cell division. In some animals, however, cell division eventually halts. In humans this occurs on average, after 52 divisions, known as the Hayflick limit. The cell is then referred to as senescent. Cells stop dividing because the telomeres, protective bits of DNA on the end of a chromosome required for replication, shorten with each copy, eventually being consumed, as described in the article on telomere shortening. Cancer cells, on the other hand, are not thought to degrade in this way, if at all. An enzyme called telomerase, present in large quantities in cancerous cells, rebuilds the telomeres, allowing division to continue indefinitely.

</doc>
<doc id="36870" url="http://en.wikipedia.org/wiki?curid=36870" title="Commonwealth of Independent States">
Commonwealth of Independent States

The Commonwealth of Independent States (CIS; Russian: Содружество Независимых Государств, СНГ, "Sodruzhestvo Nezavisimykh Gosudarstv, SNG"; also called the Russian Commonwealth)[#endnote_] is a regional organisation whose participating countries are former Soviet Republics, formed during the breakup of the Soviet Union.
The CIS is a loose association of states. Although the CIS has few supranational powers, it is aimed at being more than a purely symbolic organisation, nominally possessing coordinating powers in the realm of trade, finance, lawmaking, and security. It has also promoted cooperation on cross-border crime prevention. However, eight of the nine CIS members states form the CIS Free Trade Area, and five of these form the Eurasian Economic Union, a customs union and common market of over 180 million people. In addition, six member states participate in a mutual defence alliance: the Collective Security Treaty Organization.
History.
The organization was founded on 8 December 1991 by the Republic of Belarus, the Russian Federation, and Ukraine, when the leaders of the three countries met in the Belovezhskaya Pushcha Natural Reserve, about 50 km north of Brest in Belarus and signed the "Agreement Establishing the Commonwealth of Independent States", known as the "Creation Agreement" (Russian: Соглашение, "Soglasheniye"), on the dissolution of the Soviet Union and the creation of CIS as a successor entity to it. At the same time they announced that the new alliance would be open to all republics of the former Soviet Union, and to other nations sharing the same goals. The CIS charter stated that all the members were sovereign and independent nations and thereby effectively abolished the Soviet Union.
On 21 December 1991, the leaders of eight additional former Soviet Republics – Armenia, Azerbaijan, Kazakhstan, Kyrgyzstan, Moldova, Turkmenistan, Tajikistan, and Uzbekistan – signed the Alma-Ata Protocol expanding the CIS to these states, thus bringing the number of participating countries to 11. Georgia joined two years later, in December 1993. At this point, 12 former Soviet Republics (all except the Baltic States) participated in the CIS.
Between 2003 and 2005, three CIS member states experienced a change of government in a series of colour revolutions: Eduard Shevardnadze was overthrown in Georgia; Viktor Yushchenko was elected in Ukraine; and Askar Akayev was toppled in Kyrgyzstan. In February 2006, Georgia withdrew from the Council of Defense Ministers, with the statement that "Georgia has taken a course to join NATO and it cannot be part of two military structures simultaneously", but it remained a full member of the CIS until August 2009, one year after officially withdrawing in the immediate aftermath of the 2008 South Ossetia war. In March 2007, Igor Ivanov, the secretary of the Russian Security Council, expressed his doubts concerning the usefulness of the CIS, emphasising that the Eurasian Economic Community was becoming a more competent organisation to unify the largest countries of the CIS. Following the withdrawal of Georgia, the presidents of Uzbekistan, Tajikistan, and Turkmenistan skipped the October 2009 meeting of the CIS, each having their own issues and disagreements with the Russian Federation.
In May 2009, Armenia, Azerbaijan, Belarus, Georgia, Moldova, and Ukraine joined the Eastern Partnership, a project which was initiated by the European Union (EU).
Membership.
There are nine full member states of the Commonwealth of Independent States.
The Creation Agreement remained the main constituent document of the CIS until January 1993, when the "CIS Charter" (Russian: Устав, "Ustav") was adopted. The charter formalised the concept of membership: a member country is defined as a country that ratifies the CIS Charter (sec. 2, art. 7).
Turkmenistan has not ratified the charter and changed its CIS standing to associate member as of 26 August 2005 in order to be consistent with its UN-recognised international neutrality status.
Although Ukraine was one of the founding countries and ratified the Creation Agreement in December 1991, Ukraine chose not to ratify the CIS Charter as it disagrees with Russia being the only legal successor to the Soviet Union. Thus it does not regard itself as a member of the CIS. In 1993 Ukraine became an "Associate Member" of CIS. On March 14, 2014, a bill was introduced to Ukraine's parliament to denounce their ratification of the 1991 Agreement Establishing the CIS, following the Russian military intervention in Ukraine and annexation of Crimea, but was never approved. Following a parliamentary election, a new bill to denounce the CIS agreement was introduced.
In light of Russia’s occupation of parts of Moldova, Georgia, and Ukraine, as well as its violation of the Istanbul Agreement (see Adapted Conventional Armed Forces in Europe Treaty), legislative initiatives to denounce the agreement on the creation of CIS were tabled in Moldova's parliament on 25 March 2014, though they were not approved.
Human rights.
Since its inception, one of the primary goals of the CIS has been to provide a forum for discussing issues related to the social and economic development of the newly independent states. To achieve this goal member states have agreed to promote and protect human rights. Initially efforts to achieve this goal consisted merely of statements of good will, but on 26 May 1995, the CIS adopted a Commonwealth of Independent States Convention on Human Rights and Fundamental Freedoms.
Even before the 1995 human rights treaty, the Charter of the CIS that was adopted in 1991 created, in article 33, a Human Rights Commission sitting in Minsk, Belarus. This was confirmed by decision of the Council of Heads of States of the CIS in 1993. In 1995, the CIS adopted a human rights treaty that includes civil and political as well as social and economic human rights. This treaty entered into force in 1998. The CIS treaty is modeled on the European Convention on Human Rights, but lacking the strong implementation mechanisms of the latter. In the CIS treaty, the Human Rights Commission has very vaguely defined authority. The Statute of the Human Rights Commission, however, also adopted by the CIS Member States as a decision, gives the Commission the right to receive inter-state as well as individual communications.
CIS members, especially in Central Asia, continue to have among the world's poorest human rights records. Many activists point to the 2005 Andijan massacre in Uzbekistan, or the cult of personality around President Gurbanguly Berdimuhamedow of Turkmenistan (though not a CIS member), to show that there has been almost no improvement in human rights since the collapse of the Soviet Union in Central Asia. The consolidation of power by President Vladimir Putin has resulted in a steady decline in the modest progress of previous years in Russia. The Commonwealth of Independent States continues to face serious challenges in meeting even basic international standards.
Military structures.
The CIS Charter establishes the Council of Ministers of Defense, which is vested with the task of coordinating military cooperation of the CIS member states. To this end, the Council develops conceptual approaches to the questions of military and defense policy of the CIS member states; develops proposals aimed to prevent armed conflicts on the territory of the member states or with their participation; gives expert opinions on draft treaties and agreements related to the questions of defense and military developments; issues related suggestions and proposals to the attention of the CIS Council of the Heads of State. Also important is the Council's work on approximation of the legal acts in the area of defense and military development.
An important manifestation of integration processes in the area of military and defense collaboration of the CIS member states is the creation, in 1995, of the joint CIS Air Defense System. Over the years, the military personnel of the joint CIS Air Defense System grew twofold along the western, European border of the CIS, and by 1.5 times, on its southern borders.
When Boris Yeltsin became Russian Defence Minister on 7 May 1992, Yevgeny Shaposhnikov, the man appointed as Commander-in-Chief of the CIS Armed Forces, and his staff, were ejected from the MOD and General Staff buildings and given offices in the former Warsaw Pact Headquarters at 41 Leningradsky Prospekt on the northern outskirts of Moscow. Shaposhnikov resigned in June 1993.
In December 1993, the CIS Armed Forces Headquarters was abolished. Instead, 'the CIS Council of Defence Ministers created a CIS Military Cooperation Coordination Headquarters (MCCH) in Moscow, with 50 per cent of the funding provided by Russia.' General Viktor Samsonov was appointed as Chief of Staff. The headquarters has now moved to 101000, Москва, Сверчков переулок, 3/2, and 41 Leningradsky Prospekt has now been taken over by another Russian MOD agency.
The chiefs of the CIS general staffs have spoken in favor of integrating their national armed forces.
Associated organisations.
Free trade area (CISFTA).
1994.
In 1994, the CIS countries "agreed" to create a free trade area (FTA), but the agreements were never signed. The 1994 agreement would have covered all twelve then CIS members except Turkmenistan.
2011.
In 2009 a new agreement was begun to create a FTA, the CISFTA. In October 2011, the new free trade agreement was signed by eight of the eleven CIS prime ministers; Armenia, Belarus, Kazakhstan, Kyrgyzstan, Moldova, Russia, Tajikistan, and Ukraine at a meeting in St. Petersburg. As of 2013, it has been ratified by Ukraine, Russia, Belarus, Moldova, and Armenia, and is in force only between those states.
The free trade agreement eliminates export and import duties on a number of goods but also contains a number of exemptions that will ultimately be phased out. An agreement was also signed on the basic principles of currency regulation and currency controls in the CIS at the same October 2011 meeting.
Corruption and bureaucracy are serious problems for trade in CIS countries.
Eurasian Economic Community.
The Eurasian Economic Community (EurAsEC or EAEC) originated from a customs union between Belarus, Russia and Kazakhstan on 29 March 1996. It was named the EAEC on 10 October 2000 when Belarus, Kazakhstan, Kyrgyzstan, Russia, and Tajikistan signed the treaty. EurAsEC was formally created when the treaty was finally ratified by all five member states in May 2001. Armenia, Moldova and Ukraine hold observer status. EurAsEC is working on establishing a common energy market and exploring the more efficient use of water in central Asia.
Organisation of Central Asian Cooperation.
Kazakhstan, Kyrgyzstan, Tajikistan, Turkmenistan and Uzbekistan formed the OCAC in 1991 as Central Asian Commonwealth (CAC). The organisation continued in 1994 as the Central Asian Economic Union (CAEU), in which Tajikistan and Turkmenistan did not participate. In 1998 it became the Central Asian Economic Cooperation (CAEC), which marked the return of Tajikistan. On 28 February 2002 it was renamed to its current name. Russia joined on 28 May 2004. On 7 October 2005 it was decided between the member states that Uzbekistan will join the Eurasian Economic Community and that the organisations will merge. The organisations joined on 25 January 2006. It is not clear what will happen to the status of current CACO observers that are not observers to EurAsEC (Georgia and Turkey).
Common Economic Space.
After discussion about the creation of a common economic space between the Commonwealth of Independent States (CIS) countries of Russia, Ukraine, Belarus, and Kazakhstan, agreement in principle about the creation of this space was announced after a meeting in the Moscow suburb of Novo-Ogarevo on 23 February 2003. The Common Economic Space would involve a supranational commission on trade and tariffs that would be based in Kiev, would initially be headed by a representative of Kazakhstan, and would not be subordinate to the governments of the four nations. The ultimate goal would be a regional organisation that would be open for other countries to join as well, and could eventually lead even to a single currency.
On 22 May 2003, the "Verkhovna Rada" (the Ukrainian Parliament) voted 266 votes in favour and 51 against the joint economic space. However, most believe that Viktor Yushchenko's victory in the Ukrainian presidential election of 2004 was a significant blow against the project: Yushchenko has shown renewed interest in Ukrainian membership in the European Union and such membership would be incompatible with the envisioned common economic space. Yushchenko's successor Viktor Yanukovych stated on 27 April 2010 "Ukraine's entry into the Customs Union of Russia, Belarus and Kazakhstan is not possible today, since the economic principles and the laws of the WTO do not allow it, we develop our policy in accordance with WTO principles". Ukraine is a WTO member.
A Customs Union of Belarus, Kazakhstan and Russia was thus created in 2010, with a single market envisioned for 2012.
Collective Security Treaty Organization.
The Collective Security Treaty Organisation (CSTO) (Russian: Организация Договора о Коллективной Безопасности) or simply the Tashkent Treaty (Russian: Ташкентский договор) first began as the CIS Collective Security Treaty which was signed on 15 May 1992, by Armenia, Kazakhstan, Kyrgyzstan, Russian Federation, Tajikistan and Uzbekistan, in the city of Tashkent. Azerbaijan signed the treaty on 24 September 1993, Georgia on 9 December 1993 and Belarus on 31 December 1993. The treaty came into effect on 20 April 1994.
The CST was set to last for a 5-year period unless extended. On 2 April 1999, only six members of the CSTO signed a protocol renewing the treaty for another five-year period, while Azerbaijan, Georgia and Uzbekistan refused to sign, and withdrew from the treaty instead; together with Moldova and Ukraine, formed a non-aligned, more pro-Western pro-US group known as the "GUAM" (Georgia, Uzbekistan / Ukraine, Azerbaijan, Moldova). The organisation was named CSTO on 7 October 2002 in Tashkent. Nikolai Bordyuzha was appointed secretary general of the new organisation. During 2005, the CSTO partners conducted some common military exercises. In 2005, Uzbekistan withdrew from GUAM, and on 23 June 2006, Uzbekistan became a full participant in the CSTO and its membership was formally ratified by its parliament on 28 March 2008. The CSTO is an observer organisation at the United Nations General Assembly.
The charter reaffirmed the desire of all participating states to abstain from the use or threat of force. Signatories would not be able to join other military alliances or other groups of states, while aggression against one signatory would be perceived as an aggression against all. To this end, the CSTO holds yearly military command exercises for the CSTO nations to have an opportunity to improve inter-organisation cooperation. The largest-scale CSTO military exercise held to date were the "Rubezh 2008" exercises hosted in Armenia where a combined total of 4,000 troops from all 7 constituent CSTO member countries conducted operative, strategic, and tactical training with an emphasis towards furthering efficiency of the collective security element of the CSTO partnership.
In May 2007, the CSTO secretary-general Nikolai Bordyuzha suggested Iran could join the CSTO saying, "The CSTO is an open organisation. If Iran applies in accordance with our charter, we will consider the application." If Iran joined, it would be the first state outside the former Soviet Union to become a member of the organisation.
On 6 October 2007, CSTO members agreed to a major expansion of the organisation which would create a CSTO peacekeeping force that could deploy under a UN mandate or without one in its member states. The expansion would also allow all members to purchase Russian weapons at the same price as Russia. CSTO signed an agreement with the Shanghai Cooperation Organisation (SCO), in the Tajik capital Dushanbe, to broaden cooperation on issues such as security, crime, and drug trafficking.
On 29 August 2008, Russia announced it would seek CSTO recognition of the independence of Abkhazia and South Ossetia, three days after Russia officially recognised both. On 5 September 2008, Armenia assumed the rotating CSTO presidency during a CSTO meeting in Moscow, Russia.
In October 2009, Ukraine refused permission for the CIS Anti-Terrorist Center to hold anti-terrorist exercises on its territory because Ukraine's constitution bans foreign military units from operating on its territory.
The largest military exercises ever held by the CSTO, involving up to 12,000 troops, were conducted between 19 and 27 September 2011 to raise preparedness and co-ordination in anti-destabilization techniques, to counter any attempts at popular uprisings like the Arab Spring.
Other activities.
Controversial election observation mission.
The CIS Election Monitoring Organisation (Russian: Миссия наблюдателей от СНГ на выборах) is an election monitoring body that was formed in October 2002, following a Commonwealth of Independent States heads of states meeting which adopted the "Convention on the Standards of Democratic Elections, Electoral Rights, and Freedoms in the Member States of the Commonwealth of Independent States". The CIS-EMO has been sending election observers to member countries of the CIS since this time; they approved many elections which have been heavily criticised by independent observers.
Interparliamentary Assembly.
The CIS Interparliamentary Assembly, established in March 1995, is a consultative parliamentary wing of the CIS created to discuss problems of parliamentary cooperation. The Assembly held its 32nd Plenary meeting in Saint Petersburg on 14 May 2009. Ukraine participates, but Uzbekistan does not.
Russian language status.
Russia has been urging that the Russian language receives official status in all of the CIS member states. So far Russian is an official language in only four of these states: Russia, Belarus, Kazakhstan, and Kyrgyzstan. Russian is also considered an official language in the region of Transnistria, and the autonomous region of Gagauzia in Moldova. Viktor Yanukovych, the Moscow-supported presidential candidate in the controversial 2004 Ukrainian presidential election, declared his intention to make Russian an official second language of Ukraine. However, Viktor Yushchenko, the winner, did not do so. After his early 2010 election as President Yanukovych stated (on 9 March 2010) that "Ukraine will continue to promote the Ukrainian language as its only state language".
Sports events.
At the time of the Soviet Union's dissolution in December 1991, had been invited to or qualified for various 1992 sports events. A joint CIS team took its place in some of these. The "Unified Team" competed in the 1992 Winter Olympics and 1992 Summer Olympics, and a CIS association football team competed in UEFA Euro 1992. A CIS bandy team played some friendlies in January 1992 and made its last appearance at the 1992 Russian Government Cup, where it also played against the new Russia national bandy team. The Soviet Union bandy championship for 1991–1992 was rebranded as a CIS championship.
Since then, CIS members have each competed separately in international sport.

</doc>
<doc id="36871" url="http://en.wikipedia.org/wiki?curid=36871" title="Show jumping">
Show jumping

Show jumping, also known as "stadium jumping", "open jumping", or "jumpers", is a member of a family of English riding equestrian events that also includes dressage, eventing, hunters, and equitation. Jumping classes are commonly seen at horse shows throughout the world, including the Olympics. Sometimes shows are limited exclusively to jumpers, sometimes jumper classes are offered in conjunction with other English-style events, and sometimes show jumping is but one division of very large, all-breed competitions that include a very wide variety of disciplines. Jumping classes may be governed by various national horse show sanctioning organizations, such as the United States Equestrian Federation in the USA. International competitions are governed by the rules of the International Federation for Equestrian Sports (FEI, from the body's French name of "Fédération Équestre Internationale").
Hunters or jumpers.
People unfamiliar with horse shows may be confused by the difference between hunter classes and jumper classes. Hunters are judged subjectively on the degree to which they meet an ideal standard of manners, style, and way of going. Conversely, jumper classes are scored objectively, based entirely on a numerical score determined only by whether the horse attempts the obstacle, clears it, and finishes the course in the allotted time. Jumper courses often are colorful, and at times, quite creatively designed. Jumper courses tend to be much more complex and technical than hunter courses, because riders and horses are not being judged on style. Hunters have meticulous turnout and tend toward very quiet, conservative horse tack and rider attire. Hunter bits, bridles, crops, spurs, and martingales are tightly regulated. Jumpers, while caring for their horses and grooming them well, are not scored on turnout, are allowed a wider range of equipment, and riders may wear less conservative attire, so long as it stays within the rules. Formal turnout always is preferred; a neat rider gives a good impression at shows.
In addition to hunters and jumpers, there are equitation classes, sometimes called hunt seat equitation, which judges the ability of the rider. The equipment, clothing, and fence styles used in equitation more closely resemble hunter classes, although the technical difficulty of the courses may more closely resemble jumping events.
Courses and rules.
Jumper classes are held over a course of show jumping obstacles, including verticals, spreads, double and triple combinations, usually with many turns and changes of direction. The intent is to jump cleanly over a set course within an allotted time. Time faults are assessed for exceeding the time allowance. Jumping faults are incurred for knockdowns and blatant disobedience, such as refusals (when the horse stops before a fence or "runs out") ("see" "Modern Rules" "below"). Horses are allowed a limited number of refusals before being disqualified. A refusal may lead to a rider exceeding the time allowed on course. Placings are based on the lowest number of points or "faults" accumulated. A horse and rider who have not accumulated any jumping faults or penalty points are said to have scored a "clear round." Tied entries usually have a jump-off over a raised and shortened course, and the course is timed; if entries are tied for faults accumulated in the jump-off, the fastest time wins.
In most competitions, riders are allowed to walk the initial course, but not the jump-off course (usually the same course with missing jumps, e.g., 1, 3, 5, 7, 8 instead of 1, 2, 3, 4, 5, 6, 7, 8, 9) before competition to plan their ride. Walking the course before the event is a chance for the rider to walk the lines he or she will have to ride, in order to decide how many strides the horse will need to take between each jump and from which angle. Going off course will cost time if minor errors are made and major departures may result in disqualification.
The higher levels of competition, such as "A" or "AA" rated shows in the United States, or the international "Grand Prix" circuit, present more technical and complex courses. Not only is the height and width ("spread") of an obstacle increased to present a greater challenge, technical difficulty also increases with tighter turns and shorter or unusual distances between fences. Horses sometimes also have to jump fences from an angle rather than straight on. For example, a course designer might set up a line so that there are six and a half strides (the standard measure for a canter stride is twelve feet) between the jumps, requiring the rider to adjust the horse's stride dramatically in order to make the distance.
Unlike show hunter classes, which reward calmness and style, jumper classes require boldness, scope, power, accuracy, and control; speed also is a factor, especially in jump-off courses and speed classes (when time counts even in the first round). A jumper must jump big, bravely, and fast, but also must be careful and accurate to avoid knockdowns and must be balanced and rideable in order to rate and turn accurately. The rider must choose the best line to each fence, saving ground with well-planned turns and lines and must adjust the horse's stride for each fence and distance. In a jump-off, a rider must balance the need to go as fast as possible and turn as tightly as possible against the horse's ability to jump cleanly with good scope.
History.
Show jumping is a relatively new equestrian sport. Until the Inclosure Acts, which came into force in England in the 18th century, there had been little need for horses to jump fences routinely, but with this act of Parliament came new challenges for those who followed fox hounds. The Inclosure Acts brought fencing and boundaries to many parts of the country as common ground was dispersed amongst wealthy landowners. This meant that those wishing to pursue their sport now needed horses that were capable of jumping these obstacles.
In the early horse shows held in France, there was a parade of competitors who then took off across country for the jumping. This sport was, however, not popular with spectators as they could not follow to watch the jumping. Thus, it was not long before fences began to appear in an arena for the competitions. This became known as "Lepping". 1869 was the year ‘horse leaping’ came to prominence at Dublin horse show. Fifteen years later, "Lepping" competitions were brought to Britain and by 1900 most of the more important shows had "Lepping" classes. Separate classes were held for women riding sidesaddle.
At this time, the principal cavalry schools of Europe at Pinerolo and Tor-di-Quinto in Italy, the French school in Saumur, and the Spanish school in Vienna all preferred to use a very deep seat with long stirrups when jumping. While this style of riding may have felt more secure for the rider, it also impeded the freedom of the horse to use its body to the extent needed to clear large obstacles.
An Italian riding instructor, Captain Federico Caprilli, heavily influenced the world of jumping with his ideas promoting a forward position with shorter stirrups. This style placed the rider in a position that did not interfere with the balance of the horse while negotiating obstacles. This style, now known as the forward seat, is commonly used today. The deep, Dressage-style seat, while useful for riding on the flat and in conditions where control of the horse is of greater importance than freedom of movement, is less suitable for jumping.
The first major show jumping competition held in England was at Olympia in 1907. Most of the competitors were members of the military and it became clear at this competition and in the subsequent years, that there was no uniformity of rules for the sport. Judges marked on their own opinions. Some marked according to the severity of the obstacle and others marked according to style. Before 1907 there were no penalties for a refusal and the competitor was sometimes asked to miss the fence to please the spectators. The first courses were built with little imagination; many consisting of only a straight bar fence and a water jump. A meeting was arranged in 1923 which led to the formation of the BSJA in 1925. In the United States, a similar need for national rules for jumping and other equestrian activities led to the formation of the American Horse Shows Association in 1917, which now is known as the United States Equestrian Federation.
An early form of show jumping first was incorporated into the Olympic Games in 1900. Show jumping in its current format appeared in 1912, and has thrived ever since, its recent popularity due in part to its suitability as a spectator sport which is well adapted for viewing on television.
Original scoring tariff.
The original list of faults introduced in Great Britain in 1925 was as follows:
Water jumps were once at least fifteen feet (5 m) wide, although the water often had drained out of them by the time the last competitor jumped. High jumping would start with a pole at around five feet high, but this was later abandoned, as many horses went under the pole. It was for this reason that more poles were added and fillers came into use. Time penalties were not counted until 1917.
Modern rules.
Rules have evolved since then, with different national federations having different classes and rules. The international governing body for most major show jumping competitions is the Fédération Équestre Internationale (FEI). The two most common types of penalties are jumping penalties and time penalties.
Tack.
Show jumping competitors use a very forward style of English saddle, most often the "close contact" design, which has a forward flap and a seat and cantle that is flatter than saddles designed for general all-purpose English riding or dressage. This construction allows greater freedom of movement for the rider when in jumping position, and allows a shorter stirrup, allowing the rider to lighten the seat on the horse. Other saddles, such as those designed for dressage, are intended for riders with a deep seat, can hinder a rider over large fences, forcing them into a position that limits the horse's movement and may put the rider dangerously behind the movement of the horse.
At international levels, saddle pads are usually white and square in shape, allowing the pair to display a sponsorship, national flag, or breeding affiliation. In contrast, riders in show hunters and equitation often use "fitted" fleece pads that are the same shape as the saddle. Girths vary in type, but usually have a contour to give room for the horse's elbows, and many have belly guards to protect the underside of the horse from its shoe studs when the front legs are tightly folded under.
Bridles may be used with any style of cavesson noseband, and there are few rules regarding the severity of this equipment. The figure-8 cavesson is the most popular type. Bits may also vary in severity, and competitors may use any bit, or even a "bitless bridle" or a mechanical hackamore. The ground jury at the show has the right, however, based on veterinary advice, to refuse a bit or bridling scheme if it could cause harm to the horse.
Boots and wraps are worn by almost all horses, due to the fact that they may easily injure their legs when landing or when making tight turns at speed. Open-fronted tendon boots usually are worn on the forelegs, because they provide protection for the delicate tendons that run down the back of the leg, but still allow the horse to feel a rail should it get careless and hang its legs. Fetlock boots are sometimes seen on the rear legs, primarily to prevent the horse from hitting itself on tight turns.
Martingales are very common, especially on horses used at the Grand Prix level. The majority of jumpers are ridden in running martingales, as these provide the most freedom over fences. Although a standing martingale (a strap connecting directly to the horse's noseband) is commonly seen on show hunters and may be helpful in keeping a horse from throwing its head up, it also may be quite dangerous in the event of a stumble, restricting a horse from using its head to regain its balance. For this reason, standing martingales are not used in show jumping or eventing. Breastplates also are common, used to keep the saddle in place as the horse goes over large fences.
Rider attire.
Rider attire may be somewhat less formal than that used in hunter riding. An approved ASTM/SEI equestrian helmet with a harness is always required, however, and is a practical necessity to protect the rider's head in the event of a fall. Tall boots are required, usually black. Spurs are optional, but commonly used. Breeches are traditional in color, usually white, tan, or beige. At approved competitions, depending on sanctioning organization, a dark-colored coat usually is worn (although under the rules of the USEF tweed or wash jackets are allowed in the summer and lighter colors are currently in fashion), with a light-colored (usually white) ratcatcher-style shirt and either a choker or stock tie. In hot summer weather, many riders wear a simple short-sleeved "polo" style shirt with helmet, boots and breeches, and even where coats are required, the judges may waive the coat rule in extremely hot weather. Gloves, usually black, are optional, as is the plaiting of the horse's mane and tail.
At FEI Grand Prix levels, dress is more strictly controlled. Riders must wear white or light-colored shirts, white ties or chokers, black or brown boots, white or light fawn breeches, and red or black jackets. Members of the military, police forces, and national studs, however, retain the right to wear their service uniforms instead of FEI-prescribed dress. In some circumstances, members of international teams may wear jackets in their country's respective colors or add national insignia.
Types of show jumps.
Show jumping fences often are colorful, sometimes very elaborate and artistic in design, particularly at the highest levels of competition. Types of jumps used include the following: 
At international level competitions that are governed by FEI rules, fence heights begin at 1.50 m. Other competition levels are given different names in different nations, but are based primarily on the height and spread of fences
In the United States, jumping levels range from 0–9 as follows:
USEF Jumper Levels
In Germany, competition levels are denoted by the letters E, A, L, M, S, and correspond to heights ranging from 0.80 to 1.55 meters.
The horses.
A show jumper must have the scope and courage to jump large fences as well as the athletic ability to handle the sharp turns and bursts of speed necessary to navigate the most difficult courses. Many breeds of horses have been successful show jumpers, and even some grade horses of uncertain breeding have been champions. Most show jumpers are tall horses, over  hands , usually of Warmblood or Thoroughbred breeding, though horses as small as  hands have been on the Olympic teams of various nations and carried riders to Olympic and other international medals. There is no correlation between the size of a horse and its athletic ability, nor do tall horses necessarily have an advantage when jumping. Nonetheless, a taller horse may make a fence appear less daunting to the rider.
Ponies also compete in show jumping competitions in many countries, usually in classes limited to youth riders, defined as those under the age of 16 or 18 years, depending on the sanctioning organization. Pony-sized horses may, on occasion, compete in open competition with adult riders. The most famous example was Stroller, who only stood  hands but was nonetheless an Individual silver medal winner and part the Great Britain show jumping team in the 1968 Summer Olympics, jumping one of the few clean rounds in the competition. Significant jumpers from the United States are included in the Show Jumping Hall of Fame.

</doc>
<doc id="36875" url="http://en.wikipedia.org/wiki?curid=36875" title="Non-judicial punishment">
Non-judicial punishment

A non-judicial punishment (NJP) in the United States Armed Forces is a form of military justice authorized by Article 15 of the Uniform Code of Military Justice. Non-judicial punishment or "NJP" permits commanders to administratively discipline troops without a court-martial. Punishment can range from reprimand to reduction in rank, correctional custody, confinement on bread and water/diminished rations (aboard ships only), loss of pay, extra duty, and/or restrictions. The receipt of non-judicial punishment does not constitute a criminal conviction (it is equivalent to a civil action), but is often placed in the service record of the individual. The process for non-judicial punishment is governed by Part V of the Manual for Courts-Martial and by each service branch's regulations. 
Non-judicial punishment proceedings are known by different terms among the services. In the U.S. Army and the U.S. Air Force, non-judicial punishment is referred to as Article 15; in the Marine Corps it is called being "NJP'd", "Ninja Punched", or being sent to "Office Hours". The U.S. Navy and the U.S. Coast Guard call non-judicial punishment captain's mast or admiral's mast, depending on the rank of the commanding officer. 
Hearing.
Prior to imposition of NJP, the commander will notify the accused of the commander's intention to impose punishment, the nature of the misconduct alleged, supporting evidence and a statement of the accused's rights under the UCMJ. All service members, except those embarked or attached to a vessel currently away from its homeport, have a right to refuse NJP and request a court-martial. If the accused does not accept the NJP, the NJP hearing is terminated and the commander must make the decision of whether to process the service member for court-martial. If the accused accepts NJP, he or she, plus a representative if desired, will attend the hearing conducted by the commander. The accused may present evidence and witnesses to the commander. The commander must consider any information offered during the hearing, and must be personally convinced that the service member committed misconduct before imposing punishment.
Punishments.
Maximum penalties depend on the rank of the accused and that of the officer imposing punishment:
For Officers Accused of Misconduct.
If the officer imposing punishment holds General Court Martial authority, or if the commanding officer of the grade O-7 or greater
By Commanding Officers of the grades O-4 to O-6
By Commanding Officers of the grades O-1 to O-3
By Officers In Charge (OIC)
For Enlisted members Accused Of Misconduct.
There are three types of non-judicial punishment commonly imposed.
Summary Article 15: commanders (O-3 and below) and commissioned OIC may impose:
Company Grade (O-3 or below) commanders may impose the above plus:
Field Grade (O-4 to O-6) may impose:
The punishments listed above may be combined (with certain limitations listed in the Manual for Courts-Martial, Part 5, Section 5(d)). For example, extra duties, restriction and forfeiture of pay, and reduction in grade could be imposed.
If the member considers the punishment to be unjust or to be disproportionate to the misconduct committed, he or she may appeal the NJP to a higher authority. This is usually the next officer in the chain of command. Upon considering the appeal, the higher authority may set aside the NJP, decrease the severity of the punishment, or may deny the appeal. They may not increase the severity of the punishment.
Personnel are permitted to refuse NJP in favor of a court-martial; this might be done in cases where they do not feel their Commanding Officer will give them a fair hearing. But this option exposes them to a possible criminal court conviction. Navy and Marine Corps personnel assigned to or embarked aboard ship do not have the option of refusing NJP, nor can they appeal the decision of the officer imposing punishment; they may only appeal the severity of the punishment.

</doc>
<doc id="36877" url="http://en.wikipedia.org/wiki?curid=36877" title="Bucharest">
Bucharest

Bucharest (; Romanian: "București", ]) is the capital municipality, cultural, industrial, and financial centre of Romania. It is the largest city in Romania and located in the southeast of the country, at , lies on the banks of the Dâmbovița River, less than 70 km north of the Danube River.
Bucharest was first mentioned in documents in 1459. It became the capital of Romania in 1862 and is the centre of Romanian media, culture and art. Its architecture is a mix of historical (neo-classical), interbellum (Bauhaus and art deco), communist-era and modern. In the period between the two World Wars, the city's elegant architecture and the sophistication of its elite earned Bucharest the nickname of "Little Paris" ("Micul Paris"). Although buildings and districts in the historic city centre were heavily damaged or destroyed by war, earthquakes, and above all Nicolae Ceaușescu's program of systematization, many survived. In recent years, the city has been experiencing an economic and cultural boom.
According to 2011 census, 1,883,425 inhabitants live within the city limits, a decrease from the figure recorded at the 2002 census. The urban area extends beyond the limits of Bucharest proper and has a population of about 1.9 million people. Adding the satellite towns around the urban area, the proposed metropolitan area of Bucharest would have a population of 2.27 million people. According to Eurostat, Bucharest has a larger urban zone of 2,151,880 residents. According to unofficial data, the population is more than 3 million. Bucharest is the 6th largest city in the European Union by population within city limits, after London, Berlin, Madrid, Rome, and Paris.
Economically, Bucharest is the most prosperous city in Romania and is one of the main industrial centres and transportation hubs of Eastern Europe. The city has big convention facilities, educational institutes, cultural venues, traditional "shopping arcades" and recreational areas.
The city proper is administratively known as the "Municipality of Bucharest" ("Municipiul București"), and has the same administrative level as that of a national county, being further subdivided into six sectors, each governed by a local mayor.
Etymology.
The name of "București" has an uncertain origin: tradition connects the founding of Bucharest with the name of "Bucur" who was either a prince, an outlaw, a fisherman, a shepherd, or a hunter, according to different legends. In Romanian the word stem "bucurie" means 'joy', ("happiness") and it is believed to be of Dacian origin.
There are other etymologies given by early scholars, including the one of an Ottoman traveler, Evliya Çelebi, who said that Bucharest was named after a certain "Abu-Kariș", from the tribe of "Bani-Kureiș". In 1781, Franz Sulzer claimed that it was related to "bucurie" (joy), "bucuros" (joyful) or "a se bucura" (to become joyful), while an early 19th-century book published in Vienna assumed its name has been derived from "Bukovie", a beech forest.
The official city name in full is "The Municipality of Bucharest" (Romanian: "Municipiul București").
A native or resident of Bucharest is called a "Bucharester" (Romanian: "bucureștean").
History.
Bucharest's history alternated periods of development and decline from the early settlements in antiquity until its consolidation as the national capital of Romania late in the 19th century.
First mentioned as the "Citadel of București" in 1459, it became the residence of the famous Wallachian prince Vlad III the Impaler.:23
The Ottomans appointed Greek administrators (Phanariotes) to run the town from the 18th century. A short-lived revolt initiated by Tudor Vladimirescu in 1821 led to the end of the rule of Constantinople Greeks in Bucharest.
The Old Princely Court ("Curtea Veche") was erected by Mircea Ciobanul in the mid-16th century. Under subsequent rulers, Bucharest was established as the summer residence of the royal court. During the years to come it competed with Târgoviște on the status of capital city after an increase in the importance of southern Muntenia brought about by the demands of the suzerain power – the Ottoman Empire.
Bucharest became finally the permanent location of the Wallachian court after 1698 (starting with the reign of Constantin Brâncoveanu).
Partly destroyed by natural disasters and rebuilt several times during the following 200 years, and hit by "Caragea's plague" in 1813–14, the city was wrested from Ottoman control and occupied at several intervals by the Habsburg Monarchy (1716, 1737, 1789) and Imperial Russia (three times between 1768 and 1806). It was placed under Russian administration between 1828 and the Crimean War, with an interlude during the Bucharest-centred 1848 Wallachian revolution. Later on an Austrian garrison took possession after the Russian departure (remaining in the city until March 1857). On 23 March 1847, a fire consumed about 2,000 buildings, destroying a third of the city.
In 1862, after Wallachia and Moldavia were united to form the Principality of Romania, Bucharest became the new nation's capital city. In 1881, it became the political centre of the newly proclaimed Kingdom of Romania under King Carol I. During the second half of the 19th century the city's population increased dramatically, and a new period of urban development began. During this period, gas lighting, horse-drawn trams and limited electrification were introduced. The Dâmbovița river was also massively channelled in 1883, thus putting a stop to previously endemic floods like the 1865 flooding of Bucharest. The Fortifications of Bucharest were built. The extravagant architecture and cosmopolitan high culture of this period won Bucharest the nickname of "Little Paris" ("Micul Paris") of the east, with Calea Victoriei as its Champs-Élysées.
Between 6 December 1916 and November 1918, the city was occupied by German forces as a result of the Battle of Bucharest, with the official capital temporarily moved to Iași, in the Moldavia region. After World War I, Bucharest became the capital of Greater Romania. In the interwar years continued its urban development, with the city gaining an average of 30,000 new residents each year. Also, some of the city's main landmarks were built in this period, including Arcul de Triumf and Palatul Telefoanelor. However, the Great Depression took its toll on Bucharest's citizens, culminating in the Grivița Strike of 1933.
In January 1941, the city was the scene of the Legionnaires' rebellion and Bucharest pogrom. As capital of an Axis country and a major transit point for Axis troops en route to the Eastern Front, Bucharest suffered heavy damage during World War II due to Allied bombings. On 23 August 1944 it was the site of the royal coup which brought Romania into the Allied camp, suffering a short period of Nazi Luftwaffe bombings as well as a failed attempt by German troops to regain the city by force.
After the establishment of communism in Romania, the city continued growing. New districts were constructed, most of them dominated by tower blocks. During Nicolae Ceaușescu's leadership (1965–89), much of the historic part of the city was demolished and replaced by "Socialist realism" style development: (1) the Centrul Civic (the Civic Centre); (2) the Palace of the Parliament, where an entire historic quarter was razed to make way for Ceaușescu's megalomaniac plans. On 4 March 1977, an earthquake centered in Vrancea, about 135 km away, claimed 1,500 lives and caused further damage to the historic centre.
The Romanian Revolution of 1989 began with massive anti-Ceaușescu protests in Timișoara in December 1989 and continued in Bucharest, leading to the overthrow of the Communist regime. Dissatisfied with the post-revolutionary leadership of the National Salvation Front, some student leagues and opposition groups organized large-scale protests in 1990 (the "Golaniad"), which were violently repressed by the miners of Valea Jiului called in by the authorities (the "Mineriad"). Several other "Mineriads" followed, which finally caused political changes.
Since 2000, the city has been continuously modernized and is still undergoing urban renewal. Residential and commercial developments are underway, particularly in the northern districts, and Bucharest's old historic centre is being restored.
Geography.
General.
Bucharest is situated on the banks of the Dâmbovița River, which flows into the Argeș River, a tributary of the Danube. Several lakes – the most important of which are Lake Herăstrău, Lake Floreasca, Lake Tei, and Lake Colentina – stretch across the northern parts of the city, along the Colentina River, a tributary of the Dâmbovița. In addition, in the centre of the capital there is a small artificial lake – Lake Cișmigiu – surrounded by the Cișmigiu Gardens. The Cișmigiu Gardens have a rich history, being frequented by poets and writers. Opened in 1847 and based on the plans of German architect Carl F.W. Meyer, the gardens are the main recreational facility in the city centre.
Besides Cișmigiu, Bucharest parks and gardens include Herăstrău Park and the Botanical Garden. Herăstrău Park is located in the northern part of the city, around Lake Herăstrău, and includes the site the Village Museum. The Botanical Garden, located in the Cotroceni neighborhood a bit west of the city centre, is the largest of its kind in Romania and contains over 10,000 species of plants (many of them exotic); it originated as the pleasure park of the royal family.
Bucharest is situated in the south eastern corner of the Romanian Plain, in an area once covered by the Vlăsiei forest, which, after it was cleared, gave way for a fertile flatland. As with many cities, Bucharest is traditionally considered to be built upon seven hills, similar to the seven hills of Rome. Bucharest's seven hills are: Mihai Vodă, Dealul Mitropoliei, Radu Vodă, Cotroceni, Spirei, Văcărești and Sf. Gheorghe Nou.
The city has an area of 226 km2. The altitude varies from 55.8 m at the Dâmbovița bridge in Cățelu, south-eastern Bucharest and 91.5 m at the Militari church. The city has an approximately round shape, with the centre situated in the cross-way of the main north-south/east-west axes at University Square. The milestone for Romania's Kilometre Zero is placed just south of University Square in front of the New St. George Church (Sfântul Gheorghe Nou) at St. George Square (Piața Sfântul Gheorghe). Bucharest's radius, from University Square to the city limits in all directions, varies from about 10 to.
Until recently, the regions surrounding Bucharest were largely rural, but after 1989, suburbs started to be built around Bucharest, in the surrounding Ilfov county. Further urban consolidation is expected to take place in the late 2010s, when the "Bucharest Metropolitan Area" plan will become operational, incorporating additional communes and cities from the Ilfov and other neighbouring counties.
Climate.
Bucharest has a Humid continental climate "Dfa". Owing to its position on the Romanian Plain, the city's winters can get windy, even though some of the winds are mitigated due to urbanisation. Winter temperatures often dip below 0 °C, sometimes even to -20 °C. In summer, the average temperature is 23 °C (the average for July and August) Temperatures frequently reach 35 to in mid-summer in the city centre. Although average precipitation and humidity during summer are low, there are occasional heavy storms. During spring and autumn, daytime temperatures vary between 17 to, and precipitation during spring tends to be higher than in summer, with more frequent yet milder periods of rain.
Law and government.
Administration.
Bucharest has a unique status in Romanian administration, since it is the only municipal area that is not part of a county. Its population, however, is larger than that of any other Romanian county, hence the power of the Bucharest General Municipality ("Primăria Generală"), which is the capital's local government body, is the same as any other Romanian County Council.
The city government is headed by a general mayor (Primar General), as of 2008 Sorin Oprescu. Decisions are approved and discussed by the capital's General Council (Consiliu General) made up of 55 elected councilors. Furthermore, the city is divided into six administrative sectors (sectoare), each of which has their own 27-seat sectoral council, town hall and mayor. The powers of the local government over a certain area are therefore shared both by the Bucharest Municipality and the local sectoral councils with little or no overlapping of authority. The general rule is that the main Capital Municipality is responsible for citywide utilities such as the water and sewage system, the overall transport system and the main boulevards, while sectoral town halls manage the contact between individuals and the local government, secondary streets and parks maintenance, schools administration and cleaning services.
The six sectors are numbered from one to six and are disposed radially so that each one has under its administration a certain area of the city centre. They are numbered clockwise and are further divided into sectoral quarters ("cartiere") which are not part of the official administrative division:
Like all other local councils in Romania, the Bucharest sectoral councils, the capital's General Council and the mayors are elected every four years by the population. Additionally, Bucharest has a prefect, who is appointed by Romania's national government. The prefect is not allowed to be a member of a political party and his role is to represent the national government at the municipal level. The prefect is acting as a liaison official facilitating the implementation of National Development Plans and governing programs at local level. The prefect of Bucharest (as of 2012) is Georgeta Gavrilă.
The Municipality of Bucharest, along with the surrounding Ilfov County and several other neighbouring counties are part of the Bucharest development region project, which is equivalent to NUTS-II regions in the European Union and is used both by the Union and the Romanian government for statistical analysis and regional development planning. The Bucharest development region is not, however, an administrative entity yet.
Justice system.
Bucharest's judicial system is similar to that of the Romanian counties. Each of the six sectors has its own local first instance court ("judecătorie"), while more serious cases are directed to the Bucharest Tribunal (Tribunalul Bucureşti), the city's municipal court. The Bucharest Court of Appeal (Curtea de Apel Bucureşti) judges appeals against decisions taken by first instance courts and tribunals in Bucharest and in five surrounding counties (Teleorman, Ialomița, Giurgiu, Călărași and Ilfov). Bucharest is also home to Romania's supreme court, the High Court of Cassation and Justice, as well as to the Constitutional Court of Romania.
Bucharest has a municipal police force, the Bucharest Police ("Poliția București"), which is responsible for policing of crime within the whole city, and operates a number of divisions. The Bucharest Police are headquartered on Ștefan cel Mare Blvd. in the city centre, and at precincts throughout the city. From 2004 onwards, each Sector City Hall also has under its administration a Community Police force ("Poliția Comunitară"), dealing with local community issues. Bucharest also houses the General Inspectorates of the Gendarmerie and the National Police.
Crime.
Bucharest's crime rate is rather low in comparison to other European capital cities, with the number of total offenses declining by 51% between 2000 and 2004, and by 7% between 2012 and 2013. The violent crime rate in Bucharest remains very low, with 11 murders and 983 other violent offenses taking place in 2007. Although violent crimes fell by 13% in 2013 compared to 2012, there were 19 recorded murders (18 of which the suspects were arrested).
Although in the 2000s, there were a number of police crackdowns on organized crime gangs, such as the Cămătaru clan, organized crime generally has little impact on public life. Petty crime, however, is more common, particularly in the form of pickpocketing, which occurs mainly on the city's public transport network. Confidence tricks were common in the 1990s, especially in regards to tourists, but the frequency of these incidents has since declined. However, in general, theft was reduced by 13.6% in 2013 compared to 2012. Levels of crime are higher in the southern districts of the city, particularly in Ferentari, a socially disadvantaged area.
Although the presence of street children was a problem in Bucharest in the 1990s, their numbers have declined in recent years, now lying at or below the average of major European capital cities. A documentary called Children Underground depicted the life of Romanian street kids in 2001. There are still an estimated 1,000 street children in the city, some of whom engage in petty crime and begging.
Quality of life.
As stated by the Mercer international surveys for quality of life in cities around the world, Bucharest occupied the 94th place in 2001 and slipped lower, to the 108th place in 2009 and the 107th place in 2010. Compared to it, Vienna occupied No. 1 worldwide in 2011 and 2009. Budapest ranked 73rd (2010) and Sofia 114th (2010). Mercer Human Resource Consulting issues yearly a global ranking of the world's most livable cities based on 39 key quality-of-life issues. Among them: political stability, currency-exchange regulations, political and media censorship, school quality, housing, the environment, public safety. Mercer collects data worldwide, in 215 cities. The difficult situation of the quality of life in Bucharest is confirmed also by a vast urbanism study, done by the Ion Mincu University of Architecture and Urbanism.
Demographics.
As per the 2011 census, 1,883,425 inhabitants live within the city limits, a decrease from the figure recorded at the 2002 census. This decrease is due to low natural increase, but also to a shift in population from the city itself to neighboring small towns like Voluntari, Buftea or Otopeni. In a study published by the United Nations, Bucharest placed 19th in among 28 cities that recorded sharp declines in population from 1990 to the mid-2010s. In particular, the population fell by 3.77%.
The city's population, according to the 2002 census, was 1,926,334 inhabitants, or 8.9% of the total population of Romania. A significant number of people commute to the city every day, mostly from the surrounding Ilfov county, however official statistics regarding their numbers do not exist.
Bucharest's population experienced two phases of rapid growth, the first beginning in the late 19th century when the city was consolidated as the national capital and lasting until the Second World War, and the second during the Ceaușescu years (1965–1989), when a massive urbanization campaign was launched and many people migrated from rural areas to the capital. At this time, due to Ceaușescu's decision to ban abortion and contraception, natural increase was also significant.
Approximately 96.6% of the population of Bucharest are Romanians. Other significant ethnic groups are Roma Gypsies, Hungarians, Jews, Turks, Chinese and Germans. A relatively small number of Bucharesters are of Greek, North American, French, Armenian, Lippovan and Italian descent. One of the predominantly Greek neighborhoods was Vitan – where a Jewish population also lived; the latter was more present in Văcărești and areas around Unirii Square.
In terms of religious affiliation, 96.1% of the population are Romanian Orthodox, 1.2% are Roman Catholic, 0.5% are Muslim and 0.4% are Romanian Greek Catholic. Despite this, only 18% of the population, of any religion, attend a place of worship once a week or more. The life expectancy of residents of Bucharest in 2003–2005 was 74.14 years, around 2 years higher than the Romanian average. Female life expectancy was 77.41 years, in comparison to 70.57 years for males.
Economy.
Bucharest is the center of the Romanian economy and industry, accounting for around 22.7% (2010) of the country's GDP and about one-quarter of its industrial production, while being inhabited by 9% of the country's population. Almost one third of national taxes are paid by Bucharest's citizens and companies. In 2011, at purchasing power parity, Bucharest had a per-capita GDP of €30,700, or 122% that of the European Union average and more than twice the Romanian average. After relative stagnation in the 1990s, the city's strong economic growth has revitalized infrastructure and led to the development of shopping malls, residential estates and high-rise office buildings. In January 2013, Bucharest had an unemployment rate of 2.1%, significantly lower than the national unemployment rate of 5.8%.
Bucharest's economy is centered on industry and services, with services particularly growing in importance in the last ten years. The headquarters of 186,000 firms, including nearly all large Romanian companies are located in Bucharest. An important source of growth since 2000 has been the city's rapidly expanding property and construction sector. Bucharest is also Romania's largest centre for information technology and communications and is home to several software companies operating offshore delivery centres.
Romania's largest stock exchange, the Bucharest Stock Exchange, which was merged in December 2005 with the Bucharest-based electronic stock exchange Rasdaq, plays a major role in the city's economy.
There are international supermarket chains such as Carrefour, Cora and METRO operating in Bucharest. The city is undergoing a retail boom, with supermarkets and hypermarkets opened every year (see supermarkets in Romania). Bucharest hosts a lot of luxury brands such as Louis Vuitton, Hermes, Gucci, Armani, Hugo Boss, Prada, Calvin Klein, Rolex, Burberry and many others. Malls and large shopping centres have been built since the late 1990s, such as AFI Palace Cotroceni, Sun Plaza, Băneasa Shopping City, Plaza Romania, Unirea Shopping Center and Liberty Center. There are traditional retail arcades and markets such as the one at Obor.
Transport.
Public transport.
Bucharest's public transport system is the largest in Romania and one of the largest in Europe. It is made up of the Bucharest Metro, run by Metrorex, as well as a surface transport system run by RATB (Regia Autonomă de Transport București), which consists of buses, trams, trolleybuses, and light rail. In addition, there is a private minibus system. As of 2007, there is a limit of 10,000 taxicab licenses.
Railways.
Bucharest is the hub of Romania's national railway network, run by "Căile Ferate Române". The main railway station is Gara de Nord ("North Station"), which provides connections to all major cities in Romania as well as international destinations: Belgrade, Sofia, Varna, Chișinău, Kiev, Chernivtsi, Lviv, Thessaloniki, Vienna, Budapest, Istanbul, Moscow, etc.
The city has five other railway stations run by CFR, of which the most important are Basarab (adjacent to North Station), Obor, Băneasa and Progresu. These are in the process of being integrated into a commuter railway serving Bucharest and the surrounding Ilfov County. Seven main lines radiate out of Bucharest.
Air.
Bucharest has two international airports:
Roads.
Bucharest is a major intersection of Romania's national road network. A few of the busiest national roads and motorways, link the city to all of Romania's major cities as well as to neighbouring countries such as Hungary, Bulgaria and Ukraine. The A1 to Pitești, the A2 Sun Motorway to the Dobrogea region and Constanta and the A3 to Ploieşti all start from Bucharest.
The city's municipal road network is centred around a series of high-capacity boulevards, which generally radiate out from the city centre to the outskirts. The main axes, which run north-south, east-west and northwest-southeast, as well as one internal and one external ring road, support the bulk of the traffic. The city's roads are usually very crowded during rush hours, due to an increase in car ownership in recent years. In 2013, the number of cars registered in Bucharest amounted to 1,125,591. This results in wear and potholes appearing on busy roads, particularly secondary roads, this being identified as one of Bucharest's main infrastructural problems. There has been a comprehensive effort on behalf of the City Hall to boost road infrastructure and according to the general development plan, 2,000 roads have been repaired by 2008. On 17 June 2011, the Basarab Overpass was inaugurated and opened to traffic, thus completing the inner city traffic ring. The overpass took 5 years to build and is the longest cable-stayed bridge in Romania and the widest such bridge in Europe; upon completion, traffic on the Grant Bridge and in the Gara de Nord area became noticeably more fluid.
Water.
Although it is situated on the banks of a river, Bucharest has never functioned as a port city, with other Romanian cities such as Constanța and Galați acting as the country's main ports. The unfinished Danube-Bucharest Canal, which is 73 km long and approximately 70% completed, could link Bucharest to the Danube River and, via the Danube-Black Sea Canal, to the Black Sea. Works on the canal were suspended in 1989, but there have been proposals to resume construction as part of the European Strategy for the Danube Region.
Culture.
Bucharest has a growing cultural scene, in fields including the visual arts, performing arts and nightlife. Unlike other parts of Romania, such as the Black Sea coast or Transylvania, Bucharest's cultural scene has no defined style, and instead incorporates elements of Romanian and international culture.
Landmarks.
Bucharest has landmark buildings and monuments. Perhaps the most prominent of these is the Palace of the Parliament, built in the 1980s during the reign of Communist dictator Nicolae Ceaușescu. The largest Parliament building in the world, the Palace houses the Romanian Parliament (the Chamber of Deputies and the Senate), as well as the National Museum of Contemporary Art. The building boasts one of the largest convention centres in the world.
Another landmark in Bucharest is Arcul de Triumf (The Triumphal Arch), built in its current form in 1935 and modeled after the Arc de Triomphe in Paris. A newer landmark of the city is the Memorial of Rebirth, a stylized marble pillar unveiled in 2005 to commemorate the victims of the Romanian Revolution of 1989, which overthrew Communism. The abstract monument sparked controversy when it was unveiled, being dubbed with names such as "the olive on the toothpick", ("măslina-n scobitoare"), as many argued that it does not fit in its surroundings and believed that its choice was based on political reasons.
The Romanian Athenaeum building is considered to be a symbol of Romanian culture and since 2007 is on the list of the Label of European Heritage sights.
InterContinental Bucharest is a highrise five star hotel situated near University Square and is also a landmark of the city. The building is designed so that each room has a unique panorama of the city.
Other cultural venues include the National Museum of Art of Romania, Museum of Natural History "Grigore Antipa", Museum of the Romanian Peasant ("Muzeul țăranului Român"), National History Museum, and the Military Museum.
Visual arts.
In terms of visual arts, the city has museums featuring both classical and contemporary Romanian art, as well as selected international works. The National Museum of Art of Romania is perhaps the best-known of Bucharest museums. It is located in the royal palace and features collections of medieval and modern Romanian art, including works by sculptor Constantin Brâncuși, as well as an international collection assembled by the Romanian royal family.
Other, smaller, museums contain specialised collections. The Zambaccian Museum, which is situated in the former home of art collector Krikor H. Zambaccian contains works by well-known Romanian artists as well as international artists such as Paul Cézanne, Eugène Delacroix, Henri Matisse, Camille Pissarro and Pablo Picasso.
The Gheorghe Tattarescu Museum contains portraits of Romanian revolutionaries in exile such as Gheorghe Magheru, ștefan Golescu, Nicolae Bălcescu and allegorical compositions with revolutionary ("Romania's rebirth", 1849) and patriotic ("The Principalities' Unification", 1857) themes.
The Theodor Pallady Museum is situated in one of the oldest surviving merchant houses in Bucharest and includes works by Romanian painter Theodor Pallady as well as European and oriental furniture pieces.
The Museum of Art Collections contains the collections of Romanian art aficionados, including Krikor Zambaccian and Theodor Pallady.
Despite the classical art galleries and museums in the city, there is also a contemporary arts scene. The National Museum of Contemporary Art (MNAC), situated in a wing of the Palace of the Parliament, was opened in 2004 and contains Romanian and international contemporary art. The MNAC also manages the Kalinderu MediaLab, which caters to multimedia and experimental art. There are also private art galleries throughout the city centre.
The palace of the National Bank of Romania houses the national numismatic collection. Exhibits include banknotes, coins, documents, photographs, maps, silver and gold bullion bars, bullion coins, dies and moulds. The building was constructed between 1884 and 1890. The thesaurus room contains notable marble decorations.
Performing arts.
Performing arts are one of the strongest cultural elements of Bucharest. The most famous symphony orchestra is National Radio Orchestra of Romania. One of the most prominent buildings is the neoclassical Romanian Athenaeum, which was founded in 1852, and hosts classical music concerts, the George Enescu Festival, and is home to the George Enescu Philharmonic Orchestra.
Bucharest is home to the Romanian National Opera, as well as the I.L. Caragiale National Theatre. Another well-known theatre in Bucharest is the State Jewish Theatre, which features plays starring world-renowned Romanian-Jewish actress Maia Morgenstern. Smaller theatres throughout the city cater to specific genres, such as the Comedy Theatre, the Nottara Theatre, the Bulandra Theatre, the Odeon Theatre, and the revue theatre of Constantin Tănase.
Music and nightlife.
Bucharest is home to Romania's largest recording labels, and is often the residence of Romanian musicians. Romanian rock bands of the 1970s and 1980s, such as Iris and Holograf, continue to be popular, particularly with the middle-aged, while since the beginning of the 1990s the hip hop/rap scene has developed. Hip-hop bands and artists from Bucharest such as B.U.G. Mafia, Paraziții, La Familia enjoy national and international recognition.
The pop-rock band Taxi have been gaining international respect, as has Spitalul de Urgență's raucous updating of traditional Romanian music. While many neighbourhood discos play manele, an Oriental- and Roma-influenced genre of music that is particularly popular in Bucharest's working class districts, the city has a rich jazz and blues scene, and, to an even larger extent, house music/trance and heavy metal/punk scenes. Bucharest's jazz profile has especially risen since 2002, with the presence of two venues, Green Hours and Art Jazz, as well as an American presence alongside established Romanians.
There is no central nightlife strip, with entertainment venues dispersed throughout the city, with clusters in Lipscani and Regie. The city hosts some of the best electronic music clubs in Europe such as Kristal Glam Club and Studio Martin. Some other notable venues are Gaia, Bamboo, Fratelli, Kulturhaus and Fabrica.
Cultural events and festivals.
There are a number of cultural festivals in Bucharest throughout the year but most festivals take place in the summer months of June, July and August. The National Opera organises the International Opera Festival every year in May and June, which includes ensembles and orchestras from all over the world.
The Romanian Athaeneum Society hosts the George Enescu Festival at locations throughout the city in September every two years (odd years). The Museum of the Romanian Peasant and the Village Museum organise events throughout the year showcasing Romanian folk arts and crafts.
In the 2000s, due to the growing prominence of the Chinese community in Bucharest, Chinese cultural events took place. The first officially organised Chinese festival was the Chinese New Year's Eve Festival of February 2005 which took place in Nichita Stănescu Park and was organised by the Bucharest City Hall.
In 2005, Bucharest was the first city in Southeastern Europe to host the international CowParade, which resulted in dozens of decorated cow sculptures being placed across the city.
In 2004, Bucharest imposed in the circle of important festivals in Eastern Europe with "BIFF" (abbreviation for "Bucharest International Film Festival"), event widely acknowledged in Europe, having as guests of honor huge names from the world cinema: Andrei Konchalovsky, Danis Tanović, Nikita Mikhalkov, Rutger Hauer, Jerzy Skolimowski, Jan Harlan, Radu Mihăileanu and many others.
Since 2005 Bucharest has its own contemporary art biennale, the Bucharest Biennale.
Traditional culture.
Traditional Romanian culture continues to have a major influence in arts such as theatre, film and music. Bucharest has two internationally renowned ethnographic museums, the Museum of the Romanian Peasant and the open-air Village Museum.
The Dimitrie Gusti National Village Museum, in Herăstrău Park, contains 272 authentic buildings and peasant farms from all over Romania.
The Museum of the Romanian Peasant was declared the European Museum of the Year in 1996. Patronized by the Ministry of Culture, the museum preserves and exhibits numerous collections of objects and monuments of material and spiritual culture. The Museum of the Romanian Peasant holds one of the richest collections of peasant objects in Romania, its heritage being nearly 90,000 pieces, those being divided into several collections: ceramics, costumes, textiles, wooden objects, religious objects, customs etc.
The Museum of Romanian History is another important museum in Bucharest, containing a collection of artefacts detailing Romanian history and culture from the prehistoric times, Dacian era, medieval times and the modern era.
Religious life.
Bucharest is the seat of the Patriarch of the Romanian Orthodox Church, one of the Eastern Orthodox churches in communion with the Patriarch of Constantinople, and also of its subdivisions, the Metropolis of Muntenia and Dobrudja and the Archbishopric of Bucharest. Orthodox believers consider Demetrius Basarabov to be the patron saint of the city.
The city is a center for other religious organizations in Romania, including the Roman Catholic Archdiocese of Bucharest, established in 1883, and the Romanian Greek-Catholic Eparchy of Saint Basil the Great, founded in 2014.
Architecture.
The city centre is a mixture of medieval, neoclassical and art nouveau buildings, as well as 'neo-Romanian' buildings dating from the beginning of the 20th century and a collection of modern buildings from the 1920s and 1930s. The mostly utilitarian Communist-era architecture dominates most southern boroughs. Recently built contemporary structures such as skyscrapers and office buildings complete the landscape.
Historical architecture.
Of the city's medieval architecture, most of what survived into modern times was destroyed by Communist systematization, fire and military incursions. Some medieval and renaissance edifices remain, the most notable are in the Lipscani area. This precinct contains notable buildings such as Manuc's Inn ("Hanul lui Manuc") and the ruins of the Old Court ("Curtea Veche"), during the late Middle Ages this area was the heart of commerce in Bucharest. From the 1970s onwards, the area went through urban decline, and many historical buildings fell into disrepair. In 2005, the Lipscani area was pedestrianised and is undergoing restoration. 
The city centre has retained architecture from the late 19th and early 20th centuries, particularly the interwar period, which is often seen as the "golden age" of Bucharest architecture. During this time, the city grew in size and wealth therefore seeking to emulate other large European capitals such as Paris. Much of the architecture of the time belongs to a Modern (rationalist) Architecture current, led by Horia Creangă and Marcel Iancu.
In Romania, the tendencies of innovation in the architectural language met the need of valorisation and affirmation of the national cultural identity. The Art Nouveau movement finds expression through new architectural style initiated by Ion Mincu and taken over by other prestigious architects that capitalize important references of Romanian laic and medieval ecclesiastical architecture (for example the Mogoșoaia Palace, the Stavropoleos Church or the disappeared church of Văcărești Monastery) and Romanian folk motifs.
Two notable buildings from this time are the Crețulescu Palace, housing cultural institutions including UNESCO's European Centre for Higher Education, and the Cotroceni Palace, the residence of the Romanian President. Many large-scale constructions such as Gara de Nord, the busiest railway station in the city, National Bank of Romania's headquarters and the Telephone Palace date from these times. In the 2000s, historic buildings in the city centre underwent restoration. In some residential areas of the city, particularly in high-income central and northern districts, there are turn of the 20th century villas, most of which were restored beginning in the late 1990s.
Communist architecture.
A major part of Bucharest's architecture is made up of buildings constructed during the Communist era replacing the historical architecture with high density apartment blocks – significant portions of the historic center of Bucharest were demolished in order to construct one of the largest buildings in the world, the Palace of the Parliament (then officially called the House of the Republic). In Nicolae Ceaușescu's project of systematization new buildings were built in previously historical areas, which were razed and then built upon.
One of the singular examples of this type of architecture is Centrul Civic, a development that replaced a major part of Bucharest's historic city centre with giant utilitarian buildings, mainly with marble or travertine façades, inspired by North Korean architecture. Communist-era architecture can also be found in Bucharest's residential districts, mainly in "blocuri", which are high-density apartment blocks that house the majority of the city's population.
Contemporary architecture.
Since the fall of Communism in 1989, several Communist-era buildings have been refurbished, modernised and used for other purposes. Perhaps the best example of this is the conversion of obsolete retail complexes into shopping malls and commercial centres. These giant circular halls, which were unofficially called hunger circuses due to the food shortages experienced in the 1980s, were constructed during the Ceaușescu era to act as produce markets and refectories, although most were left unfinished at the time of the Revolution.
Modern shopping malls like Unirea Shopping Center, Bucharest Mall, Plaza Romania and City Mall emerged on pre-existent structures of former hunger circuses. Another example is the conversion of a large utilitarian construction in Centrul Civic into a Marriott Hotel. This process was accelerated after 2000, when the city underwent a property boom, and many Communist-era buildings in the city centre became prime real estate due to their location. Many Communist-era apartment blocks have also been refurbished to improve urban appearance.
The newest contribution to Bucharest's architecture took place after the fall of Communism, particularly after 2000, when the city went through a period of urban renewal – and architectural revitalization – on the back of Romania's economic growth. Buildings from this time are mostly made of glass and steel, and often have more than ten storeys. Examples include shopping malls (particularly the Bucharest Mall, a conversion and extension of an abandoned building), office buildings, bank headquarters, etc. 
As of 2005, there are office buildings under construction, particularly in the northern and eastern parts of the city. Additionally, there has been a trend to add modern wings and façades to historic buildings, the most prominent example of which is the Bucharest Architects' Association Building, which is a modern glass-and-steel construction built inside a historic stone façade. In 2013, the Bucharest skyline enriched with a 137 meters high office building ("SkyTower" of Floreasca City Center), currently the tallest building in Romania. Despite this development on vertical, the Romanian architects avoid designing tall buildings due to vulnerability to earthquakes.
Aside from buildings used for business and institutions, residential developments are underway, many of which consist of high-rise office buildings and suburban residential communities. These developments are increasingly prominent in northern Bucharest, which is less densely populated and is home to middle- and upper-class Bucharesters due to the process of gentrification.
Media.
Bucharest is headquarters of most of the national television networks as well as national newspapers, radio stations and online news websites. The largest daily newspapers in Bucharest include "Evenimentul Zilei", "Jurnalul Național", "Cotidianul", "România Liberă", "Adevărul", while the biggest news websites are Hotnews.ro (with an English and Spanish version), and "Gândul". During the rush hours, tabloid newspapers "Click!", "Libertatea" and "Cancan" are popular for commuters.
A number of newspapers and media publications are based in Casa Presei Libere (The House of the Free Press), a landmark of northern Bucharest, originally named Casa Scânteii after the Communist Romania-era official newspaper "Scînteia". Casa Presei Libere is not the only Bucharest landmark that grew out of the media and communications industry. Palatul Telefoanelor ("The Telephone Palace") was the first major modernist building on Calea Victoriei in the city's centre, and the massive, unfinished communist-era Casa Radio looms over a park a block away from the Opera.
English-language newspapers first became available in the early 1930s and reappeared in the 1990s. There are two daily English-language newspapers, "Bucharest Daily News" and "Nine O' Clock", as well as magazines. Publications in other languages are available, such as the Hungarian-language daily "Új Magyar Szó".
"Observator Cultural" covers the city's arts, and the free weekly magazines "șapte Seri" ("Seven Evenings") and "B24FUN", list entertainment events. The city is home to the intellectual journal "Dilema veche" and the satire magazine "Academia Cațavencu". Bucharest was the host city of the fourth edition of the Junior Eurovision Song Contest in 2006.
Education.
There are 16 public universities in Bucharest, the largest of which are the University of Bucharest, the Bucharest Academy of Economic Studies, the Carol Davila University of Medicine and Pharmacy, and the Politehnica University of Bucharest. These are supplemented by 19 private universities, such as the Romanian-American University and Spiru Haret University, the latter being the largest in Europe with some 302,000 enrolled students in 2009.
Overall, there are 159 faculties in 34 universities. Private universities, however, have a mixed reputation due to irregularities in the educational process as well as perceived corruption. As in the rest of Romania, universities in Bucharest are lower rated internationally, in comparison to their American and Western European counterparts.
Nevertheless, the University of Bucharest was included in the 2012 QS World University Rankings Top 200 universities of the world (151–200 band). Also, in recent years the city has seen increasing numbers of foreign students enrolling in its universities.
The first modern educational institution was the Princely Academy of Bucharest, founded in 1694 and divided in 1864 to form the present-day University of Bucharest and the Saint Sava National College, both of which are among the most prestigious of their kind in Romania.
There are over 450 public primary and secondary schools in the city, all of which are administered by the Bucharest Municipal Schooling Inspectorate. Each sector also has its own Schooling Inspectorate, subordinated to the municipal one.
Healthcare.
One of the most modern hospitals in the capital is Colțea that has been re-equipped after a 90-million-euro investment in 2011. It specializes in oncological and cardiac disorders. Also the oldest hospital in Bucharest, Coltea Hospital was built by Mihai Cantacuzino between 1701 and 1703, composed of many buildings, each with 12 to 30 beds, a church, three chapels, a school, and doctors' and teachers' houses.
Another conventional hospital is Pantelimon which was established in 1733 by Grigore II Ghica. The surface area of the hospital land property was 400000 m². The hospital had in its inventory a house for infectious diseases and a house for persons with disabilities.
Other hospitals or clinics are Bucharest Emergency Hospital, Floreasca Emergency Clinic Hospital, Bucharest University Emergency Hospital and Fundeni Clinical Institute or Biomedica International and Euroclinic, which are private.
Sports.
Football is the most widely followed sport in Bucharest, with the city having numerous club teams, some of them being known throughout Europe: Steaua, Dinamo or Rapid.
Arena Națională, a new stadium inaugurated on 6 September 2011, hosted the 2012 Europa League Final. and has a 55,600 seats capacity, making it one of the largest stadiums in Southeastern Europe.
There are sport clubs for ice hockey, rugby union, basketball, handball, water polo and volleyball. The majority of Romanian track and field athletes and most gymnasts are affiliated with clubs in Bucharest. The Athletics and many Gymnastics National Championships are held in Bucharest at the Polyvalent Hall, which is also used for other indoor sports such as volleyball and handball.
The largest indoor arena in Bucharest is the Romexpo Dome with a seating capacity of 10,000. It is used for tennis, boxing and kickboxing.
Starting in 2007 Bucharest has hosted annual races along a temporary urban track surrounding the Palace of the Parliament, called Bucharest Ring. The competition is called the Bucharest City Challenge, and has hosted FIA GT, FIA GT3, British F3, and Logan Cup races in 2007 and 2008. The 2009 and 2010 edition have not been held in Bucharest due to a lawsuit. Bucharest GP, owned by the controversial businessman Nicolae șerbu, won the lawsuit that it initiated and will host city races around the Parliament starting 2011 with the Auto GP.
Every year, Bucharest hosts BRD Năstase Țiriac Trophy international tennis tournament, which is included in the ATP Tour. The outdoors tournament is hosted by the tennis complex BNR Arenas. The ice hockey games are held at the Mihai Flamaropol Arena, which holds 8,000 spectators. The rugby games are held in different locations, but the most modern stadium is Arcul de Triumf Stadium, where also the Romanian national rugby team plays.
Twin towns and sister cities.
The twin towns and sister cities of Bucharest are listed below:

</doc>
<doc id="36880" url="http://en.wikipedia.org/wiki?curid=36880" title="Nuclear warfare">
Nuclear warfare

Nuclear warfare (sometimes atomic warfare or thermonuclear warfare) is a military conflict or political strategy in which nuclear weaponry is used to inflict damage on the enemy. Compared to conventional warfare, nuclear warfare can be vastly more destructive in range and extent of damage, and in a much shorter time. A major nuclear exchange would have long-term effects, primarily from the fallout released, and could also lead to a "nuclear winter" that could last for decades, centuries, or even millennia after the initial attack. Some analysts claim that with this potential nuclear winter side-effect of a nuclear war almost every human on Earth could starve to death. Other analysts, who dismiss the nuclear winter hypothesis, calculate that with nuclear weapon stockpiles at Cold War highs, in a surprise countervalue global nuclear war, billions of casualties would have resulted but billions of people would nevertheless have survived.
Only two nuclear weapons have been used in the course of warfare, both by the United States near the end of World War II. On August 6, 1945, a uranium gun-type device (code name "Little Boy") was detonated over the Japanese city of Hiroshima. Three days later, on August 9, a plutonium implosion-type device (code name "Fat Man") was detonated over the Japanese city of Nagasaki. These two bombings resulted in the deaths of approximately 129,000 civilians and military personnel.
After World War II, nuclear weapons were also developed by the Soviet Union (1949), the United Kingdom (1952), France (1960), and the People's Republic of China (1964), which contributed to the state of conflict and extreme tension that became known as the Cold War. In 1974, India, and in 1998, Pakistan, two countries that were openly hostile toward each other, developed nuclear weapons. Israel (1960s) and North Korea (2006) are also thought to have developed stocks of nuclear weapons, but their governments have never admitted to having nuclear weapons. South Africa also manufactured several complete nuclear weapons in the 1980s, but subsequently became the first country to voluntarily destroy their domestically made weapons stocks and abandon further production (1990s).
Nuclear weapons have been detonated on over two thousand occasions for testing purposes and demonstrations.
After the collapse of the Soviet Union in 1991 and the resultant end of the Cold War, the threat of a major nuclear war between the two nuclear superpowers was generally thought to have declined. Since then, concern over nuclear weapons has shifted to the prevention of localized nuclear conflicts resulting from nuclear proliferation, and the threat of nuclear terrorism.
Types of nuclear warfare.
The possibility of using nuclear weapons in war is usually divided into two subgroups, each with different effects and potentially fought with different types of nuclear armaments.
The first, a "limited nuclear war" (sometimes "attack" or "exchange"), refers to a small-scale use of nuclear weapons by two (or more) belligerents. A "limited nuclear war" could include targeting military facilities—either as an attempt to pre-emptively cripple the enemy's ability to attack as a defensive measure, or as a prelude to an invasion by conventional forces, as an offensive measure. This term could apply to "any" small-scale use of nuclear weapons that may involve military or civilian targets (or both). 
The second, a "full-scale nuclear war", could consist of large numbers of nuclear weapons used in an attack aimed at an entire country, including military, economic, and civilian targets. Such an attack would almost certainly destroy the entire economic, social, and military infrastructure of the target nation, and would probably have a devastating effect on Earth's biosphere.
Some Cold War strategists such as Henry Kissinger argued that a limited nuclear war "could" be possible between two heavily armed superpowers (such as the United States and the Soviet Union). Some predict, however, that a limited war could potentially "escalate" into a full-scale nuclear war. Others have called limited nuclear war "global nuclear holocaust in slow motion", arguing that—once such a war took place—others would be sure to follow over a period of decades, effectively rendering the planet uninhabitable in the same way that a "full-scale nuclear war" between superpowers would, only taking a much longer (and arguably more agonizing) path to the same result.
Even the most optimistic predictions of the effects of a major nuclear exchange foresee the death of many millions of victims within a very short period of time. More pessimistic predictions argue that a full-scale nuclear war could potentially bring about the extinction of the human race, or at least its "near" extinction, with only a relatively small number of survivors (mainly in remote areas) and a reduced quality of life and life expectancy for centuries afterward. However, such predictions, assuming total war with nuclear arsenals at Cold war highs, have not been without criticism. Such a horrific catastrophe as global nuclear warfare would almost certainly cause permanent damage to most complex life on the planet, its ecosystems, and the global climate. If predictions about the production of a nuclear winter are accurate, it would also change the balance of global power, with countries such as Australia, New Zealand, India, China, Argentina and Brazil predicted to become world superpowers if the Cold war ever led to a large-scale nuclear attack.
A study presented at the annual meeting of the American Geophysical Union in December 2006 asserted that even a small-scale regional nuclear war could produce as many direct fatalities as all of World War II and disrupt the global climate for a decade or more. In a regional nuclear conflict scenario in which two opposing nations in the subtropics each used 50 Hiroshima-sized nuclear weapons (c. 15 kiloton each) on major population centers, the researchers predicted fatalities ranging from 2.6 million to 16.7 million per country. The authors of the study estimated that as much as five million tons of soot could be released, producing a cooling of several degrees over large areas of North America and Eurasia (including most of the grain-growing regions). The cooling would last for years and could be "catastrophic", according to the researchers.
Either a limited or full-scale nuclear exchange could occur during an "accidental nuclear war", in which the use of nuclear weapons is triggered unintentionally. Postulated triggers for this scenario have included malfunctioning early warning devices and/or targeting computers, deliberate malfeasance by rogue military commanders, consequences of an accidental straying of warplanes into enemy airspace, reactions to unannounced missile tests during tense diplomatic periods, reactions to military exercises, mistranslated or miscommunicated messages, and others. A number of these scenarios actually occurred during the Cold War, though none resulted in the use of nuclear weapons. Many such scenarios have been depicted in popular culture, such as in the 1962 novel "Fail-Safe" (released as a film in 1964), the film "WarGames", released in 1983 and the film "", also released in 1964.
History.
1940s.
Atomic bombings of Hiroshima and Nagasaki.
During the final stages of World War II in 1945, the United States conducted atomic raids on the Japanese cities of Hiroshima and Nagasaki, the first on August 6, 1945, and the second on August 9, 1945. These two events are the only time nuclear weapons have been used in combat to date.
For six months before the atomic bombings, the U.S. 20th Air Force under General Curtis LeMay executed low-level incendiary raids against Japanese cities. The worst air raid to occur during the process was not the nuclear attacks but the "Operation Meetinghouse" raid on Tokyo. On the night of March 9–10, 1945, "Operation Meetinghouse" commenced and 334 B-29 Superfortress bombers took off to raid with 279 of them dropping 1,665 tons of incendiaries and explosives on Tokyo. The bombing was meant to burn wooden buildings and indeed the bombing caused fire that created a 50 m/s wind that is comparable to tornadoes. Each bomber carried 6 tons of bombs. A total of 381,300 bombs, which amount to 1,783 tons of bombs, were used in the bombing. Within a few hours of the raid, it killed an estimated 100,000 people and destroyed 41 km2 of the city and 267,000 buildings in a single night — the deadliest bombing raid in military aviation history other than the atomic raids on Hiroshima and Nagasaki. By early August 1945, an estimated 450,000 people died as the U.S. intensely firebombed a total of 67 Japanese cities.
In late June 1945, as the U.S. wrapped up the two and a half month Battle of Okinawa (which cost the lives of 260,000 people, including 150,000 civilians), it was faced with the prospect of invading the Japanese home islands in an operation code named Operation Downfall. Based on the U.S. casualties from the preceding island-hopping campaigns, American commanders estimated that between 50,000-500,000 U.S. troops would die and at least 600,000-1,000,000 others injured while invading the Japanese home islands. The U.S. manufacture of 500,000 Purple Hearts from the anticipated high level of casualties during the U.S. invasion of Japan gave a demonstration of how deadly and costly it would be. President Harry S. Truman realized he could not afford such a horrendous casualty rate, let alone the fact that over 400,000 American servicemen died fighting in both the European and the Pacific theaters of the war.
On July 26, 1945, the United States, United Kingdom, and the Republic of China issued a Potsdam Declaration that called for the unconditional surrender of Japan. It stated that if Japan did not surrender, it would face "prompt and utter destruction." The Japanese government ignored this ultimatum, sending a message that they were not going to surrender. In response to the rejection, President Truman issued an executive order ordering the U.S. military to employ atomic bombs against enemy targets. At the time of its use, there were only two atomic bombs available, and despite the fact more were in production back in mainland U.S., the third bomb wouldn't be available for combat use until September.
On August 6, 1945, the uranium-type nuclear weapon code named "Little Boy" was detonated over the Japanese city of Hiroshima with an energy of about 15 ktonTNT, destroying nearly 50,000 buildings (including the headquarters of the 2nd General Army and Fifth Division) and killing approximately 70,000 people, including 20,000 Japanese soldiers and 20,000 Koreans. Three days later, on August 9, a plutonium-type nuclear weapon code named "Fat Man" was used against the Japanese city of Nagasaki with the explosion equivalent to about 20 ktonTNT, destroying 60% of the city and killing approximately 35,000 people, including 23,200-28,200 Japanese civilian munitions workers and 150 Japanese soldiers. The industrial damage in Nagasaki was high, partly owing to the inadvertent targeting of the industrial zone, leaving 68-80 percent of the non-dock industrial production destroyed.
Six days after the detonation over Nagasaki, Japan announced its surrender to the Allied Powers on August 15, 1945, signing the Instrument of Surrender on September 2, 1945, officially ending the Pacific War and, therefore, World War II, as Germany had already signed its Instrument of Surrender on May 7, 1945, ending the war in Europe. The two atomic bombings led, in part, to post-war Japan's adopting of the Three Non-Nuclear Principles, which forbade the nation from developing nuclear armaments.
Immediately after the Japan bombings.
Immediately after the atomic bombings of Japan, the status of atomic weapons in international and military relations was unclear. Presumably, the United States hoped atomic weapons could offset the Soviet Union's larger conventional ground forces in Eastern Europe, and possibly be used to pressure Soviet leader Joseph Stalin into making concessions. Under Stalin, the Soviet Union pursued its own atomic capabilities through a combination of scientific research and espionage directed against the American program. The Soviets believed that the Americans, with their limited nuclear arsenal, were unlikely to engage in any new world wars, while the Americans were not confident they could prevent a Soviet takeover of Europe, despite their atomic advantage.
Within the United States the authority to produce and develop nuclear weapons was removed from military control and put instead under the civilian control of the United States Atomic Energy Commission. This decision reflected an understanding that nuclear weapons had unique risks and benefits that were separate from other military technology known at the time.
For several years after World War II, the United States developed and maintained a strategic force based on the Convair B-36 bomber that would be able to attack any potential enemy from bomber bases in the United States. It deployed atomic bombs around the world for potential use in conflicts. Over a period of a few years, many in the American defense community became increasingly convinced of the invincibility of the United States to a nuclear attack. Indeed, it became generally believed that the threat of nuclear war would deter any strike against the United States.
Many proposals were suggested to put all American nuclear weapons under international control (by the newly formed United Nations, for example) as an effort to deter both their usage and an arms race. However, no terms could be arrived at that would be agreed upon by both the United States and the Soviet Union.
On August 29, 1949, the Soviet Union tested its first nuclear weapon at Semipalatinsk in Kazakhstan (see also Soviet atomic bomb project). Scientists in the United States from the Manhattan Project had warned that, in time, the Soviet Union would certainly develop nuclear capabilities of its own. Nevertheless, the effect upon military thinking and planning in the United States was dramatic, primarily because American military strategists had not anticipated the Soviets would "catch up" so soon. However, at this time, they had not discovered that the Soviets had conducted significant nuclear espionage of the project from spies at Los Alamos, the most significant of which was done by the theoretical physicist Klaus Fuchs. The first Soviet bomb was more or less a deliberate copy of the Fat Man plutonium device.
With the monopoly over nuclear technology broken, worldwide nuclear proliferation accelerated. The United Kingdom tested its first independent atomic bomb in 1952, followed by France in 1960 and then China in 1964. While much smaller than the arsenals of the United States and the Soviet Union, Western Europe's nuclear reserves were nevertheless a significant factor in strategic planning during the Cold War. A top-secret White Paper, compiled by the Royal Air Force and produced for the British Government in 1959, estimated that British bombers carrying nuclear weapons were capable of destroying key cities and military targets in the Soviet Union, with an estimated 16 million deaths in the Soviet Union (half of whom were estimated to be killed on impact and the rest fatally injured) "before" bomber aircraft from the U.S. Strategic Air Command reached their targets.
After the successful Trinity nuclear test July 16, 1945, which was the very first nuclear detonation, the Manhattan project lead manager J. Robert Oppenheimer recalled:
We knew the world would not be the same. A few people laughed, a few people cried, most people were silent. I remembered the line from the Hindu scripture the "Bhagavad Gita". Vishnu is trying to persuade the prince that he should do his duty and to impress him takes on his multiarmed form and says, "Now, I am become Death, the destroyer of worlds." I suppose we all thought that one way or another."—J. Robert Oppenheimer, "The Decision To Drop The Bomb"
1950s.
Although the Soviet Union had nuclear weapon capabilities in the beginning of the Cold War, the United States still had an advantage in terms of bombers and weapons. In any exchange of hostilities, the United States would have been capable of bombing the Soviet Union, whereas the Soviet Union would have more difficulty carrying out the reverse mission.
The widespread introduction of jet-powered interceptor aircraft upset this imbalance somewhat by reducing the effectiveness of the American bomber fleet. In 1949 Curtis LeMay was placed in command of the Strategic Air Command and instituted a program to update the bomber fleet to one that was all-jet. During the early 1950s the B-47 and B-52 were introduced, providing the ability to bomb the Soviet Union more easily.
Before the development of a capable strategic missile force in the Soviet Union, much of the war-fighting doctrine held by western nations revolved around using a large number of smaller nuclear weapons used in a tactical role. It is debatable whether such use could be considered "limited" however, because it was believed that the United States would use its own strategic weapons (mainly bombers at the time) should the Soviet Union deploy any kind of nuclear weapon against civilian targets. Douglas MacArthur, an American general, was fired by President Harry Truman, partially because he persistently requested permission to use his own discretion in deciding whether to use atomic weapons on the People's Republic of China in 1951 during the Korean War. Mao Zedong, China's communist leader, gave the impression that he would welcome a nuclear war with the capitalists because it would annihilate what he viewed as their "imperialist" system.
Let us imagine how many people would die if war breaks out. There are 2.7 billion people in the world, and a third could be lost. If it is a little higher it could be half ... I say that if the worst came to the worst and one-half dies, there will still be one-half left, but imperialism would be razed to the ground and the whole world would become socialist. After a few years there would be 2.7 billion people again.— Mao Zedong, 1957 
The concept of a "Fortress North America" emerged during the Second World War and persisted into the Cold War to refer to the option of defending Canada and the United States against their enemies if the rest of the world were lost to them. This option was rejected with the formation of NATO and the decision to permanently station troops in Europe.
In the summer of 1951 Project Vista started, in which project analysts such as Robert F. Christy looked at how to defend Western Europe from a Soviet invasion. The emerging development of tactical nuclear weapons were looked upon as a means to give Western forces a qualitative advantage over the Soviet numerical supremacy in conventional weapons.
Several scares about the increasing ability of the Soviet Union's strategic bomber forces surfaced during the 1950s. The defensive response by the United States was to deploy a fairly strong "layered defense" consisting of interceptor aircraft and anti-aircraft missiles, like the Nike, and guns, like the Skysweeper, near larger cities. However, this was a small response compared to the construction of a huge fleet of nuclear bombers. The principal nuclear strategy was to massively penetrate the Soviet Union. Because such a large area could not be defended against this overwhelming attack in any credible way, the Soviet Union would lose any exchange.
This logic became ingrained in American nuclear doctrine and persisted for much of the duration of the Cold War. As long as the strategic American nuclear forces could overwhelm their Soviet counterparts, a Soviet pre-emptive strike could be averted. Moreover, the Soviet Union could not afford to build any reasonable counterforce, as the economic output of the United States was far larger than that of the Soviets, and they would be unable to achieve "nuclear parity".
Soviet nuclear doctrine, however, did not match American nuclear doctrine. Soviet military planners assumed they could win a nuclear war. Therefore, they "expected" a large-scale nuclear exchange, followed by a "conventional war" which itself would involve heavy use of tactical nuclear weapons. American doctrine rather assumed that Soviet doctrine was similar, with the "mutual" in Mutually Assured Destruction necessarily requiring that the other side see things in much the same way, rather than believing—as the Soviets did—that they could fight a large-scale, "combined nuclear and conventional" war.
In accordance with their doctrine, the Soviet Union conducted large-scale military exercises to explore the possibility of defensive and offensive warfare during a nuclear war. The exercise, under the code name of "Snowball", involved the detonation of a nuclear bomb about twice as powerful as that which fell on Nagasaki and an army of approximately 45,000 soldiers on maneuvers through the hypocenter immediately after the blast. The exercise was conducted on September 14, 1954, under command of Marshal Georgy Zhukov to the north of Totskoye village in Orenburg Oblast, Russia.
A revolution in nuclear strategic thought occurred with the introduction of the intercontinental ballistic missile (ICBM), which the Soviet Union first successfully tested in August 1957. In order to deliver a warhead to a target, a missile was much faster and more cost-effective than a bomber, and enjoyed a higher survivability due to the enormous difficulty of interception of the ICBMs (due to their high altitude and extreme speed). The Soviet Union could now afford to achieve nuclear parity with the United States in raw numbers, although for a time, they appeared to have chosen not to.
Photos of Soviet missile sites set off a wave of panic in the U.S. military, something the launch of Sputnik would do for the American public a few months later. Politicians, notably then-U.S. Senator John F. Kennedy suggested that a "missile gap" existed between the Soviet Union and the United States. The US military gave missile development programs the highest national priority, and several spy aircraft and reconnaissance satellites were designed and deployed to observe Soviet progress.
Early ICBMs and bombers were relatively inaccurate, which led to the concept of countervalue strikes — attacks directly on the enemy population, which would theoretically lead to a collapse of the enemy's will to fight. During the Cold War, the Soviet Union invested in extensive protected civilian infrastructure, such as large "nuclear-proof" bunkers and non-perishable food stores. By comparison, smaller scale civil defense programs were instituted in the United States starting in the 1950s, where schools and other public buildings had basements stocked with non-perishable food supplies, canned water, first aid, and dosimeter and Geiger counter radiation-measuring devices. Many of the locations were given "Fallout Shelter" designation signs. CONELRAD radio information systems were adopted, whereby the commercial radio sector (later supplemented by the National Emergency Alarm Repeaters) would broadcast on two AM frequencies in the event of a Civil Defense (CD) emergency. These two frequencies-640 and 1240 marked with small CD triangles on the tuning dial can still be seen on 1950s-vintage radios on online auction sites and museums. A few backyard fallout shelters were built by private individuals.
1960s.
In 1960, the United States developed its first Single Integrated Operational Plan, a range of targeting options, and described launch procedures and target sets against which nuclear weapons would be launched, variants of which were in use from 1961 to 2003. That year also saw the start of the Missile Defense Alarm System, an American system of 12 early-warning satellites that provided limited notice of Soviet intercontinental ballistic missile launches between 1960 and 1966. The Ballistic Missile Early Warning System was completed in 1964.
A complex and worrisome situation developed in 1962, in what is called the Cuban Missile Crisis. The Soviet Union placed medium-range ballistic missiles 90 mi from the United States, possibly as a direct response to American Jupiter missiles placed in Turkey. After intense negotiations, the Soviets ended up removing the missiles from Cuba and decided to institute a massive weapons-building program of their own. In exchange, the United States dismantled its launch sites in Turkey, although this was done secretly and not publicly revealed for over two decades. Khrushchev did not even reveal this part of the agreement when he came under fire by political opponents for mishandling the crisis. Communication delays during the crisis led to the establishment of the Moscow–Washington hotline to allow reliable, direct communications between the two nuclear powers.
By the late 1960s, the number of ICBMs and warheads was so high on both sides that it was believed that both the United States and the Soviet Union were capable of completely destroying the infrastructure and a large proportion of the population of the other country. Thus, by some western game theorists, a balance of power system known as mutually assured destruction (or "MAD") came into being. It was thought that no full-scale exchange between the powers would result in an outright winner, with at best one side emerging the pyrrhic victor. Thus both sides were deterred from risking the initiation of a direct confrontation, instead being forced to engage in lower intensity proxy wars.
During this decade the Peoples Republic of China began to build subterranean infrastructure such as the Underground Project 131 following the Sino-Soviet split.
One drawback of the MAD doctrine was the possibility of a nuclear war occurring without either side intentionally striking first. Warning system\Early Warning Systems (EWS) were notoriously error-prone. For example, on 78 occasions in 1979 alone, a "missile display conference" was called to evaluate detections that were "potentially threatening to the North American continent". Some of these were trivial errors and were spotted quickly, but several went to more serious levels. On September 26, 1983, Stanislav Petrov received convincing indications of an American first strike launch against the Soviet Union, but positively identified the warning as a false alarm. Though it is unclear what role Petrov's actions played in preventing a nuclear war during this incident, he has been honored by the United Nations for his actions.
Similar incidents happened many times in the United States, due to failed computer chips, misidentifications of large flights of geese, test programs, and bureaucratic failures to notify early warning military personnel of legitimate launches of test or weather missiles. For many years, the U.S. Air Force's strategic bombers were kept airborne on a daily rotating basis "around the clock" (see Operation Chrome Dome), until the number and severity of accidents, the 1968 Thule Air Base B-52 crash in particular, persuaded policymakers it was not worthwhile.
1970s.
By the late 1970s, people in both the United States and the Soviet Union, along with the rest of the world, had been living with the concept of mutual assured destruction (MAD) for about a decade, and it became deeply ingrained into the psyche and popular culture of those countries.
On May 18, 1974, India conducted its first nuclear test in the Pokhran test range. The name of the operation was Smiling Buddha, and India termed the test as a "peaceful nuclear explosion".
The Soviet Duga-3 early warning over-the-horizon radar system was made operational in 1976. The extremely powerful radio transmissions needed for such a system led to much disruption of civilian shortwave broadcasts, earning it the nickname "Russian Woodpecker".
The idea that any nuclear conflict would eventually escalate was a challenge for military strategists. This challenge was particularly severe for the United States and its NATO allies because it was believed (until the 1970s) that a Soviet tank invasion of Western Europe would quickly overwhelm NATO conventional forces, leading to the necessity of the West escalating to the use of tactical nuclear weapons, one of which was the W-70.
This strategy had one major (and possibly critical) flaw, which was soon realized by military analysts but highly underplayed by the U.S. military: conventional NATO forces in the European theatre of war were far outnumbered by similar Soviet and Warsaw Pact forces, and it was assumed that in case of a major Soviet attack (commonly envisioned as the "Red tanks rolling towards the North Sea" scenario) that NATO—in the face of quick conventional defeat—would soon have no other choice but to resort to tactical nuclear strikes against these forces. Most analysts agreed that once the first nuclear exchange had occurred, escalation to global nuclear war would likely become inevitable. The Soviet bloc's vision of an atomic war between NATO and Warsaw Pact forces was simulated in the top secret exercise Seven Days to the River Rhine in 1979. The British government exercised their vision of Soviet nuclear attack with Square Leg in early 1980.
Large hardened nuclear Weapon storage areas were built across European countries in anticipation of local US and European forces falling back as the conventional NATO defense from the Soviet Union, named REFORGER, was believed to only be capable of stalling the Soviets for a short time.
1980s.
In the late 1970s and, particularly, during the early 1980s under U.S. President Ronald Reagan, the United States renewed its commitment to a more powerful military, which required a large increase in spending on U.S. military programs. These programs, which were originally part of the defense budget of U.S. President Jimmy Carter, included spending on conventional and nuclear weapons systems. Under Reagan, defensive systems like the Strategic Defense Initiative were emphasized as well.
Another major shift in nuclear doctrine was the development and the improvement of the submarine-launched, nuclear-armed, ballistic missile, or SLBM. It was hailed by many military theorists as a weapon that would make nuclear war less likely. SLBMs—which can move with "stealth" (greatly lessened detectability) virtually anywhere in the world—give a nation a "second strike" capability (i.e. after absorbing a "first strike"). Before the advent of the SLBM, thinkers feared that a nation might be tempted to initiate a first strike if it felt confident that such a strike would incapacitate the nuclear arsenal of its enemy, making retaliation impossible. With the advent of SLBMs, no nation could be certain that a first strike would incapacitate its enemy's entire nuclear arsenal. To the contrary, it would have to fear a near certain retaliatory second strike from SLBMs. Thus, a first strike was a much less feasible (or desirable) option, and a deliberately initiated nuclear war was thought to be less likely to start.
However, it was soon realized that submarines could approach enemy coastlines undetected and decrease the warning time (the time between detection of the missile launch and the impact of the missile) from as much as half an hour to possibly under three minutes. This effect was especially significant to the United States, Britain and China, whose capitals all lay within 100 miles (160 km) of their coasts. Moscow was much more secure from this type of threat, due to its considerable distance from the sea. This greatly increased the credibility of a "surprise first strike" by one faction and (theoretically) made it possible to knock out or disrupt the chain of command of a target nation before any counterstrike could be ordered (known as a "decapitation strike"). It strengthened the notion that a nuclear war could possibly be "won", resulting not only in greatly increased tensions and increasing calls for fail-deadly control systems, but also in a dramatic increase in military spending. The submarines and their missile systems were very expensive, and one fully equipped nuclear-powered and nuclear-armed missile submarine could cost more than the entire GNP of a developing country. It was also calculated, however, that the greatest cost came in the development of "both" sea- and land-based anti-submarine defenses and in improving and strengthening the "chain of command", and as a result, military spending skyrocketed.
South Africa developed a nuclear weapon capability during the 1970s and early 1980s. It was operational for a brief period before being dismantled in the early 1990s.
According to the 1980 United Nations report "General and Complete Disarmament: Comprehensive Study on Nuclear Weapons: Report of the Secretary-General", it was estimated that there were a total of about 40,000 nuclear warheads in existence at that time, with a potential combined explosive yield of approximately 13,000 megatons.
By comparison, when the volcano Mount Tambora erupted in 1815—turning 1816 into the Year Without A Summer due to the levels of global dimming sulfate aerosols and ash expelled—it exploded with a force of roughly 800 to 1,000 megatons, and ejected 160 km3 of mostly rock/tephra, that included 120 million tonnes of sulfur dioxide as an upper estimate. A larger eruption, approximately 74,000 years ago, in Mount Toba produced 2800 km3 of tephra, forming lake Toba, and produced an estimated 6000 e6t of sulfur dioxide. The explosive energy of the eruption may have been as high as equivalent to 20,000,000 megatons(MT) of TNT, while the asteroid created Chicxulub impact, that is connected with the extinction of the dinosaurs corresponds to at least 70,000,000 MT of energy, which is roughly 7000 times the maximum arsenal of the US and Soviet Union.
However, comparisons with supervolcanos are more misleading than helpful due to the different aerosols released, the likely air burst fuzing height of nuclear weapons and the globally scattered location of these potential nuclear detonations all being in contrast to the singular and subterranean nature of a supervolcanic eruption. Moreover assuming the entire world stockpile of weapons were grouped together, it would be difficult, due to the nuclear fratricide effect, to ensure the individual weapons would go off all at once. Nonetheless, many people believe that a full-scale nuclear war would result, through the nuclear winter effect, in the extinction of the human species, though not all analysts agree on the assumptions that underpin these nuclear winter models.
On Sept. 1, 1983, Korean Air Lines Flight 007 was shot down by Soviet jet fighters. On the 26th, a Soviet early warning station under the command of Stanislav Petrov falsely detected 5 inbound intercontinental ballistic missiles from the US. Petrov correctly assessed the situation as a false alarm, and hence did not report his finding to his superiors. It is quite possible that his actions prevented "World War III", as the Soviet policy at that time was immediate nuclear response upon discovering inbound ballistic missiles.
The world came unusually close to nuclear war when the Soviet Union thought that the NATO military exercise Able Archer 83 was a ruse or "cover up" to begin a nuclear first strike. The Soviets responded by raising readiness and preparing their nuclear arsenal for immediate use. Soviet fears of an attack ceased once the exercise concluded without incident.
Post–Cold War.
Although the dissolution of the Soviet Union ended the Cold War and greatly reduced tensions between the United States and the Russian Federation, the Soviet Union's formal successor state, both countries remained in a "nuclear stand-off" due to the continuing presence of a very large number of deliverable nuclear warheads on both sides. Additionally, the end of the Cold War led the United States to become increasingly concerned with the development of nuclear technology by other nations outside of the former Soviet Union. In 1995, a branch of the U.S. Strategic Command produced an outline of forward-thinking strategies in the document "Essentials of Post–Cold War Deterrence".
In 1996, a Russian continuity of operations facility, Kosvinsky Mountain, which is believed to be a counterpart to the US Cheyenne Mountain Complex, was completed. It was designed to resist US earth-penetrating nuclear warheads, and is believed to host the Russian Strategic Rocket Forces alternate command post, a post for the general staff built to compensate for the vulnerability of older Soviet era command posts in the Moscow region. In spite of this, the primary command posts for the Strategic Rocket Forces remains Kuntsevo in Moscow and the secondary is the Kosvinsky Mountain in the Urals. The timing of the Kosvinsky facilities completion date is regarded as one explanation for U.S. interest in a new nuclear bunker buster/Earth penetrating warhead and the declaration of the deployment of the B-61 mod 11 in 1997, Kosvinksy is protected by about 1000 feet of granite.
As a consequence of the 9/11 attacks on the USA, American forces immediately increased their readiness to the highest level in 28 years, closing the blast doors of the NORAD's Cheyenne Mountain Operations Center for the first time due to a non-exercise event. But unlike similar increases during the Cold War, Russia immediately decided to stand down a large military exercise in the Arctic region, in order to minimize the risk of incidents, rather than following suit.
The former chair of the United Nations disarmament committee stated that there are more than 16,000 strategic and tactical nuclear weapons ready for deployment and another 14,000 in storage, with the U.S. having nearly 7,000 ready for use and 3,000 in storage, and Russia having about 8,500 ready for use and 11,000 in storage. In addition, China is thought to possess about 400 nuclear weapons, Britain about 200, France about 350, India about 80-100, and Pakistan 100-110. North Korea is confirmed as having nuclear weapons, though it is not known how many, with most estimates between 1 and 10. Israel is also widely believed to possess usable nuclear weapons. NATO has stationed about 480 American nuclear weapons in Belgium, the Netherlands, Italy, Germany, and Turkey, and several other nations are thought to be in pursuit of an arsenal of their own.
A key development in nuclear warfare throughout the 2000s and early 2010s is the proliferation of nuclear weapons to the developing world, with India and Pakistan both publicly testing several nuclear devices, and North Korea conducting an underground nuclear test on October 9, 2006. The U.S. Geological Survey measured a 4.2 magnitude earthquake in the area where the North Korean test is said to have occurred. A further test was announced by the North Korean government on May 25, 2009. Iran, meanwhile, has embarked on a nuclear program which, while officially for civilian purposes, has come under close scrutiny by the United Nations and many individual states.
Recent studies undertaken by the CIA cite the enduring India-Pakistan conflict as the one "flash point" most likely to escalate into a nuclear war. During the Kargil War in 1999, Pakistan came close to using its nuclear weapons in case the conventional military situation underwent further deterioration. Pakistan's foreign minister had even warned that it would "use any weapon in our arsenal", hinting at a nuclear strike against India. The statement was condemned by the international community, with Pakistan denying it later on. This conflict remains the only war (of any sort) between two declared nuclear powers. The 2001-2002 India-Pakistan standoff again stoked fears of nuclear war between the two countries. Despite these very serious and relatively recent threats, relations between India and Pakistan have been improving somewhat over the last few years. A bus line directly linking Indian- and Pakistani-administered Kashmir has recently been established. However, with the November 26, 2008 Mumbai terror attacks, India currently will not rule out war with Pakistan.
Another potential geopolitical issue which is considered particularly worrisome by military analysts is a possible conflict between the United States and the People's Republic of China over Taiwan. Although economic forces are thought to have reduced the possibility of a military conflict, there remains concern about the increasing military buildup of China (China is rapidly increasing its naval capacity), and that any move toward Taiwan independence could potentially spin out of control.
Israel is thought to possess somewhere between one hundred and four hundred nuclear warheads. It has been asserted that the submarines which Israel received from Germany have been adapted to carry missiles with nuclear warheads, so as to give Israel a second strike capability. Israel has been involved in wars with its neighbors in the Middle East (and with other "non-state actors") on numerous prior occasions, and its small geographic size and population could mean that, in the event of future wars, the Israeli military might have very little time to react to an invasion or other major threat. Such a situation could escalate to nuclear warfare very quickly in some scenarios.
In the Persian Gulf, Iran appears to many observers to be in the process of developing a nuclear weapon, which has greatly heightened fears of a nuclear conflict and arms races in the Middle East—either with Israel or with one or more Arab states (a "Shia-Sunni" conflict).
On March 7, 2013, North Korea threatened the United States with a pre-emptive nuclear strike. On April 9, North Korea urged foreigners to leave South Korea, stating that both countries were on the verge of nuclear war. On April 12, North Korea stated that a nuclear war was unavoidable. The country declared Japan as its first target.
Sub-strategic use.
The above examples envisage nuclear warfare at a strategic level, i.e. total war. However, nuclear powers have the ability to undertake more limited engagements.
"Sub-strategic use" includes the use of either "low-yield" tactical nuclear weapons, or of variable yield strategic nuclear weapons in a very limited role, as compared to battlefield exchanges of larger-yield strategic nuclear weapons. This was described by the UK Parliamentary Defence Select Committee as "the launch of one or a limited number of missiles against an adversary as a means of conveying a political message, warning or demonstration of resolve". It is believed that all current nuclear weapons states possess tactical nuclear weapons, with the exception of the United Kingdom, which decommissioned its tactical warheads in 1998. However, the UK does possess scalable-yield strategic warheads, and this technology tends to blur the difference between "strategic", "sub-strategic", and "tactical" use or weapons. American, French and British nuclear submarines are believed to carry at least "some" missiles with these types of high-tech warheads for this purpose, potentially allowing a strike as low as one kiloton (or less) against a single target. Only the People's Republic of China and the Republic of India have declarative, unqualified, unconditional "no first use" nuclear weapons policies. India and Pakistan maintain only a credible minimum deterrence.
Commodore Tim Hare, former Director of Nuclear Policy at the British Ministry of Defence, has described "sub-strategic use" as offering the Government "an extra option in the escalatory process before it goes for an all-out strategic strike which would deliver unacceptable damage". However, this sub-strategic capacity has been criticized as potentially increasing the "acceptability" of using nuclear weapons. The related consideration of new generations of limited-yield nuclear weapons by the United States (i.e. "bunker busters") has also alarmed anti-nuclear groups, who believe it will make the use of nuclear weapons "more acceptable" or likely.
Also of note is that the United States adopted a policy in 1996 of allowing the targeting of its nuclear weapons at non-state actors ("terrorists") armed with weapons of mass destruction.
Nuclear terrorism.
Nuclear terrorism by non-state organizations or actors (even individuals) is a largely unknown and understudied factor in nuclear deterrence thinking, as states possessing nuclear weapons are susceptible to retaliation in kind, while sub- or trans-state actors may be less so. The collapse of the Soviet Union has given rise to the possibility that former Soviet nuclear weapons might become available on the black market (so-called 'loose nukes'). While no warheads are known to have been mislaid, it has been alleged that at least some very small or suitcase-size bombs might be unaccounted for.
A number of other concerns have been expressed about the security of nuclear weapons in other, newer nuclear powers with relatively less stable governments, such as Pakistan, but in each case, the fears have been addressed to some extent by statements and evidence provided by those nations, as well as cooperative programs between nations. Worry remains, however, in many circles that a relative decrease in security of nuclear weapons has emerged in recent years, and that terrorists or others may attempt to exert control over (or use) nuclear weapons, militarily applicable technology, or nuclear materials and fuel.
Another possible nuclear terrorism threat are devices designed to disperse radioactive materials over a large area using conventional explosives, called dirty bombs. The detonation of a "dirty bomb" would not cause a nuclear explosion, nor would it release enough radiation to kill or injure a lot of people. However, it could cause severe disruption and require potentially very costly decontamination procedures and increased spending on security measures.
Survival.
The predictions of the effects of a major countervalue nuclear exchange include millions of city dweller deaths within a short period of time. Some predictions argue that a full-scale nuclear war could eventually bring about the extinction of the human race. Such predictions, sometimes but not always based on total war with nuclear arsenals at Cold war highs, received contemporary criticism. A number of Cold War publications advocated preparations that could purportedly enable a large proportion of civilians to survive even a total nuclear war. Among the most famous of these is Nuclear War Survival Skills.
To avoid injury and death from a nuclear weapons heat flash and blast effects, the two most far ranging prompt effects of nuclear weapons, schoolchildren were taught to duck and cover by the early Cold War film of the same name. Such advice is once again being given in case of nuclear terrorist attacks.
Prussian blue, or "Radiogardase", is stockpiled in the US, along with potassium iodide and DPTA as pharmaceuticals useful in treating internal exposure to harmful radioisotopes in fallout.
Publications on adapting to a changing diet and supplying nutritional food sources following a nuclear war, with particular focus on agricultural radioecology, include "Nutrition in the postattack environment" by the RAND corporation.
The British government developed a public alert system for use during nuclear attack with the expectation of a four-minute warning before detonation. The United States expected a warning time of anywhere from half an hour (for land based missiles) to less than three minutes (for submarine based weapons). Many countries maintain plans for continuity of government and continuity of operations following a nuclear attack or similar disasters. These range from a designated survivor, intended to ensure survival of some form of government leadership, to the Soviet Dead Hand system, which allows for retaliation even if all Soviet leadership were destroyed. Nuclear submarines are given letters of last resort; orders on what action to take in the event that an enemy nuclear strike has destroyed the government.
The Soviet government believed they could win not only a strategic nuclear war, which they planned to absorb with their extensive Civil Defense schemes and infrastructure dispersal, but also the conventional war that they predicted would follow after their strategic nuclear arsenal had been depleted.
A number of other countries around the world have taken significant efforts to maximize their survival prospects in the event of large calamities, both natural and manmade. For example, metro stations in Pyongyang, North Korea, were constructed 110 m below ground, and were designed to serve as nuclear shelters in the event of war, with each station entrance built with thick steel blast doors. An example of a privately funded fallout shelters is the Ark Two Shelter in Ontario, Canada, an autonomous shelters constructed with an emphasis on post-war networking and reconstruction.
In Switzerland, the majority of homes have an underground blast and fallout shelter. The country has an overcapacity of such shelters and can accommodate slightly more than the nation's population size.
In fiction.
Nuclear warfare and weapons are staple elements of science fiction.

</doc>
<doc id="36882" url="http://en.wikipedia.org/wiki?curid=36882" title="Blake Edwards">
Blake Edwards

Blake Edwards (born William Blake Crump; July 26, 1922 – December 15, 2010) was an American film director, screenwriter and producer.
Edwards' career began in the 1940s as an actor, but he soon turned to writing screenplays and radio scripts before turning to producing and directing in film and television. His best-known films include "Breakfast at Tiffany's", "Days of Wine and Roses", and the hugely successful Pink Panther film series with British comedian Peter Sellers. Often thought of as primarily a director of comedies, he also directed dramas and detective films. Late in his career, he transitioned to writing, producing, and directing for theater.
In 2004, he received an Honorary Academy Award in recognition of his writing, directing and producing an extraordinary body of work for the screen.
Early life.
Born William Blake Crump in Tulsa, Oklahoma, he was the son of . She married again, to Jack McEdwards, who became his stepfather. He became a film production manager after moving his family to Los Angeles in 1925. Blake's step-grandfather was J. Gordon Edwards, a director of silent movies. In an interview with the "Village Voice" in 1971, Blake Edwards said that he had "always felt alienated, estranged from my own father, Jack McEdwards". After attending grammar and high school in Los Angeles, Blake began taking jobs as an actor during World War II.
Edwards describes this period:
I worked with the best directors – Ford, Wyler, Preminger – and learned a lot from them. But I wasn't a very cooperative actor. I was a spunky, smart-assed kid. Maybe even then I was indicating that I wanted to give, not take, direction.
Edwards served in the United States Coast Guard during World War II, where he suffered a severe back injury, which left him in pain for years afterwards.
Career.
Edwards' debut as a director came in 1952 on the television program "Four Star Playhouse".
In the 1954–1955 television season, Edwards joined with Richard Quine to create Mickey Rooney's first television series, "," a sitcom about a young studio page trying to become a serious actor. Edwards's hard-boiled private detective scripts for "Richard Diamond, Private Detective" became NBC's answer to Sam Spade and Philip Marlowe, reflecting Edwards's unique humor. Edwards also created, wrote and directed the 1959 TV series "Peter Gunn," which starred Craig Stevens, with music by Henry Mancini. In the same year Edwards produced, with Mancini's musical theme, "Mr. Lucky," an adventure series on CBS starring John Vivyan and Ross Martin. Mancini's association with Edwards continued in his film work, significantly contributing to their success.
"Operation Petticoat" was Edwards's first big-budget movie as a director. The film, which starred Tony Curtis and Cary Grant, became the "greatest box-office success of the decade for Universal [Studios]," and made Edwards a recognized director.
"Breakfast at Tiffany's", based on the novel by Truman Capote, is credited with establishing him as a "cult figure" with many critics. Andrew Sarris called it the "directorial surprise of 1961", and it became a "romantic touchstone" for college students in the early 1960s.
"Days of Wine And Roses", a dark psychological film about the effects of alcoholism on a previously happy marriage, starred Jack Lemmon and Lee Remick. It has been described as "perhaps the most unsparing tract against drink that Hollywood has yet produced, more pessimistic than Billy Wilder's "The Lost Weekend"". The film gave another major boost to Edwards's reputation as an important director.
Edwards's most popular films were comedies, the melodrama "Days of Wine and Roses" being a notable exception. His most dynamic and successful collaboration was with Peter Sellers in six of the movies in the Pink Panther series. Five of the those involved Edwards and Sellers in original material, while "Trail of the Pink Panther", made after Sellers died in 1980, was made up of unused material from "The Pink Panther Strikes Again". He also worked with Sellers on the film "The Party". Edwards later directed the comedy film "10" with Dudley Moore and Bo Derek.
"Darling Lili", whose star, Julie Andrews, Edwards later married, is considered by many followers of Edwards's films as "the director's masterpiece". According to critic George Morris, "it synthesizes every major Edwards theme: the disappearance of gallantry and honor, the tension between appearances and reality and the emotional, spiritual, moral, and psychological disorder" in such a world. Edwards used difficult cinematography techniques, including long-shot zooms, tracking, and focus distortion, to great effect.
The film failed badly, however, at the box-office. At a cost of $17 million to make, few people went to see it, and the few who did were unimpressed. It brought Paramount Pictures to "the verge of financial collapse," and became an example of "self-indulgent extravagance" in filmmaking "that was ruining Hollywood."
Edwards is best known for directing most of the comedy film series "The Pink Panther," all of those starring Peter Sellers as the inept Inspector Clouseau. It was considered a fruitful, yet complicated, relationship between the director and the lead actor, with many disagreements during production. At various times in their film relationship, "he more than once swore off Sellers" as too hard to direct. However, in his later years, he admitted that working with Sellers was often irresistible:
 "We clicked on comedy, and we were lucky we found each other, because we both had so much respect for it. We also had an ability to come up with funny things and great situations that had to be explored. But in that exploration there would oftentimes be disagreement. But I couldn't resist those moments when we jelled. And if you ask me who contributed most to those things, it couldn't have happened unless both of us were involved, even though it wasn't always happy."
The films were all highly profitable. "The Return of the Pink Panther" (1975), for example, cost just $2.5 million to make, but grossed $100 million, while "The Pink Panther Strikes Again" (1976), did even better.
In 2003, Edwards received an Honorary Academy Award for cumulative achievements over the course of his film career.
Silent-film style.
Having grown up in Hollywood, the step-son of a studio production manager and step-grandson of a silent-film director, Edwards had watched the films of the great silent-era comedians, including Charlie Chaplin, Buster Keaton, Harold Lloyd, and Laurel and Hardy. Both he and Sellers appreciated and understood the comedy styles in silent-films and tried to recreate it in their work together. After their immense success with the first two Pink Panther films, "The Pink Panther" (1963) and "A Shot in the Dark" (1964), which adapted many silent-film aspects, including slapstick, they attempted to go even further in "The Party" (1968). Although the film is relatively unknown, some have considered it a "masterpiece in this vein" of silent comedy, even though it included minimal dialogue.
Personal life.
Edwards, the step-grandson of prolific silent-film director J. Gordon Edwards, married his first wife, actress Patricia Walker, in 1953. They had two children, and divorced in 1967. She appeared in the comedy "All Ashore" (1953), for which Edwards was one of the screenwriters.
Edwards' second marriage from 1969 until his death was to Julie Andrews. Andrews had a daughter from her previous marriage, and the couple adopted two orphans from Vietnam in the early 1970s, Amelia Leigh and Joanna Lynne. Andrews appeared in a number of his films, including "Darling Lili", "10", "Victor Victoria" and the autobiographical satire "S.O.B.", in which Andrews played a character who was a caricature of herself. In 1995, he wrote the book for the stage musical adaptation of "Victor/Victoria", also starring Andrews.
Edwards described his struggle with the illness chronic fatigue syndrome for 15 years in the documentary "I Remember Me" (2000).
Death.
On December 15, 2010, Edwards died of complications of pneumonia at the Saint John's Health Center in Santa Monica, California. His wife and children were at his side. His death came after 15 years of suffering from chronic fatigue syndrome and depression.
Legacy.
Edwards was greatly admired as well as strongly criticized as a filmmaker during his career. On the negative side, general critique included this by American film author George Morris:
It has been difficult for many critics to accept Blake Edwards as anything more than a popular entertainer. Edwards' detractors acknowledge his formal skill but deplore the absence of profundity in his movies. Edwards' movies "are" slick and glossy, but their shiny surfaces reflect all too accurately the disposable values of contemporary life.
Others, however, recognized him more for his significant achievements at different periods of his career. British film critic Peter Lloyd, for example, described Edwards, in 1971, as "the finest director working in the American commercial cinema at the present time." Edwards' biographers, William Luhr and Peter Lehman, in an interview in 1974, called him "the finest American director working at this time." They refer especially to the "Pink Panther"'s Clouseau, developed with the comedic skills of Peter Sellers, as a character "perfectly consistent" with his "absurdist view of the world, because he has no faith in anything and constantly adapts." Critic Stuart Byron calls his early "Pink Panther" films "two of the best comedies an American has ever made." Polls taken at the time showed that his name, as a director, was a rare "marketable commodity" in Hollywood.
Edwards himself described one of the secrets to success in the film industry:
For someone who wants to practice his art in this business, all you can hope to do, as "S.O.B." says, is stick to your guns, make the compromises you must, and hope that somewhere along the way you acquire a few good friends who understand. And keep half a conscience."

</doc>
<doc id="36885" url="http://en.wikipedia.org/wiki?curid=36885" title="Tristan Tzara">
Tristan Tzara

Tristan Tzara (]; ]; born Samuel or Samy Rosenstock, also known as S. Samyro; April 16 [O.S. April 4] 1896 – December 25, 1963) was a French avant-garde poet, essayist and performance artist of Romanian Jewish descent. Also active as a journalist, playwright, literary and art critic, composer and film director, he was known best for being one of the founders and central figures of the anti-establishment Dada movement. Under the influence of Adrian Maniu, the adolescent Tzara became interested in Symbolism and co-founded the magazine "Simbolul" with Ion Vinea (with whom he also wrote experimental poetry) and painter Marcel Janco. During World War I, after briefly collaborating on Vinea's "Chemarea", he joined Janco in Switzerland. There, Tzara's shows at the Cabaret Voltaire and Zunfthaus zur Waag, as well as his poetry and art manifestos, became a main feature of early Dadaism. His work represented Dada's nihilistic side, in contrast with the more moderate approach favored by Hugo Ball.
After moving to Paris in 1919, Tzara, by then one of the "presidents of Dada", joined the staff of "Littérature" magazine, which marked the first step in the movement's evolution toward Surrealism. He was involved in the major polemics which led to Dada's split, defending his principles against André Breton and Francis Picabia, and, in Romania, against the eclectic modernism of Vinea and Janco. This personal vision on art defined his Dadaist plays "The Gas Heart" (1921) and "Handkerchief of Clouds" (1924). A forerunner of automatist techniques, Tzara eventually aligned himself with Breton's Surrealism, and under its influence wrote his celebrated utopian poem "The Approximate Man".
During the final part of his career, Tzara combined his humanist and anti-fascist perspective with a communist vision, joining the Republicans in the Spanish Civil War and the French Resistance during World War II, and serving a term in the National Assembly. Having spoken in favor of liberalization in the People's Republic of Hungary just before the Revolution of 1956, he distanced himself from the French Communist Party, of which he was by then a member. In 1960, he was among the intellectuals who protested against French actions in the Algerian War.
Tristan Tzara was an influential author and performer, whose contribution is credited with having created a connection from Cubism and Futurism to the Beat Generation, Situationism and various currents in rock music. The friend and collaborator of many modernist figures, he was the lover of dancer Maja Kruscek in his early youth and was later married to Swedish artist and poet Greta Knutson.
Name.
"S. Samyro", a partial anagram of "Samy Rosenstock", was used by Tzara from his debut and throughout the early 1910s. A number of undated writings, which he probably authored as early as 1913, bear the signature "Tristan Ruia", and, in summer of 1915, he was signing his pieces with the name "Tristan".
In the 1960s, Rosenstock's collaborator and later rival Ion Vinea claimed that he was responsible for coining the "Tzara" part of his pseudonym in 1915. Vinea also stated that Tzara wanted to keep "Tristan" as his adopted first name, and that this choice had later attracted him the "infamous pun" "Triste Âne Tzara" (French for "Sad Donkey Tzara"). This version of events is uncertain, as manuscripts show that the writer may have already been using the full name, as well as the variations "Tristan Țara" and "Tr. Tzara", in 1913-1914 (although there is a possibility that he was signing his texts long after committing them to paper).
In 1972, art historian Serge Fauchereau, based on information received from Colomba, the wife of avant-garde poet Ilarie Voronca, recounted that Tzara himself had explained his chosen name was a pun in Romanian, "trist în țară", meaning "sad in the country"; Colomba Voronca was also dismissing rumors that Tzara had selected "Tristan" as a tribute to poet Tristan Corbière or to Richard Wagner's "Tristan und Isolde" opera. Samy Rosenstock legally adopted his new name in 1925, after filing a request with Romania's Ministry of the Interior. The French pronunciation of his name has become commonplace in Romania, where it replaces its more natural reading as "țara" ("the land", ]).
Biography.
Early life and "Simbolul" years.
Tzara was born in Moinești, Bacău County, in the historical region of Moldavia. His parents were Jewish Romanians who reportedly spoke Yiddish as their first language; his father Filip and grandfather Ilie were entrepreneurs in the forestry business. Tzara's mother was Emilia Rosenstock, "née" Zibalis. Owing to the Romanian Kingdom's discrimination laws, the Rosenstocks were not emancipated, and thus Tzara was not a full citizen of the country until after 1918.
He moved to Bucharest at the age of eleven, and attended the Schemitz-Tierin boarding school. It is believed that the young Tzara completed his secondary education at a state-run high school, which is identified as the Saint Sava National College or as the Sfântul Gheorghe High School. In October 1912, when Tzara was aged sixteen, he joined his friends Vinea and Marcel Janco in editing "Simbolul". Reputedly, Janco and Vinea provided the funds. Like Vinea, Tzara was also close to their young colleague Jacques G. Costin, who was later his self-declared promoter and admirer.
Despite their young age, the three editors were able to attract collaborations from established Symbolist authors, active within Romania's own Symbolist movement. Alongside their close friend and mentor Adrian Maniu (an Imagist who had been Vinea's tutor), they included N. Davidescu, Alfred Hefter-Hidalgo, Emil Isac, Claudia Millian, Ion Minulescu, I. M. Rașcu, Eugeniu Sperantia, Al. T. Stamatiad, Eugeniu Ștefănescu-Est, Constantin T. Stoika, as well as the journalist and lawyer Poldi Chapier. In its inaugural issue, the journal even printed a poem by one of the leading figures in Romanian Symbolism, Alexandru Macedonski. "Simbolul" also featured illustrations by Maniu, Millian and Iosif Iser.
Although the magazine ceased print in December 1912, it played an important part in shaping Romanian literature of the period. Literary historian Paul Cernat sees "Simbolul" as a main stage in Romania's modernism, and credits it with having brought about the first changes from Symbolism to the radical avant-garde. Also according to Cernat, the collaboration between Samyro, Vinea and Janco was an early instance of literature becoming "an interface between arts", which had for its contemporary equivalent the collaboration between Iser and writers such as Ion Minulescu and Tudor Arghezi. Although Maniu parted with the group and sought a change in style which brought him closer to traditionalist tenets, Tzara, Janco and Vinea continued their collaboration. Between 1913 and 1915, they were frequently vacationing together, either on the Black Sea coast or at the Rosenstock family property in Gârceni, Vaslui County; during this time, Vinea and Samyro wrote poems with similar themes and alluding to one another.
"Chemarea" and 1915 departure.
Tzara's career changed course between 1914 and 1916, during a period when the Romanian Kingdom kept out of World War I. In autumn 1915, as founder and editor of the short-lived journal "Chemarea", Vinea published two poems by his friend, the first printed works to bear the signature "Tristan Tzara". At the time, the young poet and many of his friends were adherents of an anti-war and anti-nationalist current, which progressively accommodated anti-establishment messages. "Chemarea", which was a platform for this agenda and again attracted collaborations from Chapier, may also have been financed by Tzara and Vinea. According to Romanian avant-garde writer Claude Sernet, the journal was "totally different from everything that had been printed in Romania before that moment." During the period, Tzara's works were sporadically published in Hefter-Hidalgo's "Versuri și Proză", and, in June 1915, Constantin Rădulescu-Motru's "Noua Revistă Română" published Samyro's known poem "Verișoară, fată de pension" ("Little Cousin, Boarding School Girl").
Tzara had enrolled at the University of Bucharest in 1914, studying mathematics and philosophy, but did not graduate. In autumn 1915, he left Romania for Zürich, in neutral Switzerland. Janco, together with his brother Jules, had settled there a few months before, and was later joined by his other brother Georges. Tzara, who may have applied for the Faculty of Philosophy at the local university, shared lodging with Marcel Janco, who was a student at the "Technische Hochschule", in the Altinger Guest House (by 1918, Tzara had moved to the Limmatquai Hotel). His departure from Romania, like that of the Janco brothers, may have been in part a pacifist political statement. After settling in Switzerland, the young poet almost completely discarded Romanian as his language of expression, writing most of his subsequent works in French. The poems he had written before, which were the result of poetic dialogues between him and his friend, were left in Vinea's care. Most of these pieces were first printed only in the interwar period.
It was in Zürich that the Romanian group met with the German Hugo Ball, an anarchist poet and pianist, and his young wife Emmy Hennings, a music hall performer. In February 1916, Ball had rented the Cabaret Voltaire from its owner, Jan Ephraim, and intended to use the venue for performance art and exhibits. Hugo Ball recorded this period, noting that Tzara and Marcel Janco, like Hans Arp, Arthur Segal, Otto van Rees, Max Oppenheimer, and Marcel Słodki, "readily agreed to take part in the cabaret." According to Ball, among the performances of songs mimicking or taking inspiration from various national folklores, "Herr Tristan Tzara recited Rumanian poetry." In late March, Ball recounted, the group was joined by German writer and drummer Richard Huelsenbeck. He was soon after involved in Tzara's "simultaneist verse" performance, "the first in Zürich and in the world", also including renditions of poems by two promoters of Cubism, Fernand Divoire and Henri Barzun.
Birth of Dada.
It was in this milieu that Dada was born, at some point before May 1916, when a publication of the same name first saw print. The story of its establishment was the subject of a disagreement between Tzara and his fellow writers. Cernat believes that the first Dadaist performance took place as early as February, when the nineteen-year-old Tzara, wearing a monocle, entered the Cabaret Voltaire stage singing sentimental melodies and handing paper wads to his "scandalized spectators", leaving the stage to allow room for masked actors on stilts, and returning in clown attire. The same type of performances took place at the Zunfthaus zur Waag beginning in summer 1916, after the Cabaret Voltaire was forced to close down. According to music historian Bernard Gendron, for as long as it lasted, "the Cabaret Voltaire was dada. There was no alternative institution or site that could disentangle 'pure' dada from its mere accompaniment [...] nor was any such site desired." Other opinions link Dada's beginnings with much earlier events, including the experiments of Alfred Jarry, André Gide, Christian Morgenstern, Jean-Pierre Brisset, Guillaume Apollinaire, Jacques Vaché, Marcel Duchamp or Francis Picabia.
In the first of the movement's manifestos, Ball wrote: "[The booklet] is intended to present to the Public the activities and interests of the Cabaret Voltaire, which has as its sole purpose to draw attention, across the barriers of war and nationalism, to the few independent spirits who live for other ideals. The next objective of the artists who are assembled here is to publish a "revue internationale" [French for "international magazine"]." Ball completed his message in French, and the paragraph translates as: "The magazine shall be published in Zürich and shall carry the name 'Dada' ('Dada'). Dada Dada Dada Dada." The view according to which Ball had created the movement was notably supported by writer Walter Serner, who directly accused Tzara of having abused Ball's initiative.
A secondary point of contention between the founders of Dada regarded the paternity for the movement's name, which, according to visual artist and essayist Hans Richter, was first adopted in print in June 1916. Ball, who claimed authorship and stated that he picked the word randomly from a dictionary, indicated that it stood for both the French-language equivalent of "hobby horse" and a German-language term reflecting the joy of children being rocked to sleep. Tzara himself declined interest in the matter, but Marcel Janco credited him with having coined the term. Dada manifestos, written or co-authored by Tzara, record that the name shares its form with various other terms, including a word used in the Kru languages of West Africa to designate the tail of a sacred cow; a toy and the name for "mother" in an unspecified Italian dialect; and the double affirmative in Romanian and in various Slavic languages.
Dadaist promoter.
Before the end of the war, Tzara had assumed a position as Dada's main promoter and manager, helping the Swiss group establish branches in other European countries. This period also saw the first conflict within the group: citing irreconcilable differences with Tzara, Ball left the group. With his departure, Gendron argues, Tzara was able to move Dada vaudeville-like performances into more of "an incendiary and yet jocularly provocative theater."
He is often credited with having inspired many young modernist authors from outside Switzerland to affiliate with the group, in particular the Frenchmen Louis Aragon, André Breton, Paul Éluard, Georges Ribemont-Dessaignes and Philippe Soupault. Richter, who also came into contact with Dada at this stage in its history, notes that these intellectuals often had a "very cool and distant attitude to this new movement" before being approached by the Romanian author. In June 1916, he began editing and managing the periodical "Dada" as a successor of the short-lived magazine "Cabaret Voltaire"—Richter describes his "energy, passion and talent for the job", which he claims satisfied all Dadaists. He was at the time the lover of Maja Kruscek, who was a student of Rudolf Laban; in Richter's account, their relationship was always tottering.
As early as 1916, Tristan Tzara took distance from the Italian Futurists, rejecting the militarist and proto-fascist stance of their leader Filippo Tommaso Marinetti. Richter notes that, by then, Dada had replaced Futurism as the leader of modernism, while continuing to build on its influence: "we had swallowed Futurism—bones, feathers and all. It is true that in the process of digestion all sorts of bones and feathers had been regurgitated." Despite this and the fact that Dada did not make any gains in Italy, Tzara could count poets Giuseppe Ungaretti and Alberto Savinio, painters Gino Cantarelli and Aldo Fiozzi, as well as a few other Italian Futurists, among the Dadaists. Among the Italian authors supporting Dadaist manifestos and rallying with the Dada group was the poet, painter and in the future a fascist racial theorist Julius Evola, who became a personal friend of Tzara.
The next year, Tzara and Ball opened the "Galerie Dada" permanent exhibit, through which they set contacts with the independent Italian visual artist Giorgio de Chirico and with the German Expressionist journal "Der Sturm", all of whom were described as "fathers of Dada". During the same months, and probably owing to Tzara's intervention, the Dada group organized a performance of "Sphinx and Strawman", a puppet play by the Austro-Hungarian Expressionist Oskar Kokoschka, whom he advertised as an example of "Dada theater". He was also in touch with "Nord-Sud", the magazine of French poet Pierre Reverdy (who sought to unify all avant-garde trends), and contributed articles on African art to both "Nord-Sud" and Pierre Albert-Birot's "SIC" magazine. In early 1918, through Huelsenbeck, Zürich Dadaists established contacts with their more explicitly left-wing disciples in the German Empire—George Grosz, John Heartfield, Johannes Baader, Kurt Schwitters, Walter Mehring, Raoul Hausmann, Carl Einstein, Franz Jung, and Heartfield's brother Wieland Herzfelde. With Breton, Soupault and Aragon, Tzara traveled Cologne, where he became familiarized with the elaborate collage works of Schwitters and Max Ernst, which he showed to his colleagues in Switzerland. Huelsenbeck nonetheless declined to Schwitters membership in Berlin Dada.
As a result of his campaigning, Tzara created a list of so-called "Dada presidents", who represented various regions of Europe. According to Hans Richter, it included, alongside Tzara himself, figures ranging from Ernst, Arp, Baader, Breton and Aragon to Kruscek, Evola, Rafael Lasso de la Vega, Igor Stravinsky, Vicente Huidobro, Francesco Meriano and Théodore Fraenkel. Richter notes: "I'm not sure if all the names who appear here would agree with the description."
End of World War I.
The shows Tzara staged in Zürich often turned into scandals or riots, and he was in permanent conflict with the Swiss law enforcers. Hans Richter speaks of a "pleasure of letting fly at the bourgeois, which in Tristan Tzara took the form of coldly (or hotly) calculated insolence" ("see Épater la bourgeoisie"). In one instance, as part of a series of events in which Dadaists mocked established authors, Tzara and Arp falsely publicized that they were going to fight a duel in Rehalp, near Zürich, and that they were going to have the popular novelist Jakob Christoph Heer for their witness. Richter also reports that his Romanian colleague profited from Swiss neutrality to play the Allies and Central Powers against each other, obtaining art works and funds from both, making use of their need to stimulate their respective propaganda efforts. While active as a promoter, Tzara also published his first volume of collected poetry, the 1918 "Vingt-cinq poèmes" ("Twenty-five Poems").
A major event took place in autumn 1918, when Francis Picabia, who was then publisher of "391" magazine and a distant Dada affiliate, visited Zürich and introduced his colleagues there to his nihilistic views on art and reason. In the United States, Picabia, Man Ray and Marcel Duchamp had earlier set up their own version of Dada. This circle, based in New York City, sought affiliation with Tzara's only in 1921, when they jokingly asked him to grant them permission to use "Dada" as their own name (to which Tzara replied: "Dada belongs to everybody"). The visit was credited by Richter with boosting the Romanian author's status, but also with making Tzara himself "switch suddenly from a position of balance between art and anti-art into the stratospheric regions of pure and joyful nothingness." The movement subsequently organized its last major Swiss show, held at the Saal zur Kaufleutern, with choreography by Susanne Perrottet, Sophie Taeuber-Arp, and with the participation of Käthe Wulff, Hans Heusser, Tzara, Hans Richter and Walter Serner. It was there that Serner read from his 1918 essay, whose very title advocated "Letzte Lockerung" ("Final Dissolution"): this part is believed to have caused the subsequent mêlée, during which the public attacked the performers and succeeded in interrupting, but not canceling, the show.
Following the November 1918 Armistice with Germany, Dada's evolution was marked by political developments. In October 1919, Tzara, Arp and Otto Flake began publishing "Der Zeltweg", a journal aimed at further popularizing Dada in a post-war world were the borders were again accessible. Richter, who admits that the magazine was "rather tame", also notes that Tzara and his colleagues were dealing with the impact of communist revolutions, in particular the October Revolution and the German revolts of 1918, which "had stirred men's minds, divided men's interests and diverted energies in the direction of political change." The same commentator however dismisses those accounts which, he believes, led readers to believe that "Der Zeltweg" was "an association of revolutionary artists." According to one account rendered by historian Robert Levy, Tzara shared company with a group of Romanian communist students, and, as such, may have met with Ana Pauker, who was later one of the Romanian Communist Party's most prominent activists.
Arp and Janco drifted away from the movement ca. 1919, when they created the Constructivist-inspired workshop "Das Neue Leben". In Romania, Dada was awarded an ambiguous reception from Tzara's former associate Vinea. Although he was sympathetic to its goals, treasured Hugo Ball and Hennings and promised to adapt his own writings to its requirements, Vinea cautioned Tzara and the Jancos in favor of lucidity. When Vinea submitted his poem "Doleanțe" ("Grievances") to be published by Tzara and his associates, he was turned down, an incident which critics attribute to a contrast between the reserved tone of the piece and the revolutionary tenets of Dada.
Paris Dada.
In late 1919, Tristan Tzara left Switzerland to join Breton, Soupault and Claude Rivière in editing the Paris-based magazine "Littérature". Already a mentor for the French avant-garde, he was, according to Hans Richter, perceived as an "Anti-Messiah" and a "prophet". Reportedly, Dada mythology had it that he entered the French capital in a snow-white or lilac-colored car, passing down Boulevard Raspail through a triumphal arch made from his own pamphlets, being greeted by cheering crowds and a fireworks display. Richter dismisses this account, indicating that Tzara actually walked from Gare de l'Est to Picabia's home, without anyone expecting him to arrive.
He is often described as the main figure in the "Littérature" circle, and credited with having more firmly set its artistic principles in the line of Dada. When Picabia began publishing a new series of "391" in Paris, Tzara seconded him and, Richter says, produced issues of the magazine "decked out [...] in all the colors of Dada." He was also issuing his "Dada" magazine, printed in Paris but using the same format, renaming it "Bulletin Dada" and later "Dadaphone". At around that time, he met American author Gertrude Stein, who wrote about him in "The Autobiography of Alice B. Toklas", and the artist couple Robert and Sonia Delaunay (with whom he worked in tandem for "poem-dresses" and other simultaneist literary pieces).
Tzara became involved in a number of Dada experiments, on which he collaborated with Breton, Aragon, Soupault, Picabia or Paul Éluard. Other authors who came into contact with Dada at that stage were Jean Cocteau, Paul Dermée and Raymond Radiguet. The performances staged by Dada were often meant to popularize its principles, and Dada continued to draw attention on itself by hoaxes and false advertising, announcing that the Hollywood film star Charlie Chaplin was going to appear on stage at its show, or that its members were going to have their heads shaved or their hair cut off on stage. In another instance, Tzara and his associates lectured at the "Université populaire" in front of industrial workers, who were reportedly less than impressed. Richter believes that, ideologically, Tzara was still in tribute to Picabia's nihilistic and anarchic views (which made the Dadaists attack all political and cultural ideologies), but that this also implied a measure of sympathy for the working class.
Dada activities in Paris culminated in the March 1920 variety show at the Théâtre de l'Œuvre, which featured readings from Breton, Picabia, Dermée and Tzara's earlier work, "La Première aventure céleste de M. Antipyrine" ("The First Heavenly Adventure of Mr. Antipyrine"). Tzara's melody, "Vaseline symphonique" ("Symphonic Vaseline"), which required ten or twenty people to shout "cra" and "cri" on a rising scale, was also performed. A scandal erupted when Breton read Picabia's "Manifeste cannibale" ("Cannibal Manifesto"), lashing out at the audience and mocking them, to which they answered by aiming rotten fruit at the stage.
The Dada phenomenon was only noticed in Romania beginning in 1920, and its overall reception was negative. Traditionalist historian Nicolae Iorga, Symbolist promoter Ovid Densusianu, the more reserved modernists Camil Petrescu and Benjamin Fondane all refused to accept it as a valid artistic manifestation. Although he rallied with tradition, Vinea defended the subversive current in front of more serious criticism, and rejected the widespread rumor that Tzara had acted as an agent of influence for the Central Powers during the war. Eugen Lovinescu, editor of "Sburătorul" and one of Vinea's rivals on the modernist scene, acknowledged the influence exercised by Tzara on the younger avant-garde authors, but analyzed his work only briefly, using as an example one of his pre-Dada poems, and depicting him as an advocate of literary "extremism".
Dada stagnation.
By 1921, Tzara had become involved in conflicts with other figures in the movement, whom he claimed had parted with the spirit of Dada. He was targeted by the Berlin-based Dadaists, in particular by Huelsenbeck and Serner, the former of whom was also involved in a conflict with Raoul Hausmann over leadership status. According to Richter, tensions between Breton and Tzara had surfaced in 1920, when Breton first made known his wish to do away with musical performances altogether and alleged that the Romanian was merely repeating himself. The Dada shows themselves were by then such common occurrences that audiences expected to be insulted by the performers.
A more serious crisis occurred in May, when Dada organized a mock trial of Maurice Barrès, whose early affiliation with the Symbolists had been shadowed by his antisemitism and reactionary stance: Georges Ribemont-Dessaignes was the prosecutor, Aragon and Soupault the defense attorneys, with Tzara, Ungaretti, Benjamin Péret and others as witnesses (a mannequin stood in for Barrès). Péret immediately upset Picabia and Tzara by refusing to make the trial an absurd one, and by introducing a political subtext with which Breton nevertheless agreed. In June, Tzara and Picabia clashed with each other, after Tzara expressed an opinion that his former mentor was becoming too radical. During the same season, Breton, Arp, Ernst, Maja Kruschek and Tzara were in Austria, at Imst, where they published their last manifesto as a group, "Dada au grand air" ("Dada in the Open Air") or "Der Sängerkrieg in Tirol" ("The Battle of the Singers in Tyrol"). Tzara also visited Czechoslovakia, where he reportedly hoped to gain adherents to his cause.
Also in 1921, Ion Vinea wrote an article for the Romanian newspaper "Adevărul", arguing that the movement had exhausted itself (although, in his letters to Tzara, he continued to ask his friend to return home and spread his message there). After July 1922, Marcel Janco rallied with Vinea in editing "Contimporanul", which published some of Tzara's earliest poems but never offered space to any Dadaist manifesto. Reportedly, the conflict between Tzara and Janco had a personal note: Janco later mentioned "some dramatic quarrels" between his colleague and him. They avoided each other for the rest of their lives and Tzara even struck out the dedications to Janco from his early poems. Julius Evola also grew disappointed by the movement's total rejection of tradition and began his personal search for an alternative, pursuing a path which later led him to esotericism and fascism.
"Evening of the Bearded Heart".
Tzara was openly attacked by Breton in a February 1922 article for "Le Journal de Peuple", where the Romanian writer was denounced as "an impostor" avid for "publicity". In March, Breton initiated the "Congress for the Determination and Defense of the Modern Spirit". The French writer used the occasion to strike out Tzara's name from among the Dadaists, citing in his support Dada's Huelsenbeck, Serner, and Christian Schad. Basing his statement on a note supposedly authored by Huelsenbeck, Breton also accused Tzara of opportunism, claiming that he had planned wartime editions of Dada works in such a manner as not to upset actors on the political stage, making sure that German Dadaists were not made available to the public in countries subject to the Supreme War Council. Tzara, who attended the Congress only as a means to subvert it, responded to the accusations the same month, arguing that Huelsenbeck's note was fabricated and that Schad had not been one of the original Dadaists. Rumors reported much later by American writer Brion Gysin had it that Breton's claims also depicted Tzara as an informer for the Prefecture of Police.
In May 1922, Dada staged its own funeral. According to Hans Richter, the main part of this took place in Weimar, where the Dadaists attended a festival of the Bauhaus art school, during which Tzara proclaimed the elusive nature of his art: "Dada is useless, like everything else in life. [...] Dada is a virgin microbe which penetrates with the insistence of air into all those spaces that reason has failed to fill with words and conventions."
In "The Bearded Heart" manifesto a number of artists backed the marginalization of Breton in support of Tzara. Alongside Cocteau, Arp, Ribemont-Dessaignes, and Éluard, the pro-Tzara faction included Erik Satie, Theo van Doesburg, Serge Charchoune, Louis-Ferdinand Céline, Marcel Duchamp, Ossip Zadkine, Jean Metzinger, Ilia Zdanevich, and Man Ray. During an associated soirée, "Evening of the Bearded Heart", which began on 6 July 1923, Tzara presented a re-staging of his play "The Gas Heart" (which had been first performed two years earlier to howls of derision from its audience), for which Sonia Delaunay designed the costumes. Breton interrupted its performance and reportedly fought with several of his former associates and broke furniture, prompting a theatre riot that only the intervention of the police halted. Dada's vaudeville declined in importance and disappeared altogether after that date.
Picabia took Breton's side against Tzara, and replaced the staff of his "391", enlisting collaborations from Clément Pansaers and Ezra Pound. Breton marked the end of Dada in 1924, when he issued the first "Surrealist Manifesto". Richter suggests that "Surrealism devoured and digested Dada." Tzara distanced himself from new trend, disagreeing with its methods and, increasingly, with its politics. In 1923, he and a few other former Dadaists collaborated with Richter and the Constructivist artist El Lissitzky on the magazine "G", and, the following year, he wrote pieces for the Yugoslav-Slovenian magazine "Tank" (edited by Ferdinand Delak).
Transition to Surrealism.
Tzara continued to write, becoming more seriously interested in the theater. In 1924, he published and staged the play "Handkerchief of Clouds", which was soon included in the repertoire of Serge Diaghilev's "Ballets Russes". He also collected his earlier Dada texts as the "Seven Dada Manifestos". Marxist thinker Henri Lefebvre reviewed them enthusiastically; he later became one of the author's friends.
In Romania, Tzara's work was partly recuperated by "Contimporanul", which notably staged public readings of his works during the international art exhibit it organized in 1924, and again during the "new art demonstration" of 1925. In parallel, the short-lived magazine "Integral", where Ilarie Voronca and Ion Călugăru were the main animators, took significant interest in Tzara's work. In a 1927 interview with the publication, he voiced his opposition to the Surrealist group's adoption of communism, indicating that such politics could only result in a "new bourgeoisie" being created, and explaining that he had opted for a personal "permanent revolution", which would preserve "the holiness of the ego".
In 1925, Tristan Tzara was in Stockholm, where he married Greta Knutson, with whom he had a son, Christophe (born 1927). A former student of painter André Lhote, she was known for her interest in phenomenology and abstract art. Around the same period, with funds from Knutson's inheritance, Tzara commissioned Austrian architect Adolf Loos, a former representative of the Vienna Secession whom he had met in Zürich, to build him a house in Paris. The rigidly functionalist "Maison Tristan Tzara", built in Montmartre, was designed following Tzara's specific requirements and decorated with samples of African art. It was Loos' only major contribution in his Parisian years.
In 1929, he reconciled with Breton, and sporadically attended the Surrealists' meetings in Paris. The same year, he issued the poetry book "De nos oiseaux" ("Of Our Birds"). This period saw the publication of "The Approximate Man" (1931), alongside the volumes "L'Arbre des voyageurs" ("The Travelers' Tree", 1930), "Où boivent les loups" ("Where Wolves Drink", 1932), "L'Antitête" ("The Antihead", 1933) and "Grains et issues" ("Seed and Bran", 1935). By then, it was also announced that Tzara had started work on a screenplay. In 1930, he directed and produced a cinematic version of "Le Cœur à barbe", starring Breton and other leading Surrealists. Five years later, he signed his name to "The Testimony against Gertrude Stein", published by Eugene Jolas's magazine "transition" in reply to Stein's memoir "The Autobiography of Alice B. Toklas", in which he accused his former friend of being a megalomaniac.
The poet became involved in further developing Surrealist techniques, and, together with Breton and Valentine Hugo, drew one of the better-known examples of "exquisite corpses". Tzara also prefaced a 1934 collection of Surrealist poems by his friend René Char, and the following year he and Greta Knutson visited Char in L'Isle-sur-la-Sorgue. Tzara's wife was also affiliated with the Surrealist group at around the same time. This association ended when she parted with Tzara late in the 1930s.
At home, Tzara's works were collected and edited by the Surrealist promoter Sașa Pană, who corresponded with him over several years. The first such edition saw print in 1934, and featured the 1913-1915 poems Tzara had left in Vinea's care. In 1928-1929, Tzara exchanged letters with his friend Jacques G. Costin, a "Contimporanul" affiliate who did not share all of Vinea's views on literature, who offered to organize his visit to Romania and asked him to translate his work into French.
Affiliation with communism and Spanish Civil War.
Alarmed by the establishment of Adolf Hitler's Nazi regime, which also signified the end of Berlin's avant-garde, he merged his activities as an art promoter with the cause of anti-fascism, and was close to the French Communist Party (PCF). In 1936, Richter recalled, he published a series of photographs secretly taken by Kurt Schwitters in Hanover, works which documented the destruction of Nazi propaganda by the locals, ration stamp with reduced quantities of food, and other hidden aspects of Hitler's rule. After the outbreak of the Spanish Civil War, he briefly left France and joined the Republican forces. Alongside Soviet reporter Ilya Ehrenburg, Tzara visited Madrid, which was besieged by the Nationalists ("see Siege of Madrid"). Upon his return, he published the collection of poems "Midis gagnés" ("Conquered Southern Regions"). Some of them had previously been printed in the brochure "Les poètes du monde défendent le peuple espagnol" ("The Poets of the World Defend the Spanish People", 1937), which was edited by two prominent authors and activists, Nancy Cunard and the Chilean poet Pablo Neruda. Tzara had also signed Cunard's June 1937 call to intervention against Francisco Franco. Reportedly, he and Nancy Cunard were romantically involved.
Although the poet was moving away from Surrealism, his adherence to strict Marxism-Leninism was reportedly questioned by both the PCF and the Soviet Union. Semiotician Philip Beitchman places their attitude in connection with Tzara's own vision of Utopia, which combined communist messages with Freudo-Marxist psychoanalysis and made use of particularly violent imagery. Reportedly, Tzara refused to be enlisted in supporting the party line, maintaining his independence and refusing to take the forefront at public rallies.
However, others note that the former Dadaist leader would often show himself a follower of political guidelines. As early as 1934, Tzara, together with Breton, Éluard and communist writer René Crevel, organized an informal trial of independent-minded Surrealist Salvador Dalí, who was at the time a confessed admirer of Hitler, and whose portrait of William Tell had alarmed them because it shared likeness with Bolshevik leader Vladimir Lenin. Historian Irina Livezeanu notes that Tzara, who agreed with Stalinism and shunned Trotskyism, submitted to the PCF cultural demands during the writers' congress of 1935, even when his friend Crevel committed suicide to protest the adoption of socialist realism. At a later stage, Livezeanu remarks, Tzara reinterpreted Dada and Surrealism as revolutionary currents, and presented them as such to the public. This stance she contrasts with that of Breton, who was more reserved in his attitudes.
World War II and Resistance.
During World War II, Tzara took refuge from the German occupation forces, moving to the southern areas, controlled by the Vichy regime. On one occasion, the antisemitic and collaborationist publication "Je Suis Partout" made his whereabouts known to the Gestapo.
He was in Marseille in late 1940-early 1941, joining the group of anti-fascist and Jewish refugees who, protected by American diplomat Varian Fry, were seeking to escape Nazi-occupied Europe. Among the people present there were the anti-totalitarian socialist Victor Serge, anthropologist Claude Lévi-Strauss, playwright Arthur Adamov, philosopher and poet René Daumal, and several prominent Surrealists: Breton, Char, and Benjamin Péret, as well as artists Max Ernst, André Masson, Wifredo Lam, Jacques Hérold, Victor Brauner and Óscar Domínguez. During the months spent together, and before some of them received permission to leave for America, they invented a new card game, on which traditional card imagery was replaced with Surrealist symbols.
Some time after his stay in Marseille, Tzara joined the French Resistance, rallying with the Maquis. A contributor to magazines published by the Resistance, Tzara also took charge of the cultural broadcast for the Free French Forces clandestine radio station. He lived in Aix-en-Provence, then in Souillac, and ultimately in Toulouse. His son Cristophe was at the time a Resistant in northern France, having joined the "Franc Tireurs Partisans". In Axis-allied and antisemitic Romania ("see Romania during World War II"), the regime of Ion Antonescu ordered bookstores not to sell works by Tzara and 44 other Jewish-Romanian authors. In 1942, with the generalization of antisemitic measures, Tzara was also stripped of his Romanian citizenship rights.
In December 1944, five months after the Liberation of Paris, he was contributing to "L'Éternelle Revue", a pro-communist newspaper edited by philosopher Jean-Paul Sartre, through which Sartre was publicizing the heroic image of a France united in resistance, as opposed to the perception that it had passively accepted German control. Other contributors included writers Aragon, Char, Éluard, Elsa Triolet, Eugène Guillevic, Raymond Queneau, Francis Ponge, Jacques Prévert and painter Pablo Picasso.
Upon the end of the war and the restoration of French independence, Tzara was naturalized a French citizen. During 1945, under the Provisional Government of the French Republic, he was a representative of the Sud-Ouest region to the National Assembly. According to Livezeanu, he "helped reclaim the South from the cultural figures who had associated themselves to Vichy [France]." In April 1946, his early poems, alongside similar pieces by Breton, Éluard, Aragon and Dalí, were the subject of a midnight broadcast on Parisian Radio. In 1947, he became a full member of the PCF (according to some sources, he had been one since 1934).
International leftism.
Over the following decade, Tzara lent his support to political causes. Pursuing his interest in primitivism, he became a critic of the Fourth Republic's colonial policy, and joined his voice to those who supported decolonization. Nevertheless, he was appointed cultural ambassador of the Republic by the Paul Ramadier cabinet. He also participated in the PCF-organized Congress of Writers, but, unlike Éluard and Aragon, again avoided adapting his style to socialist realism.
He returned to Romania on an official visit in late 1946-early 1947, as part of a tour of the emerging Eastern Bloc during which he also stopped in Czechoslovakia, Hungary, and the Federal People's Republic of Yugoslavia. The speeches he and Sașa Pană gave on the occasion, published by "Orizont" journal, were noted for condoning official positions of the PCF and the Romanian Communist Party, and are credited by Irina Livezeanu with causing a rift between Tzara and young Romanian avant-gardists such as Victor Brauner and Gherasim Luca (who rejected communism and were alarmed by the Iron Curtain having fallen over Europe). In September of the same year, he was present at the conference of the pro-communist International Union of Students (where he was a guest of the French-based Union of Communist Students, and met with similar organizations from Romania and other countries).
In 1949-1950, Tzara answered Aragon's call and become active in the international campaign to liberate Nazım Hikmet, a Turkish poet whose 1938 arrest for communist activities had created a "cause célèbre" for the pro-Soviet public opinion. Tzara chaired the Committee for the Liberation of Nazım Hikmet, which issued petitions to national governments and commissioned works in honor of Hikmet (including musical pieces by Louis Durey and Serge Nigg). Hikmet was eventually released in July 1950, and publicly thanked Tzara during his subsequent visit to Paris.
His works of the period include, among others: "Le Signe de vie" ("Sign of Life", 1946), "Terre sur terre" ("Earth on Earth", 1946), "Sans coup férir" ("Without a Need to Fight", 1949), "De mémoire d'homme" ("From a Man's Memory", 1950), "Parler seul" ("Speaking Alone", 1950), and "La Face intérieure" ("The Inner Face", 1953), followed in 1955 by "À haute flamme" ("Flame out Loud") and "Le Temps naissant" ("The Nascent Time"), and the 1956 "Le Fruit permis" ("The Permitted Fruit"). Tzara continued to be an active promoter of modernist culture. Around 1949, having read Irish author Samuel Beckett's manuscript of "Waiting for Godot", Tzara facilitated the play's staging by approaching producer Roger Blin. He also translated into French some poems by Hikmet and the Hungarian author Attila József. In 1949, he introduced Picasso to art dealer Heinz Berggruen (thus helping start their lifelong partnership), and, in 1951, wrote the catalog for an exhibit of works by his friend Max Ernst; the text celebrated the artist's "free use of stimuli" and "his discovery of a new kind of humor."
1956 protest and final years.
In October 1956, Tzara visited the People's Republic of Hungary, where the government of Imre Nagy was coming into conflict with the Soviet Union. This followed an invitation on the part of Hungarian writer Gyula Illyés, who wanted his colleague to be present at ceremonies marking the rehabilitation of László Rajk (a local communist leader whose prosecution had been ordered by Joseph Stalin). Tzara was receptive of the Hungarians' demand for liberalization, contacted the anti-Stalinist and former Dadaist Lajos Kassák, and deemed the anti-Soviet movement "revolutionary". However, unlike much of Hungarian public opinion, the poet did not recommend emancipation from Soviet control, and described the independence demanded by local writers as "an abstract notion". The statement he issued, widely quoted in the Hungarian and international press, forced a reaction from the PCF: through Aragon's reply, the party deplored the fact that one of its members was being used in support of "anti-communist and anti-Soviet campaigns."
His return to France coincided with the outbreak of the Hungarian Revolution, which ended with a Soviet military intervention. On October 24, Tzara was ordered to a PCF meeting, where activist Laurent Casanova reportedly ordered him to keep silent, which Tzara did. Tzara's apparent dissidence and the crisis he helped provoke within the Communist Party were celebrated by Breton, who had adopted a pro-Hungarian stance, and who defined his friend and rival as "the first spokesman of the Hungarian demand."
He was thereafter mostly withdrawn from public life, dedicating himself to researching the work of 15th-century poet François Villon, and, like his fellow Surrealist Michel Leiris, to promoting primitive and African art, which he had been collecting for years. In early 1957, Tzara attended a Dada retrospective on the Rive Gauche, which ended in a riot caused by the rival avant-garde Mouvement Jariviste, an outcome which reportedly pleased him. In August 1960, one year after the Fifth Republic had been established by President Charles de Gaulle, at a time when French forces were confronting the Algerian rebels ("see Algerian War"). Together with Simone de Beauvoir, Marguerite Duras, Jérôme Lindon, Alain Robbe-Grillet and other intellectuals, he addressed Premier Michel Debré a letter of protest, concerning France's refusal to grant Algeria its independence. As a result, Minister of Culture André Malraux announced that his cabinet would not subsidize any films to which Tzara and the others may contribute, and the signatories could no longer appear on stations managed by the state-owned French Broadcasting Service.
In 1961, as recognition for his work as a poet, Tzara was awarded the prestigious Taormina Prize. One of his final public activities took place in 1962, when he attended the International Congress on African Culture, organized by English curator Frank McEwen and held at the National Gallery in Salisbury, Southern Rhodesia. He died one year later in his Paris home, and was buried at the Cimetière du Montparnasse.
Literary contributions.
Identity issues.
Much critical commentary about Tzara surrounds the measure to which the poet identified with the national cultures which he represented. Paul Cernat notes that the association between Samyro and the Jancos, who were Jews, and their ethnic Romanian colleagues, was one sign of a cultural dialogue, in which "the openness of Romanian environments toward artistic modernity" was stimulated by "young emancipated Jewish writers." Salomon Schulman, a Swedish researcher of Yiddish literature, argues that the combined influence of Yiddish folklore and Hasidic philosophy shaped European modernism in general and Tzara's style in particular, while American poet Andrei Codrescu speaks of Tzara as one in a Balkan line of "absurdist writing", which also includes the Romanians Urmuz, Eugène Ionesco and Emil Cioran. According to literary historian George Călinescu, Samyro's early poems deal with "the voluptuousness over the strong scents of rural life, which is typical among Jews compressed into ghettos."
Tzara himself used elements alluding to his homeland in his early Dadaist performances. His collaboration with Maja Kruscek at Zuntfhaus zür Waag featured samples of African literature, to which Tzara added Romanian-language fragments. He is also known to have mixed elements of Romanian folklore, and to have sung the native suburban romanza "La moară la Hârța" ("At the Mill in Hârța") during at least one staging for Cabaret Voltaire. Addressing the Romanian public in 1947, he claimed to have been captivated by "the sweet language of Moldavian peasants".
Tzara nonetheless rebelled against his birthplace and upbringing. His earliest poems depict provincial Moldavia as a desolate and unsettling place. In Cernat's view, this imagery was in common use among Moldavian-born writers who also belonged to the avant-garde trend, notably Benjamin Fondane and George Bacovia. Like in the cases of Eugène Ionesco and Fondane, Cernat proposes, Samyro sought self-exile to Western Europe as a "modern, voluntarist" means of breaking with "the peripheral condition", which may also serve to explain the pun he selected for a pseudonym. According to the same author, two important elements in this process were "a maternal attachment and a break with paternal authority", an "Oedipus complex" which he also argued was evident in the biographies of other Symbolist and avant-garde Romanian authors, from Urmuz to Mateiu Caragiale. Unlike Vinea and the "Contimporanul" group, Cernat proposes, Tzara stood for radicalism and insurgency, which would also help explain their impossibility to communicate. In particular, Cernat argues, the writer sought to emancipate himself from competing nationalisms, and addressed himself directly to the center of European culture, with Zürich serving as a stage on his way to Paris. The 1916 "Monsieur's Antipyrine's Manifesto" featured a cosmopolitan appeal: "DADA remains within the framework of European weaknesses, it's still shit, but from now on we want to shit in different colors so as to adorn the zoo of art with all the flags of all the consulates."
With time, Tristan Tzara came to be regarded by his Dada associates as an exotic character, whose attitudes were intrinsically linked with Eastern Europe. Early on, Ball referred to him and the Janco brothers as "Orientals". Hans Richter believed him to be a fiery and impulsive figure, having little in common with his German collaborators. According to Cernat, Richter's perspective seems to indicate a vision of Tzara having a "Latin" temperament. This type of perception also had negative implications for Tzara, particularly after the 1922 split within Dada. In the 1940s, Richard Huelsenbeck alleged that his former colleague had always been separated from other Dadaists by his failure to appreciate the legacy of "German humanism", and that, compared to his German colleagues, he was "a barbarian". In his polemic with Tzara, Breton also repeatedly placed stress on his rival's foreign origin.
At home, Tzara was occasionally targeted for his Jewishness, culminating in the ban enforced by the Ion Antonescu regime. In 1931, Const. I. Emilian, the first Romanian to write an academic study on the avant-garde, attacked him from a conservative and antisemitic position. He depicted Dadaists as "Judaeo-Bolsheviks" who corrupted Romanian culture, and included Tzara among the main proponents of "literary anarchism". Alleging that Tzara's only merit was to establish a literary fashion, while recognizing his "formal virtuosity and artistic intelligence", he claimed to prefer Tzara in his "Simbolul" stage. This perspective was deplored early on by the modernist critic Perpessicius. Nine years after Emilian's polemic text, fascist poet and journalist Radu Gyr published an article in "Convorbiri Literare", in which he attacked Tzara as a representative of the "Judaic spirit", of the "foreign plague" and of "materialist-historical dialectics".
Symbolist poetry.
Tzara's earliest Symbolist poems, published in "Simbolul" during 1912, were later rejected by their author, who asked Sașa Pană not to include them in editions of his works. The influence of French Symbolists on the young Samyro was particularly important, and surfaced in both his lyric and prose poems. Attached to Symbolist musicality at that stage, he was indebted to his "Simbolul" colleague Ion Minulescu and the Belgian Maurice Maeterlinck. Philip Beitchman argues that "Tristan Tzara is one of the writers of the twentieth century who was most profoundly influenced by symbolism—and utilized many of its methods and ideas in the pursuit of his own artistic and social ends." However, Cernat believes, the young poet was by then already breaking with the syntax of conventional poetry, and that, in subsequent experimental pieces, he progressively stripped his style of its Symbolist elements.
During the 1910s, Samyro experimented with Symbolist imagery, in particular with the "hanged man" motif, which served as the basis for his poem "Se spânzură un om" ("A Man Hangs Himself"), and which built on the legacy of similar pieces authored by Christian Morgenstern and Jules Laforgue. "Se spânzură un om" was also in many ways similar to ones authored by his collaborators Adrian Maniu ("Balada spânzuratului", "The Hanged Man's Ballad") and Vinea ("Visul spânzuratului", "The Hanged Man's Dream"): all three poets, who were all in the process of discarding Symbolism, interpreted the theme from a tragicomic and iconoclastic perspective. These pieces also include "Vacanță în provincie" ("Provincial Holiday") and the anti-war fragment "Furtuna și cântecul dezertorului" ("The Storm and the Deserter's Song"), which Vinea published in his "Chemarea". The series is seen by Cernat as "the general rehearsal for the Dada adventure." The complete text of "Furtuna și cântecul dezertorului" was published at a later stage, after the missing text was discovered by Pană. At the time, he became interested in the free verse work of the American Walt Whitman, and his translation of Whitman's epic poem "Song of Myself", probably completed before World War I, was published by Alfred Hefter-Hidalgo in his magazine "Versuri și Proză" (1915).
Beitchman notes that, throughout his life, Tzara used Symbolist elements against the doctrines of Symbolism. Thus, he argues, the poet did not cultivate a memory of historical events, "since it deludes man into thinking that there was something when there was nothing." Cernat notes: "That which essentially unifies, during [the 1910s], the poetic output of Adrian Maniu, Ion Vinea and Tristan Tzara is an acute awareness of literary conventions, a satiety [...] in respect to calophile literature, which they perceived as exhausted." In Beitchman's view, the revolt against cultivated beauty was a constant in Tzara's years of maturity, and his visions of social change continued to be inspired by Arthur Rimbaud and the Comte de Lautréamont. According to Beitchman, Tzara uses the Symbolist message, "the birthright [of humans] has been sold for a mess of porridge", taking it "into the streets, cabarets and trains where he denounces the deal and asks for his birthright back."
Collaboration with Vinea.
The transition to a more radical form of poetry seems to have taken place in 1913-1915, during the periods when Tzara and Vinea were vacationing together. The pieces share a number of characteristics and subjects, and the two poets even use them to allude to one another (or, in one case, to Tzara's sister).
In addition to the lyrics were they both speak of provincial holidays and love affairs with local girls, both friends intended to reinterpret William Shakespeare's "Hamlet" from a modernist perspective, and wrote incomplete texts with this as their subject. However, Paul Cernat notes, the texts also evidence a difference in approach, with Vinea's work being "meditative and melancholic", while Tzara's is "hedonistic". Tzara often appealed to revolutionary and ironic images, portraying provincial and middle class environments as places of artificiality and decay, demystifying pastoral themes and evidencing a will to break free. His literature took a more radical perspective on life, and featured lyrics with subversive intent:
In his "Înserează" (roughly, "Night Falling"), probably authored in Mangalia, Tzara writes:
Vinea's similar poem, written in Tuzla and named after that village, reads:
Cernat notes that "Nocturnă" ("Nocturne") and "Înserează" were the pieces originally performed at Cabaret Voltaire, identified by Hugo Ball as "Rumanian poetry", and that they were recited in Tzara's own spontaneous French translation. Although they are noted for their radical break with the traditional form of Romanian verse, Ball's diary entry of February 5, 1916, indicates that Tzara's works were still "conservative in style". In Călinescu's view, they announce Dadaism, given that "bypassing the relations which lead to a realistic vision, the poet associates unimaginably dissipated images that will surprise consciousness." In 1922, Tzara himself wrote: "As early as 1914, I tried to strip the words of their proper meaning and use them in such a way as to give the verse a completely new, general, meaning [...]."
Alongside pieces depicting a Jewish cemetery in which graves "crawl like worms" on the edge of a town, chestnut trees "heavy-laden like people returning from hospitals", or wind wailing "with all the hopelessness of an orphanage", Samyro's poetry includes "Verișoară, fată de pension", which, Cernat argues, displays "playful detachment [for] the musicality of internal rhymes". It opens with the lyrics:
The Gârceni pieces were treasured by the moderate wing of the Romanian avant-garde movement. In contrast to his previous rejection of Dada, "Contimporanul" collaborator Benjamin Fondane used them as an example of "pure poetry", and compared them to the elaborate writings of French poet Paul Valéry, thus recuperating them in line with the magazine's ideology.
Dada synthesis and "simultaneism".
Tzara the Dadaist was inspired by the contributions of his experimental modernist predecessors. Among them were the literary promoters of Cubism: in addition to Henri Barzun and Fernand Divoire, Tzara cherished the works of Guillaume Apollinaire. Despite Dada's condemnation of Futurism, various authors note the influence Filippo Tommaso Marinetti and his circle exercised on Tzara's group. In 1917, he was in correspondence with both Apollinaire and Marinetti. Traditionally, Tzara is also seen as indebted to the early avant-garde and black comedy writings of Romania's Urmuz.
For a large part, Dada focused on performances and satire, with shows that often had Tzara, Marcel Janco and Huelsenbeck for their main protagonists. Often dressed up as Tyrolian peasants or wearing dark robes, they improvised poetry sessions at the Cabaret Voltaire, reciting the works of others or their spontaneous creations, which were or pretended to be in Esperanto or Māori language. Bernard Gendron describes these soirées as marked by "heterogeneity and eclecticism", and Richter notes that the songs, often punctuated by loud shrieks or other unsettling sounds, built on the legacy of noise music and Futurist compositions.
With time, Tristan Tzara merged his performances and his literature, taking part in developing Dada's "simultaneist poetry", which was meant to be read out loud and involved a collaborative effort, being, according to Hans Arp, the first instance of Surrealist automatism. Ball stated that the subject of such pieces was "the value of the human voice." Together with Arp, Tzara and Walter Serner produced the German-language "Die Hyperbel vom Krokodilcoiffeur und dem Spazierstock" ("The Hyperbole of the Crocodile's Hairdresser and the Walking-Stick"), in which, Arp stated, "the poet crows, curses, sighs, stutters, yodels, as he pleases. His poems are like Nature [where] a tiny particle is as beautiful and important as a star." Another noted simultaneist poem was "L'Amiral cherche une maison à louer" ("The Admiral Is Looking for a House to Rent"), co-authored by Tzara, Marcel Janco and Huelsenbach.
Art historian Roger Cardinal describes Tristan Tzara's Dada poetry as marked by "extreme semantic and syntactic incoherence". Tzara, who recommended destroying just as it is created, had devised a personal system for writing poetry, which implied a seemingly chaotic reassembling of words that had been randomly cut out of newspapers.
Dada and anti-art.
The Romanian writer also spent the Dada period issuing a long series of manifestos, which were often authored as prose poetry, and, according to Cardinal, were characterized by "rumbustious tomfoolery and astringent wit", which reflected "the language of a sophisticated savage". Huelsenbeck credited Tzara with having discovered in them the format for "compress[ing] what we think and feel", and, according to Hans Richter, the genre "suited Tzara perfectly." Despite its production of seemingly theoretical works, Richter indicates, Dada lacked any form of program, and Tzara tried to perpetuate this state of affairs. His Dada manifesto of 1918 stated: "Dada means nothing", adding "Thought is produced in the mouth." Tzara indicated: "I am against systems; the most acceptable system is on principle to have none." In addition, Tzara, who once stated that "logic is always false", probably approved of Serner's vision of a "final dissolution". According to Philip Beitchman, a core concept in Tzara's thought was that "as long as we do things the way we think we once did them we will be unable to achieve any kind of livable society."
Despite adopting such anti-artistic principles, Richter argues, Tzara, like many of his fellow Dadaists, did not initially discard the mission of "furthening the cause of art." He saw this evident in "La Revue Dada 2", a poem "as exquisite as freshly-picked flowers", which included the lyrics:
"La Revue Dada 2", which also includes the onomatopoeic line "tralalalalalalalalalalala", is one example where Tzara applies his principles of chance to sounds themselves. This sort of arrangement, treasured by many Dadaists, was probably connected with Apollinaire's calligrams, and with his announcement that "Man is in search of a new language." Călinescu proposed that Tzara willingly limited the impact of chance: taking as his example a short parody piece which depicts the love affair between cyclist and a Dadaist, which ends with their decapitation by a jealous husband, the critic notes that Tzara transparently intended to "shock the bourgeois". Late in his career, Huelsenbeck alleged that Tzara never actually applied the experimental methods he had devised.
The Dada series makes ample use of contrast, ellipses, ridiculous imagery and nonsensical verdicts. Tzara was aware that the public could find it difficult to follow his intentions, and, in a piece titled "Le géant blanc lépreux du paysage" ("The White Leprous Giant in the Landscape") even alluded to the "skinny, idiotic, dirty" reader who "does not understand my poetry." He called some of his own poems "lampisteries", from a French word designating storage areas for light fixtures. The Lettrist poet Isidore Isou included such pieces in a succession of experiments inaugurated by Charles Baudelaire with the "destruction of the anecdote for the form of the poem", a process which, with Tzara, became "destruction of the word for nothing". According to American literary historian Mary Ann Caws, Tzara's poems may be seen as having an "internal order", and read as "a simple spectacle, as creation complete in itself and completely obvious."
Plays of the 1920s.
Tristan Tzara's first play, "The Gas Heart", dates from the final period of Paris Dada. Created with what Enoch Brater calls a "peculiar verbal strategy", it is a dialogue between characters called Ear, Mouth, Eye, Nose, Neck, and Eyebrow. They seem unwilling to actually communicate to each other and their reliance on proverbs and idiotisms willingly creates confusion between metaphorical and literal speech. The play ends with a dance performance that recalls similar devices used by the proto-Dadaist Alfred Jarry. The text culminates in a series of doodles and illegible words. Brater describes "The Gas Heart" as a "parod[y] of theatrical conventions".
In his 1924 play "Handkerchief of Clouds", Tzara explores the relation between perception, the subconscious and memory. Largely through exchanges between commentators who act as third parties, the text presents the tribulations of a love triangle (a poet, a bored woman, and her banker husband, whose character traits borrow the clichés of conventional drama), and in part reproduces settings and lines from "Hamlet". Tzara mocks classical theater, which demands from characters to be inspiring, believable, and to function as a whole: "Handkerchief of Clouds" requires actors in the role of commentators to address each other by their real names, and their lines include dismissive comments on the play itself, while the protagonist, who in the end dies, is not assigned any name. Writing for "Integral", Tzara defined his play as a note on "the relativity of things, sentiments and events." Among the conventions ridiculed by the dramatist, Philip Beitchman notes, is that of a "privileged position for art": in what Beitchman sees as a comment on Marxism, poet and banker are interchangeable capitalists who invest in different fields. Writing in 1925, Fondane rendered a pronouncement by Jean Cocteau, who, while commenting that Tzara was one of his "most beloved" writers and a "great poet", argued: ""Handkerchief of Clouds" was poetry, and great poetry for that matter—but not theater." The work was nonetheless praised by Ion Călugăru at "Integral", who saw in it one example that modernist performance could rely not just on props, but also on a solid text.
"The Approximate Man" and later works.
After 1929, with the adoption of Surrealism, Tzara's literary works discard much of their satirical purpose, and begin to explore universal themes relating to the human condition. According to Cardinal, the period also signified the definitive move from "a studied inconsequentiality" and "unreadable gibberish" to "a seductive and fertile surrealist idiom." The critic also remarks: "Tzara arrived at a mature style of transparent simplicity, in which disparate entities could be held together in a unifying vision." In a 1930 essay, Fondane had given a similar verdict: arguing that Tzara had infused his work with "suffering", had discovered humanity, and had become a "clairvoyant" among poets.
This period in Tzara's creative activity centers on "The Approximate Man", an epic poem which is reportedly recognized as his most accomplished contribution to French literature. While maintaining some of Tzara's preoccupation with language experimentation, it is mainly a study in social alienation and the search for an escape. Cardinal calls the piece "an extended meditation on mental and elemental impulses [...] with images of stunning beauty", while Breitchman, who notes Tzara's rebellion against the "excess baggage of [man's] past and the notions [...] with which he has hitherto tried to control his life", remarks his portrayal of poets as voices who can prevent human beings from destroying themselves with their own intellects. The goal is a new man who lets intuition and spontaneity guide him through life, and who rejects measure. One of the appeals in the text reads:
The next stage in Tzara's career saw a merger of his literary and political views. His poems of the period blend a humanist vision with communist theses. The 1935 "Grains et issues", described by Beitchman as "fascinating", was a prose poem of social criticism connected with "The Approximate Man", expanding on the vision of a possible society, in which haste has been abandoned in favor of oblivion. The world imagined by Tzara abandons symbols of the past, from literature to public transportation and currency, while, like psychologists Sigmund Freud and Wilhelm Reich, the poet depicts violence as a natural means of human expression. People of the future live in a state which combines waking life and the realm of dreams, and life itself turns into revery. "Grains et issues" was accompanied by "Personage d'insomnie" ("Personage of Insomnia"), which went unpublished.
Cardinal notes: "In retrospect, harmony and contact had been Tzara's goals all along." The post-World War II volumes in the series focus on political subjects related to the conflict. In his last writings, Tzara toned down experimentation, exercising more control over the lyrical aspects. He was by then undertaking a hermeutic research into the work of Goliards and François Villon, whom he deeply admired.
Legacy.
Influence.
Beside the many authors who were attracted into Dada through his promotional activities, Tzara was able to influence successive generations of writers. This was the case in his homeland during 1928, when the first avant-garde manifesto issued by "unu" magazine, written by Sașa Pană and Moldov, cited as its mentors Tzara, writers Breton, Ribemont-Dessaignes, Vinea, Filippo Tommaso Marinetti, and Tudor Arghezi, as well as artists Constantin Brâncuși and Theo van Doesburg. One of the Romanian writers to claim inspiration from Tzara was Jacques G. Costin, who nevertheless offered an equally good reception to both Dadaism and Futurism, while Ilarie Voronca's "Zodiac" cycle, first published in France, is traditionally seen as indebted to "The Approximate Man". The Kabbalist and Surrealist author Marcel Avramescu, who wrote during the 1930s, also appears to have been directly inspired by Tzara's views on art. Other authors from that generation to have been inspired by Tzara were Polish Futurist writer Bruno Jasieński, Japanese poet and Zen thinker Takahashi Shinkichi, and Chilean poet and Dadaist sympathizer Vicente Huidobro, who cited him as a precursor for his own "Creacionismo".
An immediate precursor of Absurdism, he was acknowledged as a mentor by Eugène Ionesco, who developed on his principles for his early essays of literary and social criticism, as well as in tragic farces such as "The Bald Soprano". Tzara's poetry influenced Samuel Beckett (who translated some of it into English); the Irish author's 1972 play "Not I" shares some elements with "The Gas Heart". In the United States, the Romanian author is cited as an influence on Beat Generation members. Beat writer Allen Ginsberg, who made his acquaintance in Paris, cites him among the Europeans who influenced him and William S. Burroughs. The latter also mentioned Tzara's use of chance in writing poetry as an early example of what became the cut-up technique, adopted by Brion Gysin and Burroughs himself. Gysin, who conversed with Tzara in the late 1950s, records the latter's indignation that Beat poets were "going back over the ground we [Dadaists] covered in 1920", and accuses Tzara of having consumed his creative energies into becoming a "Communist Party bureaucrat".
Among the late 20th-century writers who acknowledged Tzara as an inspiration are Jerome Rothenberg, Isidore Isou and Andrei Codrescu. The former Situationist Isou, whose experiments with sounds and poetry come in succession to Apollinaire and Dada, declared his Lettrism to be the last connection in the Charles Baudelaire-Tzara cycle, with the goal of arranging "a nothing [...] for the creation of the anecdote." For a short period, Codrescu even adopted the pen name "Tristan Tzara". He recalled the impact of having discovered Tzara's work in his youth, and credited him with being "the most important French poet after Rimbaud."
In retrospect, various authors describe Tzara's Dadaist shows and street performances as "happenings", with a word employed by post-Dadaists and Situationists, which was coined in the 1950s. Some also credit Tzara with having provided an ideological source for the development of rock music, including punk rock, punk subculture and post-punk. Tristan Tzara has inspired the songwriting technique of Radiohead, and is one of the avant-garde authors whose voices were mixed by DJ Spooky on his trip hop album "Rhythm Science". Romanian contemporary classical musician Cornel Țăranu set to music five of Tzara's poems, all of which date from the post-Dada period. Țăranu, Anatol Vieru and ten other composers contributed to the album "La Clé de l'horizon", inspired by Tzara's work.
Tributes and portrayals.
In France, Tzara's work was collected as "Oeuvres complètes" ("Complete Works"), of which the first volume saw print in 1975, and an international poetry award is named after him ("Prix International de Poésie Tristan Tzara"). An international periodical titled "Caietele Tristan Tzara", edited by the Tristan Tzara Cultural-Literary Foundation, has been published in Moinești since 1998.
According to Paul Cernat, "Aliluia", one of the few avant-garde texts authored by Ion Vinea features a "transparent allusion" to Tristan Tzara. Vinea's fragment speaks of "the Wandering Jew", a character whom people notice because he sings "La moară la Hârța", "a suspicious song from Greater Romania." The poet is a character in Indian novelist Mulk Raj Anand's "Thieves of Fire", part four of his "The Bubble" (1984), as well as in "The Prince of West End Avenue", a 1994 book by the American Alan Isler. Rothenberg dedicated several of his poems to Tzara, as did the Neo-Dadaist Valery Oișteanu. Tzara's legacy in literature also covers specific episodes of his biography, beginning with Gertrude Stein's controversial memoir. One of his performances is enthusiastically recorded by Malcolm Cowley in his autobiographical book of 1934, "Exile's Return", and he is also mentioned in Harold Loeb's memoir "The Way It Was". Among his biographers is the French author François Buot, who records some of the lesser-known aspects of Tzara's life.
At some point between 1915 and 1917, Tzara is believed to have played chess in a coffeehouse that was also frequented by Bolshevik leader Vladimir Lenin. While Richter himself recorded the incidental proximity of Lenin's lodging to the Dadaist milieu, no record exists of an actual conversation between the two figures. Andrei Codrescu believes that Lenin and Tzara did play against each other, noting that an image of their encounter would be "the proper icon of the beginning of [modern] times." This meeting is mentioned as a fact in "Harlequin at the Chessboard", a poem by Tzara's acquaintance Kurt Schwitters. German playwright and novelist Peter Weiss, who has introduced Tzara as a character in his 1969 play about Leon Trotsky ("Trotzki im Exil"), recreated the scene in his 1975-1981 cycle "The Aesthetics of Resistance". The imagined episode also inspired much of Tom Stoppard's 1974 play "Travesties", which also depicts conversations between Tzara, Lenin, and the Irish modernist author James Joyce (who is also known to have resided in Zürich after 1915). His role was notably played by David Westhead in the 1993 British production, and by Tom Hewitt in the 2005 American version.
Alongside his collaborations with Dada artists on various pieces, Tzara himself was a subject for visual artists. Max Ernst depicts him as the only mobile character in the Dadaists' group portrait "Au Rendez-vous des Amis" ("A Friends' Reunion", 1922), while, in one of Man Ray's photographs, he is shown kneeling to kiss the hand of an androgynous Nancy Cunard. Years before their split, Francis Picabia used Tzara's calligraphed name in "Moléculaire" ("Molecular"), a composition printed on the cover of "391". The same artist also completed his schematic portrait, which showed a series of circles connected by two perpendicular arrows. In 1949, Swiss artist Alberto Giacometti made Tzara the subject of one of his first experiments with lithography. Portraits of Tzara were also made by Greta Knutson, Robert Delaunay, and the Cubist painters M. H. Maxy and Lajos Tihanyi. As an homage to Tzara the performer, art rocker David Bowie adopted his accessories and mannerisms during a number of public appearances. In 1996, he was depicted on a series of Romanian stamps, and, the same year, a concrete and steel monument dedicated to the writer was erected in Moinești.
Several of Tzara's Dadaist editions had illustrations by Picabia, Janco and Hans Arp. In its 1925 edition, "Handkerchief of Clouds" featured etchings by Juan Gris, while his late writings "Parler seul", "Le Signe de vie", "De mémoire d'homme", "Le Temps naissant", and "Le Fruit permis" were illustrated with works by, respectively, Joan Miró, Henri Matisse, Pablo Picasso, Nejad Devrim and Sonia Delaunay. Tzara was the subject of an 1949 eponymous documentary film directed by the Danish filmmaker Jørgen Roos, and footage of him featured prominently in the 1953 production "Les statues meurent aussi" ("Statues Also Die"), jointly directed by Chris Marker and Alain Resnais.
Posthumous controversies.
The many polemics which surrounded Tzara in his lifetime left traces after his death, and determine contemporary perceptions of his work. The controversy regarding Tzara's role as a founder of Dada extended into several milieus, and continued long after the writer died. Richter, who discusses the lengthy conflict between Huelsenbeck and Tzara over the issue of Dada foundation, speaks of the movement as being torn apart by "petty jealousies".
In Romania, similar debates often involved the supposed founding role of Urmuz, who wrote his avant-garde texts before World War I, and Tzara's status as a communicator between Romania and the rest of Europe. Vinea, who claimed that Dada had been invented by Tzara in Gârceni ca. 1915 and thus sought to legitimize his own modernist vision, also saw Urmuz as the ignored precursor of radical modernism, from Dada to Surrealism. In 1931 the young, modernist literary critic Lucian Boz evidenced that he partly shared Vinea's perspective on the matter, crediting Tzara and Constantin Brâncuși with having, each on his own, invented the avant-garde. Eugène Ionesco argued that "before Dadaism there was Urmuzianism", and, after World War II, sought to popularize Urmuz's work among aficionados of Dada. Rumors in the literary community had it that Tzara successfully sabotaged Ionesco's initiative to publish a French edition of Urmuz's texts, allegedly because the public could then question his claim to have initiated the avant-garde experiment in Romania and the world (the edition saw print in 1965, two years after Tzara's death).
A more radical questioning of Tzara's influence came from Romanian essayist Petre Pandrea. In his personal diary, published long after he and Tzara had died, Pandrea depicted the poet as an opportunist, accusing him of adapting his style to political requirements, of dodging military service during World War I, and of being a "Lumpenproletarian". Pandrea's text, completed just after Tzara's visit to Romania, claimed that his founding role within the avant-garde was an "illusion [...] which has swelled up like a multicolored balloon", and denounced him as "the Balkan provider of interlope odalisques, [together] with narcotics and a sort of scandalous literature." Himself an adherent to communism, Pandrea grew disillusioned with the ideology, and later became a political prisoner in Communist Romania.
From the 1960s to 1989, after a period when it ignored or attacked the avant-garde movement, the Romanian communist regime sought to recuperate Tzara, in order to validate its newly adopted emphasis on nationalist and national communist tenets. In 1977, literary historian Edgar Papu, whose controversial theories were linked to "protochronism", which presumes that Romanians took precedence in various areas of world culture, mentioned Tzara, Urmuz, Ionesco and Isou as representatives of "Romanian initiatives" and "road openers at a universal level." Elements of protochronism in this area, Paul Cernat argues, could be traced back to Vinea's claim that his friend had single-handedly created the worldwide avant-garde movement on the basis of models already present at home.

</doc>
<doc id="36886" url="http://en.wikipedia.org/wiki?curid=36886" title="Rococo">
Rococo

Rococo ( or ), less commonly roccoco, or "Late Baroque", is an 18th-century artistic movement and style, affecting many aspects of the arts including painting, sculpture, architecture, interior design, decoration, literature, music, and theatre. It developed in the early 18th century in Paris, France as a reaction against the grandeur, symmetry, and strict regulations of the Baroque, especially of the Palace of Versailles. Rococo artists and architects used a more jocular, florid, and graceful approach to the Baroque. Their style was ornate and used light colours, asymmetrical designs, curves, and gold. Unlike the political Baroque, the Rococo had playful and witty themes. The interior decoration of Rococo rooms was designed as a total work of art with elegant and ornate furniture, small sculptures, ornamental mirrors, and tapestry complementing architecture, reliefs, and wall paintings. The Rococo was also important in theatre. The book "The Rococo" states that no other culture "has produced a wittier, more elegant, and teasing dialogue full of elusive and camouflaging language and gestures, refined feelings and subtle criticism" than Rococo theatre, especially that of France.
By the end of the 18th century, Rococo was largely replaced by the Neoclassic style. In 1835 the "Dictionary of the French Academy" stated that the word "Rococo" "usually covers the kind of ornament, style and design associated with Louis XV's reign and the beginning of that of Louis XVI". It includes therefore, all types of art from around the middle of the 18th century in France. The word is seen as a combination of the French "rocaille" (stone) and "coquilles" (shell), due to reliance on these objects as decorative motifs. The term may also be a combination of the Italian word "barocco" (an irregularly shaped pearl, possibly the source of the word "baroque") and the French "rocaille" (a popular form of garden or interior ornamentation using shells and pebbles) and may describe the refined and fanciful style that became fashionable in parts of Europe in the 18th century. Owing to Rococo love of shell-like curves and focus on decorative arts, some critics used the term to derogatively imply that the style was frivolous or merely modish. When the term was first used in English in about 1836, it was a colloquialism meaning "old-fashioned". The style received harsh criticism and was seen by some to be superficial and of poor taste, especially when compared to neoclassicism; despite this, it has been praised for its aesthetic qualities, and since the mid-19th century, the term has been accepted by art historians. While there is still some debate about the historical significance of the style to art in general, Rococo is now widely recognized as a major period in the development of European art.
Historical development.
Although Rococo is usually thought of as developing first in the decorative arts and interior design, its origins lie in the late Baroque architectural work of Borromini (1599–1667) mostly in Rome and Guarini (1624–1683) mostly in Northern Italy but also in Vienna, Prague, Lisbon, and Paris. Italian architects of the late Baroque/early Rococo were wooed to Catholic (Southern) Germany, Bohemia and Austria by local princes, bishops and prince-bishops. Inspired by their example, regional families of Central European builders went further, creating churches and palaces that took the local German Baroque style to the greatest heights of Rococo elaboration and sensation.
An exotic but in some ways more formal type of Rococo appeared in France where Louis XIV's succession brought a change in the court artists and general artistic fashion. By the end of the king's long reign, rich Baroque designs were giving way to lighter elements with more curves and natural patterns. These elements are obvious in the architectural designs of Nicolas Pineau. During the Régence, court life moved away from Versailles and this artistic change became well established, first in the royal palace and then throughout French high society.
The delicacy and playfulness of Rococo designs is often seen as perfectly in tune with the excesses of Louis XV's reign.
The 1730s represented the height of Rococo development in France. The style had spread beyond architecture and furniture to painting and sculpture, exemplified by the works of Antoine Watteau and François Boucher. Rococo still maintained the Baroque taste for complex forms and intricate patterns, but by this point, it had begun to integrate a variety of diverse characteristics, including a taste for Oriental designs and asymmetric compositions. The Rococo style was spread by French artists and engraved publications.
In Great Britain, Rococo was always thought of as the "French taste" and was never widely adopted as an architectural style, although its influence was strongly felt in such areas as silverwork, porcelain, and silks, and Thomas Chippendale transformed British furniture design through his adaptation and refinement of the style. William Hogarth helped develop a theoretical foundation for Rococo beauty. Though not intentionally referencing the movement, he argued in his "Analysis of Beauty" (1753) that the undulating lines and S-curves prominent in Rococo were the basis for grace and beauty in art or nature (unlike the straight line or the circle in Classicism). The development of Rococo in Great Britain is considered to have been connected with the revival of interest in Gothic architecture early in the 18th century.
The beginning of the end for Rococo came in the early 1760s as figures like Voltaire and Jacques-François Blondel began to voice their criticism of the superficiality and degeneracy of the art. Blondel decried the "ridiculous jumble of shells, dragons, reeds, palm-trees and plants" in contemporary interiors.
By 1785, Rococo had passed out of fashion in France, replaced by the order and seriousness of Neoclassical artists like Jacques-Louis David. In Germany, late 18th century Rococo was ridiculed as "Zopf und Perücke" ("pigtail and periwig"), and this phase is sometimes referred to as "Zopfstil". Rococo remained popular in the provinces and in Italy, until the second phase of neoclassicism, "Empire style", arrived with Napoleonic governments and swept Rococo away.
There was a renewed interest in the Rococo style between 1820 and 1870. The British were among the first to revive the "Louis XIV style" as it was miscalled at first, and paid inflated prices for second-hand Rococo luxury goods that could scarcely be sold in Paris. But prominent artists like Eugène Delacroix and patrons like Empress Eugénie also rediscovered the value of grace and playfulness in art and design.
Rococo in different artistic modes.
Furniture and decorative objects.
The lighthearted themes and intricate designs of Rococo presented themselves best at a more intimate scale than the imposing Baroque architecture and sculpture. It is not surprising, then, that French Rococo art was at home indoors. Metalwork, porcelain figures and especially furniture rose to new pre-eminence as the French upper classes sought to outfit their homes in the now fashionable style.
Rococo style took pleasure in asymmetry, a taste that was new to European style. This practice of leaving elements unbalanced for effect is called "contraste".
During the Rococo period, furniture was lighthearted, physically and visually. The idea of furniture had evolved to a symbol of status and took on a role in comfort and versatility. Furniture could be easily moved around for gatherings, and many specialized forms came to be such as the fauteuil chair, the voyeuse chair, and the berger en gondola. Changes in design of these chairs ranges from cushioned detached arms, lengthening of the cushioned back (also known as "hammerhead") and a loose seat cushion. Furniture was also freestanding, instead of being anchored by the wall, to accentuate the lighthearted atmosphere and versatility of each piece. Mahogany was widely used in furniture construction due to its strength, resulting in the absence of the stretcher as seen on many chairs of the time. Also, the use of mirrors hung above mantels became ever more popular in light of the development of unblemished glass.
In a full-blown Rococo design, like the "Table d'appartement" (c. 1730), by French designer J. A. Meissonnier, working in Paris ("illustration, below"), any reference to tectonic form is gone: even the marble slab top is shaped. Apron, legs, stretcher have all been seamlessly integrated into a flow of opposed c-scrolls and "rocaille." The knot ("noeud") of the stretcher shows the asymmetrical "contraste" that was a Rococo innovation.
Most widely admired and displayed in the "minor" and decorative arts its detractors claimed that its tendency to depart from or obscure traditionally recognised forms and structures rendered it unsuitable for larger scale projects and disqualified it as a fully architectural style.
Dynasties of Parisian "ébénistes", some of them German-born, developed a style of surfaces curved in three dimensions ("bombé"), where matched veneers (marquetry temporarily being in eclipse) or "vernis martin" japanning was effortlessly complemented by gilt-bronze ("ormolu") mounts: Antoine Gaudreau, Charles Cressent, Jean-Pierre Latz, Jean-François Oeben, Bernard II van Risamburgh are the outstanding names.
French designers like François de Cuvilliés, Nicholas Pineau and the Italian Bartolomeo Rastrelli exported Parisian styles in person to Munich and Saint Petersburg, while Turin-born Juste-Aurèle Meissonier found his career at Paris. The guiding spirits of the Parisian rococo were a small group of "marchands-merciers", the forerunners of modern decorators, led by Simon-Philippe Poirier.
In French furniture the style remained somewhat more reserved, since the ornaments were mostly of wood, or, after the fashion of wood-carving, less robust and naturalistic and less exuberant in the mixture of natural with artificial forms of all kinds (e.g. plant motives, stalactitic representations, grotesques, masks, implements of various professions, badges, paintings, precious stones).
British Rococo tended to be more restrained. Thomas Chippendale's furniture designs kept the curves and feel, but stopped short of the French heights of whimsy. The most successful exponent of British Rococo was probably Thomas Johnson, a gifted carver and furniture designer working in London in the mid-18th century.
The word 'Rococo' is derived from the French "rocaille", a word used to describe the rock and shell work of the Versailles grottoes. Many pieces of carved furniture dating from the 18th century—in particular, mirror frames—depict rocks, shells, and dripping water in their composition, frequently in association with Chinese figures and pagodas.
Garden design.
"Examples designed by André Le Nôtre:"
Architecture.
Rococo architecture, as mentioned above, was a lighter, more graceful, yet also more elaborate version of Baroque architecture, which was ornate and austere. Whilst the styles were similar, there are some notable differences between both Rococo and Baroque architecture, one of them being symmetry, since Rococo emphasised the asymmetry of forms, whilst Baroque was the opposite. The styles, despite both being richly decorated, also had different themes; the Baroque, for instance, was more serious, placing an emphasis on religion, and was often characterized by Christian themes (as a matter of fact, the Baroque began in Rome as a response to the Protestant Reformation); Rococo architecture was an 18th-century, more secular, adaptation of the Baroque which was characterized by more light-hearted and jocular themes. Other elements belonging to the architectural style of Rococo include numerous curves and decorations, as well as the usage of pale colours.
There are numerous examples of Rococo buildings as well as architects. Amongst the most famous include the Catherine Palace, in Russia, the Queluz National Palace in Portugal, the Augustusburg and Falkenlust Palaces, Brühl, the Chinese House (Potsdam) the Charlottenburg Palace in Germany, as well as elements of the Château de Versailles in France. Architects who were renowned for their constructions using the style include Francesco Bartolomeo Rastrelli, an Italian architect who worked in Russia and who was noted for his lavish and opulent works, Philip de Lange, who worked in both Danish and Dutch Rococo architecture, or Matthäus Daniel Pöppelmann, who worked in the late Baroque style and who contributed to the reconstruction of the city of Dresden, in Germany.
Rococo architecture also brought significant changes to the building of edifices, placing an emphasis on privacy rather than the grand public majesty of Baroque architecture, as well as improving the structure of buildings in order to create a more healthy environment.
Interior design.
Solitude Palace in Stuttgart and Chinese Palace in Oranienbaum, the Bavarian church of Wies and Sanssouci in Potsdam are examples of how Rococo made its way into European architecture.
In those Continental contexts where Rococo is fully in control, sportive, fantastic, and sculptured forms are expressed with abstract ornament using flaming, leafy or shell-like textures in asymmetrical sweeps and flourishes and broken curves; intimate Rococo interiors suppress architectonic divisions of architrave, frieze, and cornice for the picturesque, the curious, and the whimsical, expressed in plastic materials like carved wood and above all stucco (as in the work of the Wessobrunner School). Walls, ceiling, furniture, and works of metal and porcelain present a unified ensemble. The Rococo palette is softer and paler than the rich primary colors and dark tonalities favored in Baroque tastes.
A few anti-architectural hints rapidly evolved into full-blown Rococo at the end of the 1720s and began to affect interiors and decorative arts throughout Europe. The richest forms of German Rococo are in Catholic Germany ("illustration, above").
Rococo plasterwork by immigrant Italian-Swiss artists like Bagutti and Artari is a feature of houses by James Gibbs, and the Franchini brothers working in Ireland equalled anything that was attempted in Great Britain.
Inaugurated in some rooms in Versailles, it unfolds its magnificence in several Parisian buildings (especially the Hôtel Soubise). In Germany, French and German artists (Cuvilliés, Neumann, Knobelsdorff, etc.) effected the dignified equipment of the Amalienburg near Munich, and the castles of Würzburg, Potsdam, Charlottenburg, Brühl, Bruchsal, Solitude (Stuttgart), and Schönbrunn.
In Great Britain, one of Hogarth's set of paintings forming a melodramatic morality tale titled "Marriage à la Mode", engraved in 1745, shows the parade rooms of a stylish London house, in which the only rococo is in plasterwork of the salon's ceiling. Palladian architecture is in control. Here, on the Kentian mantel, the crowd of Chinese vases and mandarins are satirically rendered as hideous little monstrosities, and the Rococo wall clock is a jumble of leafy branches.
In general, Rococo is an entirely interior style, because the wealthy and aristocratic moved back to Paris from Versailles. Paris was already built up and so rather than engaging in major architectural additions, they simply renovated the interiors of the existing buildings.
Painting.
Though Rococo originated in the purely decorative arts, the style showed clearly in painting. These painters used delicate colors and curving forms, decorating their canvases with cherubs and myths of love. Portraiture was also popular among Rococo painters. Some works show a sort of naughtiness or impurity in the behavior of their subjects, showing the historical trend of departing away from the Baroque's church/state orientation. Landscapes were pastoral and often depicted the leisurely outings of aristocratic couples.
Jean-Antoine Watteau (1684–1721) is generally considered the first great Rococo painter. He had a great influence on later painters, including François Boucher (1703–1770) and Jean-Honoré Fragonard (1732–1806), two masters of the late period. Even Thomas Gainsborough's (1727–1788) delicate touch and sensitivity are reflective of the Rococo spirit. Élisabeth-Louise Vigée-Le Brun's (1755–1842) style also shows a great deal of Rococo influence, particularly in her portraits of Marie Antoinette. Other Rococo painters include: Jean François de Troy (1679–1752), Jean-Baptiste van Loo (1685–1745), his two sons Louis-Michel van Loo (1707–1771) and Charles-Amédée-Philippe van Loo (1719–1795), his younger brother Charles-André van Loo (1705–1765), and Nicolas Lancret (1690–1743). Both Jean-Baptiste-Siméon Chardin (1699–1779) and Jean-Baptiste Greuze (1725–1805), were important French painters of the Rococo era who are considered "Anti-Rococo."
During the Rococo era Portraiture was an important component of painting in all countries, but especially in Great Britain, where the leaders were William Hogarth (1697–1764), in a blunt realist style, and Francis Hayman (1708–1776), Angelica Kauffman who was Swiss, (1741–1807), Thomas Gainsborough and Joshua Reynolds (1723–1792), in more flattering styles influenced by Anthony van Dyck (1599–1641). While in France during the Rococo era Jean-Baptiste Greuze was the favorite painter of Denis Diderot (1713–1785), and Maurice Quentin de La Tour (1704–1788), Alexander Roslin(1718–1793) Élisabeth Vigée-Lebrun were highly accomplished portrait painters and history painters.
Sculpture.
Sculpture was another area where the Rococo was widely adopted.
Étienne-Maurice Falconet (1716–1791) is widely considered one of the best representatives of French Rococo. In general, this style was best expressed through delicate porcelain sculpture rather than imposing marble statues. Falconet himself was director of a famous porcelain factory at Sèvres. The themes of love and gaiety were reflected in sculpture, as were elements of nature, curving lines and asymmetry.
The sculptor Edmé Bouchardon represented Cupid engaged in carving his darts of love from the club of Hercules ("illustration"); this serves as an excellent symbol of the Rococo style—the demigod is transformed into the soft child, the bone-shattering club becomes the heart-scathing arrows, just as marble is so freely replaced by stucco. In this connection, the French sculptors, Jean-Louis Lemoyne, Jean-Baptiste Lemoyne, Robert Le Lorrain, Louis-Simon Boizot, Michel Clodion, and Pigalle may be mentioned in passing.
Music.
A Rococo period existed in music history, although it is not as well known as the earlier Baroque and later Classical forms. The Rococo music style itself developed out of baroque music both in France, where the new style was referred to as "style galante" ("gallant" or "elegant" style), and in Germany, where it was referred to as "empfindsamer stil" ("sensitive style"). It can be characterized as light, intimate music with extremely elaborate and refined forms of ornamentation. Exemplars include Jean Philippe Rameau, Louis-Claude Daquin and François Couperin in France; in Germany, the style's main proponents were C. P. E. Bach and Johann Christian Bach, two sons of the renowned J.S. Bach.
An insight into the French term "galante" can be seen through Boucher's painting "Le Déjeuner" (above), which provides a glimpse of the society which Rococo reflected. "Courtly" would be pretentious in this upper bourgeois circle, yet the man's gesture is gallant. The stylish but cozy interior, the informal decorous intimacy of people's manners, the curious and delightful details everywhere one turns one's eye, the luxury of sipping chocolate: all are "galante."
In the second half of the 18th century, a reaction against the Rococo style occurred, primarily against its perceived overuse of ornamentation and decoration. Led by C.P.E. Bach (an accomplished Rococo composer in his own right), Domenico Scarlatti, and Christoph Willibald Gluck, this reaction ushered in the Classical era. By the early 19th century, Catholic opinion had turned against the suitability of the style for ecclesiastical contexts because it was "in no way conducive to sentiments of devotion".

</doc>
<doc id="36887" url="http://en.wikipedia.org/wiki?curid=36887" title="1493">
1493

Year 1493 (MCDXCIII) was a common year starting on Tuesday (link will display the full calendar) of the Julian calendar).
Events.
<onlyinclude>

</doc>
<doc id="36889" url="http://en.wikipedia.org/wiki?curid=36889" title="IOM">
IOM

IOM may refer to:

</doc>
<doc id="36891" url="http://en.wikipedia.org/wiki?curid=36891" title="Silicate">
Silicate

A silicate is a compound containing an anionic silicon compound. The great majority of silicates are oxides, but hexafluorosilicate ([SiF6]2−) and other anions are also included.
"Orthosilicate" is the anion SiO44− or its compounds. Related to orthosilicate are families of anions (and their compounds) with the formula [SiO2+n]2n−. Important members are the cyclic and single chain silicates {[SiO3]2−}n and the sheet-forming silicates {[SiO2.5]−}n.
Silicates comprise the majority of Earth's crust, as well as the other terrestrial planets, rocky moons, and asteroids. Sand, Portland cement, and thousands of minerals are examples of silicates. Silicate compounds, including the minerals, consist of silicate anions whose charge is balanced by various cations. Myriad silicate anions can exist, and each can form compounds with many different cations. Hence this class of compounds is very large. Both minerals and synthetic materials fit in this class.
Structural principles.
In the vast majority of silicates, including silicate minerals, the Si occupies a tetrahedral environment, being surrounded by 4 oxygen centres. In these structures, the chemical bonds to silicon conform to the octet rule. These tetrahedra sometimes occur as isolated SiO44− centres, but most commonly, the tetrahedra are joined together in various ways, such as pairs (Si2O76−) and rings (Si6O1812−). Commonly the silicate anions are chains, double chains, sheets, and three-dimensional frameworks. All these such species have negligible solubility in water at normal conditions.
Occurrence in solution.
Silicates are well characterized as solids, but are less commonly observed in solution. The anion SiO44− is the conjugate base of silicic acid, Si(OH)4, and both are elusive as are all of the intermediate species. Instead, solutions of silicates are usually observed as mixtures of condensed and partially protonated silicate clusters. The nature of soluble silicates is relevant to understanding biomineralization and the synthesis of aluminosilicates, such as the industrially important catalysts called zeolites.
Silicates with non-tetrahedral silicon.
Although the tetrahedron is the common coordination geometry for silicon compounds, silicon is well known to also adopt higher coordination numbers. A well-known example of such a high coordination number is hexafluorosilicate (SiF62−). Octahedral coordination by 6 oxygen centres is observed. At very high pressure, even SiO2 adopts this geometry in the mineral stishovite, a dense polymorph of silica found in the lower mantle of the Earth. This structure is also formed by shock during meteorite impacts. Octahedral Si in the form of hexahydroxysilicate ([Si(OH)6]2−) is observed in thaumasite a mineral occurring rarely in nature but sometimes observed amongst other calcium silicate hydrate artificially formed in cement and concrete submitted to a severe sulfate attack.
Silicate rock and minerals.
In geology and astronomy, the term silicate is used to denote types of rock that consist predominantly of silicate minerals. On Earth, a wide variety of silicate minerals occur in an even wider range of combinations as a result of the processes that form and re-work the crust. These processes include partial melting, crystallization, fractionation, metamorphism, weathering and diagenesis. Living things also contribute to the silicate cycle near the Earth's surface. A type of plankton known as diatoms construct their exoskeletons, known as tests, from silica. The tests of dead diatoms are a major constituent of deep ocean sediment.
Silica, or silicon dioxide, SiO2, is sometimes considered a silicate, although it is the special case with no negative charge and no need for counter-ions. Silica is found in nature as the mineral quartz, and its polymorphs.
Portland cement.
Portland cement is produced by hydration of clinker, which consists of various calcium silicates, including tricalcium silicate (Ca3SiO5, also written CaO.Ca2SiO4) and dicalcium silicate (Ca2SiO4). These components are often generated in situ by heating various clays and limestone.
Mineralogy.
Mineralogically, silicate minerals are divided according to structure of their silicate anion into the following groups:
Note that tectosilicates can only have additional cations if some of the silicon is replaced by a lower-charge cation such as aluminium. Al for Si substitution is common.

</doc>
<doc id="36893" url="http://en.wikipedia.org/wiki?curid=36893" title="International Organization for Migration">
International Organization for Migration

The International Organization for Migration (IOM) is an intergovernmental organization. It was initially established in 1951 as the Intergovernmental Committee for European Migration (ICEM) to help resettle people displaced by World War II. As of April 2015, the International Organization for Migration has 157 member states and 10 observer states.
It is the principal intergovernmental organization in the field of migration. IOM is dedicated to promoting humane and orderly migration for the benefit of all. It does so by providing services and advice to governments and migrants.
IOM works to help ensure the orderly and humane management of migration, to promote international cooperation on migration issues, to assist in the search for practical solutions to migration problems and to provide humanitarian assistance to migrants in need, be they refugees, displaced persons or other uprooted people. 
 gives explicit recognition to the link between migration and economic, social and cultural development, as well as to the right of freedom of movement of persons.
IOM works in the four broad areas of migration management: migration and development, facilitating migration, regulating migration, and addressing forced migration. Cross-cutting activities include the promotion of international migration law, policy debate and guidance, protection of migrants’ rights, migration health and the gender dimension of migration.
In addition, IOM has often organized elections for refugees out of their home country, as was the case in the 2004 Afghan elections and the 2005 Iraqi elections.
IOM works closely with governmental, intergovernmental and non-governmental partners.
History.
IOM, or as it was first known, the Provisional Intergovernmental Committee for the Movement of Migrants from Europe (PICMME), was born in 1951 out of the chaos and displacement of Western Europe following the Second World War.
Mandated to help European governments to identify resettlement countries for the estimated 11 million people uprooted by the war, it arranged transport for nearly a million migrants during the 1950s.
The Constitution of the International Organization for Migration was concluded on 19 October 1953 in Venice as the Constitution of the Intergovernmental Committee for European Migration. The Constitution entered into force on 30 November 1954 and the organization was formally born.
The organization underwent a succession of name changes from PICMME to the Intergovernmental Committee for European Migration (ICEM) in 1952, to the Intergovernmental Committee for Migration (ICM) in 1980, and to the International Organization for Migration (IOM) in 1989; these changes reflect the organization's transition over half a century from a logistics agency to a migration agency.
While IOM's history tracks the man-made and natural disasters of the past half century—Hungary 1956, Czechoslovakia 1968, Chile 1973, the Vietnamese Boat People 1975, Kuwait 1990, Kosovo and Timor 1999, and the Asian tsunami, the 2003 invasion of Iraq, the Pakistan earthquake of 2004/2005 and the 2010 Haiti earthquake—its credo that humane and orderly migration benefits migrants and society has steadily gained international acceptance.
From its roots as an operational logistics agency, it has broadened its scope to become the leading international agency working with governments and civil society to advance the understanding of migration issues, encourage social and economic development through migration, and uphold the human dignity and well-being of migrants.
The broader scope of activities has been matched by rapid expansion from a relatively small agency into one with an annual operating budget of $1.3 billion and some 8,400 staff working in over 100 countries worldwide.
As "The Migration Agency" IOM has become the point of reference in the heated global debate on the social, economic and political implications of migration in the 21st century.
Member States.
As of June 2014, the International Organization for Migration has 156 member states and 10 observer states.
Member States:
Observer States:

</doc>
<doc id="36895" url="http://en.wikipedia.org/wiki?curid=36895" title="History of Burgundy">
History of Burgundy

The History of Burgundy stretches back to the times when the region was inhabited in turn by Celts, Romans (Gallo-Romans), and in the 4th century, the Roman allies the Burgundians, a Germanic people possibly originating in Bornholm (Baltic Sea), who settled there and established their own kingdom. However, Agathias identifies Burgunds ("Βουρουγουνδοι") and Ultizurs as Bulgaric people of Hunnic circle tribes, near relatives of Turkic Cotrigurs and Utigurs.
This Burgundian kingdom was conquered in the 6th century by another Germanic tribe, the Franks who continued the kingdom of Burgundy under their own rule. 
Later, the region was divided between the Duchy of Burgundy (to the west) and the County of Burgundy (to the east). The Duchy of Burgundy is the better-known of the two, later becoming the French province of Burgundy, while the County of Burgundy became the French province of Franche-Comté, literally meaning "free county". 
The situation is complicated by the fact that at different times and under different geopolitical circumstances, many different entities have gone by the name of ‘Burgundy’. Historian Norman Davies has commented that "[f]ew subjects in European history have created more havoc than that summarized by the phrase ‘all the Burgundies’." In 1862, James Bryce compiled a list of ten such entities, a list which Davies himself extends to fifteen, ranging from the first Burgundian kingdom founded by Gunther in the fifth century, to the modern French "région" of Burgundy.
The Burgundians were one of the Germanic or Turko-Germanic alliance peoples who filled the power vacuum left by the collapse of the western half of the Roman Empire. In A.D. 411, they crossed the Rhine and established a kingdom at Worms. Amidst repeated clashes between the Romans and Huns, the Burgundian kingdom eventually occupied what is today the borderlands between Switzerland, France, and Italy. In 534, the Franks defeated Godomar, the last Burgundian king, and absorbed the territory into their growing empire.
Burgundy's modern existence is rooted in the dissolution of the Frankish Empire. In the 880s, there were four Burgundies: 
The two kingdoms of Upper and Lower Burgundy were reunited in 937 and absorbed into the Holy Roman Empire under Conrad II in 1032, as the Kingdom of Arles. 
The Duchy of Burgundy was annexed by the French throne in 1004. The County of Burgundy remained loosely associated with the Holy Roman Empire (intermittently independent, whence the name "Franche-Comté"), and finally incorporated into France in 1678, with the Treaties of Nijmegen.
During the Middle Ages, Burgundy was the seat of some of the most important Western churches and monasteries, among them Cluny, Cîteaux, and Vézelay.
During the Hundred Years' War, King John II of France gave the duchy to his youngest son, Philip the Bold, rather than leaving it for his successor on the French throne. The duchy soon became a major rival to the throne, because the Dukes of Burgundy succeeded in assembling an empire stretching from Switzerland to the North Sea, in large part by marriage. The Burgundian territories consisted of a number of fiefdoms on both sides of the (then largely symbolic) border between the Kingdom of France and the Holy Roman Empire. Its economic heartland was in the Low Countries, particularly Flanders and Brabant. The court in Dijon outshone the French court both economically and culturally. In Belgium and in the south of the Netherlands, a 'Burgundian lifestyle' still means 'enjoyment of life, good food, and extravagant spectacle'.
In 1477, at the battle of Nancy during the Burgundian Wars, the last duke Charles the Bold was killed in battle, and the Duchy itself was annexed by France. In the late 15th and early 16th centuries, the other Burgundian territories provided a power base for the rise of the Habsburgs, after Maximilian of Austria married the surviving daughter of the ducal family, Mary. After her death, her husband moved his court first to Mechelen and later to the palace at Coudenberg, Brussels, and from there ruled the remnants of the empire, the Low Countries (Burgundian Netherlands) and Franche-Comté, then still an imperial fief. The latter territory was ceded to France in the Treaty of Nijmegen of 1678.
With the French Revolution in the end of the 18th century, the administrative units of the regions disappeared, but were reconstituted during the Fifth Republic in the 1970s. The modern-day administrative "région" includes most of the former duchy.

</doc>
<doc id="36896" url="http://en.wikipedia.org/wiki?curid=36896" title="Lion">
Lion

The lion ("Panthera leo") is one of the five big cats in the genus "Panthera" and a member of the family Felidae. The commonly used term African lion collectively denotes the several subspecies found in Africa. With some males exceeding 250 kg in weight, it is the second-largest living cat after the tiger. Wild lions currently exist in sub-Saharan Africa and in Asia (where an endangered remnant population resides in Gir Forest National Park in India) while other types of lions have disappeared from North Africa and Southwest Asia in historic times. Until the late Pleistocene, about 10,000 years ago, the lion was the most widespread large land mammal after humans. They were found in most of Africa, across Eurasia from western Europe to India, and in the Americas from the Yukon to Peru. The lion is a vulnerable species, having seen a major population decline in its African range of 30–50% per two decades during the second half of the 20th century. Lion populations are untenable outside designated reserves and national parks. Although the cause of the decline is not fully understood, habitat loss and conflicts with humans are currently the greatest causes of concern. Within Africa, the West African lion population is particularly endangered.
Lions live for 10–14 years in the wild, although in captivity they can live more than 20 years. In the wild, males seldom live longer than 10 years, as injuries sustained from continual fighting with rival males greatly reduce their longevity. They typically inhabit savanna and grassland, although they may take to bush and forest. Lions are unusually social compared to other cats. A pride of lions consists of related females and offspring and a small number of adult males. Groups of female lions typically hunt together, preying mostly on large ungulates. Lions are apex and keystone predators, although they are also expert scavengers obtaining over 50 percent of their food by scavenging as opportunity allows. While lions do not typically hunt humans, some have been known to do so. Sleeping mainly during the day, lions are primarily nocturnal, although bordering on crepuscular in nature.
Highly distinctive, the male lion is easily recognised by its mane, and its face is one of the most widely recognised animal symbols in human culture. Depictions have existed from the Upper Paleolithic period, with carvings and paintings from the Lascaux and Chauvet Caves, through virtually all ancient and medieval cultures where they once occurred. It has been extensively depicted in sculptures, in paintings, on national flags, and in contemporary films and literature. Lions have been kept in menageries since the time of the Roman Empire, and have been a key species sought for exhibition in zoos over the world since the late eighteenth century. Zoos are cooperating worldwide in breeding programs for the endangered Asiatic subspecies.
Etymology.
The lion's name, similar in many Romance languages, is derived from the Latin "leo", and the Ancient Greek λέων ("leon"). The Hebrew word לָבִיא ("lavi") may also be related. It was one of the species originally described by Linnaeus, who gave it the name "Felis leo", in his eighteenth-century work, "Systema Naturae".
Taxonomy and evolution.
The lion's closest relatives are the other species of the genus "Panthera": the tiger, the jaguar, and the leopard. "P. leo" evolved in Africa between 1 million and 800,000 years ago, before spreading throughout the Holarctic region. It appeared in the fossil record in Europe for the first time 700,000 years ago with the subspecies "Panthera leo fossilis" at Isernia in Italy. From this lion derived the later cave lion ("Panthera leo spelaea"), which appeared about 300,000 years ago. Lions died out in northern Eurasia at the end of the last glaciation, about 10,000 years ago; this may have been secondary to the extinction of Pleistocene megafauna.
Subspecies.
Traditionally, 12 recent subspecies of lion were recognised, distinguished by mane appearance, size, and distribution. Because these characteristics are very insignificant and show a high individual variability, most of these forms were probably not true subspecies, especially as they were often based upon zoo material of unknown origin that may have had "striking, but abnormal" morphological characteristics. Today, only eight subspecies are usually accepted, although one of these, the Cape lion, formerly described as "Panthera leo melanochaita", is probably invalid. Even the remaining seven subspecies might be too many. While the status of the Asiatic lion ("P. l. persica") as a subspecies is generally accepted, the systematic relationships among African lions are still not completely resolved. Mitochondrial variation in living African lions seemed to be modest according to some newer studies, therefore all sub-Saharan lions sometimes have been considered a single subspecies, however, a recent study revealed lions from western and central Africa differ genetically from lions of southern or eastern Africa. According to this study, Western African lions are more closely related to Asian lions than to South or East African lions. These findings might be explained by a late Pleistocene extinction event of lions in western and central Africa and a subsequent recolonization of these parts from Asia. Previous studies, which were focused mainly on lions from eastern and southern parts of Africa, already showed these can be possibly divided in two main clades: one to the west of the Great Rift Valley and the other to the east. Lions from Tsavo in eastern Kenya are much closer genetically to lions in Transvaal (South Africa), than to those in the Aberdare Range in western Kenya. Another study revealed there are three major types of lions, one North African–Asian, one southern African and one middle African. Conversely, Per Christiansen found that using skull morphology allowed him to identify the subspecies "krugeri", "nubica", "persica", and "senegalensis", while there was overlap between "bleyenberghi" with "senegalensis" and "krugeri". The Asiatic lion "persica" was the most distinctive, and the Cape lion had characteristics allying it more with "P. l. persica" than the other sub-Saharan lions. He had analysed 58 lion skulls in three European museums.
The majority of lions kept in zoos are hybrids of different subspecies. Approximately 77% of the captive lions registered by the International Species Information System are of unknown origin. Nonetheless, they might carry genes that are extinct in the wild, and might be therefore important to maintain overall genetic variability of the lion. It is believed that those lions, imported to Europe before the middle of the nineteenth century, were mainly either Barbary lions from North Africa or lions from the Cape.
Recent.
Eight recent (Holocene) subspecies are recognised today:
Pleistocene.
Several additional subspecies of lion existed in prehistoric times:
Hybrids.
Lions have been known to breed with tigers (most often the Siberian and Bengal subspecies) to create hybrids called ligers and tiglons (or tigons). They also have been crossed with leopards to produce leopons, and jaguars to produce jaglions. The marozi is reputedly a spotted lion or a naturally occurring leopon, while the Congolese spotted lion is a complex lion-jaguar-leopard hybrid called a lijagulep. Such hybrids were once commonly bred in zoos, but this is now discouraged due to the emphasis on conserving species and subspecies. Hybrids are still bred in private menageries and in zoos in China.
The liger is a cross between a male lion and a tigress. Because the growth-inhibiting gene from the female tiger mother is absent, the growth-promoting gene passed on by the male lion father is unimpeded by a regulating gene and the resulting ligers grow far larger than either parent. They share physical and behavioural qualities of both parent species (spots and stripes on a sandy background). Male ligers are sterile, but female ligers often are fertile. Males have about a 50% chance of having a mane, but if they grow them, their manes will be modest: around 50% the size of a pure lion mane.
Ligers are much bigger than normal lions, typically 3.65 m in length, and can weigh up to 500 kg.
The less common tiglon or tigon is a cross between a lioness and a male tiger. In contrast to ligers, tigons are often relatively small in comparison to their parents, because of reciprocal gene effects.
Characteristics.
Behind only the tiger, the lion is the second largest living felid in length and weight. Its skull is very similar to that of the tiger, although the frontal region is usually more depressed and flattened, with a slightly shorter postorbital region. The lion's skull has broader nasal openings than the tiger, however, due to the amount of skull variation in the two species, usually, only the structure of the lower jaw can be used as a reliable indicator of species. Lion colouration varies from light buff to yellowish, reddish, or dark ochraceous brown. The underparts are generally lighter and the tail tuft is black. Lion cubs are born with brown rosettes (spots) on their body, rather like those of a leopard. Although these fade as lions reach adulthood, faint spots often may still be seen on the legs and underparts, particularly on lionesses.
Lions are the only members of the cat family to display obvious sexual dimorphism – that is, males and females look distinctly different. They also have specialised roles that each gender plays in the pride. For instance, the lioness, the hunter, lacks the male's thick mane. The colour of the male's mane varies from blond to black, generally becoming darker as the lion grows older. The most distinctive characteristic shared by both females and males is that the tail ends in a hairy tuft. In some lions, the tuft conceals a hard "spine" or "spur", approximately 5 mm long, formed of the final sections of tail bone fused together. The lion is the only felid to have a tufted tail – the function of the tuft and spine are unknown. Absent at birth, the tuft develops around 5½ months of age and is readily identifiable at 7 months.
The size of adult lions varies across their range with those from the southern African populations in Zimbabwe, the Kalahari and Kruger Park averaging around 189.6 kg and 126.9 kg in males and females respectively compared to 174.9 kg and 119.5 kg of male and female lions from East Africa. Reported body measurements in males are head-body lengths ranging from 170 to, tail lengths of 90 –. In females reported head-body lengths range from 140 to, tail lengths of 70 –, however, the frequently cited maximum head and body length of 250 cm fits rather to extinct Pleistocene forms, like the American lion, with even large modern lions measuring several centimetres less in length. Record measurements from hunting records are supposedly a total length of nearly 3.6 m for a male shot near Mucsso, southern Angola in October 1973 and a weight of 313 kg for a male shot outside Hectorspruit in eastern Transvaal, South Africa in 1936. Another notably outsized male lion, which was shot near Mount Kenya, weighed in at 272 kg.
Mane.
The mane of the adult male lion, unique among cats, is one of the most distinctive characteristics of the species. It may provide an excellent intimidation display; aiding the lion during confrontations with other lions. The presence, absence, colour, and size of the mane is associated with genetic precondition, sexual maturity, climate, and testosterone production; the rule of thumb is the darker and fuller the mane, the healthier the lion. Sexual selection of mates by lionesses favors males with the densest, darkest mane. Research in Tanzania also suggests mane length signals fighting success in male–male relationships. Darker-maned individuals may have longer reproductive lives and higher offspring survival, although they suffer in the hottest months of the year.
Scientists once believed that the distinct status of some subspecies could be justified by morphology, including the size of the mane. Morphology was used to identify subspecies such as the Barbary lion and Cape lion. Research has suggested, however, that environmental factors influence the colour and size of a lion's mane, such as the ambient temperature. The cooler ambient temperature in European and North American zoos, for example, may result in a heavier mane. Thus the mane is not an appropriate marker for identifying subspecies. The males of the Asiatic subspecies, however, are characterised by sparser manes than average African lions.
In the Pendjari National Park area almost all males are maneless or have very weak manes. Maneless male lions have also been reported from Senegal, from Sudan (Dinder National Park), and from Tsavo East National Park in Kenya, and the original male white lion from Timbavati also was maneless. The testosterone hormone has been linked to mane growth, therefore castrated lions often have minimal to no mane, as the removal of the gonads inhibits testosterone production.
Cave paintings of extinct European cave lions almost exclusively show animals with no manes, suggesting that either they were maneless, or that the paintings depict lionesses as seen hunting in a group.
White lions.
The white lion is not a distinct subspecies, but a special morph with a genetic condition, leucism, that causes paler colouration akin to that of the white tiger; the condition is similar to melanism, which causes black panthers. They are not albinos, having normal pigmentation in the eyes and skin. White Transvaal lion ("Panthera leo krugeri") individuals occasionally have been encountered in and around Kruger National Park and the adjacent Timbavati Private Game Reserve in eastern South Africa, but are more commonly found in captivity, where breeders deliberately select them. The unusual cream colour of their coats is due to a recessive allele. Reportedly, they have been bred in camps in South Africa for use as trophies to be killed during canned hunts.
Behaviour.
Lions spend much of their time resting and are inactive for about 20 hours per day. Although lions can be active at any time, their activity generally peaks after dusk with a period of socializing, grooming, and defecating. Intermittent bursts of activity follow through the night hours until dawn, when hunting most often takes place. They spend an average of two hours a day walking and 50 minutes eating.
Group organization.
Lions are the most socially inclined of all wild felids, most of which remain quite solitary in nature. The lion is a predatory carnivore with two types of social organization. Some lions are "residents," living in groups centering around related lionesses, called "prides". Females form the stable social unit in a pride and do not tolerate outside females. Membership only changes with the births and deaths of lionesses, although some females do leave and become nomadic. Although extremely large prides, consisting of up to 30 individuals, have been observed, the average pride consists of five or six females, their cubs of both sexes, and one or two males (known as a "coalition" if more than one) who mate with the adult females. The number of adult males in a coalition is usually two but may increase to as many as four before decreasing again over time. The sole exception to this pattern is the Tsavo lion pride which always has just one adult male. Male cubs are excluded from their maternal pride when they reach maturity at around 2–3 years of age. The second organizational behaviour is labeled "nomads", who range widely and move about sporadically, either singularly or in pairs. Pairs are more frequent among related males who have been excluded from their birth pride. Note that a lion may switch lifestyles; nomads may become residents and vice versa. Males, as a rule, live at least some portion of their lives as nomads, and some are never able to join another pride. A female who becomes a nomad has much greater difficulty joining a new pride, as the females in a pride are related, and they reject most attempts by an unrelated female to join their family group.
The area a pride occupies is called a "pride area", whereas that by a nomad is a "range". The males associated with a pride tend to stay on the fringes, patrolling their territory. Why sociality – the most pronounced in any cat species – has developed in lionesses is the subject of much debate. Increased hunting success appears an obvious reason, but this is less than sure upon examination: coordinated hunting does allow for more successful predation but also ensures that non-hunting members reduce per capita calorific intake; however, some take a role raising cubs, who may be left alone for extended periods of time. Members of the pride regularly tend to play the same role in hunts and hone their skills. The health of the hunters is the primary need for the survival of the pride, and they are the first to consume the prey at the site it is taken. Other benefits include possible kin selection (better to share food with a related lion than with a stranger), protection of the young, maintenance of territory, and individual insurance against injury and hunger.
Lionesses do most of the hunting for their pride. They are more effective hunters, as they are smaller, swifter, and more agile than the males and unencumbered by the heavy and conspicuous mane, which causes overheating during exertion. They act as a coordinated group with members who perform the same role consistently in order to stalk and bring down the prey successfully. Smaller prey is eaten at the location of the hunt, thereby being shared among the hunters; when the kill is larger it often is dragged to the pride area. There is more sharing of larger kills, although pride members often behave aggressively toward each other as each tries to consume as much food as possible. Near the conclusion of the hunt, males have a tendency to dominate the kill once the lionesses have succeeded. They are more likely to share this with the cubs than with the lionesses, but males rarely share food they have killed by themselves.
Both males and females can defend the pride against intruders, but the male lion is better-suited for this purpose due to its stockier, more powerful build. Some individuals consistently lead the defence against intruders, while others lag behind. Lions tend to assume specific roles in the pride. Those lagging behind may provide other valuable services to the group. An alternative hypothesis is that there is some reward associated with being a leader who fends off intruders, and the rank of lionesses in the pride is reflected in these responses. The male or males associated with the pride must defend their relationship to the pride from outside males who attempt to take over their relationship with the pride.
Hunting and diet.
Lions prefer to scavenge when the opportunity presents itself with carrion providing more than 50% of their diet. They scavenge animals either dead from natural causes (disease) or killed by other predators, and keep a constant lookout for circling vultures, being keenly aware that they indicate an animal dead or in distress. In fact, most dead prey on which both hyenas and lions feed upon are killed by the hyenas instead of the lions.
The lionesses do most of the hunting for the pride. The male lion associated with the pride usually stays and watches over young cubs until the lionesses return from the hunt. Typically, several work together and encircle the herd from different points. Once they have closed in on the herd, they usually target the animal closest to them. The attack is short and powerful; they attempt to catch the victim with a fast rush and final leap. The prey usually is killed by strangulation, which can cause cerebral ischemia or asphyxia (which results in hypoxemic, or "general", hypoxia). The prey also may be killed by the lion enclosing the animal's mouth and nostrils in its jaws (which would also result in asphyxia).
Lions usually hunt in coordinated groups and stalk their chosen prey. However, they are not particularly known for their stamina – for instance, a lioness' heart makes up only 0.57% of her body weight (a male's is about 0.45% of his body weight), whereas a hyena's heart is close to 1% of its body weight. Thus, they only run fast in short bursts, and need to be close to their prey before starting the attack. They take advantage of factors that reduce visibility; many kills take place near some form of cover or at night. They sneak up to the victim until they reach a distance of approximately 30 m or less.
The prey consists mainly of medium-sized mammals, with a preference for wildebeest, zebras, buffalo, and warthogs in Africa and nilgai, wild boar, and several deer species in India. Many other species are hunted, based on availability, mainly ungulates weighing between 50 and such as kudu, hartebeest, gemsbok, and eland. Occasionally, they take relatively small species such as Thomson's gazelle or springbok. Lions hunting in groups are capable of taking down most animals, even healthy adults, but in most parts of their range they rarely attack very large prey such as fully grown male giraffes due to the danger of injury. Giraffes and buffaloes are almost invulnerable to a solitary lion as well.
Extensive studies show that lionesses normally prey on mammals with an average weight of 126 kg, while kills made by male lions average 399 kg. In Africa, wildebeest rank at the top of preferred prey (making nearly half of the lion prey in the Serengeti) followed by zebra. Lions do not prey on fully grown adult elephants; most adult hippopotamuses, rhinoceroses, and smaller gazelles, impala, and other agile antelopes are generally excluded. However, giraffes and buffaloes are often taken in certain regions. For instance, in Kruger National Park, giraffes are regularly hunted. In Manyara Park, Cape buffaloes constitute as much as 62% of the lion's diet, due to the high number density of buffaloes. Occasionally hippopotamus is also taken, but adult rhinoceroses are generally avoided. Warthogs are often taken depending on availability. The lions of Savuti, Botswana, have adapted to hunting young elephants during the dry season, and a pride of 30 lions has been recorded killing individuals between the ages of four and eleven years. In the Kalahari desert in South Africa, black-maned lions may chase baboons up a tree, wait patiently, then attack them when they try to escape:
Lions also attack domestic livestock and in India cattle contribute significantly to their diet. Lions are capable of killing other predators such as leopards, cheetahs, hyenas, and wild dogs, though (unlike most felids) they seldom devour the competitors after killing them. A lion may gorge itself and eat up to 30 kg in one sitting; if it is unable to consume all the kill it will rest for a few hours before consuming more. On a hot day, the pride may retreat to shade leaving a male or two to stand guard. An adult lioness requires an average of about 5 kg of meat per day, a male about 7 kg.
Because lionesses hunt in open spaces where they are easily seen by their prey, cooperative hunting increases the likelihood of a successful hunt; this is especially true with larger species. Teamwork also enables them to defend their kills more easily against other large predators such as hyenas, which may be attracted by vultures from kilometres away in open savannas. Lionesses do most of the hunting; males attached to prides do not usually participate in hunting, except in the case of larger quarry such as giraffe and buffalo. In typical hunts, each lioness has a favored position in the group, either stalking prey on the "wing" then attacking, or moving a smaller distance in the centre of the group and capturing prey in flight from other lionesses. There is evidence that male lions are just as successful at hunting as females; they are solo hunters who ambush prey in small bush. Young lions first display stalking behaviour around three months of age, although they do not participate in hunting until they are almost a year old. They begin to hunt effectively when nearing the age of two.
Predator competition.
Lions and spotted hyenas occupy the same ecological niche, meaning they compete for prey and carrion in the areas where they coexist. A review of data across several studies indicates a dietary overlap of 58.6%. Lions typically ignore spotted hyenas unless the lions are on a kill or are being harassed by the hyenas, while the latter tend to visibly react to the presence of lions whether there is food or not. Lions seize the kills of spotted hyenas: in the Ngorongoro crater, it is common for lions to subsist largely on kills stolen from hyenas, causing the hyenas to increase their kill rate. On the other hand, in Northern Botswana's Chobe National Park, the situation is reversed: hyenas frequently challenge lions and steal their kills: they obtain food from 63% of all lion kills. When confronted on a kill by lions, spotted hyenas may either leave or wait patiently at a distance of 30 – until the lions have finished, but they are also bold enough to feed alongside lions, and even force the lions off a kill. The two species may attack one another even when there is no food involved for no apparent reason. Lion predation can account for up to 71% of hyena deaths in Etosha. Spotted hyenas have adapted by frequently mobbing lions that enter their territories. Experiments on captive spotted hyenas revealed that specimens with no prior experience with lions act indifferently to the sight of them, but will react fearfully to the scent. The size of male lions allows them occasionally to confront hyenas in otherwise evenly matched brawls and so to tip the balance in favour of the lions.
Lions tend to dominate smaller felines such as cheetahs and leopards where they co-occur, stealing their kills and killing their cubs and even adults when given the chance. The cheetah has a 50% chance of losing its kill to lions or other predators. Lions are major killers of cheetah cubs, up to 90% of which are lost in their first weeks of life due to attacks by other predators. Cheetahs avoid competition by hunting at different times of the day and hide their cubs in thick brush. Leopards also use such tactics, but have the advantage of being able to subsist much better on small prey than either lions or cheetahs. Also, unlike cheetahs, leopards can climb trees and use them to keep their cubs and kills away from lions; however, lionesses will occasionally be successful in climbing to retrieve leopard kills. Similarly, lions dominate African wild dogs, not only taking their kills but also preying on young and (rarely) adult dogs. Population densities of wild dogs are low in areas where lions are more abundant. However, there are a few reported cases of old and wounded lions falling prey to wild dogs.
The Nile crocodile is the only sympatric predator (besides humans) that can singly threaten the lion. Depending on the size of the crocodile and the lion, either can lose kills or carrion to the other. Lions have been known to kill crocodiles venturing onto land, while the reverse is true for lions entering waterways, as evidenced by the occasional lion claw found in crocodile stomachs.
Man-eating.
While lions do not usually hunt people, some (usually males) seem to seek out human prey; one well-publicised case includes the Tsavo maneaters, where 28 officially recorded railway workers building the Kenya-Uganda Railway were taken by lions over nine months during the construction of a bridge over the Tsavo River in Kenya in 1898. The hunter who killed the lions wrote a book detailing the animals' predatory behaviour. The lions were larger than normal, lacked manes, and one seemed to suffer from tooth decay. The infirmity theory, including tooth decay, is not favored by all researchers; an analysis of teeth and jaws of man-eating lions in museum collections suggests that while tooth decay may explain some incidents, prey depletion in human-dominated areas is a more likely cause of lion predation on humans.
In their analysis of Tsavo and general man-eating, Kerbis Peterhans and Gnoske acknowledge that sick or injured animals may be more prone to man-eating, but that the behaviour is "not unusual, nor necessarily 'aberrant'" where the opportunity exists; if inducements such as access to livestock or human corpses are present, lions will regularly prey upon human beings. The authors note that the relationship is well-attested among other pantherines and primates in the paleontological record.
The lion's proclivity for man-eating has been systematically examined. American and Tanzanian scientists report that man-eating behaviour in rural areas of Tanzania increased greatly from 1990 to 2005. At least 563 villagers were attacked and many eaten over this period – a number far exceeding the more famed "Tsavo" incidents of a century earlier. The incidents occurred near Selous National Park in Rufiji District and in Lindi Province near the Mozambican border. While the expansion of villagers into bush country is one concern, the authors argue that conservation policy must mitigate the danger because, in this case, conservation contributes directly to human deaths. Cases in Lindi have been documented where lions seize humans from the center of substantial villages. Another study of 1,000 people attacked by lions in southern Tanzania between 1988 and 2009 found that the weeks following the full moon (when there was less moonlight) were a strong indicator of increased night attacks on people.
Author Robert R. Frump wrote in "The Man-eaters of Eden" that Mozambican refugees regularly crossing Kruger National Park at night in South Africa are attacked and eaten by the lions; park officials have conceded that man-eating is a problem there. Frump believes thousands may have been killed in the decades after apartheid sealed the park and forced the refugees to cross the park at night. For nearly a century before the border was sealed, Mozambicans had regularly walked across the park in daytime with little harm.
Packer estimates more than 200 Tanzanians are killed each year by lions, crocodiles, elephants, hippos, and snakes, and that the numbers could be double that amount, with lions thought to kill at least 70 of those. Packer has documented that between 1990 and 2004, lions attacked 815 people in Tanzania, killing 563. Packer and Ikanda are among the few conservationists who believe western conservation efforts must take account of these matters not just because of ethical concerns about human life, but also for the long term success of conservation efforts and lion preservation.
A man-eating lion was killed by game scouts in Southern Tanzania in April 2004. It is believed to have killed and eaten at least 35 people in a series of incidents covering several villages in the Rufiji Delta coastal region. Dr Rolf D. Baldus, the GTZ wildlife programme coordinator, commented that it was likely that the lion preyed on humans because it had a large abscess underneath a molar that was cracked in several places. He further commented that "This lion probably experienced a lot of pain, particularly when it was chewing." GTZ is the German development cooperation agency and has been working with the Tanzanian government on wildlife conservation for nearly two decades. As in other cases this lion was large, lacked a mane, and had a tooth problem.
The "All-Africa" record of man-eating generally is considered to be not Tsavo, but incidents in the early 1930s through the late 1940s in what was then Tanganyika (now Tanzania). George Rushby, game warden and professional hunter, eventually dispatched the pride, which over three generations is thought to have killed and eaten 1,500 to 2,000 people in what is now Njombe district.
Reproduction and life cycle.
Most lionesses will have reproduced by the time they are four years of age. Lions do not mate at any specific time of year, and the females are polyestrous. As with other cats' penises, the male lion's penis has spines that point backward. During withdrawal of the penis, the spines rake the walls of the female's vagina, which may cause ovulation. A lioness may mate with more than one male when she is in heat.
The average gestation period is around 110 days, the female giving birth to a litter of one to four cubs in a secluded den (which may be a thicket, a reed-bed, a cave, or some other sheltered area) usually away from the rest of the pride. She will often hunt by herself while the cubs are still helpless, staying relatively close to the thicket or den where the cubs are kept. The cubs themselves are born blind – their eyes do not open until roughly a week after birth. They weigh 1.2 – at birth and are almost helpless, beginning to crawl a day or two after birth and walking around three weeks of age. The lioness moves her cubs to a new den site several times a month, carrying them one by one by the nape of the neck, to prevent scent from building up at a single den site and thus avoiding the attention of predators that may harm the cubs.
Usually, the mother does not integrate herself and her cubs back into the pride until the cubs are six to eight weeks old. Sometimes this introduction to pride life occurs earlier, however, particularly if other lionesses have given birth at about the same time. For instance, lionesses in a pride often synchronise their reproductive cycles so that they cooperate in the raising and suckling of the young (once the cubs are past the initial stage of isolation with their mother), who suckle indiscriminately from any or all of the nursing females in the pride. In addition to greater protection, the synchronization of births also has an advantage in that the cubs end up being roughly the same size, and thus have an equal chance of survival. If one lioness gives birth to a litter of cubs a couple of months after another lioness, for instance, then the younger cubs, being much smaller than their older brethren, usually are dominated by larger cubs at mealtimes – consequently, death by starvation is more common among the younger cubs.
In addition to starvation, cubs also face many other dangers, such as predation by jackals, hyenas, leopards, martial eagles, and snakes. Even buffaloes, should they catch the scent of lion cubs, often stampede toward the thicket or den where they are being kept, doing their best to trample the cubs to death while warding off the lioness. Furthermore, when one or more new males oust the previous male(s) associated with a pride, the conqueror(s) often kill any existing young cubs, perhaps because females do not become fertile and receptive until their cubs mature or die. All in all, as many as 80% of the cubs will die before the age of two.
When first introduced to the rest of the pride, the cubs initially lack confidence when confronted with adult lions other than their mother. They soon begin to immerse themselves in the pride life, however, playing among themselves or attempting to initiate play with the adults. Lionesses with cubs of their own are more likely to be tolerant of another lioness's cubs than lionesses without cubs. The tolerance of the male lions toward the cubs varies – sometimes, a male will patiently let the cubs play with his tail or his mane, whereas another may snarl and bat the cubs away.
Weaning occurs after six to seven months. Male lions reach maturity at about 3 years of age and, at 4–5 years of age, are capable of challenging and displacing the adult male(s) associated with another pride. They begin to age and weaken between 10 and 15 years of age at the latest, if they have not already been critically injured while defending the pride (once ousted from a pride by rival males, male lions rarely manage a second take-over). This leaves a short window for their own offspring to be born and mature. If they are able to procreate as soon as they take over a pride, potentially, they may have more offspring reaching maturity before they also are displaced. A lioness often will attempt to defend her cubs fiercely from a usurping male, but such actions are rarely successful. He usually kills all of the existing cubs who are less than two years old. A lioness is weaker and much lighter than a male; success is more likely when a group of three or four mothers within a pride join forces against one male.
Contrary to popular belief, it is not only males that are ousted from their pride to become nomads, although most females certainly do remain with their birth pride. However, when the pride becomes too large, the next generation of female cubs may be forced to leave to eke out their own territory. Furthermore, when a new male lion takes over the pride, subadult lions, both male and female, may be evicted. Life is harsh for a female nomad. Nomadic lionesses rarely manage to raise their cubs to maturity, without the protection of other pride members.
One scientific study reports that both males and females may interact homosexually. Lions are shown to be involved in group homosexual and courtship activities. Male Lions will also head rub and roll around with each other before having sex together.
Health.
Although adult lions have no natural predators, evidence suggests that the majority die violently from humans or other lions. Lions often inflict serious injuries on each other, either members of different prides encountering each other in territorial disputes, or members of the same pride fighting at a kill. Crippled lions and lion cubs may fall victim to hyenas, leopards, or be trampled by buffalo or elephants, and careless lions may be maimed when hunting prey.
Various species of tick commonly infest the ears, neck and groin regions of most lions. Adult forms of several species of the tapeworm genus "Taenia" have been isolated from intestines, the lions having ingested larval forms from antelope meat. Lions in the Ngorongoro Crater were afflicted by an outbreak of stable fly ("Stomoxys calcitrans") in 1962; this resulted in lions becoming covered in bloody bare patches and emaciated. Lions sought unsuccessfully to evade the biting flies by climbing trees or crawling into hyena burrows; many perished or emigrated as the population dropped from 70 to 15 individuals. A more recent outbreak in 2001 killed six lions. Lions, especially in captivity, are vulnerable to the canine distemper virus (CDV), feline immunodeficiency virus (FIV), and feline infectious peritonitis (FIP). CDV is spread through domestic dogs and other carnivores; a 1994 outbreak in Serengeti National Park resulted in many lions developing neurological symptoms such as seizures. During the outbreak, several lions died from pneumonia and encephalitis. FIV, which is similar to HIV while not known to adversely affect lions, is worrisome enough in its effect in domestic cats that the Species Survival Plan recommends systematic testing in captive lions. It occurs with high to endemic frequency in several wild lion populations, but is mostly absent from Asiatic and Namibian lions."
Communication.
When resting, lion socialization occurs through a number of behaviours, and the animal's expressive movements are highly developed. The most common peaceful tactile gestures are head rubbing and social licking, which have been compared with grooming in primates. Head rubbing – nuzzling one's forehead, face and neck against another lion – appears to be a form of greeting, as it is seen often after an animal has been apart from others, or after a fight or confrontation. Males tend to rub other males, while cubs and females rub females. Social licking often occurs in tandem with head rubbing; it is generally mutual and the recipient appears to express pleasure. The head and neck are the most common parts of the body licked, which may have arisen out of utility, as a lion cannot lick these areas individually.
Lions have an array of facial expressions and body postures that serve as visual gestures. Their repertoire of vocalizations is also large; variations in intensity and pitch, rather than discrete signals, appear central to communication. Lion sounds include snarling, hissing, coughing, miaowing, woofing, and roaring. Lions tend to roar in a very characteristic manner, starting with a few deep, long roars that trail off into a series of shorter ones.
They most often roar at night; the sound, which can be heard from a distance of 8 km, is used to advertise the animal's presence. Lions have the loudest roar of any big cat.
Distribution and habitat.
In Africa, lions can be found in savanna grasslands with scattered "Acacia" trees, which serve as shade; their habitat in India is a mixture of dry savanna forest and very dry deciduous scrub forest. The habitat of lions originally spanned the southern parts of Eurasia, ranging from Greece to India, and most of Africa except the central rainforest-zone and the Sahara desert. Herodotus reported that lions had been common in Greece in 480 BC; they attacked the baggage camels of the Persian king Xerxes on his march through the country. Aristotle considered them rare by 300 BC. By 100 AD they were extirpated. A population of Asiatic lions survived until the tenth century in the Caucasus, their last European outpost.
The species was eradicated from Palestine by the Middle Ages and from most of the rest of Asia after the arrival of readily available firearms in the eighteenth century. Between the late nineteenth and early twentieth century, they became extinct in North Africa and Southwest Asia. By the late nineteenth century, the lion had disappeared from Turkey and most of northern India, while the last sighting of a live Asiatic lion in Iran was in 1941 (between Shiraz and Jahrom, Fars Province), although the corpse of a lioness was found on the banks of the Karun river, Khūzestān Province in 1944. There are no subsequent reliable reports from Iran. The subspecies now survives only in and around the Gir Forest of northwestern India. Approximately 500 lions live in the area of the 1,412 km2 sanctuary in the state of Gujarat, which covers most of the forest. Their numbers have increased from 180 to 523 animals mainly because the natural prey species have recovered.
Population and conservation status.
Most lions now live in eastern and southern Africa, and their numbers there are rapidly decreasing, with an estimated 30–50% decline per 20 years in the late half of the 20th century. Estimates of the African lion population range between 16,500 and 47,000 living in the wild in 2002–2004, down from early 1990s estimates that ranged as high as 100,000 and perhaps 400,000 in 1950. Primary causes of the decline include disease and human interference. Habitat loss and conflicts with humans are considered the most significant threats to the species. The remaining populations are often geographically isolated from one another, which can lead to inbreeding, and consequently, reduced genetic diversity. Therefore the lion is considered a vulnerable species by the International Union for Conservation of Nature, while the Asiatic subspecies is endangered. The lion population in the region of West Africa is isolated from lion populations of Central Africa, with little or no exchange of breeding individuals. The number of mature individuals in West Africa is estimated by two separate recent surveys at 850–1,160 (2002/2004). There is disagreement over the size of the largest individual population in West Africa: the estimates range from 100 to 400 lions in Burkina Faso's Arly-Singou ecosystem. Another population in northwestern Africa is found in Waza National Park, where approximately 14–21 animals persist.
Conservation of both African and Asian lions has required the setup and maintenance of national parks and game reserves; among the best known are Etosha National Park in Namibia, Serengeti National Park in Tanzania, and Kruger National Park in eastern South Africa. The Ewaso Lions Project protects lions in the Samburu National Reserve, Buffalo Springs National Reserve and Shaba National Reserve of the Ewaso Ng'iro ecosystem in Northern Kenya. Outside these areas, the issues arising from lions' interaction with livestock and people usually results in the elimination of the former. In India, the last refuge of the Asiatic lion is the 1,412 km2 Gir Forest National Park in western India, which had approximately 180 lions in 1974 and about 400 in 2010. As in Africa, numerous human habitations are close by with the resultant problems between lions, livestock, locals and wildlife officials.<ref name="C4WDefault-10.1046/j.1523-1739.1994.08020501.x"></ref> The Asiatic Lion Reintroduction Project plans to establish a second independent population of Asiatic lions at the Kuno Wildlife Sanctuary in the Indian state of Madhya Pradesh. It is important to start a second population to serve as a gene pool for the last surviving Asiatic lions and to help develop and maintain genetic diversity enabling the species to survive.
The former popularity of the Barbary lion as a zoo animal has meant that scattered lions in captivity are likely to be descended from Barbary lion stock. This includes lions at Port Lympne Wild Animal Park in Kent, England that are descended from animals owned by the King of Morocco. Another eleven animals believed to be Barbary lions were found in Addis Ababa zoo, descendants of animals owned by Emperor Haile Selassie. WildLink International, in collaboration with Oxford University, launched their ambitious International Barbary Lion Project with the aim of identifying and breeding Barbary lions in captivity for eventual reintroduction into a national park in the Atlas Mountains of Morocco.
Following the discovery of the decline of lion population in Africa, several coordinated efforts involving lion conservation have been organised in an attempt to stem this decline.
Lions are one species included in the Species Survival Plan, a coordinated attempt by the Association of Zoos and Aquariums to increase its chances of survival. The plan was originally started in 1982 for the Asiatic lion, but was suspended when it was found that most Asiatic lions in North American zoos were not genetically pure, having been hybridised with African lions. The African lion plan started in 1993, focusing especially on the South African subspecies, although there are difficulties in assessing the genetic diversity of captive lions, since most individuals are of unknown origin, making maintenance of genetic diversity a problem.
In captivity.
Lions are part of a group of exotic animals that are the core of zoo exhibits since the late eighteenth century; members of this group are invariably large vertebrates and include elephants, rhinoceroses, hippopotamuses, large primates, and other big cats; zoos sought to gather as many of these species as possible. Although many modern zoos are more selective about their exhibits, there are more than 1,000 African and 100 Asiatic lions in zoos and wildlife parks around the world. They are considered an ambassador species and are kept for tourism, education and conservation purposes. Lions can reach an age of over 20 years in captivity; Apollo, a resident lion of Honolulu Zoo in Honolulu, Hawaii, died at age 22 in August 2007. His two sisters, born in 1986, were still alive in August 2007. Breeding programs need to note origins to avoid breeding different subspecies and thus reducing conservation value. However, several Asiatic-African lion crosses have been bred.
At the ancient Egyptian cities of Taremu and Per-Bast were temples to the lioness goddesses of Egypt, Sekhmet and Bast and at Taremu there was a temple to the son of the deity, Maahes the lion prince, where live lions were kept and allowed to roam within his temple. The Greeks called the city Leontopolis, the "City of Lions" and documented that practice.
Lions were kept and bred by Assyrian kings as early as 850 BC, and Alexander the Great was said to have been presented with tame lions by the Malhi of northern India. Later in Roman times, lions were kept by emperors to take part in the gladiator arenas or for executions (see bestiarii, damnatio ad bestias, and venatio). Roman notables, including Sulla, Pompey, and Julius Caesar, often ordered the mass slaughter of hundreds of lions at a time. In the East, lions were tamed by Indian princes, and Marco Polo reported that Kublai Khan kept lions inside. The first European "zoos" spread among noble and royal families in the thirteenth century, and until the seventeenth century were called seraglios; at that time, they came to be called menageries, an extension of the cabinet of curiosities. They spread from France and Italy during the Renaissance to the rest of Europe. In England, although the seraglio tradition was less developed, Lions were kept at the Tower of London in a seraglio established by King John in the thirteenth century, probably stocked with animals from an earlier menagerie started in 1125 by Henry I at his hunting lodge in Woodstock, near Oxford; where lions had reportedly been stocked by William of Malmesbury.
Seraglios served as expressions of the nobility's power and wealth. Animals such as big cats and elephants, in particular, symbolised power, and would be pitted in fights against each other or domesticated animals. By extension, menageries and seraglios served as demonstrations of the dominance of humanity over nature. Consequently, the defeat of such natural "lords" by a cow in 1682 astonished the spectators, and the flight of an elephant before a rhinoceros drew jeers. Such fights would slowly fade out in the seventeenth century with the spread of the menagerie and their appropriation by the commoners. The tradition of keeping big cats as pets would last into the nineteenth century, at which time it was seen as highly eccentric.
The presence of lions at the Tower of London was intermittent, being restocked when a monarch or his consort, such as Margaret of Anjou the wife of Henry VI, either sought or were given animals. Records indicate they were kept in poor conditions there in the seventeenth century, in contrast to more open conditions in Florence at the time. The menagerie was open to the public by the eighteenth century; admission was a sum of three half-pence or the supply of a cat or dog for feeding to the lions. A rival menagerie at the Exeter Exchange also exhibited lions until the early nineteenth century. The Tower menagerie was closed down by William IV, and animals transferred to the London Zoo, which opened its gates to the public on 27 April 1828.
The wild animals trade flourished alongside improved colonial trade of the nineteenth century. Lions were considered fairly common and inexpensive. Although they would barter higher than tigers, they were less costly than larger, or more difficult to transport animals such as the giraffe and hippopotamus, and much less than giant pandas. Like other animals, lions were seen as little more than a natural, boundless commodity that was mercilessly exploited with terrible losses in capture and transportation. The widely reproduced imagery of the heroic hunter chasing lions would dominate a large part of the century. Explorers and hunters exploited a popular Manichean division of animals into "good" and "evil" to add thrilling value to their adventures, casting themselves as heroic figures. This resulted in big cats, always suspected of being man-eaters, representing "both the fear of nature and the satisfaction of having overcome it."
Lions were kept in cramped and squalid conditions at London Zoo until a larger lion house with roomier cages was built in the 1870s. Further changes took place in the early twentieth century, when Carl Hagenbeck designed enclosures more closely resembling a natural habitat, with concrete 'rocks', more open space and a moat instead of bars. He designed lion enclosures for both Melbourne Zoo and Sydney's Taronga Zoo, among others, in the early twentieth century. Though his designs were popular, the old bars and cage enclosures prevailed until the 1960s in many zoos. In the later decades of the twentieth century, larger, more natural enclosures and the use of wire mesh or laminated glass instead of lowered dens allowed visitors to come closer than ever to the animals, with some attractions even placing the den on ground higher than visitors, such as the Cat Forest/Lion Overlook of Oklahoma City Zoological Park. Lions are now housed in much larger naturalistic areas; modern recommended guidelines more closely approximate conditions in the wild with closer attention to the lions' needs, highlighting the need for dens in separate areas, elevated positions in both sun and shade where lions can sit and adequate ground cover and drainage as well as sufficient space to roam. There have also been instances where a lion was kept by a private individual, such as the lioness Elsa, who was raised by George Adamson and his wife Joy Adamson and came to develop a strong bond with them, particularly the latter. The lioness later achieved fame, her life being documented in a series of books and films.
Baiting and taming.
Lion-baiting is a blood sport involving the baiting of lions in combat with other animals, usually dogs. Records of it exist in ancient times through until the seventeenth century. It was finally banned in Vienna by 1800 and England in 1835.
Lion taming refers to the practice of taming lions for entertainment, either as part of an established circus or as an individual act, such as Siegfried & Roy. The term is also often used for the taming and display of other big cats such as tigers, leopards, and cougars. The practice was pioneered in the first half of the nineteenth century by Frenchman Henri Martin and American Isaac Van Amburgh who both toured widely, and whose techniques were copied by a number of followers. Van Amburgh performed before Queen Victoria in 1838 when he toured Great Britain. Martin composed a pantomime titled "Les Lions de Mysore" ("the lions of Mysore"), an idea that Amburgh quickly borrowed. These acts eclipsed equestrianism acts as the central display of circus shows, but truly entered public consciousness in the early twentieth century with cinema. In demonstrating the superiority of human over animal, lion taming served a purpose similar to animal fights of previous centuries. The ultimate proof of a tamer's dominance and control over a lion is demonstrated by placing his head in the lion's mouth. The now iconic lion tamer's chair was possibly first used by American Clyde Beatty (1903–1965).
Cultural depictions.
The lion has been an icon for humanity for thousands of years, appearing in cultures across Europe, Asia, and Africa. Despite incidents of attacks on humans, lions have enjoyed a positive depiction in culture as strong and noble. A common depiction is their representation as "king of the jungle" or "king of beasts"; hence, the lion has been a popular symbol of royalty and stateliness, as well as a symbol of bravery; it is featured in several fables of the sixth century BC Greek storyteller Aesop.
Representations of lions date back to the early Upper Paleolithic. The lioness-headed ivory carving from Vogelherd cave in the Swabian Alb in southwestern Germany, dubbed "Löwenmensch" (lion-human) in German. The sculpture has been determined to be at least 32,000 years old from the Aurignacian culture, but it may date to as early as 40,000 years ago. The sculpture has been interpreted as anthropomorphic, giving human characteristics to an animal, however, it also may represent a deity.
Two lions were depicted mating in the Chamber of Felines in 15,000-year-old Paleolithic cave paintings in the Lascaux caves. Cave lions also are depicted in the Chauvet Cave, discovered in 1994; this has been dated at 32,000 years of age, though it may be of similar or younger age to Lascaux.
Ancient Egypt venerated the lioness (the fierce hunter) as their war deities and among those in the Egyptian pantheon are, Bast, Mafdet, Menhit, Pakhet, Sekhmet, Tefnut, and the Sphinx; The Nemean lion was symbolic in Ancient Greece and Rome, represented as the constellation and zodiac sign Leo, and described in mythology, where its skin was borne by the hero Heracles.
The lion was a prominent symbol in ancient Mesopotamia (from Sumer up to Assyrian and Babylonian times), where it was strongly associated with kingship. The classic Babylonian lion motif, found as a statue, carved or painted on walls, is often referred to as the "striding lion of Babylon". It is in Babylon that the biblical Daniel is said to have been delivered from the lion's den.
In the Talmud, , Rabbi Joshua ben Hananiah tells Emperor Hadrian about the giant lion of the forest of Bei Ilai called the "Tigris", a lion so huge that the space between its ears measures 9 cubits. The emperor asks the rabbi to call forth this lion. He reluctantly agrees. At a distance of 400 parasangs from Rome it roars, and all pregnant women miscarry and all the walls of Rome fall down. Then it comes to 300 parasangs and roars, and all the front teeth and molars of Roman men fall out, and even the emperor himself falls from his throne. He begs the rabbi to send it back. The rabbi prays and it returns to its place.
In the Puranic texts of Hinduism, Narasimha ("man-lion") a half-lion, half-man incarnation or (avatar) of Vishnu, is worshipped by his devotees and saved the child devotee Prahlada from his father, the evil demon king Hiranyakashipu; Vishnu takes the form of half-man/half-lion, in Narasimha, having a human torso and lower body, but with a lion-like face and claws. Singh is an ancient Indian vedic name meaning "lion" (Asiatic lion), dating back over 2000 years to ancient India. It was originally only used by Rajputs a Hindu Kshatriya or military caste in India. After the birth of the Khalsa brotherhood in 1699, the Sikhs also adopted the name "Singh" due to the wishes of Guru Gobind Singh. Along with millions of Hindu Rajputs today, it is also used by over 20 million Sikhs worldwide. Found famously on numerous flags and coats of arms all across Asia and Europe, the Asiatic lions also stand firm on the National Emblem of India. Farther south on the Indian subcontinent, the Asiatic lion is symbolic for the Sinhalese, Sri Lanka's ethnic majority; the term derived from the Indo-Aryan "Sinhala", meaning the "lion people" or "people with lion blood", while a sword-wielding lion is the central figure on the national flag of Sri Lanka.
The Asiatic lion is a common motif in Chinese art. They were first used in art during the late Spring and Autumn Period (fifth or sixth century BC), and became much more popular during the Han Dynasty (206 BC – AD 220), when imperial guardian lions started to be placed in front of imperial palaces for protection. Because lions have never been native to China, early depictions were somewhat unrealistic; after the introduction of Buddhist art to China in the Tang Dynasty (after the sixth century AD), lions usually were wingless, with shorter, thicker bodies, and curly manes. The lion dance is a form of traditional dance in Chinese culture in which performers mimic a lion's movements in a lion costume, often with musical accompaniment from cymbals, drums, and gongs. They are performed at Chinese New Year, the August Moon Festival and other celebratory occasions for good luck.
The island nation of Singapore derives its name from the Malay words "singa" (lion) and "pora" (city/fortress), which in turn is from the Tamil-Sanskrit சிங்க "singa" सिंह "siṃha" and पुर புர "pura", which is cognate to the Greek "πόλις", "pólis". According to the Malay Annals, this name was given by a fourteenth-century Sumatran Malay prince Sang Nila Utama, who, on alighting the island after a thunderstorm, spotted an auspicious beast on shore that appeared to be a lion.
The name of the nomadic Hadendoa people, inhabiting parts of Sudan, Egypt, and Eritrea, is made up of "haɖa" 'lion' and "(n)ɖiwa" 'clan'. Other variants are "Haɖai ɖiwa", "Hanɖiwa", and "Haɖaatʼar" (children of lioness).
"Lion" was the nickname of several medieval warrior rulers with a reputation for bravery, such as the English King Richard the Lionheart, Henry the Lion, (German: "Heinrich der Löwe"), Duke of Saxony, William the Lion, King of Scotland, and Robert III of Flanders nicknamed "The Lion of Flanders"—a major Flemish national icon up to the present. Lions are frequently depicted on coats of arms, either as a device on shields themselves, or as supporters, but the lioness is much more infrequent. The formal language of heraldry, called blazon, employs French terms to describe the images precisely. Such descriptions specified whether lions or other creatures were "rampant" or "passant", that is whether they were rearing or crouching. The lion is used as a symbol of sporting teams, from national association football teams such as England, Scotland and Singapore to famous clubs such as the Detroit Lions of the NFL, Chelsea and Aston Villa of the English Premier League, (and the Premiership itself), Eintracht Braunschweig of the Bundesliga, and to a host of smaller clubs around the world.
Lions continue to be featured in modern literature, from the messianic Aslan in "The Lion, the Witch and the Wardrobe" and following books from The Chronicles of Narnia series written by C. S. Lewis, to the comedic Cowardly Lion in "The Wonderful Wizard of Oz". The advent of moving pictures saw the continued presence of lion symbolism; one of the most iconic and widely recognised lions is Leo the Lion, which has been the mascot for Metro-Goldwyn-Mayer (MGM) studios since the 1920s. The 1960s saw the appearance of what is possibly the most famous lioness, the Kenyan animal Elsa in the movie "Born Free", based on the true-life international bestselling book of the same title. The lion's role as King of the Beasts has been used in cartoons, from the 1950s manga that gave rise to the first Japanese colour TV animation series, "Kimba the White Lion", Leonardo Lion of "King Leonardo and His Short Subjects", both from the 1960s, up to the 1994 Disney animated feature film "The Lion King", which also featured the popular song "The Lion Sleeps Tonight" in its soundtrack. A lion appears on the 50-rand South African banknote.
References.
Cited texts.
</dl>

</doc>
<doc id="36897" url="http://en.wikipedia.org/wiki?curid=36897" title="Gruyères">
Gruyères

Gruyères (]) is a town in the district of Gruyère in the canton of Fribourg in Switzerland. Its German name is "Greyerz".
The medieval town is an important tourist location in the upper valley of the Saane river, and gives its name to the well-known Gruyère cheese. The medieval town is located at the top of 82 metre-high hill overlooking the Saane valley and the Lake of Gruyère.
Geography.
Gruyères has an area, as of 2009[ [update]], of 28.4 km2. Of this area, 11.5 km2 or 40.5% is used for agricultural purposes, while 14.18 km2 or 50.0% is forested. Of the rest of the land, 1.55 km2 or 5.5% is settled (buildings or roads), 0.24 km2 or 0.8% is either rivers or lakes and 0.92 km2 or 3.2% is unproductive land.
Of the built up area, housing and buildings made up 2.5% and transportation infrastructure made up 2.1%. Out of the forested land, 46.8% of the total land area is heavily forested and 2.7% is covered with orchards or small clusters of trees. Of the agricultural land, 4.6% is used for growing crops and 12.9% is pastures and 22.9% is used for alpine pastures. All the water in the municipality is flowing water.
Gruyères is 810 m above sea level, 4.5 km south-south-east of the district capital Bulle. The historical town is placed on top of an isolated hill north of the alps, in the foothills of mount Moléson. It is also the location where the Saane river (French name: Sarine) leaves the Fribourg alps.
The area of the municipality comprises a section of the Saane valley and of the Fribourg alps. The central part of the area is the plains of Alluvial (690 m above sea level) next to the alps, between Gruyères and Broc, from which the hill of Gruyères rises to 828 m above sea level. From the west, the brook Trême meets the Saane. East of the Saane, the municipality area ends in a small corner, bordered by the ridges of "Dent de Broc" (1829 m above sea level) in the north and "Dent du Chamois" (1830 m above sea level) in the south, ending at the valley of Motélon. The two peaks with their saddle between them are a popular subject for photographs of Gruyères.
Southwest of Gruyères, the municipality comprises most of the catchment area of the brook "Albeuve", which originates on the flanks of mount Moléson. The top of mount Moléson is the highest point of the municipality, reaching 2002 m above sea level. West of the Moléson, the densely wooded right valley side of the Trême and the terrace of La Part Dieu belong to Gruyères.
The municipality of Gruyères also comprises the two villages of Épagny (715 m above sea level) to the north and Pringy (750 m above sea level) to the west of the town hill. Further, the small village "Saussivue" (710 m above sea level) to the south and the holiday settlement "Moléson-Village" (1132 mabove sea level) in the valley of the Albeuve in the foothills of mount Moléson as well as several isolated farms. Neighbour municipalities of Gruyères are Broc, Charmey, Bas-Intyamon, Haut-Intyamon, Semsales, Vaulruz, Vuadens, Bulle, La Tour-de-Trême and Le Pâquier.
Coat of arms.
The blazon of the municipal coat of arms is "Gules, a Crane rising Argent."
Demographics.
Gruyères has a population (as of December 2013[ [update]]) of . s of 2008[ [update]], 14.7% of the population are resident foreign nationals. Over the last 10 years (2000–2010) the population has changed at a rate of 21.2%. Migration accounted for 17.5%, while births and deaths accounted for 4.2%.
Most of the population (as of 2000[ [update]]) speaks French (1,398 or 90.4%) as their first language, German is the second most common (60 or 3.9%) and Portuguese is the third (18 or 1.2%). There are 7 people who speak Italian and 2 people who speak Romansh.
s of 2008[ [update]], the population was 50.6% male and 49.4% female. The population was made up of 760 Swiss men (42.0% of the population) and 154 (8.5%) non-Swiss men. There were 764 Swiss women (42.3%) and 130 (7.2%) non-Swiss women. Of the population in the municipality, 508 or about 32.9% were born in Gruyères and lived there in 2000. There were 598 or 38.7% who were born in the same canton, while 194 or 12.5% were born somewhere else in Switzerland, and 182 or 11.8% were born outside of Switzerland.
s of 2000[ [update]], children and teenagers (0–19 years old) make up 29.7% of the population, while adults (20–64 years old) make up 55% and seniors (over 64 years old) make up 15.3%.
s of 2000[ [update]], there were 684 people who were single and never married in the municipality. There were 710 married individuals, 94 widows or widowers and 58 individuals who are divorced.
s of 2000[ [update]], there were 581 private households in the municipality, and an average of 2.5 persons per household. There were 176 households that consist of only one person and 53 households with five or more people. In 2000[ [update]], a total of 562 apartments (64.4% of the total) were permanently occupied, while 257 apartments (29.5%) were seasonally occupied and 53 apartments (6.1%) were empty. s of 2009[ [update]], the construction rate of new housing units was 2.2 new units per 1000 residents. The vacancy rate for the municipality, in 2010[ [update]], was 0.74%.
The historical population is given in the following chart:
Economics.
Gruyères has always been a rural town. Agricultural products from the surroundings were processed and brought to the market here. Formerly, the focus was on trading cheese and small and big animals. There were several mills and sawmills and since the 18th century a gunpowder factory. Until the beginning of the 20th century, straw-twisting was also rather important.
Agriculture is still specialized in milk production and cattle-breeding. It delivers raw materials for the cheese production and meat treating. Most important is the famous Gruyère cheese. Forestry is also a factor, but tillage is less applied. In secondary sector, there are cabinetmaking, precision mechanics and craftworks. Services has a lot of jobs to offer in gastronomics and hotels. The villages of Epagny and Pringy have in the last years become a living place for commuters, mostly working in the town of Bulle.
s of 2010[ [update]], Gruyères had an unemployment rate of 2.5%. s of 2008[ [update]], there were 59 people employed in the primary economic sector and about 19 businesses involved in this sector. 229 people were employed in the secondary sector and there were 27 businesses in this sector. 447 people were employed in the tertiary sector, with 69 businesses in this sector. There were 757 residents of the municipality who were employed in some capacity, of which females made up 42.8% of the workforce.
In 2008[ [update]] the total number of full-time equivalent jobs was 601. The number of jobs in the primary sector was 44, of which 39 were in agriculture and 5 were in forestry or lumber production. The number of jobs in the secondary sector was 215 of which 120 or (55.8%) were in manufacturing and 95 (44.2%) were in construction. The number of jobs in the tertiary sector was 342. In the tertiary sector; 62 or 18.1% were in wholesale or retail sales or the repair of motor vehicles, 33 or 9.6% were in the movement and storage of goods, 131 or 38.3% were in a hotel or restaurant, 1 was in the information industry, 3 or 0.9% were technical professionals or scientists, 35 or 10.2% were in education and 45 or 13.2% were in health care.
In 2000[ [update]], there were 366 workers who commuted into the municipality and 478 workers who commuted away. The municipality is a net exporter of workers, with about 1.3 workers leaving the municipality for every one entering. Of the working population, 7.5% used public transportation to get to work, and 69.7% used a private car.
History.
Graves from the Hallstatt era and La Tène era (325-250 BC) as well as other traces from the Bronze Age were discovered in Epagny. The remains of a Roman era villa from the 2nd-3rd century AD and an Early Middle Ages cemetery were also found nearby. A Roman settlement was probably located on a hill in Gruyères.
Gruyères stands in the midst of the Fribourg green pre-Alpine foothills. The castle, towers above the medieval town. Gruerius, the legendary founder of Gruyères, captured a crane (in French: “grue”) and chose it as his heraldic animal inspiring the name Gruyères. Despite the importance of the House of Gruyères its beginnings remain quite mysterious. Gruyères is first mentioned around 1138-39 as "de Grueri". The town developed beneath the castle, which the Count of Gruyere had built on top of the hill, to control the upper Saanen valley. By 1195-96 it became a market town with a central street and city walls. The town developed separately of the castle. In 1397 Count Rudolph IV of Gruyères confirmed an older town charter that was based on the model of Moudon.
On June 22, 1476, Gruyères participated in the Battle of Morat against the Charles the Bold, Duke of Burgundy. With the help of the Old Swiss Confederacy, they routed the Burgundian army and captured three capes of the [Order of the Golden Fleece] which belonged to Charles the Bold including one with the emblems of Philip the Good, his father. At the time of the battle he was celebrating the anniversary of the death of his father.
The town church of Gruyères originally belonged to the parish of Bulle. Count Rudolph III allowed the villages on the left bank of the Saane to built St. Theodul's church. When it was dedicated in 1254, it was the parish church of the new Gruyères parish. The Counts of Gruyères were buried under the altar of St. Michael in the church. It was mostly destroyed in 1670 and again in 1856 by fire, which only left the choir and tower undamaged. The renovated church was consecrated in 1860. In addition to the parish church, the Counts had the Chapel of St. John the Baptist in the castle, with two glass windows dating from the late 15th century. The Chapel of St. Moritz in the old hospital was built with the hospital in 1431. The Chapelle du Berceau was built in 1612, following a plague that killed 140.
During the Thirty Years' War, nuns from St. Bernard and the Visitation Order fled from Besançon und Dole to settle in Gruyères. The latter remained in town between 1639 and 1651 and conducted a private school. Starting in the 15th century a primary school opened in town which was open mainly to boys. A secondary school opened in town in the 20th century but it moved in 1973 to Bulle. Gruyères had a plague house which was first mentioned in 1341. The town's hospital was founded in the mid-15th century and remained in operation until the second half of the 19th century. One side of the hospital building housed the primary school until 1988 and was then renovated into a nursing home. Between 1891 and 1925 the Ingenbohl sisters ran the Deaf and Dumb Institute of Saint-Joseph in Gruyères. In 1925 it moved to Fribourg.
Nineteen counts are accounted for in the period between the 11th and 16th centuries. The last of them, Michel, had been in financial trouble almost all his life only to end in bankruptcy in 1554. His creditors the cantons of Fribourg and Bern shared his earldom between them. From 1555 to 1798 the castle became residence to the bailiffs and then to the prefects sent by Fribourg. In 1849 the castle was put up for sale and sold to the Bovy and Balland families, who stayed at the castle during summer time and restored it with the help of their painter friends. The castle was then bought back by the canton of Fribourg in 1938, made into a museum and opened to the public. Since 1993, a foundation ensures the conservation as well as the highlighting of the building and the collection.
Heritage sites of national significance.
Tourism.
Gruyère cheese is an important factor in supporting the tourist trade in the region. A major tourist attraction is the medieval town of Gruyères with its castle, containing a regional museum and an arts museum. There are cultural activities in the castle (concerts, theater). There is a cheese factory in Pringy which is open to visitors. Nearby is Mont Moléson, a mountain suitable for climbing, or for the less athletic there is a cablecar to the summit which was rebuilt in 1998. The resort town Moléson-Village caters for both summer and winter tourism.
In 1998 Swiss surrealist painter, sculptor and set designer HR Giger acquired the Château St. Germain, and it now houses the H. R. Giger Museum, a permanent repository of his work and is a popular tourist destination. Next to this, there is a museum holding antiquities from Tibet.
Main sights.
The castle was constructed between 1270 and 1282 in the typical square plan of the fortifications in Savoy. The end of the 15th century stands out as the golden age in the history of the counts. In 1476, count Louis takes part in the Burgundy war by the Confederates’ side. Following this deed of valour, modernization works were undertaken. The adjustment of the esplanade with its chapel, the spiral staircase in the courtyard and the transformation of the main building go back to that time. Thus, the castle loses its fortress appearance to become a stately residence. The baroque interiors remind one of the time when the bailiffs sent by Fribourg lived there. The romantic landscapes were painted in the mid-19th century by Jean-Baptiste-Camille Corot, Barthélemy Menn and other well-known artists.
Politics.
In the 2011 federal election the most popular party was the SP which received 28.8% of the vote. The next three most popular parties were the CVP (21.5%), the SVP (20.7%) and the FDP (14.4%).
The SPS improved their position in Gruyères rising to first, from third in 2007 (with 21.4%) The CVP moved from first in 2007 (with 27.9%) to second in 2011, the SVP moved from second in 2007 (with 25.0%) to third and the FDP retained about the same popularity (15.9% in 2007). A total of 609 votes were cast in this election, of which 6 or 1.0% were invalid.
Religion.
From the 2000 census[ [update]], 1,261 or 81.6% were Roman Catholic, while 92 or 6.0% belonged to the Swiss Reformed Church. Of the rest of the population, there were 10 members of an Orthodox church (or about 0.65% of the population), and there were 43 individuals (or about 2.78% of the population) who belonged to another Christian church. There were 2 individuals (or about 0.13% of the population) who were Jewish, and 32 (or about 2.07% of the population) who were Islamic. There were 1 individual who belonged to another church. 74 (or about 4.79% of the population) belonged to no church, are agnostic or atheist, and 51 individuals (or about 3.30% of the population) did not answer the question.
Education.
In Gruyères about 456 or (29.5%) of the population have completed non-mandatory upper secondary education, and 155 or (10.0%) have completed additional higher education (either university or a "Fachhochschule"). Of the 155 who completed tertiary schooling, 61.9% were Swiss men, 24.5% were Swiss women, 10.3% were non-Swiss men and 3.2% were non-Swiss women.
The Canton of Fribourg school system provides one year of non-obligatory Kindergarten, followed by six years of Primary school. This is followed by three years of obligatory lower Secondary school where the students are separated according to ability and aptitude. Following the lower Secondary students may attend a three or four year optional upper Secondary school. The upper Secondary school is divided into gymnasium (university preparatory) and vocational programs. After they finish the upper Secondary program, students may choose to attend a Tertiary school or continue their apprenticeship.
During the 2010-11 school year, there were a total of 240 students attending 18 classes in Gruyères. A total of 363 students from the municipality attended any school, either in the municipality or outside of it. There was one kindergarten class with a total of 17 students in the municipality. The municipality had 7 primary classes and 149 students. During the same year, there were 3 lower secondary classes with a total of 31 students. There were 2 vocational upper Secondary classes and were 5 upper Secondary classes, with 40 upper Secondary students and 3 vocational upper Secondary students The municipality had no non-university Tertiary classes, but there were 3 specialized Tertiary students who attended classes in another municipality.
s of 2000[ [update]], there were 31 students in Gruyères who came from another municipality, while 109 residents attended schools outside the municipality.

</doc>
<doc id="36898" url="http://en.wikipedia.org/wiki?curid=36898" title="10s BC">
10s BC


</doc>
<doc id="36899" url="http://en.wikipedia.org/wiki?curid=36899" title="20s BC">
20s BC


</doc>
<doc id="36900" url="http://en.wikipedia.org/wiki?curid=36900" title="Antioch">
Antioch

Antioch on the Orontes was an ancient Greek city on the eastern side of the Orontes River. Its ruins lie near the modern city of Antakya, Turkey, and lends the modern city its name (; Greek: Ἀντιόχεια ἡ ἐπὶ Ὀρόντου; or Ἀντιόχεια ἡ ἐπὶ Δάφνῃ, "Antioch on Daphne"; or Ἀντιόχεια ἡ Μεγάλη, "Antioch the Great"; Armenian: Անտիոք "Antiok"; Turkish: "Antakya"; Arabic: انطاكية, "Anṭākiya"; Persian: انطاکیه‎; Syriac: ܐܢܛܝܘܟܝܐ "Anṭiokia"; Hebrew: אנטיוכיה, "Antiyokhya"; Georgian: ანტიოქია "Ant'iokia"; Latin: "Antiochia ad Orontem"; also Syrian Antioch).
Founded near the end of the 4th century BC by Seleucus I Nicator, one of Alexander the Great's generals, Antioch's geographic, military and economic location, particularly the spice trade, the Silk Road, the Persian Royal Road, benefited its occupants, and eventually it rivaled Alexandria as the chief city of the Near East and as the main center of Hellenistic Judaism at the end of the Second Temple period.
As a result of its longevity and the pivotal role it played in the emergence of both Hellenistic Judaism and Early Christianity, Antioch was called "the cradle of Christianity." It was one of the four cities of the Syrian tetrapolis. Its residents were known as "Antiochenes". Once a great metropolis of half a million people, it declined to insignificance during the Middle Ages because of warfare, repeated earthquakes and a change in trade routes, which no longer passed through Antioch from the far east, following the Mongol conquests.
Geography.
Two routes from the Mediterranean, lying through the Orontes gorge and the Beilan Pass, converge in the plain of the Antioch Lake ("Balük Geut" or "El Bahr") and are met there by
History.
Prehistory.
The settlement of Meroe pre-dated Antioch. A shrine of Anat, called by the Greeks the "Persian Artemis," was located here. This site was included in the eastern suburbs of Antioch. There was a village on the spur of Mount Silpius named Io, or Iopolis. This name was always adduced as evidence by Antiochenes ("e.g." Libanius) anxious to affiliate themselves to the Attic Ionians—an eagerness which is illustrated by the Athenian types used on the city's coins. Io may have been a small early colony of trading Greeks ("Javan"). John Malalas also mentions an archaic village, Bottia, in the plain by the river.
Foundation by Seleucus I.
Macedonian ruler Alexander the Great is said to have camped on the site of Antioch, and dedicated an altar to Zeus Bottiaeus; it lay in the northwest of the future city. This account is found only in the writings of Libanius, a 4th-century orator from Antioch, and may be legend intended to enhance Antioch's status. But the story is not unlikely in itself.
After Alexander's death in 323 BC, his generals divided up the territory he had conquered. Seleucus I Nicator won the territory of Syria, and he proceeded to found four "sister cities" in northwestern Syria, one of which was Antioch, a city named, according to Suda, after his son Antiochus. He is reputed to have built sixteen Antiochs.
Seleucus founded Antioch on a site chosen through ritual means. An eagle, the bird of Zeus, had been given a piece of sacrificial meat and the city was founded on the site to which the eagle carried the offering. Seleucus did this in the twelfth year of his reign. Antioch soon rose above Seleucia Pieria to become the Syrian capital.
Hellenistic age.
The original city of Seleucus was laid out in imitation of the grid plan of Alexandria by the architect Xenarius. Libanius describes the first building and arrangement of this city (i. p. 300. 17). The citadel was on Mt. Silpius and the city lay mainly on the low ground to the north, fringing the river. Two great colonnaded streets intersected in the centre. Shortly afterwards a second quarter was laid out, probably on the east and by Antiochus I, which, from an expression of Strabo, appears to have been the native, as contrasted with the Greek, town. It was enclosed by a wall of its own.
In the Orontes, north of the city, lay a large island, and on this Seleucus II Callinicus began a third walled "city," which was finished by Antiochus III. A fourth and last quarter was added by Antiochus IV Epiphanes (175-164 BC); thenceforth Antioch was known as "Tetrapolis". From west to east the whole was about 6 km in diameter and a little less from north to south. This area including many large gardens.
The new city was populated by a mix of local settlers that Athenians brought from the nearby city of Antigonia, Macedonians, and Jews (who were given full status from the beginning). The total free population of Antioch at its foundation has been estimated at between 17,000 and 25,000, not including slaves and native settlers. During the late Hellenistic period and Early Roman period, Antioch's population reached its peak of over 500,000 inhabitants (estimates vary from 400,000 to 600,000) and was the third largest city in the world after Rome and Alexandria. By the 4th century, Antioch's declining population was about 200,000 according to Chrysostom, a figure which again does not include slaves.
About 6 km west and beyond the suburb Heraclea lay the paradise of Daphne, a park of woods and waters, in the midst of which rose a great temple to the Pythian Apollo, also founded by Seleucus I and enriched with a cult-statue of the god, as Musagetes, by Bryaxis. A companion sanctuary of Hecate was constructed underground by Diocletian. The beauty and the lax morals of Daphne were celebrated all over the western world; and indeed Antioch as a whole shared in both these titles to fame. Its amenities awoke both the enthusiasm and the scorn of many writers of antiquity.
Antioch became the capital and court-city of the western Seleucid empire under Antiochus I, its counterpart in the east being Seleucia on the Tigris; but its paramount importance dates from the battle of Ancyra (240 BC), which shifted the Seleucid centre of gravity from Asia Minor, and led indirectly to the rise of Pergamum.
The Seleucids reigned from Antioch. We know little of it in the Hellenistic period, apart from Syria, all our information coming from authors of the late Roman time. Among its great Greek buildings we hear only of the theatre, of which substructures still remain on the flank of Silpius, and of the royal palace, probably situated on the island. It enjoyed a reputation for being "a populous city, full of most erudite men and rich in the most liberal studies," but the only names of distinction in these pursuits during the Seleucid period that have come down to us are Apollophanes, the Stoic, and one Phoebus, a writer on dreams. The mass of the population seems to have been only superficially Hellenic, and to have spoken Aramaic in non-official life. The nicknames which they gave to their later kings were Aramaic; and, except Apollo and Daphne, the great divinities of north Syria seem to have remained essentially native, such as the "Persian Artemis" of Meroe and Atargatis of Hierapolis Bambyce.
The epithet "Golden" suggests that the external appearance of Antioch was impressive, but the city needed constant restoration owing to the seismic disturbances to which the district has always been subjected. The first great earthquake in recorded history was related by the native chronicler John Malalas. It occurred in 148 BC and did immense damage.
Local politics were turbulent. In the many dissensions of the Seleucid house the population took sides, and frequently rose in rebellion, for example against Alexander Balas in 147 BC, and Demetrius II in 129 BC. The latter, enlisting a body of Jews, punished his capital with fire and sword. In the last struggles of the Seleucid house, Antioch turned against its feeble rulers, invited Tigranes of Armenia to occupy the city in 83 BC, tried to unseat Antiochus XIII in 65 BC, and petitioned Rome against his restoration in the following year. Antioch's wish prevailed, and it passed with Syria to the Roman Republic in 64 BC, but remained a "civitas libera".
Roman period.
The Roman emperors favoured the city from the first, seeing it as a more suitable capital for the eastern part of the empire than Alexandria could be, because of the isolated position of Egypt. To a certain extent they tried to make it an eastern Rome. Julius Caesar visited it in 47 BC, and confirmed its freedom. A great temple to Jupiter Capitolinus rose on Silpius, probably at the insistence of Octavian, whose cause the city had espoused. A forum of Roman type was laid out. Tiberius built two long colonnades on the south towards Silpius.
Agrippa and Tiberius enlarged the theatre, and Trajan finished their work. Antoninus Pius paved the great east to west artery with granite. A circus, other colonnades and great numbers of baths were built, and new aqueducts to supply them bore the names of Caesars, the finest being the work of Hadrian. The Roman client, King Herod (most likely the great builder Herod the Great), erected a long "stoa" on the east, and Agrippa (c.63 BC – 12 BC) encouraged the growth of a new suburb south of this.
Zarmanochegas (Zarmarus) a monk of the Sramana tradition of India, according to Strabo and Dio Cassius, met Nicholas of Damascus in Antioch around 13 AD as part of a Mission to Augustus. At Antioch Germanicus died in 19 AD, and his body was burnt in the forum.
An earthquake that shook Antioch in AD 37 caused the emperor Caligula to send two senators to report on the condition of the city. Another quake followed in the next reign.
Titus set up the Cherubim, captured from the Jewish temple, over one of the gates.
In 115, during Trajan's travel there during his war against Parthia, the whole site was convulsed by an earthquake. The landscape altered, and the emperor himself was forced to take shelter in the circus for several days. He and his successor restored the city.
Commodus had Olympic games celebrated at Antioch.
Edward Gibbon wrote:
Fashion was the only law, pleasure the only pursuit, and the splendour of dress and furniture was the only distinction of the citizens of Antioch. The arts of luxury were honoured, the serious and manly virtues were the subject of ridicule, and the contempt for female modesty and reverent age announced the universal corruption of the capital of the East.
In 256, the town was suddenly raided by the Persians, who slew many in the theatre.
Late Antiquity.
Christianity.
Antioch was a chief center of early Christianity. The city had a large population of Jewish origin in a quarter called the Kerateion, and so attracted the earliest missionaries. Evangelized, among others, by Peter himself, according to the tradition upon which the Antiochene patriarchate still rests its claim for primacy, and certainly later by Barnabas and Paul during Paul's first missionary journey. Its converts were the first to be called "Christians." This is not to be confused with Antioch in Pisidia, to which the early missionaries later travelled.
Georgia (Iberia) had been a part of the Patriarchate of Antioch since the fourth century. A multitude of Georgians lived in Antioch after the Byzantine victory side by side with the Greek population.
Surrounding the city were a number of Greek, Syrian, Georgian, Armenian and Latin monasteries.
The Christian population was estimated by Chrysostom at about 100,000 people at the time of Theodosius I. Between 252 and 300, ten assemblies of the church were held at Antioch and it became the seat of one of the five original patriarchates, along with Constantinople, Jerusalem, Alexandria, and Rome (see Pentarchy).
One of the canonical Eastern Orthodox churches is still called the Antiochian Orthodox Church, although it moved its headquarters from Antioch to Damascus, Syria, several centuries ago (see list of Patriarchs of Antioch), and its prime bishop retains the title "Patriarch of Antioch," somewhat analogous to the manner in which several Popes, heads of the Roman Catholic Church remained "Bishop of Rome" even while residing in Avignon, France in the 14th century.
Many Georgian monks and clergy moved from Tao-Klarjeti to Antioch and alongside literary activities, they supported the spreading of Tao-Klarjetian artistic traditions. For that time the program of manuscript illumination based both on Tao-Klarjetian traditions and, especially, on Antiochene artistic thought was gradually established. The Alaverdian version of Abgar’s story is completely connected to the Antiochene traditions its insertion into the Georgian manuscript, alongside the other features, should be considered as a sign of respect to this tradition.
Age of Julian.
When the emperor Julian visited in 362 on a detour to Persia, he had high hopes for Antioch, regarding it as a rival to the imperial capital of Constantinople. Antioch had a mixed pagan and Christian population, which Ammianus Marcellinus implies lived quite harmoniously together. However Julian's visit began ominously as it coincided with a lament for Adonis, the doomed lover of Aphrodite. Thus, Ammianus wrote, the emperor and his soldiers entered the city not to the sound of cheers but to wailing and screaming.
After being advised that the bones of 3rd-century martyred bishop Babylas were suppressing the oracle of Apollo at Daphne, he made a public-relations mistake in ordering the removal of the bones from the vicinity of the temple. The result was a massive Christian procession. Shortly after that, when the temple was destroyed by fire, Julian suspected the Christians and ordered stricter investigations than usual. He also shut up the chief Christian church of the city, before the investigations proved that the fire was the result of an accident.
Julian found much else about which to criticize the Antiochene; Julian had wanted the empire's cities to be more self-managing, as they had been some 200 years before. However Antioch's city councilmen showed themselves unwilling to shore up Antioch's food shortage with their own resources, so dependent were they on the emperor. Ammianus wrote that the councilmen shirked their duties by bribing unwitting men in the marketplace to do the job for them.
The city's impiety to the old religion was clear to Julian when he attended the city's annual feast of Apollo. To his surprise and dismay the only Antiochene present was an old priest clutching a chicken.
The Antiochenes in turn hated Julian for worsening the food shortage with the burden of his billeted troops, wrote Ammianus. The soldiers were often to be found gorged on sacrificial meat, making a drunken nuisance of themselves on the streets while Antioch's hungry citizens looked on in disgust. The Christian Antiochenes and Julian's pagan Gallic soldiers also never quite saw eye to eye.
Even Julian's piety was distasteful to the Antiochenes retaining the old faith. Julian's brand of paganism was very much unique to himself, with little support outside the most educated Neoplatonist circles. The irony of Julian's enthusiasm for large scale animal sacrifice could not have escaped the hungry Antiochenes. Julian gained no admiration for his personal involvement in the sacrifices, only the nickname "axeman", wrote Ammianus.
The emperor's high-handed, severe methods and his rigid administration prompted Antiochene lampoons about, among other things, Julian's unfashionably pointed beard.
Valens and after.
Julian's successor, Valens, who endowed Antioch with a new forum, including a statue of Valentinian on a central column, reopened the great church of Constantine, which stood till the Persian sack in 538, by Chosroes.
In 387, there was a great sedition caused by a new tax levied by order of Theodosius I, and the city was punished by the loss of its metropolitan status.
Antioch and its port, Seleucia Pieria, were severely damaged by the great earthquake of 526. Seleucia Pieria, which was already fighting a losing battle against continual silting, never recovered. Justinian I renamed Antioch Theopolis ("City of God") and restored many of its public buildings, but the destructive work was completed by the Persian king, Khosrau I, twelve years later. Antioch lost as many as 300,000 people. Justinian I made an effort to revive it, and Procopius describes his repairing of the walls; but its glory was past.
Antioch gave its name to a certain school of Christian thought, distinguished by literal interpretation of the Scriptures and insistence on the human limitations of Jesus. Diodorus of Tarsus and Theodore of Mopsuestia were the leaders of this school. The principal local saint was Simeon Stylites, who lived an extremely ascetic life atop a pillar for 40 years some 65 km east of Antioch. His body was brought to the city and buried in a building erected under the emperor Leo.
Rashidun period.
In 637, during the reign of the Byzantine emperor Heraclius, Antioch was conquered by the Rashidun Caliphate during the Battle of the Iron Bridge. The city became known in Arabic as أنطاكيّة (Antākiyyah). Since the Umayyad dynasty was unable to penetrate the Anatolian plateau, Antioch found itself on the frontline of the conflicts between two hostile empires during the next 350 years, so that the city went into a precipitous decline.
In 969, the city was recovered for the Byzantine Emperor Nikephoros II Phokas by Michael Bourtzes and the "stratopedarches" Peter. It soon became the seat of a "doux", who commanded the forces of the local themes and was the most important officer on the Empire's eastern border, held by such men as Nikephoros Ouranos. In 1078, Philaretos Brachamios, an Armenian rebel seized power. He held the city until the Seljuk Turks captured it from him in 1084. The Sultanate of Rum held it only fourteen years before the Crusaders arrived.
Crusader era.
The Crusaders' Siege of Antioch conquered the city in 1098. At this time, the bulk of far eastern trade traveled through Egypt, but in the second half of the 12th century Nur ed-Din and later Saladin brought order to Muslim Syria, opening up long distance trade routes, including to Antioch and on to its new port, St Symeon, which had replaced Seleucia Pieria. However, the Mongol conquests of the 13th century altered the main trade routes from the far east, as they encouraged merchants to take the overland route through Mongol territory to the Black Sea, reducing the prosperity of Antioch.
In 1100, Tancred became the regent of Antioch after his uncle and predecessor Bohemond I of Antioch was taken prisoner for three years (1100–03) by Gazi Gümüshtigin of the Danishmends at the Battle of Melitene. Tancred expanded the territory of Antioch by conquering Byzantine Cilicia, Tarsus, and Adana in 1101 and founding the principality, Byzantine Latakia, in 1103. In 1107 Bohemond enraged by an earlier defeat when he, allianced with Edessa, attacked Aleppo, and Baldwin of Bourcq and Joscelin of Courtenay (Bourcq's most powerful vassal) were briefly captured, as well as the Byzantines recapturing of Cilicia and the harbour and lower town of Lattakieh, he renamed Tancred as the regent of Antioch and sailed for Europe with the intent of gaining support for an attack against the Greeks.
In 1107-8 Bohemond led a 'crusade' against Byzantium, with the Latins crossing the Adriatic in October 1107 and laying siege to the city of Durazzo (in modern Albania), which is often regarded as the western gate of the Greek empire. Bohemond was outwitted by Alexius, who deployed his forces to cut the invaders' supply lines whilst avoiding direct confrontation. The Latins were weakened by hunger and proved unable to break Durazzo's defenses. Bohemond capitulated in September 1108 and was forced to accede to a peace accord, the Treaty of Devol. The terms of this agreement stipulated that Bohemond was to hold Antioch for the remainder of his life as the emperor's subject and the Greek patriarch was to be restored to power in the city. However Tancred refused to honour the Treaty of Devol in which Bohemond swore an oath, and it is not until 1158 that it truly became a vassal state of the Byzantine Empire. Six months after the Treaty of Devol Bohemond died, and Tancred remained regent of Antioch until his death during a typhoid epidemic in 1112.
After the death of Tancred, the principality passed to Roger of Salerno, who helped rebuild Antioch after an earthquake destroyed its foundations in 1114. With the defeat of Roger's crusading army and his death at the Battle of Ager Sanguinis in 1119 the role of regent was assumed by Baldwin II of Jerusalem, lasting until 1126, with the exception from 1123 to 1124 when he was briefly captured by the Artuqids and held captive alongside Joscelin of Courtenay. In 1126 Bohemond II arrived from Apulia in order to gain regency over Antioch. In February 1130 Bohemond was lured into an ambush by Leo I, Prince of Armenia who allied with the Danishmend Gazi Gümüshtigin, and was killed in the subsequent battle, his head was then embalmed, placed in a silver box, and sent as a gift to the Abbasid caliph in Baghdad.
Antioch was again ruled by a regency, firstly being Baldwin II, after his daughter and Bohemond II's wife, Alice of Antioch attempted to block Baldwin from entering Antioch, but failed when Antiochene nobles such as Fulk of Jerusalem (Alice's brother-in-law) opened up the gates for representatives of Baldwin II. Alice was then expelled from Antioch. With the death of Balwin in 1131, Alice briefly took control of Antioch and allied herself with Pons of Tripoli and Joscelin II of Edessa in an attempt to prevent Fulk, King of Jerusalem from marching north in 1132, however this attempt failed and Fulk and Pons fought a brief battle before peace was made and Alice was exiled again. In 1133 the king chose Raymond of Poitiers as a groom for Constance of Antioch, daughter of Bohemund II of Antioch and Alice, princess of Jerusalem. The marriage took place in 1136 between the 21-year-old Raymond and the 9-year-old Constance.
Immediately after assuming control, Raymond was involved in conflicts with the Byzantine Emperor John II Comnenus who had come south to recover Cilicia from Leo of Armenia, and to reassert his rights over Antioch. The engagement lasted until 1137 when emperor John II arrived with an army before the walls of Antioch. Though the basileus did not enter the city, his banner was raised atop the citadel and Raymond was compelled to do homage. Raymond agreed with the emperor that if he was capable of capturing Aleppo, Shaizar, and Homs, he would exchange Antioch for them.
John went on to attack Aleppo with the aid of Antioch and Edessa, and failed to capture it, with the Franks withdrawing their support when he moved on to capture Shaizar. John returned to Antioch ahead of his army and entered Antioch, only to be forced to leave when Joscelin II, Count of Edessa rallied the citizens to oust him. In 1142 John then returned but Raymond refused to submit and John was forced to return to Cilicia again due to the coming winter, to plan an attack the following season. However the emperor died on April 8, 1143.
Second Crusade.
The following year after the death of John II Comnenus, Imad ad-Din Zengi lay Siege to Edessa, the crusader capital, and with the death of Imad ad-Din Zengi in 1146, he was succeeded by his son, Nur ad-Din Zangi. Zangi attacked Antioch in both 1147 and 1148 and succeeded during the second venture in occupying most of the territory east of the Orontes including Artah, Kafar Latha, Basarfut, and Balat, but failing to capture Antioch itself. With the Second Crusades army previously nearly entirely defeated by the Turks and by sickness, Louis VII of France arrived in Antioch on March 19, 1148 after being delayed by storms. Louis was welcomed by the uncle of his spouse Eleanor of Aquitaine, Raymond of Poitiers.
Louis refused to help Antioch defend against the Turks and to lead an expedition against Aleppo, and instead decided to finish his pilgrimage to Jerusalem rather than focus on the military aspect of the Crusades. With Louis quickly leaving Antioch again and the Crusades returning home in 1149, Zangi launched an offensive against the territories which were dominated by the Castle of Harim, situated on the eastern bank of the Orontes, after which Zangi besieged the castle of Inag. Raymond of Poitiers quickly came to the aid of the citadel, where he was defeated and killed at the Battle of Inab, Raymond's head was then cut off and sent to Zangi, who sent it to the caliph in Baghdad. However, Zangi did not attack Antioch itself and was content with capturing all of Antiochene territory that lay east of the Orontes.
After the Second Crusade.
With Raymond dead and Bohemond III only five years of age, the principality came under the control of Raymond's widow Constance of Antioch, however real control lay with Aimery of Limoges. In 1152 Baldwin III of Jerusalem came of age, but from 1150 he had proposed three different but respectable suitors for Constance's hand in marriage, all of whom she rejected. In 1153 however, she chose Raynald of Châtillon and married him in secret without consulting her first cousin and liege lord, Baldwin III, and neither Baldwin nor Aimery of Limoges approved of her choice.
In 1156 Raynald claimed that the Byzantine emperor Manuel I Comnenus had reneged on his promises to pay Raynald a sum of money, and vowed to attack the island of Cyprus in revenge. However Aimery refused to finance Raynald's expedition, so in turn Raynalf had the Patriarch seized, beaten, stripped naked, covered in honey, and had him left in the burning sun on top of the citadel to be attacked by insects. When the Patriarch was released, he collapsed in exhaustion and agreed to finance Raynald's expedition.
In the meantime, Reynald had allied himself with the Armenian prince, Thoros II. In 1156 Raynald's forces attacked Cyprus, ravaging the island over a three-week period, with , killing, and plundering its citizens. After which, Manuel I Comnenus raised an army and began their march towards Syria, as a result Reynald threw himself to the mercy of the emperor who insisted on the installation of a Greek Patriarch and the surrender of the citadel in Antioch. The following spring, Manuel made a triumphant entry into the city and established himself as the unquestioned suzerain of Antioch.
In 1160 Reynald was captured by Muslims during a plundering raid against the Syrian and Armenian peasants of the neighbourhood of Marash. He was held captive for sixteen years, and as the stepfather of the Empress Maria, he was ransomed by Manuel for 120,000 gold dinars in 1176 (about 500 kg of gold, worth approximately £16 million or US$26 million as of October 2010). With Raynald disposed of for a long time, the patriarch Aimery became the new regent, chosen by Baldwin III. To further consolidate his own claim over Antioch, Manuel chose Maria of Antioch as his bride, daughter of Constance of Antioch and Raymond of Poitiers. But the government of Antioch remained in crisis up until 1163, when Constance asked the Armenian Kingdom of Cilicia to help maintain her rule, as a result the citizens of Antioch exiled her and installed her son Bohemond III and now brother-in-law to the emperor, as regent.
One year later, Nur ad-Din Zangi captured Bohemond III when he defeated a joint Antiochene-Tripolitan army. Bohemond III was soon released, however Harem, Syria which Reynald had recaptured in 1158, was lost again and the frontier of Antioch was permanently placed west of the Orontes. Byzantine influence remained in Antioch and in 1165, Bohemond III married a niece of the emperor, Maria of Antioch, and installed a Greek patriarch in the city, Athanasius II, Patriarch of Antioch, who remained in his position until he died in an earthquake five years later.
Third Crusade.
On October 29, 1187, Pope Gregory VIII issued the papal bull "Audita tremendi", his call for the Third Crusade. Frederick I Barbarossa, Richard I of England, and Philip II of France answered the summons. With Richard and Philip deciding to take a sea route, Frederick lacked the necessary ships and took a land route where he pushed on through Anatolia, defeating the Turks in the Battle of Inconium, however upon reaching Christian territory in Lesser Armenia (Armenian Kingdom of Cilicia) the emperor drowned in the river Saleph. The emperor was buried at Antioch and the Germans became an insignificant contingent during the crusade. Throughout the Third Crusade Antioch remained neutral, however with the end of the Third Crusade (1192), they were included in the Treaty of Ramla between Richard and Saladin.
Battles for sovereignty.
With no heir after the death of Raymond III, Count of Tripoli in the Battle of Hattin he left his godson, Raymond IV, Count of Tripoli, the eldest son of Bohemond III. However Bohemond installed his younger, the future prince Bohemond IV of Antioch, as count of Tripoli. Shortly after the end of the Third Crusade, Raymond IV, Count of Tripoli married Alice of Armenia, the niece of Leo II, or Leo I, King of Armenia, and a vassal to Antioch. Alice bore Raymond IV a son in 1199, Raymond-Roupen, after which Raymond IV died in the coming months. In 1194 Leo II tricked Bohemond III making him believe that the new born prince had been captured by the Roupenians. Leo made a failed attempt at capturing Antioch believing the city would be weakened with the absence of Bohemond.
Henry II, Count of Champagne nephew to both Richard I and Philip II, travelled to Lesser Armenia and managed to persuade Leo that in exchange for Antioch, renouncing its overlordship to Lesser Armenia and to release Bohemond, who in 1201 died. With the death of Bohemond III there followed a 15 year struggle for power of Antioch, between Tripoli and Lesser Armenia. According to the rules of primogeniture Leo's gret nephew Raymond-Roupen was the rightful heir of Antioch, and Leo's position was supported by the pope. However on the other hand, the city commune of Antioch supported Bohemond IV of Antioch, on the grounds that he was the closest blood relative to the last ruling prince, Bohemond III. In 1207 Bohemond IV installed a Greek patriarch in Antioch, despite the East-West Schism, under the help of Aleppo, Bohemond IV drove Leo out of Antioch.
Fifth Crusade and afterwards.
In 1213 Pope Innocent III's papal bull "Quia maior" called for all of Christendom to lead a new (Fifth) crusade. This strengthened the support of sultan al-Adil I (العادل), an Ayyubid-Egyptian general who supported Raymond-Roupen's claims in Antioch. In 1216 Leo installed Raymond-Roupen as prince of Antioch, and ending all military aspect of the struggle between Tripoli and Lesser Armenia, but the citizens again revolted against Raymond-Roupen in c.1219 and Bohemond of Tripoli was recognised as the fourth prince of that name. Bohemond IV and his son Bohemond V remained neutral in the struggles of the Guelphs and Ghibellines to the south which arose when Frederich II married Isabella II, and in 1233 Bohemond IV died.
From 1233 onwards Antioch declined and appeared rarely in records for 30 years, and in 1254 the altercations of the past between Antioch and Armenia were laid to rest when Bohemond VI of Antioch married the then 17 year old Sibylla of Armenia, and Bohemond VI became a vassal of the Armenian kingdom. Effectively, the Armenian kings ruled Antioch whilst the prince of Antioch resided in Tripoli. The Armenians drew up a treaty with the Mongols, who were now ravaging Muslim lands, and under protection they extended their territory into the lands of the Seljuq dynasty in the north and the Aleppo territory to the south. Antioch was part of this Armeno-Mongol alliance. Bohemond VI managed to retake Lattakieh and reestablished the land bridge between Antioch and Tripoli, while the Mongols insisted he install the Greek patriarch there rather than a Latin one, due to the Mongols attempting to strengthen ties with the Byzantine Empire. This earned Bohemond the enmity of the Latins of Acre, and Bohemond was excommunicated by the Patriarch of Jerusalem, Pope Urban IV, which was later suspended.
Fall of Antioch.
In 1259 the Mongols captured the Syrian city of Damascus, and eventually in 1260, Aleppo. The Mamluk sultan Saif ad-Din Qutuz looked to ally with the Franks, who declined. In September 1260, the Mamluks defeated the Mongols at the Battle of Ain Jalut, shortly after Qutuz was assassinated at Al-Salihiyya, and according to various sources his successor, Baibars was involved in his murder. (Baibars "came to power with [the] regicide [of Qutuz] on his conscience") according to Tschanz.
Antioch's ruler, Prince Bohemond VI was then left with no territories except the County of Tripoli. Without any southern fortifications and with Antioch isolated it could not withstand the onslaught of resurgent Muslim forces, and with the fall of the city, the remainder of northern Syria eventually capitulated, and ended the Latin presence in Syria. The Mamluk armies killed or enslaved every Christian in Antioch. In 1355 it still had a considerable population, but by 1432 there were only about 300 inhabited houses within its walls, mostly occupied by Turcomans.
Archaeology.
Few traces of the once great Roman city are visible today aside from the massive fortification walls that snake up the mountains to the east of the modern city, several aqueducts, and the Church of St Peter (St Peter's Cave Church, Cave-Church of St. Peter), said to be a meeting place of an Early Christian community. The majority of the Roman city lies buried beneath deep sediments from the Orontes River, or has been obscured by recent construction.
Between 1932 and 1939, archaeological excavations of Antioch were undertaken under the direction of the "Committee for the Excavation of Antioch and Its Vicinity," which was made up of representatives from the Louvre Museum, the Baltimore Museum of Art, the Worcester Art Museum, Princeton University, Wellesley College, and later (1936) also the Fogg Art Museum at Harvard University and its affiliate Dumbarton Oaks.
The excavation team failed to find the major buildings they hoped to unearth, including Constantine's Great Octagonal Church or the imperial palace. However, a great accomplishment of the expedition was the discovery of high-quality Roman mosaics from villas and baths in Antioch, Daphne and Seleucia. One mosaic includes a border that depicts a walk from Antioch to Daphne, showing many ancient buildings along the way. The mosaics are now displayed in the Hatay Archaeology Museum in Antakya and in the museums of the sponsoring institutions.
A statue in the Vatican and a number of figurines and statuettes perpetuate the type of its great patron goddess and civic symbol, the Tyche (Fortune) of Antioch – a majestic seated figure, crowned with the ramparts of Antioch's walls and holding wheat stalks in her right hand, with the river Orontes as a youth swimming under her feet. According to William Robertson Smith the Tyche of Antioch was originally a young virgin sacrificed at the time of the founding of the city to ensure its continued prosperity and good fortune.
The northern edge of Antakya has been growing rapidly over recent years, and this construction has begun to expose large portions of the ancient city, which are frequently bulldozed and rarely protected by the local museum.

</doc>
<doc id="36901" url="http://en.wikipedia.org/wiki?curid=36901" title="San Diego Zoo Safari Park">
San Diego Zoo Safari Park

The San Diego Zoo Safari Park, known as the San Diego Wild Animal Park until 2010, is an 1,800 acre (730 ha) zoo in the San Pasqual Valley area of San Diego, California, near Escondido. It is one of the largest tourist attractions in San Diego County. The park houses a large array of wild and endangered animals including species from the continents of Africa, Asia, Europe, North and South America, and Australia. The park is in a semi-arid environment, and one of its most notable features is the Africa Tram which explores the expansive African exhibits. These free-range enclosures house such animals as antelopes, giraffes, buffalo, cranes, and rhinoceros. The park is also noted for its California condor breeding program, the most successful such program in the United States.
The park, visited by 2 million people annually, houses over 2,600 animals representing more than 300 species, as well as 3,500 plant species.
Depending on the season, the park has about 400 to 600 employees. The park is also Southern California's quarantine center for zoo animals imported into the United States through San Diego.
The park has the world's largest veterinary hospital. Next door to the hospital is the Institute for Conservation Research which holds the park's Frozen Zoo.
Both the park and the San Diego Zoo are run by the Zoological Society of San Diego. The park is 32 mi away from the zoo, at 15500 San Pasqual Valley Road east of Escondido, California, along California State Route 78. Although the park is primarily within the San Diego city limits, it has an Escondido address.
History.
The San Diego Zoological Society became interested in developing the Wild Animal Park in 1964. The idea of the park began as a supplementary breeding facility for the San Diego Zoo, which would allow ample space for large animals and ungulates.
The development proposed would differ significantly from that of a typical zoo in that animals would be exhibited in a natural environment rather than in cages. In 1964, the park was assessed financially and then moved onto the next phase; this resulted in three alternative developments. There was an idea for a conservation farm, a game preserve, and a natural environment zoo. The natural environment zoo development was chosen over the conservation farm and game preserve even though it was the most expensive option. The estimated initial cost was $1,755,430.
The main purposes of this zoo were to be species conservation, breeding of animals for the San Diego Zoo as well as other zoos and providing areas where zoo animals could be conditioned. When it came to naming the park, five titles were considered: San Diego Animal Land, San Diego Safari Land, San Diego Wild Animal Safari, San Diego Wildlife Park and San Diego Wild Animal Park.
The scheduled opening day of the park was set for April 1, 1972; however, the gates did not open until Wednesday May 10, 1972. 
The general layout of the park, designed by Charles Faust, included a large lagoon with a jungle plaza, an African fishing village, an aviary at the entrance of the park and approximately 50,000 plants were to be included in the landscaping. Although the park was scheduled to open in three years from the time of the groundbreaking, the total development of the park was estimated to take ten years.
The first two animals to arrive at the park were the nilgai, an antelope from the plains of North India, and the black-and-white striped Grant's zebra, native to East Africa.
In the summer of 2003, the San Diego Zoological Society and Lowry Park Zoo orchestrated the capture of 11 wild African elephants from the Hlane Royal National Park in Swaziland. The zoos said the animals were scheduled to be killed due to overpopulation. However, In Defense of Animals disputes this, claiming that new fencing costing many times less than the capture and transport would have ended the need to remove any elephants from Swaziland, and that the Save Wild Elephants Coalition reported that there were three other sanctuaries in Africa that had offered to take the elephants.
Seven of these elephants are now at the San Diego Zoo Safari Park, and cumulatively they have produced thirteen babies as of 2013. In March 2012 five elephants were moved to the Reid Park Zoo in Tucson, Arizona, to form a new herd. A bull elephant, two cows, and two baby bulls were moved and in return two cow elephants that had been together for years. Connie, an Asian elephant, and Shaba, an African elephant, were sent to the San Diego Zoo Safari Park. Connie died from cancer in July 2012 just five months after the move. Shaba was slowly introduced into the herd in February 2013.
The California wildfires that officially started on October 21, 2007, burned 600 acre of native habitat preserved in the park and caused it to temporarily close. The park also moved many of their endangered animals out of danger. The fire did not reach any of the main enclosures, and no animals were killed directly by the fire, although deaths of a clapper rail and kiang were attributed to indirect effects of the blaze.
On June 30, 2010 the San Diego Zoo board of trustees voted to change the name of the park from the Wild Animal Park to the San Diego Zoo Safari Park to clarify what it offers, since some visitors were unclear as to the difference between the zoo proper and the "animal park". The name "safari" is supposed to emphasize "the park's spacious enclosures of free-ranging animals" (as opposed to "the closer quarters of the zoo"), encouraging visits to both locations.
Exhibits and attractions.
Asian Savanna and African Plains.
The park's largest exhibits, covering over 300 acre, are the open-range enclosures. Visitors view various plains habitats from Africa and Asia.
Asian Savanna covers 60 acre and displays Indian rhinoceros and several species of Asian deer and antelope such as axis deer and wapiti.
African Plains represents many regions and habitats. East Africa displays Cape buffalo, southern white rhinoceros, Ugandan giraffe, several other savanna species, and a lagoon with East African crowned crane The North Africa exhibit represents the Sahel and Sahara and houses scimitar-horned oryx, Barbary stag, red-fronted gazelle, and Ankole cattle. The Southern Africa field exhibits Grevy's zebras. The Central Africa region features a wooded waterhole with an island for pink-backed pelicans, saddle-billed storks, and Rüppell's vultures. On the shores of the lake are bongos, red river hogs, and Vaal rheboks, and other forest animals. A number of smaller enclosures visible only from the tram are home to Somali wild asses, kiangs (one of the world's only captive populations of this endangered wild equine), Arabian oryx, gorals, Japanese serows, black rhinoceroses, and Przewalski's wild horses.
Species of note in the open enclosures include two subspecies of giraffe, rhinos (the park has the world's most successful breeding program for southern white rhinos and is the only New World zoo to have northern white rhinos), gaur, vultures, markhor, and many species of antelope, gazelle, and deer.
Tiger Trail.
The tigers have three different exhibits, and there is a glass viewing window for visitors. After raising $19.6 million for the new exhibit ground was broken on December 12, 2012. The new exhibit is named the Tull Family Tiger Trail after movie producer Thomas Tull and his wife. Tiger Trail opened May 24, 2014. 
Nairobi Village and Gorilla Forest.
The park's Nairobi Village houses numerous exhibits for smaller animals. Among these are meerkats, an African Aviary, lemurs, flamingos, red river hogs, and bee eaters. A large lagoon is home to numerous species of waterfowl such as shoebill storks. Lorikeet Landing and Hidden Jungle display feedable Lories and lorikeets, and African birds, respectively. There is a nursery where visitors can watch baby animals being hand-reared as well as a nearby petting corral. Finally, a gorilla habitat houses a troop of western lowland gorillas. A flying fox bat exhibit is scheduled to be built here.
Hidden Jungle.
Located in Nairobi Village, this climate-controlled indoor exhibit opened in 1993 and displays tropical African birds and insects. The entrance to the building is a simulated earthen crevasse with displays for stick insects and arachnids. The underground segment opens up to a room representing the rainforest understory, which leads to a second room representing the canopy. On display are long-tailed paradise whydah, purple grenadier, and other birds.
Hidden Jungle is the setting of the annual "Butterfly Jungle" event.
Lion Camp.
Opened in October 2004, Lion camp houses the park's thirteen African lions in a 1 acre exhibit. One side of the enclosure is dominated by an artificial rock kopje which has a 40 foot glass viewing window and heated rocks. The path continues along an acacia-studded ravine and leads to a replica observation tent. This has a smaller viewing window as well as a Land Rover for the lions to rest on.
Condor Ridge.
Condor Ridge displays endangered North American desert wildlife. The featured species are California condors (the Wild Animal Park was the key force in the recovery effort for these birds and this is one of the only places in the world where the public can see them in captivity) and desert bighorn sheep. Other species displayed include aplomado falcons, thick-billed parrots, prairie dogs, black footed ferrets, magpies, and desert tortoises.
African Woods and African Outpost.
Formerly known as Heart of Africa, these are two of the park's major exhibits. Visitors go down a trail which replicates habitats in Africa. The exhibit begins in African Woods with scrub animals - vultures, lesser kudu, and giant eland. It then progresses to forest (okapi, duikers, and wattled cranes). The path then leads to African Outpost, which features plains animals - bontebok, common warthogs, ground hornbills, and cheetahs - against a backdrop of the open-range East Africa exhibit. A central lagoon has lesser and greater flamingos, waterfowl, an island with colobus monkeys, and an interpretive research camp on a separate island.
Tours and Rides.
The park formerly operated a monorail line, the Wgasa Bush Line, which ran through the Wild Animal Park. The name of the monorail was chosen by chief designer Chuck Faust.
The Monorail line has been retired, partially due to high maintenance costs, and in March 2007 the Journey into Africa attraction, now renamed Africa Tram, opened. The Africa Tram tour brings visitors to the field exhibits to see wildlife from different parts of Africa. In addition, another route is planned to bring visitors through the Asian field exhibits and into eight new ones that will house a variety of African animals from rock hyrax to Hartmann's mountain zebras. The tour utilizes a wheeled tram that runs on biofuel instead of a monorail.
As well as the tram, the park has also added a tethered balloon ride that allows visitors to see the plains exhibits from 400 ft in the air. The balloon ride is not included in the entrance fee.
Gardens.
The park also has extensive botanical gardens, many of which are their own attractions separate from the animal exhibits.
Conservation.
The Safari Park was a major factor in the recovery of the California condor. Beginning in 1980, it worked with the U.S. Fish and Wildlife Service and the Los Angeles Zoo to start a captive breeding program. The last 22 condors were taken into captivity in 1987 To breed the condors quickly, the Safari Park would remove the eggs from the nests to induce the females to lay a second egg. The removed egg hatches in an incubator and is raised with a condor handpuppet to prevent human imprinting, while the second egg is raised by its parents. Captive-bred condors were reintroduced into the wild beginning in 1992, and today their population is 369, with 191 in the wild as of March 2011.
On December 14, 2014, Angalifu, a 44-year-old male northern white rhinoceros, died at the park. This leaves only five northern white rhinos left in the world, including one female at the Safari Park.

</doc>
<doc id="36907" url="http://en.wikipedia.org/wiki?curid=36907" title="Moustapha Akkad">
Moustapha Akkad

Moustapha Al Akkad (Arabic: مصطفى العقاد‎; July 1, 1930 – November 11, 2005) was a Syrian American film producer and director, best known for producing the original series of "Halloween" films and directing "Mohammad, Messenger of God" and "Lion of the Desert". He was killed along with his daughter Rima Al Akkad Monla in 2005 in Amman, Jordan by a suicide bomber.
Early life and career.
Al Akkad was born on July 1, 1930 in Aleppo, Syria. He received his high school degree from the Aleppo American College. His father, then a customs officer, gave him $200 and a copy of the Quran before he left for the United States to study film direction and production at the University of California, Los Angeles (UCLA). Akkad spent a further three years studying for a Master's degree at the University of Southern California (USC), where he met the director Sam Peckinpah. Peckinpah became Akkad's mentor in Hollywood and hired him as a consultant for a film about the Algerian revolution that never made it to the big screen, but he continued to encourage him until he found a job as a producer at CBS.
In 1976, he produced and directed "Mohammad, Messenger of God" (released as "The Message" in 1977 in the United States), starring Anthony Quinn and Irene Papas. Al Akkad faced resistance from Hollywood which forced him to make the film in Morocco.
While creating "Muhammad, Messenger of God", he consulted Islamic clerics and tried to be respectful towards Islam and its views on portraying Muhammad. He got the Approval from "Al Azhar" in Egypt but was rejected by the Muslim World League in Mecca, Saudi Arabia. The Governments of Kuwait, Libya and Morocco promised to support the film financially, but when it was rejected by the Muslim World League, Kuwait withdrew its financial support. King Hassan II of Morocco gave his full support for the production of the film. The production took one year, Akkad filmed for 6 months in Morocco, but had to stop when the Saudi Government exerted great pressure on the government of Morocco to stop the production. Al Akkad went to Muammar Gaddafi of Libya for support in order to complete the project, Gaddafi allowed him to move the filming to Libya for the remaining 6 months until the film was finalized.
Al Akkad saw the film as a way to bridge the gap between the Western and Islamic worlds, stating in a 1976 interview:
In 1978, he helped make low-budget film history when he produced "Halloween". Akkad became best known for his key involvement in the first eight "Halloween" movies, as an executive producer (the only producer to participate in all of these films). The series was highly profitable.
In 1980 he directed "Lion of the Desert", in which Quinn and Irene Papas were joined by Oliver Reed, Rod Steiger, and John Gielgud. It was about the real-life Bedouin leader Omar Mukhtar (Quinn), who fought Benito Mussolini's Italian troops in the deserts of Libya. The movie is now critically acclaimed, after initially receiving negative publicity in the West for being partially funded by Libya's Muammar Gaddafi, who invested $35 million in the movie. This negative publicity may have been the cause of its relatively poor performance at the box office.
In the United Kingdom Al Akkad once tried to buy Pinewood Studios from the Rank Organisation and also had a studio at Twickenham. At the time of his death, he was in the process of producing an $80 million movie featuring Sean Connery about Saladin and the Crusades, for which he already had the script, that would be filmed in Jordan. Speaking of the film, he said:
Death.
Al Akkad and his 34-year-old daughter, Rima Akkad Monla, were killed in the November 9, 2005 Amman bombings in Amman, Jordan. They were both in the lobby at the Grand Hyatt when a bomb exploded ; his daughter died instantly, and Akkad died of his injuries two days later in a hospital. Moustapha Al Akkad is survived by his former wife, Patricia Al Akkad and their sons, Taric and Malek who helped produce most of the "Halloween" movies, as well as his widow, Suha Ascha Akkad, and their son Zaid.
He was honoured by his native city of Aleppo, and the Aleppo City Council has renamed a school and a street after Moustapha Akkad. In 2008, a street in downtown Beirut was renamed after Moustapha Akkad. The 2007 remake of "Halloween" was dedicated to Moustapha Akkad.

</doc>
<doc id="36908" url="http://en.wikipedia.org/wiki?curid=36908" title="Service club">
Service club

A service club or service organization is a voluntary non-profit organization where members meet regularly to perform charitable works either by direct hands-on efforts or by raising money for other organizations. A service club is defined firstly by its service mission and secondly its membership benefits, such as social occasions, networking, and personal growth opportunities that encourage involvement.
A service organization is not necessarily exclusive of ideological motives, although organizations with such defined motives are more likely to identify themselves through their association. Much like the historical religious organizations that formed the basis for many societal institutions, such as hospitals, service organizations perform many essential services for their community and other worthy causes. In the United States, some of these clubs usually also have a component club organization that is a tax exempt 501(c)(3) non-profit organization.
Many of today's service clubs got their start as social clubs for business networking, but quickly evolved into organizations devoted more to service than to networking, although networking may still be the primary reason many members decided join.
Historically, most service clubs consist of community-based groups that share the same name, goals, membership requirements, and meeting structure. Many of these clubs meet weekly, bi-weekly, or monthly on a recurring established day and time, commonly at a mealtime. Most of these clubs started with a single club in a single city, but then replicated themselves by organizing similar clubs in other communities. Many of the service club organizations have become world-wide movements, and have obtained official recognition by the United Nations and various governments as non-government organizations
Service clubs in this article do not refer to the term "service club" used in the United Kingdom, Australia, and some other Commonwealth countries, in which those groups consist of clubs for members of "the services", a common expression for the military or uniformed forces. In the Americas, these types of clubs are commonly known as veterans' organizations or veterans' fraternal groups.
The world's first service club, the Rotary Club of Chicago, was formed in 1905 by Paul P. Harris, an attorney who wanted to create in a professional club with the same friendly spirit he had felt in the small towns of his youth. The Rotary name derived from the early practice of rotating meetings among members' offices.
Examples.
Many of these service clubs were started early in the 20th century, such as Rotary, Kiwanis, Lions, Apex Clubs of Australia, Altrusa International, JCI, Civitan International, Sertoma, Exchange, Optimists, Soroptimists, KIN Canada, Zonta, Quota International. A new generation of service clubs includes HandsOn Network, BEAN and DoSomething.org.

</doc>
<doc id="36909" url="http://en.wikipedia.org/wiki?curid=36909" title="Melissa Sue Anderson">
Melissa Sue Anderson

Melissa Sue Anderson (born September 26, 1962) is an American-Canadian actress. She began her career as a child actress. Anderson is known for her role as Mary Ingalls on the NBC drama series "Little House on the Prairie". 
She is also known for her film roles; Vivian in "", Ginny in the cult classic slasher "Happy Birthday to Me", and Alex in the "ABC Afterschool Special", "Which Mother Is Mine?".
Career.
Acting.
Her show business career began when a dance teacher urged her parents to find an agent for her. She began doing television commercials, and soon she was in demand for television roles. Her first came in a 1972 episode of "Bewitched" entitled "Tabitha's First Day Of School." A memorable early role of hers was of Millicent, a girl who kissed Bobby and induced him to see fireworks on "The Brady Bunch".
At the age of eleven, Anderson landed the role of Mary Ingalls on "Little House on the Prairie". She would go on to star on the show for eight seasons; beginning in 1974 and leaving after season seven, later appearing in two episodes of season eight in late 1981.
In 1976, Michael Landon asked Anderson if she would appear in his autobiographical film,"The Loneliest Runner". Anderson agreed to play Nancy Rizzi, the first girlfriend of John Curtis (based on Landon and played by Lance Kerwin), saying she was very thrilled to have been asked. In 1977, she once again co-starred as the love interest opposite Lance Kerwin in the television film "James at 15".
She was nominated for a 1978 Primetime Emmy Award for Best Leading Actress in a Drama Series for her work on "Little House on the Prairie" and won the Emmy Award for her performance in "Which Mother Is Mine?", which aired as an "ABC Afterschool Special" in 1979. Also in 1979, she played the title role of Dana Lee Gilbert, a North Dakota transfer student to Los Angeles' San Fernando Valley, California in CBS's TV movie "Survival of Dana".
In 1980, Anderson earned a 'TP de Oro' Award (considered to be Spain's most prestigious award for television) for 'Best Foreign Actress' for her role in "Little House on the Prairie". This followed a successful visit to Spain in 1979 to appear as a guest on RTVE's program, 625 Lineas. In 1981, she earned a Young Artist Award nomination for her performance in the Canadian slasher film "Happy Birthday to Me". After leaving "Little House", she continued acting in television shows like "The Equalizer", "Alfred Hitchcock Presents (1980s)", and "Murder, She Wrote", and was the associate producer for the next to last TV project Michael Landon made before dying: "Where Pigeons Go to Die" (1990). In 1998, she was inducted into the Western Performers Hall of Fame at the National Cowboy & Western Heritage Museum in Oklahoma City, Oklahoma.
Author.
In 2010 Anderson released her autobiography entitled "The Way I See It - A Look Back at My Life on Little House". The book, which is primarily based on her life during her years as a child star on "The Little House On The Prairie", contains behind-the-scenes stories and anecdotes about the show itself, its stars, guest stars, and crew members.
Methodically, Anderson takes the reader through each of the first seven seasons of the show (the seasons in which she appeared). She also tells about her pre- and post-"Little House" career and her side-projects during the "Little House" years. She is frank and open about her feelings about the projects in which she has been involved, and also writes about her personal life and how it was affected by her career.
Personal life.
Anderson was born in Berkeley, California. Anderson's first publicly known romance was with actor Lorenzo Lamas, with whom she made an appearance in the television series "The Love Boat" in which two friends (Lorenzo and Melissa) resist the matchmaking efforts of their parents. After this short romance, she dated Frank Sinatra, Jr. in the late 1970s, who, at the time, was more than twice her age.
With husband Michael Sloan, Anderson has two children, daughter Piper (born February 1991) and son Griffin (born June 1996). She has lived in Montreal, Quebec, Canada since 2002. She and her husband became naturalized Canadians in 2007.

</doc>
<doc id="36911" url="http://en.wikipedia.org/wiki?curid=36911" title="Antipater of Sidon">
Antipater of Sidon

Antipater of Sidon (Greek: Ἀντίπατρος "Antipatros") or Antipatros Sidonios (Ἀντίπατρος Σιδώνιος) in the Anthologies, was an ancient Greek poet in the second half of the 2nd century BC. His poems preserved in the "Greek Anthology" include evocations of art and literature and some epitaphs. But there appears to be confusion in the Anthology between Antipater of Sidon and Antipater of Thessalonice, who lived in the next century.
Cicero describes Antipater as living at Rome in the time of Crassus and Catulus.
Antipater composed an epitaph for Sappho, in which he stated that she died of natural causes and was buried in her homeland. Cicero ("Oratore", III, 50 and "de Fato", 2) described him as a brilliant epigrammist but sometimes too fond of imitation.
He, along with Philo of Byzantium, Strabo, Herodotus and Diodoros of Sicily, is attributed with the list of the Seven Wonders of the Ancient World, which he described in a poem composed about 140 BC:
 I have set eyes on the wall of lofty Babylon on which is a road for chariots, and the statue of Zeus by the Alpheus, and the hanging gardens, and the Colossus of the Sun, and the huge labour of the high pyramids, and the vast tomb of Mausolus; but when I saw the house of Artemis that mounted to the clouds, those other marvels lost their brilliancy, and I said, 'Lo, apart from Olympus, the Sun never looked on aught so grand.'
 — Antipater, "Greek Anthology" IX.58

</doc>
<doc id="36914" url="http://en.wikipedia.org/wiki?curid=36914" title="Egg (disambiguation)">
Egg (disambiguation)

An egg is an organic vessel in which an embryo begins to develop.
Egg or eggs may also refer to:

</doc>
<doc id="36915" url="http://en.wikipedia.org/wiki?curid=36915" title="Arabesque (Islamic art)">
Arabesque (Islamic art)

The arabesque is a form of artistic decoration consisting of "surface decorations based on rhythmic linear patterns of scrolling and interlacing foliage, tendrils" or plain lines, often combined with other elements. It usually consists of a single design which can be 'tiled' or seamlessly repeated as many times as desired. Within the very wide range of Eurasian decorative art that includes motifs matching this basic definition the term "arabesque" is used consistently as a technical term by art historians to describe only elements of the decoration found in two phases: Islamic art from about the 9th century onwards, and European decorative art from the Renaissance onwards (see Arabesque (European art)).
Arabesques are a fundamental element of Islamic art but they develop what was already a long tradition by the coming of Islam. The past and current usage of the term in respect of European art can only be described as confused and inconsistent. Some Western arabesques derive from Islamic art, but others are closely based on Ancient Roman decorations. In the West they are essentially found in the decorative arts, but because of the generally non-figurative nature of Islamic art arabesque decoration is there often a very prominent element in the most significant works, and plays a large part in the decoration of architecture.
Islamic arabesque.
Early Islamic art, for example in the famous 8th century mosaics of the Great Mosque of Damascus, often contained arabesque patterns. The plants most often used are stylized versions of the acanthus, with its emphasis on leafy forms, and the vine, with an equal emphasis on twining stems. Arabesque patterns also decorated everyday items such as cups and containers. The evolution of these forms into a distinctive Islamic type was complete by the 11th century, having begun in the 8th or 9th century in works like the Mshatta Facade. In the process of development the plant forms became increasing simplified and stylized. Though the broad outline of the process is generally agreed, there is a considerable diversity of views held by specialist scholars on detailed issues concerning the development, categorization and meaning of the arabesque. The detailed study of Islamic arabesque forms was begun by Alois Riegl in his formalist study "Stilfragen: Grundlegungen zu einer Geschichte der Ornamentik" ("Problems of style: foundations for a history of ornament") of 1893, who in the process developed his influential concept of the "Kunstwollen". Riegl traced formalistic continuity and development in decorative plant forms from Ancient Egyptian art and other ancient Near Eastern civilizations through the classical world to the Islamic arabesque; while the "Kunstwollen" has few followers today, his basic analysis of the development of forms has been confirmed and refined by the wider "corpus" of examples known today. Jessica Rawson has recently extended the analysis to cover Chinese art, which Riegl did not cover, tracing many elements of Chinese decoration back to the same tradition; the shared background helping to make the assimilation of Chinese motifs into Persian art after the Mongol invasion harmonious and productive.
Claims are often made regarding the theological significance of the arabesque, and its origin in a specifically Islamic view of the world; however these are without support from written historical sources as, like most medieval cultures, the Islamic world has not left us documentation of their intentions in using the decorative motifs they did. At the popular level such theories often appear uninformed as to the wider context of the arabesque. In similar fashion, proposed connections between the arabesque and Arabic knowledge of geometry remains a subject of debate; not all art historians are persuaded that such knowledge had reached, or was needed by, those creating arabesque designs, although in certain cases there is evidence that such a connection did exist. The case for a connection with Islamic mathematics is much stronger for the development of the geometric patterns with which arabesques are often combined in art. Geometric decoration often uses patterns that are made up of straight lines and regular angles but are clearly derived as a whole from curvilinear arabesque patterns; the extent to which these too are described as arabesque varies between different writers.
Many arabesque patterns disappear at (or "under" as it often appears to a viewer) a framing edge without ending, and thus can be regarded as infinitely extendable outside the space they actually occupy; this was certainly a distinctive feature of the Islamic form, though not without precedent. Most but not all foliage decoration in the preceding cultures terminated at the edge of the occupied space, although infinitely repeatable patterns in foliage are very common in the modern world in wallpaper and textiles.
Typically, in earlier forms there is no attempt at realism; no particular species of plant is being imitated, and the forms are often botanically impossible or implausible. "Leaf" forms typically spring sideways from the stem, in what is often called a "half-palmette" form, named after its distant and very different looking ancestor in Ancient Egyptian and Greek ornament. New stems spring from leaf-tips, a type often called honeysuckle, and the stems often have no tips, winding endlessly out of the space. The early Mshatta Facade is recognisably some sort of vine, with conventional leaves on the end of short stalks and bunches of grapes or berries, but later forms usually lack these. Flowers are rare until about 1500, after which they appear more often, especially in Ottoman art, and are often identifiable by species. In Ottoman art the large and feathery leaves called "saz" became very popular, and were elaborated in drawings showing just one or more large leaves. Eventually floral decoration mostly derived from Chinese styles, especially those of Chinese porcelain, replaces the arabesque in many types of work, such as pottery, textiles and miniatures.
Significance in Islam.
The arabesques and geometric patterns of Islamic art are often said to arise from the Islamic view of the world. The depiction of animals and people is generally discouraged, which explains the preference for abstract geometric patterns.
There are two modes to arabesque art. The first recalls the principles that govern the order of the world. These principles include the bare basics of what makes objects structurally sound and, by extension, beautiful (i.e. the angle and the fixed/static shapes that it creates—esp. the truss). In the first mode, each repeating geometric form has a built-in symbolism ascribed to it. For example, the square, with its four equilateral sides, is symbolic of the equally important elements of nature: earth, air, fire and water. Without any one of the four, the physical world, represented by a circle that inscribes the square, would collapse upon itself and cease to exist. The second mode is based upon the flowing nature of plant forms. This mode recalls the feminine nature of life giving. In addition, upon inspection of the many examples of Arabesque art, some would argue that there is in fact a third mode, the mode of Arabic calligraphy.
Instead of recalling something related to the 'True Reality' (the reality of the spiritual world), Islam considers calligraphy a visible expression of the highest art of all; the art of the spoken word (the transmittal of thoughts and of history). In Islam, the most important document to be transmitted orally is the Qur'an. Proverbs and complete passages from the Qur'an can be seen today in Arabesque art. The coming together of these three forms creates the Arabesque, and this is a reflection of unity arising from diversity; a basic tenet of Islam.
The arabesque may be equally thought of as both art and science. The artwork is at the same time mathematically precise, aesthetically pleasing, and symbolic. Due to this duality of creation, the artistic part of this equation may be further subdivided into both secular and religious artwork. However, for many Muslims there is no distinction; all forms of art, the natural world, mathematics and science are all seen to be creations of God and therefore reflections of the same thing: God's will expressed through his creation. In other words, man can discover the geometric forms that constitute the Arabesque, but these forms always existed before as part of God's creation, as shown in this picture.
There is great similarity between arabesque artwork from very different geographic regions. In fact, the similarities are so pronounced that it is sometimes difficult for experts to tell where a given style of arabesque comes from. The reason for this is that the science and mathematics that are used to construct Arabesque artwork are universal. Therefore, for most Muslims, the best artwork that can be created by man for use in the Mosque is artwork that displays the underlying order and unity of nature. The order and unity of the material world, they believe, is a mere ghostly approximation of the spiritual world, which for many Muslims is the place where the only true reality exists. Discovered geometric forms, therefore, exemplify this perfect reality because God's creation has been obscured by the sins of man.
Mistakes in repetitions may be intentionally introduced as a show of humility by artists who believe only Allah can produce perfection, although this theory is disputed.
Arabesque art consists of a series of repeating geometric forms which are occasionally accompanied by calligraphy. Ettinghausen et al. describe the arabesque as a "vegetal design consisting of full...and half palmettes [as] an unending continuous pattern...in which each leaf grows out of the tip of another." To the adherents of Islam, the Arabesque is symbolic of their united faith and the way in which traditional Islamic cultures view the world.
Western arabesque.
The term was first used in the West in Italian, where "rabeschi" was used in the 16th century as a term for "pilaster ornaments featuring acanthus decoration, specifically "running scrolls" that ran vertically up a panel or pilaster, rather than horizontally along a frieze. From there it spread to England, where Henry VIII owned, in an inventory of 1549, an agate cup with a "fote and Couer of siluer and guilt enbossed with Rebeske worke", and William Herne or Heron, Serjeant Painter from 1572 to 1580, was paid for painting Elizabeth I's barge with "rebeske work". Unfortunately the styles so described can only be guessed at, although the design by Hans Holbein for a covered cup for Jane Seymour in 1536 (see gallery) already has zones in both Islamic-derived arabesque/moresque style (see below) and classically-derived acanthus volutes.
Another related term is moresque, meaning "Moorish"; Randle Cotgrave's "A Dictionarie of the French and English Tongues" of 1611 defines this as: "a rude or anticke painting, or carving, wherin the feet and tayles of beasts, &c, are intermingled with, or made to resemble, a kind of wild leaves, &c." and "arabesque", in its earliest use cited in the OED (but as a French word), as "Rebeske work; a small and curious flourishing". In France "arabesque" first appears in 1546, and "was first applied in the latter part of the 17th century" to grotesque ornament, "despite the classical origin of the latter", especially if without human figures in it - a distinction still often made, but not consistently observed,
Over the following centuries the three terms grotesque, moresque and arabesque were used largely interchangeably in English, French and German for styles of decoration derived at least as much from the European past as the Islamic world, with "grotesque" gradually acquiring its main modern meaning, related more to Gothic gargoyles and caricature than to either Pompeii-style Roman painting or Islamic patterns. Meanwhile the word "arabesque" was now being applied to Islamic art itself, by 1851 at the latest, when John Ruskin uses it in "The Stones of Venice". Writers over the last decades have attempted to salvage meaningful distinctions between the words from the confused wreckage of historical sources.
Peter Furhring, a specialist in the history of ornament, says that (also in a French context): The ornament known as moresque in the fifteenth and sixteenth centuries (but now more commonly called arabesque) is characterized by bifurcated scrolls composed of branches forming interlaced foliage patterns. These basic motifs gave rise to numerous variants, for example, where the branches, generally of a linear character, were turned into straps or bands. ... It is characteristic of the moresque, which is essentially a surface ornament, that it is impossible to locate the pattern's beginning or end. ... Originating in the Middle East, they were introduced to continental Europe via Italy and Spain ... Italian examples of this ornament, which was often used for bookbindings and embroidery, are known from as early as the late fifteenth century.
Fuhring notes that grotesques were "confusingly called arabesques in eighteenth century France", but in his terminology "the major types of ornament that appear in French sixteenth century etchings and engraving ...can be divided into two groups. The first includes ornaments adopted from antiquity: grotesques, architectural ornaments such as the orders, foliage scrolls and self-contained elements such as trophies, terms and vases. A second group, far smaller than the first, comprises modern ornaments: moresques, interlaced bands, strapwork, and elements such as cartouches...", categories he goes on to discuss individually.
The moresque or arabesque style was especially popular and long-lived in the Western arts of the book: bookbindings decorated in gold tooling, borders for illustrations, and printer's ornaments for decorating empty spaces on the page. In this field the technique of gold tooling had also arrived in the 15th century from the Islamic world, and indeed much of the leather itself was imported from there. Small motifs in this style have continued to be used by conservative book designers up to the present day.
According to Harold Osborne, in France, the "characteristic development of the French arabesque combined bandwork deriving from the moresque with decorative acanthus foliage radiating from C-scrolls connected by short bars". Apparently starting in embroidery, it then appears in garden design before being used in Northern Mannerist painted decorative schemes "with a central medallion combined with acanthus and other forms" by Simon Vouet and then Charles Lebrun who used "scrolls of flat bandwork joined by horizontal bars and contrasting with ancanthus scrolls and palmette." More exuberant arabesque designs by Jean Bérain the Elder are an early "intimation" of the Rococo, which was to take the arabesque into three dimensions in reliefs.
The use of "arabesque" as an English noun first appears, in relation to painting, in William Beckford's novel "Vathek" in 1786.
Arabesque is also used as a term for complex freehand pen flourishes in drawing or other graphic media. The Grove Dictionary of Art will have none of this confusion, and says flatly: "Over the centuries the word has been applied to a wide variety of winding and twining vegetal decoration in art and meandering themes in music, but it properly applies only to Islamic art", so contradicting the definition of 1888 still found in the Oxford English Dictionary: "A species of mural or surface decoration in colour or low relief, composed in flowing lines of branches, leaves, and scroll-work fancifully intertwined. Also fig[uratively]. As used in Moorish and Arabic decorative art (from which, almost exclusively, it was known in the Middle Ages), representations of living creatures were excluded; but in the arabesques of Raphael, founded on the ancient Græco-Roman work of this kind, and in those of Renaissance decoration, human and animal figures, both natural and grotesque, as well as vases, armour, and objects of art, are freely introduced; to this the term is now usually applied, the other being distinguished as Moorish Arabesque, or Moresque."

</doc>
<doc id="36916" url="http://en.wikipedia.org/wiki?curid=36916" title="Theotokos">
Theotokos

Theotokos (; Greek: Θεοτόκος, transliterated (Greek) "Theotókos", translation (Syriac-Aramaic): "ܝܳܠܕܰܬ ܐܰܠܳܗܳܐ‎", transliterated (Syriac): "Yoldath Alloho"; Latin: "Mater Dei") is the Greek title of Mary, the mother of Jesus used especially in the Eastern Orthodox, Oriental Orthodox, and Eastern Catholic Churches. Its literal English translations include "God-bearer", "Birth-Giver of God" and "the one who gives birth to God." Less literal translations include "Mother of God."
The ancient use of this term is emphasised in Churches of the Syriac Tradition, which have been using this title in their ancient liturgies for centuries: the Anaphora of Mari and Addai (3rd Century), and the Liturgy of St James the Just (60 AD).
Roman Catholics and Anglicans use the title "Mother of God" more often than ""Theotokos"." The Council of Ephesus decreed in 431 that Mary is "Theotokos" because her son Jesus is both God and man: one Divine Person with two natures (Divine and human) intimately, hypostatically united.
Etymology and usage.
Theotokos is a compound of two Greek words, Θεός "God" and τόκος "parturition, childbirth". Literally, this translates as "God-bearer" or "the one who gives birth to God"; historian Jaroslav Pelikan translated it more precisely as "the one who gives birth to the one who is God". However, since many English-speaking Orthodox find this literal translation awkward, in liturgical use, "Theotokos" is often left untranslated, or paraphrased as "Mother of God". The latter title is the literal translation of a distinct title in Greek, Μήτηρ του Θεού (translit. "Mētēr tou Theou"). "Mother of God" also accurately translates the Greek words Θεομήτωρ (translit. "Theomētor"; also spelled Θεομήτηρ, translit. "Theomētēr") and Μητρόθεος (translit. "Mētrotheos"), which are found in patristic and liturgical texts, e.g.
... [80] περιφανῶς ἡ ἱερὰ θεομήτωρ ἐξετέλει ... [109] ἐκφαντικώτατά σε τὴν θεοτόκον προσημαίνουσαν ...
The English term "Mother of God" is mostly used as an imprecise translation of "Theotokos", and frequently requires explanation. The other principal use of "Mother of God" has been as the precise and literal translation of Μήτηρ Θεού, a Greek term which has an established usage of its own in traditional Orthodox and Catholic theological writing, hymnography, and iconography. In an abbreviated form, ΜΡ ΘΥ, it often is found on Eastern icons (see illustration above), where it is used to identify Mary.
Within the Orthodox and Catholic tradition, "Mother of God" has not been understood, nor been intended to be understood, as referring to Mary as Mother of God "from eternity" — that is, as Mother of God the Father — but only with reference to the birth of Jesus, that is, the Incarnation. This limitation in the meaning of "Mother of God" must be understood by the person employing the term. To make it explicit, it is sometimes translated "Mother of God Incarnate".
However, those reading or hearing the English phrase "Mother of God" as a translation of a Greek text cannot — unless they know the Greek text in question, or obtain additional information — know whether the phrase is a literal translation of Μήτηρ Θεού, or an imprecise rendering of Θεοτόκος, or one its Latin equivalents or equivalents in other languages. On the other hand, "Theotokos" and its precise translations explicitly relate Mary's motherhood to Jesus' birth in time and exclude any reference to Mary as Mother of God "from eternity".
Theology.
Theotokos specifically excludes the understanding of Mary as Mother of God in the eternal sense. Christians believe that God is the cause of all, with neither origin nor source, and is therefore without a mother or father, or any relation except for what is homoousian to Him: only the persons of the Holy Trinity. He is ontologically separate from all other beings, as Creator to creation. This stands in contrast to classical Greco-Roman religion in particular, where a number of goddesses appear as the physical mothers of other divinities which were considered gods in their own right (cf. polytheism).
On the other hand, most Christians believe God the Son is begotten of God the Father "from all eternity" (see Trinity and Nicene Creed), but is born "in time" of Mary. "Theotokos" thus refers to the Incarnation, when the Second Person of the Holy Trinity took on human nature in addition to his pre-existing divine nature, this being made possible through the cooperation of Mary.
Though most Christians understand Jesus Christ as both fully God and fully human, only Orthodox Christians (in the East), and Roman Catholics, Anglicans, Lutherans, and schismatic Old Catholics (in the West), call Mary "Theotokos". The Council of Ephesus decreed, in opposition to those who denied Mary the title "Theotokos" ("the one who gives birth to God") but called her "Christotokos" ("the one who gives birth to Christ"), that Mary "is" "Theotokos" because her son Jesus is one person who is both God and man, divine and human. Cyril of Alexandria wrote, "I am amazed that there are some who are entirely in doubt as to whether the holy Virgin should be called "Theotokos" or not. For if our Lord Jesus Christ is God, how is the holy Virgin who gave [Him] birth, not ["Theotokos"]?" (Epistle 1, to the monks of Egypt; PG 77:13B). Thus the significance of "Theotokos" lies more in what it says about Jesus than any declaration about Mary, according to this Catholic doctrine.
Within the Orthodox doctrinal teaching on the economy of salvation, Mary's identity, role, and status as "Theotokos" is acknowledged as indispensable. For this reason, it is formally defined as official dogma. The only other Mariological teaching so defined is that of her virginity. Both of these teachings have a bearing on the identity of Jesus Christ. By contrast, certain other Marian beliefs which do not bear directly on the doctrine concerning the person of Jesus (for example, her sinlessness, the circumstances surrounding her conception and birth, her Presentation in the Temple, her continuing virginity following the birth of Jesus, and her death), which are taught and believed by the Orthodox Church (being expressed in the Church's liturgy and patristic writings), are not formally defined by the Church. Belief in them is not a precondition for baptism.
Use in the early Christian Church.
Origen (d. 254) is often cited as the earliest author to use "theotokos" for Mary (Socrates, Ecclesiastical History 7.32 citing Origen's Commentary on Romans) but the text upon which this assertion is based may not be genuine.
Athanasius of Alexandria in 330, Gregory the Theologian in 370, John Chrysostom in 400, and Augustine all used "theotokos".
Sub tuum praesidium, a Coptic Orthodox hymn dating approximately to the year 250, refers to Mary as the "theotokos".
Third Ecumenical Council.
The use of "Theotokos" was formally affirmed at the Third Ecumenical Council held at Ephesus in 431. The competing view, advocated by Patriarch Nestorius of Constantinople, was that Mary should be called "Christotokos", meaning "Birth-giver of Christ," to restrict her role to the mother of Christ's humanity only and not his divine nature.
Nestorius' opponents, led by Cyril of Alexandria, viewed this as dividing Jesus into two distinct persons, the human who was Son of Mary, and the divine who was not. To them, this was unacceptable since by destroying the perfect union of the divine and human natures in Christ, it sabotaged the fullness of the Incarnation and, by extension, the salvation of humanity. The council accepted Cyril's reasoning, affirmed the title "Theotokos" for Mary, and anathematised Nestorius' view as heresy. (See Nestorianism)
In letters to Nestorius which were afterwards included among the council documents, Cyril explained his doctrine. He noted that "the holy fathers... have ventured to call the holy Virgin "Theotokos", not as though the nature of the Word or his divinity received the beginning of their existence from the holy Virgin, but because from her was born his holy body, rationally endowed with a soul, with which [body] the Word was united according to the hypostasis, and is said to have been begotten according to the flesh" (Cyril's second letter to Nestorius).
Explaining his rejection of Nestorius' preferred title for Mary ("Christotokos"), Cyril wrote: 
"Confessing the Word to be united with the flesh according to the hypostasis, we worship one Son and Lord, Jesus Christ. We do not divide him into parts and separate man and God as though they were united with each other [only] through a unity of dignity and authority... nor do we name separately Christ the Word from God, and in similar fashion, separately, another Christ from the woman, but we know only one Christ, the Word from God the Father with his own flesh... But we do not say that the Word from God dwelt as in an ordinary human born of the holy virgin... we understand that, when he became flesh, not in the same way as he is said to dwell among the saints do we distinguish the manner of the indwelling; but he was united by nature and not turned into flesh... There is, then, one Christ and Son and Lord, not with the sort of conjunction that a human being might have with God as in a unity of dignity or authority; for equality of honor does not unite natures. For Peter and John were equal to each other in honor, both of them being apostles and holy disciples, but the two were not one. Nor do we understand the manner of conjunction to be one of juxtaposition, for this is insufficient in regard to natural union... Rather we reject the term 'conjunction' as being inadequate to express the union... [T]he holy virgin gave birth in the flesh to God united with the flesh according to hypostasis, for that reason we call her "Theotokos"... If anyone does not confess that Emmanuel is, in truth, God, and therefore that the holy virgin is "Theotokos" (for she bore in a fleshly manner the Word from God become flesh), let him be anathema." (Cyril's third letter to Nestorius)
Hymns.
"Theotokos" is often used in hymns to Mary in the Eastern Orthodox, Eastern Catholic and Oriental Orthodox churches. The most common is "Axion Estin" ("It is truly meet"), which is used in nearly every service.
Other examples include "Beneath thy compassion" dating from the third century, the "Hail Mary" in its Eastern form, and "All creation rejoices", which replaces "Axion Estin" at the Divine Liturgy on the Sundays of Great Lent.
Solemnity.
In the Roman Catholic Church, the solemnity of Mary as Mother of God (Theotokos) is celebrated on 1 January, on the same day as the Octave of Christmas. Her maternity was celebrated on 11 October in pre-1970 versions of the General Roman Calendar, which some traditional Catholics still observe.
This solemnity comes from around 500 AD and was originally celebrated in the Eastern Churches.
External links.
The rejection of the term Theotokos by Nestorius Constantinople more 
by EIRINI ARTEMI

</doc>
<doc id="36917" url="http://en.wikipedia.org/wiki?curid=36917" title="Alain Prost">
Alain Prost

Alain Marie Pascal Prost, OBE, Chevalier de la Légion d'honneur (born 24 February 1955 in Lorette, Loire) is a French racing driver. A four-time Formula One Drivers' Champion, only Sebastian Vettel (four championships), Juan Manuel Fangio (five championships), and Michael Schumacher (seven championships) have equalled or surpassed his number of titles. From 1987 until 2001 Prost held the record for most Grand Prix victories. Schumacher surpassed Prost's total of 51 victories at the 2001 Belgian Grand Prix. In 1999, Prost received the "World Sports Awards of the Century" in the motor sport category.
Prost discovered karting at the age of 14 during a family holiday. He progressed through motor sport's junior ranks, winning the French and European Formula Three championships, before joining the McLaren Formula One team in 1980 at the age of 24. He finished in the points on his Formula One début in Argentina and took his first race victory at his home Grand Prix in France a year later, driving for the factory Renault team.
During the 1980s and early 1990s, Prost formed a fierce rivalry mainly with Ayrton Senna, but also Nelson Piquet and Nigel Mansell. In 1986, at the last race of the season, he beat Mansell and Piquet of Williams to the title after Mansell retired late on in the race, and Piquet was pulled in for a late precautionary pit stop. Senna joined Prost at McLaren in 1988 and the two had a series of controversial clashes, including a collision at the 1989 Japanese Grand Prix that gave Prost his third Drivers' Championship. A year later at the same venue they collided again, but this time Prost, driving for Ferrari, lost out. Before the end of a winless 1991 season Prost was fired by Ferrari for his public criticism of the team. After a sabbatical in 1992, Prost joined the Williams team, prompting reigning drivers' champion Mansell to leave for CART. With a competitive car, Prost won the 1993 championship and retired from Formula One driving at the end of the year.
In 1997, Prost took over the French Ligier team, running it as Prost Grand Prix until it went bankrupt in 2002. He currently competes in the Andros Trophy, which is an ice racing championship.
Prost employed a smooth, relaxed style behind the wheel, deliberately modeling himself on personal heroes like Jackie Stewart and Jim Clark. He was nicknamed "The Professor" for his intellectual approach to competition, though it was a name he did not particularly care for. Skilled at setting up his car for race conditions, Prost would often conserve his brakes and tyres early on in a race, leaving them fresher for a challenge at the end.
Prost is a two time Absa Cape Epic finisher. He first completed the race in 2012 and then again in 2013, but did not manage to complete the mountain bike marathon stage race in 2014.
Personal and early life.
Alain Prost was born near the town of Saint-Chamond, close to the city of Saint-Etienne in the département of Loire, France, to André Prost and Marie-Rose Karatchian, born in France of Armenian descent. Prost had one younger brother called Daniel, who died of cancer in September 1986. Although short, standing at 1.67 m (5 ft 6 in) Prost was an active, athletic child, who enthusiastically took part in diverse sports, including wrestling, roller skating and football. In doing so he broke his nose several times. He considered careers as a gym instructor or a professional footballer before he discovered kart racing at the age of 14 while on a family holiday. This new sport quickly became his career of choice.
Prost is married to Anne-Marie (born 14 February 1955). They have two sons, Nicolas (born 18 October 1981) and Sacha Prost (born 30 May 1990). Prost also has a daughter, Victoria. s of 2013[ [update]], Nicolas races in the World Endurance Championship for Rebellion. Prost lived in his hometown, Saint-Chamond, until he and his Renault team fell out in the early 1980s. In April 1983 the Prost family moved to Sainte-Croix, Switzerland, and shortly after to Yens, Switzerland. They moved to Switzerland after Renault workers went to Prost's house in France and burned his Mercedes-Benz. They lived there until November 1999, when they moved to Nyon in the same country.
In 1986 or 1987 Prost was awarded the Legion d'Honneur by President François Mitterrand.
Driving career.
Pre-Formula One.
Prost won several karting championships in his teens. In 1974 he left school to become a full-time racer, supporting himself by tuning engines and becoming a kart distributor. His prize for winning the 1975 French senior karting championship was a season in French Formula Renault, a category in which he won the title and all but one race in 1976.
Prost went on to win the 1977 Formula Renault European championship before moving up to Formula Three (F3) in 1978. In 1979 he won both the French and European F3 championships, by which time he was on the shopping lists of several Formula One teams. After carefully considering his options, he chose to sign with McLaren for 1980. He surprised the British team by declining their offer of a race drive in a third car at the final race of the 1979 season at Watkins Glen — reasoning that the token effort would benefit neither him or the team.
Formula One.
1980: McLaren.
Prost began his career with McLaren (being run by Teddy Mayer) in 1980 alongside Ulsterman John Watson. On his debut in Buenos Aires he finished in sixth place earning one point, something achieved by only a handful of drivers. Prost added four more points to his tally during the season, scoring points at Interlagos, Brands Hatch and Zandvoort. Prost finished the year 15th in the drivers' championship, equalling points with former world champion Emerson Fittipaldi. Despite the encouraging debut season, Prost had several accidents, breaking his wrist during practice at Kyalami and suffering a concussion during practice at Watkins Glen. At the end of the season, despite having two years remaining on his contract, he left McLaren and signed with Renault. Prost has said that he left because of the large number of breakages on the car and because he felt the team blamed him for some of the accidents.
1981–1983: Renault.
Prost was partnered with fellow Frenchman René Arnoux for 1981. Motor sports author Nigel Roebuck reports that there were problems between Prost and Arnoux from the start of the season, Prost being immediately quicker than his more experienced teammate. He did not finish the first two Grands Prix, due to collisions with Andrea de Cesaris in Long Beach and Didier Pironi at Jacarepaguá, but scored his first podium finish at Buenos Aires. He also did not finish in the next four races, and then won his first Formula One race at his home Grand Prix in France, finishing two seconds ahead of his old teammate John Watson.
For Prost, his debut victory was memorable mostly for the change it made in his mindset. "Before, you thought you could do it," he said. "Now you know you can." Prost led from the start the next 5 races, and won two more races during the season, took his first pole position in Germany and finished on the podium every time he completed a race distance. He finished fifth in the drivers' championship, seven points behind champion Nelson Piquet.
Prost won the first two Grands Prix of the 1982 season in South Africa, where Prost recovered from losing a wheel, and Brazil, where he finished 3rd but was awarded the win after Piquet (1st) and Keke Rosberg (2nd) were disqualified. He finished in the points on four other occasions, but did not win again. Despite retiring from seven races, Prost improved on his drivers' championship position, finishing in fourth, but with nine fewer points than the previous year. His relationship with Arnoux deteriorated further after the French Grand Prix. Prost believes that Arnoux, who won the race, went back on a pre-race agreement to support Prost during the race. His relationship with the French media was also poor. He has since commented that "When I went to Renault the journalists wrote good things about me, but by 1982 I had become the bad guy. I think, to be honest, I had made the mistake of winning! The French don't really like winners."
In November 1982, three years before it became a round of the F1 World Championship, Prost, along with fellow F1 drivers Jacques Laffite and Nelson Piquet, made the trip to Melbourne, Australia to drive in the non-championship 1982 Australian Grand Prix at the short (1.609 km (1.000 mi)) Calder Park Raceway. Driving a Formula Pacific spec Ralt RT4 powered by a 1.6 litre Ford engine, Prost sat on pole for the race with a time of 39.18. He then led every lap to win what would be the first of 3 Australian Grand Prix wins. He finished 15.32 seconds clear of Laffite, with 1981 AGP winner, young Brazilian driver Roberto Moreno finishing third.
Arnoux left Renault in 1983, and American Eddie Cheever replaced him as Prost's partner. Prost earned a further four victories for Renault during the season and finished second in the drivers' championship, two points behind Nelson Piquet. Piquet and the Brabham team overhauled Prost and Renault in the last few races of the season. Prost, who felt the team had been too conservative in developing the car, found himself increasingly at odds with Renault's management, who made him the scapegoat for failing to win a championship. In addition to that, the French fans recalled the bitter fight that had caused their favourite, Arnoux, to leave the team. Prost said in an interview with ESPN during the final race that his car was "not competitive" and that he "didn't lose by my own fault" Renault fired Prost only two days after the South African race. He re-signed for McLaren for the 1984 season within days and moved his family home to Switzerland after Renault factory workers burned the second of 2 of Prost's cars, one of them being a Mercedes-Benz.
1984–1989: McLaren.
The Frenchman joined double world champion Niki Lauda at McLaren (now being run by Ron Dennis) in 1984, driving the John Barnard designed McLaren MP4/2 which used a 1.5 litre TAG-Porsche V6 engine. He lost the world championship to Lauda in the final race of the season in Portugal by half a point, despite winning seven races to Lauda's five, including winning in Portugal. The half point came from the Monaco Grand Prix, where Prost had been leading, albeit with Ayrton Senna (Toleman) and Stefan Bellof (Tyrrell) closing on him rapidly, when Clerk of the Course Jacky Ickx stopped the race at half distance due to heavy rain, which was controversial as Ickx displayed the red flag without consulting the race officials. Under Formula One regulations, Prost received only half of the nine points normally awarded for a victory.
Prost's seven wins in 1984 equalled the record set by Jim Clark in 1963.
In 1985 Prost became the first French Formula One World Champion. He won five of the sixteen Grands Prix during the season. He had also won the San Marino Grand Prix, but was disqualified after his car was found to be 2 kg underweight in post-race scrutineering. Prost finished 20 points ahead of his closest rival, Michele Alboreto. Prost's performance in 1985 earned him the Légion d'honneur distinction in France.
While proud to be the first French World Champion, Prost, annoyed that French journalists were proclaiming it as a win for France, pointed out in interviews that other than himself, nothing about the car (the MP4/2B) had anything to do with France. The team was British (having been founded by a New Zealander), the tyres were American Goodyears, the TAG-Porsche engine was German, the chassis itself was built by Hercules Aerospace in the USA, and was sponsored by an American tobacco company (Marlboro) and the Saudi Arabian owned company Techniques d'Avant Garde (TAG).
Niki Lauda retired for good at the end of 1985, and was replaced at McLaren by 1982 World Champion Keke Rosberg for 1986. Prost successfully defended his title, despite his car struggling against the Honda-powered Williams cars driven by Nelson Piquet and Nigel Mansell. Until the latter stages of the final race of the 1986 season, the Australian Grand Prix, Prost appeared set to finish second in the Championship, behind Mansell. Prost had the same number of wins as Piquet, but he had four second places to Piquet's three, thus placing him second before the final race. While running third behind Piquet, and directly behind Prost on the road (3rd was all he needed to win the title), Mansell suffered a rear tyre failure at 180 mph and crashed out. The Williams team then pitted Piquet to change tyres as a safety precaution, while Prost had already pitted earlier due to a puncture and did not need to change his tyres again. He then held the lead ahead of a charging Piquet to the chequered flag and the Championship.
Another memorable race that year for Prost was at the San Marino Grand Prix. He was cruising to victory when his car began to run out of fuel three corners from the chequered flag. Frantically weaving the car back and forth to slosh the last drops of fuel into the pickup, he managed to keep it running just long enough to creep over the line and win the race (Prost commented after the race that when his car started running dry he immediately thought to himself "shit, I am going to lose this race again", referring to his 1985 disqualification at Imola). It happened again at the German Grand Prix: while running in fourth position, Prost's car ran out of fuel on the finishing straight of the last lap. Instead of retiring at a time in the season when points were critical, Prost got out of his car and tried to push it to the finish, to great applause from the crowd. The finish line was too far, though, and he never reached it. He was eventually classified sixth in the race, as the seventh-placed car (the Brabham-BMW of Derek Warwick) was a lap behind.
With Rosberg retiring from Formula One at the end of 1986 season, underrated Swede Stefan Johansson filled the McLaren seat alongside Prost for the 1987 season. Even though McLaren had introduced the new Steve Nichols designed MP4/3 after three seasons with the MP4/2 model (Barnard had departed for Ferrari), the TAG engines were not the force they had been previously, lagging behind in power and with unreliability previously unseen. He never gave up though and challenged Piquet and Mansell almost until the end, winning three races and breaking Jackie Stewart's record for race victories by winning for the 28th time at the Portuguese Grand Prix. Prost considers his win in the opening round in Brazil as his best and most rewarding race ever. The Williams-Honda's had been dominant during qualifying, and Prost started fifth on the grid with a time three seconds slower than Mansell's pole time. Knowing he didn't have the qualifying speed, he instead worked on his race set-up, and with everyone else going for a high-downforce set-up, the Frenchman went the other way. The set-up meant less tyre wear, thanks to slower speeds in the corners while going fast down the straights. With his car having less tyre wear than his rivals, Prost was able to get through the 61 laps of the abrasive Jacarepaguá Circuit with only two stops compared to the three or more by his rivals (Piquet pitted for tyres 3 times within the first 40 laps). Prost finished 40 seconds in front of Piquet, with Johansson a further 16 seconds back in third.
Prost finished the 1987 season in fourth place in the championship behind Piquet, Mansell and Lotus driver Ayrton Senna. Prost finished 30 points behind champion Nelson Piquet. Other than his debut season in 1980, and 1991, it was the furthest away he would finish a season from the championship lead.
Despite Nelson Piquet winning the 1987 Drivers' Championship and Williams winning the Constructors' Championship, Honda decided not to supply the team with their engines, partly due to Williams' refusal to dump Nigel Mansell and hire Japanese driver and Honda test driver Satoru Nakajima (who debuted with Lotus in 1987), and instead supplied the McLaren team for 1988. Prost had convinced Ron Dennis to sign Ayrton Senna to a three-year contract, which played a role in luring Honda (Senna's ability had been highly regarded by the Japanese giant when using their engines with Lotus in 1987 and both were keen to continue their association). However, this began the rivalry that pushed two of the sport's greatest drivers to unprecedented heights of success and controversy. McLaren-Honda dominated the season, winning 15 out of 16 races. Prost finished first or second in every race other than his two retirements at Silverstone and Monza. He won seven races and in total outscored his new teammate Ayrton Senna by 11 points, despite Senna winning one more race than Prost. However, only the 11 best results from the season counted toward the championship total, and this gave Senna the title by three points. Prost went on to be a proponent of essentially the 1990s scoring system – all results counting to the final results with the winner scoring 10, not 9, points.
In November of that year, Prost had a meeting with the head of Honda's R&D department and F1 racing program, Nobuhiko Kawamoto in Geneva. He expressed his feelings that Honda was giving Senna preferential treatment, and Kawamoto then confirmed Prost's fears, explaining that the Honda engineers were of a new generation, and that they liked Senna's panache and samurai-like driving. Kawamoto was able to convince Prost that he would work something out on the Honda end of the McLaren-Honda partnership for the 1989 season, but this was not to be.
McLaren's domination continued throughout 1989, and the Prost-Senna struggle for supremacy put them on a collision course. Mutual admiration turned to all-out hatred, with the Frenchman accusing his Brazilian teammate of "dangerous driving" and of receiving more than a fair share of attention from both McLaren and Honda. For his part, Senna accused Prost of being in the pocket of FISA's French president Jean-Marie Balestre. The animosity between the two drivers came to a head at Round 2 in San Marino. The drivers made an agreement between them that whoever won the start would not be challenged by the other going into the first turn (in this case, the Tosa bend on the Imola circuit). Prost kept to the agreement after Senna won the first start. Prost however won the restart (caused by Gerhard Berger's fiery crash in his Ferrari), but was passed by Senna under brakes for Tosa. Prost went to a friend of his, a French journalist, and told him about the broken agreement between him and Senna. Against Prost's wishes, the journalist went public with the story. During testing at Pembrey in Wales, Senna denied in public any such agreement had ever existed between himself and Prost, but the Frenchman's claim was backed up by Marlboro's John Hogan who had been present when the agreement was made.
Their embittered season ended as many pundits had feared. In the Japanese Grand Prix at the end of lap 46, Senna made his move at the Casino Chicane. Prost, turning into the corner, turned into his teammate's path resulting in a collision and the cars sliding interlocked down the escape road. Prost, thinking the World Championship was over, climbed out of his stalled car. To separate the cars, the marshals pushed Senna's McLaren backwards onto the track. This left it in a dangerous position, so they pushed it forwards again. As they did so, Senna bump-started the engine. He drove through the chicane and rejoined. The nose of his car was damaged and he had to pit, but he rejoined only five seconds behind the Benetton of Alessandro Nannini. On lap 50, Ayrton sliced past Nannini at the chicane to take the lead and won the race. But it was Nannini who appeared on the top step of the podium, race officials having excluded Senna for missing the chicane. McLaren appealed the decision, but the FIA Court of Appeal not only upheld the decision but fined Senna US$100,000 and gave him a suspended six-month ban. Thus Prost clinched his third driver's title in controversial circumstances.
However, Prost had the firm belief that Honda and Ron Dennis viewed Senna as the future of the team. Prost recalled that by the Italian Grand Prix he had one car with maybe four or five mechanics, while his teammate had two cars and 20 people around him. Before the race Prost, who had announced in July 1989 that he would depart from McLaren, announced he was joining Ferrari. Although Prost was forced to make a public apology to both McLaren and Honda over his Monza comments, he received support from Nigel Mansell (who would be his 1990 team mate at Ferrari), and former team mate Rosberg who claimed that once it became known they would not be using the Japanese engines the next season, their Honda engines did not seem to work as well as was once normal. Prost actually won the Italian Grand Prix, after Senna's engine blew with only 9 laps remaining. Until that point Prost's MP4/5 had not been a match for Senna's on Monza's long straights, which had many, especially those in the press, wondering if there was actually truth to Prost's claim that his Honda engines were not as good as the ones Senna was able to use.
As 1989 wore on, Prost continually claimed his Honda V10s were not producing the same amount of power as those in Senna's car. It actually got to the point where Honda F1 boss Osamu Goto felt compelled to speak to the specialist British media on the matter. He claimed that Senna's foot-tapping style with the accelerator helped keep the RA109-E's revs up in the engine's mid-range where most of the power was, while Prost's smoother style dropped the engines into low revs where they had a pick-up problem. Apparently the talk was convincing until most of those present noticed Goto continually called them Ayrton and Prost respectively. An example of Prost's claims came during the Mexican Grand Prix. Despite his car running less wing than Senna's which theoretically would give him greater top speed, Prost's McLaren was not able to pass Senna's on the long front straight even though he came of the final Peraltada Curve clearly faster than the Brazilian and also had the benefit of a tow. In stark contrast, late in the race when Senna was lapping Prost (who was on fresh tyres), Senna was easily able to power past Prost on the straight.
1990–1991: Ferrari.
The Frenchman replaced Gerhard Berger at Ferrari and was partnered with Britain's Nigel Mansell for 1990 (Berger took Prost's seat at McLaren). As reigning world champion, Prost took over as the team's lead driver and was said to have played on Mansell's inferiority complex. Mansell recalls one incident where at the 1990 British Grand Prix, the car he drove didn't handle the same as in the previous race where he had taken pole position, and later found out from team mechanics that Prost saw Mansell as having a superior car and had them swapped without Mansell knowing. Prost won five races for Ferrari that year, in Brazil, Mexico, France, Britain and Spain. Notable among these was the Mexican Grand Prix, where he won after starting in 13th position. In both the Mexican and Spanish races, he led Mansell to Ferrari 1–2 finishes. The championship once again came to the penultimate round of the season in Japan with Prost trailing his McLaren adversary, Ayrton Senna, by nine points. As in 1989, a controversial collision between the two settled the race. At the first corner Senna, as admitted a year later, intentionally drove his race car into Prost's, taking them both out of the race and sealing the title in his favour. "What he did was disgusting," Prost said. "He is a man without value." Prost finished the season seven points behind Senna, and his Ferrari team were runners-up to McLaren.
Mansell left the Scuderia due to his unstable relationship with Prost, to rejoin Williams for the 1991 Formula One season. Mansell's replacement was Frenchman Jean Alesi, who had been impressive during the previous two years at Tyrrell. Ferrari had entered a downturn, partially as their famous V12 engine was no longer competitive against the smaller, lighter and more fuel efficient V10s of their competitors. The Ferrari chassis, despite a major revision by the French Grand Prix (F-643) was also not up to the level of the McLaren and the Williams models. Prost won no races, only getting onto the podium five times. He took this out on the team, publicly criticising the team and the Ferrari 643, and subsequently had his contract terminated before the end of the season, immediately prior to the Australian Grand Prix. He was replaced by Italian driver Gianni Morbidelli for the final race of the 1991 season and by another Italian, Ivan Capelli, for the following season. Despite being sacked, Prost received a significant payment from Ferrari to not drive for any other team.
It was the second time in his career that Alain Prost had been fired by a factory backed team for his public criticism of the team and car, having been fired under similar circumstances by Renault at the end of the 1983 season.
1991 was the first time since his debut year in 1980 in which Alain Prost did not win a Formula One Grands Prix.
1993: Williams.
Prost went onto a sabbatical year in 1992, which was dominated by Nigel Mansell in a Williams-Renault. Prost performed pre-season testing for Ligier early in 1992 and later turned down an offer to drive for the team. After hearing that Prost would be his teammate again in 1993, Mansell left Williams to race in the CART series. The Frenchman had a clause in his contract which prevented rival Ayrton Senna from joining the team that year. Prost was part of a new-look driver line-up at Williams, with test driver Damon Hill coming in to replace Riccardo Patrese, who had left to join Benetton.
Prost won his fourth, and final, title, but in a year where he was regularly challenged by teammate Hill, and Ayrton Senna. Shortly before the Portuguese Grand Prix in October 1993, Prost announced he would not defend his world title, as the clause in the Frenchman's contract did not extend to 1994 and Senna would be able to join Williams for the upcoming season, and instead opted to retire as the driver with the record for most grand prix victories — a record which stood for almost a decade. On the podium in Adelaide in 1993, Prost's last race, he and Senna embraced, and it was as if — now that Prost was no longer a rival — Senna saw no reason for any more hostility. Prost was surprised by the gesture. Prost's performances earned him an OBE.
German Michael Schumacher broke Prost's record of 51 Grand Prix wins during the 2001 season. However, the Frenchman still holds the records for the most Grand Prix starts in turbo powered cars (126), most wins at home Grand Prix (six at the French Grand Prix) and wins with most different teams (4: Renault, McLaren, Ferrari, and Williams). He also shares the record for starting every race of the season from the front row (16 in 1993), with Ayrton Senna in 1989, and Damon Hill in 1996.
He is also thus far the most recent Frenchman to win his home Grand Prix.
Rivalry with Ayrton Senna.
Prost's battles with Ayrton Senna were particularly notable. The rivalry originated in 1988, when Senna joined Prost at the McLaren team. The most notable event during the season between the two occurred during the Portuguese Grand Prix, where Senna tried to block Prost from taking the lead by forcing the Frenchman to run close to the pitwall; Prost managed to edge Senna outwards, taking the lead as they went into the first corner but he remained angered by the Brazilian's manoeuvre.
The rivalry intensified after the 1989 San Marino Grand Prix, where the two drivers had an agreement that neither would get in each other's way to the first corner ("cf." 1982 San Marino Grand Prix). At the start, Senna got away in the lead and Prost followed him through the first corner without getting in Senna's way. Gerhard Berger's crash on lap four stopped the race. At the restart, it was Prost this time that got away the better of the two; but Senna forced his way past Prost in the first corner, breaking the pair's agreement at the start of the race, leaving the Frenchman furious with Senna. Senna argued it was the restart. Prost himself was angered by McLaren apparently favouring Senna because of Senna's better relationship with engine supplier Honda, so he announced mid-season that he had signed to race for Ferrari the following season.
The rivalry reached its peak at the end of 1989, when the title was to be decided between Senna and Prost at Suzuka. The two McLarens collided at the Casio Triangle chicane when Prost blocked an attempted pass by Senna. Prost walked away while Senna returned to the track. Senna went on to win the race, but was later disqualified in a highly controversial ruling over his path back to the track. After an unsuccessful appeal by McLaren, the Brazilian received a further US$100,000 fine and a six-month suspension, leading Senna to accuse FIA president Jean-Marie Balestre of favoring his compatriot Prost. Senna's disqualification meant that it was mathematically impossible for him to overhaul Prost's points total, and so the 1989 Championship went to the Frenchman. There has been much debate as to whether Senna was overambitious in his overtaking manoeuver, whether Prost intentionally ran into Senna, or whether the collision was simply a racing incident between two team-mates who were embittered with each other.
The following season saw the two drivers collide again. With Senna leading Prost, now in a Ferrari, in the world drivers' championship, Prost qualified second for the penultimate race of the season in Suzuka with Senna on pole. Between the end of qualifying and race day, pole position was switched to the other side of the track without explanation. Senna complained that no longer being on the racing line, his side of the grid was dirty, meaning he would get less grip and therefore a slower start compared to Prost who had been moved to the clean side of the grid. The Brazilian's appeal was rejected. At the start of the race, Prost got the better start of the two; but whilst braking for the first corner, Senna refused to back off and collided with Prost at 160 mi/h, clinching the title for the Brazilian. Prost almost retired from the sport, saying "What he did was disgusting. He is a man without value." A year later, Senna admitted that the move was premeditated, in retaliation for the collision at the chicane on the same course the previous year.
There was another controversial incident in 1991. Prost's inferior Ferrari was unable to put up a challenge regularly to Senna's frontrunning McLaren. At the German Grand Prix at Hockenheim, Prost battled Senna for 4th place, however he felt Senna defended too aggressively and at the first chicane forced Prost to take avoiding action by using the escape road. Prost stalled his car rejoining the race. Coincidentally, Senna ran out of fuel on the last lap at the very same point.
The Frenchman took a sabbatical in 1992 after being fired from Ferrari for publicly criticizing the car and the team, while the Brazilian struggled as McLaren was no longer competitive with Williams. Prost announced his signing with Williams for the upcoming 1993 season. Senna had wanted to join Williams too, as they were the most competitive, but Prost had a clause in his contract forbidding the Brazilian as a teammate. An infuriated Senna called the Frenchman a "coward" during a press conference at Estoril, and decried his unwillingness to compete for the drivers' championship on equal sporting terms: I think if Prost wants to be called the sole champion, three-times world champion, come back in a sportive way, maybe win another championship, he should be sportive. The way he's doing, he's behaving like a coward. And if he wants to be sportive, he must be prepared to race anybody, at any condition, at equal terms.
During the 1993 season, Prost and Senna continued their on-track rivalry. Prost was escorted by police to the Interlagos circuit for the 1993 Brazilian Grand Prix due to the hostility of Brazilians towards him. The two continued their on-track battles at Silverstone where Senna aggressively defended his position against Prost. At Prost's last Grand Prix, the 1993 Australian Grand Prix, he was pulled up by Senna onto the top step of the podium for an embrace.
On 1 May 1994, Ayrton Senna was killed during the San Marino Grand Prix. Prost was a pallbearer at the Brazilian's funeral. Speaking four years after the Brazilian's death, Prost told Nigel Roebuck that he had "always refused to speak about him." When Senna died, Prost stated that "a part of himself had died also", because their careers had been so bound together. Senna had also felt the same when Prost had retired at the end of 1993, when he admitted to a close friend that he had realised how much of his motivation had come from fighting with Prost. Only a couple of days before his death, when filming an in-car lap of Imola for French television channel TF1, he greeted Prost, by then a pundit on the channel: "A special hello to my... to our dear friend Alain. We all miss you Alain." Prost said that he was amazed and very touched by the comment.
Comparison with team-mates.
During the course of his career, season-by-season Prost beat nearly all his team-mates on total points, including five World Champions. The only exceptions were in 1984 when Niki Lauda won by half a point, and in Prost's first F1 season, when he was beaten by John Watson. In 1988, although Prost scored more points in total than his team-mate Ayrton Senna, only the best eleven of sixteen results counted towards the championship, which Senna won.
Helmet.
Prost uses a helmet design based on the three colours of the French flag, those being blue, white and red, along with his name along the side. During his early career however, Prost used a basic design of white all over with some blue detail around the visor (blue helmet with a white 180° flipped Y and red lines in the lower branch of the flipped Y and in the upper branch, surrounding the top). During Prost's time at Renault, he used more blue details, most notably around the rear of his helmet. Prost's helmet changed in 1985, as his helmet now had the blue detail around the front, surrounding the visor (with also a blue stripe on the side region, making the white area become a P) and a white ring with red lines surrounding the top (forming a white circle with a blue half in the rear of the top). . Prost kept a similar design for his entry at Ferrari and Williams.
Sometimes, Prost used variants of his helmet design, in 2007 he used his original design, but with the circle top all red and a red line in the lower chin area. In 2010, he used a pearl white helmet with silver flames and a blue-white-red-white-blue stripe trepassing the visor, designed by kaos design.
Later life.
During 1994 and 1995, Prost worked as TV pundit for the French TV channel TF1. He also worked for Renault as a PR man. Prost went back to his old team McLaren, working as a technical advisor; he also completed L'Etape du Tour, an annual mass-participation bike ride that takes place on a stage of the Tour de France. Although not an official race, riders fight hard for places; Prost finished 12th in his category, 42nd overall out of over 5000 riders.
Prost Grand Prix.
During 1989 Prost began to contemplate starting his own team, as his relationship with his McLaren teammate, Ayrton Senna, had turned sour. Prost and John Barnard, formerly chief designer at McLaren, came close to founding a team in 1990; but a lack of sponsorship meant that this was not possible, so Prost moved to Ferrari and Barnard left Ferrari to join Benetton. After falling out with the Italian team at the end of 1991, Prost found himself without a drive for 1992; after the failure of extensive negotiations with Guy Ligier about buying his Ligier team, Prost decided to join Williams for 1993. In 1995, when Prost was working for Renault, people began to assume that a Prost-Renault team would be formed in the near future. Renault refused Prost's request to supply engines for his team, ending the speculation.
On 13 February 1997, Prost bought the Ligier team from Flavio Briatore and renamed it "Prost Grand Prix". The day after he bought the team, Prost signed a three-year deal with French car manufacturer Peugeot, who would supply the team with engines from 1998 until 2000. For the team's first season, Prost kept one of Ligier's 1996 drivers, Olivier Panis, who had won the Monaco Grand Prix the previous year; Japanese driver Shinji Nakano was signed to partner Panis. The team raced with the Mugen-Honda engines used by Ligier the previous season, while the car was actually the originally intended Ligier JS45, but was renamed the Prost JS45. Things looked promising at the start of the season, as the team picked up two points on its Grand Prix debut in Australia when Olivier Panis finished fifth. The team scored a further 13 points before Panis broke his leg in an accident during the Canadian Grand Prix. He was replaced by Minardi's Jarno Trulli. From there, things started to go downhill slightly, the team scored only five points during Panis' recovery. The Frenchman came back at the end of the season to race the final three Grand Prix. Prost GP finished sixth in the constructors' championship in its first season, with 21 points.
Prost became the president of Prost Grand Prix at the start of 1998. With Peugeot supplying the engines for Prost GP, Mugen-Honda decided to supply the Jordan team. Prost GP scored a single point during the season, Jarno Trulli finishing sixth in Belgium.
1999 was a crucial year for Prost GP. Prost hired John Barnard as a technical consultant, Barnard's B3 Technologies company helping Loic Bigois and the design of the Prost AP02. Panis and Trulli agreed to stay on with the team for the season. While the car did not prove to be a major concern, the Peugeot V10 engine proved to be heavy and unreliable.
Peugeot's final year as Prost's engine supplier in 2000 saw some optimism, Prost hiring his 1991 Ferrari team mate Jean Alesi to drive the lead car and German Nick Heidfeld, who had won the 1999 Formula 3000 championship, to partner him. The season proved to be yet another disastrous one, with the AP03 proving to be unreliable and ill handling. Things weren't helped when both drivers collided with each other in the Austrian Grand Prix. Newly hired technical director Alan Jenkins was fired midway through the year. Prost restructured the team, hiring Joan Villadelprat as the managing director and replacing Jenkins with Henri Durand as the team's new technical director.
2001 saw some much needed optimism for the team as Ferrari agreed to be the team's engine supplier for the season, the team now moving in the right direction. But the money ran out at the start of the 2002 season and Prost was out of business, leaving debts of around $30 million.
After Prost Grand Prix.
During 2002, Prost spent time with his family and competed in eight bicycle races, finishing third in the "Granite – Mont Lozère". The Frenchman raced in the Andros ice race series in 2003, finishing second in the championship behind Yvan Muller; he also became an Ambassador for Uniroyal, a position he would keep until May 2006.
Prost continued to compete in the Andros Trophy, winning the title with Toyota in 2006/07, 2007/08 and with Dacia in 2011/2012.
For the 2010 Formula One season, the Sporting Regulations were changed so that a former driver sits on the stewards' panel. Prost was the first such driver to take on this role, at the 2010 Bahrain Grand Prix. Prost also took part in the Race of Champions in 2010, a race organised for legends of motor sport to compete in equal machinery.
In February 2012, Prost was named as Renault's new international ambassador, representing the company in sports demonstrations and at events organized or attended by Renault.
In March 2012, Prost travelled to South Africa and successfully completed the Absa Cape Epic 8-day stage mountain bike race, with partner Sebastien di Pasqua. He intends to ride for a second time during the 2013 event.
External links.
All Formula One race and championship results are taken from:
class="wikitable succession-box" style="margin:0.5em auto; font-size:95%;clear:both;"

</doc>
