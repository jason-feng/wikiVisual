<doc id="26833" url="http://en.wikipedia.org/wiki?curid=26833" title="Scientific method">
Scientific method

The scientific method is a body of techniques for investigating phenomena, acquiring new knowledge, or correcting and integrating previous knowledge. To be termed scientific, a method of inquiry is commonly based on empirical or measurable evidence subject to specific principles of reasoning. The "Oxford English Dictionary" defines the scientific method as "a method or procedure that has characterized natural science since the 17th century, consisting in systematic observation, measurement, and experiment, and the formulation, testing, and modification of hypotheses."
The scientific method is an ongoing process, which usually begins with observations about the natural world. Human beings are naturally inquisitive, so they often come up with questions about things they see or hear and often develop ideas (hypotheses) about why things are the way they are. The best hypotheses lead to predictions that can be tested in various ways, including making further observations about nature. In general, the strongest tests of hypotheses come from carefully controlled and replicated experiments that gather empirical data. Depending on how well the tests match the predictions, the original hypothesis may require refinement, alteration, expansion or even rejection. If a particular hypothesis becomes very well supported a general theory may be developed. 
Although procedures vary from one field of inquiry to another, identifiable features are frequently shared in common between them. The overall process of the scientific method involves making conjectures (hypotheses), deriving predictions from them as logical consequences, and then carrying out experiments based on those predictions. An hypothesis is a conjecture, based on knowledge obtained while formulating the question. The hypothesis might be very specific or it might be broad. Scientists then test hypotheses by conducting experiments. Under modern interpretations, a scientific hypothesis must be falsifiable, implying that it is possible to identify a possible outcome of an experiment that conflicts with predictions deduced from the hypothesis; otherwise, the hypothesis cannot be meaningfully tested.
The purpose of an experiment is to determine whether observations agree with or conflict with the predictions derived from a hypothesis. Experiments can take place in a college lab, on a kitchen table, at CERN's Large Hadron Collider, at the bottom of an ocean, on Mars, and so on. There are difficulties in a formulaic statement of method, however. Though the scientific method is often presented as a fixed sequence of steps, it represents rather a set of general principles.
Not all steps take place in every scientific inquiry (or to the same degree), and are not always in the same order.
Overview.
The scientific method is the process by which science is carried out. As in other areas of inquiry, science (through the scientific method) can build on previous knowledge and develop a more sophisticated understanding of its topics of study over time. This model can be seen to underlay the scientific revolution. One thousand years ago, Alhazen argued the importance of forming questions and subsequently testing them, an approach which was advocated by Galileo in 1638 with the publication of "Two New Sciences". The current method is based on a hypothetico-deductive model formulated in the 20th century, although it has undergone significant revision since first proposed (for a more formal discussion, see below).
Process.
The overall process involves making conjectures (hypotheses), deriving predictions from them as logical consequences, and then carrying out experiments based on those predictions to determine whether the original conjecture was correct. There are difficulties in a formulaic statement of method, however. Though the scientific method is often presented as a fixed sequence of steps, they are better considered as general principles. Not all steps take place in every scientific inquiry (or to the same degree), and are not always in the same order. As noted by William Whewell (1794–1866), "invention, sagacity, [and] genius" are required at every step.
Formulation of a question.
The question can refer to the explanation of a specific "observation", as in "Why is the sky blue?", but can also be open-ended, as in "How can I design a drug to cure this particular disease?" This stage frequently involves looking up and evaluating evidence from previous experiments, personal scientific observations or assertions, and/or the work of other scientists. If the answer is already known, a different question that builds on the previous evidence can be posed. When applying the scientific method to scientific research, determining a good question can be very difficult and affects the final outcome of the investigation.
Hypothesis.
An hypothesis is a conjecture, based on knowledge obtained while formulating the question, that may explain the observed behavior of a part of our universe. The hypothesis might be very specific, e.g., Einstein's equivalence principle or Francis Crick's "DNA makes RNA makes protein", or it might be broad, e.g., unknown species of life dwell in the unexplored depths of the oceans. A statistical hypothesis is a conjecture about some population. For example, the population might be people with a particular disease. The conjecture might be that a new drug will cure the disease in some of those people. Terms commonly associated with statistical hypotheses are null hypothesis and alternative hypothesis. A null hypothesis is the conjecture that the statistical hypothesis is false, e.g., that the new drug does nothing and that any cures are due to chance effects. Researchers normally want to show that the null hypothesis is false. The alternative hypothesis is the desired outcome, e.g., that the drug does better than chance. A final point: a scientific hypothesis must be falsifiable, meaning that one can identify a possible outcome of an experiment that conflicts with predictions deduced from the hypothesis; otherwise, it cannot be meaningfully tested.
Prediction.
This step involves determining the logical consequences of the hypothesis. One or more predictions are then selected for further testing. The more unlikely that a prediction would be correct simply by coincidence, then the more convincing it would be if the prediction were fulfilled; evidence is also stronger if the answer to the prediction is not already known, due to the effects of hindsight bias (see also postdiction). Ideally, the prediction must also distinguish the hypothesis from likely alternatives; if two hypotheses make the same prediction, observing the prediction to be correct is not evidence for either one over the other. (These statements about the relative strength of evidence can be mathematically derived using Bayes' Theorem).
Testing.
This is an investigation of whether the real world behaves as predicted by the hypothesis. Scientists (and other people) test hypotheses by conducting experiments. The purpose of an experiment is to determine whether observations of the real world agree with or conflict with the predictions derived from an hypothesis. If they agree, confidence in the hypothesis increases; otherwise, it decreases. Agreement does not assure that the hypothesis is true; future experiments may reveal problems. Karl Popper advised scientists to try to falsify hypotheses, i.e., to search for and test those experiments that seem most doubtful. Large numbers of successful confirmations are not convincing if they arise from experiments that avoid risk. Experiments should be designed to minimize possible errors, especially through the use of appropriate scientific controls. For example, tests of medical treatments are commonly run as double-blind tests. Test personnel, who might unwittingly reveal to test subjects which samples are the desired test drugs and which are placebos, are kept ignorant of which are which. Such hints can bias the responses of the test subjects. Furthermore, failure of an experiment does not necessarily mean the hypothesis is false. Experiments always depend on several hypotheses, e.g., that the test equipment is working properly, and a failure may be a failure of one of the auxiliary hypotheses. (See the Duhem-Quine thesis.) Experiments can be conducted in a college lab, on a kitchen table, at CERN's Large Hadron Collider, at the bottom of an ocean, on Mars (using one of the working rovers), and so on. Astronomers do experiments, searching for planets around distant stars. Finally, most individual experiments address highly specific topics for reasons of practicality. As a result, evidence about broader topics is usually accumulated gradually.
Analysis.
This involves determining what the results of the experiment show and deciding on the next actions to take. The predictions of the hypothesis are compared to those of the null hypothesis, to determine which is better able to explain the data. In cases where an experiment is repeated many times, a statistical analysis such as a chi-squared test may be required. If the evidence has falsified the hypothesis, a new hypothesis is required; if the experiment supports the hypothesis but the evidence is not strong enough for high confidence, other predictions from the hypothesis must be tested. Once a hypothesis is strongly supported by evidence, a new question can be asked to provide further insight on the same topic. Evidence from other scientists and experience are frequently incorporated at any stage in the process. Depending on the complexity of the experiment, many iterations may be required to gather sufficient evidence to answer a question with confidence, or to build up many answers to highly specific questions in order to answer a single broader question.
DNA example.
The discovery became the starting point for many further studies involving the genetic material, such as the field of molecular genetics, and it was awarded the Nobel Prize in 1962. Each step of the example is examined in more detail later in the article.
Other components.
The scientific method also includes other components required even when all the iterations of the steps above have been completed:
Replication.
If an experiment cannot be repeated to produce the same results, this implies that the original results might have been in error. As a result, it is common for a single experiment to be performed multiple times, especially when there are uncontrolled variables or other indications of experimental error. For significant or surprising results, other scientists may also attempt to replicate the results for themselves, especially if those results would be important to their own work.
External review.
The process of peer review involves evaluation of the experiment by experts, who typically give their opinions anonymously. Some journals request that the experimenter provide lists of possible peer reviewers, especially if the field is highly specialized. Peer review does not certify correctness of the results, only that, in the opinion of the reviewer, the experiments themselves were sound (based on the description supplied by the experimenter). If the work passes peer review, which occasionally may require new experiments requested by the reviewers, it will be published in a peer-reviewed scientific journal. The specific journal that publishes the results indicates the perceived quality of the work.
Data recording and sharing.
Scientists typically are careful in recording their data, a requirement promoted by Ludwik Fleck (1896–1961) and others. Though not typically required, they might be requested to supply this data to other scientists who wish to replicate their original results (or parts of their original results), extending to the sharing of any experimental samples that may be difficult to obtain.
Scientific inquiry.
Scientific inquiry generally aims to obtain knowledge in the form of testable explanations that can be used to
predict the results of future experiments. This allows scientists to gain a better understanding of the topic being studied, and later be able to use that understanding to intervene in its causal mechanisms (such as to cure disease). The better an explanation is at making predictions, the more useful it frequently can be, and the more likely it is to continue explaining a body of evidence better than its alternatives. The most successful explanations, which explain and make accurate predictions in a wide range of circumstances, are often called scientific theories.
Most experimental results do not produce large changes in human understanding; improvements in theoretical scientific understanding is typically the result of a gradual process of development over time, sometimes across different domains of science. Scientific models vary in the extent to which they have been experimentally tested and for how long, and in their acceptance in the scientific community. In general, explanations become accepted over time as evidence accumulates on a given topic, and the explanation in question is more powerful than its alternatives at explaining the evidence. Often the explanations are altered over time, or explanations are combined to produce new explanations.
Properties of scientific inquiry.
Scientific knowledge is closely tied to empirical findings, and can remain subject to falsification if new experimental observation incompatible with it is found. That is, no theory can ever be considered final, since new problematic evidence might be discovered. If such evidence is found, a new theory may be proposed, or (more commonly) it is found that modifications to the previous theory are sufficient to explain the new evidence. The strength of a theory can be argued to be related to how long it has persisted without major alteration to its core principles.
Theories can also subject to subsumption by other theories. For example, thousands of years of scientific observations of the planets were explained by Newton's laws. However, these laws were then determined to be special cases of a more general theory (relativity), which explained both the (previously unexplained) exceptions to Newton's laws and predicting and explaining other observations such as the deflection of light by gravity. Thus, in certain cases independent, unconnected, scientific observations can be connected to each other, unified by principles of increasing explanatory power.
Since new theories might be more comprehensive than what preceded them, and thus be able to explain more than previous ones, successor theories might be able to meet a higher standard by explaining a larger body of observations than their predecessors. For example, the theory of evolution explains the diversity of life on Earth, how species adapt to their environments, and many other patterns observed in the natural world; its most recent major modification was unification with genetics to form the modern evolutionary synthesis. In subsequent modifications, it has also subsumed aspects of many other fields such as biochemistry and molecular biology.
Beliefs and biases.
Scientific methodology often directs that hypotheses be tested in controlled conditions wherever possible. This is frequently possible in certain areas, such as in the biological sciences, and more difficult in other areas, such as in astronomy. The practice of experimental control and reproducibility can have the effect of diminishing the potentially harmful effects of circumstance, and to a degree, personal bias. For example, pre-existing beliefs can alter the interpretation of results, as in confirmation bias; this is a heuristic that leads a person with a particular belief to see things as reinforcing their belief, even if another observer might disagree (in other words, people tend to observe what they expect to observe).
A historical example is the belief that the legs of a galloping horse are splayed at the point when none of the horse's legs touches the ground, to the point of this image being included in paintings by its supporters. However, the first stop-action pictures of a horse's gallop by Eadweard Muybridge showed this to be false, and that the legs are instead gathered together. Another important human bias that plays a role is a preference for new, surprising statements (see appeal to novelty), which can result in a search for evidence that the new is true. In contrast to this standard in the scientific method, poorly attested beliefs can be believed and acted upon via a less rigorous heuristic, sometimes taking advantage of the narrative fallacy that when narrative is constructed its elements become easier to believe. Sometimes, these have their elements assumed "a priori", or contain some other logical or methodological flaw in the process that ultimately produced them.
Elements of the scientific method.
There are different ways of outlining the basic method used for scientific inquiry. The scientific community and philosophers of science generally agree on the following classification of method components. These methodological elements and organization of procedures tend to be more characteristic of natural sciences than social sciences. Nonetheless, the cycle of formulating hypotheses, testing and analyzing the results, and formulating new hypotheses, will resemble the cycle described below.
Each element of the scientific method is subject to peer review for possible mistakes. These activities do not describe all that scientists do (see below) but apply mostly to experimental sciences (e.g., physics, chemistry, and biology). The elements above are often taught in the educational system as "the scientific method".
The scientific method is not a single recipe: it requires intelligence, imagination, and creativity. In this sense, it is not a mindless set of standards and procedures to follow,
but is rather an ongoing cycle, constantly developing more useful, accurate and comprehensive models and methods. For example, when Einstein developed the Special and General Theories of Relativity, he did not in any way refute or discount Newton's "Principia". On the contrary, if the astronomically large, the vanishingly small, and the extremely fast are removed from Einstein's theories – all phenomena Newton could not have observed – Newton's equations are what remain. Einstein's theories are expansions and refinements of Newton's theories and, thus, increase our confidence in Newton's work.
A linearized, pragmatic scheme of the four points above is sometimes offered as a guideline for proceeding:
The iterative cycle inherent in this step-by-step method goes from point 3 to 6 back to 3 again.
While this schema outlines a typical hypothesis/testing method, it should also be noted that a number of philosophers, historians and sociologists of science (perhaps most notably Paul Feyerabend) claim that such descriptions of scientific method have little relation to the ways that science is actually practiced.
The "operational" paradigm combines the concepts of operational definition, instrumentalism, and utility:
The essential elements of scientific method are operations, observations, models, and a utility function for evaluating models.
Characterizations.
The scientific method depends upon increasingly sophisticated characterizations of the subjects of investigation. (The "subjects" can also be called or the "unknowns".) For example, Benjamin Franklin conjectured, correctly, that St. Elmo's fire was electrical in nature, but it has taken a long series of experiments and theoretical changes to establish this. While seeking the pertinent properties of the subjects, careful thought may also entail some definitions and observations; the observations often demand careful measurements and/or counting.
The systematic, careful collection of measurements or counts of relevant quantities is often the critical difference between pseudo-sciences, such as alchemy, and science, such as chemistry or biology. Scientific measurements are usually tabulated, graphed, or mapped, and statistical manipulations, such as correlation and regression, performed on them. The measurements might be made in a controlled setting, such as a laboratory, or made on more or less inaccessible or unmanipulatable objects such as stars or human populations. The measurements often require specialized scientific instruments such as thermometers, spectroscopes, particle accelerators, or voltmeters, and the progress of a scientific field is usually intimately tied to their invention and improvement.
 I am not accustomed to saying anything with certainty after only one or two observations.
 — Andreas Vesalius, (1546)
Uncertainty.
Measurements in scientific work are also usually accompanied by estimates of their uncertainty. The uncertainty is often estimated by making repeated measurements of the desired quantity. Uncertainties may also be calculated by consideration of the uncertainties of the individual underlying quantities used. Counts of things, such as the number of people in a nation at a particular time, may also have an uncertainty due to data collection limitations. Or counts may represent a sample of desired quantities, with an uncertainty that depends upon the sampling method used and the number of samples taken.
Definition.
Measurements demand the use of "operational definitions" of relevant quantities. That is, a scientific quantity is described or defined by how it is measured, as opposed to some more vague, inexact or "idealized" definition. For example, electrical current, measured in amperes, may be operationally defined in terms of the mass of silver deposited in a certain time on an electrode in an electrochemical device that is described in some detail. The operational definition of a thing often relies on comparisons with standards: the operational definition of "mass" ultimately relies on the use of an artifact, such as a particular kilogram of platinum-iridium kept in a laboratory in France.
The scientific definition of a term sometimes differs substantially from its natural language usage. For example, mass and weight overlap in meaning in common discourse, but have distinct meanings in mechanics. Scientific quantities are often characterized by their units of measure which can later be described in terms of conventional physical units when communicating the work.
New theories are sometimes developed after realizing certain terms have not previously been sufficiently clearly defined. For example, Albert Einstein's first paper on relativity begins by defining simultaneity and the means for determining length. These ideas were skipped over by Isaac Newton with, "I do not define , space, place and motion, as being well known to all." Einstein's paper then demonstrates that they (viz., absolute time and length independent of motion) were approximations. Francis Crick cautions us that when characterizing a subject, however, it can be premature to define something when it remains ill-understood. In Crick's study of consciousness, he actually found it easier to study awareness in the visual system, rather than to study free will, for example. His cautionary example was the gene; the gene was much more poorly understood before Watson and Crick's pioneering discovery of the structure of DNA; it would have been counterproductive to spend much time on the definition of the gene, before them.
DNA-characterizations.
 The history of the discovery of the structure of DNA is a classic example of the elements of the scientific method: in 1950 it was known that genetic inheritance had a mathematical description, starting with the studies of Gregor Mendel, and that DNA contained genetic information (Oswald Avery's "transforming principle"). But the mechanism of storing genetic information (i.e., genes) in DNA was unclear. Researchers in Bragg's laboratory at Cambridge University made X-ray diffraction pictures of various molecules, starting with crystals of salt, and proceeding to more complicated substances. Using clues painstakingly assembled over decades, beginning with its chemical composition, it was determined that it should be possible to characterize the physical structure of DNA, and the X-ray images would be the vehicle. .."2. DNA-hypotheses"
Another example: precession of Mercury.
The characterization element can require extended and extensive study, even centuries. It took thousands of years of measurements, from the Chaldean, Indian, Persian, Greek, Arabic and European astronomers, to fully record the motion of planet Earth. Newton was able to include those measurements into consequences of his laws of motion. But the perihelion of the planet Mercury's orbit exhibits a precession that cannot be fully explained by Newton's laws of motion (see diagram to the right), as Leverrier pointed out in 1859. The observed difference for Mercury's precession between Newtonian theory and observation was one of the things that occurred to Einstein as a possible early test of his theory of General Relativity. His relativistic calculations matched observation much more closely than did Newtonian theory. The difference is approximately 43 arc-seconds per century.
Hypothesis development.
An hypothesis is a suggested explanation of a phenomenon, or alternately a reasoned proposal suggesting a possible correlation between or among a set of phenomena.
Normally hypotheses have the form of a mathematical model. Sometimes, but not always, they can also be formulated as existential statements, stating that some particular instance of the phenomenon being studied has some characteristic and causal explanations, which have the general form of universal statements, stating that every instance of the phenomenon has a particular characteristic.
Scientists are free to use whatever resources they have – their own creativity, ideas from other fields, induction, Bayesian inference, and so on – to imagine possible explanations for a phenomenon under study. Charles Sanders Peirce, borrowing a page from Aristotle ("Prior Analytics", 2.25) described the incipient stages of inquiry, instigated by the "irritation of doubt" to venture a plausible guess, as "abductive reasoning". The history of science is filled with stories of scientists claiming a "flash of inspiration", or a hunch, which then motivated them to look for evidence to support or refute their idea. Michael Polanyi made such creativity the centerpiece of his discussion of methodology.
William Glen observes that
In general scientists tend to look for theories that are "elegant" or "beautiful". In contrast to the usual English use of these terms, they here refer to a theory in accordance with the known facts, which is nevertheless relatively simple and easy to handle. Occam's Razor serves as a rule of thumb for choosing the most desirable amongst a group of equally explanatory hypotheses.
DNA-hypotheses.
 Linus Pauling proposed that DNA might be a triple helix. This hypothesis was also considered by Francis Crick and James D. Watson but discarded. When Watson and Crick learned of Pauling's hypothesis, they understood from existing data that Pauling was wrong and that Pauling would soon admit his difficulties with that structure. So, the race was on to figure out the correct structure (except that Pauling did not realize at the time that he was in a race) "..3. DNA-predictions"
Predictions from the hypothesis.
Any useful hypothesis will enable predictions, by reasoning including deductive reasoning. It might predict the outcome of an experiment in a laboratory setting or the observation of a phenomenon in nature. The prediction can also be statistical and deal only with probabilities.
It is essential that the outcome of testing such a prediction be currently unknown. Only in this case does a successful outcome increase the probability that the hypothesis is true. If the outcome is already known, it is called a consequence and should have already been considered while formulating the hypothesis.
If the predictions are not accessible by observation or experience, the hypothesis is not yet testable and so will remain to that extent unscientific in a strict sense. A new technology or theory might make the necessary experiments feasible. Thus, much scientifically based speculation might convince one (or many) that the hypothesis that other intelligent species exist is true. But since there no experiment now known which can test this hypothesis, science itself can have little to say about the possibility. In future, some new technique might lead to an experimental test and the speculation would then become part of accepted science.
DNA-predictions.
 James D. Watson, Francis Crick, and others hypothesized that DNA had a helical structure. This implied that DNA's X-ray diffraction pattern would be 'x shaped'. This prediction followed from the work of Cochran, Crick and Vand (and independently by Stokes). The Cochran-Crick-Vand-Stokes theorem provided a mathematical explanation for the empirical observation that diffraction from helical structures produces x shaped patterns.
In their first paper, Watson and Crick also noted that the double helix structure they proposed provided a simple mechanism for DNA replication, writing, "It has not escaped our notice that the specific pairing we have postulated immediately suggests a possible copying mechanism for the genetic material". " ..4. DNA-experiments"
Another example: general relativity.
Einstein's theory of General Relativity makes several specific predictions about the observable structure of space-time, such as that light bends in a gravitational field, and that the amount of bending depends in a precise way on the strength of that gravitational field. Arthur Eddington's observations made during a 1919 solar eclipse supported General Relativity rather than Newtonian gravitation.
Experiments.
Once predictions are made, they can be sought by experiments. If the test results contradict the predictions, the hypotheses which entailed them are called into question and become less tenable. Sometimes the experiments are conducted incorrectly or are not very well designed, when compared to a crucial experiment. If the experimental results confirm the predictions, then the hypotheses are considered more likely to be correct, but might still be wrong and continue to be subject to further testing. The experimental control is a technique for dealing with observational error. This technique uses the contrast between multiple samples (or observations) under differing conditions to see what varies or what remains the same. We vary the conditions for each measurement, to help isolate what has changed. Mill's canons can then help us figure out what the important factor is. Factor analysis is one technique for discovering the important factor in an effect.
Depending on the predictions, the experiments can have different shapes. It could be a classical experiment in a laboratory setting, a double-blind study or an archaeological excavation. Even taking a plane from New York to Paris is an experiment which tests the aerodynamical hypotheses used for constructing the plane.
Scientists assume an attitude of openness and accountability on the part of those conducting an experiment. Detailed record keeping is essential, to aid in recording and reporting on the experimental results, and supports the effectiveness and integrity of the procedure. They will also assist in reproducing the experimental results, likely by others. Traces of this approach can be seen in the work of Hipparchus (190–120 BCE), when determining a value for the precession of the Earth, while controlled experiments can be seen in the works of Jābir ibn Hayyān (721–815 CE), al-Battani (853–929) and Alhazen (965–1039).
DNA-experiments.
 Watson and Crick showed an initial (and incorrect) proposal for the structure of DNA to a team from Kings College – Rosalind Franklin, Maurice Wilkins, and Raymond Gosling. Franklin immediately spotted the flaws which concerned the water content. Later Watson saw Franklin's detailed X-ray diffraction images which showed an and was able to confirm the structure was helical. This rekindled Watson and Crick's model building and led to the correct structure. "..1. DNA-characterizations"
Evaluation and improvement.
The scientific method is iterative. At any stage it is possible to refine its accuracy and precision, so that some consideration will lead the scientist to repeat an earlier part of the process. Failure to develop an interesting hypothesis may lead a scientist to re-define the subject under consideration. Failure of a hypothesis to produce interesting and testable predictions may lead to reconsideration of the hypothesis or of the definition of the subject. Failure of an experiment to produce interesting results may lead a scientist to reconsider the experimental method, the hypothesis, or the definition of the subject.
Other scientists may start their own research and enter the process at any stage. They might adopt the characterization and formulate their own hypothesis, or they might adopt the hypothesis and deduce their own predictions. Often the experiment is not done by the person who made the prediction, and the characterization is based on experiments done by someone else. Published results of experiments can also serve as a hypothesis predicting their own reproducibility.
DNA-iterations.
 After considerable fruitless experimentation, being discouraged by their superior from continuing, and numerous false starts, Watson and Crick were able to infer the essential structure of DNA by concrete modeling of the physical shapes of the nucleotides which comprise it. They were guided by the bond lengths which had been deduced by Linus Pauling and by Rosalind Franklin's X-ray diffraction images. .."DNA Example"
Confirmation.
Science is a social enterprise, and scientific work tends to be accepted by the scientific community when it has been confirmed. Crucially, experimental and theoretical results must be reproduced by others within the scientific community. Researchers have given their lives for this vision; Georg Wilhelm Richmann was killed by ball lightning (1753) when attempting to replicate the 1752 kite-flying experiment of Benjamin Franklin.
To protect against bad science and fraudulent data, government research-granting agencies such as the National Science Foundation, and science journals, including "Nature" and "Science", have a policy that researchers must archive their data and methods so that other researchers can test the data and methods and build on the research that has gone before. Scientific data archiving can be done at a number of national archives in the U.S. or in the World Data Center.
Models of scientific inquiry.
Classical model.
The classical model of scientific inquiry derives from Aristotle, who distinguished the forms of approximate and exact reasoning, set out the threefold scheme of abductive, deductive, and inductive inference, and also treated the compound forms such as reasoning by analogy.
Pragmatic model.
In 1877, Charles Sanders Peirce ( like "purse"; 1839–1914) characterized inquiry in general not as the pursuit of truth "per se" but as the struggle to move from irritating, inhibitory doubts born of surprises, disagreements, and the like, and to reach a secure belief, belief being that on which one is prepared to act. He framed scientific inquiry as part of a broader spectrum and as spurred, like inquiry generally, by actual doubt, not mere verbal or hyperbolic doubt, which he held to be fruitless. He outlined four methods of settling opinion, ordered from least to most successful:
Peirce held that slow, stumbling ratiocination can be dangerously inferior to instinct and traditional sentiment in practical matters, and that the scientific method is best suited to theoretical research, which in turn should not be trammeled by the other methods and practical ends; reason's "first rule" is that, in order to learn, one must desire to learn and, as a corollary, must not block the way of inquiry. The scientific method excels the others by being deliberately designed to arrive – eventually – at the most secure beliefs, upon which the most successful practices can be based. Starting from the idea that people seek not truth "per se" but instead to subdue irritating, inhibitory doubt, Peirce showed how, through the struggle, some can come to submit to truth for the sake of belief's integrity, seek as truth the guidance of potential practice correctly to its given goal, and wed themselves to the scientific method.
For Peirce, rational inquiry implies presuppositions about truth and the real; to reason is to presuppose (and at least to hope), as a principle of the reasoner's self-regulation, that the real is discoverable and independent of our vagaries of opinion. In that vein he defined truth as the correspondence of a sign (in particular, a proposition) to its object and, pragmatically, not as actual consensus of some definite, finite community (such that to inquire would be to poll the experts), but instead as that final opinion which all investigators "would" reach sooner or later but still inevitably, if they were to push investigation far enough, even when they start from different points. In tandem he defined the real as a true sign's object (be that object a possibility or quality, or an actuality or brute fact, or a necessity or norm or law), which is what it is independently of any finite community's opinion and, pragmatically, depends only on the final opinion destined in a sufficient investigation. That is a destination as far, or near, as the truth itself to you or me or the given finite community. Thus, his theory of inquiry boils down to "Do the science." Those conceptions of truth and the real involve the idea of a community both without definite limits (and thus potentially self-correcting as far as needed) and capable of definite increase of knowledge. As inference, "logic is rooted in the social principle" since it depends on a standpoint that is, in a sense, unlimited.
Paying special attention to the generation of explanations, Peirce outlined the scientific method as a coordination of three kinds of inference in a purposeful cycle aimed at settling doubts, as follows (in §III–IV in "A Neglected Argument" except as otherwise noted):
1. Abduction (or retroduction). Guessing, inference to explanatory hypotheses for selection of those best worth trying. From abduction, Peirce distinguishes induction as inferring, on the basis of tests, the proportion of truth in the hypothesis. Every inquiry, whether into ideas, brute facts, or norms and laws, arises from surprising observations in one or more of those realms (and for example at any stage of an inquiry already underway). All explanatory content of theories comes from abduction, which guesses a new or outside idea so as to account in a simple, economical way for a surprising or complicative phenomenon. Oftenest, even a well-prepared mind guesses wrong. But the modicum of success of our guesses far exceeds that of sheer luck and seems born of attunement to nature by instincts developed or inherent, especially insofar as best guesses are optimally plausible and simple in the sense, said Peirce, of the "facile and natural", as by Galileo's natural light of reason and as distinct from "logical simplicity". Abduction is the most fertile but least secure mode of inference. Its general rationale is inductive: it succeeds often enough and, without it, there is no hope of sufficiently expediting inquiry (often multi-generational) toward new truths. Coordinative method leads from abducing a plausible hypothesis to judging it for its testability and for how its trial would economize inquiry itself. Peirce calls his pragmatism "the logic of abduction". His pragmatic maxim is: "Consider what effects that might conceivably have practical bearings you conceive the objects of your conception to have. Then, your conception of those effects is the whole of your conception of the object". His pragmatism is a method of reducing conceptual confusions fruitfully by equating the meaning of any conception with the conceivable practical implications of its object's conceived effects – a method of experimentational mental reflection hospitable to forming hypotheses and conducive to testing them. It favors efficiency. The hypothesis, being insecure, needs to have practical implications leading at least to mental tests and, in science, lending themselves to scientific tests. A simple but unlikely guess, if uncostly to test for falsity, may belong first in line for testing. A guess is intrinsically worth testing if it has instinctive plausibility or reasoned objective probability, while subjective likelihood, though reasoned, can be misleadingly seductive. Guesses can be chosen for trial strategically, for their caution (for which Peirce gave as example the game of Twenty Questions), breadth, and incomplexity. One can hope to discover only that which time would reveal through a learner's sufficient experience anyway, so the point is to expedite it; the economy of research is what demands the leap, so to speak, of abduction and governs its art.
2. Deduction. Two stages:
3. Induction. The long-run validity of the rule of induction is deducible from the principle (presuppositional to reasoning in general) that the real is only the object of the final opinion to which adequate investigation would lead; anything to which no such process would ever lead would not be real. Induction involving ongoing tests or observations follows a method which, sufficiently persisted in, will diminish its error below any predesignate degree. Three stages:
Communication and community.
Frequently the scientific method is employed not only by a single person, but also by several people cooperating directly or indirectly. Such cooperation can be regarded as an important element of a scientific community. Various standards of scientific methodology are used within such an environment.
Peer review evaluation.
Scientific journals use a process of "peer review", in which scientists' manuscripts are submitted by editors of scientific journals to (usually one to three) fellow (usually anonymous) scientists familiar with the field for evaluation. In certain journals, the journal itself selects the referees; while in others (especially journals that are extremely specialized), the manuscript author might recommend referees. The referees may or may not recommend publication, or they might recommend publication with suggested modifications, or sometimes, publication in another journal. This standard is practiced to various degrees by different journals, and can have the effect of keeping the literature free of obvious errors and to generally improve the quality of the material, especially in the journals who use the standard most rigorously. The peer review process can have limitations when considering research outside the conventional scientific paradigm: problems of "groupthink" can interfere with open and fair deliberation of some new research.
Documentation and replication.
Sometimes experimenters may make systematic errors during their experiments, veer from standard methods and practices (Pathological science) for various reasons, or, in rare cases, deliberately report false results. Occasionally because of this then, other scientists might attempt to repeat the experiments in order to duplicate the results.
Archiving.
Researchers sometimes practice scientific data archiving, such as in compliance with the policies of government funding agencies and scientific journals. In these cases, detailed records of their experimental procedures, raw data, statistical analyses and source code can be preserved in order to provide evidence of the methodology and practice of the procedure and assist in any potential future attempts to reproduce the result. These procedural records may also assist in the conception of new experiments to test the hypothesis, and may prove useful to engineers who might examine the potential practical applications of a discovery.
Data sharing.
When additional information is needed before a study can be reproduced, the author of the study might be asked to provide it. They might provide it, or if the author refuses to share data, appeals can be made to the journal editors who published the study or to the institution which funded the research.
Limitations.
Since it is impossible for a scientist to record "everything" that took place in an experiment, facts selected for their apparent relevance are reported. This may lead, unavoidably, to problems later if some supposedly irrelevant feature is questioned. For example, Heinrich Hertz did not report the size of the room used to test Maxwell's equations, which later turned out to account for a small deviation in the results. The problem is that parts of the theory itself need to be assumed in order to select and report the experimental conditions. The observations are hence sometimes described as being 'theory-laden'.
Dimensions of practice.
The primary constraints on contemporary science are:
It has not always been like this: in the old days of the "gentleman scientist" funding (and to a lesser extent publication) were far weaker constraints.
Both of these constraints indirectly require scientific method – work that violates the constraints will be difficult to publish and difficult to get funded. Journals require submitted papers to conform to "good scientific practice" and to a degree this can be enforced by peer review. Originality, importance and interest are more important – see for example the for "Nature".
Philosophy and sociology of science.
Philosophy of science looks at the underpinning logic of the scientific method, at what separates science from non-science, and the ethic that is implicit in science. There are basic assumptions, derived from philosophy by at least one prominent scientist, that form the base of the scientific method – namely, that reality is objective and consistent, that humans have the capacity to perceive reality accurately, and that rational explanations exist for elements of the real world. These assumptions from methodological naturalism form a basis on which science may be grounded. Logical Positivist, empiricist, falsificationist, and other theories have criticized these assumptions and given alternative accounts of the logic of science, but each has also itself been criticized.
Thomas Kuhn examined the history of science in his "The Structure of Scientific Revolutions", and found that the actual method used by scientists differed dramatically from the then-espoused method. His observations of science practice are essentially sociological and do not speak to how science is or can be practiced in other times and other cultures.
Norwood Russell Hanson, Imre Lakatos and Thomas Kuhn have done extensive work on the "theory laden" character of observation. Hanson (1958) first coined the term for the idea that all observation is dependent on the conceptual framework of the observer, using the concept of gestalt to show how preconceptions can affect both observation and description. He opens Chapter 1 with a discussion of the Golgi bodies and their initial rejection as an artefact of staining technique, and a discussion of Brahe and Kepler observing the dawn and seeing a "different" sun rise despite the same physiological phenomenon. Kuhn and Feyerabend acknowledge the pioneering significance of his work.
Kuhn (1961) said the scientist generally has a theory in mind before designing and undertaking experiments so as to make empirical observations, and that the "route from theory to measurement can almost never be traveled backward". This implies that the way in which theory is tested is dictated by the nature of the theory itself, which led Kuhn (1961, p. 166) to argue that "once it has been adopted by a profession ... no theory is recognized to be testable by any quantitative tests that it has not already passed".
Paul Feyerabend similarly examined the history of science, and was led to deny that science is genuinely a methodological process. In his book "Against Method" he argues that scientific progress is "not" the result of applying any particular method. In essence, he says that for any specific method or norm of science, one can find a historic episode where violating it has contributed to the progress of science. Thus, if believers in scientific method wish to express a single universally valid rule, Feyerabend jokingly suggests, it should be 'anything goes'. Criticisms such as his led to the strong programme, a radical approach to the sociology of science.
The postmodernist critiques of science have themselves been the subject of intense controversy. This ongoing debate, known as the science wars, is the result of conflicting values and assumptions between the postmodernist and realist camps. Whereas postmodernists assert that scientific knowledge is simply another discourse (note that this term has special meaning in this context) and not representative of any form of fundamental truth, realists in the scientific community maintain that scientific knowledge does reveal real and fundamental truths about reality. Many books have been written by scientists which take on this problem and challenge the assertions of the postmodernists while defending science as a legitimate method of deriving truth.
Role of chance in discovery.
Somewhere between 33% and 50% of all scientific discoveries are estimated to have been "stumbled upon", rather than sought out. This may explain why scientists so often express that they were lucky. Louis Pasteur is credited with the famous saying that "Luck favours the prepared mind", but some psychologists have begun to study what it means to be 'prepared for luck' in the scientific context. Research is showing that scientists are taught various heuristics that tend to harness chance and the unexpected. This is what Nassim Nicholas Taleb calls "Anti-fragility"; while some systems of investigation are fragile in the face of human error, human bias, and randomness, the scientific method is more than resistant or tough – it actually benefits from such randomness in many ways (it is anti-fragile). Taleb believes that the more anti-fragile the system, the more it will flourish in the real world.
Psychologist Kevin Dunbar says the process of discovery often starts with researchers finding bugs in their experiments. These unexpected results lead researchers to try to fix what they "think" is an error in their method. Eventually, the researcher decides the error is too persistent and systematic to be a coincidence. The highly controlled, cautious and curious aspects of the scientific method are thus what make it well suited for identifying such persistent systematic errors. At this point, the researcher will begin to think of theoretical explanations for the error, often seeking the help of colleagues across different domains of expertise.
History.
The development of the scientific method is inseparable from the history of science itself. Ancient Egyptian documents describe empirical methods in astronomy, mathematics, and medicine. The ancient Greek philosopher Thales in the 6th century BCE refused to accept supernatural, religious or mythological explanations for natural phenomena, proclaiming that every event had a natural cause. The development of deductive reasoning by Plato was an important step towards the scientific method. Empiricism seems to have been formalized by Aristotle, who believed that universal truths could be reached via induction.
For the beginnings of scientific method: Karl Popper writes of Parmenides ("fl." 5th century BCE): "So what was really new in Parmenides was his axiomatic-deductive method, which Leucippus and Democritus turned into a hypothetical-deductive method, and thus made part of scientific methodology."
According to David Lindberg, Aristotle (4th century BCE) wrote about the scientific method even if he and his followers did not actually follow what he said. Lindberg also notes that Ptolemy (2nd century CE) and Ibn al-Haytham (11th century CE) are among the early examples of people who carried out scientific experiments.
 Also, John Losee writes that "the "Physics" and the "Metaphysics" contain discussions of certain aspects of scientific method", of which, he says "Aristotle viewed scientific inquiry as a progression from observations to general principles and back to observations."
Early Christian leaders such as Clement of Alexandria (150–215) and Basil of Caesarea (330–379) encouraged future generations to view the Greek wisdom as "handmaidens to theology" and science was considered a means to more accurate understanding of the Bible and of God. Augustine of Hippo (354–430) who contributed great philosophical wealth to the Latin Middle Ages, advocated the study of science and was wary of philosophies that disagreed with the Bible, such as astrology and the Greek belief that the world had no beginning. This Christian accommodation with Greek science "laid a foundation for the later widespread, intensive study of natural philosophy during the Late Middle Ages." However, the division of Latin-speaking Western Europe from the Greek-speaking East, followed by barbarian invasions, the Plague of Justinian, and the Islamic invasion, resulted in the West largely losing access to Greek wisdom.
By the 8th century Islam had overrun the Christian lands of Syria, Iraq, Iran and Egypt This swift occupation further severed Western Europe from many of the great works of Aristotle, Plato, Euclid and others, many of which were housed in the great library of Alexandria. Having come upon such a wealth of knowledge, the Arabs, who viewed non-Arab languages as inferior, even as a source of pollution, employed conquered Christians and Jews to translate these works from the native Greek and Syriac into Arabic
Thus equipped, Arab philosopher Alhazen (Ibn al-Haytham) performed optical and physiological experiments, reported in his manifold works, the most famous being "Book of Optics" (1021). He was thus a forerunner of scientific method, having understood that a controlled environment involving experimentation and measurement is required in order to draw educated conclusions. Other Arab polymaths of the same era produced copious works on mathematics, philosophy, astronomy and alchemy. Most stuck closely to Aristotle, being hesitant to admit that some of Aristotle's thinking was errant, while others strongly criticized him.
During these years, occasionally a paraphrased translation from the Arabic, which itself had been translated from Greek and Syriac, might make its way to the West for scholarly study. It was not until 1204, during which the Latins conquered and took Constantinople from the Byzantines in the name of the fourth Crusade, that a renewed scholarly interest in the original Greek manuscripts began to grow. Due to the new easier access to the libraries of Constantinople by Western scholars, a certain revival in the study and analysis of the original Greek texts by Western scholars began. From that point a functional scientific method that would launch modern science was on the horizon.
Grosseteste (1175–1253), an English statesman, scientist and Christian theologian, was "the principal figure" in bringing about "a more adequate method of scientific inquiry" by which "medieval scientists were able eventually to outstrip their ancient European and Muslim teachers" (Dales 1973:62). ... His thinking influenced Roger Bacon, who spread Grosseteste's ideas from Oxford to the University of Paris during a visit there in the 1240s. From the prestigious universities in Oxford and Paris, the new experimental science spread rapidly throughout the medieval universities: "And so it went to Galileo, William Gilbert, Francis Bacon, William Harvey, Descartes, Robert Hooke, Newton, Leibniz, and the world of the seventeenth century" (Crombie 1962:15). So it went to us as well.| Hugh G. Gauch, 2003.
Roger Bacon (1214–1294), an English thinker and experimenter, is recognized by many to be the father of modern scientific method. His view that mathematics was essential to a correct understanding of natural philosophy was considered to be 400 years ahead of its time. He was viewed as "a lone genius proclaiming the truth about time," having correctly calculated the calendar His work in optics provided the platform on which Newton, Descartes, Huygens and others later transformed the science of light. Bacon's groundbreaking advances were due largely to his discovery that experimental science must be based on mathematics. (186–187) His works Opus Majus and De Speculis Comburentibus contain many "carefully drawn diagrams showing Bacon's meticulous investigations into the behavior of light." He gives detailed descriptions of systematic studies using prisms and measurements by which he shows how a rainbow functions.
Others who advanced scientific method during this era included Albertus Magnus (c. 1193 – 1280), Theodoric of Freiberg, (c. 1250 – c. 1310), William of Ockham (c. 1285 – c. 1350), and Jean Buridan (c. 1300 – c. 1358). These were not only scientists but leaders of the church – Christian archbishops, friars and priests.
By the late 15th century, the physician-scholar Niccolò Leoniceno was finding errors in Pliny's "Natural History". As a physician, Leoniceno was concerned about these botanical errors propagating to the materia medica on which medicines were based. To counter this, a botanical garden was established at Orto botanico di Padova, University of Padua (in use for teaching by 1546), in order that medical students might have empirical access to the plants of a pharmacopia. The philosopher and physician Francisco Sanches was led by his medical training at Rome, 1571–73, and by the philosophical skepticism recently placed in the European mainstream by the publication of Sextus Empiricus' "Outlines of Pyrrhonism", to search for a true method of knowing ("modus sciendi"), as nothing clear can be known by the methods of Aristotle and his followers – for example, syllogism fails upon circular reasoning. Following the physician Galen's "method of medicine", Sanches lists the methods of judgement and experience, which are faulty in the wrong hands, and we are left with the bleak statement "That Nothing is Known" (1581). This challenge was taken up by René Descartes in the next generation (1637), but at the least, Sanches warns us that we ought to refrain from the methods, summaries, and commentaries on Aristotle, if we seek scientific knowledge. In this, he is echoed by Francis Bacon, also influenced by skepticism; Sanches cites the humanist Juan Luis Vives who sought a better educational system, as well as a statement of human rights as a pathway for improvement of the lot of the poor.
The modern scientific method crystallized no later than in the 17th and 18th centuries. In his work "Novum Organum" (1620) – a reference to Aristotle's "Organon" – Francis Bacon outlined a new system of logic to improve upon the old philosophical process of syllogism. Then, in 1637, René Descartes established the framework for scientific method's guiding principles in his treatise, "Discourse on Method". The writings of Alhazen, Bacon and Descartes are considered critical in the historical development of the modern scientific method, as are those of John Stuart Mill.
In the late 19th century, Charles Sanders Peirce proposed a schema that would turn out to have considerable influence in the development of current scientific methodology generally. Peirce accelerated the progress on several fronts. Firstly, speaking in broader context in , Peirce outlined an objectively verifiable method to test the truth of putative knowledge on a way that goes beyond mere foundational alternatives, focusing upon both "deduction" and "induction". He thus placed induction and deduction in a complementary rather than competitive context (the latter of which had been the primary trend at least since David Hume, who wrote in the mid-to-late 18th century). Secondly, and of more direct importance to modern method, Peirce put forth the basic schema for hypothesis/testing that continues to prevail today. Extracting the theory of inquiry from its raw materials in classical logic, he refined it in parallel with the early development of symbolic logic to address the then-current problems in scientific reasoning. Peirce examined and articulated the three fundamental modes of reasoning that, as discussed above in this article, play a role in inquiry today, the processes that are currently known as abductive, deductive, and inductive inference. Thirdly, he played a major role in the progress of symbolic logic itself – indeed this was his primary specialty.
Beginning in the 1930s, Karl Popper argued that there is no such thing as inductive reasoning. All inferences ever made, including in science, are purely deductive according to this view. Accordingly, he claimed that the empirical character of science has nothing to do with induction – but with the deductive property of falsifiability that scientific hypotheses have. Contrasting his views with inductivism and positivism, he even denied the existence of the scientific method: "(1) There is no method of discovering a scientific theory (2) There is no method for ascertaining the truth of a scientific hypothesis, i.e., no method of verification; (3) There is no method for ascertaining whether a hypothesis is 'probable', or probably true". Instead, he held that there is only one universal method, a method not particular to science: The negative method of criticism, or colloquially termed trial and error. It covers not only all products of the human mind, including science, mathematics, philosophy, art and so on, but also the evolution of life. Following Peirce and others, Popper argued that science is fallible and has no authority. In contrast to empiricist-inductivist views, he welcomed metaphysics and philosophical discussion and even gave qualified support to myths and pseudosciences. Popper's view has become known as critical rationalism.
Although science in a broad sense existed before the modern era, and in many historical civilizations (as described above), modern science is so distinct in its approach and successful in its results that it now defines what science is in the strictest sense of the term.
Relationship with mathematics.
Science is the process of gathering, comparing, and evaluating proposed models against observables. A model can be a simulation, mathematical or chemical formula, or set of proposed steps. Science is like mathematics in that researchers in both disciplines can clearly distinguish what is "known" from what is "unknown" at each stage of discovery. Models, in both science and mathematics, need to be internally consistent and also ought to be "falsifiable" (capable of disproof). In mathematics, a statement need not yet be proven; at such a stage, that statement would be called a conjecture. But when a statement has attained mathematical proof, that statement gains a kind of immortality which is highly prized by mathematicians, and for which some mathematicians devote their lives.
Mathematical work and scientific work can inspire each other. For example, the technical concept of time arose in science, and timelessness was a hallmark of a mathematical topic. But today, the Poincaré conjecture has been proven using time as a mathematical concept in which objects can flow (see Ricci flow).
Nevertheless, the connection between mathematics and reality (and so science to the extent it describes reality) remains obscure. Eugene Wigner's paper, "The Unreasonable Effectiveness of Mathematics in the Natural Sciences", is a very well known account of the issue from a Nobel Prize-winning physicist. In fact, some observers (including some well known mathematicians such as Gregory Chaitin, and others such as Lakoff and Núñez) have suggested that mathematics is the result of practitioner bias and human limitation (including cultural ones), somewhat like the post-modernist view of science.
George Pólya's work on problem solving, the construction of mathematical proofs, and heuristic show that the mathematical method and the scientific method differ in detail, while nevertheless resembling each other in using iterative or recursive steps.
In Pólya's view, "understanding" involves restating unfamiliar definitions in your own words, resorting to geometrical figures, and questioning what we know and do not know already; "analysis", which Pólya takes from Pappus, involves free and heuristic construction of plausible arguments, working backward from the goal, and devising a plan for constructing the proof; "synthesis" is the strict Euclidean exposition of step-by-step details of the proof; "review" involves reconsidering and re-examining the result and the path taken to it.
Gauss, when asked how he came about his theorems, once replied "durch planmässiges Tattonieren" (through systematic palpable experimentation).
Imre Lakatos argued that mathematicians actually use contradiction, criticism and revision as principles for improving their work. In like manner to science, where truth is sought, but certainty is not found, in "Proofs and refutations" (1976), what Lakatos tried to establish was that no theorem of informal mathematics is final or perfect. This means that we should not think that a theorem is ultimately true, only that no counterexample has yet been found. Once a counterexample, i.e. an entity contradicting/not explained by the theorem is found, we adjust the theorem, possibly extending the domain of its validity. This is a continuous way our knowledge accumulates, through the logic and process of proofs and refutations. (If axioms are given for a branch of mathematics, however, Lakatos claimed that proofs from those axioms were tautological, i.e. logically true, by rewriting them, as did Poincaré ("Proofs and Refutations", 1976).)
Lakatos proposed an account of mathematical knowledge based on Polya's idea of heuristics. In "Proofs and Refutations", Lakatos gave several basic rules for finding proofs and counterexamples to conjectures. He thought that mathematical 'thought experiments' are a valid way to discover mathematical conjectures and proofs.
References.
</dl>
Further reading.
</dl>

</doc>
<doc id="26838" url="http://en.wikipedia.org/wiki?curid=26838" title="Shotgun">
Shotgun

A shotgun (also known as a scattergun and peppergun, or historically as a fowling piece) is a firearm that is usually designed to be fired from the shoulder, which uses the energy of a fixed shell to fire a number of small spherical pellets called shot, or a solid projectile called a slug. Shotguns come in a wide variety of sizes, ranging from 5.5 mm (.22 inch) bore up to 5 cm bore, and in a range of firearm operating mechanisms, including breech loading, single-barreled, double or combination gun, pump-action, bolt-, and lever-action, semi-automatic, and even fully automatic variants.
A shotgun is generally a smoothbore firearm, which means that the inside of the barrel is not rifled. Preceding smoothbore firearms, such as the musket, were widely used by armies in the 18th century. The direct ancestor to the shotgun, the blunderbuss, was also used in a similar variety of roles from self defence to riot control. It was often used by cavalry troops due to its generally shorter length and ease of use, as well as by coachmen for its substantial power. However, in the 19th century, these weapons were largely replaced on the battlefield with breechloading rifled firearms, which were more accurate over longer ranges. The military value of shotguns was rediscovered in the First World War, when American forces used 12-gauge pump action shotguns in close-quarters trench fighting to great effect. Since then, it has been used in a variety of roles in civilian, law enforcement, and military applications.
The shot pellets from a shotgun spread upon leaving the barrel, and the power of the burning charge is divided among the pellets, which means that the energy of any one ball of shot is fairly low. In a hunting context, this makes shotguns useful primarily for hunting birds and other small game. However, in a military or law enforcement context, the large number of projectiles makes the shotgun useful as a close quarters combat weapon or a defensive weapon. Shotguns are also used for target shooting sports such as skeet, trap, and sporting clays. These involve shooting clay disks, known as clay pigeons, thrown in various ways.
Characteristics.
Shotguns come in a wide variety of forms, from very small up to massive punt guns, and in nearly every type of firearm operating mechanism. The common characteristics that make a shotgun unique center around the requirements of firing shot. These features are the features typical of a shotgun shell, namely a relatively short, wide cartridge, with straight walls, and operating at a relatively low pressure.
Ammunition for shotguns is referred to in the USA as shotgun shells, shotshells, or just shells (when it is not likely to be confused with artillery shells). The term cartridges is standard usage in the United Kingdom.
The shot is usually fired from a smoothbore barrel; another configuration is the rifled slug barrel, which fires more accurate solitary projectiles.
Uses.
The typical use of a shotgun is against small and fast moving targets, often while in the air. The spreading of the shot allows the user to point the shotgun close to the target, rather than having to aim precisely as in the case of a single projectile. The disadvantages of shot are limited range and limited penetration of the shot, which is why shotguns are used at short ranges, and typically against smaller targets. Larger shot sizes, up to the extreme case of the single projectile slug load, result in increased penetration, but at the expense of fewer projectiles and lower probability of hitting the target.
Aside from the most common use against small, fast moving targets, the shotgun has several advantages when used against still targets. First, it has enormous stopping power at short range, more than nearly all handguns and many rifles. Though many believe the shotgun is a great firearm for inexperienced shooters, the truth is, at close range, the spread of shot is not very large at all, and competency in aiming is still required. A typical self-defense load of buckshot contains 8-27 large lead pellets, resulting in many wound tracks in the target. Also, unlike a fully jacketed rifle bullet, each pellet of shot is less likely to penetrate walls and hit bystanders. It is favored by law enforcement for its low penetration and high stopping power.
On the other hand, the hit potential of a defensive shotgun is often overstated. The typical defensive shot is taken at very close ranges, at which the shot charge expands no more than a few centimeters. This means the shotgun must still be aimed at the target with some care. Balancing this is the fact that shot spreads further upon entering the target, and the multiple wound channels of a defensive load are far more likely to produce a disabling wound than a rifle or handgun.
Sporting.
Some of the most common uses of shotguns are the sports of skeet shooting, trap shooting, and sporting clays. These involve shooting clay discs, also known as clay pigeons, thrown in by hand and by machine. Both skeet and trap competitions are featured at the Olympic Games.
Hunting.
The shotgun is popular for bird hunting, it is also used for more general forms of hunting especially in semi-populated areas where the range of rifle bullets may pose a hazard. Use of a smooth bore shotgun with a rifled slug or, alternatively, a rifled barrel shotgun with a sabot slug, improves accuracy to 100 m or more. This is well within the range of the majority of kill shots by experienced hunters using shotguns.
However, given the relatively low muzzle velocity of slug ammunition, typically around 500 m/s (about 1600 feet per second), and the blunt, poorly streamlined shape of typical slugs (which cause them to lose velocity very rapidly, compared to rifle bullets), a hunter must pay close attention to the ballistics of the particular ammunition used to ensure an effective and humane kill shot.
At any reasonable range, shotgun slugs make effective lethal wounds due to their tremendous mass, reducing the length of time that an animal might suffer. For example, a typical 12 gauge shotgun slug is a blunt piece of metal that could be described as an 18 mm (.729 inch) caliber that weighs 28 grams (432 grains). For comparison, a common deer-hunting rifle round is a 7.62 mm (.308 inch) slug weighing 9.7 grams (150 grains), but the dynamics of the rifle cartridge allow for a different type of wound, and a much further reach.
Shotguns are often used with rifled barrels in locations where it is not lawful to hunt with a rifle. Typically, a sabot slug is used in these barrels for maximum accuracy and performance. Shotguns are often used to hunt whitetail deer in the thick brush and briers of the Southeastern and upper Midwestern United States, where, due to the dense cover, ranges tend to be close - 25m or less.
Sabot slugs are essentially very large hollowpoint bullets, and are streamlined for maximum spin and accuracy when shot through a rifled barrel. They have greater ranges than older Foster and Brenneke-type slugs.
Law enforcement.
In the US and Canada, shotguns are widely used as a support weapon by police forces. One of the rationales for issuing shotguns is that, even without much training, an officer will probably be able to hit targets at close to intermediate range, due to the "spreading" effect of buckshot. This is largely a myth, as the spread of buckshot at 25 feet averages 8 inches, which is still very capable of missing a target. Some police forces are replacing shotguns in this role with carbine rifles such as AR-15s. Shotguns are also used in roadblock situations, where police are blocking a highway to search cars for suspects. In the US, law enforcement agencies often use riot shotguns, especially for crowd and riot control where they may be loaded with less-lethal rounds such as rubber bullets or bean bags. Shotguns are also often used as breaching devices to defeat locks.
Military.
Shotguns are common weapons in military use, particularly for special purposes. Shotguns are found aboard naval vessels for shipboard security, because the weapon is very effective at close range as a way of repelling enemy boarding parties. In a naval setting, stainless steel shotguns are often used, because regular steel is more prone to corrosion in the marine environment. Shotguns are also used by military police units. U.S. Marines have used shotguns since their inception at the squad level, often in the hands of NCOs, while the U.S. Army often issued them to a squad's point man. Shotguns were modified for and used in the trench warfare of WWI, in the jungle combat of WWII and Vietnam and are being used today in Iraq, being popular with soldiers and marines in urban combat environments. Some U.S. units in Iraq use shotguns with special frangible breaching rounds to blow the locks off doors when they are making a surprise entry into a dwelling.
Home and personal defense.
Shotguns are a popular means of home defense for many of the same reasons they are preferred for close-quarters tasks in law enforcement and the military.
Design features for various uses.
Compared to handguns, shotguns are heavier, larger, and not as maneuverable in close quarters (which also presents a greater retention problem), but do have these advantages:
Types.
The wide range of forms the shotgun can take leads to some significant differences between what is technically a shotgun and what is legally considered a shotgun. A fairly broad attempt to define a shotgun is made in the United States Code (18 USC 921), which defines the shotgun as "a weapon designed or redesigned, made or remade, and intended to be fired from the shoulder, and designed or redesigned and made or remade to use the energy of the explosive in a fixed shotgun shell to fire through a smooth bore either a number of ball shot or a single projectile for each single pull of the trigger."
A rifled slug, with finned rifling designed to enable the projectile to be safely fired through a choked barrel, is an example of a single projectile. Some shotguns have rifled barrels and are designed to be used with a "saboted" bullet, one which is typically encased in a two-piece plastic ring ("sabot") designed to peel away after it exits the barrel, leaving the bullet, now spinning after passing through the rifled barrel, to continue toward the target. These shotguns, although they have rifled barrels, still use a shotgun-style shell instead of a rifle cartridge and may in fact still fire regular multipellet shotgun shells, but the rifling in the barrel will affect the shot pattern. The use of a rifled barrel blurs the distinction between rifle and shotgun, and in fact the early rifled shotgun barrels went by the name "Paradox" for just that reason. Hunting laws may differentiate between smooth barreled and rifled barreled guns.
Riot gun has long been a synonym for a shotgun, especially a short-barrelled shotgun. During the 19th and early 20th century, these were used to disperse rioters and revolutionaries. The wide spray of the shot ensured a large group would be hit, but the light shot would ensure more wounds than fatalities. When the ground was paved, police officers would often ricochet the shot off the ground, slowing down the shot and spreading pattern even further. To this day specialized police and defensive shotguns are called riot shotguns. The introduction of rubber bullets and bean bag rounds ended the practice of using shot for the most part, but riot shotguns are still used to fire a variety of less lethal rounds for riot control.
A sawed-off shotgun (or "sawn-off") refers to a shotgun whose barrel has been shortened, leaving it more maneuverable, easier to use at short range and more readily concealed. Many countries establish a legal minimum barrel length that precludes easy concealment (this length is 18 in in the U.S.). The sawed-off shotgun is sometimes known as a "Lupara" (in Italian a generic reference to the word "lupo" ("wolf")) in Southern Italy and Sicily.
Coach guns are similar to sawn-off shotguns, except they are manufactured with an 46 cm (18") barrel and are legal for civilian ownership in some jurisdictions. Coach guns are also more commonly associated with the American Old West or Australian Colonial period, and often used for hunting in bush, scrub, or marshland where a longer barrel would be unwieldy or impractical.
A backpacker shotgun has a short barrel and either a full-size stock or pistol grip, depending on legislation in intended markets. The overall length of these weapons is frequently less than 90 cm, with some measuring up at less than 63 cm. These weapons are typically break-action .410 "gauge" (caliber), single-barrel designs with no magazine and no automatic ejection capability. They typically employ a cylinder bore and sometimes are available in modified choke as well.
Backpacker shotguns are popular for "home defense" purposes and as "survival" weapons. Other examples include a variety of .410 / rifle "survival" guns manufactured in over/under designs. In the drilling arrangement, a rimfire or centrefire rifle barrel is located beneath the barrel of a .410 gauge shotgun. Generally, there is one manually cocked external hammer and an external selection lever to select which caliber of cartridge to fire. A notable example is the Springfield Armory M6 Scout, a .410 / .22 issued to United States Air Force personnel as a "survival" gun in the event of a forced landing or accident in a wilderness area. Variants have been used by Israeli, Canadian, and American armed forces. Shotgun-rifle combination guns with two, three, and occasionally even four barrels are available from a number of makers, primarily European. These provided flexibility, enabling the hunter to effectively shoot at flushing birds or more distant small mammals while only carrying one gun.
History.
Most early firearms, such as the blunderbuss, arquebus, and musket had large diameter, smoothbore barrels, and could fire shot as well as solid balls. A firearm intended for use in wing shooting of birds was known as a fowling piece. The 1728 " Cyclopaedia" defines a "fowling piece" as:
For example, the Brown Bess musket, in service with the British army from 1722 to 1838, had a 19 mm (.75 inch) smoothbore barrel, roughly the same as a 10 gauge shotgun, and was 157 cm long, just short of the above recommended 168 cm (51⁄2 feet). On the other hand, records from the Plymouth colony show a maximum length of 137 cm (41⁄2 feet) for fowling pieces, shorter than the typical musket.
Shot was also used in warfare; the buck and ball loading, combining a musket ball with three or six buckshot, was used throughout the history of the smoothbore musket. The first recorded use of the term "shotgun" was in 1776 in Kentucky. It was noted as part of the "frontier language of the West" by James Fenimore Cooper.
With the adoption of smaller bores and rifled barrels, the shotgun began to emerge as a separate entity. Shotguns have long been the preferred method for sport hunting of birds, and the largest shotguns, the punt guns, were used for commercial hunting. The double-barreled shotgun has changed little since the development of the boxlock action in 1875. Modern innovations such as interchangeable chokes and subgauge inserts make the double-barreled shotgun the shotgun of choice in skeet, trap shooting, and sporting clays, as well as with many hunters.
As wing shooting has been a prestige sport, specialty gunsmiths such as Krieghoff or Perazzi have produced fancy double-barrel guns for wealthy European and American hunters. These weapons can cost US$5,000 or more; some elaborately decorated presentation guns have sold for up to US$100,000.
During its long history, the shotgun has been favored by bird hunters, guards, and law enforcement officials. The shotgun has fallen in and out of favor with military forces several times in its long history. Shotguns and similar weapons are simpler than long-range rifles, and were developed earlier. The development of more accurate and deadlier long-range rifles minimized the usefulness of the shotgun on the open battlefields of European wars. But armies have "rediscovered" the shotgun for specialty uses many times.
19th century.
During the 19th century, shotguns were mainly employed by cavalry units. Both sides of the American Civil War employed shotguns. U.S. cavalry used the shotgun extensively during the Indian Wars in the latter half of the 19th century. Mounted units favored the shotgun for its moving target effectiveness, and devastating close-range firepower. The shotgun was also favored by citizen militias and similar groups.
With the exception of cavalry units, the shotgun saw less and less use throughout the 19th century on the battlefield. As a defense weapon it remained popular with guards and lawmen, however, and the shotgun became one of many symbols of the American Old West. Lawman Cody Lyons killed two men with a shotgun; his friend Doc Holliday's only confirmed kill was with a shotgun. The weapon both these men used was the short-barreled version favored by private strongbox guards on stages and trains. These guards, called express messengers, became known as shotgun messengers, since they rode with the weapon (loaded with buckshot) for defense against bandits. Passenger carriages carrying a strongbox usually had at least one private guard armed with a shotgun riding in front of the coach, next to the driver. This practice has survived in American slang; the term "riding shotgun" is used for the passenger who sits in the front passenger seat. The shotgun was a popular weapon for personal protection in the American Old West, requiring less skill on the part of the user than a revolver.
Hammerless shotguns.
The origins of the hammerless shotgun are European but otherwise obscure. The earliest breechloading shotguns originated in France and Belgium in the early 19th century (see also the history of the Pinfire) and a number of them such as those by Robert and Chateauvillard from the 1830s and 1840s did not use hammers. In fact during these decades a wide variety of ingenious weapons, including rifles, adopted what is now often known as a 'needle-fire' method of igniting the charge, where a firing pin or a longer sharper needle provided the necessary impact. The most widely used British hammerless needle-fire shotgun was the unusual hinged-chamber fixed-barrel breech-loader by Joseph Needham, produced from the 1850s. By the 1860s hammerless guns were increasingly used in Europe both in war and sport although hammer guns were still very much in the majority. The first significant encroachment on hammer guns was a hammerless patent which could be used with a conventional side-lock. This was British gunmaker T Murcott's 1871 action nicknamed the 'mousetrap' on account of its loud snap action. However, the most successful hammerless innovation of the 1870s was Anson and Deeley's boxlock patent of 1875. This simple but ingenious design only used four moving parts allowing the production of cheaper and reliable shotguns.
Daniel Myron LeFever is credited with the invention of the American hammerless shotgun. Working for Barber & LeFever in Syracuse, N.Y. he introduced his first hammerless shotgun in 1878. This gun was cocked with external cocking levers on the side of the breech. He went on to patent the first truly automatic hammerless shotgun in 1883. This gun automatically cocked itself when the breech was closed. He later developed the mechanism to automatically eject the shells when the breech was opened.
John Moses Browning.
One of the men most responsible for the modern development of the shotgun was prolific gun designer John Browning. While working for Winchester Firearms, Browning revolutionized shotgun design. In 1887, Browning introduced the Model 1887 Lever Action Repeating Shotgun, which loaded a fresh cartridge from its internal magazine by the operation of the action lever. Before this time most shotguns were the 'break open' type.
This development was greatly overshadowed by two further innovations he introduced at the end of the 19th century. In 1893, Browning produced the Model 1893 Pump Action Shotgun, introducing the now familiar pump action to the market. And in 1900, he patented the Browning Auto-5, the world's first semi-automatic shotgun. The Browning Auto-5 remained in production until 1998.
World wars.
The decline in military use of shotguns reversed in World War I. American forces under General Pershing employed 12-gauge pump action shotguns when they were deployed to the Western front in 1917. These shotguns were fitted with bayonets and a heat shield so the barrel could be gripped while the bayonet was deployed. Shotguns fitted in this fashion became known as "trench guns" by the United States Army. Those without such modifications were known as "riot guns". After World War I, the United States military began referring to all shotguns as "riot guns".
Due to the cramped conditions of trench warfare, the American shotguns were extremely effective. Germany even filed an official diplomatic protest against their use, alleging they violated the laws of warfare. The judge advocate general reviewed the protest, and it was rejected because the Germans protested use of lead shot (which would have been illegal) but military shot was plated. This is the only occasion the legality of the shotgun's use in warfare has been questioned.
During World War II, the shotgun was not heavily used in the war in Europe by official military forces. However, the shotgun was a favorite weapon of Allied-supported partisans, such as the French Resistance. By contrast, in the Pacific theater, thick jungles and heavily fortified positions made the shotgun a favorite weapon of the United States Marines. Marines tended to use pump shotguns, since the pump action was less likely to jam in the humid and dirty conditions of the Pacific campaign. Similarly, the United States Navy used pump shotguns to guard ships when in port in Chinese harbors (e.g., Shanghai). The United States Army Air Forces also used pump shotguns to guard bombers and other aircraft against saboteurs when parked on airbases across the Pacific and on the West Coast of the United States. Pump and semi-automatic shotguns were used in marksmanship training, particularly for bomber gunners. The most common pump shotguns used for these duties were the 12 gauge Winchester Model 97 and Model 12. The break-open action, single barrel shotgun was used by the British Home Guard and U.S. home security forces. Notably, industrial centers (such as the Gopher State Steel Works) were guarded by National Guard soldiers with Winchester Model 37 12 gauge shotguns.
Late 20th century to present.
Since the end of World War II, the shotgun has remained a specialty weapon for modern armies. It has been deployed for specialized tasks where its strengths were put to particularly good use. It was used to defend machine gun emplacements during the Korean War, American and French jungle patrols used shotguns during the Vietnam War, and shotguns saw extensive use as door breaching and close quarter weapons in the early stages of the Iraq War, and saw limited use in tank crews. Many modern navies make extensive use of shotguns by personnel engaged in boarding hostile ships, as any shots fired will almost certainly be over a short range. Nonetheless, shotguns are far less common in military use than rifles, carbines, submachineguns, or pistols.
On the other hand, the shotgun has become a standard in law enforcement use. A variety of specialty less-lethal or non-lethal ammunitions, such as tear gas shells, bean bags, flares, explosive sonic stun rounds, and rubber projectiles, all packaged into 12 gauge shotgun shells, are produced specifically for the law enforcement market. Recently, Taser International introduced a self-contained electronic weapon which is fired from a standard 12 gauge shotgun.
The shotgun remains a standard firearm for hunting throughout the world for all sorts of game from birds and small game to large game such as deer. The versatility of the shotgun as a hunting weapon has steadily increased as slug rounds and more advanced rifled barrels have given shotguns longer range and higher killing power. The shotgun has become a ubiquitous firearm in the hunting community.
Design factors.
Action.
Action is the term for the operating mechanism of a gun. There are many types of shotguns, typically categorized by the number of barrels or the way the gun is reloaded.
Break-action.
For most of the history of the shotgun, the break-action breech loading double was the most common type, typically divided into two subtypes: the traditional "side by side" shotgun features two barrels mounted one beside the other (as the name suggests), whereas the "over and under" shotgun has the two barrels mounted one on top of the other. Side by side shotguns were traditionally used for hunting and other sporting pursuits (early long barreled side-by side shotguns were known as "fowling pieces" for their use hunting ducks and other birds), whereas over and under shotguns are more commonly associated with sporting use (such as clay pigeon and skeet shooting). Both types of double-barrel shotgun are used for hunting and sporting use, with the individual configuration largely being a matter of personal preference.
Another, less commonly encountered type of break-action shotgun is the combination gun, which is an over and under design with one shotgun barrel and one rifle barrel (more often rifle on top, but rifle on bottom was not uncommon). There is also a class of break action guns called "drillings", which contain three barrels, usually two shotgun barrels of the same gauge and a rifle barrel, though the only common theme is that at least one barrel be a shotgun barrel. The most common arrangement was essentially a side by side shotgun with the rifle barrel below and centered. Usually a drilling containing more than one rifle barrel would have both rifle barrels in the same caliber, but examples do exist with different caliber barrels, usually a .22 long rifle and a centerfire cartridge. Although very rare, drillings with three and even four (a "vierling") shotgun barrels were made.
Pump-action.
In pump-action shotguns, a sliding forearm handle (the "pump") works the action, extracting the spent shell and inserting a new one while cocking the hammer or striker as the pump is worked. A pump gun is typically fed from a tubular magazine underneath the barrel, which also serves as a guide for the pump. The rounds are fed in one by one through a port in the receiver, where they are lifted by a lever called the "elevator" and pushed forward into the chamber by the bolt. A pair of latches at the rear of the magazine hold the rounds in place and facilitate feeding of one shell at a time. If it is desired to load the gun fully, a round may be loaded through the ejection port directly into the chamber, or cycled from the magazine, which is then topped off with another round. Well-known examples include the Winchester Model 1897, Remington 870 and Mossberg 500/590.
Pump-action shotguns are common hunting, fowling and sporting shotguns. Hunting models generally have a barrel between 600 and 700 mm (24"-28"). Tube-fed models designed for hunting often come with a dowel rod or other stop that is inserted into the magazine and reduces the capacity of the gun to three shells (two in the magazine and one chambered) as is mandated by U.S. federal law when hunting migratory birds. They can also easily be used with an empty magazine as a single-shot weapon, by simply dropping the next round to be fired into the open ejection port after the spent round is ejected. For this reason, pump-actions are commonly used to teach novice shooters under supervision, as the trainer can load each round more quickly than with a break-action, while unlike a break-action the student can maintain his grip on the gun and concentrate on proper handling and firing of the weapon.
Pump action shotguns with shorter barrels and little or no barrel choke are highly popular for use in home defense, military and law enforcement, and are commonly known as riot guns. The minimum barrel length for shotguns in most of the U.S. is 18 in, and this barrel length (sometimes 18.5 - to increase magazine capacity and/or ensure the gun is legal regardless of measuring differences) is the primary choice for riot shotguns. The shorter barrel makes the weapon easier to maneuver around corners and in tight spaces, though slightly longer barrels are sometimes used outdoors for a tighter spread pattern or increased accuracy of slug projectiles. Home-defense and law enforcement shotguns are usually chambered for 12-gauge shells, providing maximum shot power and the use of a variety of projectiles such as buckshot, rubber, sandbag and slug shells, but 20-gauge (common in bird-hunting shotguns) or .410 (common in youth-size shotguns) are also available in defense-type shotgun models allowing easier use by novice shooters.
A riot shotgun has many advantages over a handgun or rifle. Compared to "defense-caliber" handguns (chambered for 9mm Parabellum, .38 Special, .357 Magnum, .40 S&W, .45 ACP and similar), a shotgun has far more power and damage potential (up to 10 times the muzzle energy of a .45 ACP cartridge), allowing a "one-shot stop" that is more difficult to achieve with typical handgun loads. Compared to a rifle, riot shotguns are easier to maneuver due to the shorter barrel, still provide better damage potential at indoor distances (generally 3–5 meters/yards), and reduce the risk of "overpenetration"; that is, the bullet or shot passing completely through the target and continuing beyond, which poses a risk to those behind the target through walls. The wide spread of the shot reduces the importance of shot placement compared to a single projectile, which increases the effectiveness of "point shooting" - rapidly aiming simply by pointing the weapon in the direction of the target. This allows easy, fast use by novices.
Lever-action.
Early attempts at repeating shotguns invariably centred around either bolt-or lever-action designs, drawing inspiration from contemporary repeating rifles, with the earliest successful repeating shotgun being the lever-action Winchester M1887, designed by John Browning at the behest of the Winchester Repeating Arms Company.
Lever shotguns, while less common, were popular in the late 19th century with the Winchester Model 1887 and Model 1901 being prime examples. Initially very popular, demand waned after the introduction of pump-action shotguns around the start of the 20th century, and production was eventually discontinued in 1920.
One major issue with lever-actions (and to a lesser extent pump-actions) was that early shotgun shells were often made of paper or similar fragile materials (modern hulls are plastic or metal). As a result the loading of shells, or working of the action of the shotgun, could often result in cartridges getting crushed and becoming unusable, or even damaging the gun.
Lever shotguns have seen a return to the gun market in recent years, however, with Winchester producing the Model 9410 (chambering the .410 gauge shotgun shell and using the action of the Winchester Model 94 series lever-action rifle, hence the name), and a handful of other firearm manufacturers (primarily Norinco of China and ADI Ltd. of Australia) producing versions of the Winchester Model 1887/1901 designed for modern 12-gauge smokeless shotshells with more durable plastic casings. There has been a notable uptick in lever-action shotgun sales in Australia since 1997, when pump-actions were effectively outlawed.
Semi-automatic.
Gas, inertia, or recoil operated actions are other popular methods of increasing the rate of fire of a shotgun; these are generally referred to as autoloaders or semi-automatics. Instead of having the action manually operated by a pump or lever, the action automatically cycles each time the shotgun is fired, ejecting the spent shell and reloading a fresh one into the chamber. The first successful semi-automatic shotgun was John Browning's Auto-5, first produced by Fabrique Nationale beginning in 1902. Other well-known examples include the Remington 1100, Benelli M1, and Saiga-12.
Some, such as the Franchi SPAS-12 and Benelli M3, are capable of switching between semi-automatic and pump action. These are popular for two reasons; first, some jurisdictions forbid the use of semi-automatic actions for hunting, and second, lower-powered rounds, like "reduced-recoil" buckshot shells and many less lethal cartridges, have insufficient power to reliably cycle a semi-automatic shotgun.
Bolt-action.
Bolt-action shotguns, while uncommon, do exist. One of the best-known examples is a 12 gauge manufactured by Mossberg featuring a 3-round magazine, marketed in Australia just after changes to the gun laws in 1997 heavily restricted the ownership and use of pump-action and semi-automatic shotguns. They were not a huge success, as they were somewhat slow and awkward to operate, and the rate of fire was noticeably slower (on average) than a double-barrelled gun. The Ishapore Arsenal in India also manufactured a single-shot .410 bore shotgun based on the SMLE Mk III* rifle. The Russian Berdana shotgun was effectively a single-shot bolt-action rifle that became obsolete, and was subsequently modified to chamber 16 gauge shotgun shells for civilian sale. The U.S. military M26 is also a bolt-action weapon. Bolt-action shotguns have also been used in the "goose gun" application, intended to kill birds such as geese at greater range. Typically, goose guns have long barrels (up to 36 inches), and small bolt-fed magazines. Bolt-action shotguns are also used in conjunction with slug shells for the maximum possible accuracy from a shotgun.
Other.
In addition to the commonly encountered shotgun actions already listed, there are also shotguns based on the Martini-Henry rifle design, originally designed by British arms maker W.W. Greener.
Some of the more interesting advances in shotgun technology include the versatile NeoStead 2000 and fully automatics such as the Pancor Jackhammer or Auto-Assault 12.
In 1925, Rodolfo Cosmi produced the first working hybrid prototype semi-automatic shotgun, which had an 8-round magazine located in the stock. While it reloaded automatically after each shot like a semi-automatic, it had a break-action to load the first shell. This design has only been repeated once, by Beretta with their UGB25 automatic shotgun. The user loads the first shell by breaking the gun in the manner of a break-action shotgun, then closes it and inserts the second shell into a clip on the gun's right side. The spent hulls are ejected downwards. The guns combine the advantages of the break action (they can be proven to be safe by breaking open, there are no flying hulls) with those of the semi-automatic (low recoil, low barrel axis position hence low muzzle flip).
Gauge.
The caliber of shotguns is measured in terms of "gauge" (U.S.) or "bore" (U.K.). The gauge number is determined by the weight, in fractions of a pound, of a solid sphere of lead with a diameter equal to the inside diameter of the barrel. So, a 10 gauge shotgun nominally should have an inside diameter equal to that of a sphere made from one-tenth of a pound of lead. By far the most common gauges are 12 (0.729 in, 18.5 mm diameter) and 20 (0.614 in, 15.6 mm), although .410 (= 67), 32, 28, 24, 16, and 10 (19.7 mm) gauge also exist. Ammunition manufacturer CCI produces 9 mm (.355 in.) and several other popular pistol calibers up to .45 ACP as well as .22 (5.5 mm) for firing from handguns. These are commonly called snake shot cartridges. rimfire caliber. Larger gauges, too powerful to shoulder, have been built but were generally affixed to small boats and referred to as punt guns. These were used for commercial water fowl hunting, to kill large numbers of birds resting on the water. Although relatively rare, single and double derringers have also been produced that are capable of firing either .45 (Long) Colt or .410 shotgun shells from the same chamber; they are commonly known as 'snake guns', and are popular among some outdoorsmen in the South and Southwest regions of the United States. There are also some revolvers, such as the Taurus Judge, that are capable of shooting the .45LC/.410 rounds; but as with derringers, these are handguns that shoot .410 shotgun shells, and are not necessarily considered shotguns.
The .410 bore (10.4 mm) is unusual, being measured in inches, and would be approximately 67 "real" gauge, though its short hull versions are nominally called 36 gauge in Europe. It uses a relatively small charge of shot. It is used for hunting and for skeet. Because of its very light recoil (approx 10 N), it is often used as a beginners gun. However, the small charge and typically tight choke make it more difficult to hit targets. It is also frequently used by expert shooters because of the difficulty, especially in expensive side by side and over/under models for hunting small bird game such as quail and doves. Inexpensive bolt-action .410 shotguns are a very common first hunting shotgun among young pre-teen hunters, as they are used mostly for hunting squirrels, while additionally teaching bolt-action manipulation skills that will transfer easily later to adult-sized hunting rifles. Most of these young hunters move up to a 20-gauge within a few years, and to 12 gauge shotguns and full-size hunting rifles by their late teens. Still, many who are particularly recoil-averse choose to stay with 20-gauge shotguns all their adult life, as it is a suitable gauge for many popular hunting uses.
A recent innovation is the back-boring of barrels, in which the barrels are bored out slightly larger than their actual gauge. This reduces the compression forces on the shot when it transitions from the chamber to the barrel. This leads to a slight reduction in perceived recoil, and an improvement in shot pattern due to reduced deformation of the shot.
Shot.
Most shotguns are used to fire "a number of ball shot", in addition to slugs and sabots. The ball shot or pellets is for the most part made of lead but this has been partially replaced by bismuth, steel, tungsten-iron, tungsten-nickel-iron and even tungsten polymer loads. Non-toxic loads are required by Federal law for waterfowl hunting in the US, as the shot may be ingested by the waterfowl, which some authorities believe can lead to health problems due to the lead exposure. Shot is termed either birdshot or buckshot depending on the shot size. Informally, birdshot pellets have a diameter smaller than 5 mm and buckshot are larger than that. Pellet size is indicated by a number; for bird shot this ranges from the smallest 12 (1.2 mm, 0.05 in) to 2 (3.8 mm, 0.15 in) and then BB (4.6 mm, 0.18 in).
For buckshot, the numbers usually start at 4 (6.1 mm, 0.24 in) and go down to 1, 0, 00 ("double aught"), 000, and finally 0000 (9.7 mm, .38 in). A different informal distinction is that "bird shot" pellets are small enough that they can be measured into the cartridge by weight, and simply poured in, whereas "buckshot" pellets are so large they must be stacked inside the cartridge in a fixed geometric arrangement in order to fit. The diameter in hundredths of an inch of bird shot sizes from #9 to #1 can be obtained by subtracting the shot size from 17. Thus, #4 bird shot is 17 - 4 = 13 = 0.13 in in diameter. Different terminology is used outside the United States. In England and Australia, for example, 00 buckshot cartridges are commonly referred to as "S.G." (small game) cartridges.
Pattern and choke.
Shot, small and round and delivered without spin, is ballistically inefficient. As the shot leaves the barrel it begins to disperse in the air. The resulting cloud of pellets is known as the shot pattern, or shotgun shot spread. The ideal pattern would be a circle with an even distribution of shot throughout, with a density sufficient to ensure enough pellets will intersect the target to achieve the desired result, such as a kill when hunting or a break when shooting clay targets. In reality the pattern is closer to a Gaussian, or normal distribution, with a higher density in the center that tapers off at the edges. Patterns are usually measured by firing at a 30 in diameter circle on a large sheet of paper placed at varying distances. The hits inside the circle are counted, and compared to the total number of pellets, and the density of the pattern inside the circle is examined. An "ideal" pattern would put nearly 100% of the pellets in the circle and would have no voids—any region where a target silhouette will fit and not cover 3 or more holes is considered a potential problem.
A constriction in the end of the barrel known as the choke is used to tailor the pattern for different purposes. Chokes may either be formed as part of the barrel at the time of manufacture, by squeezing the end of the bore down over a mandrel, or by threading the barrel and screwing in an interchangeable choke tube. The choke typically consists of a conical section that smoothly tapers from the bore diameter down to the choke diameter, followed by a cylindrical section of the choke diameter. Briley Manufacturing, a maker of interchangeable shotgun chokes, uses a conical portion about 3 times the bore diameter in length, so the shot is gradually squeezed down with minimal deformation. The cylindrical section is shorter, usually 0.6 to. The use of interchangeable chokes has made it easy to tune the performance of a given combination of shotgun and shotshell to achieve the desired performance.
The choke should be tailored to the range and size of the targets. A skeet shooter shooting at close targets might use 127 micrometres (0.005 inches) of constriction to produce a 76 cm diameter pattern at a distance of 19 m. A trap shooter shooting at distant targets might use 762 micrometres (0.030 inches) of constriction to produce a 76 cm diameter pattern at 37 m. Special chokes for turkey hunting, which requires long range shots at the small head and neck of the bird, can go as high as 1500 micrometres (0.060 inches). The use of too much choke and a small pattern increases the difficulty of hitting the target, whereas the use of too little choke produces large patterns with insufficient pellet density to reliably break targets or kill game. "Cylinder barrels" have no constriction. See also: Slug barrel
Other specialized choke tubes exist as well. Some turkey hunting tubes have constrictions greater than "Super Full", or additional features like porting to reduce recoil, or "straight rifling" that is designed to stop any spin that the shot column might acquire when traveling down the barrel. These tubes are often extended tubes, meaning they project beyond the end of the bore, giving more room for things like a longer conical section. Shot spreaders or diffusion chokes work opposite of normal chokes—they are designed to spread the shot more than a cylinder bore, generating wider patterns for very short range use. A number of recent spreader chokes, such as the Briley "Diffusion" line, actually use rifling in the choke to spin the shot slightly, creating a wider spread. The Briley Diffusion uses a 1 in 36 cm twist, as does the FABARM Lion Paradox shotgun.
Oval chokes, which are designed to provide a shot pattern wider than it is tall, are sometimes found on combat shotguns, primarily those of the Vietnam War era. They were available for aftermarket addition in the 1970s from companies like A & W Engineering. Military versions of the Ithaca 37 with "duckbill" choke were used in limited numbers during the Vietnam War by US Navy Seals. It arguably increased effectiveness in close range engagements against multiple targets. Two major disadvantages plagued the system. One was erratic patterning. The second was that the shot would spread too quickly providing a limited effective zone.
Offset chokes, where the pattern is intentionally slightly off of center, are used to change the point of impact. For instance, an offset choke can be used to make a double barrelled shotgun with poorly aligned barrels hit the same spot with both barrels.
Barrel length.
Shotguns generally have longer barrels than modern rifles. Unlike rifles, however, the long shotgun barrel is not for ballistic purposes; shotgun shells use small powder charges in large diameter bores, and this leads to very low muzzle pressures (see internal ballistics) and very little velocity change with increasing barrel length. According to Remington, modern powder in a shotgun burns completely in 25 (9.8425 in) to 36 (14.173 in) cm barrels.
Since shotguns are generally used for shooting at small, fast moving targets, it is important to "lead" the target by firing slightly ahead of the target, so that when the shot reaches the range of the target, the target will have moved into the pattern. On uphill shooting, this means to shoot "above" the target. Conversely, on downhill shooting, this means to shoot "below" the target, which is somewhat counterintuitive for many beginning hunters. Of course, depending on the barrel length, the amount of "lead" employed will vary for different barrel lengths, and must be learned by experience.
Shotguns made for close ranges, where the angular speed of the targets is great (such as skeet or upland bird hunting), tend to have shorter barrels, around 24 to. Shotguns for longer range shooting, where angular speeds are small (trap shooting; quail, pheasant, and waterfowl hunting), tend to have longer barrels, 28 to 34 in. The longer barrels have more angular momentum, and will therefore swing more slowly but more steadily. The short, low angular momentum barrels swing faster, but are less steady. These lengths are for pump or semi-auto shotguns; break open guns have shorter overall lengths for the same barrel length, and so will use longer barrels. The break open design saves between 9 and in overall length, but in most cases pays for this by having two barrels, which adds weight at the muzzle, and so usually only adds a couple of centimetres. Barrels for shotguns have been getting longer as modern steels and production methods make the barrels stronger and lighter; a longer, lighter barrel gives the same inertia for less overall weight.
Shotguns for use against larger, slower targets generally have even shorter barrels. Small game shotguns, for hunting game like rabbits and squirrels, or shotguns for use with buckshot for deer, are often 56 to.
Shotguns intended for all-round hunting are a compromise, of course, but a 72 toch) barrel pump-action 12-gauge shotgun with a modified choke can serve admirably for use as one gun intended for general all-round hunting of small-game such as quails, rabbits, pheasants, doves, and squirrels in semi-open wooded or farmland areas in many parts of the eastern US (Kentucky, Indiana, Tennessee) where dense brush is less of a hindrance and the ability to have more reach is important. For hunting in dense brush, shorter barrel lengths are often preferred when hunting the same types of game.
Ammunition.
The extremely large caliber of shotgun shells has led to a wide variety of different ammunition.
Shotshells are the most commonly used round, filled with lead or lead substitute pellets.
Of this general class, the most common subset is birdshot, which uses a large number (from dozens to hundreds) of small pellets, meant to create a wide "kill spread" to hunt birds in flight. Shot shells are described by the size and number of the pellets within, and numbered in reverse order (the smaller the number, the bigger the pellet size, similar to bore gauge). Size nine (#9) shot is the smallest size normally used for hunting and is used on small upland game birds such as dove and quail. Larger sizes are used for hunting larger upland game birds and waterfowl.
Buckshot is similar to but larger than birdshot, and was originally designed for hunting larger game, such as deer (hence the name). While the advent of new, more accurate slug technologies is making buckshot less attractive for hunting, it is still the most common choice for police, military, and home defense uses. Like birdshot, buckshot is described by pellet size, with larger numbers indicating smaller shot. From the smallest to the largest, buckshot sizes are: #4, (called "number four"), #1, 0 ("one-aught"), 00 ("double-aught"), 000 ("triple-aught") and 0000 ("four-aught"). A typical round for defensive use would be a 12 gauge 2+3/4 in length 00 buck shell, which contains 9 pellets roughly 8.4 mm (.33 inch) in diameter, each comparable to a .38 Special bullet in damage potential. New "tactical" buckshot rounds, designed specifically for defensive use, use slightly fewer shot at lower velocity to reduce recoil and increase controllability of the shotgun. There are some shotgun rounds designed specifically for police use that shoot effectively from 50 yd with a 20" diameter grouping of the balls.
Slug rounds are rounds that fire a single solid slug. They are used for hunting large game, and in certain military and law enforcement applications. Modern slugs are moderately accurate, especially when fired from special rifled slug barrels. They are often used in "shotgun-only" hunting zones near inhabited areas, where rifles are prohibited due to their greater range.
Sabots are a common type of slug round. While some slugs are exactly that—a 12-gauge metal projectile in a cartridge—a sabot is a smaller but more aerodynamic projectile surrounded by a "shoe" of some other material. This "sabot" jacket seals the barrel, increasing pressure and acceleration, while also inducing spin on the projectile in a rifled barrel. Once the projectile clears the barrel, the sabot material falls away, leaving an unmarked, aerodynamic bullet to continue toward the target. The advantages over a traditional slug are increased shot power, increased bullet velocity due to the lighter-mass bullet, and increased accuracy due to the velocity and the reduction in deformation of the slug itself. Disadvantages versus a traditional slug include lower muzzle momentum due to reduced mass, reduced damage due to smaller bullet diameter, and significantly higher per-unit cost.
Specialty ammunition.
The unique properties of the shotgun, such as large case capacity, large bore, and the lack of rifling, has led to the development of a large variety of specialty shells, ranging from novelties to high tech military rounds.
Hunting, defensive, and military.
Brenneke and Foster type slugs have the same basic configuration as normal slugs, but have increased accuracy. The hollowed rear of the Foster slug improves accuracy by placing more mass in the front of the projectile, therefore inhibiting the "tumble" that normal slugs may generate. The Brenneke slug takes this concept a bit further, with the addition of a wad that stays connected to the projectile after discharge, increasing accuracy. Both slugs are commonly found with fins or rib, which are meant to allow the projectile to safely squeeze down during passage through chokes, but they do not increase stability in flight.
Flechette rounds contain aerodynamic darts, typically from 8 to 20 in number. The flechette provide greatly extended range due to their aerodynamic shape, and improved penetration of light armor. American troops during the Vietnam War packed their own flechette shotgun rounds, called "beehive rounds", after the similar artillery rounds. However, terminal performance was poor due to the very light weight of the flechettes, and their use was quickly dropped.
Frag-12 shotgun rounds are a series of special purpose shotgun grenades, including high explosive blast, fragmentation, and HEAP grenades intended to be fired from any 12-ga shotgun. They are distinguished from regular shotgun rounds by a green hull. It has been proposed as an armament for modern UAVs and is currently being tested for military deployment.
Grenade rounds use exploding projectiles to increase long range lethality. These are currently experimental, but the British FRAG-12, which comes in both armor penetrating and fragmentary forms, is under consideration by military forces.
Less lethal rounds, for riot and animal control.
Flexible baton rounds, commonly called "bean bags", fire a fabric bag filled with birdshot or a similar loose, dense substance. The "punch" effect of the bag is useful for knocking down targets; the rounds are used by police to subdue violent suspects. The bean bag round is by far the most common less lethal round used. Due to the large surface area of these rounds, they lose velocity rapidly, and must be used at fairly short ranges to be effective, though use at extremely short ranges, under 3 m, can result in broken bones or other serious or lethal injuries. The rounds can also fly in a frisbee-like fashion and cut the person or animal being fired at. For this reason, these types of rounds are referred to as less lethal, as opposed to less-than-lethal.
Gas shells spray a cone of gas for several meters. These are primarily used by riot police. They normally contain pepper gas or tear gas. Other variations launch a gas-grenade-like projectile.
Rock salt shells are hand loaded with coarse rock salt crystals, replacing the standard lead or steel shot. Rock salt shells could be seen as the forerunners of modern less-lethal rounds. In the United States, rock salt shells were and are sometimes still used by rural civilians to defend their property. The brittle salt was unlikely to cause serious injury at long ranges, but would cause painful stinging injuries and served as a warning. British gamekeepers have used rock salt shells to deter poachers. Rather than get into a physical confrontation, they stalk the poachers, making themselves known by a loud shout of "Run!" just before firing, to avoid hitting the now-fleeing subject in the eyes.
Rubber slugs or rubber buckshot are similar in principle to the bean bag rounds. Composed of flexible rubber or plastic and fired at low velocities, these rounds are probably the most common choice for riot control.
Taser International announced in 2007 a new 12 gauge eXtended Range Electronic Projectile or XREP, which contains a small electroshock weapon unit in a carrier that can be fired from a standard 12 gauge shotgun. The XREP projectile is fin stabilized, and travels at an initial velocity of 100 m/s (300 ft/s). Barbs on the front attach the electroshock unit to the target, with a tassel deploying from the rear to widen the circuit. A twenty-second burst of electrical energy is delivered to the target. This product is expected to be released to market in 2008. They were used — despite still being subject to testing, in breach of the supplier's license — by Northumbria police in their standoff with Raoul Moat in 2010.
Breaching rounds, often called Frangible, Disintegrator, or Hatton rounds, are designed to destroy door locking mechanisms without risking lives. They are constructed of a very brittle substance that transfers most of the energy to the primary target but then fragment into much smaller pieces or dust so as not to injure unseen targets such as hostages or non-combatants that may be standing behind a breached door.
Bird bombs are low-powered rounds that fire a firecracker that is fused to explode a short time after firing. They are designed to scare animals, such as birds that congregate on airport runways.
Screechers fire a pyrotechnic whistle that emits a loud whistling sound for the duration of its flight. These are also used to scare animals.
Blank shells contain only a small amount of powder and no actual load. When fired, the blanks provide the sound and flash of a real load, but with no projectile. These may be used for simulation of gunfire, scaring wildlife, or as power for a launching device such as the Mossberg #50298 marine line launcher.<ref</ref>
Stinger is a type of shotgun shell which contains 16-00 buck balls made of zytel, and is designed as a non-lethal ammunition ideally used in small spaces.
Novelty and other.
Bolo rounds are made of two or more slugs molded onto steel wire. When fired, the slugs separate, pulling the wire taut creating a flying blade, which could theoretically decapitate people and animals or amputate limbs. However, many active shotgun users consider this to be overstated, and view bolo shells as being less effective than conventional ammunition. Bolo shell rounds are banned in many locations (including the US states of Florida and Illinois) due to concerns about their potential lethality. The round is named in reference to bolas, which use two or more weighted balls on a rope to trap cattle or game.
Dragon's Breath usually refers to a zirconium-based pyrotechnic shotgun round. When fired, a gout of flame erupts from the barrel of the gun (up to 20 ft). The visual effect it produces is impressive, similar to that of a short ranged flamethrower. However, it has few tactical uses, mainly distraction/disorientation.
Flare rounds are sometimes carried by hunters for safety and rescue purposes. They are available in low and high altitude versions. Some brands claim they can reach a height of up to 200 m.
Legal issues.
Globally, shotguns are generally not as heavily regulated as rifles or handguns, likely because they lack the range of rifles and are not easily concealable as handguns are; thus, they are perceived as a lesser threat by legislative authorities. The one exception is a sawed-off shotgun, especially a Lupara, as it is more easily concealed than a normal shotgun.
Australia.
Within Australia, all shotguns manufactured after January 1, 1901 are considered firearms and are subject to registration and licensing. Most shotguns (including break-action, bolt-action and lever-action shotguns) are classed as "Category A" weapons and, as such, are comparatively easy to obtain a licence for, given a legally recognised 'legitimate reason' (compare to the British requirement for 'good reason' for a FAC), such as target shooting or hunting. However, pump-action and semi-automatic shotguns are classed as "Category C" weapons; a licence for this type of firearm is, generally speaking, not available to the average citizen. For more information, see Gun politics in Australia.
Canada.
Canada has three classifications of firearms: non-restricted, restricted, and prohibited. Shotguns are found in all three classes.
All non-restricted shotguns must have an overall length of 660 mm. Semi-automatic shotguns must also have a barrel length of more than 470 mm and have a capacity of 5 shells or less in the magazine to remain non-restricted. All other shotgun action types (pump/slide, break open, lever, bolt) do not have a magazine limit restriction or a minimum barrel length provided the overall length of the firearm remains more than 660 mm and the barrel was produced by an approved manufacturer. Shotgun barrels may only be reduced in length to a minimum of 457 mm. Non-restricted shotguns may be possessed with any Possession and Acquisition Licence (PAL) or Possession-Only License (POL) and may be transported throughout the country without special authorization and may be used for hunting certain species at certain times of the year.
Semi-automatic shotguns with a barrel length of less than 470 mm are considered restricted and any shotgun that has been altered so its barrel length is less than 457 mm or if its overall length is less than 660 mm is considered prohibited. Restricted and prohibited shotguns may be possessed with a PAL or POL than has been endorsed for restricted or prohibited grandfathered firearms. These shotguns require special Authorization to Transport (ATT).
The Canadian Firearms Registry was a government-run registry of all legally owned firearms in Canada. The government provided amnesty from prosecution to shotgun and rifle owners if they fail to register non-restricted shotguns and rifles. The long gun portion of the registry was scrapped in 2011.
See online for an official Canadian list of non-restricted and restricted and prohibited firearms.
UK.
In the United Kingdom, a Shotgun Certificate (SGC) is required to possess a "Section 2" shotgun. These cost £50 and can only be denied if the chief of police in the area believes and can prove that the applicant poses a real danger to the public, or if the applicant has been convicted of a crime punishable by imprisonment for a term of three years or more or if the applicant cannot securely store a shotgun (gun clamps, wire locks and locking gun cabinets are considered secure). The round number restrictions apply only to the magazine, not the chamber, so it is legal to have a single-barreled semi-auto or pump-action shotgun that holds three rounds in total, or a shotgun with separate chambers (which would need to also be multi-barrelled). For a shotgun to qualify as a section 2 shotgun, it must meet the following criteria:
(a) has a barrel not less than 24 in in length and does not have any barrel with a bore more than 2 in in diameter;
(b) either has no magazine or has a non-detachable magazine not capable of holding more than two cartridges;
(c) is not a revolver gun.
Prior to a SGC being issued an interview is conducted with the local Firearms Officer, in the past this was a duty undertaken by the local police although more recently this function has been "contracted out" to civilian staff. The officer will check the location and suitability of the gun safe that is to be used for storage and conduct a general interview to establish the reasons behind the applicant requiring a SGC.
An SGC holder can own any number of shotguns meeting these requirements so long as he/she can store them securely. No certificate is required to own shotgun ammunition, but one is required to buy it. There is no restriction on the amount of shotgun ammunition that can be bought or owned. There are also no rules regarding the storage of ammunition.
However, shotgun ammunition which contains fewer than 6 projectiles requires a section 1 Firearms Certificate (FAC). Shotguns with a magazine capacity greater than 2 rounds are also considered to be section 1 firearms and, as such, require an FAC to own. An FAC costs £50 but is much more restrictive than an SGC. The applicant must nominate two referees who are known to the applicant to vouch for his or her character; a new 'variation' is required for each new caliber of gun to be owned; limits are set on how much ammunition a person can own at any one time; and an FAC can be denied if the applicant does not have sufficient 'good reason'. 'Good reason' generally means hunting, collecting, or target shooting - though other reasons may be acceptable, personal defence is not an acceptable reason.
Any pump-action or semi-automatic smooth-bore gun (such as a shotgun) with a barrel length of less than 24 inches or total length of less than 40 inches is considered to be a section 5 firearm, that is, one that is subject to general prohibition, unless it is chambered for .22 caliber rimfire ammunition.
US.
In the US, federal law prohibits shotguns from being capable of holding more than three shells including the round in the chamber when used for hunting migratory gamebirds such as doves, ducks, and geese. For other uses, a capacity of any number of shells is generally permitted. Most magazine-fed shotguns come with a removable magazine plug to limit capacity to 2, plus one in the chamber, for hunting migratory gamebirds. Certain states have restrictions on magazine capacity or design features under hunting or assault weapon laws.
Shotguns intended for defensive use have barrels as short as 18 in for private use (the minimum shotgun barrel length allowed by law in the United States without federal registration. Barrel lengths of less than 18 in as measured from the breechface to the muzzle when the weapon is in battery, or have an overall length of less than 26 in are classified as short barreled shotguns (SBS) under the 1934 National Firearms Act and are regulated. A similar short barreled weapon having a pistol grip may be classified as an AOW or "Any Other Weapon". A shotgun is defined as a weapon (with a buttstock) designed to be fired from the shoulder. The classification varies depending on how the weapon was originally manufactured.
Shotguns used by military, police, and other government agencies are regulated under the National Firearms Act of 1934; however, they are exempt from transfer taxes. These weapons commonly have barrels as short as 12 to so that they are easier to handle in confined spaces. Non-prohibited private citizens may own short-barreled shotguns by passing extensive background checks (state and local laws may be more restrictive) as well as paying a $200 federal tax and being issued a stamp. Defensive shotguns sometimes have no buttstock or will have a folding stock to reduce overall length even more when required. AOWs transfer with a $5 tax stamp from the BATFE.

</doc>
<doc id="26840" url="http://en.wikipedia.org/wiki?curid=26840" title="Saskatchewan">
Saskatchewan

Saskatchewan ( or ) is a prairie province in Canada, which has a total area of 651900 km2 and a land area of 592534 km2, the remainder being water area (covered by lakes/ponds, reservoirs and rivers). Saskatchewan is bordered on the west by the Province of Alberta, on the north by the Northwest Territories, on the east by Manitoba, and on the south by the U.S. states of Montana and North Dakota. As of December 2013, the population of Saskatchewan was estimated at 1,114,170. Residents primarily live in the southern half of the province. Of the total population, 257,300 live in the province's largest city, Saskatoon, while 210,000 live in the provincial capital, Regina. Other major cities include Prince Albert, Moose Jaw, Yorkton, Swift Current, and North Battleford.
Saskatchewan has been inhabited for thousands of years by various indigenous groups, and first explored by Europeans in 1690 and settled in 1774. It became a province in 1905, its name derived from the Saskatchewan River. The river was known as "kisiskāciwani-sīpiy" ("swift flowing river") in the Cree language. In the early 20th century the province became known as a stronghold for Canadian democratic socialism. Tommy Douglas, who was premier from 1944 to 1961, became the first social-democratic politician to be elected in North America. The province's economy is based on agriculture, mining, and energy. Saskatchewan's current premier is Brad Wall and its lieutenant-governor is Vaughn Solomon Schofield.
In 1992, the federal and provincial governments signed a historic land claim agreement with Saskatchewan First Nations. The First Nations received compensation and were permitted to buy land on the open market for the tribes; they have acquired about 3079 km2, now reserve lands. Some First Nations have used their settlement to invest in urban areas, including Saskatoon.
Geography.
As Saskatchewan's borders largely follow the geographic coordinates of longitude and latitude, the province is roughly a quadrilateral, or a shape with four sides. However the 49th parallel boundary and the 60th northern border appear curved on maps and globes. Additionally, the eastern boundary of the province is partially crooked rather than following a line of longitude, as correction lines were devised by surveyors prior to the homestead program (1880–1928).
Saskatchewan is part of the Western Provinces and is bounded on the west by Alberta, on the north by the Northwest Territories, on the north-east by Nunavut, on the east by Manitoba, and on the south by the American states of Montana and North Dakota. Saskatchewan has the distinction of being the only Canadian province for which no borders correspond to physical geographic features (i.e. they are all parallels and meridians). Along with Alberta, Saskatchewan is one of only two provinces that are land-locked.
The overwhelming majority of Saskatchewan's population is located in the southern third of the province, south of the 53rd parallel.
Saskatchewan contains two major natural regions: the Canadian Shield in the north and the Interior Plains in the south. Northern Saskatchewan is mostly covered by boreal forest except for the Lake Athabasca Sand Dunes, the largest active sand dunes in the world north of 58°, and adjacent to the southern shore of Lake Athabasca. Southern Saskatchewan contains another area with sand dunes known as the "Great Sand Hills" covering over 300 km2. The Cypress Hills, located in the southwestern corner of Saskatchewan and Killdeer Badlands (Grasslands National Park), are areas of the province that remained unglaciated during the last glaciation period.
The province's highest point, at 1392 m, is located in the Cypress Hills less than 2 km from the provincial boundary with Alberta. The lowest point is the shore of Lake Athabasca, at 213 m. The province has 14 major drainage basins made up of various rivers and watersheds draining into the Arctic Ocean, Hudson Bay and the Gulf of Mexico.
Climate.
Saskatchewan receives more hours of sunshine than any other Canadian province. The province lies far from any significant body of water. This fact, combined with its northerly latitude, gives it a warm summer, corresponding to its humid continental climate (Köppen type "Dfb") in the central and most of the eastern parts of the province, as well as the Cypress Hills; drying off to a semi-arid steppe climate (Köppen type "BSk") in the southwestern part of the province. Drought can affect agricultural areas during long periods with little or no precipitation at all. The northern parts of Saskatchewan – from about La Ronge northward – have a subarctic climate (Köppen "Dfc") with a shorter summer season. Summers can get very hot, sometimes above 38 °C during the day, and with humidity decreasing from northeast to southwest. Warm southern winds blow from the plains and intermontane regions of the Western United States during much of July and August, very cool or hot but changeable air masses often occur during spring and in September. Winters are usually bitterly cold, with frequent Arctic air descending from the north. with high temperatures not breaking -17 °C for weeks at a time. Warm chinook winds often blow from the west, bringing periods of mild weather. Annual precipitation averages 30 to 45 centimetres (12 to 18 inches) across the province, with the bulk of rain falling in June, July, and August.
Saskatchewan is one of the most tornado-active parts of Canada, averaging roughly 12 to 18 tornadoes per year, some violent. In 2012, 33 tornadoes were reported in the province. The Regina Cyclone, took place in June 1912 when 28 people died in a F4 Fujita scale tornado. Severe and non-severe thunderstorm events occur in Saskatchewan, usually from early spring to late summer. Hail, strong winds and isolated tornadoes are a temporary occurrence.
The hottest temperature ever recorded anywhere in Canada happened in Saskatchewan. The temperature rose to 45 degrees Celsius in Midale and Yellow Grass. The coldest ever recorded in the province was −56.7 degrees Celsius in Prince Albert, which is north of Saskatoon.
History.
Saskatchewan has been populated by various indigenous peoples of North America, including members of the Sarcee, Niitsitapi, Atsina, Cree, Saulteaux, Assiniboine (Nakoda), Lakota and Sioux. The first known European to enter Saskatchewan was Henry Kelsey in 1690, who travelled up the Saskatchewan River in hopes of trading fur with the province's indigenous peoples. The first permanent European settlement was a Hudson's Bay Company post at Cumberland House, founded in 1774 by Samuel Hearne. In 1762 the south of the province was part of the Spanish Louisiana until 1802.
In 1803 the Louisiana Purchase transferred from France to the United States part of what is now Alberta and Saskatchewan. In 1818 it was ceded to the United Kingdom. Most of what is now Saskatchewan, though, was part of Rupert's Land and controlled by the Hudson's Bay Company, which claimed rights to all watersheds flowing into Hudson Bay, including the Saskatchewan, Churchill, Assiniboine, Souris, and Qu'Appelle River systems.
In the late 1850s and early 1860s, scientific expeditions led by John Palliser and Henry Youle Hind explored the prairie region of the province.
In 1870, Canada acquired the Hudson's Bay Company's territories and formed the North-West Territories to administer the vast territory between British Columbia and Manitoba. The Crown also entered into a series of numbered treaties with the indigenous peoples of the area, which serve as the basis of the relationship between First Nations, as they are called today, and the Crown. Since the late twentieth century, land losses and inequities as a result of those treaties have been subject to negotiation for settlement between the First Nations in Saskatchewan and the federal government, in collaboration with provincial governments.
In 1885, post-Confederation Canada's first "naval battle" was fought in Saskatchewan, when a steamship engaged the Métis at Batoche in the North-West Rebellion.
A seminal event in the history of what was to become Western Canada was the 1874 "March West" of the federal government's new North-West Mounted Police. Despite poor equipment and lack of provisions, the men on the march persevered and established a federal presence in the new territory. Historians have argued that had this expedition been unsuccessful, the expansionist United States would have been tempted to expand into the political vacuum. The construction of the Canadian Pacific Railway would likely have been delayed or taken a different, more northerly route, stunting the early growth of towns like Brandon, Regina, Medicine Hat and Calgary – had these existed at all. Failure to construct the railway could also have forced British Columbia to join the United States.
In 1876, following their defeat of United States Army forces at the Battle of the Little Bighorn in Montana Territory in the United States, the Lakota Chief Sitting Bull led several thousand of his people to Wood Mountain. Survivors and descendants founded Wood Mountain Reserve in 1914.
European-Canadian settlement of the province started to take off as the Canadian Pacific Railway was built in the early 1880s, and the Canadian government divided up the land by the Dominion Land Survey and gave free land to any willing settlers.
The North-West Mounted Police set up several posts and forts across Saskatchewan, including Fort Walsh in the Cypress Hills, and Wood Mountain Post in south-central Saskatchewan near the United States border.
Many Métis people, who had not been signatories to a treaty, had moved to the Southbranch Settlement and Prince Albert district north of present-day Saskatoon following the Red River Rebellion in Manitoba in 1870. In the early 1880s, the Canadian government refused to hear the Métis' grievances, which stemmed from land-use issues. Finally, in 1885, the Métis, led by Louis Riel, staged the North-West Rebellion and declared a provisional government. They were defeated by a Canadian militia brought to the Canadian prairies by the new Canadian Pacific Railway. Riel, who surrendered and was convicted of treason in a packed Regina courtroom, was hanged on November 16, 1885. Since then, the government has recognized the Métis as an aboriginal people with status rights, and provided them with various benefits related to that status.
20th century.
As more settlers came to the prairies on the railway, the population grew. On September 1, 1905, Saskatchewan became a province, with inauguration day held September 4. The Dominion Lands Act permitted settlers to acquire one quarter of a square mile of land to homestead and offered an additional quarter upon establishing a homestead. Immigration peaked in 1910, and in spite of the initial difficulties of frontier life – distance from towns, sod homes, and backbreaking labour – new settlers established a European-Canadian style of prosperous agrarian society.
In 1913, the Saskatchewan Stock Growers Association was established as Saskatchewan's first ranchers' organization. At its founding convention in 1913, the members established three goals: to watch over legislation; to forward the interests of the stock growers in every honourable and legitimate way; and to suggest to parliament legislation to meet changing conditions and requirements. Its farming equivalent, the Saskatchewan Grain Growers Association, was the dominant political force in the province until the 1920s; it had close ties with the governing Liberal party.
In the late 1920s, the Ku Klux Klan, imported from the United States and Ontario, gained brief popularity in nativist circles in Saskatchewan and Alberta. The Klan, briefly allied with the provincial Conservative party because of their mutual dislike for Premier James G. "Jimmy" Gardiner and his Liberals (who ferociously fought the Klan), enjoyed about two years of prominence. It declined and disappeared, subject to widespread political and media opposition, plus internal scandals involving the use of the organization's funds.
In 1970, the first annual Canadian Western Agribition was held in Regina. This farm-industry trade show, with its strong emphasis on livestock, is rated as one of the five top livestock shows in North America, along with those in Houston, Denver, Louisville and Toronto.
The province celebrated the 75th anniversary of its establishment in 1980, with Princess Margaret, Countess of Snowdon, presiding over the official ceremonies. In 2005, 25 years later, her sister, Queen Elizabeth II, attended the events held to mark Saskatchewan's centennial.
Since the late 20th century, First Nations have become more politically active in seeking justice for past inequities, especially related to government taking of indigenous lands. The federal and provincial governments have negotiated on numerous land claims, and developed a program of "Treaty Land Entitlement", enabling First Nations to buy land to be taken into reserves with money from settlements of claims.
"In 1992, the federal and provincial governments signed an historic land claim agreement with Saskatchewan First Nations. Under the Agreement, the First Nations received money to buy land on the open market. As a result, about 761,000 acres have been turned into reserve land and many First Nations continue to invest their settlement dollars in urban areas", including Saskatoon. The money from such settlements has enabled First Nations to invest in businesses and other economic infrastructure.
Demographics.
According to the Canada 2011 Census, the largest ethnic group in Saskatchewan is German (28.6%), followed by English (24.9%), Scottish (18.9%), Canadian (18.8%), Irish (15.5%), Ukrainian (13.5%), French (Fransaskois) (12.2%), First Nations (12.1%), Norwegian (6.9%), and Polish (5.8%).
The largest denominations by number of adherents according to the 2001 census were the Roman Catholic Church with 286,815 (30%); the United Church of Canada with 187,450 (20%); and the Lutherans with 78,520 (8%). 148,535 (15.4%) responded "no religion".
Municipalities.
Saskatoon skyline and the South Saskatchewan River
Ten largest municipalities by population
This list does not include Lloydminster, which has a total population of 27,804 but straddles the Alberta–Saskatchewan border. As of 2011, 9,772 people lived on the Saskatchewan side, which would make it Saskatchewan's 10th largest municipality. All of the listed communities are considered cities by the province, with the exception of Corman Park, which is a rural municipality. Municipalities in the province with a population of 5,000 or more can receive official city status.
Economy.
Historically, Saskatchewan's economy was primarily associated with agriculture. However, increasing diversification has resulted in agriculture, forestry, fishing, and hunting only making up 6.8% of the province's GDP. Saskatchewan grows a large portion of Canada's grain. Wheat is the most familiar crop and the one most often associated with the province (there are sheafs of wheat depicted on the coat of arms of Saskatchewan), but other grains like canola, flax, rye, oats, peas, lentils, canary seed, and barley are also produced. Beef cattle production in the province is only exceeded by Alberta. In the northern part of the province, forestry is also a significant industry.
Mining is a major industry in the province, with Saskatchewan being the world's largest exporter of potash and uranium.
Oil and natural gas production is also a very important part of Saskatchewan's economy, although the oil industry is larger. Among Canadian provinces, only Alberta exceeds Saskatchewan in overall oil production. Heavy crude is extracted in the Lloydminster-Kerrobert-Kindersley areas. Light crude is found in the Kindersley-Swift Current areas as well as the Weyburn-Estevan fields. Natural gas is found almost entirely in the western part of Saskatchewan, from the Primrose Lake area through Lloydminster, Unity, Kindersley, Leader, and around Maple Creek areas.
Saskatchewan's GDP in 2006 was approximately C$45.922 billion, with economic sectors breaking down in the following way:
A list of the companies includes The Potash Corporation of Saskatchewan, Federated Cooperatives Ltd. and IPSCO.
Major Saskatchewan-based Crown corporations are Saskatchewan Government Insurance (SGI), SaskTel, SaskEnergy (the province's main supplier of natural gas), and SaskPower. Bombardier runs the NATO Flying Training Centre at 15 Wing, near Moose Jaw. Bombardier was awarded a long-term contract in the late 1990s for $2.8 billion from the federal government for the purchase of military aircraft and the running of the training facility. SaskPower since 1929 has been the principal supplier of electricity in Saskatchewan, serving more than 451,000 customers and managing $4.5 billion in assets. SaskPower is a major employer in the province with almost 2,500 permanent full-time staff located in 71 communities.
Provincial finances.
The Tabulated Data covers each fiscal year (e.g. 2012–2013 covers April 1, 2012 – March 31, 2013).
All data is in $1,000s.
1 These values reflect the estimated population at the beginning of the fiscal year.
2 These values reflect the debt of the General Revenue Fund alone at the end of the fiscal year. They do not reflect the debt of Government Service Organizations (Health Authorities, Crop Insurance Corporation, etc.).
3 These values reflect the combined debt of the Government Service Enterprises (Crown Corporations) at the end of the fiscal year. SaskPower, SaskEnergy, and SaskTel account for 62.3%, 18.2%, and 12.1% of Crown Debt, respectively (as of March 31, 2013).
4 The highest rate of provincial corporate income tax was reduced from 17% to 14% on July 1, 2006. It was further reduced to 13% on July 1, 2007, and finally to 12% on July 1, 2008. The tax on paid-up capital was reduced from 0.6% to 0.3% on July 1, 2006, to 0.15% on July 1, 2007, and abolished altogether on July 1, 2008. These displayed values were obtained by adding the corporate income tax for each year with the corporate capital tax.
5 The Provincial Sales Tax (PST) rate was reduced from 7% to 5% on October 28, 2006.
6 These values are the credit ratings from Standard & Poor's as of the end of the Fiscal Year.
"Source: Government of Saskatchewan."
Government and politics.
Saskatchewan has the same form of government as the other Canadian provinces with a lieutenant-governor (who is the representative of the Crown in Right of Saskatchewan), premier, and a unicameral legislature.
For many years, Saskatchewan was one of Canada's more progressive provinces, reflecting many of its citizens' feelings of alienation from the interests of large capital. In 1944 Tommy Douglas became premier of the first avowedly socialist regional government in North America. Most of his Members of the Legislative Assembly (MLAs) represented rural and small-town ridings. Under his Cooperative Commonwealth Federation government, Saskatchewan became the first province to have Medicare. In 1961, Douglas left provincial politics to become the first leader of the federal New Democratic Party.
Provincial politics in Saskatchewan is dominated by the social-democratic New Democrats and the centre-right Saskatchewan Party, with the latter holding the majority in the Legislative Assembly of Saskatchewan as of 2012. Numerous smaller political parties also run candidates in provincial elections, including the Green Party, Liberal Party, and the Progressive Conservative Party, but none is currently represented in the Legislative Assembly (Liberals and Conservatives generally caucus under the Saskatchewan Party banner in provincial affairs). After 16 years of New Democratic governments under premiers Roy Romanow and Lorne Calvert, the 2007 provincial election was won by the Saskatchewan Party under Brad Wall. In the 2011 election, Premier Wall and the Saskatchewan Party were returned with an increased majority.
Recent federal elections have been dominated by the Conservative Party since the party currently represents 13 of 14 federal ridings in Saskatchewan, while the Liberal Party of Canada represents one federal riding.
While both Saskatoon and Regina (Saskatchewan's largest cities) are roughly twice the population of an urban riding in Canada, both are (as of the 2011 federal election) split into multiple ridings that blend them with rural communities.
Education.
The first education on the prairies took place within the family groups of the First Nation and early fur trading settlers. There were only a few missionary or trading post schools established in Rupert's Land – later known as the North West Territories.
The first 76 North-West Territories school districts and the first Board of Education meeting formed in 1886. The pioneering boom formed ethnic bloc settlements. Communities were seeking education for their children similar to the schools of their home land. Log cabins, and dwellings were constructed for the assembly of the community, school, church, dances and meetings.
The prosperity of the Roaring Twenties and the success of farmers in proving up on their homesteads helped provide funding to standardize education. Text books, normal schools for educating teachers, formal school curricula and state of the art school house architectural plans provided continuity throughout the province. English as the school language helped to provide economic stability, because one community could communicate with another and goods could be traded and sold in a common language. The number of one-room school house districts across Saskatchewan totalled approximately 5,000 at the height of this system of education in the late 1940s. 
Following World War II, the transition from many one-room school houses to fewer and larger consolidated modern technological town and city schools occurred as a means of ensuring technical education. School buses, highways, and family vehicles create ease and accessibility of a population shift to larger towns and cities. Combines and tractors mean that the farmer could successfully manage more than a quarter section of land, so there was a shift from family farms and subsistence crops to cash crops grown on many sections of land.
School vouchers have been newly proposed as a means of allowing competition between rural schools and making the operation of co-operative schools practicable in rural areas.
Healthcare.
The Ministry of Health (Saskatchewan) is responsible for policy direction, sets and monitors standards, and provides funding for regional health authorities and provincial health services.
Saskatchewan's medical health system is widely and inaccurately characterized as "socialized medicine": medical practitioners in Saskatchewan, as in other Canadian provinces, are not civil servants but remit their accounts to the publicly funded Saskatchewan Medical Care Insurance Plan rather than to patients (i.e. a single-payer system).
Saskatchewan medical health system has faced criticism due to a lack of accessibility to the midwifery program. According to Leanne Smith, the director for maternal services in the Saskatoon Health Region declared that half of the women who apply for the midwifery program are turned away. Ministry of Health data shows that midwives saw 1,233 clients in the 2012-13 fiscal year (which runs April to March). But in that fourth quarter, 359 women were still on waiting lists for immediate or future care. The provincial Health Ministry received 47 letters about midwifery services in 2012, most of which asked for more midwives. As a continuing problem in the Saskatchewan health care system, more pressure has been placed to recruit more midwives for the province.
Transportation.
Transportation in Saskatchewan includes an infrastructure system of roads, highways, freeways, airports, ferries, pipelines, trails, waterways and railway systems serving a population of approximately 1,003,299 (according to 2007 estimates) inhabitants year-round. It is funded primarily with local and federal government funds. The Saskatchewan Department of Highways and Transportation estimates that 80% of traffic is carried on the 5,031-kilometre principal system of highways.
The Ministry of Highways and Infrastructure operates over 26000 km of highways and divided highways. There are also municipal roads which comprise different surfaces. Asphalt concrete pavements comprise almost 9000 km, granular pavement almost 5000 km, non structural or thin membrane surface TMS are close to 7000 km and finally gravel highways make up over 5600 km through the province. In the northern sector, ice roads which can only be navigated in the winter months comprise another approximately 150 km of travel.
Saskatchewan has over 250,000 kilometres (150,000 mi) of roads and highways, the highest amount of road surface of any Canadian province. The major highways in Saskatchewan are the Trans Canada expressway, Yellowhead Highway northern Trans Canada route, Louis Riel Trail, CanAm Highway, Red Coat Trail, Northern Woods and Water route, and Saskota travel route.
The first Canadian transcontinental railway was constructed by the Canadian Pacific Railway between 1881 and 1885. After the great east-west transcontinental railway was built, north-south connector branch lines were established.
The 1920s saw the largest rise in rail line track as the CPR and CNR fell into competition to provide rail service within ten kilometres. In the 1960s there were applications for abandonment of branch lines. Today the only two passenger rail services in the province are "The Canadian" and Winnipeg – Churchill train, both operated by Via Rail. "The Canadian" is a transcontinental service linking Toronto with Vancouver.
The main Saskatchewan waterways are the North Saskatchewan River or South Saskatchewan River routes. In total, there are 3,050 bridges maintained by the Department of Highways in Saskatchewan. There are currently twelve ferry services operating in the province, all under the jurisdiction of the Department of Highways.
The Saskatoon Airport (YXE) was initially established as part of the Royal Canadian Air Force training program during World War II. It was renamed the "John G. Diefenbaker Airport" in the official ceremony, June 23, 1993. "Roland J. Groome Airfield" is the official designation for the Regina International Airport (YQR) as of August 3, 2005; the airport was established in 1930. Under the British Commonwealth Air Training Plan (BCATP), twenty Service Flying Training Schools (RAF) were established at various Saskatchewan locations in World War II. 15 Wing Moose Jaw is home to the Canadian Forces formation aerobatics team, the "Snowbirds".
Airlines offering service to Saskatchewan are Air Canada, WestJet Airlines, United Airlines, Delta Air Lines, Transwest Air, Norcanair Airlines, La Ronge Aviation Services Ltd, La Loche Airways, Osprey Wings Ltd, Buffalo Narrows Airways Ltd, Skyservice Airlines, Île-à-la-Crosse Airways Ltd, Voyage Air, Pronto Airways, Venture Air Ltd, Pelican Narrows Air Service, Jackson Air Services Ltd, and Northern Dene Airways Ltd.
The Government of Canada has agreed to contribute $20 million for two new interchanges in Saskatoon. One of them being at the Sk Hwy 219 / Lorne Ave intersection with Circle Drive, the other at the Senator Sid Buckwold Bridge (Idylwyld Freeway) and Circle Drive. This is part of the Asia-Pacific Gateway and Corridor Initiative to improve access to the Canadian National Railway's intermodal freight terminal thereby increasing Asia-Pacific trade. Also, the Government of Canada will contribute $27 million to Regina to construct a Canadian Pacific Railway CPR intermodal facility and improve infrastructure transportation to the facility from both national highway networks, Sk Hwy 1, the TransCanada Highway and Sk Hwy 11, Louis Riel Trail. This also is part of the Asia-Pacific Gateway and Corridor Initiative to improve access to the CPR terminal and increase Asia-Pacific trade.
Religious institutions.
Beth Israel synagogue of Edenbridge, founded in 1906, is on the list of national historical sites.
Sports.
The Saskatchewan Roughriders are the province's only major professional sports franchise, and are extremely popular across Saskatchewan. The team's fans are also found to congregate on game days throughout Canada, and collectively they are known as "Rider Nation".
Hockey is the most popular sport in the province. More than 490 NHL players have been born in Saskatchewan, the highest per capita output of any Canadian province, U.S. state, or European country. Notable NHL figures born in Saskatchewan include Keith Allen, Gordie Howe, Bryan Trottier, Bernie Federko, Clark Gillies, Fern Flaman, Bert Olmstead, Harry Watson, Elmer Lach, Max Bentley, Sid Abel, Doug Bentley, Eddie Shore, Clint Smith, Bryan Hextall, Johnny Bower, Emile Francis, Glenn Hall, Chuck Rayner, Brad McCrimmon, Patrick Marleau, Dave Manson, Theo Fleury, Terry Harper, Wade Redden, Brian Propp, Scott Hartnell, Ryan Getzlaf, and Chris Kunitz. Saskatchewan does not have an NHL franchise, but five teams in the junior Western Hockey League are located in the province: the Moose Jaw Warriors, Prince Albert Raiders, Regina Pats, Saskatoon Blades and Swift Current Broncos.
In 2015, Budweiser honoured Saskatchewan for their abundance of hockey players by sculpting a 12-foot-tall hockey player monument in ice for Saskatchewan’s capital city of Regina. The company then filmed this frozen monument for a national television commercial, thanking the province for creating so many goal scorers throughout hockey’s history. Budweiser also gifted the “hockey player” province a trophy made of white birch—Saskatchewan’s provincial tree—which bears the name of every pro player in history. Sitting atop the trophy was a golden Budweiser Red Light, synched to every current Saskatchewan player in the pros. This trophy can currently be seen at Victoria Bar in Regina.
Cultural references.
Canadian television sitcoms "Corner Gas" and "Little Mosque on the Prairie" are set in small Saskatchewan towns. The novels of W. O. Mitchell, Sinclair Ross, Frederick Philip Grove, Guy Vanderhaeghe, Michael Helm and Gail Bowen are set in Saskatchewan, as are children's novels of Farley Mowatt. The English naturalist "Grey Owl" spent much of his life living and studying in what is now Prince Albert National Park. The Arrogant Worms' song "The Last Saskatchewan Pirate" about a disgruntled farmer who takes up piracy on the namesake river mentions various parts of the province such as Saskatoon, Regina and Moose Jaw. Québécois band Les Trois Accords recorded a song in French called "Saskatchewan" on its first album, "Gros Mammouth Album". It was the third single of that album and met moderate success in French Canada. The region is also referenced in the titular Buffy Sainte-Marie cover "Saskatchewan", by British Band Red Box; it was released as a single in 1984 and a reworked version appeared on their 1986 début album "The Circle & the Square".
In 2006, the founder of One Red Paperclip, Kyle MacDonald, ended his trading-game after swapping a movie role in the film "Donna on Demand" for a two-storey farmhouse in Kipling, Saskatchewan.
Provincial symbols.
The flag of Saskatchewan was officially adopted on September 22, 1969. The flag features the provincial shield in the upper quarter nearest the staff, with the floral emblem, the Prairie Lily, in the fly. The upper green (in forest green) half of the flag represents the northern Saskatchewan forest lands, while the golden lower half of the flag symbolizes the southern wheat fields and prairies. A province-wide competition was held to design the flag, and drew over 4,000 entries. The winning design was by Anthony Drake, then living in Hodgeville.
In 2005, Saskatchewan Environment held a province-wide vote to recognize Saskatchewan's centennial year, receiving more than 10,000 on-line and mail-in votes from the public. The walleye was the overwhelming favourite of the six native fish species nominated for the designation, receiving more than half the votes cast. Other species in the running were the lake sturgeon, lake trout, lake whitefish, northern pike and yellow perch.
Saskatchewan's other symbols include the tartan, the license plate, and the provincial flower. Saskatchewan's official tartan was registered with the Court of Lord Lyon King of Arms in Scotland in 1961. It has seven colours: gold, brown, green, red, yellow, white and black. The provincial licence plates display the slogan "Land of Living Skies". The provincial flower of Saskatchewan is the Western Red Lily.
Centennial celebrations.
In 2005, Saskatchewan celebrated its centennial. To honour it, the Royal Canadian Mint issued a commemorative five-dollar coin depicting Canada's wheat fields as well as a circulation 25-cent coin of a similar design. Queen Elizabeth II and the Duke of Edinburgh visited Regina, Saskatoon, and Lumsden, and the Saskatchewan-reared Joni Mitchell issued an album in Saskatchewan's honour.
Climate.
The effects of climate change in Saskatchewan are now being observed in parts of the province. There is evidence of reduction of biomass in Saskatchewan's boreal forests (as with those of other Canadian prairie provinces) that is linked by researchers to drought-related water stress, stemming from global warming, most likely caused by greenhouse gas emissions. While studies, as early as 1988 (Williams, et al., 1988) have shown that climate change will affect agriculture, whether the effects can be mitigated through adaptations of cultivars, or crops, is less clear. Resiliency of ecosystems may decline with large changes in temperature. The provincial government has responded to the threat of climate change by introducing a plan to reduce carbon emissions, "The Saskatchewan Energy and Climate Change Plan," in June, 2007.
See also.
Lists:
Further reading.
</dl>
External links.
 travel guide from Wikivoyage

</doc>
<doc id="26841" url="http://en.wikipedia.org/wiki?curid=26841" title="Summer solstice (disambiguation)">
Summer solstice (disambiguation)

Summer solstice is the astronomical phenomenon that occurs on the longest day of the year.
Summer solstice may also refer to:

</doc>
<doc id="26842" url="http://en.wikipedia.org/wiki?curid=26842" title="Salting">
Salting

Salting may refer to:

</doc>
<doc id="26847" url="http://en.wikipedia.org/wiki?curid=26847" title="Socialism">
Socialism

Socialism is a social and economic system characterised by social ownership of the means of production and co-operative management of the economy, as well as a political theory and movement that aims at the establishment of such a system. "Social ownership" may refer to cooperative enterprises, common ownership, state ownership, citizen ownership of equity, or any combination of these. There are many varieties of socialism and there is no single definition encapsulating all of them. They differ in the type of social ownership they advocate, the degree to which they rely on markets or planning, how management is to be organised within productive institutions, and the role of the state in constructing socialism.
A socialist economy is based on the principle of production for use, to directly satisfy economic demand and human needs, and objects are valued by their use-value, as opposed to the principle of production for profit and accumulation of capital.
In the traditional conception of a socialist economy, coordination, accounting and valuation are performed in kind (using physical quantities), by a common physical magnitude, or by a direct measure of labour-time in place of financial calculation. For distributing output, two alternative principles have been proposed: "to each according to his contribution" and "from each according to his ability, to each according to his need". The advisability, feasibility and exact way of allocating and valuing resources are the subjects of the socialist calculation debate.
The socialist political movement includes a diverse array of political philosophies. Core dichotomies include reformism "versus" revolutionary socialism, and state socialism "versus" libertarian socialism. State socialism calls for the nationalisation of the means of production as a strategy for implementing socialism, while libertarian socialism calls for decentralised means of direct democracy such as libertarian municipalism, citizens' assemblies, trade unions, and workers' councils coming from a general anti-authoritarian stance. Democratic socialism highlights the central role of democratic processes and political systems and is usually contrasted with non-democratic political movements that advocate socialism. Some socialists have adopted the causes of other social movements, such as environmentalism, feminism and liberalism.
Modern socialism originated from an 18th-century intellectual and working-class political movement that criticised the effects of industrialisation and private property on society. The revival of republicanism in the American Revolution of 1776 and the egalitarian values introduced by the French Revolution of 1789 gave rise to socialism as a distinct political movement. In the early 19th century, "socialism" referred to any concern for the social problems of capitalism regardless of the solutions to those problems. However, by the late 19th century, "socialism" had come to signify opposition to capitalism and advocacy for an alternative post-capitalist system based on some form of social ownership. During this time, German philosopher Karl Marx and his collaborator Friedrich Engels published works criticising the utopian aspects of contemporary socialist trends, and applied a materialist understanding of socialism as a phase of development which will come about through social revolution instigated by escalating and conflicting class relationships within capitalism. Alongside this appeared other tendencies such as anarchism, revolutionary syndicalism, social-democracy, Marxism–Leninism and democratic socialism as well as the confluence of socialism with anti-imperialist and anti-racist struggles around the world. Socialism became the most influential worldwide movement and political-economic world view of the 20th century. Today, socialist parties and ideas remain a political force with varying degrees of power and influence in all continents, leading national governments in many countries.
Etymology.
For Andrew Vincent "The word ‘socialism’ finds its root in the Latin "sociare", which means to combine or to share. The related, more technical term in Roman and then medieval law was "societas". This latter word could mean companionship and fellowship as well as the more legalistic idea of a consensual contract between freemen." The term "socialism" was created by Henri de Saint-Simon, one of the founders of what would later be labelled "utopian socialism". The term "socialism" was created to contrast against the liberal doctrine of "individualism", which stressed that people act or should act as if they are in isolation from one another. The original socialists condemned liberal individualism as failing to address social concerns of poverty, social oppression, and gross inequality of wealth. They viewed liberal individualism as degenerating society into supporting selfish egoism that harmed community life through promoting a society based on competition. They presented socialism as an alternative to liberal individualism, that advocated a society based on cooperation. The term "socialism" is attributed to Pierre Leroux, and to Marie Roch Louis Reybaud in France; and in Britain to Robert Owen in 1827, father of the cooperative movement.
The modern definition and usage of the term "socialism" settled by the 1860s, becoming the predominant term among the earlier associated words "co-operative", "mutualist" and "associationist". The term "communism" also fell out of use during this period, despite earlier distinctions between socialism and communism from the 1840s. An early distinction between "socialism" and "communism" was that the former aimed to only socialise production while the latter aimed to socialise both production and consumption. However, by 1888 the term "socialism" was used by Marxists in place of "communism", which was now considered an old-fashion synonym of "socialism". It was only until 1917 after the Bolshevik revolution that "socialism" came to refer to a distinct stage between capitalism and communism, introduced by Vladimir Lenin as a means to defend the Bolshevik seizure of power against traditional Marxist criticisms that Russia was not sufficiently developed for socialist revolution.
History.
Early socialism.
Socialist models and ideas espousing common or public ownership have existed since antiquity. It has been claimed, though controversially, that there were elements of socialist thought in the politics of classical Greek philosophers Plato and Aristotle. Mazdak, a Persian communal proto-socialist, instituted communal possessions and advocated the public good. In the period right after the French Revolution, activists and theorists like François-Noël Babeuf, Étienne-Gabriel Morelly, Filippo Buonarroti, and Auguste Blanqui influenced the early French labour and socialist movements. In Britain, Thomas Paine proposed a detailed plan to tax property owners to pay for the needs of the poor in "Agrarian Justice" while Charles Hall wrote "The Effects of Civilization on the People in European States", denouncing capitalism´s effects on the poor of his time which influenced the utopian schemes of Thomas Spence. The first "self-conscious socialist movements developed in the 1820s and 1830s. The Owenites, Saint-Simonians and Fourierists provided a series of coherent analyses and interpretations of society. They also, especially in the case of the Owenites, overlapped with a number of other working-class movements like the Chartists in the United Kingdom." The Chartists gathered significant numbers around the People’s Charter of 1838, which demanded the extension of suffrage to all male adults. Leaders in the movement also called for a more equitable distribution of income and better living conditions for the working classes. "The very first trade unions and consumers’ cooperative societies also emerged in the hinterland of the Chartist movement, as a way of bolstering the fight for these demands." A later important socialist thinker in France was Pierre Joseph Proudhon who proposed his philosophy of mutualism in which "everyone had an equal claim, either alone or as part of a small cooperative, to possess and use land and other resources as needed to make a living". There were also currents inspired by dissident Christianity of Christian socialism "often in Britain and then usually coming out of left liberal politics and a romantic anti-industrialism" which produced theorists such as Edward Bellamy, Frederick Denison Maurice and Charles Kingsley.
The first advocates of socialism favoured social levelling in order to create a meritocratic or technocratic society based on individual talent. Count Henri de Saint-Simon is regarded as the first individual to coin the term "socialism". Saint-Simon was fascinated by the enormous potential of science and technology and advocated a socialist society that would eliminate the disorderly aspects of capitalism and would be based on equal opportunities. He advocated the creation of a society in which each person was ranked according to his or her capacities and rewarded according to his or her work. The key focus of Saint-Simon's socialism was on administrative efficiency and industrialism, and a belief that science was the key to progress. This was accompanied by a desire to implement a rationally organised economy based on planning and geared towards large-scale scientific and material progress, and thus embodied a desire for a more directed or planned economy. Other early socialist thinkers, such as Thomas Hodgkin and Charles Hall, based their ideas on David Ricardo's economic theories. They reasoned that the equilibrium value of commodities approximated prices charged by the producer when those commodities were in elastic supply, and that these producer prices corresponded to the embodied labour – the cost of the labour (essentially the wages paid) that was required to produce the commodities. The Ricardian socialists viewed profit, interest and rent as deductions from this exchange-value.
West European social critics, including Robert Owen, Charles Fourier, Pierre-Joseph Proudhon, Louis Blanc, Charles Hall and Saint-Simon, were the first modern socialists who criticised the excessive poverty and inequality of the Industrial Revolution. They advocated reform, with some such as Robert Owen advocating the transformation of society to small communities without private property. Robert Owen's contribution to modern socialism was his understanding that actions and characteristics of individuals were largely determined by the social environment they were raised in and exposed to. On the other hand, Charles Fourier advocated phalansteres which were communities that respected individual desires (including sexual preferences), affinities and creativity and saw that work has to be made enjoyable for people. The ideas of Owen and Fourier were tried in practice in numerous intentional communities around Europe and the American continent in the mid-19th century.
Linguistically, the contemporary connotation of the words "socialism" and "communism" accorded with the adherents' and opponents' cultural attitude towards religion. In Christian Europe, of the two, communism was believed the atheist way of life. In Protestant England, the word "communism" was too culturally and aurally close to the Roman Catholic "communion rite", hence English atheists denoted themselves socialists. Friedrich Engels argued that in 1848, at the time when the "Communist Manifesto" was published, "socialism was respectable on the continent, while communism was not." The Owenites in England and the Fourierists in France were considered "respectable" socialists, while working-class movements that "proclaimed the necessity of total social change" denoted themselves communists. This latter branch of socialism produced the communist work of Étienne Cabet in France and Wilhelm Weitling in Germany. The British moral philosopher John Stuart Mill also came to advocate a form of economic socialism within a liberal context. In later editions of his "Principles of Political Economy" (1848), Mill would argue that "as far as economic theory was concerned, there is nothing in principle in economic theory that precludes an economic order based on socialist policies." While democrats looked to the Revolutions of 1848 as a democratic revolution, which in the long run ensured liberty, equality, and fraternity, Marxists denounced 1848 as a betrayal of working-class ideals by a bourgeoisie indifferent to the legitimate demands of the proletariat.
The Paris Commune was a government that briefly ruled Paris from 18 March (more formally, from 28 March) to 28 May 1871. The Commune was the result of an uprising in Paris after France was defeated in the Franco-Prussian War. The Commune elections held on 26 March elected a Commune council of 92 members, one member for each 20,000 residents. Despite internal differences, the Council began to organise the public services essential for a city of two million residents. It also reached a consensus on certain policies that tended towards a progressive, secular, and highly-democratic social democracy. Because the Commune was only able to meet on fewer than 60 days in all, only a few decrees were actually implemented. These included the separation of church and state, the remission of rents owed for the entire period of the siege (during which, payment had been suspended), the abolition of night work in the hundreds of Paris bakeries, the granting of pensions to the unmarried companions and children of National Guards killed on active service; the free return, by the city pawnshops, of all workmen's tools and household items valued up to 20 francs, pledged during the siege. The Commune was concerned that skilled workers had been forced to pawn their tools during the war; the postponement of commercial debt obligations, and the abolition of interest on the debts; and the right of employees to take over and run an enterprise if it were deserted by its owner; the Commune, nonetheless, recognised the previous owner's right to compensation.
First and Second Internationals.
The International Workingmen's Association (IWA), also known as the First International, was founded in London in 1864. The International Workingmen's Association united diverse revolutionary currents including French followers of Proudhon, Blanquists, Philadelphes, English trade unionists, socialists and social democrats. The IWA held a preliminary conference in 1865, and had its first congress at Geneva in 1866. Due to the wide variety of philosophies present in the First International, there was conflict from the start. The first objections to Marx came from the Mutualists who opposed communism and statism. However, shortly after Mikhail Bakunin and his followers (called "Collectivists" while in the International) joined in 1868, the First International became polarised into two camps headed by Marx and Bakunin respectively. The clearest differences between the groups emerged over their proposed strategies for achieving their visions of socialism. The First International became the first major international forum for the promulgation of socialist ideas.
The followers of Bakunin were called collectivist anarchists and sought to collectivise ownership of the means of production while retaining payment proportional to the amount and kind of labor of each individual. Like Proudhonists, they asserted the right of each individual to the product of his labor and to be remunerated for their particular contribution to production. By contrast, anarcho-communists sought collective ownership of both the means and the products of labor. Errico Malatesta put it: "...instead of running the risk of making a confusion in trying to distinguish what you and I each do, let us all work and put everything in common. In this way each will give to society all that his strength permits until enough is produced for every one; and each will take all that he needs, limiting his needs only in those things of which there is not yet plenty for every one." Anarchist communism as a coherent, modern economic-political philosophy was first formulated in the Italian section of the First International by Carlo Cafiero, Emilio Covelli, Errico Malatesta, Andrea Costa and other ex-Mazzinian Republicans. Out of respect for Mikhail Bakunin, they did not make their differences with collectivist anarchism explicit until after Bakunin's death.
Syndicalism emerged in France inspired in part by the ideas of Pierre Joseph Proudhon and later by Fernand Pelloutier and Georges Sorel. It developed at the end of the 19th century "out of the French trade-union movement—"syndicat" is the French word for trade union. It was a significant force in Italy and Spain in the early 20th century until it was crushed by the fascist regimes in those countries. In the United States, syndicalism appeared in the guise of the Industrial Workers of the World, or “Wobblies,” founded in 1905." Syndicalism is an economic system where industries are organised into confederations (syndicates); the economy is managed by negotiation between specialists and worker representatives of each field, comprising multiple non-competitive categorised units. Thus, syndicalism is a form of communism and economic corporatism, and also refers to the political movement and tactics used to bring about this type of system. An influential anarchist movement based on syndicalist ideas is anarcho-syndicalism. The International Workers Association is an international anarcho-syndicalist federation of various labour unions from different countries.
The Fabian Society' is a British socialist organisation which was established with the purpose of advancing the principles of socialism via gradualist and reformist means. The society laid many of the foundations of the Labour Party and subsequently affected the policies of states emerging from the decolonisation of the British Empire, most notably India and Singapore. Originally, the Fabian society was committed to the establishment of a socialist economy, alongside a commitment to British imperialism as a progressive and modernising force. Today, the society functions primarily as a think tank and is one of 15 socialist societies affiliated with the Labour Party. Similar societies exist in Australia (the Australian Fabian Society), Canada (the Douglas-Coldwell Foundation and the now disbanded League for Social Reconstruction) and in New Zealand.
Guild socialism is a political movement advocating workers' control of industry through the medium of trade-related guilds "in an implied contractual relationship with the public". It originated in the United Kingdom and was at its most influential in the first quarter of the 20th century. Inspired by the medieval guild, theorists such as Samuel G. Hobson and G.D.H. Cole advocated the public ownership of industries and their organisation into guilds, each of which would be under the democratic control of its trade union. Guild socialists were less inclined than Fabians to invest power in a state. At some point "like the American Knights of Labor, guild socialism wanted to abolish the wage system".
As the ideas of Marx and Engels took on flesh, particularly in central Europe, socialists sought to unite in an international organisation. In 1889, on the centennial of the French Revolution of 1789, the Second International was founded, with 384 delegates from 20 countries representing about 300 labour and socialist organisations. It was termed the "Socialist International" and Engels was elected honorary president at the third congress in 1893. Anarchists were ejected and not allowed in, mainly due to pressure from Marxists. It has been argued that, at some point, the Second International turned "into a battleground over the issue of libertarian versus authoritarian socialism. Not only did they effectively present themselves as champions of minority rights; they also provoked the German Marxists into demonstrating a dictatorial intolerance which was a factor in preventing the British labor movement from following the Marxist direction indicated by such leaders as H. M.
Hyndman".
Reformism arose as an alternative to revolution. Eduard Bernstein was a leading social democrat in Germany who proposed the concept of evolutionary socialism. Revolutionary socialists quickly targeted reformism: Rosa Luxemburg condemned Bernstein's "Evolutionary Socialism" in her 1900 essay "Reform or Revolution?". Revolutionary socialism encompasses multiple social and political movements that may define "revolution" differently from one another. The Social Democratic Party (SPD) in Germany became the largest and most powerful socialist party in Europe, despite working illegally until the anti-socialist laws were dropped in 1890. In the 1893 elections, it gained 1,787,000 votes, a quarter of the total votes cast, according to Engels. In 1895, the year of his death, Engels emphasised the Communist Manifesto's emphasis on winning, as a first step, the "battle of democracy".
Early 20th century and the revolutions of 1917–1936.
In 1904, Australians elected the first Australian Labor Party prime minister: Chris Watson, who became the first democratically elected social democrat. In 1909 the first Kibbutz was established in Palestine by Russian Jewish Immigrants. The Kibbutz Movement will then expand through the 20th century following a doctrine of zionist socialism. The British Labour Party first won seats in the House of Commons in 1902. The International Socialist Commission (ISC, also known as Berne International) was formed in February 1919 at a meeting in Berne by parties that wanted to resurrect the Second International. By 1917, the patriotism of World War I changed into political radicalism in most of Europe, the United States, and Australia. Other socialist parties from around the world who were beginning to gain importance in their national politics in the early 20th century included the Italian Socialist Party, the French Section of the Workers' International, the Spanish Socialist Workers' Party, the Swedish Social Democratic Party, the Russian Social Democratic Labour Party, the Socialist Party of America in the United States, the Argentinian Socialist Party and the Chilean Partido Obrero Socialista.
In February 1917, revolution exploded in Russia. Workers, soldiers and peasants established soviets (councils), the monarchy fell, and a provisional government convoked pending the election of a constituent assembly. In April of that year, Vladimir Lenin, leader of the "Majority" (or in Russian: "Bolshevik") faction of socialists in Russia and known for his profound and controversial expansions of Marxism, was allowed to cross Germany to return to his country from exile in Switzerland. Lenin had published essays on his analysis of imperialism, the monopoly and globalisation phase of capitalism as predicted by Marx, as well as analyses on the social conditions of his contemporary time. He observed that as capitalism had further developed in Europe and America, the workers remained unable to gain class consciousness so long as they were too busy working and concerning with how to make ends meet. He therefore proposed that the social revolution would require the leadership of a vanguard party of class-conscious revolutionaries from the educated and politically active part of the population. Upon arriving in Petrograd, he declared that the revolution in Russia was not over but had only begun, and that the next step was for the workers' soviets to take full state authority. He issued a thesis outlining the Bolshevik's party programme, including rejection of any legitimacy in the provisional government and advocacy for state power to be given to the peasant and working class through the soviets. The Bolsheviks became the most influential force in the soviets, and on 7 November, the capitol of the provisional government was stormed by Bolshevik Red Guards in what afterwards known as the "Great October Socialist Revolution". The rule of the provisional government was ended and the Russian Socialist Federative Soviet Republic - the world's first constitutionally socialist state - was established. On 25 January 1918, at the Petrograd Soviet, Lenin declared "Long live the world socialist revolution!" He proposed an immediate armistice on all fronts, and transferred the land of the landed proprietors, the crown and the monasteries to the peasant committees without compensation.
On 26 January 1918, the day after assuming executive power, Lenin wrote "Draft Regulations on Workers' Control", which granted workers control of businesses with more than five workers and office employees, and access to all books, documents and stocks, and whose decisions were to be "binding upon the owners of the enterprises". Governing through the elected soviets, and in alliance with the peasant-based Left Socialist-Revolutionaries, the Bolshevik government began nationalising banks, industry, and disavowed the national debts of the deposed Romanov royal régime. It sued for peace, withdrawing from World War I, and convoked a Constituent Assembly in which the peasant Socialist-Revolutionary Party (SR) won a majority. The Constituent Assembly elected Socialist-Revolutionary leader Victor Chernov President of a Russian republic, but rejected the Bolshevik proposal that it endorse the Soviet decrees on land, peace and workers' control, and acknowledge the power of the Soviets of Workers', Soldiers' and Peasants' Deputies. The next day, the Bolsheviks declared that the assembly was elected on outdated party lists, and the All-Russian Central Executive Committee of the Soviets dissolved it. In March 1919 world communist parties formed Comintern (also known as the Third International) at a meeting in Moscow.
Parties which did not want to be a part of the resurrected Second International (ISC) or Comintern formed the International Working Union of Socialist Parties (IWUSP, also known as Vienna International/Vienna Union/Two-and-a-Half International) on 27 February 1921 at a conference in Vienna. The ISC and the IWUSP joined to form the Labour and Socialist International (LSI) in May 1923 at a meeting in Hamburg Left wing groups which did not agree to the centralisation and abandonment of the soviets by the Bolshevik Party led Left-wing uprisings against the Bolsheviks; such groups included Socialist Revolutionaries, Left Socialist Revolutionaries, Mensheviks, and anarchists. Within this left wing discontent the most large scale events were the worker's Kronstadt rebellion and the anarchist led Revolutionary Insurrectionary Army of Ukraine uprising which controlled an area known as the Free Territory.
The Bolshevik Russian Revolution of January 1918 engendered Communist parties worldwide, and their concomitant revolutions of 1917–23. Few Communists doubted that the Russian success of socialism depended on successful, working-class socialist revolutions in developed capitalist countries. In 1919, Lenin and Trotsky organised the world's Communist parties into a new international association of workers – the Communist International, (Comintern), also called the Third International. The Russian Revolution also influenced uprisings in other countries around this time. The German Revolution of 1918–1919 resulted in the replacing Germany's imperial government with a republic. The revolutionary period lasted from November 1918 until the formal establishment of the Weimar Republic in August 1919, and included an episode known as the Bavarian Soviet Republic and the Spartacist uprising. In Italy, the events known as the "Biennio Rosso" was characterised by mass strikes, worker manifestations and self-management experiments through land and factories occupations. In Turin and Milan, workers councils were formed and many factory occupations took place led by anarcho-syndicalists organised around the Unione Sindacale Italiana.
By 1920, the Red Army, under its commander Trotsky, had largely defeated the royalist White Armies. In 1921, War Communism was ended and, under the New Economic Policy (NEP), private ownership was allowed for small and medium peasant enterprises. While industry remained largely state-controlled, Lenin acknowledged that the NEP was a necessary capitalist measure for a country unripe for socialism. Profiteering returned in the form of "NEP men" and rich peasants (Kulaks) gained power in the countryside. Nevertheless, the role of Trotsky in this episode has been questioned by other socialists, incluiding ex-Trostkists. In the United States, Dwight Macdonald broke with Trotsky and left the Trotskyist Socialist Workers Party, by raising the question of the Kronstadt rebellion, which Trotsky as leader of the Soviet Red Army and the other Bolsheviks had brutally repressed. He then moved towards democratic socialism and anarchism. A similar critique of Trotsky's role on the events around the Kronstadt rebellion was raised by the American anarchist Emma Goldman. In her essay "Trotsky Protests Too Much" she says "I admit, the dictatorship under Stalin's rule has become monstrous. That does not, however, lessen the guilt of Leon Trotsky as one of the actors in the revolutionary drama of which Kronstadt was one of the bloodiest scenes."
In 1922, the fourth congress of the Communist International took up the policy of the United Front, urging Communists to work with rank and file Social Democrats while remaining critical of their leaders, whom they criticised for betraying the working class by supporting the war efforts of their respective capitalist classes. For their part, the social democrats pointed to the dislocation caused by revolution, and later, the growing authoritarianism of the Communist Parties. When the Communist Party of Great Britain applied to affiliate to the Labour Party in 1920, it was turned down. In 1923, on seeing the Soviet State's growing coercive power, a dying Lenin said Russia had reverted to "a bourgeois tsarist machine... barely varnished with socialism." After Lenin's death in January 1924, the Communist Party of the Soviet Union – then increasingly under the control of Joseph Stalin – rejected the theory that socialism could not be built solely in the Soviet Union, in favour of the concept of "Socialism in One Country". Despite the marginalised Left Opposition's demand for the restoration of Soviet democracy, Stalin developed a bureaucratic, authoritarian government, that was condemned by democratic socialists, anarchists and Trotskyists for undermining the initial socialist ideals of the Bolshevik Russian Revolution.
In 1924, the Mongolian People's Republic was established and was ruled by the Mongolian People's Party. The Russian Revolution and the appearance of the Soviet State motivated a worldwide current of national Communist parties which ended having varying levels of political and social influence. Among these there appeared the Communist Party of France, the Communist Party USA, the Italian Communist Party, the Chinese Communist Party, the Mexican Communist Party, the Brazilian Communist Party, the Chilean Communist Party and the Communist Party of Indonesia.
In Spain in 1936, the national anarcho-syndicalist trade union Confederación Nacional del Trabajo (CNT) initially refused to join a popular front electoral alliance, and abstention by CNT supporters led to a right-wing election victory. But in 1936, the CNT changed its policy and anarchist votes helped bring the popular front back to power. Months later, the former ruling class responded with an attempted coup, sparking the Spanish Civil War (1936–1939). In response to the army rebellion, an anarchist-inspired movement of peasants and workers, supported by armed militias, took control of Barcelona and of large areas of rural Spain where they collectivised the land. The events known as the Spanish Revolution was a workers' social revolution that began during the outbreak of the Spanish Civil War in 1936 and resulted in the widespread implementation of anarchist and more broadly libertarian socialist organisational principles throughout various portions of the country for two to three years, primarily Catalonia, Aragon, Andalusia, and parts of the Levante. Much of Spain's economy was put under worker control; in anarchist strongholds like Catalonia, the figure was as high as 75%, but lower in areas with heavy Communist Party of Spain influence, as the Soviet-allied party actively resisted attempts at collectivisation enactment. Factories were run through worker committees, agrarian areas became collectivised and run as libertarian communes. Anarchist historian Sam Dolgoff estimated that about eight million people participated directly or indirectly in the Spanish Revolution
Mid-20th century: World War II and post war radicalisation.
Trotsky's Fourth International was established in France in 1938 when Trotskyists argued that the Comintern or Third International had become irretrievably "lost to Stalinism" and thus incapable of leading the international working class to political power. The rise of Nazism and the start of World War II led to the dissolution of the LSI in 1940. After the War, the Socialist International was formed in Frankfurt in July 1951 as a successor to the LSI.
After World War II, social democratic governments introduced social reform and wealth redistribution via state welfare and taxation. Social Democratic parties dominated post-war politics in countries such as France, Italy, Czechoslovakia, Belgium and Norway. At one point, France claimed to be the world's most state-controlled capitalist country. The nationalised public utilities included Charbonnages de France (CDF), Electricité de France (EDF), Gaz de France (GDF), Air France, Banque de France, and Régie Nationale des Usines Renault. In 1945, the British Labour Party, led by Clement Attlee, was elected to office based on a radical socialist programme. The UK Labour Government nationalised major public utilities such as mines, gas, coal, electricity, rail, iron, steel, and the Bank of England. British Petroleum was officially nationalised in 1951. Anthony Crosland said that in 1956, 25% of British industry was nationalised, and that public employees, including those in nationalised industries, constituted a similar proportion of the country's total employed population. The Labour Government of 1974–1979 intervened further. It re-nationalised steel (1967, British Steel) after the Conservatives had denationalised it, and nationalised car production (1976, British Leyland). The National Health Service provided taxpayer-funded health care to everyone, free at the point of service. Working-class housing was provided in council housing estates, and university education became available via a school grant system.
The Nordic model is the economic and social models of the Nordic countries (Denmark, Iceland, Norway, Sweden and Finland). During most of the post-war era, Sweden was governed by the Swedish Social Democratic Party largely in cooperation with trade unions and industry. In Sweden, the Social Democratic Party held power from 1936 to 1976, 1982 to 1991, and 1994 to 2006. From 1945 to 1962, the Norwegian Labour Party held an absolute majority in the parliament led by Einar Gerhardsen who was Prime Minister with 17 years in office. This particular adaptation of the mixed market economy is characterised by more generous welfare states (relative to other developed countries), which are aimed specifically at enhancing individual autonomy, ensuring the universal provision of basic human rights and stabilising the economy. It is distinguished from other welfare states with similar goals by its emphasis on maximising labour force participation, promoting gender equality, egalitarian and extensive benefit levels, large magnitude of redistribution, and expansionary fiscal policy.
The USSR played a decisive role in the Allied victory in World War II. After the War, the USSR became a recognised superpower, The Soviet era saw some of the most significant technological achievements of the 20th century, including the world's first spacecraft, and the first astronaut. The Soviet economy was the modern world's first centrally planned economy. It was based on a system of state ownership of industry managed through Gosplan (the State Planning Commission), Gosbank (the State Bank) and the Gossnab (State Commission for Materials and Equipment Supply). Economic planning was conducted through a series of Five-Year Plans. The emphasis was on fast development of heavy industry and the nation became one of the world's top manufacturers of a large number of basic and heavy industrial products, but it lagged in light industrial production and consumer durables. The Eastern Bloc was the former communist states of Central and Eastern Europe, generally the Soviet Union and the countries of the Warsaw Pact which included the People's Republic of Poland, the German Democratic Republic, the People's Republic of Hungary, the People's Republic of Bulgaria, the Czechoslovak Socialist Republic, the Socialist Republic of Romania, the People's Socialist Republic of Albania and the Socialist Federal Republic of Yugoslavia. The Hungarian Revolution of 1956 was a spontaneous nationwide revolt against the government of the People's Republic of Hungary and its Soviet-imposed policies, lasting from 23 October until 10 November 1956. Soviet leader Nikita Khrushchev´s denunciation of the excesses of Stalin´s regime during the Twentieth Party Congress of the Communist Party of the Soviet Union on 1956, as well as the revolt in Hungary, produced ideological fractures and disagreements within the communist and socialist parties of Western Europe.
In the postwar years, socialism became increasingly influential throughout the so-called Third World. Countries in Africa, Asia, and Latin America often nationalised industries held by foreign owners. The Chinese Revolution was the second part of Chinese Civil War which ended in the establishment of the People's Republic of China. The term "Third World" was coined by French demographer Alfred Sauvy in 1952, on the model of the Third Estate, which, according to the Abbé Sieyès, represented everything, but was nothing: "...because at the end this ignored, exploited, scorned Third World like the Third Estate, wants to become something too" (Sauvy). The emergence of this new political entity, in the frame of the Cold War, was complex and painful. Several tentatives were made to organise newly independent states in order to oppose a common front towards both the US's and the USSR's influence on them, with the consequences of the Sino-Soviet split already at works. Thus, the Non-Aligned Movement constituted itself, around the main figures of Prime Minister Jawaharlal Nehru of India, President Sukarno of Indonesia, leader Josip Broz Tito of Yugoslavia, and Gamal Abdel Nasser of Egypt who successfully opposed the French and British imperial powers during the 1956 Suez crisis. After the 1954 Geneva Conference which ended the French war against Ho Chi Minh in Vietnam, the 1955 Bandung Conference gathered Nasser, Nehru, Tito, Sukarno, and Zhou Enlai, Premier of the People's Republic of China. As many African countries gained independence during the 1960s, some of them rejected capitalism in favour of a more afrocentric economic model. The main architects of African Socialism were Julius Nyerere of Tanzania, Léopold Senghor of Senegal, Kwame Nkrumah of Ghana and Sékou Touré of Guinea. The Cuban Revolution (1953-1959) was an armed revolt conducted by Fidel Castro's 26th of July Movement and its allies against the government of Cuban President Fulgencio Batista. The revolution began in July 1953, and finally ousted Batista on 1 January 1959, replacing his government with Castro's revolutionary state. Castro's government later reformed along communist lines, becoming the Communist Party of Cuba in October 1965.
The New Left was a term used mainly in the United Kingdom and United States in reference to activists, educators, agitators and others in the 1960s and 1970s who sought to implement a broad range of reforms on issues such as gay rights, abortion, gender roles and drugs in contrast to earlier leftist or Marxist movements that had taken a more vanguardist approach to social justice and focused mostly on labour unionisation and questions of social class. They rejected involvement with the labour movement and Marxism's historical theory of class struggle. In the U.S., the "New Left" was associated with the Hippie movement, anti-war college campus protest movements as well as the black liberation movements such as the Black Panther Party. While initially formed in opposition to the "Old Left" Democratic party, groups composing the New Left gradually became central players in the Democratic coalition. In 1968 in Carrara, Italy the International of Anarchist Federations was founded during an international anarchist conference held there by the three existing European federations of France, the Italian and the Iberian Anarchist Federation as well as the Bulgarian federation in French exile.
The protests of 1968 comprised a worldwide escalation of social conflicts, predominantly characterised by popular rebellions against military, capitalist, and bureaucratic elites, who responded with an escalation of political repression. In capitalist countries, these protests marked a turning point for the Civil Rights movement in the United States, which produced revolutionary movements like the Black Panther Party; the prominent civil rights leader Martin Luther King Jr. organised the "Poor People's Campaign" to address issues of economic justice, while personally showing sympathy with democratic socialism. In reaction to the Tet Offensive, protests also sparked a broad movement in opposition to the Vietnam War all over the United States and even into London, Paris, Berlin and Rome. Mass socialist or communist movements grew not only in the United States but also in most European countries. The most spectacular manifestation of this were the May 1968 protests in France, in which students linked up with wildcat strikes of up to ten million workers, and for a few days the movement seemed capable of overthrowing the government. In many other capitalist countries, struggles against dictatorships, state repression, and colonisation were also marked by protests in 1968, such as the beginning of the Troubles in Northern Ireland, the Tlatelolco massacre in Mexico City, and the escalation of guerrilla warfare against the military dictatorship in Brazil. Countries governed by communist parties had protests against bureaucratic and military elites. 1968 was amidst the Great Proletarian Cultural Revolution in China (1966–1976), and in Eastern Europe there were widespread protests that escalated particularly in the Prague Spring in Czechoslovakia. In response, USSR occupied Czechoslovakia. The occupation was denounced by the Italian and French Communist parties, and the Communist Party of Finland. Few western European political leaders defended the occupation, among them the Portuguese communist secretary-general Álvaro Cunhal. along with the Luxembourg party and conservative factions of the Greek party. In the Chinese Cultural Revolution, a social-political youth movement mobilised against "bourgeois" elements which were seen to be infiltrating the government and society at large, aiming to restore capitalism. This movement motivated Maoism-inspired movements around the world in the context of the Sino-Soviet split.
In Indonesia, a right wing military regime led by Suharto killed between 500,000 and one million people, mainly to crush the growing influence of the Communist Party of Indonesia and other leftist sectors, with support from the United States government, which provided kill lists containing thousands of names of suspected high-ranking Communists. In Latin America in the 1960s, a socialist tendency within the catholic church appeared which was called Liberation theology which motivated even the Colombian priest Camilo Torres to enter the ELN guerrilla. In Chile, Salvador Allende, a physician and candidate for the Socialist Party of Chile, was elected president through democratic elections in 1970. In 1973, his government was ousted by the American-backed military dictatorship of Augusto Pinochet, which lasted until the late 1980s. In Italy, Autonomia Operaia was a leftist movement particularly active from 1976 to 1978. It took an important role in the autonomist movement in the 1970s, aside earlier organisations such as "Potere Operaio", created after May 1968, and "Lotta Continua". This experience prompted the contemporary socialist radical movement autonomism.
Late 20th century.
The Nicaraguan Revolution encompassed the rising opposition to the Somoza dictatorship in the 1960s and 1970s, the campaign led by the Sandinista National Liberation Front (FSLN) to violently oust the dictatorship in 1978-79, the subsequent efforts of the FSLN to govern Nicaragua from 1979 until 1990 and the socialist measures which included widescale agrarian reform and educational programs. The People's Revolutionary Government was proclaimed on 13 March 1979 in Grenada which was overthrown by armed forces of the United States in 1983. The Salvadoran Civil War (1979–1992) was a conflict between the military-led government of El Salvador and the Farabundo Martí National Liberation Front (FMLN), a coalition or 'umbrella organisation' of five socialist guerrilla groups. A coup on October 15, 1979 led to the killings of anti-coup protesters by the government as well as anti-disorder protesters by the guerillas, and is widely seen as the tipping point towards the civil war.
In 1982, the newly elected French socialist government of François Mitterrand made nationalisations in a few key industries, including banks and insurance companies. Eurocommunism was a trend in the 1970s and 1980s in various Western European communist parties to develop a theory and practice of social transformation that was more relevant for a Western European country and less aligned to the influence or control of the Communist Party of the Soviet Union. Outside Western Europe, it is sometimes called Neocommunism. Some Communist parties with strong popular support, notably the Italian Communist Party (PCI) and the Communist Party of Spain (PCE) adopted Eurocommunism most enthusiastically, and the Communist Party of Finland was dominated by Eurocommunists. The French Communist Party (PCF) and many smaller parties strongly opposed Eurocommunism and stayed aligned with the Communist Party of the Soviet Union until the end of the USSR.
In the late 1970s and in the 1980s, the Socialist International had extensive contacts and discussion with the two powers of the Cold War, the United States and the Soviet Union, about East-West relations and arms control. Since then, the SI has admitted as member parties the Nicaraguan FSLN, the left-wing Puerto Rican Independence Party, as well as former Communist parties such as the Democratic Party of the Left of Italy and the Front for the Liberation of Mozambique (FRELIMO). The Socialist International aided social democratic parties in re-establishing themselves when dictatorship gave way to democracy in Portugal (1974) and Spain (1975). Until its 1976 Geneva Congress, the SI had few members outside Europe and no formal involvement with Latin America.
After Mao's death in 1976 and the arrest of the faction known as the Gang of Four, who were blamed for the excesses of the Cultural Revolution, Deng Xiaoping took power and led the People´s Republic of China to significant economic reforms. The Communist Party of China loosened governmental control over citizens' personal lives and the communes were disbanded in favour of private land leases. Thus, China's transition from a planned economy to a mixed economy named as "socialism with Chinese characteristics" which maintained state ownership rights over land, state or cooperative ownership of much of the heavy industrial and manufacturing sectors and state influence in the banking and financial sectors. China adopted its current constitution on 4 December 1982. President Jiang Zemin and Premier Zhu Rongji led the nation in the 1990s. Under their administration, China's economic performance pulled an estimated 150 million peasants out of poverty and sustained an average annual gross domestic product growth rate of 11.2%. At the Sixth National Congress of the Communist Party of Vietnam in December 1986, reformist politicians replaced the "old guard" government with new leadership. The reformers were led by 71-year-old Nguyen Van Linh, who became the party's new general secretary. Linh and the reformers implemented a series of free-market reforms – known as "Đổi Mới" ("Renovation") – which carefully managed the transition from a planned economy to a "socialist-oriented market economy". Mikhail Gorbachev wished to move the USSR towards of Nordic-style social democracy, calling it "a socialist beacon for all mankind." Prior to its dissolution in 1991, the USSR had the second largest economy in the world after the United States. With the collapse of the Soviet Union, the economic integration of the Soviet republics was dissolved, and overall industrial activity declined substantially. A lasting legacy remains in the physical infrastructure created during decades of combined industrial production practices.
Many social democratic parties, particularly after the Cold war, adopted neoliberal market policies including privatisation, deregulation and financialisation. They abandoned their pursuit of moderate socialism in favour of market liberalism. By the 1980s, with the rise of conservative neoliberal politicians such as Ronald Reagan in the United States, Margaret Thatcher in Britain, Brian Mulroney in Canada and Augusto Pinochet in Chile, the Western welfare state was attacked from within. Monetarists and neoliberals attacked social welfare systems as impediments to private entrepreneurship. In the UK, Labour Party leader Neil Kinnock made a public attack against the entryist group Militant at the 1985 Labour Party conference. The Labour Party ruled that Militant was ineligible for affiliation with the Labour Party, and the party gradually expelled Militant supporters. The Kinnock leadership had refused to support the 1984–1985 miner's strike over pit closures, a decision that the party's left wing and the National Union of Mineworkers blamed for the strike's eventual defeat. In 1989, at Stockholm, the 18th Congress of the Socialist International adopted a new "Declaration of Principles", saying:
Democratic socialism is an international movement for freedom, social justice, and solidarity. Its goal is to achieve a peaceful world where these basic values can be enhanced and where each individual can live a meaningful life with the full development of his or her personality and talents, and with the guarantee of human and civil rights in a democratic framework of society.
In the 1990s, the British Labour Party, under Tony Blair, enacted policies based on the free market economy to deliver public services via the Private finance initiative. Influential in these policies was the idea of a "third Way" which called for a re-evalutation of welfare state policies. In 1995, the Labour Party re-defined its stance on socialism by re-wording Clause IV of its constitution, effectively rejecting socialism by removing all references to public, direct worker or municipal ownership of the means of production. The Labour Party stated: "The Labour Party is a democratic socialist party. It believes that, by the strength of our common endeavour we achieve more than we achieve alone, so as to create, for each of us, the means to realise our true potential, and, for all of us, a community in which power, wealth, and opportunity are in the hands of the many, not the few."
Contemporary socialist politics.
African.
African socialism has been and continues to be a major ideology around the continent. Julius Nyerere was inspired by Fabian socialist ideals. He was a firm believer in rural Africans and their traditions and ujamaa, a system of collectivisation that according to Nyerere was present before European imperialism. Essentially he believed Africans were already socialists. Other African socialists include Jomo Kenyatta, Kenneth Kaunda, Nelson Mandela and Kwame Nkrumah. Fela Kuti was inspired by socialism and called for a democratic African republic. In South Africa the African National Congress (ANC) abandoned its partial socialist allegiances after taking power, and followed a standard neoliberal route. From 2005 through to 2007, the country was wracked by many thousands of protests from poor communities. One of these gave rise to a mass movement of shack dwellers, Abahlali baseMjondolo that, despite major police suppression, continues to work for popular people's planning and against the creation of a market economy in land and housing.
Asian.
In Asia, states with socialist economies — such as the People's Republic of China, North Korea, Laos and Vietnam — have largely moved away from centralised economic planning in the 21st century, placing a greater emphasis on markets. Forms include the Chinese socialist market economy and the Vietnamese socialist-oriented market economy. They utilise state-owned corporate management models as opposed to modelling socialist enterprise on traditional management styles employed by government agencies. In China living standards continued to improve rapidly despite the late-2000s recession, but centralised political control remained tight. Brian Reynolds Myers in his book "The Cleanest Race", and later supported by other academics, dismisses the idea that "Juche" is North Korea's leading ideology, regarding its public exaltation as designed to deceive foreigners and that it exists to be praised and not actually read pointing out that North Korea's latest constitution, of 2009, omits all mention of communism. Though the authority of the state remained unchallenged under "Đổi Mới", the government of Vietnam encourages private ownership of farms and factories, economic deregulation and foreign investment, while maintaining control over strategic industries. The Vietnamese economy subsequently achieved strong growth in agricultural and industrial production, construction, exports and foreign investment. However, these reforms have also caused a rise in income inequality and gender disparities. Elsewhere in Asia, some elected socialist parties and communist parties remain prominent, particularly in India and Nepal. The Communist Party of Nepal in particular calls for multi-party democracy, social equality, and economic prosperity. In Singapore, a majority of the GDP is still generated from the state sector comprising government-linked companies. In Japan, there has been a resurgent interest in the Japanese Communist Party among workers and youth. In Malaysia, the Socialist Party of Malaysia got its first Member of Parliament, Dr. Jeyakumar Devaraj, after the 2008 general election. In 2010, there were 270 kibbutzim in Israel. Their factories and farms account for 9% of Israel's industrial output, worth US$8 billion, and 40% of its agricultural output, worth over $1.7 billion. Some Kibbutzim had also developed substantial high-tech and military industries. For example, in 2010, Kibbutz Sasa, containing some 200 members, generated $850 million in annual revenue from its military-plastics industry.
European.
The United Nations "World Happiness Report 2013" shows that the happiest nations are concentrated in northern Europe, where the Nordic model of social democracy persists, with Denmark topping the list. The Nordic countries ranked highest on the metrics of real GDP per capita, healthy life expectancy, having someone to count on, perceived freedom to make life choices, generosity and freedom from corruption. The objectives of the Party of European Socialists, the European Parliament's socialist and social-democratic bloc, are now "to pursue international aims in respect of the principles on which the European Union is based, namely principles of freedom, equality, solidarity, democracy, respect of Human Rights and Fundamental Freedoms, and respect for the Rule of Law." As a result, today, the rallying cry of the French Revolution – "Egalité, Liberté, Fraternité" – which overthrew absolutism and ushered industrialisation into French society, are promoted as essential socialist values. To the left of the PES at the European level is the Party of the European Left, (PEL; also commonly abbreviated "European Left") which is a political party at the European level and an association of democratic socialist, socialist and communist political parties in the European Union and other European countries. It was formed in January 2004 for the purposes of running in the 2004 European Parliament elections. PEL was founded on 8–9 May 2004 in Rome. Elected MEPs from member parties of the European Left sit in the European United Left–Nordic Green Left (GUE/NGL) group in the European parliament.
The socialist Left Party in Germany grew in popularity due to dissatisfaction with the increasingly neoliberal policies of the SPD, becoming the fourth biggest party in parliament in the general election on 27 September 2009. Communist candidate Dimitris Christofias won a crucial presidential runoff in Cyprus, defeating his conservative rival with a majority of 53%. In Ireland, in the 2009 European election, Joe Higgins of the Socialist Party took one of three seats in the capital Dublin European constituency.
In Denmark, the Socialist People's Party (SF or Socialist Party for short) more than doubled its parliamentary representation to 23 seats from 11, making it the fourth largest party. In 2011, the socialist parties of Social Democrats, Socialist People's Party and the Danish Social Liberal Party formed government, after a slight victory over the liberal parties. They were led by Helle Thorning-Schmidt, and had the Red-Green Alliance as a supporting party.
In Norway, the Red-Green Coalition consists of the Labour Party (Ap), the Socialist Left Party (SV), and the Centre Party (Sp), and governed the country as a majority government from the 2005 general election until 2013.
In the Greek legislative election of 2015, the Coalition of the Radical Left (SYRIZA), led by Alexis Tsipras, won a legislative election for the first time while the Communist Party of Greece won 15 seats in parliament. SYRIZA has been characterised as an anti-establishment party, whose success has sent "shock-waves across the EU".
In the UK, the National Union of Rail, Maritime and Transport Workers put forward a slate of candidates in the 2009 European Parliament elections under the banner of No to EU – Yes to Democracy, a broad left-wing alter-globalisation coalition involving socialist groups such as the Socialist Party, aiming to offer an alternative to the "anti-foreigner" and pro-business policies of the UK Independence Party. In the following May 2010 UK general election, the Trade Unionist and Socialist Coalition, launched in January 2010 and backed by Bob Crow, the leader of the National Union of Rail, Maritime and Transport Workers union (RMT), other union leaders and the Socialist Party among other socialist groups, stood against Labour in 40 constituencies. The Trade Unionist and Socialist Coalition plans to contest the 2011 elections, having gained the endorsement of the RMT June 2010 conference. Left Unity was also founded in 2013 after the film director Ken Loach appealed for a new party of the left to replace the Labour Party, which he claimed had failed to oppose austerity and had shifted towards neoliberalism.
In France, the Revolutionary Communist League (LCR) candidate in the 2007 presidential election, Olivier Besancenot, received 1,498,581 votes, 4.08%, double that of the Communist candidate. The LCR abolished itself in 2009 to initiate a broad anti-capitalist party, the New Anticapitalist Party, whose stated aim is to "build a new socialist, democratic perspective for the twenty-first century".
On 25 May 2014 in Spain the left wing party Podemos entered candidates for the 2014 European parliamentary elections, some of which were unemployed. In a surprise result, it polled 7.98% of the vote and thus was awarded five seats out of 54. while the older United Left was the third largest overall force obtaining 10,03 % and 5 seats, 4 more than the previous elections.
All around Europe and in some places of Latin America there exists a social center and Squatting movement mainly inspired by autonomist and anarchist ideas.
North American.
According to a 2013 article in "The Guardian", "Contrary to popular belief, Americans don't have an innate allergy to socialism. Milwaukee has had several socialist mayors (Frank Zeidler, Emil Seidel and Daniel Hoan), and there is currently an independent socialist in the US Senate, Bernie Sanders of Vermont." Sanders has described himself as a democratic socialist and has praised Scandinavian-style social democracy.
Anti-capitalism, anarchism and the anti-globalisation movement rose to prominence through events such as protests against the World Trade Organization Ministerial Conference of 1999 in Seattle. Socialist-inspired groups played an important role in these movements, which nevertheless embraced much broader layers of the population and were championed by figures such as Noam Chomsky. In Canada, the Co-operative Commonwealth Federation (CCF), the precursor to the social democratic New Democratic Party (NDP), had significant success in provincial politics. In 1944, the Saskatchewan CCF formed the first socialist government in North America. At the federal level, the NDP is currently the Official Opposition, after winning 103 out of 308 seats (up from 37) in the 2011 Canadian federal election.
South American and Caribbean.
For the "Encyclopedia Britannica" "the attempt by Salvador Allende to unite Marxists and other reformers in a socialist reconstruction of Chile is most representative of the direction that Latin American socialists have taken since the late 20th century. ... Several socialist (or socialist-leaning) leaders have followed Allende’s example in winning election to office in Latin American countries." Venezuelan President Hugo Chávez, Nicaraguan President Daniel Ortega, Bolivian President Evo Morales, and Ecuadorian president Rafael Correa refer to their political programmes as socialist. Chávez has adopted the term "socialism of the 21st century". After winning re-election in December 2006, Chávez said, "Now more than ever, I am obliged to move Venezuela's path towards socialism." Hugo Chávez was also reelected in October 2012 for his third six-year term as President, but he died in March 2013 from cancer. After Chávez's death on 5 March 2013, vice-president from Chavez's party Nicolás Maduro assumed the powers and responsibilities of the President. A special election was held on 14 April of the same year to elect a new President, which Maduro won by a tight margin as the candidate of the United Socialist Party of Venezuela; he was formally inaugurated on 19 April. "Pink tide" is a term being used in contemporary 21st-century political analysis in the media and elsewhere to describe the perception that Leftist ideology in general, and Left-wing politics in particular, are increasingly influential in Latin America. Foro de São Paulo is a conference of leftist political parties and other organisations from Latin America and the Caribbean. It was launched by the Workers' Party (Portuguese: "Partido dos Trabalhadores - PT") of Brazil in 1990 in the city of São Paulo. The Forum of São Paulo was constituted in 1990 when the Brazilian Workers' Party approached other parties and social movements of Latin America and the Caribbean with the objective of debating the new international scenario after the fall of the Berlin Wall and the consequences of the implementation of what were taken as neoliberal policies adopted at the time by contemporary right-leaning governments in the region, the stated main objective of the conference being to argue for alternatives to neoliberalism. Among its member include current socialist and social-democratic parties currently in government in the region such as Bolivia´s Movement for socialism, Brazil´s Workers Party, the Communist Party of Cuba, the Ecuadorian PAIS Alliance, the Venezuelan United Socialist Party of Venezuela, the Socialist Party of Chile, the Uruguayan Broad Front, the Nicaraguan Sandinista National Liberation Front and the salvadorean Farabundo Martí National Liberation Front.
International.
The Progressive Alliance is a political international founded on 22 May 2013 by political parties, the majority of whom are current or former members of the Socialist International. The organisation states the aim of becoming the global network of "the progressive", democratic, social-democratic, socialist and labour movement".
Philosophy.
Early socialist thought took influences from a diverse range of philosophies such as civic republicanism, Enlightenment rationalism, romanticism, forms of materialism, Christianity (both Catholic and Protestant), natural law and natural rights theory, utilitarianism and liberal political economy.
The philosophical basis for a lot of early socialism was heavily influenced by the emergence of positivism during the European Enlightenment. Positivism held that both the natural and social worlds could be understood through scientific knowledge and be analyzed using scientific methods. This core outlook influenced early social scientists and different types of socialists ranging from anarchists like Peter Kropotkin to technocrats like Saint Simon.
The fundamental objective of socialism is to attain an advanced level of material production and therefore greater productivity, efficiency and rationality as compared to capitalism and all previous systems, under the view that an expansion of human productive capability is the basis for the extension of freedom and equality in society.
Many forms of socialist theory hold that human behaviour is largely shaped by the social environment. In particular, socialism holds that social mores, values, cultural traits and economic practices are social creations and not the result of an immutable natural law. The object of their critique is thus not human avarice or human consciousness, but the material conditions and man-made social systems (i.e.: the economic structure of society) that gives rise to observed social problems and inefficiencies.
In the 20th century socialist economists were heavily influenced by neoclassical economics and its precepts in analytic philosophy. Notable socialists often combined neoclassical economics with Marxian analysis and historical materialism. Bertrand Russell, often considered to be the father of analytic philosophy, identified as a socialist. Bertrand Russell opposed the class struggle aspects of Marxism, viewing socialism solely as an adjustment of economic relations to accommodate modern machine production to benefit all of humanity through the progressive reduction of necessary work time.
Freedom and creativity.
Socialists tend to argue that "capitalism necessarily leads to unfair and exploitative concentrations of wealth and power in the hands of the relative few who emerge victorious from free-market competition—people who then use their wealth and power to reinforce their dominance in society. Because such people are rich, they may choose where and how to live, and their choices in turn limit the options of the poor."
From the socialist perspective, freedom is conceived of as a concrete situation as opposed to a purely abstract or moral concept, and is closely related to human creativity and the importance socialists ascribe to creative freedom. Socialists view creativity as an essential aspect of human nature, and define freedom as a state of being where individuals are able to express their creativity unhindered by constraints of both material scarcity and coercive social institutions. Marxists stress the importance of freeing the individual from coercive, exploitative and alienating social relationships they are compelled to partake in merely to survive, as well as the importance of economic development as providing the material basis for the existence of a state of society where there are enough resources to allow for each individual to pursue his or her genuine creative interests. In Marxist terminology, this is the goal of transcending alienation through material abundance.
The socialist concept of individuality is thus intertwined with the concept of individual creative expression. Karl Marx believed that expansion of the productive forces and technology was the basis for the expansion of human freedom, and that socialism, being a system that is consistent with modern developments in technology, would enable the flourishing of "free individualities" through the progressive reduction of necessary labour time. The reduction of necessary labour time to a minimum would grant individuals the opportunity to pursue the development of their true individuality and creativity.
Perspectives on equality.
In general, models of socialism often include some form of co-operative management of economic affairs based on equal power relationships, and socialists generally oppose hierarchies of a non-technical nature.
Karl Marx eschewed theorising on moral concepts. Instead of advocating principles of justice or equality, Marx's case for socialism was grounded in economic and materialist logic and his analysis of the development of the productive forces. Although Karl Marx is sometimes mistaken as an egalitarian, Marx opposed idealism and the concept of "equality". Marx did, however, have a theory of the evolution of moral principles in relation to specific economic systems.
In Marxist theory, upper-stage communism is based on a principle whereby access to goods and services is based on need, stressing equal access to the articles of consumption. The "equality" in a communist society is not about equality of outcome, but about equal access to the articles of consumption so that individuals are free from dependency on other individuals or groups, and are thus able to overcome alienation.
The American socialist economist John Roemer has put forth a new perspective of equality and its relationship to socialism. Roemer attempts to reformulate Marxist analysis to accommodate normative principles of distributive justice, shifting the argument for socialism away from purely technical and materialist reasons to one of distributive justice. Roemer argues that, according to the principle of distributive justice, the traditional definition of socialism based on the principle that individual compensation be proportional to the value of the labour one expands in production is inadequate. Roemer concludes that egalitarians must therefore go beyond socialism as it is classically defined.
Critique of capitalism.
Socialists do not base their critique of capitalism on the denunciation of greed, vilification of human nature or capitalists, or on human avarice but on the structural causes of social and economic problems that emerge from the normal functioning of the capitalist system.
Socialists generally argue that capitalism concentrates power and wealth within a small segment of society that controls the means of production and derives its wealth through economic exploitation. This creates unequal social relations which fail to provide opportunities for every individual to maximise their potential, and after a certain stage of development, fails to utilise available technology and resources to their maximum potential due to restrictive property relations.
Economics.
Socialist economics starts from the premise that "individuals do not live or work in isolation but live in cooperation with one another. Furthermore, everything that people produce is in some sense a social product, and everyone who contributes to the production of a good is entitled to a share in it. Society as a whole, therefore, should own or at least control property for the benefit of all its members."
The original conception of socialism was an economic system whereby production was organised in a way to directly produce goods and services for their utility (or use-value in classical and Marxian economics): the "direct allocation" of resources in terms of physical units as opposed to financial calculation and the economic laws of capitalism (see: Law of value), often entailing the end of capitalistic economic categories such as rent, interest, profit and money. In a fully developed socialist economy, production and balancing factor inputs with outputs becomes a technical process to be undertaken by engineers.
Market socialism refers to an array of different economic theories and systems that utilise the market mechanism to organise production and to allocate factor inputs among socially owned enterprises, with the economic surplus (profits) accruing to society in a social dividend as opposed to private capital owners. Variations of market socialism include Libertarian proposals such as mutualism, based on classical economics, and neoclassical economic models such as the Lange Model.
The ownership of the means of production can be based on direct ownership by the users of the productive property through worker cooperative; or commonly owned by all of society with management and control delegated to those who operate/use the means of production; or public ownership by a state apparatus. "Public ownership" may refer to the creation of state-owned enterprises, nationalisation, municipalisation or autonomous collective institutions. The fundamental feature of a socialist economy is that publicly owned, worker-run institutions produce goods and services in at least the "" of the economy.
Management and control over the activities of enterprises are based on self-management and self-governance, with equal power-relations in the workplace to maximise occupational autonomy. A socialist form of organisation would eliminate controlling hierarchies so that only a hierarchy based on technical knowledge in the workplace remains. Every member would have decision-making power in the firm and would be able to participate in establishing its overall policy objectives. The policies/goals would be carried out by the technical specialists that form the coordinating hierarchy of the firm, who would establish plans or directives for the work community to accomplish these goals.
The role and use of money in a hypothetical socialist economy is a contested issue. Socialists including Karl Marx, Robert Owen, Pierre-Joseph Proudhon and John Stuart Mill advocated various forms of labour vouchers or labour-credits, which like money would be used to acquire articles of consumption, but unlike money, they are unable to become capital and would not be used to allocate resources within the production process. Bolshevik revolutionary Leon Trotsky argued that money could not be arbitrarily abolished following a socialist revolution. Money had to exhaust its "historic mission", meaning it would have to be used until its function became redundant, eventually being transformed into bookkeeping receipts for statisticians, and only in the more distant future would money not be required for even that role.
 The economic anarchy of capitalist society as it exists today is, in my opinion, the real source of the evil... I am convinced there is only one way to eliminate these grave evils, namely through the establishment of a socialist economy, accompanied by an educational system which would be oriented toward social goals. In such an economy, the means of production are owned by society itself and are utilised in a planned fashion. A planned economy, which adjusts production to the needs of the community, would distribute the work to be done among all those able to work and would guarantee a livelihood to every man, woman, and child. The education of the individual, in addition to promoting his own innate abilities, would attempt to develop in him a sense of responsibility for his fellow men in place of the glorification of power and success in our present society.
 — Albert Einstein, "Why Socialism?", 1949
Planned economy.
A planned economy is a type of economy consisting of a mixture of public ownership of the means of production and the coordination of production and distribution through economic planning. There are two major types of planning: decentralised-planning and centralised-planning. Enrico Barone provided a comprehensive theoretical framework for a planned socialist economy. In his model, assuming perfect computation techniques, simultaneous equations relating inputs and outputs to ratios of equivalence would provide appropriate valuations in order to balance supply and demand.
The most prominent example of a planned economy was the economic system of the Soviet Union, and as such, the centralised-planned economic model is usually associated with the Communist states of the 20th century, where it was combined with a single-party political system. In a centrally planned economy, decisions regarding the quantity of goods and services to be produced are planned in advance by a planning agency. (See also: Analysis of Soviet-type economic planning). The economic systems of the Soviet Union and the Eastern Bloc are further classified as "command economies", which are defined as systems where economic coordination is undertaken by commands, directives and production targets.
Studies by economists of various political persuasions on the actual functioning of the Soviet economy indicate that it was not actually a planned economy. Instead of conscious planning, the Soviet economy was based on a process whereby the plan was modified by localised agents and the original plans went largely unfulfilled. Planning agencies, ministries and enterprises all adapted and bargained with each other during the formulation of the plan as opposed to following a plan passed down from a higher authority, leading some economists to suggest that planning did not actually take place within the Soviet economy and that a better description would be an "administered" or "managed" economy.
Although central planning was largely supported by Marxist Leninists, some factions within the Soviet Union before the rise of Stalinism held positions contrary to central planning. Leon Trotsky rejected central planning in favour of decentralised planning. He argued that central planners, regardless of their intellectual capacity, would be unable to coordinate effectively all economic activity within an economy because they operated without the input and tacit knowledge embodied by the participation of the millions of people who in the economy. As a result, central planners would be unable to respond to local economic conditions.
Self-managed economy.
A self-managed, decentralised economy is based on autonomous self-regulating economic units and a decentralised mechanism of resource allocation and decision-making. This model has found support in notable classical and neoclassical economists including Alfred Marshall, John Stuart Mill and Jaroslav Vanek. There are numerous variations of self-management, including labour-managed firms and worker-managed firms. The goals of self-management are to eliminate exploitation and reduce alienation. Guild socialism is a political movement advocating workers' control of industry through the medium of trade-related guilds "in an implied contractual relationship with the public". It originated in the United Kingdom and was at its most influential in the first quarter of the 20th century. It was strongly associated with G. D. H. Cole and influenced by the ideas of William Morris.
One such system is the cooperative economy, a largely free market economy in which workers manage the firms and democratically determine remuneration levels and labour divisions. Productive resources would be legally owned by the cooperative and rented to the workers, who would enjoy usufruct rights. Another form of decentralised planning is the use of cybernetics, or the use of computers to manage the allocation of economic inputs. The socialist-run government of Salvador Allende in Chile experimented with Project Cybersyn, a real-time information bridge between the government, state enterprises and consumers. Another, more recent, variant is participatory economics, wherein the economy is planned by decentralised councils of workers and consumers. Workers would be remunerated solely according to effort and sacrifice, so that those engaged in dangerous, uncomfortable, and strenuous work would receive the highest incomes and could thereby work less. A contemporary model for a self-managed, non-market socialism is Pat Devine's model of negotiated coordination. Negotiated coordination is based upon social ownership by those affected by the use of the assets involved, with decisions made by those at the most localised level of production.
Michel Bauwens identifies the emergence of the open software movement and peer-to-peer production as a new, alternative mode of production to the capitalist economy and centrally planned economy that is based on collaborative self-management, common ownership of resources, and the production of use-values through the free cooperation of producers who have access to distributed capital.
Anarchist communism is a theory of anarchism which advocates the abolition of the state, private property, and capitalism in favour of common ownership of the means of production. Anarcho-syndicalism was practiced in Catalonia and other places in the Spanish Revolution during the Spanish Civil War. Sam Dolgoff estimated that about eight million people participated directly or at least indirectly in the Spanish Revolution.
The economy of the former Socialist Federal Republic of Yugoslavia established a system based on market-based allocation, social ownership of the means of production and self-management within firms. This system substituted Yugoslavia's Soviet-type central planning with a decentralised, self-managed system after reforms in 1953.
The Marxian economist Richard D. Wolff argues that "re-organising production so that workers become collectively self-directed at their work-sites" not only moves society beyond both capitalism and state socialism of the last century, but would also mark another milestone in human history, similar to earlier transitions out of slavery and feudalism. As an example, Wolff claims that Mondragon is "a stunningly successful alternative to the capitalist organisation of production."
State-directed economy.
State socialism can be used to classify any variety of socialist philosophies that advocates the ownership of the means of production by the state apparatus, either as a transitional stage between capitalism and socialism, or as an end-goal in itself. Typically it refers to a form of technocratic management, whereby technical specialists administer or manage economic enterprises on behalf of society (and the public interest) instead of workers' councils or workplace democracy.
A state-directed economy may refer to a type of mixed economy consisting of public ownership over large industries, as promoted by various Social democratic political parties during the 20th century. This ideology influenced the policies of the British Labour Party during Clement Attlee's administration. In the biography of the 1945 UK Labour Party Prime Minister Clement Attlee, Francis Beckett states: "the government... wanted what would become known as a mixed economy".
Nationalisation in the UK was achieved through compulsory purchase of the industry (i.e. with compensation). British Aerospace was a combination of major aircraft companies British Aircraft Corporation, Hawker Siddeley and others. British Shipbuilders was a combination of the major shipbuilding companies including Cammell Laird, Govan Shipbuilders, Swan Hunter, and Yarrow Shipbuilders; the nationalisation of the coal mines in 1947 created a coal board charged with running the coal industry commercially so as to be able to meet the interest payable on the bonds which the former mine owners' shares had been converted into.
Market socialism.
Market socialism consists of publicly owned or cooperatively owned enterprises operating in a market economy. It is a system that utilises the market and monetary prices for the allocation and accounting of the means of production, thereby retaining the process of capital accumulation. The profit generated would be used to directly remunerate employees or finance public institutions. In state-oriented forms of market socialism, in which state enterprises attempt to maximise profit, the profits can be used to fund government programs and services through a social dividend, eliminating or greatly diminishing the need for various forms of taxation that exist in capitalist systems. The neoclassical economist Léon Walras believed that a socialist economy based on state ownership of land and natural resources would provide a means of public finance to make income taxes unnecessary. Yugoslavia implemented a market socialist economy based on cooperatives and worker self-management.
Mutualism is an economic theory and anarchist school of thought that advocates a society where each person might possess a means of production, either individually or collectively, with trade representing equivalent amounts of labour in the free market. Integral to the scheme was the establishment of a mutual-credit bank that would lend to producers at a minimal interest rate, just high enough to cover administration. Mutualism is based on a labour theory of value that holds that when labour or its product is sold, in exchange, it ought to receive goods or services embodying "the amount of labour necessary to produce an article of exactly similar and equal utility".
The current economic system in China is formally referred to as a Socialist market economy with Chinese characteristics. It combines a large state sector that comprises the 'commanding heights' of the economy, which are guaranteed their public ownership status by law, with a private sector mainly engaged in commodity production and light industry responsible from anywhere between 33% (People's Daily Online 2005) to over 70% of GDP generated in 2005. Although there has been a rapid expansion of private-sector activity since the 1980s, privatisation of state assets was virtually halted and were partially reversed in 2005. The current Chinese economy consists of 150 corporatised state-owned enterprises that report directly to China's central government. By 2008, these state-owned corporations had become increasingly dynamic and generated large increases in revenue for the state, resulting in a state-sector led recovery during the 2009 financial crises while accounting for most of China's economic growth. However, the Chinese economic model is widely cited as a contemporary form of state capitalism, the major difference between Western capitalism and the Chinese model being the degree of state-ownership of shares in publicly listed corporations.
The Socialist Republic of Vietnam has adopted a similar model after the Doi Moi economic renovation, but slightly differs from the Chinese model in that the Vietnamese government retains firm control over the state sector and strategic industries, but allows for private-sector activity in commodity production.
Social and political theory.
In this context, "socialism" has been used to refer to a political movement, a political philosophy and a hypothetical form of society these movements aim to achieve. As a result, in a political context socialism has come to refer to the strategy (for achieving a socialist society) or policies promoted by socialist organisations and socialist political parties; all of which have no connection to socialism as a socioeconomic system.
Marxism.
 – Karl Marx, "Critique of the Gotha Program"
Karl Marx and Friedrich Engels argued that socialism would emerge from historical necessity as capitalism rendered itself obsolete and unsustainable from increasing internal contradictions emerging from the development of the productive forces and technology. It was these advances in the productive forces combined with the old social relations of production of capitalism that would generate contradictions, leading to working-class consciousness.
Marx and Engels held the view that the consciousness of those who earn a wage or salary (the working class in the broadest Marxist sense) would be moulded by their conditions of wage slavery, leading to a tendency to seek their freedom or emancipation by overthrowing ownership of the means of production by capitalists, and consequently, overthrowing the state that upheld this economic order. For Marx and Engels, conditions determine consciousness and ending the role of the capitalist class leads eventually to a classless society in which the state would wither away.
The Marxist conception of socialism is that of a specific historical phase that will displace capitalism and precede communism. The major characteristics of socialism (particularly as conceived by Marx and Engels after the Paris Commune of 1871) are that the proletariat will control the means of production through a workers' state erected by the workers in their interests. Economic activity would still be organised through the use of incentive systems and social classes would still exist, but to a lesser and diminishing extent than under capitalism.
For orthodox Marxists, socialism is the lower stage of communism based on the principle of "from each according to his ability, to each according to his contribution" while upper stage communism is based on the principle of "from each according to his ability, to each according to his need"; the upper stage becoming possible only after the socialist stage further develops economic efficiency and the automation of production has led to a superabundance of goods and services.
Marx argued that the material productive forces (in industry and commerce) brought into existence by capitalism predicated a cooperative society since production had become a mass social, collective activity of the working class to create commodities but with private ownership (the relations of production or property relations). This conflict between collective effort in large factories and private ownership would bring about a conscious desire in the working class to establish collective ownership commensurate with the collective efforts their daily experience.
Che Guevara and Mao Zedong sought socialism based on the rural peasantry rather than the urban working class. Che Guevara attempted to inspire the peasants of Bolivia by his own example into a change of consciousness. Guevara said in 1965:
Socialism cannot exist without a change in consciousness resulting in a new fraternal attitude toward humanity, both at an individual level, within the societies where socialism is being built or has been built, and on a world scale, with regard to all peoples suffering from imperialist oppression.
Evolutionary and Institutional economics.
Thorstein Veblen, a leading American institutionalist and evolutionary economist, argued that a subset of the working-class, the technical specialists and engineers, would become the driving force behind socioeconomic change within capitalism. There is an antagonism between industry and business, where industry refers to the process of producing goods and services and business is defined as the process of "making money". Thorstein Veblen saw socialism as an immediate stage in an ongoing evolutionary process in economics that would result from the natural decay of the system of business enterprise. In contrast to Marx, he did not believe socialism would be the result of political struggle or political revolution by the working class as a whole and did not believe it to be the ultimate goal of humanity. But like Marx, Veblen saw technology as the underlying force driving social change.
Joseph Schumpeter viewed intellectuals and the intelligentsia as the group within society that would gradually move society toward socialism. Socialism would be partially a result of socio-economic evolution, the growth of workers' self-management, industrial democracy and social planning, and partially from political pressure on the part of intellectuals in Western society.
Role of the state.
Socialists have taken different perspectives on the state and the role it should play in revolutionary struggles, in constructing socialism, and within an established socialist economy.
In the 19th century the philosophy of state socialism was first explicitly expounded by the German political philosopher Ferdinand Lassalle. In contrast to Karl Marx’s perspective of the state, Lassalle rejected the concept of the state as a class-based power structure whose main function was to preserve existing class structures. Thus Lassalle also rejected the Marxist view that the state was destined to “wither away”. Lassalle considered the state to be an entity independent of class allegiances and an instrument of justice that would therefore be essential for achieving socialism.
Preceding the Bolshevik-led revolution in Russia, many socialists including reformists, orthodox Marxist currents such as council communism and the Mensheviks, Anarchists and Libertarian socialists criticised the idea of using the state to conduct central planning and own the means of production as a way to establish socialism. Following the victory of Leninism in Russia, the idea of "state socialism" spread rapidly throughout the socialist movement, and eventually "state socialism" came to be identified with the Soviet economic model.
Joseph Schumpeter rejected the association of socialism (and social ownership) with state ownership over the means of production, because the state as it exists in its current form is a product of capitalist society and cannot be transplanted to a different institutional framework. Schumpeter argued that there would be different institutions within socialism than those that exist within modern capitalism, just as feudalism had its own distinct and unique institutional forms. The state, along with concepts like property and taxation were concepts exclusive to commercial society (capitalism) and attempting to place them within the context of a future socialist society would amount to a distortion of these concepts by using them out of context
Utopian versus scientific.
Utopian socialism is a term used to define the first currents of modern socialist thought as exemplified by the work of Henri de Saint-Simon, Charles Fourier, and Robert Owen, which inspired Karl Marx and other early socialists. However, visions of imaginary ideal societies, which competed with revolutionary social-democratic movements, were viewed as not being grounded in the material conditions of society and as reactionary. Although it is technically possible for any set of ideas or any person living at any time in history to be a utopian socialist, the term is most often applied to those socialists who lived in the first quarter of the 19th century who were ascribed the label "utopian" by later socialists as a negative term, in order to imply naivete and dismiss their ideas as fanciful or unrealistic.
Religious sects whose members live communally, such as the Hutterites, for example, are not usually called "utopian socialists", although their way of living is a prime example. They have been categorised as religious socialists by some. Likewise, modern intentional communities based on socialist ideas could also be categorised as "utopian socialist".
For Marxists, the development of capitalism in western Europe provided a material basis for the possibility of bringing about socialism because, according to the "Communist Manifesto", "What the bourgeoisie produces above all is its own grave diggers", namely the working class, which must become conscious of the historical objectives set it by society.
Reform versus revolution.
Revolutionary socialists believe that a social revolution is necessary to effect structural changes to the socio-economic structure of society. Among revolutionary socialists there are differences in strategy, theory and the definition of "revolution". Orthodox Maxists and Left Communists take an Impossibilist stance, believing revolution should be spontaneous as a result of contradictions in society resulting from technological changes in the productive forces. Lenin theorised that under capitalism the workers cannot achieve class consciousness beyond organising into unions and making demands of the capitalists. Therefore, Leninists advocate that it is historically necessity for a vanguard of class conscious revolutionaries to take a central role in coordinating the social revolution to overthrow the capitalist state and, eventually, the institution of the state altogether. "Revolution" is not necessarily defined by revolutionary socialists as violent insurrection, but as a complete dismantling and rapid transformation of all areas of class society led by the majority of the masses: the working class.
Reformism is generally associated with social democracy and gradualist democratic socialism. Reformism is the belief that socialists should stand in parliamentary elections within capitalist society, and if elected, us the machinery of government to pass political and social reforms for the purposes of ameliorating the instabilities and inequities of capitalism.
Politics.
The major socialist political movements are described below. Independent socialist theorists, utopian socialist authors, and academic supporters of socialism may not be represented in these movements. Some political groups have called themselves socialist while holding views that some consider antithetical to socialism. The term "socialist" has also been used by some politicians on the political right as an epithet against certain individuals who do not consider themselves to be socialists, and against policies that are not considered socialist by their proponents.
There are many variations of socialism and as such there is no single definition encapsulating all of socialism. However there have been common elements identified by scholars. Angelo S. Rappoport in his "Dictionary of Socialism" (1924) analysed forty definitions of socialism to conclude that common elements of socialism include: general criticisms of the social effects of private ownership and control of capital – as being the cause of poverty, low wages, unemployment, economic and social inequality, and a lack of economic security; a general view that the solution to these problems is a form of collective control over the means of production, distribution and exchange (the degree and means of control vary amongst socialist movements); agreement that the outcome of this collective control should be a society based upon social justice, including social equality, economic protection of people, and should provide a more satisfying life for most people. Bhikhu Parekh in "The Concepts of Socialism" (1975) identifies four core principles of socialism and particularly socialist society: sociality, social responsibility, cooperation, and planning. Michael Freeden in his study "Ideologies and Political Theory" (1996) states that all socialists share five themes: the first is that socialism posits that society is more than a mere collection of individuals; second, that it considers human welfare a desirable objective; third, that it considers humans by nature to be active and productive; fourth, it holds the belief of human equality; and fifth, that history is progressive and will create positive change on the condition that humans work to achieve such change.
Anarchism.
Anarchism is a political philosophy that advocates stateless societies often defined as self-governed voluntary institutions, but that several authors have defined as more specific institutions based on non-hierarchical free associations. Anarchism holds the state to be undesirable, unnecessary, or harmful. While anti-statism is central, some argue that anarchism entails opposing authority or hierarchical organisation in the conduct of human relations, including, but not limited to, the state system. Mutualists advocate market socialism, collectivist anarchists workers cooperatives and salaries based on the amount of time contributed to production, anarcho-communists advocate a direct transition from capitalism to libertarian communism and a gift economy and anarcho-syndicalists worker's direct action and the general strike.
Libertarian socialism.
Libertarian socialism (sometimes called social anarchism, left-libertarianism and socialist libertarianism) is a group of political philosophies within the socialist movement that reject the view of socialism as state ownership or command of the means of production within a more general criticism of the state form iself as well as of wage labour relationships within the workplace. Instead it emphasises workers self-management of the workplace and decentralised structures of political government asserting that a society based on freedom and equality can be achieved through abolishing authoritarian institutions that control certain means of production and subordinate the majority to an owning class or political and economic elite. Libertarian socialists generally place their hopes in decentralised means of direct democracy and federal or confederal associations such as libertarian municipalism, citizens' assemblies, trade unions, and workers' councils. All of this is generally done within a general call for libertarian and voluntary human relationships through the identification, criticism, and practical dismantling of illegitimate authority in all aspects of life.
Past and present political philosophies and movements commonly described as libertarian socialist include anarchism (especially anarchist communism, anarchist collectivism, anarcho-syndicalism, and mutualism) as well as autonomism, communalism, participism, revolutionary syndicalism, and libertarian Marxist philosophies such as council communism and Luxemburgism,; as well as some versions of "utopian socialism" and individualist anarchism.
Democratic socialism.
Modern democratic socialism is a broad political movement that seeks to promote the ideals of socialism within the context of a democratic system. Some Democratic socialists support social democracy as a temporary measure to reform the current system, while others reject reformism in favour of more revolutionary methods. Modern social democracy emphasises a program of gradual legislative modification of capitalism in order to make it more equitable and humane, while the theoretical end goal of building a socialist society is either completely forgotten or redefined in a pro-capitalist way. The two movements are widely similar both in terminology and in ideology, although there are a few key differences.
The major difference between social democracy and democratic socialism is the object of their politics: contemporary social democrats support a welfare state and unemployment insurance as a means to "humanise" capitalism, whereas democratic socialists seek to replace capitalism with a socialist economic system, arguing that any attempt to "humanise" capitalism through regulations and welfare policies would distort the market and create economic contradictions.
Democratic socialism generally refers to any political movement that seeks to establish an economy based on economic democracy by and for the working class. Democratic socialism is difficult to define, and groups of scholars have radically different definitions for the term. Some definitions simply refer to all forms of socialism that follow an electoral, reformist or evolutionary path to socialism, rather than a revolutionary one.
 You can't talk about ending the slums without first saying profit must be taken out of slums. You're really tampering and getting on dangerous ground because you are messing with folk then. You are messing with captains of industry. Now this means that we are treading in difficult water, because it really means that we are saying that something is wrong with capitalism. There must be a better distribution of wealth, and maybe America must move toward a democratic socialism.
 — Martin Luther King, Jr., 1966.
Religious socialism.
Christian socialism is a broad concept involving an intertwining of the Christian religion with the politics and economic theories of socialism.
Islamic socialism is a term coined by various Muslim leaders to describe a more spiritual form of socialism. Muslim socialists believe that the teachings of the Qur'an and Muhammad are compatible with principles of equality and public ownership drawing inspiration from the early Medina welfare state established by Muhammad. Muslim Socialists are more conservative than their western contemporaries and find their roots in Anti-imperialism, anti-colonialism and Arab nationalism. Islamic Socialist leaders believe in Democracy and deriving legitimacy from public mandate as opposed to religious texts.
Leninism and precedents.
Blanquism refers to a conception of revolution generally attributed to Louis Auguste Blanqui which holds that socialist revolution should be carried out by a relatively small group of highly organised and secretive conspirators. Having seized power, the revolutionaries would then use the power of the state to introduce socialism. It is considered a particular sort of 'putschism' – that is, the view that political revolution should take the form of a "putsch" or "coup d'état". Rosa Luxemburg and Eduard Bernstein have criticised Lenin that his conception of revolution was elitist and essentially 'Blanquist'. Marxism–Leninism is a political ideology combining Marxism (the scientific socialist concepts theorised by Karl Marx and Friedrich Engels) and Leninism (Vladimir Lenin's theoretical expansions of Marxism which include anti-imperialism, democratic centralism, and party-building principles). Marxism–Leninism was the official ideology of the Communist Party of the Soviet Union and of the Communist International (1919–43) and later it became the main guiding ideology for trotskists, maoists, and stalinists.
Social democracy.
Social democracy is a political ideology which "is derived from a socialist tradition of political thought. Many social democrats refer to themselves as socialists
or democratic socialists, and some use these terms interchangeably. Others have opined that there are clear differences between the three terms, and preferred to describe their own political beliefs by using the term ‘social democracy’ only." There are two main directions, either to establish democratic socialism, or to build a welfare state within the framework of the capitalist system. The first variant has officially its goal by establishing democratic socialism through reformist and gradualist methods. In the second variant Social democracy becomes a policy regime involving a welfare state, collective bargaining schemes, support for publicly financed public services, and a Capitalist-based economy like a mixed economy. It is often used in this manner to refer to the social models and economic policies prominent in Western and Northern Europe during the later half of the 20th century. It has been described by Jerry Mander as “hybrid” economics, an active collaboration of capitalist and socialist visions, and, while such systems aren't perfect, they tend to provide high standards of living. Numerous studies and surveys indicate that people tend to live happier lives in social democratic societies rather than neoliberal ones.
Social democrats supporting the first variant, advocate for a peaceful, evolutionary transition of the economy to socialism through progressive social reform of capitalism. It asserts that the only acceptable constitutional form of government is representative democracy under the rule of law. It promotes extending democratic decision-making beyond political democracy to include economic democracy to guarantee employees and other economic stakeholders sufficient rights of co-determination. It supports a mixed economy that opposes the excesses of capitalism such as inequality, poverty, and oppression of various groups, while rejecting both a totally free market or a fully planned economy. Common social democratic policies include advocacy of universal social rights to attain universally accessible public services such as education, health care, workers' compensation, and other services, including child care and care for the elderly. Social democracy is connected with the trade union labour movement and supports collective bargaining rights for workers. Most social democratic parties are affiliated with the Socialist International.
Syndicalism.
Syndicalism is a social movement that operates through industrial trade unions and rejects state socialism and the use of establishment politics to establish or promote socialism. They reject using state power to construct a socialist society, favouring strategies such as the General strike. Syndicalists advocate a socialist economy based on federated unions or syndicates of workers who own and manage the means of production. Some Marxist currents advocate Syndicalism, such as DeLeonism. Anarcho-syndicalism is a theory of anarchism which views syndicalism as a method for workers in capitalist society to gain control of an economy and, with that control, influence broader society. The Spanish Revolution, largely orchestrated by the anarcho-syndicalist trade union CNT during the Spanish Civil War offers an historical example. The International Workers' Association is an international federation of anarcho-syndicalist labor unions and initiatives.
Socialism and progressive social movements.
Socialist feminism is a branch of feminism that focuses upon both the public and private spheres of a woman's life and argues that liberation can only be achieved by working to end both the economic and cultural sources of women's oppression. Marxist feminism's foundation is laid by Friedrich Engels in his analysis of gender oppression in "The Origin of the Family, Private Property, and the State" (1884). August Bebel's "Woman under Socialism" (1879), the "single work dealing with sexuality most widely read by rank-and-file members of the Social Democratic Party of Germany (SPD)". In the late nineteenth and early twentieth centuries, both Clara Zetkin and Eleanor Marx were against the demonisation of men and supported a proletariat revolution that would overcome as many male–female inequalities as possible. As their movement already had the most radical demands in women's equality, most Marxist leaders, including Clara Zetkin and Alexandra Kollontai, counterposed Marxism against liberal feminism, rather than trying to combine them. Anarcha-feminism began with late 19th and early 20th century authors and theorists such as anarchist feminists Emma Goldman and Voltairine de Cleyre In the Spanish Civil War, an anarcha-feminist group, Mujeres Libres ("Free Women") linked to the Federación Anarquista Ibérica, organised to defend both anarchist and feminist ideas. In 1972, the Chicago Women's Liberation Union published "Socialist Feminism: A Strategy for the Women's Movement," which is believed to be the first to use the term "socialist feminism," in publication.
Many socialists were early advocates for LGBT rights. For early socialist Charles Fourier, true freedom could only occur without suppressing passions; the suppression of passions is not only destructive to the individual, but to society as a whole. Writing before the advent of the term 'homosexuality', Fourier recognised that both men and women have a wide range of sexual needs and preferences which may change throughout their lives, including same-sex sexuality and "androgénité". He argued that all sexual expressions should be enjoyed as long as people are not abused, and that "affirming one's difference" can actually enhance social integration. In Oscar Wilde's "The Soul of Man Under Socialism", he passionately advocates for an egalitarian society where wealth is shared by all, while warning of the dangers of social systems that crush individuality. Wilde's libertarian socialist politics were shared by other figures who actively campaigned for homosexual emancipation in the late 19th century such as Edward Carpenter. "The Intermediate Sex: A Study of Some Transitional Types of Men and Women" was a book from 1908 and an early work arguing for gay liberation written by Edward Carpenter who was also an influential personality in the foundation of the Fabian Society and the Labour Party. After the Russian Revolution under the leadership of Vladimir Lenin and Leon Trotsky, the Soviet Union abolished previous laws against homosexuality. Harry Hay was an early leader in the American LGBT rights movement as well as a member of the Communist Party USA. He is known for his roles in helping to found several gay organisations, including the Mattachine Society, the first sustained gay rights group in the United States which in its early days had a strong marxist influence. The "Encyclopedia of Homosexuality" reports that "As Marxists the founders of the group believed that the injustice and oppression which they suffered stemmed from relationships deeply embedded in the structure of American society". Also emerging from a number of events, such as the May 1968 insurrection in France, the anti-Vietnam war movement in the US and the Stonewall riots of 1969, militant Gay Liberation organisations began to spring up around the world. Many saw their roots in left radicalism more than in the established homophile groups of the time, The Gay Liberation Front took an anti-capitalist stance and attacked the nuclear family and traditional gender roles.
Eco-socialism, green socialism or socialist ecology is an political position merging aspects of Marxism, socialism, and/or libertarian socialism with that of green politics, ecology and alter-globalisation. Eco-socialists generally believe that the expansion of the capitalist system is the cause of social exclusion, poverty, war and environmental degradation through globalisation and imperialism, under the supervision of repressive states and transnational structures. Contrary to the depiction of Karl Marx by some environmentalists, social ecologists and fellow socialists as a productivist who favoured the domination of nature, eco-socialists have revisited Marx's writings and believe that he "was a main originator of the ecological world-view". Eco-socialist authors, like John Bellamy Foster and Paul Burkett, point to Marx's discussion of a "metabolic rift" between man and nature, his statement that "private ownership of the globe by single individuals will appear quite absurd as private ownership of one man by another" and his observation that a society must "hand it [the planet] down to succeeding generations in an improved condition". The English socialist William Morris is largely credited with developing key principles of what was later called eco-socialism. During the 1880s and 1890s, Morris promoted his eco-socialist ideas within the Social Democratic Federation and Socialist League. Green anarchism, or ecoanarchism, is a school of thought within anarchism which puts a particular emphasis on environmental issues. An important early influence was the thought of the American anarchist Henry David Thoreau and his book "Walden" as well as Leo Tolstoy and Élisée Reclus. In the late 19th century there emerged anarcho-naturism as the fusion of anarchism and naturist philosophies within individualist anarchist circles in France, Spain, Cuba and Portugal.Social ecology is closely related to the work and ideas of Murray Bookchin and influenced by anarchist Peter Kropotkin. Bookchin´s first book, "Our Synthetic Environment," was published under the pseudonym Lewis Herber in 1962, a few months before Rachel Carson's "Silent Spring". His groundbreaking essay "Ecology and Revolutionary Thought" introduced ecology as a concept in radical politics. In the 1970s, Barry Commoner, suggesting a left-wing response to the "Limits to Growth" model that predicted catastrophic resource depletion and spurred environmentalism, postulated that capitalist technologies were chiefly responsible for environmental degradation, as opposed to population pressures. The 1990s saw the socialist feminists Mary Mellor and Ariel Salleh address environmental issues within an eco-socialist paradigm. With the rising profile of the anti-globalisation movement in the Global South, an "environmentalism of the poor", combining ecological awareness and social justice, has also become prominent. David Pepper also released his important work, "Ecosocialism: From Deep Ecology to Social Justice", in 1994, which critiques the current approach of many within Green politics, particularly deep ecologists. Currently, many Green Parties around the world, such as the Dutch Green Left Party (GroenLinks), contain strong eco-socialist elements. Radical Red-green alliances have been formed in many countries by eco-socialists, radical Greens and other radical left groups. In Denmark, the Red-Green Alliance was formed as a coalition of numerous radical parties. Within the European Parliament, a number of far-left parties from Northern Europe have organised themselves into the Nordic Green Left Alliance.
Criticism.
Socialism has been critiqued from numerous different perspectives. Because there are many models of socialism, most critiques are only focused on a specific type of socialism.
Economic liberals and right libertarians view private ownership of the means of production and the market exchange as natural entities or moral rights which are central to their conceptions of freedom and liberty, and view the economic dynamics of capitalism as immutable and absolute. Therefore, they perceive public ownership of the means of production, cooperatives and economic planning as infringements upon liberty.
According to the Austrian school economist Ludwig von Mises, an economic system that does not use money, financial calculation and market pricing will be unable to effectively value capital goods and coordinate production, and therefore these types of socialism are impossible because they lack the necessary information to perform economic calculation in the first place. Another central argument leveled against socialist systems based on economic planning is based on the use of dispersed knowledge. State socialism is unfeasible in this view because information cannot be aggregated by a central body and effectively used to formulate a plan for an entire economy, because doing so would result in distorted or absent price signals.
Many economic criticisms of socialism focus on the experiences of Soviet-type planned economies. It is argued that a lack of budget constraints in enterprises operating in a planned economy reduces incentives for enterprises to act on information efficiently, thereby reducing overall welfare for society.
Other economists criticise models of socialism based on neoclassical economics for their reliance on economic equilibrium and pareto efficiency.
In light of these criticisms, philosophers such as Howard Zinn retort:
Let's talk about socialism. I think it's very important to bring back the idea of socialism into the national discussion to where it was at the turn of the [last] century before the Soviet Union gave it a bad name. Socialism had a good name in this country. Socialism had Eugene Debs. It had Clarence Darrow. It had Mother Jones. It had Emma Goldman. It had several million people reading socialist newspapers around the country. Socialism basically said, hey, let's have a kinder, gentler society. Let's share things. Let's have an economic system that produces things not because they're profitable for some corporation, but produces things that people need. People should not be retreating from the word socialism because you have to go beyond capitalism.
Further reading.
</dl>

</doc>
<doc id="26849" url="http://en.wikipedia.org/wiki?curid=26849" title="Sabine River (Texas–Louisiana)">
Sabine River (Texas–Louisiana)

The Sabine River (; Alibamu: "Sabìina, Sabìnka" ) is a river, 510 mi long, in the U.S. states of Texas and Louisiana. In its lower course, it forms part of the boundary between the two states and empties into Sabine Lake, an estuary of the Gulf of Mexico. The river formed part of the United States-Mexican as well as the United States-Republic of Texas international boundary during the early 19th century. The upper reaches of the river flow through the prairie country of northeast Texas. Along much of its lower reaches, it flows through pine forests along the Texas-Louisiana border, and the bayou country near the Gulf Coast. The river drains an area of 9756 mi2, of which 7426 mi2 is in Texas and 2330 mi2 in Louisiana. It flows through an area of abundant rainfall and discharges the largest volume of any river in Texas. The name Sabine (Sp: "Río de Sabinas") comes from the Spanish word for cypress, in reference to the extensive growth of Bald cypresses along the lower river. The river flows through an important petroleum-producing region, and the lower river near the Gulf is among the most industrialized areas of the southeastern United States. The river was often described as the dividing line between the Old South and the New Southwest.
Description.
The Sabine rises in northeast Texas by the union of three branches: the Cowleech Fork, Caddo Fork, and South Fork. The Cowleech Fork rises in northwestern Hunt County and flows southeast for 49.2 mi. The Caddo Fork, shown as "Caddo Creek" on federal maps, rises in two tributary forks, the East Caddo Fork and the West Caddo Fork, in northwestern Hunt County. The South Fork rises in the southwestern corner of Hunt County and flows east for 28.3 mi, joining the Caddo Fork and Cowleech Fork in southeastern Hunt County. The confluence of the forks is now submerged in the Lake Tawakoni reservoir. The combined river flows southeast across northeast Texas and is joined by a fourth branch, Lake Fork Creek, 70.0 mi downstream from the reservoir.
In northeast Texas, the river flows past Mineola, Gladewater, Big Sandy, and Longview, the largest city on the river, to southwest of Shreveport at the 32nd parallel north, where it establishes the Texas-Louisiana boundary. It flows south, forming the state line for the remainder of its course. It is impounded 10 mi west of Leesville, Louisiana, to form the 70 mi Toledo Bend Reservoir, with the Sabine National Forest along its western bank. South of the reservoir it passes through the bayou country, surrounded by wetlands, as well as widespread industrial areas near the Gulf Coast. Approximately 10 mi south of Orange, Texas, it meets the Neches River from the west to form the 17 mi and 7 mi Sabine Lake, which drains through Sabine Pass to the Gulf of Mexico. The city of Port Arthur, Texas, sits along the western shore of Sabine Lake.
History.
Archeological evidence indicates the valley of the river was inhabited as far back as 12,000 years ago. Starting in the 8th century the Caddo inhabited the area, building extensive mounds. The Caddo culture flourished until the late 13th century, but remnants of the Caddo were living along the river when the first European explorers arrived in the 16th century.
The river was given its name in 1716 by Domingo Ramón and appeared as "Río de Sabinas" on a 1721 map. The river was used by French traders, and at various times, the river was claimed by both Spain and France. After the acquisition by Spain of the French territory of Louisiana in 1763, the capital of the Spanish province of Texas was established on the east side of the river, near present-day Robeline, Louisiana.
River transportation.
The Sabine River was too deep to ford, proving to be navigable, and by the 1840s steamboats were traveling from Logansport to Sabine Lake. Early travelers and settlers would have to swim the river on horseback and cattle would have to be driven into the river to swim across.
Ferries.
Recorded ferry use began 1794, when Louis Chabinan (Sharben), his wife Margarite LaFleur, and their four children settled on the east bank of the Sabine River on land purchased from Vicinte Michele. Louis built a ferry on the river where, called Paso del Chaland, near where Louisiana State Highway 6 (La 6) and Texas State Highway 21 now meet, at the site of the present day Pendleton Bridge. In 1796, Louis was drowned after being kicked by a horse and falling into the Sabine. Michel Crow married his widow and ran the ferry, until he sold it to James Gaines circa 1819, and was renamed Gaines Ferry. This ferry was in service until replaced by the Pendleton bridge in 1937. Crow also operated a ferry he started farther north, a 120 foot crossing started in 1796, on what became known as Carter's Ferry Road that is now Texas FM 276. Carter's ferry was 25 miles from San Augustine and 15 miles from Many. Crow sold the ferry to Carter. Farther north, and just above Bayou Lanan was Williamson Ferry. 
Other ferries on the Sabine River:
The main Sabine River crossings were the El Camino Real (King’s Highway) from Natchitoches, or “Upper Route” from Shreveport and the “Lower” Route, from Opelousas called “The Old Beef Trail”. It was used to drive thousands of cattle from Texas to Alexandria for shipment to cities such as New Orleans. Hickman Ferry was a shipping point for areas as far west as Burkeville. Sabine River Ports from Sabine Pass in river mileage were "Belgrade", 171 miles; "Stark’s Landing" 191 miles; "Loftin Ferry" and "Bayou Lanacoco" 220 miles; "Hickman’s Ferry" 252 miles; "Burnham’s Landing" 261 miles; and "Burr’s Ferry" 281 miles.
Border dispute.
The area's geography remained one of the least understood in the region, with various Spanish maps containing errors in the naming of the Sabine and Neches, and sometimes showed them flowing independently into the Gulf of Mexico. After the Louisiana Purchase by the United States in 1803, this indefinite nature of the boundary between the U.S. and Spain led to an agreement on November 6, 1806, negotiated by Gen. James Wilkinson and Lt. Col. Simón de Herrera, to establish a neutral territory on both sides of the river.
The indefinite boundary was resolved by the Adams-Onís Treaty of 1819, which established the river as the boundary from the Gulf to the 32nd parallel. The Spanish delay in the ratification of the treaty, as well as the 1821 independence of Mexico, re-ignited the boundary dispute. The United States, at the insistence of Anthony Butler, claimed for a while that the names of the Sabine and Neches had been reversed, and thus claimed the treaty established the boundary at the Neches. The first American settlers began arriving in the region in the 1820s, soon outnumbering the Mexicans by 10 to 1. After the independence of the Republic of Texas from Mexico in 1836, the boundary between the U.S. and Texas was firmly established at the Sabine in accordance with the Adams-Onís Treaty. The river served as the western boundary of the United States until the Texas Annexation in 1845.
Riverboats.
In 1843, Capt. John Clemmons made the first trip up the Sabine in the steamboat Sabine. Steamboats carried passengers, as well as commodities such as cotton, from as far north as Logansport down to Sabine Pass.
Jean Lafitte made many trips up the Sabine and reportedly started the colony of Shacklefoot on the Texas side of the Sabine River, south of Carter's ferry up Bayou Patroon.
During the American Civil War, on September 8, 1863, a small Confederate force thwarted a Union invasion of Texas at the Second Battle of Sabine Pass, fought at the mouth of the river.
In the late 19th and early 20th century, the middle course of the river became the scene of widespread logging. The discovery of petroleum at nearby Spindletop led to the river basin becoming the scene of widespread oil drilling. The lower river saw the development of many oil refineries and chemical plants, leading to a degradation of the water quality, which in turn led to on-going efforts to restore the quality of the river.
The lower river south of Orange, Texas, to Sabine Lake forms part of the Intracoastal Waterway, carrying barge traffic.
As a young man, Captain Bill McDonald of the Texas Rangers operated a small store at Brown's Bluff (modern-day Elderville, Texas) on the Sabine in Gregg County, Texas.
Toledo Bend reservoir.
Hadden's ferry was the site of the ground breaking ceremony held on October 5, 1961 for the 181,600 acre Toledo Bend Reservoir. Dedicated October 11, 1969, the reservoir is the largest man-made lake in the south and inundated all of the ferry sites within its boundary.
In literature and music.
Joe R. Lansdale, who grew up in East Texas, often features the river in his work.
Gerald Duff, novelist and short story writer, has set several of his works in the territory of the Sabine, including the stories "Texas Wherever You Look," "The Way a Blind Man Tracks Light," and "Redemption". His novels "Graveyard Working" and "Coasters" are centered geographically and metaphorically along the Sabine. His novel Blue Sabine (2012) was chosen by the Texas State History Museum as a book of the month for discussion of the light it sheds on the valley of the Sabine and its people.
In Jack Kerouac's 1955 novel, "On The Road," the book's narrator Sal Paradise and other prominent character Dean Moriarty (an alias of Kerouac's friend Neal Cassady) encounter the Sabine River. It is recorded as an "evil old river," and "the mansion of the snake...we could almost hear the slither of a million copperheads." A novel in which the theme rests heavily on familiarity with the American continent, it is interesting that Kerouac labels the region as "a manuscript of the night we couldn't read."
Blues singer Alger "Texas" Alexander wrote a song called the "Sabine River Blues".
January 2010 oil spill.
Up to around 450,000 gallons (about 11,000 bls) of crude oil spilled over the Sabine River when the tanker "Eagle Otome" which was carrying the shipment struck two chemical-carrying barges due to loss of engine power on January 24, 2010, at 10 AM local time.

</doc>
<doc id="26859" url="http://en.wikipedia.org/wiki?curid=26859" title="Synergy">
Synergy

Synergy is the creation of a whole that is greater than the simple sum of its parts. The term "synergy" comes from the Attic Greek word συνεργία "synergia" from "synergos", συνεργός, meaning "working together".
History.
The words "synergy" and "synergetic" have been used in the field of physiology since at least the middle of the 19th century:
SYN'ERGY, "Synergi'a", "Synenergi'a", (F.) "Synergie"; from "συν", 'with,' and "εργον", 'work.' A correlation or concourse of action between different organs in health; and, according to some, in disease.
In 1896, applied the term "synergy" to social psychology by writing "La synergie sociale", in which he argued that Darwinian theory failed to account for "social synergy" or "social love", a collective evolutionary drive. The highest civilizations were the work not only of the elite but of the masses too; those masses must be led, however, because the croud, a feminine and unconscious force, cannot distinguish between good and evil.
In 1909, Lester Frank Ward defined synergy as the universal constructive principle of nature:
I have characterized the social struggle as centrifugal and social solidarity as centripetal. Either alone is productive of evil consequences. Struggle is essentially destructive of the social order, while communism removes individual initiative. The one leads to disorder, the other to degeneracy. What is not seen—the truth that has no expounders—is that the wholesome, constructive movement consists in the properly ordered combination and interaction of both these principles. This is "social synergy", which is a form of cosmic synergy, the universal constructive principle of nature.
Descriptions and usages.
In the natural world, synergistic phenomena are ubiquitous, ranging from physics (for example, the different combinations of quarks that produce protons and neutrons) to chemistry (a popular example is water, a compound of hydrogen and oxygen), to the cooperative interactions among the genes in genomes, the division of labor in bacterial colonies, the synergies of scale in multi-cellular organisms, as well as the many different kinds of synergies produced by socially-organized groups, from honeybee colonies to wolf packs and human societies: compare stigmergy, a mechanism of indirect coordination between agents or actions that results in the self-assembly of complex systems. Even the tools and technologies that are widespread in the natural world represent important sources of synergistic effects. The tools that enabled early hominins to become systematic big-game hunters is a primordial human example.
In the context of organizational behavior, following the view that a cohesive group is more than the sum of its parts, synergy is the ability of a group to outperform even its best individual member. These conclusions are derived from the studies conducted by Jay Hall on a number of laboratory-based group ranking and prediction tasks. He found that effective groups actively looked for the points in which they disagreed and in consequence encouraged conflicts amongst the participants in the early stages of the discussion. In contrast, the ineffective groups felt a need to establish a common view quickly, used simple decision making methods such as averaging, and focused on completing the task rather than on finding solutions they could agree on.
In a technical context, its meaning is a construct or collection of different elements working together to produce results not obtainable by any of the elements alone. The elements, or parts, can include people, hardware, software, facilities, policies, documents: all things required to produce system-level results. The value added by the system as a whole, beyond that contributed independently by the parts, is created primarily by the relationship among the parts, that is, how they are interconnected. In essence, a system constitutes a set of interrelated components working together with a common objective: fulfilling some designated need.
If used in a business application, synergy means that teamwork will produce an overall better result than if each person within the group were working toward the same goal individually. However, the concept of group cohesion needs to be considered. Group cohesion is that property that is inferred from the number and strength of mutual positive attitudes among members of the group. As the group becomes more cohesive, its functioning is affected in a number of ways. First, the interactions and communication between members increase. Common goals, interests and small size all contribute to this. In addition, group member satisfaction increases as the group provides friendship and support against outside threats.
There are negative aspects of group cohesion that have an effect on group decision-making and hence on group effectiveness. There are two issues arising. The risky shift phenomenon is the tendency of a group to make decisions that are riskier than those that the group would have recommended individually. Group Polarisation is when individuals in a group begin by taking a moderate stance on an issue regarding a common value and, after having discussed it, end up taking a more extreme stance.
A second, potential negative consequence of group cohesion is group think. Group think is a mode of thinking that people engage in when they are deeply involved in cohesive group, when the members' striving for unanimity overrides their motivation to appraise realistically the alternative courses of action. Studying the events of several American policy "disasters" such as the failure to anticipate the Japanese attack on Pearl Harbor (1941) and the Bay of Pigs Invasion fiasco (1961), Irving Janis argued that they were due to the cohesive nature of the committees that made the relevant decisions.
That decisions made by committees lead to failure in a simple system is noted by Dr. Chris Elliot. His case study looked at IEEE-488, an international standard set by the leading US standards body; it led to a failure of small automation systems using the IEEE-488 standard (which codified a proprietary communications standard HP-IB). But the external devices used for communication were made by two different companies, and the incompatibility between the external devices led to a financial loss for the company. He argues that systems will be safe only if they are designed, not if they emerge by chance.
The idea of a systemic approach is endorsed by the United Kingdom Health and Safety Executive. The successful performance of the health and safety management depends upon the analyzing the causes of incidents and accidents and learning correct lessons from them. The idea is that all events (not just those causing injuries) represent failures in control, and present an opportunity for learning and improvement. UK Health and Safety Executive, "Successful health and safety management" (1997): this book describes the principles and management practices, which provide the basis of effective health and safety management. It sets out the issues that need to be addressed, and can be used for developing improvement programs, self-audit, or self-assessment. Its message is that organizations must manage health and safety with the same degree of expertise and to the same standards as other core business activities, if they are to effectively control risks and prevent harm to people.
The term synergy was refined by R. Buckminster Fuller, who analyzed some of its implications more fully and coined the term Synergetics.
Drug synergy.
Drug synergy occurs when drugs can interact in ways that enhance or magnify one or more effects, or side-effects, of those drugs. This is sometimes exploited in combination preparations, such as codeine mixed with acetaminophen or ibuprofen to enhance the action of codeine as a pain reliever. Some drug users frequently utilize 5-HTP, a serotonin precursor often used as an antidepressant, prior to and after ingestion of MDMA. It is said to increase the "high" and decreases the "comedown" stages of MDMA use, although most anecdotal evidence has pointed to 5-HTP significantly altering the effect of MDMA when used at the same time, as well as potentiating the side effects associated with serotonin syndrome ). Other examples include the use of cannabis with LSD, where the active chemicals in cannabis have been reported to enhance the hallucinatory experience of LSD..
Negative effects of synergy are a form of contraindication. For example, a combination of depressant drugs that affect the central nervous system (CNS), such as alcohol and Valium, can cause a greater reaction than simply the sum of the individual effects of each drug if they were used separately. In this particular case, the most serious consequence of drug synergy is exaggerated respiratory depression, which can be fatal if left untreated. Mixing drugs can produce potentially fatal reactions within the brain, such as serotonin syndrome, due to synergistic reactions changing chemical and receptor activity. In the case of Monoamine oxidase inhibitor (MAOI) medications, mainly used as last-straw antidepressants, mixing certain foods and drugs may cause hypertension or hyperserotonemia.
Drug synergy can occur both in biological activity and because of pharmacokinetics. Shared metabolic enzymes can cause drugs to remain in the bloodstream much longer in higher concentrations than if individually taken.
Biological sciences.
Synergy of various kinds has been advanced by Peter Corning as a causal agency that can explain the progressive evolution of complexity in living systems over the course of time. According to the Synergism Hypothesis, synergistic effects have been the drivers of cooperative relationships of all kinds and at all levels in living systems. The thesis, in a nutshell, is that synergistic effects have often provided functional advantages (economic benefits) in relation to survival and reproduction that have been favored by natural selection. The cooperating parts, elements, or individuals become, in effect, functional “units” of selection in evolutionary change. Similarly, environmental systems may react in a non-linear way to perturbations, such as climate change, so that the outcome may be greater than the sum of the individual component alterations. Synergistic responses are a complicating factor in environmental modeling.
Pest synergy.
Pest synergy would occur in a biological host organism population, where, for example, the introduction of parasite A may cause 10% fatalities, and parasite B may also cause 10% loss. When both parasites are present, the losses would normally be expected to total less than 20%, yet, in some cases, losses are significantly greater. In such cases, it is said that the parasites in combination have a synergistic effect.
Toxicological synergy.
Toxicological synergy is of concern to the public and regulatory agencies because chemicals individually considered safe might pose unacceptable health or ecological risk in combination. Articles in scientific and lay journals include many definitions of chemical or toxicological synergy, often vague or in conflict with each other. Because toxic interactions are defined relative to the expectation under "no interaction", a determination of synergy (or antagonism) depends on what is meant by "no interaction". The United States Environmental Protection Agency has one of the more detailed and precise definitions of toxic interaction, designed to facilitate risk assessment. In their guidance documents, the no-interaction default assumption is dose addition, so synergy means a mixture response that exceeds that predicted from dose addition. The EPA emphasizes that synergy does not always make a mixture dangerous, nor does antagonism always make the mixture safe; each depends on the predicted risk under dose addition.
For example, a consequence of pesticide use is the risk of health effects. During the registration of pesticides in the United States exhaustive tests are performed to discern health effects on humans at various exposure levels. A regulatory upper limit of presence in foods is then placed on this pesticide. As long as residues in the food stay below this regulatory level, health effects are deemed highly unlikely and the food is considered safe to consume.
However, in normal agricultural practice, it is rare to use only a single pesticide. During the production of a crop, several different materials may be used. Each of them has had determined a regulatory level at which they would be considered individually safe. In many cases, a commercial pesticide is itself a combination of several chemical agents, and thus the safe levels actually represent levels of the mixture. In contrast, a combination created by the end user, such as a farmer, has rarely been tested in that combination. The potential for synergy is then unknown or estimated from data on similar combinations. This lack of information also applies to many of the chemical combinations to which humans are exposed, including residues in food, indoor air contaminants, and occupational exposures to chemicals. Some groups think that the rising rates of cancer, asthma, and other health problems may be caused by these combination exposures; others have alternative explanations. This question will likely be answered only after years of exposure by the population in general and research on chemical toxicity, usually performed on animals. Examples of pesticide synergists include Piperonyl butoxide and MGK 264.
Human synergy.
Human synergy relates to human interaction and teamwork. For example, say person A alone is too short to reach an apple on a tree and person B is too short as well. Once person B sits on the shoulders of person A, they are tall enough to reach the apple. In this example, the product of their synergy would be one apple. Another case would be two politicians. If each is able to gather one million votes on their own, but together they were able to appeal to 2.5 million voters, their synergy would have produced 500,000 more votes than had they each worked independently. A song is also a good example of human synergy, taking more than one musical part and putting them together to create a song that has a much more dramatic effect than each of the parts when played individually.
A third form of human synergy is when one person is able to complete two separate tasks by doing one action, for example, if a person were asked by a teacher and his boss at work to write an essay on how he could improve his work. A more visual example of this synergy is a drummer using four separate rhythms to create one drum beat.
Synergy usually arises when two persons with different complementary skills cooperate. In business, cooperation of people with organizational and technical skills happens very often. In general, the most common reason why people cooperate is that it brings a synergy. On the other hand, people tend to specialize just to be able to form groups with high synergy (see also division of labor and teamwork).
Example: Two teams in System Administration working together to combine technical and organizational skills in order to better the client experience, thus creating synergy. Counter-examples can be found in books like The Mythical Man-Month, in which the addition of additional team members is shown to have negative effects on productivity.
Organismic computing is an approach to improving group efficacy by increasing synergy in human groups via technological means.
When synergy occurs in the work place, the individuals involved get to work in a positive and supportive working environment. When individuals get to work in environments such as these, the company reaps the benefits. The authors of Creating the Best Workplace on Earth Rob Goffee and Gareth Jones, state that "highly engaged employees are, on average, 50% more likely to exceed expectations that the least-engaged workers. And companies with highly engaged people outperform firms with the most disengaged folks- by 54% in employee retention, by 89% in customer satisfaction, and by fourfold in revenue growth (Goffee & Jones, pg. 100)." Also, those that are able to be open about their views on the company, and have confidence that they will be heard, are likely to be a more organized employee who helps his/ her fellow team members succeed.
Corporate synergy.
Corporate synergy occurs when corporations interact congruently. A corporate synergy refers to a financial benefit that a corporation
expects to realize when it merges with or acquires another corporation. This type of synergy is a nearly ubiquitous feature of a corporate acquisition and is a negotiating point between the buyer and seller that impacts the final price both parties agree to. There are distinct types of corporate synergies, as follows.
Marketing.
A marketing synergy refers to the use of information campaigns, studies, and scientific discovery or experimentation for research or development. This promotes the sale of products for varied use or off-market sales as well as development of marketing tools and in several cases exaggeration of effects. It is also often a meaningless buzzword used by corporate leaders.
Revenue.
A revenue synergy refers to the opportunity of a combined corporate entity to generate more revenue than its two predecessor stand-alone companies would be able to generate. For example, if company A sells product X through its sales force, company B sells product Y, and company A decides to buy company B then the new company could use each sales person to sell products X and Y, thereby increasing the revenue that each sales person generates for the company.
In media revenue, synergy is the promotion and sale of a product throughout the various subsidiaries of a media conglomerate, e.g. films, soundtracks, or video games.
Financial.
Financial synergy gained by the combined firm is a result of number of benefits which flow to the entity as a consequence of acquisition and merger. These benefits may be:
Cash slack.
This is when a firm having number of cash extensive projects acquires a firm which is cash-rich, thus enabling the new combined firm to enjoy the profits from investing the cash of one firm in the projects of the other.
Debt capacity.
If two firms have no or little capacity to carry debt before individually, it is possible for them to join and gain the capacity to carry the debt through decreased gearing (leverage). This creates value for the firm, as debt is thought to be a cheaper source of finance.
Tax benefits.
It is possible for one firm to have unused tax benefits which might be offset against the profits of another after combination, thus resulting in less tax being paid. However this greatly depends on the tax law of the country.
Management.
Synergy in terms of management and in relation to team working refers to the combined effort of individuals as participants of the team. The condition that exists when the organization's parts interact to produce a joint effect that is greater than the sum of the parts acting alone. Positive or negative synergies can exist. In these cases, positive synergy has positive effects such as improved efficiency in operations, greater exploitation of opportunities, and improved utilization of resources. Negative synergy on the other hand has negative effects on production in the firm with effects such as reduced efficiency of operations, underutilization of resources and disequilibrium with the external environment.
Cost.
A cost synergy refers to the opportunity of a combined corporate entity to reduce or eliminate expenses associated with running a business. Cost synergies are realized by eliminating positions that are viewed as duplicate within the merged entity. Examples include the headquarters office of one of the predecessor companies, certain executives, the human resources department, or other employees of the predecessor companies. This is related to the economic concept of economies of scale.
Synergistic action in economy.
The synergistic action of the economic players lies within the economic phenomenon's profundity. The synergistic action gives different dimensions to competitiveness, strategy and network identity becoming an unconventional "weapon" which belongs to those who exploit the economic systems’ potential in depth.
Synergistic determinants.
The synergistic gravity equation (SYNGEq), according to its complex “title”, represents a synthesis of the endogenous and exogenous factors which determine the private and non-private economic decision makers to call to actions of synergistic exploitation of the economic network in which they operate. That is to say, SYNGEq constitutes a big picture of the factors/motivations which determine the entrepreneurs to contour an active synergistic network. SYNGEq includes both factors which character is changing over time (such as the competitive conditions), as well as classics factors, such as the imperative of the access to resources of the collaboration and the quick answers. The synergistic gravity equation (SINGEq) comes to be represented by the formula: 
 ∑SYN.Act =∑R-*I(CRed+COOP++AUnimit.)*V(Cust.+Info.)*cc 
where: 
∑SYN.Act = the sum of the synergistic actions adopted (by the economic actor)
∑ R- = the amount of unpurchased but necessary resources
ICRed = the imperative for cost reductions
ICOOP+ = the imperative for deep cooperation (functional interdependence) 
IAUnimit. = the imperative for purchasing unimitable competitive advantages (for the economic actor) 
VCust = the necessity of customer value in purchasing future profits and competitive advantages VInfo = the necessity of informational value in purchasing future profits and competitive advantages 
cc = the specific competitive conditions in which the economic actor operates
Synergistic networks and systems.
The synergistic network represents an integrated part of the economic system which, through the coordination and control functions (of the undertaken economic actions), agrees synergies. The neworks which promote synergistic actions can be divided in horizontal synergistic networks and vertical synergistic networks.
Synergy effects.
The synergy effects are difficult (even impossible) to imitate by competitors and difficult to reproduce by their authors because these effects depend on the combination of factors with time-varying characteristics. The synergy effects are often called "synergistic benefits", representing the direct and implied result of the developed/adopted synergistic actions.
Computers.
Synergy can also be defined as the combination of human strengths and computer strengths, such as advanced chess. Computers can process data much more quickly than humans, but lack the ability to respond meaningfully to arbitrary stimuli.
Synergy in literature.
Etymologically, the "synergy" term was first used around 1600, deriving from the Greek word “synergos”, which means “to work together” or “to cooperate”. If during this period the synergy concept was mainly used in the theological field (describing “the cooperation of human effort with divine will”), in the 19th and 20th centuries, "synergy" was promoted in physics and biochemistry, being implemented in the study of the open economic systems only in the 1960 and 1970s.
In 1938, J. R. R. Tolkien wrote an essay titled "On Fairy Stores", delivered at an Andrew Lang Lecture, and reprinted in his book, "The Tolkien Reader", published in 1966. In it, he made two references to synergy, although he did not use that term. He wrote:
Faerie cannot be caught in a net of words; for it is one of its qualities to be indescribable, though not imperceptible. It has many ingredients, but analysis will not necessarily discover the secret of the whole.
And more succinctly, in a footnote, about the "part of producing the web of an intricate story", he wrote:
It is indeed easier to unravel a single "thread" — an incident, a name, a motive — than to trace the history of any "picture" defined by many threads. For with the picture in the tapestry a new element has come in: the picture is greater than, and not explained by, the sum of the component threads.
Synergy in the media.
The informational synergies which can be applied also in media involve a compression of transmission, access and use of information’s time, the flows, circuits and means of handling information being based on a complementary, integrated, transparent and coordinated use of knowledge.
In media economics, synergy is the promotion and sale of a product (and all its versions) throughout the various subsidiaries of a media conglomerate, e.g. films, soundtracks or video games. Walt Disney pioneered synergistic marketing techniques in the 1930s by granting dozens of firms the right to use his Mickey Mouse character in products and ads, and continued to market Disney media through licensing arrangements. These products can help advertise the film itself and thus help to increase the film's sales. For example, the Spider-Man films had toys of webshooters and figures of the characters made, as well as posters and games. The NBC sitcom 30 Rock often shows the power of synergy, while also poking fun at the use of the term in the corporate world. There are also different forms of synergy in popular card games like Yu-Gi-Oh!, Cardfight!! Vanguard, and Future Card Buddyfight.
In video game media a Synergist role is adapted in games, such as Square Enix's Final Fantasy XIII series to allow a character to buff up themselves or their party. In short, Synergists add resiliencies to certain attacks, lessen status ailments that are inflicted on a character, or oftentimes blocking most attacks all together.
Obligatory synergies (medicine).
When spasticity occurs, such as following a stroke, it manifests in abnormal and stereotypical patterns across multiple joints called obligatory synergies. They are described as either a flexion synergy or an extension synergy and affect both the upper and lower extremity (see below). When these patterns occur in a patient, he or she is unable to move a limb segment in isolation of the pattern. This interferes with normal activities of daily living. Some aspects of the obligatory synergy patterns however, can be cleverly used to increase function relative to the movement available to the individual. Careful thought should, therefore, be considered in deciding which muscle groups to stretch at specific times during recovery. Obligatory synergy patterns are observed when a patient tries to make a minimal voluntary movement, or as a result of stimulated reflexes.
The flexion synergy for the upper extremity includes scapular retraction and elevation, shoulder abduction and external rotation, elbow flexion, forearm supination, and wrist and finger flexion.
The extension synergy for the upper extremity includes scapular protraction, shoulder adduction and internal rotation, elbow extension, forearm pronation, and wrist and finger flexion.
The flexion synergy for the lower extremity includes hip flexion, abduction and external rotation, knee flexion, ankle dorsiflexion and inversion and toe dorsiflexion.
The extension synergy for the lower extremity includes hip extension, adduction and internal rotation, knee extension, ankle plantar flexion and inversion, and toe plantar flexion.
Note that some muscles are not usually involved in these synergy patterns and include the lattisimus dorsi, teres major, serratus anterior, finger extensors, and ankle evertors.

</doc>
<doc id="26860" url="http://en.wikipedia.org/wiki?curid=26860" title="Syntax">
Syntax

In linguistics, syntax is the set of rules, principles, and processes that govern the structure of sentences in a given language. The term "syntax" is also used to refer to the study of such principles and processes. The goal of many syntacticians is to discover the syntactic rules common to all languages.
In mathematics, "syntax" refers to the rules governing the behavior of mathematical systems, such as formal languages used in logic. (See logical syntax.)
Etymology.
From Ancient Greek: σύνταξις "coordination" from σύν "syn", "together," and τάξις "táxis", "an ordering".
Early history.
Works on grammar were written long before modern syntax came about; the "Aṣṭādhyāyī" of Pāṇini (c. 4th century BC) is often cited as an example of a premodern work that approaches the sophistication of a modern syntactic theory. In the West, the school of thought that came to be known as "traditional grammar" began with the work of Dionysius Thrax.
For centuries, work in syntax was dominated by a framework known as "grammaire générale", first expounded in 1660 by Antoine Arnauld in a book of the same title. This system took as its basic premise the assumption that language is a direct reflection of thought processes and therefore there is a single, most natural way to express a thought.
However, in the 19th century, with the development of historical-comparative linguistics, linguists began to realize the sheer diversity of human language and to question fundamental assumptions about the relationship between language and logic. It became apparent that there was no such thing as the most natural way to express a thought, and therefore logic could no longer be relied upon as a basis for studying the structure of language.
The Port-Royal grammar modeled the study of syntax upon that of logic. (Indeed, large parts of the Port-Royal Logic were copied or adapted from the "Grammaire générale.") Syntactic categories were identified with logical ones, and all sentences were analyzed in terms of "Subject – Copula – Predicate." Initially, this view was adopted even by the early comparative linguists such as Franz Bopp.
The central role of syntax within theoretical linguistics became clear only in the 20th century, which could reasonably be called the "century of syntactic theory" as far as linguistics is concerned. (For a detailed and critical survey of the history of syntax in the last two centuries, see the monumental work by Giorgio Graffi (2001).)
Modern theories.
There are a number of theoretical approaches to the discipline of syntax. One school of thought, founded in the works of Derek Bickerton, sees syntax as a branch of biology, since it conceives of syntax as the study of linguistic knowledge as embodied in the human mind. Other linguists (e.g., Gerald Gazdar) take a more Platonistic view, since they regard syntax to be the study of an abstract formal system. Yet others (e.g., Joseph Greenberg) consider syntax a taxonomical device to reach broad generalizations across languages.
Generative grammar.
The hypothesis of generative grammar is that language is a structure of the human mind. The goal of generative grammar is to make a complete model of this inner language (known as "i-language"). This model could be used to describe all human language and to predict the grammaticality of any given utterance (that is, to predict whether the utterance would sound correct to native speakers of the language). This approach to language was pioneered by Noam Chomsky. Most generative theories (although not all of them) assume that syntax is based upon the constituent structure of sentences. Generative grammars are among the theories that focus primarily on the form of a sentence, rather than its communicative function.
Among the many generative theories of linguistics, the Chomskyan theories are:
Other theories that find their origin in the generative paradigm are:
Categorial grammar.
Categorial grammar is an approach that attributes the syntactic structure not to rules of grammar, but to the properties of the syntactic categories themselves. For example, rather than asserting that sentences are constructed by a rule that combines a noun phrase (NP) and a verb phrase (VP) (e.g., the phrase structure rule S → NP VP), in categorial grammar, such principles are embedded in the category of the head word itself. So the syntactic category for an intransitive verb is a complex formula representing the fact that the verb acts as a function word requiring an NP as an input and produces a sentence level structure as an output. This complex category is notated as (NP\S) instead of V. NP\S is read as "a category that searches to the left (indicated by \) for an NP (the element on the left) and outputs a sentence (the element on the right)." The category of transitive verb is defined as an element that requires two NPs (its subject and its direct object) to form a sentence. This is notated as (NP/(NP\S)) which means "a category that searches to the right (indicated by /) for an NP (the object), and generates a function (equivalent to the VP) which is (NP\S), which in turn represents a function that searches to the left for an NP and produces a sentence."
Tree-adjoining grammar is a categorial grammar that adds in partial tree structures to the categories.
Dependency grammar.
Dependency grammar is an approach to sentence structure where syntactic units are arranged according to the dependency relation, as opposed to the constituency relation of phrase structure grammars. Dependencies are directed links between words. The (finite) verb is seen as the root of all clause structure and all the other words in the clause are either directly or indirectly dependent on this root. Some prominent dependency-based theories of syntax are:
Lucien Tesnière (1893–1954) is widely seen as the father of modern dependency-based theories of syntax and grammar. He argued vehemently against the binary division of the clause into subject and predicate that is associated with the grammars of his day (S → NP VP) and which remains at the core of all phrase structure grammars. In the place of this division, he positioned the verb as the root of all clause structure.
Stochastic/probabilistic grammars/network theories.
Theoretical approaches to syntax that are based upon probability theory are known as stochastic grammars. One common implementation of such an approach makes use of a neural network or connectionism. Some theories based within this approach are:
Functionalist grammars.
Functionalist theories, although focused upon form, are driven by explanation based upon the function of a sentence (i.e. its communicative function). Some typical functionalist theories include:

</doc>
<doc id="26861" url="http://en.wikipedia.org/wiki?curid=26861" title="Shamanism">
Shamanism

Shamanism ( or ) is a practice that involves a practitioner reaching altered states of consciousness in order to encounter and interact with the spirit world and channel these transcendental energies into this world. A shaman is a person regarded as having access to, and influence in, the world of benevolent and malevolent spirits, who typically enters into a trance state during a ritual, and practices divination and healing.
The word "shaman" probably originates from the Tungusic Evenki language of North Asia, specifically for the spirit-workers in these cultures. According to the noted Finnish ethnolinguist Juha Janhunen,"the word is attested in all of the Tungusic idioms" such as Negidal, Lamut, Udehe/Orochi, Nanai, Ilcha, Orok, Manchu and Ulcha, and "nothing seems to contradict the assumption that that the meaning 'shaman' also derives from Proto-Tunguisic" and may have roots that extend back in time at least two millennia. The term was introduced to the west after Russian forces conquered the shamanistic Khanate of Kazan in 1552. The term "shamanism" was first applied by western anthropologists to the ancient religion of the Turks and Mongols, as well as those of the neighboring Tungusic and Samoyedic-speaking peoples. Upon learning more about religious traditions across the world, some anthropologists began to also use the term to describe unrelated magico-religious practices found within the ethnic religions of other parts of Asia, Africa, Australasia and the Americas, as they believed these practices to be similar to one another.
Mircea Eliade writes, "A first definition of this complex phenomenon, and perhaps the least hazardous, will be: shamanism = 'technique of religious ecstasy'." Shamanism encompasses the premise that shamans are intermediaries or messengers between the human world and the spirit worlds. Shamans are said to treat ailments/illness by mending the soul. Alleviating traumas affecting the soul/spirit restores the physical body of the individual to balance and wholeness. The shaman also enters supernatural realms or dimensions to obtain solutions to problems afflicting the community. Shamans may visit other worlds/dimensions to bring guidance to misguided souls and to ameliorate illnesses of the human soul caused by foreign elements. The shaman operates primarily within the spiritual world, which in turn affects the human world. The restoration of balance results in the elimination of the ailment.
Shamanic beliefs and practices have attracted the interest of scholars from a wide variety of disciplines, including anthropologists, archaeologists, historians, religious studies scholars, and psychologists. Hundreds of books and academic papers on the subject have been produced, with a peer-reviewed academic journal being devoted to the study of shamanisms. In the 20th century, many westerners involved in the counter-cultural movement have created modern magico-religious practices influenced by their ideas of Indigenous religions from across the world, creating what some call the Neoshamanic movement.
Terminology.
Etymology.
The word "shaman" probably originates from the Evenki word "šamán", most likely from the southwestern dialect spoken by the Sym Evenki peoples. The Tungusic term was subsequently adopted by Russians interacting with the indigenous peoples in Siberia. It is found in the memoirs of the exiled Russian churchman Avvakum. The word was brought to Western Europe in 1692 by the Dutch traveler Nicolaes Witsen who reported his stay and journeys among the Tungusic and Samoyedic-speaking indigenous peoples of Siberia in his book "Noord en Oost Tataryen". Adam Brand, a merchant from Lübeck, published in 1698 his account of a Russian embassy to China and a translation of his book, published the same year, introduced the word to English speakers.
The etymology of the Evenki word is sometimes connected to a Tungus root "ša-" "to know". This has been questioned on linguistic grounds: "The possibility cannot be completely rejected, but neither should it be accepted without reservation since the assumed derivational relationship is phonologically irregular (note especially the vowel quantities)."Other scholars assert that the word comes directly from the Manchu language, and would therefore be "the only commonly used English word that is a loan from this language".
However, it has been pointed out that the Sanskrit word "śramaṇa", designating a wandering monastic or holy figure, has spread to many Central Asian languages with Buddhism and could be the ultimate origin of the Tungusic word. (Compare the Wiktionary entry, which lists further sources for this derivation). This proposal has been thoroughly critiqued since 1917, and ethnolinguist Juha Janhunen regards it as an "anachronism" and an "impossibility" that is nothing more than a "far-fetched etymology."
Recently the proposal has been made that the word "shaman" or "saman" is not of ancient or indigenous Tungus origin. Ethnolinguists have studied Tungusic languages in depth only since the late 1800s and may be making the mistake of anachronistically "reading backward" in time, not appreciating how languages change through the addition of new words based on the speech of conquering or colonizing peoples, or of explorers and missionaries. Anthropologist and archeologist Silvia Tomaskova argues that by the mid-1600s many Europeans applied the Arabic term "shaitan" or "devil" to the non-Christian practices and beliefs of indigenous peoples. "Shaman" may have entered the various Tungus dialects as a corruption of this term, a word parroted back to the white, male and Christian missionaries, explorers, soldiers and colonial administrators with whom they had increasing contact for centuries before ethnolinguists arrived on the scene to collect and categorize their languages. The analogy can be made to today's Native Americans who use the term "indian" in a self-referential manner.
Definitions.
There is no single agreed upon definition for the word "shamanism" among anthropologists. The English historian Ronald Hutton noted that by the dawn of the 21st century, there were four separate definitions of the term which appeared to be in use. The first of these uses the term to refer to "anybody who contacts a spirit world while in an altered state of consciousness." The second definition limits the term to refer to those who contact a spirit world while in an altered state of consciousness at the behest of others. The third definition attempts to distinguish shamans from other magico-religious specialists who are believed to contact spirits, such as "mediums", "witch doctors", "spiritual healers" or "prophets" by claiming that they undertake some particular technique not used by the others. Problematically, scholars advocating the third view have failed to agree on what the defining technique should be. The fourth definition identified by Hutton uses "shamanism" to refer to the indigenous religions of Siberia and neighboring parts of Asia. According to the Golomt Center for Shamanic Studies, a Mongolian organisation of shamans, the Evenk word "shaman" would more accurately be translated as "priest".
Initiation and learning.
Shamans are normally "called" by dreams or signs which require lengthy training. However, shamanic powers may be "inherited".
Turner and colleagues mention a phenomenon called shamanistic initiatory crisis, a rite of passage for shamans-to-be, commonly involving physical illness and/or psychological crisis. The significant role of initiatory illnesses in the calling of a shaman can be found in the detailed case history of Chuonnasuan, the last master shaman among the Tungus peoples in Northeast China.
The wounded healer is an archetype for a shamanic trail and journey. This process is important to the young shaman. S/he undergoes a type of sickness that pushes her or him to the brink of death. This happens for two reasons:
Roles.
Shamans claim to gain knowledge and the power to heal by entering into the spiritual world or dimension. Most shamans have dreams or visions that tell them certain things. The shaman may have or acquire many spirit guides, who often guide and direct the shaman in his/her travels in the spirit world. These spirit guides are always present within the shaman although others only encounter them when the shaman is in a trance. The spirit guide energizes the shaman, enabling him/her to enter the spiritual dimension. The shaman heals within the spiritual dimension by returning 'lost' parts of the human soul from wherever they have gone. The shaman also cleanses excess negative energies which confuse or pollute the soul.
Shamans act as mediators in their culture. The shaman communicates with the spirits on behalf of the community, including the spirits of the deceased. The shaman communicates with both living and dead to alleviate unrest, unsettled issues, and to deliver gifts to the spirits.
Shamans assist in soul retrieval. In shamanism it is believed that part of the human soul is free to leave the body. Because a portion of the soul is free to leave the body it will do so when dreaming, or it will leave the body to protect itself from potentially damaging situations, be they emotional or physical. In situations of trauma the soul piece may not return to the body on its own, and a shaman must intervene and return the soul essence.
Among the Selkups, the sea duck is a spirit animal because ducks fly in the air and dive in the water. Thus ducks belong to both the upper world and the world below. Among other Siberian peoples these characteristics are attributed to water fowl in general.
Shamans perform a variety of functions depending upon their respective cultures; healing, leading a sacrifice, preserving the tradition by storytelling and songs, fortune-telling, and acting as a psychopomp (literal meaning, "guide of souls"). A single shaman may fulfill several of these functions.
The functions of a shaman may include either guiding to their proper abode the souls of the dead (which may be guided either one-at-a-time or in a cumulative group, depending on culture), and/or curing (healing) of ailments. The ailments may be either purely physical afflictions—such as disease, which may be cured by gifting, flattering, threatening, or wrestling the disease-spirit (sometimes trying all these, sequentially), and which may be completed by displaying a supposedly extracted token of the disease-spirit (displaying this, even if "fraudulent", is supposed to impress the disease-spirit that it has been, or is in the process of being, defeated, so that it will retreat and stay out of the patient's body), or else mental (including psychosomatic) afflictions—such as persistent terror (on account of a frightening experience), which may be likewise cured by similar methods. Usually in most languages a different term other than the one translated "shaman" is applied to a religious official leading sacrificial rites ("priest"), or to a raconteur ("sage") of traditional lore; there may be more of an overlap in functions (with that of a shaman), however, in the case of an interpreter of omens or of dreams.
The !Kung practised healing dances which they performed at night. These dances were an integrating and enhancing force central to group solidarity. The dances may have cured an ill person by “pulling out” a sickness, but the healing was also synergistic…… bringing people together and thereby creating a whole society from separate individuals. !Kung healers are what we might call shamans and they were able to see what was troubling everyone. By getting in to a trance they could “see” inside people’s bodies, or travel to the realm where the gods and the spirits of dead ancestors lived. A struggle would ensue between the spirits of the dead and the healer, who would attempt to bring back the soul of a sick person to the realm of the living.
There are distinct types of shaman who perform more specialized functions. For example, among the Nani people, a distinct kind of shaman acts as a psychopomp. Other specialized shamans may be distinguished according to the type of spirits, or realms of the spirit world, with which the shaman most commonly interacts. These roles vary among the Nenets, Enets, and Selkup shaman (paper; online). Among the Huichol, there are two categories of shaman. This demonstrates the differences among shamans within a single tribe.
Among the Hmong people, the shaman or the "Ntxiv Neej" (Tee-Neng), acts as healer. The Ntxiv Neej also performs rituals/ceremonies designed to call the soul back from its many travels to the physical human body. A Ntxiv Neej may use several shamanistic tools such as swords, divinity horns, a gong (drum), or finger bells/jingles. All tools serve to protect the spirits from the eyes of the unknown, thus enabling the Ntxiv Neej to deliver souls back to their proper owner. The Ntxiv Neej may wear a white, red, or black veil to disguise the soul from its attackers in the spiritual dimension.
Boundaries between the shaman and laity are not always clearly defined. Among the Barasana of Brazil, there is no absolute difference between those men recognized as shamans and those who are not. At the lowest level, most adult men have abilities as shamans and will carry out the same functions as those men who have a widespread reputation for their powers and knowledge. The Barasana shaman knows more myths and understands their meaning better, nonetheless the majority of adult men also know many myths.
Among Inuit peoples the laity have experiences which are commonly attributed to the shamans of those Inuit groups. Daydream, reverie, and trance are not restricted to shamans. Control over / alliance with helping spirits is the primary characteristic attributed to shamans. The laity usually employ amulets, spells, formulas, songs. Among the Greenland Inuit, the laity have greater capacity to relate with spiritual beings. These people are often apprentice shamans who failed to complete their initiations.
The assistant of an Oroqen shaman (called "jardalanin", or "second spirit") knows many things about the associated beliefs. He or she accompanies the rituals and interprets the behavior of the shaman. Despite these functions, the jardalanin is "not" a shaman. For this interpretative assistant, it would be unwelcome to fall into trance.
Ecological aspect.
Resources for human consumption are easily depletable in tropical rainforests. Among the Tucano people, a sophisticated system exists for environmental resources management and for avoiding resource depletion through overhunting. This system is conceptualized mythologically and symbolically by the belief that breaking hunting restrictions may cause illness. As the primary teacher of tribal symbolism, the shaman may have a leading role in this ecological management, actively restricting hunting and fishing. The shaman is able to "release" game animals, or their souls, from their hidden abodes. The Piaroa people have ecological concerns related to shamanism. Among the Inuit, shamans fetch the souls of game from remote places, or soul travel to ask for game from mythological beings like the Sea Woman.
Economics.
The way shamans get sustenance and take part in everyday life varies among cultures. In many Inuit groups, they provide services for the community and get a "due payment" (cultures believe the payment is given to the helping spirits), but these goods are only "welcome addenda." They are not enough to enable shamanizing as a full-time activity. Shamans live like any other member of the group, as hunter or housewife. Due to the popularity of ayahuasca tourism in South America, there are practitioners in areas frequented by backpackers who make a living from leading ceremonies. 
Beliefs.
There are many variations of shamanism throughout the world, but several common beliefs are shared by all forms of shamanism. Common beliefs identified by Eliade (1972) are the following:
Shamanism is based on the premise that the visible world is pervaded by invisible forces or spirits which affect the lives of the living. Although the causes of disease lie in the spiritual realm, inspired by malicious spirits, both spiritual and physical methods are used to heal. Commonly, a shaman "enters the body" of the patient to confront the spiritual infirmity and heals by banishing the infectious spirit.
Many shamans have expert knowledge of medicinal plants native to their area, and an herbal treatment is often prescribed. In many places shamans learn directly from the plants, harnessing their effects and healing properties, after obtaining permission from the indwelling or patron spirits. In the Peruvian Amazon Basin, shamans and "curanderos" use medicine songs called "icaros" to evoke spirits. Before a spirit can be summoned it must teach the shaman its song. The use of totemic items such as rocks with special powers and an animating spirit is common.
Such practices are presumably very ancient. Plato wrote in his "Phaedrus" that the "first prophecies were the words of an oak", and that those who lived at that time found it rewarding enough to "listen to an oak or a stone, so long as it was telling the truth".
Belief in witchcraft and sorcery, known as "brujería" in Latin America, exists in many societies. Other societies assert all shamans have the power to both cure and kill. Shamanic knowledge usually enjoys great power and prestige in the community, but it may also be regarded suspiciously or fearfully as potentially harmful to others.
By engaging in their work, a shaman is exposed to significant personal risk, from the spirit world, from enemy shamans, or from the means employed to alter the shaman's state of consciousness. Shamanic plant materials can be toxic or fatal if misused. Failure to return from an out-of-body journey can lead to death. Spells are commonly used to protect against these dangers, and the use of more dangerous plants is often very highly ritualized.
Soul and spirit concepts.
The variety of functions described above may seem like distinct tasks, but they may be united by underlying soul and spirit concepts.
Practice.
Generally, the shaman traverses the axis mundi and enters the spirit world by effecting a transition of consciousness, entering into an ecstatic trance, either autohypnotically or through the use of entheogens. The methods employed are diverse, and are often used together.
Entheogens.
An entheogen ("generating the divine within") is a psychoactive substance used in a religious, shamanic, or spiritual context. Entheogens have been used in a ritualized context for thousands of years; their religious significance is well established in anthropological and modern evidences. Examples of traditional entheogens include: peyote, psilocybin mushrooms, uncured tobacco, cannabis, ayahuasca, "Salvia divinorum", "Tabernanthe iboga", "Ipomoea tricolor", and "Amanita muscaria".
Some shamans observe dietary or customary restrictions particular to their tradition. These restrictions are more than just cultural. For example, the diet followed by shamans and apprentices prior to participating in an ayahuasca ceremony includes foods rich in tryptophan (a biosynthetic precursor to serotonin) as well as avoiding foods rich in tyramine, which could induce hypertensive crisis if ingested with MAOIs such as are found in ayahuasca brews as well as abstinence from alcohol or sex.
Music, songs.
Just like shamanism itself, music and songs related to it in various cultures are diverse, far from being alike. In several instances, songs related to shamanism are intended to imitate natural sounds, via onomatopoeia.
Sound mimesis in various cultures may serve other functions not necessarily related to shamanism: practical goals as luring game in the hunt; or entertainment (Inuit throat singing).
Paraphernalia.
Shamans may have various kinds of paraphernalia in different cultures.
Academic study.
Cognitive, semiotic, hermeneutic approaches.
As mentioned, a (debated) approach explains the etymology of word "shaman" as meaning "one who knows". Really, the shaman is a person who is an expert in keeping together the multiple codes of the society. Accordingly, the society's codes are the manifestation of the society's underlying complex belief system. Thus to be effective, shamans maintain a comprehensive view in their mind which gives them certainty of knowledge. The shaman uses (and the audience understands) multiple codes. Shamans express meanings in many ways: verbally, musically, artistically, and in dance. Meanings may be manifested in objects such as amulets.
The shaman knows the culture of his or her community well, and acts accordingly. Thus, their audience knows the used symbols and meanings—that is why shamanism can be efficient: people in the audience trust it. For example, the shaman's drumming can appear to its members as certainty of "knowledge"—this explains the above described etymology for the word "shaman" as meaning "one who knows."
There are semiotic theoretical approaches to shamanism, ("ethnosemiotics"). The symbols on the shaman's costume and drum can refer to Power animals, or to the rank of the shaman.
There are also examples of "mutually opposing symbols", distinguishing a "white" shaman who contacts sky spirits for good aims by day, from a "black" shaman who contacts evil spirits for bad aims by night. (Series of such opposing symbols referred to a world-view behind them. Analogously to the way grammar arranges words to express meanings and convey a world, also this formed a cognitive map). Shaman's lore is rooted in the folklore of the community, which provides a "mythological mental map". Juha Pentikäinen uses the concept "grammar of mind". Linking to a Sami example, Kathleen Osgood Dana writes:
Juha Pentikäinen, in his introduction to Shamanism and Northern Ecology, explains how the Sámi drum embodies Sámi worldviews. He considers shamanism to be a "‘grammar of mind’" (10), because shamans need to be experts in the folklore of their cultures (11).
Armin Geertz coined and introduced the hermeneutics, "ethnohermeneutics", approaches to the practice of interpretation. Hoppál extended the term to include not only the interpretation of oral and written texts, but that of "visual texts as well (including motions, gestures and more complex ritual, and ceremonies performed for instance by shamans)". It not only reveals the animistic views hiding behind shamanism, but also conveys their relevance for the contemporary world, where ecological problems have validated paradigms about balance and protection.
Ecological approaches, systems theory.
Other fieldworks use systems theory concepts and ecological considerations to understand the shaman's lore. Desana and Tucano Indians have developed a sophisticated symbolism and concepts of "energy" flowing between people and animals in cyclic paths. Gerardo Reichel-Dolmatoff relates these concepts to developments in the ways that modern science (systems theory, ecology, new approaches in anthropology and archeology) treats causality in a less linear fashion. He also suggests a cooperation of modern science and indigenous lore (online).
Hypotheses on origins.
Shamanic practices may originate as early as the Paleolithic, predating all organized religions, and certainly as early as the Neolithic period. The earliest known undisputed burial of a shaman (and by extension the earliest undisputed evidence of shamans and shamanic practices) dates back to the early Upper Paleolithic era (c. 30,000 BP) in what is now the Czech Republic.
Sanskrit scholar and comparative mythologist Michael Witzel proposes that all of the world's mythologies, and also the concepts and practices of shamans, can be traced to the migrations of two prehistoric populations: the Gondwana type (of circa 65,000 years ago) and the Laurasian type (of circa 40,000 years ago). The more recent Laurasian types of myths and forms of shamanism are found in Eurasian and North and South America and are later cultural elaborations based upon the earlier Gondwana types of myths and shamanism, both of which probably derived from an earlier human source population. Witzel argues that survivals of the older, original forms of shamanism are therefore to be found in the southern hemisphere among peoples such as the San Bushmen of Botswana, the Andamanese of the Andaman Islands off the coast of Burma, and the Aborigines of Australia. The so-called "classical" shamanism of Siberia and the Americas reflect a further cultural evolutionary development at the local levels. 
Early anthropologist studies theorise that shamanism developed as a magic practice to ensure a successful hunt or gathering of food. Evidence in caves and drawings on walls support indications that shamanism started during the Paleolithic era. One such picture featured a half-animal, with the face and legs of a man, with antlers and a tail of a stag.
Archaeological evidence exists for Mesolithic shamanism. The oldest known Shaman grave in the world is located in the Czech Republic at Dolni Vestonice (National Geographic No 174 October 1988). This grave site was evidence of a female shaman.
In November 2008, researchers from the Hebrew University of Jerusalem announced the discovery of a 12,000-year-old site in Israel that is perceived as one of the earliest known shaman burials. The elderly woman had been arranged on her side, with her legs apart and folded inward at the knee. Ten large stones were placed on the head, pelvis and arms. Among her unusual grave goods were 50 complete tortoise shells, a human foot, and certain body parts from animals such as a cow tail and eagle wings. Other animal remains came from a boar, leopard, and two martens. "It seems that the woman … was perceived as being in a close relationship with these animal spirits", researchers noted. The grave was one of at least 28 graves at the site, located in a cave in lower Galilee and belonging to the Natufian culture, but is said to be unlike any other among the Epipaleolithic Natufians or in the Paleolithic period.
Robert Sapolsky has theorized that shamanism is practiced by schizotypal individuals.
Historical-anthropological school of folkloristics.
Folklorists have evaluated the presence of remnants of shamanism and shamanic practice in folktales from around the world. Michael Berman identified the genre of the shamanic story, examples of which are only produced by folk groups with shamanic cosmology or a shamanic world view. Kultkrantz points out that, “in areas where shamanism has long been a thing of the past, many tales contain only vague, piecemeal or inaccurate recollections of shamans and their like.” The presence of distinctive characteristics and features of shamanic stories help folklorists and anthropologists reconstruct a culture’s practice of shamanism.
Decline and revitalization / tradition-preserving movements.
Shamanism is believed to be declining around the world, possibly due to other organised religious influences, like Christianity, that want people who practice shamanism to convert to their own system and doctrine. Another reason is western views of shamanism as 'primitive', 'superstitious', backward and outdated. Whalers who frequently interact with Inuit tribes are one source of this decline in that region.
In many areas, former shamans ceased to fulfill the functions in the community they used to, as they felt mocked by their own community, or regarded their own past as deprecated and are unwilling to talk about it to an ethnographer.
Moreover, besides personal communications of former shamans, folklore texts may narrate directly about a deterioration process. For example, a Buryat epic text details the wonderful deeds of the ancient "first shaman" Kara-Gürgän: he could even compete with God, create life, steal back the soul of the sick from God without his consent. A subsequent text laments that shamans of older times were stronger, possessing capabilities like omnividence, fortune-telling even for decades in the future, moving as fast as a bullet; the texts contrast them to the recent heartless, unknowing, greedy shamans.
In most affected areas, shamanic practices ceased to exist, with authentic shamans dying and their personal experiences dying with them. The loss of memories is not always lessened by the fact the shaman is not always the only person in a community who knows the beliefs and motives related to the local shaman-hood (laics know myths as well, among Barasana, even though less; there are former shaman apprentices unable to complete the learning among Greenlandic Inuit peoples, moreover, even laics can have trance-like experiences among the Inuit; the assistant of a shaman can be extremely knowledgeable among Dagara). Although the shaman is often believed and trusted precisely because s/he "accommodates" to the "grammar" of the beliefs of the community, several parts of the knowledge related to the local shamanhood consist of personal experiences of the shaman (illness), or root in his/her family life (the interpretation of the symbolics of his/her drum), thus, those are lost with his/her death. Besides that, in many cultures, the entire traditional belief system has become endangered (often together with a partial or total language shift), the other people of the community remembering the associated beliefs and practices (or the language at all) grew old or died, many folklore memories (songs, texts) were forgotten - which may threaten even such peoples who could preserve their isolation until the middle of the 20th century, like the Nganasan.
Some areas could enjoy a prolonged resistance due to their remoteness.
After exemplifying the general decline even in the most remote areas, it should be noted that there are revitalization or tradition-preserving efforts as a response. Besides collecting the memories, there are also tradition-preserving and even revitalization efforts, led by authentic former shamans (for example among Sakha people and Tuvans). However, according to Richard L. Allen, Research & Policy Analyst for the Cherokee Nation, they are overwhelmed with fraudulent shaman, also known as plastic medicine people. "One may assume that anyone claiming to be a Cherokee 'shaman, spiritual healer, or pipe-carrier', is equivalent to a modern day medicine show and snake-oil vendor." One indicator of a plastic shaman might be someone who discusses "Native American spirituality" but does not mention any specific Native American tribe. The "New Age Frauds and Plastic Shamans" website discusses potentially plastic shamans.
Besides tradition-preserving efforts, there are also neoshamanistic movements, these may differ from many traditional shamanistic practice and beliefs in several points. Admittedly, several traditional beliefs systems indeed have ecological considerations (for example, many Eskimo peoples), and among Tukano people, the shaman indeed has direct resource-protecting roles, see details in section Ecological aspect.
Today, shamanism survives primarily among indigenous peoples. Shamanic practices continue today in the tundras, jungles, deserts, and other rural areas, and even in cities, towns, suburbs, and shantytowns all over the world. This is especially true for Africa and South America, where "mestizo shamanism" is widespread.
Regional variations.
Asia.
Mongolia.
Mongolian classics, such as "The Secret History of the Mongols", provide details about male and female shamans serving as exorcists, healers, rainmakers, oneiromancers, soothsayers, and officials. Shamanic practices continue in present day Mongolia culture.
The spiritual hierarchy in clan-based Mongolian society was complex. The highest group consisted of 99 "tngri" (55 of them benevolent or "white" and 44 terrifying or "black"), 77 "natigai" or "earth-mothers", besides others. The "tngri" were called upon only by leaders and great shamans and were common to all the clans. After these, three groups of ancestral spirits dominated. The "Lord-Spirits" were the souls of clan leaders to whom any member of a clan could appeal for physical or spiritual help. The "Protector-Spirits" included the souls of great shamans ("ĵigari") and shamanesses ("abĵiya"). The "Guardian-Spirits" were made up of the souls of smaller shamans ("böge") and shamanesses ("idugan") and were associated with a specific locality (including mountains, rivers, etc.) in the clan's territory.
In the 1990s, a form of Mongolian neo-shamanism was created which has given a more modern approach to shamanism. Mongolian shamans are now making a business out of their profession and even have offices in the larger towns. At these businesses, a shaman generally heads the organization and performs services such as healing, fortunetelling, and solving all kinds of problems.
Hmong shamanism.
The Hmong people, as an ancient people of China with a 5,000-year history, continue to maintain and practice its form of shamanism known as "Ua Neeb" in mainland Asia. At the end of the Vietnam War, some 300,000 Hmong have been settled across the globe. They have continued to practice Ua Neeb in various countries in North and South America, Europe and Australia. In the U.S., the Hmong shaman practitioner is known as "Txiv Neeb" has been licensed by many hospitals in California as being part of the medical health team to treat patients in hospital. This revival of Ua Neeb in the West has been brought great success and has been hailed in the media as "Doctor for the disease, shaman for the soul".
Being a Hmong shaman represents a true vocation, chosen by the shaman God "Sivyis".
The Shaman's main job is to bring harmony to the individual, their family, and their community within their environment by performing various rituals (usually through trance).
Animal sacrifice has been part of the Hmong shamanic practice for the past 5,000 years. Contrary to the belief of many Westerners, the Hmong practice of using animals in shamanic practice is performed with great respect. After the Vietnam War, over 200,000 Hmong were resettled in the United States and shamanism is still part of the Hmong culture. Due the colluding of culture and the law, as Professor Alison Dundes Renteln, a political science professor at the University of Southern California and author of The Cultural Defense, a book that examines the influence of such cases on U.S. courts, once said, "We say that as a society we welcome diversity, and in fact that we embrace it...In practice, it's not that easy".
The Hmong believe that all things on Earth have a soul (or multiple souls) and those souls are treated as equal and can be considered interchangeable. When a person is sick due to his soul being lost, or captured by wild spirit, it is necessary to ask for and receive permission of that animal, whether it is a chicken, pig, dog, goat or any other animals required, to use its soul for an exchange with the afflicted person's soul for a period of 12 months. At the end of that period, during the Hmong New Year, the shaman would perform a special ritual to release the soul of that animal and send it off to the world beyond. As part of his service to mankind, the animal soul is sent off to be reincarnated into a higher form of animal, or even to become a member of a god's family (ua Fuab Tais Ntuj tus tub, tus ntxhais) to live a life of luxury, free of the suffering as an animal. Hence, being asked to perform this duty (what is known in the West as "animal sacrifice") is one of the greatest honors for that animal, to be able to serve mankind. The Hmong of Southeast Guizhou will cover the cock with a piece of red cloth and then hold it up to worship and sacrifice to the Heaven and the Earth before the Sacred cockfight. In a 2010 trial of a Sheboygan Wisconsin Hmong who was charged with staging a cockfight, it was stated that the roosters were “kept for both food and religious purposes”, and the case was followed by an acquittal.
In addition to the spiritual dimension, Hmong shaman are able to treat many physical illnesses through use of the text of sacred words (khawv koob).
Indonesia.
Throughout the villages and towns of Indonesia, local healers known as dukun practice diverse activities from massage, bonesetting, midwivery, herbal medicine, spirit mediumship and divination. 
Korea.
Shamanism is still practiced in North and South Korea. In the south the role of a shaman is most frequently taken by women known as "mudangs", while male shamans (rare) are called baksoo mudangs.
A person can become a shaman through hereditary title or through natural ability. Shamans are consulted in contemporary society for financial and marital decisions.
Japan.
Shamanism is part of the indigenous Ainu religion and Japanese religion of Shinto, although Shinto is distinct in that it is shamanism for an agricultural society. Since the early middle-ages Shinto has been influenced by and syncretized with Buddhism and other elements of continental East Asian culture. The book "Occult Japan: Shinto, Shamanism and the Way of the Gods" by Percival Lowell delves further into researching Japanese shamanism or Shintoism. The book "Japan Through the Looking Glass: Shaman to Shinto" uncovers the extraordinary aspects of Japanese beliefs.
Siberia and North Asia.
Siberia is regarded as the "locus classicus" of shamanism. The area is inhabited by many different ethnic groups, and many of its peoples observe shamanistic practices, even in modern times. Many classical ethnographic sources of "shamanism" were recorded among Siberian peoples.
Manchu Shamanism is one of very few Shamanist traditions which held official status into the modern era, by becoming one of the imperial cults of the Qing Dynasty of China (alongside Buddhism, Taoism and traditional Heaven worship). The Palace of Earthly Tranquility, one of the principal halls of the Forbidden City in Beijing, was partly dedicated to Shamanistic rituals. The ritual set-up is still preserved "in situ" today.
Among the Siberian Chukchis peoples, a shaman is interpreted as someone who is possessed by a spirit, who demands that someone assume the shamanic role for their people. Among the Buryat, there is a ritual known as "shanar" whereby a candidate is consecrated as shaman by another, already-established shaman.
Among several Samoyedic peoples shamanism was a living tradition also in modern times, especially at groups living in isolation, until recent times (Nganasans). The last notable Nganasan shaman's seances could be recorded on film in the 1970s.
When the People's Republic of China was formed in 1949 and the border with Russian Siberia was formally sealed, many nomadic Tungus groups (including the Evenki) that practiced shamanism were confined in Manchuria and Inner Mongolia. The last shaman of the Oroqen, Chuonnasuan (Meng Jin Fu), died in October 2000.
In many other cases, shamanism was in decline even at the beginning of 20th century (Gypsies).
India and Nepal.
Tantra, Shaktism is sometimes considered as a Shaman sect of Hinduism. Also various sub-sects of Shaivism tend to practice Shaman practices.
Central Asia.
Geographic influences on Central Asian shamanism.
Geographical factors heavily influence the character and development of the religion, myths, rituals and epics of Central Asia. While in other parts of the world, religious rituals are primarily used to promote agricultural prosperity, here they were used to ensure success in hunting and breeding livestock. Animals are one of the most important elements of indigenous religion in Central Asia because of the role they play in the survival of the nomadic civilizations of the steppes as well as sedentary populations living on land not conducive to agriculture. Shamans wore animal skins and feathers and underwent transformations into animals during spiritual journeys. In addition, animals served as humans' guides, rescuers, ancestors, totems and sacrificial victims. As a religion of nature, shamanism throughout Central Asia held particular reverence for the relations between sky, earth and water and believed in the mystical importance of trees and mountains. Shamanism in Central Asia also places a strong emphasis on the opposition between summer and winter, corresponding to the huge differences in temperature common in the region. The harsh conditions and poverty caused by the extreme temperatures drove Central Asian nomads throughout history to pursue militaristic goals against their sedentary neighbors. This military background can be seen in the reverence for horses and warriors within many indigenous religions.
Common shamanic practices and beliefs shared among Central Asians.
Central Asian shamans served as sacred intermediaries between the human and spirit world. In this role they took on tasks such as healing, divination, appealing to ancestors, manipulating the elements, leading lost souls and officiating public religious rituals. The shamanic séance served as a public display of the shaman's journey to the spirit world and usually involved intense trances, drumming, dancing, chanting, elaborate costumes, miraculous displays of physical strength, and audience involvement. The goal of these séances ranged from recovering the lost soul of a sick patient and divining the future to controlling the weather and finding a lost person or thing. The use of sleight-of-hand tricks, ventriloquism, and hypnosis were common in these rituals but did not explain the more impressive feats and actual cures accomplished by shamans.
Shamans perform in a "state of ecstasy" deliberately induced by an effort of will. Reaching this altered state of consciousness required great mental exertion, concentration and strict self-discipline. Mental and physical preparation included long periods of silent meditation, fasting, and smoking. In this state, skilled shamans employ capabilities that the human organism cannot accomplish in the ordinary state. Shamans in ecstasy displayed unusual physical strength, the ability to withstand extreme temperatures, the bearing of stabbing and cutting without pain, and the heightened receptivity of the sense organs. Shamans made use of intoxicating substances and hallucinogens, especially mukhomor mushrooms and alcohol, as a means of hastening the attainment of ecstasy.
The use of purification by fire is an important element of the shamanic tradition dating back as early as the 6th century. People and things connected with the dead had to be purified by passing between fires. These purifications were complex exorcisms while others simply involved the act of literally walking between two fires while being blessed by the Shaman. Shamans in literature and practice were also responsible for using special stones to manipulate weather. Rituals are performed with these stones to attract rain or repel snow, cold or wind. This "rain-stone" was used for many occasions including bringing an end to drought as well as producing hailstorms as a means of warfare.
Despite distinctions between various types of shamans and specific traditions, there is a uniformity throughout the region manifested in the personal beliefs, objectives, rituals, symbols and the appearance of shamans.
Shamanic rituals as artistic performance.
The shamanic ceremony is both a religious ceremony and an artistic performance. The fundamental purpose of the dramatic displays seen during shamanic ceremonies is not to draw attention or to create a spectacle for the audience as many Westerners have come to believe, but to lead the tribe in a solemn ritualistic process.
In general, all performances consist of four elements: dance, music, poetry and dramatic or mimetic action. The use of these elements serves the purpose of outwardly expressing his mystical communion with nature and the spirits for the rest of the tribe. The true shaman can make the journey to the spirit world at any time and any place, but shamanic ceremonies provide a way for the rest of the tribe to share in this religious experience. The shaman changes his voice mimetically to represent different persons, gods, and animals while his music and dance change to show his progress in the spirit world and his different spiritual interactions. Many shamans practice ventriloquism and make use of their ability to accurately imitate the sounds of animals, nature, humans and other noises in order to provide the audience with the ambiance of the journey. Elaborate dances and recitations of songs and poetry are used to make the shamans spiritual adventures into a matter of living reality to his audience.
Costume and accessories.
The shaman's attire varies throughout the region but his chief accessories are his coat, cap, and tambourine or drum. The transformation into an animal is an important aspect of the journey into the spirit world undertaken during shamanic rituals so the coat is often decorated with birds feathers and representations of animals, coloured handkerchiefs, bells and metal ornaments. The cap is usually made from the skin of a bird with the feathers and sometimes head, still attached.
The drum or tambourine is the essential means of communicating with spirits and enabling the shaman to reach altred states of consciousness on his journey. The drum, representing the universe in epitome, is often divided into equal halves to represent the earth and lower realms. Symbols and natural objects are added to the drum representing natural forces and heavenly bodies.
Shamanism in Tsarist and Soviet Russia.
In Soviet Central Asia, the Soviet government persecuted and denounced shamans as practitioners of fraudulent medicine and perpetuators of outdated religious beliefs in the new age of science and logic. The radical transformations occurring after the October Socialist Revolution led to a sharp decrease in the activity of shamans. Shamans represented an important component in the traditional culture of Central Asians and because of their important role in society, Soviet organizations and campaigns targeted shamans in their attempt to eradicate traditional influences in the lives of the indigenous peoples. Along with persecution under the tsarist and Soviet regimes, the spread of Christianity and Islam had a role in the disintegration of native faith throughout central Asia. Poverty, political instability and foreign influence are also detrimental to a religion that requires publicity and patronage to flourish.
By the 1980s most shamans were discredited in the eyes of their people by Soviet officials and physicians.
Other Asian traditions.
There is a strong shamanistic influence in the Bön religion in Central Asian, and in Tibetan Buddhism. Buddhism became popular with shamanic peoples such as the Tibetans, Mongols, and Manchu beginning in the eighth century. Forms of shamanistic ritual combined with Tibetan Buddhism became institutionalized as a major religion under the Mongolian Yuan dynasty and the Manchurian Qing dynasty. However, in the shamanic cultures still practiced by various ethnic groups in areas such as Nepal and northern India, shamans are not necessarily considered enlightened, and often are even feared for their ability to use their power to carry out malicious intent.
In Tibet, the Nyingma schools in particular, had a Tantric tradition that had married "priests" known as Ngakpas or Ngakmas/mos (fem.). The Ngakpas were often employed or commissioned to rid the villages of demons or disease, creations of protective amulets, the carrying out of religious rites etc. The Ngakpas should however, have been grounded in Buddhist philosophy and not simply another form of shaman, but sadly, this was most often not the case. There have always been, however, highly realised and accomplished ngakpas. They were in their own right great lamas who were of equal status as lamas with monastic backgrounds. The monasteries, as in many conventional religious institutions, wished to preserve their own traditions. The monasteries depended upon the excesses of patrons for support. This situation often led to a clash between the more grassroots and shamanic character of the travelling "Chödpa" and "Ngakpa" culture and the more conservative religious monastic system.
"Jhakri" is the common name used for shamans in Sikkim, India. They exist in the Limbu, Sunuwar, Rai, Sherpa, Kami, Tamang, Gurung and Lepcha communities. They are inflluenced by Hinduism, Tibetan Buddhism, Mun and Bön rites.
Shamanism is still widely practiced in the Ryukyu Islands (Okinawa, Japan), where shamans are known as 'Noro' (all women) and 'Yuta'. 'Noro' generally administer public or communal ceremonies while 'Yuta' focus on civil and private matters. Shamanism is also practiced in a few rural areas in Japan proper. It is commonly believed that the Shinto religion is the result of the transformation of a shamanistic tradition into a religion.
Forms of practice vary somewhat in the several Ryukyu islands, so that there is, for example, a distinct .
Shamanism practices seem to have been preserved in the Catholic religious traditions of aborigines in Taiwan.
In Vietnam, shamans conduct rituals in many of the religious traditions that co-mingle in the majority and minority populations. In their rituals, music, dance, special garments and offerings are part of the performance that surround the spirit journey.
Europe.
While shamanism had a strong tradition in Europe before the rise of monotheism, shamanism remains a traditional, organized religion in northern Eurasia, including Mari-El and Udmurtia, two semi-autonomous provinces of Russia with large minority populations. Shamanism in Scandinavia may be represented in rock art dating to the Neolithic era and was practiced throughout the Iron Age by the various Teutonic tribes and the Baltic-Finnic peoples. People which used to live in Siberia, have wandered to their present locations since then. For example, many Uralic peoples live now outside Siberia, however the original location of the Proto-Uralic peoples (and its extent) is debated. Combined phytogeographical and linguistic considerations (distribution of various tree species and the presence of their names in various Uralic languages) suggest that this area was north of Central Ural Mountains and on lower and middle parts of Ob River. The ancestors of Hungarian people or Magyars have wandered from their ancestral proto-Uralic area to the Pannonian Basin. Shamanism played an important role in Turko-Mongol mythology. Tengriism, the major belief among Xiongnu or Mongol and Turkic peoples, Magyars and Bulgars in ancient times incorporates elements of shamanism. Shamanism is no more a living practice among Hungarians, but remnants have been reserved as fragments of folklore, in folktales, customs.
Some historians of the Late Middle Ages and Early Modern period have argued that traces of shamanistic traditions can be seen in the popular folk belief of this period. Most prominent among these was the Italian Carlo Ginzburg, who claimed shamanistic elements in the "benandanti" custom of 16th century Italy, the Hungarian Éva Pócs, who identified them in the "táltos" tradition of Hungary, and the Frenchman Claude Lecouteux, who has argued that Medieval traditions regarding the soul are based on earlier shamanic ideas. Ginzburg in particular has argued that some of these shamanistic traditions influenced the conception of witchcraft in Christendom, in particular ideas regarding the witches' sabbath, leading to the events of the witch trials in the Early Modern period.
Cunning folk is an English language term which, like "shaman," is found as a broad generalization in academia, to cover both practitioners of beneficial folk magic as well as witches who did harm. However, the term was not generally used in the period being discussed. Christian sanctioned Laws were enacted across England, Scotland and Wales that often condemned witches.
In Scandinavia the klok gumma ("wise woman") or klok gubbe ("wise man"), and collectively De kloka ("The Wise ones"), as they were known in Swedish, were usually elder members of the community who acted as naturopathic doctors and midwives as well as using folk magic such as magic rhymes. In Denmark they were called klog mand ("wise man") and klog kone ("wise woman") and collectively as kloge folk ("wise folk").
The names used for cunning-folk in Italy vary from region to region, although such names include praticos (wise people), guaritori (healers), fattucchiere (fixers), donne che aiutano (women who help) and mago, maga or maghiardzha (sorcerers). At times, they were sometimes called streghe (witches), although usually only "behind their backs or by those who either are sceptical of their powers or believe they deal in black magic." The cunning profession akin to Shamanism survived the 20th century and into the early 21st, allowing Italian-American sociologist Sabina Magliocco to make a brief study of them (2009).
Circumpolar shamanism.
Inuit and Yupik cultures.
Eskimo groups inhabit a huge area stretching from Eastern Siberia through Alaska and Northern Canada (including Labrador Peninsula) to Greenland. Shamanistic practice and beliefs have been recorded at several parts of this vast area crosscutting continental borders.
When speaking of "shamanism" in various Eskimo groups, we must remember that (as mentioned above) the term "shamanism" can cover certain characteristics of "various" different cultures. Mediation is regarded often as an important aspect of shamanism in general. Also in most Eskimo groups, the role of mediator is known well: the person filling it in is actually believed to be able to contact the beings who populate the belief system. Term "shaman" is used in several English-language publications also in relation to Eskimos. Also the "alignalghi" (]) of the Asian Eskimos is translated as "shaman" in the Russian and English literature.
The belief system assumes specific links between the living people, the souls of hunted animals, and those of dead people. The soul concepts of several groups are specific examples of soul dualism (showing variability in details in the various cultures).
Unlike the majority of shamanisms the careers of most Eskimo shamans lack the motivation of "force": becoming a shaman is usually a result of deliberate consideration, not a necessity forced by the spirits.
Diversity, with similarities.
Another possible concern: do the belief systems of various Eskimo groups have such common features at all, that would justify any mentioning them together? There was no political structure above the groups, their languages were relative, but differed more or less, often forming language continuums (online).
There are similarities in the cultures of the Eskimo groups together with diversity, far from homogeneity.
The Russian linguist Menovshikov (Меновщиков), an expert of Siberian Yupik and Sireniki Eskimo languages (while admitting that he is not a specialist in ethnology) mentions, that the shamanistic seances of those Siberian Yupik and Sireniki groups he has seen have many similarities to those of Greenland Inuit groups described by Fridtjof Nansen, although a large distance separates Siberia and Greenland. There may be certain similarities also in Asiatic groups with North American ones. Also the usage of a specific shaman's language is documented among several Eskimo groups, used mostly for talking to spirits. Also the Ungazighmiit (belonging to Siberian Yupiks) had a special allegoric usage of some expressions.
The local cultures showed great diversity. The myths concerning the role of shaman had several variants, and also the name of their protagonists varied from culture to culture. For example, a mythological figure, usually referred to in the literature by the collective term Sea Woman, has factually many local names: Nerrivik "meat dish" among Polar Inuit, Nuliayuk "lubricous" among Netsilingmiut, Sedna "the nether one" among Baffin Land Inuit. Also the soul conceptions, e.g. the details of the soul dualism showed great variability, ranging from guardianship to a kind of reincarnation. Conceptions of spirits or other beings had also many variants (see e.g. the tupilaq concept).
Americas.
North America.
Native American and First Nations cultures have diverse religious beliefs and there was never one universal Native American religion or spiritual system. Although many Native American cultures have traditional healers, ritualists, singers, mystics, lore-keepers and Medicine people, none of them ever used, or use, the term "shaman" to describe these religious leaders. Rather, like other indigenous cultures the world over, their spiritual functionaries are described by words in their own languages, and in many cases are not taught to outsiders.
Many of these indigenous religions have been grossly misrepresented by outside observers and anthropologists, even to the extent of superficial or seriously mistaken anthropological accounts being taken as more authentic than the accounts of actual members of the cultures and religions in question. Often these accounts suffer from "Noble Savage"-type romanticism and racism. Some contribute to the fallacy that Native American cultures and religions are something that only existed in the past, and which can be mined for data despite the opinions of Native communities.
Not all Indigenous communities have roles for specific individuals who mediate with the spirit world on behalf of the community. Among those that do have this sort of religious structure, spiritual methods and beliefs may have some commonalities, though many of these commonalities are due to some nations being closely related, from the same region, or through post-Colonial governmental policies leading to the combining of formerly independent nations on reservations. This can sometimes lead to the impression that there is more unity among belief systems than there was in antiquity.
With the arrival of European settlers and colonial administration, the practice of Native American traditional beliefs was discouraged and Christianity was imposed upon the indigenous people. In most communities, the traditions were not completely eradicated, but rather went underground, and were practiced secretly until the prohibitive laws were repealed.
Up until and during the last hundred years, thousands of Native American and First Nations children from many different communities were sent into the Canadian Indian residential school system, and Indian boarding schools in an effort to destroy tribal languages, cultures and beliefs. The Trail of Tears, in the US, forced Native Americans to relocate from their traditional homes. Canadian laws enacted in 1982, and henceforth, have attempted to reverse previous attempts at extinguishing Native culture.
Mesoamerica.
Maya.
The Maya people of Guatemala, Belize, and southern Mexico practice astrology and a form of divination known as "the blood speaking", in which the spiritual worker is guided in divination and healing by pulses in the veins of his arms and legs. 
Aztec.
In contemporary Nahuatl, there is a spiritual practice known as "cualli ohtli" - the "good path" followed during dreaming by "friends of the night" to "Tlalocán".
South America.
Amazonia.
In the Peruvian Amazon Basin and north coastal regions of the country, the healers are known as curanderos. "Ayahuasqueros" are Peruvians who specialize in the use of ayahuasca. "Ayahuasqueros" have become popular among Western spiritual seekers, who claim that the "ayauasqueros" and their ayahuasca brews have cured them of everything from depression to addiction to cancer.
In addition to "curanderos" use of ayahuasca and their ritualized ingestion of mescaline-bearing San Pedro cactuses (Trichocereus pachanoi) for the divination and diagnosis of sorcery, north-coastal shamans are famous throughout the region for their intricately complex and symbolically dense healing altars called mesas (tables). Sharon (1993) has argued that the mesas symbolize the dualistic ideology underpinning the practice and experience of north-coastal shamanism. For Sharon, the mesas are the, "physical embodiment of the supernatural opposition between benevolent and malevolent energies" (Dean 1998: 61).
In several tribes living in the Amazon rainforest, the spiritual leaders also act as managers of scarce ecological resources (paper; online). The rich symbolism in Tukano culture has been documented in field works even in the last decades of the 20th century.
The "yaskomo" of the Waiwai is believed to be able to perform a soul flight. The soul flight can serve several functions:
Thus, a yaskomo is believed to be able to reach sky, earth, and water.
Mapuche.
Among the Mapuche people of Chile, "Machi" is usually a woman who serves the community by performing ceremonies to cure diseases, ward off evil, influence the weather and harvest, and by practicing other forms of healing such as herbalism.
Aymara.
For the Aymara people of South America the Yatiri is a healer who heals the body and the soul, they serve the community and do the rituals for Pachamama.
Fuegians.
Although Fuegians (the indigenous peoples of Tierra del Fuego) were all hunter-gatherers, they did not share a common culture. The material culture was not homogenous, either: the big island and the archipelago made two different adaptations possible. Some of the cultures were coast-dwelling, others were land-oriented.
Both Selk'nam and Yámana had persons filling in shaman-like roles.
The Selk'nams believed their /xon/s to have supernatural capabilities, e.g. to control weather. The figure of /xon/ appeared in myths, too. The Yámana /jekamuʃ/ corresponds to the Selknam /xon/.
Oceania.
On the island of Papua New Guinea, indigenous tribes believe that illness and calamity are caused by dark spirits, or "masalai", which cling to a person's body and poison them. Shamans are summoned in order to purge the unwholesome spirits from a person. Shamans also perform rainmaking ceremonies and can allegedly improve a hunter's ability to catch animals.
In Australia various aboriginal groups refer to their shamans as "clever men" and "clever women" also as "kadji". These aboriginal shamans use "maban" or "mabain", the material that is believed to give them their purported magical powers. Besides healing, contact with spiritual beings, involvement in initiation and other secret ceremonies, they are also enforcers of tribal laws, keepers of special knowledge and may "hex" to death one who breaks a social taboo by singing a song only known to the "clever men".
Africa.
In Mali, Dogon sorcerers (both male and female) communicate with a spirit named Amma, who advises them on healing and divination practices.
The classical meaning of shaman as a person who, after recovering from a mental illness (or insanity) takes up the professional calling of socially recognized religious practitioner, is exemplified among the Sisala (of northern Gold Coast) : "the fairies "seized" him and made him insane for several months. Eventually, though, he learned to control their power, which he now uses to divine."
The term "sangoma", as employed in Zulu and congeneric languages, is effectively equivalent to shaman. Sangomas are highly revered and respected in their society, where illness is thought to be caused by witchcraft, pollution (contact with impure objects or occurrences), bad spirits, or the ancestors themselves, either malevolently, or through neglect if they are not respected, or to show an individual her calling to become a sangoma ("thwasa"). For harmony between the living and the dead, vital for a trouble-free life, the ancestors must be shown respect through ritual and animal sacrifice.
The term "inyanga" also employed by the Nguni cultures is equivalent to 'herbalist' as used by the Zulu people and a variation used by the Karanga, among whom remedies (locally known as muti) for ailments are discovered by the inyanga being informed in a dream, of the herb able to effect the cure and also of where that herb is to be found. The majority of the herbal knowledge base is passed down from one "inyanga" to the next, often within a particular family circle in any one village.
Shamanism is known among the Nuba of Kordofan in Sudan.
Contemporary Western shamanism.
There is an endeavor in some contemporary occult and esoteric circles to reinvent shamanism in a modern form, often drawing from core shamanism—a set of beliefs and practices synthesized by Michael Harner—centered on the use of ritual drumming and dance, and Harner's interpretations of various indigenous religions. Harner has faced criticism for taking pieces of diverse religions out of their cultural contexts and synthesising a set of universal shamanic techniques. Some neoshamans focus on the ritual use of entheogens, and also embrace the philosophies of chaos magic while others (such as Jan Fries) have created their own forms of shamanism.
European-based neoshamanic traditions are focused upon the researched or imagined traditions of ancient Europe, where many mystical practices and belief systems were suppressed by the Christian church. Some of these practitioners express a desire to practice a system that is based upon their own ancestral traditions. Some anthropologists and practitioners have discussed the impact of such neoshamanism as "giving extra pay" (Harvey, 1997 and elsewhere) to indigenous American traditions, particularly as many pagan or heathen shamanic practitioners do not call themselves shamans, but instead use specific names derived from the European traditions—they work within such as "völva" or "seidkona" (seid-woman) of the sagas (see Blain 2002, Wallis 2003).
Many spiritual seekers travel to Peru to work with "ayahuasqueros", shamans who engage in the ritual use of ayahuasca, a psychedelic tea which has been documented to cure everything from depression to addiction. When taking ayahuasca, participants frequently report meeting spirits, and receiving divine revelations. Shamanistic techniques have also been used in New Age therapies which use enactment and association with other realities as an intervention.
Criticism of the term.
The anthropologist Alice Kehoe criticizes the term "shaman" in her book "Shamans and Religion: An Anthropological Exploration in Critical Thinking". Part of this criticism involves the notion of cultural appropriation. This includes criticism of New Age and modern Western forms of shamanism, which, according to Kehoe, misrepresent or dilute indigenous practices. Alice Kehoe also believes that the term reinforces racist ideas such as the Noble Savage.
Kehoe is highly critical of Mircea Eliade's work on shamanism as an invention synthesized from various sources unsupported by more direct research. To Kehoe, citing that ritualistic practices (most notably drumming, trance, chanting, entheogens and hallucinogens, spirit communication and healing) as being definitive of shamanism is poor practice. Such citations ignore the fact that those practices exist outside of what is defined as shamanism and play similar roles even in non-shamanic cultures (such as the role of chanting in Judeo-Christian and Islamic rituals) and that in their expression are unique to each culture that uses them. Such practices cannot be generalized easily, accurately, or usefully into a global religion of shamanism. Because of this, Kehoe is also highly critical of the hypothesis that shamanism is an ancient, unchanged, and surviving religion from the Paleolithic period.
Anthropologist Mihály Hoppál also discusses whether the term "shamanism" is appropriate. He notes that for many readers, "-ism" implies a particular dogma, like Buddhism or Judaism. He recommends using the term "shamanhood" or "shamanship" (a term used in old Russian and German ethnographic reports at the beginning of the 20th century) for stressing the diversity and the specific features of the discussed cultures. He believes that this places more stress on the local variations and emphasizes that shamanism is not a religion of sacred dogmas, but linked to the everyday life in a practical way. Following similar thoughts, he also conjectures a contemporary paradigm shift. Piers Vitebsky also mentions that, despite really astonishing similarities, there is no unity in shamanism. The various, fragmented shamanistic practices and beliefs coexist with other beliefs everywhere. There is no record of pure shamanistic societies (although, as for the past, their existence is not impossible).
These questions tend to hold greater interest among anthropologists than among those who are themselves engaged in shamanic practices.
References.
</dl>
Further reading.
</dl>

</doc>
<doc id="26862" url="http://en.wikipedia.org/wiki?curid=26862" title="Sexology">
Sexology

Sexology is the interdisciplinary study of human sexuality, including human sexual interests, behaviors and function. The term "sexology" does not generally refer to the non-scientific study of sexuality, such as political science or social criticism.
In modern sexology, researchers apply tools from several academic fields, such as biology, medicine, psychology, epidemiology, sociology and criminology. Sexologists study sexual development (puberty), sexual orientation, sexual relationships and sexual activity, as well as document the sexualities of special groups; for example, child sexuality, adolescent sexuality, sexuality among the elderly and the disabled. The sexological study of sexual dysfunctions and disorders, including erectile dysfunction, anorgasmia, and pedophilia, are also common.
History.
Sexology as it exists today, as a specific research-based scientific field, is relatively new. While there are works dedicated towards sex in antiquity, the scientific study of sexual behavior in human beings began in the 19th century. Shifts in Europe's national borders at that time brought into conflict laws that were sexually liberal and laws that criminalized behaviors such as homosexual activity.
Early.
Sexual manuals have existed since antiquity, such as Ovid's "Ars Amatoria", the "Kama Sutra" of Vatsyayana, the "Ananga Ranga" and "The Perfumed Garden for the Soul's Recreation". However, none of these treat sex as the subject of a formal field of scientific or medical research.
"De la prostitution dans la ville de Paris" ("Prostitution in the City of Paris"), an early 1830s study on 3,558 registered prostitutes in Paris, published by Alexander Jean Baptiste Parent-Duchatelet (and published in 1837, a year after he died), has been called the first work of modern sex research.
Sexology as an academic discipline.
Despite the prevailing social attitude of sexual repression in the Victorian era, the movement towards sexual emancipation began towards the end of the nineteenth century in England and Germany. In 1886, Richard Freiherr von Krafft-Ebing published "Psychopathia Sexualis." That work is considered as having established sexology as a scientific discipline.
In England, the founding father of sexology was the doctor and sexologist Havelock Ellis who challenged the sexual taboos of his era regarding masturbation and homosexuality and revolutionized the conception of sex in his time.
His seminal work was the 1897 "Sexual Inversion", which describes the sexual relations of homosexual males, including men with boys. Ellis wrote the first objective study of homosexuality, (the term was coined by Kertbeny) as he did not characterize it as a disease, immoral, or a crime. The work assumes that same-sex love transcended age taboos as well as gender taboos. Seven of his twenty-one case studies are of inter-generational relationships. He also developed other important psychological concepts, such as autoerotism and narcissism, both of which were later developed further by Sigmund Freud.
Ellis pioneered transgender phenomena alongside the German Magnus Hirschfeld. He established it as new category that was separate and distinct from homosexuality. Aware of Hirschfeld's studies of transvestism, but disagreeing with his terminology, in 1913 Ellis proposed the term "sexo-aesthetic inversion" to describe the phenomenon.
In 1908, the first scholarly journal of the field, "Journal of Sexology" (Zeitschrift für Sexualwissenschaft), began publication and was published monthly for one year. Those issues contained articles by Freud, Alfred Adler, and Wilhelm Stekel. In 1913, the first academic association was founded: the "Society for Sexology".
Freud developed a theory of sexuality. These stages of development include: Oral, Anal, Phallic, Latency and Genital. These stages run from infancy to puberty and onwards. based on his studies of his clients, between the late 19th and early 20th centuries. Wilhelm Reich and Otto Gross, were disciples of Freud, but rejected by his theories because of their emphasis on the role of sexuality in the revolutionary struggle for the emancipation of mankind.
Pre-Nazi Germany, under the sexually liberal Napoleonic code, organized and resisted the anti-sexual, Victorian cultural influences. The momentum from those groups led them to coordinate sex research across traditional academic disciplines, bringing Germany to the leadership of sexology. Physician Magnus Hirschfeld was an outspoken advocate for sexual minorities, founding the Scientific Humanitarian Committee, the first advocacy for homosexual and transgender rights.
Hirschfeld also set up the first Institut für Sexualwissenschaft (Institute for Sexology) in Berlin in 1919. Its library housed over 20,000 volumes, 35,000 photographs, a large collection of art and other objects. People from around Europe visited the Institute to gain a clearer understanding of their sexuality and to betreated for their sexual concerns and dysfunctions.
Hirschfeld developed a system which identified numerous actual or hypothetical types of sexual intermediary between heterosexual male and female to represent the potential diversity of human sexuality, and is credited with identifying a group of people that today are referred to as transsexual or transgender as separate from the categories of homosexuality, he referred to these people as 'transvestiten' (transvestites). Germany's dominance in sexual behavior research ended with the Nazi regime. The Institute and its library were destroyed by the Nazis less than three months after they took power, May 8, 1933. The institute was shut down and Hirschfeld's books were burned.
Other sexologists in the early gay rights movement included Ernst Burchard, Hans Blüher, and Benedict Friedlaender. Ernst Grafenberg, after whom the G-spot is named, published the initial research developing the intrauterine device (IUD).
Postwar expansion.
After World War II, sexology experienced a renaissance, both in the United States and Europe. Large scale studies of sexual behavior, sexual function, and sexual dysfunction gave rise to the development of sex therapy. Post-WWII sexology in the U.S. was influenced by the influx of European refugees escaping the Nazi regime and the popularity of the Kinsey studies. Until that time, American sexology consisted primarily of groups working to end prostitution and to educate youth about sexually transmitted diseases. Alfred Kinsey founded the Institute for Sex Research at Indiana University at Bloomington in 1947. This is now called the Kinsey Institute for Research in Sex, Gender and Reproduction. He wrote in his 1948 book that more was scientifically known about the sexual behavior of farm animals than of humans.
Psychologist and sexologist John Money developed theories on sexual identity and gender identity in the 1950s. His work, notably on the David Reimer case has since been regarded as controversial, even while the case was key to the development of treatment protocols for intersex infants and children.
Kurt Freund developed the penile plethysmograph in Czechoslovakia in the 1950s. The device was designed to provide an objective measurement of sexual arousal in males and is currently used in the assessment of pedophilia and hebephilia. This tool has since been used with sex offenders.
In 1966 and 1970, Masters and Johnson released their works "Human Sexual Response" and "Human Sexual Inadequacy," respectively. Those volumes sold well, and they were founders of what became known as the Masters & Johnson Institute in 1978.
Vern Bullough was a historian of sexology during this era, as well as being a researcher in the field.
The emergence of HIV/AIDS in the 1980s caused a dramatic shift in sexological research efforts towards understanding and controlling the spread of the disease. Similarly, the emergence of an intersex movement in the late 1990s and 2000s saw the emergence of critical sexology through authors such as Iain Morland and Morgan Holmes. Lisa Downing, Iain Morland and Nikki Sullivan critique the work on "hermaphroditism", "transsexualism" and "paraphilia" by sexologist and psychologist John Money in the 2014 book "Fuckology".
Today.
Technological advances have permitted sexological questions to be addressed with studies using behavioral genetics, neuroimaging, and large-scale Internet-based surveys. A person who studies sexology may be called a "sexpert".
Notable contributors.
This is a list of sexologists and notable contributors to the field of sexology, by year of birth:

</doc>
<doc id="26865" url="http://en.wikipedia.org/wiki?curid=26865" title="List of leaders of the Soviet Union">
List of leaders of the Soviet Union

Under the 1977 Constitution of the Union of Soviet Socialist Republics (USSR), the Chairman of the Council of Ministers was the head of government and the Chairman of the Presidium of the Supreme Soviet was the head of state. The office of the Chairman of the Council of Ministers was the equivalent to a First World Prime Minister, while the office of the Chairman of the Presidium was equivalent to the office of the President. In the Soviet Union's seventy-year history there was no official "leader of the Soviet Union" offices but a Soviet leader usually led the country through the office of the Premier and/or the office of the General Secretary of the Communist Party of the Soviet Union (CPSU). In the idea of Vladimir Lenin the head of the Soviet state was a collegiate body of the vanguard party (see "What Is to Be Done?").
Following Joseph Stalin's consolidation of power in the 1920s the post of the General Secretary of the Central Committee of the Communist Party became synonymous with 'Leader of the Soviet Union' because the post controlled both the CPSU and the Soviet Government. The post of the General Secretary was abolished under Stalin and later re-established by Nikita Khrushchev under the name of "First Secretary"; in 1966 Leonid Brezhnev reverted the office title to its former name. Being the head of the communist party, the office of the General Secretary was the highest in the Soviet Union until 1990. The post of General Secretary lacked clear guidelines of succession, so after the death or removal of a Soviet leader, the successor usually needed the support of the Politburo, the Central Committee, or another government or party apparatus to both take and stay in power. The President of the Soviet Union, an office created in March 1990, replaced the General Secretary as the highest Soviet political office.
Contemporaneously to establishment of the office of the President, representatives of the Congress of People's Deputies voted to remove Article 6 from the Soviet constitution which stated that the Soviet Union was a one-party state controlled by the Communist Party which, in turn, played the leading role in society. This vote weakened the Party and its hegemony over the Soviet Union and its people. Upon death, resignation, or removal from office of an incumbent President, the Vice President of the Soviet Union would assume the office, though the Soviet Union collapsed before this was actually tested. After the failed August Coup the Vice President was replaced by an elected member of the State Council of the Soviet Union.
Summary.
Vladimir Lenin was voted the Chairman of the Council of People's Commissars of the USSR (Sovnarkom) on 30 December 1922 by the Congress of Soviets. His health, at the age of 53, declined from effects of two bullet wounds, later aggravated by three strokes which culminated with his death in 1924. Irrespective of his health status in his final days, Lenin was already losing much of his power to Stalin. Alexei Rykov succeeded Lenin as Chairman of the Sovnarkom, and although he was "de jure" the most powerful person in the country, the Politburo of the Communist Party began to overshadow the Sovnarkom in the mid-1920s. By the end of the decade, Rykov merely rubber stamped the decisions predetermined by Stalin and the Politburo.
Stalin's early policies pushed for rapid industrialisation, nationalisation of private industry and the collectivisation of private plots created under Lenin's New Economic Policy. As leader of the Politburo, Stalin consolidated near-absolute power by 1938 after the Great Purge, a series of campaigns of political repression and persecution. Nazi German troops invaded the Soviet Union in June 1941, but were repulsed by the Soviets in December. On Stalin's orders, the USSR launched a counter-attack on Nazi Germany. Stalin died in March 1953, his death triggered a power struggle in which Khrushchev after several years emerged victorious against Georgy Malenkov.
Khrushchev denounced Stalin on two occasions: in 1956 and 1962. His policy of de-Stalinisation earned him many enemies within the party, especially from old Stalinist appointees. Many saw this approach as destructive and destabilising. A group known as Anti-Party Group tried, but failed, to oust Khrushchev from office in 1957. As Khrushchev grew older, his erratic behavior became worse, usually making decisions without discussing or confirming them with the Politburo. Leonid Brezhnev, a close companion of Khrushchev, was elected First Secretary the same day of Khrushchev's removal from power; Alexei Kosygin became the new Premier and Anastas Mikoyan kept his office as Chairman of the Presidium of the Supreme Soviet. In 1965, on the orders of the Politburo, Mikoyan was forced to retire; Nikolai Podgorny took over the office of Chairman of the Presidium. The USSR in the post-Khrushchev 1960s was governed by a collective leadership. Henry A. Kissinger, the American National Security Advisor, mistakenly believed that Kosygin was the 'Leader of the Soviet Union and that he was at the helm of 'Soviet foreign policy' because he represented the Soviet Union at the 1967 Glassboro Summit Conference. The "Era of Stagnation", a derogatory term coined by Mikhail Gorbachev, was a period marked by low socio-economic efficiency in the country and a gerontocracy ruling the country. Yuri Andropov succeeded Brezhnev in his post as General Secretary in 1982. In 1983 Andropov was hospitalised, and rarely met up at work to chair the politburo meetings due to his declining health. Nikolai Tikhonov usually chaired the meetings in his place. Following Andropov's death, an even older leader, Konstantin Chernenko was elected to the General Secretariat. His rule lasted for little more than a year.
Gorbachev was elected to the General Secretariat by the Politburo on 11 March 1985. By the mid-to-late 1980s Gorbachev had launched the policies of "perestroika" (literally meaning "reconstruction", but varies) and "glasnost" ("openness" and "transparency"). The dismantling of the principal defining features of communism in 1988 and 1989 in the Soviet Union led to the unintended consequence of breaking-up the Soviet state into 15 successor states after the failed August Coup of 1991 led by Gennady Yanayev.
List of leaders.
The following list includes only those persons who were able to gather enough support from the Communist Party of the Soviet Union (CPSU) and the government, or one of these to lead the Soviet Union.
List of troikas.
On three occasions—between Lenin's death and Stalin's rise; Stalin's death and Nikita Khrushchev's rise; and Khrushchev's fall and Leonid Brezhnev's consolidation of power—a form of collective leadership known as the troika ("triumvirate") governed the Soviet Union, with no single individual holding leadership alone.
Bibliography.
</dl>

</doc>
<doc id="26866" url="http://en.wikipedia.org/wiki?curid=26866" title="Seafood">
Seafood

Seafood is any form of sea life regarded as food by humans. Seafood prominently includes fish and shellfish.
Shellfish include various species of molluscs, crustaceans, and echinoderms. Historically, sea mammals such as whales and dolphins have been consumed as food, though that happens to a lesser extent in modern times. Edible sea plants, such as some seaweeds and microalgae, are widely eaten as seafood around the world, especially in Asia (see the ). In North America, although not generally in the United Kingdom, the term "seafood" is extended to fresh water organisms eaten by humans, so all edible aquatic life may be referred to as seafood. For the sake of completeness, this article includes all edible aquatic life.
The harvesting of wild seafood is usually known as fishing or hunting, and the cultivation and farming of seafood is known as aquaculture, or fish farming in the case of fish. Seafood is often distinguished from meat, although it is still animal and is excluded in a strict vegetarian diet. Seafood is an important source of protein in many diets around the world, especially in coastal areas.
Most of the seafood harvest is consumed by humans, but a significant proportion is used as fish food to farm other fish or rear farm animal. Some seafoods (kelp) are used as food for other plants (fertilizer). In these ways, seafoods are indirectly used to produce further food for human consumption. Products, such as fish oil and spirulina tablets are also extracted from seafoods. Some seafood is feed to aquarium fish, or used to feed domestic pets, such as cats, and a small proportion is used in medicine, or is used industrially for non-food purposes (leather).
History.
The harvesting, processing, and consuming of seafoods are ancient practices with archaeological evidence dating back well into the Paleolithic. Findings in a sea cave at Pinnacle Point in South Africa indicate "Homo sapiens" (modern humans) harvested marine life as early as 165,000 years ago, while the Neanderthals, an extinct human species contemporary with early "Homo sapiens", appear to have been eating seafood at sites along the Mediterranean coast beginning around the same time. Isotopic analysis of the skeletal remains of Tianyuan man, a 40,000 year old modern human from eastern Asia, has shown that he regularly consumed freshwater fish. Archaeology features such as shell middens, discarded fish bones and cave paintings show that sea foods were important for survival and consumed in significant quantities. During this period, most people lived a hunter-gatherer lifestyle and were, of necessity, constantly on the move. However, where there are early examples of permanent settlements (though not necessarily permanently occupied) such as those at Lepenski Vir, they are almost always associated with fishing as a major source of food.
The ancient river Nile was full of fish; fresh and dried fish were a staple food for much of the population. The Egyptians had implements and methods for fishing and these are illustrated in tomb scenes, drawings, and papyrus documents. Some representations hint at fishing being pursued as a pastime.
Fishing scenes are rarely represented in ancient Greek culture, a reflection of the low social status of fishing. However, Oppian of Corycus, a Greek author wrote a major treatise on sea fishing, the "Halieulica" or "Halieutika", composed between 177 and 180. This is the earliest such work to have survived to the modern day. The consumption of fish varied in accordance with the wealth and location of the household. In the Greek islands and on the coast, fresh fish and seafood (squid, octopus, and shellfish) were common. They were eaten locally but more often transported inland. Sardines and anchovies were regular fare for the citizens of Athens. They were sometimes sold fresh, but more frequently salted. A stele of the late 3rd century BCE from the small Boeotian city of Akraiphia, on Lake Copais, provides us with a list of fish prices. The cheapest was "skaren" (probably parrotfish) whereas Atlantic bluefin tuna was three times as expensive. Common salt water fish were yellowfin tuna, red mullet, ray, swordfish or sturgeon, a delicacy which was eaten salted. Lake Copais itself was famous in all Greece for its eels, celebrated by the hero of "The Acharnians". Other fresh water fish were pike-fish, carp and the less appreciated catfish.
Pictorial evidence of Roman fishing comes from mosaics. At a certain time the goatfish was considered the epitome of luxury, above all because its scales exhibit a bright red color when it dies out of water. For this reason these fish were occasionally allowed to die slowly at the table. There even was a recipe where this would take place "in garo", in the sauce. At the beginning of the Imperial era, however, this custom suddenly came to an end, which is why "mullus" in the feast of Trimalchio (see "the Satyricon") could be shown as a characteristic of the "parvenu", who bores his guests with an unfashionable display of dying fish.
In medieval times, seafood was less prestigious than other animal meats, and often seen as merely an alternative to meat on fast days. Still, seafood was the mainstay of many coastal populations. Kippers made from herring caught in the North Sea could be found in markets as far away as Constantinople. While large quantities of fish were eaten fresh, a large proportion was salted, dried, and, to a lesser extent, smoked. Stockfish, cod that was split down the middle, fixed to a pole and dried, was very common, though preparation could be time-consuming, and meant beating the dried fish with a mallet before soaking it in water. A wide range of mollusks including oysters, mussels and scallops were eaten by coastal and river-dwelling populations, and freshwater crayfish were seen as a desirable alternative to meat during fish days. Compared to meat, fish was much more expensive for inland populations, especially in Central Europe, and therefore not an option for most.
Modern knowledge of the reproductive cycles of aquatic species has led to the development of hatcheries and improved techniques of fish farming and aquaculture. Better understanding of the hazards of eating raw and undercooked fish and shellfish has led to improved preservation methods and processing.
Types of seafood.
The following table is based on the ISSCAAP classification (International Standard Statistical Classification of Aquatic Animals and Plants) used by the FAO for the purposes of collecting and compiling fishery statistics. The production figures have been extracted from the FAO FishStat database, and include both capture from wild fisheries and aquaculture production.
Processing.
Fish is a highly perishable product. The "fishy" smell of dead fish is due to the breakdown of amino acids into biogenic amines and ammonia.
Live food fish are often transported in tanks at high expense for an international market that prefers its seafood killed immediately before it is cooked. This process originally was started by Lindeye. Delivery of live fish without water is also being explored. While some seafood restaurants keep live fish in aquaria for display purposes or for cultural beliefs, the majority of live fish are kept for dining customers. The live food fish trade in Hong Kong, for example, is estimated to have driven imports of live food fish to more than 15,000 tonnes in 2000. Worldwide sales that year were estimated at US$400 million, according to the World Resources Institute.
If the cool chain has not been adhered to correctly, food products generally decay and become harmful before the validity date printed on the package. As the potential harm for a consumer when eating rotten fish is much larger than for example with dairy products, the U.S. Food and Drug Administration (FDA) has introduced regulation in the USA requiring the use of a time temperature indicator on certain fresh chilled seafood products.
Fresh fish is a highly perishable food product, so it must be eaten promptly or discarded; it can be kept for only a short time. In many countries, fresh fish are filleted and displayed for sale on a bed of crushed ice or refrigerated. Fresh fish is most commonly found near bodies of water, but the advent of refrigerated train and truck transportation has made fresh fish more widely available inland.
Long term preservation of fish is accomplished in a variety of ways. The oldest and still most widely used techniques are drying and salting. Desiccation (complete drying) is commonly used to preserve fish such as cod. Partial drying and salting is popular for the preservation of fish like herring and mackerel. Fish such as salmon, tuna, and herring are cooked and canned. Most fish are filleted prior to canning, but some small fish (e.g. sardines) are only decapitated and gutted prior to canning.
Consumption.
Seafood is consumed all over the world; it provides the world's prime source of high-quality protein: 14–16% of the animal protein consumed worldwide; over one billion people rely on seafood as their primary source of animal protein. Fish is among the most common food allergens.
Iceland, Japan, and Portugal are the greatest consumers of seafood per capita in the world.
The UK Food Standards Agency recommends that at least two portions of seafood should be consumed each week, one of which should be oil-rich. There are over 100 different types of seafood available around the coast of the UK.
Oil-rich fish such as mackerel or herring are rich in long chain Omega-3 oils. These oils are found in every cell of the human body, and are required for human biological functions such as brain functionality.
Whitefish such as haddock and cod are very low in fat and calories which, combined with oily fish rich in Omega-3 such as mackerel, sardines, fresh tuna, salmon and trout, can help to protect against coronary heart disease, as well as helping to develop strong bones and teeth.
Shellfish are particularly rich in zinc, which is essential for healthy skin and muscles as well as fertility. Casanova reputedly ate 50 oysters a day.
Texture and taste.
Over 32,000 fish species of many more marine invertebrate species have been described. However, only a small number of species are commonly eaten by humans.
Health benefits.
Research over the past few decades has shown that the nutrients and minerals in seafood can make improvements in brain development and reproduction and has highlighted the role for seafood in the functions of the human body.
Doctors have known of strong links between fish and healthy hearts ever since they noticed that fish-eating Inuit populations in the Arctic had low levels of heart disease. One study has suggested that adding one portion of fish a week to your diet can cut your chances of suffering a heart attack by half. Fish is thought to protect the heart because eating less saturated fat and more omega-3 can help to lower the amount of cholesterol and triglycerides in the blood – two fats that, in excess, increase the risk of heart disease. Omega-3 fats also have natural built-in anti-oxidants, which are thought to stop the thickening and damaging of artery walls. Regularly eating fish oils is also thought to reduce the risk of arrhythmia – irregular electrical activity in the heart which increases the risk of sudden heart attacks.
10-12% of the human brain is composed of lipids, including the omega-3 fat DHA. Recent studies suggest that older people can boost their brain power by eating more oily fish, what with regular consumers being able to remember better and think faster than those who don't consume at all. Other research has also suggested that adding more DHA to the diet of children with attention-deficit hyperactivity disorder can reduce their behavioural problems and improve their reading skills, while there have also been links suggested between DHA and better concentration. Separate studies have suggested that older people who eat fish at least once a week could also have a lower chance of developing dementia and Alzheimer's disease.
Including fish as a regular part of a balanced diet has been shown to help the symptoms of rheumatoid arthritis – a painful condition that causes joints to swell up, reducing strength and mobility. Studies also show that sufferers feel less stiff and sore in the morning if they keep their fish oil intake topped up. Recent research has also found a link between omega-3 fats and a slowing down in the wearing of cartilage that leads to osteoarthritis, opening the door for more research into whether eating more fish could help prevent the disease.
Fish is high in minerals such as zinc, iodine and selenium, which keep the body running smoothly. Iodine is essential for the thyroid gland, which controls growth and metabolism, while selenium is used to make enzymes that protect cell walls from cancer-causing free radicals, and helps prevent DNA damage caused by radiation and some chemicals. Fish is also a source of vitamin A, which is needed for healthy skin and eyes, and vitamin D, which is needed to help the body absorb calcium to strengthen teeth and bones.
Health hazards.
Fish and shellfish have a natural tendency to concentrate mercury in their bodies, often in the form of methylmercury, a highly toxic organic compound of mercury. Species of fish that are high on the food chain, such as shark, swordfish, king mackerel, albacore tuna, and tilefish contain higher concentrations of mercury than others. This is because mercury is stored in the muscle tissues of fish, and when a predatory fish eats another fish, it assumes the entire body burden of mercury in the consumed fish. Since fish are less efficient at depurating than accumulating methylmercury, fish-tissue concentrations increase over time. Thus species that are high on the food chain amass body burdens of mercury that can be ten times higher than the species they consume. This process is called biomagnification. The first occurrence of widespread mercury poisoning in humans occurred this way in Minamata, Japan, now called Minamata disease.
Shellfish are among the more common food allergens.
A common misconception is a cross-reactivity between seafood and iodinated radiocontrast agents.
Mislabelling.
A 2013 study by Oceana found that one third of seafood sampled from the United States was incorrectly labelled. Snapper and tuna were particularly susceptible to mislabelling, and seafood substitution was the most common type of fraud. These practices can harm both the consumers' wallet and pose health risks. Another type of mislabelling is short-weighting, where practices such as overglazing or soaking can misleadingly increase the apparent weight of the fish. The detection of water retention agents helps identify the fraud and its origin.
Sustainability.
Research into population trends of various species of seafood is pointing to a global collapse of seafood species by 2048. Such a collapse would occur due to pollution and overfishing, threatening oceanic ecosystems, according to some researchers.
A major international scientific study released in November 2006 in the journal "Science" found that about one-third of all fishing stocks worldwide have collapsed (with a collapse being defined as a decline to less than 10% of their maximum observed abundance), and that if current trends continue all fish stocks worldwide will collapse within fifty years. In July 2009, Boris Worm of Dalhousie University, the author of the November 2006 study in "Science", co-authored an update on the state of the world's fisheries with one of the original study's critics, Ray Hilborn of the University of Washington at Seattle. The new study found that through good fisheries management techniques even depleted fish stocks can be revived and made commercially viable again.
The FAO State of World Fisheries and Aquaculture 2004 report estimates that in 2003, of the main fish stocks or groups of resources for which assessment information is available, "approximately one-quarter were overexploited, depleted or recovering from depletion (16%, 7% and 1% respectively) and needed rebuilding."
The National Fisheries Institute, a trade advocacy group representing the United States seafood industry, disagree. They claim that currently observed declines in fish population are due to natural fluctuations and that enhanced technologies will eventually alleviate whatever impact humanity is having on oceanic life.
In religion.
For the most part Islamic dietary laws allow the eating of seafood, though the Hanbali forbid eels, the Shafi forbid frogs and crocodiles, and the Hanafi forbid bottom feeders such as shellfish and carp. The Jewish laws of Kashrut forbid the eating of shellfish and eels. In the Old Testament, the Mosaic Covenant allowed the Israelites to eat finfish, but shellfish and eels were an abomination and not allowed. In ancient and medieval times, the Catholic Church forbade the practice of eating meat, eggs and dairy products during Lent. Thomas Aquinas argued that these "afford greater pleasure as food [than fish], and greater nourishment to the human body, so that from their consumption there results a greater surplus available for seminal matter, which when abundant becomes a great incentive to lust." In the United States, the Catholic practice of abstaining from meat on Fridays during Lent has popularized the Friday fish fry, and parishes often sponsor a fish fry during Lent. In predominantly Roman Catholic areas, restaurants may adjust their menus during Lent by adding seafood items to the menu.
References.
</dl>
Bibliography.
</dl>

</doc>
<doc id="26872" url="http://en.wikipedia.org/wiki?curid=26872" title="SI base unit">
SI base unit

The International System of Units (SI) defines seven units of measure as a basic set from which all other SI units are derived. The SI base units and their physical quantities are:
The SI base quantities form a set of mutually independent dimensions as required by dimensional analysis commonly employed in science and technology. However, in a given realization in these units they may well be interdependent, i.e. defined in terms of each other.
The names and symbols of SI base units are written in lowercase (e.g. "metre" (US English: "meter") has the symbol m), except the symbols of those named after persons which are written with an initial capital letter (i.e., the "kelvin" after Lord Kelvin has the symbol K and the "ampere" after André-Marie Ampère has the symbol A).
Many other units, such as the litre (US English: "liter"), are formally not part of the SI, but are accepted for use with SI.
Proposed redefinitions.
There have been several modifications to the definitions of the base units, and additions of base units, since the Metre Convention in 1875. Since the redefinition of the metre in 1960, the kilogram is the only unit which is directly defined in terms of a physical artifact rather than a property of nature. However, the mole, the ampere and the candela are also linked through their definitions to the mass of this platinum–iridium cylinder stored in a vault near Paris. It has long been an objective of metrology to find a way to define the kilogram in terms of a fundamental constant, in the same way that the metre is now defined in terms of the speed of light.
The 21st General Conference on Weights and Measures (CGPM, 1999) placed these efforts on an official footing, and recommended "that national laboratories continue their efforts to refine experiments that link the unit of mass to fundamental or atomic constants with a view to a future redefinition of the kilogram." Two main possibilities have attracted attention: the Planck constant and the Avogadro constant.
In 2005, the International Committee for Weights and Measures (CIPM) approved the preparation of new definitions for the kilogram, the ampere, and the kelvin and it noted the possibility of a new definition for the mole based on the Avogadro constant. The 23rd CGPM (2007) decided to postpone any formal change until the next General Conference in 2011.
In a note to the CIPM in October 2009, Ian Mills, the President of the CIPM "Consultative Committee - Units (CCU)" cataloged the uncertainties of the fundamental constants of physics according to the current definitions and their values under the proposed new definition. He urged the CIPM to accept the proposed changes in the definition of the "kilogram", "ampere", "kelvin" and "mole" so that they are referenced to the values of the fundamental constants, namely Planck's constant (h), the electron charge (e), Boltzmann's constant (k), and Avogadro's constant (NA).

</doc>
<doc id="26873" url="http://en.wikipedia.org/wiki?curid=26873" title="Second">
Second

The second (symbol: s) is the base unit of time in the International System of Units (SI)
and is also a unit of time in other systems of measurement (abbreviated s or sec); it is the second division of the hour by sixty, the first division by 60 being the minute. Between 1000 CE (when al-Biruni used seconds) and 1960 the second was defined as 1/86,400 of a mean solar day (that definition still applies in some astronomical and legal contexts). Between 1960 and 1967, it was defined in terms of the period of the Earth's orbit around the Sun in 1900,
but it is now defined more precisely in atomic terms. Seconds may be measured using mechanical, electric or atomic clocks.
Astronomical observations of the 19th and 20th centuries revealed that the mean solar day is slowly but measurably lengthening and the length of a tropical year is not entirely predictable either; thus the sun–earth motion is no longer considered a suitable basis for definition. With the advent of atomic clocks, it became feasible to define the second based on fundamental properties of nature. Since 1967, the second has been defined to be:
the duration of periods of the radiation corresponding to the transition between the two hyperfine levels of the ground state of the caesium 133 atom.
In 1997, the CIPM affirmed that the preceding definition "refers to a caesium atom at rest at a temperature of 0 K."
SI prefixes are frequently combined with the word "second" to denote subdivisions of the second, "e.g.", the millisecond (one thousandth of a second), the microsecond (one millionth of a second), and the nanosecond (one billionth of a second). Though SI prefixes may also be used to form multiples of the second such as kilosecond (one thousand seconds), such units are rarely used in practice. The more common larger non-SI units of time are not formed by powers of ten; instead, the second is multiplied by 60 to form a minute, which is multiplied by 60 to form an hour, which is multiplied by 24 to form a day.
The second is also the base unit of time in the centimetre-gram-second, metre-kilogram-second, metre-tonne-second, and foot-pound-second systems of units.
International second.
Under the International System of Units (via the International Committee for Weights and Measures, or CIPM), since 1967 the second has been defined as the duration of periods of the radiation corresponding to the transition between the two hyperfine levels of the ground state of the caesium 133 atom. In 1997 CIPM added that the periods would be defined for a caesium atom at rest, and approaching the theoretical temperature of absolute zero (0 K), and in 1999, it included corrections from ambient radiation. Absolute zero implies no movement, and therefore zero external radiation effects (i.e., zero local electric and magnetic fields).
The second thus defined is consistent with the ephemeris second, which was based on astronomical measurements. (See History below.) The realization of the standard second is described briefly in a special publication from the National Institute of Standards and Technology, and in detail by the National Research Council of Canada.
Equivalence to other units of time.
1 international second is equal to:
History.
Before mechanical clocks.
The Egyptians subdivided daytime and nighttime into twelve hours each since at least 2000 BC, hence the seasonal variation of their hours. The Hellenistic astronomers Hipparchus ("c." 150 BC) and Ptolemy ("c." AD 150) subdivided the day sexagesimally and also used a mean hour (1⁄24 day), simple fractions of an hour (1⁄4, 2⁄3, etc.) and time-degrees (1⁄360 day or four modern minutes), but not modern minutes or seconds.
The day was subdivided sexagesimally, that is by 1⁄60, by 1⁄60 of that, by 1⁄60 of that, etc., to at least six places after the sexagesimal point (a precision of better than 2 microseconds) by the Babylonians after 300 BC. For example, six fractional sexagesimal places of a day was used in their specification of the length of the year, although they were unable to measure such a small fraction of a day in real time. As another example, they specified that the mean synodic month was 29;31,50,8,20 days (four fractional sexagesimal positions), which was repeated by Hipparchus and Ptolemy sexagesimally, and is currently the mean synodic month of the Hebrew calendar, though restated as 29 days 12 hours 793 halakim (where 1 hour = 1080 halakim). The Babylonians did not use the hour, but did use a double-hour lasting 120 modern minutes, a time-degree lasting four modern minutes, and a barleycorn lasting 31⁄3 modern seconds (the "helek" of the modern Hebrew calendar), but did not sexagesimally subdivide these smaller units of time. No sexagesimal unit of the day was ever used as an independent unit of time.
In 1000, the Persian scholar al-Biruni gave the times of the new moons of specific weeks as a number of days, hours, minutes, seconds, thirds, and fourths after noon Sunday. In 1267, the medieval scientist Roger Bacon stated the times of full moons as a number of hours, minutes, seconds, thirds, and fourths ("horae", "minuta", "secunda", "tertia", and "quarta") after noon on specified calendar dates. Although a "third" for 1⁄60 of a second remains in some languages, for example Polish ("tercja") and Turkish ("salise"), the modern second is subdivided decimally.
Seconds measured by mechanical clocks.
The earliest clocks to display seconds appeared during the last half of the 16th century. The earliest spring-driven timepiece with a second hand which marked seconds is an unsigned clock depicting Orpheus in the Fremersdorf collection, dated between 1560 and 1570.:417–418 During the 3rd quarter of the 16th century, Taqi al-Din built a clock with marks every 1/5 minute.
In 1579, Jost Bürgi built a clock for William of Hesse that marked seconds.:105 In 1581, Tycho Brahe redesigned clocks that displayed minutes at his observatory so they also displayed seconds. However, they were not yet accurate enough for seconds. In 1587, Tycho complained that his four clocks disagreed by plus or minus four seconds.:104
The second first became accurately measurable with the development of pendulum clocks keeping "mean time" (as opposed to the "apparent time" displayed by sundials). In 1644, Marin Mersenne calculated that a pendulum with a length of 39.1 inches (0.994 m) would have a period at one standard gravity of precisely two seconds, one second for a swing forward and one second for the return swing, enabling such a pendulum to tick in precise seconds.
In 1670, London clockmaker William Clement added this seconds pendulum to the original pendulum clock of Christiaan Huygens. From 1670 to 1680, Clement made many improvements to his clock and introduced the longcase or grandfather clock to the public. This clock used an anchor escapement mechanism with a seconds pendulum to display seconds in a small subdial. This mechanism required less power, caused less friction and was accurate enough to measure seconds reliably as one-sixtieth of a minute than the older verge escapement. Within a few years, most British precision clockmakers were producing longcase clocks and other clockmakers soon followed. Thus the second could now be reliably measured.
Modern measurements.
As a unit of time, the second (meaning the "second" division by 60 of an hour) entered English in the late 16th century, about a hundred years before it was measured accurately. Those who wrote in Latin, including scientists like Bacon, Tycho and Kepler, used the Latin term "secunda" with the same meaning as far back as the 1200s.
In 1832, Gauss proposed using the second as the base unit of time in his millimeter-milligram-second system of units. The British Association for the Advancement of Science (BAAS) in 1862 stated that "All men of science are agreed to use the second of mean solar time as the unit of time." BAAS formally proposed the CGS system in 1874, although this system was gradually replaced over the next 70 years by MKS units. Both the CGS and MKS systems used the same second as their base unit of time. MKS was adopted internationally during the 1940s, defining the second as 1/86,400th of a mean solar day.
In 1956, the second was redefined in terms of a "year" (the period of the Earth's revolution around the Sun) "for a particular epoch" because, by then, it had become recognized that the Earth's rotation on its own axis was not sufficiently uniform as a standard of time. The Earth's motion was described in Newcomb's Tables of the Sun (1895), which provided a formula for estimating the motion of the Sun relative to the epoch 1900 based on astronomical observations made between 1750 and 1892.
The second was thus defined as:
the fraction 1/31,556,925.9747 of the tropical year for 1900 January 0 at 12 hours ephemeris time.
This definition was ratified by the Eleventh General Conference on Weights and Measures in 1960, which also established the International System of Units.
The "tropical year" in the 1960 definition was not measured but calculated from a formula describing a mean tropical year that decreased linearly over time, hence the curious reference to a specific "instantaneous" tropical year. This was in conformity with the ephemeris time scale adopted by the IAU in 1952. This definition brings the observed positions of the celestial bodies into accord with Newtonian dynamical theories of their motion. Specifically, those tables used for most of the 20th century were Newcomb's Tables of the Sun (used from 1900 through 1983) and Brown's Tables of the Moon (used from 1923 through 1983).
Thus, the 1960 SI definition abandoned any explicit relationship between the scientific second and the length of a day, as most people understand the term. With the development of the atomic clock in the early 1960s, it was decided to use atomic time as the basis of the definition of the second, rather than the revolution of the Earth around the Sun.
Following several years of work, Louis Essen from the National Physical Laboratory (Teddington, England) and William Markowitz from the United States Naval Observatory (USNO) determined the relationship between the hyperfine transition frequency of the caesium atom and the ephemeris second. Using a common-view measurement method based on the received signals from radio station WWV, they determined the orbital motion of the Moon about the Earth, from which the apparent motion of the Sun could be inferred, in terms of time as measured by an atomic clock. They found that the second of ephemeris time (ET) had the duration of 9,192,631,770 ± 20 cycles of the chosen caesium frequency. As a result, in 1967 the "Thirteenth General Conference on Weights and Measures" defined the SI second of atomic time as:
the duration of 9,192,631,770 periods of the radiation corresponding to the transition between the two hyperfine levels of the ground state of the caesium-133 atom.
This SI second, referred to atomic time, was later verified to be in agreement, within 1 part in 1010, with the second of ephemeris time as determined from lunar observations. (Nevertheless, this SI second was already, when adopted, a little shorter than the then-current value of the second of mean solar time.)
During the 1970s it was realized that gravitational time dilation caused the second produced by each atomic clock to differ depending on its altitude. A uniform second was produced by correcting the output of each atomic clock to mean sea level (the rotating geoid), lengthening the second by about 1×10−10. This correction was applied at the beginning of 1977 and formalized in 1980. In relativistic terms, the SI second is defined as the proper time on the rotating geoid.
The definition of the second was later refined at the 1997 meeting of the BIPM to include the statement
This definition refers to a caesium atom at rest at a temperature of 0 K.
The revised definition seems to imply that the ideal atomic clock contains a single caesium atom at rest emitting a single frequency. In practice, however, the definition means that high-precision realizations of the second should compensate for the effects of the ambient temperature (black-body radiation) within which atomic clocks operate, and extrapolate accordingly to the value of the second at a temperature of absolute zero.
Possible future enhancements.
Today, the atomic clock operating in the microwave region is challenged by atomic clocks operating in the optical region. To quote Ludlow "et al.", “In recent years, optical atomic clocks have become increasingly competitive in performance with their microwave counterparts. The overall accuracy of single-trapped-ion-based optical standards closely approaches that of the state-of-the-art caesium fountain standards. Large ensembles of ultracold alkaline earth atoms have provided impressive clock stability for short averaging times, surpassing that of single-ion-based systems. So far, interrogation of neutral-atom-based optical standards has been carried out primarily in free space, unavoidably including atomic motional effects that typically limit the overall system accuracy. An alternative approach is to explore the ultranarrow optical transitions of atoms held in an optical lattice. The atoms are tightly localized so that Doppler and photon-recoil related effects on the transition frequency are eliminated.”
The attaches a "relative uncertainty" of 2.5×10−11 (limited by day-to-day and device-to-device reproducibility) to their atomic clock based upon the 127I2 molecule, and is advocating use of an 88Sr ion trap instead (relative uncertainty due to linewidth of 2.2×10−15). See magneto-optical trap and Such uncertainties rival that of the NIST-F1 caesium atomic clock in the microwave region, estimated as a few parts in 1016 averaged over a day.
SI multiples.
SI prefixes are commonly used to measure time less than a second, but rarely for multiples of a second (which is known as metric time). Instead, the non-SI units minutes, hours, days, Julian years, Julian centuries, and Julian millennia are used.
Other current definitions.
For specialized purposes, a second may be used as a unit of time in time scales where the precise length differs slightly from the SI definition. One such time scale is UT1, a form of universal time. McCarthy and Seidelmann refrain from stating that the SI second is the legal standard for timekeeping throughout the world, saying only that "over the years UTC [which ticks SI seconds] has become either the basis for legal time of many countries, or accepted as the "de facto" basis for standard civil time".

</doc>
<doc id="26874" url="http://en.wikipedia.org/wiki?curid=26874" title="Metric prefix">
Metric prefix

A metric prefix or SI prefix is a unit prefix that precedes a basic unit of measure to indicate a decadic multiple or fraction of the unit. Each prefix has a unique symbol that is prepended to the unit symbol. The prefix "kilo-", for example, may be added to "gram" to indicate multiplication by one thousand; one kilogram is equal to one thousand grams. The prefix "milli-", likewise, may be added to "metre" to indicate division by one thousand; one millimetre is equal to one thousandth of a metre.
Decimal multiplicative prefixes have been a feature of all forms of the metric system with six dating back to the system's introduction in the 1790s. Metric prefixes have even been pre-pended to non-metric units. Today the prefixes are standardized for use in the International System of Units (SI) by the International Bureau of Weights and Measures (BIPM) in resolutions dating from 1960 to 1991. Since 2009, they have formed part of the International System of Quantities.
List of SI prefixes.
The BIPM specifies twenty prefixes for the International System of Units (SI).
Each prefix name has a symbol which is used in combination with the symbols for units of measure. For example, the symbol for "kilo-" is "k", and is used to produce "km", "kg", and "kW", which are kilometre, kilogram, and kilowatt, respectively.
Prefixes may not be used in combination. This also applies to mass, for which the SI base unit (kilogram) already contains a prefix. For example, milligram (mg) is used instead of microkilogram (µkg).
In arithmetic of measurements having prefixed units, the prefixes must be expanded to their numeric multiplier, except when adding or subtracting values with identical units.
Hence,  ×  =  ×  =  = .
Prefixes corresponding to an integer power of one thousand are generally preferred. Hence "100 m" is preferred over "1 hm" (hectometre) or "10 dam" (decametres). The prefixes hecto, deca, deci, and centi were commonly used for everyday purposes, especially the centimeter (cm) is common. However, some modern building codes require that the millimetre be used in preference to the centimetre, because "use of centimeters leads to extensive usage of decimal points and confusion".
When units occur in exponentiation, for example, in square and cubic forms, the multiplication prefix must be considered part of the unit, and thus included in the exponentiation.
Application to units of measurement.
The use of prefixes can be traced back to the introduction of the metric system in the 1790s, long before the 1960 introduction of the SI. The prefixes, including those introduced after 1960, are used with any metric unit, whether officially included in the SI or not (e.g. millidynes and milligauss). Metric prefixes may also be used with non-metric units.
The choice of prefixes with a given unit is usually dictated by convenience of use. Unit prefixes for amounts that are much larger or smaller than those actually encountered are seldom used, though they remain valid combinations. In most contexts only a few most common combinations are established as standard.
The kilogram, gram, milligram, microgram, and smaller are common. However, megagram (and gigagram, teragram, etc.) are rarely used; tonnes (and kilotonnes, megatonnes, etc.) or scientific notation are used instead. Megagram is occasionally used to disambiguate the metric tonne from the various non-metric tons. An exception is pollution emission rates, which are typically on the order of Tg/yr. Sometimes only one element is denoted for an emission, such as Tg C/yr or Tg N/yr, so that inter-comparisons of different compounds are easier.
The litre, millilitre (equal to a cubic centimetre), microlitre, and smaller are common. In Europe, the centilitre is often used for packaged products but the use of the decilitre is rare everywhere. (The latter two items include prefixes corresponding to an exponent that is not divisible by three.)
Larger volumes are usually denoted in kilolitres, megalitres or gigalitres, or else in cubic metres (1 cubic metre = 1 kilolitre) or cubic kilometres (1 cubic kilometre = 1 teralitre).
The kilometre, metre, centimetre, millimetre, and smaller are common. (However, the decimetre is rarely used.) The micrometre is often referred to by the non-SI term "micron". In some fields such as chemistry, the angstrom (equal to 0.1 nm) historically competed with the nanometre. The femtometre, used mainly in particle physics, is usually called a fermi. For large scales, megametre, gigametre, and larger are rarely used. Often used are astronomical units, light years, and parsecs; the astronomical unit is mentioned in the SI standards as an accepted non-SI unit.
The second, millisecond, microsecond, and shorter are common. The kilosecond and megasecond also have some use, though for these and longer times one usually uses either scientific notation or minutes, hours, and so on.
Official policies about the use of these prefixes vary slightly between the Bureau International des Poids et Mesures (BIPM) and the American National Institute of Standards and Technology (NIST); and some of the policies of both bodies are at variance with everyday practice. For instance, the NIST advises that "…to avoid confusion, prefix symbols (and prefixes) are not used with the time-related unit symbols (names) min (minute), h (hour), d (day); nor with the angle-related symbols (names) ° (degree), ′ (minute), and ″ (second)." 
The BIPM’s position on the use of SI prefixes with units of time larger than the second is the same as that of the NIST but their position with regard to angles differs: they state "However astronomers use milliarcsecond, which they denote mas, and microarcsecond, µas, which they use as units for measuring very small angles." 
Official policy also varies from common practice for the degree Celsius (°C). NIST ; "Prefix symbols may be used with the unit symbol °C and prefixes may be used with the unit name 'degree Celsius'. For example, 12 m°C (12 millidegrees Celsius) is acceptable." In practice, it is more common for prefixes to be used with the kelvin when it is desirable to denote extremely large or small absolute temperatures or temperature differences. Thus, temperatures of star interiors may be given in units of MK (megakelvins), and molecular cooling may be described in mK (millikelvins).
There exist a number of definitions for the non-SI unit, the calorie. There are gram calories and kilogram calories. One kilogram calorie, which equals one thousand gram calories, often appears capitalized and without a prefix (i.e. 'Cal') when referring to "dietary calories" in food. It is common to apply metric prefixes to the gram calorie but not to the kilogram calorie: thus, for example, 1 kcal = 1000 cal = 1 Cal.
Non-metric units.
Metric prefixes are widely used outside the system of metric units. Common examples include the megabyte and the decibel. Metric prefixes rarely appear with imperial or US units except in some special cases (e.g., microinch, kilofoot, kilopound or 'kip'). They are also used with other specialized units used in particular fields (e.g., megaelectronvolt, gigaparsec, millibarn). They are also occasionally used with currency units (e.g., gigadollar), mainly by people who are familiar with the prefixes from scientific usage.
Presentation.
Pronunciation.
The prefix "giga" is usually pronounced but sometimes . According to the American writer Kevin Self, in the 1920s a German committee member of the International Electrotechnical Commission proposed "giga" as a prefix for 109, drawing on a verse by the humorous poet Christian Morgenstern that appeared in the third (1908) edition of "Galgenlieder" (Gallows Songs). This suggests a hard German "g" was originally intended as the pronunciation. Self was unable to ascertain when the /dʒ/ (soft "g") pronunciation was accepted, but as of 1995 current practice had returned to /ɡ/ (hard "g").
When an SI prefix is affixed to a root word, the prefix carries the stress, while the root drops its stress but retains a full vowel in the syllable that is stressed when the root word stands alone. For example, "gigabyte" is , with stress on the first syllable. However, words in common use outside the scientific community may follow idiosyncratic stress rules. In English speaking countries "kilometre" is often pronounced /kɨˈlɒmɨtər/, with reduced vowels on both syllables of "metre."
Typesetting.
The LaTeX typesetting system features an "SIunitx" package, in which the units of measurement are spelled out, for example, codice_1 formats as "3 THz".
Non-standard prefixes.
Obsolete metric prefixes.
Some of the prefixes formerly used in the metric system have fallen into disuse and were not adopted into the SI.
The prefix "myria-" (ten thousand) originated from the Greek μύριοι ("mýrioi") (myriad), and the prefixes "demi" and "double", denoting a factor of 1⁄2 and 2, respectively, were parts of the original metric system adopted by France in 1795. These were not retained when the SI prefixes were internationally adopted by the 11th CGPM conference in 1960. The halving and doubling prefixes were dropped because they were neither decimal nor symmetrical. Most were rarely used, although the myriametre (10 km) is occasionally encountered in 19th-century train tariffs, or in some classifications of wavelengths as the adjective "myriametric". In Sweden and Norway, the myriametre is still common in everyday use. In these countries this unit is called "mil". Of units customarily used in trade in France, the myriagramme (10 kg) was the metric replacement for an avoirdupois unit, the "quartier" (25 pounds). Isaac Asimov's novel "Foundation and Empire" mentions the "myriaton".
Double prefixes.
Double prefixes have been used in the past, such as "micromillimetres" or "millimicrons" (now nanometres), "micromicrofarads" (now picofarads), "hectokilometres" (now 100 kilometres) and the derived adjective "hectokilometric" (typically used for qualifying the fuel consumption measures). These were disallowed with the introduction of the SI.
Other obsolete double prefixes included "decimilli-" (10−4), which was contracted to "dimi-".
"Hella" prefix proposal.
In 2010, UC Davis student Austin Sendek started a petition to designate "hella" as the SI prefix for one octillion (1027). The petition gathered over 60,000 supporters by circulating through Facebook and receiving a significant amount of media coverage. Although the Consultative Committee for Units considered the proposal, it was ultimately rejected. However, "hella" has been adopted by certain websites, such as Google Calculator and Wolfram Alpha.
X, W and V.
Brian C. Lacki follows Z and Y with the adopted prefixes X, W and V to mean , and respectively, thus continuing the inverse alphabetical order.
Similar symbols and abbreviations.
In written English, the symbol "K" is often used informally to mean a multiple of thousand in many contexts. For example, one may talk of a "40K salary" (), or call the Year 2000 problem the "Y2K problem". In these cases an uppercase K is often used. This informal postfix is read or spoken as "thousand" or "grand", or just "k", but never "kilo" (despite that being the origin of the letter).
The financial and general news media mostly use m/M, b/B and t/T as abbreviations for million, billion (109) and trillion (1012) for large quantities, typically currency and population.
The medical and automotive fields in the United States use the abbreviations "cc" or "ccm" for cubic centimetres. 1 cubic centimetre is equivalent to 1 millilitre. Most nations use millilitres in preference to cubic centimetres.
For nearly a century, the electrical construction industry used the abbreviation "MCM" to designate a "thousand circular mils" in specifying thicknesses of large electrical cables. Since the mid-1990s, "kcmil" has been adopted as the "official" designation of a thousand circular mils, but the designation "MCM" still remains in wide use. A similar system is used in natural gas sales in the United States: m (or M) for thousands and mm (or MM) for millions of British thermal units or therms, and in the oil industry, where 'MMbbl' is the symbol for 'millions of barrels'.
Binary prefixes.
In some fields of information technology it has been common to designate non-decimal multiples based on powers of 1024, rather than 1000, for some SI prefixes (kilo, mega, giga), contrary to the definitions in the International System of Units (SI). This practice has been sanctioned by some industry associations, including JEDEC. The International Electrotechnical Commission (IEC) standardized the system of binary prefixes for this purpose.
References.
This article is based on material taken from the Free On-line Dictionary of Computing prior to 1 November 2008 and incorporated under the "relicensing" terms of the GFDL, version 1.3 or later.

</doc>
<doc id="26876" url="http://en.wikipedia.org/wiki?curid=26876" title="SI derived unit">
SI derived unit

The International System of Units (SI) specifies a set of seven base units from which all other SI units of measurement are derived. Each of these other units (SI derived units) is either dimensionless or can be expressed as a product of (positive or negative, but usually integral) powers of one or more of the base units. 
For example, the SI derived unit of area is the square metre (m2), and the SI derived unit of density is the kilogram per cubic metre (kg/m3 or kg m−3). The degree Celsius (see the table below) has a somewhat unclear status, and is arguably an exception to this rule. The names of SI units are written in lowercase. The symbols for units named after persons, however, are always written with an uppercase initial letter (e.g. the symbol for the hertz is "Hz"; but the symbol for the metre is "m").
Derived units with special names.
In addition to the two dimensionless derived units radian (rad) and steradian (sr), 20 other derived units have special names.
Other units used with SI.
Some other units such as the hour, litre, tonne, and electron volt are not SI units, but are widely used in conjunction with SI units.
Supplementary units.
Until 1995, the SI classified the radian and the steradian as "supplementary units", but this designation was abandoned and the units were grouped as derived units.

</doc>
<doc id="26882" url="http://en.wikipedia.org/wiki?curid=26882" title="Split (poker)">
Split (poker)

In poker it is sometimes necessary to split, or divide the pot among two or more players rather than awarding it all to a single player. This can happen because of ties, and also by playing intentional split-pot poker variants (the most typical of these is high-low split poker, where the high hand and low hand split the pot).
To split a pot, one player uses both hands to take the chips from the pot and make stacks, placing them side by side to compare height (and therefore value). Equal stacks are placed aside. If there is more than one denomination of chip in the pot, the largest value chip is done first, and then progressively smaller value chips. If there is an odd number of larger chips, smaller chips from the pot can be used to equalize stacks or make change as necessary. Pots are always split down to the lowest denomination of chip used in the game. Three-way ties or further splits can also be done this way.
After fully dividing a pot, there may be a single odd lowest-denomination chip remaining (or two odd chips if splitting three ways, etc.). Odd chips can be awarded in several ways, agreed upon before the beginning of the game. The following rules are common:
Sometimes it is necessary to further split a half pot into quarters, or even smaller portions. This is especially common in community card high-low split games such as Omaha hold'em, where one player has the high hand and two or more players have tied low hands. Unfortunate players receiving such a fractional pot call it being "quartered". When this happens, an exception to the odd chip rules above can be made: if the high hand wins its half of the pot alone, and the low half is going to be quartered, the odd chip (if any) from the first split should be placed in the low half, rather than being awarded to the high hand.

</doc>
<doc id="26884" url="http://en.wikipedia.org/wiki?curid=26884" title="Superconductivity">
Superconductivity

Superconductivity is a phenomenon of exactly zero electrical resistance and expulsion of magnetic fields occurring in certain materials when cooled below a characteristic critical temperature. It was discovered by Dutch physicist Heike Kamerlingh Onnes on April 8, 1911 in Leiden. Like ferromagnetism and atomic spectral lines, superconductivity is a quantum mechanical phenomenon. It is characterized by the Meissner effect, the complete ejection of magnetic field lines from the interior of the superconductor as it transitions into the superconducting state. The occurrence of the Meissner effect indicates that superconductivity cannot be understood simply as the idealization of "perfect conductivity" in classical physics.
The electrical resistivity of a metallic conductor decreases gradually as temperature is lowered. In ordinary conductors, such as copper or silver, this decrease is limited by impurities and other defects. Even near absolute zero, a real sample of a normal conductor shows some resistance. In a superconductor, the resistance drops abruptly to zero when the material is cooled below its critical temperature. An electric current flowing through a loop of superconducting wire can persist indefinitely with no power source.
In 1986, it was discovered that some cuprate-perovskite ceramic materials have a critical temperature above 90 K. Such a high transition temperature is theoretically impossible for a conventional superconductor, leading the materials to be termed high-temperature superconductors. Liquid nitrogen boils at 77 K, and superconduction at higher temperatures than this facilitates many experiments and applications that are less practical at lower temperatures.
Classification.
There are many criteria by which superconductors are classified. The most common are:
Elementary properties of superconductors.
Most of the physical properties of superconductors vary from material to material, such as the heat capacity and the critical temperature, critical field, and critical current density at which superconductivity is destroyed.
On the other hand, there is a class of properties that are independent of the underlying material. For instance, all superconductors have "exactly" zero resistivity to low applied currents when there is no magnetic field present or if the applied field does not exceed a critical value. The existence of these "universal" properties implies that superconductivity is a thermodynamic phase, and thus possesses certain distinguishing properties which are largely independent of microscopic details.
Zero electrical DC resistance.
The simplest method to measure the electrical resistance of a sample of some material is to place it in an electrical circuit in series with a current source "I" and measure the resulting voltage "V" across the sample. The resistance of the sample is given by Ohm's law as "R = V / I". If the voltage is zero, this means that the resistance is zero.
Superconductors are also able to maintain a current with no applied voltage whatsoever, a property exploited in superconducting electromagnets such as those found in MRI machines. Experiments have demonstrated that currents in superconducting coils can persist for years without any measurable degradation. Experimental evidence points to a current lifetime of at least 100,000 years. Theoretical estimates for the lifetime of a persistent current can exceed the estimated lifetime of the universe, depending on the wire geometry and the temperature.
In a normal conductor, an electric current may be visualized as a fluid of electrons moving across a heavy ionic lattice. The electrons are constantly colliding with the ions in the lattice, and during each collision some of the energy carried by the current is absorbed by the lattice and converted into heat, which is essentially the vibrational kinetic energy of the lattice ions. As a result, the energy carried by the current is constantly being dissipated. This is the phenomenon of electrical resistance.
The situation is different in a superconductor. In a conventional superconductor, the electronic fluid cannot be resolved into individual electrons. Instead, it consists of bound "pairs" of electrons known as Cooper pairs. This pairing is caused by an attractive force between electrons from the exchange of phonons. Due to quantum mechanics, the energy spectrum of this Cooper pair fluid possesses an "energy gap", meaning there is a minimum amount of energy Δ"E" that must be supplied in order to excite the fluid. Therefore, if Δ"E" is larger than the thermal energy of the lattice, given by "kT", where "k" is Boltzmann's constant and "T" is the temperature, the fluid will not be scattered by the lattice. The Cooper pair fluid is thus a superfluid, meaning it can flow without energy dissipation.
In a class of superconductors known as type II superconductors, including all known high-temperature superconductors, an extremely small amount of resistivity appears at temperatures not too far below the nominal superconducting transition when an electric current is applied in conjunction with a strong magnetic field, which may be caused by the electric current. This is due to the motion of magnetic vortices in the electronic superfluid, which dissipates some of the energy carried by the current. If the current is sufficiently small, the vortices are stationary, and the resistivity vanishes. The resistance due to this effect is tiny compared with that of non-superconducting materials, but must be taken into account in sensitive experiments. However, as the temperature decreases far enough below the nominal superconducting transition, these vortices can become frozen into a disordered but stationary phase known as a "vortex glass". Below this vortex glass transition temperature, the resistance of the material becomes truly zero.
Superconducting phase transition.
In superconducting materials, the characteristics of superconductivity appear when the temperature "T" is lowered below a critical temperature "Tc". The value of this critical temperature varies from material to material. Conventional superconductors usually have critical temperatures ranging from around 20 K to less than 1 K. Solid mercury, for example, has a critical temperature of 4.2 K. s of 2009[ [update]], the highest critical temperature found for a conventional superconductor is 39 K for magnesium diboride (MgB2), although this material displays enough exotic properties that there is some doubt about classifying it as a "conventional" superconductor. Cuprate superconductors can have much higher critical temperatures: YBa2Cu3O7, one of the first cuprate superconductors to be discovered, has a critical temperature of 92 K, and mercury-based cuprates have been found with critical temperatures in excess of 130 K. The explanation for these high critical temperatures remains unknown. Electron pairing due to phonon exchanges explains superconductivity in conventional superconductors, but it does not explain superconductivity in the newer superconductors that have a very high critical temperature.
Similarly, at a fixed temperature below the critical temperature, superconducting materials cease to superconduct when an external magnetic field is applied which is greater than the "critical magnetic field". This is because the Gibbs free energy of the superconducting phase increases quadratically with the magnetic field while the free energy of the normal phase is roughly independent of the magnetic field. If the material superconducts in the absence of a field, then the superconducting phase free energy is lower than that of the normal phase and so for some finite value of the magnetic field (proportional to the square root of the difference of the free energies at zero magnetic field) the two free energies will be equal and a phase transition to the normal phase will occur. More generally, a higher temperature and a stronger magnetic field lead to a smaller fraction of the electrons in the superconducting band and consequently a longer London penetration depth of external magnetic fields and currents. The penetration depth becomes infinite at the phase transition.
The onset of superconductivity is accompanied by abrupt changes in various physical properties, which is the hallmark of a phase transition. For example, the electronic heat capacity is proportional to the temperature in the normal (non-superconducting) regime. At the superconducting transition, it suffers a discontinuous jump and thereafter ceases to be linear. At low temperatures, it varies instead as "e"−α/"T" for some constant, α. This exponential behavior is one of the pieces of evidence for the existence of the energy gap.
The order of the superconducting phase transition was long a matter of debate. Experiments indicate that the transition is second-order, meaning there is no latent heat. However in the presence of an external magnetic field there is latent heat, because the superconducting phase has a lower entropy below the critical temperature than the normal phase. It has been experimentally demonstrated that, as a consequence, when the magnetic field is increased beyond the critical field, the resulting phase transition leads to a decrease in the temperature of the superconducting material.
Calculations in the 1970s suggested that it may actually be weakly first-order due to the effect of long-range fluctuations in the electromagnetic field. In the 1980s it was shown theoretically with the help of a disorder field theory, in which the vortex lines of the superconductor play a major role, that the transition is of second order within the type II regime and of first order (i.e., latent heat) within the type I regime, and that the two regions are separated by a tricritical point. The results were strongly supported by Monte Carlo computer simulations.
Meissner effect.
When a superconductor is placed in a weak external magnetic field H, and cooled below its transition temperature, the magnetic field is ejected. The Meissner effect does not cause the field to be completely ejected but instead the field penetrates the superconductor but only to a very small distance, characterized by a parameter "λ", called the London penetration depth, decaying exponentially to zero within the bulk of the material. The Meissner effect is a defining characteristic of superconductivity. For most superconductors, the London penetration depth is on the order of 100 nm.
The Meissner effect is sometimes confused with the kind of diamagnetism one would expect in a perfect electrical conductor: according to Lenz's law, when a "changing" magnetic field is applied to a conductor, it will induce an electric current in the conductor that creates an opposing magnetic field. In a perfect conductor, an arbitrarily large current can be induced, and the resulting magnetic field exactly cancels the applied field.
The Meissner effect is distinct from this—it is the spontaneous expulsion which occurs during transition to superconductivity. Suppose we have a material in its normal state, containing a constant internal magnetic field. When the material is cooled below the critical temperature, we would observe the abrupt expulsion of the internal magnetic field, which we would not expect based on Lenz's law.
The Meissner effect was given a phenomenological explanation by the brothers Fritz and Heinz London, who showed that the electromagnetic free energy in a superconductor is minimized provided
where H is the magnetic field and λ is the London penetration depth.
This equation, which is known as the London equation, predicts that the magnetic field in a superconductor decays exponentially from whatever value it possesses at the surface.
A superconductor with little or no magnetic field within it is said to be in the Meissner state. The Meissner state breaks down when the applied magnetic field is too large. Superconductors can be divided into two classes according to how this breakdown occurs. In Type I superconductors, superconductivity is abruptly destroyed when the strength of the applied field rises above a critical value "Hc". Depending on the geometry of the sample, one may obtain an intermediate state consisting of a baroque pattern of regions of normal material carrying a magnetic field mixed with regions of superconducting material containing no field. In Type II superconductors, raising the applied field past a critical value "H""c"1 leads to a mixed state (also known as the vortex state) in which an increasing amount of magnetic flux penetrates the material, but there remains no resistance to the flow of electric current as long as the current is not too large. At a second critical field strength "H""c"2, superconductivity is destroyed. The mixed state is actually caused by vortices in the electronic superfluid, sometimes called fluxons because the flux carried by these vortices is quantized. Most pure elemental superconductors, except niobium and carbon nanotubes, are Type I, while almost all impure and compound superconductors are Type II.
London moment.
Conversely, a spinning superconductor generates a magnetic field, precisely aligned with the spin axis. The effect, the London moment, was put to good use in Gravity Probe B. This experiment measured the magnetic fields of four superconducting gyroscopes to determine their spin axes. This was critical to the experiment since it is one of the few ways to accurately determine the spin axis of an otherwise featureless sphere.
History of superconductivity.
Superconductivity was discovered on April 8, 1911 by Heike Kamerlingh Onnes, who was studying the resistance of solid mercury at cryogenic temperatures using the recently produced liquid helium as a refrigerant. At the temperature of 4.2 K, he observed that the resistance abruptly disappeared. In the same experiment, he also observed the superfluid transition of helium at 2.2 K, without recognizing its significance. The precise date and circumstances of the discovery were only reconstructed a century later, when Onnes's notebook was found. In subsequent decades, superconductivity was observed in several other materials. In 1913, lead was found to superconduct at 7 K, and in 1941 niobium nitride was found to superconduct at 16 K.
Great efforts have been devoted to finding out how and why superconductivity works; the important step occurred in 1933, when Meissner and Ochsenfeld discovered that superconductors expelled applied magnetic fields, a phenomenon which has come to be known as the Meissner effect. In 1935, Fritz and Heinz London showed that the Meissner effect was a consequence of the minimization of the electromagnetic free energy carried by superconducting current.
London theory.
The first phenomenological theory of superconductivity was London theory. It was put forward by the brothers Fritz and Heinz London in 1935, shortly after the discovery that magnetic fields are expelled from superconductors. A major triumph of the equations of this theory is their ability to explain the Meissner effect, wherein a material exponentially expels all internal magnetic fields as it crosses the superconducting threshold. By using the London equation, one can obtain the dependence of the magnetic field inside the superconductor on the distance to the surface.
There are two London equations: 
The first equation follows from Newton's second law for superconducting electrons.
Conventional theories (1950s).
During the 1950s, theoretical condensed matter physicists arrived at a solid understanding of "conventional" superconductivity, through a pair of remarkable and important theories: the phenomenological Ginzburg-Landau theory (1950) and the microscopic BCS theory (1957).
In 1950, the phenomenological Ginzburg-Landau theory of superconductivity was devised by Landau and Ginzburg. This theory, which combined Landau's theory of second-order phase transitions with a Schrödinger-like wave equation, had great success in explaining the macroscopic properties of superconductors. In particular, Abrikosov showed that Ginzburg-Landau theory predicts the division of superconductors into the two categories now referred to as Type I and Type II. Abrikosov and Ginzburg were awarded the 2003 Nobel Prize for their work (Landau had received the 1962 Nobel Prize for other work, and died in 1968). The four-dimensional extension of the Ginzburg-Landau theory, the Coleman-Weinberg model, is important in quantum field theory and cosmology.
Also in 1950, Maxwell and Reynolds "et al." found that the critical temperature of a superconductor depends on the isotopic mass of the constituent element. This important discovery pointed to the electron-phonon interaction as the microscopic mechanism responsible for superconductivity.
The complete microscopic theory of superconductivity was finally proposed in 1957 by Bardeen, Cooper and Schrieffer. This BCS theory explained the superconducting current as a superfluid of Cooper pairs, pairs of electrons interacting through the exchange of phonons. For this work, the authors were awarded the Nobel Prize in 1972.
The BCS theory was set on a firmer footing in 1958, when N. N. Bogolyubov showed that the BCS wavefunction, which had originally been derived from a variational argument, could be obtained using a canonical transformation of the electronic Hamiltonian. In 1959, Lev Gor'kov showed that the BCS theory reduced to the Ginzburg-Landau theory close to the critical temperature.
Generalizations of BCS theory for conventional superconductors form the basis for understanding of the phenomenon of superfluidity, because they fall into the lambda transition universality class. The extent to which such generalizations can be applied to unconventional superconductors is still controversial.
Further history.
The first practical application of superconductivity was developed in 1954 with Dudley Allen Buck's invention of the cryotron. Two superconductors with greatly different values of critical magnetic field are combined to produce a fast, simple, switch for computer elements.
In 1962, the first commercial superconducting wire, a niobium-titanium alloy, was developed by researchers at Westinghouse, allowing the construction of the first practical superconducting magnets. In the same year, Josephson made the important theoretical prediction that a supercurrent can flow between two pieces of superconductor separated by a thin layer of insulator. This phenomenon, now called the Josephson effect, is exploited by superconducting devices such as SQUIDs. It is used in the most accurate available measurements of the magnetic flux quantum "Φ"0 = "h"/(2"e"), where "h" is the Planck constant. Coupled with the quantum Hall resistivity, this leads to a precise measurement of the Planck constant. Josephson was awarded the Nobel Prize for this work in 1973.
In 2008, it was proposed that the same mechanism that produces superconductivity could produce a superinsulator state in some materials, with almost infinite electrical resistance.
High-temperature superconductivity.
Until 1986, physicists had believed that BCS theory forbade superconductivity at temperatures above about 30 K. In that year, Bednorz and Müller discovered superconductivity in a lanthanum-based cuprate perovskite material, which had a transition temperature of 35 K (Nobel Prize in Physics, 1987). It was soon found that replacing the lanthanum with yttrium (i.e., making YBCO) raised the critical temperature to 92 K.
This temperature jump is particularly significant, since it allows liquid nitrogen as a refrigerant, replacing liquid helium.
This can be important commercially because liquid nitrogen can be produced relatively cheaply, even on-site, avoiding some of the problems (such as so-called "solid air" plugs) which arise when liquid helium is used in piping.
Many other cuprate superconductors have since been discovered, and the theory of superconductivity in these materials is one of the major outstanding challenges of theoretical condensed matter physics.
There are currently two main hypotheses – the resonating-valence-bond theory, and spin fluctuation which has the most support in the research community. The second hypothesis proposed that electron pairing in high-temperature superconductors is mediated by short-range spin waves known as paramagnons.
Since about 1993, the highest temperature superconductor was a ceramic material consisting of mercury, barium, calcium, copper and oxygen (HgBa2Ca2Cu3O8+δ) with "T"c = 133–138 K. The latter experiment (138 K) still awaits experimental confirmation, however.
In February 2008, an iron-based family of high-temperature superconductors was discovered. Hideo Hosono, of the Tokyo Institute of Technology, and colleagues found lanthanum oxygen fluorine iron arsenide (LaO1-xFxFeAs), an oxypnictide that superconducts below 26 K. Replacing the lanthanum in LaO1−"x"F"x"FeAs with samarium leads to superconductors that work at 55 K.
Applications.
Superconducting magnets are some of the most powerful electromagnets known. They are used in MRI/NMR machines, mass spectrometers, and the beam-steering magnets used in particle accelerators. They can also be used for magnetic separation, where weakly magnetic particles are extracted from a background of less or non-magnetic particles, as in the pigment industries.
In the 1950s and 1960s, superconductors were used to build experimental digital computers using cryotron switches. More recently, superconductors have been used to make digital circuits based on rapid single flux quantum technology and RF and microwave filters for mobile phone base stations.
Superconductors are used to build Josephson junctions which are the building blocks of SQUIDs (superconducting quantum interference devices), the most sensitive magnetometers known. SQUIDs are used in scanning SQUID microscopes and magnetoencephalography. Series of Josephson devices are used to realize the SI volt. Depending on the particular mode of operation, a superconductor-insulator-superconductor Josephson junction can be used as a photon detector or as a mixer. The large resistance change at the transition from the normal- to the superconducting state is used to build thermometers in cryogenic micro-calorimeter photon detectors. The same effect is used in ultrasensitive bolometers made from superconducting materials.
Other early markets are arising where the relative efficiency, size and weight advantages of devices based on high-temperature superconductivity outweigh the additional costs involved.
Promising future applications include high-performance smart grid, electric power transmission, transformers, power storage devices, electric motors (e.g. for vehicle propulsion, as in vactrains or maglev trains), magnetic levitation devices, fault current limiters, enhancing spintronic devices with superconducting materials, and superconducting magnetic refrigeration. However, superconductivity is sensitive to moving magnetic fields so applications that use alternating current (e.g. transformers) will be more difficult to develop than those that rely upon direct current.

</doc>
<doc id="26886" url="http://en.wikipedia.org/wiki?curid=26886" title="Siam (disambiguation)">
Siam (disambiguation)

Siam is an exonym that was formerly used as the name of Thailand, especially Central, Eastern, Western, and Southern Thailand (except the provinces Pattani, Yala, and Narathiwat).
Siam may also refer to:

</doc>
<doc id="26889" url="http://en.wikipedia.org/wiki?curid=26889" title="Geography of Sweden">
Geography of Sweden

Sweden is a country in Northern Europe on the Scandinavian Peninsula. It borders Norway to the west; Finland to the northeast; and the Baltic Sea and Gulf of Bothnia to the east and south.
Sweden has a long coastline on the eastern side and the Scandinavian mountain chain (Skanderna) on the western border, a range that separates Sweden from Norway. It has maritime borders with Denmark, Germany, Poland, Russia, Lithuania, Latvia and Estonia, and it is also linked to Denmark (southwest) by the Öresund Bridge.
At 450295 km2, Sweden is the 56th largest country in the world. It is the fifth largest in Europe and the largest in Northern Europe.
Terrain.
Much of Sweden is heavily forested, with 69% of the country being forest and woodland, while farmland constitutes only 8% of land use. Southern Sweden is predominantly agricultural, with increasing forest coverage northward. Mountains and hills are dominant in the west. About 15% of Sweden lies north of the Arctic Circle.
The lowest elevation in Sweden is in the bay of Lake Hammarsjön, near Kristianstad at -2.41 m below sea level. The highest point is Kebnekaise at 2111 m above sea level.
The highest population density is in the Öresund region in southern Sweden and in the valley of lake Mälaren near to Stockholm. Vänern and Vättern are Sweden's largest lakes. Vänern is the third largest in Europe, after Lake Ladoga and Lake Onega in Russia.
Sweden consists of 39,960 km² of water area, constituting around 95,700 lakes. The lakes are sometimes used for water power plants, especially the large northern rivers and lakes. The two largest islands are Gotland and Öland in the southeast. They each have their own culture, most notably Gotland with the old, largely intact and heritage-filled city Visby.
Political divisions.
Provinces.
Sweden has 25 provinces or "landskap" (landscapes), based on culture, geography and history: Bohuslän, Blekinge, Dalarna, Dalsland, Gotland, Gästrikland, Halland, Hälsingland, Härjedalen, Jämtland, Lapland, Medelpad, Norrbotten, Närke, Skåne, Småland, Södermanland, Uppland, Värmland, Västmanland, Västerbotten, Västergötland, Ångermanland, Öland and Östergötland.
While these provinces serve no political or administrative purpose, they play an important role for people's self-identification. The provinces are usually grouped together in three large lands ("landsdelar"): the northern Norrland, the central Svealand and southern Götaland. The sparsely populated Norrland encompasses almost 60% of the country.
Counties.
Administratively, Sweden is divided into 21 counties, or "län". In each county there is a County Administrative Board, or "länsstyrelse", which is appointed by the national government.
In each county there is also a separate County Council, or "landsting", which is the municipal representation appointed by the county electorate.
The letters shown were on the vehicle registration plates until 1973.
Municipalities.
Each county is further divided into municipalities or "kommuner", ranging from only one (in Gotland County) to forty-nine (in Västra Götaland County). The total number of municipalities is 290.
The northern municipalities are often large in size, but have small populations – the largest municipality is Kiruna with an area as large as the three southern provinces in Sweden (Scania, Blekinge and Halland) combined, but it only has a population of 25,000, and its density is about 1 / km².
Population.
Sweden has a population of about 9.6 million. The north is less populated than the southern and central parts, mostly because of its colder climate.
Cities.
Cities and towns in Sweden are not political or administrative entities but localities or urban areas, independent of the municipal subdivision.
The largest city, in terms of population, is the capital Stockholm, in the east, the dominant city for culture and media, with a population of 1,250,000. The second largest city is Gothenburg, with 510,500, in the west. The third largest is Malmö in the south, with 258,000. The largest city in the north is Umeå with 76,000 inhabitants.
Natural resources.
Sweden's natural resources include copper, gold, hydropower, iron ore, lead, silver, timber, uranium, and zinc.
Environment.
Acid rain has become an issue because it is damaging soils and lakes and polluting the North Sea and the Baltic Sea. The HBV hydrology transport model has been used to analyze nutrient discharge to the Baltic from tributary watersheds.
Extreme points.
The extreme points of Sweden include the coordinates that are farthest north, south, east and west in Sweden, and the ones that are at the highest and the lowest elevations in the country. In opposite to Norway and Denmark, Sweden has no external territories that can be considered either inside or outside the country depending on definition, meaning that the extreme points of Sweden are unambiguous.
The latitude and longitude are expressed in , in which a positive latitude value refers to the northern hemisphere, and a negative value refers to the southern hemisphere. Additionally, a negative elevation value refers to land below sea level. The coordinates used in this article are sourced from Google Earth, which makes use of the World Geodetic System (WGS) 84, a geodetic reference system.
Latitude and longitude.
Sweden's northernmost point is Treriksröset, in the Lapland province, where the borders of Sweden, Norway, and Finland meet. The closest Swedish city to the area is Kiruna, which is Sweden's northern-most city. Sweden's southernmost point is in the harbour of the fishing village Smygehuk, near the city of Trelleborg, which borders the Baltic Sea. At the pier of the harbour, a signpost displays the exact position of the point, as well as the distance to Treriksröset, Stockholm, Berlin, Paris, and Moscow.
Sweden's westernmost point is on Stora Drammen, an islet in Skagerrak outside the coast of Bohuslän. Seabirds and harbor seals have colonies on the islet, but it is uninhabited by humans. Sweden's easternmost point is on Kataja, an islet south of Haparanda in the Bothnian Bay. The islet is divided between Sweden and Finland. The border was established in 1809, after the Finnish War, between what was previously two islets, a Swedish one called Kataja and a smaller Finnish one called Inakari. Since 1809, post-glacial rebound has caused the sea level in the region to drop relative to land level, joining the two islets. If counting the mainland only, Stensvik in Strömstad is Sweden's westernmost point, and Sundholmen in Haparanda is the easternmost point.
Elevation.
The highest point in Sweden is Kebnekaise, which stands at 2098 m (August 2014). It is in the Scandinavian Mountains chain, in the province of Lapland. The mountain has two peaks, of which the glaciated southern one is the highest at 2104 m. The northern peak, which stands at 2096 m, is free of ice. Although the south top is traditionally said to be 2111 m high, new measurements have shown that the glacier has shrunk fairly fast; therefore the summit is not as high as earlier. It was 2104 m in 2008. Other points of comparable height in the vicinity of Kebnekaise include Sarektjåkka at 2089 m, and Kaskasatjåkka at 2076 m. If the summers of 2016 and 2017 get as warm as the previous years, the northern peak will become the highest.
Sweden's lowest point, which is 2.41 m below sea level, is in the Kristianstads Vattenrike Biosphere Reserve in the city of Kristianstad. The point is at the bottom of what was once Nosabyviken, a bay on the lake of Hammarsjön. The bay was drained in the 1860s by John Nun Milner, an engineer, to get more arable land for Kristianstad.

</doc>
<doc id="26890" url="http://en.wikipedia.org/wiki?curid=26890" title="Demographics of Sweden">
Demographics of Sweden

The demography of Sweden is monitored by Statistics Sweden (SCB). As of 31 December 2013, Sweden's population was estimated to be 9.64 million people, making it the 90th most populous country in the world. The three biggest cities are Stockholm, Gothenburg and Malmö. Approximately 85% of the country's population resides in its urban areas.
Population statistics.
At the housing and population census 1990 the Swedish population stood at 8 587 353 out of which 4 242 351 male and 4 345 002 female.
According to a 2012 survey there were 1 473 256 foreign born within the country making up 15% of the population.
Sweden census 2005.
The 2005 Swedish census showed an increase of 475,322 compared to the 1990 census, an average increase of 31,680 annually. During the 1990s, birth rate increased by more than 100,000 children per year while death rates fell and immigration surged. In the early 2000s, birth rate declined as immigration increased further, with the context of unrest in the Middle East, upholding steady population growth.
Ethnicity.
The majority of the population are Swedes. The Sweden Finns are a large ethnic minority comprising approximately 50,000 along the Swedish-Finnish border, and 450,000 first and second generation immigrated ethnic Finns, mainly living in the Mälaren Valley region. In addition, Sweden's indigenous population groups includes the Sami people, historically a nomadic reindeer herding group that has been native to Fenno-Scandinavia for at least 5000 years. Today, the Sami language holds the status of official minority language in four municipalities in the Norrbotten county.
Immigrants from the Middle East have been a rapidly growing share of Sweden’s population. According to the government agency Statistics Sweden, the number of Swedes born in all of Asia (including the Middle East) rose from just 1,000 in 1950 to 295,000 in 2003. Most of those immigrants came from Iraq, Iran, Lebanon and Syria, according to Statistics Sweden.
Additionally, the birth rate among immigrants is higher than among ethnic Swedes.
Vital statistics since 1900.
Data according to Statistics Sweden, which collects the official statistics for Sweden.
Current vital statistics.
Number of births :
Number of deaths :
Natural increase :
Population projections.
Statistics Sweden projects the following population development in Sweden: 
Eurostat projects a population in Sweden reaching 10,382,000 people in 2035 and 10,875,000 in 2060.
Migration.
Immigration.
As of 2011, Statistics Sweden reported that around 19.6% or 1.858.000 inhabitants of Sweden had foreign background, defined as born abroad or born in Sweden by two parents born abroad.
Demographics.
According to Eurostat, in 2010, there were 1.33 million foreign-born residents in Sweden, corresponding to 14.3% of the total population. Of these, 859,000 (9.2%) were born outside the EU and 477,000 (5.1%) were born in another EU Member State.
The ten largest groups of foreign-born persons in the Swedish civil registry in 2014 were:
The seven successor states of Yugoslavia (Slovenia, Croatia, Bosnia, Serbia, Kosovo, Macedonia and Montenegro) have a combined population of 162,136 persons residing in Sweden which would make them the largest foreign-born group.
The number of Assyrians in Sweden is about 100,000-120,000.
The ten fastest growing groups of foreign-born residents in Sweden between 2013 and 2014 were the following nationalities:
History.
Immigration increased markedly with World War II. Historically, the most numerous of foreign born nationalities are ethnic Germans from Germany and other Scandinavians from Denmark and Norway. In short order, 70,000 war children were evacuated from Finland, of which 15,000 remained in Sweden. Also, many of Denmark's nearly 7,000 Jews who were evacuated to Sweden decided to remain there.
A sizable community from the Baltic States (Estonia, Latvia and Lithuania) arrived during the Second World War.
During the 1950s and 1960s, the recruitment of immigrant labor was an important factor of immigration. The Nordic countries signed a trade agreement in 1952, establishing a common labour market and free movement across borders. This migration within the Nordic countries, especially from Finland to Scandinavia, was essential to create the tax-base required for the expansion of the strong public sector now charactreristic of Scandinavia. 
This continued until 1967, when the labour market became saturated, and Sweden introduced new immigration controls.
On a smaller scale, Sweden took in political refugees from Hungary and the former Czechoslovakia after their countries were invaded by the Soviet Union in 1956 and 1968 respectively.
Contemporary immigration.
Since the early 1970s, immigration to Sweden has been mostly due to refugee migration and family reunification from countries in the Middle East and Latin America.
The first group of Assyrians/Syriacs moved to Sweden from Lebanon in 1967. Many of them live in Södertälje (Stockholm). 
There are also around 40,000 Roma in Sweden.
Immigration of Iraqis increased dramatically during the Iraq War, during 2003 to 2007. A total of 8,951 Iraqis came to Sweden in 2006, accounting for 45% of the entire Iraqi migration to Europe. By 2007, the community of Iraqis in Sweden numbered above 70,000. In 2008, Sweden introduced tighter rules on asylum seekers.
Emigration.
In the 19th century, Sweden's yearly population growth rate peaked at 1.2% (i.e. it doubled in less than 60 years), compared to 1% today (migration excluded). This considerable population growth rate led, before the Industrial Revolution, to a pauperization of the rural population, for each generation inherited smaller and smaller shares. Due to years of crop failure in the 1840s and 1860s, the U.S. Homestead Act of 1862, and to a lesser extent religious persecution, emigration started and grew. Between 1850 and 1930 1,050,000 Swedes emigrated (re-migration excluded), chiefly to Canada, U.S. and to Denmark. If they had not left, Sweden's population would have been about 2,000,000 higher today, assuming famine and civil war would not have resulted from their staying. (After 1929 the net-migration has been directed towards Sweden.)
The re-migration of Swedish nationals from the U.S. was culturally more important than the absolute figures reveal. The re-migrants often re-settled in their native parish, where their relative wealth and foreign experience ensured a prestigious position in the community. U.S. views, values and not the least world-view followed the re-migrants, ensuring a popular perception of closeness to U.S., contrary to the situation in for instance neighbouring Denmark or Finland (and contrary to the Swedish elite's closeness to Germany and Continental Europe).
Language.
The Swedish language is by far the dominating language in Sweden, and is used by the government administration.
Since 1999, Sweden has five officially recognized minority languages: Sami, Meänkieli, Standard Finnish, Romani chib and Yiddish.
The Sami language, spoken by about 7,000 people in Sweden, may be used in government agencies, courts, preschools and nursing homes in the municipalities of Arjeplog, Gällivare, Jokkmokk and Kiruna and its immediate neighbourhood.
Similarly, Finnish and Meänkieli can be used in the municipalities of Gällivare, Haparanda, Kiruna, Pajala and Övertorneå and its immediate neighbourhood. 
Finnish is also official language, along with Swedish, in the city of Eskilstuna.
During the mid to late 20th century, immigrant communities brought other languages, among others being Turkish, Serbo-Croatian, Arabic, Neo-Aramaic.
Religion.
The majority (66%) of the population belongs to the Church of Sweden, the Lutheran church that was disestablished in 2000. This is because until 1996, those who had family members in the church automatically became members at birth. Other Christian denominations in Sweden include the Roman Catholic Church (see Catholic Church of Sweden), several Orthodox churches in diaspora, Baptist, Pentecostal, Neo-pietistic ("nyevangeliska") and other evangelical Christian churches ("frikyrkor" = "free churches"). Shamanism persisted among the Sami people up until the 18th century, but no longer exists in its traditional form as most Sami today belong to the Lutheran church.
Jews were permitted to practice their religion in five Swedish cities in 1782, and have enjoyed full rights as citizens since 1870. The new Freedom of Religion Bill was passed in 1951, and former obstacles against Non-Lutherans working in schools and hospitals were removed. Further, that bill made it legal to leave any religious denomination, without entering another. There are also a number of Muslims, Buddhists, and Bahá'í in Sweden, mainly from immigration.

</doc>
<doc id="26893" url="http://en.wikipedia.org/wiki?curid=26893" title="Telecommunications in Sweden">
Telecommunications in Sweden

This article covers telecommunications in Sweden.
Telecommunications.
Sweden liberalized its telecommunications industry starting in 1980s and being formally liberalized in 1993. This was three years ahead of USA and five years before the European common policy introduced in January 1998 allowed for an open and competitive telecommunication market. The Swedes, most of who are computer literate, enjoy a continuous growth in the Internet market and the availability of technologies such as Metro Ethernet, fiber, satellite, WAN access technologies and even the availability of 3G services. Statistically, 6.447 (2004) million telephone main lines are in use, 8.0436 (2005) million mobile cellular telephones are in use and 6.7 million Swedes are regular internet users.
This abundance of telecommunication technology is a result of promoting a competitive industry that was made possible by deregulation. Since Sweden was the first to take on this arduous task the government had to come up with “a regulatory framework of its own”. The processes that went about resulting in the liberalization of the telecommunications’ industry can be structured into three phases: “Phase 1 of monopoly to Phase 2 with a mix of monopoly and competition to a “mature” Phase 3 with extensive competition”.
During the period of 1993-2000 there is rise in competition with legislation of the regulatory body being changed several times. In the case of the POTS, Telia in 2000 still held monopoly in the fixed-line access market. Whereas, mobile phone and Internet penetration in the household market ended up being one of the highest in the world with more than 50 percent of the revenue coming from these two industries. There were three major organizations providing GSM services and 120 internet service providers. One of the major causes that lead competitions thrive in areas that did not have a history of monopoly was the light handed approach taken towards the interconnection issue by the regulatory body initially. Telia held very high interconnection charges, making it very difficult for new entrants to enter. But what it did do was push the new entrants to enter other markets. Tele2 did just that by taking out a massive marketing campaign to attract a huge number of customers to its internet access service. This campaign was successful enough to bring back Telia to the negotiation table over the interconnection issue . This process eventually lead to the abolition of the light handed regulatory approach towards interconnection and put more power in the hands of the regulatory body. The intensity of regulation kept increasing around 1999 in areas other than POTS, especially the mobile market.
Signals intelligence.
In 2009, the Riksdag passed new legislation regulating the National Defence Radio Establishment (FRA), enabling them to collect information from both wireless and cable bound signals passing the Swedish border. Since most communications in Sweden pass through its borders at one point or another, this monitoring in practice affects most traffic within Sweden as well.

</doc>
<doc id="26894" url="http://en.wikipedia.org/wiki?curid=26894" title="Transport in Sweden">
Transport in Sweden

Transportation in Sweden.
Railways.
Rail transport is operated by SJ, DSBFirst, Green Cargo, Tågkompaniet and more. Most counties have companies that do ticketing, marketing and financing of local passenger rail, but the actual operation are done by the above-mentioned companies.
Light rail and metros.
Stockholm Metro (Stockholms Tunnelbana) is the only metro system in Sweden.
Cities with light rail (trams);
Stockholm previously had a large tram network, but this was discontinued in favour of bus and metro; a revival of the tram network was seen in the construction of Tvärbanan in the late 1990s and early 2000s. 
Road traffic.
Sweden has right-hand traffic today like all its neighbours.
Sweden had left-hand traffic ("Vänstertrafik" in Swedish) from approximately 1736 and continued to do so until 1967. Despite this virtually all cars in Sweden were actually left-hand drive and the neighbouring Nordic countries already drove on the right, leading to mistakes by visitors. The Swedish voters rejected a change to driving on the right in a referendum held in 1955.
Nevertheless, in 1963 the Riksdag passed legislation ordering the switch to right-hand traffic. The changeover took place on a Sunday morning at 5am on September 3, 1967, which was known in Swedish as "Dagen H" (H-Day), the 'H' standing for "Högertrafik" or right-hand traffic.
Since Swedish cars were left-hand drive, experts had suggested that changing to driving on the right would reduce accidents, because drivers would have a better view of the road ahead. Indeed, fatal car-to-car and car-to-pedestrian accidents did drop sharply as a result. This was likely due to drivers initially being more careful and because of the initially very low speed limits, since accident rates soon returned to nearly the same as earlier.
Total roadways: 572,900 km, as of 2009.
Motorways.
Motorways run through Sweden, Denmark and over the Öresund Bridge to Stockholm, Gothenburg, Uppsala and Uddevalla. The system of motorways is still being extended. The longest continuous motorways are Värnamo-Gävle (E4; 585 km) and Rabbalshede-Vellinge (E6; 412 km; will by 2013 be extended so the motorway between Trelleborg and Oslo in Norway will be completed).
Airports.
"See also: Swedish Civil Aviation Administration and List of airports in Sweden"

</doc>
<doc id="26895" url="http://en.wikipedia.org/wiki?curid=26895" title="Swedish Armed Forces">
Swedish Armed Forces

The Swedish Armed Forces (Swedish: "Försvarsmakten") form the military forces of Sweden, tasked with defence of the country, as well as promoting Sweden's wider interests, supporting international peacekeeping efforts, and providing humanitarian aid.
It consists of: the Swedish Army, the Swedish Air Force and the Swedish Navy, with addition of a military reserve force, the Home Guard (Swedish: "Hemvärnet"). Since 1994, the first three service branches are organised within a unified government agency, headed by the Supreme Commander, while the Home Guard reports directly to the Supreme Commander. King Carl XVI Gustaf of Sweden is traditionally attributed as Honorary Commander-in-Chief "à la suite".
The military history of Sweden includes several unions and wars with all of its neighbour states, including extended Swedish intervention in the Thirty Years' War at the times of the Swedish Empire during the 17th and early 18th centuries. Wars with Russia culminated in the Finnish War (1808-1809), with Sweden permanently losing Finland. During the World Wars, the Cold War and throughout the 20th century, Sweden maintained a national policy of non-alignment, while the Swedish Armed Forces strength was based upon the concepts of conscription. In 2010, peacetime conscription was abolished, replacing it with volunteer armed forces including the Home Guard – National Security Force until 2018.
Units from the Swedish Armed Forces are currently on deployment in several international operations either actively or as military observers, including Afghanistan as part of ISAF and in Kosovo. Moreover, Swedish Armed Forces contribute as the lead nation for an EU Battle Group approximately once every three years.
History.
The military history of Sweden includes several unions and wars with all of its neighbour states, including extended Swedish intervention in the Thirty Years' War at the times of the Swedish Empire during the 17th and early 18th centuries. Wars with Russia culminated in the Finnish War (1808-1809), with Sweden permanently losing Finland. During the World Wars, the Cold War and throughout the 20th century, Sweden maintained a national policy of non-alignment, while the Swedish Armed Forces strength was based upon the concepts of conscription. In 2010, peacetime conscription was abolished, replacing it with volunteer armed forces including the Home Guard – National Security Force until 2018.
Doctrine.
The Swedish Armed Forces have four main tasks:
Sweden aims to have the option of remaining neutral in case of proximate war. However, Sweden cooperates militarily with a number of foreign countries. As a member of the European Union, Sweden is acting as the lead nation for EU Battlegroups and also has a close cooperation, including joint exercises, with NATO through its membership in Partnership for Peace and Euro-Atlantic Partnership Council. In 2008 a partnership was initiated between the Nordic countries to, among other things, increase the capability of joint action, and this led to the creation of NORDEFCO. As a response to the expanded military cooperation the defence proposition of 2009 stated that Sweden will not remain passive if a Nordic country or a member of the European Union were attacked.
Recent political decisions have strongly emphasized the capability to participate in international operations, to the point where this has become the main short-term goal of training and equipment acquisition. However, after the 2008 South Ossetia war territorial defense was once again emphasized. Until then most units could not be mobilized within one year. In 2009 the Minister for Defence stated that in the future all of the armed forces must capable of fully mobilizing within one week.
In 2013, after Russian air exercises in close proximity to the Swedish border were widely reported, only six percent of Swedes expressed confidence in the ability of the nation to defend itself.
Organisation.
The Supreme Commander (Swedish: "Överbefälhavaren") is a four-star general or flag officer that is the agency head of the Swedish Armed Forces, and is the highest ranking professional officer on active duty. The Supreme Commander in turn reports, normally through the Minister for Defence, directly to the Government of Sweden, which in turn answers to the Riksdag.
The King of Sweden was, before the enactment of the 1974 Instrument of Government, the de jure commander in chief (Swedish: "högste befälhavare"), but currently only has a stricly ceremonial and representative role with respect to the Armed Forces.
The Swedish Armed Forces consists of three service branches; the Army, the Air Force and the Navy, with addition of the Home Guard (Swedish: "Hemvärnet"), a military reserve force. Since 1994, the first three service branches are organized within a single unified government agency, headed by the Supreme Commander, while the Home Guard reports directly to the Supreme Commander. However, the services maintain their separate identities through the use of different uniforms, ranks, and other service specific traditions.
Armed Forces Headquarters.
The Armed Forces Headquarters is the highest level of command in the Swedish Armed Forces. It is led by the Supreme Commander with a civilian Director General as his deputy, with functional directorates having different responsibilities (e.g. the Military Intelligence and Security Service). Overall, the Armed Forces Headquarters have about 1000 employees, including civilian personnel.
Schools.
Some of the schools listed below answer to other units, listed under the various branches of the Armed Forces.
Military units.
Deployed units and units ready for or mobilization.
The table describes what units Sweden currently has deployed abroad and what units may be mobilized within one year. Ready-within-one-year means that there is equipment but no currently contracted personnel. Mobilizing units outside of the R10-R90 readiness range will entail placing units on a wartime footing, wherein officers would have to leave their current assignments in order to command their units.
aSwedish aviation squadrons consist of 8 combat aircraft.
bSwedish naval squadrons consist of 6 ships.
References: 
Nordic Battle Group.
The Nordic Battle Group is a temporary formation of the Swedish Armed Forces, tasked as one of the EU Battle Groups. Sweden was lead nation for a Battle Group during the first half of 2011.
International deployments.
Currently, Sweden has military forces deployed in Afghanistan with the NATO-led Resolute Support Mission. Swedish forces were part of the previous International Security Assistance Force (2002-2014) in Afghanistan. Sweden is also part of the multinational Kosovo Force and has a naval force deployed to the gulf of Aden as a part of Operation Atalanta. Military observers from Sweden have been sent to a large number of countries, including Georgia, Lebanon, Israel and Sri Lanka and Sweden also participates with staff officers to missions in Sudan and Chad. Sweden has been one of the Peacekeeping nations of the Neutral Nations Supervisory Commission that is tasked with overseeing the truce in the Korean Demilitarized Zone since the Korean war ended in 1953.
Past deployments.
A battalion and other units were deployed with the NATO-led peacekeeping SFOR in Bosnia and Herzegovina (1996-2000), following the Bosnian War.
Swedish air and ground forces saw combat during the Congo Crisis, as part of the United Nations Operation in the Congo force. 9 army battalions were sent in all, and their mission lasted 1960-1964.
Personnel.
From national service to an all-volunteer force.
In mid-1995, with the national service system based on universal military training, the Swedish Army consisted of 15 maneuver brigades and, in addition, 100 battalions of various sorts (artillery, engineers, rangers, air defense, amphibious, security, surveillance etc.) with a mobilization-time of between one and two days. When national service was replaced by a selective service system, fewer and fewer young men were drafted due to the reduction in size of the armed forces. By 2010 the Swedish Army had two battalions that could be mobilized within 90 days. When the volunteer system has been fully implemented by 2019, the army will consist of 7 maneuver battalions and 14 battalions of various sorts with a readiness of one week. The Home Guard will be reduced in size to 22 000 soldiers.
Personnel structure.
Military personnel of the Swedish Armed Forces consists of:
K = Continuously
T = Part-time
P = Conscript, for personnel drafted under the Swedish law of comprehensive defense duty
Planned size of the Swedish Armed Forces 2011–2020.
Annual recruitment of GSS is assumed to be about 4,000 persons.
Source:
Criticism and research.
In 2008, professor Mats Alvesson of the University of Lund and Karl Ydén of the University of Göteborg claimed in an op-ed, based on Ydén's doctoral dissertation, that a large part of the officer corps of the Swedish Armed Forces was preoccupied with administrative tasks instead of training soldiers or partaking in international operations. They claimed that Swedish officers were mainly focused on climbing the ranks and thereby increasing their wages and that the main way of doing this is to take more training courses, which decreases the number of officer that are specialized in their field. Therefore, the authors claimed, the Swedish Armed Forces were poorly prepared for its mission.
Major changes have been made to the officer system since then.
The transformation of the old invasion armed forces to the new smaller and more mobile force has also been criticized. According to the Supreme Commander of the Swedish Armed Forces the present defence budget will not be enough to implement the new defence structure by 2019. And that even when finished the armed forces will only be able to fight for a week at most.
During 2013 several Russian Air Force exercises over the Baltic Sea aimed at Swedish Military targets have made 
the future of the Swedish Armed Forces a hot topic and several political parties now want to increase defence funding.
Ranks.
See: Military ranks of the Swedish armed forces
When an army based on national service (conscription) was introduced in 1901 all commissioned officers had ranks that were senior of the warrant officers (underofficerare) and non-commissioned officers (underbefäl). In a reform 1926 the relative rank of the then senior warrant officer, fanjunkare, was increased to be equal with the junior officer rank underlöjtnant and above the most junior officer rank fänrik. In 1960 the relative rank of the warrant officers were elevated further so that
i. The lowest warrant officer, sergeant, had relative rank just below the lowest officer rank, fänrik.
ii. The second warrant officer rank, fanjunkare, had relative rank between fänrik and löjtnant
iii. The highest warrant officer rank, förvaltare, had relative rank between first lieutenant and captain.
In 1972 the personnel structure changed, reflecting increased responsibilities of warrant and non-commissioned officers, renaming the "underofficerare" as "kompaniofficerare", giving them the same ranks as company grade officers ("fänrik", "löjtnant", "kapten"). "Underbefäl" was renamed "plutonsofficerare" and given the rank titles of sergeant and "fanjunkare", although their relative rank were now placed below "fänrik". The commissioned officers were renamed "regementsofficerare", beginning with "löjtnant". The three-track career system was maintained, as well as three separate messes.
A major change in the personnel structure in 1983 (NBO 1983), merged the three professional corps of platoon officers, company officers, and regimental officers into a one-track career system within a single corps called professional officers (yrkesofficerare). The three messes were also merged to one.
In 2008 the Riksdag decided to create a two-track career system with a category called "specialistofficerare". When implementing the parliamentary resolution the Supreme Commander decided that some ranks in this category should, like the old "underofficerare" ranks in 1960-1972, have a relative rank higher than the most junior officers.
References.
Manpower-numbers are taken from 

</doc>
<doc id="26896" url="http://en.wikipedia.org/wiki?curid=26896" title="Foreign relations of Sweden">
Foreign relations of Sweden

The foreign policy of Sweden is based on the premise that national security is best served by staying free of alliances in peacetime in order to remain a neutral country in the event of war. In 2002, Sweden revised its security doctrine. The security doctrine still states that "Sweden pursues a policy of non-participation in military alliances," but permits cooperation in response to threats against peace and security. The government also seeks to maintain Sweden's high standard of living. These two objectives require heavy expenditures for social welfare, defense spending at rates considered high by Western European standards (currently around 2.2% of GNP), and close attention to foreign trade opportunities and world economic cooperation.
United Nations.
Sweden has been a member of the United Nations since 19 November 1946, and participates actively in the activities of the organisation, including as an elected member of the Security Council (1957–1958, 1975–1976 and 1997–1998), providing Dag Hammarskjöld as the second elected Secretary-General of the UN, etc. The strong interest of the Swedish Government and people in international cooperation and peacemaking has been supplemented in the early 1980s by renewed attention to Nordic and European security questions.
European Union.
After the then Prime Minister Ingvar Carlsson had submitted Sweden's application in July 1991 the negotiations began in February 1993. Finally, on 1 January 1995, Sweden became a member of the European Union. While some argued that it went against Sweden's historic policy of neutrality, where Sweden had not joined during the Cold War because it was seen as incompatible with neutrality, others viewed the move as a natural extension of the economic cooperation that had been going on since 1972 with the EU. Sweden addressed this controversy by reserving the right not to participate in any future EU defense alliance. In membership negotiations in 1993–1994, Sweden also had reserved the right to make the final decision on whether to join the third stage of the EMU "in light of continued developments." In a nationwide referendum in November 1994, 52.3 percent of participants voted in favour of EU membership. Voter turnout was high, 83.3 percent of the eligible voters voted. The main Swedish concerns included winning popular support for EU cooperation, EU enlargement, and strengthening the EU in areas such as economic growth, job promotion, and environmental issues.
In polls taken a few years after the referendum, many Swedes indicated that they were unhappy with Sweden's membership in the EU. However, after Sweden successfully hosted its first presidency of the EU in the first half of 2001, most Swedes today have a more positive attitude towards the EU. The government, with the support of the Center Party, decided in spring 1997 to remain outside of the EMU, at least until 2002. A referendum was held on 14 September 2003. The results were 55.9% for "no", 42.0% "yes" and 2.1% giving no answer ("blank vote").
Nordic Council.
Swedish foreign policy has been the result of a wide consensus. Sweden cooperates closely with its Nordic neighbors, formally in economic and social matters through the Nordic Council of Ministers and informally in political matters through direct consultation.
Nonalignment.
Swedish neutrality and nonalignment policy in peacetime may partly explain how the country could stay out of wars since 1810. Swedish governments have not defined nonalignment as precluding outspoken positions in international affairs. Government leaders have favored national liberation movements that enjoy broad support among developing world countries, with notable attention to Africa. During the Cold War, Sweden was suspicious of the superpowers, which it saw as making decisions affecting small countries without always consulting those countries. With the end of the Cold War, that suspicion has lessened somewhat, although Sweden still chooses to remain nonaligned. Sweden has devoted particular attention to issues of disarmament, arms control, and nuclear nonproliferation and has contributed importantly to UN and other international peacekeeping efforts, including the NATO-led peacekeeping forces in the Balkans. It sat as an observer in the Western European Union from 1995 to 2011, but it is not an active member of NATO's Partnership for Peace and the Euro-Atlantic Partnership Council.
Sweden's engagement with NATO was especially strengthened during the term of Anders Fogh Rasmussen.
Sweden's nonalignment policy has led it to serve as the protecting power for a number of nations who don't have formal diplomatic relations with each other for various reasons. It currently represents the United States, Canada, and several Western European nations in North Korea for consular matters. On several occasions when the United Kingdom broke off relations with Iran (including the 1979 Iranian Revolution, the Salman Rushdie affair, and the 2012 storming of the British embassy in Tehran), Sweden has served as the protecting power for the UK.

</doc>
<doc id="26897" url="http://en.wikipedia.org/wiki?curid=26897" title="Spice">
Spice

A spice is a dried seed, fruit, root, bark, or vegetable substance primarily used for flavoring, coloring or preserving food. 
Spices are distinguished from herbs, which are parts of leafy green plants used for flavoring or as a garnish.
Many spices have antimicrobial properties. This may explain why spices are more commonly used in warmer climates, which have more infectious disease, and why the use of spices is prominent in meat, which is particularly susceptible to spoiling.
A spice may have other uses, including medicinal, religious ritual, cosmetics or perfume production, or as a vegetable. For example, turmeric roots are consumed as a vegetable and garlic as an antibiotic.
History.
Early history.
The spice trade developed throughout South Asia and Middle East in around 2000 BCE with cinnamon and pepper, and in East Asia with herbs and pepper. The Egyptians used herbs for embalming and their demand for exotic herbs helped stimulate world trade. The word "spice" comes from the Old French word "espice", which became "epice", and which came from the Latin root "spec", the noun referring to "appearance, sort, kind": "species" has the same root. By 1000 BCE, medical systems based upon herbs could be found in China, Korea, and India. Early uses were connected with magic, medicine, religion, tradition, and preservation.
Archaeological excavations have uncovered clove burnt onto the floor of a kitchen, dated to 1700 BCE, at the Mesopotamian site of Terqa, in modern-day Syria. The ancient Indian epic Ramayana mentions cloves. The Romans had cloves in the 1st century CE, as Pliny the Elder wrote about them.
In the story of Genesis, Joseph was sold into slavery by his brothers to spice merchants. In the biblical poem Song of Solomon, the male speaker compares his beloved to many forms of spices. Generally, early Egyptian, Chinese, Indian, and Mesopotamian sources do not refer to known spices.
Historians believe that nutmeg, which originates from the Banda Islands in South Asia, was introduced to Europe in the 6th century BCE.
Indonesian merchants traveled around China, India, the Middle East, and the east coast of Africa. Arab merchants facilitated the routes through the Middle East and India. This resulted in the Egyptian port city of Alexandria being the main trading center for spices. The most important discovery prior to the European spice trade were the monsoon winds (40 CE). Sailing from Eastern spice growers to Western European consumers gradually replaced the land-locked spice routes once facilitated by the Middle East Arab caravans.
Middle Ages.
Spices were among the most demanded and expensive products available in Europe in the Middle Ages, the most common being black pepper, cinnamon (and the cheaper alternative cassia), cumin, nutmeg, ginger and cloves. Given medieval medicine's main theory of humorism, spices and herbs were indispensable to balance "humors" in food, a daily basis for good health at a time of recurrent pandemics.
Spices were all imported from plantations in Asia and Africa, which made them expensive. From the 8th until the 15th century, the Republic of Venice had the monopoly on spice trade with the Middle East, and along with it the neighboring Italian city-states. The trade made the region rich. It has been estimated that around 1,000 tons of pepper and 1,000 tons of the other common spices were imported into Western Europe each year during the Late Middle Ages. The value of these goods was the equivalent of a yearly supply of grain for 1.5 million people. The most exclusive was saffron, used as much for its vivid yellow-red color as for its flavor. Spices that have now fallen into obscurity in European cuisine include grains of paradise, a relative of cardamom which mostly replaced pepper in late medieval north French cooking, long pepper, mace, spikenard, galangal and cubeb.
Early modern period.
The control of trade routes and the spice-producing regions were the main reasons that Portuguese navigator Vasco da Gama sailed to India in 1499. Spain and Portugal were not happy to pay the high price that Venice demanded for spices. At around the same time, Christopher Columbus returned from the New World, he described to investors new spices available there.
Another source of competition in the spice trade during the 15th and 16th century was the Ragusans from the maritime republic of Dubrovnik in southern Croatia.
The military prowess of Afonso de Albuquerque (1453–1515) allowed the Portuguese to take control of the sea routes to India. In 1506, he took the island of Socotra in the mouth of the Red Sea and, in 1507, Ormuz in the Persian Gulf. Since becoming the viceroy of the Indies, he took Goa in India in 1510, and Malacca on the Malay peninsula in 1511. The Portuguese could now trade directly with Siam, China, and the Maluku Islands. The Silk Road complemented the Portuguese sea routes, and brought the treasures of the Orient to Europe via Lisbon, including many spices.
With the discovery of the New World came new spices, including allspice, chili peppers, vanilla, and chocolate. This development kept the spice trade, with America as a late comer with its new seasonings, profitable well into the 19th century.
As times have changed and convenience has become a major factor for consumers, the spice trade has shifted into finding cheaper alternatives to satisfy demand. One of these ways is diluting spices to make inferior quality powdered spices, by including roots, skins and other admixture in production of spice powder.
Handling spices.
A spice may be available in several forms: fresh, whole dried, or pre-ground dried. Generally, spices are dried. A whole dried spice has the longest shelf life, so it can be purchased and stored in larger amounts, making it cheaper on a per-serving basis. Some spices are not always available either fresh or whole, for example turmeric, and often must be purchased in ground form. Small seeds, such as fennel and mustard seeds, are often used both whole and in powder form.
The flavor of a spice is derived in part from compounds (volatile oils) that oxidize or evaporate when exposed to air. Grinding a spice greatly increases its surface area and so increases the rates of oxidation and evaporation. Thus, flavor is maximized by storing a spice whole and grinding when needed. The shelf life of a whole dry spice is roughly two years; of a ground spice roughly six months. The "flavor life" of a ground spice can be much shorter. Ground spices are better stored away from light.
To grind a whole spice, the classic tool is mortar and pestle. Less labor-intensive tools are more common now: a microplane or fine grater can be used to grind small amounts; a coffee grinder is useful for larger amounts. A frequently used spice such as black pepper may merit storage in its own hand grinder or mill.
Some flavor elements in spices are soluble in water; many are soluble in oil or fat. As a general rule, the flavors from a spice take time to infuse into the food so spices are added early in preparation.
Salmonella contamination.
A study by the Food and Drug Administration of shipments of spices to the United States during fiscal years 2007-2009 showed about 7% of the shipments were contaminated by Salmonella bacteria, some of it antibiotic-resistant. As most spices are cooked before being served salmonella contamination often has no effect, but some spices, particularly pepper, are often eaten raw and present at table for convenient use. Shipments from Mexico and India, a major producer, were the most frequently contaminated.
Nutrition.
Because they tend to have strong flavors and are used in small quantities, spices tend to add few calories to food, even though many spices, especially those made from seeds, contain high portions of fat, protein, and carbohydrate by weight. Many spices, however, can contribute significant portions of micronutrients to the diet. For example, a teaspoon of paprika contains about 1133 IU of Vitamin A, which is over 20% of the recommended daily allowance specified by the US FDA. When used in larger quantity, spices can also contribute a substantial amount of minerals, including iron, magnesium, calcium, and many others, to the diet.
Most herbs and spices have substantial antioxidant activity, owing primarily to phenolic compounds, especially flavonoids, which influence nutrition through many pathways, including affecting the absorption of other nutrients. One study found cumin and fresh ginger to be highest in antioxidant activity. These antioxidants can also act as natural preservatives, preventing or slowing the spoilage of food, leading to a higher nutritional content in stored food.
Production.
India contributes 70% of global spice production.
Standardization.
The International Organization for Standardization addresses spices and condiments, along with related food additives, as part of the International Classification for Standards 67.220 series.
Research.
The Indian Institute of Spices Research in Kozhikode, Kerala, is devoted exclusively to researching all aspects of spice crops: black pepper, cardamom, ginger, turmeric, cinnamon, clove, nutmeg, garcinia, vanilla, etc.
Further reading.
Books
Articles

</doc>
<doc id="26898" url="http://en.wikipedia.org/wiki?curid=26898" title="Sect">
Sect

A sect is a subgroup of a religious, political or philosophical belief system, usually an offshoot of a larger religious group. Although in past it was mostly used to refer to religious groups, it has since expanded and in modern culture can refer to any organization that breaks away from a larger one to follow a different set of rules and principles. The term is occasionally used in a malicious way to suggest the broken-off group follows a more negative path than the original. The historical usage of the term "sect" in Christendom has had pejorative connotations, referring to a group or movement with heretical beliefs or practices that deviate from those of groups considered orthodox.
A sect as used in an Indian context refers to an organized tradition.
Etymology.
The word "sect" comes from the Latin noun "secta" (a feminine form of a variant past participle of the verb "sequi", to follow), meaning "a way, road", and figuratively a (prescribed) way, mode, or manner, and hence metonymously, a discipline or school of thought as defined by a set of methods and doctrines. The present gamut of meanings of "sect" has been influenced by confusion with the homonymous (but etymologically unrelated) Latin word "secta" (the feminine form of the past participle of the verb "", to cut), as sects were scissions cut away from the mainstream religion.
Sociological definitions and descriptions.
There are several different sociological definitions and descriptions for the term. Among the first to define them were Max Weber and Ernst Troeltsch (1912). In the church-sect typology they are described as newly formed religious groups that form to protest elements of their parent religion (generally a denomination). Their motivation tends to be situated in accusations of apostasy or heresy in the parent denomination; they are often decrying liberal trends in denominational development and advocating a return to true religion. The American sociologists Rodney Stark and William Sims Bainbridge assert that "sects claim to be authentic purged, refurbished version of the faith from which they split". They further assert that sects have, in contrast to churches, a high degree of tension with the surrounding society. Other sociologists of religion such as Fred Kniss have asserted that sectarianism is best described with regard to what a sect is in tension with. Some religious groups exist in tension only with co-religious groups of different ethnicities, or exist in tension with the whole of society rather than the church which the sect originated from.
Sectarianism is sometimes defined in the sociology of religion as a worldview that emphasizes the unique legitimacy of believers' creed and practices and that heightens tension with the larger society by engaging in boundary-maintaining practices.
The English sociologist Roy Wallis argues that a sect is characterized by “epistemological authoritarianism”: sects possess some authoritative locus for the legitimate attribution of heresy. According to Wallis, “sects lay a claim to possess unique and privileged access to the truth or salvation and “their committed adherents typically regard all those outside the confines of the collectivity as 'in error'”. He contrasts this with a cult that he described as characterized by “epistemological individualism” by which he means that “the cult has no clear locus of final authority beyond the individual member.”
In other languages.
The corresponding words for "sect" in European languages other than English — "Sekte" (German), "secte" (French), "secta" (Spanish, Catalan, Romanian), "seita" (Portuguese), "sekta" (Polish, Czech, Slovak, Croatian, Serbian, Slovenian, Latvian), "sekt" (Danish, Estonian, Norwegian, Swedish), "sekte" (Dutch) and "szekta" (Hungarian), "секта" (Russian, Bulgarian) — refer to a harmful religious sect and translate into English as "cult". In France, since the 1970s, "secte" has a specific meaning which is very different from the English word.
In Christianity.
While the historical usage of the term "sect" in Christendom has had pejorative connotations, referring to a group or movement with heretical beliefs or practices that deviate from those of groups considered orthodox, its primary meaning is to indicate a community which has separated itself in some way from the larger body from which its members came and to which they may or may not still adhere. The term remains valid for this purpose. 
Roman Catholic sects.
There are many groups outside the Roman Catholic Church which regard themselves as Catholic, such as the Community of the Lady of All Nations, the Palmarian Catholic Church, the Philippine Independent Church, the Brazilian Catholic Apostolic Church, the Movement for the Restoration of the Ten Commandments of God, and others.
In Hinduism.
The Indologist Axel Michaels writes in his book about Hinduism that in an Indian context the word sect does not denote a split or excluded community, but rather an organized tradition, usually established by founder with ascetic practices.
 according to Michaels, Indian sects do not focus on heresy, since the lack of a center or a compulsory center makes this impossible – instead, the focus is on adherents and followers.

</doc>
<doc id="26899" url="http://en.wikipedia.org/wiki?curid=26899" title="Spearmint">
Spearmint

Spearmint or spear mint (Mentha spicata) is a species of mint native to much of Europe and Asia (Middle East, Himalayas, China etc.), and naturalized in parts of northern and western Africa, North and South America, as well as various oceanic islands.
Description.
It is a herbaceous, rhizomatous, perennial plant growing 30–100 cm tall, with variably hairless to hairy stems and foliage, and a wide-spreading fleshy underground rhizome. The leaves are 5–9 cm long and 1.5–3 cm broad, with a serrated margin. The stem is square-shaped, a trademark of the mint family of herbs. Spearmint produces flowers in slender spikes, each flower pink or white, 2.5–3 mm long, and broad.
Hybrids involving spearmint include "Mentha × piperita" (peppermint; hybrid with "Mentha aquatica"), "Mentha × gracilis" (ginger mint, syn. "M. cardiaca"; hybrid with "Mentha arvensis"), and "Mentha × villosa" (large apple mint, hybrid with "Mentha suaveolens").
The name 'spear' mint derives from the pointed leaf tips.
Cultivation and uses.
Spearmint grows well in nearly all temperate climates. Gardeners often grow it in pots or planters due to its invasive, spreading rhizomes. The plant prefers partial shade, but can flourish in full sun to mostly shade. Spearmint is best suited to loamy soils with abundant organic material.
Spearmint leaves can be used fresh, dried, or frozen. They can also be preserved in salt, sugar, sugar syrup, alcohol, or oil. The leaves lose their aromatic appeal after the plant flowers. It can be dried by cutting just before, or right (at peak) as the flowers open, about one-half to three-quarters the way down the stalk (leaving smaller shoots room to grow). Some dispute exists as to what drying method works best; some prefer different materials (such as plastic or cloth) and different lighting conditions (such as darkness or sunlight).
Spearmint is often cultivated for its aromatic and carminative oil, referred to as oil of spearmint. The most abundant compound in spearmint oil is R-(–)-carvone, which gives spearmint its distinctive smell. Spearmint oil also contains significant amounts of limonene, dihydrocarvone, and 1,8-cineol. Unlike peppermint oil, oil of spearmint contains minimal amounts of menthol and menthone. It is used as a flavoring for toothpaste and confectionery, and is sometimes added to shampoos and soaps.
Tea.
The cultivar "Mentha spicata" 'Nana', the nana mint of Morocco, possesses a clear, pungent, but mild aroma, and is an essential ingredient of Touareg tea.
Spearmint is an ingredient in several mixed drinks, such as the mojito and mint julep. Sweet tea, iced and flavored with spearmint, is a summer tradition in the Southern United States. As a medicinal plant, spearmint is steeped as tea for the treatment of stomach ache.
Health effects.
Spearmint tea may be used as a treatment for hirsutism in women. Its antiandrogenic properties reduce the level of free testosterone in the blood, while leaving total testosterone and DHEA unaffected. However, administration of spearmint tea to rats causes dose-dependent, temporary or permanent negative effects on the reproductive system of the male rat and leads to lipid peroxidation, that results in histopathologies in the kidney, liver, and uterine tissues; more research into the toxic effects of the tea in humans is warranted. It can also be used to treat a variety of digestive ailments.
Spearmint has been studied for antifungal activity; its essential oil was found to have some antifungal activity, although less than oregano. Its essential oil did not show any evidence of mutagenicity in the Ames test. It can have a calming effect when used for insomnia or massages. Spearmint has also been described as having excellent antioxidant activity, comparable to BHT. Due both to its antioxidant activity and its common use to season lamb in South Asian cuisine, it has been studied as an additive to radiation-processed lamb meat, and was found effective in delaying oxidation of fats and reducing formation of harmful substances, which can be detected using thiobarbituric acid as a reagent.

</doc>
<doc id="26902" url="http://en.wikipedia.org/wiki?curid=26902" title="Satureja">
Satureja

Satureja is a genus of aromatic plants of the family Lamiaceae, related to rosemary and thyme. It is native to North Africa, southern + southeastern Europe, the Middle East, and Central Asia. A few New World species were formerly included in "Satureja", but they have all been moved to other genera. Several species are cultivated as culinary herbs and they have become established in the wild in a few places.
Description.
"Satureja" species may be annual or perennial. They are low-growing herbs and subshrubs, reaching heights of 15 -.
The leaves are 1-3 cm long, with flowers forming in whorls on the stem, white to pale pink-violet.
Ecology and cultivation.
"Satureja" species are food plants for the larva of some Lepidoptera (butterflies and moths). Caterpillars of the moth "Coleophora bifrondella" feed exclusively on winter savory ("S. montana").
Savory may be grown purely for ornamental purposes; members of the genus need sun and well-drained soil.
Uses.
Both summer savory ("Satureja hortensis") and winter savory ("Satureja montana") are used to flavor food. The former is preferred by cooks but as an annual is only available in summer; winter savory is an evergreen perennial.
Savory plays an important part in Bulgarian and Italian cuisine, particularly when cooking beans. It is also used to season the traditional Acadian stew known as "fricot". Savory is also a key ingredient in "sarmale", a stuffed cabbage dish in traditional Romanian cuisine. The modern spice mixture Herbes de Provence has savory as one of the principal ingredients. 
In Azerbaijan, savory is often incorporated as a flavoring in black tea.
Etymology.
The etymology of the Latin word 'satureia' is unclear. Speculation that it is related to "saturare", to "satyr", or to za'atar is not well supported. The ancient Hebrew name is ṣathrá צתרה.

</doc>
<doc id="26903" url="http://en.wikipedia.org/wiki?curid=26903" title="Solar System">
Solar System

The Solar System comprises the Sun and the objects that orbit it, either directly or indirectly. Of those objects that orbit the Sun directly, the largest eight are the planets that form the planetary system around it, while the remainder are significantly smaller objects, such as dwarf planets and small Solar System bodies (SSSBs) such as comets and asteroids.
The Solar System formed 4.6 billion years ago from the gravitational collapse of a giant interstellar molecular cloud. The vast majority of the system's mass is in the Sun, with most of the remaining mass contained in Jupiter. The four smaller inner planets, Mercury, Venus, Earth and Mars, also called the terrestrial planets, are primarily composed of rock and metal. The four outer planets, the giant planets, are substantially more massive than the terrestrials. The two largest, the gas giants Jupiter and Saturn, are composed mainly of hydrogen and helium; the two outermost planets, the ice giants Uranus and Neptune, are composed largely of substances with relatively high melting points compared with hydrogen and helium, called ices, such as water, ammonia and methane. All planets have almost circular orbits that lie within a nearly flat disc called the ecliptic.
The Solar System also contains smaller objects. The asteroid belt, which lies between Mars and Jupiter, mostly contains objects composed, like the terrestrial planets, of rock and metal. Beyond Neptune's orbit lie the Kuiper belt and scattered disc, populations of trans-Neptunian objects composed mostly of ices, and beyond them a newly discovered population of sednoids. Within these populations are several dozen to possibly tens of thousands of objects large enough to have been rounded by their own gravity. Such objects are categorized as dwarf planets. Identified dwarf planets include the asteroid Ceres and the trans-Neptunian objects Pluto and Eris. In addition to these two regions, various other small-body populations, including comets, centaurs and interplanetary dust, freely travel between regions. Six of the planets, at least three of the dwarf planets, and many of the smaller bodies are orbited by natural satellites, usually termed "moons" after Earth's Moon. Each of the outer planets is encircled by planetary rings of dust and other small objects.
The solar wind, plasma flowing outwards from the Sun, creates a bubble in the interstellar medium known as the heliosphere. The heliopause is the point at which pressure from the solar wind is equal to the opposing pressure of interstellar wind; it extends out to the edge of the scattered disc. The Oort cloud, which is believed to be the source for long-period comets, may also exist at a distance roughly a thousand times further than the heliosphere. The Solar System is located in the Orion Arm, 26,000 light years from the center of the Milky Way.
Discovery and exploration.
For many thousands of years, humanity, with a few notable exceptions, did not recognize the existence of the Solar System. People believed Earth to be stationary at the centre of the universe and categorically different from the divine or ethereal objects that moved through the sky. Although the Greek philosopher Aristarchus of Samos had speculated on a heliocentric reordering of the cosmos, Nicolaus Copernicus was the first to develop a mathematically predictive heliocentric system. In the 17th-century, Galileo Galilei, Johannes Kepler and Isaac Newton, developed an understanding of physics that led to the gradual acceptance of the idea that Earth moves around the Sun and that the planets are governed by the same physical laws that governed Earth. The invention of the telescope led to the discovery of further planets and moons. Improvements in the telescope and the use of unmanned spacecraft have enabled the investigation of geological phenomena, such as mountains, craters, seasonal meteorological phenomena, such as clouds, dust storms and ice caps on the other planets.
Structure and composition.
The principal component of the Solar System is the Sun, a G2 main-sequence star that contains 99.86% of the system's known mass and dominates it gravitationally. The Sun's four largest orbiting bodies, the giant planets, account for 99% of the remaining mass, with Jupiter and Saturn together comprising more than 90%. The remaining objects of the Solar System (including the four terrestrial planets, the dwarf planets, moons, asteroids, and comets) together comprise less than 0.002% of the Solar System's total mass.
Most large objects in orbit around the Sun lie near the plane of Earth's orbit, known as the ecliptic. The planets are very close to the ecliptic, whereas comets and Kuiper belt objects are frequently at significantly greater angles to it. All the planets and most other objects orbit the Sun in the same direction that the Sun is rotating (counter-clockwise, as viewed from above Earth's north pole). There are exceptions, such as Halley's Comet.
The overall structure of the charted regions of the Solar System consists of the Sun, four relatively small inner planets surrounded by a belt of rocky asteroids, and four giant planets surrounded by the Kuiper belt of icy objects. Astronomers sometimes informally divide this structure into separate regions. The inner Solar System includes the four terrestrial planets and the asteroid belt. The outer Solar System is beyond the asteroids, including the four giant planets. Since the discovery of the Kuiper belt, the outermost parts of the Solar System are considered a distinct region consisting of the objects beyond Neptune.
Most of the planets in the Solar System possess secondary systems of their own, being orbited by planetary objects called natural satellites, or moons (two of which are larger than the planet Mercury), and, in the case of the four giant planets, by planetary rings, thin bands of tiny particles that orbit them in unison. Most of the largest natural satellites are in synchronous rotation, with one face permanently turned toward their parent.
Kepler's laws of planetary motion describe the orbits of objects about the Sun. Following Kepler's laws, each object travels along an ellipse with the Sun at one focus. Objects closer to the Sun (with smaller semi-major axes) travel more quickly because they are more affected by the Sun's gravity. On an elliptical orbit, a body's distance from the Sun varies over the course of its year. A body's closest approach to the Sun is called its "perihelion", whereas its most distant point from the Sun is called its "aphelion". The orbits of the planets are nearly circular, but many comets, asteroids, and Kuiper belt objects follow highly elliptical orbits. The positions of the bodies in the Solar System can be predicted using numerical models.
Although the Sun dominates the system by mass, it accounts for only about 2% of the angular momentum. The planets, dominated by Jupiter, account for most of the rest of the angular momentum due to the combination of their mass, orbit, and distance from the Sun, with a possibly significant contribution from comets.
The Sun, which comprises nearly all the matter in the Solar System, is composed of roughly 98% hydrogen and helium. Jupiter and Saturn, which comprise nearly all the remaining matter, possess atmospheres composed of roughly 99% of these elements. A composition gradient exists in the Solar System, created by heat and light pressure from the Sun; those objects closer to the Sun, which are more affected by heat and light pressure, are composed of elements with high melting points. Objects farther from the Sun are composed largely of materials with lower melting points. The boundary in the Solar System beyond which those volatile substances could condense is known as the frost line, and it lies at roughly 5 AU from the Sun.
The objects of the inner Solar System are composed mostly of rock, the collective name for compounds with high melting points, such as silicates, iron or nickel, that remained solid under almost all conditions in the protoplanetary nebula. Jupiter and Saturn are composed mainly of gases, the astronomical term for materials with extremely low melting points and high vapour pressure, such as hydrogen, helium, and neon, which were always in the gaseous phase in the nebula. Ices, like water, methane, ammonia, hydrogen sulfide and carbon dioxide, have melting points up to a few hundred kelvins. They can be found as ices, liquids, or gases in various places in the Solar System, whereas in the nebula they were either in the solid or gaseous phase. Icy substances comprise the majority of the satellites of the giant planets, as well as most of Uranus and Neptune (the so-called "ice giants") and the numerous small objects that lie beyond Neptune's orbit. Together, gases and ices are referred to as "volatiles".
Distances and scales.
The distance from Earth to the Sun is 1 AU, or AU. For comparison, the radius of the Sun is 0.0047 AU. Thus, the Sun occupies 0.00001% (10−5 %) of the volume of a sphere with a radius the size of Earth's orbit, whereas Earth's volume is roughly one millionth (10−6) that of the Sun. Jupiter, the largest planet, is 5.2 AU from the Sun and has a radius of 71000 km, whereas the most distant planet, Neptune, is 30 AU from the Sun.
With a few exceptions, the farther a planet or belt is from the Sun, the larger the distance between its orbit and the orbit of the next nearer object to the Sun. For example, Venus is approximately 0.33 AU farther out from the Sun than Mercury, whereas Saturn is 4.3 AU out from Jupiter, and Neptune lies 10.5 AU out from Uranus. Attempts have been made to determine a relationship between these orbital distances (for example, the Titius–Bode law), but no such theory has been accepted. The images at the beginning of this section show the orbits of the various constituents of the Solar System on different scales.
Some Solar System models attempt to convey the relative scales involved in the Solar System on human terms. Some are small in scale (and may be mechanical—called orreries)—whereas others extend across cities or regional areas. The largest such scale model, the Sweden Solar System, uses the 110-metre (361-ft) Ericsson Globe in Stockholm as its substitute Sun, and, following the scale, Jupiter is a 7.5-metre (25-foot) sphere at Arlanda International Airport, 40 km (25 mi) away, whereas the farthest current object, Sedna, is a 10-cm (4-in) sphere in Luleå, 912 km (567 mi) away.
If the Sun–Neptune distance is scaled to 100 metres, then the Sun would be about 3 cm in diameter (roughly two-thirds the diameter of a golf ball), the giant planets would be all smaller than about 3 mm, and Earth's diameter along with the that of the other terrestrial planets would be smaller than a flea (0.3 mm) at this scale.
Distances of selected bodies of the Solar System from the Sun. The left and right edges of each bar correspond to the perihelion and aphelion of the body, respectively. Long bars denote high orbital eccentricity. The radius of the Sun is 0.7 million km, and the radius of Jupiter (the largest planet) is 0.07 million km, both too small to resolve on this image.
Formation and evolution.
The Solar System formed 4.568 billion years ago from the gravitational collapse of a region within a large molecular cloud. This initial cloud was likely several light-years across and probably birthed several stars. As is typical of molecular clouds, this one consisted mostly of hydrogen, with some helium, and small amounts of heavier elements fused by previous generations of stars. As the region that would become the Solar System, known as the pre-solar nebula, collapsed, conservation of angular momentum caused it to rotate faster. The centre, where most of the mass collected, became increasingly hotter than the surrounding disc. As the contracting nebula rotated faster, it began to flatten into a protoplanetary disc with a diameter of roughly 200 AU and a hot, dense protostar at the centre. The planets formed by accretion from this disc, in which dust and gas gravitationally attracted each other, coalescing to form ever larger bodies. Hundreds of protoplanets may have existed in the early Solar System, but they either merged or were destroyed, leaving the planets, dwarf planets, and leftover minor bodies.
Due to their higher boiling points, only metals and silicates could exist in solid form in the warm inner Solar System close to the Sun, and these would eventually form the rocky planets of Mercury, Venus, Earth, and Mars. Because metallic elements only comprised a very small fraction of the solar nebula, the terrestrial planets could not grow very large. The giant planets (Jupiter, Saturn, Uranus, and Neptune) formed further out, beyond the frost line, the point between the orbits of Mars and Jupiter where material is cool enough for volatile icy compounds to remain solid. The ices that formed these planets were more plentiful than the metals and silicates that formed the terrestrial inner planets, allowing them to grow massive enough to capture large atmospheres of hydrogen and helium, the lightest and most abundant elements. Leftover debris that never became planets congregated in regions such as the asteroid belt, Kuiper belt, and Oort cloud. The Nice model is an explanation for the creation of these regions and how the outer planets could have formed in different positions and migrated to their current orbits through various gravitational interactions.
Within 50 million years, the pressure and density of hydrogen in the centre of the protostar became great enough for it to begin thermonuclear fusion. The temperature, reaction rate, pressure, and density increased until hydrostatic equilibrium was achieved: the thermal pressure equalled the force of gravity. At this point, the Sun became a main-sequence star. The main-sequence phase, from beginning to end, will last about 10 billion years for the Sun compared to around two billion years for all other phases of the Sun's pre-remnant life combined. Solar wind from the Sun created the heliosphere and swept away the remaining gas and dust from the protoplanetary disc into interstellar space, ending the planetary formation process. The Sun is growing brighter; early in its main-sequence life its brightness was 70% that of what it is today.
The Solar System will remain roughly as we know it today until the hydrogen in the core of the Sun has been entirely converted to helium, which will occur roughly 5 billion years from now. This will mark the end of the Sun's main-sequence life. At this time, the core of the Sun will collapse, and the energy output will be much greater than at present. The outer layers of the Sun will expand to roughly 260 times its current diameter, and the Sun will become a red giant. Because of its vastly increased surface area, the surface of the Sun will be considerably cooler (2,600 K at its coolest) than it is on the main sequence. The expanding Sun is expected to vaporize Mercury and Venus and render Earth uninhabitable as the habitable zone moves out to the orbit of Mars. Eventually, the core will be hot enough for helium fusion; the Sun will burn helium for a fraction of the time it burned hydrogen in the core. The Sun is not massive enough to commence the fusion of heavier elements, and nuclear reactions in the core will dwindle. Its outer layers will move away into space, leaving a white dwarf, an extraordinarily dense object, half the original mass of the Sun but only the size of Earth. The ejected outer layers will form what is known as a planetary nebula, returning some of the material that formed the Sun—but now enriched with heavier elements like carbon—to the interstellar medium.
Sun.
The Sun is the Solar System's star and by far its most massive component. Its large mass (332,900 Earth masses) produces temperatures and densities in its core high enough to sustain nuclear fusion of hydrogen into helium, making it a main-sequence star. This releases an enormous amount of energy, mostly radiated into space as electromagnetic radiation peaking in visible light.
The Sun is a G2-type main-sequence star. Hotter main-sequence stars are more luminous. The Sun's temperature is intermediate between that of the hottest stars and that of the coolest stars. Stars brighter and hotter than the Sun are rare, whereas substantially dimmer and cooler stars, known as red dwarfs, make up 85% of the stars in the Milky Way.
The Sun is a population I star; it contains more elements heavier than hydrogen and helium ("metals" in astronomical parlance) than the older population II stars. Elements heavier than hydrogen and helium were formed in the cores of ancient and exploding stars, so the first generation of stars had to die before the Universe could be enriched with these atoms. The oldest stars contain few metals, whereas stars born later have more. This high metallicity is thought to have been crucial to the Sun's development of a planetary system because the planets form from the accretion of "metals".
Interplanetary medium.
The vast majority of the Solar System consists of a near-vacuum known as the interplanetary medium. Along with light, the Sun radiates a continuous stream of charged particles (a plasma) known as the solar wind. This stream of particles spreads outwards at roughly 1.5 million km per hour, creating a tenuous atmosphere (the heliosphere) that permeates the interplanetary medium out to at least 100 AU (see heliopause). Activity on the Sun's surface, such as solar flares and coronal mass ejections, disturb the heliosphere, creating space weather and causing geomagnetic storms. The largest structure within the heliosphere is the heliospheric current sheet, a spiral form created by the actions of the Sun's rotating magnetic field on the interplanetary medium.
Earth's magnetic field stops its atmosphere from being stripped away by the solar wind. Venus and Mars do not have magnetic fields, and as a result the solar wind is causing their atmospheres to gradually bleed away into space. Coronal mass ejections and similar events blow a magnetic field and huge quantities of material from the surface of the Sun. The interaction of this magnetic field and material with Earth's magnetic field funnels charged particles into Earth's upper atmosphere, where its interactions create aurorae seen near the magnetic poles.
The heliosphere and planetary magnetic fields (for those planets that have them) partially shield the Solar System from high-energy interstellar particles called cosmic rays. The density of cosmic rays in the interstellar medium and the strength of the Sun's magnetic field change on very long timescales, so the level of cosmic-ray penetration in the Solar System varies, though by how much is unknown.
The interplanetary medium is home to at least two disc-like regions of cosmic dust. The first, the zodiacal dust cloud, lies in the inner Solar System and causes the zodiacal light. It was likely formed by collisions within the asteroid belt brought on by interactions with the planets. The second dust cloud extends from about 10 AU to about 40 AU, and was probably created by similar collisions within the Kuiper belt.
Inner Solar System.
The inner Solar System is the traditional name for the region comprising the terrestrial planets and asteroids. Composed mainly of silicates and metals, the objects of the inner Solar System are relatively close to the Sun; the radius of this entire region is less than the distance between the orbits of Jupiter and Saturn. This region is also within the frost line, which is a little less than 5 AU (about 700 million km) from the Sun.
Inner planets.
The four inner or terrestrial planets have dense, rocky compositions, few or no moons, and no ring systems. They are composed largely of refractory minerals, such as the silicates, which form their crusts and mantles, and metals, such as iron and nickel, which form their cores. Three of the four inner planets (Venus, Earth and Mars) have atmospheres substantial enough to generate weather; all have impact craters and tectonic surface features, such as rift valleys and volcanoes. The term "inner planet" should not be confused with "inferior planet", which designates those planets that are closer to the Sun than Earth is (i.e. Mercury and Venus).
Asteroid belt.
Asteroids are small Solar System bodies composed mainly of refractory rocky and metallic minerals, with some ice.
The asteroid belt occupies the orbit between Mars and Jupiter, between 2.3 and 3.3 AU from the Sun. It is thought to be remnants from the Solar System's formation that failed to coalesce because of the gravitational interference of Jupiter.
Asteroids range in size from hundreds of kilometres across to microscopic. All asteroids except the largest, Ceres, are classified as small Solar System bodies.
The asteroid belt contains tens of thousands, possibly millions, of objects over one kilometre in diameter. Despite this, the total mass of the asteroid belt is unlikely to be more than a thousandth of that of Earth. The asteroid belt is very sparsely populated; spacecraft routinely pass through without incident. Asteroids with diameters between 10 and 10−4 m are called meteoroids.
Ceres.
Ceres (2.77 AU) is the largest asteroid, a protoplanet, and a dwarf planet. It has a diameter of slightly under 1,000 km, and a mass large enough for its own gravity to pull it into a spherical shape. Ceres was considered a planet when it was discovered in 1801, and was reclassified to asteroid in the 1850s as further observations revealed additional asteroids. It was classified as a dwarf planet in 2006.
Asteroid groups.
Asteroids in the asteroid belt are divided into asteroid groups and based on their orbital characteristics. Asteroid moons are asteroids that orbit larger asteroids. They are not as clearly distinguished as planetary moons, sometimes being almost as large as their partners. The asteroid belt also contains main-belt comets, which may have been the source of Earth's water.
Jupiter trojans are located in either of Jupiter's L4 or L5 points (gravitationally stable regions leading and trailing a planet in its orbit); the term "trojan" is also used for small bodies in any other planetary or satellite Lagrange point. Hilda asteroids are in a 2:3 resonance with Jupiter; that is, they go around the Sun three times for every two Jupiter orbits.
The inner Solar System is also dusted with rogue asteroids, many of which cross the orbits of the inner planets.
Outer Solar System.
The outer region of the Solar System is home to the giant planets and their large moons. The centaurs and many short-period comets also orbit in this region. Due to their greater distance from the Sun, the solid objects in the outer Solar System contain a higher proportion of volatiles, such as water, ammonia, and methane than those of the inner Solar System because the lower temperatures allow these compounds to remain solid.
Outer planets.
The four outer planets, or giant planets (sometimes called Jovian planets), collectively make up 99% of the mass known to orbit the Sun. Jupiter and Saturn are each many tens of times the mass of Earth and consist overwhelmingly of hydrogen and helium; Uranus and Neptune are far less massive (<20 Earth masses) and possess more ices in their makeup. For these reasons, some astronomers suggest they belong in their own category, "ice giants". All four giant planets have rings, although only Saturn's ring system is easily observed from Earth. The term "superior planet" designates planets outside Earth's orbit and thus includes both the outer planets and Mars.
Centaurs.
The centaurs are icy comet-like bodies whose orbits have semi-major axes greater than Jupiter's (5.5 AU) and less than Neptune's (30 AU). The largest known centaur, 10199 Chariklo, has a diameter of about 250 km. The first centaur discovered, 2060 Chiron, has also been classified as comet (95P) because it develops a coma just as comets do when they approach the Sun.
Comets.
Comets are small Solar System bodies, typically only a few kilometres across, composed largely of volatile ices. They have highly eccentric orbits, generally a perihelion within the orbits of the inner planets and an aphelion far beyond Pluto. When a comet enters the inner Solar System, its proximity to the Sun causes its icy surface to sublimate and ionise, creating a coma: a long tail of gas and dust often visible to the naked eye.
Short-period comets have orbits lasting less than two hundred years. Long-period comets have orbits lasting thousands of years. Short-period comets are believed to originate in the Kuiper belt, whereas long-period comets, such as Hale–Bopp, are believed to originate in the Oort cloud. Many comet groups, such as the Kreutz Sungrazers, formed from the breakup of a single parent. Some comets with hyperbolic orbits may originate outside the Solar System, but determining their precise orbits is difficult. Old comets that have had most of their volatiles driven out by solar warming are often categorised as asteroids.
Trans-Neptunian region.
The area beyond Neptune, or the "trans-Neptunian region", is still largely unexplored. It appears to consist overwhelmingly of small worlds (the largest having a diameter only a fifth that of Earth and a mass far smaller than that of the Moon) composed mainly of rock and ice. This region is sometimes known as the "outer Solar System", though others use that term to mean the region beyond the asteroid belt.
Kuiper belt.
The Kuiper belt is a great ring of debris similar to the asteroid belt, but consisting mainly of objects composed primarily of ice. It extends between 30 and 50 AU from the Sun. Though it is estimated to contain anything from dozens to thousands of dwarf planets, it is composed mainly of small Solar System bodies. Many of the larger Kuiper belt objects, such as Quaoar, Varuna, and Orcus, may prove to be dwarf planets with further data. There are estimated to be over 100,000 Kuiper belt objects with a diameter greater than 50 km, but the total mass of the Kuiper belt is thought to be only a tenth or even a hundredth the mass of Earth. Many Kuiper belt objects have multiple satellites, and most have orbits that take them outside the plane of the ecliptic.
The Kuiper belt can be roughly divided into the "classical" belt and the resonances. Resonances are orbits linked to that of Neptune (e.g. twice for every three Neptune orbits, or once for every two). The first resonance begins within the orbit of Neptune itself. The classical belt consists of objects having no resonance with Neptune, and extends from roughly 39.4 AU to 47.7 AU. Members of the classical Kuiper belt are classified as cubewanos, after the first of their kind to be discovered, (15760) 1992 QB1, and are still in near primordial, low-eccentricity orbits.
Pluto and Charon.
The dwarf planet Pluto (39 AU average) is the largest known object in the Kuiper belt. When discovered in 1930, it was considered to be the ninth planet; this changed in 2006 with the adoption of a formal definition of planet. Pluto has a relatively eccentric orbit inclined 17 degrees to the ecliptic plane and ranging from 29.7 AU from the Sun at perihelion (within the orbit of Neptune) to 49.5 AU at aphelion.
Charon, Pluto's largest moon, is sometimes described as part of a binary system with Pluto, as the two bodies orbit a barycentre of gravity above their surfaces (i.e. they appear to "orbit each other"). Beyond Charon, four much smaller moons, Styx, Nix, Kerberos, and Hydra, are known to orbit within the system.
Pluto has a 3:2 resonance with Neptune, meaning that Pluto orbits twice round the Sun for every three Neptunian orbits. Kuiper belt objects whose orbits share this resonance are called plutinos.
Makemake and Haumea.
Makemake (45.79 AU average), although smaller than Pluto, is the largest known object in the "classical" Kuiper belt (that is, a Kuiper belt object not in a confirmed resonance with Neptune). Makemake is the brightest object in the Kuiper belt after Pluto. It was named and designated a dwarf planet in 2008. Its orbit is far more inclined than Pluto's, at 29°.
Haumea (43.13 AU average) is in an orbit similar to Makemake except that it is in a 7:12 orbital resonance with Neptune. It is about the same size as Makemake and has two natural satellites. A rapid, 3.9-hour rotation gives it a flattened and elongated shape. It was named and designated a dwarf planet in 2008.
Scattered disc.
The scattered disc, which overlaps the Kuiper belt but extends much further outwards, is thought to be the source of short-period comets. Scattered disc objects are believed to have been ejected into erratic orbits by the gravitational influence of Neptune's early outward migration. Most scattered disc objects (SDOs) have perihelia within the Kuiper belt but aphelia far beyond it (some more than 150 AU from the Sun). SDOs' orbits are also highly inclined to the ecliptic plane and are often almost perpendicular to it. Some astronomers consider the scattered disc to be merely another region of the Kuiper belt and describe scattered disc objects as "scattered Kuiper belt objects". Some astronomers also classify centaurs as inward-scattered Kuiper belt objects along with the outward-scattered residents of the scattered disc.
Eris.
Eris (68 AU average) is the largest known scattered disc object, and caused a debate about what constitutes a planet, because it is 25% more massive than Pluto and about the same diameter. It is the most massive of the known dwarf planets. It has one known moon, Dysnomia. Like Pluto, its orbit is highly eccentric, with a perihelion of 38.2 AU (roughly Pluto's distance from the Sun) and an aphelion of 97.6 AU, and steeply inclined to the ecliptic plane.
Farthest regions.
The point at which the Solar System ends and interstellar space begins is not precisely defined because its outer boundaries are shaped by two separate forces: the solar wind and the Sun's gravity. The outer limit of the solar wind's influence is roughly four times Pluto's distance from the Sun; this "heliopause" is considered the beginning of the interstellar medium. The Sun's Hill sphere, the effective range of its gravitational dominance, is believed to extend up to a thousand times farther.
Heliopause.
The heliosphere is divided into two regions; the solar wind travels at roughly 400 km/s until it collides with the interstellar wind; the flow of plasma in the interstellar medium. The collision occurs at the termination shock, which is roughly 80–100 AU from the Sun upwind of the interstellar medium and roughly 200 AU from the Sun downwind. Here the wind slows dramatically, condenses and becomes more turbulent, forming a great oval structure known as the heliosheath. This structure is believed to look and behave very much like a comet's tail, extending outward for a further 40 AU on the upwind side but tailing many times that distance downwind; evidence from the Cassini and Interstellar Boundary Explorer spacecraft has suggested that it is forced into a bubble shape by the constraining action of the interstellar magnetic field. The outer boundary of the heliosphere, the heliopause, is the point at which the solar wind finally terminates and is the beginning of interstellar space. "Voyager 1" and "Voyager 2" are reported to have passed the termination shock and entered the heliosheath, at 94 and 84 AU from the Sun, respectively. "Voyager 1" is reported to have crossed the heliopause in August, 2012.
The shape and form of the outer edge of the heliosphere is likely affected by the fluid dynamics of interactions with the interstellar medium as well as solar magnetic fields prevailing to the south, e.g. it is bluntly shaped with the northern hemisphere extending 9 AU farther than the southern hemisphere. Beyond the heliopause, at around 230 AU, lies the bow shock, a plasma "wake" left by the Sun as it travels through the Milky Way.
Due to a lack of data, conditions in local interstellar space are not known for certain. It is expected that NASA's Voyager spacecraft, as they pass the heliopause, will transmit valuable data on radiation levels and solar wind to Earth. How well the heliosphere shields the Solar System from cosmic rays is poorly understood. A NASA-funded team has developed a concept of a "Vision Mission" dedicated to sending a probe to the heliosphere.
Detached objects.
90377 Sedna (520 AU average) is a large, reddish object with a gigantic, highly elliptical orbit that takes it from about 76 AU at perihelion to 940 AU at aphelion and takes 11,400 years to complete. Mike Brown, who discovered the object in 2003, asserts that it cannot be part of the scattered disc or the Kuiper belt because its perihelion is too distant to have been affected by Neptune's migration. He and other astronomers consider it to be the first in an entirely new population, sometimes termed "distant detached objects" (DDOs), which also may include the object 2000 CR105, which has a perihelion of 45 AU, an aphelion of 415 AU, and an orbital period of 3,420 years. Brown terms this population the "inner Oort cloud" because it may have formed through a similar process, although it is far closer to the Sun. Sedna is very likely a dwarf planet, though its shape has yet to be determined. The second unequivocally detached object, with a perihelion farther than Sedna's at roughly 81 AU, is 2012 VP113, discovered in 2012. Its aphelion is only half that of Sedna's, at 400–500 AU.
Oort cloud.
The Oort cloud is a hypothetical spherical cloud of up to a trillion icy objects that is believed to be the source for all long-period comets and to surround the Solar System at roughly 50,000 AU (around 1 light-year (ly)), and possibly to as far as 100,000 AU (1.87 ly). It is believed to be composed of comets that were ejected from the inner Solar System by gravitational interactions with the outer planets. Oort cloud objects move very slowly, and can be perturbed by infrequent events, such as collisions, the gravitational effects of a passing star, or the galactic tide, the tidal force exerted by the Milky Way.
Boundaries.
Much of the Solar System is still unknown. The Sun's gravitational field is estimated to dominate the gravitational forces of surrounding stars out to about two light years (125,000 AU). Lower estimates for the radius of the Oort cloud, by contrast, do not place it farther than 50,000 AU. Despite discoveries such as Sedna, the region between the Kuiper belt and the Oort cloud, an area tens of thousands of AU in radius, is still virtually unmapped. There are also ongoing studies of the region between Mercury and the Sun. Objects may yet be discovered in the Solar System's uncharted regions.
Galactic context.
 Position of the Solar System within the Milky Way
The Solar System is located in the Milky Way, a barred spiral galaxy with a diameter of about 100,000 light-years containing about 200 billion stars. The Sun resides in one of the Milky Way's outer spiral arms, known as the Orion–Cygnus Arm or Local Spur. The Sun lies between 25,000 and 28,000 light years from the Galactic Centre, and its speed within the Milky Way is about 220 kilometres per second (140 mi/s), so that it completes one revolution every 225–250 million years. This revolution is known as the Solar System's galactic year. The solar apex, the direction of the Sun's path through interstellar space, is near the constellation Hercules in the direction of the current location of the bright star Vega. The plane of the ecliptic lies at an angle of about 60° to the galactic plane.
The Solar System's location in the Milky Way is a factor in the evolution of life on Earth. Its orbit is close to circular, and orbits near the Sun are at roughly the same speed as that of the spiral arms. Therefore, the Sun passes through arms only rarely. Because spiral arms are home to a far larger concentration of supernovae, gravitational instabilities, and radiation that could disrupt the Solar System, this has given Earth long periods of stability for life to evolve. The Solar System also lies well outside the star-crowded environs of the galactic centre. Near the centre, gravitational tugs from nearby stars could perturb bodies in the Oort Cloud and send many comets into the inner Solar System, producing collisions with potentially catastrophic implications for life on Earth. The intense radiation of the galactic centre could also interfere with the development of complex life. Even at the Solar System's current location, some scientists have speculated that recent supernovae may have adversely affected life in the last 35,000 years, by flinging pieces of expelled stellar core towards the Sun, as radioactive dust grains and larger, comet-like bodies.
Neighbourhood.
The Solar System is in the Local Interstellar Cloud or Local Fluff. It is thought to be near the neighbouring G-Cloud but it is not known if the Solar System is embedded in the Local Interstellar Cloud, or if it is in the region where the Local Interstellar Cloud and G-Cloud are interacting. The Local Interstellar Cloud is an area of denser cloud in an otherwise sparse region known as the Local Bubble, an hourglass-shaped cavity in the interstellar medium roughly 300 light years across. The bubble is suffused with high-temperature plasma, that suggests it is the product of several recent supernovae.
There are relatively few stars within ten light years (95 trillion km, or 60 trillion mi) of the Sun. The closest is the triple star system Alpha Centauri, which is about 4.4 light years away. Alpha Centauri A and B are a closely tied pair of Sun-like stars, whereas the small red dwarf Alpha Centauri C (also known as Proxima Centauri) orbits the pair at a distance of 0.2 light years. The stars next closest to the Sun are the red dwarfs Barnard's Star (at 5.9 light years), Wolf 359 (7.8 light years), and Lalande 21185 (8.3 light years). The largest star within ten light years is Sirius, a bright main-sequence star roughly 8.6 light years away and roughly twice the Sun's mass and that is orbited by a white dwarf, Sirius B. The nearest brown dwarfs are the binary Luhman 16 system at 6.6 light years. The remaining systems within ten light years are the binary red-dwarf system Luyten 726-8 (8.7 light years) and the solitary red dwarf Ross 154 (9.7 light years). The closest solitary Sun-like star to the Solar System is Tau Ceti at 11.9 light years. It has roughly 80% of the Sun's mass but only 60% of its luminosity. The closest known extrasolar planet to the Sun orbits Alpha Centauri B. This planet, Alpha Centauri Bb, is at least 1.1 times Earth's mass and orbits its star every 3.236 days. The closest known free-floating planetary-mass object to the Sun is WISE 0855−0714, an object with a mass less than 10 Jupiter masses located roughly 7 light years away.
A diagram of Earth's location in the observable Universe. (".")
Visual summary.
This section is a sampling of Solar System bodies, selected for size and quality of imagery, and sorted by volume. Some omitted objects are larger than the ones included here, notably Pluto and Eris, because these have not been imaged in high quality.

</doc>
<doc id="26904" url="http://en.wikipedia.org/wiki?curid=26904" title="Silurian">
Silurian

The Silurian is a geologic period and system that extends from the end of the Ordovician Period, about 443.8 ± 1.5 million years ago (mya), to the beginning of the Devonian Period, about 419.2 ± 3.2 mya (ICS, ). As with other geologic periods, the rock beds that define the period's start and end are well identified, but the exact dates are uncertain by several million years. The base of the Silurian is set at a major extinction event when 60% of marine species were wiped out. See Ordovician-Silurian extinction events.
A significant evolutionary milestone during the Silurian was the diversification of jawed and bony fish. Life also began to appear on land in the form of small, moss-like, vascular plants which grew beside lakes, streams, and coastlines, and also in the form of small terrestrial arthropods. However, terrestrial life would not greatly diversify and affect the landscape until the Devonian.
History of study.
The Silurian system was first identified by British geologist Sir Roderick Impey Murchison, who was examining fossil-bearing sedimentary rock strata in south Wales in the early 1830s. He named the sequences for a Celtic tribe of Wales, the Silures, inspired by his friend Adam Sedgwick, who had named the period of his study the Cambrian, the Latin name for Wales. This naming does not indicate any correlation between the occurrence of the Silurian rocks and the land inhabited by the Silures; . , . In 1835 the two men presented a joint paper, under the title "On the Silurian and Cambrian Systems, Exhibiting the Order in which the Older Sedimentary Strata Succeed each other in England and Wales," which was the germ of the modern geological time scale. As it was first identified, the "Silurian" series when traced farther afield quickly came to overlap Sedgwick's "Cambrian" sequence, however, provoking furious disagreements that ended the friendship. Charles Lapworth resolved the conflict by defining a new Ordovician system including the contested beds. An early alternative name for the Silurian was "Gotlandian" after the strata of the Baltic island of Gotland.
The French geologist Joachim Barrande, building on Murchison's work, used the term "Silurian" in a more comprehensive sense than was justified by subsequent knowledge. He divided the Silurian rocks of Bohemia into eight stages. His interpretation was questioned in 1854 by Edward Forbes, and the later stages of Barrande, F, G and H, have since been shown to be Devonian. Despite these modifications in the original groupings of the strata, it is recognized that Barrande established Bohemia as a classic ground for the study of the earliest fossils.
Subdivisions.
Key events in the Silurian</div Scale><div id=ScaleBar style="width:1px; float:left; height:45em; padding:0; background-color:#242020" />em;
 height:45.0em;
 margin-left:0em;
 width:0.9em;
">em; 
">P a l e o z o i c
em;
 height:2.63736263736em;
 margin-left:0.95em;
 width:9.05em;
">em; 
">Ordovician
em;
 height:39.7901098901em;
 margin-left:0.95em;
 width:1.25em;
">em; 
">S<br>i<br>l<br>u<br>r<br>i<br>a<br>n
em;
 height:2.47252747253em;
 margin-left:0.95em;
 width:9.05em;
">em; 
">Devonian
em;
 height:16.3835164835em;
 margin-left:2.3em;
 width:1.1em;
">em; 
">Llandovery
em;
 height:9.79010989011em;
 margin-left:2.3em;
 width:1.1em;
">em; 
">Wenlock
em;
 height:7.15274725275em;
 margin-left:2.3em;
 width:1.1em;
">em; 
">Ludlow
em;
 height:6.16373626374em;
 margin-left:2.3em;
 width:7.7em;
">em; 
">Pridoli
em;
 height:4.18571428571em;
 margin-left:3.45em;
 width:6.55em;
">em; 
">Rhuddanian
em;
 height:3.69120879121em;
 margin-left:3.45em;
 width:6.55em;
">em; 
">Aeronian
em;
 height:8.30659340659em;
 margin-left:3.45em;
 width:6.55em;
">em; 
">Telychian
em;
 height:4.68021978022em;
 margin-left:3.45em;
 width:6.55em;
">em; 
">Sheinwoodian
em;
 height:5.00989010989em;
 margin-left:3.45em;
 width:6.55em;
">em; 
">Homerian
em;
 height:2.86703296703em;
 margin-left:3.45em;
 width:6.55em;
">em; 
">Gorstian
em;
 height:4.18571428571em;
 margin-left:3.45em;
 width:6.55em;
">em; 
">Ludfordian
em;
 height:45.0em;
 margin-left:9.9em;
 width:0.1em;
">em; 
"> em;
 height:45.0em;
 margin-left:0.9em;
 width:0.05em;
">em; 
"> em;
 height:39.8901098901em;
 margin-left:2.2em;
 width:0.1em;
">em; 
"> em;
 height:39.8901098901em;
 margin-left:2.2em;
 width:0.1em;
">em; 
"> em;
 height:33.6263736264em;
 margin-left:3.4em;
 width:0.05em;
">em; 
"> </div Timeline>em;
">←Lau event
em;
">←Mulde event
em;
">←Ireviken<br>event
em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
">em;
"></div containsTSN></div Legend>Key events of the Silurian Period. <br>Axis scale: millions of years ago.<br></div caption></div Container>
Llandovery.
The Llandovery Epoch lasted from {{}}: Error! the period you specified has not been recognised! This could be because you mis-spelt it, or because it is missing from or . mya, and is subdivided into three stages: the Rhuddanian, lasting until million years ago, the Aeronian, lasting to million years ago, and the Telychian. The epoch is named for the town of Llandovery in Carmarthenshire, Wales.
Wenlock.
The Wenlock, which lasted from {{}}: Error! the period you specified has not been recognised! This could be because you mis-spelt it, or because it is missing from or . mya, is subdivided into the Sheinwoodian (to million years ago) and Homerian ages. It is named after Wenlock Edge in Shropshire, England. During the Wenlock, the oldest known tracheophytes of the genus "Cooksonia", appear. The complexity of slightly younger Gondwana plants like "Baragwanathia" indicates a much longer history for vascular plants, perhaps extending into the early Silurian or even Ordovician. See Evolutionary history of plants. The first terrestrial animals also appear in the Wenlock, represented by air-breathing millipedes from Scotland.
Ludlow.
The Ludlow, lasting from {{}}: Error! the period you specified has not been recognised! This could be because you mis-spelt it, or because it is missing from or . mya, comprises the Gorstian stage, lasting until million years ago, and the Ludfordian stage. It is named for the town of Ludlow (and neighbouring Ludford) in Shropshire, England.
Přídolí.
The Pridoli, lasting from {{}}: Error! the period you specified has not been recognised! This could be because you mis-spelt it, or because it is missing from or . mya, is the final and shortest epoch of the Silurian. It is named after one locality at the "Homolka a Přídolí" nature reserve near the Prague suburb Slivenec in the Czech Republic. "Přídolí" is the old name of a cadastral field area.
Regional stages.
In North America a different suite of regional stages is sometimes used:
Geography.
With the supercontinent Gondwana covering the equator and much of the southern hemisphere, a large ocean occupied most of the northern half of the globe. The high sea levels of the Silurian and the relatively flat land (with few significant mountain belts) resulted in a number of island chains, and thus a rich diversity of environmental settings.
During the Silurian, Gondwana continued a slow southward drift to high southern latitudes, but there is evidence that the Silurian icecaps were less extensive than those of the late Ordovician glaciation. The southern continents remained united during this period. The melting of icecaps and glaciers contributed to a rise in sea level, recognizable from the fact that Silurian sediments overlie eroded Ordovician sediments, forming an unconformity. The continents of Avalonia, Baltica, and Laurentia drifted together near the equator, starting the formation of a second supercontinent known as Euramerica.
When the proto-Europe collided with North America, the collision folded coastal sediments that had been accumulating since the Cambrian off the east coast of North America and the west coast of Europe. This event is the Caledonian orogeny, a spate of mountain building that stretched from New York State through conjoined Europe and Greenland to Norway. At the end of the Silurian, sea levels dropped again, leaving telltale basins of evaporites in a basin extending from Michigan to West Virginia, and the new mountain ranges were rapidly eroded. The Teays River, flowing into the shallow mid-continental sea, eroded Ordovician strata, leaving traces in the Silurian strata of northern Ohio and Indiana.
The vast ocean of Panthalassa covered most of the northern hemisphere. Other minor oceans include two phases of the Tethys— the Proto-Tethys and Paleo-Tethys— the Rheic Ocean, a seaway of the Iapetus Ocean (now in between Avalonia and Laurentia), and the newly formed Ural Ocean.
Climate and sea level.
 <imagemap>
Image:Extinction intensity.svg
Marine extinction intensity during the Phanerozoic
Millions of years ago
K–Pg
Tr–J
P–Tr
Late D
O–S
<imagemap>
Image:Extinction intensity.svg
The blue graph shows the apparent "percentage" (not the absolute number) of marine animal genera becoming extinct during any given time interval. It does not represent all marine species, just those that are readily fossilized. The labels of the "Big Five" extinction events are clickable hyperlinks; see Extinction event for more details. "()"
The Silurian period enjoyed relatively stable and warm temperatures, in contrast with the extreme glaciations of the Ordovician before it, and the extreme heat of the ensuing Devonian. Sea levels rose from their Hirnantian low throughout the first half of the Silurian; they subsequently fell throughout the rest of the period, although smaller scale patterns are superimposed on this general trend; fifteen high-stands can be identified, and the highest Silurian sea level was probably around 140 m higher than the lowest level reached.
During this period, the Earth entered a long, warm greenhouse phase, and warm shallow seas covered much of the equatorial land masses. Early in the Silurian, glaciers retreated back into the South Pole until they almost disappeared in the middle of Silurian. The period witnessed a relative stabilization of the Earth's general climate, ending the previous pattern of erratic climatic fluctuations. Layers of broken shells (called coquina) provide strong evidence of a climate dominated by violent storms generated then as now by warm sea surfaces. Later in the Silurian, the climate cooled slightly, but in the Silurian-Devonian boundary, the climate became warmer.
Perturbations.
The climate and carbon cycle appears to be rather unsettled during the Silurian, which has a higher concentration of isotopic excursions than any other period. The Ireviken event, Mulde event and Lau event each represent isotopic excursions following a minor mass extinction and associated with rapid sea-level change, in addition to the larger extinction at the end of the Silurian. Each one leaves a similar signature in the geological record, both geochemically and biologically; pelagic (free-swimming) organisms were particularly hard hit, as were brachiopods, corals and trilobites, and extinctions rarely occur in a rapid series of fast bursts.
Flora and fauna.
The Silurian was the first period to see macrofossils of extensive terrestrial biota, in the form of moss forests along lakes and streams. However, the land fauna did not have a major impact on the Earth until it diversified in the Devonian.
The first fossil records of vascular plants, that is, land plants with tissues that carry food, appeared in the second half of the Silurian period. The earliest known representatives of this group are "Cooksonia" (mostly from the northern hemisphere) and "Baragwanathia" (from Australia). Most of the sediments containing "Cooksonia" are marine in nature. Preferred habitats were likely along rivers and streams. "Baragwanathia", appears to be almost as old dating to the Early Ludlow (420 million years) and has branching stems and needle-like leaves of 10–20 cm. The plant shows a high degree of development in relation to its age. As mentioned, fossils of this plant are only found in Australia.
The much-branched "Psilophyton" was a primitive Silurian land plant with xylem and phloem but no differentiation in root, stem or leaf. It reproduced by spores, had stomata on every surface, and probably photosynthesized in every tissue exposed to light. Rhyniophyta and primitive lycopods were other land plants that first appear during this period. Neither mosses nor the earliest vascular plants had deep roots. Silurian rocks often have a brownish tint, possibly a result of extensive erosion of the early soils.
The first bony fish, the Osteichthyes, appeared, represented by the Acanthodians covered with bony scales; fish reached considerable diversity and developed movable jaws, adapted from the supports of the front two or three gill arches. A diverse fauna of Eurypterids (sea scorpions)—some of them several meters in length—prowled the shallow Silurian seas of North America; many of their fossils have been found in New York state. Leeches also made their appearance during the Silurian Period. Brachiopods, bryozoa, molluscs, hederelloids, tentaculitoids, crinoids and trilobites were abundant and diverse. Endobiotic symbionts were common in the corals and stromatoporoids.
Reef abundance was patchy; sometimes fossils are frequent but at other points are virtually absent from the rock record.
The earliest known terrestrial animals appear during the Mid Silurian, including the millipede "Pneumodesmus". Some evidence also suggests the presence of predatory trigonotarbid arachnoids and myriapods in Late Silurian facies. Predatory invertebrates would indicate that simple food webs were in place that included non-predatory prey animals. Extrapolating back from Early Devonian biota, Andrew Jeram "et al." in 1990 suggested a food web based on as yet undiscovered detritivores and grazers on micro-organisms.

</doc>
<doc id="26905" url="http://en.wikipedia.org/wiki?curid=26905" title="Siege">
Siege

A siege is a military blockade of a city or fortress with the intent of conquering by attrition or assault. The term derives from "sedere", Latin for "to sit". Siege warfare is a form of constant, low-intensity conflict characterized by one party holding a strong, static defensive position. Consequently, an opportunity for negotiation between combatants is not uncommon, as proximity and fluctuating advantage can encourage diplomacy.
A siege occurs when an attacker encounters a city or fortress that cannot be easily taken by a "coup de main" and refuses to surrender. Sieges involve surrounding the target and blocking the reinforcement or escape of troops or provision of supplies (a tactic known as "investment"), typically coupled with attempts to reduce the fortifications by means of siege engines, artillery bombardment, mining (also known as sapping), or the use of deception or treachery to bypass defences. Failing a military outcome, sieges can often be decided by starvation, thirst, or disease, which can afflict either the attacker or defender. This form of siege, though, can take many months or even years, depending upon the size of the stores of food the fortified position holds. During the process of circumvallation, the attacking force can be set upon by another force of enemies due to the lengthy amount of time required to starve a position. A defensive ring of forts outside the ring of circumvallated forts, called contravallation, is also sometimes used to defend the attackers from outside enemy forces.
Sieges probably pre-date the development of cities as large population centres. Ancient cities in the Middle East show archaeological evidence of having had fortified city walls. During the Warring States era of ancient China, there is both textual and archaeological evidence of prolonged sieges and siege machinery used against the defenders of city walls. Siege machinery was also a tradition of the ancient Greco-Roman world. During the Renaissance and the early modern period, siege warfare dominated the conduct of war in Europe. Leonardo da Vinci gained as much of his renown from the design of fortifications as from his artwork.
Medieval campaigns were generally designed around a succession of sieges. In the Napoleonic era, increasing use of ever more powerful cannon reduced the value of fortifications. In the 20th century, the significance of the classical siege declined. With the advent of mobile warfare, a single fortified stronghold is no longer as decisive as it once was. While traditional sieges do still occur, they are not as common as they once were due to changes in modes of battle, principally the ease by which huge volumes of destructive power can be directed onto a static target. Modern sieges are more commonly the result of smaller hostage, militant, or extreme resisting arrest situations.
Ancient era.
The necessity of city walls.
The Assyrians deployed large labour forces to build new palaces, temples, and defensive walls. Some settlements in the Indus Valley Civilization were also fortified. By about 3500 BC, hundreds of small farming villages dotted the Indus River floodplain. Many of these settlements had fortifications and planned streets.
The stone and mud brick houses of Kot Diji were clustered behind massive stone flood dikes and defensive walls, for neighbouring communities quarrelled constantly about the control of prime agricultural land. Mundigak (c. 2500 BC) in present-day south-east Afghanistan has defensive walls and square bastions of sun-dried bricks.
City walls and fortifications were essential for the defence of the first cities in the ancient Near East. The walls were built of mudbricks, stone, wood, or a combination of these materials, depending on local availability. They may also have served the dual purpose of showing presumptive enemies the might of the kingdom. The great walls surrounding the Sumerian city of Uruk gained a widespread reputation. The walls were 9.5 km in length, and up to 12 m in height.
Later, the walls of Babylon, reinforced by towers, moats, and ditches, gained a similar reputation. In Anatolia, the Hittites built massive stone walls around their cities atop hillsides, taking advantage of the terrain. In Shang Dynasty China, at the site of Ao, large walls were erected in the 15th century BC that had dimensions of 20 m in width at the base and enclosed an area of some 2100 yd squared. The ancient Chinese capital for the State of Zhao, Handan, founded in 386 BC, also had walls that were 20 m wide at the base; they were 15 m tall, with two separate sides of its rectangular enclosure at a length of 1,530 yd (1,400 m).
The cities of the Indus Valley Civilization showed less effort in constructing defences, as did the Minoan civilization on Crete. These civilizations probably relied more on the defence of their outer borders or sea shores. Unlike the ancient Minoan civilization, the Mycenaean Greeks emphasized the need for fortifications alongside natural defences of mountainous terrain, such as the massive Cyclopean walls built at Mycenae during the last half of the 2nd millennium BC.
Archaeological evidence.
Although there are depictions of sieges from the ancient Near East in historical sources and in art, there are very few examples of siege systems that have been found archaeologically. Of the few examples, several are noteworthy:
Depictions.
The earliest representations of siege warfare have been dated to the Protodynastic Period of Egypt, c. 3000 BC. These show the symbolic destruction of city walls by divine animals using hoes.
The first siege equipment is known from Egyptian tomb reliefs of the 24th century BC, showing Egyptian soldiers storming Canaanite town walls on wheeled siege ladders. Later Egyptian temple reliefs of the 13th century BC portray the violent siege of Dapur, a Syrian city, with soldiers climbing scale ladders supported by archers.
Assyrian palace reliefs of the 9th to 7th centuries BC display sieges of several Near Eastern cities. Though a simple battering ram had come into use in the previous millennium, the Assyrians improved siege warfare and used huge wooden tower-shaped battering rams with archers positioned on top.
In ancient China, sieges of city walls (along with naval battles) were portrayed on bronze 'hu' vessels, like those found in Chengdu, Sichuan in 1965, which have been dated to the Warring States period (5th to 3rd centuries BC).
Tactics.
Offensive.
An attacker's first act in a siege might be a surprise attack, attempting to overwhelm the defenders before they were ready or were even aware there was a threat. This was how William de Forz captured Fotheringhay Castle in 1221.
The most common practice of siege warfare was to lay siege and just wait for the surrender of the enemies inside or, quite commonly, to coerce someone inside to betray the fortification. During the medieval period, negotiations would frequently take place during the early part of the siege. An attacker – aware of a prolonged siege's great cost in time, money, and lives – might offer generous terms to a defender who surrendered quickly. The defending troops would be allowed to march away unharmed, often retaining their weapons. However, a garrison commander who was thought to have surrendered too quickly might face execution by his own side for treason.
As a siege progressed, the surrounding army would build earthworks (a line of circumvallation) to completely encircle their target, preventing food, water, and other supplies from reaching the besieged city. If sufficiently desperate as the siege progressed, defenders and civilians might have been reduced to eating anything vaguely edible – horses, family pets, the leather from shoes, and even each other.
The Hittite siege of a rebellious Anatolian vassal in the 14th century BC ended when the queen mother came out of the city and begged for mercy on behalf of her people. The Hittite campaign against the kingdom of Mitanni in the 14th century BC bypassed the fortified city of Carchemish. If the main objective of a campaign was not the conquest of a particular city, it could simply be passed by. When the main objective of the campaign had been fulfilled, the Hittite army returned to Carchemish and the city fell after an eight-day siege.
Disease was another effective siege weapon, although the attackers were often as vulnerable as the defenders. In some instances, catapults or similar weapons were used to fling diseased animals over city walls in an early example of biological warfare. If all else failed, a besieger could claim the booty of his conquest undamaged, and retain his men and equipment intact, for the price of a well-placed bribe to a disgruntled gatekeeper. The Assyrian Siege of Jerusalem in the 8th century BC came to an end when the Israelites bought them off with gifts and tribute, according to the Assyrian account, or when the Assyrian camp was struck by mass death, according to the Biblical account. Due to logistics, long-lasting sieges involving a minor force could seldom be maintained. A besieging army, encamped in possibly squalid field conditions and dependent on the countryside and its own supply lines for food, could very well be threatened with the disease and starvation intended for the besieged.
To end a siege more rapidly, various methods were developed in ancient and medieval times to counter fortifications, and a large variety of siege engines were developed for use by besieging armies. Ladders could be used to escalade over the defences. Battering rams and siege hooks could also be used to force through gates or walls, while catapults, ballistae, trebuchets, mangonels, and onagers could be used to launch projectiles to break down a city's fortifications and kill its defenders. A siege tower, a substantial structure built to equal or greater height than the fortification's walls, could allow the attackers to fire down upon the defenders and also advance troops to the wall with less danger than using ladders.
In addition to launching projectiles at the fortifications or defenders, it was also quite common to attempt to undermine the fortifications, causing them to collapse. This could be accomplished by digging a tunnel beneath the foundations of the walls, and then deliberately collapsing or exploding the tunnel. This process is known as mining. The defenders could dig counter-tunnels to cut into the attackers' works and collapse them prematurely.
Fire was often used as a weapon when dealing with wooden fortifications. The Byzantine Empire used Greek fire, which contained additives that made it hard to extinguish. Combined with a primitive flamethrower, it proved an effective offensive and defensive weapon.
Defensive.
The universal method for defending against siege is the use of fortifications, principally walls and ditches, to supplement natural features. A sufficient supply of food and water was also important to defeat the simplest method of siege warfare: starvation. On occasion, the defenders would drive 'surplus' civilians out to reduce the demands on stored food and water.
During the Warring States period in China (481–221 BC), warfare lost its honourable, gentlemen's duty that was found in the previous era of the Spring and Autumn period, and became more practical, competitive, cut-throat, and efficient for gaining victory. The Chinese invention of the hand-held, trigger-mechanism crossbow during this period revolutionized warfare, giving greater emphasis to infantry and cavalry and less to traditional chariot warfare.
The philosophically pacifist Mohists (followers of the philosopher Mozi) of the 5th century BC believed in aiding the defensive warfare of smaller Chinese states against the hostile offensive warfare of larger domineering states. The Mohists were renowned in the smaller states (and the enemies of the larger states) for the inventions of siege machinery to scale or destroy walls. These included traction trebuchet catapults, eight-foot-high ballistas, a wheeled siege ramp with grappling hooks known as the Cloud Bridge (the protractable, folded ramp slinging forward by means of a counterweight with rope and pulley), and wheeled 'hook-carts' used to latch large iron hooks onto the tops of walls to pull them down.
When enemies attempted to dig tunnels under walls for mining or entry into the city, the defenders used large bellows (the type the Chinese commonly used in heating up a blast furnace for smelting cast iron) to pump smoke into the tunnels in order to suffocate the intruders.
Advances in the prosecution of sieges in ancient and medieval times naturally encouraged the development of a variety of defensive countermeasures. In particular, medieval fortifications became progressively stronger—for example, the advent of the concentric castle from the period of the Crusades—and more dangerous to attackers—witness the increasing use of machicolations and murder-holes, as well the preparation of hot or incendiary substances. Arrowslits (also called arrow loops or loopholes), sally ports (airlock-like doors) for sallies, and deep water wells were also integral means of resisting siege at this time. Particular attention would be paid to defending entrances, with gates protected by drawbridges, portcullises, and barbicans. Moats and other water defences, whether natural or augmented, were also vital to defenders.
In the European Middle Ages, virtually all large cities had city walls—Dubrovnik in Dalmatia is a well-preserved example—and more important cities had citadels, forts, or castles. Great effort was expended to ensure a good water supply inside the city in case of siege. In some cases, long tunnels were constructed to carry water into the city. Complex systems of underground tunnels were used for storage and communications in medieval cities like Tábor in Bohemia, similar to those used much later in Vietnam during the Vietnam War.
Until the invention of gunpowder-based weapons (and the resulting higher-velocity projectiles), the balance of power and logistics definitely favoured the defender. With the invention of gunpowder, cannon and mortars and howitzers (in modern times), the traditional methods of defence became less effective against a determined siege.
Siege accounts.
Although there are numerous ancient accounts of cities being sacked, few contain any clues to how this was achieved. Some popular tales existed on how the cunning heroes succeeded in their sieges. The best-known is the Trojan Horse of the Trojan War, and a similar story tells how the Canaanite city of Joppa was conquered by the Egyptians in the 15th century BC. The Biblical Book of Joshua contains the story of the miraculous Battle of Jericho.
A more detailed historical account from the 8th century BC, called the Piankhi stela, records how the Nubians laid siege to and conquered several Egyptian cities by using battering rams, archers, and slingers and building causeways across moats.
Greco-Roman era.
Alexander the Great's army successfully besieged many powerful cities during his astounding conquests. Two of his most impressive achievements in siegecraft took place in the Siege of Tyre and the Siege of the Sogdian Rock. His engineers built a causeway that was originally 60 m wide and reached the range of his torsion-powered artillery, while his soldiers pushed siege towers housing stone throwers and light catapults to bombard the city walls.
Most conquerors before him had found Tyre, a Phoenician island-city about 1 km from the mainland, impregnable. The Greeks built a mole, a raised spit of earth across the water, by piling stones up on a natural land bridge that extended underwater to the island, and although the Tyrians rallied by sending a fire ship to destroy the towers, and captured the mole in a swarming frenzy, the city eventually fell to the Greeks after a seven-month siege. In complete contrast to Tyre, Sogdian Rock was captured by stealthy attack. Alexander used commando-like tactics to scale the cliffs and capture the high ground, and the demoralized defenders surrendered.
The importance of siege warfare in the ancient period should not be underestimated. One of the contributing causes of Hannibal's inability to defeat Rome was his lack of a siege train, thus, while he was able to defeat Roman armies in the field, he was unable to capture Rome itself. The legionary armies of the Roman Republic and Empire are noted as being particularly skilled and determined in siege warfare. An astonishing number and variety of sieges, for example, formed the core of Julius Caesar's mid-1st-century BC conquest of Gaul (modern France).
In his "Commentarii de Bello Gallico" ("Commentaries on the Gallic War"), Caesar describes how, at the Battle of Alesia, the Roman legions created two huge fortified walls around the city. The inner circumvallation, 10 mi, held in Vercingetorix's forces, while the outer contravallation kept relief from reaching them. The Romans held the ground in between the two walls. The besieged Gauls, facing starvation, eventually surrendered after their relief force met defeat against Caesar's auxiliary cavalry.
The Sicarii Zealots who defended Masada in AD 73 were defeated by the Roman legions, who built a ramp 100 m high up to the fortress's west wall.
Arabia during Muhammad's era.
Muhammad, considered a prophet for Muslims, made use of sieges extensively during his military campaigns. The first use was during the Invasion of Banu Qaynuqa. According to Islamic tradition, the invasion of Banu Qaynuqa occurred in 624 AD. The Banu Qaynuqa were a Jewish tribe expelled by Muhammad for allegedly breaking the treaty known as the Constitution of Medina:209 by pinning the clothes of a Muslim woman, which lead to her being stripped naked. A Muslim killed a Jew in retaliation, and the Jews in turn killed the Muslim man. This escalated to a chain of revenge killings, and enmity grew between Muslims and the Banu Qaynuqa, leading to the siege of their fortress.:122 The tribe eventually surrendered to Muhammad, who initially wanted to kill the members of Banu Qaynuqa, but ultimately yielded to Abdullah ibn Ubayy's insistence and agreed to expel the Qaynuqa.
The second siege was during the Invasion of Banu Nadir. According to "The Sealed Nectar", the siege did not last long; the Banu Nadir Jews willingly offered to comply with the Muhammad's order and leave Madinah. Their caravan counted 600 loaded camels, including their chiefs, Huyai bin Akhtab, and Salam bin Abi Al-Huqaiq, who left for Khaibar, whereas another party shifted to Syria. Two of them embraced Islam, Yameen bin ‘Amr and Abu Sa‘d bin Wahab, and so they retained their personal wealth. Muhammad seized their weapons, land, houses, and wealth. Amongst the other booty he managed to capture, there were 50 armours, 50 helmets, and 340 swords. This booty was exclusively Muhammad's because no fighting was involved in capturing it. He divided the booty at his own discretion among the early Emigrants and two poor Helpers, Abu Dujana and Suhail bin Haneef.
Other examples include the Invasion of Banu Qurayza in February–March 627 and the Siege of Ta'if in January 630.
Chinese and Mongols.
In the Middle Ages, the Mongol Empire's campaign against China (then comprising the Western Xia Dynasty, Jin Dynasty, and Southern Song Dynasty) by Genghis Khan until Kublai Khan, who eventually established the Yuan Dynasty in 1271, with their armies was extremely effective, allowing the Mongols to sweep through large areas. Even if they could not enter some of the more well-fortified cities, they used innovative battle tactics to grab hold of the land and the people:
Another Mongol tactic was to use catapults to launch corpses of plague victims into besieged cities. The disease-carrying fleas from the bodies would then infest the city, and the plague would spread, allowing the city to be easily captured, although this transmission mechanism was not known at the time. In 1346, the bodies of Mongol warriors of the Golden Horde who had died of plague were thrown over the walls of the besieged Crimean city of Kaffa (now Feodosiya). It has been speculated that this operation may have been responsible for the advent of the Black Death in Europe. The Black Death is estimated to have killed 30%–60% of Europe's population.
On the first night while laying siege to a city, the leader of the Mongol forces would lead from a white tent: if the city surrendered, all would be spared. On the second day, he would use a red tent: if the city surrendered, the men would all be killed, but the rest would be spared. On the third day, he would use a black tent: no quarter would be given.
However, the Chinese were not completely defenceless, and from AD 1234 until 1279, the Southern Song Chinese held out against the enormous barrage of Mongol attacks. Much of this success in defense lay in the world's first use of gunpowder (i.e. with early flamethrowers, grenades, firearms, cannons, and land mines) to fight back against the Khitans, the Tanguts, the Jurchens, and then the Mongols.
The Chinese of the Song period also discovered the explosive potential of packing hollowed cannonball shells with gunpowder. Written later around 1350 in the "Huo Long Jing", this manuscript of Jiao Yu recorded an earlier Song-era cast-iron cannon known as the 'flying-cloud thunderclap eruptor' (fei yun pi-li pao). The manuscript stated that (Wade–Giles spelling):
The shells ("phao") are made of cast iron, as large as a bowl and shaped like a ball. Inside they contain half a pound of 'magic' gunpowder ("shen huo"). They are sent flying towards the enemy camp from an eruptor ("mu phao"); and when they get there a sound like a thunder-clap is heard, and flashes of light appear. If ten of these shells are fired successfully into the enemy camp, the whole place will be set ablaze...
During the Ming Dynasty (AD 1368–1644), the Chinese were very concerned with city planning in regards to gunpowder warfare. The site for constructing the walls and the thickness of the walls in Beijing's Forbidden City were favoured by the Chinese Yongle Emperor (r. 1402–1424) because they were in pristine position to resist cannon volley and were built thick enough to withstand attacks from cannon fire.
"For more, see Technology of the Song Dynasty."
Age of gunpowder.
The introduction of gunpowder and the use of cannons brought about a new age in siege warfare. Cannons were first used in Song Dynasty China during the early 13th century, but did not become significant weapons for another 150 years or so. In early decades, cannons could do little against strong castles and fortresses, providing little more than smoke and fire. By the 16th century, however, they were an essential and regularized part of any campaigning army, or castle's defences.
The greatest advantage of cannons over other siege weapons was the ability to fire a heavier projectile, further, faster, and more often than previous weapons. They could also fire projectiles in a straight line, so that they could destroy the bases of high walls. Thus, 'old fashioned' walls – that is, high and, relatively, thin – were excellent targets, and, over time, easily demolished. In 1453, the great walls of Constantinople, the capital of the Byzantine Empire, were broken through in just six weeks by the 62 cannons of Mehmed II's army.
However, new fortifications, designed to withstand gunpowder weapons, were soon constructed throughout Europe. During the Renaissance and the early modern period, siege warfare continued to dominate the conduct of the European wars.
Once siege guns were developed, the techniques for assaulting a town or fortress became well known and ritualized. The attacking army would surround a town. Then the town would be asked to surrender. If they did not comply, the besieging army would surround the town with temporary fortifications to stop sallies from the stronghold or relief getting in. The attackers would then build a length of trenches parallel to the defences (these are known as the "First parallel") and just out of range of the defending artillery. They would then dig a trench (known as a Forward) towards the town in a zigzag pattern so that it could not be enfiladed by defending fire. Once within artillery range, another parallel (the Second Parallel) trench would be dug with gun emplacements. This technique is commonly called entrenchment.
If necessary, using the first artillery fire for cover, this process would be repeated until guns were close enough to be laid accurately to make a breach in the fortifications. In order to allow the forlorn hope and support troops to get close enough to exploit the breach, more zigzag trenches could be dug even closer to the walls with more parallel trenches to protect and conceal the attacking troops. After each step in the process, the besiegers would ask the besieged to surrender. If the forlorn hope stormed the breach successfully, the defenders could expect no mercy.
Emerging theories.
The castles that in earlier years had been formidable obstacles were easily breached by the new weapons. For example, in Spain, the newly equipped army of Ferdinand and Isabella was able to conquer Moorish strongholds in Granada in 1482–92 that had held out for centuries before the invention of cannons.
In the early 15th century, Italian architect Leon Battista Alberti wrote a treatise entitled "De Re aedificatoria", which theorized methods of building fortifications capable of withstanding the new guns. He proposed that walls be "built in uneven lines, like the teeth of a saw." He proposed star-shaped fortresses with low, thick walls.
However, few rulers paid any attention to his theories. A few towns in Italy began building in the new style late in the 1480s, but it was only with the French invasion of the Italian peninsula in 1494–95 that the new fortifications were built on a large scale. Charles VIII invaded Italy with an army of 18,000 men and a horse-drawn siege-train. As a result, he could defeat virtually any city or state, no matter how well defended. In a panic, military strategy was completely rethought throughout the Italian states of the time, with a strong emphasis on the new fortifications that could withstand a modern siege.
New fortresses.
The most effective way to protect walls against cannonfire proved to be depth (increasing the width of the defences) and angles (ensuring that attackers could only fire on walls at an oblique angle, not square on). Initially, walls were lowered and backed, in front and behind, with earth. Towers were reformed into triangular bastions. This design matured into the "trace italienne". Star-shaped fortresses surrounding towns and even cities with outlying defences proved very difficult to capture, even for a well-equipped army. Fortresses built in this style throughout the 16th century did not become fully obsolete until the 19th century, and were still in use throughout World War I (though modified for 20th-century warfare). During World War II, "trace italienne" fortresses could still present a formidable challenge, for example, in the last days of World War II, during the Battle in Berlin, that saw some of the heaviest urban fighting of the war, the Soviets did not attempt to storm the Spandau Citadel (built between 1559 and 1594), but chose to invest it and negotiate its surrender.
However, the cost of building such vast modern fortifications was incredibly high, and was often too much for individual cities to undertake. Many were bankrupted in the process of building them; others, such as Siena, spent so much money on fortifications that they were unable to maintain their armies properly, and so lost their wars anyway. Nonetheless, innumerable large and impressive fortresses were built throughout northern Italy in the first decades of the 16th century to resist repeated French invasions that became known as the Italian Wars. Many stand to this day.
In the 1530s and '40s, the new style of fortification began to spread out of Italy into the rest of Europe, particularly to France, the Netherlands, and Spain. Italian engineers were in enormous demand throughout Europe, especially in war-torn areas such as the Netherlands, which became dotted by towns encircled in modern fortifications. The densely populated areas of Northern Italy and the United Provinces (the Netherlands) were infamous for their high degree of fortification of cities. It made campaigns in these areas very hard to successfully conduct, considering even minor cities had to be captured by siege within the span of the campaigning season. In the Dutch case, the possibility of flooding large parts of the land provided an additional obstacle to besiegers, for example at the Siege of Leiden. For many years, defensive and offensive tactics were well balanced, leading to protracted and costly wars such as Europe had never known, involving more and more planning and government involvement. The new fortresses ensured that war rarely extended beyond a series of sieges. Because the new fortresses could easily hold 10,000 men, an attacking army could not ignore a powerfully fortified position without serious risk of counterattack. As a result, virtually all towns had to be taken, and that was usually a long, drawn-out affair, potentially lasting from several months to years, while the members of the town were starved to death. Most battles in this period were between besieging armies and relief columns sent to rescue the besieged.
Marshal Vauban and Van Coehoorn.
At the end of the 17th century, two influential military engineers, the French Marshal Vauban and the Dutch military engineer Menno van Coehoorn, developed modern fortification to its pinnacle, refining siege warfare without fundamentally altering it: ditches would be dug; walls would be protected by glacis; and bastions would enfilade an attacker. Both engineers developed their ideas independently, but came to similar general rules regarding defensive construction and offensive action against fortifications. Both were skilled in conducting sieges and defences themselves. Before Vauban and Van Coehoorn, sieges had been somewhat slapdash operations. Vauban and Van Coehoorn refined besieging to a science with a methodical process that, if uninterrupted, would break even the strongest fortifications. Examples of their styles of fortifications are Arras (Vauban) and the no-longer-existent fortress of Bergen op Zoom (Van Coehoorn). The main differences between the two lay in the difference in terrain on which Vauban and Van Coehoorn constructed their defences: Vauban in the sometimes more hilly and mountainous terrain of France, Van Coehoorn in the flat and floodable lowlands of the Netherlands.
Planning and maintaining a siege is just as difficult as fending one off. A besieging army must be prepared to repel both sorties from the besieged area and also any attack that may try to relieve the defenders. It was thus usual to construct lines of trenches and defenses facing in both directions. The outermost lines, known as the lines of contravallation, would surround the entire besieging army and protect it from attackers.
This would be the first construction effort of a besieging army, built soon after a fortress or city had been invested. A line of circumvallation would also be constructed, facing in towards the besieged area, to protect against sorties by the defenders and to prevent the besieged from escaping. The next line, which Vauban usually placed at about 600 meters from the target, would contain the main batteries of heavy cannons so that they could hit the target without being vulnerable themselves. Once this line was established, work crews would move forward, creating another line at 250 meters. This line contained smaller guns. The final line would be constructed only 30 to 60 meters from the fortress. This line would contain the mortars and would act as a staging area for attack parties once the walls were breached. Van Coehoorn developed a small and easily movable mortar named the coehorn, variations of which were used in sieges until the 19th century. It would also be from this line that miners working to undermine the fortress would operate.
The trenches connecting the various lines of the besiegers could not be built perpendicular to the walls of the fortress, as the defenders would have a clear line of fire along the whole trench. Thus, these lines (known as saps) needed to be sharply jagged.
Another element of a fortress was the citadel. Usually, a citadel was a "mini fortress" within the larger fortress, sometimes designed as a reduit, but more often as a means of protecting the garrison from potential revolt in the city. The citadel was used in wartime and peacetime to keep the residents of the city in line.
As in ages past, most sieges were decided with very little fighting between the opposing armies. An attacker's army was poorly served, incurring the high casualties that a direct assault on a fortress would entail. Usually, they would wait until supplies inside the fortifications were exhausted or disease had weakened the defenders to the point that they were willing to surrender. At the same time, diseases, especially typhus, were a constant danger to the encamped armies outside the fortress, and often forced a premature retreat. Sieges were often won by the army that lasted the longest.
An important element of strategy for the besieging army was whether or not to allow the encamped city to surrender. Usually, it was preferable to graciously allow a surrender, both to save on casualties, and to set an example for future defending cities. A city that was allowed to surrender with minimal loss of life was much better off than a city that held out for a long time and was brutally butchered at the end. Moreover, if an attacking army had a reputation of killing and pillaging regardless of a surrender, then other cities' defensive efforts would be redoubled. Usually, a city would surrender (with no honour lost) when its inner lines of defence were reached by the attacker. In case of refusal, however, the inner lines would have to be stormed by the attacker and the attacking troops would be seen to be justified in sacking the city.
Mobile warfare.
Siege warfare dominated in Western Europe for most of the 17th and 18th centuries. An entire campaign, or longer, could be used in a single siege (for example, Ostend in 1601–04; La Rochelle in 1627–28). This resulted in extremely prolonged conflicts. The balance was that, while siege warfare was extremely expensive and very slow, it was very successful—or, at least, more so than encounters in the field. Battles arose through clashes between besiegers and relieving armies, but the principle was a slow, grinding victory by the greater economic power. The relatively rare attempts at forcing pitched battles (Gustavus Adolphus in 1630; the French against the Dutch in 1672 or 1688) were almost always expensive failures.
The exception to this rule were the English. During the English Civil War, anything which tended to prolong the struggle, or seemed like want of energy and avoidance of a decision, was bitterly resented by the men of both sides. In France and Germany, the prolongation of a war meant continued employment for the soldiers, but in England, both sides were looking to end the war quickly. Even when in the end the New Model Army—a regular professional army—developed the original decision-compelling spirit permeated the whole organisation, as was seen when pitched against regular professional continental troops the Battle of the Dunes during the Interregnum.
Experienced commanders on both sides in the English Civil War recommended the abandonment of garrisoned fortifications for two primary reasons. The first, as for example proposed by the Royalist Sir Richard Willis to King Charles, was that by abandoning the garrisoning of all but the most strategic locations in one's own territory, far more troops would be available for the field armies, and it was the field armies which would decide the conflict. The other argument was that by slighting potential strong points in ones own territory, an enemy expeditionary force, or local enemy rising, would find it more difficult to consolidate territorial gains against an inevitable counterattack. Sir John Meldrum put forward just such an argument to the Parliamentary Committee of Both Kingdoms, to justify his slighting of Gainsborough in Lincolnshire.
Sixty years later, during the War of the Spanish Succession, the Duke of Marlborough preferred to engage the enemy in pitched battles, rather than engage in siege warfare, although he was very proficient in both types of warfare.
On 15 April 1746, the day before the Battle of Culloden, at Dunrobin Castle, a party of William Sutherland's militia conducted the last siege fought on the mainland of Great Britain against Jacobite members of Clan MacLeod.
Strategic concepts.
In the French Revolutionary and Napoleonic Wars, new techniques stressed the division of armies into all-arms corps that would march separately and only come together on the battlefield. The less-concentrated army could now live off the country and move more rapidly over a larger number of roads.
Fortresses commanding lines of communication could be bypassed and would no longer stop an invasion. Since armies could not live off the land indefinitely, Napoleon Bonaparte always sought a quick end to any conflict by pitched battle. This military revolution was described and codified by Clausewitz.
Industrial advances.
Advances in artillery made previously impregnable defences useless. For example, the walls of Vienna that had held off the Turks in the mid-17th century were no obstacle to Napoleon in the late 18th.
Where sieges occurred (such as the Siege of Delhi and the Siege of Cawnpore during the Indian Rebellion of 1857), the attackers were usually able to defeat the defences within a matter of days or weeks, rather than weeks or months as previously. The great Swedish white-elephant fortress of Karlsborg was built in the tradition of Vauban and intended as a reserve capital for Sweden, but it was obsolete before it was completed in 1869.
Railways, when they were introduced, made possible the movement and supply of larger armies than those that fought in the Napoleonic Wars. It also reintroduced siege warfare, as armies seeking to use railway lines in enemy territory were forced to capture fortresses which blocked these lines.
During the Franco-Prussian War, the battlefield front-lines moved rapidly through France. However, the Prussian and other German armies were delayed for months at the Siege of Metz and the Siege of Paris, due to the greatly increased firepower of the defending infantry, and the principle of detached or semi-detached forts with heavy-caliber artillery. This resulted in the later construction of fortress works across Europe, such as the massive fortifications at Verdun. It also led to the introduction of tactics which sought to induce surrender by bombarding the civilian population within a fortress, rather than the defending works themselves.
The Siege of Sevastopol during the Crimean War and the Siege of Petersburg (1864–1865) during the American Civil War showed that modern citadels, when improved by improvised defences, could still resist an enemy for many months. The Siege of Plevna during the Russo-Turkish War (1877–78) proved that hastily-constructed field defences could resist attacks prepared without proper resources, and were a portent of the trench warfare of World War I.
Advances in firearms technology without the necessary advances in battlefield communications gradually led to the defence again gaining the ascendancy. An example of siege during this time, prolonged during 337 days due to the isolation of the surrounded troops, was the Siege of Baler, in which a reduced group of Spanish soldiers was besieged in a small church by the Philippine rebels in the course of the Philippine Revolution and the Spanish–American War, until months after the Treaty of Paris, the end of the conflict.
Furthermore, the development of steamships availed greater speed to blockade runners, ships with the purpose of bringing cargo, e.g. food, to cities under blockade, as with Charleston, South Carolina during the American Civil War.
Modern warfare.
First World War.
Mainly as a result of the increasing firepower (such as machine guns) available to defensive forces, First World War trench warfare briefly revived a form of siege warfare. Although siege warfare had moved out from an urban setting because city walls had become ineffective against modern weapons, trench warfare was nonetheless able to use many of the techniques of siege warfare in its prosecution (sapping, mining, barrage and, of course, attrition), but on a much larger scale and on a greatly extended front.
More traditional sieges of fortifications took place in addition to trench sieges. The Siege of Tsingtao was one of the first major sieges of the war, but the inability for significant resupply of the German garrison made it a relatively one-sided battle. The Germans and the crew of an Austro-Hungarian protected cruiser put up a hopeless defence and, after holding out for more than a week, surrendered to the Japanese, forcing the German East Asia Squadron to steam towards South America for a new coal source.
The other major siege outside Europe during the First World War was in Mesopotamia, at the Siege of Kut. After a failed attempt to move on Baghdad, stopped by the Ottomans at the bloody Battle of Ctesiphon, the British and their large contingent of Indian sepoy soldiers were forced to retreat to Kut, where the Ottomans under German General Baron Colmar von der Goltz laid siege. The British attempts to resupply the force via the Tigris river failed, and rationing was complicated by the refusal of many Indian troops to eat cattle products. By the time the garrison fell on 29 April 1916, starvation was rampant. Conditions did not improve greatly under Turkish imprisonment. Along with the battles of Tanga, Sandfontein, Gallipoli, and Namakura, it would be one of Britain's numerous embarrassing colonial defeats of the war.
The largest sieges of the war, however, took place in Europe. The initial German advance into Belgium produced four major sieges: the Battle of Liège, the Battle of Namur, the Siege of Maubeuge, and the Siege of Antwerp. All three would prove crushing German victories, at Liège and Namur against the Belgians, at Maubeuge against the French and at Antwerp against a combined Anglo-Belgian force. The weapon that made these victories possible were the German Big Berthas and the Skoda 305 mm Model 1911 siege mortars, one of the best siege mortars of the war, on loan from Austria-Hungary. These huge guns were the decisive weapon of siege warfare in the 20th century, taking part at Przemyśl, the Belgian sieges, on the Italian Front and Serbian Front, and even being reused in World War II.
At the second Siege of Przemyśl, the Austro-Hungarian garrison showed an excellent knowledge of siege warfare, not only waiting for relief, but sending sorties into Russian lines and employing an active defence that resulted in the capture of the Russian General Lavr Kornilov. Despite its excellent performance, the garrison's food supply had been requisitioned for earlier offensives, a relief expedition was stalled by the weather, ethnic rivalries flared up between the defending soldiers, and a breakout attempt failed. When the commander of the garrison Hermann Kusmanek finally surrendered, his troops were eating their horses and the first attempt of large-scale air supply had failed. It was one of the few great victories obtained by either side during the war; 110,000 Austro-Hungarian prisoners were marched back to Russia. Use of aircraft for siege running, bringing supplies to areas under siege, would nevertheless prove useful in many sieges to come.
The largest siege of the war, and the arguably the roughest, most gruesome battle in history, was the Battle of Verdun. Whether the battle can be considered true siege warfare is debatable. Under the theories of Erich von Falkenhayn, it is more distinguishable as purely attrition with a coincidental presence of fortifications on the battlefield. When considering the plans of Crown Prince Wilhelm, purely concerned with taking the citadel and not with French casualty figures, it can be considered a true siege. The main fortifications were Fort Douaumont, Fort Vaux, and the fortified city of Verdun itself. The Germans, through the use of huge artillery bombardments, flamethrowers, and infiltration tactics, were able to capture both Vaux and Douaumont, but were never able to take the city, and eventually lost most of their gains. It was a battle that, despite the French ability to fend off the Germans, neither side won. The German losses were not worth the potential capture of the city, and the French casualties were not worth holding the symbol of her defence.
The development of the armoured tank and improved infantry tactics at the end of World War I swung the pendulum back in favour of manoeuvre, and with the advent of Blitzkrieg in 1939, the end of traditional siege warfare was at hand. The Maginot Line would be the prime example of the failure of immobile, post–World War I fortifications. Although sieges would continue, it would be in a totally different style and on a reduced scale.
Second World War.
The Blitzkrieg of the Second World War truly showed that fixed fortifications are easily defeated by manoeuvre instead of frontal assault or long sieges. The great Maginot Line was bypassed, and battles that would have taken weeks of siege could now be avoided with the careful application of air power (such as the German paratrooper capture of Fort Eben-Emael, Belgium, early in World War II).
The most important siege was the Siege of Leningrad, that lasted over 29 months, about half of the duration of the entire Second World War. The siege of Leningrad resulted in the deaths of some one million of the city's inhabitants. Along with the Battle of Stalingrad, the Siege of Leningrad on the Eastern Front was the deadliest siege of a city in history. In the west, apart from the Battle of the Atlantic, the sieges were not on the same scale as those on the European Eastern front; however, there were several notable or critical sieges: the island of Malta, for which the population won the George Cross, Tobruk. In the South-East Asian Theatre, there was the siege of Singapore, and in the Burma Campaign, sieges of Myitkyina, the Admin Box, Imphal, and Kohima, which was the high-water mark for the Japanese advance into India.
The siege of Sevastopol saw the use of the heaviest and most powerful individual siege engines ever to be used: the German 800mm railway gun and the 600mm siege mortar. Though a single shell could have disastrous local effect, the guns were susceptible to air attack in addition to being slow to move.
The airbridge methods which were developed and used extensively in the Burma Campaign for supplying the Chindits and other units, including those in sieges such as Imphal, as well as flying the Hump into China, allowed the western powers to develop airlift expertise, which would prove vital during the Cold War Berlin Blockade. Air supply failed to prevent the fall of Dien Bien Phu to the Vietnamese in 1954, but proved crucial in maintaining the American base at Khe Sanh in 1968.
Post-Second World War.
During the Vietnam War, the battles of Dien Bien Phu (1954) and Khe Sanh (1968) possessed siege-like characteristics. In both cases, the Viet Minh and NLF were able to cut off the opposing army by capturing the surrounding rugged terrain. At Dien Bien Phu, the French were unable to use air power to overcome the siege and were defeated. However, at Khe Sanh, a mere 14 years later, advances in air power – and a reduction in Vietnamese anti-aircraft capability – allowed the United States to withstand the siege. The resistance of US forces was assisted by the PAVN and PLAF forces' decision to use the Khe Sanh siege as a strategic distraction to allow their mobile warfare offensive, the first Tet Offensive, to unfold securely.
The Siege of Khe Sanh displays typical features of modern sieges, as the defender has greater capacity to withstand the siege, the attacker's main aim is to bottle operational forces or create a strategic distraction, rather than take the siege to a conclusion.
In neighbouring Cambodia, at that time known as the Khmer Republic, the Khmer Rouge used siege tactics to cut off supplies from Phnom Penh to other government-held enclaves in an attempt to break the will of the government to continue fighting.
In 1972, the Easter offensive, the Siege of An Lộc Vietnam occurred. ARVN troops and U.S. advisers and air power successfully defeated communist forces. The Battle of An Lộc pitted some 6,350 ARVN men against a force three times that size. During the peak of the battle, ARVN had access to only one 105 mm howitzer to provide close support, while the enemy attack was backed by an entire artillery division. ARVN had no tanks, the NVA communist forces had two armoured regiments. ARVN prevailed after over two months of continuous fighting. As General Paul Vanuxem, a French veteran of the Indochina War, wrote in 1972 after visiting the liberated city of An Lộc: "An Lộc was the Verdun of Vietnam, where Vietnam received as in baptism the supreme consecration of her will."
During the Yugoslav Wars in the 1990s, Republika Srpska forces besieged Sarajevo, the capital of Bosnia-Herzegovina. The siege lasted from 1992 until 1996.
Police activity.
Siege tactics continue to be employed in police conflicts. This has been due to a number of factors, primarily risk to life, whether that of the police, the besieged, bystanders, or hostages. Police make use of trained negotiators, psychologists, and, if necessary, force, generally being able to rely on the support of their nation's armed forces if required.
One of the complications facing police in a siege involving hostages is Stockholm syndrome, where sometimes hostages can develop a sympathetic rapport with their captors. If this helps keep them safe from harm, this is considered to be a good thing, but there have been cases where hostages have tried to shield the captors during an assault or refused to cooperate with the authorities in bringing prosecutions.
The 1993 police siege on the Branch Davidian church in Waco, Texas, lasted 51 days, an atypically long police siege. Unlike traditional military sieges, police sieges tend to last for hours or days, rather than weeks, months, or years.
In Britain, if the siege involves perpetrators who are considered by the British Government to be terrorists, and if an assault is to take place, the civilian authorities hand command and control over to the military. The threat of such an action ended the Balcombe Street siege in 1975, but the Iranian Embassy siege in 1980 ended in a military assault and the deaths of all but one of the hostage-takers.
External links.
Listen to this article (2 parts) · 
This audio file was created from a revision of the "Siege" article dated 2006-01-14, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="26906" url="http://en.wikipedia.org/wiki?curid=26906" title="Semantic dispute">
Semantic dispute

"For semantic arguments in linguistics, see verb argument."
A semantic dispute is a disagreement that arises if the parties involved disagree about the definition of a word, not because
they disagree on material facts, but rather because they disagree on the definitions of a word (or several words) essential to formulating the claim at issue. It is sometimes held that semantic disputes are not genuine disputes at all. But very often they "are" regarded as perfectly genuine, e.g., in philosophy. It is also sometimes held that when a semantic dispute arises, the focus of the debate should switch from the original thesis to the meaning of the terms of which there are different definitions (understandings, concepts, etc.). Semantic disputes can result in the logical fallacy of equivocation. In politics, for example, semantic disputes can involve the meaning of words such as liberal, democrat, conservative, republican, progressive, free, welfare or socialist.

</doc>
<doc id="26907" url="http://en.wikipedia.org/wiki?curid=26907" title="Social engineering">
Social engineering

Social engineering may refer to:

</doc>
<doc id="26908" url="http://en.wikipedia.org/wiki?curid=26908" title="Saint Lawrence Seaway">
Saint Lawrence Seaway

The Saint Lawrence Seaway (French: "la Voie Maritime du Saint-Laurent") is the common name for a system of locks, canals and channels that permit ocean-going vessels to travel from the Atlantic Ocean to the Great Lakes, as far inland as the western end of Lake Superior. The Seaway is named for the Saint Lawrence River, which flows from Lake Ontario to the Atlantic Ocean. Legally, the Seaway extends from Montreal, Quebec, to Lake Erie and includes the Welland Canal. 
This section upstream of the Seaway is not a continuous canal; rather, it consists of several stretches of navigable channels within the river, a number of locks, and canals along the banks of the St. Lawrence River to bypass several rapids and dams along the way. A number of the locks are managed by the Canadian Saint Lawrence Seaway Management Corporation, and others are managed by the American Saint Lawrence Seaway Development Corporation, which together advertise the Seaway as part of "Highway H2O". The section of the river downstream of Montreal, which is fully within Canadian jurisdiction, is regulated by the offices of Transport Canada in the Port of Quebec.
History.
The Saint Lawrence Seaway was preceded by a number of other canals. In 1871, locks on the Saint Lawrence allowed transit of vessels 186 ft long, 44 ft wide, and 9 ft deep. The Welland Canal, constructed in 1830, at that time allowed transit of vessels 142 ft long, 26 ft wide, and 10 ft deep, but it was generally too small to allow passage of larger ocean-going ships.
The first proposals for a bi-national comprehensive deep waterway along the St. Lawrence were made in the 1890s. In the following decades, developers proposed a hydropower project as inseparable from the seaway; the various governments and seaway supporters believed that the deeper water to be created by the hydro project was necessary to make the seaway channels feasible for ocean-going ships. United States proposals for development up to and including the First World War met with little interest from the Canadian federal government. But the two national governments submitted St. Lawrence plans to a group for study. By the early 1920s, both "The Wooten-Bowden Report" and the International Joint Commission recommended the project. 
Although the Liberal Prime Minister Mackenzie King was reluctant to proceed, in part because of opposition to the project in Quebec, in 1932 he and the United States representative signed a treaty of intent. This treaty was submitted to the United States Senate in November 1932 and hearings continued until a vote was taken on March 14, 1934. The majority voted in favor of the treaty, but it failed to gain the necessary two-thirds vote for ratification. Subsequent attempts between the governments in the 1930s to forge an agreement came to naught due to opposition by the Ontario government of Mitchell Hepburn, and that of Quebec.. In 1936, John C. Beukema, head of the Great Lakes Harbors Association and a member of the Great Lakes Tidewater Commission, was among a delegation of eight from the Great Lakes states to meet at the White House with President Franklin Delano Roosevelt to get his support of the Seaway concept. 
Beukema and St. Lawrence Seaway proponents were convinced that such a nautical link would lead to development of the communities and economies of the Great Lakes region by enabling ocean-going ships. In this period, grain exports to Europe were highly important to the national economy, along with other commodities. The negotiations on the treaty resumed in 1938 and by January 1940, substantial agreement was reached between Canada and the United States. By 1941, President Roosevelt and Prime Minister King made an executive agreement to build the joint hydro and navigation works, but this failed to receive the assent of Congress. Proposals for the seaway were met with resistance; primary opposition came from interests representing existing harbors on the Atlantic and Gulf coasts and internal waterways, as well as from the railroads associations. The railroads carried freight and goods between the coastal ports and the Great Lakes cities. 
In the post-1945 years, proposals to introduce tolls to the Seaway were not sufficient to gain support by the U.S. Congress for the project. Growing impatient, and with Ontario desperate for the power to be generated by hydro-electricity, Canada began to consider "going it alone." This seized the imagination of Canadians, engendering a groundswell of St. Lawrence nationalism. Canadian Prime Minister Louis St. Laurent advised President Harry S. Truman on September 28, 1951 that Canada was unwilling to wait for the United States and would build a seaway alone; the Canadian Legislature authorized the founding of the St. Lawrence Seaway Authority on December 21 of that year. Fueled by this support, Laurent's administration decided over the course of 1951 and 1952 to construct the waterway alone, combined with the Moses-Saunders Power Dam. (This became the joint responsibility of Ontario and New York: as a hydro-power dam would change the water levels, it required bilateral cooperation). 
The International Joint Commission issued an order of approval for joint construction of the dam in October 1952. Senate debate on the bill began on January 12, 1953, and the bill emerged from the House of Representatives Committee of Public Works on February 22, 1954. It received approval by both the Senate and the House by May 1954. The first positive action to enlarge the seaway was taken on May 13, 1954 when President Dwight D. Eisenhower signed the Wiley-Dondero Act to authorize joint construction and to establish the St. Lawrence Seaway Development Corporation as the US authority. The need for cheap haulage of Quebec - Labrador iron ore was one of the arguments that finally swung the balance in favor of the seaway. Ground-breaking ceremonies took place on August 10, 1954. That year John C. Beukema was appointed by Eisenhower to the five-member St. Lawrence Seaway Advisory Board.
In May 1957, the Connecting Channels Project was begun by the United States Army Corps of Engineers. By 1959, Beukema was on board the U.S. Coast Guard Cutter "Maple" for the first trip through the U.S. locks that opened up the Great Lakes to ocean-going ships. On April 25, 1959, large, deep-draft, ocean vessels began streaming to the heart of the North American continent through the seaway, a project which had been supported by every administration from Woodrow Wilson through Eisenhower.
In the United States, Dr. N.R. Danelian (who was the Director of the 13-volume St. Lawrence Seaway Survey in the U.S. Department of Navigation (1932–1963)), worked with the U.S. Secretary of State on Canadian-United States issues regarding the Seaway, persevering through 15 years to gain passage by Congress of the Seaway Act. He later became President of the Great Lakes St. Lawrence Association to promote Seaway development to benefit the American Heartland. The Seaway was heavily promoted by the Eisenhower administration, who were concerned with the its locus of control.
The seaway opened in 1959 and cost C$470 million, $336.2 million of which was paid by the Canadian government. Queen Elizabeth II, Queen of Canada and President Dwight D. Eisenhower formally opened the Seaway with a short cruise aboard Royal Yacht "Britannia" after addressing crowds in St. Lambert, Quebec. 22,000 workers were employed at one time or another on the project, a 2,300-mile-long superhighway for ocean freighters. Port of Milwaukee director Harry C. Brockel forecast just before the Seaway opened in 1959 that "The St. Lawrence Seaway will be the greatest single development of this century in its effects on Milwaukee's future growth and prosperity." Lester Olsen, president of the Milwaukee Association of Commerce, said, "The magnitude and potential of the St. Lawrence Seaway and the power project stir the imagination of the world."
The Port of Montreal, which is officially the Eastern inlet to the Seaway, has welcomed ships year-round since 1964. The first modern container vessel was launched in 1956. By the 1970s, the container ships that dominate shipping in the 21st century had begun to change the industry, dramatically altering the jobs of remaining longshoremen and creating new labor union issues.
The seaway's opening is often credited with making the Erie Canal obsolete, and causing the severe economic decline of several cities along the canal in Upstate New York. By the turn of the 20th century, the Erie Canal had already been largely supplanted by the railroads, which had been constructed across New York and could carry freight more quickly and cheaply. The economic decline of Upstate New York was precipitated by numerous factors, only some of which had to do with the St. Lawrence Seaway.
Since 1970 a new foreign invasive species has been discovered along the Seaway and in the Great Lakes about every six months. Researchers have identified overseas ships as the carriers for nearly 70% of the species of these invasions. In 1988, the zebra mussel was noticed, and regulations were soon put in place to mandate the use salt-water ballast, such as the National Invasive Species Act. But a loophole in the regulations was not closed until the early 2000s, and the zebra mussels have caused enormous damage. Another invasive species introduced via the Seaway is the Asian carp. Ballast water can also be a source of biohazards, and one researcher says that the effects of the disposal of ballast water in this system has been "one the great ecological disasters of all time". The International Maritime Organisation has a Ballast Water Management Convention but, 10 years after the Convention was approved, it had been ratified by only 40 nations which accounted for 30% of world shipping tonnage. By 2014 it was still not in force.
Under the Canada Marine Act (1998), the Canadian portions of the Seaway were set up with a non-profit corporate structure; this legislation also introduced changes to the federal Ports.
Great Lakes and Seaway shipping generates $3.4 billion in business revenue annually in the US. In 2002, ships moved 222 million tons of cargo per year. Overseas shipments, mostly of inbound steel and outbound grain, accounted for 15.4 million tons, 6.9% of the total cargo moved. In 2004, Seaway grain exports accounted for about 3.6% of the US' overseas grain shipments, according to the U.S. Grains Council. In a typical year, Seaway steel imports account for around 6% of the U.S. annual total. The toll revenue obtained from ocean vessels is about 25-30% of cargo revenue. The Port of Duluth shipped just over 2.5 million metric tons of grain, which is less than the port typically moved in the decade before the Seaway opened Lake Superior to deep-draft oceangoing vessels in 1959. 
International changes have affected shipping through the Seaway. Europe is no longer a major grain importer; big US export shipments are now going to South America, Asia and Africa. These destinations make Gulf and West Coast ports more critical to 21st-century grain exports. Referring to the Seaway project, a retired Iowa State University economics professor who specialized in transportation issues said, "It probably did make sense, at about the time it (the Seaway) was constructed and conceived, but since then everything has changed."
Certain Seaway users have been concerned about the low water levels of the Great Lakes that have occurred since 2010.
Expansion proposal.
The Panama Canal had been completed in 1914 and also serves ocean-going traffic. In the 1950s Seaway designers chose not to build the locks to match the Panama size, 1,000 feet long by 110 feet wide. Instead, they built them to match the smaller locks of Welland Canal, which opened in 1932, and are 766 feet long by 80 feet wide. The US Army Corps of Engineers did a study to expand the St. Lawrence Seaway in the near future, but it was scrapped in 2011 due to tight budgets.
In the long term, the Seaway is planned for expansion in 2030. The expansion would allow outsize container ships to travel into the Great Lakes. The maximum height clearance would be 150 feet because of the Mackinac Bridge, Ambassador Bridge, Blue Water Bridge, and the New International Trade Crossing to be completed in 2015. Maximum water draft would be 35 or 36 feet compared to 27 feet now. The Port of Montreal, at the eastern end of the St. Lawrence Seaway, allows 36 foot drafts in the Estuary. The locks would be 1000 × 105 feet.
Compared to the Panama Canal or the Panamax, the allowable ship sizes would not be as large on the New SeawayMax. The Panamax allows for ships that are 190 feet above the water line (air draft) and a water draft of 41.2 feet max. Ship length is 50 feet shorter and width is the same size as the expansion proposal.
Locks in the Saint Lawrence River.
There are seven locks in the Saint Lawrence River portion of the Seaway. From downstream to upstream they are:
Locks in the Welland Canal.
There are eight locks on the Welland Canal.
Lock, channel dimensions and other useful data.
The size of vessels that can traverse the seaway is limited by the size of locks. Locks on the St. Lawrence and on the Welland Canal are 766 ft long, 80 ft wide, and 30 ft deep. The maximum allowed vessel size is slightly smaller: 740 ft long, 78 ft wide, and 26.5 ft deep. Many vessels designed for use on the Great Lakes following the opening of the seaway were built to the maximum size permissible by the locks, known informally as Seawaymax or Seaway-Max. Large vessels of the lake freighter fleet are built on the lakes and cannot travel downstream beyond the Welland Canal. On the remaining Great Lakes, these ships are constrained only by the largest lock on the Great Lakes Waterway, the Poe Lock at the Soo Locks (at Sault Ste. Marie), which is 1200 ft long, 110 ft wide and 32 ft deep.
A vessel's draft is another obstacle to passage on the seaway, particularly in connecting waterways such as the St. Lawrence River. The depth in the channels of the seaway is 41 ft (Panamax-depth) downstream of Quebec City, 35 ft between Quebec City and Deschaillons, 37 ft to Montreal, and 27 ft upstream of Montreal. Channel depths and limited lock sizes mean that only 10% of current ocean-going ships, which have been built much larger than in the 1950s, can traverse the entire seaway. Proposals to expand the seaway, dating from as early as the 1960s, have been rejected since the late 20th century as too costly. In addition, researchers, policymakers and the public are much more aware of the environmental issues that have accompanied Seaway development and are reluctant to open the Great Lakes to more invasions of damaging species, as well as associated issues along the canals and river. Questions have been raised as to whether such infrastructure costs could ever be recovered. Lower water levels in the Great Lakes have also posed problems for some vessels in recent years, and pose greater issues to communities, industries and agriculture in the region.
While the seaway is currently (2010) mostly used for shipping bulk cargo, the possibility of its use for large-scale container shipping is under consideration as well. If the expansion project goes ahead, feeder ships would take containers from the port of Oswego on Lake Ontario in upstate New York to Melford International Terminal in Nova Scotia for transfer to larger ocean-going ships.
A useful website hosts measurements of wind, water levels and water temperatures. A real-time interactive map of Seaway Locks, Vessels and Ports is available at . The NOAA-funded Great Lakes Water Level Dashboard compiles statistics on water depth at various points along the Seaway.
Ecology.
To create a navigable channel through the Long Sault rapids and to allow hydroelectric stations to be established immediately upriver from Cornwall, Ontario and Massena, New York, Lake St. Lawrence was created behind a dam. It required the condemnation and acquisition by the government of all the properties of six villages and three hamlets in Ontario; these are now collectively known as "The Lost Villages". The area was flooded on 1 July 1958, creating the lake. There was also inundation on the New York side of the border, but no communities were affected. A notable adverse environmental effect of the operation of the Seaway has been the introduction of numerous invasive species of aquatic animals into the Great Lakes Basin. The zebra mussel has been most damaging in the Great Lakes and through its invasion of related rivers, waterways and city water facilities. 
The Seaway also provides opportunities for outdoor recreation, such as boating, camping, fishing, and scuba diving. Of note, The Old Power House near Lock 23 (near Morrisburg, Ontario) became an attractive site for scuba divers. The submerged stone building has become covered with barnacles and is home to an abundance of underwater life.
The Seaway also provides a number of divable shipwrecks within recreational scuba limits (shallower than 130 ft) The region also offers technical diving with some wrecks lying at 240 ft. Surprisingly, the water temperature can be as warm as 75 F during the mid to late summer months. The first 10 ft of Lake Ontario is warmed and enters the St. Lawrence river as the fast-moving water body has no thermocline circulation.
On 12 July 2010, "Richelieu" (owned by Canada Steamship Lines) ran aground after losing power near the Côte-Sainte-Catherine lock. The grounding punctured a fuel tank, spilling an estimated 200 tonnes of diesel fuel, covering approximately 500 m2. The Seaway and the lock were shut down to help contain the spill.
International trade and tourism.
The seaway is important for American and Canadian international trade. The seaway handles 40 to 50 million annual tons of cargo. About 50% of the cargo carried travels to and from international ports in Europe, Middle East and Africa. The rest comprises coastal trade, or short sea shipping, between various American and Canadian ports. Among international shippers are found:
The Saint Lawrence seaway (along with ports in Quebec) is the main route for Ontario grain exports to overseas markets. Its fees are publicly known, and were limited in 2013 to an increase of 3%. A trained Pilot is required for any foreign trade vessel, and the employment of these skilled personnel follows the law of supply and demand. A set of rules and regulations are available to help transit.
Commercial vessel transit information on the U.S. Saint Lawrence Seaway Development Corporation website.
Since 1997, international cruise liners have been known to transit the Seaway. The Hapag-Lloyd "Christopher Columbus" carried 400 passengers to Duluth, Minnesota that year. Since then, the number of annual Seaway cruising passengers has increased to 14,000.
Every year, more than 2,000 recreational boats, of more than 20 ft and one ton, transit the Seaway. The tolls have been fixed for 2013 at $30 per lock, except for the Welland Canal, where $30 pays for all eight locks between Lake Erie and Lake Ontario. Lockages are scheduled 12 hours a day between the hours of 07:00 and 19:00 from June 15 to September 15.
A list of organisations that serve the Seaway in some fashion, such as Chambers of Commerce and Municipal or Port authorities, . A 56-page electronic "Great Lakes St. Lawrence Seaway System" Directory is published by Harbor House Publishers.
Map.
"Map of the North American Great Lakes and the St. Lawrence Seaway from 1959," depicting the entire length beginning at the Gulf of Saint Lawrence in the east to the western-most terminus at Lake Superior. This map is in the public domain and is available at Wikimedia Commons in several resolutions.

</doc>
<doc id="26909" url="http://en.wikipedia.org/wiki?curid=26909" title="Silvio Berlusconi">
Silvio Berlusconi

Silvio Berlusconi (]; born 29 September 1936) is an Italian media tycoon and politician who served three times as Prime Minister of Italy, from 1994 to 1995, 2001 to 2006 and 2008 to 2011. Berlusconi is the controlling shareholder of Mediaset and owner of the Italian football club A.C. Milan since 1986. He is nicknamed "Il Cavaliere" (The Knight) for his Order of Merit for Labour, although he voluntarily resigned from this order in March 2013.
In 2015, "Forbes" magazine ranked him as the 141st richest man in the world with a net worth of US$8.0 billion. In 2009, "Forbes" ranked him 12th in the List of The World's Most Powerful People due to his domination in Italian politics.
Berlusconi was Prime Minister for nine years in total, making him the longest-serving post-war Prime Minister of Italy, and the third longest-serving since the Unification of Italy, after Benito Mussolini and Giovanni Giolitti. He was the leader of the centre-right party Forza Italia from 1994 to 2009, and its successor party The People of Freedom from 2009 to 2013. Since November 2013, he is acting as the current leader of a revived Forza Italia.
After serving nearly 19 years as member of the Chamber of Deputies, Italy's lower house, after the 2013 general election he became a member of the Senate.
On 1 August 2013, he was convicted of tax-fraud by the final appeal instance, Court of Cassation (of which three years are automatically pardoned) along with a public office ban for two years. As his age exceeds 70 years, he will be exempted from direct imprisonment, and instead serve his sentence by doing unpaid social community work. Because of being sentenced to a gross imprisonment for more than two years, a new Italian anticorruption law made the Italian Senate expel and bar him from serving any legislative office for six years. Berlusconi has pledged to stay leader of Forza Italia throughout the period where he serves his imprisonment sentence and public office ban.
Family background and personal life.
Berlusconi was born in Milan in 1936, where he was raised in a middle-class family. His father, Luigi Berlusconi (1908–1989), was a bank employee, and his mother, Rosa Bossi (1911–2008), a housewife. Silvio was the first of three children; he had a sister, Maria Francesca Antonietta Berlusconi (1943–2009), and has a brother, Paolo Berlusconi (born 1949).
After completing his secondary school education at a Salesian college, he studied law at the Università Statale in Milan, graduating (with honours) in 1961, with a thesis on the legal aspects of advertising. Berlusconi was not required to serve the standard one-year stint in the Italian army which was compulsory at the time. During his university studies, he was an upright bass player in a group formed with the now Mediaset Chairman and amateur pianist Fedele Confalonieri and occasionally performed as a cruise ship crooner. In later life, he wrote AC Milan's anthem with the Italian music producer and pop singer Tony Renis and Forza Italia's anthem with the opera director Renato Serio. With the Neapolitan singer Mariano Apicella, he wrote two Neapolitan song albums: "Meglio 'na canzone" in 2003 and "L'ultimo amore" in 2006.
In 1965, he married Carla Elvira Dall'Oglio, and they had two children: Maria Elvira, better known as Marina (born 1966), and Pier Silvio (born 1969). By 1980, Berlusconi had established a relationship with the actress Veronica Lario (born Miriam Bartolini), with whom he subsequently had three children: Barbara (born 1984), Eleonora (born 1986) and Luigi (born 1988). He was divorced from Dall'Oglio in 1985, and married Lario in 1990. By this time, Berlusconi was a well-known entrepreneur, and his wedding was a notable social event. One of his best men was Bettino Craxi, a former prime minister and leader of the Italian Socialist Party. In May 2009, Lario announced that she was to file for divorce.
On 28 December 2012, Berlusconi was ordered to pay his ex-wife Veronica Lario $48 million a year in a divorce settlement that was filed Christmas Day, and he will keep the $100 million house they live in with their three children.
Business career.
Milano Due.
Berlusconi's business career began in construction. In the late 1960s, he built Milano Due (Italian for "Milan Two"), 4,000 residential apartments east of Milan. The profits from this venture provided the seed money for his advertising agency.
Telemilano.
Berlusconi first entered the media world in 1973, by setting up a small cable television company, Telemilano, to service units built on his Segrate properties. It began transmitting in September the following year. After buying two further channels, Berlusconi relocated the station to central Milan in 1977 and began broadcasting over the airwaves.
Fininvest.
In 1978, Berlusconi founded his first media group, Fininvest, and joined the Propaganda Due masonic lodge. In the five years leading up to 1983 he earned some 113 billion Italian lire (€58.3 million). The funding sources are still unknown because of a complex system of holding companies, despite investigations conducted by various state attorneys.
Fininvest soon expanded into a country-wide network of local TV stations which had similar programming, forming, in effect, a single national network. This was seen as breaching the Italian public broadcaster RAI's statutory monopoly by creating a national network, which was later abolished. In 1980, Berlusconi founded Italy's first private national network, Canale 5, followed shortly thereafter by Italia 1, which was bought from the Rusconi family in 1982, and Rete 4, which was bought from Mondadori in 1984.
Berlusconi created the first and only Italian commercial TV empire. He was assisted by his connections to Bettino Craxi, secretary-general of the Italian Socialist Party and also prime minister of Italy at that time, whose government passed, on 20 October 1984, an emergency decree legalising the nationwide transmissions made by Berlusconi's television stations. This was in response to judgements on 16 October 1984, in Turin, Pescara and Rome, enforcing a law which previously restricted nationwide broadcasting to RAI, that had ordered these private networks to cease transmitting.
After political turmoil in 1985, the decree was approved definitively. But for some years, Berlusconi's three channels remained in a legal limbo, and were not allowed to broadcast news and political commentary. They were elevated to the status of full national TV channels in 1990, by the so-called Mammì law.
In 1995, Berlusconi sold a portion of his media holdings, first to the German media group Kirch Group (now bankrupt) and then by public offer. In 1999, Berlusconi expanded his media interests by forming a partnership with Kirch called the "Epsilon MediaGroup".
On 9 July 2011, a Milan court ordered Fininvest to pay 560 million euros in damages to Compagnie Industriali Riunite in a long-running legal dispute.
Political career.
Berlusconi rapidly rose to the forefront of Italian politics in January 1994. He was elected to the Chamber of Deputies for the first time and appointed as Prime Minister following the 1994 parliamentary elections, when Forza Italia gained a relative majority a mere three months after having been launched. However, his cabinet collapsed after nine months, due to internal disagreements among the coalition parties. In the April 1996 snap parliamentary elections, Berlusconi was defeated by the centre-left candidate Romano Prodi. In the May 2001 parliamentary elections, he was again the centre-right candidate for Prime Minister and won against the centre-left candidate Francesco Rutelli. Berlusconi then formed his second and third cabinets, until 2006. Berlusconi was leader of the centre-right coalition in the April 2006 parliamentary elections, which he lost by a very narrow margin, his opponent again being Romano Prodi. He was re-elected in the parliamentary elections of April 2008 following the collapse of Prodi's government and sworn in for a third time as Prime Minister on 8 May 2008.
After losing his majority in parliament amid growing fiscal problems related to the European debt crisis, Berlusconi resigned as Prime Minister on 16 November 2011. In February 2013 Berlusconi has led the People of Freedom and its right-wing allies in the campaign for the parliamentary elections. Although he initially planned to run for a fifth term as Prime Minister, as part of the agreement with the Lega Nord he would instead plan to lead the coalition without becoming Prime Minister. Berlusconi's Centre-right coalition gained 29% of votes, ranking second, after the centre-left coalition Italy Common Good led by Pier Luigi Bersani. Now the PdL is supporting the government of Enrico Letta, together with the Democratic Party and the centrist Civic Choice, of the former Prime Minister Mario Monti.
He was criticised for his electoral coalitions with right wing populist parties (the Lega Nord and the National Alliance) and for apologetic remarks about Mussolini, though he also officially apologised for Italy's actions in Libya during colonial rule. While in power, Berlusconi maintained ownership of Mediaset, the largest media company in Italy, and was criticised for his dominance of the Italian media. His leadership was also undermined by sex scandals.
The beginnings.
Berlusconi's political career began in 1994, when he entered politics, reportedly admitting to Indro Montanelli and Enzo Biagi that he was forced to do so to avoid imprisonment. He subsequently served as Prime Minister of Italy from 1994 to 1995, 2001 to 2006, and 2008 to 2011. His career was racked with controversies and trials; amongst these was his failure to honour his promise to sell his personal assets in Mediaset, the largest television broadcaster in Italy, in order to dispel any perceived conflicts of interest.
In the early 1990s, the Pentapartito () – the five governing parties, Christian Democracy ("Democrazia Cristiana"), the Italian Socialist Party, the Italian Social-Democratic Party, the Italian Republican Party and the Italian Liberal Party – lost much of their electoral strength almost overnight due to a large number of judicial investigations concerning the financial corruption of many of their foremost members (see the Mani Pulite affair). This led to a general expectation that upcoming elections would be won by the Democratic Party of the Left, the heirs to the former Italian Communist Party, and their Alliance of Progressives coalition - unless an alternative arose. On 26 January 1994, Berlusconi announced his decision to enter politics, ("enter the field", in his own words) presenting his own political party, Forza Italia, on a platform focused on defeating "the Communists". His political aim was to convince the voters of the Pentapartito, who were shocked and confused by Mani Pulite scandals, that Forza Italia offered both a fresh uniqueness and the continuation of the pro-western free market policies followed by Italy since the end of the Second World War. Shortly after he decided to enter the political arena, investigators into the Mani Pulite affair were said to be close to issuing warrants for the arrest of Berlusconi and senior executives of his business group. During his political career Berlusconi repeatedly stated that the Mani Pulite investigations were led by communist prosecutors who wanted to establish a soviet-style government in Italy.
1994 electoral victory.
In order to win the March 1994 general election, Berlusconi formed two separate electoral alliances: Pole of Freedoms ("Polo delle Libertà") with the Lega Nord ("Northern League") in northern Italian districts, and another, the Pole of Good Government ("Polo del Buon Governo"), with the National Alliance ("Alleanza Nazionale"; heir to the Italian Social Movement) in central and southern regions. In a pragmatic move, he did not ally with the latter in the North because the League disliked them. As a result, Forza Italia was allied with two parties that were not allied with each other.
Berlusconi launched a massive campaign of electoral advertisements on his three TV networks, grooming with seminars and screen tests his top advertisement salesmen, of whom 50, subsequently elected though devoid of legislative experience, came from his own advertising company alone. He subsequently won the elections, with Forza Italia garnering 21% of the popular vote, the highest percentage of any single party. One of the most significant promises that he made in order to secure victory was that his government would create "one million more jobs". He was appointed Prime Minister in 1994, but his term in office was short because of the inherent contradictions in his coalition: the League, a regional party with a strong electoral base in northern Italy, was at that time fluctuating between federalist and separatist positions, and the National Alliance was a nationalist party that had yet to renounce neo-fascism at the time.
Fall of the Berlusconi I cabinet.
In December 1994, following the leaking to the press of news of a fresh investigation by Milan magistrates, Umberto Bossi, leader of the Lega Nord, left the coalition claiming that the electoral pact had not been respected, forcing Berlusconi to resign from office and shifting the majority's weight to the centre-left. Lega Nord also resented the fact that many of its MPs had switched to Forza Italia, allegedly lured by promises of more prestigious portfolios. In 1998, various articles attacking Berlusconi were published by Lega Nord's official newspaper (www.lapadania.it), with titles such as "La Fininvest è nata da Cosa Nostra" – "Fininvest (Berlusconi's principal company) was founded by the Mafia".
Berlusconi remained as caretaker prime minister for a little over a month, until his replacement by a technocratic government headed by Lamberto Dini. Dini had been a key minister in the Berlusconi cabinet, and Berlusconi said the only way he would support a technocratic government would be if Dini headed it. In the end, however, Dini was only supported by most opposition parties but not by Forza Italia and Lega Nord. In 1996, Berlusconi and his coalition lost the elections and were replaced by a centre-left government led by Romano Prodi.
Electoral victory of 2001.
In 2001, Berlusconi ran again, as leader of the right-wing coalition House of Freedoms (Italian: "La Casa delle Libertà"), which included the Union of Christian and Centre Democrats, the Lega Nord, the National Alliance and other parties. Berlusconi's success in the May 2001 general election led to him becoming Prime Minister once more, with the coalition receiving 45.4% of the vote for the Chamber of Deputies and 42.5% for the Senate.
On the television interviews programme "Porta a Porta", during the last days of the electoral campaign, Berlusconi created a powerful impression on the public by undertaking to sign a so-called "Contratto con gli Italiani" (English: Contract with the Italians), an idea copied outright by his advisor Luigi Crespi from Newt Gingrich's Contract with America introduced six weeks before the 1994 US Congressional election. This was considered to be a creative masterstroke in his 2001 bid for prime ministership. Berlusconi committed in this contract to improve several aspects of the Italian economy and life. Firstly, he undertook to simplify the complex tax system by introducing just two tax rates (33% for those earning over 100,000 euros, and 23% for anyone earning less than that figure: anyone earning less than 11,000 euros a year would not be taxed). Secondly, he promised to halve the unemployment rate. Thirdly, he undertook to finance and develop a massive new public works programme. Fourthly, he promised to raise the minimum monthly pension rate to 516 euros. Fifthly, he would suppress the crime wave by introducing police officers to patrol all local zones and areas in Italy's major cities. Berlusconi undertook to refrain from putting himself up for re-election in 2006, if he failed to honour at least four of these five promises.
The Berlusconi II cabinet.
Opposition parties claim Berlusconi was not able to achieve the goals he promised in his "Contratto con gli Italiani". Some of his partners in government, especially the National Alliance and the Union of Christian and Centre Democrats, admitted the Government fell short of the promises made in the agreement, attributing the failure to an unforeseeable downturn in global economic conditions. Berlusconi himself consistently asserted that he achieved all the goals of the agreement, and said his Government provided "un miracolo continuo" (a continuous miracle) that made all 'earlier governments pale' (by comparison). He attributed the widespread failure to recognize these achievements to a campaign of mystification and vilification in the printed media, asserting that 85% of newspapers were opposed to him. Luca Ricolfi, an independent analyst, held that Berlusconi had managed to deliver only one promise out of five, the one concerning minimum pension levels. The other four promises were not, in Luca Ricolfi's view, honoured, in particular, the undertakings on the tax simplification and the reduction of crime.
Subsequent elections.
House of Freedoms did not do as well in the 2003 local elections as it did in the 2001 national elections. In common with many other European governing groups, in the 2004 elections of the European Parliament, gaining 43.37% support. Forza Italia's support was also reduced from 29.5% to 21.0% (in the 1999 European elections Forza Italia had 25.2%). As an outcome of these results the other coalition parties, whose electoral results were more satisfactory, asked Berlusconi and Forza Italia for greater influence in the government's political line.
The Berlusconi III cabinet.
In the 2005 regional elections (3 April/4 April 2005), the centre-left gubernatorial candidates won in 12 out of 14 regions where control of local governments and governorships was at stake. Berlusconi's coalition held only two of the regional bodies (Lombardy and Veneto) up for re-election. Three parties, Union of Christian and Centre Democrats, National Alliance and New Italian Socialist Party, threatened to withdraw from the Berlusconi government. Berlusconi after some hesitation, then presented to the President of the Republic a request for the dissolution of his government on 20 April 2005. On 23 April, he formed a new government with the same allies, reshuffling ministers and amending the government programme. A key point demanded by the Union of Christian and Centre Democrats (and to a lesser extent by National Alliance) for their continued support was that the strong focus on tax reduction central to the government's ambitions be changed.
Attempt to reform the Italian constitution.
A key point in the Berlusconi government's programme was a planned reform of the Italian Constitution, which Berlusconi considered to be 'inspired by the Soviets', an issue the coalition parties themselves initially had significantly different opinions about. The Lega Nord insisted on a federalist reform (devolution of more power to the regions) as a condition for remaining in the coalition. The National Alliance party pushed for a so-called 'strong premiership' (more powers to the executive), intended as a counterweight to any federalist reform, in order to preserve the integrity of the nation. The Union of Christian and Centre Democrats asked for a proportional electoral law that would not damage small parties, and was generally more willing to discuss compromises with the moderate wing of the opposition.
Difficulties in arranging a mediation caused some internal unrest in the Berlusconi government in 2003, but then they were mostly overcome and the law (comprising power devolution to the regions, Federal Senate and "strong premiership") was passed by the Senate in April 2004; it was slightly modified by the Chamber of Deputies in October 2004, and again on October 2005, and finally approved by the Senate on 16 November 2005, with a bare majority. Approval in a referendum is necessary in order to amend the Italian Constitution without a qualified two-thirds parliamentary majority. The referendum was held on 25–26 July 2006 and resulted in the rejection of the constitutional reform, refused by 61.3% of the voters.
The 2006 elections.
Operating under a new electoral law written unilaterally by the governing parties over strong criticism from the parliamentary opposition, the April 2006 general election was held. The results of this election handed Romano Prodi's centre-left coalition, known as The Union, (Berlusconi's opposition) a very thin majority: 49.8% against 49.7% for the centre-right coalition House of Freedoms in the Lower House, and a two-senator lead in the Senate (158 senators for The Union and 156 for the House of Freedoms). The Court of Cassation subsequently validated the voting procedures and determined that the election process was constitutional.
According to the new electoral rules, The Union, (nicknamed "The Soviet Union" by Berlusconi with a margin of only 25,224 votes (out of over 38 million voters), nevertheless won 348 seats (compared to 281 for the House of Freedoms) in the lower house as a result of a majority premium given to whichever coalition of parties was awarded more votes.
Ironically, this electoral law, approved shortly before the election by Berlusconi's coalition in an attempt to improve their chances of winning the election, led to the coalition's defeat and gave Prodi the chance to form a new cabinet. However, Prodi's coalition consisted of a large number of smaller parties. If only one of these nine parties that formed The Union withdrew its support to Prodi, his government would have collapsed. This situation was also the result of the new "diabolic" electoral system.
Centrist parties such as the Union of Christian and Centre Democrats immediately conceded The Union's victory, while other parties, like Berlusconi's Forza Italia and the Northern League, refused to accept its validity, right up until 2 May 2006, when Berlusconi submitted his resignation to President Ciampi.
2008 electoral victory.
In the run-up to the 2006 general election, there had been talk among some of the coalition members of the House of Freedoms about a possible merger into a "united party of moderates and reformers". Forza Italia, the National Alliance party of Gianfranco Fini, and the Union of Christian and Centre Democrats of Pier Ferdinando Casini all seemed interested in the project. Soon after the election, however, Casini started to distance his party from its historical allies.
On 2 December 2006, during a major demonstration of the centre-right in Rome against the government led by Romano Prodi, Berlusconi proposed the foundation of a ""Freedom Party", arguing that the people and voters of the different political movements aligned to the demonstration were all part of a "people of freedom".
On 18 November 2007, after claiming the collection of more than 7 million signatures (including that of Umberto Bossi) demanding that the President of the Republic Giorgio Napolitano call a fresh election, Berlusconi announced from the running board of a car in a crowded Piazza San Babila in Milan that Forza Italia would soon merge or transform into The People of Freedom party, also known as the PdL (Il Popolo della Libertà). Berlusconi also stated that this new political movement could include the participation of other parties. Both supporters and critics of the new party called Berlusconi's announcement "the running board revolution"".
After the sudden fall of the Prodi II Cabinet on 24 January, the break-up of The Union coalition and the subsequent political crisis (which paved the way for a fresh general election on April 2008), Berlusconi, Gianfranco Fini and other party leaders finally agreed on 8 February 2008 to form a joint list named "The People of Freedom" (Italian: "Il Popolo della Libertà"), allied with the Lega Nord of Umberto Bossi and with the Sicilian Movement for Autonomy of Raffaele Lombardo.
In the snap parliamentary elections held on 13/14 April 2008, this coalition won against Walter Veltroni's centre-left coalition in both houses of the Italian Parliament.
In the 315-member Senate of the Republic, Berlusconi's coalition won 174 seats to Veltroni's 134. In the lower house, Berlusconi's conservative bloc led by a margin of 9% of the vote: 46.5% (344 seats) to 37.5% (246 seats). Berlusconi capitalised on discontent over the nation's stagnating economy and the unpopularity of Prodi's government. His declared top priorities were to remove piles of trash from the streets of Naples and to improve the state of the Italian economy, which had underperformed the rest of the Eurozone for years. He also said he was open to working with the opposition, and pledged to fight tax evasion, reform justice and reduce public debt. He intended to reduce the number of Cabinet ministers to 12. Berlusconi and his ministers (Berlusconi IV Cabinet) were sworn in on 8 May 2008.
On 21 November 2008, the National Council of Forza Italia, chaired by Alfredo Biondi and attended by Berlusconi himself, dissolved Forza Italia and established The People of Freedom, whose inauguration took place on 27 March 2009, the 15th anniversary of Berlusconi's first electoral victory.
While Forza Italia had never held a formal party congress to formulate its rules, procedures, and democratic balloting for candidates and issues, (since 1994 three party conventions of Forza Italia have been held, all of them resolving to support Berlusconi and reelecting him by acclamation) on 27 March 2009, at the foundation congress of the People of Freedom political movement the statute of the new party was subject to a vote of approval. On 5,820 voting delegates, 5,811 voted in favour, 4 against and 5 abstained. During that political congress Berlusconi was elected as Chairman of the People of Freedom by handraising. According to the official minutes of the congress the result favoured Berlusconi, with 100 per cent of the delegates voting for him.
The People of Freedom split.
Between 2009 and 2010, Gianfranco Fini, former leader of the national conservative National Alliance (AN) and President of the Italian Chamber of Deputies, became a vocal critic of the leadership of Berlusconi. Fini departed from party's majority line on several issues but, most of all, he was a proponent of a more structured party organisation. His criticism was aimed at the leadership style of Berlusconi, who tends to rely on his personal charisma to lead the party from the centre and supports a less structured form of party, a movement-party that organises itself only at election times.
On 15 April 2010, an association named Generation Italy was launched in order to better represent Fini's views within the party and push for a different party organisation. On 22 April 2010 the National Committee of the PdL convened in Rome for the first time in a year. The conflict between Fini and Berlusconi was covered live on television. At the end of the day, a resolution proposed by Berlusconi's loyalists was put before the assembly and approved by a landslide margin. On 29 July 2010, the party executive released a document in which Fini was described as "incompatible" with the political line of the PdL and unable to perform his job of President of the Chamber of Deputies in a neutral way. Berlusconi asked Fini to step down, and the executive proposed the suspension from party membership of three MPs who had harshly criticized Berlusconi and accused some party members of criminal offences. As response, Fini and his followers formed their own groups in both chambers under the name of Future and Freedom (FLI). It was soon clear that FLI would leave the PdL and become an independent party. On 7 November, during a convention in Bastia Umbra, Fini asked Berlusconi to step down from his post of Prime Minister and proposed a new government including the Union of the Centre (UdC). A few days later, the four FLI members of the government resigned. On 14 December, FLI voted against Berlusconi in a vote of confidence in the Chamber of Deputies, a vote nonetheless won by Berlusconi by 314 to 311.
In May 2011, PdL suffered a big blow in local elections. Particularly painful was the loss of Milan, Berlusconi's hometown and party stronghold. In response to this and to conflicts within party ranks, Angelino Alfano, the Justice minister, was chosen as national secretary in charge of reorganising and renewing the party. The appointment of 40-year old Alfano, a former Christian Democrat and later leader of Forza Italia in Sicily, was unanimously decided by the party executive. On 1 July, the National Council modified the party's constitution and Alfano was elected secretary almost unanimously. In his acceptance speech, Alfano proposed the introduction of primaries.
Resignation.
On 10 October, the Chamber of Deputies rejected the law on the budget of the State proposed by the government. As a result of this event Berlusconi moved for a confidence vote in the Chamber on 14 October, he won the vote with just 316 votes to 310, minimum required to retain a majority. An increasing number of Deputies continued to cross the floor and join the opposition and on 8 November the Chamber approved the law on the budget of the State previously rejected but with only 308 votes, while opposition parties didn't participate in the vote to highlight that Berlusconi lost his majority. After the vote, Berlusconi announced his resignation after Parliament passed economic reforms. Among other things, his perceived failure to tackle Italy's debt crisis with an estimated debt sum of €1.9 trillion ($2.6 trillion) had urged Berlusconi to leave office. The popularity of this decision was reflected in the fact that while he was resigning crowds sang the hallelujah portion of George Frederick Handel's "Messiah", complete with some vocal accompaniment; there was also dancing in the streets outside the Quirinal Palace, the official residence of the President of Italy, where Berlusconi went to tender his resignation.
The austerity package was passed, it will raise €59.8 billion in savings from spending cuts and tax raises, including freezing public-sector salaries until 2014 and gradually increasing the retirement age for women in the private sector from 60 in 2014 to 65 in 2026. The resignation also came at a difficult time for Berlusconi, as he was involved in numerous trials for corruption, fraud and sex offences. He was often found guilty in lower courts but used loopholes in Italy's legal system to evade incarceration.
Berlusconi had also failed to meet some of his pre-election promises and had failed to prevent economic decline and introduce serious reforms. Many believed that the problems and doubts over Berlusconi's leadership and his coalition were one of the factors that contributed to market anxieties over an imminent Italian financial disaster, which could have a potentially catastrophic effect on the 17-nation eurozone and the world economy. Many critics of Berlusconi accused him of using his power primarily to protect his own business ventures. Umberto Bossi, leader of the Northern League, a partner in Berlusconi's right-wing coalition, was quoted as informing reporters outside parliament, "We asked the prime minister to step aside."
On 12 November 2011, after a final meeting with his cabinet, Berlusconi met Italian President Giorgio Napolitano at the Palazzo del Quirinale to tend his resignation. As he arrived at the presidential residence, a hostile crowd gathered with banners shouting insults at Berlusconi and throwing coins at the car. After his resignation, the booing and jeering continued as he left in his convoy, with the public shouting words such as "buffoon", "dictator" and "mafioso". Following Berlusconi's resignation, Mario Monti formed a new government that would remain in office until the next scheduled elections in 2013. On 16 November, Monti announced that he had formed a Cabinet and was sworn in as Prime Minister of Italy, also appointing himself as Minister of Economy and Finances.
2013 general election.
In December 2012, Berlusconi announced on television that he would run again to become Prime Minister. Berlusconi said the platform his party would run on includes opposition to Monti's economic performance, which he said put Italy into a "recessive spiral without end." He also told the media, on the sidelines of AC Milan's practice session (the football club he owns along with Mediaset, the largest media outlet in the country): "I race to win. To win, everyone said there had to be a tested leader. It's not that we did not look for one. We did, and how! But there isn't one...I'm doing it out of a sense of responsibility."
On 7 January 2013, Berlusconi announced he had penned a coalition agreement (Centre-right coalition) with Lega Nord (LN); as part of it, PdL will support Roberto Maroni's bid for the presidency of Lombardy, and he will run as "leader of the coalition", but suggested he could accept a role as Minister of Economy under a cabinet headed by another People of Freedom member, such as Angelino Alfano. Later that day, LN leader Maroni confirmed his party will not support a new candidacy of Berlusconi as Prime Minister in the case of an electoral win.
Berlusconi's coalition gained 29.1% of votes and 125 seats in the Chamber of Deputies, 30.7% of votes and 117 seats in the Senate.
In April 2013, Berlusconi's People of Freedom announced his support to the government of Enrico Letta, together with the Democratic Party and the centrist Civic Choice, of former Prime Minister Mario Monti.
Refoundation of Forza Italia.
In June 2013, Berlusconi announced the refoundation of his first party Forza Italia. On 18 September the new party was launched and officially founded on 16 November. After the foundation of Forza Italia, Berlusconi announced that his new party will be at the opposition of the Grand coalition government of Enrico Letta; but the new political position taken by Berlusconi caused dissent in the movement, and the "governmental" wing of Forza Italia, led by the Vice-Prime Minister and Minister of Interior Angelino Alfano split from FI and founded a Christian democratic party called New Centre-Right, which still supported the government.
Foreign policy.
Berlusconi and his cabinets have had a strong tendency to support American foreign policies, despite the policy divide between the U.S. and many founding members of the European Union (Germany, France, Belgium) during the Bush administration. Under Berlusconi's lead, the Italian Government also shifted its traditional position on foreign policy from being the most pro-Arab western government towards a greater friendship with Israel and Turkey than in the past. This resulted in a rebalancing of relations between all the Mediterranean countries, to reach "equal closeness" with them. Berlusconi is one of the strongest supporters of Turkey's application to accede to the European Union. In order to support Turkey's application the Italian Premier invited Prime Minister Erdoğan to take part in a meeting of the European leaders of Denmark, France, Germany, the Netherlands, Spain, Sweden, and the United Kingdom, gathered in L'Aquila for the 2009 G8 summit. Italy, with Berlusconi in office, became a solid ally of the United States due to his support in the War in Afghanistan and the Iraq War following the 2003 invasion of Iraq in the War on Terror.
Berlusconi, in his meetings with United Nations Secretary-General Kofi Annan and U.S. President George W. Bush, said that he pushed for "a clear turnaround in the Iraqi situation" and for a quick handover of sovereignty to the government chosen by the Iraqi people. Italy had some 3,200 troops deployed in Southern Iraq, the third largest contingent there after the American and British forces. When Romano Prodi became Premier, Italian troops were gradually withdrawn from Iraq in the second half of 2006 with the last soldiers leaving the country in December of that year.
Relations with Russia.
In November 2007, Italy's state-owned energy company Eni signed an agreement with Russian state-owned Gazprom to build the South Stream pipeline. Investigating Italian parliament members discovered that Central Energy Italian Gas Holding (CEIGH), a part of the Centrex Group, was to play a major role in the lucrative agreement. Bruno Mentasti-Granelli, a close friend of Berlusconi, owned 33 percent of CEIGH. The Italian parliament blocked the contract and accused Berlusconi of having a personal interest in the Eni-Gazprom agreement.
Berlusconi is among the most vocal supporters of closer ties between Russia and the European Union. In an article published in Italian media on 26 May 2002, he said that the next step in Russia's growing integration with the West should be EU membership. On 17 November 2005, Berlusconi commented, in relation to the prospect of such membership, that he is "convinced that even if it is a dream ... it is not too distant a dream and I think it will happen one day." The Prime Minister of Italy has made similar comments on other occasions as well.
Berlusconi has a warm relationship with Vladimir Putin. In September 2014, Berlusconi accused the United States, NATO and EU of "a ridiculously and irresponsibly sanctioning approach to the Russian Federation, which cannot but defend Ukrainian citizens of Russian origin that it considers brothers."
Relations with Belarus.
Berlusconi visited Alexander Lukashenko in Belarus in 2009. Berlusconi became the first Western leader to visit Lukashenko since Lukashenko came to power in 1994. At a press conference, Berlusconi paid compliments to Lukashenko and said "Good luck to you and your people, whom I know love you".
Cooperation with the Western Balkans.
On 5 April 2009, at the EU-USA summit in Prague Berlusconi proposed an eight-point road map to accelerate the Euro-Atlantic integration of the western Balkans. During that summit the Italian Foreign Minister Franco Frattini urged his European colleagues to send "visible and concrete" signs to the countries concerned (Serbia, Kosovo, Bosnia, Montenegro, Croatia, Macedonia, and Albania).
Relations with Libya.
On 30 August 2008, the Libyan leader Muammar Gaddafi and Italian Prime Minister Berlusconi signed a historic cooperation treaty in Benghazi. Under its terms, Italy would pay $5 billion to Libya as compensation for its former military occupation. In exchange, Libya would take measures to combat illegal immigration coming from its shores and boost investment in Italian companies. The treaty was ratified by the Italian government in 6 February 2009, and by Libya on 2 March, during a visit to Tripoli by Berlusconi. In June Gaddafi made his first visit to Rome, where he met Prime Minister Berlusconi, Italian President of the Republic Giorgio Napolitano and Senate's Speaker Renato Schifani.
Gaddafi also took part in the G8 summit in L'Aquila in July as Chairman of the African Union. During the summit a warm handshake between US President Barack Obama and Muammar Gaddafi took place (the first time the Libyan leader had been greeted by a serving US president). Later, at the summit's official dinner hosted by President Giorgio Napolitano, US and Libyan leaders upset protocol by sitting next to Italian Prime Minister and G8 host Berlusconi. (According to protocol, Gaddafi should have sat three places away from Berlusconi.)
Berlusconism.
Berlusconism (Italian: "Berlusconismo") is a term used in the Western media and by few Italian analysts to describe the political positions of Berlusconi.
Origins and features.
The term "Berlusconismo" arose in the 1980s, characterized by a strongly positive valence, as a synonym for "entrepreneurial optimism", that is, as an entrepreneurial spirit which does not get upset from difficulties, and trusts that problems can be solved. However, in the 21st century, the meaning has changed.
According to the Italian definition given by the online vocabulary of the Encyclopedia Institute, Berlusconismo has a wide range which runs down a big ambit variety, all having their origins in the figure of Berlusconi, and the political movement inspired by him: the substantive refers, in fact, to the "thought movement", but also to "social phenomenon", and, even, the phenomenon "of custom" bound to his entrepreneurial and political figure. The Berlusconismo term is also used to refer to a certain laissez-faire vision supported by him, not only of the economy and the markets, but also with reference to the same policy.
According to the political and entrepreneurial opponents, the "Berlusconismo" is only a demagogic populism form, comparing it to the Fascism, also for the fact that Berlusconi has declared more turned his liking for Benito Mussolini, even though he has criticized the racial Fascist laws and the alliance with Nazi Germany, referring to himself as pro-Israel. In 2013, he returned to calling Mussolini a good leader whose biggest mistake was signing up to exterminate the Jews. Instead his supporters compare "Berlusconismo" to the French Gaullism and the Argentine Peronism.
Political positions.
Berlusconi, like the same Berlusconism, defines himself as moderate, liberal, and a free trader, but he is often accused of being a populist and a conservative. After his resignation in 2011, Berlusconi has become increasingly Eurosceptical, and he is often criticized by German Chancellor Angela Merkel.
A Berlusconi leadership tactics feature is to use the party as half to reach the power (defined "light party", because deprive of a complex structure). This is decidedly comparable to the political tactics used by Charles De Gaulle in France. Another feature of great importance is emphasis of a "Liberal revolution", thrown and summarized by the "Contract with the Italians" of 2001. The strong reformism is added to these pillars, principally on the form of the Italian state and the constitution" between of these am there the passage from Parliamentary Republic to Presidential one, a bigger electoral blockage, the abolition of Senate, the deputies's halving, the abolition of the provinces and the reform of the justice, with separation of the careers between magistrates and magistrates's civil responsibility, from Berlusconi considered impartial. Berlusconi has declared more turned than be persecuted by the judges, having undergone 34 processes, accusing them to be manoeuvred from left-wing and comparing him to Enzo Tortora, victim of a judicial mistake.
Newly, Berlusconi has declared himself favourable to the Civil Unions.
Legal problems.
Ongoing trials.
As of April 2014, after the Unipol case had been completed with the ruling "acquittal due to statute of limitations", Berlusconi is involved in three ongoing court trials.
Abuse of office – The Unipol case (2005).
In February 2012, Milan prosecutors brought charges against Berlusconi for alleged abuse of office connected with the publication of confidential wiretaps by the Italian newspaper "Il Giornale", which is owned by Berlusconi's brother, in 2005.<ref name="FT 07/02/12"></ref><ref name="BBC 07/02/12"></ref> The publication of the conversations between then Governor of the Bank of Italy Antonio Fazio, senior management of Unipol and Italian centre-left politician Piero Fassino was a breach of secrecy rules and was seen at the time as an attempt to discredit Berlusconi's political rivals. Their publication also eventually led to the collapse of the proposed takeover of Banca Nazionale del Lavoro by Unipol and the resignation of Fazio. The head of the company used by Italian prosecutors to record the conversations has been previously convicted of stealing the recordings and making them available to Berlusconi. On 7 February 2012, at an initial court hearing, Berlusconi denied he had listened to the tapes and ordered their publication. On 7 March 2013, Berlusconi was sentenced to a one-year jail term. On 31 March 2014, the Milan Court of Appeal ruled that the evidence did not clear Paolo and Silvio Berlusconi from guilt, but that the facts are now prescribed, which mean they were both acquitted due to the statutes of limitations. Although Paolo still had to pay €80,000 as compensatory damages to Fassino.
Bribery of senators supporting the Prodi-government (2006).
In February 2013, Berlusconi was under investigation for corruption and illegal financing of political parties from the public prosecutor of Naples, in the figures of Vincenzo Piscitelli, Henry John Woodcock, Francesco Curcio, Alessandro Milita and Fabrizio Vanorio. He is accused of bribing in 2006, with €3 million (of which 1 million and 2 million declared to the tax authorities in black), directed to Senator (the former leader of the Italians in the World party) to facilitate its passage into the ranks of the Berlusconi led coalition House of Freedoms. Along with Berlusconi, a journalist (Valter Lavitola) at the head of the socialist newspaper "L'Avanti!" was also investigated, and Sergio De Gregorio self-confessed being the recipient of the bribery.
On 23 October 2013, Berlusconi and Valter Lavitola were both indicted by the judge for preliminary hearings, Amelia Primavera. For Senator De Gregorio the process has already been closed in a preliminary hearing, because he opted to self-confess and bargained a reduced sentence of 20 months in prison for the crime. The court hearing at first-instance for the indicted Berlusconi, has been scheduled to start on 11 February 2014. During the court proceedings, ex-senator (a former member of the The Olive Tree party) also testified to have been offered a bribe from Berlusconi by another ex-Senator (a former member of the defunct Christian Democrats), to change political sides and join Silvio Berlusconi's center-right bloc, so that they together could cause the fall of the Romano Prodi government in 2006–08. According to the prosecutors, Valter Lavitola was as well working on behalf of Berlusconi as a go-between attempting to also bribe other senators.
Defamation against Antonio Di Pietro (2008).
Berlusconi has repeatedly questioned the legitimacy of the educational degree of the former Operation "Clean Hands" magistrate and leader of the Italy of Values party, Antonio Di Pietro, when he during a 2008 election rally and in an episode of the talk show Porta a Porta in March 2008, repeatedly claimed, that Di Pietro had not obtained his magistrate degree by passing the exams, but with the complicity of the secret services diverted, in order to have a judge placed in the system to overturn the parties of the so-called First Republic. Di Pietro subsequently sued Berlusconi for aggravated defamation in June 2008. The public prosecutor concluded the preliminary investigation 13 November 2009, by indicting Berlusconi for the defamation offense referred to in Article 595 paragraph 2 of the Criminal Code. The Italian Chamber of Deputies then intervened in the case by passing a decree 22 September 2010, granting all Italian parliamentarians "absolute immunity" for words spoken while elected.
On 5 October 2010, the court in Viterbo considered Berlusconi could not be judged or punished, because of the parliamentarian immunity Article 68 of the Italian constitution forbidding any legal prosecutions against words spoken by parliamentarians in the process of their "exercise of parliamentary duties", in conjunction with the Chamber of Deputies recently having voted for a decree to appoint Berlusconi absolute immunity for any spoken words while serving as a deputy. On 19 January 2012, this judgment was set aside by the Supreme Court, which ruled that Berlusconi had been speaking during a campaign rally and not in an institutional setting; meaning he was not covered by the immunity protection provided for by the constitutions Article 68, and consequently should face a new court trial to be held either at the Viterbo court or the Constitutional Court.
On 10 January 2013, the Viterbo court decided to transfer the case for judgement directly to the Constitutional Court. The Constitutional Court ruled on 20 June 2013, that the Chamber of Deputies decree having extended Berlusconi's immunity beyond what was provided for by the constitution, was a case with conflict of powers and should be disregarded. This mean that Berlusconi do not enjoy any special immunity protection for his spoken words during election campaigns, and that a court case now shall be held by the constitutional court, to decide the merits of the case. Before the case against Berlusconi can begin, the Italian Chamber of Deputies however shall be called for trial to defend and explain the reasons for passing their unconstitutional law from 2010. The court hearing against the Chamber of Deputies took place on 8 July 2014, where the constitutional court was asked to deem the concerned Chamber of Deputies decree to be unconstitutional and annul it, by the Court of Rome and the Viterbo court. On 18 July 2014, the Constitutional Court indeed ruled the decree to be unconstitutional and annulled it; meaning that the civil court proceedings against Berlusconi now can continue.
Ongoing investigations.
In addition to the ongoing court trials, Berlusconi is currently also involved in the following two ongoing legal investigations, which will evolve to become an ongoing court trial if the judge at the preliminary hearing indict him of the alleged crime:
Cases with final convictions.
s of October 2013[ [update]], Berlusconi has only been convicted by the final appeal instance in 1 out of 32 court cases.
Tax-fraud conviction in Mediaset trial (1988-98).
The Mediaset trial was launched in April 2005, with indictment of 14 persons (including Berlusconi) for having committed:
(A) false accounting and embezzlement in order to mask payments of substantial "black funds", committed in 1988–94.
(B) tax fraud equal in total to more than €62 million (120bn lira), committed in 1988–98.
Both indictments were related to achievement of personal tax evasion, through illicit trade of movie rights between Mediaset and secret fictive foreign companies situated in tax haven nations, causing fictive losses for Mediaset, with the trade gains being accumulated by the foreign companies owned by the indicted tax fraudsters, who ultimately had the gains paid out as personal profit without paying tax in Italy. In 2007, the court case at first-instance had not yet been launched, and the prosecutors dropped the (A) charges against Berlusconi due to the statute of limitations, and for the same reason the (B) charges were narrowed down to the 1994-98 period, in which the prosecutor charged Berlusconi for having committed a personal tax evasion of €7.3 million.
On 26 October 2012, Berlusconi was sentenced to four years of punishment by an Italian court for tax evasion. The charges were in relation to a scheme to purchase overseas film rights at inflated prices through offshore companies. The four-year term was longer than the three years and eight months the prosecutors had requested, but was shortened to one year in accord with a 2006 amnesty law intended to reduce prison overcrowding. Berlusconi and his co-defendants were also ordered to pay a 10 million euro fine and were banned from holding public office for three years.
On 8 May 2013, the Court of Appeals in Milan confirmed the four-year prison sentence, and extended the public office ban to five years. On 1 August 2013, the Court of Cassation (final appeal) confirmed the sentence of 4 years, of which the last three years are automatically pardoned. The decision marked the first time that Berlusconi received a definitive sentence, despite being on trial nearly 30 times during the last 25 years. In regards of calculating the exact length of the public office ban, the Court of Cassation asked the lower court to re-judge this, because of prosecutors having presented new legal arguments for the ban to be reduced from five to three years. However, a new anti-corruption law passed in late 2012, referred to as the , will anyway bar Berlusconi from seeking elective office for six years, independently of the court's final ruling for the public office ban duration. The ramifications of his public office ban is, that it makes him ineligible to serve any public office, but technically he will still be allowed as a non-candidate to continue leading his party and center-right coalition in election campaigns. A similar situation occurred in March 2013, when the leader of the Five Star Movement, Beppe Grillo, convicted over a road accident in 1988, led his party's 2013 election campaign despite he couldn't run for a public office because of a rule established within his movement.
Berlusconi will due to his high age above 70 years, not be placed direct in prison, but can instead decide if he want to serve his one-year jail term either by a house arrest at one of his private residences or by doing community service. As the gross prison term exceeds two years, the "Severino law" prompts the Italian senate to vote if Berlusconi shall be forced to resign his current senate seat immediately, or alternatively allowing the court imposed ban on holding public office only to take effect by the end of his current legislative term. The pending senate vote, combined with anger over Berlusconi's conviction – a poll indicated 42% of the public believe he has been unfairly persecuted by the magistrates – present a serious political challenge for the fragile ruling coalition. On 3 August, Berlusconi suggested that unless a "solution" to his predicament could be found, Italy was at "risk of a civil war". The following day, thousands of supporters gathered in front of his house in protest of the ruling.
On 30 August, the Italian President Giorgio Napolitano announced he had not selected Berlusconi as one of the new four lifetime senators, which are granted the privileges of being a lawmaker for life with some protected legal immunity, meaning they can continue working in politics even after being convicted guilty for criminal offences that otherwise would lead to ban from serving one of the public offices. A Senate committee will begin its deliberations on 9 September, to decide if Berlusconi's public office ban shall start immediately or by the end of his current legislative term. Before the committee decision becomes effective, it will need also to be approved by a vote in the full Senate.
The deliberations of the Senate committee are expected to last for several weeks, before they reach a decision. According to the "Severino law", which became enacted by the Monti government in December 2012, anyone sentenced to more than two years in prison is deemed ineligible to hold public office for a period of six years (or eight years if convicted for "abuse of power"), and should immediately be expelled from the parliament. Berlusconi has argued that the "Severino law" can not be used to expel persons convicted for crimes committed ahead of December 2012, and plead for the proceedings to be postponed until the European Court of Human Rights or Italy's constitutional court had ruled, whether or not he was correct about his interpretation of the law. Berlusconi also informed, that he in any case had decided to appeal the court ruling against him to the European Court of Human Rights, as he still claimed the ruling itself to be a political and unjust attempt by his opponents, to deprive him of his political power. The response by Prime Minister Enrico Letta's centre-left Democratic Party was however to reject Berlusconi's plea, accusing him of only launching time-wasting maneuvers. Berlusconi's PDL party then made a threat to withdraw their government support, in case the Senate committee expelled Berlusconi as senator. The Democratic Party replied by warning PDL, that they would reject any blackmail attempts, and in any case only would vote in the Senate committee according to the standard of the Italian law. Ahead of the Senate committee's voting, the leading criminal lawyer Paola Severino, who helped design the "Severino law", stated to the La Repubblica newspaper that this specific law according to her professional opinion, clearly also applied for crimes being committed before its enactment in December 2012.
On 10 September, at the second day of the Senate deliberations, the Democratic Party stated they intend to vote down all three PDL submitted motions to delay the Senate deliberations, and accused PDL for obstructing the work of the Senate committee by playing delaying tactics. Renato Brunetta, floor leader of the PDL in the lower house, responded by saying "If the Democratic Party and Grillo's people decide this evening to vote against the proposals, the Democratic Party will bring down the Letta government". The meeting at the second day ended with PDL accepting to drop their series of technical objections to try to halt the hearings, on the agreement that each of the committee members could speak at greater length in a broad discussion on the merits of the case. On 18 September, Berlusconi made a national televised speech, in which he pledged to stay as party leader of a revived Forza Italia, no matter if the Senate would end up deciding to expel him or not. On 25 September, the PDL parliamentary group agreed on a resolution to threat the Senate, that if Berlusconi would be expelled, then all PDL parliamentarians would immediately "reflect on and decide according to his or her conscience", whether or not to show sympathy with Berlusconi by resigning their own seats in the Senate. The Senate Committee never-the-less voted 15:8 in support for a recommendation to expel Berlusconi on 4 October, and ten days later submitted a final report about the case, so that it can be scheduled for a final vote in the full Senate by early November. The "Rules of Procedure Committee" decided at its meeting on 30 October, by the votes 7:6, that Berlusconi's expulsion vote shall not be conducted as a secret vote but as an open public vote. On 27 November 2013, the Senate voted 192:113 for enforcement of Berlusconi's immediate expulsion and a six-year ban from serving any legislative office.
Berlusconi was expected to start serving his four-year prison sentence (reduced to one year), either under house arrest or doing unpaid social community service, in mid-October 2013. In mid-October he informed the court, that he prefers to serve the sentence by doing community service. Because of bureaucracy in the legal court system, it is however expected his one-year-long full-time community service will only start around April 2014. On 19 October, the Milan appeal court ruled that Berlusconi's public office ban should be reduced from five to two years; which was later also confirmed by the Court of Cassation. The court imposed public office ban, however did not change that Berlusconi according to the "Severino law", anyway received a legislative office ban preventing him to run as candidate in legislative elections for a prolonged six-year period, which then by effect superseded the shorter court imposed public office ban. Berlusconi began serving his community service at a catholic care home center on 9 May 2014, where he is required to work four hours a week for a year with elderly dementia patients.
Controversies.
Berlusconi has been involved in many controversies and over 20 court cases during his political career, including a conviction to 4 years prison and 5 years suspension of public functions by the Court of Appeals for €7M tax evasion (and €280M slush fund) on 8 May 2013, confirmed by the Court of Cassation on 1 August 2013. Due to a general pardon, his imprisonment was reduced to one year, which due to his age can be served either as a house arrest at his private residence or as community service.
On 24 June 2013, Berlusconi was found guilty of paying an underage prostitute for sex, and of abusing his powers in an ensuing cover up. He was sentenced to seven years in jail, and banned from public office for life. He is certain to appeal, and the sentence will not be enforced until the result of the trial is confirmed at appeal.
Economic conflicts of interest.
According to journalists Marco Travaglio and Enzo Biagi, Berlusconi entered politics to save his companies from bankruptcy and himself from convictions. From the very beginning he said it clearly to his associates. Berlusconi's supporters hailed him as the "novus homo", an outsider who was going to bring a new efficiency to the public bureaucracy and reform the state from top to bottom.
Berlusconi was investigated for forty different inquests in less than two years.
− Berlusconi's governments passed laws that shortened statutory terms for tax fraud. Romano Prodi, who defeated Berlusconi in 2006, claimed that these were "ad personam laws," meant to solve Berlusconi's problems and defend his interests.
Media control and conflict of interest.
Berlusconi's extensive control over the media has been widely criticised by some analysts, some press freedom organisations, and extensively on several Italian newspapers, national and private TV channels by opposition leaders and in general opposition parties members, who allege Italy's media has limited freedom of expression. However such coverage of the complaint in practice put under discussion the point of the complaint itself. The "Freedom of the Press 2004 Global Survey", an annual study issued by the American organisation Freedom House, downgraded Italy's ranking from 'Free' to 'Partly Free' due to Berlusconi's influence over RAI, a ranking which, in "Western Europe" was shared only with Turkey (as of 2005[ [update]]). Reporters Without Borders states that in 2004, "The conflict of interests involving Prime Minister Berlusconi and his vast media empire was still not resolved and continued to threaten news diversity". In April 2004, the International Federation of Journalists joined the criticism, objecting to the passage of a law vetoed by Carlo Azeglio Ciampi in 2003, which critics believe is designed to protect Berlusconi's reported 90% control of the Italian national media.
Berlusconi owns via Mediaset 3 of 7 national TV channels: (Canale 5, Italia 1, and Rete 4). In 2002, Luciano Violante, a prominent member of the Left, said in a speech in Parliament: "Honourable Anedda, I invite you to ask the honourable Berlusconi, because he certainly knows that he received a full guarantee in 1994, when the government changed — that TV stations would not be touched. He knows it and the Honourable Letta knows it." The authors of the book "Inciucio" cite this sentence as evidence for the idea that the Left made a deal with Berlusconi in 1994, in which a promise was made not to honour a law in the Constitutional Court of Italy that would have required Berlusconi to give up one of his three TV channels in order to uphold pluralism and competition. According to the authors, this would be an explanation of why the Left, despite having won the 1996 elections, did not pass a law to solve the conflicts of interest between media ownership and politics.
Berlusconi's influence over RAI became evident when in Sofia, Bulgaria he expressed his views on journalists Enzo Biagi and Michele Santoro, and comedian Daniele Luttazzi. Berlusconi said that they "use television as a criminal means of communication". They lost their jobs as a result. This statement was called by critics "Editto Bulgaro".
The TV broadcasting of a satirical programme called "RAIot" was censored in November 2003 after the comedienne Sabina Guzzanti made outspoken criticism of the Berlusconi media empire. Mediaset, one of Berlusconi's companies, sued RAI over Guzzanti's program, demanding 20 million euros for "damages"; in November 2003 the show was cancelled by the president of RAI, Lucia Annunziata. The details of the event were made into a Michael Moore-style documentary called "Viva Zapatero!", which was produced by Guzzanti.
Mediaset, Berlusconi's television group, has stated that it uses the same criteria as the public (state-owned) television RAI in assigning a proper visibility to all the most important political parties and movements (the so-called 'Par Condicio') – which has been since often disproved. In March 2006, on the television channel Rai Tre, in a television interview with Lucia Annunziata during his talk show, "In 1/2 h", he stormed out of the studio because of a disagreement with the host journalist regarding the economic consequences of his government. In November 2007, allegations of news manipulation caused the departure from RAI of Berlusconi's personal assistant.
Enrico Mentana, the news anchor long seen as a guarantor of Canale 5's independence, walked out in April 2008, saying that he no longer felt "at home in a group that seems like an electoral campaign committee".
On 24 June 2009, Berlusconi during the Confindustria young members congress in Santa Margherita Ligure, Italy has invited the advertisers to interrupt or boycott the advertising contracts with the magazines and newspapers published by Gruppo Editoriale L'Espresso, in particular the "la Repubblica" and the newsmagazine "L'espresso", calling the publishing group "shameless", because is fueling the economic crisis speaking more and more about it and accusing also to make a subversive attack against him to replace with an "un-elected". The publishing group has announced to begin legal proceedings against Berlusconi, to protect the image and the interests of the group.
On 12 October 2009, Berlusconi during the Confindustria Monza and Brianza members congress, has again invited the industrialists present to a "widespread rebellion" against a "newspaper that hadn't any limits in discrediting the government and the country and indoctrinating foreign newspapers".
In October 2009, Reporters Without Borders secretary-general declared that Berlusconi "is on the verge of being added to our list of Predators of Press Freedom", which would be a first for a European leader. He also added that Italy will probably be ranked last in the European Union in the upcoming edition of the RWB press freedom index.
"The Economist".
One of Berlusconi's strongest critics in the media outside Italy is the British weekly "The Economist" (nicknamed by Berlusconi "The Ecommunist"), which in its issue of 26 April 2001 carried a title on its front cover, 'Why Silvio Berlusconi is unfit to lead Italy'. The war of words between Berlusconi and "The Economist" has gained notoriety, with Berlusconi taking the publication to court in Rome and "The Economist" publishing letters against him. The magazine claimed that the documentation contained in its article proves that Berlusconi is 'unfit' for office because of his numerous conflicts of interest. Berlusconi claimed the article contained "a series of old accusations" that was an "insult to truth and intelligence".
According to "The Economist"‍‍ '​‍s findings, Berlusconi, while Prime Minister of Italy, retained in effective control of 90% of all national television broadcasting. This figure included stations he owns directly as well as those over which he had indirect control by dint of his position as Prime Minister and his ability to influence the choice of the management bodies of these stations. "The Economist" has also claimed that the Italian Prime Minister is corrupt and self-serving. A key journalist for "The Economist", David Lane, has set out many of these charges in his book "Berlusconi's Shadow".
− Lane points out that Berlusconi has not defended himself in court against the main charges, but has relied upon political and legal manipulations, most notably by changing the statute of limitation to prevent charges being completed in the first place. In order to publicly prove the truth of the documented accusations contained in their articles, the newspaper has publicly challenged Berlusconi to sue "The Economist" for libel. Berlusconi did so, losing versus "The Economist", and being charged for all the trial costs on 5 September 2008, when the Court in Milan issued a judgment rejecting all Mr Berlusconi's claims and sentenced him to compensate for legal expenses.
− In June 2011, "The Economist" published a strong article dealing with Mr. Berlusconi, titled "The man who screwed an entire country".
Legislative changes.
On some occasions, laws passed by the Berlusconi administration have effectively delayed ongoing trials on him. For example the law reducing punishment for all cases of false accounting and the law on "legitimate suspicion", which allowed defendants to request their cases to be moved to another court if they believe that the local judges are biased against them. Because of these legislative actions, political opponents accuse Berlusconi of passing these laws for the purpose of protecting himself from legal charges. "La Repubblica", for example, sustained that Berlusconi passed 17 different laws which have advantaged himself. Berlusconi and his allies, on the other hand, maintain that such laws are consistent with everyone's right to a rapid and just trial, and with the principle of "presumption of innocence" (garantismo); furthermore, they claim that Berlusconi is being subjected to a political "witch hunt", orchestrated by certain (allegedly left-wing) judges.
Berlusconi and his government quarreled with the Italian judiciary often. His administration attempted a judiciary reform intended to limit the flexibility of judges and magistrates in their decision-making. Critics said it would instead limit the magistrature's independence by "de facto" subjecting the judiciary to the executive's control. The reform was met by almost unanimous dissent from the Italian judges, but was passed by the Italian parliament in December 2004. It was vetoed by the Italian President, Carlo Azeglio Ciampi.
During the night hours between 5 and 6 March 2010, the Berlusconi-led Italian government passed a decree "interpreting" the electoral law to let the PDL candidate run for governor in Lazio after she had failed to properly register for the elections. The Italian Constitution states that electoral procedures can only be changed in Parliament, and must not be changed by governmental decree. Italy's President, whose endorsement of the decree was required by law, said that the measure taken by the government may not violate the Constitution.
Alleged links to the Mafia.
Berlusconi has never been tried on charges relating to "Cosa Nostra", although several Mafia turncoats have stated that Berlusconi had connections with the Sicilian criminal association. The claims arise mostly from the hiring of Vittorio Mangano, charged for Mafia association, as a gardener and stable-man at Berlusconi's Villa San Martino in Arcore, a small town near Milan. It was Berlusconi's friend Marcello Dell'Utri who introduced Mangano to Berlusconi in 1973. Berlusconi denied any ties to the Mafia. Marcello Dell'Utri even stated that the Mafia did not exist at all.
In 2004, Dell'Utri, co-founder of Forza Italia, was sentenced to nine years by a Palermo court on charge of "external association to the Mafia", a sentence describing Dell'Utri as a mediator between the economical interests of Berlusconi and members of the criminal organisation. Berlusconi refused to comment on the sentence. In 2010, Palermo's appeals court cut the sentence to seven years but fully confirmed Dell'Utri's role as a link between Berlusconi and the Mafia until 1992.
In 1996, a Mafia informer, Salvatore Cancemi, declared that Berlusconi and Dell'Utri were in direct contact with Salvatore Riina, head of the Sicilian Mafia in the 1980s and 1990s. Cancemi disclosed that Fininvest, through Marcello Dell'Utri and mafioso Vittorio Mangano, had paid Cosa Nostra 200 million lire (between 100,000 and 200,000 of today's euro) annually. The alleged contacts, according to Cancemi, were to lead to legislation favourable to Cosa Nostra, in particular the harsh 41-bis prison regime. The underlying premise was that Cosa Nostra would support Berlusconi's Forza Italia party in return for political favours. After a two-year investigation, magistrates closed the inquiry without charges. They did not find evidence to corroborate Cancemi's allegations. Similarly, a two-year investigation, also launched on evidence from Cancemi, into Berlusconi's alleged association with the Mafia was closed in 1996.
According to yet another Mafia turncoat, Antonino Giuffrè – arrested on 16 April 2002 – the Mafia turned to Berlusconi's Forza Italia party to look after the Mafia's interests, after the decline in the early 1990s of the ruling Christian Democrat party, whose leaders in Sicily looked after the Mafia's interests in Rome. The Mafia's fall out with the Christian Democrats became clear when Salvo Lima was killed in March 1992. "The Lima murder marked the end of an era," Giuffrè told the court. "A new era opened with a new political force on the horizon which provided the guarantees that the Christian Democrats were no longer able to deliver. To be clear, that party was Forza Italia." Dell'Utri was the go-between on a range of legislative efforts to ease pressure on mafiosi in exchange for electoral support, according to Giuffrè. "Dell'Utri was very close to Cosa Nostra and a very good contact point for Berlusconi," he said. Mafia boss Bernardo Provenzano told Giuffrè that they "were in good hands" with Dell'Utri, who was a "serious and trustworthy person". Provenzano stated that the Mafia's judicial problems would be resolved within 10 years after 1992, thanks to the undertakings given by Forza Italia.
Giuffrè also said that Berlusconi himself used to be in touch with Stefano Bontade, a top Mafia boss, in the mid-1970s. At the time Berlusconi still was just a wealthy real estate developer and started his private television empire. Bontade visited Berlusconi's villa in Arcore through his contact Vittorio Mangano. Berlusconi's lawyer dismissed Giuffrè's testimony as "false" and an attempt to discredit the Prime Minister and his party. Giuffrè said that other Mafia representatives who were in contact with Berlusconi included the Palermo Mafia bosses Filippo Graviano and Giuseppe Graviano. The Graviano brothers allegedly treated directly with Berlusconi through the business-man Gianni Letta, somewhere between September/October 1993. The alleged pact with the Mafia fell apart in 2002. Cosa Nostra had achieved nothing.
Dell'Utri's lawyer, Enrico Trantino, dismissed Giuffrè's allegations as an "anthology of hearsay". He said Giuffrè had perpetuated the trend that every new turncoat would attack Dell'Utri and the former Christian Democrat prime minister Giulio Andreotti in order to earn money and judicial privileges.
In October 2009, Gaspare Spatuzza, a Mafioso turned pentito in 2008, has confirmed Giuffrè statements. Spatuzza testified that his boss Giuseppe Graviano had told him in 1994, that Berlusconi was bargaining with the Mafia, concerning a political-electoral agreement between Cosa Nostra and Berlusconi's Forza Italia. Spatuzza said Graviano disclosed the information to him during a conversation in a bar Graviano owned in the upscale Via Veneto district of the Italian capital Rome. Dell'Utri was the intermediary, according to Spatuzza. Dell'Utri has dismissed Spatuzza's allegations as "nonsense". Berlusconi's lawyer and MP for the PdL, Niccolò Ghedini said that "the statements given by Spatuzza about prime minister Berlusconi are baseless and can be in no way verified."
Remarks on Western civilisation and Islam.
After the 11 September 2001 attacks in New York, Berlusconi said: "We must be aware of the superiority of our civilisation, a system that has guaranteed well-being, respect for human rights and – in contrast with Islamic countries – respect for religious and political rights, a system that has as its value understanding of diversity and tolerance." This declaration caused an uproar, not only in the Arab and Muslim world, but also all around Europe, including Italy. Subsequently Berlusconi told the press: "We are aware of the crucial role of moderate Arab countries... I am sorry that words that have been misunderstood have offended the sensitivity of my Arab and Muslim friends."
Right-to-die case.
After the family of Eluana Englaro (who had been comatose for 17 years) succeeded in having her right to die recognized by the judges and getting doctors to start the process of allowing her to die in the way established by the court, Berlusconi issued a decree to stop the doctor from letting her die. Stating that, "This is murder. I would be failing to rescue her. I'm not a Pontius Pilate", Berlusconi went on to defend his decision by claiming that she was "in the condition to have babies", arguing that comatose women were still subject to menstruation.
Critics said that this controversial move had been staged to repair relations with the Vatican, following harsh criticism of the treatment of immigrants by the Berlusconi administration.
Anti-immigration laws.
During his long career as Prime Minister, Berlusconi has had to deal with massive immigration from the coast of the North Africa. To limit illegal immigration, the Berlusconi's government promulgated the "Bossi-Fini law" in 2002. This law took the name by the leaders of the two right-wing allied parties in Berlusconi's government coalition, Umberto Bossi of Lega Nord and Gianfranco Fini of National Alliance.
The law provides the expulsion, issued by the Prefect of the Province where an illegal foreign immigrant is found, and is immediately performed with the assistance at the border of the police. Illegal immigrants without valid identity documents, are taken to detention centers, set up by the "Turco-Napolitano law", in order to be identified. The law provides for the issuance of residence permits to persons who provide proof of having a job for their maintenance budget. To this general rule you add the special residence permits and those in the application of the right to asylum.
The standard allows the repatriation to the country of origin on the high seas, on the basis of bilateral agreements between Italy and neighboring countries, which commit the police forces of their respective countries to cooperate in the prevention of illegal immigration. If the illegal immigrant ships dock on Italian soil, the identification of those entitled to political asylum and the supply of medical treatment and care is undertaken by the marine police force. The law had been severely criticized by the centre-left opposition.
In 2013, the European Parliament asked Italy to modified the "Bossi-Fini law" because it was too restrictive and severe.
Jokes, gestures, and blunders.
Berlusconi has developed a reputation for making gaffes or insensitive remarks.
On 2 July 2003, Berlusconi suggested that German SPD MEP Martin Schulz, who had criticised his domestic policies, should play a Nazi concentration camp guard in a film. Berlusconi insisted that he was joking, but accused Schulz and others to be "bad-willing tourists of democracy". This incident caused a brief cooling of Italy's relationship with Germany.
Addressing traders at the New York Stock Exchange in September 2003, Berlusconi listed a series of reasons to invest in Italy, the first of which was that "we have the most beautiful secretaries in the world". This remark resulted in uproar in Italy where female members of parliament took part in a one-day cross-party protest. Berlusconi's list also included the claim that Italy had "fewer communists, and those who are still here deny having been one".
In 2003, during an interview with Nicholas Farrell, then editor of "The Spectator", Berlusconi claimed that Mussolini "had been a benign dictator who did not murder opponents but sent them 'on holiday'". In 2013, he returned to calling Mussolini a good leader whose biggest mistake was signing up to exterminate the Jews.
Berlusconi had made disparaging remarks about Finnish cuisine during negotiations to decide on the location of the European Food Safety Authority in 2001. He caused further offence in 2005, when he claimed that during the negotiations he had had to "dust off his playboy charms" in order to persuade the Finnish president, Tarja Halonen, to concede that the EFSA should be based in Parma instead of Finland, and compared Finnish smoked reindeer unfavourably to culatello. The Italian ambassador in Helsinki was summoned by the Finnish foreign minister. One of Berlusconi's ministers later 'explained' the comment by saying that "anyone who had seen a picture of Halonen must have been aware that he had been joking". Halonen took the incident in good humour, retorting that Berlusconi had "overestimated his persuasion skills". The Finnish pizza chain Kotipizza responded by launching a variety of pizza called "Pizza Berlusconi", using smoked reindeer as the topping. The pizza won first prize in America's Plate International pizza contest in March 2008.
In March 2006, Berlusconi alleged that Chinese communists under Mao Zedong had "boiled [children] to fertilise the fields". His opponent Romano Prodi criticised Berlusconi for offending the Chinese people and called his comments 'unthinkable'.
In the run-up to the 2008 Italian general election, Berlusconi was angrily accused of sexism for saying that female politicians from the right were "more beautiful" and that "the left has no taste, even when it comes to women". In 2008 Berlusconi criticised the composition of the Council of Ministers of the Spanish Government as being too 'pink' by virtue of the fact that it has (once the President of the Council, José Luis Rodríguez Zapatero, is counted) an equal number of men and women. He also stated that he doubted that such a composition would be possible in Italy given the "prevalence of men" in Italian politics.
Also in 2008, Berlusconi caused controversy at a joint press conference with Russian president Vladimir Putin. When a journalist from the Russian paper Nezavisimaya Gazeta asked a question about Mr Putin's personal relationships, Berlusconi made a gesture towards the journalist imitating a gunman shooting.
On 6 November 2008, two days after Barack Obama was elected the first black US President, Berlusconi referred to Obama as "young, handsome and even tanned": On 26 March 2009 he said "I'm paler [than Mr Obama], because it's been so long since I went sunbathing. He's more handsome, younger and taller."
On 24 January 2009, Berlusconi announced his aim to increase the numbers of military patrolling the Italian cities from 3,000 to 30,000 in order to crack down on what he called an "evil army" of criminals. Responding to a female journalist who asked him if this tenfold increase in patrolling soldiers would be enough to secure Italian women from being raped, he said: "We could not field a big enough force to avoid this risk [of rape]. We would need as many soldiers as beautiful women and I don't think that would be possible, because our women are so beautiful." Opposition leaders called the remarks insensitive and in bad taste. Berlusconi retorted that he had merely wanted to compliment Italian women. Other critics accused him of creating a "police state".
Two days after the 2009 L'Aquila earthquake, Berlusconi suggested that people left homeless should view their experience as a camping weekend.
Subsequently, at a tent camp on the outskirts of L'Aquila housing some of the more than 30,000 people who lost their homes during the 2009 earthquake he said to an African priest: "you have a nice tan."
In October 2010, Berlusconi was chastised by the Vatican newspaper "L'Osservatore Romano" after he was filmed telling "offensive and deplorable jokes", including one whose punchline was similar to one of the gravest blasphemies in the Italian language. It was also revealed he had made another antisemitic joke a few days previously. Berlusconi responded to the allegations by saying the jokes were "neither an offence nor a sin, but merely a laugh".
On 1 November 2010, after once again being accused of involvement in juvenile prostitution, he suggested that an audience at the Milan trade fair should stop reading newspapers: "Don't read newspapers any more because they deceive you. [...] I am a man who works hard all day long and if sometimes I look at some good-looking girl, it's better to be fond of pretty girls than to be gay". The remarks were immediately condemned by Arcigay, Italy's main gay rights organisation.
On 13 July 2011, according to a leaked telephone surveillance transcript, Berlusconi told his presumed blackmailer Valter Lavitola: "The only thing they can say about me is that I screw around [...] Now they're spying on me, controlling my phone calls. I don't give a fuck. In a few months [...] I'll be leaving this shit country that makes me sick."
On 27 January 2013, on the occasion of the Holocaust Remembrance Day, Berlusconi said the Italian fascist dictator Benito Mussolini, except from passing anti-Jewish laws in 1938, only had done "good things" for Italy; and also said Mussolini from a strategic point of view did the right thing in siding with Adolf Hitler during World War II, because Hitler at the point of time when the alliance was made had appeared to be winning the war.
Friendship with Bettino Craxi.
Berlusconi's career as an entrepreneur is also often questioned by his detractors. The allegations made against him generally include suspicions about the extremely fast increase of his activity as a construction entrepreneur in years 1961–63, hinting at the possibility that in those years he received money from unknown and possibly illegal sources. These accusations are regarded by Berlusconi and his supporters as empty slander, trying to undermine Berlusconi's reputation as a self-made man. Also frequently cited by opponents are events dating to the 1980s, including supposed "favour exchanges" between Berlusconi and Bettino Craxi, the former Socialist prime minister and leader of the Italian Socialist Party convicted in 1994, for various corruption charges. The Milan magistrates who indicted and successfully convicted Mr. Craxi in their "Clean Hands" investigation laid bare an entrenched system in which businessmen paid hundreds of millions of dollars to political parties or individual politicians in exchange for sweetheart deals with Italian state companies and the government itself. Berlusconi acknowledges a personal friendship with Craxi.
Freedom Army.
On 28 May 2013, Berlusconi and his entourage launched an online initiative which consisted in the recruitment of volunteers, who are available to defend Berlusconi from the convictions of Milan's prosecutors, who are dealing with his trials, and who, Berlusconi often accused of being communists and anti-democratic.
Simone Furlan, the creator of the army said in an interview: "There comes a time in life, when you realize that fighting for an ideal is no longer a choice but an obligation. We civil society we were helpless spectators of the "War of the Twenty Years" which saw Berlusconi fight and defend against slanderous accusations of all kinds, the result of a judicial persecution without precedent in history".
This initiative, launched as "Freedom Army", has been immediately surnamed by media "Silvio's Army", and it was severely condemned, by the Democratic Party, the Five Star Movement and Left Ecology Freedom.
Wiretaps and accusations of corruption.
In December 2007, the audio recording of a phone call between Berlusconi, then leader of the opposition parties, and Agostino Saccà (general director of RAI) were published by the magazine "L'espresso" and caused a scandal in several media.
The wiretap was part of an investigation by the Public Prosecutor Office of Naples, where Berlusconi was investigated for corruption.
In the phone call, Saccà expresses words of impassioned political support to Berlusconi and criticises the behaviour of Berlusconi's allies. Berlusconi urges Saccà to broadcast a telefilm series which was strongly advocated by his ally Umberto Bossi. Saccà laments that many people have spread rumours on this agreement causing problems to him. Then Berlusconi asks Saccà to find a job in RAI for a young woman explicitly telling him that this woman would serve as an asset in a secret exchange with a senator of the majority who would help him to cause Prodi, with his administration, to fall. After the publication of these wiretaps, Berlusconi has been accused by other politicians and by some journalists of political corruption through the exploitation of prostitution. Berlusconi said, in his own defence: "In the entertainment world everybody knows that, in certain situations in RAI TV you work only if you prostitute yourself or if you are leftist. I have intervened on behalf of some personalities who are not leftists and have been completely set apart by RAI TV." In the US State Department's 2011 Trafficking in Persons report authorized by Secretary of State Hillary Clinton Mr. Berlusconi was explicitly named as a person involved in the "commercial sexual exploitation of a Moroccan child".
Divorce and allegations of sexual misconduct.
At the end of April 2009, Veronica Lario wrote an open letter expressing her anger at Berlusconi's choice of young, attractive female candidates—some with little or no political experience—to represent the party in the 2009 European Parliament elections. Berlusconi demanded a public apology, claiming that for the third time his wife had "done this to me in the middle of an election campaign", and stated that there was little prospect of his marriage continuing. On 3 May, Lario announced she was filing for divorce. She claimed that Berlusconi had not attended his own sons' 18th birthday parties, and that she "cannot remain with a man who consorts with minors" and "is not well".
Noemi Letizia, the girl in question, gave interviews to the Italian press, revealing that she calls Berlusconi "papi" ("daddy"), that they often spent time together in the past, and that Berlusconi would take care of her career as showgirl or politician, whichever she opted to pursue. Berlusconi claimed that he knew Letizia only through her father and that he never met her alone without her parents.
On 14 May, "la Repubblica" published an article alleging many inconsistencies in Berlusconi's story and asked him to answer ten questions to clarify the situation.
Ten days later, Letizia's ex-boyfriend, Luigi Flaminio, claimed that Berlusconi had contacted Letizia personally in October 2008 and said she had spent a week without her parents at Berlusconi's Sardinian villa around New Year's Eve 2009, a fact confirmed later by her mother. On 28 May 2009, Berlusconi said that he had never had "spicy" relations with Letizia, and said that if any such thing had occurred, he would have resigned immediately.
On 17 June 2009, Patrizia D'Addario, a 42-year old escort and retired actress from Bari, Italy, claimed that she had been recruited twice to spend the evening with Berlusconi. Berlusconi denied any knowledge of D'Addario being a paid escort: "I have never paid a woman... I have never understood what satisfaction there is if the pleasure of conquest is absent". He also accused an unspecified person of manoeuvring and bribing D'Addario.
On 26 June 2009, the "ten questions" to Berlusconi were reformulated by "la Repubblica" newspaper, and subsequently republished multiple times. On 28 August 2009, Berlusconi sued Gruppo Editoriale L'Espresso, the owner company of the newspaper, and classified the ten questions as "defamatory" and "rhetorical".
Berlusconi's lifestyle has raised eyebrows in Catholic circles, with vigorous criticism being expressed in particular by the newspaper "Avvenire", owned by the Conferenza Episcopale Italiana (Conference of Italian Bishops). This was followed by the publication in the newspaper il Giornale (owned by the Berlusconi family) of details with regard to legal proceedings against the editor of "Avvenire", Dino Boffo, which seemed to implicate him for a harassment case against the wife of his ex-partner. Dino Boffo has always declared the details of the proceedings to be false, although he has not denied the basic premise.
After a period of tense exchanges and polemics, on 3 September 2009, Boffo resigned from his editorial position and the assistant editor Marco Tarquinio became editor "ad interim".
On 22 September 2009, after a press conference, Berlusconi declared that he had asked his ministers not to respond anymore to questions regarding "gossip". He stated also that the Italian press should talk only about the "successes" of Italian Government in internal and foreign policies, adding also that the press now will be able only to ask questions relating to his administration and not to gossip.
During a contested episode of "AnnoZero" on 1 October 2009, the journalist and presenter Michele Santoro interviewed Patrizia D'Addario. She stated she was contacted by Giampaolo Tarantini – a businessman from Bari – who already knew her and requested her presence at Palazzo Grazioli with "the President". D'Addario also stated that Berlusconi knew that she was a paid escort.
Ruby Rubacuori.
In November 2010, teenage Moroccan belly dancer and alleged prostitute Karima El Mahroug (better known as "Ruby Rubacuori") claimed to have been given $10,000 by Berlusconi at parties at his private villas. The girl told prosecutors in Milan that these events were like orgies where Berlusconi and 20 young women performed an African-style ritual known as the "bunga bunga" in the nude.
It was also found out that, on 27 May 2010, El Mahroug had been arrested for theft by the Milan police but (being still a minor) she was directed to a shelter for juvenile offenders. After a couple of hours, while she was being questioned, Berlusconi, who was at the time in Paris, called the head of the police in Milan and pressured for her release, claiming the girl was related to then President Hosni Mubarak of Egypt and that in order to avoid a diplomatic crisis, she was to be brought to the custody of Nicole Minetti. Following repeated telephone calls by Berlusconi to the police authorities, El Mahroug was eventually released and entrusted to Minetti's care.
The investigation of Berlusconi for extortion ("") and child prostitution regarding Karima El Mahroug has been referred to as "Rubygate". MP Gaetano Pecorella proposed to lower the age of majority in Italy to solve the case. Minetti was known for previous associations with Berlusconi, having danced for "Colorado Cafe", a show on one of Berlusconi's TV channels, and on "Scorie", an Italian version of Candid Camera. In November 2009 she became a dental hygienist, and shortly afterward treated Berlusconi for two broken teeth and facial injuries after he was attacked with a marble statue at a political rally. In February 2010, she was selected as one of the candidates representing Berlusconi's The People of Freedom party, despite her lack of any political experience, and was seated on the Regional Council of Lombardy the following month.
"The Guardian" reported that according to a series of media reports in October 2010, Berlusconi had met El Mahroug, then 17, through Nicole Minetti. Mahroug insisted that she had not slept with the then 74-year-old prime minister. She told Italian newspapers that she merely attended dinner at his mansion near Milan. El Mahroug said she sat next to Berlusconi, who later took her upstairs and gave her an envelope containing €7,000. She said he also gave her jewelry.
Berlusconi has also come under fire for reportedly spending $1.8 million in state funds from RAI Cinema to further the career of a largely unknown Bulgarian actress, Michelle Bonev. The fact that this coincided with severe cuts being made to the country's arts budget provoked a strong reaction from the public.
In January 2011, Berlusconi was placed under criminal investigation relating to El Mahroug for allegedly having sex with an underage prostitute and for abuse of office relating to her release from detention. Berlusconi's lawyers were quick to deny the allegations as "absurd and without foundation" and called the investigation a "serious interference with the private life of the prime minister without precedent in the judicial history of the country".
On 15 February 2011, a judge indicted Berlusconi to stand trial on charges carrying up to 15 years in prison. Paying for sex with a minor in Italy is punished within a range of six months to three years imprisonment, while the crime of malfeasance in office (It: "concussione") is more severely punished, from four years to twelve years imprisonment, as it is considered a type of extortion committed by a public officer.
The fast-track trial opened on 6 April and was adjourned until 31 May. El Mahroug's lawyer said that Mahroug would not be attaching herself to the case as a civil complainant and denies that she ever made herself available for money. Another alleged victim, Giorgia Iafrate, also decided not to be a party to the case. In January 2013, judges rejected an application from Berlusconi's lawyers to have the trial adjourned so that it would not interfere with Italy's 2013 general election in which Berlusconi participated.
On 24 June 2013, Berlusconi was found guilty of paying for sex with an underage prostitute and of abusing his office. He was sentenced to seven years in prison, one more year than had been requested by the prosecution, and banned from public office for life. Although facing a custodial sentence, if Berlusconi appeals the sentence as expected, it will not be executed until after the appeals process. In the trial, the prosecution claimed that Berlusconi had paid over 4.5 million euros in total for El Mahroug's services. Berlusconi's conviction was quashed on 18 July 2014.
Assault at rally.
On 13 December 2009, Berlusconi was hit in the face with an alabaster statuette of Milan Cathedral after a rally in Milan's "Piazza del Duomo". As Berlusconi was shaking hands with the public, a man in the crowd stepped forward and launched the statuette at him. The assailant was subsequently detained and identified as Massimo Tartaglia, a 42-year-old surveyor with a history of mental illness but no criminal record, living in the outskirts of Milan. According to a letter released to the Italian news agency ANSA, Tartaglia has apologised for the attack, writing: "I don't recognise myself", and adding that he had "acted alone [with no] form of militancy or political affiliation". Berlusconi suffered facial injuries, a broken nose and two broken teeth; he was subsequently hospitalised. Italian president Giorgio Napolitano and politicians from all parties in Italy condemned the attack.
In the night of 15–16 December, a 26-year-old man was stopped by police and Berlusconi's bodyguards while trying to gain access to Berlusconi's hospital room. A search revealed that he carried no weapons, although three hockey sticks and two knives were later found in his car. The suspect was known to have a history of mental illness and mandatory treatment in mental institutions.
Berlusconi was discharged from the hospital on 17 December 2009.
Personal fortune.
In 2012, Forbes magazine reported that Berlusconi was Italy's sixth richest man, with a net worth of $5.9 billion. He holds significant assets in television, newspaper, publishing, cinema, finance, banking, insurance, and sports. Berlusconi's main company, Mediaset, operates three national television channels covering half of the national television sector; and "Publitalia" (), the leading Italian advertising and publicity agency. Berlusconi also owns a controlling stake in Arnoldo Mondadori Editore, the largest Italian publishing house, whose publications include Panorama, one of the country's most popular news magazines. His brother, Paolo Berlusconi, owns and operates "il Giornale", a centre-right wing newspaper which provides a pro-Berlusconi slant on Italian politics. "Il Foglio", one of the most influential Italian right-wing newspapers, is partially owned by his wife, Veronica Lario. After Lario sold some of her ownership in 2010, Paolo Berlusconi acquired a majority interest in the newspaper. Berlusconi is also the founder and major shareholder of Fininvest, which is among the largest private companies in Italy
and operates in media and finance. With Ennio Doris he founded Mediolanum, one of the country's biggest banking and insurance groups. He has interests in cinema and home video distribution (Medusa Film and Penta Film). He is also the owner of the football club A.C. Milan.
Further reading.
</dl>

</doc>
<doc id="26911" url="http://en.wikipedia.org/wiki?curid=26911" title="Sprung rhythm">
Sprung rhythm

Sprung rhythm is a poetic rhythm designed to imitate the rhythm of natural speech. It is constructed from feet in which the first syllable is stressed and may be followed by a variable number of unstressed syllables. The British poet Gerard Manley Hopkins claimed to have discovered this previously unnamed poetic rhythm in the natural patterns of English in folk songs, spoken poetry, Shakespeare, Milton, "et al." He used diacritical marks on syllables to indicate which should be drawn out (acute e.g. á ) and which uttered quickly (grave, e.g., è).
Some critics believe he merely coined a name for poems with mixed, irregular feet, like free verse. However, while sprung rhythm allows for an indeterminate number of syllables to a foot, Hopkins was very careful to keep the number of feet he had per line consistent across each individual work, a trait that free verse does not share. Sprung rhythm may be classed as a form of accentual verse, due to its being stress-timed, rather than syllable-timed, and while sprung rhythm did not become a popular literary form, Hopkins's advocacy did assist in a revival of accentual verse more generally.
Example.
Pied Beauty
<br>
<br>Glory be to God for dappled things—
<br>For skies of couple-colour as a brinded cow;
<br>For rose-moles all in stipple upon trout that swim;
<br>Fresh-firecoal chestnut-falls; finches' wings;
<br>Landscape plotted and pieced—fold, fallow, and plough;
<br>And áll trades, their gear and tackle and trim.
<br>
<br>All things counter, original, spáre, strange;
<br>Whatever is fickle, frecklèd (who knows how?)
<br>With swíft, slów; sweet, sóur; adázzle, dím;
<br>He fathers-forth whose beauty is pást change:
<br>Práise hím.
<br>
<br>—Gerard Manley Hopkins (1844–1889)
<br>
Proposed scansion:
<br>
<br>|Glory|be to|God for|dappled|things—
<br>For|skies of|couple-|colour as a|brinded|cow;
<br>For|rose-moles|all in|stipple upon|trout that|swim;
<br>Fresh-|firecoal|chestnut-|falls;|finches'|wings;
<br>|Landscape|plotted and|pieced—fold,|fallow, and|plough;
<br>And|all|trades, their|gear and|tackle and|trim.
<br>
<br>|All things|counter, o|riginal,|spare,|strange;
<br>What|ever is|fickle,|freckled|(who knows|how?)
<br>With|swift,|slow; sweet,|sour; a|dazzle,|dim;
<br>He|fathers-|forth whose|beauty is|past|change:
<br>|Praise|him.|
<br>
References.
</dl>

</doc>
<doc id="26912" url="http://en.wikipedia.org/wiki?curid=26912" title="Sapindales">
Sapindales

Sapindales is a botanical name for an order of flowering plants. Well-known members of Sapindales include citrus; maples, horse-chestnuts, lychees and rambutans; mangos and cashews; frankincense and myrrh; mahogany and neem.
The APG III system of 2009 includes it in the clade malvids (in rosids, in eudicots) with the following 9 families:
The APG II system of 2003 allowed the optional segregation of families now included in the Nitrariaceae.
The Cronquist system of 1981 used a somewhat different circumscription, including the following families:
The difference from the APG III system is not as large as may appear, as the plants in the families Aceraceae and Hippocastanaceae stay in this order at APG III (both included in family Sapindaceae). The species now composing the family Nitrariaceae in APG III also belonged to this order in the Cronquist system as part of the family Zygophyllaceae, while those now in the family Kirkiaceae were present as part of the family Simaroubaceae.

</doc>
<doc id="26913" url="http://en.wikipedia.org/wiki?curid=26913" title="Solanales">
Solanales

The Solanales are an order of flowering plants, included in the asterid group of dicotyledons. Some older sources used the name Polemoniales for this order.
The following families are included here in newer systems such as that of the Angiosperm Phylogeny Group (APG):
The APG II classification treats the Solanales in the group Euasterids I.
Under the older Cronquist system, the latter three families were placed elsewhere, and a number of others were included:
External links.
 Media related to at Wikimedia Commons

</doc>
<doc id="26914" url="http://en.wikipedia.org/wiki?curid=26914" title="Sheepshead (game)">
Sheepshead (game)

Sheepshead or Sheephead is a trick-taking card game related to the Skat family of games. It is the Americanized version of a card game that originated in Central Europe in the late 18th century under the German name "Schafkopf". Sheepshead is most commonly played by five players, but variants exist to allow for two to eight players. There are also many other variants to the game rules, and many slang terms used with the game. 
Although Schafkopf literally means "sheepshead," it has nothing to do with sheep; the term probably was derived and translated incorrectly from Middle High German and referred to playing cards on a barrel head (from "kopf", meaning head, and "Schaff", meaning a barrel). 
In the United States, sheepshead is most commonly played in Wisconsin as well as the German counties in Southern Indiana, which has large German-American populations, and on the internet. Numerous tournaments are held throughout Wisconsin during the year, with the largest tournament being the "Nationals", held annually in the Wisconsin Dells during a weekend in September, October or November, and mini-tournaments held hourly throughout Germanfest in Milwaukee during the last weekend of each July.
Rules.
Preparation.
Sheepshead is played with 7-8-9-10-J-Q-K-A in four suits, for a total of 32 cards. This is also known as a Piquet deck, as opposed to the 52 or 54 present in a full French deck (also known as a Poker deck, or a regular deck of playing cards). A sheepshead deck is made by removing all of the jokers, sixes, fives, fours, threes, and twos from a standard deck.
Card strength.
Card strength in sheepshead is different from in most other games. It is one of the most difficult things for some beginners to grasp.
There are 14 cards in the trump suit: all four queens, all four jacks, and all of the diamonds. In order of strength from greatest to least:
Also, there are 6 of each "fail" suit (18 total).
Clubs, spades, and hearts take no precedence over other fail suits, unlike trump, which always take fail. (Notice how both aces and tens outrank kings; arguably the most confusing aspect of card strength). The lead suit must be followed if possible; if not, then any card may be played such as trump (which will take the trick), or a fail card. Playing a fail of a different suit is called "throwing off" and can be a way to clear up another suit. Additionally, throwing off a point card is called "schmearing."
Card point values.
Each card is given a separate point value as follows:
The strongest cards (queens and jacks) are not worth the most points, giving Sheepshead some of its unusual character.
There are 120 points total in the deck. The goal of the game is to get half of these (60 or 61); in case of a tie, the player who picked up the blinds loses, and that player's opponents win. (There are variant rules for more peculiar situations, such as the Leaster.)
Keeping score.
Score is kept using points (not to be confused with the point values of the cards) or using money. Points are given/taken on a zero-sum basis. 
The following chart shows the points for a five-person game (though other variations, with a different number of players, have different scoring). Points are awarded based on the point value of cards taken during the hand. When playing for money, each point generally represents a common money unit.
Doubling stakes.
Each of the following verbal declarations doubles the stakes. Each must be called before the first card is played, and players are allowed to say "hold the lead" while considering doing so. Aside from blitz and schmaltz, the rest must be called in the order indicated:
Picker may only blitz or schmaltz before picking or after being cracked. No pass-cracks allowed. After that, everything is a matter of judgment alone.
The deal.
The deck is shuffled and cut. The dealer then deals cards, starting with the player to the dealer's left, and typically two or three at a time to each person. In most standard five and six-handed games, two cards are also dealt to a separate pile called the "blind." Usually this is dealt as a pair between rounds of dealing at any time so long as the last two card is not dealt into the blind (because the dealer might inadvertently reveal the bottom card while dealing or shuffling).
When done with a five-handed deal, each player should have six cards, with two in the blind.
In one variant, a player may require a redeal if the player's hand has no aces, no face cards, and no trump.
Picking.
The player to the left of the dealer gets first choice to take the blind (the two face-down cards not dealt to any player). If he passes, the option is given to the next player (in clockwise order). There several Variations for if the dealer does not wish to pick up the blind -- the deal may be required to pick up the blind, or may have the option to call a Leaster, or may be able to call a Doubler.
The individual who takes the blind is called the "picker". The picker adds the two cards in the blind to his hand and then must choose two cards to lay down or "bury". The buried cards are added to the picker's score if the picker's side takes at least one trick.
The picker may also have a partner on his team who will then play against the remaining players. Depending on the variant or house-rule, the partner must automatically be the player with the jack of diamonds, or the picker may be able to call the ace of a fail suit and have that player be his partner. These are discussed in the Variations section.
One of the more intriguing aspects of Sheepshead is that the picker and partner change each hand, and a good deal of the game's strategy is in determining which player is the partner, as his identity is usually not revealed until after the game has begun.
Game play.
After the picker has buried his cards, the person to the left of the dealer plays the first card. Play continues clockwise until everyone has played. Then, the person who played the card with the highest strength takes the "trick" (the highest trump, or if none, the highest card of the fail suit that was led). The player who took the previous trick then plays, or "leads," a new card for the second trick. After all tricks have been taken, their point values are totaled and the winner declared, with all players adding or reducing their personal points accordingly (see the charts, above). The deal then shifts to the person to the left of the previous dealer.
Play variations.
There are a number of different play variations for Sheepshead. Variants may change how partners are chosen, scoring, the suits considered fail, or what occurs when the blind is not picked. Variations in the number of players is discussed in the next section.
Partners.
The following two variants apply only to five and six-player games, and possibly four-player games. Variants differ in whether the picker is permitted to choose to play alone, and in whether there are some situations where the picker may be "required "to play alone.
Called Ace.
The picker chooses a "called ace suit" after picking the blind. Whoever has this called ace will be his partner. There are a few further rules behind this.
Jack of diamonds.
In this variant, the partner is automatically the individual with the jack of diamonds. Unlike the Called Ace variant, the partner is not required to play the jack of diamonds with any required haste; thus the identity of the partner is usually secret for more of the game.
The normal rule is that if the picker has the jack of diamonds, whether as a result of the deal or picking up the jack in the blind, the picker must play alone. However, there are a number of variants within this method of play.
Scoring.
Calling sheepshead.
One variant allows the picker to call "sheepshead." This means that the picker believes he can take every trick. If he succeeds he receives twice the number of points for a trickless game, but if he misses a single trick (even one lacking points), he must pay twice the value his opponents would have paid him for a trickless hand.
Double on the bump.
If the picker/partner do not win, they are "bumped". The standard method of playing Sheepshead is that the picker/partner lose two times the points that opponents would lose in a similar loss. This may be called the "Punish the picker" rule. Some house rules do not enforce this "Punish" rule.
Some house rules require the picker to take at least one trick. If the picker/partner do not take at least one trick and lose, then only the picker loses points. Picker -18, partner 0, opponents +6.
Cracking.
In this variant, when a player picks up the blind, any player who was not given the opportunity to pick up the blind and who is not the picker's partner may knock or crack by knocking the table with their fist. This automatically doubles the point values determining the score when the game ends. In the "aces" variant, the crack must take place after the ace has been called but before the first card is played.
Blitzing or blitzers.
This variant allows players to double the point value of the game by revealing that they have the two black or red queens. 
Trump.
Diamonds vs. clubs.
Typically, diamonds are considered trump, but some groups use another suit (typically clubs around North Central WIsconsin). This would mean a nine of diamonds would be fail while a nine of clubs is trump instead.
Alternatively, in some groups, the strengths of the various queens and jacks differ from standard rules.
Spitz.
A variant popular in some areas of Minnesota and Wisconsin is to change the order of strength of the trump cards. This is done by increasing the seven of diamond's strength to second in the list of trump:
When playing this variant the seven of diamonds is referred to as "the Spitz". Another variation puts the seven of diamonds first in the list of trump.
No picker.
Several different scenarios can occur if no one picks up the blind, including a forced pick, a Leaster, or a Doubler.
Forced pick.
In this variant, the person on the end is required to pick the blind. This is sometimes offset by a "No Punish" rule, and statistics; if no one desired the blind, then there's a better chance that the blind has decent cards, unless the trump is evenly spread out.
Leasters.
In a leaster, the person with the fewest points wins the hand. There is no partner, and the winner simply receives one point from every opponent in the game. The blind is set aside and normally given to the player who takes the last trick. House rules may allow the dealer to declare which trick is given the blind (e.g. the first trick, or the second, etc.). Another house rule may be to set the blind aside so it is not given to anyone. The blind is not viewed until after the hand is over.
Doublers.
In a doubler, the cards are reshuffled and a new hand is dealt and played as normal. However, at the end of this redeal, the point values lost and gained are doubled.
The pot.
Typically occurring with a leaster (and during cash games), one point is placed into a pot for the next hand. Then, if the picker wins the hand, he splits the pot with the partner (in a five handed game, the extra point goes to the picker such that he receives three and the partner receives a single point). However, if the picker loses the hand, the picker and partner must pay into the pot what they would have received.
Variations in the number of players.
There are numerous variations in rules, so a discussion of house rules generally occurs before play begins. The following variations can be employed to accommodate different numbers of players.
Two-handed.
1) Each player is dealt four cards in a row, face down. Then, four cards are dealt face up to each player and placed on top of the first four cards. Then, eight cards are dealt to each player's hand. When one of the face up cards is played, the card below it is turned face up and may then be played.
2) Sixteen cards are dealt face down in a four by four rectangle. Players are not allowed to look at the face-down cards. Then, a card is dealt face up on top of these. The sixteen cards (eight stacks of two cards) closest to the dealer are the dealer's cards. A card must be face-up to be played. The opponent starts the first trick by playing one of his face-up cards, and the dealer responds by playing one of his. After each trick is played, any face-down cards uncovered are turned face-up. Play continues until all 32 cards have been played. Players are not allowed to look at their own face-down cards.
Three-handed.
1) Each player is dealt ten cards, with two going to the blind. The picker faces the other two players.
2) The sevens of clubs and spades are removed, leaving thirty cards. Nine cards are then dealt to each player, with three going to the blind. The picker faces the others.
3) The six non-trump sevens and eights are removed, dealing eight cards to each player, with two in the blind.
Four-handed.
1) Seven cards are dealt to each player with four in the blind. Given the large blind, this variation required the picker go "cut-throat "(without a partner).
2) The seven of clubs and seven of spades are removed ("or "the six of clubs and six of spades are added). Seven (or eight) cards are dealt to each player, with two in the blind. Either the jack or ace partner rules may be used.
3) Each player is dealt eight cards, with no blind. Either (A) the two players holding the black queens are partners, where the partners are secret until both cards are played, a player holding both black queens plays cut-throat against the three other; or (B) the partners are the first two queens played. In both these variations, the players with the queens (black or first two played) are considered the picker and partner for scoring purposes. In the latter variation, the timing of playing queens is important. For example, it may be worth it to waste the queen to become partners with an individual who has already taken a good trick or two, or to avoid being stuck cut-throat.
5) In this variation popular in southern Indiana, jacks are higher than queens (still clubs-spades-hearts-diamonds), and hearts (rather than diamonds) are trump. All four players are dealt eight cards. Starting with the player to the left of the dealer, the player has the option to "call" (call an fail-suit ace for a partner), go solo (cut-throat), or pass. When going solo, the player may play a "best" (pay normally against the other three), a "side solo" (call another suit rather than hearts to be trump, and then play against the other three), or a "Billy" (plays against the three others but attempts not to take a trick).
Scoring: Players play to 24 on the given system:
Five-handed.
Six cards are dealt to each player, with two to the blind. A partner may be chosen by either the ace or jack rules. The partner is the player with the called ace.
Six-handed.
1) Five cards are dealt to each player, with two cards in the blind. The partner is automatically the jack of diamonds, and the game is played two against four. If the picker gets the jack of diamonds in the blind, he/she may call the next higher jack not in his/her hand.
2) Five cards are dealt to each player, with two cards in the blind. The partner is automatically the jack of diamonds "and "the ace of the called suit, with the game played three against three. If the picker gets the jack of diamonds in the blind or the jack of diamonds has the ace of the called suit, it is played two against four.
Seven-handed.
1) Four cards are dealt to each player, with four to the blind. The picker takes all four cards from the blind, and buries four. The partner is automatically the jack of diamonds. If the picker has the jack, he/she may call up to the next highest jack not in his/her hand.
2) Four cards are dealt to each player, with four to the blind. The picker takes two cards from the blind, and the player immediately behind him takes the other two blind cards; they bury together and then play as partners against the other five. Also known as Shit-On-Your-Neighbor sheepshead.
3) Four cards are dealt to each player, with four to the blind. The picker takes three cards from the blind, and the player immediately behind him take the other card. The partner is automatically the jack of diamonds. The player behind the picker is not automatically the partner, so his bury may count towards the picker's opponents.
4) Four cards are dealt to each player, with four to the blind. A die is rolled, and the partner is whatever number is on the die with 1 representing the player to the pickers left, and counting clockwise with six being the person to the picker's right. Each takes and buries two cards.
Eight-handed.
1) Four cards are dealt to each player. The two black queens are partners.
2) Four cards are dealt to each player. The queen of clubs, jack of diamonds, and 7 of diamonds are partners. If one partner has two of these cards, they can call the 8 of diamonds (if they have the 7 and the queen or jack) or jack of hearts (if they have the queen and the jack). If the other partner already has the 8 of diamonds or jack of hearts they can call again. It should always be 3 on 5 unless the partner chooses not to call another partner.
Glossary / Slang.
The following phrases or slang can be used to describe certain behaviors or situations in the game.
Mauer.
A player "mauers" when the player has enough power-cards to pick up the blind, and yet passes (whether for fear one's hand is not actually good enough, or worse, one hopes to set up another player to lose). Mauering is considered to be in very poor taste and in some cases players who do it often enough can be asked to leave a game. Of course, mauering can backfire if the hand results in a leaster, and the mauerer is stuck with what is then a poor hand.
There are different methods of deciding if a player has a strong hand. In a five-handed game, some players pick on any four trump, while others decide based on the number of higher trump (queens and jacks). Others use a numbering system, giving each type of trump a point value and making the decision to pick based on a certain number of points. Statistically, players who have an opportunity to pick first need a stronger hand, while picking on the end usually means that since nobody else picked, the trump are fairly evenly spread out. Because of the complex nature of the game, in most cases mauering is a matter of opinion. 
Schmear.
A player "schmears" a trick by playing a high-point card (usually an ace or ten) into a trick that a player thinks will be (or has already been) taken by one of their partners, in order to increase the points earned on that trick. The term may also be a noun, referring to the high-point card played in this manner. An example of schmearing (by Opponents 2 and 3):
This trick was worth 34 points. That's schneider all by itself.
Opponent 1 is guaranteed to win the trick as the queen of clubs is the highest card. As a result, opponents 2 and 3 both took advantage of the situation and put high-counting cards down. Also note that the picker played the 8♦, a no-counting card -- the opposite of schmearing.
Schmearing is an important strategy. In this example, schmearing increased the value of the trick by 21 points to a total of 34 points -- schneider all by itself and over a quarter of the points available.
Renege (Cheating).
A player "reneges" means to fail to follow suit when able and required by the rules to do so. Reneging is a form of cheating. In most circles, this results in the guilty party forfeiting the hand.
Granny hand.
When a player holds all or most of the top trump there is no way for the opposition to win. This unusually powerful hand is often derided for its ease of play; "My granny could win that hand." The hand still counts and is played out.
In some circles, the player simply lays down the granny hand and the opponents conceding by acclamation. Even if not completely a granny hand, some circles permit a player to state that he believes he will take all of the remaining tricks (possibly requiring an explanation, say, "I have all of the remaining trump"), giving opponents an opportunity to object (say, if the calling player miscounted trump) -- forestalling the players from needing to play out the remainder of the hand.
Bumping.
When a teammate uses a higher powered card to take a trick that already is already going to his/her team -- usually when the trick is necessarily going to another teammate. Sometimes this is unavoidable especially in cases where there is only one card of a particular suit left in a player's hand. Sometimes this is strategic, such as to place an opponent on each side of the picker and/or the partner.
Collusion (Cheating).
As with any partner game, code words or signs can be used to cheat. This involves 2 players creating a word or phrase which tells their partner in crime what to lead. For instance, Player A and Player B are colluding with each other in a game of 4 handed. Player A has the lead and Player B is behind the dealer without a fail Spade. Player B uses the phrase "let's rock n' roll" to signal Player A to lead spades. Player A leads spades, the picker trumps it, and Player B trumps over the Picker. This is very much frowned upon and if caught, the players are usually kicked out of the game.
Throwing Off.
A player "throws off" when, after a fail card is played and the player does not have any of that fail suit but does have trump, decides to play a fail card rather than trump. The throw off is key to winning at Sheepshead. One must know when to throw off and when not to throw off. One popular situation to throw off is as follows and is known as "The Throw Off"; (1) a fail suit is led that the picker does not have, (2) the picker is 2nd in line, and (3) the picker throws off, usually because he has a poor hand, hoping his partner can take the trick.

</doc>
<doc id="26915" url="http://en.wikipedia.org/wiki?curid=26915" title="Linguistic relativity">
Linguistic relativity

The principle of linguistic relativity holds that the structure of a language affects the ways in which its respective speakers conceptualize their world, i.e. their world view, or otherwise influences their cognitive processes. Popularly known as the Sapir–Whorf hypothesis, or Whorfianism, the principle is often defined to include two versions. The "strong" version says that language determines thought, and that linguistic categories limit and determine cognitive categories, whereas the "weak" version says only that linguistic categories and usage influence thought and certain kinds of non-linguistic behavior.
The term "Sapir–Whorf hypothesis" is considered a misnomer by linguists for several reasons: because Edward Sapir and Benjamin Lee Whorf never co-authored anything, and never stated their ideas in terms of a hypothesis. The distinction between a weak and a strong version of this hypothesis is also a later invention; Sapir and Whorf never set up such a dichotomy, although often in their writings their views of this relativity principle are phrased in stronger or weaker terms.
The idea was first clearly expressed by 19th-century thinkers, such as Wilhelm von Humboldt, who saw language as the expression of the spirit of a nation. Members of the early 20th-century school of American anthropology headed by Franz Boas and Edward Sapir also embraced forms of the idea to one extent or another, but Sapir in particular wrote more often against than in favor of anything like linguistic determinism. Sapir's student, Benjamin Lee Whorf, came to be seen as the primary proponent as a result of his published observations of how he perceived linguistic differences to have consequences in human cognition and behavior. Harry Hoijer, one of Sapir's students, introduced the term "Sapir–Whorf hypothesis", even though the two scholars never formally advanced any such hypothesis. A strong version of relativist theory was developed from the late 1920s by the German linguist Leo Weisgerber. Whorf's principle of linguistic relativity was reformulated as a testable hypothesis by Roger Brown and Eric Lenneberg who conducted experiments designed to find out whether color perception varies between speakers of languages that classified colors differently. As the study of the universal nature of human language and cognition came into focus in the 1960s the idea of linguistic relativity fell out of favor among linguists. A 1969 study by Brent Berlin and Paul Kay demonstrated the existence of universal semantic constraints in the field of color terminology which were widely seen to discredit the existence of linguistic relativity in this domain, although this conclusion has been disputed by relativist researchers.
From the late 1980s a new school of linguistic relativity scholars have examined the effects of differences in linguistic categorization on cognition, finding broad support for non-deterministic versions of the hypothesis in experimental contexts. Some effects of linguistic relativity have been shown in several semantic domains, although they are generally weak. Currently, a balanced view of linguistic relativity is espoused by most linguists holding that language influences certain kinds of cognitive processes in non-trivial ways, but that other processes are better seen as arising from connectionist factors. Research is focused on exploring the ways and extent to which language influences thought. The principle of linguistic relativity and the relation between language and thought has also received attention in varying academic fields from philosophy to psychology and anthropology, and it has also inspired and colored works of fiction and the invention of constructed languages.
Definitional issues and debates.
The concept of linguistic relativity holds that cognitive processes, such as thought and experience, may be influenced by the categories and patterns of the language a person speaks. Empirical research into the question has been associated mainly with the names of Benjamin Lee Whorf, who wrote on the topic in the 1930s, and his mentor Edward Sapir, who did not, himself, write extensively on the topic. Whorf's writings became the focus of empirical studies in psychology in the mid 20th century, and this strand of research often referred to the question as the Sapir-Whorf Hypothesis, or sometimes the Whorfian hypothesis. This usage has been criticized as a misnomer, since Sapir and Whorf did not in fact formulate a hypothesis for empirical research, and because it is unclear to what extent Sapir actually subscribed to the idea of language influencing thought. Currently, researchers prefer to use Whorf's own terminology, by referring to the principle of linguistic relativity. This formulation implicitly acknowledges that Sapir and Whorf were not the first or only scholars to have theorized about relations between language and thought and that other strands of thinking about the issue also exist.
Linguistic determinism.
A main point of debate in the discussion of linguistic relativity is the correlation between language and thought. The strongest form of correlation is linguistic determinism, which would hold that language entirely determines the range of possible cognitive processes of an individual. This view has sometimes been attributed to Benjamin Lee Whorf, and to Ludwig Wittgenstein, but it is not currently the consensus that either of these thinkers actually espoused determinist views of the relation between language and thought. Linguistic determinism is also sometimes described as "the strong Sapir-Whorf hypothesis", while other forms of correlation are referred to as "the weak Sapir-Whorf hypothesis". The notion of "weak" and "strong" versions of Whorf's principle of linguistic relativity is a misunderstanding of Whorf promulgated by Stuart Chase, whom Whorf considered "utterly incompetent by training and background to handle such a subject." Neither Sapir nor Whorf ever suggested a distinction between weak or strong versions of their views. The hypothesis of linguistic determinism is now generally agreed to be false, but weaker forms of correlation are still being studied by many researchers, often producing positive empirical evidence for a correlation.
Relation to debates in science and philosophy.
The question bears on many significant philosophical, psychological, linguistic and anthropological debates.
A major question of debate is of whether human psychological faculties are mostly universal and innate or whether they are mostly a result of learning, and hence subject to cultural and social processes that vary between places and times. The universalist view holds that all humans share the same set of basic faculties, and that variability due to cultural differences is negligible. This position often sees the human mind as a mostly biological construction, so that all humans sharing the same neurological configuration can be expected to have similar or identical basic cognitive patterns. The contrary position can be described as constructivist, stating that human faculties and concepts are largely influenced by socially constructed and learned categories, that is not subject to many biological restrictions. Or it can be described as idealist, holding that the human mental capacities are generally unrestricted by its biological-material basis. And it can be described as essentialist, holding that there may be essential differences in the ways individuals or groups experience and conceptualize the world. It may also be described as relativist, basically a kind of Cultural relativism, which sees different cultural groups as having different conceptual schemes that are not necessarily compatible or commensurable, nor more or less in accord with the external reality.
Another question that bears on the debate is about the relation between language and thought. Some philosophers and psychologists have tended to understand thought as basically a form of internal speech, suggesting that either this speech must be innate or thought has to be learned while acquiring language. Others have understood thought as experience and reason, as independent of and before language.
In the philosophy of language the debate has relevance for the question of the relation between language, knowledge and the external world, and the concept of truth. Some philosophers (e.g. Putnam, Fodor, Davidson, Dennett) see language as representing directly entities that already exist in the objective world, and that categorization is therefore not generally variable but to some extent pre-given. Other philosophers (e.g. Wittgenstein, Quine, Searle, Foucault) argue that categorization and conceptualization is learned and basically arbitrary, and that the objects in the world can be categorized in multiple ways, giving rise to different ways of describing or understanding the same phenomena. Philosophers also vary in the question of whether language is basically a tool for representing and referring to objects in the world, or whether it is a system used to construct mental representations of the world that can be shared and circulated between people.
Because of the centrality of the question of the relation between thought and language to these debates, the issue of linguistic relativity has received attention not only from linguists and psychologists, but from anthropologists, philosophers, literary theorists and political scientists.
History.
The idea that language and thought are intertwined goes back to the classical civilizations. Famously Plato argued against sophist thinkers such as Gorgias of Leontini, who held the physical world cannot be experienced except through language; this meant that for Gorgias the question of truth was dependent on aesthetic preferences or functional consequences. Contrary to this idea Plato held that the world consisted in pregiven eternal ideas and that language in order to be true should strive to reflect these ideas as accurately as possible. Following Plato, St. Augustine, for example, held the view that language was merely labels applied to already existing concepts, and this view remained prevalent throughout the Middle Ages. Others, such as Roger Bacon, held the opinion that language was but a veil covering up the eternal truths hiding them from real human experience. For Immanuel Kant, language was but one of several tools used by humans to experience the world.
German Romantic philosophers.
In the late 18th and early 19th century the idea of the existence of different national characters, or "Volksgeister", of different ethnic groups was the moving force behind the German school of national romanticism and the beginning ideologies of ethnic nationalism.
In 1820, Wilhelm von Humboldt connected the study of language to the national romanticist program by proposing the view that language is the very fabric of thought. That is, thoughts are produced as a kind of internal dialog using the same grammar as the thinker's native language. This view was part of a larger picture in which the world view of an ethnic nation, their "Weltanschauung", was seen as being faithfully reflected in the grammar of their language. Von Humboldt argued that languages with an inflectional morphological type, such as German, English and the other Indo-European languages were the most perfect languages and that accordingly this explained the dominance of their speakers over the speakers of less perfect languages. Wilhelm von Humboldt declared in 1820:
The diversity of languages is not a diversity of signs and sounds but a diversity of views of the world.
Boas and Sapir.
The idea that some languages were naturally superior to others and that the use of primitive languages maintained their speakers in intellectual poverty was widespread in the early 20th century. The American linguist William Dwight Whitney, for example, actively strove to eradicate the Native American languages arguing that their speakers were savages and would be better off abandoning their languages and learning English and adopting a civilized way of life. The first anthropologist and linguist to challenge this view was Franz Boas who was educated in Germany in the late 19th century where he received his doctorate in physics. While undertaking geographical research in northern Canada he became fascinated with the Inuit people and decided to become an ethnographer. In contrast to von Humboldt, Boas always stressed the equal worth of all cultures and languages, and argued that there was no such thing as primitive languages, but that all languages were capable of expressing the same content albeit by widely differing means. Boas saw language as an inseparable part of culture and he was among the first to require of ethnographers to learn the native language of the culture being studied, and to document verbal culture such as myths and legends in the original language.
According to Franz Boas:
It does not seem likely [...] that there is any direct relation between the culture of a tribe and the language they speak, except in so far as the form of the language will be moulded by the state of the culture, but not in so far as a certain state of the culture is conditioned by the morphological traits of the language."
Boas' student Edward Sapir reached back to the Humboldtian idea that languages contained the key to understanding the differing world views of peoples. In his writings he espoused the viewpoint that because of the staggering differences in the grammatical systems of languages no two languages were ever similar enough to allow for perfect translation between them. Sapir also thought because language represented reality differently, it followed that the speakers of different languages would perceive reality differently. According to Edward Sapir:
No two languages are ever sufficiently similar to be considered as representing the same social reality. The worlds in which different societies live are distinct worlds, not merely the same world with different labels attached.
On the other hand, Sapir explicitly rejected strong linguistic determinism by stating, "It would be naïve to imagine that any analysis of experience is dependent on pattern expressed in language."
Sapir was explicit that the connections between language and culture were neither thoroughgoing nor particularly deep, if they existed at all:
It is easy to show that language and culture are not intrinsically associated. Totally unrelated languages share in one culture; closely related languages—even a single language—belong to distinct culture spheres. There are many excellent examples in Aboriginal America. The Athabaskan languages form as clearly unified, as structurally specialized, a group as any that I know of. The speakers of these languages belong to four distinct culture areas... The cultural adaptability of the Athabaskan-speaking peoples is in the strangest contrast to the inaccessibility to foreign influences of the languages themselves.
Sapir offers similar observations about speakers of so-called "world" or "modern" languages, noting that "possession of a common language is still and will continue to be a smoother of the way to a mutual understanding between England and America, but it is very clear that other factors, some of them rapidly cumulative, are working powerfully to counteract this leveling influence. A common language cannot indefinitely set the seal on a common culture when the geographical, physical, and economics determinants of the culture are no longer the same throughout the area."
While Sapir never made a point of studying directly how languages affected the thought processes of their speakers, some notion of (probably "weak") linguistic relativity lay inherent in his basic understanding of language, and would be taken up by his student Benjamin Lee Whorf.
Drawing on influences such as Humboldt or Friedrich Nietzsche some European thinkers developed similar ideas to those of Sapir and Whorf, generally working in isolation from one another. Prominent in Germany from the late 1920s through into the 1960s were the strongly relativist theories of Leo Weisgerber and his key concept of a 'linguistic inter-world', mediating between external reality and the forms of a given language, in ways peculiar to that language. Russian psychologist Lev Vygotsky read Sapir's work and experimentally studied the ways in which the development of concepts in children was influenced by structures given in language. His theories and results were published in 1934 as "Thought and Language" Vygotsky's ideas have been compared to Whorf's and taken as mutually supportive evidence of language's influence on cognition. Drawing on Nietzsche's ideas of perspectivism Alfred Korzybski developed the theory of general semantics which has been compared to Whorf's notions of linguistic relativity. Though influential in their own right, these strands of research have not been given much attention in the debate surrounding linguistic relativity, which has tended to center on the American paradigm exemplified by Sapir and Whorf.
Benjamin Lee Whorf.
More than any other linguist, Benjamin Lee Whorf has become associated with what he called "the principle of linguistic relativity". Instead of merely assuming that language influences the thought and behavior of its speakers (after Humboldt and Sapir) he looked at Native American languages and attempted to account for the ways in which differences in grammatical systems and language use affected the way their speakers perceived the world. Whorf was also concerned with how a scientific account of the world differed to such an extent from a religious account, which led him to study the languages of old religious scripture and to write several anti-evolutionist pamphlets There is not a lot of agreement about Whorf's opinions regarding the nature of the relation between language and thought. One tradition of interpretation, exemplified by his critics such as Eric Lenneberg, Max Black and Steven Pinker, attributes to Whorf a very strong view of linguistic determinism, according to which commensuration between conceptual schemes and translation between languages are impossible. Another tradition of interpretation, exemplified in the work of linguists including John A. Lucy, Michael Silverstein and Stephen C. Levinson, points to the many places in Whorf's writings where he explicitly rejects determinism, and where he clearly notes that translation and commensuration between linguistic conceptual schemes is possible. This line of interpretation suggests that a more sympathetic reading of Whorf would lead to a greater understanding of the subtleties in Whorf's use of terminology and consequently to resolving some of the apparent contradictions noted by Whorf's critics.
Whorf has sometimes been dismissed as an 'amateur' because of his lack of an advanced degree in linguistics. However, his not having a degree in linguistics cannot be taken to mean that he was linguistically incompetent. The reputation he had during his lifetime belies this idea: his academic peers at Yale University considered the 'amateur' Whorf to be the best man available to take over Sapir's graduate seminar in Native American linguistics while Sapir was on sabbatical in 1937–38. He was highly regarded by authorities such as Boas, Sapir, Leonard Bloomfield and Alfred M. Tozzer. Indeed, John A. Lucy writes: "despite his 'amateur' status, Whorf's work in linguistics was and still is recognized as being of superb professional quality by linguists".
Still, detractors such as Eric Lenneberg, Noam Chomsky and Steven Pinker have criticized him for not being sufficiently clear in his formulation of how he meant language influences thought, and for not providing actual proof for his conjectures. Most of his arguments were in the form of examples that were anecdotal or speculative in nature, and functioned as attempts to show how 'exotic' grammatical traits were connected to what were apparently equally exotic worlds of thought. In Whorf's words:
We dissect nature along lines laid down by our native language. The categories and types that we isolate from the world of phenomena we do not find there because they stare every observer in the face; on the contrary, the world is presented in a kaleidoscope flux of impressions which has to be organized by our minds—and this means largely by the linguistic systems of our minds. We cut nature up, organize it into concepts, and ascribe significances as we do, largely because we are parties to an agreement to organize it in this way—an agreement that holds throughout our speech community and is codified in the patterns of our language [...] all observers are not led by the same physical evidence to the same picture of the universe, unless their linguistic backgrounds are similar, or can in some way be calibrated.
Among Whorf's best-known examples of linguistic relativity are instances where an indigenous language has several terms for a concept that is only described with one word in English and other European languages (Whorf used the acronym SAE "Standard Average European" to allude to the rather similar grammatical structures of the well-studied European languages in contrast to the greater diversity of the less-studied languages). One of Whorf's examples of this phenomenon was the supposedly large number of words for 'snow' in the Inuit language, an example which some have later contested as a misrepresentation. Another of Whorf's examples are the Hopi language words for water, one indicating drinking water in a container and another indicating a natural body of water. These examples of polysemy served the double purpose of showing that indigenous languages sometimes made more fine grained semantic distinctions than European languages and that direct translation between two languages, even of seemingly basic concepts like snow or water, is not always possible.
Another example in which Whorf attempted to show that language use affects behavior came from his experience in his day job as a chemical engineer working for an insurance company as a fire inspector. On inspecting a chemical plant he once observed that the plant had two storage rooms for gasoline barrels, one for the full barrels and one for the empty ones. He further noticed that while no employees smoked cigarettes in the room for full barrels, no-one minded smoking in the room with empty barrels, although this was potentially much more dangerous because of the highly flammable vapors that still existed in the barrels. He concluded that the use of the word "empty" in connection to the barrels had led the workers to unconsciously regard them as harmless, although consciously they were probably aware of the risk of explosion from the vapors. This example was later criticized by Lenneberg as not actually demonstrating causality between the use of the word "empty" and the action of smoking, but instead being an example of circular reasoning. Steven Pinker in "The Language Instinct" ridiculed this example, claiming that this was a failing of human insight rather than language.
Whorf's most elaborate argument for the existence of linguistic relativity regarded what he believed to be a fundamental difference in the understanding of time as a conceptual category among the Hopi. He argued that in contrast to English and other SAE languages, the Hopi language does not treat the flow of time as a sequence of distinct, countable instances, like "three days" or "five years," but rather as a single process and that consequentially it does not have nouns referring to units of time as SAE speakers understand them. He proposed that this view of time was fundamental in all aspects of Hopi culture and explained certain Hopi behavioral patterns. However, later Malotki (1983), who researched Hopi, claimed that he found no evidence of Whorf's claims in 1980's era speakers, nor in historical documents going back to the preconquest era. Malotki used evidence from archaeological data, calendars, historical documents, modern speech and concluded that there was no evidence that Hopi conceptualize time the way Whorf suggests. Universalist scholars such as Steven Pinker often see Malotki's study as a final refutation of Whorf's claim about Hopi, whereas relativist scholars such as John A Lucy and Penny Lee have criticized Malotki's study for mischaracterizing Whorf's claims and for forcing Hopi grammar into a pregiven model of analysis that doesn't fit the data.
Whorf died in 1941 at age 44 and left behind a number of unpublished papers. His line of thought was continued by linguists and anthropologists such as Harry Hoijer and Dorothy D. Lee who both continued investigations into the effect of language on habitual thought, and George L. Trager who prepared a number of Whorf's left-behind papers for publishing. The most important event for the dissemination of Whorf's ideas to a larger public was the publication in 1956 of his major writings on the topic of linguistic relativity in a single volume titled "Language, Thought and Reality," edited by J. B. Carroll.
Eric Lenneberg.
In 1953 psychologist Eric Lenneberg published a detailed criticism of the line of thought that had been fundamental for Sapir and Whorf. He criticized Whorf's examples from an objectivist view of language holding that languages are principally meant to represent events in the real world and that even though different languages express these ideas in different ways, the meanings of such expressions and therefore the thoughts of the speaker are equivalent. He argued that when Whorf was describing in English how a Hopi speaker's view of time was different, he was in fact translating the Hopi concept into English and therefore disproving the existence of linguistic relativity. He did not address the fact that Whorf was not principally concerned with translatability, but rather with how the habitual "use" of language influences habitual behavior. Whorf's point was that while English speakers may be able to "understand" how a Hopi speaker thinks, they are not actually able to "think" in that way.
Lenneberg's main criticism of Whorf's works was that he had never actually shown the causality between a linguistic phenomenon and a phenomenon in the realm of thought or behavior, but merely assumed it to be there. Together with his colleague, Roger Brown, Lenneberg proposed that in order to prove such a causality one would have to be able to directly correlate linguistic phenomena with behavior. They took up the task of proving or disproving the existence of linguistic relativity experimentally and published their findings in 1954.
Since neither Sapir nor Whorf had ever stated an actual hypothesis, Brown and Lenneberg formulated one based on a condensation of the different expressions of the notion of linguistic relativity in their works. They identified the two tenets of the Whorf thesis as (i) "the world is differently experienced and conceived in different linguistic communities" and (ii) "language causes a particular cognitive structure". These two tenets were later developed by Roger Brown into the so-called "weak" and "strong" formulation respectively:
1. Structural differences between language systems will, in general, be paralleled by nonlinguistic cognitive differences, of an unspecified sort, in the native speakers of the language.
2. The structure of anyone's native language strongly influences or fully determines the worldview he will acquire as he learns the language.
It is these two formulations of Roger Brown's which have become widely known and attributed to Whorf and Sapir while in fact the second formulation, verging on linguistic determinism, was never advanced by either of them.
Since Brown and Lenneberg believed that the objective reality denoted by language was the same for speakers of all languages, they decided to test how different languages codified the same message differently and whether differences in codification could be proven to affect behavior.
They designed a number of experiments involving the codification of colors. In their first experiment, they investigated whether it was easier for speakers of English to remember color shades for which they had a specific name than to remember colors that were not as easily definable by words. This allowed them to correlate the linguistic categorization directly to a non-linguistic task, that of recognizing and remembering colors. In a later experiment, speakers of two languages that categorize colors differently (English and Zuni) were asked to perform tasks of color recognition. In this way, it could be determined whether the differing color categories of the two speakers would determine their ability to recognize nuances within color categories. Brown and Lenneberg in fact found that Zuñi speakers who classify green and blue together as a single category did have trouble recognizing and remembering nuances within the green/blue category. Brown and Lenneberg's study became the beginning of a tradition of investigation of the linguistic relativity through color terminology (see below).
Universalist period.
Lenneberg was also one of the first cognitive scientists to begin development of the Universalist theory of language which was finally formulated by Noam Chomsky in the form of Universal Grammar, effectively arguing that all languages share the same underlying structure. The Chomskyan school also holds the belief that linguistic structures are largely innate and that what are perceived as differences between specific languages – the knowledge acquired by learning a language – are merely surface phenomena and do not affect cognitive processes that are universal to all human beings.
This theory became the dominant paradigm in American linguistics from the 1960s through the 1980s and the notion of linguistic relativity fell out of favor and became even the object of ridicule.
An example of the influence of universalist theory in the 1960s is the studies by Brent Berlin and Paul Kay who continued Lenneberg's research in color terminology. Berlin and Kay studied color terminology formation in languages and showed clear universal trends in color naming. For example, they found that even though languages have different color terminologies, they generally recognize certain hues as more focal than others. They showed that in languages with few color terms, it is predictable from the number of terms which hues are chosen as focal colors, for example, languages with only three color terms always have the focal colors black, white and red. The fact that what had been believed to be random differences between color naming in different languages could be shown to follow universal patterns was seen as a powerful argument against linguistic relativity. Berlin and Kay's research has since been criticized by relativists such as John A. Lucy, who has argued that Berlin and Kay's conclusions were skewed by their insistence that color terms should encode only color information. This, Lucy argues, made them blind to the instances in which color terms provided other information that might be considered examples of linguistic relativity.
Other universalist researchers dedicated themselves to dispelling other notions of linguistic relativity, often attacking specific points and examples given by Whorf. For example, Ekkehart Malotki's monumental study of time expressions in Hopi presented many examples that challenged Whorf's interpretation of Hopi language and culture as being "timeless".
Today many followers of the universalist school of thought still oppose the idea of linguistic relativity. For example, Steven Pinker argues in his book "The Language Instinct" that thought is independent of language, that language is itself meaningless in any fundamental way to human thought, and that human beings do not even think in "natural" language, i.e. any language that we actually communicate in; rather, we think in a meta-language, preceding any natural language, called "mentalese." Pinker attacks what he calls "Whorf's radical position," declaring, "the more you examine Whorf's arguments, the less sense they make."
Pinker and other universalist opponents of the linguistic relativity hypothesis have been accused by relativists of misrepresenting Whorf's views and arguing against strawmen put up by themselves.
Fishman's 'Whorfianism of the third kind'.
Joshua Fishman argued that Whorf's true position was for a long time largely overlooked by most linguists. In 1978, he suggested that Whorf was a 'neo-Herderian champion'
and in 1982, he proposed his 'Whorfianism of the third kind' in an attempt to refocus linguists' attention on what he claimed was Whorf's real interest, namely the intrinsic value of 'little peoples' and 'little languages'. Whorf had expressed the sentiment thus:
But to restrict thinking to the patterns merely of English […] is to lose a power of thought which, once lost, can never be regained. It is the 'plainest' English which contains the greatest number of unconscious assumptions about nature. […] We handle even our plain English with much greater effect if we direct it from the vantage point of a multilingual awareness.
Where Brown's weak version of the linguistic relativity hypothesis proposes that language "influences" thought and the strong version that language "determines" thought, Fishman's 'Whorfianism of the third kind' proposes that language "is a key to culture".
Cognitive linguistics.
In the late 1980s and early 1990s, advances in cognitive psychology and cognitive linguistics renewed interest in the Sapir–Whorf hypothesis. One of those who adopted a more Whorfian approach was George Lakoff. He argued that language is often used metaphorically and that languages use different cultural metaphors that reveal something about how speakers of that language think. For example, English employs metaphors likening time with money, whereas other languages may not talk about time in that fashion. Other linguistic metaphors may be common to most languages because they are based on general human experience, for example, metaphors likening "up" with "good" and "bad" with "down". Lakoff also argues that metaphor plays an important part in political debates where it matters whether one is arguing in favor of the "right to life" or against the "right to choose"; whether one is discussing "illegal aliens" or "undocumented workers".
In his book "Women, Fire and Dangerous things: What categories reveal about the mind," Lakoff reappraised the hypothesis of linguistic relativity and especially Whorf's views about how linguistic categorization reflects and/or influences mental categories. He concluded that the debate on linguistic relativity had been confused and resultingly fruitless. He identified four parameters on which researchers differed in their opinions about what constitutes linguistic relativity. One parameter is the degree and depth of linguistic relativity. Some scholars believe that a few examples of superficial differences in language and associated behavior are enough to demonstrate the existence of linguistic relativity, while others contend that only deep differences that permeate the linguistic and cultural system suffice as proof. A second parameter is whether conceptual systems are to be seen as absolute or whether they can be expanded or exchanged during the lifetime of a human being. A third parameter is whether translatability is accepted as a proof of similarity or difference between concept systems or whether it is rather the actual habitual use of linguistic expressions that is to be examined. A fourth parameter is whether to view the locus of linguistic relativity as being in the language or in the mind. Lakoff concluded that since many of Whorf's critics had criticized him using definitions of linguistic relativity that Whorf did not himself use, their criticisms were often ineffective.
The publication of the 1996 anthology "Rethinking linguistic relativity" edited by sociolinguist John J. Gumperz and psycholinguist Stephen C. Levinson marked the entrance to a new period of linguistic relativity studies and a new way of defining the concept that focused on cognitive as well as social aspects of linguistic relativity. The book included studies by cognitive linguists sympathetic to the hypothesis as well as some working in the opposing universalist tradition. In this volume, cognitive and social scientists laid out a new paradigm for investigations in linguistic relativity. Levinson presented research results documenting rather significant linguistic relativity effects in the linguistic conceptualization of spatial categories between languages. Two separate studies by Melissa Bowerman and Dan I. Slobin treated the role of language in cognitive processes. Bowerman showed that certain cognitive processes did not use language to any significant extent and therefore could not be subject to effects of linguistic relativity. Slobin described another kind of cognitive process that he named "thinking for speaking" – the kind of processes in which perceptional data and other kinds of prelinguistic cognition are translated into linguistic terms for the purpose of communicating them to others. These, Slobin argues, are the kinds of cognitive process that are at the root of linguistic relativity.
Present status.
Current researchers such as Lera Boroditsky, John A. Lucy and Stephen C. Levinson believe that language influences thought, but in more limited ways than the broadest early claims. Exploring these parameters has sparked novel research that increases both scope and precision of prior examinations. Current studies of linguistic relativity are neither marked by the naive approach to exotic linguistic structures and their often merely presumed effect on thought that marked the early period, nor are they ridiculed and discouraged as in the universalist period. Instead of proving or disproving a theory, researchers in linguistic relativity now examine the interface between thought (or cognition), language and culture, and describe the degree and kind of interrelatedness or influence. Following the tradition of Lenneberg, they use experimental data to back up their conclusions. Paul Kay, co-author of the seminal work about color naming, ultimately reached the conclusion that "[the] Whorf hypothesis is supported in the right visual field but not the left". His findings show that taking in account brain lateralization allows another perspective on the debate.
Psycholinguistic studies have gone far beyond color perception (although that is still studied), having explored motion perception, emotion perception, object representation, and memory. The gold standard of psycholinguistic studies on linguistic relativity is now finding cognitive differences in speakers of different language when no language is involved in an experimental task (thus rendering inapplicable Pinker's claim that linguistic relativity is "circular").
Recent work with bilingual speakers attempts to tease apart the effects of language from the effects of culture on aspects of bilingual cognition including perceptions of time, space, motion, colors, and emotion. Researchers have described differences between bilinguals and monolinguals in perception of color, representations of time, or other elements of cognition.
Empirical research.
John Lucy has identified three main strands of research into linguistic relativity. The first is what he calls the "structure centered" approach. This approach starts with observing a structural peculiarity in a language and goes on to examine its possible ramifications for thought and behavior. The first example of this kind of research is Whorf's observation of discrepancies between the grammar of time expressions in Hopi and English. More recent research in this vein is the research made by John Lucy describing how usage of the categories of grammatical number and of numeral classifiers in the Mayan language Yucatec result in Mayan speakers classifying objects according to material rather than to shape as preferred by speakers of English.
The second strand of research is the "domain centered" approach, in which a semantic domain is chosen and compared across linguistic and cultural groups for correlations between linguistic encoding and behavior. The main strand of domain centered research has been the research on color terminology, although this domain according to Lucy and admitted by color terminology researchers such as Paul Kay, is not optimal for studying linguistic relativity, because color perception, unlike other semantic domains, is known to be hard wired into the neural system and as such subject to more universal restrictions than other semantic domains. Since the tradition of research on color terminology is by far the largest area of research into linguistic relativity it is described below in its own section.
Another semantic domain which has proven fruitful for studies of linguistic relativity is the domain of space. Spatial categories vary greatly between languages and recent research has shown that speakers rely on the linguistic conceptualization of space in performing many quotidian tasks. Research carried out by Stephen C. Levinson and other cognitive scientists from the Max Planck Institute for Psycholinguistics has reported three basic kinds of spatial categorization and while many languages use combinations of them some languages exhibit only one kind of spatial categorization and corresponding differences in behavior. For example the Australian language Guugu Yimithirr only uses absolute directions when describing spatial relations — the position of everything is described by using the cardinal directions. A speaker of Guugu yimithirr will define a person as being "north of the house", while a speaker of English may say that he is "in front of the house" or "to the left of the house" depending on the speaker's point of view. This difference makes Guugu yimithirr speakers better at performing some kinds of tasks, such as finding and describing locations in open terrain, whereas English speakers perform better in tasks regarding the positioning of objects relative to the speaker (for example telling someone to set a round table putting forks to the right of the plate and knives to the left would be extremely difficult in Guugu yimithirr).
The third strand of research is the "behavior centered" approach which starts by observing different behavior between linguistic groups and then proceeds to search for possible causes for that behavior in the linguistic system. This kind of approach was used by Whorf when he attributed the occurrence of fires at a chemical plant to the workers' use of the word 'empty' to describe the barrels containing only explosive vapors. One study in this line of research has been conducted by Bloom who noticed that speakers of Chinese had unexpected difficulties answering counter-factual questions posed to them in a questionnaire. After a study, he concluded that this was related to the way in which counter-factuality is marked grammatically in the Chinese language. However, other researchers have attributed this result to flawed translations that Bloom used. Another line of study by Frode Strømnes examined why Finnish factories had a higher occurrence of work related accidents than similar Swedish ones. He concluded that cognitive differences between the grammatical usage of Swedish prepositions and Finnish cases could have caused Swedish factories to pay more attention to the work process where Finnish factory organizers paid more attention to the individual worker.
Another widely publicized project with relevance to linguistic relativity is Daniel Everett's work on the Pirahã language of the Brazilian Amazon. Everett observed several peculiarities in Pirahã culture that he interpreted as corresponding to linguistically rare features, such as a lack of numbers and color terms in the way those are normally defined, and a lack of certain types of clauses. Everett's conclusions about the exceptional status of the Pirahã have been met with skepticism from universalists, who disagree with his conclusions. That is, these critics argue, the lack of need for numbers and color discrimination explains both the lack of counting ability and the lack of color vocabulary.
Recent research with non-linguistic experiments in languages with different grammatical properties (e.g., languages with and without numeral classifiers or with different gender grammar systems) showed that there are—to a certain degree—differences in human categorization due to such differences. But there is also experimental research suggesting, that this linguistic influence on thought is not of long continuance, but diminishes rapidly over time, when speakers of one language are immersed by another.
Color terminology research.
The tradition of using the semantic domain of color names as an object for investigation of linguistic relativity began with Lenneberg and Roberts' 1953 study of Zuni color terms and color memory, and Brown and Lenneberg's 1954 study of English color terms and color memory. The studies showed a correlation between the availability of color terms for specific colors and the ease with which those colors were remembered in both speakers of Zuni and English. Researchers concluded that this had to do with properties of the focal colors having higher codability than less focal colors, and not with linguistic relativity effects. Berlin and Kay's 1969 study of color terms across languages concluded that there are universal typological principles of color naming that are determined by biological factors with little or no room for relativity related effects. This study sparked a long tradition of studies into the typological universals of color terminology. Some researchers such as John A Lucy, Barbara Saunders and Stephen C Levinson have argued that Berlin and Kay's study does not in fact show that linguistic relativity in color naming is impossible, because of a number of basic unsupported assumptions in their study (such as whether all cultures in fact have a category of "color" that can be unproblematically defined and equated with the one found in Indo-European languages) and because of problems with their data stemming from those basic assumptions. Other researchers such as Robert E. Maclaury have continued investigation into the evolution of color names in specific languages, refining the possibilities of basic color term inventories. Like Berlin and Kay, Maclaury found no significant room for linguistic relativity in this domain, but rather concluded as did Berlin and Kay that the domain is governed mostly by physical-biological universals of human color perception.
Outside of science.
The hypothesis of linguistic relativity has inspired many to think about how it might be possible to influence thought by consciously manipulating language.
Therapy and self-development.
Already as Sapir and Whorf were formulating the ideas of linguistic relativity, Polish-American engineer Alfred Korzybski was independently developing his theory of General Semantics which was aimed at using language's influence on thinking to maximize human cognitive abilities. Korzybski's thinking was influenced by logical philosophy such as Russel and Whitehead's "Principia Mathematica" and Wittgenstein's "Tractatus Logico-Philosophicus"." Although Korzybski was not aware of Sapir and Whorf's writings when he developed his thinking, the movement was followed by Whorf's admirer Stuart Chase, who fused Whorf's interest in cultural-linguistic variation with Korzybski's programme in his popular work "The Tyranny of Words". Another follower and popularizer of Korzybski's work was S. I. Hayakawa, who wrote "Language in Thought and Action". The General Semantics movement in turn influenced the development of Neurolinguistic programming, another therapeutic technique that seeks to use awareness of language use to influence cognitive patterns.
Independently of Whorf and Sapir, Korzybski described the basic principle of his theory in a way that is a "strong" version of the hypothesis of linguistic relativity.
We do not realize what tremendous power the structure of an habitual language has. It is not an exaggeration to say that it enslaves us through the mechanism of s[emantic] r[eactions] and that the structure which a language exhibits, and impresses upon us unconsciously, is automatically projected upon the world around us.—Korzybski (1930) in "Science & Sanity" p. 90
Artificial languages.
In their fiction, authors such as Ayn Rand and George Orwell have explored how linguistic relativity might be exploited for political purposes. In Rand's "Anthem", a fictive communist society has removed the possibility of individualism by removing the word "I" from the language, and in Orwell's "1984" the authoritarian state has created the language Newspeak to make it impossible for people to think critically about the government.
Others have been fascinated by the possibilities of creating new languages that could enable new, and perhaps better, ways of thinking. Examples of such languages designed to explore the human mind include Loglan, explicitly designed by its inventor James Cooke Brown to test the hypothesis of linguistic relativity, by experimenting whether it would make its speakers think more logically. Speakers of Lojban, a development of Loglan, report that they feel speaking the language enhances their ability for logical thinking. Suzette Haden Elgin, who also was involved in the early development of neurolinguistic programming, invented the language Láadan, specifically devised to explore linguistic relativity, by making it easier to express what Elgin considered the female worldview, as opposed to Standard Average European languages which she considers to convey a "male centered" world view. Also the language Ithkuil developed by John Quijada, has been designed with linguistic relativity in mind, exploring the limits of how many cognitive categories a language can make use of, and keep its speakers aware of at a single time.
Programming languages.
Kenneth E. Iverson, the originator of the APL programming language, believed that the Sapir–Whorf hypothesis applied to computer languages (without actually mentioning the hypothesis by name). His Turing award lecture, "Notation as a tool of thought", was devoted to this theme, arguing that more powerful notations aided thinking about computer algorithms.
The essays of Paul Graham explore similar themes, such as a conceptual hierarchy of computer languages, with more expressive and succinct languages at the top. Thus, the so-called "blub" paradox (after a hypothetical programming language of average complexity called "Blub") says that anyone preferentially using some particular programming language will "know" that it is more powerful than some, but not that it is less powerful than others. The reason is that "writing" in some language means "thinking" in that language. Hence the paradox, because typically programmers are "satisfied with whatever language they happen to use, because it dictates the way they think about programs".
In a 2003 presentation at an open source convention, Yukihiro Matsumoto, creator of the programming language Ruby, said that one of his inspirations for developing the language was the science fiction novel "Babel-17", based on the Sapir–Whorf Hypothesis.

</doc>
<doc id="26917" url="http://en.wikipedia.org/wiki?curid=26917" title="Statute of limitations">
Statute of limitations

Statutes of limitations are written laws passed by a legislative body in common law systems to set the maximum time after an event when legal proceedings may be initiated. When the period of time specified in a statute of limitations passes, a claim can no longer be filed. The intention of these laws is to facilitate resolution in a reasonable length of time. In civil-law systems, similar provisions are typically part of the civil or criminal codes and known collectively as "periods of prescription". The cause of action dictates the statute of limitations, which can be reduced (or extended) to ensure a fair trial. When a statute of limitations expires in a criminal case, the court no longer has jurisdiction. Analysis of a statute of limitations includes the examination of any associated statute of repose, tolling provisions and exclusions.
Applications.
Common-law legal systems use a statute specifying the length of time a claimant or prosecutor has to file a case. A case cannot begin after the period specified, and courts have no jurisdiction over cases filed after the statute of limitations has expired. Once filed, cases do not need to resolve within the period specified in the statute of limitations.
Purpose.
The purpose and effect of statutes of limitations are to protect defendants. There are three reasons for their existence: 
The limitation period generally begins when the plaintiff’s cause of action accrues, or they become aware of a previous injury (for example, occupational lung diseases such as asbestosis). In Classical Athens, a five-year statute of limitations was established for all cases except homicide and the prosecution of non-constitutional laws (which had no limitation). Demosthenes wrote that these statutes of limitations were adopted to control "sycophants" (professional accusers).
Statute of repose.
A statute of limitations is a type of statute of repose which may be extended for a variety of reasons (such as the minority of the victim). Other statutes of repose limit the time within which an action may be brought based upon when a particular event occurred (such as the completion of construction of a building or the purchase of manufactured goods), and often do not permit extensions. 
If a person is electrocuted by a wiring defect which occurred during construction of a building, the builder is liable for damages if the suit is brought within a certain number of years after construction was completed. After that, any injury is considered due to the natural degradation of the structure or a lack of proper maintenance rather than the builder's actions. Statues of repose are sometimes controversial; manufacturers contend that they are necessary to avoid unfair litigation and encourage consumers to maintain their property, while consumer advocates argue that they reduce incentives to manufacture durable products and disproportionately affect the poor.
Tolling and the discovery rule.
Many jurisdictions suspend, or toll, the limitation period under certain circumstances—for example, if the aggrieved party (plaintiff) is a minor or has filed a bankruptcy proceeding. In those instances, the running of limitations is tolled (paused) until the condition ends. Equitable tolling may also be applied if an individual may intimidate a plaintiff into not reporting or has been promised a suspended period.
The statute of limitations may begin when the harmful event (such as fraud or injury) occurs or when it is discovered. The Supreme Court of the United States has described the "standard rule" of when the time begins as "when the plaintiff has a complete and present cause of action", a rule in existence since the 1830s. A "discovery rule" applies in other cases (including medical malpractice), or a similar effect may be applied through tolling. As discussed in "Wolk v. Olson", the discovery rule does not apply to mass media such as newspapers and the Internet; the statute of limitations begins to run at the date of publication. In 2013 the Supreme Court of the United States ruled unanimously in "Gabelli v. SEC" that the discovery rule does not apply to U.S. Securities and Exchange Commission's investment-advisor-fraud lawsuits, since one purpose of the agency is to root out fraud.
In private civil matters, the limitations period may generally be shortened or lengthened by agreement of the parties. Under the Uniform Commercial Code, the parties to a contract for sale of goods may reduce the limitations period to one year but not extend it.
Limitation periods known as laches may apply in situations of equity; a judge will not issue an injunction if the requesting party waited too long to ask for it. Such periods are subject to broad judicial discretion.
For U.S. military cases, the Uniform Code of Military Justice (UCMJ) states that all charges except those facing court-martial on a capital charge have a five-year statute of limitations. In all UCMJ proceedings except those headed for general court-martial, if the charges are dropped there is a six-month window in which they can be reinstated. If six months have passed without reinstatement, the statute of limitations has run out.
Prescription.
In civil-law countries, almost all lawsuits must be brought within a legally-determined period known as prescription. Under Italian and Romanian law, criminal trials must be ended within a time limit. 
In criminal cases, the public prosecutor must lay charges within a time limit which varies by country and increases with the seriousness of the charge; in most jurisdictions, there is no statute of limitations for murder. Common triggers for suspending the prescription include a defendant's fugitive status or the commission of a new crime. A criminal may be convicted "in absentia". Prescription should not be confused with the need to prosecute within "a reasonable delay" as obligated by the European Court of Human Rights.
Exclusions.
International crimes.
Under international law, genocide, crimes against humanity and war crimes are usually not subject to the statute of limitations as codified in a number of multilateral treaties. States ratifying the Convention on the Non-Applicability of Statutory Limitations to War Crimes and Crimes Against Humanity agree to disallow limitations claims for these crimes. In Article 29 of the Rome Statute of the International Criminal Court, genocide, crimes against humanity and war crimes "shall not be subject to any statute of limitations".
United States.
Fraud upon the court.
When an officer of the court is found to have fraudulently presented facts to impair the court's impartial performance of its legal task, the act (known as "fraud upon the court") is not subject to a statute of limitation. Officers of the court include lawyers, judges, referees, legal guardians, parenting-time expeditors, mediators, evaluators, administrators, special appointees and any others whose influence is part of the judicial mechanism. Fraud upon the court has been defined by the 7th Circuit Court of Appeals to "embrace that species of fraud which does, or attempts to, defile the court itself, or is a fraud perpetrated by officers of the court so that the judicial machinery can not perform in the usual manner its impartial task of adjudging cases that are presented for adjudication". In "Bulloch v. United States", the 10th Circuit Court of Appeals ruled: "Fraud upon the court is fraud which is directed to the judicial machinery itself and is not fraud between the parties or fraudulent documents, false statements or perjury ... It is where the court or a member is corrupted or influenced or influence is attempted or where the judge has not performed his judicial function—thus where the impartial functions of the court have been directly corrupted."
Heinous crimes.
Crimes considered heinous by society have no statute of limitations.
Although there is usually no statute of limitations for murder (particularly first-degree murder), judges have been known to dismiss murder charges in cold cases if they feel the delay violates the defendant's right to a speedy trial.
Continuing-violations doctrine.
In tort law, if a defendant commits a series of illegal acts against another person (or in criminal law if someone commits a continuing crime) the limitation period may begin to run from the last act in the series. In the 8th Circuit case of "Treanor v. MCI Telecommunications, Inc.", the court explained that the continuing-violations doctrine "tolls [freezes] the statute of limitations in situations where a continuing pattern forms due to [illegal] acts occurring over a period of time, as long as at least one incident ... occurred within the limitations period." Whether the continuing-violations doctrine applies to a particular violation is subject to judicial discretion; it was ruled to apply to copyright infringement in "Taylor v. Meirick" (712 F.2d 1112, 1119; 7th Cir. 1983) but not in "Stone v. Williams" (970 F.2d 1043, 1049–50; 2d Cir. 1992).
Canada.
For crimes other than summary offences, there is no statute of limitations in Canadian criminal law. For indictable (serious) offences such as major theft, murder, kidnapping or sexual assault, a defendant may be charged at any future date; in some cases, warrants have remained outstanding for more than 20 years. Civil-law limitations vary by province, with Ontario introducing the Limitations Act, 2002 on January 1, 2004.
United Kingdom.
Unlike other European countries, the UK has no statute of limitations for serious sexual crimes.
Australia.
The Limitations Act of 1958 allows 12 years for child survivors and the disabled to make a claim, with age 37 the latest at which a claim can be made. The police submitted evidence to a commission, the Victorian Inquiry into Church and Institutional Child Abuse (in existence since 2012) indicating that it takes an average of 24 years for a survivor of child sexual abuse to go to the police. According to Attorney General Robert Clark, the government will remove statutes of limitations on criminal child abuse; survivors of violent crime should be given additional time, as adults, to deal with the legal system. Offenders of minors and the disabled have used the statute of limitations to avoid detection and prosecution, moving from state to state and country to country; an example presented to the Victorian Inquiry was the Christian Brothers.
An argument for abolishing statutes of limitations for civil claims by minors and people under guardianship is ensuring that abuse of vulnerable people would be acknowledged by lawyers, police, organisations and governments, with enforceable penalties for organisations which have turned a blind eye in the past. Support groups such as SNAP Australia, Care Leavers Australia Network and Broken Rites have submitted evidence to the Victoria inquiry, and the Law Institute of Victoria has advocated changes to the statute of limitations.
India.
The statute of limitations in India is defined by the Limitations Act, 1963.

</doc>
<doc id="26918" url="http://en.wikipedia.org/wiki?curid=26918" title="Submarine sandwich">
Submarine sandwich

A submarine sandwich, also known as a sub, wedge, hoagie, hero, grinder, baguette, or one of the many regional naming variations, is a type of sandwich that consists of a long roll of Italian or French bread, split widthwise either into two pieces or opened in a "V" on one side, and filled with a variety of meats, cheeses, vegetables, seasonings, and sauces. The sandwich has no standardized name, and many U.S. regions have their own names for it; one study found 13 different names for the sandwich in the United States. The usage of the several terms varies regionally but not in any pattern, as they have been used variously by the people and enterprises who make and sell them. The terms submarine and sub are widespread and not assignable to any certain region, though many of the localized terms are clustered in the northeast United States.
History and etymology.
The sandwich originated in several different Italian American communities in the Northeastern United States from the late 19th to mid-20th centuries. Portland, Maine claims to be the birthplace of the "Italian sandwich" and it is considered Maine's signature sandwich. The popularity of this Italian-American cuisine has grown from its origins in Connecticut, Pennsylvania, Delaware, New York, New Jersey, and Massachusetts to most parts of the United States, Canada, and with the advent of chain restaurants, is now available in many parts of the world. In Europe, it would simply be known as a baguette, or a ciabatta, named after traditional breads long baked in France and Italy.
Submarine.
The use of the term "submarine" or "sub" (after the resemblance of the roll to the shape of a submarine) is widespread. An advertisement appears in the Trenton Evening Times [New Jersey] on March 15, 1940 for "Charlie & Buddy's 'Italian Submarine Sandwich' 46 South Broad Street", indicating the sandwich originated prior to the United States' entry into World War II.
One theory says the submarine was brought to the U.S. by Dominic Conti (1874–1954), an Italian immigrant who came to New York in the early 1900s. He is said to have named it after seeing the recovered 1901 submarine called "Fenian Ram" in the Paterson Museum of New Jersey in 1928. His granddaughter has stated the following: "My grandfather came to this country circa 1895 from Montella, Italy. Around 1910, he started his grocery store, called Dominic Conti's Grocery Store, on Mill Street in Paterson, New Jersey where he was selling the traditional Italian sandwiches. His sandwiches were made from a recipe he brought with him from Italy which consisted of a long crust roll, filled with cold cuts, topped with lettuce, tomatoes, peppers, onions, oil, vinegar, Italian herbs and spices, salt, and pepper. The sandwich started with a layer of cheese and ended with a layer of cheese (this was so the bread wouldn't get soggy)."
Hoagie.
The term "hoagie" originated in the Philadelphia area. The "Philadelphia Evening Bulletin" reported, in 1953, that Italians working at the World War I–era shipyard in Philadelphia, known as Hog Island where emergency shipping was produced for the war effort, introduced the sandwich, by putting various meats, cheeses, and lettuce between two slices of bread. This became known as the "Hog Island" sandwich; shortened to "Hoggies", then the "hoagie".
The "Philadelphia Almanac and Citizen's Manual" offers a different explanation, that the sandwich was created by early-twentieth-century street vendors called "hokey-pokey men", who sold antipasto salad, meats and cookies. When Gilbert and Sullivan's operetta "H.M.S. Pinafore" opened in Philadelphia in 1879, bakeries produced a long loaf called the pinafore. Entrepreneurial "hokey-pokey men" sliced the loaf in half, stuffed it with antipasto salad, and sold the world's first "hoagie".
Another explanation is that the word "hoagie" arose in the late 19th to early 20th century, among the Italian community in South Philadelphia, when "on the hoke" was a slang term used to describe a destitute person. Deli owners would give away scraps of cheeses and meats in an Italian bread-roll known as a "hokie", but the Italian immigrants pronounced it "hoagie".
Other less likely explanations involve "Hogan" (a nickname for Irish workers at the Hog Island shipyard), a reference to the pork or "hog" meat used in hoagies, "honky sandwich" (using a racial slur for white people seen eating them) or "hooky sandwich" (derived from "hookie" for truant kids seen eating them). Shortly after World War II, there were numerous varieties of the term in use throughout Philadelphia. By the 1940s, the spellings "hoagie" and, to a lesser extent, "hoagy" had come to dominate less used variations like "hoogie" and "hoggie". By 1955, restaurants throughout the area were using the term "hoagie", with many selling hoagies and subs or hoagies and pizza. Listings in Pittsburgh show hoagies arriving in 1961 and becoming widespread in that city by 1966.
Former Philadelphia mayor (and later Pennsylvania governor) Ed Rendell declared the hoagie the "Official Sandwich of Philadelphia". However, there are claims that the hoagie was actually a product of nearby Chester, Pennsylvania. DiCostanza's in Boothwyn, Pennsylvania claims that the mother of DiConstanza's owner originated the hoagie in 1925 in Chester. DiCostanza relates the story that a customer came into the family deli and through an exchange matching the customer's requests and the deli's offerings, the hoagie was created.
A local Philadelphia variation on the hoagie is the "zep" made in Norristown, Pennsylvania. It is a variation on the traditional hoagie, with no lettuce and only one meat. It is made on a round roll, with provolone cheese covering meat, chunks of raw onion, and slabs of tomato. It is dressed with oregano, salt, pepper, olive oil, and hot pepper relish.
Bánh mì sandwiches are sometimes referred to as "Vietnamese hoagies" in Philadelphia.
Hero.
The New York term "hero" is first attested in 1937. The name is sometimes credited to the "New York Herald Tribune" food writer Clementine Paddleford in the 1930s, but there is no good evidence for this. It is also sometimes claimed that it is related to the "gyro", but this is unlikely as the "gyro" was unknown in the United States until the 1960s, according to some sources.
"Hero" (plural usually "heros") remains the prevailing New York City term for most sandwiches on an oblong roll with a generally Italian flavor, in addition to the original described above. Pizzeria menus often include eggplant parmigiana, chicken parmigiana, and meatball heros, each served with sauce.
Grinder.
A common term in New England, its origin has several possibilities. One theory has the name coming from Italian-American slang for a dock worker, among whom the sandwich was popular. Others say it was called a grinder because it took a lot of chewing to eat the hard crust of the bread used.
 In Pennsylvania and Delaware, the term grinder simply refers to a submarine sandwich that has been heated in any fashion.
Popularity and availability.
From its origins with the Italian American labor force in the Northeastern United States, the sub began to show up on menus of local pizzerias. As time went on and popularity grew, small restaurants, called hoagie shops and sub shops, that specialized in the sandwich began to open.
After World War II, Italian food grew in popularity in the US and started to become assimilated. This brought the use of other meats to the sandwich including turkey, roast beef, American and Swiss cheese, as well as spreads such as mayonnaise and mustard.
Pizzerias may have been among the first Italian-American eateries, but even at the turn of the [20th] century distinctions were clear-cut as to what constituted a true ristorante. To be merely a pizza-maker was to be at the bottom of the culinary and social scale; so many pizzeria owners began offering other dishes, including the hero sandwich (also, depending on the region of the United States, called a 'wedge,' a 'hoagie,' a 'sub,' or a 'grinder') made on a Italian loaf of bread with lots of salami, cheese, and peppers.—John Mariani, America Eats Out, p. 66
By the late 20th century, due to the rise of large franchisee chain restaurants and fast food, the sandwich became available worldwide. Many outlets offer non-traditional ingredient combinations.
In the United States, many chain restaurants have arisen that specialize in subs including Capriotti's, Submarina, Jersey Mike's Subs, Charley's Grilled Subs, Blimpie, Jimmy John's, Lenny's Sub Shop, Milio's, Port of Subs, Eegee's, Firehouse Subs, Penn Station, Planet Sub, Potbelly, Togo's, Tubby's, Which Wich and D'Angelo Sandwich Shops. Major international chains include Quiznos, Mr. Sub and the largest restaurant chain in the world, Subway. The sandwich is also usually available at supermarkets and convenience stores.

</doc>
<doc id="26919" url="http://en.wikipedia.org/wiki?curid=26919" title="Semitic languages">
Semitic languages

The Semitic languages are a branch of the Afroasiatic language family originating in the Middle East. Semitic languages are spoken by more than 470 million people across much of Western Asia, North Africa and the Horn of Africa, as well as in large expatriate communities in North America and Europe. The terminology was first used in the 1780s by German orientalists von Schlözer and Eichhorn, who derived the name from Shem, one of the three sons of Noah in the Book of Genesis.
The most widely spoken Semitic languages today are (numbers given are for native speakers only) Arabic (300 million), Amharic (22 million), Tigrinya (7 million), and Hebrew (unknown; 5 million native and non-native L1 speakers).
Semitic languages are attested in written form from a very early date, with Akkadian and Eblaite texts (written in a script adapted from Sumerian cuneiform) appearing from around the middle of the third millennium BC in Mesopotamia and the northern Levant respectively. However, most scripts used to write Semitic languages are abjads—a type of alphabetic script that omits some or all of the vowels, which is feasible for these languages because the consonants in the Semitic languages are the primary carriers of meaning.
Among them are the Ugaritic, Phoenician, Aramaic, Hebrew, Syriac, Arabic, and South Arabian alphabets. The Ge'ez alphabet, used for writing the Semitic languages of Ethiopia and Eritrea, is technically an abugida—a modified abjad in which vowels are notated using diacritic marks added to the consonants at all times, in contrast with other Semitic languages which indicate diacritics based on need or for introductory purposes. Maltese is the only Semitic language written in the Latin script and the only official Semitic language of the European Union.
The Semitic languages are notable for their nonconcatenative morphology. That is, word roots are not themselves syllables or words, but instead are isolated sets of consonants (usually three, making a so-called "triliteral root"). Words are composed out of roots not so much by adding prefixes or suffixes, but rather by filling in the vowels "between" the root consonants (although prefixes and suffixes are often added as well). For example, in Arabic, the root meaning "write" has the form "k-t-b". From this root, words are formed by filling in the vowels and sometimes adding additional consonants, e.g. kitāb "book", kutub "books", kātib "writer", kuttāb "writers", "kataba" "he wrote", "yaktubu" "he writes", etc.
Name and identification.
The similarity of the Hebrew language, Arabic language and Aramaic language has been accepted by Jewish and Islamic scholars since medieval times. The languages were familiar to Western European scholars due to historical contact with neighbouring Islamic countries and through Biblical studies, and a comparative analysis of Hebrew, Arabic, and Aramaic was published in Latin in 1538 by Guillaume Postel. Almost two centuries later, Hiob Ludolf described the similarities between these three languages and the Ethiopic languages. However, neither scholar named this grouping as "Semitic".
The German orientalists August Ludwig von Schlözer (1781) and Johann Gottfried Eichhorn (1787) first coined the name "Semitic" in the late 18th century to designate the languages closely related to Arabic, Aramaic, and Hebrew. The choice of name was derived from Shem, one of the three sons of Noah in the genealogical accounts of the biblical Book of Genesis, or more precisely from the Greek rendering of the name, Σημ (Sēm). Eichhorn is credited with popularising the term, particularly via a 1795 article "Semitische Sprachen" ("Semitic languages") in which he justified the terminology against criticism that Hebrew and Canaanite were the same language despite Canaan being "Hamitic" in the Table of Nations:
 In the Mosaic Table of Nations, those names which are listed as Semites are purely names of tribes who speak the so-called Oriental languages and live in Southwest Asia. As far as we can trace the history of these very languages back in time, they have always been written with syllabograms or with alphabetic script (never with hieroglyphs or pictograms); and the legends about the invention of the syllabograms and alphabetic script go back to the Semites. In contrast, all Hamitic peoples originally used hieroglyphs, until they here and there, either through contact with the Semites, or through their settlement among them, became familiar with their syllabograms or alphabetic script, and partly adopted them. Viewed from this aspect too, with respect to the alphabet used, the name "Semitic languages" is completely appropriate.
 — Johann Gottfried Eichhorn, "Semitische Sprachen (1795) (translated from the original German)"
Previously these languages had been commonly known as the "Oriental languages" in European literature. In the 19th century, "Semitic" became the conventional name; however, an alternative name: "Syro-Arabian languages" was later introduced and used by some writers.
 That important family of languages, of which the Arabic is the most cultivated and most widely-extended branch, has long wanted an appropriate common name. The term "Oriental" languages, which was exclusively applied to it from the time of Jerome down to the end of the last century, and which is even now not entirely abandoned, must always have been an unscientific one, inasmuch as the countries in which these languages prevailed are only the "east" in respect to Europe; and when Sanskrit, Chinese, and other idioms of the remoter East were brought within the reach of our research, it became palpably incorrect. Under a sense of this impropriety, Eichhorn was the first, as he says himself (Allg. Bibl. Biblioth. vi. 772), to introduce the name "Semitic" languages, which was soon generally adopted, and which is the most usual one at the present day.
[...] In modern times, however, the very appropriate designation "Syro-Arabian languages" has been proposed by Dr. Prichard, in his "Physical History of Man". This term, [...] has the advantage of forming an exact counterpart to the name by which the only other great family of languages with which we are likely to bring the Syro-Arabian into relations of contrast or accordance, is now universally known—the "Indo-Germanic". Like it, by taking up only the two extreme members of a whole sisterhood according to their geographical position when in their native seats, it embraces all the intermediate branches under a common band; and, like it, it constitutes a name which is not only at once intelligible, but one which in itself conveys a notion of that affinity between the sister dialects, which it is one of the objects of comparative philology to demonstrate and to apply.
 — John Kitto, "A Cyclopædia of Biblical Literature (1845)."
History.
Origins.
The Semitic family is a member of the larger Afroasiatic family, all of whose other five or more branches have their origin in North Africa and North East Africa. Largely for this reason, the ancestors of Proto-Semitic speakers were originally believed by some to have first arrived in the Middle East from North Africa, possibly as part of the operation of the Saharan pump, around the late Neolithic. Diakonoff sees Semitic originating between the Nile Delta and Canaan as the northernmost branch of Afroasiatic. Blench even wonders whether the highly divergent Gurage languages indicate an origin in Ethiopia (with the rest of Ethiopic Semitic a later back migration).
A recent Bayesian analysis of alternative Semitic histories supports the former possibility and identifies an origin of Semitic languages in the Levant around 3,750 BC with a single introduction from southern Arabia into Africa around 800 BC.
In one interpretation, Proto-Semitic itself is assumed to have reached the Arabian Peninsula by approximately the 4th millennium BC, from which Semitic daughter languages continued to spread outwards. When written records began in the late 4th millennium BC, the Semitic-speaking Akkadians (Assyrians/Babylonians) were entering Mesopotamia from the deserts to the west, and were probably already present in places such as Ebla in Syria. Akkadian personal names began appearing in written record in Mesopotamia from the late 29th Century BC.
2nd millennium BC.
By the late 3rd millennium BC, East Semitic languages, such as Akkadian and Eblaite, were dominant in Mesopotamia and north east Syria, while West Semitic languages, such as Amorite, Canaanite and Ugaritic, were probably spoken from Syria to the Arabian Peninsula, although Old South Arabian is considered by most people to be South Semitic despite the sparsity of data. The Akkadian language of Akkad, Assyria and Babylonia had become the dominant literary language of the Fertile Crescent, using the cuneiform script that was adapted from the Sumerians. The Middle Assyrian Empire, which originated in the 14th century BC, facilitated the use of Akkadian as a 'lingua franca' in many regions outside its homeland. The related, but more sparsely attested, Eblaite disappeared with the city, and Amorite is attested only from proper names in Mesopotamian records.
For the 2nd millennium, somewhat more data are available, thanks to the spread of an invention first used to capture the sounds of Semitic languages — the alphabet. Proto-Canaanite texts from around 1500 BC yield the first undisputed attestations of a West Semitic language (although earlier testimonies are possibly preserved in Middle Bronze Age alphabets), followed by the much more extensive Ugaritic tablets of northern Syria from around 1300 BC. Incursions of nomadic Semitic Aramaeans, and later still Chaldeans and Suteans, from the Syrian desert begin around this time. Akkadian continued to flourish, splitting into Babylonian and Assyrian dialects.
1st millennium BC.
In the 1st millennium BC, the alphabet spread much further, giving us a picture not just of Canaanite, but also of Aramaic, Old South Arabian, and early Ge'ez. During this period, the case system, once vigorous in Ugaritic, seems to have started decaying in Northwest Semitic. Phoenician colonies (such as Carthage) spread their Canaanite language throughout much of the Mediterranean, while its close relative, Hebrew, became the vehicle of a religious literature, the Torah and Tanakh, which would have global ramifications. However, as an ironic result of the Assyrian Empire's vast conquests, Aramaic became the "lingua franca" of the Fertile Crescent and much of the Near East and parts of Asia Minor, gradually pushing Akkadian, Hebrew, Phoenician-Canaanite, and several other languages to extinction, although Hebrew and Akkadian remained in use as liturgical languages, Hebrew in particular developing a substantial literature. Ethiopian Semitic is attested by the 9th century BC, with the earliest proto-Ge'ez inscriptions of the kingdom of D'mt using the South Arabian alphabet.
Common Era (AD).
Syriac, an Assyrian Mesopotamian descendant of Aramaic used in North Eastern Syria, Assyria (Assuristan) and Mesopotamia, rose to importance as a literary language of early Christianity in the 3rd to 5th centuries and continued into the early Arab Islamic era.
With the emergence of Islam in the 7th century, the ascendancy of Aramaic was dealt a fatal blow by the Arab conquests, which made another Semitic language — Arabic — the official language of an empire stretching from Spain to Central Asia.
With the patronage of the caliphs and the prestige of its liturgical status, it rapidly became one of the world's main literary languages. Its spread among the masses took much longer, however, as many (although not all) of the native populations outside the Arabian Peninsula only gradually abandoned their languages in favour of Arabic. As Bedouin tribes settled in conquered areas, it became the main language of not only central Arabia, but also Yemen, the Fertile Crescent, and Egypt. Most of the Maghreb (Northwest Africa) followed, particularly in the wake of the Banu Hilal's incursion in the 11th century, and Arabic became the native language of many inhabitants of Spain. After the collapse of the Nubian kingdom of Dongola in the 14th century, Arabic began to spread south of Egypt; soon after, the Beni Ḥassān brought Arabization to Mauritania.
Meanwhile, Semitic languages were diversifying in Ethiopia and Eritrea, where, under heavy Cushitic influence, they split into a number of languages, including Amharic and Tigrinya. With the expansion of Ethiopia under the Solomonic dynasty, Amharic, previously a minor local language, spread throughout much of the country, replacing both Semitic (such as Gafat) and non-Semitic (such as Weyto) languages, and replacing Ge'ez as the principal literary language (though Ge'ez remains the liturgical language for Christians in the region); this spread continues to this day, with Qimant set to disappear in another generation.
Present situation.
Arabic languages are the native languages of majorities from Mauritania to Oman, and from Iraq to the Sudan. Classical Arabic is the language of the Qur'an, it is also studied widely in the non-Arabic-speaking Muslim world. Maltese language is genetically a descendant of the extinct Sicilian Arabic dialect. The Maltese alphabet is based on the Latin script with the addition of some letters with diacritic marks and digraphs. Maltese is the only Semitic official language of a nation state within the European Union.
Despite the ascendancy of Arabic in the Middle East, other Semitic languages still exist. Hebrew, long extinct as a colloquial language and in use only in Jewish literary, intellectual, and liturgical activity, was revived in spoken form at the end of the 19th century. It has become the main language of Israel, while remaining the language of liturgy and religious scholarship of Jews worldwide.
Several smaller ethnic groups, in particular the ethnic Assyrians and Gnostic Mandeans, continue to speak and write Mesopotamian Aramaic dialects (especially Neo-Aramaic, descended from Syriac) in those areas roughly corresponding to Kurdistan (northern Iraq, northeast Syria, south eastern Turkey and northwestern Iran) and the Caucasus. These dialects still contain a number of Akkadian loan words and have more structural commonality with the Akkadian language than Western Aramaic. Syriac language itself, a descendant of Eastern Aramaic languages (Mesopotamian Old Aramaic), is used also liturgically by the Syriac Christians throughout the area.
In Arab-dominated Yemen and Oman, on the southern rim of the Arabian Peninsula, a few tribes continue to speak Modern South Arabian languages such as Mahri and Soqotri. These languages differ greatly from both the surrounding Arabic dialects and from the (unrelated but previously thought to be related) languages of the Old South Arabian inscriptions.
Historically linked to the peninsular homeland of the Old South Arabian languages, Ethiopia and Eritrea contain a substantial number of Semitic languages; the most widely spoken are Amharic in Ethiopia, Tigre in Eritrea, and Tigrinya in both. Amharic is the official language of Ethiopia. Tigrinya is a working language in Eritrea. Tigre is spoken by over one million people in the northern and central Eritrean lowlands and parts of eastern Sudan. A number of Gurage languages are spoken by populations in the semi-mountainous region of southwest Ethiopia, while Harari is restricted to the city of Harar. Ge'ez remains the liturgical language for certain groups of Christians in Ethiopia and in Eritrea.
Phonology.
The phonologies of the attested Semitic languages are presented here from a comparative point of view. See Proto-Semitic language#Phonology for details on the phonological reconstruction of Proto-Semitic used in this article. This comparative approach is natural for the consonants, as sound correspondences among the consonants of the Semitic languages are very straightforward for a family of its time depth; for the vowels there are more subtleties.
Consonants.
Each Proto-Semitic phoneme was reconstructed to explain a certain regular sound correspondence between various Semitic languages. Note that Latin letter values ("italicized") for extinct languages are a question of transcription; the exact pronunciation is not recorded.
Most of the attested languages have merged a number of the reconstructed original fricatives, though South Arabian retains all fourteen (and has added a fifteenth from *p > f).
In Aramaic and Hebrew, all non-emphatic stops occurring singly after a vowel were softened to fricatives, leading to an alternation that was often later phonemicized as a result of the loss of gemination.
In languages exhibiting pharyngealization of emphatics, the original velar emphatic has rather developed to a uvular stop [q].
Notes:
In addition to those in the table, Modern Hebrew has introduced the new phonemes /tʃ/, /dʒ/, /ʒ/ through borrowings.
The following table shows the development of the various fricatives in Hebrew, Aramaic and Arabic through cognate words:
Vowels.
Proto-Semitic vowels are, in general, harder to deduce due to the templatic nature of Semitic languages. The history of vowel changes in the languages makes drawing up a complete table of correspondences impossible, so only the most common reflexes can be given:
Correspondence of sounds with other Afroasiatic languages.
"See table at Proto-Afroasiatic language#Consonant correspondences."
Grammar.
The Semitic languages share a number of grammatical features, although variation – both between separate languages, and within the languages themselves – has naturally occurred over time.
Word order.
The reconstructed default word order in Proto-Semitic is verb–subject–object (VSO), possessed–possessor (NG), and noun–adjective (NA). This was still the case in Classical Arabic and Biblical Hebrew, e.g. Classical Arabic "ra'ā muħammadun farīdan." (literally "saw Muhammad Farid", "Muhammad saw Farid"). In the modern Arabic vernaculars, however, as well as sometimes in Modern Standard Arabic (the modern literary language based on Classical Arabic) and Modern Hebrew, the classical VSO order has given way to SVO. Modern Ethiopian Semitic languages follow a different word order: SOV, possessor–possessed, and adjective–noun; however, the oldest attested Ethiopian Semitic language, Ge'ez, was VSO, possessed–possessor, and noun–adjective. Akkadian was also predominantly SOV.
Cases in nouns and adjectives.
The proto-Semitic three-case system (nominative, accusative and genitive) with differing vowel endings (-u, -a -i), fully preserved in Qur'anic Arabic (see ʾIʿrab), Akkadian and Ugaritic, has disappeared everywhere in the many colloquial forms of Semitic languages. Modern Standard Arabic maintains such case distinctions, although they are often lost in free speech (due to colloquial influence). An accusative ending -n is preserved in Ethiopian Semitic. The archaic Samalian dialect of Old Aramaic reflects a case distinction in the plural between nominative "-ū" and oblique "-ī" (compare the same distinction in Classical Arabic). Additionally, Semitic nouns and adjectives had a category of state, the indefinite state being expressed by nunation.
Number in nouns.
Semitic languages originally had three grammatical numbers: singular, dual, and plural. Classical Arabic still has a mandatory dual (i.e. it must be used in all circumstances when referring to two entities), marked on nouns, verbs, adjectives and pronouns. Many contemporary dialects of Arabic still have a dual, as in the name for the nation of Bahrain ("baħr" "sea" + "-ayn" "two"), although it is marked only on nouns. It also occurs in Hebrew in a few nouns ("šana" means "one year", "šnatayim" means "two years", and "šanim" means "years"), but for those it is obligatory. The curious phenomenon of broken plurals – e.g. in Arabic, "sadd" "one dam" vs. "sudūd" "dams" – found most profusely in the languages of Arabia and Ethiopia, may be partly of proto-Semitic origin, and partly elaborated from simpler origins.
Verb aspect and tense.
All Semitic languages show two quite distinct styles of morphology used for conjugating verbs. "Suffix conjugations" take suffixes indicating the person, number and gender of the subject, which bear some resemblance to the pronominal suffixes used to indicate direct objects on verbs ("I saw him") and possession on nouns ("his dog"). So-called "prefix conjugations" actually takes both prefixes and suffixes, with the prefixes primarily indicating person (and sometimes number and/or gender), while the suffixes (which are completely different from those used in the suffix conjugation) indicate number and gender whenever the prefix does not mark this. The prefix conjugation is noted for a particular pattern of "ʔ- t- y- n-" prefixes where (1) a "t-" prefix is used in the singular to mark the second person and third-person feminine, while a "y-" prefix marks the third-person masculine; and (2) identical words are used for second-person masculine and third-person feminine singular. The prefix conjugation is extremely old, with clear analogues in nearly all the families of Afroasiatic languages (i.e. at least 10,000 years old). The table on the right shows examples of the prefix and suffix conjugations in Classical Arabic, which has forms that are close to Proto-Semitic.
In Proto-Semitic, as still largely reflected in East Semitic, prefix conjugations are used both for the past and the non-past, with different vocalizations. Cf. Akkadian "niprus" "we decided" (preterite), "niptaras" "we have decided" (perfect), "niparras" "we decide" (non-past or imperfect), vs. suffix-conjugated "parsānu" "we are/were/will be deciding" (stative). Some of these features, e.g. gemination indicating the non-past/imperfect, are generally attributed to Afroasiatic. According to Hetzron, Proto-Semitic had an additional form, the jussive, which was distinguished from the preterite only by the position of stress: the jussive had final stress while the preterite had non-final (retracted) stress.
The West Semitic languages significantly reshaped the system. The most substantial changes occurred in the Central Semitic languages (the ancestors of modern Hebrew, Arabic and Aramaic). Essentially, the old prefix-conjugated jussive and/or preterite became a new non-past (or imperfect), while the stative became a new past (or perfect), and the old prefix-conjugated non-past (or imperfect) with gemination was discarded. New suffixes were used to mark different moods in the non-past, e.g. Classical Arabic "-u" (indicative), "-a" (subjunctive), vs no suffix (jussive). (It is not generally agreed whether the systems of the various Semitic languages are better interpreted in terms of tense, i.e. past vs. non-past, or aspect, i.e. perfect vs. imperfect.) However, in Hebrew, elements of the old system survived alongside the new system for a while, in forms known as the waw-consecutive and marked with a prefixed "w-". The South Semitic languages show a system somewhere between the East and Central Semitic languages.
Later languages show further developments. In the modern varieties of Arabic, for example, the old mood suffixes were dropped, and new mood prefixes developed (e.g. "bi-" for indicative vs. no prefix for subjunctive in many varieties). In the extreme case of Neo-Aramaic, the verb conjugations have been entirely reworked under Iranian influence.
Morphology: triliteral roots.
All Semitic languages exhibit a unique pattern of stems consisting typically of "triliteral", or 3-consonant consonantal roots (2- and 4-consonant roots also exist), from which nouns, adjectives, and verbs are formed in various ways: e.g. by inserting vowels, doubling consonants, lengthening vowels, and/or adding prefixes, suffixes, or infixes.
For instance, the root k-t-b, (dealing with "writing" generally) yields in Arabic:
and the same root in Hebrew:
In Tigrinya and Amharic, this root survives only in the noun "kitab", meaning "amulet", and the verb "to vaccinate". Ethiopic-derived languages use different roots for things that have to do with writing (and in some cases counting) primitive root: ṣ-f and trilateral root stems: m-ṣ-f, ṣ-h-f, and ṣ-f-r are used. This roots also exists in other Semitic languages like (Hebrew: "sep̄er" "book", "sōp̄er" "scribe", "mispār" "number" and "sippūr" "story"). (this root also exists in Arabic and is used to form words with a close meaning to "writing", such as "ṣaḥāfa" "journalism", and "ṣaḥīfa" "newspaper" or "parchment").
Verbs in other non-Semitic Afroasiatic languages show similar radical patterns, but more usually with biconsonantal roots; e.g. Kabyle "afeg" means "fly!", while "affug" means "flight", and "yufeg" means "he flew" (compare with Hebrew, where "hap̄lēḡ" means "set sail!", "hap̄lāḡā" means "a sailing trip", and "hip̄līḡ" means "he sailed", while the unrelated "ʕūp̄", "təʕūp̄ā" and "ʕāp̄" pertain to flight).
Cardinal numerals.
These are the basic numeral stems without feminine suffixes. Note that in most older Semitic languages, the forms of the numerals from 3 to 10 exhibit gender polarity (also called "chiastic concord" or reverse agreement), i.e. if the counted noun is masculine, the numeral would be feminine and vice versa.
Typology.
Some early Semitic languages are speculated to have had weak ergative features.
Common vocabulary.
Due to the Semitic languages' common origin, they share many words and roots. Others differ. For example:
Sometimes, certain roots differ in meaning from one Semitic language to another. For example, the root "b-y-ḍ" in Arabic has the meaning of "white" as well as "egg", whereas in Hebrew it only means "egg". The root "l-b-n" means "milk" in Arabic, but the color "white" in Hebrew. The root "l-ḥ-m" means "meat" in Arabic, but "bread" in Hebrew and "cow" in Ethiopian Semitic; the original meaning was most probably "food". The word "medina" (root: m-d-n) has the meaning of "metropolis" in Amharic and "city" in Arabic and Hebrew, but in Modern Hebrew it is usually used as "state".
Of course, there is sometimes no relation between the roots. For example, "knowledge" is represented in Hebrew by the root "y-d-ʿ", but in Arabic by the roots "ʿ-r-f" and "ʿ-l-m" and in Ethiosemitic by the roots "ʿ-w-q" and "f-l-ṭ".
For more comparative vocabulary lists, see Wiktionary appendices:
Classification.
There are six fairly uncontroversial nodes within the Semitic languages: East Semitic, Northwest Semitic, North Arabian, Old South Arabian (also known as Sayhadic), Modern South Arabian, and Ethiopic. These are generally grouped further, but there is ongoing debate as to which belong together. The classification based on shared innovations given below, established by Robert Hetzron in 1976 and with later emendations by John Huehnergard and Rodgers as summarized in Hetzron 1997, is the most widely accepted today. In particular, several Semiticists still argue for the traditional (partially nonlinguistic) view of Arabic as part of South Semitic, and a few (e.g. Alexander Militarev or the German-Egyptian professor Arafa Hussein Mustafa) see the South Arabian languages as a third branch of Semitic alongside East and West Semitic, rather than as a subgroup of South Semitic. Roger Blench notes that the Gurage languages are highly divergent and wonders whether they might not be a primary branch, reflecting an origin of Afroasiatic in or near Ethiopia. At a lower level, there is still no general agreement on where to draw the line between "languages" and "dialects" – an issue particularly relevant in Arabic, Aramaic, and Gurage – and the strong mutual influences between Arabic dialects render a genetic subclassification of them particularly difficult.
The Himyaritic language appears to have been Semitic, but is unclassified due to insufficient data.
Additional reference literature.
</dl>

</doc>
<doc id="26920" url="http://en.wikipedia.org/wiki?curid=26920" title="Sammy Sosa">
Sammy Sosa

Samuel Kelvin "Sammy" Peralta Sosa (born November 12, 1968) is a Dominican retired professional baseball right fielder. Sosa played with four Major League Baseball teams over his career, which spanned from 1989 to 2007. Sosa's Major League career began with the Texas Rangers in 1989. After three seasons with the Chicago White Sox, Sosa became a member of the Chicago Cubs in 1992 and became one of the league's best hitters. In 1998, Sosa and Mark McGwire achieved national fame for their home run-hitting prowess in pursuit of Roger Maris' home run record.
Sosa finished his career with brief stints with the Baltimore Orioles and the Texas Rangers. With the Rangers, Sosa hit his 600th career home run to become the fifth player in MLB history to reach the milestone. He is also the all-time home run leader among foreign-born MLB players. Sosa is one of only two National League players since 1900 to ever reach 160 RBIs in a season, a milestone he reached in 2001. Sosa is the only player to have hit 60 or more home runs in a single season three times.
Early life.
Sosa is known to family and friends as "Mikey." His maternal grandmother, who had suggested his birth name of Samuel, also came up with his nickname: "[She] heard the name on a soap opera she liked and decided from that moment on he would be Mikey."
Sosa was born in the Dominican Republic. Although his officially registered birthplace is San Pedro de Macorís, Sosa was actually born in Consuelo. San Pedro de Macorís was "the largest town nearby." Both Consuelo and San Pedro de Macorís are in San Pedro de Macorís Province.
Major league career.
Texas Rangers, Chicago White Sox (1989–1991).
Sosa made his major league debut on June 16, 1989, with the Texas Rangers Wearing #17 Leading off as the Starting Centerfielder, and he hit first career home run off Roger Clemens. Later in the season, the Rangers traded Sammy to the Chicago White Sox where he would don the #25. In 1990, Sosa batted .233 with 15 home runs, 70 runs batted in, 10 triples, and 32 stolen bases. However, he also struck out 150 times, fourth most in the American League. Sosa started the 1991 season by hitting 2 home runs and driving in 5 runs. However, he would slump for the rest of the year and ended up batting .203 with 10 home runs and 33 runs batted in. He was traded to the Chicago Cubs for outfielder George Bell before the 1992 season.
Chicago Cubs (1992–2004).
Sosa batted .260 with 8 home runs and 25 RBIs in his first season with the Cubs. Although not spectacular numbers, it showed that Sosa improved as a hitter. In 1993, Sosa batted .261 with 33 home runs with 93 RBIs. He also showed his speed by stealing 38 bases. He became the Cubs' first 30-30 player in their history. Sosa continued to hit for power and speed in 1994 but he also improved his batting average. He ended up batting .300 with 25 home runs, 70 RBIs, and 22 stolen bases.
Sosa was named to his first All-Star team in 1995. In 144 games, he batted .268 with 36 home runs and 119 RBIs. Sosa continued his success with the Cubs in 1996 as he batted .273 with 40 home runs and 100 RBIs. However, the next year, Sosa struggled. Despite hitting 36 home runs with 119 RBIs, Sosa batted just .251. He struggled to get on base(.300 on-base percentage) and led the league in strikeouts with 174.
After years as a respected power/speed threat with a rocket arm in right field, he emerged during the 1998 season as one of baseball's greatest. It was in this season that both Sosa and Mark McGwire were involved in the "home run record chase", when both players' prowess for hitting home runs drew national attention as they attempted to pass Roger Maris' single season home run mark of 61 home runs that had stood since 1961. For the early months of the year, Sosa trailed McGwire significantly, being as many as 16 homers behind at one point in May. But as the chase progressed, Sosa would rally and eventually tie McGwire with 46 home runs each on August 10, after a couple months of straggling within a few homers for the lead. However, the moment was short lived as McGwire would pull away slightly and reach 62 home runs to break the record first on September 8, but once again Sosa would excitingly heat up the race by tying McGwire once again at 62 on September 13. Eleven days later, with two games left to play in the season, the two were tied at 66 home runs each. Sosa would end the season with 66 after playing both games without a home run(still a team record), just behind McGwire's 70 after hitting two home runs in each of the last two games. However, Sammy had become the first Major League batter ever to hit 66 home runs in a season. It was during that season, that Cubs announcer Chip Caray nicknamed him "Slammin' Sammy", a nickname that quickly spread. In addition, Sammy produced then career highs in batting average and slugging percentage, at .308 and .647 respectively. Sosa also led the league in RBIs and runs scored. Also in 1998, Sosa's 416 total bases were the most in a single season since Stan Musial's 429 in 1948. Sosa's performance in the month of June, during which Sosa belted 20 home runs, knocked in 47 runs, and posted an .842 slugging percentage, was one of the greatest offensive outbursts in major league history. Sosa won the National League Most Valuable Player Award for leading the Cubs into the playoffs in 1998, earning every first-place vote except for the two cast by St. Louis writers, who voted for McGwire. He and McGwire shared "Sports Illustrated" magazine's 1998 "Sportsman of the Year" award. Sosa was honored with a ticker-tape parade in his honor in New York City, and he was invited to be a guest at US President Bill Clinton's 1999 State of the Union Address. 1998 was also the first time the Cubs made the post-season since 1989. The Cubs qualified as the NL Wild Card team, but were swept by the Atlanta Braves in the NLDS.
In the 1999 season, Sosa hit 63 home runs, again trailing Mark McGwire who hit 65. In the 2000 season, Sammy led the league by hitting 50 home runs. He received the Babe Ruth Home Run Award for leading MLB in homers.
In 2001, he hit 64 home runs, becoming the first player to hit 60 home runs in three seasons in his career. However, he did not lead the league in any of those seasons; in 2001, he finished behind Barry Bonds, who hit 73 homers, breaking the single-season home run record set by McGwire in 1998 (70). In the same season he set personal records in runs scored (146), RBI (160), walks (116), on-base percentage (.437), slugging percentage (.737), and batting average (.328). He led the majors in runs and RBI, was 2nd in home runs, 2nd in slugging percentage, 1st in total bases, 3rd in walks, 4th in on-base percentage, 12th in batting average, and 15th in hits. He also surpassed his 1998 number in total bases, racking up 425. Sosa once again led the league in home runs with 49 in 2002. Known as a free-swinger in his early years, and as a good strikeout candidate, Sammy became an effective hitter for average. He owns numerous team records for the Cubs, and he holds the major-league record for the most home runs hit in a month (20, in June 1998). In recognition of his accomplishments as a hitter, Sosa won the Silver Slugger award (an award for offensive output, voted on by managers and coaches) in 1995 and in 1998 through 2002.
In 2003, the Cubs won the National League Central Division title. The year was not all good news for Sosa, however. In May, he spent his first period on the disabled list since 1996 after having an injured toenail removed. On June 3, 2003, Sosa was ejected from a Chicago Cubs-Tampa Bay Devil Rays game in the first inning when umpires discovered he had been using a corked bat. Major League Baseball confiscated and tested 76 of Sosa's other bats after his ejection; all were found to be clean, with no cork. Five bats he had sent to the Hall of Fame in past years were also tested, and were all clean as well. Sosa stated that he had accidentally used the corked bat, which he claimed he only used during batting practice.
"I use that bat for batting practice. It's something that I take the blame for. It's a mistake, I know that. I feel sorry. I just apologize to everybody that are embarrassed."
When Dusty Baker, the Cub manager was interviewed later, he stated any use of corked bats on his team is strictly prohibited. On June 6, Sosa was suspended for eight games. However, the suspension was reduced to seven games after appeal on June 11. Sosa finished the season with 40 home runs, and he hit two more in the 2003 NLCS against the Florida Marlins, which the Cubs led 3 games to 1 before ultimately falling in seven games.
In May 2004, Sosa suffered an odd injury while sitting next to his locker chatting with reporters before a game in San Diego's PETCO Park. He sneezed very violently, causing severe back pain. He was diagnosed with back spasms and placed on the disabled list. Later, he fell into one of the worst slumps of his career, only snapping out of it during the last week of the season. He was greatly depressed when the officials told him he couldn't play. He finished with 35 homers, far below his numbers of his best years. In his final 10 years with the Cubs he clubbed 479 home runs; the most in history over a 10-year span. The final straw for the Cubs was an incident in late 2004. Sosa requested to sit out the last game of the season, which was at home against the Atlanta Braves, and he left Wrigley Field early in the game. It was his last time in a Cubs uniform.
Baltimore Orioles and year off (2005–2006).
On January 28, 2005, the Cubs traded Sosa to the Baltimore Orioles in exchange for infielder/outfielder Jerry Hairston, Jr., infielder Mike Fontenot, and RHP Dave Crouthers. To facilitate the deal, Sosa and his agent agreed to waive the clause that guaranteed his 2006 salary, and the players' union indicated it would not object to that agreement. Under the deal, Sosa earned $17,875,000 for the 2005 season, with the Cubs paying $7 million of his salary. By playing for the 2005 Orioles alongside fellow 500-home-run batter Rafael Palmeiro, Sosa and Palmeiro became the first 500 home run club members in history to play together on the same team after reaching the 500 home run plateau.
Sosa finished the 2005 season batting .221 with 14 home runs, his worst performance since 1992, and continuing his post-2001 trend of declines in batting average, homers, total bases, and RBI. On December 7, 2005, the Orioles decided not to offer him an arbitration contract, effectively ending his Baltimore Orioles tenure and making him a free agent.
In 2005, "The Sporting News" published an update of their 1999 book "Baseball's 100 Greatest Players". Sosa did not make the original edition, but for the 2005 update, with his career totals considerably higher, he was ranked at Number 95. During a stretch of nine consecutive years, Sosa hit 35+ home runs and 100+ RBIs, all with the Chicago Cubs.
At the end of January 2006, the Washington Nationals offered Sosa two different minor-league offers, both of which he turned down. On February 15, 2006, Sosa's agent Adam Katz stated: "We're not going to put him on the retirement list. We decided that [not putting him on that list] was the best thing to do. But I can say, with reasonable certainty, that we've seen Sammy in a baseball uniform for the last time."
During this year, Sosa accompanied President Fernández of the Dominican Republic on several diplomatic trips including to the United States, Japan, and Taiwan.
Texas Rangers and end of career (2007–2009).
The Texas Rangers, Sosa's original team, signed him to a minor league deal worth $500,000 on January 30, 2007. This was the same contract that Sosa turned down the previous year from the Nationals. The contract included an invitation to spring training, where Sosa competed for a spot in the lineup with Nelson Cruz, Jason Botts, and other rookies/prospects. Sosa was successful during spring training and was added to the team's 25-man roster. He started the 2007 season as the Rangers' designated hitter and occasional right fielder.
At the same time, the Chicago Cubs awarded Sosa's # 21 to new pitcher Jason Marquis, despite the fact that it was formerly worn by Sosa, who coincidentally later hit his 600th home run against Marquis. Ted Lilly, who had also signed with the Cubs that prior winter had requested #31 but was told it was not available as it was going to be retired for Greg Maddux and Fergie Jenkins, and they were just waiting for Maddux to retire. This caused some concern, due to Sosa's accomplishments with the Cubs, including his status as the Cubs' all-time home run leader.
On April 26, 2007, Sosa made history by hitting a home run in his 45th major league ballpark. He has also homered in The Ballpark at Disney's Wide World of Sports, near Orlando, Florida, a usually minor-league and Spring Training park that hosted a regular season series between the Rangers and the Tampa Bay Devil Rays in May 2007, although he did not hit a homer at the two regular season games the Cubs played at the Tokyo Dome in 2000 vs. the Mets.
On June 20, 2007, Sosa hit a home run off of Jason Marquis during an inter-league game against the Chicago Cubs. Sosa became only the fifth man in history, following Babe Ruth, Willie Mays, Hank Aaron, and Barry Bonds, to hit 600 regular season home runs. The home run was the first one that Sosa had recorded against the Cubs, and as a result he has hit a home run against every active MLB team. Sosa is the Cubs' all-time home run leader, having hit 545 with that team.
On May 28, 2008, Sosa announced that he instructed his agent not to offer his services to any MLB team for the 2008 season, and planned on filing for retirement, but never did.
On December 25, 2008, Sosa announced he intended to unretire and play in the World Baseball Classic and once again test the free agent market in hopes of signing with a Major League ballclub in 2009. Sosa said that he had been keeping in shape at his home, and was hoping that after a strong World Baseball Classic he would prove to major-league teams that he was still capable of playing in the MLB. However, he was not selected as part of the Dominican Republic's roster. He remained a free agent and did not actively look for a team.
On June 3, 2009, Sosa announced his intention to retire from baseball. He made the announcement in the Dominican Republic and said that he was calmly looking forward to his induction into the Baseball Hall of Fame since his statistics were up to par.
Drug test controversy and Hall of Fame.
On June 16, 2009, the "New York Times" reported Sosa was on a list of players who tested positive for performance-enhancing drugs in 2003. The paper did not identify the drug. Sosa's agent, Adam Katz, told The Associated Press he had no comment on the report. Rich Levin, commissioner Bud Selig's office spokesman, declined to comment on the situation, claiming that MLB did not have a copy of the test results. Michael Weiner, the union general counsel, also declined comment. The union, while fighting to get the list back from the government, has mostly refused to discuss reports.
Previously, Sosa sat alongside Rafael Palmeiro, Jose Canseco and Mark McGwire at a 2005 hearing before Congress. His attorney testified on his behalf, stating "To be clear, I have never taken illegal performance-enhancing drugs. I have never injected myself or had anyone inject me with anything. I have not broken the laws of the United States or the laws of the Dominican Republic. I have been tested as recently as 2004, and I am clean."
In an interview with ESPN Deportes, Sosa said he would "calmly wait" for his induction into baseball's Hall of Fame, for which he became eligible in 2013. On January 9, 2013, Sosa was not elected by the Baseball Writers Association of America into baseball's Hall of Fame in Cooperstown, receiving 12.5% on his first year on the ballot (the requirement for election is 75%). In 2014 he received 7.2%, and in 2015 he received 6.6%.
Personal life.
Sosa is married to Sonia Rodriguez, whom he has dated since 1993 and with whom he has four children: Keysha, Kenya, Sammy Jr., and Michael. The couple married on December 18, 2005, at Altos de Chavon, La Romana.

</doc>
<doc id="26926" url="http://en.wikipedia.org/wiki?curid=26926" title="Spenser (character)">
Spenser (character)

Spenser—his first name is never officially revealed—is a fictional character in a series of detective novels initially by the American mystery writer Robert B. Parker and later by Ace Atkins. He is also featured in a television series ("") and a series of TV movies (Spenser (TV films)) based on the novels.
Fictional biography.
Spenser was born in Laramie, Wyoming and is a Boston private eye in the mold of Raymond Chandler's Philip Marlowe, a smart-mouthed tough guy with a heart of gold. Unlike Marlowe, Spenser maintains a committed relationship with one woman (Susan Silverman). Although he is an ex-boxer (who likes to remind readers that he once fought the former heavyweight champ Jersey Joe Walcott) and lifts weights to stay in shape, he also is quite well educated, cooks, and lives by a code of honor he and Susan discuss occasionally—though as infrequently as he can manage.
Spenser bears more than a passing resemblance to his creator, Robert B. Parker. Both are Bostonians, and both spent time in Korea with the U.S. Army. Spenser served as an infantryman in the 1st Infantry Division during the Korean War.
The other major character in the Spenser novels is his close friend Hawk. An African American, Hawk is an equally tough but somewhat shady echo of Spenser himself. Hawk served in the French Foreign Legion and served in combat overseas. Hawk is a "Gun for Hire" who lives by his own personal code. Spenser and Hawk met as boxing opponents in a preliminary bout in the Boston Arena (now known as Matthews Arena). Each man believes he was the victor. Hawk may be modeled on the sidekick in Book Five of Edmund Spenser's "The Faerie Queene"; Artegal, the knight of justice, has a helper named Talus, an invincible man of iron. Spenser and Hawk respect each other and are friends who each understand the other's philosophy of how to conduct themselves in life.
Spenser is a former State trooper assigned to the Suffolk County DA's Office (although some novels state that he also worked out of the Middlesex County DA's Office; "Walking Shadow" and the pilot episode of "" say he was a Boston Police detective), and regularly seeks help from (or sometimes butts heads with) Martin Quirk (originally a lieutenant, later a captain) of the Boston Police Department. Among his other police contacts are Sergeant Frank Belson and Detective Lee Farrell, both homicide investigators under Quirk's command; Healy, a captain of the Massachusetts State Police; and Mark Samuelson, an LAPD lieutenant (later promoted to captain, as mentioned in "Back Story"). In Massachusetts each county District Attorney's office has a squad of State Police Detectives assigned to their office to conduct investigations of major crimes committed in their jurisdictions.
Scotch is Spenser's drink of celebration. This is mostly having to do with an encounter with a bear while bird hunting in his teens. Spenser seems to agree with William Faulkner's assessment of scotch — "that brown liquor which not women, not boys and children, but only hunters drank."
After his mother's death (which occurred prior to Spenser's birth — he was an emergency C-section), Spenser was raised by his father and two uncles (his mother's brothers), all of them carpenters, who do not appear in the series. Spenser received a football scholarship to Holy Cross, where he played strong safety. Spenser injured his knee and dropped out because he didn't have the funds to complete his schooling. He took up boxing, and met Hawk and Henry Cimoli, the owner of a gym where Spenser and Hawk still work out. His family unit beyond his near-fraternal relationship with Hawk is essentially Susan Silverman, an unofficial foster son named Paul Giacomin, and a series of dogs all named Pearl after Spenser's childhood dog of the same breed, a German Shorthaired Pointer. (Author Parker has been photographed on the "Spenser" series dustjackets with a dog matching his description of the Pearls.) Silverman, originally a high school guidance counselor, continues to assist Spenser in his cases after becoming a Harvard-trained Ph.D. psychologist. Giacomin, initially an awkward, unsocialized teenager, becomes a professional actor/dancer.
Maternal mystery.
One of the inconsistencies (or, more likely, cases of retconning) within the Spenser series surrounds his mother. In some of the early books he refers to his mother and, in 1981's "A Savage Place", for example, he even quotes advice his mother gave him. However, by the time of the novel "Pastime", Spenser states that his mother died during labor and he was delivered via Caesarian section, i.e. "not of woman born" as Parker has Spenser put it; he was raised by his father and his two maternal uncles. Parker never explained the inconsistencies.
Young Spenser.
Released in 2009, a young adult novel, "Chasing the Bear", discusses some of Spenser's childhood, and further complicates the continuity issue with his family. At the end of the novel, Spenser leaves his father and uncles behind in Wyoming to attend college in Boston. No information was released as to whether this would commence a fourth regular series for Parker before his death in January 2010.
Spenser's Firearms.
In the 1970s and 1980s Spenser usually carried a Smith & Wesson Model 36, .38 Special caliber, "Chief's Special" revolver. He would sometimes carry a .357 Magnum revolver that he usually kept in the top drawer of his office desk, for "just in case" situations. Spenser also had a small .32 caliber revolver that he carried as a "back up" weapon in the 1970s and early 1980s. In 1992 Spenser started regularly carrying a Browning Hi-Power 9mm semi-automatic pistol. In 2010 Spenser replaces the Browning with a Smith & Wesson .40 caliber semi-automatic pistol. In 2012, he starts carrying the Chief's Special again while working, but also carries the .357 Magnum or the .40 caliber Smith & Wesson, in addition to the .38 Special, when anticipating a possible gunfight. On rare occasions Spenser would use a rifle or shotgun when the situation required them. Spenser of the TV show carried a Beretta 92.
Novels.
By Robert B. Parker:
Adaptations.
The universe depicted in the TV episodes and movies diverges from that in the novels, though many of the filmed presentations are based on, and named after, novels in the series.
Spenser TV series.
The Spenser books were the inspiration for the 1985-1988 ABC TV series "" starring Robert Urich as Spenser, Barbara Stock as Susan, and Avery Brooks as Hawk. Though the series has not been available in broadcast syndication for many years, it has recently been made part of the lineup at AOL's new in2TV online broadcasting site. The series has also never been released on DVD, though several internet vendors sell bootleg sets of questionable quality.
Avery Brooks starred in a spin-off series entitled "A Man Called Hawk".
Several made-for-TV movies based upon the series followed in the early 1990s featuring Robert Urich and Avery Brooks, with Barbara Williams and later Wendy Crewson as Susan.
Spenser TV movies.
Beginning in 1999, Joe Mantegna played Spenser in three TV movies on the A&E cable network: "Small Vices" (1999), "Thin Air" (2000), "Walking Shadow" (2001), with Marcia Gay Harden as Susan and Shiek Mahmud-Bey and later Ernie Hudson as Hawk.
Shared universe.
Spenser and Hawk live in the same Boston literary universe as Parker's other, newer series characters: private investigator Sunny Randall and small town police chief Jesse Stone, the former of whom was possibly mentioned in passing as a blonde jogging with an English bull terrier (named Rosie in the Randall novels) while the latter had a much larger role in "Back Story". Susan Silverman is Sunny Randall's psychiatrist in "Melancholy Baby".
The fictional Taft University, where Susan teaches, was also a primary setting for the Spenser novel "Playmates", and the non-Spenser novel "Love and Glory".

</doc>
<doc id="26929" url="http://en.wikipedia.org/wiki?curid=26929" title="Spanish">
Spanish

Spanish may refer to:

</doc>
<doc id="26930" url="http://en.wikipedia.org/wiki?curid=26930" title="Sideshow">
Sideshow

In America, a sideshow is an extra, secondary production associated with a circus, carnival, fair or other such attraction.
Types of attractions.
There are four main classified types of classic sideshow attractions:
 * A "Girl Show" was sometimes offered in which women were the primary attraction. These could range from the revue (such as a "Broadway Revue") with fully clothed performers to the racier "kootch" or "hootchie-kootchie" show (a strip show) which might play either partly clothed or "strong" (nude).
Sideshow arts.
"Working acts" often exhibited a number of stunts that could be counted on to draw crowds. These stunts used little-known methods and offered the elements of danger and excitement. Although the mainstream media often explained fanciful methods of performing these acts, the real secret was usually that there is no secret, you just do it. Such acts included fire eating, sword swallowing, knife throwing, body piercing, lying on a bed of nails, walking up a ladder of sharp swords, and more. The renewed attention to these feats has prompted a new round of oversimplified or inaccurate explanations, leading some inexperienced people to attempt them without adequate training often resulting in injury and sometimes even death.
Decline and revival.
Interest in sideshows declined as television made it easy (and free) to see the world's most exotic attractions. Moreover, viewing "human oddities" became distasteful as the public conscience changed, and many localities passed laws forbidding the exhibition of freaks. The performers often protested (to no avail) that they had no objection to the sideshow, especially since it provided not only a good income for them, but in many cases it provided their only possible job. The sideshow seemed destined for oblivion, until only a few exemplars of the ten-in-one remained. A greater number of "Single O" attractions still tour carnivals.
In the early 1990s Jim Rose developed a modern sideshow called "the Jim Rose Circus", reinventing the sideshow with two types of acts that would attract modern audiences and stay within legal bounds. The show featured acts reviving traditional sideshow stunts and carrying some of them to extremes, and "fringe" artists (often exhibiting extreme body modification) performing bizarre or masochistic acts like eating insects, lifting weights by means of hooks inserted in their body piercings, or stapling currency to their forehead. The show drew audiences at venues unknown to old-time sideshows, like rock clubs and the 1992 Lollapalooza festival. The Jim Rose Circus held its last known performance in 2013 at The London Burlesque Festival. The impact of the Jim Rose Circus on pop culture inspired a new wave of performers. There are now more sideshow performers than at any other time in the genre's history. At the same time in Canada, Scott McClelland, grandson of itinerant showman N.P. Lewchuk, formed Carnival Diablo, a show that performs frequently to this day. The success of these shows sparked a growing number of performers to revive the traditional sideshow arts, taught by sideshow veterans, and many now perform in spot engagements from rock clubs and comedy clubs to corporate events. "Sideshows by the Seashore", sponsored by Coney Island USA in Brooklyn, NY has performed since 1983, and tours under the name "Coney Island Circus Sideshow". Circus Historian and collector Ken Harck runs the Brothers Grim Sideshow, which toured with the OzzFest music festival in the summer of 2006 and 2007. is a circus sideshow revival with an all ages twist that originated in St. Louis in 2000 and continues to perform nationwide including being featured at St. Louis Six Flags' annual Fright Fest.
In Australia, the 2007 Sydney Royal Easter Show also introduced a sideshow program amongst its attractions.

</doc>
<doc id="26931" url="http://en.wikipedia.org/wiki?curid=26931" title="Scorpio">
Scorpio

Scorpio is the Latin word for scorpion.

</doc>
<doc id="26932" url="http://en.wikipedia.org/wiki?curid=26932" title="Sagittarius (constellation)">
Sagittarius (constellation)

Sagittarius is one of the constellations of the zodiac. It is one of the 48 constellations listed by the 2nd-century astronomer Ptolemy and remains one of the 88 modern constellations. Its name is Latin for the archer, and its symbol is (Unicode U+2650 ♐), a stylized arrow. Sagittarius is commonly represented as a centaur drawing a bow. It lies between Scorpius and Ophiuchus to the west and Capricornus to the east.
Visualizations.
As seen from the northern hemisphere, the constellation's brighter stars form an easily recognizable asterism known as 'the Teapot'. The stars δ Sgr (Kaus Media), ε Sgr (Kaus Australis), ζ Sgr (Ascella), and φ Sgr (Nanto) form the body of the pot; λ Sgr (Kaus Borealis) is the point of the lid; γ2 Sgr (Alnasl) is the tip of the spout; and σ Sgr (Nunki) and τ Sgr (the closest bright star to the possible origin of the Wow! signal) the handle.
Marking the bottom of the teapot's "handle" (or the shoulder area of the archer, are the bright star (2.59 magnitude) Zeta Sagittarii (ζ Sgr), named Ascella, and the fainter Tau Sagittarii (τ Sgr).
To complete the teapot metaphor, under good conditions, a particularly dense area of the Milky Way can be seen rising in a north-westerly arc above the spout, like a puff of steam rising from a boiling kettle.
The constellation as a whole is often depicted as having the rough appearance of a stick-figure archer drawing its bow, with the fainter stars providing the outline of the horse's body. Sagittarius famously points its arrow at the heart of Scorpius, represented by the reddish star Antares, as the two constellations race around the sky. Following the direct line formed by Delta Sagittarii (δ Sgr) and Gamma Sagittarii (γ Sgr) leads nearly directly to Antares.
Fittingly, Gamma Sagittarii is
Alnasl, the Arabic word for "arrowhead", and Delta Sagittarii is called Kaus Media, the "center of the bow," from which the arrow protrudes. Kaus Media bisects Lambda Sagittarii (λ Sgr) and Epsilon Sagittarii (ε Sgr), whose names Kaus Borealis and Kaus Australis refer to the northern and southern portions of the bow, respectively.
Notable features.
Stars.
α Sgr (Rukbat, meaning "the archer's knee") despite having the "alpha" appellation, is not the brightest star of the constellation, having a magnitude of only 3.96 (not shown on the main map as it is located below the map's southeastern corner, north is up). Instead, the brightest star is Epsilon Sagittarii (ε Sgr) ("Kaus Australis," or "southern part of the bow"), at magnitude 1.85.
Sigma Sagittarii (σ Sgr) ("Nunki") is the constellation's second-brightest star at magnitude 2.08. Nunki is a B2V star approximately 260 light years away. "Nunki" is a Babylonian name of uncertain origin, but thought to represent the sacred Babylonian city of Eridu on the Euphrates, which would make Nunki the oldest star name currently in use.
Zeta Sagittarii (ζ Sgr) ("Ascella"), with apparent magnitude 2.61 of A2 spectra, is actually a double star whose two components have magnitudes 3.3 and 3.5.
Delta Sagittarii (δ Sgr) ("Kaus Maridionalis"), is a K2 spectra star with magnitude 2.71 and only 85 light years from Earth.
Eta Sagittarii (η Sgr) is a double star with component magnitudes of 3.18 and 10, while Pi Sagittarii (π Sgr) is actually a triple system whose components have magnitudes 3.7, 3.8, and 6.0.
The Bayer designation Beta Sagittarii (Beta Sgr, β Sagittarii, β Sgr) is shared by two star systems, β¹ Sagittarii, with apparent magnitude 3.96, and β² Sagittarii, magnitude 7.4. The two stars are separated by 0.36° in the sky and are 378 light years from earth. Beta Sagittarii, located at a position associated with the forelegs of the centaur, has the traditional name Arkab, meaning "achilles tendon."
Nova Sagittarii 2015 No. 2 was discovered on March 15, 2015, by John Seach of Chatsworth Island, NSW, Australia. It lies near the center of the constellation. It reached a peak magnitude of 4.3 before steadily fading.
Deep-Space objects.
The Milky Way is at its densest near Sagittarius, as this is where the galactic center lies. Consequently, Sagittarius contains many star clusters and nebulae.
Nebulae.
Sagittarius contains several well-known nebulae, including the Lagoon Nebula (Messier 8), near λ Sagittarii; the Omega Nebula (Messier 17), also known as the Horseshoe Nebula or Swan Nebula, near the border with Scutum; and the Trifid Nebula (Messier 20), a large nebula containing some very young, hot stars.
The grouping of the Lagoon Nebula, the Trifid Nebula, and NGC 6559 is often called the "Sagittarius triplet".
In addition, several other nebulae have been located within Sagittarius and are of interest to astronomers.
Other deep sky objects.
In 1999 a violent outburst at V4641 Sgr was thought to have revealed the location of the closest known black hole to Earth, but later investigation increased its estimated distance by a factor of 15. The complex radio source Sagittarius A is also here. Astronomers believe that one of its components, known as Sagittarius A*, is associated with a supermassive black hole at the center of the galaxy, with a mass of 2.6 million solar masses. The Sagittarius Dwarf Elliptical Galaxy is located just outside the Milky Way.
Baade's Window is an area with very little obscuring dust that shows objects closer to the Milky Way's center than would normally be visible. NGC 6522, magnitude 8.6, and NGC 6528, magnitude 9.5, are both globular clusters visible through Baade's Window. 20,000 and 24,000 light-years from Earth, with Shapley classes of VI and V respectively, both are moderately concentrated at their cores. NGC 6528 is closer to the galactic core at an approximate distance of 2,000 light-years.
Mythology.
The Babylonians identified Sagittarius as the god Nergal, a strange centaur-like creature firing an arrow from a bow. It is generally depicted with wings, with two heads, one panther head and one human head, as well as a scorpion's stinger raised above its more conventional horse's tail. The Sumerian name Pabilsag is composed of two elements – Pabil, meaning 'elder paternal kinsman' and Sag, meaning 'chief, head'. The name may thus be translated as the 'Forefather' or 'Chief Ancestor'. The figure is reminiscent of modern depictions of Sagittarius.
In Greek mythology, Sagittarius is usually identified as a centaur: half human, half horse. However, perhaps due to the Greek's adoption of the Sumerian constellation, some confusion surrounds the identity of the archer. Some identify Sagittarius as the centaur Chiron, the son of Philyra and Saturn and tutor to Jason, who was said to have changed himself into a horse to escape his jealous wife, Rhea. However, Chiron is in fact represented by the constellation Centaurus, the other heavenly centaur. An alternative tradition is that Chiron merely invented the constellation Sagittarius to help in guiding the Argonauts in their quest for the Golden Fleece.
A competing mythological tradition, as espoused by Eratosthenes, identified the Archer not as a centaur but as the satyr Crotus, son of Pan, who Greeks credited with the invention of archery. According to myth, Crotus often went hunting on horseback and lived among the Muses, who requested that Zeus place him in the sky, where he is seen demonstrating archery.
The arrow of this constellation points towards the star Antares, the "heart of the scorpion," and Sagittarius stands poised to attack should Scorpius ever attack the nearby Hercules, or to avenge Scorpius's slaying of Orion.
Astrology.
s of 2002[ [update]], the Sun appears in the constellation Sagittarius from 18 December to 18 January. In tropical astrology, the Sun is considered to be in the sign Sagittarius from 22 November to 21 December, and in sidereal astrology, from 16 December to 14 January.
Space exploration.
The Space probe New Horizons is moving in the direction of this constellation, though it will not be nearing any of the stars in this constellation for many thousands of years, by which time its radioisotope thermoelectric generator will have exhausted itself.
References.
</dl>
External links.
Coordinates: 

</doc>
<doc id="26933" url="http://en.wikipedia.org/wiki?curid=26933" title="Scorpius">
Scorpius

Scorpius, sometimes known as Scorpio, is one of the constellations of the zodiac. Its name is Latin for scorpion, and its symbol is (Unicode ♏). It lies between Libra to the west and Sagittarius to the east. It is a large constellation located in the southern hemisphere near the center of the Milky Way.
Notable features.
Stars.
Scorpius contains many bright stars, including Antares (α Sco), "rival of Mars," so named because of its distinct reddish hue; β1 Sco (Graffias or Acrab), a triple star; δ Sco (Dschubba, "the forehead"); θ Sco (Sargas, of unknown origin); ν Sco (Jabbah); ξ Sco (Girtab, "the scorpion"); π Sco (Iclil); σ Sco (Alniyat); and τ Sco (also known as Alniyat, "the arteries").
Marking the tip of the scorpion's curved tail are λ Sco (Shaula) and υ Sco (Lesath), whose names both mean "sting." Given their proximity to one another, λ Sco and υ Sco are sometimes referred to as the Cat's Eyes.
The constellation's bright stars form a pattern like a longshoreman's hook. Most of them are massive members of the nearest OB association: Scorpius-Centaurus.
The star δ Sco, after having been a stable 2.3 magnitude star, flared in July 2000 to 1.9 in a matter of weeks. It has since become a variable star fluctuating between 2.0 and 1.6. This means that at its brightest it is the second brightest star in Scorpius.
U Scorpii is the fastest known nova with a period of about 10 years.
ω¹ Scorpii and ω² Scorpii are an optical double, which can be resolved by the unaided eye. They have contrasting blue and yellow colours.
The star once designated γ Sco (despite being well within the boundaries of Libra) is today known as σ Lib. Moreover, the entire constellation of Libra was considered to be claws of Scorpius ("Chelae Scorpionis") in Ancient Greek times, with a set of scales held aloft by Astraea (represented by adjacent Virgo) being formed from these western-most stars during later Greek times. The division into Libra was formalised during Roman times.
Deep-sky objects.
Due to its location on the Milky Way, this constellation contains many deep-sky objects such as the open clusters Messier 6 (the Butterfly Cluster) and Messier 7 (the Ptolemy Cluster), NGC 6231 (by ζ² Sco), and the globular clusters Messier 4 and Messier 80.
Messier 80 (NGC 6093) is a globular cluster of magnitude 7.3, 33,000 light-years from Earth. It is a compact Shapley class II cluster; the classification indicates that it is highly concentrated and dense at its nucleus. M80 was discovered in 1781 by Charles Messier. It was the site of a rare discovery in 1860 when Arthur von Auwers discovered the nova T Scorpii.
Mythology.
In Greek mythology, the myths associated with Scorpio almost invariably also contain a reference to Orion. According to one of these myths it is written that Orion boasted to goddess Artemis and her mother, Leto, that he would kill every animal on the earth. Although Artemis was known to be a hunter herself she offered protection to all creatures. Artemis and her mother Leto sent a scorpion to deal with Orion. The pair battled and the scorpion killed Orion. However, the contest was apparently a lively one that caught the attention of the king of the gods Zeus, who later raised the scorpion to heaven and afterwards, at the request of Artemis, did the same for Orion to serve as a reminder for mortals to curb their excessive pride. There is also a version that Orion was better than the goddess Artemis but said that Artemis was better than he and so Artemis took a liking to Orion. The god Apollo, Artemis's twin brother, grew angry and sent a scorpion to attack Orion. After Orion was killed, Artemis asked Zeus to put Orion up in the sky. So every winter Orion hunts in the sky, but every summer he flees as the constellation of the scorpion comes.
In another Greek story involving Scorpio without Orion, Phaeton (the mortal male offspring of Helios) went to his father, who had earlier sworn by the River Styx to give Phaeton anything he should ask for. Phaeton wanted to drive his father's Sun Chariot for a day. Although Helios tried to dissuade his son, Phaeton was adamant. However, when the day arrived, Phaeton panicked and lost control of the white horses that drew the chariot. First, the Earth grew chill as Phaeton flew too high and encountered the celestial scorpion, its deadly sting raised to strike. Alarmed, he dipped the chariot too close, causing the vegetation to burn. By accident, Phaeton turned most of Africa into desert and darkened the skin of the Ethiopian nation until it was black. Eventually, Zeus was forced to intervene by striking the runaway chariot and Phaeton with a lightning bolt to put an end to its rampage and Phaeton plunged into the River Eridanos.
Origins.
The Babylonians called this constellation MUL.GIR.TAB - the 'Scorpion', the signs can be literally read as 'the (creature with) a burning sting'.
In some old descriptions the constellation of Libra is treated as the Scorpion's claws. Libra was known as the Claws of the Scorpion in Babylonian ("zibānītu" (compare Arabic "zubānā")) and in Greek (χηλαι).
Astrology.
The Western astrological sign Scorpio of the tropical zodiac (October 23 – November 21) differs from the astronomical constellation and the Hindu astrological sign of the sidereal zodiac (November 16 – December 16). Astronomically, the sun is in Scorpius for just six days, from November 23 to November 28. Much of the difference is due to the constellation Ophiuchus, which is used by only a few astrologers. Scorpius corresponds to the nakshatras Anuradha, Jyeshtha, and Mula.
Culture.
The Javanese people of Indonesia call this constellation "Banyakangrem" ("the brooded swan") or "Kalapa Doyong" ("leaning coconut tree") due to the shape similarity.
External links.
Coordinates: 

</doc>
<doc id="26934" url="http://en.wikipedia.org/wiki?curid=26934" title="Scheme">
Scheme

Scheme or The Scheme may refer to:

</doc>
<doc id="26938" url="http://en.wikipedia.org/wiki?curid=26938" title="SF">
SF

SF may refer to:
In sports:
In politics:
In science, math and engineering:
In entertainment:
In music:
In other uses:

</doc>
<doc id="26940" url="http://en.wikipedia.org/wiki?curid=26940" title="Steven Spielberg">
Steven Spielberg

Steven Allan Spielberg (born December 18, 1946) is an American filmmaker. Spielberg is considered as one of the founding pioneers of the New Hollywood era, as well as being viewed as one of the most popular and influential directors and producers in film history. In a career spanning more than four decades, Spielberg's films have covered many themes and genres. Spielberg's early science-fiction and adventure films were seen as archetypes of modern Hollywood blockbuster filmmaking. In later years, his films began addressing humanistic issues such as the Holocaust, the transatlantic slave trade, war, and terrorism. He is one of the co-founders of DreamWorks Studios.
Spielberg won the Academy Award for Best Director for "Schindler's List" (1993) and "Saving Private Ryan" (1998). Three of Spielberg's films—"Jaws" (1975), "E.T. the Extra-Terrestrial" (1982), and "Jurassic Park" (1993)—achieved box office records, originated and came to epitomize the blockbuster movie.
The unadjusted gross of all Spielberg-directed films exceeds $8.5 billion worldwide. His personal net worth is estimated to be more than $3 billion.
Early life.
Spielberg was born in Cincinnati, Ohio, to an Orthodox Jewish family. His mother, Leah Adler Posner (born 1920), was a restaurateur and concert pianist, and his father, Arnold Spielberg (born 1917), was an electrical engineer involved in the development of computers. In 1950, his family moved to Haddon Township, New Jersey when his father took a job with RCA. Three years later, the family moved to Phoenix, Arizona.:548 Spielberg attended Hebrew school from 1953 to 1957, in classes taught by Rabbi Albert L. Lewis,
As a child, Spielberg faced difficulty reconciling being an Orthodox Jew with the perception of him by other children he played with. "It isn't something I enjoy admitting," he once said, "but when I was seven, eight, nine years old, God forgive me, I was embarrassed because we were Orthodox Jews. I was embarrassed by the outward perception of my parents' Jewish practices. I was never really ashamed to be Jewish, but I was uneasy at times." Spielberg also said he suffered from acts of anti-Semitic prejudice and bullying: "In high school, I got smacked and kicked around. Two bloody noses. It was horrible."
His first home movie was of a train wreck involving his toy Lionel trains, then age 12. Throughout his early teens, and after entering high school, Spielberg continued to make amateur 8 mm "adventure" films. 
In 1958, he became a Boy Scout and fulfilled a requirement for the photography merit badge by making a nine-minute 8 mm film entitled "The Last Gunfight". Years later, Spielberg recalled to a magazine interviewer, "My dad's still-camera was broken, so I asked the scoutmaster if I could tell a story with my father's movie camera. He said yes, and I got an idea to do a Western. I made it and got my merit badge. That was how it all started."
At age thirteen, while living in Phoenix, Spielberg won a prize for a 40-minute war film he titled "Escape to Nowhere", using a cast composed of other high school friends. That motivated him to make 15 more amateur 8mm films.:548 In 1963, at age sixteen, Spielberg wrote and directed his first independent film, a 140-minute science fiction adventure called "Firelight", which would later inspire "Close Encounters". The film was made for $500, most of which came from his father, and was shown in a local cinema for one evening, which earned back its cost.
After attending Arcadia High School in Phoenix for three years, his family next moved to Saratoga, California, where he later graduated from Saratoga High School in 1965. He attained the rank of Eagle Scout. His parents divorced while he was still in school, and soon after he graduated Spielberg moved to Los Angeles, staying initially with his father. His long-term goal was to become a film director. His three sisters and mother remained in Saratoga.
In Los Angeles, he applied to the University of Southern California's film school, but was turned down because of his "C" grade average.:548 He then applied and was admitted to California State University, Long Beach, where he majored in English, and became a brother of Theta Chi Fraternity.
While still a student, he was offered a small unpaid intern job at Universal Studios with the editing department. He was later given the opportunity to make a short film for theatrical release, the 26-minute, 35mm, "Amblin"', which he wrote and directed. Studio vice president Sidney Sheinberg was impressed by the film, which had won a number of awards, and offered Spielberg a seven-year directing contract. It made him the youngest director ever to be signed for a long-term deal with a major Hollywood studio.:548 He subsequently dropped out of college to begin professionally directing TV productions with Universal.
Career.
1970s.
His first professional TV job came when he was hired to direct one of the segments for the 1969 pilot episode of "Night Gallery". The segment, "Eyes," starred Joan Crawford; she and Spielberg were reportedly close friends until her death. The episode is unusual in his body of work, in that the camerawork is more highly stylized than his later, more "mature" films. After this, and an episode of "Marcus Welby, M.D.", Spielberg got his first feature-length assignment: an episode of "The Name of the Game" called "L.A. 2017". This futuristic science fiction episode impressed Universal Studios and they signed him to a short contract. He did another segment on "Night Gallery" and did some work for shows such as "" and "The Psychiatrist", before landing the first series episode of "Columbo" (previous episodes were actually TV films).
Based on the strength of his work, Universal signed Spielberg to do four TV films. The first was a Richard Matheson adaptation called "Duel". The film is about a psychotic Peterbilt 281 tanker truck driver who chases the terrified driver (Dennis Weaver) of a small Plymouth Valiant and tries to run him off the road. Special praise of this film by the influential British critic Dilys Powell was highly significant to Spielberg's career. Another TV film ("Something Evil") was made and released to capitalize on the popularity of "The Exorcist", then a major best-selling book which had not yet been released as a film. He fulfilled his contract by directing the TV film-length pilot of a show called "Savage", starring Martin Landau. Spielberg's debut full-length feature film was "The Sugarland Express", about a married couple who are chased by police as the couple tries to regain custody of their baby. Spielberg's cinematography for the police chase was praised by reviewers, and "The Hollywood Reporter" stated that "a major new director is on the horizon." However, the film fared poorly at the box office and received a limited release.
Studio producers Richard D. Zanuck and David Brown offered Spielberg the director's chair for "Jaws", a thriller-horror film based on the Peter Benchley novel about an enormous killer shark. Spielberg has often referred to the gruelling shoot as his professional crucible. Despite the film's ultimate, enormous success, it was nearly shut down due to delays and budget over-runs. But Spielberg persevered and finished the film. It was an enormous hit, winning three Academy Awards (for editing, original score and sound) and grossing more than $470 million worldwide at the box office. It also set the domestic record for box office gross, leading to what the press described as "Jawsmania." "Jaws" made Spielberg a household name and one of America's youngest multi-millionaires, allowing him a great deal of autonomy for his future projects. It was nominated for Best Picture and featured Spielberg's first of three collaborations with actor Richard Dreyfuss.
Rejecting offers to direct "Jaws 2", "King Kong" and "Superman", Spielberg and actor Richard Dreyfuss re-convened to work on a film about UFOs, which became "Close Encounters of the Third Kind" (1977). One of the rare films both written and directed by Spielberg, "Close Encounters" was a critical and box office hit, giving Spielberg his first Best Director nomination from the Academy as well as earning six other Academy Awards nominations. It won Oscars in two categories (Cinematography, Vilmos Zsigmond, and a Special Achievement Award for Sound Effects Editing, Frank E. Warner). This second blockbuster helped to secure Spielberg's rise. His next film, "1941", a big-budgeted World War II farce, was not nearly as successful and though it grossed over $92.4 million worldwide (and did make a small profit for co-producing studios Columbia and Universal) it was seen as a disappointment, mainly with the critics.
Spielberg then revisited his "Close Encounters" project and, with financial backing from Columbia Pictures, released "Close Encounters: The Special Edition" in 1980. For this, Spielberg fixed some of the flaws he thought impeded the original 1977 version of the film and also, at the behest of Columbia, and as a condition of Spielberg revising the film, shot additional footage showing the audience the interior of the mothership seen at the end of the film (a decision Spielberg would later regret as he felt the interior of the mothership should have remained a mystery). Nevertheless, the re-release was a moderate success, while the 2001 DVD release of the film restored the original ending.
1980s.
Next, Spielberg teamed with "Star Wars" creator and friend George Lucas on an action adventure film, "Raiders of the Lost Ark", the first of the Indiana Jones films. The archaeologist and adventurer hero Indiana Jones was played by Harrison Ford (whom Lucas had previously cast in his "Star Wars" films as Han Solo). The film was considered an homage to the cliffhanger serials of the Golden Age of Hollywood. It became the biggest film at the box office in 1981, and the recipient of numerous Oscar nominations including Best Director (Spielberg's second nomination) and Best Picture (the second Spielberg film to be nominated for Best Picture). "Raiders" is still considered a landmark example of the action-adventure genre. The film also led to Ford's casting in Ridley Scott's "Blade Runner".
A year later, Spielberg returned to the science fiction genre with "E.T. the Extra-Terrestrial". It was the story of a young boy and the alien he befriends, who was accidentally left behind by his companions and is attempting to return home. "E.T. the Extra-Terrestrial" went on to become the top-grossing film of all time. "E.T." was also nominated for nine Academy Awards including Best Picture and Best Director.
Between 1982 and 1985, Spielberg produced three high-grossing films: "Poltergeist" (for which he also co-wrote the screenplay), a big-screen adaptation of "" (for which he directed the segment "Kick The Can"), and "The Goonies" (Spielberg, executive producer, also wrote the story on which the screenplay was based). Spielberg appeared in a cameo on Cyndi Lauper's music video for the movie's theme song, "The Goonies R Good Enough".
His next directorial feature was the "Raiders" prequel "Indiana Jones and the Temple of Doom". Teaming up once again with Lucas and Ford, the film was plagued with uncertainty for the material and script. This film and the Spielberg-produced "Gremlins" led to the creation of the PG-13 rating due to the high level of violence in films targeted at younger audiences. In spite of this, "Temple of Doom" is rated PG by the MPAA, even though it is the darkest and, possibly, most violent Indy film. Nonetheless, the film was still a huge blockbuster hit in 1984. It was on this project that Spielberg also met his future wife, actress Kate Capshaw.
In 1985, Spielberg released "The Color Purple," an adaptation of Alice Walker's Pulitzer Prize-winning novel of the same name, about a generation of empowered African-American women during depression-era America. Starring Whoopi Goldberg and future talk-show superstar Oprah Winfrey, the film was a box office smash and critics hailed Spielberg's successful foray into the dramatic genre. Roger Ebert proclaimed it the best film of the year and later entered it into his Great Films archive. The film received eleven Academy Award nominations, including two for Goldberg and Winfrey. However, much to the surprise of many, Spielberg did not get a Best Director nomination. "The Color Purple" is the second of two Spielberg films not to be scored by John Williams, the first being "Duel".
In 1987, as China began opening to Western capital investment, Spielberg shot the first American film in Shanghai since the 1930s, an adaptation of J. G. Ballard's autobiographical novel "Empire of the Sun", starring John Malkovich and a young Christian Bale. The film garnered much praise from critics and was nominated for several Oscars, but did not yield substantial box office revenues. Reviewer Andrew Sarris called it the best film of the year and later included it among the best films of the decade. Spielberg was also a co-producer of the 1987 film "*batteries not included".
After two forays into more serious dramatic films, Spielberg then directed the third Indiana Jones film, 1989's "Indiana Jones and the Last Crusade". Once again teaming up with Lucas and Ford, Spielberg also cast actor Sean Connery in a supporting role as Indy's father. The film earned generally positive reviews and was another box office success, becoming the highest grossing film worldwide that year; its total box office receipts even topped those of Tim Burton's much-anticipated film "Batman", which had been the bigger hit domestically. Also in 1989, he re-united with actor Richard Dreyfuss for the romantic comedy-drama "Always", about a daredevil pilot who extinguishes forest fires. Spielberg's first romantic film, "Always" was only a moderate success and had mixed reviews.
1990s.
In 1991, Spielberg directed "Hook", about a middle-aged Peter Pan, played by Robin Williams, who returns to Neverland. Despite innumerable rewrites and creative changes coupled with mixed reviews, the film proved popular with audiences, making over $300 million worldwide (from a $70 million budget).
In 1993, Spielberg returned to the adventure genre with the film version of Michael Crichton's novel "Jurassic Park", about a theme park with genetically engineered dinosaurs. With revolutionary special effects provided by friend George Lucas's Industrial Light & Magic company, the film would eventually become the highest grossing film of all time (at the worldwide box office) with $914.7 million. This would be the third time that one of Spielberg's films became the highest grossing film ever.
Spielberg's next film, "Schindler's List", was based on the true story of Oskar Schindler, a man who risked his life to save 1,100 Jews from the Holocaust. "Schindler's List" earned Spielberg his first Academy Award for Best Director (it also won Best Picture). With the film a huge success at the box office, Spielberg used the profits to set up the Shoah Foundation, a non-profit organization that archives filmed testimony of Holocaust survivors. In 1997, the American Film Institute listed it among the 10 Greatest American Films ever Made (#9) which moved up to (#8) when the list was remade in 2007.
In 1994, Spielberg took a hiatus from directing to spend more time with his family and build his new studio, DreamWorks, with partners Jeffrey Katzenberg and David Geffen. In 1997, he helmed the sequel to 1993's "Jurassic Park" with "", which generated over $618 million worldwide despite mixed reviews, and was the second biggest hit of 1997 behind James Cameron's "Titanic" (which topped the original "Jurassic Park" to become the new recordholder for box office receipts).
His next film, "Amistad", was based on a true story (like "Schindler's List"), specifically about an African slave rebellion. Despite decent reviews from critics, it did not do well at the box office. Spielberg released "Amistad" under DreamWorks Pictures, which issued all of his films from "Amistad" until "Indiana Jones and the Kingdom of the Crystal Skull" in May 2008.
In 1998, Spielberg re-visited "Close Encounters" yet again, this time for a more definitive 137-minute "Collector's Edition" that puts more emphasis on the original 1977 release, while adding some elements of the previous 1980 "Special Edition," but deleting the latter version's "Mothership Finale," which Spielberg regretted shooting in the first place, feeling it should have remained ambiguous in the minds of viewers.
His next theatrical release in that same year was the World War II film "Saving Private Ryan", about a group of U.S. soldiers led by Capt. Miller (Tom Hanks) sent to bring home a paratrooper whose three older brothers were killed in the same twenty-four hours, June 5–6, of the Normandy landing. The film was a huge box office success, grossing over $481 million worldwide and was the biggest film of the year at the North American box office (worldwide it made second place after Michael Bay's "Armageddon"). Spielberg won his second Academy Award for his direction. The film's graphic, realistic depiction of combat violence influenced later war films such as "Black Hawk Down" and "Enemy at the Gates". The film was also the first major hit for DreamWorks, which co-produced the film with Paramount Pictures (as such, it was Spielberg's first release from the latter that was not part of the "Indiana Jones" series). Later, Spielberg and Tom Hanks produced a TV mini-series based on Stephen Ambrose's book "Band of Brothers". The ten-part HBO mini-series follows Easy Company of the 101st Airborne Division's 506th Parachute Infantry Regiment. The series won a number of awards at the Golden Globes and the Emmys.
2000s.
In 2001, Spielberg filmed fellow director and friend Stanley Kubrick's final project, "A.I. Artificial Intelligence" which Kubrick was unable to begin during his lifetime. A futuristic film about a humanoid android longing for love, "A.I." featured groundbreaking visual effects and a multi-layered, allegorical storyline, adapted by Spielberg himself. Though the film's reception in the US was relatively muted, it performed better overseas for a worldwide total box office gross of $236 million.
Spielberg and actor Tom Cruise collaborated for the first time for the futuristic neo-noir "Minority Report", based upon the science fiction short story written by Philip K. Dick about a Washington D.C. police captain in the year 2054 who has been foreseen to murder a man he has not yet met. The film received strong reviews with the review tallying website Rotten Tomatoes giving it a 92% approval rating, reporting that 206 out of the 225 reviews they tallied were positive. The film earned over $358 million worldwide. Roger Ebert, who named it the best film of 2002, praised its breathtaking vision of the future as well as for the way Spielberg blended CGI with live-action.
Spielberg's 2002 film "Catch Me If You Can" is about the daring adventures of a youthful con artist (played by Leonardo DiCaprio). It earned Christopher Walken an Academy Award nomination for Best Supporting Actor. The film is known for John Williams' score and its unique title sequence. It was a hit both commercially and critically.
Spielberg collaborated again with Tom Hanks along with Catherine Zeta-Jones and Stanley Tucci in 2004's "The Terminal", a warm-hearted comedy about a man of Eastern European descent who is stranded in an airport. It received mixed reviews but performed relatively well at the box office. In 2005, "Empire" magazine ranked Spielberg number one on a list of the greatest film directors of all time.
Also in 2005, Spielberg directed a modern adaptation of "War of the Worlds" (a co-production of Paramount and DreamWorks), based on the H. G. Wells book of the same name (Spielberg had been a huge fan of the book and the original 1953 film). It starred Tom Cruise and Dakota Fanning, and, as with past Spielberg films, Industrial Light & Magic (ILM) provided the visual effects. Unlike "E.T." and "Close Encounters of the Third Kind", which depicted friendly alien visitors, "War of the Worlds" featured violent invaders. The film was another huge box office smash, grossing over $591 million worldwide.
Spielberg's film "Munich", about the events following the 1972 Munich Massacre of Israeli athletes at the Olympic Games, was his second film essaying Jewish relations in the world (the first being "Schindler's List"). The film is based on "", a book by Canadian journalist George Jonas. It was previously adapted into the 1986 made-for-TV film "Sword of Gideon". The film received strong critical praise, but underperformed at the U.S. and world box-office; it remains one of Spielberg's most controversial films to date. "Munich" received five Academy Awards nominations, including Best Picture, Film Editing, Original Music Score (by John Williams), Best Adapted Screenplay, and Best Director for Spielberg. It was Spielberg's sixth Best Director nomination and fifth Best Picture nomination.
Spielberg directed "Indiana Jones and the Kingdom of the Crystal Skull", which wrapped filming in October 2007 and was released on May 22, 2008. This was his first film not to be released by DreamWorks since 1997. The film received generally positive reviews from critics, and has performed very well in theaters. As of May 10, 2010, "Indiana Jones and the Kingdom of the Crystal Skull" has grossed $317 million domestically, and over $786 million worldwide.
2010s.
In early 2009, Spielberg shot the first film in a planned trilogy of motion capture films based on "The Adventures of Tintin", written by Belgian artist Hergé, with Peter Jackson. "", was not released until October 2011, due to the complexity of the computer animation involved. The world premiere took place on October 22, 2011 in Brussels, Belgium. The film was released in North American theaters on December 21, 2011, in Digital 3D and IMAX. It received generally positive reviews from critics, and grossed over $373 million worldwide. "The Adventures of Tintin" won the award for Best Animated Feature Film at the Golden Globe Awards that year. It is the first non-Pixar film to win the award since the category was first introduced. Jackson has been announced to direct the second film.
Spielberg followed with "War Horse", shot in England in the summer of 2010. It was released just four days after "The Adventures of Tintin", on December 25, 2011. The film, based on the novel of the same name written by Michael Morpurgo and published in 1982, follows the long friendship between a British boy and his horse Joey before and during World War I – the novel was also adapted into a hit play in London which is still running there, as well as on Broadway. The film was released and distributed by Disney, with whom DreamWorks made a 30-picture deal in 2009. "War Horse" received generally positive reviews from critics, and was nominated for six Academy Awards including Best Picture.
Spielberg next directed the historical drama film "Lincoln", starring Daniel Day-Lewis as United States President Abraham Lincoln and Sally Field as Mary Todd Lincoln. Based on Doris Kearns Goodwin's bestseller "", the film covered the final four months of Lincoln's life. Written by Tony Kushner, the film was shot in Richmond, Virginia, in late 2011, and was released in November 2012 by Disney's Touchstone Pictures label in the United States. The film's international distribution was handled by 20th Century Fox. Upon release, "Lincoln" received widespread critical acclaim, and was nominated for twelve Academy Awards (the most of any film that year) including Best Picture and Best Director for Spielberg. It won the award for Best Production Design and Day-Lewis won the Academy Award for Best Actor for his portrayal of Lincoln, becoming the first three time winner in that category as well as the first to win for a performance directed by Spielberg.
Spielberg's upcoming film, "Bridge of Spies", is a Cold War thriller based on the 1960 U-2 incident, focusing on James B. Donovan's negotiations with the Soviets for the release of pilot Gary Powers after his aircraft was shot down over Soviet territory. The film stars Tom Hanks as Donovan, and costars Mark Rylance, Amy Ryan, Alan Alda, Billy Magnussen and Eve Hewson, and has a script by the Coen brothers. The film was shot from September to December 2014 on location in New York City, Berlin and Wroclaw, Poland (which doubled for East Berlin) and will be released on October 16, 2015. Participant Media will co-produce the film.
Production credits.
Since the mid-1980s, Spielberg has increased his role as a film producer. He headed up the production team for several cartoons, including the Warner Brothers hits "Tiny Toon Adventures", "Animaniacs", "Pinky and the Brain", "Toonsylvania", and "Freakazoid!", for which he collaborated with Jean MacCurdy and Tom Ruegger. Due to his work on these series, in the official titles, most of them say, "Steven Spielberg presents" as well as making numerous cameos on the shows. Spielberg also produced the Don Bluth animated features, "An American Tail" and "The Land Before Time", which were released by Universal Studios. He also served as one of the executive producers of "Who Framed Roger Rabbit" and its three related shorts ("Tummy Trouble", "Roller Coaster Rabbit", "Trail Mix-Up"), which were all released by Disney, under both the Walt Disney Pictures and the Touchstone Pictures banners. He was furthermore, for a short time, the executive producer of the long-running medical drama "ER". In 1989, he brought the concept of "The Dig" to LucasArts. He contributed to the project from that time until 1995 when the game was released. He also collaborated with software publishers Knowledge Adventure on the multimedia game "Steven Spielberg's Director's Chair", which was released in 1996. Spielberg appears, as himself, in the game to direct the player. The Spielberg name provided branding for a Lego Moviemaker kit, the proceeds of which went to the Starbright Foundation.
In 1993, Spielberg acted as executive producer for the highly anticipated television series "seaQuest DSV"; a science fiction series set "in the near future" starring Roy Scheider (who Spielberg had directed in "Jaws") and Jonathan Brandis that aired on Sundays at 8:00 pm. on NBC. While the first season was moderately successful, the second season did less well. Spielberg's name no longer appeared in the third season and the show was cancelled midway through it.
Spielberg served as an uncredited executive producer on "The Haunting", "The Prince of Egypt", "Just Like Heaven", "Shrek", "Road to Perdition", and "Evolution". He served as an executive producer for the 1997 film "Men in Black", and its sequels, "Men in Black II" and "Men in Black III". In 2005, he served as a producer of "Memoirs of a Geisha", an adaptation of the novel by Arthur Golden, a film to which he was previously attached as director. In 2006, Spielberg co-executive produced with famed filmmaker Robert Zemeckis a CGI children's film called "Monster House", marking their eighth collaboration since 1990's "Back to the Future Part III". He also teamed with Clint Eastwood for the first time in their careers, co-producing Eastwood's "Flags of Our Fathers" and "Letters from Iwo Jima" with Robert Lorenz and Eastwood himself. He earned his twelfth Academy Award nomination for the latter film as it was nominated for Best Picture. Spielberg served as executive producer for "Disturbia" and the "Transformers" live action film with Brian Goldner, an employee of Hasbro. The film was directed by Michael Bay and written by Roberto Orci and Alex Kurtzman, and Spielberg continued to collaborate on the sequels, ' and '. In 2011, he produced the J. J. Abrams science fiction thriller film "Super 8" for Paramount Pictures.
Other major television series Spielberg produced were "Band of Brothers", "Taken" and "The Pacific". He was an executive producer on the critically acclaimed 2005 TV miniseries "Into the West" which won two Emmy awards, including one for Geoff Zanelli's score. For his 2010 miniseries "The Pacific" he teamed up once again with co-producer Tom Hanks, with Gary Goetzman also co-producing'. The miniseries is believed to have cost $250 million and is a 10-part war miniseries centered on the battles in the Pacific Theater during World War II. Writer Bruce McKenna, who penned several installments of ("Band of Brothers"), was the head writer.
In 2007, Steven Spielberg and Mark Burnett co-produced "On the Lot" a short-lived TV reality show about filmmaking. Despite this, he never gave up working on television. He currently serves as one of the executive producers on "United States of Tara", a show created by Academy Award winner Diablo Cody which they developed together (Spielberg is uncredited as creator).
In 2011, Spielberg launched "Falling Skies", a science fiction television series, on the TNT network. He developed the series with Robert Rodat and is credited as an executive producer. Spielberg is also producing the Fox TV series "Terra Nova". "Terra Nova" begins in the year 2149 when all life on the planet Earth is threatened with extinction resulting in scientists opening a door that allows people to travel back 85 million years to prehistoric times. Spielberg also produced "The River" and "Smash".
Acting credits.
Steven Spielberg had cameo roles in "The Blues Brothers", "Gremlins", "Vanilla Sky", and "Austin Powers in Goldmember", as well as small uncredited cameos in a handful of other films, such as a life-station worker in "Jaws". He also made numerous cameo roles in the Warner Brothers cartoons he produced, such as Animaniacs, and even made reference to some of his films. Spielberg voiced himself in the film "Paul", and in one episode of "Tiny Toon Adventures" titled "Buster and Babs Go Hawaiian".
Involvement in video games.
Apart from being an ardent gamer Spielberg has had a long history of involvement in video games. He has been giving thanks to his games of his division DreamWorks Interactive most notable as "Someone's in the Kitchen" with script written by Animaniacs' Paul Rugg, "Goosebumps: Escape from HorrorLand", "The Neverhood" (all in 1996), "Skullmonkeys", "Dilbert's Desktop Games", ' (all 1997), "Boombots" (1999), ' (1999), and "Clive Barker's Undying" (2001). In 2005 the director signed with Electronic Arts to collaborate on three games including an action game and an award winning puzzle game for the Wii called "Boom Blox" (and its 2009 sequel: "Boom Blox Bash Party"). Previously, he was involved in creating the scenario for the adventure game "The Dig". In 1996, Spielberg worked on and shot original footage for a movie-making simulation game called "Steven Spielberg's Director's Chair". He is the creator of the "Medal of Honor" series by Electronic Arts. He is credited in the special thanks section of the 1998 video game "". In 2013, Spielberg has announced he is collaborating with 343 Industries for a live-action TV show of "Halo".
Upcoming and announced projects.
Spielberg's next announced project is an adaptation of Roald Dahl's celebrated children's story "The BFG". Spielberg's DreamWorks bought the rights in 2010, originally intending John Madden to direct. The film is being written by "E.T." screenwriter Melissa Mathison and is set for release on July 1, 2016.
Spielberg is attached to direct an adaptation of American photojournalist Lynsey Addario's memoir "It's What I Do". Jennifer Lawrence is attached to star in the lead role.
Spielberg was scheduled to shoot a $200 million adaptation of Daniel H. Wilson's novel "Robopocalypse", adapted for the screen by Drew Goddard. The film would follow a global human war against a robot uprising about 15–20 years in the future. Like "Lincoln", it was to be released by Disney in the United States and Fox overseas. It was set for release on April 25, 2014, with Anne Hathaway and Chris Hemsworth set to star, but Spielberg postponed production indefinitely in January 2013, just before it had been set to begin.
In 2009, Spielberg reportedly tried to obtain the screen rights to make a film based on Microsoft's "Halo" series. In September 2008, Steven Spielberg bought film rights for John Wyndham's novel "Chocky" and is interested in directing it. He is also interested in making an adaptation of "A Steady Rain", "Pirate Latitudes", "The 39 Clues", and "Under the Dome", along with a remake of "When Worlds Collide".
In May 2009, Steven Spielberg bought the rights to the life story of Martin Luther King, Jr. Spielberg will be involved not only as producer but also as a director. However, the purchase was made from the King estate, led by son Dexter, while the two other surviving children, the Reverend Bernice and Martin III, immediately threatened to sue, not having given their approvals to the project.
In June 2006, Steven Spielberg announced he would direct a scientifically accurate film about "a group of explorers who travel through a worm hole and into another dimension", from a treatment by Kip Thorne and producer Lynda Obst. In January 2007, screenwriter Jonathan Nolan met with them to discuss adapting Obst and Thorne's treatment into a narrative screenplay. The screenwriter suggested the addition of a "time element" to the treatment's basic idea, which was welcomed by Obst and Thorne. In March of that year, Paramount hired Nolan, as well as scientists from Caltech, forming a workshop to adapt the treatment under the title "Interstellar". The following July, Kip Thorne said there was a push by people for him to portray himself in the film. Spielberg later abandoned "Interstellar", which was eventually directed by Christopher Nolan.
In 2008, Spielberg and DreamWorks acquired the rights to produce a live-action film adaptation of the original "Ghost in the Shell" manga. Avi Arad and Steven Paul were later confirmed as producers, Rupert Sanders to direct, and Scarlett Johansson to star in the lead role.
In March 2013, Spielberg announced that he was "developing a Stanley Kubrick screenplay for a miniseries, not for a motion picture, about the life of Napoleon."
It was announced on May 2, 2013, that Spielberg would direct the film about the story of U.S. sniper Chris Kyle, titled "American Sniper". However, on August 5, 2013, it was announced that Spielberg had decided not to direct the film, which was instead directed by Clint Eastwood.
Spielberg has also considered directing "The Kidnapping of Edgardo Mortara" and a remake of "West Side Story".
Themes.
Spielberg's films often deal with several recurring themes. Most of his films deal with ordinary characters searching for or coming in contact with extraordinary beings or finding themselves in extraordinary circumstances. In an AFI interview in August 2000 Spielberg commented on his interest in the possibility of extra terrestrial life and how it has influenced some of his films. Spielberg described himself as feeling like an alien during childhood, and his interest came from his father, a science fiction fan, and his opinion that aliens would not travel light years for conquest, but instead curiosity and sharing of knowledge.
A strong consistent theme in his family-friendly work is a childlike, even naïve, sense of wonder and faith, as attested by works such as "Close Encounters of the Third Kind", "E.T. the Extra-Terrestrial", "Hook", and "A.I. Artificial Intelligence". According to Warren Buckland, these themes are portrayed through the use of low height camera tracking shots, which have become one of Spielberg's directing trademarks. In the cases when his films include children ("E.T. the Extra-Terrestrial", "Empire of the Sun", "Jurassic Park", etc.), this type of shot is more apparent, but it is also used in films like "Munich", "Saving Private Ryan", "The Terminal", "Minority Report", and "Amistad". If one views each of his films, one will see this shot utilized by the director, notably the water scenes in "Jaws" are filmed from the low-angle perspective of someone swimming. Another child oriented theme in Spielberg's films is that of loss of innocence and coming-of-age. In "Empire of the Sun", Jim, a well-groomed and spoiled English youth, loses his innocence as he suffers through World War II China. Similarly, in "Catch Me If You Can", Frank naively and foolishly believes that he can reclaim his shattered family if he accumulates enough money to support them.
The most persistent theme throughout his films is tension in parent-child relationships. Parents (often fathers) are reluctant, absent or ignorant. Peter Banning in "Hook" starts off in the beginning of the film as a reluctant married-to-his-work parent who through the course of the film regains the respect of his children. The notable absence of Elliott's father in "E.T.", is the most famous example of this theme. In "Indiana Jones and the Last Crusade", it is revealed that Indy has always had a very strained relationship with his father, who is a professor of medieval literature, as his father always seemed more interested in his work, specifically in his studies of the Holy Grail, than in his own son, although his father does not seem to realize or understand the negative effect that his aloof nature had on Indy (he even believes he was a good father in the sense that he taught his son "self reliance," which is not how Indy saw it). Even Oskar Schindler, from "Schindler's List", is reluctant to have a child with his wife. "Munich" depicts Avner as a man away from his wife and newborn daughter. There are of course exceptions; Brody in "Jaws" is a committed family man, while John Anderton in "Minority Report" is a shattered man after the disappearance of his son. This theme is arguably the most autobiographical aspect of Spielberg's films, since Spielberg himself was affected by his parents' divorce as a child and by the absence of his father. Furthermore to this theme, protagonists in his films often come from families with divorced parents, most notably "E.T. the Extra-Terrestrial" (protagonist Elliot's mother is divorced) and "Catch Me If You Can" (Frank Abagnale's mother and father split early on in the film). Little known also is Tim in "Jurassic Park" (early in the film, another secondary character mentions Tim and Lex's parents' divorce). The family often shown divided is often resolved in the ending as well. Following this theme of reluctant fathers and father figures, Tim looks to Dr. Alan Grant as a father figure. Initially, Dr. Grant is reluctant to return those paternal feelings to Tim. However, by the end of the film, he has changed, and the kids even fall asleep with their heads on his shoulders.
Most of his films are generally optimistic in nature. Critics frequently accuse his films of being overly sentimental, though Spielberg feels it is fine as long as it is disguised. The influence comes from directors Frank Capra and John Ford.
Frequent collaborators.
Actors.
In terms of casting and production itself, Spielberg has a known penchant for working with actors and production members from his previous films. For instance, he has cast Richard Dreyfuss in several films: "Jaws", "Close Encounters of the Third Kind", and "Always". Aside from his role as Indiana Jones, Spielberg also cast Harrison Ford as a headteacher in "E.T. the Extra-Terrestrial" (though the scene was ultimately cut). Although Spielberg directed him only once (in Raiders of the Lost Ark, for which he voiced many of the animals), veteran voice actor Frank Welker has lent his voice in a number of productions Spielberg has executively produced from "Gremlins" to its sequel ', as well as "The Land Before Time" (and lending his voice to its sequels which Spielberg had no involvement in), "Who Framed Roger Rabbit", and television shows such as "Tiny Toons", "Animaniacs", and SeaQuest DSV. Recently Spielberg has used Tom Hanks on several occasions and has cast him in "Saving Private Ryan", "Catch Me If You Can", and "The Terminal". Spielberg also has collaborated with Tom Cruise twice on "Minority Report" and "War of the Worlds". Spielberg has also cast Shia LaBeouf in five films: "Transformers", "Eagle Eye", "Indiana Jones and the Kingdom of the Crystal Skull", ', and "".
Other collaborations.
Spielberg prefers working with production members with whom he has developed an existing working relationship. An example of this is his production relationship with Kathleen Kennedy who has served as producer on all his major films from "E.T. the Extra-Terrestrial" to the recent "Lincoln". For cinematography, Allen Daviau, a childhood friend and cinematographer, shot the early Spielberg film "Amblin" and most of his films up to "Empire of the Sun"; Janusz Kamiński who has shot every Spielberg film since "Schindler's List" (see List of film director and cinematographer collaborations); and the film editor Michael Kahn who has edited every film directed by Spielberg from "Close Encounters" to "Munich" (except "E.T. the Extra-Terrestrial"). Most of the DVDs of Spielberg's films have documentaries by Laurent Bouzereau.
A famous example of Spielberg working with the same professionals is his long-time collaboration with John Williams and the use of his musical scores in all of his films since "The Sugarland Express" (except "Bridge of Spies", "The Color Purple" and ""). One of Spielberg's trademarks is his use of music by John Williams to add to the visual impact of his scenes and to try and create a lasting picture and sound of the film in the memories of the film audience. These visual scenes often uses images of the sun (e.g. "Empire of the Sun", "Saving Private Ryan", the final scene of "Jurassic Park", and the end credits of "Indiana Jones and the Last Crusade" (where they ride into the sunset)), of which the last two feature a Williams score at that end scene. Spielberg is a contemporary of filmmakers George Lucas, Francis Ford Coppola, Martin Scorsese, John Milius, and Brian De Palma, collectively known as the "Movie Brats". Aside from his principal role as a director, Spielberg has acted as a producer for a considerable number of films, including early hits for Joe Dante and Robert Zemeckis. Spielberg has often never worked with the same screenwriter in his films, beside Tony Kushner and David Koepp, who have written a few of his films more than once.
Personal life.
Marriages and children.
Spielberg first met actress Amy Irving in 1976 at the suggestion of director Brian De Palma, who knew he was looking for an actress to play in "Close Encounters". After meeting her, Spielberg told his co-producer Julia Phillips, "I met a real heartbreaker last night.":293 Although she was too young for the role, she and Spielberg began dating and she eventually moved in to what she described as his "bachelor funky" house.:294 They lived together for four years, but the stresses of their professional careers took a toll on their relationship. Irving wanted to be certain that whatever success she attained as an actress would be her own: "I don't want to be known as Steven's girlfriend," she said, and chose not to be in any of his films during those years.:295 
As a result, they broke up in 1979, but remained close friends. Then in 1984 they renewed their romance, and in November 1985, they married, already having had a son, Max Samuel. After three and a half years of marriage, however, many of the same competing stresses of their careers caused them to divorce in 1989. They agreed to maintain homes near each other as to facilitate the shared custody and parenting of their son.:403 Their divorce was recorded as the third most costly celebrity divorce in history. 
Spielberg subsequently developed a relationship with actress Kate Capshaw, whom he met when he cast her in "Indiana Jones and the Temple of Doom". They married on October 12, 1991. Capshaw is a convert to Judaism. They currently move among their four homes in Pacific Palisades, California; New York City; Quelle Farm, Georgica Pond in East Hampton, New York, on Long Island; and Naples, Florida.
There are seven children in the Spielberg-Capshaw family:
Religion.
Spielberg grew up in a Jewish household, including having a bar mitzvah in Phoenix when he turned 13. He grew away from Judaism after his family moved to various cities during his high school years, where they became the only Jews in the neighborhood.:29 Before those years, his family was involved in the synagogue and had many Jewish friends and nearby relatives. 
He remembers his grandparents telling him about their life in Russia, where they were subjected to religious persecution, causing them to eventually flee to the United States. He was made aware of the Holocaust by his parents, who he says “talked about it all the time, and so it was always on my mind.”:30 His father had lost between sixteen and twenty relatives during the Holocaust.:21
Spielberg "rediscovered the honor of being a Jew," he says, before he made "Schindler's List", when he married Kate Capshaw.:25 Until then, having become a filmmaker, he only felt his connection to Judaism when he visited his parents. He says he made the film to partly to create “something that would confirm my Judaism to my family and myself.”
Kate is Protestant and she insisted on converting to Judaism. She spent a year studying, did the “mikveh,” the whole thing. She chose to do a full conversion "before" we were married in 1991, and she married me after becoming a Jew. I think "that," more than anything else, brought me back to Judaism.:25
He credits her with fueling his family's current level of observance and for keeping the “momentum flowing" in their lives, as they now observe Jewish holidays, light candles on Friday nights, and give their children Bar and Bat Mitzvahs.:26 "This shiksa goddess has made me a better Jew than my own parents.":27
Producing "Schindler's List" in 1993 also renewed his faith, Spielberg says, but "it really was the fact that my wife took a profound interest in Judaism.":25 He waited ten years after being given the story in 1982 to make the film, as he didn't yet feel "mature" enough.:32 He first wanted to have a family, "to figure out what my place was in the world. . . . When my first son, [Max] was born, it greatly affected me. . . . A spirit began to ignite in me, and I became a Jewish dad. . .":21
He said that making the film became a “natural experience” for him, adding, "I "had" to tell the story. I've lived on its outer edges." The film, writes biographer Joseph McBride, thereby became the "culmination" of Spielberg's long personal struggle with his Jewish identity.:18 Some claim the film has made Spielberg "the one true heir to the great Jewish moguls who created Hollywood," most of whom had actively avoided depicting Jews or the Holocaust in their films.
Wealth.
"Forbes" magazine places Spielberg's personal net worth at $3 billion.
Recognition.
In 2002, Spielberg was one of eight flagbearers who carried the Olympic Flag into Rice-Eccles Stadium at the Opening Ceremonies of the 2002 Winter Olympic Games in Salt Lake City. In 2006, "Premiere" listed him as the most powerful and influential figure in the motion picture industry. "Time" listed him as one of the . At the end of the 20th century, "Life" named him the most influential person of his generation. In 2009, Boston University presented him an honorary Doctor of Humane Letters degree.
According to "Forbes"‍ '​ Most Influential Celebrities 2014 list, Spielberg was listed as the most influential celebrity in America. The annual list is conducted by E-Poll Market Research and it gave more than 6,600 celebrities on 46 different personality attributes a score representing "how that person is perceived as influencing the public, their peers, or both." Spielberg received a score of 47, meaning 47% of the US believes he is influential. Gerry Philpott, president of E-Poll Market Research, supported Spielberg's score by stating, "If anyone doubts that Steven Spielberg has greatly influenced the public, think about how many will think for a second before going into the water this summer."
Hobbies.
In June 1982 Steven Spielberg spent $60,500 to buy a Rosebud sled from the 1941 film "Citizen Kane" – one of three balsa sleds used in the closing scenes and the only one that was not burned. Spielberg had paid homage to the Orson Welles classic in the final shot of the government warehouse in his 1981 film, "Raiders of the Lost Ark". "When you look at Rosebud, you don't think of fast dollars, fast sequels and remakes," Spielberg said. "This to me says that movies of my generation had better be good." In 1994 Spielberg also purchased an original script for Welles's 1938 radio broadcast "The War of the Worlds" – Welles's own directorial copy and one of only two radioscripts known to survive. Spielberg adapted "The War of the Worlds" for a feature film in 2005.
Spielberg is a major collector of the American illustrator and painter Norman Rockwell. A collection of 57 Rockwell paintings and drawings owned by Spielberg and fellow Rockwell collector and film director George Lucas were displayed at the Smithsonian American Art Museum from July 2, 2010 to January 2, 2011 in an exhibition titled "Telling Stories".
Spielberg is an avid film buff, and, when not shooting a picture, he will indulge in "movie orgies" (watching many over a single weekend). He sees almost every major summer blockbuster in theaters if not preoccupied and enjoys most of them; "If I get pleasure from anything, I can't think of it as dumb or myself as shallow [...] I'll probably go late to that movie and go, 'What the dickens was everybody complaining about, that wasn't so bad!'".
Since playing Pong while filming "Jaws" in 1974, Spielberg has been an avid video gamer. Spielberg played many of LucasArts adventure games, including the first Monkey Island games. He owns a Wii, a PlayStation 3, a PSP, and Xbox 360, and enjoys playing first-person shooters such as the "Medal of Honor" series and "". He has also criticized the use of cut scenes in games, calling them intrusive, and feels making story flow naturally into the gameplay is a challenge for future game developers.
Stalking.
In 2001, Spielberg was stalked by conspiracy theorist and former social worker Diana Napolis. She accused him, along with actress Jennifer Love Hewitt, of controlling her thoughts through "cybertronic" technology and being part of a satanic conspiracy against her. Napolis was committed to a mental institution before pleading guilty to stalking, and released on probation with a condition that she have no contact with either Spielberg or Hewitt.
Spielberg was a target of the 2002 white supremacist terror plot.
Jonathan Norman was arrested after making two attempts to enter Spielberg's Pacific Palisades home in June and July 1997. Norman was jailed for 25 years in California. Spielberg told the court: "Had Jonathan Norman actually confronted me, I genuinely, in my heart of hearts, believe that I would have been raped or maimed or killed."
Awards and honors.
Spielberg has won three Academy Awards. He has been nominated for seven Academy Awards for the category of Best Director, winning two of them ("Schindler's List" and "Saving Private Ryan"), and nine of the films he directed were up for the Best Picture Oscar ("Schindler's List" won). In 1987 he was awarded the Irving G. Thalberg Memorial Award for his work as a creative producer.
Drawing from his own experiences in Scouting, Spielberg helped the Boy Scouts of America develop a merit badge in cinematography in order to help promote filmmaking as a marketable skill. The badge was launched at the 1989 National Scout Jamboree, which Spielberg attended, and where he personally counseled many boys in their work on requirements.
That same year, 1989, saw the release of "Indiana Jones and the Last Crusade". The opening scene shows a teenage Indiana Jones in scout uniform bearing the rank of a Life Scout. Spielberg stated he made Indiana Jones a Boy Scout in honor of his experience in Scouting. For his career accomplishments, service to others, and dedication to a new merit badge Spielberg was awarded the Distinguished Eagle Scout Award.
Steven Spielberg received the AFI Life Achievement Award in 1995.
In 1998 he was awarded the Federal Cross of Merit with Ribbon of the Federal Republic of Germany. The Award was presented to him by President Roman Herzog in recognition of his film "Schindler's List" and his Shoa-Foundation.
In 1999, Spielberg received an honorary degree from Brown University. Spielberg was also awarded the Department of Defense Medal for Distinguished Public Service by Secretary of Defense William Cohen at the Pentagon on August 11, 1999; Cohen presented the award in recognition of Spielberg's film "Saving Private Ryan".
In 2001, he was honored as an honorary Knight Commander of the Order of the British Empire (KBE) by Queen Elizabeth II.
In 2004 he was admitted as knight of the Légion d'honneur by president Jacques Chirac. On July 15, 2006, Spielberg was also awarded the at the Summer Gala of the Chicago International Film Festival, and also was awarded a Kennedy Center honour on December 3. The tribute to Spielberg featured a short, filmed biography narrated by Tom Hanks and included thank-yous from World War II veterans for "Saving Private Ryan", as well as a performance of the finale to Leonard Bernstein's "Candide", conducted by John Williams (Spielberg's frequent composer).
The Science Fiction Hall of Fame inducted Spielberg in 2005, the first year it considered non-literary contributors. In November 2007, he was chosen for a Lifetime Achievement Award to be presented at the sixth annual Visual Effects Society Awards in February 2009. He was set to be honored with the Cecil B. DeMille Award at the January 2008 Golden Globes; however, the new, watered-down format of the ceremony resulting from conflicts in the 2007–08 writers strike, the HFPA postponed his honor to the 2009 ceremony. In 2008, Spielberg was awarded the Légion d'honneur.
In June 2008, Spielberg received Arizona State University's Hugh Downs Award for Communication Excellence.
Spielberg received an honorary degree at Boston University's 136th Annual Commencement on May 17, 2009. In October 2009 Steven Spielberg received the Philadelphia Liberty Medal; presenting him with the medal was former US president and Liberty Medal recipient Bill Clinton. Special guests included Whoopi Goldberg, Pennsylvania Governor Ed Rendell and Philadelphia Mayor Michael Nutter.
On October 22, 2011 he was admitted as a Commander of the Belgian Order of the Crown. He was given the badge on a red neck ribbon by the Belgian Federal Minister of Finance Didier Reynders. The Commander is the third highest rank of the Order of the Crown. He was the president of the jury for the 2013 Cannes Film Festival.
On November 19, 2013, Spielberg was honored by the National Archives and Records Administration with its Records of Achievement Award. Spielberg was given two facsimiles of the 13th Amendment to the United States Constitution, one passed but not ratified in 1861, as well as a facsimile of the actual 1865 amendment signed into law by President Abraham Lincoln. The amendment and the process of passing it were the subject of his film "Lincoln".
Further reading.
</dl>

</doc>
<doc id="26941" url="http://en.wikipedia.org/wiki?curid=26941" title="Spike Lee">
Spike Lee

Shelton Jackson "Spike" Lee (born March 20, 1957) is an American film director, producer, writer, and actor. His production company, 40 Acres and a Mule Filmworks, has produced over 35 films since 1983.
Lee's movies have examined race relations, colorism in the black community, the role of media in contemporary life, urban crime and poverty, and other political issues. Lee has received two Academy Award nominations and won numerous other awards, including an Emmy Award as well as the 2013 Gish Prize "for his brilliance and unwavering courage in using film to challenge conventional thinking."
Early life.
Lee was born in Atlanta, Georgia, the son of Jacqueline Carroll (née Shelton), a teacher of arts and black literature, and William James Edward Lee III, a jazz musician and composer. Lee also had three younger siblings Joie, David, and Cinqué, who all worked in many different positions in Lee's films. Director Malcolm D. Lee is his cousin. When he was a child, the family moved to Brooklyn, New York. During his childhood, his mother nicknamed him "Spike". In Brooklyn, he attended John Dewey High School.
Lee enrolled in Morehouse College, a historically black college, where he made his first student film, "Last Hustle in Brooklyn". He took film courses at Clark Atlanta University and graduated with a BA in Mass Communication from Morehouse. He did graduate work at New York University's Tisch School of the Arts, where he earned a Master of Fine Arts in Film & Television.
Career.
Film.
Lee's thesis film, "", was the first student film to be showcased in Lincoln Center's New Directors New Films Festival.
In 1985, Lee began work on his first feature film, "She's Gotta Have It". With a budget of $175,000, he shot the film in two weeks. When the film was released in 1986, it grossed over $7,000,000 at the U.S. box office.
Lee's 1989 film "Do the Right Thing" was nominated for an Academy Award for Best Original Screenplay in 1989. Many people, including Hollywood's Kim Basinger believed that "Do the Right Thing" also deserved a Best Picture nomination. "Driving Miss Daisy" won Best Picture that year. Lee said in an April 7, 2006 interview with "New York" magazine that the other film's success, which he thought was based on safe stereotypes, hurt him more than if his film had not been nominated for an award.
After the 1990 release of "Mo' Better Blues", Lee was accused of antisemitism by the Anti-Defamation League and several film critics. They criticized the characters of the club owners Josh and Moe Flatbush, described as "Shylocks". Lee denied the charge, explaining that he wrote those characters in order to depict how black artists struggled against exploitation. Lee said that Lew Wasserman, Sidney Sheinberg or Tom Pollock, the Jewish heads of MCA and Universal Studios, were unlikely to allow antisemitic content in a film they produced. He said he could not make an antisemitic film because Jews run Hollywood, and "that's a fact."
His 1997 documentary "4 Little Girls," about the children killed in the 16th Street Baptist Church bombing in Birmingham, Alabama in 1963, was nominated for the Best Feature Documentary Academy Award.
On May 2, 2007, the 50th San Francisco International Film Festival honored Spike Lee with the San Francisco Film Society's Directing Award. He received the 2008 Wexner Prize. In 2013, he won The Dorothy and Lillian Gish Prize, one of the richest prizes in the American arts worth $300,000.
Lee's films are typically referred to as "Spike Lee Joints" and the closing credits always end with the phrases "By Any Means Necessary", "Ya Dig" and "Sho Nuff".
Commercials.
In mid-1990, Levi's began producing a series of TV commercials directed by Lee for their 501 button fly jeans.
Marketing executives from Nike offered Lee a job directing commercials for the company. They wanted to pair Lee's character, the Michael Jordan-loving Mars Blackmon, and Jordan in a marketing campaign for the Air Jordan line. Later, Lee was called on to comment on the controversy surrounding the inner-city rash of violence involving youths trying to steal Air Jordans from other kids. He said that, rather than blaming manufacturers of apparel that gained popularity, "deal with the conditions that make a kid put so much importance on a pair of sneakers, a jacket and gold".
Through the marketing wing of 40 Acres and a Mule, Lee has directed commercials for Converse, Jaguar, Taco Bell and Ben & Jerry's.
Personal life.
Lee and his wife, attorney Tonya Lewis, had their first child, daughter Satchel, in December 1994. They also have a son, Jackson, born in 1997. Spike Lee is a fan of the American baseball team the New York Yankees, basketball team the New York Knicks, and the English football team Arsenal. One of the documentaries in ESPN's "30 for 30" series, "Winning Time: Reggie Miller vs. The New York Knicks", focuses partly on Lee's interaction with Miller at Knicks games in Madison Square Garden.
In June 2003 Lee sought an injunction against Spike TV to prevent them from using his nickname. Lee claimed that because of his fame, viewers would think he was associated with the new channel.
While Lee continues to maintain an office in Fort Greene, Brooklyn, he and his wife live on the Upper East Side of Manhattan.
Controversial remarks.
As Lee became more well known and his work and comments were followed more closely, he became embroiled in some controversies.
In May 1999, the "New York Post" reported that Lee made an inflammatory comment about Charlton Heston, president of the National Rifle Association, while speaking to reporters at the Cannes Film Festival. Lee was quoted as saying the National Rifle Association should be disbanded and, of Heston, someone should "Shoot him with a .44 Bull Dog." Lee said he intended it as a joke. He was responding to coverage about whether Hollywood was responsible for school shootings. Lee said, "The problem is guns," he said. Republican House Majority Leader Dick Armey condemned Lee as having "nothing to offer the debate on school violence except more violence and more hate."
In October 2005, Lee responded to a CNN anchor's question as to whether the government intentionally ignored the plight of black Americans during the 2005 Hurricane Katrina catastrophe by saying, "It's not too far-fetched. I don't put anything past the United States government. I don't find it too far-fetched that they tried to displace all the black people out of New Orleans." In later comments, Lee cited the government's past atrocities including the Tuskegee Study of Untreated Syphilis in the Negro Male.
At the 2008 Cannes Film Festival, Lee, who was then making "Miracle at St. Anna," about an all-black U.S. division fighting in Italy during World War II, criticized director Clint Eastwood for not depicting black Marines in his own WWII film, "Flags of Our Fathers". Citing historical accuracy, Eastwood responded that his film was specifically about the Marines who raised the flag on Mount Suribachi at Iwo Jima, pointing out that while black Marines did fight at Iwo Jima, the U.S. military was segregated during WWII, and none of the men who raised the flag were black. He angrily said that Lee should "shut his face". Lee responded that Eastwood was acting like an "angry old man", and incorrectly argued that despite making two Iwo Jima films back to back, "Letters from Iwo Jima" and "Flags of Our Fathers", "there was not one black soldier in both of those films". He added that he and Eastwood were "not on a plantation." Lee later claimed that the event was exaggerated by the media and that he and Eastwood had reconciled through mutual friend Steven Spielberg, culminating in his sending Eastwood a print of "Miracle at St. Anna".
In March 2012, after the shooting of Trayvon Martin, Spike Lee was one of many people who used Twitter to circulate a message which claimed to give the home address of the shooter George Zimmerman. The address turned out to be incorrect, causing the real occupants, Elaine and David McClain, to leave home and stay at a hotel due to numerous death threats. Lee issued an apology and reached an agreement with the McClains which reportedly included "compensation", with their attorney stating "The McClains’ claim is fully resolved". Nevertheless, in November 2013, the McClains filed a negligence lawsuit which accused Lee of "encouraging a dangerous mob mentality among his Twitter followers, as well as the public-at-large". The lawsuit, which a court filing reportedly valued at $1.2 million, alleged that the couple suffered "injuries and damages" that continued after the initial settlement up through Zimmerman's trial in 2013.

</doc>
<doc id="26942" url="http://en.wikipedia.org/wiki?curid=26942" title="Spike Jonze">
Spike Jonze

Spike Jonze (pronounced "Jones" ; born Adam Spiegel; October 22, 1969) is an American director, producer, screenwriter and actor, whose work includes music videos, commercials, film and television. He started his feature film directing career with "Being John Malkovich" (1999) and "Adaptation" (2002), both written by Charlie Kaufman, and then started movies with screenplays of his own with "Where the Wild Things Are" (2009) and "Her" (2013).
Jonze is well known for his music video collaborations with Fatboy Slim, Weezer, Beastie Boys, and Björk. He was a co-creator and executive producer of MTV's "Jackass". He is currently the creative director of Vice Media, Inc.. He is part owner of skateboard company Girl Skateboards with riders Rick Howard and Mike Carroll.
He co-founded Directors Label, with filmmakers Chris Cunningham and Michel Gondry, and the Palm Pictures company.
He has been nominated for four Academy Awards: Best Director for "Being John Malkovich", and Best Picture, Best Original Screenplay and Best Original Song ("The Moon Song") for "Her". He won the Golden Globe Award for Best Screenplay, the Writers Guild of America Award for Best Original Screenplay, and the 2014 Academy Award for Best Original Screenplay for "Her".
Early life and education.
Jonze was born on October 22, 1969 in Rockville, Maryland, and grew up in Bethesda, Maryland and in Gulph Mills, Pennsylvania. His father, Arthur H. Spiegel III, was a distant relation of the Spiegel catalog family, and founded APM Management Consultants. His mother, Sandra L. Granzow, is a writer, communications consultant in developing countries, and artist. His brother, Sam "Squeak E. Clean" Spiegel, is a producer and DJ. He also has a sister, Julia. His father was from a German Jewish family, while his mother has German, Scottish, and English (Christian) ancestry.
Jonze attended the San Francisco Art Institute in San Francisco, California. When he was in junior high in high school (Walt Whitman High School), Jonze spent time at a Bethesda community store, where the former owner Mike Henderson gave him his nickname "Spike Jonze" in reference to Spike Jones. He fronted Club Homeboy, an international BMX club, with Mark "Lew" Lewman and Andy Jenkins, both co-editors of "Freestylin' Magazine" in the mid- to late 1980s, where Jonze worked as a photographer. The three also created the youth culture magazines "Homeboy" and "Dirt" (the latter of which was described as ""Sassy Magazine" for boys," being published by the same company and distributed in cellophane bags with the landmark magazine for young women).
Career.
In 2006, he was nominated by the Directors Guild of America for "Outstanding Achievement in Commercials in 2005." He was nominated for a body of work that included "Hello Tomorrow" for Adidas, "Lamp" for IKEA, and "Pardon Our Dust" for The Gap. He was a producer and co-creator of MTV television series "Jackass" and "", also directing some of the segments. Jonze has acted in some videos and films; his most prominent role was in "Three Kings" as the sweet, dimwitted, casually racist Conrad, in which he was directed by friend David O. Russell.
Jonze was a co-founder and editor of "Dirt" magazine along with Mark Lewman and Andy Jenkins, as well as an editor for "Grand Royal Magazine" and senior photographer for "Transworld Skateboarding". In the past, Jonze shot street skateboarding videos, most notably Blind's highly influential "Video Days" in 1991, and Lakai Footwear's "Fully Flared" in 2007. He co-directed the Girl Skateboards film "Yeah Right!" and the Chocolate Skateboards video "Hot Chocolate". In the closing credits montage of "Yeah Right!," Spike is shown doing a nollie heelflip in loafers. He is co-owner of Girl Skateboards.
Jonze has many alter egos, including Richard Koufey (alternately spelled Coufey or Couffe), the leader of the Torrance Community Dance Group, an urban troupe that performs in public spaces. The Koufey persona appeared when Jonze, in character, filmed himself dancing to Fatboy Slim's "The Rockafeller Skank" as it played on a boom box in a public area. Jonze showed the video to Slim, who appears briefly in the video around the 3:57 mark. Jonze then assembled a group of dancers to perform to Slim's "Praise You" outside a Westwood, California movie theater and taped the performance. The resulting clip was a huge success, and "Koufey" and his troupe were invited to New York City to perform the song for the 1999 MTV Video Music Awards. The video received awards for Best Direction, Breakthrough, and Best Choreography, which Jonze accepted, still in character. Jonze made a mockumentary about the experience called "Torrance Rises".
He has a speaking part along with Dave Eggers in the Beck song "The Horrible Fanfare/Landslide/Exoskeleton" from his 2006 album, "The Information". He appears in the "Exoskeleton" part.
Since 2007, he has been the creative director at VBS.tv, an online television network supplied by "Vice" and funded by MTV.
Spike Jonze was part of the Detour-Moleskine project in New York in 2007. The project invites authors to compile and illustrate Moleskine notebooks to provide an intimate insight into the artists' creative process.
In 2008 he co-produced a new video for the Chocolate Skateboards "Easy Steady", direct by Ty Evans and Federico Vitetta in Milan, featuring the song "Felicità" by Bugo.
Jonze directed "Where the Wild Things Are", which opened in the United States on October 16, 2009. It was arguably his most anticipated film to date, the product of an almost decade long collaboration with author Maurice Sendak. The film received generally favorable reviews, and appeared on many critics' end-of-the-year top ten lists.
In July 2009, Jonze acquired the rights to make a film adaptation of the Shane Jones novel "Light Boxes". However, Jonze, in an interview with Times Online, said that Ray Tintori was no longer a director for that project as expected. In an interview with "Interview Magazine" in June 2010, Jones said the film option had been dropped.
In 2010, he made a 28-minute short titled "Scenes from the Suburbs", inspired by the Arcade Fire album "The Suburbs". Scenes from his short were used in the music video to the album's title song, "The Suburbs". A dystopian vision of suburbia in the near-future, the short was co-written by Jonze, Win Butler, and Will Butler. Expanding on the themes of nostalgia, alienation, and childhood, the short premiered at the Berlin International Film Festival and saw its online premiere at MUBI on June 27, 2011.
Jonze is good friends with Björk and frequently works with her. He has directed three videos for her and she contributed the theme song for Jonze's "Being John Malkovich" film.
Jonze is working on another project with the Beastie Boys for the release of their Santigold collaboration, "Don't Play No Game That I Can't Win." In a similar fashion to Jonze's recent work with Arcade Fire, he has directed both "short and epic-length videos" to partner with the single.
In 2011, Jonze directed the music video for "Otis" the second single from the album "Watch The Throne" by Jay-Z and Kanye West. On November 3, 2013, Jonze directed the live music video for Arcade Fire's "Afterlife" and documented Lady Gaga's live performance of "Dope" with Chris Milk for the YouTube Music Awards.
Jonze's next theatrical project "Her" was released in late 2013. "Her" is a science fiction romance film starring Joaquin Phoenix, Amy Adams, Olivia Wilde, Rooney Mara, and Scarlett Johansson, and is Jonze's first feature-length original screenplay. The film follows a man (Phoenix) who develops a relationship with a seemingly intuitive and humanistic female voice, named "Samantha" (Johansson), produced by an advanced computer operating system. Jonze won the 2014 Golden Globe Award for Best Screenplay for "Her". Jonze has been nominated for three Academy Awards for "Her", as producer for Best Picture, writer for Best Original Screenplay, and lyric writer for Best Original Song. On March 2, 2014, Jonze won the Oscar for Best Original Screenplay, which marks his first win. In 2013, Jonze played a role in "The Wolf of Wall Street".
Personal life.
On June 26, 1999, Jonze married director Sofia Coppola, whom he had first met in 1992. On December 5, 2003, the couple filed for divorce, citing "irreconcilable differences." The character of John, a career-driven photographer (Giovanni Ribisi) in Coppola's "Lost in Translation" (2003), was rumored to be based on Jonze, though Coppola commented ”It’s not Spike, but there are elements of him there, elements of experiences".
Jonze began dating Michelle Williams in July 2008, after the death of Heath Ledger. They met on the set of "Synecdoche, New York", which Williams starred in and Jonze produced. Williams called the timing of their relationship "impossible", and ended it in September 2009.
In 2011, it was reported that he was dating Japanese actress Rinko Kikuchi, but they have since broken up.

</doc>
