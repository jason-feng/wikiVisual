<doc id="28246" url="http://en.wikipedia.org/wiki?curid=28246" title="Sufism">
Sufism

Sufism or Tasawwuf (Arabic: تصوف‎) is defined as the inner mystical dimension of Islam. Practitioners of Sufism ("Tasawuf") referred to as Sufis (ṣūfī) (; صُوفِيّ) often belong to different "ṭuruq" or "orders"—congregations formed around a grand master referred to as a "Mawla" who maintains a direct chain of teachers back to the Prophet Muhammad. These orders meet for spiritual sessions (majalis) in meeting places known as zawiyahs, khanqahs, or tekke. Sufis strive for "ihsan" (perfection of worship) as detailed in a hadith: "Ihsan is to worship Allah as if you see Him; if you can't see Him, surely He sees you." Jalaluddin Rumi stated: "The Sufi is hanging on to Muhammad, like Abu Bakr." Sufis consider themselves to be the original true proponents of this pure original form of Islam.
Sufi orders ("turuq") trace many of their original precepts from the Islamic prophet Muhammad either through his cousin and son-in-law Ali ibn Abi Talib or through his (companion) and friend Abu Bakr. Sufi orders are largely Sunni and follow one of the four schools of Sunni Islam and maintain a Sunni Aqidah or creed. Over the years various Sufi orders have been influenced by and adopted into various Shi'ite movements including Ismailism- which led to the Safaviyya order's conversion to Shi'ite Islam and the spread of Twelver Shi'ism throughout Persia. Some Sufi orders include Alevi, Bektashi, Burhaniya, Mevlevi, Ba 'Alawiyya, Chishti, Rifa'i, Khalwati, Naqshbandi, Nimatullahi, Oveyssi, Qadiria Boutshishia, Qadiriyyah, Qalandariyya, Sarwari Qadiri, Shadhiliyya and Suhrawardiyya.
Classical Sufi scholars have defined Sufism as "a science whose objective is the reparation of the heart and turning it away from all else but God". Alternatively, in the words of the Darqawi Sufi teacher Ahmad ibn Ajiba, "a science through which one can know how to travel into the presence of the Divine, purify one's inner self from filth, and beautify it with a variety of praiseworthy traits". Traditional Sufis, such as Bayazid Bastami, Jalaluddin Rumi, Haji Bektash Veli, Junaid Baghdadi, and Al-Ghazali, define Sufism as purely based upon the tenets of Islam and the teachings of Muhammad. Some Orientalists, however, have proposed a variety of diverse theories pertaining to the nature of Sufism, such as Sufism being influenced by Neoplatonism or was an Aryan reaction against Semites. Seyyed Hossein Nasr, states that the preceding theories are false according to the point of view of Sufism. According to William Chittick, "In a broad sense, Sufism can be described as the interiorization and intensification of Islamic faith and practice."
Muslims and mainstream scholars of Islam define Sufism as simply the name for the inner or esoteric dimension of Islam which is supported and complemented by outward or exoteric practices of Islam, such as Islamic law. In this view, "it is absolutely necessary to be a Muslim" to be a true Sufi, because Sufism's "methods are inoperative without" Muslim "affiliation". Orthodox views also maintain that Sufism is unique to Islam. In contrast, author Idries Shah states Sufi philosophy is universal in nature, its roots predating the rise of Islam and Christianity. Some schools of Sufism in Western countries allow non-Muslims to receive "instructions on following the Sufi path". Some Muslim opponents of Sufism also consider it outside the sphere of Islam.
Classical Sufis were characterised by their attachment to dhikr, (a practice of repeating the names of God, often performed after prayers) and asceticism. Sufism gained adherents among a number of Muslims as a reaction against the worldliness of the early Umayyad Caliphate (661–750 CE). Sufis have spanned several continents and cultures over a millennium, originally expressing their beliefs in Arabic, before spreading into Persian, Turkish, and Urdu among dozens of other languages.
Terminology.
Tasawwuf vs Sufism.
Historically, Muslims have used the word "Tasawwuf" to identify the practice of Sufis. According to traditional Sufis, Tasawwuf is an aspect of Islam similar to Islamic law (Shariah). According to them, just as Shariah should govern the external or outer world to rid the external world of evil and impurity, Tasawwuf should, therefore, govern the internal or spiritual world to rid the internal world of evil and impurity. Tasawwuf is considered by these people as inseparable from Islam and an integral part of Islamic belief and practice. According to Carl Ernst, the term "Sufism" came into being, not by Islamic texts or Sufis themselves but by British Orientalists who wanted to create an artificial divide between what they found attractive in Islamic civilization (i.e. Islamic Spirituality) and the negative stereotypes that were present in Britain about Islam. These British Orientalists, therefore, fabricated a divide that was previously non-existent. The term "Sufism" has, however, persisted especially in the Western world ever since.
Etymology.
Sufi.
Two origins of the word "sufi" have been suggested. Commonly, the lexical root of the word is traced to "ṣafā" "(صفاء)", which in Arabic means "purity". Another origin is "ṣūf" "(صُوف)", "wool" in Arabic, referring to the simple cloaks the early Muslim ascetics wore. The two were combined by the Sufi al-Rudhabari who said, "The Sufi is the one who wears wool on top of purity". Scholars, generally agree that "ṣūf" or "wool" is probably the root word of "Sufi."
Others have suggested that the word comes from the term "ahl aṣ-ṣuffah" ("the people of the bench"), who were a group of impoverished companions of Muhammad who held regular gatherings of dhikr. These men and women who sat at Al-Masjid al-Nabawi are considered by some to be the first Sufites in existence. Abd al-Karīm ibn Hawāzin Qushayri and Ibn Khaldun both rejected all possibilities other than "ṣūf" on linguistic grounds.
As an Islamic discipline.
Sufism is a mystical-ascetic aspect of Islam. It is not a sect, rather it is considered as the 
part of Islamic teaching that deals with the purification of inner self. By focusing on the more spiritual aspects of religion, Sufis strive to obtain direct experience of God by making use of "intuitive and emotional faculties" that one must be trained to use. Tasawwuf is regarded as a science of Islam that has always been an integral part of Orthodox Islam.In his Al-Risala al-safadiyya, Ibn Taymiyya describes the Sufis as those who belong to the path of the Sunna and represent it in their teachings and writings.
Ibn Taymiyya's Sufi inclinations and his reverence for Sufis like 'Abd al-Qadir Gilani can also be seen in his hundred-page commentary on Futuh al-ghayb, covering only five of the seventy-eight sermons of the book, but showing that he considered tasawwuf essential within the life of the Islamic community.
In his commentary, Ibn Taymiyya stresses that the primacy of the Shari`a forms the soundest tradition in tasawwuf, and to argue this point he lists over a dozen early masters, as well as more contemporary shaykhs like his fellow Hanbalis, al-Ansari al-Harawi and `Abd al-Qadir, and the latter's own shaykh, Hammad al-Dabbas:The upright among the followers of the Path—like the majority of the early shaykhs (shuyukh al-salaf) such as Fudayl ibn `Iyad, Ibrahim ibn Adham, Ma`ruf al-Karkhi, al-Sari al-Saqati, al-Junayd ibn Muhammad, and others of the early teachers, as well as Shaykh Abd al-Qadir, Shaykh Hammad, Shaykh Abu al-Bayan and others of the later masters—do not permit the followers of the Sufi path to depart from the divinely legislated command and prohibition
Imam Ghazali narrates in Al-Munqidh min-al-dalal:
The vicissitudes of life, family affairs and financial constraints engulfed my life and deprived me of the congenial solitude. The heavy odds confronted me and provided me with few moments for my pursuits. This state of affairs lasted for ten years but wherever I had some spare and congenial moments I resorted to my intrinsic proclivity. During these turbulent years, numerous astonishing and indescribable secrets of life were unveiled to me. I was convinced that the group of Aulia (holy mystics) is the only truthful group who follow the right path, display best conduct and surpass all sages in their wisdom and insight. They derive all their overt or covert behaviour from the illumining guidance of the holy Prophet, the only guidance worth quest and pursuit.
Aims and objectives.
While all Muslims believe that they are on the pathway to Allah and hope to become close to Allah in Paradise—after death and after the "Final Judgment"—Sufis also believe that it is possible to draw closer to Allah and to more fully embrace the Divine Presence in this life. The chief aim of all Sufis is to seek the pleasing of Allah by working to restore within themselves the primordial state of "fitra", described in the Qur'an. In this state nothing one does defies Allah, and all is undertaken with the single motivation of love of Allah.
To Sufis, Sufism involves the study and ritual purification of traits deemed reprehensible while adding praiseworthy traits. This is independent of whether or not this process of religious cleansing and purifying leads to esoteric knowledge of Allah. This can be conceived in terms of two basic types of law ("fiqh"), an outer law concerned with actions, and an inner law concerned with one's own actions and qualities. The outer law consists of rules pertaining to worship, transactions, marriage, judicial rulings, and criminal law—what is often referred to, broadly, as "qanun". The inner law of Sufism consists of rules about repentance from sin, the purging of contemptible qualities and evil traits of character, and adornment with virtues and good character.
Teachings.
A Sufi student enters the faith by seeking a teacher. Sufism emphasises a strong relationship between the seeker and the teacher. To be considered legitimate by the Sufi community, the teacher must have received the authorization to teach ("ijazah") from another "Master of the Way", in an unbroken succession ("silsilah") leading back to Muhammad. To the Sufi, it is the transmission of divine light from the teacher's heart to the heart of the student, rather than worldly knowledge, that allows the adept to progress. They further believe that the teacher should attempt to inerrantly follow the Divine Law.
According to Moojan Momen "one of the most important doctrines of Sufism is the concept of the "Perfect Man" ("al-Insan al-Kamil"). This doctrine states that there will always exist upon the earth a "Qutb" (Pole or Axis, of the Universe)—a man who is the perfect channel of grace from Allah to man and in a state of "wilaya" (sanctity, being under the protection of Allah). The concept of the Sufi Qutb is similar to that of the Shi'i Imam. However, this belief puts Sufism in "direct conflict" with Shi'ism, since both the Qutb (who for most Sufi orders is the head of the order) and the Imam fulfill the role of "the purveyor of spiritual guidance and of Allah's grace to mankind". The vow of obedience to the Shaykh or Qutb which is taken by Sufis is considered incompatible with devotion to the Imam".
As a further example, the prospective adherent of the Mevlevi Order would have been ordered to serve in the kitchens of a hospice for the poor for 1,001 days prior to being accepted for spiritual instruction, and a further 1,001 days in solitary retreat as a precondition of completing that instruction.
Some teachers, especially when addressing more general audiences, or mixed groups of Muslims and non-Muslims, make extensive use of parable, allegory, and metaphor. Although approaches to teaching vary among different Sufi orders, Sufism as a whole is primarily concerned with direct personal experience, and as such has sometimes been compared to other, non-Islamic forms of mysticism (e.g., as in the books of Hossein Nasr).
Many Sufi believe that to reach the highest levels of success in Sufism typically requires that the disciple live with and serve the teacher for a large period of time. An example is the folk story about Baha-ud-Din Naqshband Bukhari, who gave his name to the Naqshbandi Order. He is believed to have served his first teacher, Sayyid Muhammad Baba As-Samasi, for 20 years, until as-Samasi died. He is said to then have served several other teachers for lengthy periods of time. He is said to have helped the poorer members of the community for many years and after this concluded his teacher directed him to care for animals cleaning their wounds, and assisting them.
Devotion to Prophet Muhammad.
According to Carl W. Ernst, devotion to Prophet Muhammad is an exceptionally strong practice within Sufism. Sufis have historically revered Prophet Muhammad as the prime personality of spiritual greatness. The Sufi poet, Saadi Shirazi stated, "He who chooses a path contrary to that of the prophet [Muhammad], shall never reach the destination. O Saadi, do not think that one can treat that way of purity except in the wake of the chosen one [Muhammad]." Rumi attributes his self-control and abstinence from worldly desires as qualities attained by him through the guidance of Muhammad. Rumi states, ""I "sewed" my two eyes shut from [desires for] this world and the next - this I learned from Muhammad."" Ibn Arabi regards Muhammad as the greatest man ever and states "Muhammad's wisdom is uniqueness (fardiya) because he is the most perfect existent creature of this human species. For this reason, the command began with him and was sealed with him. He was a Prophet while Adam was between water and clay, and his elemental structure is the Seal of the Prophets." Fariduddin Attar claimed that he praised Muhammad in such a manner that was not done before, in his book the "Ilahi-nama". Fariduddin Attar stated "Muhammad is the exemplar to both worlds, the guide of the descendants of Adam. He is the sun of creation, the moon of the celestial spheres, the all-seeing eye...The seven heavens and the eight gardens of paradise were created for him, he is both the eye and the light in the light of our eyes." Sufis have historically stressed the importance of Prophet Muhammad's perfection and his ability to intercede. The persona of Prophet Muhammad has historically been and remains an integral and critical aspect of Sufi belief and practice. The Sufi, Bayazid Bastami is recorded to have been so devoted to the "Sunnah" of Prophet Muhammad, that he refused to eat a watermelon due to the fact that he could not establish that the Prophet Muhammad ever ate one.
In the 13th century, a Sufi poet from Egypt, Al-Busiri, wrote the "al-Kawākib ad-Durrīya fī Madḥ Khayr al-Barīya" (The Celestial Lights in Praise of the Best of Creation) commonly referred to as "Qaṣīdat al-Burda" (Poem of the Mantle), in which he extensively praised Prophet Muhammad. This poem is still widely recited and sung amongst Sufi groups all over the world.
History.
Origins.
Eminent Sufis such as Ali Hujwiri claim that the tradition first began with Ali ibn Abi Talib. Furthermore, Junayd of Baghdad regarded Ali as the Sheikh of the principals and practices of Sufism.
Practitioners of Sufism hold that in its early stages of development Sufism effectively referred to nothing more than the internalization of Islam. According to one perspective, it is directly from the Qur'an, constantly recited, meditated, and experienced, that Sufism proceeded, in its origin and its development. Others have held that Sufism is the strict emulation of the way of Muhammad, through which the heart's connection to the Divine is strengthened.
According to Marshall Hodgson, the Muslim conquests had brought large numbers of Christian monks and hermits, especially in Syria and Egypt, under the rule of Muslims. They retained a vigorous spiritual life for centuries after the conquests, and many of the especially pious Muslims who founded Sufism were influenced by their techniques and methods. However, others disagree with this view by asserting Sufism to be unique within the confines of the Islamic religion and contend that Sufism developed from devout followers of Islam, like Bayazid Bastami who in his utmost reverence to the Sunnah refused to eat a watermelon as he did not find any proof that the prophet Muhammad ever ate it. According to late Medieval mystic Jami, Abd-Allah ibn Muhammad ibn al-Hanafiyyah was the first person to be called a "Sufi".
Important contributions in writing are attributed to Uwais al-Qarni, Harrm bin Hian, Hasan Basri and Sayid ibn al-Mussib. Ruwaym, from the second generation of Sufis in Baghdad, was also an influential early figure, as was Junayd of Baghdad; a number of early practitioners of Sufism were disciples of one of the two.
Sufism had a long history already before the subsequent institutionalization of Sufi teachings into devotional orders ("tarîqât") in the early Middle Ages. The Naqshbandi order is a notable exception to general rule of orders tracing their spiritual lineage through Muhammad's grandsons, as it traces the origin of its teachings from Muhammad to the first Islamic Caliph, Abu Bakr.
Formalization of doctrine.
Towards the end of the first millennium CE, a number of manuals began to be written summarizing the doctrines of Sufism and describing some typical Sufi practices. Two of the most famous of these are now available in English translation: the "Kashf al-Mahjûb" of Hujwiri, and the "Risâla" of Qushayri.
Two of Imam Al Ghazali's greatest treatises, the "Revival of Religious Sciences" and the "Alchemy of Happiness", argued that Sufism originated from the Qur'an and thus was compatible with mainstream Islamic thought, and did not in any way contradict Islamic Law—being instead necessary to its complete fulfillment. This became the mainstream position among Islamic scholars for centuries, challenged only recently on the basis of selective use of a limited body of texts.[] Ongoing efforts by both traditionally trained Muslim scholars and Western academics are making Imam Al-Ghazali's works available in English translation for the first time, allowing English-speaking readers to judge for themselves the compatibility of Islamic Law and Sufi doctrine. Several sections of the "Revival of Religious Sciences" have been published in translation by the Islamic Texts Society. "The Alchemy of Happiness" has been published in a complete translation by Claud Field (ISBN 978-0935782288), and presents the argument of the much larger "Revival of Religious Sciences" in summary form.
Growth of influence.
The rise of Islamic civilization coincides strongly with the spread of Sufi philosophy in Islam. The spread of Sufism has been considered a definitive factor in the spread of Islam, and in the creation of integrally Islamic cultures, especially in Africa and Asia. The Senussi tribes of Libya and Sudan are one of the strongest adherents of Sufism. Sufi poets and philosophers such as Khoja Akhmet Yassawi, Rumi and Attar of Nishapur (c. 1145 – c. 1221) greatly enhanced the spread of Islamic culture in Anatolia, Central Asia, and South Asia. Sufism also played a role in creating and propagating the culture of the Ottoman world, and in resisting European imperialism in North Africa and South Asia.
Between the 13th and 16th centuries CE, Sufism produced a flourishing intellectual culture throughout the Islamic world, a "Golden Age" whose physical artifacts survive. In many places a pious foundation would endow a lodge (known variously as a "zaouia", "khanqah", or "tekke") in perpetuity ("waqf") to provide a gathering place for Sufi adepts, as well as lodging for itinerant seekers of knowledge. The same system of endowments could also pay for a complex of buildings, such as that surrounding the Süleymaniye Mosque in Istanbul, including a lodge for Sufi seekers, a hospice with kitchens where these seekers could serve the poor and/or complete a period of initiation, a library, and other structures. No important domain in the civilization of Islam remained unaffected by Sufism in this period.
Present.
Current Sufi orders include Azeemia, Alians, Bektashi Order, Mevlevi Order, Ba 'Alawiyya, Chishti, Jerrahi, Naqshbandi, Nimatullahi, Qadiriyyah, Qalandariyya, Sarwari Qadiri, Shadhiliyya, Suhrawardiyya, Ashrafia, Saifiah (Naqshbandiah) and Uwaisi (Oveyssi). The relationship of Sufi orders to modern societies is usually defined by their relationship to governments.
Turkey and Persia together have been a center for many Sufi lineages and orders. The Bektashi was closely affiliated with the Ottoman Janissary and is the heart of Turkey's large and mostly liberal Alevi population. It has been spread westwards to Cyprus, Greece, Albania, Bulgaria, Macedonia, Bosnia, Kosovo and more recently to the USA (via Albania). Most Sufi Orders have influences from pre-Islamic traditions such as Pythagoreanism, but the Turkic Sufi traditions (including Alians, Bektashi and Mevlevi) also have traces of the ancient Tengrism shamanism.
Sufism is popular in such African countries as Tunisia, Algeria, Morocco and Senegal, where it is seen as a mystical expression of Islam. Sufism is traditional in Morocco but has seen a growing revival with the renewal of Sufism around contemporary spiritual teachers such as Sidi Hamza al Qadiri al Boutshishi. Mbacke suggests that one reason Sufism has taken hold in Senegal is because it can accommodate local beliefs and customs, which tend toward the mystical.
The life of the Algerian Sufi master Emir Abd al-Qadir is instructive in this regard. Notable as well are the lives of Amadou Bamba and Hajj Umar Tall in sub-Saharan Africa, and Sheikh Mansur Ushurma and Imam Shamil in the Caucasus region. In the twentieth century some Muslims have called Sufism a superstitious religion that holds back Islamic achievement in the fields of science and technology.
A number of Westerners have embarked with varying degrees of success on the path of Sufism. One of the first to return to Europe as an official representative of a Sufi order, and with the specific purpose to spread Sufism in Western Europe, was the Swedish-born wandering Sufi Abd al-Hadi Aqhili (also known as Ivan Aguéli). René Guénon, the French scholar, became a Sufi in the early twentieth century and was known as Sheikh Abdul Wahid Yahya. His manifold writings defined the practice of Sufism as the essence of Islam but also pointed to the universality of its message. Other spiritualists, such as G. I. Gurdjieff, may or may not conform to the tenets of Sufism as understood by orthodox Muslims.
Other noteworthy Sufi teachers who have been active in the West in recent years include Bawa Muhaiyaddeen, Inayat Khan, Nazim Al-Haqqani, Javad Nurbakhsh, Bulent Rauf, Irina Tweedie, Idries Shah, Muzaffer Ozak, Nahid Angha and Ali Kianfar.
Currently active Sufi academics and publishers include Llewellyn Vaughan-Lee, Nuh Ha Mim Keller, Abdullah Nooruddeen Durkee, Waheed Ashraf, Omer Tarin and Abdal Hakim Murad.
Theoretical perspectives.
Traditional Islamic scholars have recognized two major branches within the practice of Sufism, and use this as one key to differentiating among the approaches of different masters and devotional lineages.
On the one hand there is the order from the signs to the Signifier (or from the arts to the Artisan). In this branch, the seeker begins by purifying the lower self of every corrupting influence that stands in the way of recognizing all of creation as the work of God, as God's active Self-disclosure or theophany. This is the way of Imam Al-Ghazali and of the majority of the Sufi orders.
On the other hand there is the order from the Signifier to His signs, from the Artisan to His works. In this branch the seeker experiences divine attraction ("jadhba"), and is able to enter the order with a glimpse of its endpoint, of direct apprehension of the Divine Presence towards which all spiritual striving is directed. This does not replace the striving to purify the heart, as in the other branch; it simply stems from a different point of entry into the path. This is the way primarily of the masters of the Naqshbandi and Shadhili orders.
Contemporary scholars may also recognize a third branch, attributed to the late Ottoman scholar Said Nursi and explicated in his vast Qur'an commentary called the Risale-i Nur. This approach entails strict adherence to the way of Muhammad, in the understanding that this wont, or "sunnah", proposes a complete devotional spirituality adequate to those without access to a master of the Sufi way.
Contributions to other domains of scholarship.
Sufism has contributed significantly to the elaboration of theoretical perspectives in many domains of intellectual endeavor. For instance, the doctrine of "subtle centers" or centers of subtle cognition (known as "Lataif-e-sitta") addresses the matter of the awakening of spiritual intuition. In general, these subtle centers or "latâ'if" are thought of as faculties that are to be purified sequentially in order to bring the seeker's wayfaring to completion. A concise and useful summary of this system from a living exponent of this tradition has been published by Muhammad Emin Er.
Sufi psychology has influenced many areas of thinking both within and outside of Islam, drawing primarily upon three concepts. Ja'far al-Sadiq (both an imam in the Shia tradition and a respected scholar and link in chains of Sufi transmission in all Islamic sects) held that human beings are dominated by a lower self called the "nafs", a faculty of spiritual intuition called the "qalb" or spiritual heart, and a spirit or soul called "ruh". These interact in various ways, producing the spiritual types of the tyrant (dominated by "nafs"), the person of faith and moderation (dominated by the spiritual heart), and the person lost in love for God (dominated by the "ruh").
Of note with regard to the spread of Sufi psychology in the West is Robert Frager, a Sufi teacher authorized in the Khalwati Jerrahi order. Frager was a trained psychologist, born in the United States, who converted to Islam in the course of his practice of Sufism and wrote extensively on Sufism and psychology.
Sufi cosmology and Sufi metaphysics are also noteworthy areas of intellectual accomplishment.
Devotional practices.
The devotional practices of Sufis vary widely. This is because an acknowledged and authorized master of the Sufi path is in effect a physician of the heart, able to diagnose the seeker's impediments to knowledge and pure intention in serving God, and to prescribe to the seeker a course of treatment appropriate to his or her maladies. The consensus among Sufi scholars is that the seeker cannot self-diagnose, and that it can be extremely harmful to undertake any of these practices alone and without formal authorization.
Prerequisites to practice include rigorous adherence to Islamic norms (ritual prayer in its five prescribed times each day, the fast of Ramadan, and so forth). Additionally, the seeker ought to be firmly grounded in supererogatory practices known from the life of Muhammad (such as the "sunna prayers"). This is in accordance with the words, attributed to God, of the following, a famous Hadith Qudsi:
My servant draws near to Me through nothing I love more than that which I have made obligatory for him. My servant never ceases drawing near to Me through supererogatory works until I love him. Then, when I love him, I am his hearing through which he hears, his sight through which he sees, his hand through which he grasps, and his foot through which he walks.
It is also necessary for the seeker to have a correct creed ("Aqidah"), and to embrace with certainty its tenets. The seeker must also, of necessity, turn away from sins, love of this world, the love of company and renown, obedience to satanic impulse, and the promptings of the lower self. (The way in which this purification of the heart is achieved is outlined in certain books, but must be prescribed in detail by a Sufi master.) The seeker must also be trained to prevent the corruption of those good deeds which have accrued to his or her credit by overcoming the traps of ostentation, pride, arrogance, envy, and long hopes (meaning the hope for a long life allowing us to mend our ways later, rather than immediately, here and now).
Sufi practices, while attractive to some, are not a "means" for gaining knowledge. The traditional scholars of Sufism hold it as absolutely axiomatic that knowledge of God is not a psychological state generated through breath control. Thus, practice of "techniques" is not the cause, but instead the "occasion" for such knowledge to be obtained (if at all), given proper prerequisites and proper guidance by a master of the way. Furthermore, the emphasis on practices may obscure a far more important fact: The seeker is, in a sense, to become a broken person, stripped of all habits through the practice of (in the words of Imam Al-Ghazali) solitude, silence, sleeplessness, and hunger.
Magic may have also been a part of some Sufi practices, notably in India. The practice of magic intensified during the declining years of Sufism in India when the Sufi orders grew steadily in wealth and in political influence while their spirituality gradually declined and they concentrated on saint veneration, miracle working, magic and superstition.
Dhikr.
Dhikr is the remembrance of Allah commanded in the Qur'an for all Muslims through a specific devotional act, such as the repetition of divine names, supplications and aphorisms from hadith literature and the Qur'an. More generally, dhikr takes a wide range and various layers of meaning. This includes dhikr as any activity in which the Muslim maintains awareness of Allah. To engage in dhikr is to practice consciousness of the Divine Presence and love, or "to seek a state of godwariness". The Qur'an refers to Muhammad as the very embodiment of dhikr of Allah (65:10–11). Some types of dhikr are prescribed for all Muslims and do not require Sufi initiation or the prescription of a Sufi master because they are deemed to be good for every seeker under every circumstance.
Some Sufi orders engage in ritualized dhikr ceremonies, or sema. Sema includes various forms of worship such as: recitation, singing (the most well known being the Qawwali music of the Indian subcontinent), instrumental music, dance (most famously the Sufi whirling of the Mevlevi order), incense, meditation, ecstasy, and trance.
Some Sufi orders stress and place extensive reliance upon Dhikr. This practice of Dhikr is called Dhikr-e-Qulb (invocation of Allah within the heartbeats). The basic idea in this practice is to visualize the Allah as having been written on the disciple's heart.
Muraqaba.
The practice of "muraqaba" can be likened to the practices of meditation attested in many faith communities. The word "muraqaba" is derived from the same root ("r-q-b") occurring as one of the 99 Names of God in the Qur'an, al-Raqîb, meaning "the Vigilant" and attested in verse 4:1 of the Qur'an. Through "muraqaba", a person watches over or takes care of the spiritual heart, acquires knowledge about it, and becomes attuned to the Divine Presence, which is ever vigilant.
While variation exists, one description of the practice within a Naqshbandi lineage reads as follows:
He is to collect all of his bodily senses in concentration, and to cut himself off from all preoccupation and notions that inflict themselves upon the heart. And thus he is to turn his full consciousness towards God Most High while saying three times: ""Ilahî anta maqsûdî wa-ridâka matlûbî"—my God, you are my Goal and Your good pleasure is what I seek". Then he brings to his heart the Name of the Essence—Allâh—and as it courses through his heart he remains attentive to its meaning, which is "Essence without likeness". The seeker remains aware that He is Present, Watchful, Encompassing of all, thereby exemplifying the meaning of his saying (may God bless him and grant him peace): "Worship God as though you see Him, for if you do not see Him, He sees you". And likewise the prophetic tradition: "The most favored level of faith is to know that God is witness over you, wherever you may be".
Visitation.
In popular Sufism (i.e., devotional practices that have achieved currency in world cultures through Sufi influence), one common practice is to visit or make pilgrimages to the tombs of saints, great scholars, and righteous people. This is a particularly common practice in South Asia, where famous tombs include those of Khoja Afāq, near Kashgar, in China; Lal Shahbaz Qalander, in Sindh,Ali Hajwari in Lahore Bawaldin Zikrya in Multan Pakistan; Moinuddin Chishti in Ajmer, India; Nizamuddin Auliya in Delhi, India, and Shah Jalal in Sylhet, Bangladesh. Likewise, in Fez, Morocco, a popular destination for such pious visitation is the Zaouia Moulay Idriss II and the yearly visitation to see the current Sheikh of the Qadiri Boutchichi Tariqah, Sheikh Sidi Hamza al Qadiri al Boutchichi to celebrate the Mawlid (which is usually televised on Moroccan National television). The purpose of such visitations is usually two-fold, first and foremost the aim is to receive spiritual guidance and blessings from the Saint who rests in the shrine, which helps the Seeker in his or her own path towards enlightenment. Secondly, the Saint is also approached for intercession in prayers, be it in worldly matters or religious.
Persecution.
Sufis and Sufism has been subject to destruction of Sufi shrines and mosques, suppression of orders, and discrimination against adherents in a number of Muslim countries where most Sufis live. The Turkish Republican state banned all the different Sufi orders and closed their institutions in 1925 after Sufis opposed the new secular order. The Iranian Islamic Republic has harassed Shia Sufi, reportedly for their lack of support for the government doctrine of "" (i.e., that the supreme Shiite jurist should be the nation's political leader). In most other Muslim countries, attacks on Sufis and especially their shrines has come from some Muslims from the more puritanical schools of thought who believe Sufi practices such as celebration of the birthdays of Sufi saints, and Dhikr ("remembrance" of God) ceremonies are Bid‘ah or impure innovation, and polytheistic (Shirk).
History.
During the Safavid era of Iran, "both the wandering dervishes of 'low' Sufism" and "the philosopher-ulama of 'high' Sufism came under relentless pressure" from power cleric Muhammad Baqir Majlisi (d1110/1699). Majlisi—"one of the most powerful and influential" Twelver Shi'a ulama "of all time"—was famous for (among other things), suppression of Sufism, which he and his followers believed paid insufficient attention to Shariah law. Prior to Majlisi's rise, Shiism and Sufism had been "closely linked".
In 1843, the Senussi Sufi were forced to flee Mecca and Medina and head to Sudan and Libya.
According to a 2005 article in "The Guardian":
Before the first world war there were almost 100,000 disciples of the Mevlevi order throughout the Ottoman empire. But in 1925, as part of his desire to create a modern, western-orientated, secular state, Atatürk banned all the different Sufi orders and closed their tekkes. Pious foundations were suspended and their endowments expropriated; Sufi hospices were closed and their contents seized; all religious titles were abolished and dervish clothes outlawed. [...] In 1937, Atatürk went even further, prohibiting by law any form of traditional music, especially the playing of the ney, the Sufis' reed flute.
Current attacks.
In recent years, Sufi shrines, and sometimes Sufi mosques, have been damaged or destroyed in many parts of the Muslim world. Some Sufi adherents have been killed as well. Ali Gomaa, a Sufi scholar and Grand Mufti of Al Azhar, has criticized the destruction of shrines and public property as unacceptable.
Pakistan.
Since March 2005, 209 people have been killed and 560 injured in 29 different terrorist attacks targeting shrines devoted to Sufi saints in Pakistan, according to data compiled by the Center for Islamic Research Collaboration and Learning (CIRCLe). At least as of 2010, the attacks have increased each year. The attacks are generally attributed to banned militant organizations of Deobandi or Ahl-e-Hadith (Salafi) backgrounds. (Primarily Deobandi background according to another source—author John R. Schmidt). Deobandi and Barelvi being the "two major sub-sects" of Sunni Muslims in South Asia that have clashed—sometimes violently—since the late 1970s in Pakistan. Although Barelvi are fully described as Sunni Sufis, whether the destruction and death is a result of Deobandi's banned militant organizations persecution of Sufis(Barelvus).
In 2005, the militant organizations began attacking "symbols" of the Barelvi community such as mosques, prominent religious leaders, and shrines.
Timeline.
Pakistani faith healers are known as pirs, a term that applies to the descendants of Sufi Muslim saints. Under Sufism, those descendants are thought to serve as conduits to God. The popularity of pirs as a viable healthcare alternative stems from the fact that, in much of rural Pakistan, clinics don't exist or are dismissed as unreliable.
Kashmir, India.
In this predominately Muslim, traditionally Sufi region, some six places of worship have been either completely or partially burnt in "mysterious fires" in several months leading up to November 2012. The most prominent victim of damage was the Dastageer Sahib Sufi shrine in Srinagar which burned in June 2012, injuring 20. While investigators have so far found no sign of arson, according to journalist Amir Rana the fires have occurred within the context of a surging Salafi movement which preaches that "Kashmiri tradition of venerating the tombs and relics of saints is outside the pale of Islam".
mourners outside the burning shrine cursed the Salafis for creating an atmosphere of hate, [while] some Salafis began posting incendiary messages on Facebook, terming the destruction of the shrine a "divine act of God".
Somalia.
Under the Al-Shabab rule in Somali, Sufi ceremonies were banned and shrines . As the power of Al-Shabab has waned, however, Sufi ceremonies are said to have "re-emerged".
Mali.
In the ancient city of Timbuktu, sometimes called "the city of 333 saints", UNESCO reports that as many as half of the city's shrines "have been destroyed in a display of fanaticism", as of July 2012. A spokesman for Ansar Dine has stated that "the destruction is a divine order", and that the group had plans to destroy every single Sufi shrine in the city, "without exception". In Gao and Kidal, as well as Timbuktu, Salafi Islamists have destroyed musical instruments and driven musicians (music is not Haraam under Sufi Islam) into "economic exile" away from Mali.
International Criminal Court Chief Prosecutor Fatou Bensouda described the Islamists' actions as a "war crime".
Egypt.
A May 2010 ban by the ministry of awqaf (religious endowments) of centuries old Sufi dhikr gatherings (devoted to the remembrance of God, and including dancing and religious songs) has been described as a "another victory for extreme Salafi thinking at the expense of Egypt's moderate Sufism". Clashes followed at Cairo's Al-Hussein Mosque and al-Sayyida Zeinab mosques between members of Sufi orders and security forces who forced them to evacuate the two shrines. In 2009, the moulid of al-Sayyida Zeinab, Muhammad's granddaughter, was banned ostensibly over concern over the spread of swine flu but also at the urging of Salafis.
According to Gaber Qassem, deputy of the Sufi Orders, approximately 14 shrines have been violated in Egypt since the January 2011 revolution. According to Sheikh Tarek El-Rifai, head of the Rifai Sufi Order, a number of Salafis have prevented Sufi prayers in Al-Haram. Sheikh Rifai said that the order's lawyer has filed a report at the Al-Haram police station to that effect. In early April 2011, a Sufi march from Al-Azhar Mosque to Al-Hussein Mosque was followed by a massive protest before Al-Hussein Mosque, "expressing outrage at the destruction" of Sufi shrines. The Islamic Research Centre of Egypt, led by Grand Imam of Al-Azhar Ahmed El-Tayeb, has also renounced the attacks on the shrines. According to the Muslim Brotherhood website ikhwanweb.com, in 2011 "a memorandum was submitted to the Armed Forces" citing 20 "encroachments" on Sufi shrines.
Libya.
Following the overthrow of Muammar Gaddafi, several Sufi religious sites in Libya were deliberately destroyed or damaged. In the weeks leading up to September 2012, "armed groups motivated by their religious views" attacked Sufi religious sites across the country, "destroying several mosques and tombs of Sufi religious leaders and scholars". Perpetrators were described as "groups that have a strict Islamic ideology where they believe that graves and shrines must be desecrated." Libyan Interior Minister Fawzi Abdel A'al, was quoted as saying, "If all shrines in Libya are destroyed so we can avoid the death of one person [in clashes with security forces], then that is a price we are ready to pay."
In September 2012, three people were killed in clashes between residents of Rajma (50 km south-east of Benghazi) and "Salafist Islamists" trying to destroy a Sufi shrine in Rajma, the Sidi al-Lafi mausoleum. In August 2012 the United Nations cultural agency Unesco urged Libyan authorities to protect Sufi mosques and shrines from attacks by Islamic hardliners "who consider the traditional mystical school of Islam heretical". The attacked have "wrecked mosques in at least three cities and desecrated many graves of revered Sufi scholars".
Tunisia.
In an article on the rise of Salafism in Tunisia, the media site Al-Monitor reported that 39 Sufi shrines were destroyed or desecrated in Tunisia, from the 2011 revolution to January 2013.
Russia, Dagestan.
Said Atsayev—also known as Sheikh Said Afandi al-Chirkavi—a prominent 74-year-old Sufi Muslim spiritual leader in Dagestan Russia, was killed by a suicide bombing August 28, 2012 along with six of his followers. His murder follows "similar religiously-motivated killings" in Dagestan and other regions of ex-Soviet Central Asia, targeting religious leaders—not necessarily Sufi—who are hostile to violent jihad. Afandi had survived previous attempts on his life and was reportedly in the process of negotiating a peace agreement between the Sufis and Salafis.
Iran.
The book "Mystic Regimes. Sufism and the State in Iran, from the late Qajar era to the Islamic Republic" by Matthijs van den Bos discusses the status of Sufism in Iran in the 19th and 20th century.
According to Seyed Mostafa Azmayesh, an expert on Sufism and the representative of the Ni'matullāhī order outside Iran, a campaign against the Sufis in Iran (or at least Shia Sufis) began in 2005 when several books were published arguing that because Sufis follow their own spiritual leaders do not believe in the Islamic state's principle of "" (i.e., that the supreme Shiite jurist should be the nation's political leader), Sufis should be treated as second-class citizens. They should not be allowed to have government jobs, and if they already have them, should be identified and fired.
Since 2005 the Ni'matullāhī order—Iran's largest Sufi order—have come under increasing state pressure. Three of their houses of worship have been demolished. Officials accused the Sufis of not having building permits and of narcotics possession—charges the Sufis reject.
The government of Iran is considering an outright ban on Sufism, according to the 2009 Annual Report of the United States Commission on International Religious Freedom.
It also reports:
In February 2009, at least 40 Sufis in Isfahan were arrested after protesting the destruction of a Sufi place of worship; all were released within days.
In January, Jamshid Lak, a Gonabadi Dervish from the Nematollahi Sufi order was flogged 74 times after being convicted in 2006 of slander following his public allegation of ill-treatment by a Ministry of Intelligence official.
In late December 2008, after the closure of a Sufi place of worship, authorities arrested without charge at least six members of the Gonabadi Dervishes on Kish Island and confiscated their books and computer equipment; their status is unknown.
In November 2008, Amir Ali Mohammad Labaf was sentenced to a five-year prison term, 74 lashes, and internal exile to the southeastern town of Babak for spreading lies, based on his membership in the Nematollahi Gonabadi Sufi order.
In October, at least seven Sufi Muslims in Isfahan, and five others in Karaj, were arrested because of their affiliation with the Nematollahi Gonabadi Sufi order; they remain in detention.
In November 2007, clashes in the western city of Borujerd between security forces and followers of a mystic Sufi order resulted in dozens of injuries and the arrests of approximately 180 Sufi Muslims. The clashes occurred after authorities began bulldozing a Sufi monastery. It is unclear how many remain in detention or if any charges have been brought against those arrested. During the past year, there were numerous reports of Shi'a clerics and prayer leaders, particularly in Qom, denouncing Sufism and the activities of Sufi Muslims in the country in both sermons and public statements.
In 2009 the mausoleum of the 19th century Sufi poet Nasir Ali and an adjoining Sufi prayer house were bulldozed.
Not all Sufis in Iran have been subject to government pressure. Sunni dervish orders—such as the Qhaderi dervishes—in the Sunni-populated parts of the country are thought by some to be seen as allies of the government against Al-Qaeda.
Islam and Sufism.
Critique of Sufism's anti-materialistic aspects.
Certain aspects of Sufi philosophy are controversial and often debated, chief among them is the anti-materialistic strain within its ethos. Gamal Marzouq, Professor of Islamic Philosophy in Ain-Shams University, in his paper titled "The effect of Christianity on the first emergence of Islamic Sufism", has highlighted the monastic and anti-materialist trends within Sufism, calling attention to their "abandoning materialism and living only for praying, something similar to monasticism".
Conversely, the Quran calls out monasticism as a human invention not prescribed by God in the verse 57:27: "monasticism, which they innovated; We did not prescribe it for them...". Furthermore, there is much emphasis on physical laws of the universe within the Quran, urging believers to study and understand the "signs" of God in the physical world (e.g. verse 2:164), which precludes the possibility of avoiding or shunning the material world. Ibrahim B. Syed has called attention to the fact that the only definition of the word "alim" in the Quran, a word commonly understood to mean "religious leader" today, is actually referring to scientists, indicating the high importance afforded by the Quran to the material world and the act of engaging with it, so as to understand God's universe. There are also the active aspects of the Quran's teachings which urge believers to seek to improve the human condition and work to establish the laws of God within human society (verse 22:41), a mission that does not fit well with the hermetic and monastic tendencies within Sufism.
Sufism and Islamic law.
Scholars and adherents of Sufism sometimes describe Sufism in terms of a threefold approach to God as explained by a tradition ("hadîth") attributed to Muhammad, ""The Canon is my word, the order is my deed, and the truth is my interior state"." Sufis believe the "sharia" (exoteric "canon"), "tariqa" (esoteric "order") and "haqiqa" ("truth") are mutually interdependent.
The "tariqa", the 'path' on which the mystics walk, has been defined as 'the path which comes out of the "sharia", for the main road is called "branch", the path, "tariq".'
No mystical experience can be realized if the binding injunctions of the sharia are not followed faithfully first. The tariqa however, is narrower and more difficult to walk.
It leads the adept, called "salik" or "wayfarer", in his "sulûk" or "road" through different stations ("maqâmât") until he reaches his goal, the perfect "tawhîd", the existential confession that God is One. Shaykh al-Akbar Muhiuddeen Ibn Arabi mentions, "When we see someone in this Community who claims to be able to guide others to God, but is remiss in but one rule of the Sacred Law—even if he manifests miracles that stagger the mind—asserting that his shortcoming is a special dispensation for him, we do not even turn to look at him, for such a person is not a sheikh, nor is he speaking the truth, for no one is entrusted with the secrets of God Most High save one in whom the ordinances of the Sacred Law are preserved. (Jami' karamat al-awliya')".
The Amman Message, a detailed statement issued by 200 leading Islamic scholars in 2005 in Amman, and adopted by the Islamic world's political and temporal leaderships at the Organisation of the Islamic Conference summit at Mecca in December 2005, and by six other international Islamic scholarly assemblies including the International Islamic Fiqh Academy of Jeddah, in July 2006, specifically recognized the validity of Sufism as a part of Islam—however the definition of Sufism can vary drastically between different traditions (what may be intended is simple tazkiah as opposed to the various manifestations of Sufism around the Islamic world).
Traditional Islamic thought and Sufism.
The literature of Sufism emphasizes highly subjective matters that resist outside observation, such as the subtle states of the heart. Often these resist direct reference or description, with the consequence that the authors of various Sufi treatises took recourse to allegorical language. For instance, much Sufi poetry refers to intoxication, which Islam expressly forbids. This usage of indirect language and the existence of interpretations by people who had no training in Islam or Sufism led to doubts being cast over the validity of Sufism as a part of Islam. Also, some groups emerged that considered themselves above the Sharia and discussed Sufism as a method of bypassing the rules of Islam in order to attain salvation directly. This was disapproved of by traditional scholars.
For these and other reasons, the relationship between traditional Islamic scholars and Sufism is complex and a range of scholarly opinion on Sufism in Islam has been the norm. Some scholars, such as Al-Ghazali, helped its propagation while other scholars opposed it. W. Chittick explains the position of Sufism and Sufis this way:
In short, Muslim scholars who focused their energies on understanding the normative guidelines for the body came to be known as jurists, and those who held that the most important task was to train the mind in achieving correct understanding came to be divided into three main schools of thought: theology, philosophy, and Sufism. This leaves us with the third domain of human existence, the spirit. Most Muslims who devoted their major efforts to developing the spiritual dimensions of the human person came to be known as Sufis.
Traditional and Neo-Sufi groups.
The traditional Sufi orders, which are in majority, emphasize the role of Sufism as a spiritual discipline within Islam. Therefore, the Sharia (traditional Islamic law) and the Sunnah are seen as crucial for any Sufi aspirant. One proof traditional orders assert is that almost all the famous Sufi masters of the past Caliphates were experts in Sharia and were renowned as people with great Iman (faith) and excellent practice. Many were also Qadis (Sharia law judges) in courts. They held that Sufism was never distinct from Islam and to fully comprehend and practice Sufism one must be an observant Muslim.
"Neo-Sufism," "pseudo-Sufism," and "universal Sufism" are terms used to denote forms of Sufism that do not require adherence to Shariah, or a Muslim faith. The terms are not always accepted by those it is applied to. The Universal Sufism movement was founded by Inayat Khan, teaches the essential unity of all faiths, and accepts members of all creeds. Sufism Reoriented is an offshoot of Khan's Western Sufism charted by the syncretistic teacher Meher Baba. The Golden Sufi Center exists in England, Switzerland and the United States. It was founded by Llewellyn Vaughan-Lee to continue the work of his teacher Irina Tweedie, herself a practitioner of both Hinduism and neo-Sufism. The Afghan-Scottish teacher Idries Shah has been described as a neo-Sufi by the Gurdjieffian James Moore. Other Western Sufi organisations include the Sufi Foundation of America and the International Association of Sufism.
Western Neo-Sufi practices may differ from traditional forms, for instance having mixed-gender meetings and less emphasis on the Qur'an.
Prominent Sufis.
Abul Hasan al-Shadhili.
Abul Hasan al-Shadhili (died 1258 CE), the founder of the Shadhiliyya Sufi order, introduced "dhikr jahri" (The method of remembering Allah through loud means). Sufi orders generally preach to deny oneself and to destroy the ego-self "(nafs)" and its worldly desires. This is sometimes characterized as the "Order of Patience-Tariqus Sabr". In contrast, Imam Shadhili taught that his followers need not abstain from what Islam has not forbidden, but to be grateful for what God has bestowed upon them. This notion, known as the "Order of Gratitude-Tariqush Shukr", was espoused by Imam Shadhili. Imam Shadhili gave eighteen valuable "hizbs" (litanies) to his followers out of which the notable "Hizbul Bahr" is recited worldwide even today.
Abd al-Qadir al-Jilani.
Al-Sayyid Muhiyudin Abu Muhammad Abdal Qadir Al-Jilani Al-Hasani Wal-Hussaini (born 11 Rabi al-Thani), 470 Hijri, in the town of Na'if, district of Gilan, Ilam Province Or Amol of Tabarestan, Persia, died 8 Rabi al-Awwal 561 AH, in Baghdad,[1] (1077–1166 CE), was a Persian Hanbali jurist and Sufi based in Baghdad. Qadiriyya was his patronym. Al Gilani spent his early life in Na'if, the town of his birth. There, he pursued the study of Hanbali law. Abu Ali al-Mukharrimi gave Al Gilani lessons in Fiqh. He was given lessons about Hadith by Abu Bakr ibn Muzaffar. He was given lessons about Tafsir by Abu Muhammad Ja'far, a commentator. 
In Tasawwuf, his spiritual instructor was Abu'l-Khair Hammad ibn Muslim al-Dabbas. After completing his education, Gilani left Baghdad. He spent twenty-five years as a reclusive wanderer in the desert regions of Iraq. In 1127, Al Gilani returned to Baghdad and began to preach to the public. He joined the teaching staff of the school belonging to his own teacher, al-Mukharrimii,and was popular with students. In the morning he taught hadith and tafsir, and in the afternoon he held discourse on the science of the heart and the virtues of the Qur'an. He was said to have been a convincing preacher and converted numerous Jews and Christians to Islam. His strength came in the reconciling of the mystical nature of the Sufi and strict nature of the Qur'an. He felt it important to control egotism and worldliness in submission to God.
Bayazid Bastami.
Bayazid Bastami is a very well recognized and influential Sufi personality. Bastami was born in 804 in Bastam. Bayazid is regarded for his devout commitment to the Sunnah and his dedication to fundamental Islamic principals and practices.
Ibn Arabi.
Muhyiddin Muhammad b. 'Ali Ibn 'Arabi (or Ibn al-'Arabi) AH 561- AH 638 (July 28, 1165 – November 10, 1240) is considered to be one of the most important Sufi masters, although he never founded any order ("tariqa"). His writings, especially al-Futuhat al-Makkiyya and Fusus al-hikam, have been studied within all the Sufi orders as the clearest expression of "tawhid" (Divine Unity), though because of their recondite nature they were often only given to initiates. Later those who followed his teaching became known as the school of "wahdat al-wujud" (the Oneness of Being). He himself considered his writings to have been divinely inspired. As he expressed the Way to one of his close disciples, his legacy is that 'you should never ever abandon your servanthood ("'ubudiyya"), and that there may never be in your soul a longing for any existing thing'.
Junayd Baghdadi.
Junayd Baghdadi (830–910 CE) was one of the great early Sufis, and is a central figure in the golden chain of many Sufi orders. He laid the groundwork for sober mysticism in contrast to that of God-intoxicated Sufis like al-Hallaj, Bayazid Bastami and Abusaeid Abolkheir. During the trial of al-Hallaj, his former disciple, the Caliph of the time demanded his fatwa. In response, he issued this fatwa: "From the outward appearance he is to die and we judge according to the outward appearance and God knows better". He is referred to by Sufis as Sayyid-ut Taifa—i.e., the leader of the group. He lived and died in the city of Baghdad.
Moinuddin Chishti.
He was born in 1141 and died in 1236 CE. Also known as Gharīb Nawāz "Benefactor of the Poor", he is the most famous Sufi saint of the Chishti Order of the Indian Subcontinent. Moinuddin Chishti introduced and established the order in the subcontinent. The initial spiritual chain or silsila of the Chishti order in India, comprising Moinuddin Chishti, Bakhtiyar Kaki, Baba Farid, Nizamuddin Auliya (each successive person being the disciple of the previous one), constitutes the great Sufi saints of Indian history.
Moinuddin Chishtī turned towards India, reputedly after a dream in which Prophet Muhammad blessed him to do so. After a brief stay at Lahore, he reached Ajmer along with Sultan Shahāb-ud-Din Muhammad Ghori, and settled down there.[4] In Ajmer, he attracted a substantial following, acquiring a great deal of respect amongst the residents of the city. Moinuddin Chishtī practiced the Sufi Sulh-e-Kul (peace to all) concept to promote understanding between Muslims and non-Muslims
Mansur al-Hallaj.
Mansur al-Hallaj (died 922 CE) is renowned for his claim "Ana-l-Haqq" (I am The Truth). His refusal to recant this utterance, which was regarded as apostasy, led to a long trial. He was imprisoned for 11 years in a Baghdad prison, before being tortured and publicly dismembered on March 26, 922. He is still revered by Sufis for his willingness to embrace torture and death rather than recant. It is said that during his prayers, he would say "O Lord! You are the guide of those who are passing through the Valley of Bewilderment. If I am a heretic, enlarge my heresy".
Sufi Orders.
The term "Tariqa" is used for a school or order of Sufism, or especially for the mystical teaching and spiritual practices of such an order with the aim of seeking ḥaqīqah (ultimate truth).A tariqa has a murshid (guide) who plays the role of leader or spiritual director. The members or followers of a tariqa are known as murīdīn (singular murīd), meaning "desirous", viz. "desiring the knowledge of knowing God and loving God".
Bektashi.
The Bektashi Order was founded in the 13th century by the Islamic saint Haji Bektash Veli, and greatly influenced during its fomulative period by the Hurufi Ali al-'Ala in the 15th century and reorganized by Balım Sultan in the 16th century.
Chishti.
The Chishti Order (Persian: چشتیہ‎) was founded by (Khawaja) Abu Ishaq Shami ("the Syrian"; died 941) who brought Sufism to the town of Chisht, some 95 miles east of Herat in present-day Afghanistan. Before returning to the Levant, Shami initiated, trained and deputized the son of the local Emir (Khwaja) Abu Ahmad Abdal (died 966). Under the leadership of Abu Ahmad’s descendants, the "Chishtiyya" as they are also known, flourished as a regional mystical order.
Kubrawiya.
The Kubrawiya order is a Sufi order ("tariqa") named after its 13th-century founder Najmuddin Kubra. The Kubrawiya Sufi order was founded in the 13th century by Najmuddin Kubra in Bukhara in modern Uzbekistan. The Mongols had captured Bukhara in 1221, they committed genocide and killed nearly the whole population. Sheikh Nadjm ed-Din Kubra was among those killed by the Mongols.
Mawlawiyya.
 
The Mevlevi Order is better known in the West as the "whirling dervishes".
Muridiyya.
Mouride is a large Islamic Sufi order most prominent in Senegal and The Gambia, with headquarters in the holy city of Touba, Senegal.
Naqshbandi.
The Naqshbandi order is one of the major Sufi orders of Islam. Formed in 1380, the order is considered by some to be a "sober" order known for its silent dhikr (remembrance of God) rather than the vocalized forms of dhikr common in other orders. The word "Naqshbandi" (نقشبندی) is Persian, taken from the name of the founder of the order, Baha-ud-Din Naqshband Bukhari. Some have said that the translation means "related to the image-maker", some also consider it to mean "Pattern Maker" rather than "image maker", and interpret "Naqshbandi" to mean "Reformer of Patterns", and others consider it to mean "Way of the Chain" or "Golden Chain".
As mentioned below, the conception of Naqshbandi may require more elaboration and clarity as the explanation to this effect creating ambiguity and complicity with in it.
The meanings of "Naqshbandi" is to follow the pattern of head of the former. In other words, "Naqshbandi" may be taken as "followup or like a flow chart" of practices exercised by the head of this school of thought.
Nimatullahi.
The Ni'matullāhī order is the most widespread Sufi order of Persia today. It was founded by Shah Ni'matullah Wali (d. 1367), established and transformed from his inheritance of the Ma'rufiyyah circle. There are several suborders in existence today, the most known and influential in the West following the lineage of Dr. Javad Nurbakhsh who brought the order to the West following the 1979 Revolution in Iran.
"Naqshbandi" does not meant for images or patterns followed by the followers of this school of thoughts. "Naqshbandi" manes the "flow chart" OR to follow the sayings and doings of former.
Nurbakshi.
The "Noorbakshia" (Arabic: ش‎) also called Nubakshia is an Islamic sect and the Sufi order and way that claims to trace its direct spiritual lineage and chain (silsilah) to the Islamic prophet Muhammad, through Ali, by way of Imam Ali Al-Ridha. This order became famous as Nurbakshi after Shah Syed Muhammad Nurbakhsh Qahistani who was attached with Kubrawiya order Sufi order ("tariqa") .
Oveyssi (Uwaiysi).
The Oveyssi (or Uwaiysi) order claim to be founded 1,400 years ago by Uwais al-Qarni from Yemen. Uways received the teachings of Islam inwardly through his heart and lived by the principles taught by him, although he had never physically met Muhammad. At times Muhammad would say of him, "I feel the breath of the Merciful, coming to me from Yemen." Shortly before Muhammad died, he directed Umar (second Caliph) and Ali (the first Imam of the Shia) to take his cloak to Uwais. "According to Ali Hujwiri, Farid ad-Din Attar of Nishapur and Sheikh Muhammad Ghader Bagheri, the first recipient of Muhammad's cloak was Uwais al-Qarni. The 'Original Cloak' as it is known is thought to have passed down the generations from the prophet Abraham to Muhammad, to Uwais al-Qarni, and so on."
Now developed into an international non-profit organization, the MTO Shahmaghsoudi led by Hazrat Salaheddin Ali Nader Angha has over five-hundred thousand students with centers spanning five continents. With the use of modern technology and reach of the internet, weekly webcasts of the order's lecture and zekr sessions are broadcast live through the order's official website.
The Oveyssi order exists today in various forms and in different countries. According to Dr. Alan Godlas of the University of Georgia's Department of Religion, a Sufi Order or tariqa known as the Uwaysi is "very active", having been introduced in the West by the 20th century Sufi, Shah Maghsoud Angha. The Uwaysi Order is a Shi'i branch of the Kubrawiya.
Godlas writes that there are two recent and distinct contemporary branches of the Uwaysi Order in the West:
Uwaiysi Tarighat, led by Shah Maghsoud Sadegh Angha's daughter, Seyyedeh Dr. Nahid Angha, and her husband Shah Nazar Seyed Ali Kianfar. Dr. Angha and Dr. Kianfar went on to found another the International Association of Sufism (IAS) which operates in California and organizes international Sufi symposia. Ali Kianfar in the book Oveys-E Gharani and his School [Z1]; (by G. A. Kianfar; 1983) under the subtitle of Caliph (The Successor) states:
On Sept., 4, 1970, Hazrat Shahmaghsoud (41st Sufi Master of Oveyssi)in his lecture with regards to the greatness and importance of school of Sufism and the duty of the seekers (Believers) in paying attention to this school’s goal of human excellence:
“For thirty years, what was needed to say and to pass on with regards to the secrets of the Sufi path and the truth of Islam, I have told and written for you, and every soul based on his/her potential has benefited from them, both physically and spiritually.
Based on what God has proven to you and your hearts, you are responsible and should pass on the truth and with the will of God and his wisdom I appoint Salaheddin Ali Nader Angha as my caliph (successor). And gave his blessed robe and the special kashkool (special cup of emptiness) and the tabarzin (The healing axe) to him, and mentioned other specific orders in this regard.
The chosen Pir Hazrat Salaheddin Ali Nader Angha has followed the direct instructions of Hazrat Ghotbeddin Mohammad Angha(40th Sufi Master of Oveyssi)since childhood, and based on his inner aptitude at those years has shown His readiness and with Hazrat Pir Shahmaghsoud’s attention has passed all the stages.
Now developed into an international non-profit organization, the MTO Shahmaghsoudi led by Hazrat Salaheddin Ali Nader Angha has over five-hundred thousand students with centers spanning five continents. With the use of modern technology and reach of the internet, weekly webcasts of the order's lecture and zekr sessions are broadcast live through the order's official website.
Qadiri.
The Qadiri Order is one of the oldest Sufi Orders. It derives its name from Abdul-Qadir Gilani (1077-1166), a native of the Iranian province of Gīlān. The order is one of the most widespread of the Sufi orders in the Islamic world, and can be found in Central Asia, Turkey, Balkans and much of East and West Africa. The Qadiriyyah have not developed any distinctive doctrines or teachings outside of mainstream Islam. They believe in the fundamental principles of Islam, but interpreted through mystical experience. read more 
Senussi.
Senussi is a religious-political Sufi order established by Muhammad ibn Ali as-Senussi. Muhammad ibn Ali as-Senussi founded this movement due to his criticism of the Egyptian ulema. Originally from Mecca, as-Senussi left due to pressure from Wahhabis to leave and settled in Cyrenaica where he was well received. Idris bin Muhammad al-Mahdi as-Senussi was later recognized as Emir of Cyrenaica and eventually became King of Libya. The monarchy was abolished by Muammar Gaddafi but, a third of Libyan still claim to be Senussi.
Shadiliyya.
The Shadhili is a Sufi order founded by Abu-l-Hassan ash-Shadhili. Followers ("murids" Arabic: seekers) of the Shadhiliyya are often known as Shadhilis.
Suhrawardiyya.
The Suhrawardiyya order (Arabic: سهروردية‎) is a Sufi order founded by Abu al-Najib al-Suhrawardi (1097–1168). The order was formalized by his nephew, Shahab al-Din Abu Hafs Umar Suhrawardi.
Tijaniyya.
The Tijaniyyah order attach a large importance to culture and education, and emphasize the individual adhesion of the disciple (murīd).
Reception.
Perception outside Islam.
Sufi mysticism has long exercised a fascination upon the Western world, and especially its orientalist scholars. Figures like Rumi have become well known in the United States, where Sufism is perceived as a peaceful and apolitical form of Islam.
The Islamic Institute in Mannheim, Germany, which works towards the integration of Europe and Muslims, sees Sufism as particularly suited for interreligious dialogue and intercultural harmonisation in democratic and pluralist societies; it has described Sufism as a symbol of tolerance and humanism—nondogmatic, flexible and non-violent. According to Philip Jenkins, a Professor at Baylor University, "the Sufis are much more than tactical allies for the West: they are, potentially, the greatest hope for pluralism and democracy within Muslim nations." Likewise, several governments and organisations have advocated the promotion of Sufism as a means of combating intolerant and violent strains of Islam. For example, the Chinese and Russian governments openly favor Sufism as the best means of protecting against Islamist subversion. The British government, especially following the 7 July 2005 London bombings, has favoured Sufi groups in its battle against Muslim extremist currents. The influential RAND Corporation, an American think-tank, issued a major report titled "Building Moderate Muslim Networks," which urged the US government to form links with and bolster Muslim groups that opposed Islamist extremism. The report stressed the Sufi role as moderate traditionalists open to change, and thus as allies against violence. News organisations such as the BBC, Economist and Boston Globe have also seen Sufism as a means to deal with violent Muslim extremists.
Influence on Judaism.
Both Judaism and Islam are monotheistic. However, there is evidence that Sufism did influence the development of some schools of Jewish philosophy and ethics. A great influence was exercised by Sufism upon the ethical writings of Jews in the Middle Ages[]. In the first writing of this kind, we see "Kitab al-Hidayah ila Fara'iḍ al-Ḳulub", "Duties of the Heart", of Bahya ibn Paquda. This book was translated by Judah ibn Tibbon into Hebrew under the title "Ḥōḇōṯ Ha-lleḇāḇōṯ".The precepts prescribed by the Torah number 613 only; those dictated by the intellect are innumerable.
 This was precisely the argument used by the Sufis against their adversaries, the Ulamas. The arrangement of the book seems to have been inspired by Sufism. Its ten sections correspond to the ten stages through which the Sufi had to pass in order to attain that true and passionate love of God which is the aim and goal of all ethical self-discipline. A considerable amount of Sufi ideas entered the Jewish mainstream[] through Bahya ibn Paquda's work, which remains one of the most popular ethical treatises in Judaism[].
It is noteworthy that in the ethical writings of the Sufis Al-Kusajri and Al-Harawi there are sections which treat of the same subjects as those treated in the "Ḥovot ha-Lebabot" and which bear the same titles: e.g., "Bab al-Tawakkul"; "Bab al-Taubah"; "Bab al-Muḥasabah"; "Bab al-Tawaḍu'"; "Bab al-Zuhd". In the ninth gate, Baḥya directly quotes sayings of the Sufis, whom he calls "Perushim". However, the author of the "Ḥōḇōṯ Ha-lleḇāḇōṯ" did not go so far as to approve of the asceticism of the Sufis, although he showed a marked predilection for their ethical principles.
The Jewish writer Abraham bar Ḥiyya teaches the asceticism of the Sufis. His distinction with regard to the observance of Jewish law by various classes of men is essentially a Sufic theory. According to it there are four principal degrees of human perfection or sanctity; namely:
Abraham ben Moses ben Maimon, the son of the Jewish philosopher Maimonides, believed that Sufi practices and doctrines continue the tradition of the Biblical prophets. See Sefer Hammaspiq, "Happerishuth", Chapter 11 ("Ha-mmaʿaḇāq") s.v. hithbonen efo be-masoreth mufla'a zo, citing the Talmudic explanation of Jeremiah 13:27 in Chagigah 5b; in Rabbi Yaakov Wincelberg's translation, "The Way of Serving God" (Feldheim), p. 429 and above, p. 427. Also see ibid., Chapter 10 ("Iqquḇim"), s.v. wa-halo yoḏeʾaʿ atta; in "The Way of Serving God", p. 371. There are other such references in Rabbi Abraham's writings, as well. He introduced into the Jewish prayer such practices as reciting God's names (dhikr)[].
Abraham Maimuni's principal work is originally composed in Judeo-Arabic and entitled "כתאב כפאיה אלעאבדין" "Kitāb Kifāyah al-'Ābidīn" ("A Comprehensive Guide for the Servants of God"). From the extant surviving portion it is conjectured that Maimuni's treatise was three times as long as his father's Guide for the Perplexed. In the book, Maimuni evidences a great appreciation for, and affinity to, Sufism. Followers of his path continued to foster a Jewish-Sufi form of pietism for at least a century, and he is rightly considered the founder of this pietistic school, which was centered in Egypt.
The followers of this path, which they called, interchangeably, Hasidism (not to be confused with the [later] Jewish Hasidic movement) or Sufism (Tasawwuf), practiced spiritual retreats, solitude, fasting and sleep deprivation. The Jewish Sufis maintained their own brotherhood, guided by a religious leader—like a Sufi sheikh.
Abraham Maimuni's two sons, Obadyah and David, continued to lead this Jewish-Sufi brotherhood. Obadyah Maimonides wrote "Al-Mawala Al Hawdiyya" ("The Treatise of the Pool")—an ethico-mystical manual based on the typically Sufi comparison of the heart to a pool that must be cleansed before it can experience the Divine.
The Maimonidean legacy extended right through to the 15th century with the 5th generation of Maimonidean Sufis, David ben Joshua Maimonides, who wrote "Al-Murshid ila al-Tafarrud" (The Guide to Detachment), which includes numerous extracts of Suhrawardi's "Kalimat at-Tasawwuf".[]
In popular culture.
Music.
Abida Parveen, a Pakistani Sufi singer is one of the foremost exponents of Sufi music, together with Nusrat Fateh Ali Khan are considered the finest Sufi vocalists of the modern era. Sanam Marvi another Pakistani singer has recently gained recognition for her Sufi vocal performances.
A. R. Rahman, the Oscar-winning Indian musician, has several compositions which draw inspiration from the Sufi genre; examples are the filmi qawwalis "Khwaja Mere Khwaja" in the film "Jodhaa Akbar", "Arziyan" in the film "Delhi 6" and "Kun Faya Kun" in the film "Rockstar".
Bengali singer Lalan Fakir and Bangladesh's national poet Kazi Nazrul Islam scored several Sufi songs.
Junoon, a band from Pakistan, created the genre of Sufi rock by combining elements of modern hard rock and traditional folk music with Sufi poetry.
In 2005, Rabbi Shergill released a Sufi rock song called "Bulla Ki Jaana", which became a chart-topper in India and Pakistan.
Madonna, on her 1994 record "Bedtime Stories", sings a song called "Bedtime Story" that discusses achieving a high unconsciousness level. The video for the song shows an ecstatic Sufi ritual with many dervishes dancing, Arabic calligraphy and some other Sufi elements. In her 1998 song "Bittersweet", she recites Rumi's poem by the same name. In her 2001 Drowned World Tour, Madonna sang the song "Secret" showing rituals from many religions, including a Sufi dance.
Singer/songwriter Loreena McKennitt's record "The Mask and Mirror" (1994) has a song called "The Mystic's Dream" that is influenced by Sufi music and poetry. The band mewithoutYou has made references to Sufi parables, including the name of their album "It's All Crazy! It's All False! It's All a Dream! It's Alright" (2009). Tori Amos makes a reference to Sufis in her song "Cruel".
Mercan Dede is a Turkish composer who incorporates Sufism into his music and performances.
British folk singer Richard Thompson is a long-time Sufi.
Literature.
The Persian poet Rumi has become one of the most widely read poets in the United States, thanks largely to the interpretative translations published by Coleman Barks. Elif Safak's novel "The Forty Rules of Love" tells the story of Rumi becoming a disciple of the Persian Sufi dervish Shams Tabrizi.

</doc>
<doc id="28249" url="http://en.wikipedia.org/wiki?curid=28249" title="Search algorithm">
Search algorithm

In computer science, a search algorithm is an algorithm for finding an item with specified properties among a collection of items. The items may be stored individually as records in a database; or may be elements of a search space defined by a mathematical formula or procedure, such as the roots of an equation with integer variables; or a combination of the two, such as the Hamiltonian circuits of a graph.
Classes of search algorithms.
For virtual search spaces.
Algorithms for searching virtual spaces are used in constraint satisfaction problem, where the goal is to find a set of value assignments to certain variables that will satisfy specific mathematical equations and inequations. They are also used when the goal is to find a variable assignment that will maximize or minimize a certain function of those variables. Algorithms for these problems include the basic brute-force search (also called "naïve" or "uninformed" search), and a variety of heuristics that try to exploit partial knowledge about structure of the space, such as linear relaxation, 'constraint generation, and constraint propagation.
An important subclass are the local search methods, that view the elements of the search space as the vertices of a graph, with edges defined by a set of heuristics applicable to the case; and scan the space by moving from item to item along the edges, for example according to the steepest descent or best-first criterion, or in a stochastic search. This category includes a great variety of general metaheuristic methods, such as simulated annealing, tabu search, A-teams, and genetic programming, that combine arbitrary heuristics in specific ways.
This class also includes various tree search algorithms, that view the elements as vertices of a tree, and traverse that tree in some special order. Examples of the latter include the exhaustive methods such as depth-first search and breadth-first search, as well as various heuristic-based search tree pruning methods such as backtracking and branch and bound. Unlike general metaheuristics, which at best work only in a probabilistic sense, many of these tree-search methods are guaranteed to find the exact or optimal solution, if given enough time.
Another important sub-class consists of algorithms for exploring the game tree of multiple-player games, such as chess or backgammon, whose nodes consist of all possible game situations that could result from the current situation. The goal in these problems is to find the move that provides the best chance of a win, taking into account all possible moves of the opponent(s). Similar problems occur when humans or machines have to make successive decisions whose outcomes are not entirely under one's control, such as in robot guidance or in marketing, financial, or military strategy planning. This kind of problem — combinatorial search — has been extensively studied in the context of artificial intelligence. Examples of algorithms for this class are the minimax algorithm, alpha–beta pruning, and the A* algorithm.
For sub-structures of a given structure.
The name combinatorial search is generally used for algorithms that look for a specific sub-structure of a given discrete structure, such as a graph, a string, a finite group, and so on. The term combinatorial optimization is typically used when the goal is to find a sub-structure with a maximum (or minimum) value of some parameter. (Since the sub-structure is usually represented in the computer by a set of integer variables with constraints, these problems can be viewed as special cases of constraint satisfaction or discrete optimization; but they are usually formulated and solved in a more abstract setting where the internal representation is not explicitly mentioned.)
An important and extensively studied subclass are the graph algorithms, in particular graph traversal algorithms, for finding specific sub-structures in a given graph — such as subgraphs, paths, circuits, and so on. Examples include Dijkstra's algorithm, Kruskal's algorithm, the nearest neighbour algorithm, and Prim's algorithm.
Another important subclass of this category are the string searching algorithms, that search for patterns within strings. Two famous examples are the Boyer–Moore and Knuth–Morris–Pratt algorithms, and several algorithms based on the suffix tree data structure.
Search for the maximum of a function.
In 1953, American statistician Jack Kiefer devised Fibonacci search which can be used to find the maximum of a unimodal function and has many other applications in computer science.
For quantum computers.
There are also search methods designed for quantum computers, like Grover's algorithm, that are theoretically faster than linear or brute-force search even without the help of data structures or heuristics.
Further reading.
</dl>
External links.
</dl>

</doc>
<doc id="28250" url="http://en.wikipedia.org/wiki?curid=28250" title="Sorcerer (Linux distribution)">
Sorcerer (Linux distribution)

Sorcerer is a source based Linux distribution. Sorcerer's source management tool is called sorcery. Sorcery downloads and compiles source code in order to install and update installed software. Instead of using cryptic hard to remember acronyms, such as rpm and dpkg, Sorcerer's tool terminology is based upon magic words. For example, a recipe for downloading, compiling, and installing software is called a "spell." Software to install is "cast" onto the box. Installed software can be removed by "dispelling." Consequently, the command line tools for casting and dispelling software are called cast and dispel, respectively.
In 2000, Kyle Sallee created a source-based Linux distribution called "Sorcerer GNU/Linux" and released it under the GNU GPL. During this time Sorcerer was a technology demonstration rather than a stable distribution. Eventually the distribution tools, called sorcery, and the software catalog, called grimoire, were redesigned and rewritten in order to become stable and usable on production machines. A month or two before the rewrite happened, in early 2002, Chuck S. Mead, who had previously created a fork of RedHat, created a fork of Sorcerer GNU/Linux. The first fork of Sorcerer GNU/Linux was called by the same name as Mr. Mead's fork of RedHat. It was called either "Lunar Penguin" or Lunar Linux. This fork's timing was fortunate for system administrators, because it granted them an opportunity to continue deployment of the distribution that Mr. Sallee was about to discontinue.
Due to the immense effort involved in single handedly creating and maintaining a distribution Mr. Sallee ceased "Sorcerer GNU/Linux" during the redesign and rewrite of sorcery and grimoire. System administrators with deployed boxes were encouraged to painlessly transition to the nearly identical fork.
The earliest versions of Sorcerer were named "Sorcerer GNU/Linux", with key components licensed under the GNU General Public License (GPL). However, from around 2002 and forward current versions of Sorcerer release some key components under the "Sorcerer Public License" and not the GPL, and the distribution has dropped the term "GNU/Linux". Sorcerer has two ancient forks: Lunar Linux and Source Mage which are not based on nor compatible with the current sorcery code nor compatible with current grimoire. Their terminology also deviates from Sorcerer terminology.
Technical Distinctions.
A somewhat distinctive feature of Sorcerer is the fact that it is based almost exclusively on source code. While many other operating systems generally make use of a package that contains pre-compiled (executable) programs, Sorcerer compiles source code on the machine prior to installation.
A new "grimoire", which is a catalog of software supported for immediate installation, is made available daily. When new sources are available, the spells in the grimoire are updated. One's desktop is updated by first installing a current grimoire. If necessary, the installed Sorcery is updated. Finally, any and all installed software can be updated according to the user's decision.
Sorcery automatically recompiles installed software as necessary to ensure continued compatibility and usability when installed libraries are updated to newer or older versions. Unlike a pre-compiled binary-based distro that must always download new packages, Sorcery most often recompiles installed software from previously downloaded sources. When a new source is required and an older source was previously downloaded, then Sorcerer will download a tiny patch that transforms the old source tarball into a current source tarball. The practice of keeping old source tarballs and downloading patches for updates allows Sorcerer systems to be updated using less bandwidth than distributions that provide pre-compiled packages.
Users can add new spells to the grimoire on their local machine and can submit the new spell for inclusion in the general distribution.
The minimum system requirements are given as 1 GB of RAM and 20 GB of hard disk space. This is suggested because compiling some sources will consume large amounts of resources. Sorcerer has recently started using cgroups to limit the impact of software compilation has on the system performance. Therefore, Sorcerer installations are normally updated while still in multi-user mode while causing no interruption to services or downtime. Changing to single user run level mode for updating is not recommended.
See also.
Other source-base Linux distributions:

</doc>
<doc id="28251" url="http://en.wikipedia.org/wiki?curid=28251" title="Software package">
Software package

Software package refers to a piece of software that provides certain functionality as part of a larger system (the individual files or resources have been "packaged"), or a collection of multiple such pieces (a "package" of multiple pieces):

</doc>
<doc id="28254" url="http://en.wikipedia.org/wiki?curid=28254" title="Safe semantics">
Safe semantics

Safe semantics is a consistency model that describes one type of guarantee a data register provides when it is shared by several processors in a parallel machine or in a network of computers working together.
This notion was first defined by Lamport in 1985. Later on, it was formally defined in Leslie Lamport's "On Interprocess Communication", which was published in "Distributed Computing" in 1986.
Safe semantics are defined for a variable with a single writer but multiple readers (SWMR). A SWMR register is safe if each read operation satisfies the two following properties:
In particular, if there is concurrency between a read and a write operation, the read operation can return a value which has never been written by any write operation. The return value only belongs to the register domain.
We can see a binary safe register as modeling a bit flickering. Whatever the previous value of the register is, the register's value could flicker until the write operation finishes. Therefore, the read operation which overlaps with a write operation could return 0 r 1.
There have been many implementations of safe register in distributed systems. Baldoni et al. show that there is no way to implement a register having the stronger property of regular semantics in a synchronous system under continuous churn. On the other hand, it has been demonstrated in that a safe register can be implemented under continuous churn in a non-synchronous system. Here, churn refers to the
leaving and joining of servers from/into a distributed system. Modeling and Implementing a type of storage memory (Safe Register) under non-quiescent churn in required some system models such as client and server systems.Client systems contains finite arbitrary number of processes and they are responsible for reading and writing into the server system.On the other hand,the server system just make sure that read and write operations happen properly.Safe register implementation was as follow:
-Safe register was maintained by the set of active servers.
-Clients do not maintain any register information (trigger operation, and interact with servers)
-Eventually synchronous system
-Quorums(set of server or client systems)
-Size of the Read() and Write() operation executed on quorums = n – f – J (n is the number of servers, J is the number of servers that leave and join,and f is the number of Byzantine failures.
Before implementing the safe register,in some algorithms were introduced such as join,read, and write operation.
Join Operation():A server(si) which wants to get entered into a server system will broadcast an inquiry message to other servers to inform other servers of its arrival into the distributed system,si also wants to find a current value of the register.Once other server received this inquiry they will send a reply message to si.After si receives enough reply from other servers,it will collect all the replies and saves them into a reply set.Si waits until it gets enough reply(n-f-j) from other servers then it will pick up the most frequent value among other values.Si will also do the following :
-Updates its local copy of the register
-It becomes active
-Sends reply to the processes in the set reply
-If si its active it will sends reply message to the other servers immediately.
-Otherwise,if Si is not active, it will store the inquiries somewhere to reply them by the time it become active.
-When si gets reply from other servers it will eventually add the new reply to the reply set and throw the old value from the reply set.
-If the value of the respond server is bigger that si value, then si will update its information with the new value.
Read operation(): the read operation algorithm is a basic version of the join operation.The only difference between these two algorithms is the broadcast mechanism used by the read operation.A client (cw)will broadcast a message to the system and once a server receives the inquiry,it will send a reply message to the client.Once the client receives enough replies (n-f-j) it will stop sending an inquiry.
Write operation:Client(cw) sends an inquiry into the system in different rounds and it will wait until it receives two acknowledgment.(sn =sequence number)
The reason for receiving two acknowledgment is because there could be a danger in a system. When a process Sends an acks, it may die after one millisecond.Therefore,there will be no confirmation received by the client.
In the validity of the safe register(If a read() not concurrent with any write(), returns the last value written before its invocation) was proved based on the quorum system.Assume that there are two quorum system(Qw,Qr).Qw indicates the Servers that know about the latest value,and Qr indicates Values of Read’s responses.Based on the assumption in the size of each quorum is equal to n-f-j.To prove the safe register's validity we need to prove the following equation:
(Qw∩Qr)\B >(Qr∩B) :Note that B is the number of Byzantine failures.
Proof : Red region indicates (Qw∩Qr)\B and the blue region indicates Qr∩B.Based on the assumption,we know that the size of each quorum is n-f-j,so the red region will have n-3f-2j active servers.Therefore,n-3f-2J > f --> n > 4f+2J --> n is strictly greater than f. 

</doc>
<doc id="28258" url="http://en.wikipedia.org/wiki?curid=28258" title="Sarawak">
Sarawak

Sarawak (]) is one of the two Malaysian states on the island of Borneo. It is also one of the founding members of the Malaysian federation alongside North Borneo (Sabah), Singapore (expelled in 1965) and the Federation of Malaya (Peninsula Malaysia or West Malaysia). Like Sabah, this territory has an autonomous law especially in immigration, which differentiates it from the rest of the Malaysian Peninsula states. Today, the state is known as "Bumi Kenyalang" ("Land of the Hornbills").
Sarawak is situated on the northwest of Borneo, bordering the state of Sabah to the northeast, Indonesia to the south, and surrounding the independent state of Brunei. The administrative capital is Kuching, which has a population of 700,000. Major cities and towns include Miri (pop. 350,000), Sibu (pop. 257,000) and Bintulu (pop. 200,000). As of the last census (2010), the state population was 2,420,009.
History.
Bruneian Empire.
During the 15th century, the area was under the influence of the Bruneian Empire and was self-governed under Sultan Tengah. The eastern seaboard of Borneo was charted, though not settled, by the Portuguese in the early 16th century. The area of Sarawak was known to Portuguese cartographers as "Cerava". By the early 19th century, Sarawak had become a loosely governed territory under the control of the Brunei Sultanate. During the reign of Pangeran Indera Mahkota in the 19th century, Sarawak was facing chaos. Sultan Omar Ali Saifuddin II (1827–1852), the Sultan of Brunei, ordered Pangeran Muda Hashim in 1839 to restore order and it was during this time that James Brooke arrived in Sarawak. Pangeran Muda Hashim initially requested assistance in the matter, but Brooke refused. In 1841, Brooke paid another visit to Sarawak and this time he agreed to provide assistance. Pangeran Muda Hashim signed a treaty in 1841 surrendering Sarawak and Sinian to Brooke. On 24 September 1841, Pangeran Muda Hashim bestowed the title Governor on James Brooke. Then in 1846, he effectively became the Rajah of Sarawak and founded the White Rajah Dynasty of Sarawak after the death of Pengeran Muda Hashim.
Brooke Dynasty.
James Brooke was appointed Rajah by the Sultan of Brunei on August 1846. Brooke ruled the territory, later expanded, across the western regions of Sarawak around Kuching until his death in 1868. His nephew Charles Anthoni Johnson Brooke became Rajah after his death; he was succeeded on his death in 1917 by his son, Charles Vyner Brooke, with the condition that Charles should rule in consultation with his brother Bertram Brooke. The Sarawak territories were greatly enlarged under the Brooke dynasty, mostly at the expense of areas nominally under the control of Brunei. In practice Brunei had only controlled strategic river and coastal forts in much of the lost territory, so most of the gain was at the expense of Muslim warlords and of the de facto independence of local tribes.
The Brooke dynasty ruled Sarawak for a hundred years and became famous as the "White Rajahs", accorded a status within the British Empire similar to that of the rulers of Indian princely states. In contrast to many other areas of the empire, however, the Brooke dynasty was intent on a policy of paternalism to protect the indigenous population against exploitation. They governed with the aid of the Muslim Malay and enlisted the Ibans and other "Dayak" as a contingent militia. The Brooke dynasty also encouraged the immigration of Chinese merchants but forbade the Chinese to settle outside of towns to minimise the impact on the Dayak way of life. Charles Brooke, the second White Rajah of Sarawak, established the Sarawak Museum, the oldest museum in Borneo.
In the early part of 1941, preparations were afoot to introduce a new constitution, designed to limit the power of the Rajah and give the people of Sarawak a greater say in government. Despite this democratic intention, the draft constitution contained irregularities, including a secret agreement drawn up between Charles Vyner Brooke and his top government officials, financially compensating him via treasury funds.
Second World War and occupation.
Japan invaded Sarawak and occupied the island of Borneo in 1941, occupying Miri on 16 December and Kuching on 24 December, holding both territories for the duration of World War II until the area was secured by Australian forces in 1945 and managed under the British Military Administration. Charles Vyner Brooke formally ceded sovereignty to the British Crown on 1 July 1946, under pressure from his wife among others. In addition, the British Government offered a healthy pension to Brooke. Anthony Brooke, the designated heir, opposed the cession of the Rajah's territory to the British Crown, and was associated with anti-cessionist groups in Sarawak, consisting of a majority of the native members of the Council Negri (Parliament).
Post-Japanese Occupation.
Anthony Brooke continued to claim sovereignty as Rajah of Sarawak. For this he was banished from Sarawak and he was allowed to return only seventeen years later, when Sarawak became part of Malaysia. Sarawak became a British Crown colony in July 1946, but Anthony's campaign continued. The Malays in particular resisted the cession to Britain, dramatically assassinating the second British governor, Sir Duncan George Stewart.
Self-government and the Federation of Malaysia.
Sarawak was officially granted self-government on 22 July 1963, and later formed the federation of Malaysia with Malaya, North Borneo, and Singapore on 16 September 1963, despite the initial opposition from parts of the population. Sarawak was also a flashpoint during the Indonesia–Malaysia confrontation between 1962 and 1966. Between 1962 and 1990, there was also a Communist insurgency in Sarawak.
Geography.
Having land area of 124,450 km2 spreading between latitude 0° 50′ and 5°N and longitude 109° 36′ and 115° 40′ E, it makes up 37.5% of the land of Malaysia. Sarawak also contains large tracts of tropical rainforest home to an abundance of plant and animal species but has been severely logged since the 1950s.
The state of Sarawak stretches for over 750 kilometres (466 mi) along the northeast coastline of Borneo, interrupted in the north by about 150 kilometres (93 mi) of Bruneian coast. Should Brunei not be taking up Sarawak's coast, the entire coastline of Sarawak would be 900 kilometres (559 mi) long. Sarawak is separated from the Indonesian part of Borneo (Kalimantan) by ranges of high hills and mountains that are part of the central mountain range of Borneo. These get higher to the north and culminate near the source of the Baram River with the steep Mount Selidang (4504 ft) at central plateau of Usun Apau, Mount Batu Lawi, Mount Mulu in the park of the same name and Mount Murud with the highest peak in Sarawak.
The major rivers from the south to the north include the Sarawak River, Lupar River, Saribas River, and Rajang River, which is the longest river in Malaysia at 563 km. The Baleh River branch, the Baram River, and the Limbang River drains into the Brunei Bay as it divides the two parts of Brunei and the Trusan River. The Sarawak river is 2,459 km2 in area and is the main river flowing through the capital of Kuching.
Sarawak can be divided into three natural regions. The coastal region is rather low lying flat country with large extents of swamps and other wet environments. The hill region provides most of the easily inhabited land and most of the larger cities and towns have been built in this region. The ports of Kuching and Sibu have been built some distance from the coast on rivers. Bintulu and Miri are close to the coastline where the hills stretch right to the South China Sea. The third region is the mountain region along the border and with the Kelabit (Bario), Murut (Ba Kelalan) and Kenyah (Usun Apau) highlands in the north.
Demographics.
Population.
As of the 2010 census, the population of Sarawak was 2,399,839, making it the 4th most populous state in Malaysia. Due to the large area of Sarawak, it has the lowest population density in Malaysia, which stands at 22 people per km2. Sarawak also has some of the lowest population growth in Malaysia.
Ethnic groups.
Sarawak has more than 40 sub-ethnic groups, each with its own distinct language, culture and lifestyle. Cities and larger towns are populated predominantly by Malays, Melanaus, Chinese, Indians, and a smaller percentage of Ibans and Bidayuhs who have migrated from their home villages to look for employment.
Generally, Sarawak has six major ethnic groups namely Iban, Chinese, Malay, Bidayuh, Melanau, and Orang Ulu. Several minor ethnic groups include Kedayan, Javanese, Bugis, Murut, and Indian. Unlike Indonesia, the term Dayak is not officially used to address Sarawakian's native ethnicity.
Iban.
The Ibans comprise the largest percentage (almost 30%) of Sarawak's population. Iban is native to Sarawak and Sarawak has the highest number of Ibans in Borneo.
The large majority of Ibans practise Christianity. However, like most other ethnic groups in Sarawak, they still observe many of their traditional rituals and beliefs. Sarawak celebrates colourful festivals such as the generic Gawai Dayak (Harvest Festival), Gawai Kenyalang (Hornbill Festival), Gawai Burong (Bird Festival), Gawai Tuah (Luck Festival), Gawai Pangkong Tiang (House Post Banging Festival), Gawai Tajau (Jar Festival), Gawai Sakit (Healing Festival) and Gawai Antu (festival of the dead).
Chinese.
Sarawakian Chinese are mostly made up of Han Chinese being 99.99% classified as ethnic Han as Chinese is a loose term which inclusive of all the 55 ethnic group of People's Republic of China.
Chinese pioneers first came to Sarawak as traders and explorers in the 6th century. Today, they make up 24% of the population of Sarawak and consist of communities built from the economic migrants of the 19th and early 20th centuries. They are classified as a non-Bumiputera ethnic group.
The Sarawak Chinese belong to a wide range of dialect groups, the most significant being Cantonese, Foochow, Hakka, Hokkien, Teochew, Hainanese, and Puxian Min. The Chinese maintain their ethnic heritage and culture and celebrate all the major cultural festivals, most notably the Chinese New Year and the Hungry Ghost Festival. The Sarawak Chinese are predominantly Buddhists.
Ethnic Chinese were encouraged to settle in Sarawak because of their commercial and business acumen. The biggest dialect group is the Hokkien people; many originated from Choanchew, Chiangchew, Longhai, Kinmen, Amoy and Taiwan.
The Hakka people, Teochew people, Henghua people, Hainan people, Shanghainese people and Cantonese people represent a minority of the Chinese population. Despite their small numbers, the Hokkien have a considerable presence in Sarawak's private and business sector, providing commercial and entrepreneurial expertise and often operating joint business ventures with Malaysian Chinese entreprises.
A notable person namely Ong Tiang Swee safeguard the interest and welfare of the Chinese communities in Sarawak back in the old days, he was considered as Kapitan China.
Some Chinese settled in Sarawak after the Sun Yat Sen led Kuomintang lost the civil war in 1949 against the Communist Party of China namely Longhai Campaign.
In 1963, when Sarawak helped Malaya to form Malaysia, most of the Chinese which hails from Coastal cities from Xiamen, Guangzhou, Quanzhou automatically gained Malaysian citizenship despite having the Republic of China citizenship under Kuomintang (not to be confused with Communist Party of China).
Fuzhou people came in Sarawak in 1901 from Fuzhou, Fujian due to numerous violent incident such as the infamous Boxer Rebellion that occurred in the Qing Dynasty in 1899. During the boxer rebellion many Chinese Christian were brutally murdered, and women and children were being punished for their faith, as of this action the Qing Dynasty supported the causes, Wong Nai Siong a Christian leader, led them to a safer place to live and to create a community by agreeing with terms and contract with late Charles Brooke, Rajah of Sarawak and later allocated them to a nearby town called Sibu and decided to name it the New Foochow Settlement. However, due to the sizeable presence of other Chinese sub-ethnic groups such as the Hokkiens, Hakka, and the Cantonese they ultimately retained the original name of the area.
Sarawak Hakka were particularly from Jiexi County, Guangdong. As most of these Hakka spoke Hopo Hakka which differs from the other Hakka.
Malay.
The Malays make up 23% of the population in Sarawak. They mostly populate the southern region and urban areas of Sarawak. Despite being Malays, Sarawak Malay has a distinct culture and language to that of other Malays in Peninsular Malaysia. They speak local variant of Bahasa Melayu Sarawak (or Sarawak Malay), and been classified as Bumiputera Sarawak in Sarawak Gazette.
Melanau.
The Melanaus have been thought to be amongst the original settlers of Sarawak. They make up 6% of the population in Sarawak.
Today most of the Melanaus community profess Islam and Christianity, though they still celebrate traditional animist festivals such as the annual Kaul festival.
Bidayuh.
Concentrated mainly on the West end of Borneo, the Bidayuhs make up 8% of the population in Sarawak.
The Bidayuhs speak a number of different but related dialects. Some Bidayuhs speak either English or Sarawak Malay as their main language. While some of them still practise traditional religions, the majority of modern-day Bidayuhs have adopted the Christian faith. Another ethnic associated to Bidayuh is Salako, classified as Bidayuh by the Malaysian government for political convenience.
Orang Ulu.
Orang Ulu is an ethnic group in Sarawak. The various Orang Ulu ethnics together make up roughly 6% of Sarawak's population. The phrase "Orang Ulu" means upriver people and is a term used to collectively describe the numerous tribes that live upriver in Sarawak's vast interior. Such groups include the major Kenyah and Kayan people, and the smaller neighbouring groups of the Kajang, Kejaman, Punan, Ukit, and Penan. Nowadays, the definition also includes the down-river tribes of the Lun Bawang, Lun Dayeh, "mean upriver" or "far upstream", Berawan, Saban as well as the plateau-dwelling Kelabits. "Orang Ulu" is a term coined officially by the government to identify several ethnics and sub-ethnics who live mostly at the upriver and uphill areas of Sarawak. Most of them live in the district of Baram, Miri, Belaga, Limbang, and Lawas.
A vast majority of the Orang Ulu tribe are Christians but traditional religions are still practised in some areas.
Some of the major tribes making up the Orang Ulu group include:
Others.
Other minority ethnic groups residing in Sarawak are the Kedayan ethnic groups and also the Punan Bah people (in fact is a collective of obscure and unaccounted ethnic communities grouped together as a single ethnic entity), and also non-Bumiputera ethnic groups, which are the Indian and Eurasian.
The Kedayan are an ethnic group residing in parts of Sarawak. The Kedayan language is spoken by more than 37,000 people in Sarawak, with most of the members of the Kedayan community residing in Lawas, Limbang, Miri, and Sibuti areas. Unlike its Peninsular counterpart, Sarawakians of Indian descent are small in number and have assimilated very well to the other communities. Eurasians continues to be the smallest among the minority ethnic groups in Sarawak, mostly due to assimilation and interracial marriages. The Punan Bah communities are usually located in areas that encompass the borders of Sarawak, Sabah, Brunei, and Indonesia. More studies need to be carried out about them, as they are one of the lesser known group in the state.
Religion.
As of 2010 the population of Sarawak disregarding foreign immigrants is 44.0% Christian, 30.0% Muslim, 13.5% Buddhist, 6.0% Taoist or Chinese religion follower, 3.1% follower of other religions, and 2.6% non-religious.
Sarawak is the only state in Malaysia where Christians outnumber Muslims. Major Christian denominations in Sarawak are the Roman Catholics, Anglicans, Methodists, Borneo Evangelical Mission (BEM or Sidang Injil Borneo, S.I.B.), and Baptists. Many Sarawakian Christians are non-Malay Bumiputera, ranging from Iban, Bidayuh, Orang Ulu and Melanau. Islam is the second largest religion in Sarawak. Many Muslims are from Malay, Melanau, and Kedayan ethnic groups. Buddhism is the third largest, predominantly practised by Chinese Malaysians. Taoism and Chinese Folk Religion are together the fourth largest religious group, also represented by ethnic Chinese. Other minor religions in Sarawak are Baha'i, Hinduism, Sikhism, and animism. Many Dayaks especially the Ibans, continue to practice their ethnic religion, particularly with dual marriage rites and during the important harvest and ancestral festivals such as Gawai Dayak, Gawai Kenyalang and Gawai Antu. Other ethnics who have trace number of animism followers are Melanau and Bidayuh.
Government.
The parliament of Sarawak is the Sarawak State Legislative Assembly.
Politics of Sarawak.
The first political party, Sarawak United Peoples' Party (SUPP) was established in 1959 followed by Parti Negara Sarawak (PANAS) in 1960, and Sarawak National Party (SNAP) in 1961. Other parties such as Barisan Ra'ayat Jati Sarawak (BARJASA), Sarawak Chinese Association (SCA), and Parti Pesaka Sarawak (PESAKA) later appeared by 1962.
Sarawak has been a political stronghold of ruling Alliance Party and later Barisan Nasional (BN) coalition since its independence in 1963. Stephen Kalong Ningkan (SNAP) was the first Chief Minister of Sarawak from 1963 to 1966 following his landslide winnings of three tier system of local authority elections. He was later ousted in 1966 by Tawi Sli (PESAKA) with the help of Malaysian federal government, causing 1966 Sarawak constitutional crisis.
Sarawak political climate was stable since then until the Ming Court Affair which lasted from 1987 to 1991. Ming Court Affair was a political coup initiated by Abdul Taib Mahmud's uncle in order to topple the Taib led Sarawak BN coalition. However, the coup was unsuccessful and Taib was able to retain his chief minister post. The issue of human rights of Penan and deforestation in Sarawak became an international environmental issue when Swiss activist Bruno Manser entered Sarawak from 1984 until 2000 where he brought himself into direct conflict with the Sarawak state government.
The year 1970 saw the completion the first Sarawak state election where members of Council Negri (now Sarawak State Legislative Assembly) was directly elected by the voters. This election also marks the beginning of ethnic Melanau domination in Sarawak politics at first by Abdul Rahman Ya'kub and followed by his nephew Abdul Taib Mahmud. In the same year, North Kalimantan Communist Party (NKCP) was formed which mounted guerilla warfare against the newly elected Sarawak state government. The party was dissolved after the signing of peace agreement in 1990. The year 1973 saw the demise of SCA after it was booted out by the government coalition and the birth of Parti Pesaka Bumiputera Bersatu (PBB). PBB was formed by the merger of three parties namely PANAS, BARJASA, and PESAKA. This party would later become the backbone of Sarawak BN coalition, currently holding 35 out of 71 state assembly seats after 2011 Sarawak state election.
A splinter party named Parti Bansa Dayak Sarawak (PBDS) broke off from SNAP in 1983 due to leadership tussle. PBDS would later dissolved in 2004 also due to another leadership crisis. Parti Rakyat Sarawak (PRS), a splinter party from PBDS, was formed after that in 2004. PRS is currently a component party in Barisan Nasional (BN). SNAP was deregistered in 2002. Sarawak Progressive Democratic Party (SPDP), another splinter party from SNAP, was formed after that in 2002 which would later become a component party of BN. The SNAP deregistration would later be reversed by Court of Appeal in June 2010. However, the revival was short-lived. SNAP was deregistered again in January 2013 by the verdict of Federal Court of Malaysia. In 2010, another splinter party named Sarawak Workers Party (SWP) emerged to absorb dissidents from PRS. In 2014, Parti Tenaga Rakyat Sarawak (Teras) was formed following a split in SUPP, a component party in BN coalition.
In 1978, Democratic Action Party (DAP) was the first Peninsular-based party to open its branches in Sarawak. This party derived majority of its support from urban centres such as Miri, Bintulu, Sibu, and Kuching since 2006 state election and become the largest opposition party in Sarawak, currently holding 12 out of 71 state assembly seats. In 2010, it forms Pakatan Rakyat coalition with Parti Keadilan Rakyat (PKR) and Parti Islam Se-Malaysia (PAS) where the latter 2 parties entered Sarawak only between 1996 and 2001. Sarawak is the only state in Malaysia where Peninsular-based component parties in BN coalition especially UMNO has not entered Sarawak.
Administrative divisions.
Unlike other states in Malaysia, Sarawak is divided into divisions rather than districts. Each division is headed by one resident. Currently, the state been divided into 12 divisions:
Limbang 
Miri 
Bintulu 
Kapit 
Sibu 
Mukah 
Sarikei 
Betong 
Sri Aman 
Samarahan 
Kuching 
Serian 
  Limbang
  Miri
  Bintulu
  Kapit
  Sibu
  Mukah
  Sarikei
  Betong
  Sri Aman
  Samarahan
  Kuching
  Serian
Administrative districts.
The divisions are further divided into districts, each of which is headed by a district officer; and each district is divided into sub-districts, which every sub-districts headed by an administrative officer. Currently, there are around 32 districts in the state.
Energy.
The state of Sarawak has introduced the Sarawak Corridor of Renewable Energy (SCORE), a new development corridor launched on 11 February 2008. It is one of the five regional development corridors throughout Malaysia that aims to transform Sarawak into a developed state by 2020 by accelerating the state's economic growth, as well as improving the quality of life for the people of Sarawak.
Overseas interest is key to the development of SCORE with investment in the aluminium, the polysilicon, and minerals-based industries as well as agriculture including aquaculture and halal.
Focusing on five major growth nodes, Tanjung Manis, Samalaju, Mukah, Baram, and Tunoh, SCORE singles out 10 key industries for development. These include tourism, oil, aluminium, metals, glass, fishing, aquaculture, livestock, forestry, ship building and palm oil. Investors are being drawn to the region because it is rich in energy resources, with an energy potential of 28,000 MW, of which 20,000 MW are in hydropower, 5,000 MW in coal-fired plants, and the remaining 3,000 MW in other energy sources including biofuel. This allows Sarawak to price its energy competitively and encourage investments in power generation and energy-intensive industries that will stimulate strong industrial development in the corridor.
SCORE is developing a vast area that stretches 320 kilometres along Sarawak’s coast from Tanjung Manis to Samalaju and extends all the way into the extensive and remote hinterlands where two rural growth nodes, Baram and Tunoh, will also be developed. To connect urban centres across the central region with the rest of Sarawak, new roads will be created to provide more efficient transport of goods, access to resources and human capital.
According to environmental initiatives like , the targeted construction of 50 hydroelectric dams will seriously effect Sarawak's natural environment and wildlife: the Baram dam alone would flood 400 square kilometres of forest and farmland and 20,000 native people would have to be resettled.
Economy.
Sarawak has an abundance of natural resources. LNG and petroleum have provided the mainstay of the Malaysia federal government's economy for decades while the State of Sarawak only gets a 5% royalty share from it. Sarawak is also one of the world's largest exporters of tropical hardwood timber and is the major contributor to Malaysian exports. The last UN statistics estimated Sarawak's sawlog exports at an average of 14,109,000 m³ between 1996 and 2000. In 2010, Sarawak had the 3 third largest state economy in Malaysia after Selangor and Johor with a total nominal GDP of RM 50,804M (USD$16,542M). Sarawak is also the 2nd largest state in terms of GDP per capita after Penang with RM 33,307.00 (USD$10,845.00) in 2010.
Tourism.
Tourism plays a major role in the state's economy. In 2012, Sarawak was visited by 4 million tourists, both international and domestic. As for 2013, the state is targeting 6 million visitors. This is in line with more direct flights from countries such as Japan and South Korea. The Sarawak Hornbill Tourism Award is held each year to appreciate the best in the tourism sector of the state. Some of the most popular tourist attractions are Kuching city, Gunung Mulu National Park, the Rainforest World Music Festival (RWMF) and many more. The RWMF is the region's premier "world music" event, attracting more than 20,000 music fans. Malaysia will showcase the Sarawak tourism industry in 2014 when it hosts the ASEAN Tourism Forum in Kuching, the Sarawak state capital. It will be the first international tourism event in Malaysia for 2014 and will bring together tourism ministers and heads of national tourism organisations from ASEAN and the region.
Environment.
Agriculture, logging, and land usage.
Sarawak's rainforests have been gradually depleted by the demand driven by the logging industry and the following introduction of palm oil plantations. They possibly are going to be destroyed by 2020. Many of Sarawak's rural communities have felt changes affected by the economic activity of these industries. Peaceful protests and timber blockades between native communities and logging companies are common, often resulting in preventive police action. The Penan, Borneo's nomadic hunter-gatherers have been most affected by these changes, complaining of illness through polluted rivers, game depletion resulting in widespread hunger and loss of traditional medicines and forest products. Their resistance to logging companies culminated in a series of protests and timber blockades in the 1990s, of which many were dismantled by the Police, within the remit of the law. The Penan claim that their rights are not respected by the State nor by logging companies. Another example, the native customary rights court case of Rumah Nor in the Kemena Basin gave rural communities engaged in subsistence farming hope for continued communal use of land reserves. Although the Court of Appeal ruled against Rumah Nor on the grounds that they had not produced sufficient evidence for their claim, it nevertheless upheld the principles stated by the lower court. These principles are the basis of not only Rumah Nor's claim, but of the claims of all Sarawak's native communities as that native customary rights are not created by legislation, although they can be extinguished by legislation, on condition of adequate compensation, and these communities have a territory including forest reserves and rivers, and farmland, including land under fallow. Thus although the Court of Appeal ruled against Rumah Nor's specific claims, it upheld the lower court's ruling in favour of Rumah Nor with regard to the general principles.
Malaysia's deforestation rate is increasing faster than anywhere else in the world. Statistics estimate Sarawak's forests have been depleted but there is no definitive study to know how much. Malaysia's deforestation rates overall are among the highest in Asia, jumping almost 86 percent between the 1990–2000 period and 2000–2005. In total, Malaysia lost an average of 1,402 km2 —0.65 percent of its forest area—per year since 2000. The rainforest is the habitat of endangered animals, including borneo pygmy elephant, proboscis monkey, orangutans and rhinoceroses.
Conservation.
The Sarawak government announced that they are stepping up their effort for wildlife conservation and protection. A programme has been put in place by Sarawak government to save the flora and fauna affected by the construction of the Bakun Dam. Other programmes include the Heart 2 Heart orangutan campaign which invites the public to get involved with orangutan conservation; orang-utan and turtle adoption; protection of the dugong and the Irrawaddy dolphin, which are both endangered species; and the Reef Ball project that will rehabilitate Sarawak's ocean ecosystem by placing artificial reef modules in the sea to form new habitats.
In 1992, International Tropical Timber Organization (ITTO) also financed the establishment of Lanjak Entimau Wildlife Sanctuary which now houses about 4000 orangutans. This wildlife sanctuary also aimed to improve the livelihood of the rural population and to reduce their dependence on forests.
Places of interest.
The Gunung Mulu National Park is home to one of the longest networks of caves in the world and the world's largest underground chamber, the Sarawak Chamber. Key attractions include Deer Cave and Clear Water Cave. The massive caves here are home to millions of bats and cave swiftlets.
Known as the 'Living Museum', the Sarawak Cultural Village was set up to preserve and showcase Sarawak's cultural heritage. Get introduced to local culture and lifestyle by the approximately 150 people living in the village through the demonstration of daily living. The village also has a theatre, where you can enjoy multicultural dance performances.
Bako National Park is Sarawak's oldest park, established in 1957 and covers and area of 27 km2. Known for its extraordinary natural scenery, habitats, plants and wild life, it is also the home to approximately 275 rare proboscis monkeys, found only in Borneo.
The Gunung Gading National Park is the home to the spectacular Rafflesia, the largest flower in the world that can grow up to one metre in diameter. Originally a closed conservation zone, the park opened to the public in 1994 while being closely watched by the National Parks Department.
The Matang Wildlife Centre is a large enclosed area of rainforest and home to endangered wildlife with a training programme to teach Orang Utans, who have been orphaned or rescued from captivity, how to survive in the wild. There are also Sun Bears, Sambar Deer, Civet cats as well as three large aviaries that house Sea Eagles, Hornbills and other birds.
The Niah National Park covers a vast swathe of 3,140 hectares of peat swamp, dipterocarp forests, as well as the massive limestone outcroppings within which the giant Niah caves are concealed. In 1958, archaeologists discovered evidence of human occupation of the caves dating back some 40,000 years.
Similajau National Park was gazetted in 1978, and covers 7,064 hectares of virgin coastal forest, starting from Sungai Likau in the south to Similajau River in the north. It is abundant in flora and fauna with 24 recorded species of mammals, such as gibbons, banded langurs and long-tailed macaques, and 230 species of birds, which include hornbills and migratory water birds like Storms Stork.
The main attraction of the Lambir Hills National Park is its beautiful waterfalls, which are the Latak Waterfall, Pantu Waterfall, Nibong Waterfall, Pancur Waterfall, Tengkorong Waterfall and Dinding Waterfall. There are around 1,173 tree species in the park alone, with 286 genera and 81 tree families. Wild animals can also be found in the deeper parts of the park, especially monkeys, sun bear, pangolin and bats.
The Kuching Cat Museum hosts 2000 exhibits, artefacts, statues about cats from all over the world. It is owned by the Kuching North City Hall (DBKU).

</doc>
<doc id="28259" url="http://en.wikipedia.org/wiki?curid=28259" title="Seneca">
Seneca

Seneca may refer to:

</doc>
<doc id="28260" url="http://en.wikipedia.org/wiki?curid=28260" title="Sonnet">
Sonnet

A sonnet is a poetic form which originated in Italy; Giacomo Da Lentini is credited with its invention.
The term "sonnet" is derived from the Italian word "sonetto" (from Old Provençal "sonet" a little poem, from "son" song, from Latin "sonus" a sound). By the thirteenth century it signified a poem of fourteen lines that follows a strict rhyme scheme and specific structure. Conventions associated with the sonnet have evolved over its history.
Writers of sonnets are sometimes called "sonneteers", although the term can be used derisively.
Italian (Petrarchan) sonnet.
The sonnet was created by Giacomo da Lentini, head of the Sicilian School under Emperor Frederick II. Guittone d'Arezzo rediscovered it and brought it to Tuscany where he adapted it to his language when he founded the Neo-Sicilian School (1235–1294). He wrote almost 250 sonnets. Other Italian poets of the time, including Dante Alighieri (1265–1321) and Guido Cavalcanti (c. 1250–1300), wrote sonnets, but the most famous early sonneteer was Petrarca (known in English as Petrarch). Other fine examples were written by Michelangelo. 
The structure of a typical Italian sonnet of the time included two parts that together formed a compact form of "argument". First, the octave (two quatrains), forms the "proposition", which describes a "problem", or "question", followed by a sestet (two tercets), which proposes a "resolution". Typically, the ninth line initiates what is called the "turn", or "volta", which signals the move from proposition to resolution. Even in sonnets that don't strictly follow the problem/resolution structure, the ninth line still often marks a "turn" by signaling a change in the tone, mood, or stance of the poem.
Later, the "abba, abba" pattern became the standard for Italian sonnets. For the sestet there were two different possibilities: "cdd, cde" and "cdc, cdc". In time, other variants on this rhyming scheme were introduced, such as "cdcdcd". Petrarch typically used an "abba, abba" pattern for the octave, followed by either "cde, cde" or "cdc, cdc" rhymes in the sestet. (The symmetries ("abba" vs. "cdc") of these rhyme schemes have also been rendered in musical structure in the late 20th century composition "Scrivo in Vento" inspired by Petrarch's Sonnet 212, "Beato in Sogno". ))
In English, both English type (Shakespearean) sonnets and Italian type (Petrarchan) sonnets are traditionally written in iambic pentameter lines.
The first known sonnets in English, written by Sir Thomas Wyatt and Henry Howard, Earl of Surrey, used this Italian scheme, as did sonnets by later English poets including John Milton, Thomas Gray, William Wordsworth and Elizabeth Barrett Browning. Early twentieth-century American poet Edna St. Vincent Millay also wrote most of her sonnets using the Italian form. 
This example, "On His Blindness" by Milton, gives a sense of the Italian rhyming scheme: 
<poem style="margin-left: 2em">
When I consider how my light is spent (a)
 Ere half my days, in this dark world and wide, (b)
 And that one talent which is death to hide, (b)
 Lodged with me useless, though my soul more bent (a)
To serve therewith my Maker, and present (a)
 My true account, lest he returning chide; (b)
 "Doth God exact day-labor, light denied?" (b)
 I fondly ask; but Patience to prevent (a)
That murmur, soon replies, "God doth not need (c)
 Either man's work or his own gifts; who best (d)
 Bear his mild yoke, they serve him best. His state (e)
Is Kingly. Thousands at his bidding speed (c)
 And post o'er land and ocean without rest; (d)
 They also serve who only stand and wait." (e)
</poem>
Dante's variation.
Most Sonnets in Dante's "La Vita Nuova" are Petrarchan. Chapter VII gives sonnet "O voi che per la via", with two sestets (AABAAB AABAAB) and two quatrains (CDDC CDDC), and Ch. VIII, "Morte villana", with two sestets (AABBBA AABBBA) and two quatrains (CDDC CDDC).
Occitan sonnet.
The sole confirmed surviving sonnet in the Occitan language is confidently dated to 1284, and is conserved only in troubadour manuscript "P", an Italian chansonnier of 1310, now XLI.42 in the Biblioteca Laurenziana in Florence. It was written by Paolo Lanfranchi da Pistoia and is addressed to Peter III of Aragon. It employs the rhyme scheme "a-b-a-b, a-b-a-b, c-d-c-d-c-d". This poem is historically interesting for its information on north Italian perspectives concerning the War of the Sicilian Vespers, the conflict between the Angevins and Aragonese for the Sicily. Peter III and the Aragonese cause was popular in northern Italy at the time and Paolo's sonnet is a celebration of his victory over the Angevins and Capetians in the Aragonese Crusade: 
An Occitan sonnet, dated to 1321 and assigned to one "William of Almarichi", is found in Jean de Nostredame and cited in Giovanni Crescembeni, "Storia della volgar Poesia". It congratulates Robert of Naples on his recent victory. Its authenticity is dubious. There are also two poorly regarded sonnets by the Italian Dante de Maiano.
English (Shakespearean) sonnet.
When English sonnets were introduced by Thomas Wyatt in the early 16th century, his sonnets and those of his contemporary the Earl of Surrey were chiefly translations from the Italian of Petrarch and the French of Ronsard and others. While Wyatt introduced the sonnet into English, it was Surrey who gave it a rhyming meter, and a structural division into quatrains of a kind that now characterizes the typical English sonnet. Having previously circulated in manuscripts only, both poets' sonnets were first published in Richard Tottel's "Songes and Sonnetts," better known as Tottel's Miscellany (1557).
It was, however, Sir Philip Sidney's sequence "Astrophel and Stella" (1591) that started the English vogue for sonnet sequences. The next two decades saw sonnet sequences by William Shakespeare, Edmund Spenser, Michael Drayton, Samuel Daniel, Fulke Greville, William Drummond of Hawthornden, and many others. This literature is often attributed to the Elizabethan Age and known as Elizabethan sonnets. These sonnets were all essentially inspired by the Petrarchan tradition, and generally treat of the poet's love for some woman, with the exception of Shakespeare's sequence of 154 sonnets. The form is often named after Shakespeare, not because he was the first to write in this form but because he became its most famous practitioner. The form consists of fourteen lines structured as three quatrains and a couplet. The third quatrain generally introduces an unexpected sharp thematic or imagistic "turn", the volta. In Shakespeare's sonnets, however, the volta usually comes in the couplet, and usually summarizes the theme of the poem or introduces a fresh new look at the theme. With only a rare exception, the meter is iambic pentameter, although there is some accepted metrical flexibility (e.g., lines ending with an extra-syllable feminine rhyme, or a trochaic foot rather than an iamb, particularly at the beginning of a line). The usual rhyme scheme is end-rhymed "a-b-a-b, c-d-c-d, e-f-e-f, g-g". 
This example, Shakespeare's "Sonnet 116", illustrates the form (with some typical variances one may expect when reading an Elizabethan-age sonnet with modern eyes):
<poem style="margin-left: 2em">
Let me not to the marriage of true minds (a)
Admit impediments, love is not love (b)*
Which alters when it alteration finds, (a)
Or bends with the remover to remove. (b)*
O no, it is an ever fixèd mark (c)** 
That looks on tempests and is never shaken; (d)***
It is the star to every wand'ring bark, (c)**
Whose worth's unknown although his height be taken. (d)***
Love's not time's fool, though rosy lips and cheeks (e)
Within his bending sickle's compass come, (f)*
Love alters not with his brief hours and weeks, (e)
But bears it out even to the edge of doom: (f)*
</poem>
"* "<br>
"** <br>
"*** "<br>
The Prologue to "Romeo and Juliet" is also a sonnet, as is Romeo and Juliet's first exchange in Act One, Scene Five, lines 104–117, beginning with "If I profane with my unworthiest hand" (104) and ending with "Then move not while my prayer's effect I take" (117).
In the 17th century, the sonnet was adapted to other purposes, with John Donne and George Herbert writing religious sonnets, and John Milton using the sonnet as a general meditative poem. Both the Shakespearean and Petrarchan rhyme schemes were popular throughout this period, as well as many variants.
The fashion for the sonnet went out with the Restoration, and hardly any sonnets were written between 1670 and Wordsworth's time. However, sonnets came back strongly with the French Revolution. Wordsworth himself wrote hundreds of sonnets, of which amongst the best-known are "Upon Westminster Bridge", "The world is too much with us" and the sonnet "London, 1802" addressed to Milton; his sonnets were essentially modelled on Milton's. Keats and Shelley also wrote major sonnets; Keats's sonnets used formal and rhetorical patterns inspired partly by Shakespeare, and Shelley innovated radically, creating his own rhyme scheme for the sonnet "Ozymandias". Sonnets were written throughout the 19th century, but, apart from Elizabeth Barrett Browning's "Sonnets from the Portuguese" and the sonnets of Dante Gabriel Rossetti, there were few very successful traditional sonnets. In Canada during the last decades of the century, the Confederation Poets and especially Archibald Lampman were known for their sonnets, which were mainly on pastoral themes. Gerard Manley Hopkins wrote several major sonnets, often in sprung rhythm, such as "The Windhover", and also several sonnet variants such as the 10½-line curtal sonnet "Pied Beauty" and the 24-line caudate sonnet "That Nature is a Heraclitean Fire". By the end of the 19th century, the sonnet had been adapted into a general-purpose form of great flexibility. 
This flexibility was extended even further in the 20th century. Among the major poets of the early Modernist period, Robert Frost, Edna St. Vincent Millay and E. E. Cummings all used the sonnet regularly. William Butler Yeats wrote the major sonnet "Leda and the Swan", which used half rhymes. Wilfred Owen's sonnet "Anthem for Doomed Youth" was another sonnet of the early 20th century. W. H. Auden wrote two sonnet sequences and several other sonnets throughout his career, and widened the range of rhyme-schemes used considerably. Auden also wrote one of the first unrhymed sonnets in English, "The Secret Agent" (1928). Robert Lowell wrote five books of unrhymed "American sonnets", including his Pulitzer Prize-winning volume "The Dolphin" (1973). Half-rhymed, unrhymed, and even unmetrical sonnets have been very popular since 1950; perhaps the best works in the genre are Seamus Heaney's "Glanmore Sonnets" and "Clearances," both of which use half rhymes, and Geoffrey Hill's mid-period sequence "An Apology for the Revival of Christian Architecture in England". The 1990s saw something of a formalist revival, however, and several traditional sonnets have been written in the past decade.
Spenserian sonnet.
A variant on the English form is the Spenserian sonnet, named after Edmund Spenser (c.1552–1599), in which the rhyme scheme is "abab, bcbc, cdcd, ee". A Spenserian sonnet does not appear to require that the initial octave set up a problem that the closing sestet answers, as with a Petrarchan sonnet. Instead, the form is treated as three quatrains connected by the interlocking rhyme scheme and closed by a couplet. The linked rhymes of his quatrains suggest the linked rhymes of such Italian forms as terza rima. This example is taken from "Amoretti":
<poem style="margin-left: 2em">
"Happy ye leaves! whenas those lily hands"
Happy ye leaves. whenas those lily hands, (a) 
Which hold my life in their dead doing might, (b)
Shall handle you, and hold in love's soft bands, (a)
Like captives trembling at the victor's sight. (b)
And happy lines on which, with starry light, (b)
Those lamping eyes will deign sometimes to look,(c) 
And read the sorrows of my dying sprite, (b)
Written with tears in heart's close bleeding book. (c)
And happy rhymes! bathed in the sacred brook (c)
Of Helicon, whence she derived is, (d)
When ye behold that angel's blessed look, (c)
My soul's long lacked food, my heaven's bliss. (d)
Leaves, lines, and rhymes seek her to please alone, (e) 
Whom if ye please, I care for other none. (e)
</poem>
Urdu Sonnet.
In the Indian subcontinent, sonnets have been written in the Assamese, Bengali, Dogri, English, Gujarati, Hindi, Kashmiri, Malayalam, Manipuri, Marathi, Nepali, Oriya, Sindhi and Urdu languages.Urdu poets, also influenced by English and other European poets, took to writing sonnets in the Urdu language rather late. Azmatullah Khan (1887–1923) is believed to have introduced this format to Urdu literature in the very early part of the 20th century. The other renowned Urdu poets who wrote sonnets were Akhtar Junagarhi, Akhtar Sheerani, Noon Meem Rashid, Mehr Lal Soni Zia Fatehabadi, Salaam Machhalishahari and Wazir Agha. This example, a sonnet by Zia Fatehabadi taken from his collection "Meri Tasveer", is in the usual English (Shakespearean) sonnet rhyme-scheme.
<poem>
 ڈبکںی
پسِ پردہ کِسی نے میرے ارمانوں کی محفِل کو،
کچھ اِس انداز سے دیکھا، کچھ ایسے طور سے دیکھا،
غُبارِ آہ سے دے کر جلا آئینۂ دل کو، 
ہر اِک صورت کو میں نے خوب دیکھا، غور سے دیکھا 
نظر آئی نہ وہ صورت ، مجھے جس کی تمنّا تھی 
بہت ڈھُونڈا کیا گلشن میں، ویرانے میں، بستی میں 
منّور شمعِ مہر و ماہ سے دِن رات دُنیا تھی 
مگر چاروں طرف تھا گُھپ اندھیرا میری ہستی میں 
دلِ مجبور کو مجروحِ اُلفت کر دیا کِس نے
مرے احساس کی گہرایوں میں ہے چُبھن غم کی 
مٹا کر جسم، میری روح کو اپنا لیا کس نے 
جوانی بن گئی آما جگہ صدماتِ پیہم کی 
حجاباتِ نظر کا سلسلہ توڈ اور آ بھی جا 
مجھے اِک بار اپنا جلوۂ رنگیں دکھا بھی جا 
</poem>
”
 Sonnet 'Dubkani' ڈبکںی by Zia Fatehabadi taken from his book titled "Meri Tasveer"
Modern sonnet.
With the advent of free verse, the sonnet was seen as somewhat old-fashioned and fell out of use for a time among some schools of poets. However, a number of modern poets, including Federico García Lorca, E.E. Cummings, Joan Brossa, Paul Muldoon and Seamus Heaney continued to use the form. Elizabeth Bishop's inverted "Sonnet" was one of her last poems. Ted Berrigan's book, "The Sonnets", is an arresting and curious take on the form. Paul Muldoon often experiments with 14 lines and sonnet rhymes, though without regular sonnet meter. The advent of the New Formalism movement in the United States has also contributed to contemporary interest in the sonnet. The sonnet sees its revival with the word sonnet. Concise and visual in effect, word sonnets are fourteen line poems, with one word per line. Frequently allusive and imagistic, they can also be irreverent and playful. The Canadian poet Seymour Mayne published a few collections of word sonnets, and is one of the chief innovators of the form. Contemporary word sonnets combine a variation of styles often considered to be mutually exclusive to separate genres, as demonstrated in works such as . Also, the contemporary Greek poet Yannis Livadas invented the "fusion sonnet", consisting of 21 lines, essentially a variable half of a "jazz" sonnet, accompanied by a half sonnet as a coda. Both parts of the poem appear as a whole in a dismantled form of a series of 3, 2, 4, 3, 4, and 5-lined stanzas.

</doc>
<doc id="28261" url="http://en.wikipedia.org/wiki?curid=28261" title="Samba">
Samba

Samba (]) is a Brazilian musical genre and dance style originating in Brazil, with its roots in Africa via the West African slave trade and African religious traditions, particularly Angola and the Congo. Although there were various forms of samba in Brazil in the form of various popular rhythms and regional dances that originated from the drumming, samba as music genre is seen as a musical expression of urban Rio de Janeiro, then the capital of Imperial Brazil.
It is recognized around the world as a symbol of Brazil and the Brazilian Carnival. Considered one of the most popular Brazilian cultural expressions, samba has become an icon of Brazilian national identity.
The Bahian Samba de Roda (dance circle), which became a UNESCO Heritage of Humanity in 2005, is the main root of the "samba carioca", the samba that is played and danced in Rio de Janeiro.
The modern samba that emerged at the beginning of the 20th century is predominantly in a 2/4 tempo varied with the conscious use of a sung chorus to a batucada rhythm, with various stanzas of declaratory verses. Traditionally, the samba is played by strings (cavaquinho and various types of guitar) and various percussion instruments such as tamborim. Influenced by American orchestras in vogue since the Second World War and the cultural impact of US music post-war, samba began to use trombones, trumpets, choros, flutes, and clarinets.
In addition to distinct rhythms and meters, samba brings a whole historical culture of food, varied dances (miudinho, coco, samba de roda, and pernada), parties, clothes such as linen shirts, and the Naif painting of established names such as Nelson Sargento, Guilherme de Brito, and Heitor dos Prazeres. Anonymous community artists, including painters, sculptors, designers, and stylists, make the clothes, costumes, carnival floats, and cars, opening the doors of schools of samba. There is also a great tradition of ballroom samba in Brazil, with many styles. Samba de Gafieira is the style more famous in Rio de Janeiro, where common people used to go to the gafieira parties since the 1930s, and where the moves and identity of this dance has emerged, getting more and more different from its African, European, Argentinian and Cuban origins and influences.
The Samba National Day is celebrated on December 2. The date was established at the initiative of Luis Monteiro da Costa, an Alderman of Salvador, in honor of Ary Barroso. He composed "Na Baixa do Sapateiro" even though he had never been in Bahia. Thus 2 December marked the first visit of Ary Barroso to Salvador. Initially, this day was celebrated only in Salvador, but eventually it turned into a national holiday.
Samba is a local style in Southeastern Brazil and Northeast Brazil, especially in Rio de Janeiro, São Paulo, Salvador and Belo Horizonte. Its importance as Brazil's national music transcends region, however; samba schools, samba musicians and carnival organizations centered around the performance of samba exist in every region of the country, even though other musical styles prevail in various regions (for instance, in Southern Brazil, Center-West Brazil, and all of the Brazilian countryside, Sertanejo, or Brazilian country music, is the most popular style). Since Rio de Janeiro is the most popular Brazilian city worldwide, usually samba is used to identify Brazilians as part of the same national culture.
Etymology.
There are several theories about the origin of the word samba. One of them claims that samba came from the word "Zumba" or "Zamba", both coming from Arabic, from when the Moors conquered the Iberian Peninsula in the 8th century. Another theory says it originated from one of several African languages, possibly the Kimbundu, and the Kimbundu "semba" (a dance form and music style that was one of the forerunners of samba). The word "semba" comes from the singular "Masemba" which mean “a touch of the bellies,” a move that also characterizes the Semba dance. Semba can have the meaning of “Umbigada” which describes a dance movement when the contact between the two bodies is provoked by the man who suddenly takes the woman on the hip and brings her towards his belly button. Other writers have suggested that "semba" designated a circle dance. In Brazil, folklorists have also suggested that the word samba is a corruption of the Kikongo word "Semba", translated as "umbigada" in Portuguese, meaning "a blow struck with the belly button".
One of the oldest records of the word samba appeared in Pernambuco magazine's "O Carapuceiro", dated February 1838, when Father Miguel Lopes Gama of Sacramento wrote against what he called "teh samba d'almocreve" – not referring to the future musical genre, but a kind of merriment (dance drama) popular for black people of that time. According to Hiram Araújo da Costa, over the centuries, the festival of dances of slaves in Bahia were called samba.
In the middle of the 19th century, the word samba defined different types of music made by African slaves when conducted by different types of Batuque, but it assumed its own characteristics in each Brazilian state, not only by the diversity of tribes for slaves, but also the peculiarity of each region in which they were settlers. Some of these popular dances were known as bate-baú, samba-corrido, samba-de-roda, samba-de-Chave and samba-de-barravento in Bahia; coco in Ceará; tambor-de-crioula (or ponga) in Maranhão; trocada, coco-de-parelha, samba de coco and soco-travado in Pernambuco; bambelô in Rio Grande do Norte; partido-alto, miudinho, jongo and caxambu in Rio de Janeiro; and samba-lenço, samba-rural, tiririca, miudinho, and jongo in São Paulo.
In Argentina, there is a dance called "Zamba", a name which seems to share etymological origins with the Samba, though the dance itself is quite different.
History.
Origins of the Samba.
Although samba exists throughout Brazil – especially in the states of Bahia, Maranhão, Minas Gerais, and São Paulo – in the form of various popular rhythms and dances that originated from the regional batuque, a type of music and associated dance form from Cape Verde, the samba is most frequently identified as a musical expression of urban Rio de Janeiro, where it was born and developed between the end of the 19th century and the first years of the 20th century. Early styles of samba - and specifically samba de roda - are traced back to the Recôncavo region of Bahia during the 17th century, and the informal dancing following a candomblé ceremony. It was in Rio that the dance practiced by former slaves who migrated from Bahia came into contact with and incorporated other genres played in the city (such as the polka, the maxixe, the lundu, and the xote), acquiring a completely unique character and creating the "samba carioca urbana" (samba school) and "carnavalesco" (Carnaval school director). Samba schools are large organizations of up to 5,000 people which compete annually in the Carnival with thematic floats, elaborate costumes, and original music.
During the first decade of the 20th century, some songs under the name of samba were recorded, but these recordings did not achieve great popularity. However, in 1917, "Pelo Telefone" ("Through the Telephone") was recorded, and it is considered the first true samba. The song was claimed to be authored by Ernesto dos Santos, best known as Donga (musician), with co-composition attributed to Mauro de Almeida, a well-known Carnival columnist. Actually, "Pelo Telefone" was created by a collective of musicians who participated in celebrations at the house of Tia Ciata (Aunt Ciata). It was eventually registered by Donga and the Almeida National Library.
"Pelo Telefone" was the first composition to achieve great success with the style of samba and to contribute to the dissemination and popularization of the genre. From that moment on, samba started to spread across the country, initially associated with Carnival and then developing its own place in the music market. There were many composers, including Heitor dos Prazeres, João da Bahiana, Pixinguinha, and Sinhô, but the sambas of these composers were "amaxixados" (a mix of maxixe), known as sambas-maxixes.
The contours of the modern samba came only at the end of the 1920s, from the innovations of a group of composers of carnival blocks in the neighborhoods of Estácio de Sá and Osvaldo Cruz, and the hills of Mangueira, Salgueiro, and São Carlos. Since then, there have been many great names in samba, such as Ismael Silva, Cartola, Ary Barroso, Noel Rosa, Ataulfo Alves, Wilson Batista, Geraldo Pereira, Zé Kéti, Candeia, Ciro Monteiro, Nelson Cavaquinho, Elton Medeiros, Paulinho da Viola, Martinho da Vila, and many others.
As the samba consolidated as an urban and modern expression, it began to be played on radio stations, spreading across the hills and neighborhoods to the affluent southern areas of Rio de Janeiro. Initially viewed with prejudice and discrimination because it had black roots, the samba, because of its hypnotic rhythms and melodic intonations in addition to its playful lyrics, eventually conquered the white middle class as well. Other musical genres derived from samba, such as samba-canção, partido alto, samba-enredo, samba de gafieira, samba de breque, bossa nova, samba-rock, and pagode, have all earned names for themselves.
The samba is frequently associated abroad with football and Carnival. This history began with the international success of Aquarela do Brasil, by Ary Barroso, followed by Carmen Miranda (supported by Getúlio Vargas government and the US Good Neighbor policy), which led samba to the United States. Bossa nova finally entered the country into the world of samba music. Brazilian percussionist and studio musician Paulinho Da Costa, currently based in Los Angeles, incorporates the rhythms and instrumentation of the samba into the albums of hundreds of American, European and Japanese artists — including producer Quincy Jones, jazz performer Dizzy Gillespie, pop singer Michael Jackson and vocalist Barbra Streisand.
The success of the samba in Europe and Japan only confirms its ability to win fans, regardless of their language. Currently, there are hundreds of samba schools held on European soil and scattered among countries like Germany, Belgium, Netherlands, France, Sweden, and Switzerland. Already in Japan, the records invest heavily in the launch of former Sambista's set of discs, which eventually created a market composed solely of catalogs of Japanese record labels.
Favela and Tias Baianas.
From the second half of the 19th century onward, as blacks, mestizas, and ex-soldiers of the War of Canudos in Rio de Janeiro came from various parts of Brazil (mainly Bahia) and settled in the vicinity of Morro da Conceição, Pedra do Sal, Praça Mauá, Praça Onze, Cidade Nova, Saúde, and Zona Portuária. These stands form poor communities that these people called the favelas (later the term became synonymous with the irregular buildings of the poor).
These communities would be the scene of a significant part of Brazilian black culture, particularly with respect to Candomblé and "samba amaxixado" at that time. Among the early highlights were the musician and dancer Hilário Jovino Ferreira—responsible for the founding of several blocks of afoxé and Carnival's ranchos—and "Tias Baianas", a term given to the female descendants of Bahian slaves.
Thus, the samba and musical genre was born in the houses of "Tias Baianas" (Bahian aunts) in the beginning of the 20th century, as a descendant of the style lundu of the candomblé de terreiro parties between umbigada (Samba) and capoeira's pernadas, marked in pandeiro, prato-e-faca (plate-and-knife) and in the "palmas", hand claps. There are some controversies about the word "samba-raiado", one of the first appointments to the samba. It is known that the "samba-raiado" is marked by the sound and accent sertanejos / rural brought by "Tias Baianas" to Rio de Janeiro. According to João da Baiana, the "samba-raiado" was the same as "chula raiada" or samba de partido-alto. For the sambist Caninha, this was the first name would have heard at the home of Tia Dadá. At the same time, there were the "samba-corrido", a line that had more work together with the rural Bahian accent, and the samba-chulado, a more rhyming and melodic style that characterized the urban samba carioca.
By the 1870s, Republican propagandists were attempting to prohibit samba on the pretext that folklorist dances shamed Brazil's national image. It would take the edict of a federal administration to halt the persecution of neighborhood samba groups and to recognize officially their parades. Later, the views of anthropologist Gilberto Freyre, and Getrllio Vargas, who became Brazil's new populist president in 1930, provided the country with fresh perspectives on racial mixing. Under Vargas, samba schools and carnaval parades were supported by the state and quickly established themselves all over Brazil. Samba significantly benefited from these political efforts to create a homogeneous national culture. While certain types of music suggested different racial or class origins, samba dissipated social antagonisms and helped unify a society that varied in its origins, appearance, and ways of living and thinking. Samba's triumph over the airwaves allowed it to penetrate all sectors of Brazilian society.
According to anthropologist Hermano Vianna, configuring Samba as a symbol of Brazilianness was possible thanks to the cultural exchange between the working classes and intellectual elite. He cites a guitar meeting between anthropologist Gilberto Freyre, the historian Sérgio Buarque de Holanda, promoter and journalist Prudente de Moraes Neto, the classical composer Villa Lobos and pianist Lucio Gallet, all representative of the intellectual and cultural elite of white origin on the one hand; and Pixinguinha musician and composers / samba Donga and Patrick Teixeira, from the popular and crossbred layers on the other, saying how the occasion marked the meeting of two different or even opposing groups of Brazilian society.
Scenes in Bahia and São Paulo.
The urban carioca samba is the anchor of 20th century "Brazilian samba" par excellence. However, before this type of samba was to consolidate as the "national samba" in Brazil, there were traditional forms of sambas in Bahia and São Paulo.
The rural Bahia samba acquired additional names as choreographic variations – for example, the "samba-de-chave", where the soloist dancer faking looking "roda" in the middle of a key, and when found, was replaced. The poetic structure of Bahian samba followed the way call-and-response—composed of a single verse, a solo, followed by another, and repeated by the chorus of dancers as the falderal. With no chorus, the samba is called "samba-corrido", which is an uncommon variant. The chants were taken by one singer, one of the musicians, or soloist dancer. Another peculiarity of Bahian samba was a form of competition that dances sometimes presented: it was a dispute between participants to see who performed better. Besides the umbigada, common to all the bahianian samba, the Bahia presented three basic steps: "corta-a-jaca", "separa-o-visgo", and "apanha-o-bag". There is also another choreographic element danced by women: the "miudinho" (this also appeared in São Paulo, as dance solo in the center of the "roda"). The instruments of the Bahian samba were pandeiros, shakers, guitars, and sometimes the castanets and berimbaus.
In São Paulo state, samba became the domain of blacks and caboclos. In rural areas, samba can occur without the traditional umbigada. There are also other choreographic variations—the dancers may be placed in rows with men on one side and women on another. The instruments of the samba paulista were violas and pandeiros. It is possible that the early provision of the "roda", in Goiás, has been modified by the influence of quadrilha or cateretê. According to historian Luís da Câmara Cascudo, it is possible to observe the influence of city in the samba, by the fact that it is also danced by pair connections.
One of the most noticeable groups of São Paulo's samba, Demônios da Garoa (Drizzle's Demons), had a strong link with Adoniran Barbosa, who composed the musics they sang. Musics like "Samba do Arnesto" and "Saudosa Maloca" turned into legendary musics, and nowadays are recognized as "the real Samba Paulistano". This group is still alive, but without the original formation. In 2000, one of their most famous musics, "Trem das Onze", was elected São Paulo's symbol music.
The first decades of the 20th century.
"Pelo Telefone".
Tia Ciata, grandmother of the composer Bucy Moreira, was responsible for the sedimentation of samba carioca. According to the folklore of that time, for a samba musician to achieve success, he would have to pass the house of Tia Ciata and be approved on the "rodas de samba". Many compositions were created and sung in improvisation, where the samba "Pelo Telefone" (from Donga and Mauro de Almeida), samba for which there were also many other versions, but to come to the history of samba, Pelo Telefon was the first person to record Samba in 1917
Meanwhile, other recordings have been done as samba before "Pelo Telefone", as this composition was done by double Donga / Mauro de Almeida, who is regarded as a founder of the genre. Still, the song is written and discussed, and its proximity to the maxixe made it finally be designated samba-maxixe. This section was influenced by maxixe dance and basically played the piano—unlike the Rio samba played in the Morros hills—and the composer has musician Sinhô, self-titled "o rei do samba" ("the king of Samba") which with other pioneers such as Heitor dos Prazeres and Caninha, lay the first foundations of the musical genre.
Turma do Estácio.
The growing shantytowns in the hills of suburban Rio would become the home of new musical talents. Almost simultaneously, the "samba carioca", which was born in the city center, would climb the slopes of the hills and spread outside the periphery, to the point that, over time, it came to be identified as "samba de morro" (samba from the hills).
At the end of the 1920s, the carnival samba of blocks of the districts Estácio de Sá and Osvaldo Cruz was born, and in the hills of Mangueira, Salgueiro, and São Carlos, there were innovations in rhythmic samba that persist until the present day. This group, the "Turma do Estácio", from which would arise "Deixa Falar", was the first samba school in Brazil. Formed by some composers in the neighborhood of Estácio, including Alcebíades Barcellos (aka Bide) Armando Marçal, Ismael Silva, Nilton Bastos and the more "malandros" such as Baiaco, Brancura, Mano Edgar, Mano Rubem, the "Turma do Estácio" marked the history of the Brazilian samba by injecting more pace to the genre one performed, which has the endorsement of the youth's middle class, as the ex-student of law Ary Barroso and former student of medicine Noel Rosa.
Initially a "rancho carnavalesco", then a Carnival's Block, and finally a samba school, the "Deixa Falar" was the first to Rio Carnival parade in the sound of an orchestra made up of percussion surdos, tambourines, and cuícas, who joined pandeiro and shakers. This group was instrumental and is called "bateria", and it lends itself to the monitoring of a type of samba that was quite different from those of Donga, Sinhô, and Pixinguinha. The samba of Estácio de Sá signed up quickly as the samba carioca par excellence.
The "Turma do Estácio" has made the appropriate rhythmic samba were so it could be accompanied in the carnival's parade, thus distancing the progress "samba-amaxixado" of composers such as Sinhô. Moreover, its "rodas" of samba were attended by composers from other Rio hills, as Cartola, Carlos Cachaça, and then Nelson Cavaquinho, e Geraldo Pereira, Paulo da Portela, Alcides Malandro Histórico, Manacéia, Chico Santana, and others. Accompanied by a pandeiro, a tambourine, a cuíca and a surdo, they created and spread the samba-de-morro.
Popularization in the 1930s and 1940s.
After the founding of "Deixa Falar", the phenomenon of the samba schools took over the scene and helped boost Rio's samba subgenera of Partido Alto, singing and challenging in "candomblé terreiros" the samba-enredo.
From the 1930s, the popularization of radio in Brazil helped to spread the samba across the country, mainly the subgenres "samba-canção" and "samba-exaltação". The "samba-canção" was released in 1928 with the recording "Ai, yo-yo" by Aracy Cortes. Also known as "samba half of the year", the "samba-canção" became established in the next decade. It was a slow and rhythmic samba music and had an emphasis on melody and generally easy acceptance. This aspect was later influenced by the rhythms of foreigners, first by foxtrot in the 1940s and then bolero the 1950s. The most famous composers were Noel Rosa, Ary Barroso, Lamartine Babo, Braguinha (also known as João de Barro), and Ataulfo Alves. Other practitioners of this style were Antonio Maria, Custódio Mesquita, Dolores Duran, Fernando Lobo, Ismael Neto, Lupicínio Rodrigues, Batatinha, and Adoniran Barbosa (this latter by sharply satirical doses).
The ideology of Getúlio Vargas's Estado Novo changed the scene of the samba. With "Aquarela do Brasil", composed by Ary Barroso and recorded by Francisco Alves in 1939, the "samba-exaltação" become the first success abroad. This kind of samba was characterized by extensive compositions of melody and patriotic verses. Carmen Miranda popularized samba internationally through her Hollywood films.
With the support of the Brazilian president Getúlio Vargas, the samba won status as the "official music" of Brazil. With this status of national identity came the recognition of the intellectual and classical composer Heitor Villa-Lobos, who arranged a recording with the maestro Leopold Stokowski in 1940, which involved Cartola, Donga, João da Baiana, Pixinguinha, and Zé da Zilda.
Also in the 1940s, there arose a new crop of artists: Francisco Alves, Mário Reis, Orlando Silva, Silvio Caldas, Aracy de Almeida, Dalva de Oliveira, and Elizeth Cardoso, among others. Others such as Assis Valente, Ataulfo Alves, Dorival Caymmi, Herivelto Martins, Pedro Caetano, and Synval Silva led the samba to the music industry.
A new beat in the 1950s: the Bossa Nova.
A movement was born in the southern area of Rio de Janeiro, strongly influenced by jazz, marking the history of samba and Brazilian popular music in the 1950s. The bossa nova emerged at the end of that decade, with an original rhythmic accent which divided the phrasing of the samba and added influences of impressionist music and jazz and a different style of singing which was both intimate and gentle. After precursors such as Johnny Alf, João Donato, and musicians like Luis Bonfá and Garoto, this subgenre was inaugurated by João Gilberto, Tom Jobim, and Vinicius de Moraes. It then had a generation of disciples and followers including Carlos Lyra, Roberto Menescal, Durval Ferreira, and groups like Tamba Trio, Bossa 3, Zimbo Trio, and The Cariocas.
The sambalanço also began at the end of the 1950s. It was a branch of the popular bossa nova (most appreciated by the middle class) which also mingled samba rhythms and American jazz. Sambalanço was often found at suburban dances of the 1960s, 1970s, and 1980s. This style was developed by artists such as Bebeto, Bedeu, Scotland 7, Djalma Ferreira, the Daydreams, Dhema, Ed Lincoln, Elza Soares, and Miltinho, among others. In the 21st century, groups like Funk Como Le Gusta and Clube do Balanço continue to keep this subgenre alive.
Rediscovering of samba's roots in the 1960s and 1970s.
In the 1960s, Brazil became politically divided with the arrival of a military dictatorship, and the leftist musicians of bossa nova started to gather attention to the music made in the "favelas". Many popular artists were discovered at this time. Musicians like Cartola, Nelson Cavaquinho, Guilherme de Brito, Velha Guarda da Portela, Zé Keti, and Clementina de Jesus recorded their first albums during this time.
In the 1970s, samba returned strongly to the air waves with composers and singers like Paulinho da Viola, Martinho da Vila, Clara Nunes, and Beth Carvalho dominating the hit parade. Great samba lyricists like Paulo César Pinheiro (especially in the praised partnership with João Nogueira) and Aldir Blanc started to appear around that time.
Rapprochement with the hill.
With bossa nova, samba is further away from its popular roots. The influence of jazz deepened, and techniques have been incorporated from classical music. From a festival in Carnegie Hall of New York, in 1962, the bossa nova reached worldwide success. But over the 1960s and 1970s, many artists who emerged—like Chico Buarque, Billy Blanco, Martinho da Vila, and Paulinho da Viola—advocated the return of the samba beat in its traditional form. They also wanted veterans like Candeia, Cartola, Nelson Cavaquinho, and Zé Kéti to return. In the early 1960s, the "Movement for Revitalization of Traditional Samba", promoted by Center for Popular Culture, started in partnership with the Brazilian National Union of Students. During the 1960s, some samba groups appeared and were formed by previous experiences with the world of samba and songs recorded by great names of Brazilian music. Among them were The Cinco Crioulos, The Voz do Morro, Mensageiros do Samba, and The Cinco Só.
Outside the main scene of the Brazilian Popular Music festivals, the sambists founded the Bienal do Samba in the late 1960s, and it became the space for the big names of the genre and followers. Even in the final decade, the "samba-empolgação" (samba-excitement) of carnival blocks "Bafo da Onça", "Cacique de Ramos," and "Boêmios de Irajá" came into being.
A fusion: the samba-funk.
Also in the 1960s came the samba funk. The samba-funk emerged at the end of the 1960s with pianist Dom Salvador and his group, which merged the samba with American funk, which was then newly arrived in the Brazil. With the departure of Dom Salvador to the United States, the band broke up, but at the beginning of the 1970s, some ex-members, including Luiz Carlos, José Carlos Barroso, and Oberdan joined Christovao Bastos, Jamil Joanes, Cláudio Stevenson and Lúcio da Silva to form Banda Black Rio. The new group has deepened the work of Don Salvador in the double mixture of the bar with the Brazilian samba funk of the American Quaternary, based on the dynamics of implementation, driven by drums and bass. Even after the Banda Black Rio in the 1980s, British disc jockeys began to play the group's work. It was rediscovered throughout Europe, but mainly in UK and Germany.
Partido-Alto for the masses.
At the turn of the 1960s to the 1970s, the young Martinho da Vila would give a new face to the traditional sambas-enredo established by authors such as Silas de Oliveira and Mano Decio da Viola, compressing them and expanding its potential in the music market. Martin popularized the style of the Partido alto with songs like "Casa de Bamba" and "Pequeno Burguês" and launched his first album in 1969.
Although the term "partido alto" originally arose at the beginning of the 1900s to describe instrumental music, the term came to be used to signify a type of samba which is characterized by a highly percussive beat of pandeiro, using the palm of the hand in the center of the instrument in place. The harmony of Partido alto is always higher in pitch, usually played by a set of percussion instruments (usually surdo, pandeiro, and tambourine) and accompanied by a cavaquinho and/or a guitar.
Also in that decade, some popular singers and composers appeared in the samba, including Alcione, Beth Carvalho, and Clara Nunes. As highlighted in city of São Paulo, Geraldo Filme was one of the leading names in samba paulistano, next to Germano Mathias, Osvaldinho of Cuíca, Tobias da Vai-Vai, Aldo Bueno, and Adoniran Barbosa.
1980s until 1990s.
In the early 1980s, after having been eclipsed by the popularity of disco and Brazilian rock, Samba reappeared in the media with a musical movement created in the suburbs of Rio de Janeiro. It was the "pagode", a renewed samba, with new instruments like the banjo and the tan-tan. It also had a new language that reflected the way that many people actually spoke by including heavy "gíria", or slang. The most popular artists were Zeca Pagodinho, Almir Guineto, Grupo Fundo de Quintal, Jorge Aragão, and Jovelina Pérola Negra.<ref name="cliquemusic/pagode"> (</ref>
In 1995, the world saw one of the most popular Pagode groups, the Gera Samba, later renamed to "É o Tchan", come out from Savador. This group created the most sexual dance of the Pagode during the 1990s, mixing a lot of Axé music in it. Some groups like Patrulha do Samba and Harmonia do Samba, also mixed in a bit of Axé. Samba, as a result, morphed during this period, embracing types of music that were growing popular in the Caribbean such as rap, reggae, and rock. Examples of Samba fusions with popular Caribbean music is samba-rap, samba-rock, and samba-reggae, all of which were efforts to not only entertain, but also to unify all Blacks throughout the Americas culturally and politically via song. In other words, samba-rap and the like often carried lyrics that encouraged Black pride, and spoke out against social injustice. Samba, however, is not accepted by all as the national music of Brazil, or as a valuable art form. Light-skinned "upper-class" Brazilians often associated Samba with dark-skinned blacks because of its arrival from West Africa. As a result, there are some light-skinned Brazilians who claim that samba is the music of low-class, dark-skinned Brazilians and, therefore, is a "thing of bums and bandits".
Samba continued to act as a unifying agent during the 1990s, when Rio stood as a national Brazilian symbol. Even though it was not the capital city, Rio acted as a Brazilian unifier, and the fact that samba originated in Rio helped the unification process. In 1994, the FIFA World Cup had its own samba composed for the occasion, the "Copa 94". The 1994 FIFA World Cup, in which samba played a major cultural role, holds the record for highest attendance in World Cup history. Samba is thought to be able to unify because individuals participate in it regardless of social or ethnic group. Today, samba is viewed as perhaps the only uniting factor in a country fragmented by political division.
The Afro-Brazilians played a significant role in the development of the samba over time. This change in the samba was an integral part of Brazilian nationalism, which was referred to as "Brazilianism".
"What appears to be new is the local response to that flow, in that instead of simply assimilating outside influences into a local genre or movement, the presence of foreign genres is acknowledged
as part of the local scene: samba-rock, samba-reggae, samba-rap.
But this acknowledgment does not imply mere imitation of the foreign
models or, for that matter, passive consumption by national audiences." – Gerard Béhague, "Selected Reports in Ethnomusicology." Pg. 84
Samba in the 21st century.
From the year 2000 onwards, there were some artists who were looking to reconnect the most popular traditions of samba. The cases of Marquinhos of Oswaldo Cruz and Teresa Cristina, were, among others, the ones that contributed to the revitalization of the region of Lapa in Rio de Janeiro. In São Paulo, samba resumed the tradition with concerts in Sesc Pompéia Club and with the work of several groups, including the group Quinteto em Branco e Preto which developed the event "Pagode da Vela" ("Pagoda of Sail"). These all helped to attract many artists from Rio de Janeiro, which has established residence in neighborhoods of the capital paulistana.
Samba was also mixed with Drum and Bass leading to the foundation of Sambass.
In 2004, the minister of culture Gilberto Gil submitted to Unesco an application for declaring samba as a Cultural Heritage of Humanity in the category "Intangible Goods" by the Institute of National Historical and Artistic Heritage. In 2005 the samba-de-roda of Baiano Recôncavo was proclaimed part of the Heritage of Humanity by Unesco, in the category of "Oral and intangible expressions". The Samba is often performed on different dance shows, such as Dancing with the Stars.

</doc>
<doc id="28262" url="http://en.wikipedia.org/wiki?curid=28262" title="Snowboard">
Snowboard

Snowboards are boards that are usually the width of one's foot longways, with the ability to glide on snow. Snowboards are differentiated from monoskis by the stance of the user. In monoskiing, the user stands with feet inline with direction of travel (facing tip of monoski/downhill) (parallel to long axis of board), whereas in snowboarding, users stand with feet transverse (more or less) to the longitude of the board. Users of such equipment may be referred to as "snowboarder"s. "Commercial snowboards" generally require extra equipment such as bindings and special boots which help secure both feet of a snowboarder, who generally rides in an upright position. These types of boards are commonly used by people at ski hills or resorts for leisure, entertainment and competitive purposes in the activity called snowboarding.
History.
In 1939, Vern Wicklund, at the age of 13, fashioned a shred deck in Cloquet, Minnesota. This modified sled was dubbed a “bunker" by Vern and his friends. He, along with relatives Harvey and Gunnnar Burgeson, patented the very first snowboard twenty two years later.
However, a man by the name of Sherman Poppen, from Muskegon, MI, came up with what most consider the first "snowboard" in 1965 and was called the Snurfer (a blend of "snow" and "surfer") who sold his first 4 "snurfers" to Randall Baldwin Lee of Muskegon, MI who worked at Outdoorsman Sports Center 605 Ottawa Street in Muskegon, MI (owned by Justin and Richard Frey or Muskegon). Randy believes that Sherman took an old water ski and made it into the snurfer for his children who were bored in the winter. He added bindings to keep their boots secure. (Randy Lee October 14, 2014) The Snurfer was believed to be fairly simple and had no bindings, but this is debatable. It is widely accepted that Jake Burton Carpenter (founder of Burton Snowboards) and/or Tom Sims (founder of Sims Snowboards) invented modern snowboarding.
In 1981, a couple of Winterstick team riders went to France at the invitation of Alain Gaimard, marketing director at Les Arcs. After seeing an early film of this event, French skiers/surfers Augustin Coppey, Olivier Lehaneur, Olivier Roland and Antoine Yarmola made their first successful attempts during the winter of 1983 in France (Val Thorens), using primitive, home-made clones of the Winterstick. Starting with pure powder, skateboard-shaped wooden-boards equipped with aluminium fins, foot-straps and leashes, their technology evolved within a few years to pressed wood/fiber composite boards fitted with polyethylene soles, steel edges and modified ski boot shells. These were more suitable for the mixed conditions encountered while snowboarding mainly off-piste, but having to get back to ski lifts on packed snow.
In 1985, James Bond popularized snowboarding in the movie "A View to a Kill". In the scene, he escapes Soviet agents who are on skis. The snowboard he used was from the debris of a snowmobile that exploded.
By 1986, although still very much a minority sport, commercial snowboards started appearing in leading French ski resorts.
In 2008, selling snowboarding equipment was a $487 million industry. In 2008, average equipment ran about $540 including board, boots, and bindings.
Board types.
Size and shape variances in the boards accommodate for different snow conditions and riding styles. Shorter boards are typically considered youth size and designed for use by children, though some varieties of short boards are specifically designed for a special purpose, such as the performance of snowboarding tricks. Such tricks may take place in a snowpark alongside freestyle skiers.
The bottom or 'base' of the snowboard is generally made of UHMW. (and is surrounded by a thin strip of steel, known as the 'edge'. Artwork was primarily printed on PBT using a sublimation process in the 1990s, but poor color retention and fade after moderate use moved high-end producers to longer-lasting materials.
Snowboards come in several different styles, depending on the type of riding intended:
Snowboards are generally constructed of a hardwood core which is sandwiched between multiple layers of fibreglass. Some snowboards incorporate the use of more exotic materials such as Carbon Fiber, Kevlar, Aluminium (as a honeycomb core structure), and have even incorporated Piezo dampers. The front (or "nose,") of the board is upturned to help the board glide over uneven snow. The back (or "tail") of the board is also upturned to enable backwards (or "switch") riding. The base (the side of the board which contacts the ground) is made of Polyethylene plastic. The two major types of base construction are Extruded and Sintered. An extruded base is a basic, low-maintenance design which basically consists of the plastic base material melted into its form. A sintered base uses the same material as an Extruded base, but first grinds the material into a powder, then, using heat and pressure, molds the material into its desired form. A sintered base is generally softer than its extruded counterpart, but has a porous structure which enables it to absorb wax. This wax absorption (along with a properly done 'hot wax'), greatly reduces surface friction between the base and the snow, allowing the snowboard to travel on a thin layer of water. Snowboards with sintered bases are much faster, but require semi-regular maintenance and are easier to damage. The bottom-edges of the snowboard are fitted with a thin strip of steel, just a couple of millimeters wide. This steel edge allows the board to grab or 'dig into' hard snow and ice (like the blade of an ice skate), and also protects the boards internal structure. The top of the board is typically a layer of acrylic with some form of graphic designed to attract attention, showcase artwork, or serve the purpose similar to that of any other form of printed media. Flite Snowboards, an early and often underquoted designer, pressed the first closed-molded boards from a garage in Newport, RI in the mid-1980s. Snowboard topsheet graphics can be a highly personal statement and many riders spend many hours customizing the look of their boards. The top of some boards may even include thin inlays with other materials, and some are made entirely of epoxy-impregnated wood. The base of the board may also feature graphics, often designed in a manner to make the board's manufacturer recognizable in photos.
Snowboard designs differ primarily in:
Board construction.
The various components of a snowboard are:
Sustainable Snowboard Manufacturing.
Amongst Climate Change, the winter sports community is a growing environmentalist group, whom depend on snowy winters for the survival of their culture. This movement is, in part, being energized by a nonprofit named "Protect Our Winters" and the legendary rider Jeremy Jones. The organization provides education initiatives, support for community based projects, and is active in climate discussions with the government. Alongside this organization, there are many other winter sports companies who see the ensuing calamity and are striving to produce products that are less damaging to the environment. Snowboard manufacturers are adapting to decreasing supplies of petroleum and timber with ingenious designs.
With human ingenuity, hopefully the snow sports community will continue to help create a future that relies less on petroleum products and deforestation. Because when it comes down to it "the least of our worries will be that skiers and snowboarders don't get to go play," says Jeremy Jones.
Boots.
Snowboard boots are mostly considered soft boots, though alpine snowboarding uses a harder boot similar to a ski boot. A boot's primary function is to transfer the rider's energy into the board, protect the rider with support, and keep the rider's feet warm. A snowboarder shopping for boots is usually looking for a good fit, flex, and looks. Boots can have different features such as lacing styles, heat molding liners, and gel padding that the snowboarder also might be looking for. Tradeoffs include rigidity versus comfort, and built in forward lean, versus comfort.
There are three incompatible types:
Bindings.
Bindings are separate components from the snowboard deck and are very important parts of the total snowboard interface. The bindings' main function is to hold the rider's boot in place tightly to transfer their energy to the board. Most bindings are attached to the board with three or four screws that are placed in the center of the binding. Although a rather new technology from Burton called Infinite channel system uses two screws, both on the outsides of the binding.
There are several types of bindings. Strap-in, step-in, and hybrid bindings are used by most recreational riders and all freestyle riders.
Strap-in.
These are the most popular bindings in snowboarding. Before snowboard specific boots existed, snowboarders used any means necessary to attach their feet to their snowboards and gain the leverage needed for turning. Typical boots used in these early days of snowboarding were Sorels or snowmobile boots. These boots were not designed for snowboarding and did not provide the support desired for doing turns on the heel edge of a snowboard. As a result, early innovators such as Louis Fournier conceived the "high-back" binding design which was later commercialized and patented by Jeff Grell. The highback binding is the technology produced by most binding equipment manufacturers in the snowboard industry. The leverage provided by highbacks greatly improved board control. Snowboarders such as Craig Kelly adapted plastic "tongues" to their boots to provide the same support for toe-side turns that the highback provided for heel-side turns. In response, companies such as Burton and Gnu began to offer "tongues".
With modern strap bindings, the rider wears a boot which has a thick but flexible sole, and padded uppers. The foot is held onto the board with two buckle straps – one strapped across the top of the toe area, and one across the ankle area. They can be tightly ratcheted closed for a tight fit and good rider control of the board. Straps are typically padded to more evenly distribute pressure across the foot. While nowhere near as popular as two-strap bindings, some people prefer three-strap bindings for more specialized riding such as carving. The third strap tends to provide additional stiffness to the binding.
Cap-strap bindings are a recent modification that provide a very tight fit to the toe of the boot, and seats the boot more securely in the binding. Numerous companies have adopted various versions of the cap strap.
Step-in.
Innovators of step-in systems produced prototypes and designed proprietary step-in boot and binding systems with the goal of improving the performance of snowboard boots and bindings, and as a result, the mid-90s saw an explosion of step-in binding and boot development. New companies, Switch and Device, were built on new step-in binding technology. Existing companies Shimano, K2 and Emery were also quick to market with new step-in technology. Meanwhile early market leaders Burton and Sims were noticeably absent from the step-in market. Sims was the first established industry leader to market with a step-in binding. Sims licensed a step-in system called DNR which was produced by the established ski-binding company Marker. Marker never improved the product which was eventually discontinued. Sims never re-entered the step-in market.
The risk of commercial failure from a poorly performing Step-in binding presented serious risk to established market leaders. This was evidenced by Airwalk who enjoyed 30% market share in snowboard boot sales when they began development of their step-in binding system. The Airwalk step-in System experienced serious product failure at the first dealer demonstrations, seriously damaging the company's credibility and heralded a decline in the company's former position as the market leader in Snowboard boots. Established snowboarding brands seeking to gain market share while reducing risk, purchased proven step-in innovators. For example snowboard boot company Vans purchased the Switch step-in company, while Device step-in company was purchased by Ride Snowboards.
Although initially refusing to expose themselves to the risk and expense associated with bringing a step-in system to market, Burton chose to focus primarily on improvements to existing strap-in technology. However, Burton eventually released 2 models of step-in systems, the SI and the PSI, Burton's SI system enjoyed moderate success, yet never matched the performance of the company's strap-in products and was never improved upon. Burton never marketed any improvements to either of their step-in binding systems and eventually discontinued the products.
Most Popular (and incompatible) step-in systems used unique and proprietary mechanisms, such as the step-ins produced by Burton, Rossignol and Switch. Shimano and K2 used a technology similar to clipless bicycle pedals. Burton and K2 Clicker step-in binding systems are no longer in production as both companies have opted to focus on the strap-in binding system. Rossignol remains as the sole provider of step-in binding systems and offers them primarily to the rental market as most consumers and retailers alike have been discouraged by lack of adequate development and industry support for step-in technology.
Speed entry (hybrid).
There are also proprietary systems that seek to combine the convenience of step-in systems with the control levels attainable with strap-ins. An example is the Flow binding system, which is similar to a strap-in binding, except that the foot enters the binding through the back. The back flips down and allows the boot to slide in; it's then flipped up and locked into place with a clamp, eliminating the need to loosen and then re-tighten straps every time the rider frees and then re-secures his rear foot. The rider's boot is held down by an adjustable webbing that covers most of the foot. Newer Flow models have connected straps in place of the webbing found on older models; these straps are also micro adjustable. In 2004, K2 released the Cinch series, a similar rear-entry binding; riders slip their foot in as they would a Flow binding, however rather than webbing, the foot is held down by straps.
Highback.
A stiff molded support behind the heel and up the calf area. The HyBak was originally designed by inventor Jeff Grell and built by Flite Snowboards. This allows the rider to apply pressure and effect a "heelside" turn. Some high backs are stiff vertically but provide some flex for twisting of the riders legs.
Plate.
Plate bindings are used with hardboots on Alpine or racing snowboards. Extreme carvers and some Boarder Cross racers also use plate bindings. The stiff bindings and boots give much more control over the board and allow the board to be carved much more easily than with softer bindings. Alpine snowboards tend to be longer and thinner with a much stiffer flex for greater edge hold and better carving performance.
Snowboard bindings, unlike ski bindings, do not automatically release upon impact or after falling over. With skis, this mechanism is designed to protect from injuries (particularly to the knee) caused by skis torn in different directions. Automatic release is not required in snowboarding, as the rider's legs are fixed in a static position and twisting of the knee joint cannot occur to the same extent. Furthermore it reduces the dangerous prospect of a board hurtling downhill riderless, and the rider slipping downhill on his back with no means to maintain grip on a steep slope. Nevertheless, some ski areas require the use of a "leash" that connects the snowboard to the rider's leg or boot, in case the snowboard manages to get away from its rider. This is most likely to happen when the rider removes the board at the top or the bottom of a run (or while on a chairlift, which could be dangerous).
A Noboard is a snowboard binding alternative with only peel and stick pads applied directly to any snowboard deck and no attachment.
Stomp pad.
Stomp pads, which are placed between the bindings closer to the rear binding, allow the rider to better control the board with only one boot strapped in, such as when maneuvering onto a chair lift, riding a ski tow or performing a one footed trick. Whereas the upper surface of the board is smooth, the stomp pad has a textured pattern which provides grip to the underside of the boot. Stomp pads can be decorative and vary in their size, shape and the kind and number of small spikes or friction points they provide.
Stances.
There are two types of stance-direction used by snowboarders. A "regular" stance places the rider's left foot at the front of the snowboard. "Goofy", the opposite stance direction, places the rider's right foot at the front, as in skateboarding. Regular is the most common. There are different ways to determine whether a rider is "regular" or "goofy". One method used for first time riders is to observe the first step forward when walking or climbing up stairs. The first foot forward would be the foot set up at the front of the snowboard. Another method used for first time riders is to use the same foot that you kick a football with as your back foot (though this can be an inaccurate sign for some, as there are people who prefer goofy though are right handed, and therefore naturally kick a football with their right foot). This is a good method for setting up the snowboard stance for a new snowboarder. However having a surfing or skateboarding background will also help a person determine their preferred stance, although not all riders will have the same stance skateboarding and snowboarding. The most accurate way to determine a rider's stance is to get the rider to run and slide on a tiled or wooden floor, wearing only socks, and observe which foot the person puts forward during the slide. This simulates the motion of riding a snowboard and exposes that persons natural tendency to put a particular foot forward. Another method is to stand behind the first-timer and give them a shove, enough for them to put one foot forward to stop themselves from falling. 
Most experienced riders are able to ride in the opposite direction to their usual stance (i.e. a "regular" rider would lead with their right foot instead of their left foot). This is called riding "fakie" or "switch".
Stance width.
Stance width helps determine the rider's balance on the board. The size of the rider is an important factor as well as the style of their riding when determining a proper stance width. A common measurement used for new riders is to position the bindings so that the feet are placed a little wider than shoulder width apart. Another, less orthodox form of measurement may be taken by putting your feet together and place your hands, palm down, on the ground in a straight line with your body by squatting down. This generally gives a good natural measurement for how wide of a base your body uses to properly balance itself when knees are bent. However, personal preference and comfort are important and most experienced riders will adjust the stance width to personal preference. Skateboarders should find that their snowboarding and skateboarding stance widths are relatively similar.
A wider stance, common for freestyle riders, gives more stability when landing a jump or jibbing a rail. Control in a wider stance is reduced when turning on the piste. Conversely a narrow stance will give the rider more control when turning on the piste but less stability when freestyling. A narrow stance is more common for riders looking for quicker turn edge-hold (i.e. small radius turns). The narrow stance will give the rider a concentrated stability between the bindings allowing the board to dig into the snow quicker than a wider stance so the rider is less prone to wash out.
Binding angle.
Binding angle is defined by the degrees off of perpendicular from the length of the snowboard. A binding angle of 0° is when the foot is perpendicular to the length of the snowboard. Positive angles are pointed towards the front of the board, whereas negative angles are pointed towards the back of the board. The question of "how much" the bindings are angled depends on the rider's purpose and preference. Different binding angles can be used for different types of snowboarding. Someone who participates in freestyle competition would have a much different "stance" than someone who explores backcountry and powder. The recent advancement and boom of snowboard culture and technology has made binding angle adjustments relatively easy. Binding companies design their bindings with similar baseplates that can easily mount onto any type of snowboard regardless of the brand. With the exception of Burton, and their newly released "channel system", adjusting bindings is something that remains constant among all snowboarders. Done with a small screw-driver or a snowboard tool, the base plates on bindings can be easily rotated to whatever preferred stance. One must un-screw the baseplate, pick their degree angles, and then re-screw the baseplates. Bindings should also regularly be checked to ensure that the screws don't come undone from the movements of snowboarding. 

</doc>
<doc id="28263" url="http://en.wikipedia.org/wiki?curid=28263" title="Stanza">
Stanza

In poetry, a stanza is a grouped set of lines within a poem, usually set off from other stanzas by a blank line or indentation. Stanzas can have regular rhyme and metrical schemes, though stanzas are not strictly required to have either. There are many unique . Some stanzaic forms are simple, such as four-line quatrains. Other forms are more complex, such as the lolrian stanza]]. Fixed verse poems, such as sestinas, can be defined by the number and form of their stanzas. The term "stanza" is similar to "strophe", though strophe is sometimes used to refer to irregular of lines, as opposed to regular, rhymed stanzas.
The stanza in poetry is analogous with the paragraph that is seen in prose; related thoughts are grouped into units. In music, groups of lines are typically referred to as "verses". The stanza has also been known by terms such as "batch", "fit", and "stave".
Example.
This short poem by Emily Dickinson has two stanzas of four lines each.
<poem>I had no time to hate, because
The grave would hinder me,
And life was not so ample It
Could finish enmity.
Nor had I time to love; but since
Some industry must be, 
The little toil of love, I thought, 
Was large enough for me.</poem>

</doc>
<doc id="28265" url="http://en.wikipedia.org/wiki?curid=28265" title="Spanish–American War">
Spanish–American War

The Spanish–American War (Spanish: "Guerra hispano-estadounidense") was a conflict in 1898 between Spain and the United States, the result of US intervention in the Cuban War of Independence. US attacks on Spain's Pacific possessions led to involvement in the Philippine Revolution and ultimately to the Philippine–American War.
Revolts against Spanish rule had occurred for some years in Cuba. There had been war scares before, as in the Virginius Affair in 1873. In the late 1890s, US public opinion was agitated by anti-Spanish propaganda led by journalists such as Joseph Pulitzer and William Hearst which used yellow journalism to criticize Spanish administration of Cuba. After the mysterious sinking of the US Navy battleship "Maine" in Havana harbor, political pressures from the Democratic Party and certain industrialists pushed the administration of Republican President William McKinley into a war he had wished to avoid. Compromise was sought by Spain, but rejected by the United States which sent an ultimatum to Spain demanding it surrender control of Cuba. First Madrid, then Washington, formally declared war.
Although the main issue was Cuban independence, the ten-week war was fought in both the Caribbean and the Pacific. US naval power proved decisive, allowing expeditionary forces to disembark in Cuba against a Spanish garrison already brought to its knees by nationwide Cuban insurgent attacks and further wasted by yellow fever. Numerically superior Cuban, Philippine, and US forces obtained the surrender of Santiago de Cuba and Manila despite the good performance of some Spanish infantry units and fierce fighting for positions such as San Juan Hill. With two obsolete Spanish squadrons sunk in Santiago de Cuba and Manila Bay and a third, more modern fleet recalled home to protect the Spanish coasts, Madrid sued for peace.
The result was the 1898 Treaty of Paris, negotiated on terms favorable to the US, which allowed it temporary control of Cuba, and ceded indefinite colonial authority over Puerto Rico, Guam and the Philippine islands from Spain. The defeat and collapse of the Spanish Empire was a profound shock to Spain's national psyche, and provoked a thorough philosophical and artistic revaluation of Spanish society known as the Generation of '98. The United States gained several island possessions spanning the globe and a rancorous new debate over the wisdom of expansionism.
The war began exactly fifty-two years after the Mexican–American War began, and was one of only five US wars to have been formally declared by Congress.
Historical background.
Spain's attitude towards its colonies.
The combined problems arising from the Peninsular War (1807–1814), the loss of most of its colonies in the Americas in the early 19th-century Spanish American wars of independence, and three Carlist Wars (1832–1876) effected a new interpretation of Spain's remaining empire. Liberal Spanish elites like Antonio Cánovas del Castillo and Emilio Castelar offered new interpretations of the concept of "empire" to dovetail with Spain's emerging nationalism. Cánovas made clear in an address to the University of Madrid in 1882 his view of the Spanish nation as based on shared cultural and linguistic elements – on both sides of the Atlantic – that tied Spain's territories together.
As many historians have argued in the present and the past, Cánovas saw Spanish imperialism as markedly different in its methods and purposes of colonization from those of rival empires like the British or French. Spaniards regarded the spreading of civilization and Christianity as Spain's major objective and contribution to the New World. The concept of cultural unity bestowed special significance on Cuba, which had been Spanish for almost four hundred years, as an integral part of the Spanish nation. The focus on preserving the empire would have negative consequences for Spain's national pride in the aftermath of the Spanish–American War.
American interest in the Caribbean.
In 1823, U.S. President James Monroe enunciated the Monroe Doctrine, which stated that the United States would not tolerate further efforts by European governments to colonize land or interfere with states in the Americas; however, Spain's colony in Cuba was exempted. Before the Civil War Southern interests attempted to have the U.S. purchase Cuba and make it new slave territory. The proposal failed, and national attention shifted to the Civil War.
After the US Civil War and Cuba's Ten Years' War, US businessmen began monopolizing the devalued sugar markets in Cuba. By 1894, 90% of Cuba's total exports went to the US. Additionally, 40% of Cuba's imports came from the US. Cuba's total exports to the US were almost twelve times larger than the export to her mother country, Spain. US business interests indicated that while Spain still held political authority over Cuba, economic authority in Cuba, acting-authority, was shifting to the US.
The U.S. became interested in a canal either in Nicaragua, or in Panama, where the Panama Canal would eventually be built, and realized the need for naval protection. Captain Alfred Thayer Mahan was an especially influential theorist; his ideas were much admired by Theodore Roosevelt, as the U.S. rapidly built a powerful fleet in the 1890s. Roosevelt served as Assistant Secretary of the Navy in 1897–98 and was an aggressive supporter of a war with Spain over Cuba.
Meanwhile the Cuba Libre movement, led by Cuban intellectual José Martí, had established offices in Florida and New York to buy and smuggle weapons. It mounted a large propaganda campaign to generate sympathy that would lead to official pressure on Spain. Protestant churches and Democratic farmers were supportive, but business interests called on Washington to ignore them.
Although Cuba attracted American attention, little note was made of the Philippines, Guam, or Puerto Rico.
Historians see little popular demand for an empire, but note that Britain, France, Germany and Japan had expanded their overseas empires dramatically, in Africa, Asia and the Pacific.
Path to war.
Cuban struggle for independence.
The first serious bid for Cuban independence, the Ten Years War, erupted in 1868 and was subdued by the authorities a decade later. Neither the fighting nor the reforms in the Pact of Zanjón (February 1878) quelled the desire of some revolutionaries for wider autonomy and ultimately independence. One such revolutionary, José Martí, continued to promote Cuban financial and political autonomy in exile. In early 1895, after years of organizing, Martí launched a three-pronged invasion of the island.
The plan called for one group from Santo Domingo led by Máximo Gómez, one group from Costa Rica led by Antonio Maceo Grajales, and another from the United States (preemptively thwarted by U.S. officials in Florida) to land in different places on the island and provoke an uprising. While their call for revolution, the "grito de Baíre", was successful, the result was not the grand show of force Martí had expected. With a quick victory effectively lost, the revolutionaries settled in to fight a protracted guerrilla campaign.
Antonio Cánovas del Castillo, the architect of Spain's Restoration constitution and the prime minister at the time, ordered General Arsenio Martínez-Campos, a distinguished veteran of the war against the previous uprising in Cuba, to quell the revolt. Campos's reluctance to accept his new assignment and his method of containing the revolt to the province of Oriente earned him criticism in the Spanish press.
The mounting pressure forced Cánovas to replace General Campos with General Valeriano Weyler, a soldier who had experience in quelling rebellions in overseas provinces and the Spanish metropole. Weyler deprived the insurgency of weaponry, supplies, and assistance by ordering the residents of some Cuban districts to move to reconcentration areas near the military headquarters. This strategy was effective in slowing the spread of rebellion. In the United States, this fueled the fire of anti-Spanish propaganda. In a political speech President William McKinley used this to ram Spanish actions against armed rebels. He even said this "was not civilized warfare" but "extermination".
Spanish attitude.
The Spanish Government regarded Cuba as a province of Spain rather than a colony, and depended on it for prestige and trade, and as a training ground for the army. Prime minister Antonio Cánovas del Castillo announced that "the Spanish nation is disposed to sacrifice to the last peseta of its treasure and to the last drop of blood of the last Spaniard before consenting that anyone snatch from it even one piece of its territory." He had long dominated and stabilized Spanish politics. He was assassinated in 1897 by Italian anarchist Michele Angiolillo, leaving a Spanish political system that was not stable and could not risk a blow to its prestige.
U.S. response.
The eruption of the Cuban revolt, Weyler's measures, and the popular fury these events whipped up proved to be a boon to the newspaper industry in New York City, where Joseph Pulitzer of the "New York World" and William Randolph Hearst of the "New York Journal" recognized the potential for great headlines and stories that would sell copies. Both papers covered Spain's actions and Weyler's tactics in a way that confirmed the popular disparaging attitude toward Spain in America. In the minds, schoolbooks, and scholarship of the mostly Protestant U.S. public, the Spanish Empire was a backward, immoral union built on the backs of enslaved natives and funded with stolen gold.
The U.S. had important economic interests that were being harmed by the prolonged conflict and deepening uncertainty about the future of Cuba. Shipping firms that relied heavily on trade with Cuba suffered huge losses as the conflict continued unresolved. These firms pressed Congress and McKinley to seek an end to the revolt. Other U.S. business concerns, specifically those who had invested in Cuban sugar, looked to the Spanish to restore order. Stability, not war, was the goal of both interests. How stability would be achieved would depend largely on the ability of Spain and the U.S. to work out their issues diplomatically.
While tension increased among the Cubans and Spanish Government, popular support of intervention began to spring up in the United States, due to the emergence of the "Cuba Libre" movement and that many Americans began to envision the Cuban people as themselves from just over a century before. The American people drew parallels between the American Revolution and the Cuban revolt, and saw the Spanish Government as the tyrannical colonial oppressor. Historian Louis Pérez notes that "The proposition of war in behalf of Cuban independence took hold immediately and held on thereafter. Such was the sense of the public mood." At the time many poems and songs were written in the United States to express support of the "Cuba Libre" movement.
President McKinley, well aware of the political complexity surrounding the conflict, wanted to end the revolt peacefully. Threatening to consider recognizing Cuba's belligerent status, and thus allowing the legal rearming of Cuban insurgents by U.S. firms, he sent Stewart L. Woodford to Madrid to negotiate an end to the conflict. With Práxedes Sagasta, an open advocate of Cuban autonomy, now Prime Minister of Spain (the more hard-line Cánovas del Castillo had been assassinated before Woodford arrived), negotiations went smoothly. Cuban autonomy was set to begin on January 1, 1898.
USS "Maine".
Eleven days after the Cuban autonomous government took power, a small riot erupted in Havana. The riot was thought to be ignited by Spanish officers who were offended by the persistent newspaper criticism of General Valeriano Weyler's policies. McKinley sent the USS "Maine" to Havana to ensure the safety of American citizens and interests.
The need for the U.S. to send the "Maine" to Havana had been expected for months, but the Spanish Government was notified just 18 hours before its arrival, which was contrary to diplomatic convention. Preparations for the possible conflict started in October 1897, when McKinley arranged for "Maine" to be deployed to Key West, Florida, as a part of a larger, global deployment of U.S. naval power to attack simultaneously on several fronts if the war was not avoided. As "Maine" left Florida, a large part of the North Atlantic Squadron was moved to Key West and the Gulf of Mexico. Others were also moved just off the shore of Lisbon, and still others were moved to Hong Kong.
At 9:40 on the evening of February 15, 1898, "Maine" sank in Havana Harbor after suffering a massive explosion. While McKinley urged patience, the news of the explosion and the deaths of 266 out of 355 sailors on board stirred popular American opinion into demanding a swift belligerent response. McKinley asked Congress to appropriate $50 million for defense, and Congress unanimously obliged. Most American leaders took the position that the cause of the explosion was unknown, but public attention was now riveted on the situation and Spain could not find a diplomatic solution to avoid war. It appealed to the European powers, all of whom advised Spain to back down and avoid war.
The U.S. Navy's investigation, made public on March 28, concluded that the ship's powder magazines were ignited when an external explosion was set off under the ship's hull. This report poured fuel on popular indignation in the U.S., making the war inevitable. Spain's investigation came to the opposite conclusion: the explosion originated within the ship. Other investigations in later years came to various contradictory conclusions, but had no bearing on the coming of the war. In 1974, Admiral Hyman George Rickover had his staff look at the documents and decided there was an internal explosion. A study commissioned by "National Geographic" magazine in 1999, using AME computer modelling, stated that the explosion could have been caused by a mine, but no definitive evidence was found.
Declaring war.
After the "Maine" was destroyed, newspaper publishers Hearst and Pulitzer decided that the Spanish were to blame, and they publicized this theory as fact in their New York City papers using sensationalistic and astonishing accounts of "atrocities" committed by the Spanish in Cuba by using headlines in their newspapers, such as "Spanish Murderers" and "Remember The Maine". Their press exaggerated what was happening and how the Spanish were treating the Cuban prisoners. The stories were based on factual accounts, but most of the time, the articles that were published were embellished and written with incendiary language causing emotional and often heated responses among readers. This caused many Americans to become jingoes, who were American citizens that were excessively patriotic about supporting their country and who would look down upon any people who they thought were inferior to them or who disparaged American culture. A common myth states, to the opinion of his illustrator Frederic Remington, that conditions in Cuba were not bad enough to warrant hostilities, Hearst responded: "You furnish the pictures and I'll furnish the war."
This new "yellow journalism" was, however, uncommon outside New York City, and historians no longer consider it the major force shaping the national mood. Public opinion nationwide did demand immediate action, overwhelming the efforts of President McKinley, Speaker of the House Thomas Brackett Reed, and the business community to find a negotiated solution.
A speech delivered by Republican Senator Redfield Proctor of Vermont on March 17, 1898 thoroughly analyzed the situation, concluding that war was the only answer. The speech helped provide one final push for the United States to declare war.: Many in the business and religious communities which had until then opposed war, switched sides, leaving McKinley and Speaker Reed almost alone in their resistance to a war. On April 11, McKinley ended his resistance and asked Congress for authority to send American troops to Cuba to end the civil war there, knowing that Congress would force a war.
On April 19, while Congress was considering joint resolutions supporting Cuban independence, Republican Senator Henry M. Teller of Colorado proposed the Teller Amendment to ensure that the U.S. would not establish permanent control over Cuba after the war. The amendment, disclaiming any intention to annex Cuba, passed the Senate 42 to 35; the House concurred the same day, 311 to 6. The amended resolution demanded Spanish withdrawal and authorized the President to use as much military force as he thought necessary to help Cuba gain independence from Spain. President McKinley signed the joint resolution on April 20, 1898, and the ultimatum was sent to Spain. In response, Spain severed diplomatic relations with the United States on April 21. On the same day, the U.S. Navy began a blockade of Cuba. Spain declared war on April 23. On April 25, Congress declared that a state of war between the U.S. and Spain had existed since April 21, the day the blockade of Cuba had begun.
The Navy was ready, but the Army was not well-prepared for the war and made radical changes in plans and quickly purchased supplies. In the spring of 1898, the strength of the Regular U.S. Army was just 28,000 men. The Army wanted 50,000 new men but received over 220,000, through volunteers and the mobilization of state National Guard units.
Pacific Theater.
Philippines.
In the 333 years of Spanish rule, the Philippines developed from a small overseas colony governed from the Viceroyalty of New Spain to a land with modern elements in the cities. The Spanish-speaking middle classes of the 19th century were mostly educated in the liberal ideas coming from Europe. Among these Ilustrados was the Filipino national hero José Rizal, who demanded larger reforms from the Spanish authorities. This movement eventually led to the Philippine Revolution against Spanish colonial rule. The revolution had been in a state of truce since the signing of the Pact of Biak-na-Bato in 1897, with revolutionary leaders having accepted exile outside of the country.
The first battle between American and Spanish forces was at Manila Bay where, on May 1, Commodore George Dewey, commanding the U.S. Navy's Asiatic Squadron aboard USS "Olympia", in a matter of hours defeated a Spanish squadron under Admiral Patricio Montojo. Dewey managed this with only nine wounded. With the German seizure of Tsingtao in 1897, Dewey's squadron had become the only naval force in the Far East without a local base of its own, and was beset with coal and ammunition problems. Despite these problems, the Asiatic Squadron not only destroyed the Spanish fleet but also captured the harbor of Manila.
Following Dewey's victory, Manila Bay was filled with the warships of Britain, Germany, France and Japan. The German fleet of eight ships, ostensibly in Philippine waters to protect German interests, acted provocatively – cutting in front of American ships, refusing to salute the United States flag (according to customs of naval courtesy), taking soundings of the harbor, and landing supplies for the besieged Spanish.
The Germans, with interests of their own, were eager to take advantage of whatever opportunities the conflict in the islands might afford. There was a fear at the time that the islands would become a German possession. The Americans called the bluff of the Germans, threatening conflict if the aggression continued, and the Germans backed down. At the time, the Germans expected the confrontation in the Philippines to end in an American defeat, with the revolutionaries capturing Manila and leaving the Philippines ripe for German picking.
Commodore Dewey transported Emilio Aguinaldo, a Filipino leader who had led rebellion against Spanish rule in the Philippines in 1896, from exile in Hong Kong to the Philippines to rally more Filipinos against the Spanish colonial government. By June, U.S. and Filipino forces had taken control of most of the islands, except for the walled city of Intramuros. On June 12, Aguinaldo proclaimed the independence of the Philippines.
On August 13, with American commanders unaware that a cease-fire had been signed between Spain and the U.S. on the previous day, American forces captured the city of Manila from the Spanish in the Battle of Manila. This battle marked the end of Filipino-American collaboration, as the American action of preventing Filipino forces from entering the captured city of Manila was deeply resented by the Filipinos. This later led to the Philippine–American War, which would prove to be more deadly and costly than the Spanish–American War.
The U.S. had sent a force of some 11,000 ground troops to the Philippines. Armed conflict broke out between U.S. forces and the Filipinos when U.S. troops began to take the place of the Spanish in control of the country after the end of the war, resulting in the Philippine–American War. On August 14, 1899, the Schurman Commission recommended that the U.S. retain control of the Philippines, possibly granting independence in the future.
Guam.
On June 20, a U.S. fleet commanded by Captain Henry Glass, consisting of the protected cruiser USS "Charleston" and three transports carrying troops to the Philippines, entered Guam's Apra Harbor, Captain Glass having opened sealed orders instructing him to proceed to Guam and capture it. "Charleston" fired a few cannon rounds at Fort Santa Cruz without receiving return fire. Two local officials, not knowing that war had been declared and believing the firing had been a salute, came out to "Charleston" to apologize for their inability to return the salute as they were out of gunpowder. Glass informed them that the U.S. and Spain were at war.
The following day, Glass sent Lt. William Braunersruehter to meet the Spanish Governor to arrange the surrender of the island and the Spanish garrison there. Some 54 Spanish infantry were captured and transported to the Philippines as prisoners of war. No U.S. forces were left on Guam, but the only U.S. citizen on the island, Frank Portusach, told Captain Glass that he would look after things until U.S. forces returned.
Caribbean theater.
Cuba.
Theodore Roosevelt advocated intervention in Cuba, both for the Cuban people and to promote the Monroe Doctrine. While Assistant Secretary of the Navy, he placed the Navy on a war-time footing and prepared Dewey's Asiatic Squadron for battle. He also worked with Leonard Wood in convincing the Army to raise an all-volunteer regiment, the 1st U.S. Volunteer Cavalry. Wood was given command of the regiment that quickly became known as the "Rough Riders".
The Americans planned to capture the city of Santiago de Cuba to destroy Linares' army and Cervera's fleet. To reach Santiago they had to pass through concentrated Spanish defenses in the San Juan Hills and a small town in El Caney. The American forces were aided in Cuba by the pro-independence rebels led by General Calixto García.
Cuban sentiment.
For quite some time the Cuban public believed the United States government to possibly hold the key to its independence, and even annexation was considered for a time, which historian Louis Pérez explored in his book, "Cuba and the United States: Ties of Singular Intimacy." The Cubans harbored a great deal of discontent towards the Spanish Government, due to years of manipulation on the part of the Spanish. The prospect of getting the United States involved in the fight was considered by many Cubans as a step in the right direction. While the Cubans were wary of the United States' intentions, the overwhelming support from the American public provided the Cubans with some peace of mind, because they believed that the United States was committed to helping them achieve their independence. However, with the emergence of the Platt Amendment of 1903 after the war, as well as economic and military manipulation on the part of the United States, Cuban sentiment towards the United States became very polarized in its anger towards the United States to give the freedom they were promised.
Land campaign.
From June 22 to 24, the Fifth Army Corps under General William R. Shafter landed at Daiquirí and Siboney, east of Santiago, and established an American base of operations. A contingent of Spanish troops, having fought a skirmish with the Americans near Siboney on June 23, had retired to their lightly entrenched positions at Las Guasimas. An advance guard of U.S. forces under former Confederate General Joseph Wheeler ignored Cuban scouting parties and orders to proceed with caution. They caught up with and engaged the Spanish rearguard of about 2,000 soldiers led by General Antero Rubín who effectively ambushed them, in the Battle of Las Guasimas on June 24. The battle ended indecisively in favor of Spain and the Spanish left Las Guasimas on their planned retreat to Santiago.
The U.S. Army employed Civil War-era skirmishers at the head of the advancing columns. Three of four of the U.S. soldiers who had volunteered to act as skirmishers walking point at the head of the American column were killed, including Hamilton Fish II (grandson of Hamilton Fish, the Secretary of State under Ulysses S. Grant), and Captain Allyn K. Capron, Jr., whom Theodore Roosevelt would describe as one of the finest natural leaders and soldiers he ever met. Only Oklahoma Territory Pawnee Indian, Tom Isbell, wounded seven times, survived.
The Battle of Las Guasimas showed the U.S. that quick-thinking American soldiers would not stick to the linear tactics which did not work effectively against Spanish troops who had learned the art of cover and concealment from their own struggle with Cuban insurgents, and never made the error of revealing their positions while on the defense. Americans advanced by rushes and stayed in the weeds so that they, too, were largely invisible to the Spaniards who used un-targeted volley fire to try to mass fires against the advancing Americans. While some troops were hit, this technique was mostly a waste of bullets as the Americans learned to duck as soon as they heard the Spanish word Fire, "Fuego" yelled by the Spanish officers. Spanish troops were equipped with smokeless powder arms that also helped them to hide their positions while firing.
Regular Spanish troops were mostly armed with modern charger-loaded 1893 7mm Spanish Mauser rifles and using smokeless powder. The high-speed 7×57mm Mauser round was termed the "Spanish Hornet" by the Americans because of the supersonic crack as it passed overhead. Other irregular troops were armed with Remington Rolling Block rifles in .43 Spanish using smokeless powder and brass-jacketed bullets. US regular infantry were armed with the .30-40 Krag-Jørgensen, a bolt-action rifle with a complex rotating magazine. Both the US regular cavalry and the volunteer cavalry used smokeless ammunition. In later battles, state volunteers used the .45–70 Springfield a single-shot black powder rifle.
On July 1, a combined force of about 15,000 American troops in regular infantry and cavalry regiments, including all four of the army's "Colored" regiments, and volunteer regiments, among them Roosevelt and his "Rough Riders", the 71st New York, the 2nd Massachusetts Infantry, and 1st North Carolina, and rebel Cuban forces attacked 1,270 entrenched Spaniards in dangerous Civil War-style frontal assaults at the Battle of El Caney and Battle of San Juan Hill outside of Santiago. More than 200 U.S. soldiers were killed and close to 1,200 wounded in the fighting, thanks to the high rate of fire the Spanish were able to put down range at the Americans. Supporting fire by Gatling guns was critical to the success of the assault. Cervera decided to escape Santiago two days later.
The Spanish forces at Guantánamo were so isolated by Marines and Cuban forces that they did not know that Santiago was under siege, and their forces in the northern part of the province could not break through Cuban lines. This was not true of the Escario relief column from Manzanillo, which fought its way past determined Cuban resistance but arrived too late to participate in the siege.
After the battles of San Juan Hill and El Caney, the American advance halted. Spanish troops successfully defended Fort Canosa, allowing them to stabilize their line and bar the entry to Santiago. The Americans and Cubans forcibly began a bloody, strangling siege of the city. During the nights, Cuban troops dug successive series of "trenches" (raised parapets), toward the Spanish positions. Once completed, these parapets were occupied by U.S. soldiers and a new set of excavations went forward. American troops, while suffering daily losses from Spanish fire, suffered far more casualties from heat exhaustion and mosquito-borne disease. At the western approaches to the city, Cuban general Calixto Garcia began to encroach on the city, causing much panic and fear of reprisals among the Spanish forces.
Naval operations.
The major port of Santiago de Cuba was the main target of naval operations during the war. The U.S. fleet attacking Santiago needed shelter from the summer hurricane season; Guantánamo Bay, with its excellent harbor, was chosen. The 1898 invasion of Guantánamo Bay happened between June 6 and 10, with the first U.S. naval attack and subsequent successful landing of U.S. Marines with naval support.
The Battle of Santiago de Cuba on July 3, was the largest naval engagement of the Spanish–American War and resulted in the destruction of the Spanish Caribbean Squadron (also known as the "Flota de Ultramar"). In May, the fleet of Spanish Admiral Pascual Cervera y Topete had been spotted by American forces in Santiago harbor, where they had taken shelter for protection from sea attack. A two-month stand-off between Spanish and American naval forces followed.
When the Spanish squadron finally attempted to leave the harbor on July 3, the American forces destroyed or grounded five of the six ships. Only one Spanish vessel, the new armored cruiser "Cristobal Colon", survived, but her captain hauled down her flag and scuttled her when the Americans finally caught up with her. The 1,612 Spanish sailors who were captured, including Admiral Cervera, were sent to Seavey's Island at the Portsmouth Naval Shipyard in Kittery, Maine, where they were confined at Camp Long as prisoners of war from July 11 until mid-September.
During the stand-off, U.S. Assistant Naval Constructor, Lieutenant Richmond Pearson Hobson had been ordered by Rear Admiral William T. Sampson to sink the collier USS "Merrimac" in the harbor to bottle up the Spanish fleet. The mission was a failure, and Hobson and his crew were captured. They were exchanged on July 6, and Hobson became a national hero; he received the Medal of Honor in 1933, retired as a Rear Admiral and became a Congressman.
U.S. withdrawal.
Yellow fever had quickly spread amongst the American occupation force, crippling it. A group of concerned officers of the American army chose Theodore Roosevelt to draft a request to Washington that it withdraw the Army, a request that paralleled a similar one from General Shafter, who described his force as an "army of convalescents". By the time of his letter, 75% of the force in Cuba was unfit for service.
On August 7, the American invasion force started to leave Cuba. The evacuation was not total. The U.S. Army kept the black Ninth Infantry Regiment in Cuba to support the occupation. The logic was that their race and the fact that many black volunteers came from southern states would protect them; this logic led to these soldiers being nicknamed "Immunes". Still, when the Ninth left, 73 of its 984 soldiers had contracted the disease.
Puerto Rico.
In May 1898, Lt. Henry H. Whitney of the United States Fourth Artillery was sent to Puerto Rico on a reconnaissance mission, sponsored by the Army's Bureau of Military Intelligence. He provided maps and information on the Spanish military forces to the U.S. government prior to the invasion.
The American offensive began on May 12, 1898, when a squadron of 12 U.S. ships commanded by Rear Adm. William T. Sampson of the United States Navy attacked the archipelago's capital, San Juan. Though the damage inflicted on the city was minimal, the Americans were able to establish a blockade in the city's harbor, San Juan Bay. On June 22, the cruiser "Isabel II" and the destroyer "Terror" delivered a Spanish counterattack, but were unable to break the blockade and the "Terror" was damaged.
The land offensive began on July 25, when 1,300 infantry soldiers led by Nelson A. Miles disembarked off the coast of Guánica. The first organized armed opposition occurred in Yauco in what became known as the Battle of Yauco.
This encounter was followed by the Battle of Fajardo. The United States was able to seize control of Fajardo on August 1, but were forced to withdraw on August 5 after a group of 200 Puerto Rican-Spanish soldiers led by Pedro del Pino gained control of the city, while most civilian inhabitants fled to a nearby lighthouse. The Americans encountered larger opposition during the Battle of Guayama and as they advanced towards the main island's interior. They engaged in crossfire at Guamaní River Bridge, Coamo and Silva Heights and finally at the Battle of Asomante. The battles were inconclusive as the allied soldiers retreated.
A battle in San Germán concluded in a similar fashion with the Spanish retreating to Lares. On August 9, 1898, American troops that were pursuing units retreating from Coamo encountered heavy resistance in Aibonito in a mountain known as "Cerro Gervasio del Asomante" and retreated after six of their soldiers were injured. They returned three days later, reinforced with artillery units and attempted a surprise attack. In the subsequent crossfire, confused soldiers reported seeing Spanish reinforcements nearby and five American officers were gravely injured, which prompted a retreat order. All military actions in Puerto Rico were suspended on August 13, after U.S. President William McKinley and French Ambassador Jules Cambon, acting on behalf of the Spanish Government, signed an armistice whereby Spain relinquished its sovereignty over Puerto Rico.
Making peace.
With defeats in Cuba and the Philippines, and both of its fleets incapacitated, Spain sued for peace and negotiations were opened between the two parties. After the sickness and death of British consul Edward Henry Rawson-Walker, American admiral George Dewey requested the Belgian consul to Manila, Édouard André, to take Rawson-Walker's place as intermediary with the Spanish Government.
Hostilities were halted on August 12, 1898, with the signing in Washington of a Protocol of Peace between the United States and Spain. After over two months of difficult negotiations, the formal peace treaty, the Treaty of Paris, was signed in Paris on December 10, 1898, and was ratified by the United States Senate on February 6, 1899.
The United States gained all of Spain's colonies outside of Africa in the treaty, including the Philippines, Guam and Puerto Rico but with the exception of Cuba, which became a U.S. protectorate. The treaty came into force in Cuba April 11, 1899, with Cubans participating only as observers. Having been occupied since July 17, 1898, and thus under the jurisdiction of the United States Military Government (USMG), Cuba formed its own civil government and gained independence on May 20, 1902, with the announced end of USMG jurisdiction over the island. However, the U.S. imposed various restrictions on the new government, including prohibiting alliances with other countries, and reserved the right to intervene. The U.S. also established a perpetual lease of Guantánamo Bay.
Aftermath.
The war lasted ten weeks. John Hay (the United States Ambassador to the United Kingdom), writing from London to his friend Theodore Roosevelt declared that it had been "a splendid little war". The press showed Northerners and Southerners, blacks and whites fighting against a common foe, helping to ease the scars left from the American Civil War.
The war marked American entry into world affairs. Since then, the U.S. has had a significant hand in various conflicts around the world, and entered many treaties and agreements. The Panic of 1893 was over by this point, and the U.S. entered a long and prosperous period of economic and population growth, and technological innovation that lasted through the 1920s.
The war redefined national identity, served as a solution of sorts to the social divisions plaguing the American mind, and provided a model for all future news reporting.
The idea of American imperialism changed in the public's mind after the short and successful Spanish–American War. Due to the United States' powerful influence diplomatically and militarily, Cuba's status after the war relied heavily upon American actions. Two major developments emerged from the Spanish–American War: one, it greatly enforced the United States' vision of itself as a "defender of democracy" and as a major world power, and two, it had severe implications for Cuban-American relations in the future. As historian Louis Pérez argued in his book "Cuba in the American Imagination: Metaphor and the Imperial Ethos", the Spanish–American War of 1898 "fixed permanently how Americans came to think of themselves: a righteous people given to the service of righteous purpose".
The war greatly reduced the Spanish Empire. Spain had been declining as an imperial power since the early 19th century as a result of Napoleon's invasion. The loss of Cuba caused a national trauma because of the affinity of peninsular Spaniards with Cuba, which was seen as another province of Spain rather than as a colony. Spain retained only a handful of overseas holdings: Spanish West Africa (Spanish Sahara), Spanish Guinea, Spanish Morocco, and the Canary Islands.
The Spanish soldier Julio Cervera Baviera, who served in the Puerto Rican Campaign, published a pamphlet in which he blamed the natives of that colony for its occupation by the Americans, saying, "I have never seen such a servile, ungrateful country [i.e., Puerto Rico]... In twenty-four hours, the people of Puerto Rico went from being fervently Spanish to enthusiastically American... They humiliated themselves, giving in to the invader as the slave bows to the powerful lord." He was challenged to a duel by a group of young Puerto Ricans for writing this pamphlet.
Culturally, a new wave called the Generation of '98 originated as a response to this trauma, marking a renaissance in Spanish culture. Economically, the war benefited Spain, because after the war large sums of capital held by Spaniards in Cuba and America were returned to the peninsula and invested in Spain. This massive flow of capital (equivalent to 25% of the gross domestic product of one year) helped to develop the large modern firms in Spain in the steel, chemical, financial, mechanical, textile, shipyard, and electrical power industries. However, the political consequences were serious. The defeat in the war began the weakening of the fragile political stability that had been established earlier by the rule of Alfonso XII.
The Teller Amendment, which was enacted on April 20, 1898, was a promise from the United States to the Cuban people that it was not declaring war to annex Cuba, but to help it gain its independence from Spain. The Platt Amendment was a move by the United States' government to shape Cuban affairs without violating the Teller Amendment.
The U.S. Congress had passed the Teller Amendment prior to the war, promising Cuban independence. However, the Senate passed the Platt Amendment as a rider to an Army appropriations bill, forcing a peace treaty on Cuba which prohibited it from signing treaties with other nations or contracting a public debt. The Platt Amendment was pushed by imperialists who wanted to project U.S. power abroad (in contrast to the Teller Amendment which was pushed by anti-imperialists who called for a restraint on U.S. rule). The amendment granted the United States the right to stabilize Cuba militarily as needed. In addition, the Platt Amendment permitted the United States to deploy marines to Cuba if its freedom and independence was ever threatened or jeopardized by an external or internal force. The Platt Amendment also provided for a permanent American naval base in Cuba. Guantánamo Bay was established after the signing of treaties between Cuba and the U.S. beginning in 1903. Thus, despite that Cuba technically gained its independence after the war ended, the United States government ensured that it had some form of power and control over Cuban affairs.
The U.S. annexed the former Spanish colonies of Puerto Rico, the Philippines and Guam. The notion of the United States as an imperial power, with colonies, was hotly debated domestically with President McKinley and the Pro-Imperialists winning their way over vocal opposition led by Democrat William Jennings Bryan, who had supported the war. The American public largely supported the possession of colonies, but there were many outspoken critics such as Mark Twain, who wrote "The War Prayer" in protest.
Roosevelt returned to the United States a war hero, and he was soon elected governor and then vice president.
The war served to further repair relations between the American North and South. The war gave both sides a common enemy for the first time since the end of the Civil War in 1865, and many friendships were formed between soldiers of northern and southern states during their tours of duty. This was an important development, since many soldiers in this war were the children of Civil War veterans on both sides.
The African-American community strongly supported the rebels in Cuba, supported entry into the war, and gained prestige from their wartime performance in the Army. Spokesmen noted that 33 African-American seamen had died in the "Maine" explosion. The most influential Black leader, Booker T. Washington, argued that his race was ready to fight. War offered them a chance "to render service to our country that no other race can", because, unlike Whites, they were "accustomed" to the "peculiar and dangerous climate" of Cuba. One of the Black units that served in the war was the 9th Cavalry Regiment. In March 1898, Washington promised the Secretary of the Navy that war would be answered by "at least ten thousand loyal, brave, strong Black men in the south who crave an opportunity to show their loyalty to our land, and would gladly take this method of showing their gratitude for the lives laid down, and the sacrifices made, that Blacks might have their freedom and rights."
In 1904, the United Spanish War Veterans was created from smaller groups of the veterans of the Spanish American War. Today, that organization is defunct, but it left an heir in the Sons of Spanish–American War Veterans, created in 1937 at the 39th National Encampment of the United Spanish War Veterans. According to data from the United States Department of Veterans Affairs, the last surviving U.S. veteran of the conflict, Nathan E. Cook, died on September 10, 1992, at age 106. (If the data is to be believed, Cook, born October 10, 1885, would have been only 12 years old when he served in the war.)
The Veterans of Foreign Wars of the United States (VFW) was formed in 1914 from the merger of two prior veterans organizations which both arose in 1899: the American Veterans of Foreign Service and the National Society of the Army of the Philippines. The former was formed for veterans of the Spanish–American War, while the latter was formed for veterans of the Philippine–American War. Both organizations were formed in response to the general neglect veterans returning from the war experienced at the hands of the government.
To pay the costs of the war, Congress passed an excise tax on long-distance phone service. At the time, it affected only wealthy Americans who owned telephones. However, the Congress neglected to repeal the tax after the war ended four months later, and the tax remained in place for over 100 years until, on August 1, 2006, it was announced that the U.S. Department of the Treasury and the IRS would no longer collect the tax.
Postwar American Investment in Puerto Rico.
The change in sovereignty of Puerto Rico, like the occupation of Cuba, brought about major changes in both the insular and U.S. economies. Prior to 1898 the sugar industry in Puerto Rico was in decline for nearly half a century. In the second half of the nineteenth century technological advances increased the capital requirements to remain competitive in the sugar industry. Agriculture began to shift toward coffee production, which required less capital and land accumulation. However, these trends were reversed with U.S. hegemony. Early U.S. monetary and legal policies made it both harder for local farmers to continue operations and easier for American businesses to accumulate land. This, along with the large capital reserves of American businesses, led to a resurgence in the Puerto Rican sugar industry in the form of large American owned agro-industrial complexes.
At the same time, the inclusion of Puerto Rico into the U.S. tariff system as a customs area, effectively treating Puerto Rico as a state with respect to internal or external trade, increased the codependence of the insular and mainland economies and benefitted sugar exports with tariff protection. In 1897 the United States purchased 19.6 percent of Puerto Rico's exports while supplying 18.5 percent of its imports. By 1905 these figures jumped to 84 percent and 85 percent, respectively. However, coffee was not protected, as it was not a product of the mainland. At the same time, Cuba and Spain, traditionally the largest importers of Puerto Rican coffee, now subjected Puerto Rico to previously nonexistent import tariffs. These two effects led to a decline in the coffee industry. From 1897 to 1901 coffee went from 65.8 percent of exports to 19.6 percent while sugar went from 21.6 percent to 55 percent. The tariff system also provided a protected market place for Puerto Rican tobacco exports. The tobacco industry went from nearly nonexistent in Puerto Rico to a major part of the country's agricultural sector.
Spanish–American War in film and television.
The Spanish–American War was the first U.S. war in which the motion picture camera played a role. The Library of Congress archives contain many films and film clips from the war. In addition, a few feature films have been made about the war. These include
Military decorations.
United States.
The United States awards and decorations of the Spanish–American War were as follows:
Other countries.
The governments of Spain and Cuba also issued a wide variety of military awards to honor Spanish, Cuban, and Philippine soldiers who had served in the conflict.
References.
</dl>
Further reading.
</dl>

</doc>
<doc id="28266" url="http://en.wikipedia.org/wiki?curid=28266" title="Scurvy">
Scurvy

Scurvy is a disease resulting from a deficiency of vitamin C, which is required for the synthesis of collagen in humans. The chemical name for vitamin C, ascorbic acid, is derived from the Latin name of scurvy, "scorbutus", which also provides the adjective scorbutic ("of, characterized by or having to do with scurvy"). Scurvy often presents itself initially as symptoms of malaise and lethargy, followed by formation of spots on the skin, spongy gums, and bleeding from the mucous membranes. Spots are most abundant on the thighs and legs, and a person with the ailment looks pale, feels depressed, and is partially immobilized. As scurvy advances, there can be open, suppurating wounds, loss of teeth, jaundice, fever, neuropathy and finally death from hemorrhage when blood vessels become too weak.
Scurvy was at one time common among sailors, pirates and others aboard ships at sea longer than perishable fruits and vegetables could be stored (subsisting instead only on cured and salted meats and dried grains) and by soldiers similarly deprived of these foods for extended periods. It was described by Hippocrates (c. 460 BC–c. 380 BC), and herbal cures for scurvy have been known in many native cultures since prehistory. Scurvy was one of the limiting factors of marine travel, often killing large numbers of the passengers and crew on long-distance voyages. This became a significant issue in Europe from the beginning of the modern era in the Age of Discovery in the 15th century, continuing to play a significant role through World War I in the early 20th century.
While today scurvy is known to be caused by a nutritional deficiency, until the isolation of vitamin C and direct evidence of its link to scurvy in 1932, numerous theories and treatments were proposed, often on little or no experimental data. This inconsistency is attributed to the lack of vitamin C as a distinct concept, an inability to reliably link different foods (notably present in fresh citrus, watercress, and organ meat) to scurvy. An additional concept required to understand scurvy was the degradation of vitamin C by exposure to air and copper and other transition metal salts such as those of iron, thus changing the links of foods to scurvy over time.
Treatment by fresh food, particularly citrus fruit, was periodically implemented, as it had been since antiquity. However until the 1930s, treatment was inconsistent, with many ineffective treatments used into the 20th century. It was a Scottish surgeon in the Royal Navy, James Lind, who first proved it could be treated with citrus fruit in experiments he described in his 1753 book "A Treatise of the Scurvy", though following a failed trial with extracted lime juice, it would be 40 years before effective prevention based on fresh produce became widespread.
In infants, scurvy is sometimes referred to as Barlow's disease, named after Sir Thomas Barlow, a British physician who described it in 1883. However, Barlow's disease may also refer to mitral valve prolapse. Other eponyms for scurvy include Moeller's disease and Cheadle's disease.
Scurvy does not occur in most animals because they can synthesize their own vitamin C. However, humans and other higher primates (the simians—monkeys and apes—and tarsiers), guinea pigs, most or all bats, and some species of birds and fish lack an enzyme (L-gulonolactone oxidase) necessary for such synthesis and must obtain vitamin C through their diet. Vitamin C is widespread in plant tissues, with particularly high concentrations occurring in cruciferous vegetables, capsicum fruit including chili and all colours of bell peppers, citrus fruits (oranges, lemons, limes, grapefruits), and almost all fruits including botanical fruits that are culinary vegetables, like tomatoes. The fruit with the highest concentration of vitamin C is the Kakadu Plum with nearly 3000 mg per 100g. Cooking significantly reduces the concentration of Vitamin C.
Ascorbic acid (Vitamin C) has a number of centrally important roles in plants.
Cause.
Scurvy or subclinical scurvy is caused by the lack of vitamin C. In modern Western societies, scurvy is rarely present in adults, although infants and elderly people are affected. Vitamin C is destroyed by the process of pasteurization, so babies fed with ordinary bottled milk sometimes suffer from scurvy if they are not provided with adequate vitamin supplements. Virtually all commercially available baby formulas contain added vitamin C for this reason, but heat and storage destroy vitamin C. Human breast milk contains sufficient vitamin C, if the mother has an adequate intake.
Scurvy is one of the accompanying diseases of malnutrition (other such micronutrient deficiencies are beriberi or pellagra) and thus is still widespread in areas of the world depending on external food aid. Though rare, there are also documented cases of scurvy due to poor dietary choices by people living in industrialized nations.
Pathogenesis.
Ascorbic acid is needed for a variety of biosynthetic pathways, by accelerating hydroxylation and amidation reactions. In the synthesis of collagen, ascorbic acid is required as a cofactor for prolyl hydroxylase and lysyl hydroxylase. These two enzymes are responsible for the hydroxylation of the proline and lysine amino acids in collagen. Hydroxyproline and hydroxylysine are important for stabilizing collagen by cross-linking the propeptides in collagen. Defective collagen fibrillogenesis impairs wound healing. Collagen is an important part of bone, so bone formation is affected. Defective connective tissue leads to fragile capillaries, resulting in abnormal bleeding.
Symptoms.
Early symptoms are malaise and lethargy. After 1–3 months, patients develop shortness of breath and bone pain. Myalgias may occur because of reduced carnitine production. Other symptoms include skin changes with roughness, easy bruising and petechiae, gum disease, loosening of teeth, poor wound healing, and (which may appear before any physical changes). Dry mouth and dry eyes similar to Sjögren's syndrome may occur. In the late stages, jaundice, generalized edema, oliguria, neuropathy, fever, convulsions, and eventual death are frequently seen.
Prevention.
Scurvy can be prevented by a diet that includes certain citrus fruits such as oranges or lemons. Other sources rich in vitamin C are fruits such as blackcurrants, guava, kiwifruit, papaya, tomatoes, bell peppers, and strawberries. It can also be found in some vegetables, such as carrots, broccoli, potatoes, cabbage, spinach and paprika. Some fruits and vegetables not high in vitamin C may be pickled in lemon juice, which is high in vitamin C. Though redundant in the presence of a balanced diet, various nutritional supplements are available that provide ascorbic acid well in excess of that required to prevent scurvy, and even some candies contain vitamin C as a preservative.
Many animal products, including liver, Muktuk (whale skin), oysters, and parts of the central nervous system, including the brain, spinal cord, and adrenal medulla, contain large amounts of vitamin C, and can even be used to treat scurvy.
Fresh meat from animals which make their own vitamin C (which most animals do) contains enough vitamin C to prevent scurvy, and even partly treat it. This caused confusion in the early history of scurvy, since the disease was only seen in people eating long-preserved diets or canned goods, but not in people eating any sort of fresh diet, including arctic diets primarily based upon meat. In some cases (notably in French soldiers eating fresh horse meat), it was discovered that meat alone, even partly cooked meat, could alleviate scurvy. In other cases, a meat-only diet could cause scurvy. Some of these observations that scurvy was associated only with preserved foods prompted explorers to blame scurvy upon some type of tainting or poison which pervaded tinned foods.
Treatment.
Scurvy can be treated by eating vitamin C rich foods (such as oranges, papaya, strawberries, lemon) and by ingesting vitamin C tablets.
Prognosis.
Untreated scurvy is invariably fatal. However, death from scurvy is rare in modern times. Since all that is required for a full recovery is the resumption of normal vitamin C intake, it is easy to treat if identified correctly. Consumption of dietary supplements and/or citrus fruits are means by which to accomplish this.
History.
Scurvy was documented as a disease by Hippocrates, and Egyptians have recorded its symptoms as early as 1550 BC. The knowledge that consuming foods containing vitamin C is a cure for scurvy has been repeatedly rediscovered and forgotten into the early 20th century.
Early modern era.
In the 13th century, the Crusaders frequently suffered from scurvy. In the 1497 expedition of Vasco de Gama, the curative effects of citrus fruit were known.
The Portuguese also planted fruit trees and vegetables in Saint Helena, a stopping point for homebound voyages from Asia, and left their sick, suffering from scurvy and other ailments to be taken home, if they recovered, by the next ship.
In 1536, the French explorer Jacques Cartier, exploring the St. Lawrence River, used the local natives' knowledge to save his men who were dying of scurvy. He boiled the needles of the arbor vitae tree (Eastern White Cedar) to make a tea that was later shown to contain 50 mg of vitamin C per 100 grams. Such treatments were not available aboard ship, where the disease was most common.
Between 1500 and 1800, it has been estimated that scurvy killed at least two million sailors. Jonathan Lamb wrote: "In 1499, Vasco da Gama lost 116 of his crew of 170; In 1520, Magellan lost 208 out of 230;...all mainly to scurvy."
In 1593, Admiral Sir Richard Hawkins advocated drinking orange and lemon juice as a means of preventing scurvy.
The British civilian medical profession of 1614 believed that it was the acidic principle of citrus fruit which was lacking, although they considered any acid acceptable when ascorbic acid (Vitamin C) was unavailable. In 1614 John Woodall, Surgeon General of the East India Company, published "The Surgion's Mate" as a handbook for apprentice surgeons aboard the company's ships. In it he described scurvy as resulting from a dietary deficiency. His recommendation for its cure was fresh food or, if not available, oranges, lemons, limes and tamarinds, or as a last resort, Oil of Vitriol (sulfuric acid).
18th century.
A 1707 handwritten book is by Mrs. Ebot Mitchell discovered in a house in Hasfield, Gloucestershire, contains a "Recp.t for the Scurvy" that consisted of extracts from various plants mixed with a plentiful supply of orange juice, white wine or beer.
In 1734, the Leiden-based physician Johann Bachstrom published a book on scurvy in which he stated that "scurvy is solely owing to a total abstinence from fresh vegetable food, and greens; which is alone the primary cause of the disease" and urged the use of fresh fruit and vegetables as a cure. In 1740, citrus juice (usually lemon or lime juice) was added to the recipe of the traditional daily ration of watered-down rum known as grog to cut down on the water's foulness. Although they did not know the reason at the time, Admiral Edward Vernon's sailors were healthier than the rest of the navy because of the daily doses of vitamin C his sailors received. However, it was not until 1747 that James Lind formally proved that scurvy could be treated and prevented by supplementing the diet with citrus fruit, though not by other acids, in the first ever clinical trial. In 1753, Lind published "A Treatise of the Scurvy", in which he explained the details of his clinical trial and how scurvy was successfully eradicated from his test subjects (nuns). He then attempted to sell extracted lime juice as a medicine, but the lime juice had no effect in treating scurvy, due to the oxidization of vitamin C. Therefore, this solution was not adopted by the Royal Navy until the 1790s, and the idea that any acid would suffice continued in Britain into the late 19th century.
During the 18th century, scurvy killed more British sailors than enemy action. It was mainly by scurvy that George Anson, in his celebrated voyage of 1740–1744, lost nearly two-thirds of his crew (1300 out of 2000) within the first ten months of the voyage. The Royal Navy enlisted 184,899 sailors during the Seven Years' War; 133,708 of these were "missing" or died by disease, and scurvy was the leading cause.
James Cook succeeded in circumnavigating the world (1768–1771) in HM Bark "Endeavour" without losing a single man to scurvy, but his suggested methods, including a diet of sauerkraut and wort of malt, were of limited value. Sauerkraut was the only vegetable food that retained a reasonable amount of ascorbic acid in a pickled state, but it was boiled to reduce it for preservation, and much of the vitamin C content was lost. In Cook's time it was impractical to preserve citrus fruit for long sea voyages. More important was Cook's regime of shipboard cleanliness, enforced by strict discipline, as well as frequent replenishment of fresh food. The most effective rule implemented by Cook was his prohibition against the consumption of fat scrubbed from the ship's copper pans, then a common practice in the Navy. In contact with air the copper formed compounds that catalytically oxidised the vitamin C, destroying its efficacy.
The first major long distance expedition that experienced virtually no scurvy was that of Alessandro Malaspina, 1789–1794. Malaspina's medical officer, Pedro González, was convinced that fresh oranges and lemons were essential for preventing scurvy. Only one outbreak occurred, during a 56-day trip across the open sea. Five sailors came down with symptoms, one seriously. After three days at Guam all five were healthy again. Spain's large empire and many ports of call made it easier to acquire fresh fruit.
Despite advances, British sailors throughout the American Revolution continued to suffer from scurvy, particularly in the Channel Fleet. Scurvy was finally eradicated from the Royal Navy during the Napoleonic Wars, when Gilbert Blane, the chairman of the Navy's Sick and Hurt Board, implemented the use of fresh lemons. This led to a remarkable health improvement among the sailors and consequently played a critical role in naval battles, notably the Battle of Trafalgar. Other navies soon adopted this successful solution.
19th century.
The surgeon-in-chief of Napoleon's army at the Siege of Alexandria (1801), Baron Dominique-Jean Larrey, wrote in his memoirs that the consumption of horse meat helped the French to curb an epidemic of scurvy. The meat was cooked but was freshly obtained from young horses bought from Arabs and was nevertheless effective. This helped to start the 19th-century tradition of horse meat consumption in France.
Lauchlin Rose patented a method used to preserve citrus juice without alcohol in 1867, creating a concentrated drink known as Rose's lime juice. The Merchant Shipping Act of 1867 required all ships of the Royal Navy and Merchant Navy to provide a daily lime ration to sailors to prevent scurvy. The product became nearly ubiquitous, hence the term "limey", first for British sailors, then for English immigrants within the former British colonies (particularly America, New Zealand and South Africa), and finally, in old American slang, all British people.
The plant "Cochlearia officinalis", also known as "Common Scurvygrass", acquired its common name from the observation that it cured scurvy, and it was taken on board ships in dried bundles or distilled extracts. Its very bitter taste was usually disguised with herbs and spices; however, this did not prevent scurvygrass drinks and sandwiches becoming a popular fad in the UK until the middle of the nineteenth century, when citrus fruits became more readily available.
West Indian limes replaced lemons because they were more easily obtained from Britain's Caribbean colonies and were believed to be more effective because they were more acidic, and it was the acid, not the (then-unknown) Vitamin C that was believed to cure scurvy. In fact, the West Indian limes were significantly lower in Vitamin C than the previous lemons and further were not served fresh but rather as lime juice, which had been exposed to light and air and piped through copper tubing, all of which significantly reduced the Vitamin C. Indeed, a 1918 animal experiment using representative samples of the Navy and Merchant Marine's lime juice showed that it had virtually no antiscorbutic power at all.
The belief that scurvy was fundamentally a nutritional deficiency, best treated by consumption of fresh food, particularly fresh citrus or fresh meat, was not universal in Britain in the 19th and early 20th centuries, and thus British sailors and explorers continued to suffer from scurvy into the 20th century.
In the Royal Navy's Arctic expeditions in the 19th century it was widely believed that scurvy was prevented by good hygiene on board ship, regular exercise, and maintaining the morale of the crew, rather than by a diet of fresh food. Navy expeditions continued to be plagued by scurvy even while fresh (not jerked or tinned) meat was well known as a practical antiscorbutic among civilian whalers and explorers in the Arctic. Even cooking fresh meat did not entirely destroy its antiscorbutic properties, especially as many cooking methods failed to bring all the meat to high temperature.
The confusion is attributed to a number of factors:
In the resulting confusion, a new hypothesis was proposed, following the new germ theory of disease – that scurvy was caused by ptomaine, a waste product of bacteria, particularly in tainted tinned meat.
Infantile scurvy emerged in the late 19th century because children were being fed pasteurized cow's milk, particularly in the urban upper class – the pasteurization killed bacteria but also destroyed vitamin C. This was eventually resolved by supplementing with onion juice or cooked potatoes.
20th century.
At the time Robert Falcon Scott made his two expeditions (1903 and 1911) to the Antarctic in the early 20th century, the prevailing theory was that scurvy was caused by "tainted" meat, particularly tinned meat. Accordingly, Scott's expeditions suffered from scurvy, though he initially did not record this in his notes on his 1903 expedition, because of stigma associated with the disease.
Vilhjalmur Stefansson, an arctic explorer who lived among the Eskimos, proved that the all meat diet they consumed did not lead to vitamin deficiencies. He participated in a study in New York's Bellevue Hospital in 1935, where he and a companion ate only meat for a year while under close medical observation, yet remained in good health. Some Antarctic expeditions, such as Scott's two expeditions and Shackleton's Ross Sea party, suffered from scurvy, mainly during inland sledge journeys when the men had access to a very limited range of food, virtually none of it fresh. Scurvy was rare or absent when they had access to a wider range of stored food or relied on seal meat.
In 1907, the needed biological-assay model to isolate and identify the antiscorbutic factor was discovered. Axel Holst and Theodor Frølich, two Norwegian physicians studying shipboard beriberi contracted aboard ship's crews in the Norwegian Fishing Fleet, wanted a small test mammal to substitute for the pigeons then used in beriberi research. They fed guinea pigs their test diet of grains and flour, which had earlier produced beriberi in their pigeons, and were surprised when classic scurvy resulted instead. This was a serendipitous choice of model. Until that time, scurvy had not been observed in any organism apart from humans and had been considered an exclusively human disease. (Some birds are susceptible to scurvy, but pigeons, as seed-eating birds, were later found to be unaffected by scurvy, as they produce vitamin C.) Holst and Frølich found they could cure scurvy in guinea pigs with the addition of various fresh foods and extracts. This discovery of a "clean" (reliable) animal experimental model for scurvy, which was made even before the essential idea of "vitamins" in foods had been put forward, has been called the single most important piece of vitamin C research.
In 1927, Hungarian biochemist Szent-Györgyi isolated a compound he called "hexuronic acid". Szent-Györgyi suspected hexuronic acid, which he had isolated from adrenal glands, to be the antiscorbutic agent, but he could not prove it without an animal-deficiency model. In 1932, the connection between hexuronic acid and scurvy was finally proven by American researcher Charles Glen King of the University of Pittsburgh. King's laboratory was given some hexuronic acid by Szent-Györgyi and soon established that it was the sought-after anti-scorbutic agent. Because of this, hexuronic acid was subsequently renamed "ascorbic acid."
Experimental human trials.
Notable human dietary studies of experimentally induced scurvy have been conducted on conscientious objectors during WWII in Britain and on Iowa state prisoner "volunteers" in the late 1960s. These studies both found that all obvious symptoms of scurvy previously induced by an experimental scorbutic diet with extremely low vitamin C content could be completely reversed by additional vitamin C supplementation of only 10 mg per day. In these experiments, no clinical difference was noted between men given 70 mg vitamin C per day (which produced blood levels of vitamin C of about 0.55 mg/dl, about 1/3 of tissue saturation levels), and those given 10 mg per day (which produced lower blood levels). Men in the prison study developed the first signs of scurvy about 4 weeks after starting the vitamin C-free diet, whereas in the British study, six to eight months were required, possibly because the subjects were pre-loaded with a 70 mg/day supplement for six weeks before the scorbutic diet was fed.
Men in both studies on a diet devoid or nearly devoid of vitamin C had blood levels of vitamin C too low to be accurately measured when they developed signs of scurvy, and in the Iowa study, at this time were estimated (by labeled vitamin C dilution) to have a body pool of less than 300 mg, with daily turnover of only 2.5 mg/day.
In animals.
Almost all plant and animal species synthesize vitamin C. Notable mammalian exceptions include most or all of the order Chiroptera (bats), and one of the two major primate suborders, the "Anthropoidea" (Haplorrhini) which include tarsiers, monkeys, and apes, including human beings. The Strepsirrhini (non-tarsier prosimians) can make their own vitamin C, and these include lemurs, lorises, pottos, and galagos. Ascorbic acid is also not synthesized by at least two species of Caviidae, the capybara and the guinea pig. There are known species of birds and fish that do not synthesize their own Vitamin C. All species that do not synthesize ascorbate require it in the diet. Deficiency causes scurvy in humans, and somewhat similar symptoms in other animals.

</doc>
<doc id="28267" url="http://en.wikipedia.org/wiki?curid=28267" title="Sydney Harbour Bridge">
Sydney Harbour Bridge

The Sydney Harbour Bridge is a steel through arch bridge across Sydney Harbour that carries rail, vehicular, bicycle, and pedestrian traffic between the Sydney central business district (CBD) and the North Shore. The dramatic view of the bridge, the harbour, and the nearby Sydney Opera House is an iconic image of Sydney, and Australia. The bridge is nicknamed "The Coathanger" because of its arch-based design. Furthermore, the bridge is ubiquitously known to Sydneysiders simply as "the Bridge".
Under the direction of Dr J.J.C. Bradfield of the NSW Department of Public Works, the bridge was designed and built by British firm Dorman Long and Co Ltd of Middlesbrough and opened in 1932. The bridge's design was influenced by the Hell Gate Bridge in New York City. It is the sixth longest spanning-arch bridge in the world and the tallest steel arch bridge, measuring 134 m from top to water level. It was also the world's widest long-span bridge, at 48.8 m wide, until construction of the new Port Mann Bridge in Vancouver was completed in 2012.
Structure.
The southern (CBD) end of the bridge is located at Millers Point in The Rocks area, and the northern end at Milsons Point in the lower North Shore area. There are six original lanes of road traffic through the main roadway, plus an additional two lanes of road traffic on its eastern side, using lanes that were formerly tram tracks. Adjacent to the road traffic, a path for pedestrian use runs along the eastern side of the bridge, whilst a dedicated path for bicycle use only runs along the western side. Finally, between the main roadway and the western bicycle path are two lanes used for railway tracks, servicing the T1 North Shore Line for Sydney Trains.
The main roadway across the bridge is known as the Bradfield Highway and is about 2.4 km long, making it one of the shortest highways in Australia.
Arch.
The arch is composed of two 28-panel arch trusses; their heights vary from 18 m at the centre of the arch to 57 m at the ends next to the pylons.
The arch has a span of 504 m and its summit is 134 m above mean sea level; however, expansion of the steel structure on hot days can increase the height of the arch by as much as 18 cm. Large steel pins (or bearings) support each end of the arch, allowing it to rotate to accommodate expansion and contraction caused by changes of temperature, and avoiding stresses that would otherwise cause damage.
The total weight of the steelwork of the bridge, including the arch and approach spans, is 52800 t, with the arch itself weighing 39000 t. About 79% of the steel was imported from England, with the rest being sourced from Newcastle. On site, the contractors (Dorman Long and Co.) set up two workshops at Milsons Point, at the site of the present day Luna Park, and fabricated the steel into the girders and other required parts.
The bridge is held together by six million Australian-made hand-driven rivets supplied by the McPherson company of Melbourne, the last being driven through the deck on 21 January 1932. The rivets were heated red-hot and inserted into the plates; the headless end was immediately rounded over with a large pneumatic rivet gun. The largest of the rivets used weighed 3.5 kg and was 39.5 cm long. The practice of riveting large steel structures, rather than welding, was, at the time, a proven and understood construction technique, whilst structural welding had not at that stage been adequately developed for use on the bridge.
Pylons.
At each end of the arch stands a pair of 89 m high concrete pylons, faced with granite. The pylons were designed by the Scottish architect Thomas S. Tait, a partner in the architectural firm John Burnet & Partners.
Some 250 Australian, Scottish, and Italian stonemasons and their families relocated to a temporary settlement at Moruya, NSW, 300 km south of Sydney, where they quarried around 18000 m3 of granite for the bridge pylons. The stonemasons cut, dressed, and numbered the blocks, which were then transported to Sydney on three ships built specifically for this purpose. The concrete used was also Australian-made.
Abutments at the base of the pylons are essential to support the loads from the arch and hold its span firmly in place, but the pylons themselves have no structural purpose. They were included to provide a frame for the arch panels and to give better visual balance to the bridge. The pylons were not part of the original design, and were only added to allay public concern about the structural integrity of the bridge.
Although originally added to the bridge solely for their aesthetic value, all four pylons have now been put to use. The south-eastern pylon contains a museum and tourist centre, with a 360° lookout at the top providing views across the harbour and city. The south-western pylon is used by the New South Wales Roads and Traffic Authority (RTA) to support its CCTV cameras overlooking the bridge and the roads around that area. The two pylons on the north shore include venting chimneys for fumes from the Sydney Harbour Tunnel, with the base of the southern pylon containing the RMS maintenance shed for the bridge, and the base of the northern pylon containing the traffic management shed for tow trucks and safety vehicles used on the bridge.
In 1942 the pylons were modified to include parapets and anti-aircraft guns designed to assist in both Australia's defence and general war effort. The top level of stonework was never removed.
History.
Early proposals.
There had been plans to build a bridge as early as 1815, when convict and noted architect Francis Greenway reputedly proposed to Governor Lachlan Macquarie that a bridge be built from the northern to the southern shore of the harbour. In 1825, Greenway wrote a letter to the then "The Australian" newspaper stating that such a bridge would "give an idea of strength and magnificence that would reflect credit and glory on the colony and the Mother Country".
Nothing came of Greenway's suggestions, but the idea remained alive, and many further suggestions were made during the nineteenth century. In 1840, naval architect Robert Brindley proposed that a floating bridge be built. Engineer Peter Henderson produced one of the earliest known drawings of a bridge across the harbour around 1857. A suggestion for a truss bridge was made in 1879, and in 1880 a high-level bridge estimated at $850,000 was proposed.
In 1900, the Lyne government committed to building a new Central railway station and organised a worldwide competition for the design and construction of a harbour bridge. Local engineer Norman Selfe submitted a design for a suspension bridge and won the second prize of £500. In 1902, when the outcome of the first competition became mired in controversy, Selfe won a second competition outright, with a design for a steel cantilever bridge. The selection board were unanimous, commenting that, "The structural lines are correct and in true proportion, and... the outline is graceful". However due to an economic downturn and a change of government at the 1904 NSW State election construction never began.
Planning.
In 1914 J.J.C. Bradfield was appointed "Chief Engineer of Sydney Harbour Bridge and Metropolitan Railway Construction", and his work on the project over many years earned him the legacy as the "father" of the bridge. Bradfield's preference at the time was for a cantilever bridge without piers, and in 1916 the NSW Legislative Assembly passed a bill for such a construction, however it did not proceed as the Legislative Council rejected the legislation on the basis that the money would be better spent on the war effort.
Following World War I, plans to build the bridge again built momentum. Bradfield persevered with the project, fleshing out the details of the specifications and financing for his cantilever bridge proposal, and in 1921 he travelled overseas to investigate tenders. On return from his travels Bradfield decided that an arch design would also be suitable and he and officers of the NSW Department of Public Works prepared a general design for a single-arch bridge based upon New York City's Hell Gate Bridge. In 1922 the government passed the Sydney Harbour Bridge Act No. 28, specifying the construction of a high-level cantilever or arch bridge across the harbour between Dawes Point and Milsons Point, along with construction of necessary approaches and electric railway lines, and worldwide tenders were invited for the project.
As a result of the tendering process, the government received twenty proposals from six companies; on 24 March 1924 the contract was awarded to English firm Dorman Long and Co Ltd, of Middlesbrough well known as the contractors who built the similar Tyne Bridge of Newcastle Upon Tyne, for an arch bridge at a quoted price of AU£4,217,721 11s 10d. The arch design was cheaper than alternative cantilever and suspension bridge proposals, and also provided greater rigidity making it better suited for the heavy loads expected.
To offset concerns about a foreign firm participating in the project, assurances were given by Bradfield that the workforce building the bridge would all be Australians. Bradfield and his staff were ultimately to oversee the entire bridge design and building process, while Dorman Long and Co's Consulting Engineer, Sir Ralph Freeman of Sir Douglas Fox and Partners, and his associate Mr. G.C. Imbault, carried out the detailed design and erection process of the bridge. Architects for the contractors were from the British firm John Burnet & Partners of Glasgow, Scotland.
The building of the bridge coincided with the construction of a system of underground railways in Sydney's CBD, known today as the City Circle, and the bridge was designed with this in mind. The bridge was designed to carry six lanes of road traffic, flanked on each side by two railway tracks and a footpath. Both sets of rail tracks were linked into the underground Wynyard railway station on the south (city) side of the bridge by symmetrical ramps and tunnels. The eastern-side railway tracks were intended for use by a planned rail link to the Northern Beaches; in the interim they were used to carry trams from the North Shore into a terminal within Wynyard station, and when tram services were discontinued in 1958, they were converted into extra traffic lanes. The Bradfield Highway, which is the main roadway section of the bridge and its approaches, is named in honour of Bradfield's contribution to the bridge.
Construction.
The building of the bridge was under the management of Bradfield. Three other people heavily involved in the bridge's design and construction were Lawrence Ennis, Edward Judge, and Sir Ralph Freeman. Ennis was the engineer-in-charge at Dorman Long and Co and the main on-site supervisor (Bradfield visited occasionally throughout the project and, in particular, at many key stages of the project, to inspect progress and make managerial decisions), Judge was chief technical engineer of Dorman Long, and Freeman was hired by the company to design the accepted model in further detail. Later a bitter disagreement broke out between Bradfield and Freeman as to who actually designed the bridge. Another name connected with the bridge's design is that of Arthur Plunkett.
The official ceremony to mark the "turning of the first sod" occurred on 28 July 1923, on the spot at Milsons Point on the north shore where two workshops to assist in building the bridge were to be constructed.
An estimated 469 buildings on the north shore, both private homes and commercial operations, were demolished to allow construction to proceed, with little or no compensation being paid. Work on the bridge itself commenced with the construction of approaches and approach spans, and by September 1926 concrete piers to support the approach spans were in place on each side of the harbour.
As construction of the approaches took place, work was also started on preparing the foundations required to support the enormous weight of the arch and loadings. Concrete and granite faced abutment towers were constructed, with the angled foundations built into their sides.
Once work had progressed sufficiently on the support structures, a giant "creeper crane" was erected on each side of the harbour. These cranes were fitted with a cradle, and then used to hoist men and materials into position to allow for erection of the steelwork. To stabilise works while building the arches, tunnels were excavated on each shore with steel cables passed through them and then fixed to the upper sections of each half-arch to stop them collapsing as they extended outwards.
Arch construction itself began on 26 October 1928. The southern end of the bridge was worked on ahead of the northern end, to detect any errors and to help with alignment. The cranes would "creep" along the arches as they were constructed, eventually meeting up in the middle. In less than two years, on Tuesday, 19 August 1930, the two halves of the arch touched for the first time. Workers riveted both top and bottom sections of the arch together, and the arch became self-supporting, allowing the support cables to be removed. On 20 August 1930 the joining of the arches was celebrated by flying the flags of Australia and the United Kingdom (Australia being very much part of the British Commonwealth) from the jibs of the creeper cranes.
Once the arch was completed, the creeper cranes were then worked back down the arches, allowing the roadway and other parts of the bridge to be constructed from the centre out. The vertical hangers were attached to the arch, and these were then joined with horizontal crossbeams. The deck for the roadway and railway were built on top of the crossbeams, with the deck itself being completed by June 1931, and the creeper cranes were dismantled. Rails for trains and trams were laid, and road was surfaced using concrete topped with asphalt. Power and telephone lines, and water, gas, and drainage pipes were also all added to the bridge in 1931.
The pylons were built atop the abutment towers, with construction advancing rapidly from July 1931. Carpenters built wooden scaffolding, with concreters and masons then setting the masonry and pouring the concrete behind it. Gangers built the steelwork in the towers, while day labourers manually cleaned the granite with wire brushes. The last stone of the north-west pylon was set in place on 15 January 1932, and the timber towers used to support the cranes were removed.
On 19 January 1932, the first test train, a steam locomotive, safely crossed the bridge. Load testing of the bridge took place in February 1932, with the four rail tracks being loaded with as many as 96 steam locomotives positioned end-to-end. The bridge underwent testing for three weeks, after which it was declared safe and ready to be opened. The construction worksheds were demolished after the bridge was completed, and the land that they were on is now occupied by Luna Park.
The standards of industrial safety during construction were poor by today's standards. Sixteen workers died during construction, but surprisingly only two from falling off the bridge. Several more were injured from unsafe working practices undertaken whilst heating and inserting its rivets, and the deafness experienced by many of the workers in later years was blamed on the project. Henri Mallard between 1930 and 1932 produced hundreds of stills and film footage which reveal at close quarters the bravery of the workers in tough Depression-era conditions.
The total financial cost of the bridge was AU£6.25 million, which was not paid off in full until 1988.
Opening.
The bridge was formally opened on Saturday, 19 March 1932. Amongst those who attended and gave speeches were the state Governor, Sir Philip Game, the Minister for Public Works, and Lawrence Ennis. The Labor Premier of New South Wales, Jack Lang, was to open the bridge by cutting a ribbon at its southern end.
However, just as Lang was about to cut the ribbon, a man in military uniform rode up on a horse, slashing the ribbon with his sword and opening the Sydney Harbour Bridge in the name of the people of New South Wales before the official ceremony began. He was promptly arrested. The ribbon was hurriedly retied and Lang performed the official opening ceremony. After he did so, there was a 21-gun salute and an RAAF flypast. The intruder was identified as Francis de Groot. He was convicted of offensive behaviour and fined £5 after a psychiatric test proved he was sane, but this verdict was reversed on appeal. De Groot then successfully sued the Commissioner of Police for wrongful arrest, and was awarded an undisclosed out of court settlement. De Groot was a member of a right-wing paramilitary group called the New Guard, opposed to Lang's leftist policies and resentful of the fact that a member of the Royal Family had not been asked to open the bridge. De Groot was not a member of the regular army but his uniform allowed him to blend in with the real cavalry. This incident was one of several involving Lang and the New Guard during that year.
A similar ribbon-cutting ceremony on the bridge's northern side by North Sydney's mayor, Alderman Primrose, was carried out without incident. It was later discovered that Primrose was also a New Guard member but his role in and knowledge of the de Groot incident, if any, are unclear. The pair of golden scissors used in the ribbon cutting ceremonies on both sides of the bridge was also used to cut the ribbon at the dedication of the Bayonne Bridge, which had opened in Bayonne, New Jersey, close to New York City, the year before.
Despite the bridge opening in the midst of the Great Depression, opening celebrations were organised by the Citizens of Sydney Organising Committee, an influential body of prominent men and politicians that formed in 1931 under the chairmanship of the Lord Mayor to oversee the festivities. The celebrations included an array of decorated floats a procession of passenger ships sailing below the bridge, and a Venetian Carnival. A message from a primary school in Tottenham, 515 km away in rural New South Wales, arrived at the bridge on the day and was presented at the opening ceremony. It had been carried all the way from Tottenham to the bridge by relays of school children, with the final relay being run by two children from the nearby Fort Street Boys' and Girls' schools. The City of Sydney organising Committee also announced plans for a Great Eisteddfod. Lord Mayor told the press that the competition would begin at the Town Hall in August 1933 and thus began the Sydney Eisteddfod.
After the official ceremonies, the public was allowed to walk across the bridge on the deck, something that would not be repeated until the 50th anniversary celebrations. Estimates suggest that between 300,000 and one million people took part in the opening festivities, a phenomenal number given that the entire population of Sydney at the time was only a little over a million people.
There had also been numerous preparatory arrangements. On 14 March 1932, three postage stamps were issued to commemorate the imminent opening of the bridge. Several songs were composed for the occasion.
The bridge itself was regarded as a triumph over Depression times, earning the nickname "the Iron Lung", as it kept many Depression-era workers employed.
Operations.
In 2010, the average daily traffic included 204 trains, 160,435 vehicles and 1650 bicycles. 
Road.
From the Sydney CBD side, motor vehicle access to the bridge is normally via Grosvenor Street, Clarence Street, Kent Street, the Cahill Expressway, or the Western Distributor. Drivers on the northern side will find themselves on the Warringah Freeway, though it is easy to turn off the freeway to drive westwards into North Sydney or eastwards to Neutral Bay and beyond upon arrival on the northern side.
The bridge originally only had four wider traffic lanes occupying the central space which now has six, as photos taken soon after the opening clearly show. In 1958 tram services across the bridge were withdrawn and the tracks replaced by two extra road lanes; these lanes are now the leftmost southbound lanes on the bridge and are still clearly distinguishable from the other six road lanes. Lanes 7 and 8 now connect the bridge to the elevated Cahill Expressway that carries traffic to the Eastern Distributor.
In 1988, work began to build a tunnel to complement the bridge. It was determined that the bridge could no longer support the increased traffic flow of the 1980s. The Sydney Harbour Tunnel was completed in August 1992. It is intended for use only by motor vehicles.
The Bradfield Highway is designated as a Travelling Stock Route which means that it is permissible to herd livestock across the bridge, but only between midnight and dawn, and after giving notice of intention to do so. In practice, owing to the high-density urban nature of modern Sydney, and the relocation of abattoirs and markets, this has not taken place for approximately half a century.
Tidal flow.
The bridge is equipped for tidal flow operation, permitting the direction of traffic flow on the bridge to be altered to better suit the morning and evening rush hours' traffic patterns.
The bridge has eight lanes in total, numbered one to eight from west to east. Lanes three, four and five are reversible. One and two always flow north. Six, seven, and eight always flow south. The default is four each way. For the morning rush hour, the lane changes on the bridge also require changes to the Warringah Freeway, with its inner western reversible carriageway directing traffic to the bridge lane numbers three and four southbound.
The bridge has a series of overhead gantries which indicate the direction of flow for each traffic lane. A green arrow pointing down to a traffic lane means the lane is open. A flashing red "X" indicates the lane is closing, but is not yet in use for traffic travelling in the other direction. A static red "X" means the lane is in use for oncoming traffic. This arrangement was introduced in the 1990s, replacing a slow operation where lane markers were manually moved to mark the centre median.
It is possible to see odd arrangements of flow during night periods when maintenance occurs, which may involve completely closing some lanes. Normally this is done between midnight and dawn, because of the enormous traffic demands placed on the bridge outside these hours.
Tolls.
The vehicular traffic lanes on the bridge are operated as a toll road. As of 27 January 2009 there is a variable tolling system for all vehicles headed into the CBD (southbound). The toll paid is dependent on the time of day in which the vehicle passes through the toll plaza. The toll varies from a minimum value of $2.50 to a maximum value of $4. There is no toll for northbound traffic (though taxis travelling north may charge passengers the toll in anticipation of the toll the taxi must pay on the return journey). There are toll plazas at the northern and southern ends. The two eastern lanes (which continue over the Cahill Expressway at the southern end of the bridge) have their tollbooths at the northern end, while the other southbound lanes (for CBD traffic) are serviced by tollbooths at the southern end of the bridge. There is a bridge-long median strip between lanes 6 and 7 to separate traffic which has already paid the toll (at the northern end) from other southbound traffic (which must pay the toll at the southern end).
The toll was originally placed on travel across the bridge, in both directions, to recoup the cost of its construction. This cost was recovered in the 1980s, but the toll has been kept (indeed increased) by the state government's Roads and Traffic Authority to recoup the costs of the Sydney Harbour Tunnel.
After the decision to build the Sydney Harbour Tunnel was made in the early 1980s, the toll was increased (from 20 cents to $1, then to $1.50, and finally to $2 by the time the tunnel opened) to pay for its construction. The tunnel also had an initial toll of $2 southbound. After the increase to $1, the concrete barrier on the bridge separating the Bradfield Highway from the Cahill Expressway was increased in height, because of the large numbers of drivers crossing it illegally from lane 6 to 7, to avoid the toll. The toll for all southbound vehicles was increased to $3 in March 2004.
Originally it cost a car or motorcycle six pence to cross, a horse and rider being three pence. Use of the bridge by bicycle riders (provided that they use the cycleway) and by pedestrians is free. Later governments capped the fee for motorcycles at one-quarter of the passenger-vehicle cost, but now it is again the same as the cost for a passenger vehicle.
In July 2008 a new electronic tolling system called e-TAG was introduced. The Sydney Harbour Tunnel was converted to this new tolling system while the Sydney Harbour Bridge itself had several cash lanes. The electronic system as of 12 January 2009 has now replaced all booths with E-tag lanes.
Pedestrians.
The pedestrian-only footway is located on the east side of the bridge. Access from the northern side involves climbing an easily spotted flight of stairs, located on the east side of the bridge at Broughton St, Kirribilli. Pedestrian access on the southern side is more complicated, but signposts in the Rocks area now direct pedestrians to the long and sheltered flight of stairs that leads to the bridge's southern end. These stairs are located near Gloucester Street and Cumberland Street.
The bridge can also be approached from the south by accessing Cahill Walk, which runs along the Cahill Expressway. Pedestrians can access this walkway from the east end of Circular Quay by a flight of stairs or a lift. Alternatively it can be accessed from the Botanic Gardens.
Cyclists.
The bike only cycleway is located on the west side of the bridge. Access from the northern side involves carrying or pushing a bicycle up a staircase, consisting of 55 steps, located on the west side of the bridge at Burton St, Milsons Point. A campaign to eliminate the steps on this popular cycling route to the CBD has been running since at least 2008. Cyclist access on the southern side is via the north end of the Kent St. cycleway and/or Upper Fort St.
Rail.
The bridge lies between Milsons Point and Wynyard railway stations, located on the north and south shores respectively, with two tracks running along the western side of the bridge. These tracks are part of the North Shore railway line.
In 1958 tram services across the bridge were withdrawn and the tracks they had used were removed and replaced by two extra road lanes; these lanes are now the leftmost southbound lanes on the bridge and are still clearly distinguishable from the other six road lanes. The original ramp that took the trams into their terminus at the underground Wynyard railway station is still visible at the southern end of the main walkway under lanes 7 and 8, although the tunnels have been converted into a car park and firing range.
Maintenance.
The Sydney Harbour Bridge requires constant inspections and other maintenance work to keep it safe for the public, and to protect from corrosion. Among the trades employed on the bridge are painters, ironworkers, boilermakers, fitters, electricians, plasterers, carpenters, plumbers, and riggers.
The most noticeable maintenance work on the bridge involves painting. The steelwork of the bridge that needs to be painted is a combined 485000 m2, the equivalent of sixty football fields. Each coat on the bridge requires some 30000 l of paint. A special fast-drying paint is used, so that any paint drops have dried before reaching the vehicles or bridge surface. One notable identity from previous bridge-painting crews is Australian comedian and actor Paul Hogan, who worked as a bridge painter before rising to media fame in the 1970s.
In 2003 the Roads & Traffic Authority began completely repainting the southern approach spans of the bridge. This involved removing the old lead-based paint, and repainting the 90000 m2 of steel below the deck. Workers operated from self-contained platforms below the deck, with each platform having an air extraction system to filter airborne particles. An abrasive blasting was used, with the lead waste collected and safely removed from the site for disposal.
Between December 2006 and March 2010 the bridge was subject to works designed to ensure its longevity. The work included some strengthening.
Since 2013, two grit-blasting robots specially developed with the University of Technology, Sydney have been employed to help with the paint stripping operation on the bridge. The robots, nicknamed Rosie and Sandy, are intended to reduce workers' potential exposure to dangerous lead paint and asbestos and the blasting equipment which has enough force to cut through clothes and skin.
Tourism.
South-east pylon.
Even during its construction, the bridge was such a prominent feature of Sydney that it would attract tourist interest. One of the ongoing tourist attractions of the bridge has been the south-east pylon, which is accessed via the pedestrian walkway across the bridge, and then a climb to the top of the pylon of about 200 steps.
Not long after the bridge's opening, commencing in 1934, Archer Whitford first converted this pylon into a tourist destination. He installed a number of attractions, including a café, a camera obscura, an Aboriginal museum, a "Mother's Nook" where visitors could write letters, and a "pashometer". The main attraction was the viewing platform, where "charming attendants" assisted visitors to use the telescopes available, and a copper cladding (still present) over the granite guard rails identified the suburbs and landmarks of Sydney at the time.
The outbreak of World War II in 1939 saw tourist activities on the bridge cease, as the military took over the four pylons and modified them to include parapets and anti-aircraft guns.
In 1948 Yvonne Rentoul opened the "All Australian Exhibition" in the pylon. This contained dioramas, and displays about Australian perspectives on subjects such as farming, sport, transport, mining, and the armed forces. An orientation table was installed at the viewing platform, along with a wall guide and binoculars. The owner kept several white cats in a rooftop cattery, which also served as an attraction, and there was a souvenir shop and postal outlet. Rentoul's lease expired in 1971, and the pylon and its lookout remained closed to the public for over a decade.
The pylon was reopened in 1982, with a new exhibition celebrating the bridge's 50th anniversary. In 1987 a "Bicentennial Exhibition" was opened to mark the 200th anniversary of European settlement in Australia in 1988.
The pylon was closed from April to November 2000 for the Roads & Traffic Authority and BridgeClimb to create a new exhibition called "Proud Arch". The exhibition focussed on Bradfield, and included a glass direction finder on the observation level, and various important heritage items.
The pylon again closed for four weeks in 2003 for the installation of an exhibit called "Dangerous Works", highlighting the dangerous conditions experienced by the original construction workers on the bridge, and two stained glass feature windows in memory of the workers.
BridgeClimb.
In 1950s and 1960s there were occasional newspaper reports of climbers who had made illegal arch traversals of the bridge, invariably by night. In 1973 Philippe Petit walked across a wire between the two pylons at the southern end of the Sydney Harbour Bridge. Since 1998, BridgeClimb has made it possible for tourists to legally climb the southern half of the bridge. Tours run throughout the day, from dawn to night, and are only cancelled for electrical storms or high wind.
Groups of climbers are provided with protective clothing appropriate to the prevailing weather conditions, and are given an orientation briefing before climbing. During the climb, attendees are secured to the bridge by a wire lifeline. Each climb begins on the eastern side of the bridge and ascends to the top. At the summit, the group crosses to the western side of the arch for the descent. Each climb takes three-and-a-half-hours, including the preparations.
In December 2006, BridgeClimb launched an alternative to climbing the upper arches of the bridge. The Discovery Climb allows climbers to ascend the lower chord of the bridge and view its internal structure. From the apex of the lower chord, climbers ascend a staircase to a platform at the summit.
Celebrations.
Since the opening, the bridge has been the focal point of much tourism and national pride.
50th Anniversary celebrations (1982).
In 1982 the bridge celebrated the 50th anniversary of its opening. For the first time since its opening in 1932, the bridge was closed to vehicles, and pedestrians were allowed full access for the day. The celebrations were attended by Edward Judge, who represented Dorman Long.
Bicentennial Australia Day celebrations (1988).
Australia's bicentennial celebrations on 26 January 1988 attracted large crowds in the bridge's vicinity as merrymakers flocked to the foreshores to view the events on the harbour. The highlight was the biggest parade of sail ever held in Sydney, square-riggers from all over the world, surrounded by hundreds of smaller craft of every description, passing majestically under the Sydney Harbour Bridge. The day's festivities culminated in a fireworks display in which the bridge was the focal point of the finale, with fireworks streaming from the arch and roadway. This was to become the pattern for later firework displays.
Sydney New Year's Eve (1993–present).
The Harbour Bridge is an integral part of the Sydney New Year's Eve celebrations, generally being used in spectacular ways during the fireworks displays at 9:00 P.M. and midnight. In recent times, the bridge has included a ropelight display on a framework in the centre of the eastern arch, which is used to complement the fireworks. As the scaffolding and framework are clearly visible for some weeks before the event, revealing the outline of the design, there is much speculation as to how the effect is to be realised.
During the millennium celebrations in 2000, the Sydney Harbour Bridge was lit up with the word "Eternity", as a tribute to the legacy of Arthur Stace a Sydney artist who for many years inscribed that word on pavements in chalk in beautiful copperplate writing despite the fact that he was illiterate.
The effects have been as follows:
The numbers for the New Year's Eve countdown also appear on the eastern side of the Bridge pylons.
Walk for Reconciliation (2000).
In May 2000 the bridge was closed to vehicular access for a day to allow a special reconciliation march—the "Walk for Reconciliation"—to take place. This was part of a response to an Aboriginal Stolen Generations inquiry, which found widespread suffering had taken place amongst Australian Aboriginal children forcibly placed into the care of white parents in a little-publicised state government scheme. Between 200,000 and 300,000 people were estimated to have walked the bridge in a symbolic gesture of crossing a divide.
Sydney 2000 Olympics.
During the Sydney 2000 Olympics in September and October 2000, the bridge was adorned with the Olympic Rings. It was included in the Olympic torch's route to the Olympic stadium. The men's and women's Olympic marathon events likewise included the bridge as part of their route to the Olympic stadium. A fireworks display at the end of the closing ceremony ended at the bridge. The east-facing side of the bridge has been used several times since as a framework from which to hang static fireworks, especially during the elaborate New Year's Eve displays.
Formula One promotion (2005).
In 2005 Mark Webber drove a Williams-BMW Formula One car across the bridge.
75th anniversary (2007).
In 2007, the 75th anniversary of its opening was commemorated with an exhibition at the Museum of Sydney, called "Bridging Sydney". An initiative of the Historic Houses Trust, the exhibition featured dramatic photographs and paintings with rare and previously unseen alternative bridge and tunnel proposals, plans and sketches.
On 18 March 2007, the Sydney Harbour Bridge celebrated its 75th anniversary. The occasion was marked with a ribbon-cutting ceremony by the governor, Marie Bashir and the premier of New South Wales, Morris Iemma. The bridge was subsequently open to the public to walk southward from Milsons Point or North Sydney. Several major roads, mainly in the CBD, were closed for the day. An Aboriginal smoking ceremony was held at 7 pm.
Approximately 250,000 people (50,000 more than were registered) took part in the event. Bright yellow souvenir caps were distributed to walkers. A series of speakers placed at intervals along the bridge formed a sound installation. Each group of speakers broadcast sound and music from a particular era (e.g. King Edward VIII's abdication speech; Gough Whitlam's speech at Parliament House in 1975), the overall effect being that the soundscape would "flow" through history as walkers proceeded along the bridge. A light-show began after sunset and continued late into the night, the bridge being bathed in constantly changing, multi-coloured lighting, designed to highlight structural features of the bridge. In the evening the bright green caps were replaced by orange caps with a small, bright LED attached. The bridge was closed to walkers at about 8.30 p.m.
Breakfast on the Bridge (2009–10).
On 25 October 2009 turf was laid across the eight lanes of bitumen, and 6,000 people celebrated a picnic on the bridge accompanied by live music. The event was repeated in 2010. Although originally scheduled again in 2011, this event was moved to Bondi Beach due to traffic concerns about the prolonged closing of the bridge.
80th anniversary.
On 19 March 2012 the 80th anniversary of the Sydney Harbour Bridge was celebrated with a picnic dedicated to the stories of people with personal connections to the bridge. In addition, Google dedicated its Google Doodle on the 19th to the event.
The proposal to upgrade the bridge tolling equipment was announced by the NSW Roads Minister Duncan Gay.
Quotations.
There the proud arch Colossus like bestrideYon glittering streams and bound the strafing tide.—Prophetic observation of Sydney Cove by Erasmus Darwin, grandfather of Charles Darwin, from his poem "Visit of Hope to Sydney Cove, near Botany Bay", (1789).
I open this bridge in the name of His Majesty the King and all the decent citizens of NSW.—Francis de Groot "opening" the Sydney Harbour Bridge, (1932). His organisation, the New Guard, had resented the fact that King George V had not been asked to open the bridge.
To get on in Australia, you must make two observations. Say, "You have the most beautiful bridge in the world" and "They tell me you trounced England again in the cricket." The first statement will be a lie. Sydney Bridge ["sic"] is big, utilitarian and the symbol of Australia, like the Statue of Liberty or the Eiffel Tower. But it is very ugly. No Australian will admit this.—James Michener assesses the Sydney Harbour Bridge in his book "Return to Paradise", (1951).
...you can see it from every corner of the city, creeping into frame from the oddest angles, like an uncle who wants to get into every snapshot. From a distance it has a kind of gallant restraint, majestic but not assertive, but up close it is all might. It soars above you, so high that you could pass a ten-storey building beneath it, and looks like the heaviest thing on earth. Everything that is in it – the stone blocks in its four towers, the latticework of girders, the metal plates, the six-million rivets (with heads like halved apples) – is the biggest of its type you have ever seen... This is a great bridge.—American travel-writer Bill Bryson's impressions of the Sydney Harbour Bridge in his book "Down Under", (2000).
Sydney Harbour Bridge as viewed from Kirribilli on the North Shore, with the Sydney Opera House on the left.
External links.
Webcams:
Images:

</doc>
<doc id="28269" url="http://en.wikipedia.org/wiki?curid=28269" title="Saving Private Ryan">
Saving Private Ryan

Saving Private Ryan is a 1998 American epic drama war film set during the Invasion of Normandy in World War II. Directed by Steven Spielberg and written by Robert Rodat, the film is notable for its graphic and realistic portrayal of war, and for the intensity of its opening 27 minutes, which depict the Omaha Beach assault of June 6, 1944. It follows United States Army Rangers Captain John H. Miller (Tom Hanks) and a squad (Tom Sizemore, Edward Burns, Barry Pepper, Vin Diesel, Giovanni Ribisi, Adam Goldberg, and Jeremy Davies) as they search for a paratrooper, Private First Class James Francis Ryan (Matt Damon), who is the last-surviving brother of four servicemen.
"Saving Private Ryan" received universal critical acclaim, winning several awards for film, cast, and crew as well as earning significant returns at the box office. The film grossed US$481.8 million worldwide, making it the second highest-grossing film of the year. The Academy of Motion Picture Arts and Sciences nominated the film for eleven Academy Awards; Spielberg's direction won him a second Academy Award for Best Director, with four more awards going to the film. "Saving Private Ryan" was released on home video in May 1999, earning $44 million from sales. In 2014, "Saving Private Ryan" was selected for preservation in the National Film Registry as per being deemed "culturally, historically, or aesthetically significant."
Plot.
On the morning of June 6, 1944, the beginning of the Normandy Invasion, American soldiers prepare to land on Omaha Beach. They suffer heavily from their struggle against German infantry, machine gun nests, and artillery fire. Captain John H. Miller, a company commander of the 2nd Ranger Battalion, survives the initial landing and assembles a group of his Rangers to penetrate the German defenses, leading to a breakout from the beach. In Washington, D.C, at the U.S. War Department, General George Marshall is informed that three of the four brothers of the Ryan family were killed in action and that their mother is to receive all three telegrams in the same day. He learns that the fourth son, Private First Class James Francis Ryan, is a paratrooper and is missing in action somewhere in Normandy. Marshall, after reading Abraham Lincoln's Bixby letter, orders that Ryan be found and sent home immediately.
Three days after D-Day, Miller receives orders to find Ryan and bring him back from the front. He assembles six men from his company— TSgt. Mike Horvath, Privates Richard Reiben, Stanley Mellish, Adrian Caparzo, Danny Jackson, medic Irwin Wade—and T/5 Timothy Upham, a cartographer who speaks French and German, loaned from the 29th Infantry Division. Miller and his men move out to Neuville; there, they meet a platoon from the 101st Airborne Division, and Caparzo dies after being shot by a sniper, who Jackson kills with a skillful shot. Eventually, they locate a Private James Ryan, but soon learn that he is not their man. They find a member of Ryan's regiment who informs them that his drop zone was at Vierville and that his and Ryan's companies had the same rally point. Once they reach it, Miller meets a friend of Ryan's, who reveals that Ryan is defending a strategically important bridge over the Merderet River in the town of Ramelle. On the way to Ramelle, Miller decides to neutralize a German machine gun position, despite the misgivings of his men. Wade is fatally wounded in the ensuing skirmish, but Miller, at Upham's urging, declines to execute a surviving German and sets him free on condition that he gives himself up. No longer confident in Miller's leadership, Reiben declares his intention to desert the squad and the mission, prompting a confrontation with Horvath. The argument heats up until Miller defuses the situation by revealing his origins, upon which the squad had earlier set up a betting pool. Reiben then reluctantly decides to stay.
Upon arrival at Ramelle, Miller and the squad come upon a small group of paratroopers commanded by Corporal Henderson, one of whom is Ryan. Ryan is told of his brothers' deaths, the mission to bring him home, and that two men had been lost in the quest to find him. He is distressed at the loss of his brothers, but does not feel it is fair to go home, asking Miller to tell his mother that he intends to stay "with the only brothers [he has] left." Miller decides to take command and defend the bridge with what little manpower and resources are available. Elements of the 2nd SS Panzer Division arrive with infantry and armor. In the ensuing battle, while inflicting heavy German casualties, most of the Americans—including Jackson, Mellish, Horvath, and all the paratroopers, save Ryan—are killed. While attempting to blow the bridge, Miller is shot and mortally wounded by the German prisoner set free earlier, who has returned to battle alongside the SS. Just before a Tiger tank reaches the bridge, an American P-51 Mustang flies over and destroys the tank, followed by American reinforcements who rout the remaining Germans. Upham, furious at the perfidy of the German prisoner, shoots him, and the rest flee in panic.
Reiben and Ryan are with Miller as he dies and says his last words, "James ... earn this. Earn it." In the present day, the elderly Ryan and his family visit the Normandy American Cemetery and Memorial. Ryan stands at Miller's grave and asks his wife to confirm that he has led a good life, that he is a "good man" and thus worthy of the sacrifice of Miller and the others. His wife replies, "You are." At this point, Ryan stands at attention and delivers a military salute towards Miller's grave.
Production.
Development.
In 1994, Robert Rodat saw a monument in Putney Corners, New Hampshire, memorializing Americans who were killed from the American Civil War to the Vietnam War. He noticed the names of eight siblings who died during the American Civil War. Inspired by the story, Rodat did some research and decided to write a similar story set in World War II. Rodat's script was submitted to producer Mark Gordon, who liked the story but only accepted the text after 11 redrafts. Gordon shared the finished script with Hanks, who liked it and in turn passed it along to Spielberg to direct. A shooting date was set for June 27, 1997.
Pre-production.
Before filming began, several of the film's stars, including Edward Burns, Barry Pepper, Vin Diesel, Adam Goldberg, Giovanni Ribisi, and Tom Hanks, endured ten days of "boot camp" training led by Marine veteran Dale Dye and Warriors, Inc., a California-based company that specializes in training actors for realistic military portrayals. Matt Damon was intentionally not brought into the camp, to make the rest of the group feel resentment towards the character.
Spielberg had already demonstrated his interest in World War II themes with the films "1941", "Empire of the Sun", "Schindler's List", and the "Indiana Jones" series. Spielberg later co-produced the World War II themed television miniseries "Band of Brothers" and its counterpart "The Pacific" with Tom Hanks. When asked about this by "American Cinematographer", Spielberg said, "I think that World War II is the most significant event of the last 100 years; the fate of the baby boomers and even Generation X was linked to the outcome. Beyond that, I've just always been interested in World War II. My earliest films, which I made when I was about 14 years old, were combat pictures that were set both on the ground and in the air. For years now, I've been looking for the right World War II story to shoot, and when Robert Rodat wrote "Saving Private Ryan", I found it."
Filming.
The D-Day scenes were shot in Ballinesker Beach, Curracloe Strand, Ballinesker, just east of Curracloe, County Wexford, Ireland. Filming began June 27, 1997, and lasted for two months. Some shooting was done in Normandy, for the Normandy American Cemetery and Memorial in Colleville-sur-Mer and Calvados. Other scenes were filmed in England, such as a former British Aerospace factory in Hatfield, Hertfordshire, Thame Park, Oxfordshire and Wiltshire. Production was due to also take place in Seaham, County Durham, but government restrictions disallowed this.
Portrayal of history.
"Saving Private Ryan" has received critical acclaim for its realistic portrayal of World War II combat. In particular, the sequence depicting the Omaha Beach landings was named the "best battle scene of all time" by "Empire" magazine and was ranked number one on "TV Guide's" list of the "50 Greatest Movie Moments". The scene cost US$12 million and involved up to 1,500 extras, some of whom were members of the Irish Reserve Defence Forces. Members of local reenactment groups such as the Second Battle Group were cast as extras to play German soldiers. In addition, twenty to thirty actual amputees were used to portray American soldiers maimed during the landing. Spielberg did not storyboard the sequence, as he wanted spontaneous reactions and for "the action to inspire me as to where to put the camera".
The historical representation of Charlie Company's actions, led by its commander, Captain Ralph E. Goranson, was well maintained in the opening sequence. The sequence and details of the events are very close to the historical record, including the seasickness experienced by many of the soldiers as the landing craft moved toward the shoreline, significant casualties among the men as they disembarked from the boats, and difficulty linking up with adjacent units on the shore. The contextual details of the Company's actions were well maintained, for instance, the correct code names for the sector Charlie Company assaulted, and adjacent sectors, were used. Included in the cinematic depiction of the landing was a follow-on mission of clearing a bunker and trench system at the top of the cliffs which was not part of the original mission objectives for Charlie Company, but which they did undertake after the assault on the beach.
The landing craft used included twelve actual World War II examples, 10 LCVPs and 2 LCMs, standing in for the British LCAs that the Ranger Companies rode in to the beach during Operation Overlord. The film-makers used underwater cameras to better depict soldiers being hit by bullets in the water. Forty barrels of fake blood were used to simulate the effect of blood in the seawater. This degree of realism was more difficult to achieve when depicting World War II German armored vehicles, as few examples survive in operating condition. The Tiger I tanks in the film were copies built on the chassis of old, but functional, Soviet T-34 tanks. The two vehicles described in the film as Panzers were meant to portray Marder III tank destroyers. One was created for the film using the chassis of a Czech-built Panzer 38(t) tank similar to the construction of the original Marder III; the other was a cosmetically modified Swedish SAV m/43 assault gun, which also used the 38(t) chassis.
Inevitably, some artistic license was taken by the filmmakers for the sake of drama, distorting the historical veracity of the film's presentation. There are strategic and operational, as well as tactical flaws in the film's depiction of the Normandy campaign. There is a strategic problem in that at the time of the mission, American forces from the two American beach areas of Utah and Omaha had not yet linked up. Had such a mission been executed in reality, a Ranger team operating out of the Omaha beach area would have had to move through the heavily enemy-occupied city of Carentan, or swim or boat across the estuary linking Carentan to the channel, or transfer by boat to the Utah landing area. On the other hand, US forces moving out of Utah would have had direct and much shorter routes, relatively unencumbered by enemy positions, and were already in contact with some teams from both US airborne divisions landed in the area. The Utah beach landings, however, were relatively uncontested, with assault units landing on largely unoccupied beaches, and experiencing far less action than the landings at Omaha. The film-makers chose to begin the narrative with a depiction of the more dramatic story of Omaha, despite the strategic inaccuracy of an impossible mission that could easily have been pursued from the other beach area. In addition, one of the most notable of the operational flaws is the depiction of the 2nd SS Panzer Division Das Reich, as the adversary during the fictional Battle of Ramelle. The 2nd SS was not engaged in Normandy until July, and then at Caen against the British and Canadians, one hundred miles east. Furthermore, the Merderet River bridges were not an objective of the 101st Airborne Division but of the 82nd Airborne Division, part of Mission Boston.
Much has also been said about various "tactical errors" made by both the German and American forces in the film's climactic battle. Spielberg responded, saying that in many scenes he opted to replace sound military tactics and strict historical accuracy for dramatic effect. Some other technical errors were also made, often censored, including the mistaken reversed orientation of the beach barriers; the tripod obstructions with a mine at the apex.
To achieve a tone and quality that was true to the story as well as reflected the period in which it is set, Spielberg once again collaborated with cinematographer Janusz Kamiński, saying, "Early on, we both knew that we did not want this to look like a Technicolor extravaganza about World War II, but more like color newsreel footage from the 1940s, which is very desaturated and low-tech." Kamiński had the protective coating stripped from the camera lenses, making them closer to those used in the 1940s. He explains that "without the protective coating, the light goes in and starts bouncing around, which makes it slightly more diffused and a bit softer without being out of focus." The cinematographer completed the overall effect by putting the negative through bleach bypass, a process that reduces brightness and color saturation. The shutter timing was set to 90 or 45 degrees for many of the battle sequences, as opposed to the standard of 180-degree timing. Kamiński clarifies, "In this way, we attained a certain staccato in the actors' movements and a certain crispness in the explosions, which makes them slightly more realistic."
Reception.
Box office.
"Saving Private Ryan" was a critical and commercial success and is credited with contributing to a resurgence in America's interest in World War II. Old and new films, video games, and novels about the war enjoyed renewed popularity after its release. The film's use of desaturated colors, hand-held cameras, and tight angles has profoundly influenced subsequent films and video games. "Saving Private Ryan" was released in 2,463 theaters on July 24, 1998, and grossed $30.5 million on its opening weekend. The film grossed $216.5 million in North America and $265.3 million in other territories, bringing its worldwide total to $481.8 million and making it the highest-grossing domestic film of the year.
Critical response.
The film received critical acclaim and has a 'certified fresh' rating of 93% on Rotten Tomatoes based on 124 reviews with an average score of 8.6 out of 10. The consensus states "Anchored by another winning performance from Hanks, Spielberg's unflinchingly realistic war film virtually redefines the genre." The film also has a score of 90 out of 100 on Metacritic based on 34 reviews indicating 'universal acclaim'.
Much of the praise went for the realistic battle scenes and the actors' performances. It earned some criticism for ignoring the contributions of several other countries to the D-Day landings in general and at Omaha Beach specifically. The most direct example of the latter is that during the actual landing the 2nd Rangers disembarked from British ships and were taken to Omaha Beach by Royal Navy landing craft (LCAs). The film depicts them as being United States Coast Guard-crewed craft (LCVPs and LCMs) from an American ship, the . This criticism was far from universal with other critics recognizing the director's intent to make an "American" film. The film was not released in Malaysia after Spielberg refused to cut the violent scenes; however, the film was finally released there on DVD with an 18SG certificate much later in 2005. Many critics associations, such as New York Film Critics Circle and Los Angeles Film Critics Association, chose "Saving Private Ryan" as Film of the Year. Roger Ebert gave it four stars out of four and called it "a powerful experience".
Filmmaker Quentin Tarantino has expressed admiration for the film and has cited it as an influence on his 2009 war epic, "Inglourious Basterds". Conversely, film director and military veteran Oliver Stone has accused the film of promoting "the worship of World War II as the good war," and has lumped it alongside films such as "Gladiator" and "Black Hawk Down" that he believes were well-made, but may have inadvertently contributed to Americans' readiness for the 2003 invasion of Iraq. In defense of the film's portrait of warfare, Brian De Palma commented, "The level of violence in something like "Saving Private Ryan" makes sense because Spielberg is trying to show something about the brutality of what happened."
Actor Richard Todd, who performed in "The Longest Day" and was amongst the first of the Allied soldiers to land in Normandy, said the film was "Rubbish. Overdone." Other World War II veterans, however, stated that the film was the most realistic depiction of combat they had ever seen. The film was so realistic that combat veterans of D-Day and Vietnam left theaters rather than finish watching the opening scene depicting the Normandy invasion. Their visits to posttraumatic stress disorder counselors rose in number after the film's release, and many counselors advised "'more psychologically vulnerable'" veterans to avoid watching it.
Awards.
The film was nominated for eleven Academy Awards, with wins for Best Cinematography, Best Sound, Best Sound Effects Editing, Best Film Editing, and Best Director for Spielberg, but lost the Best Picture award to "Shakespeare in Love", being one of a few that have won the Best Director award without also winning Best Picture. The Academy's decision to not award the film with the Best Picture Oscar has resulted in much criticism in recent years, many of whom believe it is one of the biggest Oscar snubs. The film also won the Golden Globes for Best Picture – Drama and Director, the BAFTA Award for Special Effects and Sound, the Directors Guild of America Award, a Grammy Award for Best Film Soundtrack, the Producers Guild of America Golden Laurel Award, and the Saturn Award for Best Action, Adventure, or Thriller Film. In June 2008, the American Film Institute revealed its "Ten Top Ten"—the best ten films in ten "classic" American film genres—after polling over 1,500 people from the creative community. "Saving Private Ryan" was listed as the eighth best film in the epic films genre.
Television broadcasts.
On Veterans Day from 2001–2004, the American Broadcasting Company aired the film uncut and with limited commercial interruption. The network airings were given a TV-MA rating, as the violent battle scenes and the profanity were left intact. The 2004 airing was marred by pre-emptions in many markets because of the language, in the backlash of Super Bowl XXXVIII's halftime show controversy. However, critics and veterans' groups such as the American Legion and the Veterans of Foreign Wars assailed those stations and their owners, including Hearst-Argyle Television (owner of 12 ABC affiliates); Scripps Howard Broadcasting (owner of six); and Belo (owner of four) for putting profits ahead of programming and honoring those who gave their lives at wartime, saying the stations made more money running their own programming instead of being paid by the network to carry the film, especially during a sweeps period. A total of 65 ABC affiliates—28% of the network—did not clear the available timeslot for the film, even with the offer of The Walt Disney Company, ABC's parent, to pay all fines for language to the Federal Communications Commission. In the end, however, no complaints were lodged against ABC affiliates who showed "Ryan", perhaps because even conservative watchdogs like the Parents Television Council supported the unedited rebroadcast of the film. Additionally, some ABC affiliates in other markets that were near affected markets, such as Youngstown, Ohio ABC affiliate WYTV (which is viewable in parts of the Columbus, Cleveland, and Pittsburgh markets, none of which aired the film), still aired the film and gave those nearby markets the option of viewing the film. TNT and Turner Classic Movies have also broadcast the film.
Home video.
The film was released on home video in May 1999 with a VHS release that earned over $44 million. The DVD release became available in November of the same year, and was one of the best-selling titles of the year, with over 1.5 million units sold. The DVD was released in two separate versions: one with Dolby Digital and the other with DTS 5.1 surround sound. Besides the different 5.1 tracks, the two DVDs are identical. The film was also issued in a very limited 2-disc LaserDisc release in November 1999, making it one of the very last feature films to ever be issued in this format, as LaserDiscs ceased manufacturing and distribution by the year's end, due in part to the growing popularity of DVDs.
In 2004, a "Saving Private Ryan" special edition DVD was released to commemorate the 60th anniversary of D-Day. This two-disc edition was also included in a box set titled "World War II Collection", along with two documentaries produced by Spielberg, "Price For Peace" (about the Pacific War) and "Shooting War" (about war photographers, narrated by Tom Hanks). The film was released on Blu-ray Disc on April 26, 2010 in the UK and on May 4, 2010 in the US, as part of Paramount Home Video's premium Sapphire Series. However, only weeks after its release, Paramount issued a recall due to audio synchronization problems. The studio issued an official statement acknowledging the problem, which they attributed to an authoring error by Technicolor that escaped the quality control process, and that they had already begun the process of replacing the defective discs.
Real-life similarities.
Niland brothers.
The Niland brothers were four American brothers of Irish descent from Tonawanda, New York, serving in the military during World War II. Of the four, two survived the war, but for a time it was believed that only one, Frederick "Fritz" Niland, had survived. After the reported deaths of his three brothers, Fritz was sent back to the United States to complete his service and only later learned that his brother Edward, missing and presumed dead, was actually captive in a Japanese POW camp in Burma.

</doc>
<doc id="28270" url="http://en.wikipedia.org/wiki?curid=28270" title="Shaggy dog story">
Shaggy dog story

In its original sense, a shaggy dog story is an extremely long-winded anecdote characterized by extensive narration of typically irrelevant incidents and terminated by an anticlimax or a pointless punchline.
Shaggy dog stories play upon the audience's preconceptions of joke-telling. The audience listens to the story with certain expectations, which are either simply not met or met in some entirely unexpected manner. A lengthy shaggy dog story derives its humour from the fact that the joke-teller held the attention of the listeners for a long time (such jokes can take five minutes or more to tell) for no reason at all, as the end resolution is essentially meaningless.
The archetypal shaggy dog story.
The commonly believed archetype of the shaggy dog story is a story that concerns a shaggy dog. The story builds up, repeatedly emphasizing how shaggy the dog is. At the climax of the story, someone in the story reacts with, "That dog's not so shaggy." The expectations of the audience that have been built up by the presentation of the story, that the story will end with a punchline, are thus disappointed. Ted Cohen gives the following example of this story:
A boy owned a dog that was uncommonly shaggy. Many people remarked upon its considerable shagginess. When the boy learned that there are contests for shaggy dogs, he entered his dog. The dog won first prize for shagginess in both the local and the regional competitions. The boy entered the dog in ever-larger contests, until finally he entered it in the world championship for shaggy dogs. When the judges had inspected all of the competing dogs, they remarked about the boy's dog: "He's not that shaggy."
However, authorities disagree as to whether this particular story is the archetype after which the category is named. Eric Partridge, for example, provides a very different story, as do William and Mary Morris in "The Morris Dictionary of Word and Phrase Origins".
According to Partridge and the Morrises, the archetypical shaggy dog story involves an advertisement placed in "The Times" announcing a search for a shaggy dog. In the Partridge story, an aristocratic family living in Park Lane is searching for a lost dog, and an American answers the advertisement with a shaggy dog that he has found and personally brought across the Atlantic, only to be received by the butler at the end of the story who takes one look at the dog and shuts the door in his face saying "But not so shaggy as "that", sir!" In the Morris story, the advertiser is organizing a competition to find the shaggiest dog in the world, and after a lengthy exposition of the search for such a dog a winner is presented to the aristocratic instigator of the competition, who says "I don't think he's so shaggy."
Examples in literature.
A typical shaggy dog story occurs in Mark Twain's book about his travels west, "Roughing It". Twain's friends encourage him to go find a man called Jim Blaine when he is properly drunk, and ask him to tell "the stirring story about his grandfather's old ram". Twain, encouraged by his friends who have already heard the story, finally finds Blaine, an old silver miner, who sets out to tell Twain and his friends the tale. Blaine starts out with the ram ("There never was a bullier old ram than what he was"), and goes on for four more mostly dull but occasionally hilarious unparagraphed pages. Along the way, Blaine tells many stories, each of which connects back to the one before by some tenuous thread, and none of which has to do with the old ram. Among these stories are: a tale of boiled missionaries; of a lady who borrows a false eye, a peg leg, and the wig of a coffin-salesman's wife; and a final tale of a man who gets caught in machinery at a carpet factory and whose "widder bought the piece of carpet that had his remains wove in..." As Blaine tells the story of the carpet man's funeral, he begins to fall asleep, and Twain, looking around, sees his friends "suffocating with suppressed laughter." They now inform him that "at a certain stage of intoxication, no human power could keep [Blaine] from setting out, with impressive unction, to tell about a wonderful adventure which he had once had with his grandfather's old ram — and the mention of the ram in the first sentence was as far as any man had heard him get, concerning it."
Examples in music.
Arlo Guthrie's classic anti-war story-song "Alice's Restaurant Massacree" is a shaggy dog story about the military draft, hippies, and improper disposal of garbage.
David Bromberg's version of "Bullfrog Blues" (on "How Late'll Ya Play 'Til?") is a rambling shaggy dog story performed as a talking blues song.

</doc>
<doc id="28271" url="http://en.wikipedia.org/wiki?curid=28271" title="Sushi">
Sushi

Sushi (すし, 寿司, 鮨) is a Japanese food consisting of cooked vinegared rice (鮨飯, sushi-meshi) combined with other ingredients (ネタ, neta), seafood, vegetables and sometimes tropical fruits. Ingredients and forms of sushi presentation vary widely, but the ingredient which all sushi have in common is rice (also referred to as "shari" (しゃり) or "sumeshi" (酢飯)).
Sushi can be prepared with either brown or white rice. Sushi is often prepared with raw seafood, but some common varieties of sushi use cooked ingredients or are vegetarian. Raw fish (or occasionally other meat) sliced and served without rice is called "sashimi".
Sushi is often served with pickled ginger (ガリ "gari"), wasabi, and soy sauce. Popular garnishes are often made using daikon.
History.
The original type of sushi, known today as "nare-zushi" (馴れ寿司, 熟寿司,) was first made in Southeast Asia, possibly along what is now known as the Mekong River. The term "sushi" comes from an archaic grammatical form no longer used in other contexts, and literally means "sour-tasting", a reflection of its historic origin as a fermented food. The oldest form of sushi in Japan, "narezushi", is still made by wrapping fish in soured fermenting rice, which causes the fish proteins to break down into their constituent amino acids. The fermenting rice and fish have both a sour and an "umami" taste.
Contemporary Japanese sushi has little resemblance to the traditional lacto-fermented rice dish. Originally, when the fermented fish was taken out of the rice, only the fish was consumed while the fermented rice was discarded. The strong-tasting and smelling "funazushi", a kind of "narezushi" made near Lake Biwa in Japan, resembles the traditional fermented dish. Beginning in the Muromachi period (1336–1573) of Japan, vinegar was added to the mixture for better taste and preservation. The vinegar accentuated the rice's sourness and was known to increase its shelf life, allowing the fermentation process to be shortened and eventually abandoned. In the following centuries, sushi in Osaka evolved into "oshi-zushi". The seafood and rice were pressed using wooden (usually bamboo) molds. By the mid 18th century, this form of sushi had reached Edo (contemporary Tokyo).
The contemporary version, internationally known as "sushi", was created by Hanaya Yohei (1799–1858) at the end of the Edo period in Edo. Sushi invented by Hanaya was an early form of fast food that was not fermented (therefore prepared quickly) and could be conveniently eaten with one's hands. The size of the previous sushi was about three times as large as contemporary ones. Originally, this sushi was known as "Edomae zushi" because it used freshly caught fish in the "Edo-mae" (Edo Bay or Tokyo Bay). Though the fish used in modern sushi no longer usually comes from Tokyo Bay, it is still formally known as "Edomae nigirizushi".
The "Oxford English Dictionary" notes the earliest written mention of sushi in English in an 1893 book, "A Japanese Interior", where it mentions sushi as "a roll of cold rice with fish, sea-weed, or some other flavoring". However, there is also mention of sushi in a Japanese-English dictionary from 1873, and an 1879 article on Japanese cookery in the journal "Notes and Queries".
Types.
The common ingredient across all kinds of sushi is vinegared "sushi rice". Variety arises from fillings, toppings, condiments, and preparation. Traditional versus contemporary methods of assembly may create very different results from very similar ingredients.
In spelling sushi, its first letter "s" is replaced with "z" when a prefix is attached, as in nigirizushi, due to consonant mutation called rendaku in Japanese.
Chirashizushi.
"Chirashizushi" (ちらし寿司, "scattered sushi") is a bowl of sushi rice topped with a variety of raw fish and vegetables/garnishes (also refers to "barazushi"). There is no set formula for the ingredients; they are either chef's choice or specified by the customer. It is commonly eaten because it is filling, fast and easy to make. "Chirashizushi" also often varies regionally. It is eaten annually on Hinamatsuri in March.
Inarizushi.
Inarizushi (稲荷寿司) is a pouch of fried tofu typically filled with sushi rice alone. It is named after the Shinto god "Inari", who is believed to have a fondness for fried tofu. The pouch is normally fashioned as deep-fried tofu (油揚げ, "abura age"). Regional variations include pouches made of a thin omelette (帛紗寿司, "fukusa-zushi", or 茶巾寿司, "chakin-zushi"). It should not be confused with "inari maki", which is a roll filled with flavored fried tofu.
A version of "inarizushi" that includes green beans, carrots, and gobo along with rice, wrapped in a triangular aburage (fried tofu) piece, is a Hawaiian specialty, where it is called cone sushi and is often sold in "okazu-ya" (Japanese delis) and as a component of bento boxes.
Makizushi.
Makizushi (巻き寿司, "rolled sushi"), norimaki (海苔巻き, "Nori roll") or makimono (巻物, "variety of rolls") is a cylindrical piece, formed with the help of a bamboo mat known as a "makisu" (巻簾). "Makizushi" is generally wrapped in nori (seaweed), but is occasionally wrapped in a thin omelette, soy paper, cucumber, or shiso (perilla) leaves. "Makizushi" is usually cut into six or eight pieces, which constitutes a single roll order. Below are some common types of "makizushi", but many other kinds exist.
Futomaki (太巻, "thick, large or fat rolls") is a large cylindrical piece, usually with "nori" on the outside. A typical "futomaki" is five to six centimeters (2–2.5 in) in diameter. They are often made with two, three, or more fillings that are chosen for their complementary tastes and colors. During the evening of the Setsubun festival, it is traditional in the Kansai region to eat uncut futomaki in its cylindrical form, where it is called "ehō-maki" (恵方巻, lit. happy direction rolls). By 2000 the custom had spread to all of Japan. Futomaki are often vegetarian, and may utilize strips of cucumber, "kampyō" gourd, "takenoko" bamboo shoots, or lotus root. Strips of "tamagoyaki" omelette, tiny fish roe, chopped tuna, and "oboro" whitefish flakes are typical non-vegetarian fillings.
Hosomaki (細巻, "thin rolls") is a small cylindrical piece, with "nori" on the outside. A typical "hosomaki" has a diameter of about two and a half centimeters (1 in). They generally contain only one filling, often tuna, cucumber, "kanpyō", thinly sliced carrots, or, more recently, avocado. "Kappamaki", (河童巻) a kind of "Hosomaki" filled with cucumber, is named after the Japanese legendary water imp fond of cucumbers called the kappa. Traditionally, "kappamaki" is consumed to clear the palate between eating raw fish and other kinds of food, so that the flavors of the fish are distinct from the tastes of other foods. "Tekkamaki" (鉄火巻) is a kind of "hosomaki" filled with raw tuna. Although it is believed that the word "tekka", meaning "red hot iron", alludes to the color of the tuna flesh or salmon flesh, it actually originated as a quick snack to eat in gambling dens called "tekkaba" (鉄火場), much like the sandwich. "Negitoromaki" (ねぎとろ巻) is a kind of "hosomaki" filled with scallion ("negi") and chopped tuna ("toro"). Fatty tuna is often used in this style. "Tsunamayomaki" (ツナマヨ巻) is a kind of "hosomaki" filled with canned tuna tossed with mayonnaise.
 Ehōmaki (恵方巻, "lucky direction roll") is a roll composed of 7 ingredients considered to be lucky. Ehōmaki are often eaten on setsubun in Japan. The typical ingredients include kanpyō, egg, eel, and shiitake mushrooms. Ehōmaki often include other ingredients too. People usually eat the ehōmaki while facing the direction considered to be auspicious that year. 
Temaki (手巻, "hand roll") is a large cone-shaped piece of "nori" on the outside and the ingredients spilling out the wide end. A typical "temaki" is about ten centimeters (4 in) long, and is eaten with fingers because it is too awkward to pick it up with chopsticks. For optimal taste and texture, "temaki" must be eaten quickly after being made because the "nori" cone soon absorbs moisture from the filling and loses its crispness, making it somewhat difficult to bite through. For this reason, the "nori" in pre-made or take-out temaki is sealed in plastic film which is removed immediately before eating.
Narezushi.
"Narezushi" (熟れ寿司, "matured sushi") is a traditional form of fermented sushi. Skinned and gutted fish are stuffed with salt, placed in a wooden barrel, doused with salt again, then weighed down with a heavy tsukemonoishi (pickling stone). As days pass, water seeps out and is removed. After six months, this "sushi" can be eaten, remaining edible for another six months or more. The most famous variety of "narezushi" still being produced is "funa-zushi" (made from fish of the crucian carp genus, authentically from "C. auratus grandoculis" ("nigoro-buna") endemic to Lake Biwa), a typical dish of Shiga Prefecture.
Nigirizushi.
"Nigirizushi" (握り寿司, "hand-pressed sushi") consists of an oblong mound of "sushi rice" that the chef presses into a small rectangular box between the palms of the hands, usually with a bit of "wasabi", and a topping (the "neta") draped over it. "Neta" are typically fish such as salmon, tuna or other seafood. Certain toppings are typically bound to the rice with a thin strip of "nori", most commonly octopus ("tako"), freshwater eel ("unagi"), sea eel ("anago"), squid ("ika"), and sweet egg ("tamago"). One order of a given type of fish typically results in two pieces, while a sushi set (sampler dish) may contain only one piece of each topping.
"Gunkanmaki" (軍艦巻, "warship roll") is a special type of "nigirizushi": an oval, hand-formed clump of sushi rice that has a strip of "nori" wrapped around its perimeter to form a vessel that is filled with some soft, loose or fine-chopped ingredient that requires the confinement of "nori" such as roe, "nattō", oysters, "uni" (sea urchin roe), corn with mayonnaise, scallops, and quail eggs. "Gunkan-maki" was invented at the "Ginza Kyubey" restaurant in 1941; its invention significantly expanded the repertoire of soft toppings used in sushi.
"Temarizushi" (手まり寿司, "ball sushi") is a ball-shaped sushi made by pressing rice and fish into a ball-shaped form by hand using a plastic wrap.
Oshizushi.
Oshizushi (押し寿司, "pressed sushi"), also known as 箱寿司, "hako-zushi", "box sushi"), is a pressed sushi from the Kansai region, a favorite and specialty of Osaka. A block-shaped piece is formed using a wooden mold, called an "oshibako". The chef lines the bottom of the "oshibako" with the toppings, covers them with sushi rice, and then presses the lid of the mold down to create a compact, rectilinear block. The block is removed from the mold and then cut into bite-sized pieces. Particularly famous is バッテラ ("battera", pressed mackerel sushi) or 鯖寿司 ("saba zushi"). In "oshizushi", all the ingredients are either cooked or cured and raw fish is never used.
Western-style sushi.
The increasing popularity of "sushi" around the world has resulted in variations typically found in the Western world, but rarely in Japan (a notable exception to this is the use of salmon which was introduced by the Norwegians in the early 1980s). Such creations to suit the Western palate were initially fueled by the invention of the California roll (a "norimaki" with crab (later, imitation crab), cucumber, and avocado). A wide variety of popular rolls ("norimaki" and "uramaki") has evolved since.
Uramaki.
Uramaki (裏巻, "inside-out roll") is a medium-sized cylindrical piece with two or more fillings, and was innovated as a result of the creation of the California roll, as a method originally meant to hide the nori. Uramaki differs from other "makimono" because the rice is on the outside and the "nori" inside. The filling is in the center surrounded by "nori", then a layer of rice, and optionally an outer coating of some other ingredients such as "roe" or toasted sesame seeds. It can be made with different fillings, such as tuna, crab meat, avocado, mayonnaise, cucumber or carrots.
Examples of variations include the rainbow roll (an inside-out topped with thinly sliced "maguro, hamachi, ebi, sake" and avocado) and the caterpillar roll (an inside-out topped with thinly sliced avocado). Also commonly found is the "rock and roll" (an inside-out roll with barbecued freshwater eel and avocado with toasted sesame seeds on the outside).
In Japan, "uramaki" is an uncommon type of "makimono"; because sushi is traditionally eaten by hand in Japan, the outer layer of rice can be quite difficult to handle with fingers.
United States–style makizushi.
"Futomaki" is a more popular variation of sushi within the United States, and comes in variations that take their names from their state of origin. Other rolls may include pretty much anything, including chopped scallops, spicy tuna, beef or chicken teriyaki roll, okra, and assorted vegetables such as cucumber and avocado, and the "tempura roll", where shrimp tempura is inside the roll or the entire roll is battered and fried tempura-style. In the Southern United States, many sushi restaurants prepare rolls using crawfish. Sometimes, rolls are made with brown rice or black rice, which appear in Japanese cuisine as well.
Per Food and Drug Administration regulations, raw fish served in the United States must be frozen prior to serving in order to kill parasites. Because of this and the relative difficulty of acquiring fresh seafood compared to Japan, raw seafood (e.g., sashimi) is not as prevalent of a component in American-style sushi.
Since rolls are usually made to-order, it is not unusual for the customer to specify the exact ingredients desired. Though the menu names of dishes often vary by restaurant, some examples include:
Ingredients.
All sushi has a base of specially prepared rice, complemented with other ingredients.
Sushi-meshi.
"Sushi-meshi" 鮨飯 (also known as "Su-meshi" 酢飯, "shari" 舎利, or "gohan" ご飯) is a preparation of white, short-grained, Japanese rice mixed with a dressing consisting of rice vinegar, sugar, salt, and occasionally kombu and "sake". It has to be cooled to room temperature before being used for a filling in a "sushi" or else it will get too sticky while being seasoned. Traditionally, the mixing is done with a hangiri, which is a round, flat-bottom wooden tub or barrel, and a wooden paddle (shamoji).
Sushi rice is prepared with short-grain Japanese rice, which has a consistency that differs from long-grain strains such as those from India, Pakistan, Thailand, and Vietnam. The essential quality is its stickiness or glutinousness, although the type of rice used for sushi is different from glutinous rice. Freshly harvested rice ("shinmai") typically contains too much water, and requires extra time to drain the rice cooker after washing. In some fusion cuisine restaurants, short grain brown rice and wild rice are also used.
There are regional variations in sushi rice and, of course, individual chefs have their individual methods. Most of the variations are in the rice vinegar dressing: the Kantō region (or East Japan) version of the dressing commonly uses more salt; in Kansai region (or West Japan), the dressing has more sugar.
Nori.
The black seaweed wrappers used in "makimono" are called "nori". "Nori" is a type of algae, traditionally cultivated in the harbors of Japan. Originally, algae was scraped from dock pilings, rolled out into thin, edible sheets, and dried in the sun, in a process similar to making rice paper. Today, the commercial product is farmed, processed, toasted, packaged, and sold in sheets.
The size of a "nori" sheet influences the size of "makimono". A full-size sheet produces "futomaki", and a half produces "hosomaki" and "temaki". To produce "gunkan" and some other "makimono", an appropriately-sized piece of "nori" is cut from a whole sheet.
"Nori" by itself is an edible snack and is available with salt or flavored with teriyaki sauce. The flavored variety, however, tends to be of lesser quality and is not suitable for sushi.
When making "fukusazushi", a paper-thin omelette may replace a sheet of "nori" as the wrapping. The omelette is traditionally made on a rectangular omelette pan (makiyakinabe), and used to form the pouch for the rice and fillings.
Neta.
For culinary, sanitary, and aesthetic reasons, the minimum quality and freshness of fish to be eaten raw must be superior to that of fish which is to be cooked. Sushi chefs are trained to recognize important attributes, including smell, color, firmness, and freedom from parasites that may go undetected in commercial inspection. Commonly used fish are tuna ("maguro, shiro-maguro"), Japanese amberjack, yellowtail ("hamachi"), snapper ("kurodai"), mackerel ("saba"), and salmon ("sake"). The most valued sushi ingredient is "toro," the fatty cut of the fish. This comes in a variety of "ōtoro" (often from the bluefin species of tuna) and "chūtoro", meaning "middle toro", implying that it is halfway into the fattiness between "toro" and the regular cut. "Aburi" style refers to "nigiri" sushi where the fish is partially grilled (topside) and partially raw. Most nigiri sushi will have completely raw "neta".
Other seafoods such as squid ("ika"), eel ("anago" and "unagi"), pike conger ("hamo"), octopus ("tako"), shrimp ("ebi" and "amaebi"), clam ("mirugai", "aoyagi" and "akagai"), fish roe ("ikura", "masago", "kazunoko" and "tobiko"), sea urchin ("uni"), crab ("kani"), and various kinds of shellfish (abalone, prawn, scallop) are the most popular seafoods in sushi. Oysters, however, are less common, as the taste is not thought to go well with the rice. "Kani kama", or imitation crab stick, is commonly substituted for real crab, most notably in California rolls.
Pickled daikon radish ("takuan") in "shinko maki", pickled vegetables ("tsukemono"), fermented soybeans ("nattō") in "nattō maki", avocado, cucumber in "kappa maki", asparagus, yam, pickled ume ("umeboshi"), gourd ("kanpyō"), burdock ("gobo"), and sweet corn (possibly mixed with mayonnaise) are also used in sushi.
Tofu and eggs (in the form of slightly sweet, layered omelette called "tamagoyaki" and raw quail eggs ride as a "gunkan-maki" topping) are common.
Condiments.
Sushi is commonly eaten with condiments. Sushi may be dipped in shōyu, soy sauce, and is usually flavored with wasabi, a piquant paste made from the grated root of the "Wasabia japonica" plant. Japanese-style mayonnaise is a common condiment in Japan on salmon, pork and other sushi cuts.
True wasabi has anti-microbial properties and may reduce the risk of food poisoning. The traditional grating tool for wasabi is a sharkskin grater or "samegawa oroshi". An imitation wasabi ("seiyo-wasabi"), made from horseradish, mustard powder and green dye is common. It is found at lower-end "kaiten-zushi" restaurants, in bento box sushi and at most restaurants outside Japan. If manufactured in Japan, it may be labelled "Japanese Horseradish".
Gari (sweet, pickled ginger) is eaten in between sushi courses to both cleanse the palate and aid in digestion. In Japan, green tea ("ocha") is invariably served together with sushi. Better sushi restaurants often use a distinctive premium tea known as "mecha". In sushi vocabulary, green tea is known as "agari".
Sushi may be garnished with gobo, grated daikon, thinly sliced vegetables, carrots/radishes/cucumbers that have been shaped to look like flowers, real flowers and/or seaweed salad.
When closely arranged on a tray, different pieces are often separated by green strips called "baran" or "kiri-zasa" (切り笹). Originally, these were cut leaves from the "Aspidistra elatior" (葉蘭 "haran") and "Sasa veitchii" (熊笹 "kuma-zasa") plants, respectively, but today the strips are usually made from green plastic.
Nutrition.
The main ingredients of traditional Japanese sushi, raw fish and rice, are naturally low in fat, high in protein, carbohydrates (the rice only), vitamins, and minerals, as are "gari" and "nori". Other vegetables wrapped within the sushi also offer various vitamins and minerals. Many of the seafood ingredients also contain omega-3 fatty acids, which have a variety of health benefits.
Health risks.
Some of the ingredients in sushi can present health risks. Large marine apex predators such as tuna (especially bluefin) can harbor high levels of methylmercury, which can lead to mercury poisoning when consumed in large quantity or when consumed by certain higher-risk groups, including women who might get pregnant, pregnant women, nursing mothers and young children.
Sashimi or other types of sushi containing raw fish present a risk of infection by three main types of parasites:
For the above reasons, EU regulations forbid the use of fresh raw fish. It must be frozen at temperatures below -20 °C in all parts of the product for no less than 24 hours. As such, a number of fishing boats, suppliers and end users "super-freeze" fish for sushi to temperatures as low as −60 °C. As well as parasite destruction, super-freezing also prevents oxidation of the blood in tuna flesh, thus preventing the discoloration that happens at temperatures above −20 °C.
Some forms of sushi, notably those containing pufferfish fugu and some kinds of shellfish, can cause severe poisoning if not prepared properly. Particularly, fugu consumption can be fatal – a few deaths occur in Japan every year from eating fugu fish sushi. Fugu fish has a lethal dose of tetrodotoxin in its internal organs and, by law in many countries, must be prepared by a licensed fugu chef who has passed the prefectural examination in Japan. The licensing examination process consists of a written test, a fish-identification test, and a practical test, preparing and eating the fish. Only about 35 percent of the applicants pass.
Presentation.
Traditionally, sushi is served on minimalist Japanese-style, geometric, mono- or duo-tone wood or lacquer plates, in keeping with the aesthetic qualities of this cuisine.
Many sushi restaurants offer fixed-price sets, selected by the chef from the catch of the day. These are often graded as "shō-chiku-bai" (松竹梅), "shō/matsu" (松, pine), "chiku/take" (竹, bamboo) and ("bai/ume"), with "matsu" the most expensive and " ume" the cheapest. Sushi restaurants will often have private booth dining, where guests are asked to remove their shoes, leaving them outside the room; However, most sushi bars offer diners a casual experience with an open dining room concept.
Sushi may be served "kaiten zushi" (sushi train) style. Color-coded plates of sushi are placed on a conveyor belt; as the belt passes, customers choose as they please. After finishing, the bill is tallied by counting how many plates of each color have been taken. Newer "kaiten zushi" restaurants use barcodes or RFID tags embedded in the dishes to manage elapsed time after the item was prepared.
Glossary.
Some specialized or slang terms are used in the sushi culture. Most of these terms are used only in sushi bars.
Etiquette.
Unlike sashimi, which is almost always eaten with chopsticks, "nigirizushi" is traditionally eaten with the fingers, even in formal settings. Although it is commonly served on a small platter with a side dish for dipping, sushi can also be served in a "bento", a box with small compartments that hold the various dishes of the meal.
Soy sauce is the usual condiment, and sushi is normally served with a small sauce dish, or a compartment in the bento. Traditional etiquette suggests that the sushi is turned over so that only the topping is dipped; this is because the soy sauce is for flavoring the topping, not the rice, and because the rice would absorb too much soy sauce and would fall apart. If it is difficult to turn the sushi upside-down, one can baste the sushi in soy sauce using "gari" (sliced ginger) as a brush. Toppings that have their own sauce (such as eel) should not be eaten with soy sauce.
Traditionally, the sushi chef will add an appropriate amount of wasabi to the sushi while preparing it, and etiquette suggests eating the sushi as is, since the chef is supposed to know the proper amount of wasabi to use. However, today wasabi is more a matter of personal taste, and even restaurants in Japan may serve wasabi on the side for customers to use at their discretion, even when there is wasabi already in the dish.

</doc>
<doc id="28272" url="http://en.wikipedia.org/wiki?curid=28272" title="Shinto">
Shinto

Shinto (神道, "Shintō"), also kami-no-michi, is an indigenous religion of Japan and the people of Japan. It is defined as an action-centered religion, focused on ritual practices to be carried out diligently, to establish a connection between present-day Japan and its ancient past. Shinto practices were first recorded and codified in the written historical records of the "Kojiki" and "Nihon Shoki" in the 8th century. Still, these earliest Japanese writings do not refer to a unified "Shinto religion", but rather to a collection of native beliefs and mythology. Shinto today is a term that applies to the religion of public shrines devoted to the worship of a multitude of gods ("kami"), suited to various purposes such as war memorials and harvest festivals, and applies as well to various sectarian organizations. Practitioners express their diverse beliefs through a standard language and practice, adopting a similar style in dress and ritual, dating from around the time of the Nara and Heian periods.
The word "Shinto" ("way of the gods") was adopted, originally as "Shindo", from the written Chinese "Shendao" (神道, ), combining two "kanji": "shin" (神), meaning "spirit" or "kami"; and "tō" (道), meaning a philosophical path or study (from the Chinese word "dào"). The oldest recorded usage of the word "Shindo" is from the second half of the 6th century. "Kami" are defined in English as "spirits", "essences" or "gods", referring to the energy generating the phenomena. Since Japanese language does not distinguish between singular and plural, "kami" refers to the divinity, or sacred essence, that manifests in multiple forms: rocks, trees, rivers, animals, places, and even people can be said to possess the nature of "kami". Kami and people are not separate; they exist within the same world and share its interrelated complexity.
Shinto is the largest religion in Japan, practiced by nearly 80% of the population, yet only a small percentage of these identify themselves as "Shintoists" in surveys. This is due to the fact that "Shinto" has different meanings in Japan: most of the Japanese attend Shinto shrines and beseech kami without belonging to an institutional "Shinto" religion, and since there are no formal rituals to become a member of folk "Shinto", "Shinto membership" is often estimated counting those who join organised Shinto sects. Shinto has 100,000 shrines and 78,890 priests in the country.
According to Inoue (2003):
In modern scholarship, the term is often used with reference to kami worship and related theologies, rituals and practices. In these contexts, "Shinto" takes on the meaning of "Japan’s traditional religion", as opposed to foreign religions such as Christianity, Buddhism, Islam and so forth.
Types of Shinto.
Shinto religious expressions have been distinguished by scholars into a series of categories:
Many other sects and schools can be distinguished. Faction Shinto (宗派神道, Shūha-Shintō) is a grouping of Japanese new religions developed since the second half of the 20th century that have significantly departed from traditional Shinto and are not always regarded as part of it.
Theology and cosmology.
"Kami".
"Kami" or "shin" (神) is defined in English as "god", "spirit", "spiritual essence", all these terms meaning the energy generating a thing. Since the Japanese language does not distinguish between singular and plural, "kami" refers to the divinity, or sacred essence, that manifests in multiple forms. Rocks, trees, rivers, animals, places, and even people can be said to possess the nature of "kami". Kami and people exist within the same world and share its interrelated complexity.
Early anthropologists called Shinto "animistic" in which animate and inanimate things have spirits or souls that are worshiped. The concept of animism in Shinto is no longer argued.
Shinto gods are collectively called "yaoyorozu no kami" (八百万の神), an expression literally meaning "eight million kami", but interpreted as meaning "myriad", although it can be translated as "many Kami". There is a phonetic variation, "kamu", and a similar word in the Ainu language, "kamui". An analogous word is "mi-koto".
"Kami" refers particularly to the power of phenomena that inspire a sense of wonder and awe in the beholder (the sacred), testifying to the divinity of such a phenomenon. It is comparable to what Rudolf Otto described as the "mysterium tremendum and fascinans".
The "kami" reside in all things, but certain objects and places are designated for the interface of people and kami: "yorishiro", "shintai", shrines, and "kamidana". There are natural places considered to have an unusually sacred spirit about them, and are objects of worship. They are frequently mountains, trees, unusual rocks, rivers, waterfalls, and other natural things. In most cases they are on or near a shrine grounds. The shrine is a building in which the kami is enshrined (housed). It is a sacred space, creating a separation from the "ordinary" world. The "kamidana" is a household shrine that acts as a substitute for a large shrine on a daily basis. In each case the object of worship is considered a sacred space inside which the kami spirit actually dwells, being treated with the utmost respect.
"Kannagara".
In Shinto "kannagara", meaning "way [path] of [expression] of the "kami"", refers to the law of the natural order. It is the sense of the terms "michi" or "to", "way", in the terms "kami-no-michi" or "Shinto". Those who understand "kannagara" know the divine, the human, and how people should live. From this knowledge stems the ethical dimension of Shinto, focusing on sincerity ("makoto"), honesty ("tadashii") and purity.
"Amenominakanushi".
According to the "Kojiki", "Amenominakanushi" (天御中主 "All-Father of the Originating Hub", or 天之御中主神 "Heavenly Ancestral God of the Originating Heart of the Universe") is the first "kami", and the concept of the source of the universe according to theologies. In mythology he is described as a "god who came into being alone" ("hitorigami"), the first of the "zōka sanshin" ("three "kami" of creation"), and one of the five "kotoamatsukami" ("distinguished heavenly gods").
Amenominakanushi has been considered a concept developed under the influence of Chinese thought. With the flourishing of "kokugaku" the concept was studied by scholars. The theologian Hirata Atsutane identified Amenominakanushi as the spirit of the North Star, master of the seven stars of the Big Dipper. The god was emphasised by the "Daikyōin" in the Meiji period, and worshiped by some Shinto sects.
The god manifests in a duality, a male and a female function, respectively "Takamimusubi" and "Kamimusubi". In other mythical accounts the originating "kami" is called "Umashiashikabihikoji" ("God of the "Ashi" [Reed]") or "Kuninotokotachi" (the "God Founder of the Nation"), the latter used in the "Nihon Shoki".
Creation of Japan.
The generation of the Japanese archipelago is expressed mythologically as the action of two gods: Izanagi ("He-who-invites") and Izanami ("She-who-is-invited"). The interaction of these two principles begets the islands of Japan and a further group of "kami".
The events are described in the "Kojiki" as follows:
In the myth, the birth of the god of fire ("Kagu-Tsuchi") causes the death of Izanami, who descends into "Yomi-no-kuni", the netherworld. Izanagi chases her there, but runs away when he finds the dead figure of his spouse. As he returns to the land of the living, Amaterasu (the sun goddess) is born from his left eye, Tsukiyomi (the moon deity) from his right eye, and Susanoo (the storm deity) is born from Izanagi's nose.
Purity.
Impurity.
Shinto teaches that certain deeds create a kind of ritual impurity that one should want cleansed for one's own peace of mind and good fortune rather than because impurity is wrong. Wrong deeds are called "impurity" (穢れ, kegare), which is opposed to "purity" (清め, kiyome). Normal days are called "day" ("ke"), and festive days are called "sunny" or, simply, "good" ("hare").
Those who are killed without being shown gratitude for their sacrifice will hold a grudge (怨み, urami) (grudge) and become powerful and evil "kami" who seek revenge ("aragami"). Additionally, if anyone is injured on the grounds of a shrine, the area must be ritually purified.
Purification.
Purification rites called Harae are a vital part of Shinto. They are done on a daily, weekly, seasonal, lunar, and annual basis. These rituals are the lifeblood of the practice of Shinto. Such ceremonies have also been adapted to modern life. New buildings made in Japan are frequently blessed by a Shinto priest called kannushi (神主) during the groundbreaking ceremony (Jichinsai 地鎮祭), and many cars made in Japan have been blessed as part of the assembly process. Moreover, many Japanese businesses built outside Japan have had ceremonies performed by a Shinto priest, with occasionally an annual visitation by the priest to re-purify.
Afterlife.
It is common for families to participate in ceremonies for children at a shrine, yet have a Buddhist funeral at the time of death mostly due to the negative Japanese conception of the afterlife and death as well as Buddhism's historical monopoly on funeral rites. In old Japanese legends, it is often claimed that the dead go to a place called "yomi" (黄泉), a gloomy underground realm with a river separating the living from the dead mentioned in the legend of Izanami and Izanagi. This "yomi" is very close to the Greek Hades; however, later myths include notions of resurrection and even Elysium-like descriptions such as in the legend of Okuninushi and Susanoo. Shinto tends to hold negative views on death and corpses as a source of pollution called "kegare". However, death is also viewed as a path towards apotheosis in Shintoism as can be evidenced by how legendary individuals become enshrined after death. Perhaps the most famous would be Emperor Ojin who was enshrined as Hachiman the God of War after his death.
Unlike many religions, one does not need to publicly profess belief in Shinto to be a believer. Whenever a child is born in Japan, a local Shinto shrine adds the child's name to a list kept at the shrine and declares him or her a "family child" (氏子, ujiko). After death an "ujiko" becomes a "family spirit", or "family "kami"" (氏神, ujigami). One may choose to have one's name added to another list when moving and then be listed at both places. Names can be added to the list without consent and regardless of the beliefs of the person added to the list. This is not considered an imposition of belief, but a sign of being welcomed by the local "kami", with the promise of addition to the pantheon of "kami" after death.
Shrines.
The principal worship of "kami" is done at public shrines or worship at small home shrines called "kamidana" (神棚, lit. "god-shelf"). The public shrine is a building or place that functions as a conduit for "kami". A fewer number of shrines are also natural places called "mori". The most common of the "mori" are sacred groves of trees, or mountains, or waterfalls. All shrines are open to the public at some times or throughout the year.
While many of the public shrines are elaborate structures, all are characteristic Japanese architectural styles of different periods depending on their age. Shrines are fronted by a distinctive Japanese gate (鳥居, "torii") made of two uprights and two crossbars denoting the separation between common space and sacred space. The "torii" have 20 styles and matching buildings based on the enshrined kami and lineage.
There are a number of symbolic and real barriers that exist between the normal world and the shrine grounds including: statues of protection, gates, fences, ropes, and other delineations of ordinary to sacred space. Usually there will be only one or sometimes two approaches to the Shrine for the public and all will have the "torii" over the way. In shrine compounds, there are a "haiden" (拝殿) or public hall of worship, "heiden" (幣殿) or hall of offerings and the "honden" (本殿) or the main hall. The innermost precinct of the grounds is the "honden" or worship hall, which is entered only by the high priest, or worshippers on certain occasions. The "honden" houses the symbol of the enshrined "kami".
The heart of the shrine is periodic rituals, spiritual events in parishioners' lives, and festivals. All of this is organized by priests who are both spiritual conduits and administrators. Shrines are private institutions, and are supported financially by the congregation and visitors. Some shrines may have festivals that attract hundreds of thousands, especially in the New Year season.
Notable shrines.
Of the 80,000 Shinto shrines:
Practices.
"Omairi".
Any person may visit a shrine and one need not be Shinto to do this. Doing so is called "Omairi".
Typically there are a few basic steps to visiting a shrine.
"Harae".
The rite of ritual purification usually done daily at a shrine is a ceremony of offerings and prayers of several forms. Shinsen (food offerings of fruit, fish, vegetables), Tamagushi (sakaki tree branches), Shio (salt), Gohan (rice), Mochi (rice paste), and Sake (rice wine) are all typical offerings. On holidays and other special occasions the inner shrine doors may be opened and special offerings made.
"Misogi".
Misogi means purification. Misogi harai or Misogi Shūhō (禊修法) is the term for water purification.
The practice of purification by ritual use of water while reciting prayers is typically done daily by regular practitioners, and when possible by lay practitioners. There is a defined set of prayers and physical activities that precede and occur during the ritual. This will usually be performed at a shrine, in a natural setting, but can be done anywhere there is clean running water.
The basic performance of this is the hand and mouth washing (Temizu 手水) done at the entrance to a shrine. The more dedicated believer may perform misogi by standing beneath a waterfall or performing the ritual ablutions in a river. This practice comes from Shinto history, when the kami Izanagi-no-Mikoto first performed misogi after returning from the land of Yomi, where he was made impure by Izanami-no-Mikoto after her death.
"Imi".
Another form of ritual cleanliness is avoidance, which means that a taboo is placed upon certain persons or acts. To illustrate, one would not visit a shrine if a close relative in the household had died recently. Killing is generally unclean and is to be avoided. When one is performing acts that harm the land or other living things, prayers and rituals are performed to placate the Kami of the area. This type of cleanliness is usually performed to prevent ill outcomes.
Amulets and talismans.
Ema are small wooden plaques that wishes or desires are written upon and left at a place in the shrine grounds so that one may get a wish or desire fulfilled. They have a picture on them and are frequently associated with the larger Shrines.
"Ofuda" are talismans—made of paper, wood, or metal—that are issued at shrines. They are inscribed with the names of kamis and are used for protection in the home. They are typically placed in the home at a kamidana. Ofuda may be kept anywhere, as long as they are in their protective pouches, but there are several rules about the proper placement of kamidana. They are also renewed annually.
"Omamori" are personal-protection amulets that sold by shrines. They are frequently used to ward off bad luck and to gain better health. More recently, there are also amulets to promote good driving, good business, and success at school. Their history lies with Buddhist practice of selling amulets.
"Omikuji" are paper lots upon which personal fortunes are written.
A "daruma" is a round, paper doll of the Indian monk, Bodhidharma. The recipient makes a wish and paints one eye; when the goal is accomplished, the recipient paints the other eye. While this is a Buddhist practice, darumas can be found at shrines, as well. These dolls are very common.
Other protective items include "dorei", which are earthenware bells that are used to pray for good fortune. These bells are usually in the shapes of the zodiacal animals: "hamaya", which are symbolic arrows for the fight against evil and bad luck; and "Inuhariko", which are paper dogs that are used to induce and to bless good births.
"Kagura".
"Kagura" is the ancient Shinto ritual dance of shamanic origin. The word "kagura" is thought to be a contracted form of "kami no kura" or "seat of the kami" or the "site where the kami is received." There is a mythological tale of how "kagura" dance came into existence. The sun goddess Amaterasu became very upset at her brother so she hid in a cave. All of the other gods and goddesses were concerned and wanted her to come outside. Ame-no-uzeme began to dance and create a noisy commotion in order to entice Amaterasu to come out. The kami (gods) tricked Amaterasu by telling her there was a better sun goddess in the heavens. Amaterasu came out and light returned to the universe.
Music plays a very important role in the "kagura" performance. Everything from the setup of the instruments to the most subtle sounds and the arrangement of the music is crucial to encouraging the kami to come down and dance. The songs are used as magical devices to summon the gods and as prayers for blessings. Rhythm patterns of five and seven are common, possibly relating to the Shinto belief of the twelve generations of heavenly and earthly deities. There is also vocal accompaniment called "kami uta" in which the drummer sings sacred songs to the gods. Often the vocal accompaniment is overshadowed by the drumming and instruments, reinforcing that the vocal aspect of the music is more for incantation rather than aesthetics.
In both ancient Japanese collections, the Nihongi and Kojiki, Ame-no-uzeme’s dance is described as "asobi", which in old Japanese language means a ceremony that is designed to appease the spirits of the departed, and which was conducted at funeral ceremonies. Therefore, "kagura" is a rite of "tama shizume", of pacifying the spirits of the departed. In the Heian period (8th–12th centuries) this was one of the important rites at the Imperial Court and had found its fixed place in the "tama shizume" festival in the eleventh month. At this festival people sing as accompaniment to the dance: “Depart! Depart! Be cleansed and go! Be purified and leave!”
This rite of purification is also known as "chinkon". It was used for securing and strengthening the soul of a dying person. It was closely related to the ritual of "tama furi" (shaking the spirit), to call back the departed soul of the dead or to energize a weakened spirit. Spirit pacification and rejuvenation were usually achieved by songs and dances, also called "asobi". The ritual of "chinkon" continued to be performed on the emperors of Japan, thought to be descendents of Amaterasu. It is possible that this ritual is connected with the ritual to revive the sun goddess during the low point of the winter solstice.
There is a division between the "kagura" that is performed at the Imperial palace and the shrines related to it, and the "kagura" that is performed in the countryside. Folk "kagura", or "kagura" from the countryside is divided according to region. The following descriptions relate to "sato kagura", "kagura" that is from the countryside. The main types are: "miko kagura", "Ise kagura", "Izumo kagura", and "shishi kagura".
Miko kagura is the oldest type of "kagura" and is danced by women in Shinto shrines and during folk festivals. The ancient miko were shamanesses, but are now considered priestesses in the service of the Shinto Shrines. "Miko kagura" originally was a shamanic trance dance, but later, it became an art and was interpreted as a prayer dance. It is performed in many of the larger Shinto shrines and is characterized by slow, elegant, circular movements, by emphasis on the four directions and by the central use of torimono (objects dancers carry in their hands), especially the fan and bells.
Ise kagura is a collective name for rituals that are based upon the "yudate" (boiling water rites of Shugendō origin) ritual. It includes "miko" dances as well as dancing of the "torimono" type. The "kami" are believed to be present in the pot of boiling water, so the dancers dip their "torimono" in the water and sprinkle it in the four directions and on the observers for purification and blessing.
Izumo kagura is centered in the Sada shrine of Izumo, Shimane prefecture. It has two types: "torimono ma", unmasked dances that include held objects, and "shinno" (sacred No), dramatic masked dances based on myths. "Izumo kagura" appears to be the most popular type of "kagura".
Shishi kagura also known as the Shugen-No tradition, uses the dance of a "shishi" (lion or mountain animal) mask as the image and presence of the deity. It includes the "Ise daikagura" group and the "yamabushi kagura" and "bangaku" groups of the Tohoku area (Northeastern Japan). "Ise daikagura" employs a large red Chinese type of lion head which can move its ears. The lion head of the "yamabushi kagura" schools is black and can click its teeth. Unlike other "kagura" types in which the "kami" appear only temporarily, during the "shishi kagura" the "kami" is constantly present in the shishi head mask. During the Edo period, the lion dances became showy and acrobatic losing its touch with spirituality. However, the "yamabushi kagura" tradition has retained its ritualistic and religious nature.
Originally, the practice of "kagura" involved authentic possession by the "kami" invoked. In modern day Japan it appears to be difficult to find authentic ritual possession, called "kamigakari", in "kagura" dance. However, it is common to see choreographed possession in the dances. Actual possession is not taking place but elements of possession such as losing control and high jumps are applied in the dance.
History.
Historical records.
There is no core sacred text in Shinto, as the Bible is in Christianity or Qur'an is in Islam. Instead there are books of lore and history which provide stories and background to many Shinto beliefs.
Origins.
Shinto has very ancient roots in the Japanese islands. The recorded history dates to the Kojiki (712) and Nihon Shoki (720), but archeological records date back significantly further. Both are compilations of prior oral traditions. The Kojiki establishes the Japanese imperial family as the foundation of Japanese culture, being the descendants of Amaterasu Omikami. There is also a creation myth and a genealogy of the gods. The Nihonshoki was more interested in creating a structural system of government, foreign policy, religious hierarchy, and domestic social order.
There is an internal system of historical Shinto development that configures the relationships between Shinto and other religious practices over its long history; the inside and outside Kami (spirits). The inside or "ujigami" ("uji" meaning clan) Kami roles that supports cohesion and continuation of established roles and patterns; and the "hitogami" or outside Kami, bringing innovation, new beliefs, new messages, and some instability.
Jomon peoples of Japan used natural housing, predated rice farming, and frequently were hunter-gatherers; the physical evidence for ritual practices are difficult to document. There are many locations of stone ritual structures, refined burial practices and early Torii that lend to the continuity of primal Shinto. The Jomon had a clan-based tribal system developed similar to much of the world's indigenous people. In the context of this clan based system, local beliefs developed naturally and when assimilation between clans occurred, they also took on some beliefs of the neighboring tribes. At some point there was a recognition that the ancestors created the current generations and the reverence of ancestors ("tama") took shape. There was some trade amongst the indigenous peoples within Japanese islands and the mainland, as well as some varying migrations. The trade and interchange of people helped the growth and complexity of the peoples spirituality by exposure to new beliefs. The natural spirituality of the people appeared to be based on the worship of nature forces or "mono", and the natural elements to which they all depended.
The gradual introduction of methodical religious and government organizations from mainland Asia starting around 300 BCE seeded the reactive changes in primal Shinto over the next 700 years to a more formalized system. These changes were directed internally by the various clans frequently as a syncratic cultural event to outside influences. Eventually as the Yamato gained power a formalization process began. The genesis of the Imperial household and subsequent creation of the Kojiki helped facilitate the continuity needed for this long term development through modern history. There is today a balance between outside influences of Buddhist, Confucian, Taoist, Abrahamic, Hindu and secular beliefs. In more modern times Shinto has developed new branches and forms on a regular basis, including leaving Japan.
Jomon Period.
By the end of the Jōmon period, a dramatic shift had taken place according to archaeological studies. New arrivals from the continent seem to have invaded Japan from the West, bringing with them new technologies such as rice farming and metallurgy. The settlements of the new arrivals seem to have coexisted with those of the Jōmon for some time. Under these influences, the incipient cultivation of the Jōmon evolved into sophisticated rice-paddy farming and government control. Many other elements of Japanese culture also may date from this period and reflect a mingled migration from the northern Asian continent and the southern Pacific areas. Among these elements are Shinto mythology, marriage customs, architectural styles, and technological developments such as lacquerware, textiles, laminated bows, metalworking, and glass making. The Jōmon is succeeded by the Yayoi period.
Yayoi Period.
Japanese culture begins to develop in no small part due to influences from mainland trade and immigration from China. During this time in the pre-writing historical period, objects from the mainland start appearing in large amounts, specifically mirrors, swords, and jewels. All three of these have a direct connection to the imperial divine status as they are the symbols of imperial divinity and are Shinto honorary objects. Also the rice culture begins to blossom throughout Japan and this leads to the settlement of society, and seasonal reliance of crops. Both of these changes are highly influential on the Japanese people's relationship to the natural world, and likely development of a more complex system of religion. This is also the period that is referenced as the beginning of the divine imperial family. The Yayoi culture was a clan based culture that lived in compounds with a defined leader who was the chief and head priest. They were responsible for the relationship with their "gods" Kami and if one clan conquered another, their "god" would be assimilated. The earliest records of Japanese culture were written by Chinese traders who described this land as "Wa". This time period led to the creation of the Yamato culture and development of formal Shinto practices.
The development of "niiname" or the (now) Shinto harvest festival is attributed to this period as offerings for good harvests of similar format (typically rice) become common.
Kofun Period.
The great bells and drums, Kofun burial mounds, and the founding of the imperial family are important to this period. This is the period of the development of the feudal state, and the Yamato and Izumo cultures. Both of these dominant cultures have a large and central shrine which still exists today, Ise Shrine in the South West and Izumo Taisha in the North East. This time period is defined by the increase of central power in Naniwa, now Osaka, of the feudal lord system. Also there was an increasing influence of Chinese culture which profoundly changed the practices of government structure, social structure, burial practices, and warfare. The Japanese also held close alliance and trade with the Gaya confederacy which was in the south of the peninsula. The Paekche in the Three Kingdoms of Korea had political alliances with Yamato, and in the 5th century imported the Chinese writing system to record Japanese names and events for trade and political records. In 513 they sent a Confucian scholar to the court to assist in the teachings of Confucian thought. In 552 or 538 a Buddha image was given to the Yamato leader which profoundly changed the course of Japanese religious history, especially in relation to the undeveloped native religious conglomeration that was Shinto. In the latter 6th century, there was a breakdown of the alliances between Japan and Paekche but the influence led to the codification of Shinto as the native religion in opposition to the extreme outside influences of the mainland. Up to this time Shinto had been largely a clan ('uji') based religious practice, exclusive to each clan.
Asuka Period.
The Theory of Five Elements in Yin and Yang philosophy of Taoism and the esoteric Buddhism had a profound impact on the development of a unified system of Shinto beliefs. In the early Nara period, the "Kojiki" and the "Nihon Shoki" were written by compiling existing myths and legends into a unified account of Japanese mythology. These accounts were written with two purposes in mind: the introduction of Taoist, Confucian, and Buddhist themes into Japanese religion; and garnering support for the legitimacy of the Imperial house, based on its lineage from the sun goddess, Amaterasu. Much of modern Japan was under only fragmentary control by the Imperial family, and rival ethnic groups. The mythological anthologies, along with other poetry anthologies like the "Collection of Ten Thousand Leaves" ("Man'yōshū") and others, were intended to impress others with the worthiness of the Imperial family and their divine mandate to rule.
In particular the Asuka rulers of 552–645 saw disputes between the more major families of the clan Shinto families. There were disputes about who would ascend to power and support the imperial family between the Soga and Mononobe/Nakatomi Shinto families. The Soga family eventually prevailed and supported Empress Suiko and Prince Shotoku, who helped impress Buddhist faith into Japan. However, it was not until the Hakuho ruling period of 645–710 was Shinto installed at the imperial faith along with the Fujiwara Clan and reforms that followed.
Hakuho Period.
Beginning with Emperor Temmu (672–686), continuing through Empress Jito (686–697) and Emperor Mommu (697–707) Court Shinto rites are strengthened and made parallel to Buddhist beliefs in court life. Prior to this time clan Shinto had dominated and a codification of "Imperial Shinto" did not exist as such. The Nakatomi family are made the chief court Shinto chaplains and chief priests at Ise Daijingu which held until 1892. Also the practice of sending imperial princesses to the Ise shrine begins. This marks the rise of Ise Daijingu as the main imperial shrine historically. Due to increasing influence from Buddhism and mainland Asian thought, codification of the "Japanese" way of religion and laws begins in earnest. This culminates in three major outcomes: Taiho Code (701 but started earlier), The Kojiki (712),and The Nihon Shoki (720).
The Taiho Code also called Ritsuryō (律令?) was an attempt to create a bulwark to dynamic external influences and stabilize the society through imperial power. It was a liturgy of rules and codifications, primarily focused on regulation of religion, government structure, land codes, criminal and civil law. All priests, monks, and nuns were required to be registered, as were temples. The Shinto rites of the imperial line were codified, especially seasonal cycles, lunar calendar rituals, harvest festivals, and purification rites. The creation of the imperial Jingi-kan or Shinto Shrine office was completed.
Nara Period.
This period hosted many changes to the country, government, and religion. The capital is moved again to Heijō-kyō, or Nara, in AD 710 by Empress Gemmei due to the death of the Emperor. This practice was necessary due to the Shinto belief in the impurity of death and the need to avoid this pollution. However, this practice of moving the capital due to "death impurity" is then abolished by the Taihō Code and rise in Buddhist influence. The establishment of the imperial city in partnership with Taihō Code is important to Shinto as the office of the Shinto rites becomes more powerful in assimilating local clan shrines into the imperial fold. New shrines are built and assimilated each time the city is moved. All of the grand shrines are regulated under Taihō and are required to account for incomes, priests, and practices due to their national contributions.
During this time, Buddhism becomes structurally established within Japan by Emperor Shōmu (reign 724–749), and several large building projects are undertaken. The Emperor lays out plans for the Buddha Dainichi (Great Sun Buddha), at Tōdai-ji assisted by the Priest Gyogi (or Gyoki) Bosatsu. The priest Gyogi went to Ise Daijingu Shrine for blessings to build the Buddha Dainichi. They identified the statue of Viarocana with Amatarasu (the sun goddess) as the manifestation of the supreme expression of universality.
The priest Gyogi is known for his belief in assimilation of Shinto Kami and Buddhas. Shinto kami are commonly being seen by Buddhist clergy as guardians of manifestation, guardians, or pupils of Buddhas and bodhisattvas. The priest Gyogi conferred boddhisattva precepts on the Emperor in 749 effectively making the Imperial line the head of state and divine to Shinto while beholden to Buddhism.
Syncretism with Buddhism.
With the introduction of Buddhism and its rapid adoption by the court in the 6th century, it was necessary to explain the apparent differences between native Japanese beliefs and Buddhist teachings. One Buddhist explanation saw the "kami" as supernatural beings still caught in the cycle of birth and rebirth (reincarnation). The "kami" are born, live, die, and are reborn like all other beings in the karmic cycle. However, the "kami" played a special role in protecting Buddhism and allowing its teachings of compassion to flourish.
This explanation was later challenged by Kūkai (空海, 774–835), who saw the "kami" as different embodiments of the Buddhas themselves ("honji suijaku" theory). For example, he linked Amaterasu (the sun goddess and ancestor of the Imperial family) with Dainichi Nyorai, a central manifestation of the Buddhists, whose name means literally "Great Sun Buddha". In his view, the "kami" were just Buddhas by another name.
"Kokugaku".
Buddhism and Shinto coexisted and were amalgamated in the "shinbutsu shūgō" and Kūkai's syncretic view held wide sway up until the end of the Edo period. There was no theological study that could be called "Shinto" during medieval and early modern Japanese history, and a mixture of Buddhist and popular beliefs proliferated. At that time, there was a renewed interest in "Japanese studies" ("kokugaku"), perhaps as a result of the closed country policy.
In the 18th century, various Japanese scholars, in particular Motoori Norinaga (本居 宣長, 1730–1801), tried to tear apart the "real" Shinto from various foreign influences. The attempt was largely unsuccessful, since as early as the "Nihon Shoki" parts of the mythology were explicitly borrowed from Taoism doctrines. For example, the co-creator deities Izanami and Izanagi are explicitly compared to yin and yang. However, the attempt did set the stage for the arrival of state Shinto, following the Meiji Restoration (c.1868), when Shinto and Buddhism were separated ("shinbutsu bunri").
State Shinto.
Fridell argues that scholars call the period 1868-1945 the "State Shinto period" because, "during these decades, Shinto elements came under a great deal of overt state influence and control as the Japanese government systematically utilized shrine worship as a major force for mobilizing imperial loyalties on behalf of modern nation-building." However, the government had already been treating shrines as an extension of government before Meiji; see for example the Tenpō Reforms. Moreover, according to the scholar Jason Ānanda Josephson, It is inaccurate to describe shrines as constituting a "state religion" or a "theocracy" during this period since they had neither organization, nor doctrine, and were uninterested in conversion. 
The Meiji Restoration reasserted the importance of the emperor and the ancient chronicles to establish the Empire of Japan, and in 1868 the government attempted to recreate the ancient imperial Shinto by separating shrines from the temples that housed them. During this period, numerous scholars of "kokugaku" believed that this national Shinto could be the unifying agent of the country around the Emperor while the process of modernization was undertaken with all possible speed. The psychological shock of the Western "Black Ships" and the subsequent collapse of the shogunate convinced many that the nation needed to unify in order to resist being colonized by outside forces.
In 1871, a Ministry of Rites was formed and Shinto shrines were divided into twelve levels with the Ise Shrine (dedicated to Amaterasu, and thus symbolic of the legitimacy of the Imperial family) at the peak and small sanctuaries of humble towns at the base. The following year, the ministry was replaced with a new Ministry of Religion, charged with leading instruction in "shushin" (moral courses). Priests were officially nominated and organized by the state, and they instructed the youth in a form of Shinto theology based on the official dogma of the divinity of Japan's national origins and its Emperor. However, this propaganda did not take, and the unpopular Ministry of Rites was dissolved in the mid-1870s.
Although the government sponsorship of shrines declined, Japanese nationalism remained closely linked to the legends of foundation and emperors, as developed by the "kokugaku" scholars. In 1890, the Imperial Rescript on Education was issued, and students were required to ritually recite its oath to "offer yourselves courageously to the State" as well as to protect the Imperial family. Such processes continued to deepen throughout the early Shōwa period, coming to an abrupt end in August 1945 when Japan lost the war in the Pacific. On 1 January 1946, Emperor Shōwa issued the Ningen-sengen, in which he quoted the Five Charter Oath of Emperor Meiji and declared that he was not an "akitsumikami".
Post-war.
The imperial era came to an abrupt close with the end of World War II, when Americans declared that Japanese nationalism had been informed by something called "State Shinto", which they attempted to define with the Shinto Directive. The meaning of "State Shinto" has been a matter of debate ever since.
In the post-war period, numerous "New Religions" cropped up, many of them ostensibly based on Shinto, but on the whole, Japanese religiosity may have decreased. However, the concept of religion in Japan is a complex one. A survey conducted in the mid-1970s indicated that of those participants who claimed not to believe in religion, one-third had a Buddhist or Shinto altar in their home, and about one quarter carried an "omamori" (an amulet to gain protection by "kami") on their person. Following the war, Shinto shrines tended to focus on helping ordinary people gain better fortunes for themselves through maintaining good relations with their ancestors and other "kami". The number of Japanese citizens identifying their religious beliefs as Shinto has declined a great deal, yet the general practice of Shinto rituals has not decreased in proportion, and many practices have persisted as general cultural beliefs (such as ancestor worship), and community festivals ("matsuri")—focusing more on religious practices. The explanation generally given for this anomaly is that, following the demise of State Shinto, modern Shinto has reverted to its more traditional position as a traditional religion which is culturally ingrained, rather than enforced. In any case, Shinto and its values continue to be a fundamental component of the Japanese cultural mindset.
Shinto has also spread abroad to a limited extent, and a few non-Japanese Shinto priests have been ordained. A relatively small number of people practice Shinto in America. There are several Shinto shrines in America. Shrines were also established in Taiwan and Korea of those areas in Empire of Japan times, but following the war, they were either destroyed or converted into some other use.
New sects.
Within Shinto, there are a variety of new sects outside Shrine Shinto and the officially defunct State Shinto. Sect Shinto, like Tenrikyo and Konkokyo, have a unique dogma or leader, with some exhibiting the influence of Messianic Christianity and cult of personality, in the 19th and 20th century, particularly the "New Religions" like ("Shinshūkyō") that proliferated in the post-war era.
Further reading.
</dl>

</doc>
<doc id="28273" url="http://en.wikipedia.org/wiki?curid=28273" title="Shell">
Shell

Shell may refer to:

</doc>
<doc id="28278" url="http://en.wikipedia.org/wiki?curid=28278" title="Scottish Rite">
Scottish Rite

The Ancient and Accepted Scottish Rite of Freemasonry (the Northern Masonic Jurisdiction in the United States often omits the "and", while the English Constitution in the United Kingdom omits the "Scottish"), commonly known as simply the Scottish Rite, is one of several Rites of Freemasonry. A Rite is a progressive series of degrees conferred by various Masonic organizations or bodies, each of which operates under the control of its own central authority. In the Scottish Rite the central authority is called a Supreme Council.
The Scottish Rite is one of the appendant bodies of Freemasonry that a Master Mason may join for further exposure to the principles of Freemasonry. In England and some other countries, while the Scottish Rite is not accorded official recognition by the Grand Lodge, there is no prohibition against a Freemason electing to join it. In the United States, however, the Scottish Rite is officially recognized by Grand Lodges as an extension of the degrees of Freemasonry. The Scottish Rite builds upon the ethical teachings and philosophy offered in the craft lodge, or Blue Lodge, through dramatic presentation of the individual degrees.
The thirty-three degrees of the Scottish Rite are conferred by several controlling bodies. The first of these is the Craft Lodge which confers the Entered Apprentice, Fellowcraft, and Master Mason degrees. Craft lodges operate under the authority of Grand Lodges, not the Scottish Rite. Although most lodges throughout the English-speaking world do not confer the Scottish Rite versions of the first three degrees, there are a handful of lodges in New Orleans and in several other major cities that have traditionally conferred the Scottish Rite version of these degrees.
History.
There are records of lodges conferring the degree of "Scots Master" or "Scotch Master" as early as 1733. A lodge at Temple Bar in London is the earliest such lodge on record. Other lodges include a lodge at Bath in 1735, and the French lodge, St. George de l'Observance No. 49 at Covent Garden in 1736. The references to these few occasions indicate that these were special meetings held for the purpose of performing unusual ceremonies, probably by visiting Freemasons. The Copiale cipher, dating from the 1730s, says, "The rank of a Scottish master is an entirely new invention..."
Legend of Jacobite Origins.
The seed of the myth of Stuart Jacobite influence on the higher degrees may have been a careless and unsubstantiated remark made by John Noorthouk in the 1784 Book of Constitutions of the Premier Grand Lodge of London. It was stated, without support, that King Charles II (older brother and predecessor to James II) was made a Freemason in the Netherlands during the years of his exile (1649–60). However, there were no documented lodges of Freemasons on the continent during those years. The statement may have been made to flatter the fraternity by claiming membership for a previous monarch. This folly was then embellished by John Robison (1739–1805), a professor of Natural Philosophy at the University of Edinburgh, in an anti-Masonic work published in 1797. The lack of scholarship exhibited by Robison in that work caused the "Encyclopædia Britannica" to denounce it.
A German bookseller and Freemason, living in Paris, working under the assumed name of C. Lenning, embellished the story further in a manuscript titled "Encyclopedia of Freemasonry" probably written between 1822 and 1828 at Leipzig. This manuscript was later revised and published by another German Freemason named Friedrich Mossdorf (1757–1830). Lenning stated that King James II of England, after his flight to France in 1688, resided at the Jesuit College of Clermont, where his followers fabricated certain degrees for the purpose of carrying out their political ends.
By the mid-19th century, the story had gained currency. The well-known English Masonic writer, Dr. George Oliver (1782–1867), in his "Historical Landmarks", 1846, carried the story forward and even claimed that King Charles II was active in his attendance at meetings—an obvious invention, for if it had been true, it would not have escaped the notice of the historians of the time. The story was then repeated by the French writers Jean-Baptiste Ragon (1771–1862) and Emmanuel Rebold, in their Masonic histories. Rebold's claim that the high degrees were created and practiced in Lodge Canongate Kilwinning at Edinburgh are entirely false.
James II died in 1701 at the Palace of St. Germain en Laye, and was succeeded in his claims to the British throne by his son, James Francis Edward Stuart (1699–1766), the Chevalier St. George, better known as "the Old Pretender", but recognized as James III by the French King Louis XIV. He was succeeded in his claim by Charles Edward Stuart ("Bonnie Prince Charles"), also known as "the Young Pretender", whose ultimate defeat at the Battle of Culloden in 1746 effectively put an end to any serious hopes of the Stuarts regaining the British crowns.
The natural confusion between the names of the Jesuit College of Clermont, and the short-lived Masonic Chapter of Clermont, a Masonic body that controlled a few high degrees during its brief existence, only served to add fuel to the myth of Stuart Jacobite influence in Freemasonry's high degrees. However, the College and the Chapter had nothing to do with each other. The Jesuit College was located at Clermont, whereas the Masonic Chapter was not. Rather, it was named "Clermont" in honor of the French Grand Master, the Comte de Clermont (Louis de Bourbon, Comte de Clermont) (1709–1771), and not because of any connection with the Jesuit College of Clermont.
Estienne Morin and his Rite of 25 degrees.
A French trader, by the name of Estienne Morin, had been involved in high degree Masonry in Bordeaux since 1744 and, in 1747, founded an "Ecossais" lodge (Scots Masters Lodge) in the city of Le Cap Français, on the north coast of the French colony of Saint-Domingue (now Haiti). Over the next decade, high degree Freemasonry continued to spread to the Western hemisphere as the high degree lodge at Bordeaux warranted or recognized seven Ecossais lodges there. In Paris in the year 1761, a patent was issued to Estienne Morin, dated 27 August, creating him "Grand Inspector for all parts of the New World". This Patent was signed by officials of the Grand Lodge at Paris and appears to have originally granted him power over the craft lodges only, and not over the high, or "Ecossais", degree lodges. Later copies of this Patent appear to have been embellished, probably by Morin, to improve his position over the high degree lodges in the West Indies.
Early writers long believed that a "Rite of Perfection" consisting of 25 degrees, the highest being the "Sublime Prince of the Royal Secret", and being the predecessor of the Scottish Rite, had been formed in Paris by a high degree council calling itself "The Council of Emperors of the East and West". The title "Rite of Perfection" first appeared in the Preface to the "Grand Constitutions of 1786", the authority for which is now known to be faulty. It is now generally accepted that this Rite of twenty-five degrees was compiled by Estienne Morin and is more properly called "The Rite of the Royal Secret", or "Morin's Rite". However, it was known as "The Order of Prince of the Royal Secret" by the founders of the Scottish Rite, who mentioned it in their "Circular throughout the two Hemispheres" or "Manifesto", issued on December 4, 1802.
Morin returned to the West Indies in 1762 or 1763, to Saint-Domingue, where, armed with his new Patent, he assumed powers to constitute lodges of all degrees, spreading the high degrees throughout the West Indies and North America. Morin stayed in Saint-Domingue until 1766 when he moved to Jamaica. At Kingston, Jamaica, in 1770, Morin created a "Grand Chapter" of his new Rite (the Grand Council of Jamaica). Morin died in 1771 and was buried in Kingston.
Henry Andrew Francken and his manuscripts.
The one man who was most important in assisting Morin in spreading the degrees in the New World was a naturalized French subject of Dutch origin named Henry Andrew Francken. Morin appointed him Deputy Grand Inspector General as one of his first acts after returning to the West Indies. Francken worked closely with Morin and, in 1771, produced a manuscript book giving the rituals for the 15th through the 25th degrees. Francken produced at least two more similar manuscripts, one in 1783 and another about 1786. The second and third of these manuscripts included all the degrees from the 4th through the 25th.
A Loge de Parfaits d' Écosse was formed on 12 April 1764 at New Orleans, becoming the first high degree lodge on the North American continent. Its life, however, was short, as the Treaty of Paris (1763) ceded New Orleans to Spain, and the Catholic Spanish crown had been historically hostile to Freemasonry. Documented Masonic activity ceased for a time and did not return to New Orleans until the 1790s.
Francken traveled to New York in 1767 where he granted a Patent, dated 26 December 1767, for the formation of a Lodge of Perfection at Albany, which was called "Ineffable Lodge of Perfection". This marked the first time the Degrees of Perfection (the 4th through the 14th) were conferred in one of the thirteen British colonies. This Patent, and the early minutes of the Lodge, are still extant and are in the archives of Supreme Council, Northern Jurisdiction. (The minutes of Ineffable Lodge of Perfection reveal that it ceased activity on December 5, 1774. It was revived by Giles Fonda Yates about 1820 or 1821, and came under authority of the Supreme Council, Southern Jurisdiction until 1827, when it was transferred to the Supreme Council, Northern Jurisdiction.)
While in New York, Francken also communicated the degrees to Moses Michael Hays, a Jewish businessman, and appointed him a Deputy Inspector General. In 1781, Hays made eight Deputy Inspectors General, four of whom were later important in the establishment of Scottish Rite Freemasonry in South Carolina:
<br>◊_ Isaac Da Costa Sr., D.I.G. for South Carolina;
<br>◊_ Abraham Forst, D.I.G. for Virginia;
<br>◊_ Joseph M. Myers, D.I.G. for Maryland;
<br>◊_ and Barend M. Spitzer, D.I.G. for Georgia.
Da Costa returned to Charleston, S.C., and established the "Sublime Grand Lodge of Perfection" in February 1783. After Da Costa's death in November 1783, Hays appointed Myers as Da Costa's successor. Joined by Forst and Spitzer, Myers created additional high degree bodies in Charleston and, by 1801, the Charleston bodies were the only extant bodies of the Rite in North America.
Birth of the Scottish Rite.
Although most of the thirty-three degrees of the Scottish Rite existed in parts of previous degree systems, the Scottish Rite did not come into being until the formation of the Mother Supreme Council at Charleston, South Carolina, in May 1801. The Founding Fathers of the Scottish Rite who attended became known as "The Eleven Gentlemen of Charleston".
Subsequently, other Supreme Councils were formed in Saint-Domingue in 1802, in France in 1804, in Italy in 1805, and in Spain in 1811.
On May 1, 1813, an officer from the Supreme Council at Charleston initiated several New York Masons into the Thirty-third Degree and organized a Supreme Council for the "Northern Masonic District and Jurisdiction". On May 21, 1814 this Supreme Council reopened and proceeded to "nominate, elect, appoint, install and proclaim in due, legal and ample form" the elected officers "as forming the "second" Grand and Supreme Council...". Finally, the charter of this organization (written January 7, 1815) added, “We think the "Ratification" ought to be dated 21st day May 5815."
Officially, the Supreme Council, 33°, N.M.J. dates itself from May 15, 1867. This was the date of the "Union of 1867", when it merged with the competing Cerneau "Supreme Council" in New York. The current Ancient and Accepted Scottish Rite, Northern Masonic Jurisdiction of the United States, was thus formed.
Albert Pike.
Born in Boston, Massachusetts on December 29, 1809, Albert Pike is asserted within the Southern Jurisdiction as the man most responsible for the growth and success of the Scottish Rite from an obscure Masonic Rite in the mid-19th century to the international fraternity that it became. Pike received the 4th through the 32nd Degrees in March 1853 from Dr. Albert G. Mackey, in Charleston, S.C., and was appointed Deputy Inspector for Arkansas that same year.
At this point, the degrees were in a rudimentary form, and often only included a brief history and legend of each degree as well as other brief details which usually lacked a workable ritual for their conferral. In 1855, the Supreme Council appointed a committee to prepare and compile rituals for the 4th through the 32nd Degrees. That committee was composed of Albert G. Mackey, John H. Honour, William S. Rockwell, Claude P. Samory, and Albert Pike. Of these five committee members, Pike did all the work of the committee.
In 1857 Pike completed his first revision of the 4°-32° ritual, and printed 100 copies. This revision, which Mackey dubbed the "Magnum Opus" was never adopted by the Supreme Council. According to Arturo de Hoyos, 33°, the Scottish Rite's Grand Historian, the Magnum Opus became the basis for future ritual revisions.
In March 1858, Pike was elected a member of the Supreme Council for the Southern Jurisdiction of the United States, and in January 1859 he became its Grand Commander. The American Civil War interrupted his work on the Scottish Rite rituals. About 1870 he, and the Supreme Council, moved to Washington, DC, and in 1884 his revision of the rituals was complete.
Scottish Rite Grand Archivist and Grand Historian de Hoyos created the following chart of Pike's ritual revisions:
Pike also wrote lectures for all the degrees which were published in 1871 under the title "Morals and Dogma of the Ancient and Accepted Scottish Rite of Freemasonry".
Revisions after Pike.
In 2000 the Southern Jurisdiction revised its ritual. The current ritual is based upon Pike's, but with some significant differences.
Organization.
The Ancient and Accepted Scottish Rite in each country is governed by a Supreme Council. There is no international governing body — each Supreme Council in each country is sovereign unto itself in its own jurisdiction.
United States.
In the United States of America there are two Supreme Councils: one in Washington, D.C. (which controls the Southern Jurisdiction), and one in Lexington, Massachusetts (which controls the Northern Masonic Jurisdiction). They each have particular characteristics that make them different.
Southern Jurisdiction.
Based in Washington, D.C., the Southern Jurisdiction (often referred to as the "Mother Supreme Council of the World") was founded in Charleston, South Carolina in 1801. It oversees the Scottish Rite in 35 states, which are referred to as "Orients", and local bodies, which are called "Valleys".
In the Southern Jurisdiction of the United States, the Supreme Council consists of no more than 33 members, and is presided over by a Grand Commander. Other members of the Supreme Council are called "Sovereign Grand Inspectors General" (S.G.I.G.), and each is the head of the Rite in his respective Orient (or state). Other heads of the various Orients who are not members of the Supreme Council are called "Deputies of the Supreme Council." The Supreme Council of the Southern Jurisdiction meets every odd year during the month of August at the House of the Temple, Scottish Rite of Freemasonry Southern Jurisdiction Headquarters, in Washington, DC. During this conference, closed meetings between the Grand Commander and the S.G.I.G.'s are held, and many members of the fraternity from all over the world attend the open ceremony on the 5th of 6 council meeting days.
Northern Masonic Jurisdiction.
The Lexington, Massachusetts-based Northern Masonic Jurisdiction, formed in 1813, oversees the bodies in fifteen states: Connecticut, Delaware, Illinois, Indiana, Maine, Massachusetts, Michigan, New Jersey, New Hampshire, New York, Ohio, Pennsylvania, Rhode Island, Wisconsin and Vermont. The Northern Jurisdiction is only divided into "Valleys", not Orients. Each Valley has up to four Scottish Rite bodies, and each body confers a set of degrees.
In the Northern Jurisdiction, the Supreme Council consists of no more than 66 members. All members of the Supreme Council are designated Sovereign Grand Inspectors General, but the head of the Rite in each Valley of the Northern Jurisdiction is called a "Deputy of the Supreme Council." The Northern Council meets yearly.
Degree Structure in the United States and Canada.
Attainment of the third Masonic degree, that of a Master Mason, represents the attainment of the highest rank in all of Masonry. Additional degrees are sometimes referred to as appendant degrees, even where the degree numbering might imply a hierarchy. They represent a lateral movement in Masonic Education rather than an upward movement, and are degrees of instruction rather than rank.
In 2000, the Southern Masonic Jurisdiction completed a revision of its ritual scripts. In 2004, the Northern Masonic Jurisdiction rewrote and reorganized its degrees. Further changes have occurred in 2006. The current titles of the degrees and their arrangement in the Southern Jurisdiction of the United States remains substantially unchanged from the beginning. The list of degrees for the Supreme Councils of Australia, England and Wales, and most other jurisdictions agrees with that of the Southern Jurisdiction of the U.S. However, the list of degrees for the Northern Jurisdiction of the United States is now somewhat different and is given in the table below. The list of degrees of the Supreme Council of Canada reflects a mixture of the two, with some unique titles as well:
In the United States, members of the Scottish Rite can be elected to receive the 33° by the Supreme Council. It is conferred on members who have made major contributions to society or to Masonry in general. In the Southern Jurisdiction, a member who has been a 32° Scottish Rite Mason for 46 months or more is eligible to be elected to receive the "rank and decoration" of Knight Commander of the Court of Honour (K.C.C.H.) in recognition of outstanding service. After 46 months as a K.C.C.H. he is then eligible to be elected to the 33rd degree, upon approval of the Supreme Council and Grand Commander. In the Northern Jurisdiction, there is only one 46-month requirement for eligibility to receive the 33rd degree, and while there is a Meritorious Service Award (as well as a Distinguished Service Award), they are not required intermediate steps towards the 33°.
A recipient of the 33rd Degree is an honorary member of the Supreme Council and is therefore called an "Inspector General Honorary." However, those who are appointed Deputies of the Supreme Council that are later elected to membership on the Supreme Council are then designated "Sovereign Grand Inspectors General." In the Northern Jurisdiction
a recipient of the 33rd Degree is an honorary member of the Supreme Council, and all members are referred to as a "Sovereign Grand Inspectors General."
Scottish Rite outside of the United States.
United Kingdom.
In England and Wales, whose Supreme Council was warranted by that of the Northern Jurisdiction of the USA (in 1845), the Rite is known colloquially as the "Rose Croix" or more formally as "The Ancient and Accepted Rite for England and Wales and its Districts and Chapters Overseas" (continental European jurisdictions retain the "Écossais"). The only local bodies are Rose Croix Chapters; many degrees are conferred in name only, and degrees beyond the 18° are conferred only by the Supreme Council itself.
In England, the candidate is perfected in the 18th degree with the preceding degrees awarded in name only. Continuing to the 30th degree is restricted to those who have served in the chair of the Chapter. Elevation beyond the 30th degree is as in Scotland.
In Scotland, candidates are perfected in the 18th degree, with the preceding degrees awarded in name only. A minimum of a two-year interval is required before continuing to the 30th degree, again with the intervening degrees awarded by name only. Elevation beyond that is by invitation only, and numbers are severely restricted.
France.
The Ancient and Accepted Scottish Rite appeared in France thanks to Grasse-Tilly in 1804 on his return from the Antilles. He founded the first Supreme Council in France that same year.
The Grand Orient of France signed a treaty of union in December 1804 with the Supreme Council of the 33rd Degree in France; the treaty declared that "the Grand Orient united to itself" the Supreme Council in France. This accord was applied in fact until 1814. Thanks to this treaty, the Grand Orient of France took ownership, as it were, of the Scottish Rite.
From 1805 to 1814, the Grand Orient of France administered the first 18 degrees of the Rite, leaving the Supreme Council of France to administer the last 15. In 1815, five of the leaders of the Supreme Council founded the "Suprême Conseil des Rites" within the Grand Orient of France. The original Supreme Council of France fell dormant from 1815 to 1821.
The "Suprême Conseil des Isles d'Amérique" (founded in 1802 by Grasse-Tilly and revived around 1810 by Delahogue) breathed new life into the Supreme Council for the 33rd Degree in France, and they merged into a single organization: the Supreme Council of France. This grew into an independent and sovereign Masonic power. It created symbolic lodges (those composed of the first three degrees, which otherwise would be federated around a Grand Lodge or a Grand Orient).
In 1894, the Supreme Council of France created the Grand Lodge of France, which became fully independent in 1904 when the Supreme Council of France ceased chartering new lodges. The Supreme Council of France still considers itself the overseer of all 33 degrees of the Rite, and relations between the two structures remain close, as witnessed by the two joint meetings that they organize each year.
In 1964, the Sovereign Grand Commander Charles Riandey along with 400 to 500 members left the jurisdiction of the Supreme Council of France and joined the Grande Loge Nationale Française, considering that thanks to his resignation and despite the fact that the Supreme Council of France had continued to work without him, there was no longer a Supreme Council of France. Riandey then reinitiated the 33 degrees of the rite in Amsterdam; with the support of the Supreme Council of the Southern Jurisdiction of the United States, he founded a new Supreme Council, called the "Suprême Conseil pour la France", the sole to be recognized by the Supreme Councils of the United States after it was designated as the sole authority of the Scottish Rite for France by the Supreme Council of the Southern Jurisdiction (the oldest Supreme Council in the world) at the Barranquilla conference in 1970.
France thus finds itself in the unusual situation of having three different and arguably legitimate Supreme Councils:
Canada.
In Canada, whose Supreme Council was warranted in 1874 by that of England and Wales, the Rite is known as Ancient and Accepted Scottish Rite. The council is called "Supreme Council 33° Ancient and Accepted Scottish Rite of Freemasonry of Canada". Canada's Supreme Council office is located at 4 Queen Street South in Hamilton, Ontario. There are 45 local units or "Valleys" across Canada.

</doc>
<doc id="28279" url="http://en.wikipedia.org/wiki?curid=28279" title="Sandman (disambiguation)">
Sandman (disambiguation)

The Sandman is a figure in folklore who brings good sleep and dreams.
Sandman may also refer to:

</doc>
<doc id="28284" url="http://en.wikipedia.org/wiki?curid=28284" title="Switch">
Switch

In electrical engineering, a switch is an electrical component that can break an electrical circuit, interrupting the current or diverting it from one conductor to another.
The mechanism of a switch may be operated directly by a human operator to control a circuit (for example, a light switch or a keyboard button), may be operated by a moving object such as a door-operated switch, or may be operated by some sensing element for pressure, temperature or flow. A relay is a switch that is operated by electricity. Switches are made to handle a wide range of voltages and currents; very large switches may be used to isolate high-voltage circuits in electrical substations. 
Description.
The most familiar form of switch is a manually operated electromechanical device with one or more sets of electrical contacts, which are connected to external circuits. Each set of contacts can be in one of two states: either "closed" meaning the contacts are touching and electricity can flow between them, or "open", meaning the contacts are separated and the switch is nonconducting. The mechanism actuating the transition between these two states (open or closed) can be either a "toggle" (flip switch for continuous "on" or "off") or "momentary" (push-for "on" or push-for "off") type.
A switch may be directly manipulated by a human as a control signal to a system, such as a computer keyboard button, or to control power flow in a circuit, such as a light switch. Automatically operated switches can be used to control the motions of machines, for example, to indicate that a garage door has reached its full open position or that a machine tool is in a position to accept another workpiece. Switches may be operated by process variables such as pressure, temperature, flow, current, voltage, and force, acting as sensors in a process and used to automatically control a system. For example, a thermostat is a temperature-operated switch used to control a heating process. A switch that is operated by another electrical circuit is called a relay. Large switches may be remotely operated by a motor drive mechanism. Some switches are used to isolate electric power from a system, providing a visible point of isolation that can be padlocked if necessary to prevent accidental operation of a machine during maintenance, or to prevent electric shock.
An ideal switch would have no voltage drop when closed, and would have no limits on voltage or current rating. It would have zero rise time and fall time during state changes, and would change state without "bouncing" between on and off positions.
Practical switches fall short of this ideal; they have resistance, limits on the current and voltage they can handle, finite switching time, etc. The ideal switch is often used in circuit analysis as it greatly simplifies the system of equations to be solved, but this can lead to a less accurate solution. Theoretical treatment of the effects of non-ideal properties is required in the design of large networks of switches, as for example used in telephone exchanges.
Contacts.
In the simplest case, a switch has two conductive pieces, often metal, called "contacts", connected to an external circuit, that touch to complete (make) the circuit, and separate to open (break) the circuit. The contact material is chosen for its resistance to corrosion, because most metals form insulating oxides that would prevent the switch from working. Contact materials are also chosen on the basis of electrical conductivity, hardness (resistance to abrasive wear), mechanical strength, low cost and low toxicity.
Sometimes the contacts are plated with noble metals. They may be designed to wipe against each other to clean off any contamination. Nonmetallic conductors, such as conductive plastic, are sometimes used. To prevent the formation of insulating oxides, a minimum wetting current may be specified for a given switch design.
Contact terminology.
In electronics, switches are classified according to the arrangement of their contacts. A pair of contacts is said to be ""closed" when current can flow from one to the other. When the contacts are separated by an insulating air gap, they are said to be "open", and no current can flow between them at normal voltages. The terms "make" for closure of contacts and "break" for opening of contacts are also widely used.
The terms pole and throw are also used to describe switch contact variations. The number of "poles" is the number of separate circuits which are controlled by a single switch. For example, a "2-pole" switch has two separate identical sets of contacts controlled by the same switch. The number of "throws"" is the number of separate wiring path choices other than "open" that the switch can adopt for each pole. A single-throw switch has one pair of contacts that can either be closed or open. A double-throw switch has a contact that can be connected to either of two other contacts, a triple-throw has a contact which can be connected to one of three other contacts, etc.
In a switch where the contacts remain in one state unless actuated, such as a push-button switch, the contacts can either be normally open (abbreviated "n.o." or "no") until closed by operation of the switch, or normally closed ("n.c." or "nc") and opened by the switch action. A switch with both types of contact is called a "changeover switch". These may be "make-before-break" ("MBB" or shorting) which momentarily connects both circuits, or may be "break-before-make" ("BBM" or non-shorting) which interrupts one circuit before closing the other.
These terms have given rise to abbreviations for the types of switch which are used in the electronics industry such as "single-pole, single-throw" (SPST) (the simplest type, "on or off") or "single-pole, double-throw" (SPDT), connecting either of two terminals to the common terminal. In electrical power wiring (i.e., house and building wiring by electricians), names generally involve the suffix "-way"; however, these terms differ between British English and American English (i.e., the terms "two way" and "three  way" are used with different meanings).
Switches with larger numbers of poles or throws can be described by replacing the "S" or "D" with a number (e.g. 3PST, 4PST, etc.) or in some cases the letter "T" (for "triple") or "Q" (for "quadruple"). In the rest of this article the terms "SPST", "SPDT" and "intermediate" will be used to avoid the ambiguity.
Contact bounce.
Contact bounce (also called "chatter") is a common problem with mechanical switches and relays. Switch and relay contacts are usually made of springy metals. When the contacts strike together, their momentum and elasticity act together to cause them to bounce apart one or more times before making steady contact. The result is a rapidly pulsed electric current instead of a clean transition from zero to full current. The effect is usually unimportant in power circuits, but causes problems in some analogue and logic circuits that respond fast enough to misinterpret the on‑off pulses as a data stream.
The effects of contact bounce can be eliminated by use of mercury-wetted contacts, but these are now infrequently used because of the hazard of mercury release. Alternatively, contact circuits can be low-pass filtered to reduce or eliminate multiple pulses. In digital systems, multiple samples of the contact state can be taken or a time delay can be implemented in order for the contact bounce to settle before the contact input is used to control anything. Bounce in an SPDT switch can be eliminated by an SR latch. All of these methods are referred to as "debouncing" circuits.
By analogy, the term "debounce" has arisen in the software development industry to describe rate-limiting or throttling the frequency of a method's execution.
Arcs and quenching.
When the power being switched is sufficiently large, the electron flow across opening switch contacts is sufficient to ionize the air molecules across the tiny gap between the contacts as the switch is opened, forming a gas plasma, also known as an electric arc. The plasma is of low resistance and is able to sustain power flow, even with the separation distance between the switch contacts steadily increasing. The plasma is also very hot and is capable of eroding the metal surfaces of the switch contacts. Electric current arcing causes significant degradation of the contacts and also significant electromagnetic interference (EMI), requiring the use of arc suppression methods.
Where the voltage is sufficiently high, an arc can also form as the switch is closed and the contacts approach. If the voltage potential is sufficient to exceed the breakdown voltage of the air separating the contacts, an arc forms which is sustained until the switch closes completely and the switch surfaces make contact.
In either case, the standard method for minimizing arc formation and preventing contact damage is to use a fast-moving switch mechanism, typically using a spring-operated tipping-point mechanism to assure quick motion of switch contacts, regardless of the speed at which the switch control is operated by the user. Movement of the switch control lever applies tension to a spring until a tipping point is reached, and the contacts suddenly snap open or closed as the spring tension is released.
As the power being switched increases, other methods are used to minimize or prevent arc formation. A plasma is hot and will rise due to convection air currents. The arc can be quenched with a series of nonconductive blades spanning the distance between switch contacts, and as the arc rises its length increases as it forms ridges rising into the spaces between the blades, until the arc is too long to stay sustained and is extinguished. A "puffer" may be used to blow a sudden high velocity burst of gas across the switch contacts, which rapidly extends the length of the arc to extinguish it quickly.
Extremely large switches in excess of 100,000‑watt capacity often have switch contacts surrounded by something other than air to more rapidly extinguish the arc. For example, the switch contacts may operate in a vacuum, immersed in mineral oil, or in sulfur hexafluoride.
In AC power service, the current periodically passes through zero; this effect makes it harder to sustain an arc on opening. Manufacturers may rate switches with lower voltage or current rating when used in DC circuits.
Power switching.
When a switch is designed to switch significant power, the transitional state of the switch as well as the ability to withstand continuous operating currents must be considered. When a switch is in the on state, its resistance is near zero and very little power is dropped in the contacts; when a switch is in the off state, its resistance is extremely high and even less power is dropped in the contacts. However, when the switch is flicked, the resistance must pass through a state where a quarter of the load's rated power (or worse if the load is not purely resistive) is briefly dropped in the switch.
For this reason, power switches intended to interrupt a load current have spring mechanisms to make sure the transition between on and off is as short as possible regardless of the speed at which the user moves the rocker.
Power switches usually come in two types. A momentary on‑off switch (such as on a laser pointer) usually takes the form of a button and only closes the circuit when the button is depressed. A regular on‑off switch (such as on a flashlight) has a constant on-off feature. Dual-action switches incorporate both of these features.
Inductive loads.
When a strongly inductive load such as an electric motor is switched off, the current cannot drop instantaneously to zero; a spark will jump across the opening contacts. Switches for inductive loads must be rated to handle these cases. The spark will cause electromagnetic interference if not suppressed; a snubber network of a resistor and capacitor in series will quell the spark.
Incandescent loads.
When turned on, an incandescent lamp draws a large inrush current of about ten times the steady-state current; as the filament heats up, its resistance rises and the current decreases to a steady-state value. A switch designed for an incandescent lamp load can withstand this inrush current.
Wetting current.
"Wetting current" is the minimum current needing to flow through a mechanical switch while it is operated to break through any film of oxidation that may have been deposited on the switch contacts. The film of oxidation occurs often in areas with high humidity. Providing a sufficient amount of wetting current is a crucial step in designing systems that use delicate switches with small contact pressure as sensor inputs. Failing to do this might result in switches remaining electrically "open" due to contact oxidation.
Actuator.
The moving part that applies the operating force to the contacts is called the "actuator", and may be a toggle or "dolly", a rocker, a push-button or any type of mechanical linkage "(see photo)."
Biased switches.
The momentary push-button switch is a type of biased switch. The most common type is a "push-to-make" (or normally-open or NO) switch, which makes contact when the button is pressed and breaks when the button is released. Each key of a computer keyboard, for example, is a normally-open "push-to-make" switch. A "push-to-break" (or normally-closed or NC) switch, on the other hand, breaks contact when the button is pressed and makes contact when it is released. An example of a push-to-break switch is a button used to release a door held closed by an electromagnet. The interior lamp of a household refrigerator is controlled by a switch that is held open when the door is closed.
Rotary switch.
A rotary switch operates with a twisting motion of the operating handle with at least two positions. One or more positions of the switch may be momentary (biased with a spring), requiring the operator to hold the switch in the position. Other positions may have a detent to hold the position when released. A rotary switch may have multiple levels or "decks" in order to allow it to control multiple circuits.
One form of rotary switch consists of a spindle or "rotor" that has a contact arm or "spoke" which projects from its surface like a cam. It has an array of terminals, arranged in a circle around the rotor, each of which serves as a contact for the "spoke" through which any one of a number of different electrical circuits can be connected to the rotor. The switch is layered to allow the use of multiple poles, each layer is equivalent to one pole. Usually such a switch has a detent mechanism so it "clicks" from one active position to another rather than stalls in an intermediate position. Thus a rotary switch provides greater pole and throw capabilities than simpler switches do.
Other types use a cam mechanism to operate multiple independent sets of contacts.
Rotary switches were used as channel selectors on television receivers until the early 1970s, as range selectors on electrical metering equipment, as band selectors on multi-band radios and other similar purposes. In industry, rotary switches are used for control of measuring instruments, switchgear, or in control circuits. For example, a radio controlled overhead crane may have a large multi-circuit rotary switch to transfer hard-wired control signals from the local manual controls in the cab to the outputs of the remote control receiver.
Toggle switch.
A toggle switch is a class of electrical switches that are manually actuated by a mechanical lever, handle, or rocking mechanism.
Toggle switches are available in many different styles and sizes, and are used in numerous applications. Many are designed to provide the simultaneous actuation of multiple sets of electrical contacts, or the control of large amounts of electric current or mains voltages.
The word "toggle" is a reference to a kind of mechanism or joint consisting of two arms, which are almost in line with each other, connected with an elbow-like pivot. However, the phrase "toggle switch" is applied to a switch with a short handle and a positive snap-action, whether it actually contains a toggle mechanism or not. Similarly, a switch where a definitive click is heard, is called a "positive on-off switch" - - the most common use of this type of switch is a typical light switch or electrical outlet switch.
Multiple toggle switches may be mechanically interlocked to prevent forbidden combinations.
Special types.
Switches can be designed to respond to any type of mechanical stimulus: for example, vibration (the trembler switch), tilt, air pressure, fluid level (a float switch), the turning of a key (key switch), linear or rotary movement (a limit switch or microswitch), or presence of a magnetic field (the reed switch). Many switches are operated automatically by changes in some environmental condition or by motion of machinery. A limit switch is used, for example, in machine tools to interlock operation with the proper position of tools. In heating or cooling systems a sail switch ensures that air flow is adequate in a duct. Pressure switches respond to fluid pressure.
Mercury tilt switch.
The mercury switch consists of a drop of mercury inside a glass bulb with two or more contacts. The two contacts pass through the glass, and are connected by the mercury when the bulb is tilted to make the mercury roll on to them.
This type of switch performs much better than the ball tilt switch, as the liquid metal connection is unaffected by dirt, debris and oxidation, it wets the contacts ensuring a very low resistance bounce-free connection, and movement and vibration do not produce a poor contact. These types can be used for precision works.
It can also be used where arcing is dangerous (such as in the presence of explosive vapour) as the entire unit is sealed.
Knife switch.
Knife switches consist of a flat metal blade, hinged at one end, with an insulating handle for operation, and a fixed contact. When the switch is closed, current flows through the hinged pivot and blade and through the fixed contact. Such switches are usually not enclosed. The knife and contacts are typically formed of copper, steel, or brass, depending on the application. Fixed contacts may be backed up with a spring. Several parallel blades can be operated at the same time by one handle. The parts may be mounted on an insulating base with terminals for wiring, or may be directly bolted to an insulated switch board in a large assembly. Since the electrical contacts are exposed, the switch is used only where people cannot accidentally come in contact with the switch or where the voltage is so low as to not present a hazard.
Knife switches are made in many sizes from miniature switches to large devices used to carry thousands of amperes. In electrical transmission and distribution, gang-operated switches are used in circuits up to the highest voltages.
The disadvantages of the knife switch are the slow opening speed and the proximity of the operator to exposed live parts. Metal-enclosed safety disconnect switches are used for isolation of circuits in industrial power distribution. Sometimes spring-loaded auxiliary blades are fitted which momentarily carry the full current during opening, then quickly part to rapidly extinguish the arc.
Footswitch.
A footswitch is a rugged switch which is operated by foot pressure. An example of use is in the control of a machine tool, allowing the operator to have both hands free to manipulate the workpiece. The foot control of an electric guitar is also a footswitch.
Reversing switch.
A DPDT switch has six connections, but since polarity reversal is a very common usage of DPDT switches, some variations of the DPDT switch are internally wired specifically for polarity reversal. These crossover switches only have four terminals rather than six. Two of the terminals are inputs and two are outputs. When connected to a battery or other DC source, the 4-way switch selects from either normal or reversed polarity. Such switches can also be used as intermediate switches in a multiway switching system for control of lamps by more than two switches.
Light switches.
In building wiring, light switches are installed at convenient locations to control lighting and occasionally other circuits. By use of multiple-pole switches, multiway switching control of a lamp can be obtained from two or more places, such as the ends of a corridor or stairwell. A wireless light switch allows remote control of lamps for convenience; some lamps include a touch switch which electronically controls the lamp if touched anywhere. In public buildings several types of vandal resistant switches are used to prevent unauthorized use.
Electronic switches.
A relay is an electrically operated switch. Many relays use an electromagnet to operate a switching mechanism mechanically, but other operating principles are also used. Solid-state relays control power circuits with no moving parts, instead using a semiconductor device to perform switching—often a silicon-controlled rectifier or triac.
The analogue switch uses two MOSFET transistors in a transmission gate arrangement as a switch that works much like a relay, with some advantages and several limitations compared to an electromechanical relay.
The power transistor(s) in a switching voltage regulator, such as a power supply unit, are used like a switch to alternately let power flow and block power from flowing.
Many people use metonymy to call a variety of devices "switches" that conceptually connect or disconnect signals and communication paths between electrical devices, analogous to the way mechanical switches connect and disconnect paths for electrons to flow between two conductors. Early telephone systems used an automatically operated Strowger switch to connect telephone callers; telephone exchanges contain one or more crossbar switches today.
Since the advent of digital logic in the 1950s, the term "switch" has spread to a variety of digital active devices such as transistors and logic gates whose function is to change their output state between two logic levels or connect different signal lines, and even computers, network switches, whose function is to provide connections between different ports in a computer network. The term 'switched' is also applied to telecommunications networks, and signifies a network that is circuit switched, providing dedicated circuits for communication between end nodes, such as the public switched telephone network. The common feature of all these usages is they refer to devices that control a binary state: they are either "on" or "off", "closed" or "open", "connected" or "not connected".

</doc>
<doc id="28287" url="http://en.wikipedia.org/wiki?curid=28287" title="Sutra">
Sutra

A sutra (Sanskrit: सूत्र, Pāli: "sutta", Ardhamagadhi: "sūya") is an aphorism or a collection of aphorisms in the form of a manual or, more broadly, a text in Hinduism or Buddhism. Literally it means a thread or line that holds things together and is derived from the verbal root "siv-", meaning "to sew". The word "sutra" was very likely meant to apply quite literally to these texts, as they were written down in books of palm leaves sewn together with thread. This distinguishes them from the older sacred Vedas, which until recently were only memorised, never committed to paper.
In ancient Indian literature, "sutra" denotes a distinct type of literary composition, based on short aphoristic statements, generally using various technical terms. This literary form was designed for concision, as the texts were intended to be memorized by students in some of the formal methods of scriptural and scientific study (Sanskrit: "svādhyāya"). Since each line is highly condensed, another literary form arose in which commentaries (Sanskrit: "bhāṣya") on the "sutras" were added, to clarify and explain them. For discussion of the literary form for sutras, their terse nature as a summary of ideas for memorization, and the rise of the commentorial literary form as an adjunct to sutras, see: Tubb & Boose 2007, pp. 1–2.
In Brahmin lineage, each family is supposed to have one Gotra, and one Sutra, meaning that a certain Veda (Śruti) is treasured by this family in way of learning by heart.
One of the most famous definitions of a sutra in Indian literature is itself a sutra and comes from the Vayu Purana:
"alpākṣaraṃ asandigdhaṃ sāravad viśvatomukhamastobhaṃ anavadyaṃ ca sūtram sūtravido viduḥ"
Of minimal syllabary, unambiguous, pithy, comprehensive, continuous, and without flaw: who knows the sutra knows it to be thus.
In Jainism, "sutra" refers to canonical sermons of the Mahavira contained in the Jain Agamas, and to some later (post-canonical) normative texts. 
In Buddhism, the "sutra" refers mostly to canonical scriptures, many of which are regarded as records of the oral teachings of Gautama Buddha. In Chinese, these are known as 經 (pinyin: "jīng"). These teachings are assembled in part of the "Tripitaka" which is called "Sutra Pitaka". There are also some Buddhist texts, such as the Platform Sutra, that are called sutras despite being attributed to much later authors. 
Some scholars consider that the Buddhist use of "sutra" is a mis-Sanskritization of Prakrit or Pali "sutta", and that the latter represented Sanskrit "sūkta", "well spoken", "good news" (as the Buddha himself refers to his speech in his first sermon; compare the original meaning of "Gospel"), which would also resolve as "sutta" in Pali. The early Buddhist sutras do not present the aphoristic, nearly cryptic nature of the Hindu sutras, even though they also have been designed for mnemonic purposes in an oral tradition. On the contrary, they are most often lengthy, with many repetitions which serve the mnemonic purpose of the audience. They share the character of sermons of "good news" with the Jaina sutras, whose original name of "sūya" (in Ardhamagadhi language) can derive from Sanskrit "sūkta", but hardly from "sutra". 
The Pali form of the word, sutta is used exclusively to refer to the scriptures of the early Pali Canon, the only texts recognized by Theravada Buddhism as canonical.

</doc>
<doc id="28288" url="http://en.wikipedia.org/wiki?curid=28288" title="Samurai">
Samurai

Samurai (侍) were the military nobility of medieval and early-modern Japan.
In Japanese, they are usually referred to as bushi (武士, ]) or buke (武家). According to translator William Scott Wilson: "In Chinese, the character 侍 was originally a verb meaning to wait upon or accompany persons in the upper ranks of society, and this is also true of the original term in Japanese, saburau. In both countries the terms were nominalized to mean "those who serve in close attendance to the nobility", the pronunciation in Japanese changing to saburai. According to Wilson, an early reference to the word "samurai" appears in the Kokin Wakashū (905–914), the first imperial anthology of poems, completed in the first part of the 10th century.
By the end of the 12th century, samurai became almost entirely synonymous with "bushi", and the word was closely associated with the middle and upper echelons of the warrior class. The samurai followed a set of rules that came to be known as bushidō. While the samurai numbered less than 10% of Japan's population, their teachings can still be found today in both everyday life and in modern Japanese martial arts.
History.
Asuka and Nara periods.
Following the Battle of Hakusukinoe against Tang China and Silla in 663 AD that led to a Japanese retreat from Korean affairs, Japan underwent widespread reform. One of the most important was that of the Taika Reform, issued by Prince Naka no Ōe (Emperor Tenji) in 646 AD. This edict allowed the Japanese aristocracy to adopt the Tang dynasty political structure, bureaucracy, culture, religion, and philosophy. As part of the Taihō Code, of 702 AD, and the later Yōrō Code, the population was required to report regularly for census, a precursor for national conscription. With an understanding of how the population was distributed, Emperor Mommu introduced a law whereby 1 in 3–4 adult males was drafted into the national military. These soldiers were required to supply their own weapons, and in return were exempted from duties and taxes. This was one of the first attempts by the Imperial government to form an organized army modeled after the Chinese system. It was called "Gundan-Sei" (軍団制) by later historians and is believed to have been short-lived.
The Taihō Code classified most of the Imperial bureaucrats into 12 ranks, each divided into two sub-ranks, 1st rank being the highest adviser to the Emperor. Those of 6th rank and below were referred to as "samurai" and dealt with day-to-day affairs. Although these "samurai" were civilian public servants, the name is believed to have derived from this term. Military men, however, would not be referred to as "samurai" for many more centuries.
Heian period.
In the early Heian period, the late 8th and early 9th centuries, Emperor Kammu sought to consolidate and expand his rule in northern Honshū, but the armies he sent to conquer the rebellious Emishi people lacked motivation and discipline, and failed in their task. Emperor Kammu introduced the title of "sei'i-taishōgun" (征夷大将軍) or Shogun, and began to rely on the powerful regional clans to conquer the Emishi. Skilled in mounted combat and archery (kyūdō), these clan warriors became the Emperor's preferred tool for putting down rebellions. Though this is the first known use of the "Shogun" title, it was a temporary title, and was not imbued with political power until the 13th century. At this time (the 7th to 9th century) the Imperial Court officials considered them merely a military section under the control of the Imperial Court.
Ultimately, Emperor Kammu disbanded his army. From this time, the emperor's power gradually declined. While the emperor was still the ruler, powerful clans around Kyoto (京都) assumed positions as ministers, and their relatives bought positions as magistrates. To amass wealth and repay their debts, magistrates often imposed heavy taxes, resulting in many farmers becoming landless.
Through protective agreements and political marriages, they accumulated, or gathered, political power, eventually surpassing the traditional aristocracy.
Some clans were originally formed by farmers who had taken up arms to protect themselves from the Imperial magistrates sent to govern their lands and collect taxes. These clans formed alliances to protect themselves against more powerful clans, and by the mid-Heian period they had adopted characteristic Japanese armor and weapons, and laid the foundations of "Bushidō", their ethical code.
After the Genpei war of the late 12th century, a clan leader Minamoto no Yoritomo obtained the right to appoint "shugo" and "jito", and was allowed to organize soldiers and police, and to collect a certain amount of tax. Initially, their responsibility was restricted to arresting rebels and collecting needed army provisions, and they were forbidden from interfering with "Kokushi" Governors, but their responsibility gradually expanded and thus the samurai-class appeared as the political ruling power in Japan. Minamoto no Yoritomo opened the Kamakura Bakufu Shogunate in 1192.
Kamakura Bakufu and the rise of samurai.
Originally the emperor and nobility employed these warriors. In time, they amassed enough manpower, resources and political backing in the form of alliances with one another, to establish the first samurai-dominated government. As the power of these regional clans grew, their chief was typically a distant relative of the emperor and a lesser member of either the Fujiwara, Minamoto, or Taira clans. Though originally sent to provincial areas for a fixed four-year term as a magistrate, the "toryo" declined to return to the capital when their terms ended, and their sons inherited their positions and continued to lead the clans in putting down rebellions throughout Japan during the middle- and later-Heian period. Because of their rising military and economic power, the warriors ultimately became a new force in the politics of the court. Their involvement in the Hōgen in the late Heian period consolidated their power, and finally pitted the rival Minamoto and Taira clans against each other in the Heiji Rebellion of 1160.
The winner, Taira no Kiyomori, became an imperial advisor, and was the first warrior to attain such a position. He eventually seized control of the central government, establishing the first samurai-dominated government and relegating the emperor to figurehead status. However, the Taira clan was still very conservative when compared to its eventual successor, the Minamoto, and instead of expanding or strengthening its military might, the clan had its women marry emperors and exercise control through the emperor.
The Taira and the Minamoto clashed again in 1180, beginning the Gempei War, which ended in 1185. Samurai fought at the naval battle of Dan-no-ura, at the Shimonoseki Strait which separates Honshu and Kyushu in 1185. The victorious Minamoto no Yoritomo established the superiority of the samurai over the aristocracy. In 1190 he visited Kyoto and in 1192 became Sei'i-taishōgun, establishing the Kamakura Shogunate, or "Kamakura Bakufu". Instead of ruling from Kyoto, he set up the Shogunate in Kamakura, near his base of power. "Bakufu" means "tent government", taken from the encampments the soldiers would live in, in accordance with the Bakufu's status as a military government.
Over time, powerful samurai clans became warrior nobility, or "buke", who were only nominally under the court aristocracy. When the samurai began to adopt aristocratic pastimes like calligraphy, poetry and music, some court aristocrats in turn began to adopt samurai customs. Despite machinations and brief periods of rule by emperors, real power was then in the hands of the Shogun and the samurai.
Ashikaga Shogunate.
Various samurai clans struggled for power during the Kamakura and Ashikaga Shogunates. Zen Buddhism spread among the samurai in the 13th century and helped to shape their standards of conduct, particularly overcoming fear of death and killing, but among the general populace, Pure Land Buddhism was favored.
In 1274, the Mongol-founded Yuan dynasty in China sent a force of some 40,000 men and 900 ships to invade Japan in northern Kyūshū. Japan mustered a mere 10,000 samurai to meet this threat. The invading army was harassed by major thunderstorms throughout the invasion, which aided the defenders by inflicting heavy casualties. The Yuan army was eventually recalled and the invasion was called off. The Mongol invaders used small bombs, which was likely the first appearance of bombs and gunpowder in Japan.
The Japanese defenders recognized the possibility of a renewed invasion, and began construction of a great stone barrier around Hakata Bay in 1276. Completed in 1277, this wall stretched for 20 kilometers around the border of the bay. This would later serve as a strong defensive point against the Mongols. The Mongols attempted to settle matters in a diplomatic way from 1275 to 1279, but every envoy sent to Japan was executed. This set the stage for one of the most famous engagements in Japanese history.
In 1281, a Yuan army of 140,000 men with 5,000 ships was mustered for another invasion of Japan. Northern Kyūshū was defended by a Japanese army of 40,000 men. The Mongol army was still on its ships preparing for the landing operation when a typhoon hit north Kyūshū island. The casualties and damage inflicted by the typhoon, followed by the Japanese defense of the Hakata Bay barrier, resulted in the Mongols again recalling their armies.
The thunderstorms of 1274 and the typhoon of 1281 helped the samurai defenders of Japan repel the Mongol invaders despite being vastly outnumbered. These winds became known as "kami-no-kaze", which literally translates as "wind of the gods". This is often given a simplified translation as "divine wind". The "kami-no-kaze" lent credence to the Japanese belief that their lands were indeed divine and under supernatural protection.
In the 14th century, a blacksmith called Masamune developed a two-layer structure of soft and hard steel for use in swords. This structure gave much improved cutting power and endurance, and the production technique led to Japanese swords (katana) being recognized as some of the most potent hand weapons of pre-industrial East Asia. Many swords made using this technique were exported across the East China Sea, a few making their way as far as India.
Issues of inheritance caused family strife as primogeniture became common, in contrast to the division of succession designated by law before the 14th century. To avoid infighting, invasions of neighboring samurai territories became common and bickering among samurai was a constant problem for the Kamakura and Ashikaga Shogunates.
Sengoku period.
The "Sengoku jidai" ("warring-states period") was marked by the loosening of samurai culture with people born into other social strata sometimes making names for themselves as warriors and thus becoming de facto samurai. In this turbulent period, bushido ethics became important factors in controlling and maintaining public order.
Japanese war tactics and technologies improved rapidly in the 15th and 16th century. Use of large numbers of infantry called ashigaru ("light-foot", due to their light armor), formed of humble warriors or ordinary people with "nagayari" (a long lance) or (naginata), was introduced and combined with cavalry in maneuvers. The number of people mobilized in warfare ranged from thousands to hundreds of thousands.
The arquebus, a matchlock gun, was introduced by the Portuguese via a Chinese pirate ship in 1543 and the Japanese succeeded in assimilating it within a decade. Groups of mercenaries with mass-produced arquebuses began playing a critical role. By the end of the Sengoku Period, several hundred thousand firearms existed in Japan and massive armies numbering over 100,000 clashed in battles.
Azuchi–Momoyama period.
In 1592, and again in 1597, Toyotomi Hideyoshi decided to invade China (唐入り) through Korea and mobilized an army of 160,000 peasants and samurai.(See Hideyoshi's invasions of Korea, "Chōsen-seibatsu" (朝鮮征伐). Taking advantage of its mastery of the arquebus, Japanese samurai made major gains in most of Korea. Kato Kiyomasa advanced to Orangkai (present northeastern region of China) and crossed the Korean border, but withdrew when it was clear he had outpaced the rest of the Japanese invasion force. A few of the more famous samurai generals of this war were Katō Kiyomasa, Konishi Yukinaga, and Shimazu Yoshihiro. Shimazu Yoshihiro led 7,000 Samurai and defeated the tens of thousands of soldiers of Ming and Korean allied Forces at the Battle of Sacheon in 1598. Yoshihiro was feared as "Oni-Shimazu" ("Shimazu ogre") and his nickname spread across not only Korea but to Ming Dynasty China.
Social mobility was high, as the ancient regime collapsed and emerging samurai needed to maintain large military and administrative organizations in their areas of influence. Most of the samurai families that survived to the 19th century originated in this era, declaring themselves to be the blood of one of the four ancient noble clans: Minamoto, Taira, Fujiwara and Tachibana. In most cases, however, it is hard to prove these claims.
Oda, Toyotomi and Tokugawa.
Oda Nobunaga was the well-known lord of the Nagoya area (once called Owari Province) and an exceptional example of a samurai of the Sengoku Period. He came within a few years of, and laid down the path for his successors to follow, the reunification of Japan under a new Bakufu (Shogunate).
Oda Nobunaga made innovations in the fields of organization and war tactics, heavily used arquebuses, developed commerce and industry and treasured innovation. Consecutive victories enabled him to realize the termination of the Ashikaga Bakufu and the disarmament of the military powers of the Buddhist monks, which had inflamed futile struggles among the populace for centuries. Attacking from the "sanctuary" of Buddhist temples, they were constant headaches to any warlord and even the emperor who tried to control their actions. He died in 1582 when one of his generals, Akechi Mitsuhide, turned upon him with his army.
Importantly, Toyotomi Hideyoshi (see below) and Tokugawa Ieyasu, who founded the Tokugawa Shogunate, were loyal followers of Nobunaga. Hideyoshi began as a peasant and became one of Nobunaga's top generals, and Ieyasu had shared his childhood with Nobunaga. Hideyoshi defeated Mitsuhide within a month, and was regarded as the rightful successor of Nobunaga by avenging the treachery of Mitsuhide.
These two were able to use Nobunaga's previous achievements on which build a unified Japan and there was a saying: "The reunification is a rice cake; Oda made it. Hashiba shaped it. At last, only Ieyasu tastes it." (Hashiba is the family name that Toyotomi Hideyoshi used while he was a follower of Nobunaga.)
Toyotomi Hideyoshi, who became a grand minister in 1586, himself the son of a poor peasant family, created a law that the samurai caste became codified as permanent and hereditary, and that non-samurai were forbidden to carry weapons, thereby ending the social mobility of Japan up until that point, which lasted until the dissolution of the Edo Shogunate by the Meiji revolutionaries.
It is important to note that the distinction between samurai and non-samurai was so obscure that during the 16th century, most male adults in any social class (even small farmers) belonged to at least one military organization of their own and served in wars before and during Hideyoshi's rule. It can be said that an "all against all" situation continued for a century.
The authorized samurai families after the 17th century were those that chose to follow Nobunaga, Hideyoshi and Ieyasu. Large battles occurred during the change between regimes, and a number of defeated samurai were destroyed, went ronin or were absorbed into the general populace.
Tokugawa Shogunate.
During the Tokugawa shogunate, samurai increasingly became courtiers, bureaucrats, and administrators rather than warriors. With no warfare since the early 17th century, samurai gradually lost their military function during the Tokugawa era (also called the Edo period). By the end of the Tokugawa era, samurai were aristocratic bureaucrats for the daimyo, with their "daisho", the paired long and short swords of the samurai (cf. katana and wakizashi) becoming more of a symbolic emblem of power rather than a weapon used in daily life. They still had the legal right to cut down any commoner who did not show proper respect "kiri-sute gomen" (斬り捨て御免), but to what extent this right was used is unknown. When the central government forced daimyos to cut the size of their armies, unemployed rōnin became a social problem.
Theoretical obligations between a samurai and his lord (usually a daimyo) increased from the Genpei era to the Edo era. They were strongly emphasized by the teachings of Confucius and Mencius (ca 550 BC), which were required reading for the educated samurai class. Bushido was formalized by several influential leaders and families before the Edo Period. Bushido was an ideal, and it remained fairly uniform from the 13th century to the 19th century — the ideals of Bushido transcended social class, time and geographic location of the warrior class.
Bushido was formalized by samurai such as Imagawa Ryoshun as early as the 13th century. The conduct of samurai served as role model behavior for the other social classes. With time on their hands, samurai spent more time in pursuit of other interests such as becoming scholars.
Modernization.
The relative peace of the Tokugawa era was shattered with the arrival of Commodore Matthew Perry's massive U.S. Navy steamships in 1853. Perry used his superior firepower to force Japan to open its borders to trade. Prior to that only a few harbor towns, under strict control from the Shogunate, were allowed to participate in Western trade, and even then, it was based largely on the idea of playing the Franciscans and Dominicans off against one another (in exchange for the crucial arquebus technology, which in turn was a major contributor to the downfall of the classical samurai).
From 1854, the samurai army and the navy were modernized. A Naval training school was established in Nagasaki in 1855. Naval students were sent to study in Western naval schools for several years, starting a tradition of foreign-educated future leaders, such as Admiral Enomoto. French naval engineers were hired to build naval arsenals, such as Yokosuka and Nagasaki. By the end of the Tokugawa shogunate in 1867, the Japanese navy of the shogun already possessed eight western-style steam warships around the flagship "Kaiyō Maru", which were used against pro-imperial forces during the Boshin war, under the command of Admiral Enomoto. A French Military Mission to Japan (1867) was established to help modernize the armies of the Bakufu.
The last showing of the original samurai was in 1867 when samurai from Chōshū and Satsuma provinces defeated the Shogunate forces in favor of the rule of the emperor in the Boshin War (1868–1869). The two provinces were the lands of the daimyo that submitted to Ieyasu after the Battle of Sekigahara (1600).
Decline.
Emperor Meiji abolished the samurai's right to be the only armed force in favor of a more modern, western-style, conscripted army in 1873. Samurai became "Shizoku" (士族) who retained some of their salaries, but the right to wear a katana in public was eventually abolished along with the right to execute commoners who paid them disrespect. The samurai finally came to an end after hundreds of years of enjoyment of their status, their powers, and their ability to shape the government of Japan. However, the rule of the state by the military class was not yet over. In defining how a modern Japan should be, members of the Meiji government decided to follow the footsteps of the United Kingdom and Germany, basing the country on the concept of "noblesse oblige". Samurai were not a political force under the new order. With the Meiji reforms in the late 19th century, the samurai class was abolished, and a western-style national army was established. The Imperial Japanese Armies were conscripted, but many samurai volunteered as soldiers, and many advanced to be trained as officers. Much of the Imperial Army officer class was of samurai origin, and were highly motivated, disciplined, and exceptionally trained.
The last samurai conflict was arguably in 1877, during the Satsuma Rebellion in the Battle of Shiroyama. This conflict had its genesis in the previous uprising to defeat the Tokugawa Shogunate, leading to the Meiji Restoration. The newly formed government instituted radical changes, aimed at reducing the power of the feudal domains, including Satsuma, and the dissolution of samurai status. This led to the ultimately premature uprising, led by Saigō Takamori.
Samurai were many of the early exchange students, not directly because they were samurai, but because many samurai were literate and well-educated scholars. Some of these exchange students started private schools for higher educations, while many samurai took pens instead of guns and became reporters and writers, setting up newspaper companies, and others entered governmental service. Some samurai became businessmen. For example, Iwasaki Yatarō, who was great-grandson of a samurai, established Mitsubishi.
Only the name Shizoku existed after that. After Japan lost World War II, the name Shizoku disappeared under the law on 1 January 1947.
Philosophy.
Religious influences.
The philosophies of Buddhism and Zen, and to a lesser extent Confucianism and Shinto, influenced the samurai culture. Zen meditation became an important teaching due to it offering a process to calm one's mind. The Buddhist concept of reincarnation and rebirth led samurai to abandon torture and needless killing, while some samurai even gave up violence altogether and became Buddhist monks after realizing how fruitless their killings were. Some were killed as they came to terms with these realizations in the battlefield. The most defining role that Confucianism played in samurai philosophy was to stress the importance of the lord-retainer relationship—the loyalty that a samurai was required to show his lord.
Bushidō ("way of the warrior") was a term that began to appear in intellectual and nationalist discourse after the Japanese defeat of China in 1895 and of Russia in 1905. "Hagakure" or "Hidden in Leaves" by Yamamoto Tsunetomo and " Gorin no Sho" or "Book of the Five Rings" by Miyamoto Musashi, both written in the Tokugawa period (1603–1868), are theories often associated with Bushido and Zen philosophy.
The philosophies of Buddhism and Zen, and to a lesser extent Confucianism and Shinto, are attributed to the development of the samurai culture. "The notion that Zen is somehow related to Japanese culture in general, and bushido in particular, is familiar to Western students of Zen through the writings of D. T. Suzuki, no doubt the single most important figure in the spread of Zen in the West."
In an account of Japan sent to Father Ignatius Loyola at Rome, drawn from the statements of Anger (Han-Siro's western name), Xavier describes the importance of honor to the Japanese (Letter preserved at College of Coimbra.):
In the first place, the nation with which we have had to do here surpasses in goodness any of the nations lately discovered. I really think that among barbarous nations there can be none that has more natural goodness than the Japanese. They are of a kindly disposition, not at all given to cheating, wonderfully desirous of honour and rank. Honour with them is placed above everything else. There are a great many poor among them, but poverty is not a disgrace to any one. There is one thing among them of which I hardly know whether it is practised anywhere among Christians. The nobles, however poor they may be, receive the same honour from the rest as if they were rich.
Doctrine.
Samurai warriors described themselves as followers of "The Way of the Warrior" or Bushido. Bushidō is defined by the Japanese dictionary "Shogakukan Kokugo Daijiten" as "a unique philosophy ("ronri") that spread through the warrior class from the Muromachi ("chusei") period. From the earliest times, the Samurai felt that the path of the warrior was one of honor, emphasizing duty to one's master, and loyalty unto death".
In the 13th century, Hōjō Shigetoki (1198–1261 AD) wrote: "When one is serving officially or in the master's court, he should not think of a hundred or a thousand people, but should consider only the importance of the master." Carl Steenstrup noted that 13th and 14th century warrior writings ("gunki") "portrayed the bushi in their natural element, war, eulogizing such virtues as reckless bravery, fierce family pride, and selfless, at times senseless devotion of master and man". Feudal lords such as Shiba Yoshimasa (1350–1410 AD) stated that a warrior looked forward to a glorious death in the service of a military leader or the emperor: "It is a matter of regret to let the moment when one should die pass by...First, a man whose profession is the use of arms should think and then act upon not only his own fame, but also that of his descendants. He should not scandalize his name forever by holding his one and only life too dear...One's main purpose in throwing away his life is to do so either for the sake of the Emperor or in some great undertaking of a military general. It is that exactly that will be the great fame of one's descendants."
In 1412 AD, Imagawa Sadayo wrote a letter of admonishment to his brother stressing the importance of duty to one's master. Imagawa was admired for his balance of military and administrative skills during his lifetime and his writings became widespread. The letters became central to Tokugawa-era laws and were a required study for traditional Japanese until World War II:
"First of all, a samurai who dislikes battle and has not put his heart in the right place even though he has been born in the house of the warrior, should not be reckoned among one's retainers...It is forbidden to forget the great debt of kindness one owes to his master and ancestors and thereby make light of the virtues of loyalty and filial piety...It is forbidden that one should...attach little importance to his duties to his master...There is a primary need to distinguish loyalty from disloyalty and to establish rewards and punishments."
Similarly, the feudal lord Takeda Nobushige (1525–1561 AD) stated: "In matters both great and small, one should not turn his back on his master's commands...One should not ask for gifts or enfiefments from the master...No matter how unreasonably the master may treat a man, he should not feel disgruntled...An underling does not pass judgments on a superior"
Nobushige's brother Takeda Shingen (1521–1573 AD) also made similar observations: "One who was born in the house of a warrior, regardless of his rank or class, first acquaints himself with a man of military feats and achievements in loyalty...Everyone knows that if a man doesn't hold filial piety toward his own parents he would also neglect his duties toward his lord. Such a neglect means a disloyalty toward humanity. Therefore such a man doesn't deserve to be called 'samurai'."
The feudal lord Asakura Yoshikage (1428–1481 AD) wrote: "In the fief of the Asakura, one should not determine hereditary chief retainers. A man should be assigned according to his ability and loyalty." Asakura also observed that the successes of his father were obtained by the kind treatment of the warriors and common people living in domain. By his civility, "all were willing to sacrifice their lives for him and become his allies."
Katō Kiyomasa was one of the most powerful and well-known lords of the Sengoku Era. He commanded most of Japan's major clans during the invasion of Korea (1592–1598). In a handbook he addressed to "all samurai, regardless of rank" he told his followers that a warrior's only duty in life was to "...grasp the long and the short swords and to die". He also ordered his followers to put forth great effort in studying the military classics, especially those related to loyalty and filial piety. He is best known for his quote: "If a man does not investigate into the matter of Bushido daily, it will be difficult for him to die a brave and manly death. Thus it is essential to engrave this business of the warrior into one's mind well."
Nabeshima Naoshige (1538–1618 AD) was another Sengoku Daimyo who fought alongside Kato Kiyomasa in Korea. He stated that it was shameful for any man to have not risked his life at least once in the line of duty, regardless of his rank. Nabeshima's sayings would be passed down to his son and grandson and would become the basis for Tsunetomo Yamamoto's "Hagakure". He is best known for his saying "The way of the Samurai is in desperateness. Ten men or more cannot kill such a man."
Torii Mototada (1539–1600) was a feudal lord in the service of Tokugawa Ieyasu. On the eve of the battle of Sekigahara, he volunteered to remain behind in the doomed Fushimi Castle while his lord advanced to the east. Torii and Tokugawa both agreed that the castle was indefensible. In an act of loyalty to his lord, Torii chose to remain behind, pledging that he and his men would fight to the finish. As was custom, Torii vowed that he would not be taken alive. In a dramatic last stand, the garrison of 2,000 men held out against overwhelming odds for ten days against the massive army of Ishida Mitsunari's 40,000 warriors. In a moving to his son Tadamasa, he wrote:
"It is not the Way of the Warrior [i.e., bushido] to be shamed and avoid death even under circumstances that are not particularly important. It goes without saying that to sacrifice one's life for the sake of his master is an unchanging principle. That I should be able to go ahead of all the other warriors of this country and lay down my life for the sake of my master's benevolence is an honor to my family and has been my most fervent desire for many years."
It is said that both men cried when they parted ways, because they knew they would never see each other again. Torii's father and grandfather had served the Tokugawa before him and his own brother had already been killed in battle. Torii's actions changed the course of Japanese history. Ieyasu Tokugawa would successfully raise an army and win at Sekigahara.
The translator of "Hagakure", William Scott Wilson observed examples of warrior emphasis on death in clans other than Yamamoto's: "he (Takeda Shingen) was a strict disciplinarian as a warrior, and there is an exemplary story in the "Hagakure" relating his execution of two brawlers, not because they had fought, but because they had not fought to the death".
The rival of Takeda Shingen (1521–1573) was Uesugi Kenshin (1530–1578), a legendary Sengoku warlord well-versed in the Chinese military classics and who advocated the "way of the warrior as death". Japanese historian Daisetz Teitaro Suzuki describes Uesugi's beliefs as: "Those who are reluctant to give up their lives and embrace death are not true warriors...
Go to the battlefield firmly confident of victory, and you will come home with no wounds whatever. Engage in combat fully determined to die and you will be alive; wish to survive in the battle and you will surely meet death. When you leave the house determined not to see it again you will come home safely; when you have any thought of returning you will not return. You may not be in the wrong to think that the world is always subject to change, but the warrior must not entertain this way of thinking, for his fate is always determined."
Families such as the Imagawa were influential in the development of warrior ethics and were widely quoted by other lords during their lifetime. The writings of Imagawa Sadayo were highly respected and sought out by Tokugawa Ieyasu as the source of . These writings were a required study among traditional Japanese until World War II.
Historian H. Paul Varley notes the description of Japan given by Jesuit leader St. Francis Xavier (1506–1552): "There is no nation in the world which fears death less." Xavier further the honour and manners of the people: "I fancy that there are no people in the world more punctilious about their honour than the Japanese, for they will not put up with a single insult or even a word spoken in anger." Xavier spent the years 1549–1551 converting Japanese to Christianity. He also observed: "The Japanese are much braver and more warlike than the people of China, Korea, Ternate and all of the other nations around the Philippines."
Arts.
In December 1547, Francis was in Malacca (Malaysia) waiting to return to Goa (India) when he met a low-ranked samurai named Anjiro (possibly spelled "Yajiro"). Anjiro was not a nobleman or an intellectual, but he impressed Xavier because he took careful notes of everything he said in church. Xavier made the decision to go to Japan in part because this low-ranking samurai convinced him in Portuguese that the Japanese people were highly educated and eager to learn. They were hard workers and respectful of authority. In their laws and customs they were led by reason, and, should the Christian faith convince them of its truth, they would accept it en masse.
By the 12th century, upper-class samurai were highly literate due to the general introduction of Confucianism from China during the 7th to 9th centuries, and in response to their perceived need to deal with the imperial court, who had a monopoly on culture and literacy for most of the Heian period. As a result they aspired to the more cultured abilities of the nobility.
Examples such as Taira Tadanori (a samurai who appears in the "Heike Monogatari") demonstrate that warriors idealized the arts and aspired to become skilled in them.
Tadanori was famous for his skill with the pen and the sword or the "bun and the bu", the harmony of fighting and learning.
Samurai were expected to be cultured and literate, and admired the ancient saying "bunbu-ryōdō" (文武両道, lit., literary arts, military arts, both ways) or "The pen and the sword in accord". By the time of the Edo period, Japan had a higher literacy comparable to that in central Europe.
The number of men who actually achieved the ideal and lived their lives by it was high. An early term for warrior, "uruwashii", was written with a kanji that combined the characters for literary study ("bun" 文) and military arts ("bu" 武), and is mentioned in the Heike Monogatari (late 12th century). The Heike Monogatari makes reference to the educated poet-swordsman ideal in its mention of Taira no Tadanori's death:
Friends and foes alike wet their sleeves with tears and said,<br>
What a pity! Tadanori was a great general,<br>
pre-eminent in the arts of both sword and poetry.
In his book "Ideals of the Samurai" translator William Scott Wilson states: "The warriors in the served as models for the educated warriors of later generations, and the ideals depicted by them were not assumed to be beyond reach. Rather, these ideals were vigorously pursued in the upper echelons of warrior society and recommended as the proper form of the Japanese man of arms. With the Heike Monogatari, the image of the Japanese warrior in literature came to its full maturity." Wilson then translates the writings of several warriors who mention the Heike Monogatari as an example for their men to follow.
Plenty of warrior writings document this ideal from the 13th century onward. Most warriors aspired to or followed this ideal otherwise there would have been no cohesion in the samurai armies.
Culture.
As aristocrats for centuries, samurai developed their own cultures that influenced Japanese culture as a whole. The culture associated with the samurai such as the tea ceremony, monochrome ink painting, rock gardens and poetry were adopted by warrior patrons throughout the centuries 1200–1600. These practices were adapted from the Chinese arts. Zen monks introduced them to Japan and they were allowed to flourish due to the interest of powerful warrior elites. Musō Soseki (1275–1351) was a Zen monk who was advisor to both Emperor Go-Daigo and General Ashikaga Takauji (1304–58). Musō, as well as other monks, acted as political and cultural diplomat between Japan and China. Musō was particularly well known for his garden design. Another Ashikaga patron of the arts was Yoshimasa. His cultural advisor, the Zen monk Zeami, introduced tea ceremony to him. Previously, tea had been used primarily for Buddhist monks to stay awake during meditation.
Education.
In general, samurai, aristocrats, and priests had a very high literacy rate in kanji. Recent studies have shown that literacy in kanji among other groups in society was somewhat higher than previously understood. For example, court documents, birth and death records and marriage records from the Kamakura period, submitted by farmers, were prepared in Kanji. Both the kanji literacy rate and skills in math improved toward the end of Kamakura period.
Literacy was generally high among the warriors and the common classes as well. The feudal lord Asakura Norikage (1474–1555 AD) noted the great loyalty given to his father, due to his polite letters, not just to fellow samurai, but also to the farmers and townspeople:
There were to Lord Eirin's character many high points difficult to measure, but according to the elders the foremost of these was the way he governed the province by his civility. It goes without saying that he acted this way toward those in the samurai class, but he was also polite in writing letters to the farmers and townspeople, and even in addressing these letters he was gracious beyond normal practice. In this way, all were willing to sacrifice their lives for him and become his allies.
In a letter dated 29 January 1552, St Francis Xavier observed the ease of which the Japanese understood prayers due to the high level of literacy in Japan at that time:
There are two kinds of writing in Japan, one used by men and the other by women; and for the most part both men and women, especially of the nobility and the commercial class, have a literary education. The bonzes, or bonzesses, in their monasteries teach letters to the girls and boys, though rich and noble persons entrust the education of their children to private tutors.<br>
Most of them can read, and this is a great help to them for the easy understanding of our usual prayers and the chief points of our holy religion.
In a letter to Father Ignatius Loyola at Rome, Xavier further noted the education of the upper classes:
The Nobles send their sons to monasteries to be educated as soon as they are 8 years old, and they remain there until they are 19 or 20, learning reading, writing and religion; as soon as they come out, they marry and apply themselves to politics.
They are discreet, magnanimous and lovers of virtue and letters, honouring learned men very much.
In a letter dated 11 November 1549, Xavier described a multi-tiered educational system in Japan consisting of "universities", "colleges", "academies" and hundreds of monasteries that served as a principle center for learning by the populace:
But now we must give you an account of our stay at Cagoxima. We put into that port because the wind was adverse to our sailing to Meaco, which is the largest city in Japan, and most famous as the residence of the King and the Princes. It is said that after four months are passed the favourable season for a voyage to Meaco will return, and then with the good help of God we shall sail thither. The distance from Cagoxima is three hundred leagues. We hear wonderful stories about the size of Meaco: they say that it consists of more than ninety thousand dwellings. There is a very famous University there, as well as five chief colleges of students, and more than two hundred monasteries of bonzes, and of others who are like coenobites, called Legioxi, as well as of women of the same kind, who are called Hamacutis. Besides this of Meaco, there are in Japan five other principal academies, at Coya, at Negu, at Fisso, and at Homia. These are situated round Meaco, with short distances between them, and each is frequented by about three thousand five hundred scholars. Besides these there is the Academy at Bandou, much the largest and most famous in all Japan, and at a great distance from Meaco. Bandou is a large territory, ruled by six minor princes, one of whom is more powerful than the others and is obeyed by them, being himself subject to the King of Japan, who is called the Great King of Meaco. The things that are given out as to the greatness and celebrity of these universities and cities are so wonderful as to make us think of seeing them first with our own eyes and ascertaining the truth, and then when we have discovered and know how things really are, of writing an account of them to you. They say that there are several lesser academies besides those which we have mentioned.
Names.
A samurai was usually named by combining one kanji from his father or grandfather and one new kanji. Samurai normally used only a small part of their total name.
For example, the full name of Oda Nobunaga would be "Oda Kazusanosuke Saburo Nobunaga" (織田上総介三郎信長), in which "Oda" is a clan or family name, "Kazusanosuke" is a title of vice-governor of Kazusa province, "Saburo" is a name before genpuku, a coming of age ceremony, and "Nobunaga" is an adult name. Samurai were able to choose their own first names.
Marriage.
The marriage of samurai was done by having a marriage arranged by someone with the same or higher rank than those being married. While for those samurai in the upper ranks this was a necessity (as most had few opportunities to meet a female), this was a formality for lower ranked samurai. Most samurai married women from a samurai family, but for a lower ranked samurai, marriages with commoners were permitted. In these marriages a dowry was brought by the woman and was used to start their new lives.
A samurai could have a mistress but her background was strictly checked by higher ranked samurai. In many cases, this was treated like a marriage. "Kidnapping" a mistress, although common in fiction, would have been shameful, if not a crime. When she was a commoner, a messenger would be sent with betrothal money or a note for exemption of tax to ask for her parent's acceptance and many parents gladly accepted. If a samurai's wife gave birth to a son he could then one day become a samurai.
A samurai could divorce his wife for a variety of reasons with approval from a superior, but divorce was, while not entirely nonexistent, a rare event. A reason for divorce would be if she could not produce a son, but then adoption could be arranged as an alternative to divorce. A samurai could divorce for personal reasons, even if he simply did not like his wife, but this was generally avoided as it would embarrass the samurai who had arranged the marriage. A woman could also arrange a divorce, although it would generally take the form of the samurai divorcing her. After a divorce samurai had to return the betrothal money, which often prevented divorces. Some rich merchants had their daughters marry samurai to erase a samurai's debt and advance their positions.
Women.
Maintaining the household was the main duty of samurai women. This was especially crucial during early feudal Japan, when warrior husbands were often traveling abroad or engaged in clan battles. The wife, or "okugatasama" (meaning: one who remains in the home), was left to manage all household affairs, care for the children, and perhaps even defend the home forcibly. For this reason, many women of the samurai class were trained in wielding a polearm called a naginata or a special knife called the "kaiken" in an art called "tantojutsu" (lit. the skill of the knife), which they could use to protect their household, family, and honor if the need arose.
Traits valued in women of the samurai class were humility, obedience, self-control, strength, and loyalty. Ideally, a samurai wife would be skilled at managing property, keeping records, dealing with financial matters, educating the children (and perhaps servants, too), and caring for elderly parents or in-laws that may be living under her roof. Confucian law, which helped define personal relationships and the code of ethics of the warrior class required that a woman show subservience to her husband, filial piety to her parents, and care to the children. Too much love and affection was also said to indulge and spoil the youngsters. Thus, a woman was also to exercise discipline.
Though women of wealthier samurai families enjoyed perks of their elevated position in society, such as avoiding the physical labor that those of lower classes often engaged in, they were still viewed as far beneath men. Women were prohibited from engaging in any political affairs and were usually not the heads of their household.
This does not mean that samurai women were always powerless. Powerful women both wisely and unwisely wielded power at various occasions. After Ashikaga Yoshimasa, 8th shogun of the Muromachi shogunate lost interest in politics, his wife Hino Tomiko largely ruled in his place. Nene, wife of Toyotomi Hideyoshi, was known to overrule her husband's decisions at times and Yodo, his mistress, became the de facto master of Osaka castle and the Toyotomi clan after Hideyoshi's death. Tachibana Ginchiyo was chosen to lead the Tachibana clan after her father's death. Chiyo, wife of Yamauchi Kazutoyo, has long been considered the ideal samurai wife. According to legend, she made her kimono out of a quilted patchwork of bits of old cloth and saved pennies to buy her husband a magnificent horse, on which he rode to many victories. The fact that Chiyo (though she is better known as "Wife of Yamauchi Kazutoyo") is held to such high esteem for her economic sense is illuminating in the light of the fact that she never produced an heir and the Yamauchi clan was succeeded by Kazutoyo's younger brother. The source of power for women may have been that samurai left their finances to their wives.
As the Tokugawa period progressed more value became placed on education, and the education of females beginning at a young age became important to families and society as a whole. Marriage criteria began to weigh intelligence and education as desirable attributes in a wife, right along with physical attractiveness. Though many of the texts written for women during the Tokugawa period only pertained to how a woman could become a successful wife and household manager, there were those that undertook the challenge of learning to read, and also tackled philosophical and literary classics. Nearly all women of the samurai class were literate by the end of the Tokugawa period.
Western samurai.
The English sailor and adventurer William Adams (1564–1620) seems to have been the first Westerner to receive the dignity of samurai. The Shogun Tokugawa Ieyasu presented him with two swords representing the authority of a samurai, and decreed that William Adams the sailor was dead and that Anjin Miura (三浦按針), a samurai, was born. Adams also received the title of "hatamoto" (bannerman), a high-prestige position as a direct retainer in the Shogun's court. He was provided with generous revenues: "For the services that I have done and do daily, being employed in the Emperor's service, the emperor has given me a living" (Letters). He was granted a fief in Hemi (逸見) within the boundaries of present-day Yokosuka City, "with eighty or ninety husbandmen, that be my slaves or servants" (Letters). His estate was valued at 250 koku. He finally wrote "God hath provided for me after my great misery," (Letters) by which he meant the disaster-ridden voyage that initially brought him to Japan.
Jan Joosten van Lodensteijn (1556?–1623?), a Dutch colleague of Adams' on their ill-fated voyage to Japan in the ship De Liefde, was also given similar privileges by Tokugawa Ieyasu. It appears Joosten became a samurai and was given a residence within Ieyasu's castle at Edo. Today, this area at the east exit of Tokyo Station is known as Yaesu (八重洲). Yaesu is a corruption of the Dutchman's Japanese name, Yayousu (耶楊子). Also in common with Adam's, Joostens was given a Red Seal Ship (朱印船) allowing him to trade between Japan and Indo-China. On a return journey from Batavia Joosten drowned after his ship ran aground.
During the Boshin War (1868–1869), French soldiers joined the forces of the Shogun against the Southern Daimyos favorable to the restoration of the Meiji emperor. It is recorded that the French Navy officer Eugène Collache fought in samurai attire with his Japanese brothers-in-arms.
In the same war, the Prussian Edward Schnell served the Aizu domain as a military instructor and procurer of weapons. He was granted the Japanese name Hiramatsu Buhei (平松武兵衛), which inverted the characters of the daimyo's name Matsudaira. Hiramatsu (Schnell) was given the right to wear swords, as well as a residence in the castle town of Wakamatsu, a Japanese wife, and retainers. In many contemporary references, he is portrayed wearing a Japanese kimono, overcoat, and swords, with Western riding trousers and boots.
Armour.
As far back as the seventh century Japanese warriors wore a form of "lamellar armor", this armor eventually evolved into the armor worn by the samurai. The first types of Japanese armors identified as samurai armor were known as "yoroi". These early samurai armors were made from small individual scales known as "kozane". The kozane were made from either iron or leather and were bound together into small strips, the strips were coated with lacquer to protect the kozane from water. A series of strips of kozane were then laced together with silk or leather lace and formed into a complete chest armor ("dou or dō").
In the 1500s a new type of armor started to become popular due to the advent of firearms, new fighting tactics and the need for additional protection. The "kozane dou" made from individual scales was replaced by "plate armor". This new armor, which used iron plated "dou (dō)", was referred to as "Tosei-gusoku", or modern armor. Various other components of armor protected the samurai's body. The helmet "kabuto" was an important part of the samurai's armor. Samurai armor changed and developed as the methods of samurai warfare changed over the centuries. The known last use of samurai armor occurring in 1877 during the satsuma rebellion. As the last samurai rebellion was crushed, Japan modernized its defenses and turned to a national conscription army that used uniforms.
Etymology.
The term "samurai" originally meant "those who serve in close attendance to nobility", and was written with a Chinese character (or "kanji") that had the same meaning. In Japanese, it was originally recorded in the Nara Period as a verb *"samorapu" ("to watch, to keep watch, to observe, to be on the lookout for something; to serve, to attend"), which is believed to be derived from the frequentative form (*"morapu" 守らふ) of the verb "moru" (守る, "to watch, to guard, to be on the lookout; to keep, to protect, to take care of, to be in charge of, to have as one's ward"). By the Heian period, this word had developed into the verb "saburahu" (さぶらふ, "to serve, to attend"), from which a deverbal noun "saburahi" (さぶらひ, "servant, attendant") was later derived, and this noun then yielded "samurahi" (さむらひ) in the Edo period. In Japanese literature, there is an early reference to samurai in the Kokinshū (古今集, early 10th century):
Attendant to your nobility<br>
Ask for your master's umbrella<br>
The dews 'neath the trees of Miyagino<br>
Are thicker than rain
The word "bushi" (武士, lit. "warrior or armsman") first appears in an early history of Japan called "Shoku Nihongi" (続日本記, AD 797). In a portion of the book covering the year AD 721, "Shoku Nihongi" states: "Literary men and Warriors are they whom the nation values". The term "bushi" is of Chinese origin and adds to the indigenous Japanese words for "warrior": "tsuwamono" and "mononofu".
"Bushi" was the name given to the ancient Japanese soldiers from traditional warrior families. The "bushi" class was developed mainly in the north of Japan. They formed powerful clans, which in the 12th century were against the noble families who were grouping themselves to support the imperial family who lived in Kyoto. Samurai was a word used by the Kuge aristocratic class with warriors themselves preferring the word "bushi". The term "Bushidō", the "way of the warrior", is derived from this term and the mansion of a warrior was called "bukeyashiki".
The terms "bushi" and "samurai" became synonymous near the end of the 12th century, according to William Scott Wilson in his book "Ideals of the Samurai—Writings of Japanese Warriors". Wilson's book explores the origins of the word "warrior" in Japanese history as well as the "kanji" used to represent the word.
"Breaking down the character bu (武) reveals the radical (止), meaning "to stop", and an abbreviation of the radical (戈 ) "spear". The Shuo Wen, an early Chinese dictionary, gives this definition: "Bu consists of subduing the weapon and therefore stopping the spear." The Tso Chuan, another early Chinese source, goes further:
Bu consists of bun (文), literature or letters (and generally the arts of peace), stopping the spear. Bu prohibits violence and subdues weapons ... it puts the people at peace, and harmonizes the masses.
The radical shi (士) on the other hand seems to have originally meant a person who performs some function or who has the ability in some field. Early in Chinese history it came to define the upper class of society, and in the Book of Han this definition is given:
The shi, the farmer, the craftsman, and the tradesman are the four professions of the people. He who occupies his rank by means of learning is called a shi.
Wilson states that the shi, as the highest of the four classes, brandished the weapons as well as the books. "bushi" therefore translates as "a man who has the ability to keep the peace, either by literary or military means, but predominantly by the latter".
It was not until the early modern period, namely the Azuchi-Momoyama period and early Edo period of the late 16th and early 17th centuries that the word "saburai" was replaced with "samurai". However, the meaning had changed long before that.
During the era of the rule of the samurai, the term "yumitori" (弓取, "bowman") was also used as an honorary title of an accomplished warrior even though swordsmanship had become more important. (Japanese archery ("kyujutsu") is still strongly associated with the war god Hachiman.)
A samurai with no attachment to a clan or "daimyo" (大名) was called a "rōnin" (浪人). In Japanese, the word "rōnin" means "wave man", a person destined to wander aimlessly forever, like the waves in the sea. The word came to mean a samurai who was no longer in the service of a lord because his lord had died, because he had been banished, or simply because he chose to become a rōnin.
The pay of samurai was measured in "koku" of rice (180 liters; enough to feed a man for one year). Samurai in the service of the "han" are called "hanshi".
The following terms are related to samurai or the samurai tradition:
Myth and reality.
Most samurai were bound by a code of honor and were expected to set an example for those below them. A notable part of their code is seppuku (切腹, seppuku) or "hara kiri", which allowed a disgraced samurai to regain his honor by passing into death, where samurai were still beholden to social rules. Whilst there are many romanticized characterizations of samurai behavior such as the writing of Bushido (武士道, Bushidō) in 1905, studies of Kobudo and traditional Budō indicate that the samurai were as practical on the battlefield as were any other warrior.
Despite the rampant romanticism of the 20th century, samurai could be disloyal and treacherous (e.g., Akechi Mitsuhide), cowardly, brave, or overly loyal (e.g., Kusunoki Masashige). Samurai were usually loyal to their immediate superiors, who in turn allied themselves with higher lords. These loyalties to the higher lords often shifted; for example, the high lords allied under Toyotomi Hideyoshi (豊臣秀吉) were served by loyal samurai, but the feudal lords under them could shift their support to Tokugawa, taking their samurai with them. There were, however, also notable instances where samurai would be disloyal to their lord or daimyo, when loyalty to the emperor was seen to have supremacy.
Popular culture.
Jidaigeki (lit. historical drama) has always been a staple program on Japanese movies and TV. The programs typically feature a samurai. Samurai films and westerns share a number of similarities and the two have influenced each other over the years. One of Japan’s most renowned directors, Akira Kurosawa, greatly influenced the samurai aspect in western film-making. George Lucas’ Star Wars series incorporated many aspects from the Seven Samurai film. One example, is that in the Japanese film, seven samurai warriors are hired by local farmers to protect their land from being overrun by bandits; In George Lucas’ Star Wars: A New Hope, a similar situation arises. Kurosawa was inspired by the works of director John Ford and in turn Kurosawa's works have been remade into westerns such as "The Seven Samurai" into "The Magnificent Seven" and "Yojimbo" into "A Fistful of Dollars". There is also a 26 episode anime adaptation (Samurai 7) of "The Seven Samurai". Along with film, literature containing samurai influences are seen as well.
Most common are historical works where the protagonist is either a samurai or former samurai (or another rank/position) who possesses considerable martial skill. Eiji Yoshikawa is one of the most famous Japanese historical novelists. His retellings of popular works, including Taiko, Musashi and Heike Tale are popular among readers for their epic narratives and rich realism in depicting samurai and warrior culture. The samurai have also appeared frequently in Japanese comics (manga) and animation (anime). Samurai-like characters are not just restricted to historical settings and a number of works set in the modern age, and even the future, include characters who live, train and fight like samurai. Examples being Samurai Champloo, Requiem from the Darkness, , and Afro Samurai. Some of these works have made its way to the west, where it has been increasing in popularity with America.
Just in the last two decades, samurai have become more popular in America. “Hyperbolizing the samurai in such a way that they appear as a whole to be a loyal body of master warriors provides international interest in certain characters due to admirable traits” (Moscardi, N.D.). Through various medium, producers and writers have been capitalizing on the notion that Americans admire the samurai lifestyle. The animated series, Afro Samurai, became well-liked in American popular culture due to its blend of hack-and-slash animation and gritty urban music.
Created by Takashi Okazaki, Afro Samurai was initially a doujinshi, or manga series, which was then made into an animated series by Studio Gonzo. In 2007 the animated series debuted on American cable television on the Spike TV channel (Denison, 2010). The series was produced for American viewers which “embodies the trend... comparing hip-hop artists to samurai warriors, an image some rappers claim for themselves (Solomon, 2009). The storyline keeps in tone with the perception of a samurais finding vengeance against someone who has wronged him. Starring the voice of well known American actor Samuel L. Jackson, “Afro is the second-strongest fighter in a futuristic, yet, still feudal Japan and seeks revenge upon the gunman who killed his father” (King 2008). Due to its popularity, Afro Samurai was adopted into a full feature animated film and also became titles on gaming consoles such as the Playstation 3 and Xbox. Not only has the samurai culture been adopted into animation and video games, it can also be seen in comic books.
American comic books have adopted the character type for stories of their own like the mutant-villain Silver Samurai of Marvel Comics. The design of this character preserves the samurai appearance; the villain is “Clad in traditional gleaming samurai armor and wielding an energy charged katana” (Buxton, 2013). Not only does the Silver Samurai make over 350 comic book appearances, the character is playable in several video games, such as Marvel Vs. Capcom 1 and 2. In 2013, the samurai villain has been depicted in James Mangold’s film, The Wolverine. Ten years before the Wolverine debuted, another film help paved the way to ensure the samurai were made known to American cinema.
A film released in 2003 titled The Last Samurai, starring Tom Cruise, is inspired by the Samurai way of life. In the film, Tom Cruise’s character finds himself deeply immersed in samurai culture. The character in the film, “Nathan Algren, is a fictional contrivance to make nineteenth-century Japanese history less foreign to American viewers” (Ravina, 2010). After being captured by a group of samurai rebels, he becomes empathetic towards the cause they fight for. Taking place during the Meiji Period, Tom Cruise plays the role of US Army Captain Nathan Algren, who travels to Japan to train a rookie army in fighting off samurai rebel groups. Becoming a product of his environment, Algren joins the samurai clan in an attempt to rescue a captured samurai leader. “By the end of the film, he has clearly taken on many of the samurai traits, such as zen-like mastery of the sword, and a budding understanding of spirituality” (Manion, 2006)
The television series Power Rangers Samurai (adapted from Samurai Sentai Shinkenger) is also inspired by the way of the Samurai.
Bibliography.
</dl>

</doc>
<doc id="28290" url="http://en.wikipedia.org/wiki?curid=28290" title="Slackware">
Slackware

Slackware is a Linux distribution created by Patrick Volkerding in 1993. Originally based on Softlanding Linux System, Slackware has been the basis for many other Linux distributions, most notably the first versions of SUSE Linux, and is the oldest currently being maintained.
Slackware aims for design stability and simplicity and to be the most "Unix-like" Linux distribution. It makes as few modifications as possible to software packages from upstream and tries not to anticipate use cases or preclude user decisions. In contrast to most modern Linux distributions, Slackware provides no graphical installation procedure and no automatic dependency resolution of software packages. It uses plain text files and only a small set of shell scripts for configuration and administration. Without further modification it boots into a command-line interface environment. Because of its many conservative and simplistic features, Slackware is considered to be most suitable for advanced and technically inclined Linux users.
Slackware is available for the IA-32 and x86-64 architectures, with a port to the ARM architecture. While Slackware is mostly free and open source software, it does not have a formal bug tracking facility or public code repository, with releases periodically announced by Volkerding. There is no formal membership procedure for developers and Volkerding is the primary contributor to releases.
Name.
The name "Slackware" stems from the fact that the distribution started as a private side project with no intended commitment. To prevent it from being taken too seriously at first, Volkerding gave it a humorous name, which stuck even after Slackware became a serious project.
Slackware refers to the "pursuit of Slack", a tenet of the Church of the Subgenius. Certain aspects of Slackware logos reflect this — the pipe which Tux is smoking, as influenced by the image of J. R. "Bob" Dobbs' head.
A humorous reference to the Church of the Subgenius can be found in many versions of the "install.end" text files, which indicate the end of a software series to the setup program. In recent versions, including Slackware release 14.1, the text is ROT13 obfuscated.
History.
1993–2003.
Slackware was originally derived from the Softlanding Linux System (SLS), the most popular of the original Linux distributions and the first to offer a comprehensive software collection that comprised more than just the kernel and basic utilities, including X11 graphical interface, TCP/IP and UUCP networking and GNU Emacs.
Being a student at that time, Patrick Volkerding was asked by his artificial intelligence professor at the Minnesota State University Moorhead (MSUM) to make SLS installations for the computer lab. First Volkerding made notes on bug fixes and modifications of the system's configuration, to be applied after the installation was complete. Later he incorporated the changes directly into the SLS install disks "so that new machines would have these fixes right away". He changed parts of the original SLS installation scripts and added a mechanism that installed important packages like the shared libraries and the kernel image automatically.
Volkerding had no intentions to provide his modified SLS version for the public, assuming that "SLS would be putting out a new version that included these things soon enough". However, seeing that this was not the case and that many SLS users were asking on the Internet for a new SLS release, he made a post titled "Anyone want an SLS-like 0.99pl11A system?", to which he received a lot of responses. Volkerding's friends at MSUM also urged him to put his SLS modifications onto an FTP server, resulting in them becoming publicly available on one of the university's anonymous FTP servers. This first Slackware release, version 1.00, was distributed on 17 July 1993 at 00:16:36 (UTC), and was supplied as 24 3½" floppy disk images.
Version 2.1, released in October 1994, already consisted of 73 floppy disks, showing the rapid growth of the distribution.
With version 3.0, released in November 1995, Slackware made the transition to the Executable and Linkable Format (ELF). It was also the first release offering a CD-ROM based installation.
Slackware 3.1, released in July 1996, shipped with Linux kernel 2.0.0 and was called "Slackware 96" in allusion to Windows 95.
In 1999, Slackware's release number jumped from 4 to 7. Patrick Volkerding explained this as a marketing effort to show that Slackware was as up-to-date as other Linux distributions, many of which had release numbers of 6 at the time, and Volkerding expected them to reach version 7 by the time of the jump.
The 8.0 version, released on 28 June 2001, was the first Slackware release with support for the Mozilla browser. It was based on the 2.2.19 version of the Linux kernel. The 2.4.5 Linux kernel, which provided support for the ReiserFS file system, was shipped as an alternative installation option.
Slackware 9.1 was released on 25 September 2003. Major changes included the switch to the Advanced Linux Sound Architecture (ALSA) as the default sound system, and the inclusion of Sun's Java 2 Development Kit.
2004–present.
With version 10.0, released in June 2004, Slackware saw a major change in its implementation of the X Window System, making the transition from XFree86 to the X.org Server. Volkerding explained his motives in the version's change log: "Seems the community has spoken, because the opinions were more than 4 to 1 in favor of using the X.Org release as the default version of X. It's primarily (as is usual around here) a technical decision."
In 2005, the GNOME desktop environment was removed from the pending future release (starting with version 10.2), and turned over to community support and distribution. The removal of GNOME was seen by some in the Linux community as significant because this desktop environment is found in many Linux distributions. In lieu of this, several community-based projects began offering complete GNOME distributions for Slackware such as Ximian and LinuxSalute.
Slackware 12.0, released in July 2007, was the first release shipped with Linux 2.6 by default. This version also had support for the Hardware Abstraction Layer (HAL), for the first time.
In May 2009 the development team announced the public (testing) release of an x86 64 variant called Slackware64. As of Slackware 13.0 (released in August 2009), a stable 64-bit version has been available and officially supported.
Version 13.1, released in May 2010, introduced PolicyKit and ConsoleKit in the desktop framework. Furthermore, Slackware made a switchover from the IDE to the libata subsystem, changing the nomenclature of device nodes for almost all types of disk drives.
Version 13.37 was released in April 2011. Among the new features are support for the GUID Partition Table hard disc partitioning scheme which could replace the MBR system, as well as utilities for the Btrfs filesystem.
Version 14.0 was released in September 2012, shipped with a 3.x kernel for the first time and added support for NetworkManager. HAL was dropped again as its functionality was merged into udev.
Version 14.1 was released in November 2013 and shipped with Linux 3.10.17, a longterm support kernel. This release also adds support for booting on computers which use UEFI firmware.
Design philosophy.
The design philosophy of Slackware is oriented toward simplicity, software purity, and a core design that emphasizes lack of change to upstream sources. Many design choices in Slackware can be seen as a heritage of the simplicity of traditional Unix systems and as examples of the KISS principle. In this context, "simple" refers to the simplicity in system design, rather than system usage. Thus, ease of use may vary between users: those lacking knowledge of command line interfaces and classic Unix tools may experience a steep learning curve using Slackware, whereas users with a Unix background may benefit from a less abstract system environment. In keeping with Slackware's design philosophy, and its spirit of purity, most software in Slackware uses the original configuration mechanisms supplied by the software's authors; however, for some administrative tasks, distribution-specific configuration tools are delivered.
Development model.
There is no formal issue tracking system and no official procedure to become a code contributor or developer. The project does not maintain a public code repository. Bug reports and contributions, while being essential to the project, are managed in an informal way. All the final decisions about what is going to be included in a Slackware release strictly remain with Slackware's benevolent dictator for life, Patrick Volkerding.
The first versions of Slackware were developed by Patrick Volkerding alone. Beginning with version 4.0, the official Slackware announce files list David Cantrell and Logan Johnson as part of the "Slackware team". Later announce statements, up to release version 8.1, include Chris Lumens. Lumens, Johnson and Cantrell are also the authors of the first edition of "Slackware Linux Essentials", the official guide to Slackware Linux. The Slackware website mentions Chris Lumens and David Cantrell as being "Slackware Alumni", who "worked full-time on the Slackware project for several years." In his release notes for Slackware 10.0 and 10.1 Volkerding thanks Eric Hameleers for "his work on supporting USB, PCI, and Cardbus wireless cards". Starting with version 12.0 there is, for a second time, a team building around Volkerding. According to the release notes of 12.2, the development team consists of seven people. Future versions added people. Since version 13.0, the Slackware team seems to have core members. Eric Hameleers gives an insight into the core team with his essay on the "History of Slackware Development", written on 3–4 October 2009 (shortly after the release of version 13.0).
Packages.
Management.
Slackware's package management system can install, upgrade, and remove packages from local sources and over a network.
As of Slackware 12.2, slackpkg has been added as the official network-capable package manager, complementing the traditional package tools suite that only operates locally.
Slackware packages are tarballs. Prior to version 13.0, the compression method was DEFLATE (gzip) with filenames ending in .tgz. Beginning with version 13.0, the compression method for packages is based on the LZMA algorithm, indicated by the .txz extension. Since the change in compression methods, the package filename extensions comprise .tgz.txz.tbz and .tlz.
The package contains the files that form part of the software being installed, as well as additional metadata files for the benefit of the Slackware package manager. The package tarball contains a directory structure such that the files which make up the software being installed are organized in a hierarchical way that mirrors their respective locations in the root directory of the destination system.
The metadata files are placed under the install/ directory of the package. Two files are commonly found there: slack-desc and doinst.sh. The slack-desc file is a simple text file which contains a description of the package being installed. It is used when viewing packages with the package manager. The doinst.sh file is a shell script which is run at the end of the installation of a package and usually executes commands or makes changes which could not be best made by changing the contents of the package.
Dependency resolution.
The package management system does not track or manage "dependencies", instead it relies on the user to ensure that the system has all the supporting system libraries and programs required by the new package. If any of these are missing, there may be no indication until the newly installed software is used.
While Slackware itself does not incorporate tools to resolve dependencies for the user by automatically downloading and installing them, some community supported software tools do provide this function, similar to the way APT does for Debian and its derivatives.
Alternative packaging tools include:
Repositories.
Third-party projects may include more recent versions of software or software not provided by Slackware Linux.
pkgs.org is a Linux package search engine which also provides links to official and well-known third-party Slackware Linux repositories.
SlackBuilds.org is a community-supported project offering so called SlackBuilds to build extra software not included with Slackware. A SlackBuild mainly provides a shell script that builds a particular package on the user's system. This build process is nearly identical to the way Slackware's official packages are built. SlackBuilds have several advantages over pre-built packages: Since they build from the original author's source code, the user does not have to trust a third-party packager; furthermore the local compilation process allows for machine-specific optimization. In comparison to manual compilation and installation, SlackBuilds assure better integration into the user's system, inasmuch as they utilize Slackware's package system.
Since GNOME was dropped from Slackware Linux, several community projects now provide GNOME binary packages and SlackBuilds for Slackware Linux. These include Dropline GNOME, , GWARE, Gnome-Slacky (Italian), and SlackBot.
Since Slackware has migrated in recent releases from KDE 3.5 to KDE Plasma Workspaces 4, there is an alternative for Slackware users who prefer using KDE 3.5 (Trinity desktop).
Releases.
Slackware's release policy can be said to follow a feature and stability based release cycle, in contrast to the time-bound ("e.g.", Ubuntu) or rolling release ("e.g.", Gentoo Linux) schemes of other Linux distributions.
As stated by Patrick Volkerding, "it's usually our policy not to speculate on release dates, since that's what it is — pure speculation. It's not always possible to know how long it will take to make the upgrades needed and tie up all the related loose ends. As things are built for the upcoming release, they'll be uploaded into the -current tree."
Despite this conservative development paradigm the Slackware team aims to deliver up-to-date software, on at least an annual basis. Thus, new versions are released continuously and within a reasonably foreseeable time frame. From inception through 2013, Slackware had at least one release per year. Release activity peaked in 1994, 1995, 1997 and 1999, when there were three releases per year. Starting with version 7.1 (22 June 2000) the release progression became more stable. There were two releases per year in only 2003, 2005 and 2008.
Slackware's latest stable i386 and x86_64 releases are at version 14.1 (as of 7 November 2013), which include support for Linux 3.10.17.
There is also a testing/developmental version of Slackware called "-current" that can be used for a more bleeding edge configuration.
Support.
Until recently, Slackware had no officially stated support term policy. The oldest release supported with security patches was version 8.1 (release date: June 18, 2002).
On June 14, 2012, a notice appeared in the change logs of Slackware versions 8.1, 9.0, 9.1, 10.0, 10.1, 10.2, 11.0, and 12.0, stating that, effective August 1, 2012, security patches will no longer be provided for these versions (which were all more than 5 years old by that time).
12.1 and 12.2 were EOL on December 9, 2013 after no less than five years of support.
Hardware architectures.
Slackware has traditionally concentrated solely on the IA-32 architecture and previous releases were available as 32-bit only. Users wanting 64-bit were required to use unofficial ports such as slamd64. As of Slackware 13.0, a 64-bit x86-64 variant is available and officially supported in symmetrical development with the 32-bit platform.
Slackware is also available for the ARM architecture in the form of Slackware ARM (originally known as 'ARMedslack') and for IBM S/390. Both ports have been declared "official" by Patrick Volkerding, but the S/390 port is still at version 10.0 for the stable version and 11.0 for the testing/developmental version, and has had no updates since 2009.
Distribution.
Slackware 14.1 can be ordered from the official Slackware store as a 6-CD set or as a single DVD. The CD set is targeted at the IA-32 platform but also runs on x86_64 processors in 32-bit mode. The DVD contains both the IA-32 distribution and a 64-bit x86_64 version.
Slackware ISO images for the CD set and the DVD can also be downloaded via BitTorrent or from various FTP and HTTP mirrors.
The distributions of the ports for the ARM architecture and for IBM S/390 are neither available as CD/DVDs nor as ISO images, but can be downloaded. Slackware S/390 installs from a DOS Partition or from floppy disk. Slackware ARM does not distribute ISO files because most ARM devices can not boot from a CD or DVD. Instead, it is installed off a network, using Das U-Boot and a TFTP boot server or from a mini-root filesystem. Slackware ARM can also be installed on a PC running QEMU using the same technique.
Use.
DistroWatch shows a decreasing but still substantial visitor's interest regarding Slackware: In 2002 the Slackware page was ranked as number 7, but dropped to number 10 by 2005. In 2006 it reached number 9, whereas since then being constantly below the ten most popular pages. In 2010 it had been listed as number 11, in the years 2011 and 2012 as number 12. Slackware had its lowest rank (30) in 2014.

</doc>
<doc id="28291" url="http://en.wikipedia.org/wiki?curid=28291" title="Sequencer">
Sequencer

Sequencer may refer to:

</doc>
<doc id="28292" url="http://en.wikipedia.org/wiki?curid=28292" title="Stalingrad (disambiguation)">
Stalingrad (disambiguation)

Stalingrad is the former name of Volgograd, a city in Russia.
Stalingrad may also refer to:

</doc>
<doc id="28296" url="http://en.wikipedia.org/wiki?curid=28296" title="Short story">
Short story

A short story is a brief work of literature, usually written in narrative prose. Emerging from earlier oral storytelling traditions in the 17th century, the short story has grown to encompass a body of work so diverse as to defy easy characterization. At its most prototypical the short story features a small cast of named characters, and focuses on a self-contained incident with the intent of evoking a "single effect" or mood. In doing so, short stories make use of plot, resonance, and other dynamic components to a far greater degree than is typical of an anecdote, yet to a far lesser degree than a novel. While the short story is largely distinct from the novel, authors of both generally draw from a common pool of literary techniques.
Short stories have no set length. In terms of word count there is no official demarcation between an anecdote, a short story, and a novel. Rather, the form's parameters are given by the rhetorical and practical context in which a given story is produced and considered, so that what constitutes a short story may differ between genres, countries, eras, and commentators. Like the novel, the short story's predominant shape reflects the demands of the available markets for publication, and the evolution of the form seems closely tied to the evolution of the publishing industry and the submission guidelines of its constituent houses.
The short story has been considered both an apprenticeship form preceding more lengthy works, and a crafted form in its own right, collected together in books of similar length, price, and distribution as novels. Short story writers may define their works as part of the artistic and personal expression of the form. They may also attempt to resist categorization by genre and fixed form.
Length.
"See the article novella for related debate about length."
Determining what exactly separates a short story from longer fictional formats is problematic. A classic definition of a short story is that one should be able to read it in one sitting, a point most notably made in Edgar Allan Poe's essay "Thomas Le Moineau (Le Moile)" (1846). Interpreting this standard nowadays is problematic, since the expected length of "one sitting" may now be briefer than it was in Poe's era. Other definitions place the maximum word count of the short story at anywhere from 1,000 to 4,000. In contemporary usage, the term short story most often refers to a work of fiction no shorter than 1,000 and no longer than 20,000 words. Stories of fewer than 1,000 words are sometimes referred to as "short short stories", or "flash fiction."
As a point of reference for the genre writer, the Science Fiction and Fantasy Writers of America define short story length in the Nebula Awards for science fiction submission guidelines as having a word count of fewer than 7,500.
Longer stories that cannot be called novels are sometimes considered "novellas" or novelettes and, like short stories, may be collected into the more marketable form of "collections", often containing previously unpublished stories. Sometimes, authors who do not have the time or money to write a novella or novel decide to write short stories instead, working out a deal with a popular website or magazine to publish them for profit.
Characteristics.
As a concentrated form of narrative prose fiction, the short story has been theorised through the traditional elements of dramatic structure: exposition (the introduction of setting, situation and main characters), complication (the event that introduces the conflict), rising action, crisis (the decisive moment for the protagonist and his commitment to a course of action), climax (the point of highest interest in terms of the conflict and the point with the most action) and resolution (the point when the conflict is resolved). Because of their length, short stories may or may not follow this pattern. For example, modern short stories only occasionally have an exposition, more typically beginning in the middle of the action ("in medias res"). As with longer stories, plots of short stories also have a climax, crisis, or turning point. However, the endings of many short stories are abrupt and open and may or may not have a moral or practical lesson. As with any art form, the exact characteristics of a short story will vary by creator.
Short stories tend to be less complex than novels. Usually a short story focuses on one incident; has a single plot, a single setting, and a small number of characters; and covers a short period of time. The modern short story form emerged from oral story-telling traditions, the brief moralistic narratives of parables and fables, and the prose anecdote, all of these being forms of a swiftly sketched situation that quickly comes to its point.
With the rise of the realistic novel, the short story evolved in a parallel tradition, with some of its first distinctive examples in the tales of E. T. A. Hoffmann. The character of the form developed particularly with authors known for their short fiction, either by choice (they wrote nothing else) or by critical regard, which acknowledged the focus and craft required in the short form. An example is Jorge Luis Borges, who won American fame with "The Garden of Forking Paths", published in the August 1948 "Ellery Queen's Mystery Magazine". Another example is O. Henry (author of "Gift of the Magi"), for whom the O. Henry Award is named. American examples include Flannery O'Connor, John Cheever, and Raymond Carver.
History.
Predecessors.
Short stories date back to oral storytelling traditions which originally produced epics such as Homer's "Iliad" and "Odyssey". Oral narratives were often told in the form of rhyming or rhythmic verse, often including recurring sections or, in the case of Homer, "Homeric epithets". Such stylistic devices often acted as mnemonics for easier recall, rendition and adaptation of the story. Short sections of verse might focus on individual narratives that could be told at one sitting. The overall arc of the tale would emerge only through the telling of multiple such sections.
Fables, succinct tales with an explicit "moral," were said by the Greek historian Herodotus to have been invented in the 6th century BCE by a Greek slave named Aesop, though other times and nationalities have also been given for him. These ancient fables are today known as "Aesop's Fables".
The other ancient form of short story, the anecdote, was popular under the Roman Empire. Anecdotes functioned as a sort of parable, a brief realistic narrative that embodies a point. Many surviving Roman anecdotes were collected in the 13th or 14th century as the "Gesta Romanorum". Anecdotes remained popular in Europe well into the 18th century, when the fictional anecdotal letters of Sir Roger de Coverley were published.
In Europe, the oral story-telling tradition began to develop into written stories in the early 14th century, most notably with Geoffrey Chaucer's "Canterbury Tales" and Giovanni Boccaccio's "Decameron". Both of these books are composed of individual short stories (which range from farce or humorous anecdotes to well-crafted literary fictions) set within a larger narrative story (a frame story), although the frame-tale device was not adopted by all writers. At the end of the 16th century, some of the most popular short stories in Europe were the darkly tragic "novella" of Matteo Bandello (especially in their French translation).
The mid 17th century in France saw the development of a refined short novel, the "nouvelle", by such authors as Madame de Lafayette. In the 1690s, traditional fairy tales began to be published (one of the most famous collections was by Charles Perrault). The appearance of Antoine Galland's first modern translation of the "Thousand and One Nights" (or "Arabian Nights") (from 1704; another translation appeared in 1710–12) would have an enormous influence on the 18th-century European short stories of Voltaire, Diderot and others.
1790–1850.
There are early examples of short stories published separately between 1790 and 1810, but the first true collections of short stories appeared between 1810 and 1830 in several countries around the same period.
The first short stories in the United Kingdom were gothic tales like Richard Cumberland's "remarkable narrative" "The Poisoner of Montremos" (1791). Great novelists like Sir Walter Scott and Charles Dickens also wrote some short stories.
One of the earliest short stories in the United States was Charles Brockden Brown's "Somnambulism" from 1805. Washington Irving wrote mysterious tales including "Rip van Winkle" (1819) and "The Legend of Sleepy Hollow" (1820). Nathaniel Hawthorne published the first part of his "Twice-Told Tales" in 1837. Edgar Allan Poe wrote his tales of mystery
and imagination between 1832 and 1849. Classic stories are "The Fall of the House of Usher", "The Tell-Tale Heart", "The Cask of Amontillado", "The Pit and the Pendulum", and the first detective story, "The Murders in the Rue Morgue". In "The Philosophy of Composition" (1846) Poe argued that a literary work should be short enough for a reader to finish in one sitting.
In Germany, the first collection of short stories was by Heinrich von Kleist in 1810 and 1811. The Brothers Grimm published their first volume of collected fairy tales in 1812. E. T. A. Hoffmann followed with his own original fantasy tales, of which "The Nutcracker and the Mouse King" (1816) is the most famous.
In France, Prosper Mérimée wrote "Mateo Falcone" in 1829.
1850–1900.
In the latter 19th century, the growth of print magazines and journals created a strong demand for short fiction of between 3,000 and 15,000 words.
In the United Kingdom, Thomas Hardy wrote dozens of short stories, including "The Three Strangers" (1883), "A Mere Interlude" (1885) and "Barbara of the House of Grebe" (1890). Rudyard Kipling published short story collections for grown-ups, e.g. "Plain Tales from the Hills" (1888), as well as for children, e.g. "The Jungle Book" (1894). In 1892 Arthur Conan Doyle brought the detective story to a new height with "The Adventures of Sherlock Holmes". H. G. Wells wrote his first science fiction stories in the 1880s. One of his best known is "The Country of the Blind" (1904).
In the United States, Herman Melville published his story collection "The Piazza Tales" in 1856. "The Celebrated Jumping Frog of Calaveras County" was the title story of Mark Twain's first book one year later. In 1884, Brander Matthews, the first American professor of dramatic literature, published "The Philosophy of the Short-Story". At that same year, Matthews was the first one to name the emerging genre "short story". Another theorist of narrative fiction was Henry James. James wrote a lot of short stories himself, including "The Real Thing" (1892), "Maud-Evelyn" and "The Beast in the Jungle" (1903). In the 1890s Kate Chopin published short stories in several magazines.
The most prolific French author of short stories was Guy de Maupassant. Stories like "Boule de Suif" ("Ball of Fat", 1880) and "L'Inutile Beauté" ("The Useless Beauty", 1890) are good examples of French realism.
In Russia, Ivan Turgenev gained recognition with his story collection "A Sportsman's Sketches". Nikolai Leskov created his first short stories in the 1860s. Late in his life Fyodor Dostoyevski wrote "The Meek One" (1876) and "The Dream of a Ridiculous Man" (1877), two stories with great psychological and philosophical depth. Leo Tolstoy handled ethical questions in his short stories, for example in "Ivan the Fool" (1885), "How Much Land Does a Man Need?" (1886) and "Alyosha the Pot" (1905). The greatest specialist of the Russian short story however was Anton Chekhov. Classic examples of his realistic prose are "The Bet" (1889), "Ward No. 6" (1892), and "The Lady with the Dog" (1899). Maxim Gorky's best known short story is "Twenty-six Men and a Girl" (1899).
The prolific Indian author of short stories Munshi Premchand, pioneered the genre in the Hindustani language, writing a substantial body of short stories and novels in a style characterized by realism and an unsentimental and authentic introspection into the complexities of Indian society. Premchand's work, including his over 200 short stories (such as the story "Lottery") and his novel Godaan remain substantial works.
A master of the short story, the Urdu language writer Saadat Hasan Manto, is revered for his exceptional depth, irony and sardonic humour. The author of some 250 short stories, radio plays, essays, reminiscences and a novel, Manto is widely admired for his analyses of violence, bigotry, prejudice and the relationships between reason and unreason. Combining realism with surrealism and irony, Manto's works such as the celebrated short story Toba Tek Singh are aesthetic masterpieces which continue to give profound insight into the nature of human loss, violence and devastation.
In India, Rabindranath Tagore published short stories, on the lives of the poor and oppressed such as peasants, Women and villagers under colonial misrule and exploitation.
In Poland, Bolesław Prus was the most important author of short stories. In 1888 he wrote "A Legend of Old Egypt".
Machado de Assis, one of the majors novelist from Brazil was the most important short story writer from his country at the time, under influences (among others) of Xavier de Maistre, Lawrence Sterne, Guy de Maupassant. In the end of the 19 th century the writer João do Rio became popular by short stories about the bohemianism. Writing about the former slaves, and very ironical about nationalism, Lima Barreto died almost forgotten, but became very popular in the 20th century.
In Portuguese literature, the major names of the time are Almeida Garrett and the historian and novelist Alexandre Herculano. Still influential, Eça de Queiroz produced some short stories with a style influenced by Émile Zola, Balzac and Dickens.
1900–1945.
In the United Kingdom, periodicals like "The Strand Magazine" and "Story-Teller" contributed to the popularity of the short story. Hector Hugh Munro (1870–1916), also known by his pen name of Saki, wrote satirical short stories about Edwardian England. W. Somerset Maugham, who wrote over a hundred short stories, was one of the most popular authors of his time. P. G. Wodehouse published his first collection of comical stories about valet Jeeves in 1917. Many detective stories were written by G. K. Chesterton, Agatha Christie and Dorothy L. Sayers. Short stories by Virginia Woolf are "Kew Gardens" (1919) and "Solid Objects," about a politician with mental problems. Graham Greene wrote his Twenty-One Stories between 1929 and 1954. A specialist of the short story was V. S. Pritchett, whose first collection appeared in 1932. Arthur C. Clarke published his first science fiction story, "Travel by Wire!" in 1937.
In Ireland, James Joyce published his short story collection "Dubliners" in 1914. These stories, written in a more accessible style than his later novels, are based on careful observation of the inhabitants of his birth city.
In the first half of the 20th century, a number of high-profile American magazines such as "The Atlantic Monthly", "Harper's Magazine", "The New Yorker" "Scribner's", "The Saturday Evening Post", "Esquire", and "The Bookman" published short stories in each issue. The demand for quality short stories was so great and the money paid for such so well that F. Scott Fitzgerald repeatedly turned to short-story (as Matthews preferred to write it) writing to pay his numerous debts. His first collection "Flappers and Philosophers" appeared in book form in 1920. William Faulkner wrote over one hundred short stories. "Go Down, Moses", a collection of seven stories, appeared in 1941. Ernest Hemingway's concise writing style was perfectly fit for shorter fiction. Stories like "A Clean, Well-Lighted Place" (1926), "Hills Like White Elephants" (1927) and "The Snows of Kilimanjaro" (1936) are only a few pages long, but carefully crafted. Dorothy Parker's bittersweet story "Big Blonde" debuted in 1929. A popular science fiction story is "Nightfall" by Isaac Asimov.
Katherine Mansfield from New Zealand wrote many of short stories between 1912 and her death in 1923. "The Doll's House" (1922) treats the topic of social inequity.
Two important authors of short stories in the German language were Thomas Mann and Franz Kafka. In 1922 the latter wrote "A Hunger Artist", about a man who fasts for several days.
Ryūnosuke Akutagawa (1892-1927) is called the Father of the Japanese short story.
In Brazil, the most famous modern short story writer is Mário de Andrade. At the time, Paulistan writer António de Alcantâra Machado became very popular from his collection of short stories titled, "Brás, Bexiga e Barra Funda" (1928), about several Italian neighborhoods, but now he is mostly read in just São Paulo. Also, novelist Graciliano Ramos and poet Carlos Drummond de Andrade have significant short story works.
Portuguese writers like Mário de Sá-Carneiro, Florbela Espanca and Fernando Pessoa wrote well-known short stories, although their major genre was poetry.
After 1945.
The period following World War II saw a great flowering of literary short fiction in the United States. "The New Yorker" continued to publish the works of the form’s leading mid-century practitioners, including Shirley Jackson, whose story, "The Lottery", published in 1948, elicited the strongest response in the magazine’s history to that time. Other frequent contributors during the last 1940s included John Cheever, John Steinbeck, Jean Stafford, and Eudora Welty. J. D. Salinger's "Nine Stories" (1953) experimented with point of view and voice, while Flannery O'Connor's story "A Good Man is Hard to Find" (1955) reinvigorated the Southern Gothic style. Cultural and social identity played a considerable role in much of the short fiction of the 1960s. Philip Roth and Grace Paley cultivated distinctive Jewish-American voices. Tillie Olsen’s "I Stand Here Ironing" (1961) adopted a consciously feminist perspective. James Baldwin’s collection "Going to Meet the Man" (1965) told stories of African-American life. Frank O'Connor’s "The Lonely Voice", an exploration of the short story, appeared in 1963. Wallace Stegner's short stories are primarily set in the American West. Stephen King published many short stories in men's magazines in the 1960s and after. The 1970s saw the rise of the postmodern short story in the works of Donald Barthelme and John Barth. Traditionalists including John Updike and Joyce Carol Oates maintained significant influence on the form. Minimalism gained widespread influence in the 1980s, most notably in the work of Raymond Carver and Ann Beattie.
Canadian short story writers include Alice Munro, Mavis Gallant, and Lynn Coady.
In the United Kingdom, Daphne du Maurier wrote suspense stories like "The Birds" (1952) and "Don't Look Now" (1971). Roald Dahl was the master of the twist-in-the-tale. Short story collections like "Lamb to the Slaughter" (1953) and "Kiss Kiss" (1960) illustrate his dark humour.
In Italy, Italo Calvino published the short story collection "Marcovaldo", about a poor man in a city, in 1963.
In Brazil, the short story became popular among female writers like Clarice Lispector, Lygia Fagundes Telles, Adélia Prado, who wrote about their society from a feminine viewpoint, although the genre has great male writers like Dalton Trevisan, Autran Dourado Moacyr Scliar and Carlos Heitor Cony too. Also, writing about poverty and the favelas, João Antonio became a well known writer. Other post-modern short fiction authors include writers Hilda Hilst and Caio Fernando Abreu. Detective literature was led by Rubem Fonseca. It is also necessary to mention João Guimarães Rosa, wrote short stories in the book "Sagarana" using a complex, experimental language based on tales of oral traditional.
Portuguese writers like Virgílo Ferreira, Fernando Goncalves Namora and Sophia de Mello Breyner Andresen are among the most influential short story writers from 20th-century Portuguese language literature. Manuel da Silva Ramos is one of the most well-known names of postmodernism in the country. Nobel Prize-winner José Saramago published few short stories, but became popular from his novels.
The Angolan writer José Luandino Vieira is one of the most well-known writers from his country and has several short stories. José Eduardo Agualusa is also increasingly read in Portuguese-speaking countries.
Mozambican Mia Couto is a widely known writer of post modern prose, and he is read even in non-Portuguese speaking countries. Other Mozambican writers such as Suleiman Cassamo, Paulina Chiziane and Eduardo White are gaining popularity with Portuguese-speakers too.
The Argentine writer Jorge Luis Borges is one of the most famous writers of short stories in the Spanish language. "The Library of Babel" (1941) and "The Aleph" (1945) handle difficult subjects like infinity. Two of the most representative writers of the Magical realism genre are also widely known Argentinan short story writers: Adolfo Bioy Casares and Julio Cortázar.
The Uruguayan writer Juan Carlos Onetti is known as one of the most important magical realist writer from Latin America.
In Colombia, the Nobel prize laureate author Gabriel Garcia Marquez is the main novelist and short story writer, known by his magical realist stories and his defense of the Communist Party in his country.
The Peruvian writer Mario Vargas Llosa, also a Nobel prize winner, has significant short story works.
The Egyptian Nobel Prize-winner Naguib Mafouz is the most well-known author from his country, but has only a few short stories.
Japanese world-known short story writers include Kenzaburō Ōe (Nobel prize winner of 1994), Yukio Mishima and Haruki Murakami.
eShort.
" For those unfamiliar with eshorts, they are short stories ranging from 12-150 pages, usually linked to a series. They vary in price from free to $3.99 and are available in electronic format only. The stories told in eshorts are often told from a perspective other than the main character in a series or tell of a side event that is loosely linked to the overall story. They are a great way for readers to revisit their favorite stories and characters in a new light. Stories of this nature normally would require a collection before they could be printed but because of the emergence of ebooks and their pricing scheme, they are available almost as quickly as authors write them."
Recognition.
Alice Munro, "master of the contemporary short story" according to her citation for the 2013 Nobel Prize in Literature, said she hopes the award would bring readership for the short story in general.
Adaptations.
Short stories have frequently been adapted for:

</doc>
<doc id="28297" url="http://en.wikipedia.org/wiki?curid=28297" title="Soul">
Soul

The soul, in many religious, philosophical and mythological traditions, is the incorporeal and, in many conceptions, immortal essence of a living thing. According to most of the Abrahamic religions, immortal souls belong only to human beings. For example, the Catholic theologian Thomas Aquinas attributed "soul" ("anima") to all organisms but argued that only human souls are immortal. Other religions (most notably Jainism and Hinduism) teach that all biological organisms have souls, and others teach that even non-biological entities (such as rivers and mountains) possess souls. This latter belief is called animism.
Greek philosophers such as Socrates, Plato and Aristotle understood the "psyche" (ψυχή) to be crowned with the logical faculty, the exercise of which was the most divine of human actions. At his defense trial, Socrates even summarized his teachings as nothing other than an exhortation for his fellow Athenians to excel in matters of the psyche since all bodily goods are dependent on such excellence ("The Apology" 30a–b).
"Anima mundi" is the concept of a "world soul" connecting all living organisms on the planet.
Linguistic aspects.
Etymology.
The Modern English word "soul", derived from Old English "sáwol, sáwel", was first attested to in the 8th-century poem "Beowulf" v. 2820 and in the Vespasian Psalter 77.50—it is cognate with other Germanic and Baltic terms for the same idea, including Gothic "saiwala", Old High German "sêula, sêla", Old Saxon "sêola", Old Low Franconian "sêla, sîla", Old Norse "sála" and Lithuanian "siela". Further etymology of the Germanic word is uncertain. The original concept is said to mean originally 'coming from or belonging to the sea/lake' because of the Germanic belief in souls being born out of and returning to sacred lakes, c.f., Old Saxon "sêola" (soul) compared to Old Saxon "sêo" (sea).
The Koine Greek word ψυχή "psychē", "life, spirit, consciousness", is derived from a verb meaning "to cool, to blow", and hence refers to the breath, as opposed to σῶμα ("soma"), meaning "body". "Psychē" occurs juxtaposed to σῶμα, as seen in :
φοβεῖσθε δὲ μᾶλλον τὸν δυνάμενον καὶ ψυχὴν καὶ σῶμα ἀπολέσαι ἐν γεέννῃ.
In the Septuagint (LXX), ψυχή translates Hebrew נפש "nephesh", meaning "life, vital breath", and specifically refers to a mortal, physical life, but is in English variously translated as "soul, self, life, creature, person, appetite, mind, living being, desire, emotion, passion"; an example can be found in :
Paul of Tarsus used ψυχή and πνεῦμα specifically to distinguish between the Jewish notions of נפש "nephesh" and רוח "ruah" (spirit) (also in LXX, e.g. וְר֣וּחַאֱלֹהִ֔ים = πνεῦμα θεοῦ = "spiritus Dei" = "the Spirit of God").
Semantics.
Although the terms "soul" and "spirit" are sometimes used interchangeably, "soul" can denote a more worldly and less transcendent aspect of a person. According to James Hillman, a psychologist, the soul displays an affinity for negative thoughts and images, whereas the spirit seeks to rise above the entanglements of life and death. The words "soul" and "psyche" can also be used in a synonymous manner; although, "psyche" has more psychological connotations, whereas "soul" is more closely connected to spirituality and religion.
Philosophical views.
The Ancient Greeks used the word for "alive" to also apply to the concept of being "ensouled", indicating that the earliest surviving western philosophical view believed that the soul was that which gave the body life. The soul was considered the incorporeal or spiritual "breath" that animates (from the Latin, "anima", cf. "animal") the living organism.
Francis M. Cornford quotes Pindar by saying that the soul sleeps while the limbs are active, but when one is sleeping, the soul is active and reveals "an award of joy or sorrow drawing near"in dreams.
Erwin Rohde writes that an early pre-Pythagorean belief presented the soul as lifeless when it departed the body, and that it retired into Hades with no hope of returning to a body.
Socrates and Plato.
Drawing on the words of his teacher Socrates, Plato considered the psyche to be the essence of a person, being that which decides how we behave. He considered this essence to be an incorporeal, eternal occupant of our being. Socrates says that even after death, the soul exists and is able to think. He believed that as bodies die, the soul is continually reborn in subsequent bodies and Plato believed this as well; however, he thought that only one part of the soul was immortal ("logos"). The Platonic soul consists of three parts:
The parts are located in different regions of the body:
Plato also compares the three parts of the soul or psyche to a societal caste system. According to Plato's theory, the three-part soul is essentially the same thing as a state's class system because, to function well, each part must contribute so that the whole functions well. Logos keeps the other functions of the soul regulated.
Aristotle.
Aristotle (384 BC – 322 BC) defined the soul, or "Psūchê" (ψυχή), as the "first actuality" of a naturally organized body, and argued against its separate existence from the physical body. In Aristotle's view, the primary activity, or full actualization, of a living thing constitutes its soul. For example, the full actualization of an eye, as an independent organism, is seeing (its purpose or final cause). Another example is that the full actualization of a human being would be living a fully functional human life in accordance with reason (which he considered to be a faculty unique to humanity). For Aristotle, the soul is the organization of the form and matter of a natural being which allows it to strive for its full actualization. This organization between form and matter is necessary for any activity, or functionality, to be possible in a natural being. Using an artifact (non-natural being) as an example, a house is a building for human habituation, but for a house to be actualized requires the material (wood, nails, bricks, etc.) necessary for its actuality (i.e. being a fully functional house). However, this does not imply that a house has a soul. In regards to artifacts, the source of motion that is required for their full actualization is outside of themselves (for example, a builder builds a house). In natural beings, this source of motion is contained within the being itself. Aristotle elaborates on this point when he addresses the faculties of the soul.
The various faculties of the soul, such as nutrition (also known as vegetative (peculiar to plants)); movement (also known as passionate (peculiar to animals)); reason (peculiar to humans); sensation (special, common, and incidental); and so forth, when exercised, constitute the "second" actuality, or fulfillment, of the capacity to be alive. For example, someone who falls asleep, as opposed to someone who falls dead, can wake up and go about their life, while the latter can no longer do so.
Aristotle identified three hierarchical levels of natural beings: plants, animals, and people. For these groups, he identified three corresponding levels of soul, or biological activity: the nutritive activity of growth, sustenance and reproduction which all life shares; the self-willed motive activity and sensory faculties, which only animals and people have in common; and finally "reason", of which people alone are capable.
Aristotle's discussion of the soul is in his work, "De Anima" ("On the Soul"). Although mostly seen as opposing Plato in regard to the immortality of the soul, a controversy arose in relation to the fifth chapter of the third book. In this text, both interpretations can be argued for: soul as a whole is mortal, or a part called "active intellect" or "active mind" is immortal and eternal. Commentators exist on both sides of the controversy, but it is understood that there will be permanent disagreement about its final conclusions, as no other Aristotelian text contains this specific point, and this part of "De Anima" is obscure.
Avicenna and Ibn al-Nafis.
Following Aristotle, Avicenna (Ibn Sina) and Ibn al-Nafis, a Persian philosopher, further elaborated upon the Aristotelian understanding of the soul and developed their own theories on the soul. They both made a distinction between the soul and the spirit, and the Avicennian doctrine on the nature of the soul was influential among the Scholastics. Some of Avicenna's views on the soul include the idea that the immortality of the soul is a consequence of its nature, and not a purpose for it to fulfill. In his theory of "The Ten Intellects", he viewed the human soul as the tenth and final intellect.
While he was imprisoned, Avicenna wrote his famous "Floating Man" thought experiment to demonstrate human self-awareness and the substantial nature of the soul. He told his readers to imagine themselves suspended in the air, isolated from all sensations, which includes no sensory contact with even their own bodies. He argues that in this scenario one would still have self-consciousness. He thus concludes that the idea of the self is not logically dependent on any physical thing, and that the soul should not be seen in relative terms, but as a primary given, a substance. This argument was later refined and simplified by René Descartes in epistemic terms, when he stated: "I can abstract from the supposition of all external things, but not from the supposition of my own consciousness."
Avicenna generally supported Aristotle's idea of the soul originating from the heart, whereas Ibn al-Nafis rejected this idea and instead argued that the soul "is related to the entirety and not to one or a few organs". He further criticized Aristotle's idea whereby every unique soul requires the existence of a unique source, in this case the heart. al-Nafis concluded that "the soul is related primarily neither to the spirit nor to any organ, but rather to the entire matter whose temperament is prepared to receive that soul," and he defined the soul as nothing other than "what a human indicates by saying "I".
Thomas Aquinas.
Following Aristotle and Avicenna, Thomas Aquinas (1225–74) understood the soul to be the first actuality of the living body. Consequent to this, he distinguished three orders of life: plants, which feed and grow; animals, which add sensation to the operations of plants; and humans, which add intellect to the operations of animals.
Concerning the human soul, his epistemological theory required that, since the knower becomes what he knows, the soul is definitely not corporeal—if it is corporeal when it knows what some corporeal thing is, that thing would come to be within it. Therefore, the soul has an operation which does not rely on a bodily organ, and therefore the soul could subsist without a body. Furthermore, since the rational soul of human beings is a subsistent form and not something made of matter and form, it cannot be destroyed in any natural process. The full argument for the immortality of the soul and Aquinas' elaboration of Aristotelian theory is found in Question 75 of the Summa Theologica.
Immanuel Kant.
In his discussions of rational psychology, Immanuel Kant (1724–1804) identified the soul as the "I" in the strictest sense, and that the existence of inner experience can neither be proved nor disproved. "We cannot prove a priori the immateriality of the soul, but rather only so much: that all properties and actions of the soul cannot be cognized from materiality". It is from the "I", or soul, that Kant proposes transcendental rationalization, but cautions that such rationalization can only determine the limits of knowledge if it is to remain practical.
James Hillman.
Contemporary psychology is defined as the study of mental processes and behavior. However, the word "psychology" literally means "study of the soul", and Hillman, the founder of archetypal psychology, has been credited with "restoring 'soul' to its psychological sense". Although the words "soul" and "spirit" are often viewed as synonyms, Hillman argues that they can refer to antagonistic components of a person.
Summarizing Hillman's views, psychotherapist and author Thomas Moore associates spirit with "afterlife, cosmic issues, idealistic values and hopes, and universal truths", while placing soul "in the thick of things: in the repressed, in the shadow, in the messes of life, in illness, and in the pain and confusion of love". Hillman believes that religion—especially monotheism and monastic faiths—and humanistic psychology have tended to the spirit, often at the unfortunate expense of soul. This happens, Moore says, because to transcend the "lowly conditions of the soul ... is to lose touch with the soul, and a split-off spirituality, with no influence from the soul, readily falls into extremes of literalism and destructive fanaticism".
Hillman's archetypal psychology is an attempt to tend to the oft-neglected soul, which Hillman views as the "self-sustaining and imagining substrate" upon which consciousness rests. Hillman described the soul as that "which makes meaning possible, [deepens] events into experiences, is communicated in love, and has a religious concern", as well as "a special relation with death". Departing from the Cartesian dualism "between outer tangible reality and inner states of mind", Hillman takes the Neoplatonic stance that there is a "third, middle position" in which soul resides. Archetypal psychology acknowledges this third position by attuning to, and often accepting, the archetypes, dreams, myths, and even psychopathologies through which, in Hillman's view, soul expresses itself.
Philosophy of mind.
Gilbert Ryle's ghost-in-the-machine argument, which is a rejection of Descartes' mind-body dualism, can provide a contemporary understanding of the soul/mind, and the problem concerning its connection to the brain/body.
Religious views.
Ancient Near East.
In the ancient Egyptian religion, an individual was believed to be made up of various elements, some physical and some spiritual.
Similar ideas are found in ancient Assyrian and Babylonian religion. Kuttamuwa, an 8th-century BC royal official from Sam'al, ordered an inscribed stele erected upon his death. The inscription requested that his mourners commemorate his life and his afterlife with feasts "for my soul that is in this stele". It is one of the earliest references to a soul as a separate entity from the body. The 800 lb basalt stele is 3 ft tall and 2 ft wide. It was uncovered in the third season of excavations by the Neubauer Expedition of the Oriental Institute in Chicago, Illinois.
Bahá'í.
The Bahá'í Faith affirms that "the soul is a sign of God, a heavenly gem whose reality the most learned of men hath failed to grasp, and whose mystery no mind, however acute, can ever hope to unravel". Bahá'u'lláh stated that the soul not only continues to live after the physical death of the human body, but is, in fact, immortal. Heaven can be seen partly as the soul's state of nearness to God; and hell as a state of remoteness from God. Each state follows as a natural consequence of individual efforts, or the lack thereof, to develop spiritually. Bahá'u'lláh taught that individuals have no existence prior to their life here on earth and the soul's evolution is always towards God and away from the material world.
Buddhism.
Buddhism teaches that all things are in a constant state of flux: all is changing, and no permanent state exists by itself. This applies to human beings as much as to anything else in the cosmos. Thus, a human being has no permanent self. According to this doctrine of "anatta" (Pāli; Sanskrit: "anātman") – "no-self" or "no soul" – the words "I" or "me" do not refer to any fixed thing. They are simply convenient terms that allow us to refer to an ever-changing entity.
The "anatta" doctrine is not a kind of materialism. Buddhism does not deny the existence of "immaterial" entities, and it (at least traditionally) distinguishes bodily states from mental states. Thus, the conventional translation of "anatta" as "no-soul" can be confusing. If the word "soul" simply refers to an incorporeal component in living things that can continue after death, then Buddhism does not deny the existence of the soul. Instead, Buddhism denies the existence of a permanent entity that remains constant behind the changing corporeal and incorporeal components of a living being. Just as the body changes from moment to moment, so thoughts come and go. And there is no permanent, underlying mind that experiences these thoughts, as in Cartesianism; rather, conscious mental states simply arise and perish with no "thinker" behind them. When the body dies, Buddhists believe the incorporeal mental processes continue and are reborn in a new body. Because the mental processes are constantly changing, the being that is reborn is neither entirely different from, nor exactly the same as, the being that died. However, the new being is "continuous" with the being that died – in the same way that the "you" of this moment is continuous with the "you" of a moment before, despite the fact that you are constantly changing.
Buddhist teaching holds that a notion of a permanent, abiding self is a delusion that is one of the causes of human conflict on the emotional, social, and political levels. They add that an understanding of "anatta" provides an accurate description of the human condition, and that this understanding allows us to pacify our mundane desires.
Various schools of Buddhism have differing ideas about what continues after death. The Yogacara school in Mahayana Buddhism said there are Store consciousness which continue to exist after death. In some schools, particularly Tibetan Buddhism, the view is that there are three minds: "very subtle mind", which does not disintegrate in death; "subtle mind", which disintegrates in death and which is "dreaming mind" or "unconscious mind"; and "gross mind", which does not exist when one is "sleeping". Therefore, "gross mind" less permanent than subtle mind, which does not exist in death. "Very subtle mind", however, does continue, and when it "catches on", or coincides with phenomena, again, a new "subtle mind" emerges, with its own personality/assumptions/habits, and "that" entity experiences karma in the current continuum.
Plants were said to be non-sentient (無情), but Buddhist monks should avoid cutting or burning trees, because some sentient beings rely on them. Some Mahayana monks said non-sentient beings such as plants and stones have buddha-nature. Some buddhists said about plants or divisible consciousnesses.
Certain modern Buddhists, particularly in Western countries, reject—or at least take an agnostic stance toward—the concept of rebirth or reincarnation, which they view as incompatible with the concept of "anatta". Stephen Batchelor discusses this issue in his book "Buddhism Without Beliefs". Others point to research that has been conducted at the University of Virginia as proof that some people are reborn.
Christianity.
Most Christians understand the soul as an ontological reality distinct from, yet integrally connected with, the body. Its characteristics are described in moral, spiritual, and philosophical terms. Richard Swinburne, a Christian philosopher of religion at Oxford University, wrote that "it is a frequent criticism of substance dualism that dualists cannot say what souls are...Souls are immaterial subjects of mental properties. They have sensations and thoughts, desires and beliefs, and perform intentional actions. Souls are essential parts of human beings". According to a common Christian eschatology, when people die, their souls will be judged by God and determined to go to Heaven or to Hell. Though all branches of Christianity – Catholics, Eastern Orthodox, Oriental Orthodox, Evangelical and mainline Protestants – teach that Jesus Christ plays a decisive role in the Christian salvation process, the specifics of that role and the part played by individual persons or ecclesiastical rituals and relationships, is a matter of wide diversity in official church teaching, theological speculation and popular practice. Some Christians believe that if one has not repented of one's sins and trusted in Jesus Christ as Lord and Savior, one will go to Hell and suffer eternal damnation or eternal separation from God. Some hold a belief that babies (including the unborn) and those with cognitive or mental impairments who have died will be received into Heaven on the basis of God's grace through the sacrifice of Jesus.
Other Christians understand the soul as the life and believe that the dead sleep (Christian conditionalism). This belief is traditionally accompanied by the belief that the unrighteous soul will cease to exist instead of suffering eternally (annihilationism). Believers will inherit eternal life either in Heaven, or in a Kingdom of God on earth, and enjoy eternal fellowship with God.
There are also beliefs in universal salvation.
Trichotomy of the soul.
Augustine, one of western Christianity's most influential early Christian thinkers, described the soul as "a special substance, endowed with reason, adapted to rule the body". Some Christians espouse a trichotomic view of humans, which characterizes humans as consisting of a body ("soma"), soul ("psyche"), and spirit ("pneuma"). However, the majority of modern Bible scholars point out how spirit and soul are used interchangeably in many biblical passages, and so hold to dichotomy: the view that each of us is body and soul. Paul said that the "body wars against" the soul, and that "I buffet my body", to keep it under control.
Trichotomy was changed to dichotomy as tenet of Christian faith at the 8th Ecumenical Council in Constantinople in 869.
Origin of the soul.
The origin of the soul has provided a vexing question in Christianity; the major theories put forward include soul creationism, traducianism and pre-existence. According to creationism, each individual soul is created directly by God, either at the moment of conception or some later time. According to traducianism, the soul comes from the parents by natural generation. According to the preexistence theory, the soul exists before the moment of conception. There have been differing thoughts regarding whether human embryos have souls from conception, or there is a point between conception and birth where the fetus acquires a soul, consciousness, and/or personhood. Stances in this question might more or less influence judgements on the immorality of abortion.
Various denominations.
The present Catechism of the Catholic Church defines the soul as "the innermost aspect of humans, that which is of greatest value in them, that by which they are most especially in God's image: 'soul' signifies the "spiritual principle" in man". All souls living and dead will be judged by Jesus Christ when he comes back to earth. The Catholic Church teaches that the existence of each individual soul is dependent wholly upon God: "The doctrine of the faith affirms that the spiritual and immortal soul is created immediately by God."
Protestants generally believe in the soul's existence, but fall into two major camps about what this means in terms of an afterlife. Some, following Calvin, believe in the immortality of the soul and conscious existence after death, while others, following Luther, believe in the mortality of the soul and unconscious "sleep" until the resurrection of the dead.
Christadelphians believe that we are all created out of the dust of the earth and became living souls once we received the breath of life based on the Genesis 2 account of humanity's creation. Adam was said to have become a living soul. His body did not contain a soul, rather his body (made from dust) plus the breath of life together were called a soul, in other words a living being. They believe that we are mortal and when we die our breath leaves our body, and our bodies return to the soil. They believe that we are mortal until the resurrection from the dead when Christ returns to this earth and grants immortality to the faithful. In the meantime, the dead lie in the earth in the sleep of death until Jesus comes.
Seventh-day Adventists believe that the main definition of the term "Soul" is a combination of spirit (breath of life) and body, disagreeing with the view that the soul has a consciousness or sentient existence of its own. They affirm this through Genesis 2:7 "And (God) breathed into his nostrils the breath of life; and man became a living soul." When God united His breath, or spirit, with man, man became a living soul. A living soul is composed of body and spirit. Adventists believe at death the body returns to dust and life returns to the God who bestowed it. This belief is expressed in the following quotation from their fundamental beliefs,
"The wages of sin is death. But God, who alone is immortal, will grant eternal life to His redeemed. Until that day death is an unconscious state for all people..." (Rom. 6:23; 1 Tim. 6:15, 16; Eccl. 9:5, 6; Ps. 146:3, 4; John 11:11–14; Col. 3:4; 1 Cor. 15:51–54; 1 Thess. 4:13–17; John 5:28, 29; Rev. 20:1–10).
Jehovah's Witnesses take the Hebrew word "nephesh", which is commonly translated as "soul", to be a person, an animal, or the life that a person or an animal enjoys. They believe that the Hebrew word "ruach" (Greek "pneuma"), which is commonly translated as "spirit" but literally means "wind", refers to the life force or the power that animates living things. A person is a breathing creature, a body animated by the "spirit of God", not an invisible being contained in a body and able to survive apart from that body after death. Jesus spoke of himself, having life, as having a soul. When he surrendered his life, he surrendered his soul. John 10:15 reads "just as the Father knows me and I know the father, and I surrender my soul in behalf of the sheep". This belief that man is a soul, rather than having a soul, is also in line with the knowledge that Hell ("Sheol" in Hebrew and Hades in Greek) represents the common grave with the hope of resurrection rather than eternal torment in hellfire.
The Church of Jesus Christ of Latter-day Saints teaches that the spirit and body together constitute the Soul of Man (Mankind). "The spirit and the body are the soul of man." Latter-Day Saints believe that the soul is the union of a pre-existing, God-made spirit and a temporal body, which is formed by physical conception on earth. After death, the spirit continues to live and progress in the Spirit world until the resurrection, when it is reunited with the body that once housed it. This reuniting of body and spirit results in a perfect soul that is immortal and eternally young and healthy and capable of receiving a fulness of joy. Latter-Day Saint cosmology also describes "intelligences" as the essence of consciousness or agency. These are co-eternal with God, and animate the spirits. The union of a newly created spirit body with an eternally-existing intelligence constitutes a "spirit birth" and justifies God's title "Father of our spirits".
Hinduism.
In Hinduism, the Sanskrit words most closely corresponding to soul are "jiva", "Ātman" and "purusha", meaning the individual self. The term "soul" is misleading as it implies an object possessed, whereas self signifies the subject which perceives all objects. This self is held to be distinct from the various mental faculties such as desires, thinking, understanding, reasoning and self-image (ego), all of which are considered to be part of "prakriti" (nature).
The three major schools of Hindu philosophy agree that the "atman" (individual self) is related to Brahman or the "Paramatman", the Absolute Atman or Supreme Self, but they differ in the nature of this relationship. In Advaita Vedanta the individual self and the Supreme Self are one and the same. Dvaita rejects this concept of identity, instead identifying the self as a separate but similar part of Supreme Self (God), that never loses its individual identity. Visishtadvaita takes a middle path and accepts the "atman" as a "mode" ("prakara") or attribute of the Brahman. For an alternative atheistic and dualistic view of the "atman" in ancient Hindu philosophy, see "Samkhya".
The "atman" becomes involved in the process of becoming and transmigrating through cycles of birth and death because of ignorance of its own true nature. The spiritual path consists of self-realization – a process in which one acquires the knowledge of the self ("brahma-jñanam") and through this knowledge applied through meditation and realization one then returns to the Source which is Brahman.
The qualities which are common to both Brahman and atmam are being ("sat"), consciousness ("chit"), and bliss/love ("ananda"). Liberation or "moksha" is liberation from all limiting adjuncts ("upadhis") and the unification with Brahman.
The Mandukya Upanishad verse 7 describes the "atman" in the following way:
"Not inwardly cognitive, not outwardly cognitive, not both-wise cognitive, not a cognition-mass, not cognitive, not non-cognitive, unseen, with which there can be no dealing, ungraspable, having no distinctive mark, non-thinkable, that cannot be designated, the essence of the assurance of which is the state of being one with the Self, the cessation of development, tranquil, benign, without a second (a-dvaita)—[such] they think is the fourth. That is the Self. That should be discerned."
In Bhagavad Gita 2.20 Lord Krishna describes the "atman" in the following way:
"na jayate mriyate va kadacin 'nayam bhutva bhavita va na bhuyah 'ajo nityah sasvato yam purano ""na hanyate hanyamane sarire"
"For the "atman" there is neither birth nor death at any time. He has not come into being, does not come into being, and will not come into being. He is unborn, eternal, ever – existing and primeval. He is not slain when the body is slain". [Translation by A. C. Bhaktivedanta Swami Prabhupada (Srila Prabhupada)]
Srila Prabhupada, a great Vaishnava saint of the modern time further explains: "The "atman" does not take birth there, and the atman does not die... And because the atman has no birth, he therefore has no past, present or future. He is eternal, ever-existing and primeval – that is, there is no trace in history of his coming into being."
Since the quality of Atma is primarily consciousness, all sentient and insentient beings are pervaded by Atma, including plants, animals, humans and gods. The difference between them is the contracted or expanded state of that consciousness. For example, animals and humans share in common the desire to live, fear of death, desire to procreate and to protect their families and territory and the need for sleep, but animals' consciousness is more contracted and has less possibility to expand than does human consciousness.
When the Atma becomes embodied it is called birth, when the Aatma leaves a body it is called death. The Aatma transmigrates from one body to another body based on karmic [performed deeds] reactions.
In Hinduism, the Sanskrit word most closely corresponding to soul is Atma, which can mean soul or even God. It is seen as the portion of Brahman within us. Hinduism contains many variant beliefs on the origin, purpose, and fate of the atma. For example, advaita or non-dualistic conception of the aatma accords it union with Brahman, the absolute uncreated (roughly, the Godhead), in eventuality or in pre-existing fact. Dvaita or dualistic concepts reject this, instead identifying the atma as a different and incompatible substance.
There are 25 coverings wrapped on our Atma (Reference Taken from "Vaikunta Varnane" written by Sanyasi Vadiraja Swami)
1. Iccha avarka,
2. Linga deha,
3. Avyakta Sharira,
4. Avidya Avarna,
5. Karma avarna,
6. Kama avarna,
7. Jeevacchadaka,
8. Paramacchadaka,
9. Narayana rupa avarna,
10. Vasudeva rupa Avarna,
11. Sankarshana rupa avarna,
12. Pradhyumna Avarka,
13. Anniruddha avarka,
14. Anniruddha Sharira,
15. Vasudeva Kavaca,
16. Narayana Kavaca,
17. Anandamaya kosha,
18. Vignanamaya kosha,
19. Manomaya kosha,
20. Vangmaya kosha,
21. Shrotrumaya kosha,
22. Chakshurmaya kosha,
23. Pranamaya kosha,
24. Annamaya kosha,
25. Gross Body.
Islam.
Islam teaches that the soul is immortal and eternal, and that what a person does is recorded and will be judged at the final court of God. They will either go to heaven or hell, depending on whether or not they did well in the test that was given to them by Allah.
The Qur'an mentions the soul:
Jainism.
In Jainism every living being, from a plant or a bacterium to human, has a soul and the concept forms the very basis of Jainism. The soul "(Atman (Jainism))" is basically categorized in two based on its liberation state.
Irrespective of which state the soul is in, it has got the same attributes and qualities. The difference between the liberated and non-liberated souls is that the qualities and attributes are exhibited completely in case of Siddhas ("Siddha") as they have overcome all the karmic bondages whereas in case of non-liberated souls they are partially exhibited.
Concerning the Jain view of the soul, Virchand Gandhi quoted "the soul lives its own life, not for the purpose of the body, but the body lives for the purpose of the soul. If we believe that the soul is to be controlled by the body then soul misses its power".
Judaism.
The fruit of a righteous man is the tree of life, and the wise man acquires נְפָשׁוֹת souls.
The Hebrew terms נפש "nephesh" (literally "living being"), רוח "ruach" (literally "wind"), נשמה "neshama" (literally "breath"), חיה "chaya" (literally "life") and יחידה "yechidah" (literally "singularity") are used to describe the soul or spirit. In modern Judaism the soul is believed to be given by God to a person by his/her first breath, as mentioned in Genesis, "And the LORD God formed man [of] the dust of the ground, and breathed into his nostrils the breath of life; and man became a living being." . Judaism relates the quality of one's soul to one's performance of the commandments, "mitzvot", and reaching higher levels of understanding, and thus closeness to God. A person with such closeness is called a "tzadik". Therefore Judaism embraces the commemoration of the day of one's death, "nahala"/"Yahrtzeit" and not the birthday as a festive of remembrance, for only toward the end of life's struggles, tests and challenges human souls could be judged and credited - b'ezrat hashem ("with God's help") - for righteousness and holiness. Judaism places great importance on the study of the souls, which is expected to make a practical difference in the world.
For I [Hashem] will not contend forever, neither will I be wroth to eternity, when a spirit from before Me humbles itself, and רוּחַ souls [which] I have made.
Nevi'im, 
Kabbalah and other mystic traditions go into greater detail into the nature of the soul. Kabbalah separates the soul into five elements, corresponding to the five worlds:
Kabbalah also proposed a concept of reincarnation, the "gilgul". (See also "nefesh habehamit" the "animal soul".)
Shamanism.
According to Nadya Yuguseva, a shaman from the Altai, "'A woman has 40 souls; men have just one[.]'"
Sikhism.
Sikhism considers Soul (atma) to be part of God (Waheguru). Various hymns are cited from the holy book "Sri Guru Granth Sahib" (SGGS) that suggests this belief. "God is in the Soul and the Soul is in the God." The same concept is repeated at various pages of the SGGS. For example: "The soul is divine; divine is the soul. Worship Him with love." and "The soul is the Lord, and the Lord is the soul; contemplating the Shabad, the Lord is found."
The "Atma" or "Soul" according to Sikhism is an entity or "spiritual spark" or "light" in our body because of which the body can sustain life. On the departure of this entity from the body, the body becomes lifeless – No amount of manipulations to the body can make the person make any physical actions. The soul is the ‘driver’ in the body. It is the ‘roohu’ or spirit or atma, the presence of which makes the physical body alive.
Many religious and philosophical traditions, support the view that the soul is the ethereal substance – a spirit; a non material spark – particular to a unique living being. Such traditions often consider the soul both immortal and innately aware of its immortal nature, as well as the true basis for sentience in each living being. The concept of the soul has strong links with notions of an afterlife, but opinions may vary wildly even within a given religion as to what happens to the soul after death. Many within these religions and philosophies see the soul as immaterial, while others consider it possibly material.
Taoism.
According to Chinese traditions, every person has two types of soul called hun and po (魂 and 魄), which are respectively yang and yin. Taoism believes in ten souls, "sanhunqipo" () "three "hun" and seven "po"". The pò is linked to the dead body and the grave, whereas the hún is linked to the ancestral tablet. A living being that loses any of them is said to have mental illness or unconsciousness, while a dead soul may reincarnate to a disability, lower desire realms or may even be unable to reincarnate.
Other religious beliefs and views.
In theological reference to the soul, the terms "life" and "death" are viewed as emphatically more definitive than the common concepts of "biological life" and "biological death". Because the soul is said to be transcendent of the "material existence," and is said to have (potentially) eternal life, the death of the soul is likewise said to be an "eternal death". Thus, in the concept of divine judgment, God is commonly said to have options with regard to the dispensation of souls, ranging from Heaven (i.e., angels) to hell (i.e., demons), with various concepts in between. Typically both Heaven and hell are said to be eternal, or at least far beyond a typical human concept of lifespan and time.
Spirituality, New Age and new religions.
Brahma Kumaris.
In Brahma Kumaris, human souls are believed to be incorporeal and eternal. God is considered to be the Supreme Soul, with maximum degrees of spiritual qualities, such as peace, love and purity.
Theosophy.
In Helena Blavatsky's Theosophy, the soul is the field of our psychological activity (thinking, emotions, memory, desires, will, and so on) as well as of the so-called paranormal or psychic phenomena (extrasensory perception, out-of-body experiences, etc.). However, the soul is not the highest, but a middle dimension of human beings. Higher than the soul is the spirit, which is considered to be the real self; the source of everything we call “good”—happiness, wisdom, love, compassion, harmony, peace, etc. While the spirit is eternal and incorruptible, the soul is not. The soul acts as a link between the material body and the spiritual self, and therefore shares some characteristics of both. The soul can be attracted either towards the spiritual or towards the material realm, being thus the “battlefield” of good and evil. It is only when the soul is attracted towards the spiritual and merges with the Self that it becomes eternal and divine.
Anthroposophy.
Rudolf Steiner differentiated three stages of soul development, which interpenetrate one another in consciousness:
Miscellaneous.
In Surat Shabda Yoga, the soul is considered to be an exact replica and spark of the Divine. The purpose of Surat Shabd Yoga is to realize one's True Self as soul (Self-Realisation), True Essence (Spirit-Realisation) and True Divinity (God-Realisation) while living in the physical body.
Similarly, the spiritual teacher Meher Baba held that "Atma, or the soul, is in reality identical with Paramatma the Oversoul — which is one, infinite, and eternal...[and] [t]he sole purpose of creation is for the soul to enjoy the infinite state of the Oversoul consciously." 
Eckankar, founded by Paul Twitchell in 1965, defines Soul as the true self; the inner, most sacred part of each person.
Science.
The findings of science may be relevant to one's understanding of the soul depending on one's belief regarding the relationship between the soul and the mind. One problem with seeking scientific evidence for the soul is that there is no clear or unique definition of what the soul is.
Neuroscience and the soul.
Neuroscience as an interdisciplinary field, and its branch of cognitive neuroscience particularly, operates under the ontological assumption of physicalism, according to which only the fundamental phenomena studied by physics exist. Thus, neuroscience seeks to understand mental phenomena within the framework according to which human thought and behavior are caused solely by physical processes taking place inside the brain, and it operates by the way of reduction by seeking an explanation for the mind in terms of brain activity.
To study the mind in terms of the brain several methods of functional neuroimaging are used to study the neuroanatomical correlates of various cognitive processes that constitute the mind. The evidence from brain imaging indicates that all processes of the mind have physical correlates in brain function. However, such correlational studies cannot determine whether neural activity plays a causal role in the occurrence of these cognitive processes (correlation does not imply causation) and they cannot determine if the neural activity is either necessary and sufficient for such processes to occur. Identification of causation and necessary and sufficient conditions requires explicit experimental manipulation of that activity. If manipulation of brain activity changes consciousness, then a causal role for that brain activity can be inferred. Two of the most common types of manipulation experiments are loss-of-function and gain-of-function experiments. In a loss-of-function (also called "necessity") experiment, a part of the nervous system is diminished or removed in an attempt to determine if it is necessary for a certain process to occur, and in a gain-of-function (also called "sufficiency") experiment, an aspect of the nervous system is increased relative to normal. Manipulations of brain activity can be performed with direct electrical brain stimulation, magnetic brain stimulation using transcranial magnetic stimulation, psychopharmacological manipulation, optogenetic manipulation and by studying the symptoms of brain damage (case studies) and lesions. In addition, neuroscientists are also investigating how the mind develops with the development of the brain.
Physics and the soul.
Physicist Sean M. Carroll has written that the idea of a soul is in opposition to quantum field theory (QFT). He writes that for a soul to exist "Not only is new physics required, but dramatically new physics. Within QFT, there can’t be a new collection of "spirit particles" and "spirit forces" that interact with our regular atoms, because we would have detected them in existing experiments."
Parapsychology.
Some parapsychologists have attempted to establish by scientific experiment whether a soul separate from the brain, as more commonly defined in religion rather than as a synonym of psyche or mind, exists. Milbourne Christopher (1979) and Mary Roach (2010) have argued that none of the attempts by parapsychologists have yet succeeded.
Weight of the soul.
In 1901 Duncan MacDougall made weight measurements of patients as they died. He claimed that there was weight loss of varying amounts at the time of death. The physicist Robert L. Park has written MacDougall's experiments "are not regarded today as having any scientific merit" and the psychologist Bruce Hood wrote that "because the weight loss was not reliable or replicable, his findings were unscientific."

</doc>
<doc id="28299" url="http://en.wikipedia.org/wiki?curid=28299" title="Steradian">
Steradian

The steradian (symbol: sr) or square radian is the SI unit of solid angle. It is used in three-dimensional space, and functions analogously to the manner in which the radian quantifies planar angles. The name is derived from the Greek "stereos" for "solid" and the Latin "radius" for "ray, beam".
The steradian, like the radian, is dimensionless, essentially because a solid angle is the ratio between the area subtended and the square of its distance from the vertex: both the numerator and denominator of this ratio have dimension length squared (i.e., L²/L² = Φ - no unit). It is useful, however, to distinguish between dimensionless quantities of a different nature, so in practice the symbol "sr" is used to indicate a solid angle. For example, radiant intensity can be measured in watts per steradian (W·sr−1). The steradian was formerly an SI supplementary unit, but this category was abolished from the SI in 1995 and the steradian is now considered an SI derived unit.
Definition.
A steradian can be defined as the solid angle subtended at the center of a unit sphere by a unit area on its surface. For a general sphere of radius "r", any portion of its surface with area "A" = r2 subtends one steradian.
The solid angle is related to the area it cuts out of a sphere:
Because the surface area "A" of a sphere is 4π"r"2, the definition implies that a sphere measures 4π (≈ 12.56637) steradians. By the same argument, the maximum solid angle that can be subtended at any point is 4π sr.
Other properties.
Since "A" = "r"2, it corresponds to the area of a spherical cap ("A" = 2π"rh") (wherein "h" stands for the "height" of the cap), and the relationship "h"/"r" = 1/(2π) holds. Therefore one steradian corresponds to the plane (i.e. radian) angle of the cross-section of a simple cone subtending the plane angle "2θ", with "θ" given by:
This angle corresponds to the plane aperture angle of 2"θ" ≈ 1.144 rad or 65.54°.
A steradian is also equal to the spherical area of a polygon having an angle excess of 1 radian, to 1/(4π) of a complete sphere, or to (180/π)2 ≈ 3282.80635 square degrees.
The solid angle of a cone whose cross-section subtends the angle 2"θ" is:
Analogue to radians.
In two dimensions, an angle is related to the arc length it cuts out:
Instead in three dimensions, the solid angle is related to the area it cuts out:
So to give an example, a measurement of the width of an object seen would be given in radians. At the same time its visible area over one's visible field would be given in steradians. Just as the area of a circle is quadratically related to its diameter or radius, so is the area of the piece of a spherical surface cut out by a circular cone related to the angle across the patch. That area, or equivalently the proportion of a sphere its cone takes up, is a measure of three dimensional proportional volume, analogous to the two dimensional measure over the circle represented by an angle.
The one dimensional circular measure has the units of degree, while the two dimensional one is expressed in steradians. In higher dimensional mathematical spaces, units for analogous solid angles haven't been explicitly named. When they are used, they are dealt with by analogy with the the circular or spherical cases. That is, as a proportion of the relevant unit hypersphere taken up by the generalized angle, or set expressed in spherical coordinates.
SI multiples.
A complete sphere subtends only 4π ≈ 12.56637 steradians, so multiples larger than the decasteradian are rarely used.
Any range in excess of the whole area of a sphere would only be needed in conjunction with non-Euclidean, spherical geometry. Then it would also usually only be required in the context of nonlocal analysis. As such, solid angles over four times pi are used exceedingly rarely in the literature.

</doc>
<doc id="28305" url="http://en.wikipedia.org/wiki?curid=28305" title="String theory">
String theory

In physics, string theory is a theoretical framework in which the point-like particles of particle physics are replaced by one-dimensional objects called strings. String theory aims to explain all types of observed elementary particles using quantum states of these strings. In addition to the particles postulated by the standard model of particle physics, string theory naturally incorporates gravity and so is a candidate for a theory of everything, a self-contained mathematical model that describes all fundamental forces and forms of matter. Besides this potential role, string theory is now widely used as a theoretical tool and has shed light on many aspects of quantum field theory and quantum gravity.
The earliest version of string theory, bosonic string theory, incorporated only the class of particles known as bosons. It was then developed into superstring theory, which posits that a connection – a "supersymmetry" – exists between bosons and the class of particles called fermions. String theory requires the existence of extra spatial dimensions for its mathematical consistency. In realistic physical models constructed from string theory, these extra dimensions are typically compactified to extremely small scales.
String theory was first studied in the late 1960s as a theory of the strong nuclear force before being abandoned in favor of the theory of quantum chromodynamics. Subsequently, it was realized that the very properties that made string theory unsuitable as a theory of nuclear physics made it a promising candidate for a quantum theory of gravity. Five consistent versions of string theory were developed until it was realized in the mid-1990s that they were different limits of a conjectured single 11-dimensional theory now known as M-theory.
Many theoretical physicists, including Stephen Hawking, Edward Witten and Juan Maldacena, believe that string theory is a step towards the correct fundamental description of nature: it accommodates a consistent combination of quantum field theory and general relativity, agrees with insights in quantum gravity (such as the holographic principle and black hole thermodynamics) and has passed many non-trivial checks of its internal consistency. According to Hawking, "M-theory is the "only" candidate for a complete theory of the universe." Other physicists, such as Richard Feynman, Roger Penrose and Sheldon Lee Glashow, have criticized string theory for not providing novel experimental predictions at accessible energy scales.
Overview.
The starting point for string theory is the idea that the point-like particles of elementary particle physics can also be modeled as one-dimensional objects called "strings". According to string theory, strings can oscillate in many ways. On distance scales larger than the string radius, each oscillation mode gives rise to a different species of particle, with its mass, charge, and other properties determined by the string's dynamics. Splitting and recombination of strings correspond to particle emission and absorption, giving rise to the interactions between particles. An analogy for strings' modes of vibration is a guitar string's production of multiple distinct musical notes. In this analogy, different notes correspond to different particles.
In string theory, one of the modes of oscillation of the string corresponds to a massless, spin-2 particle. Such a particle is called a graviton since it mediates a force which has the properties of gravity. Since string theory is believed to be a mathematically consistent quantum mechanical theory, the existence of this graviton state implies that string theory is a theory of quantum gravity.
String theory includes both "open" strings, which have two distinct endpoints, and "closed" strings, which form a complete loop. The two types of string behave in slightly different ways, yielding different particle types. For example, all string theories have closed string graviton modes, but only open strings can correspond to the particles known as photons. Because the two ends of an open string can always meet and connect, forming a closed string, all string theories contain closed strings.
The earliest string model, the bosonic string, incorporated only the class of particles known as bosons. This model describes, at low enough energies, a quantum gravity theory, which also includes (if open strings are incorporated as well) gauge bosons such as the photon. However, this model has problems. What is most significant is that the theory has a fundamental instability, believed to result in the decay (at least partially) of spacetime itself. In addition, as the name implies, the spectrum of particles contains only bosons, particles which, like the photon, obey particular rules of behavior. Roughly speaking, bosons are the constituents of radiation, but not of matter, which is made of fermions. Investigating how a string theory may include fermions led to the invention of supersymmetry, a mathematical relation between bosons and fermions. String theories that include fermionic vibrations are now known as superstring theories; several kinds have been described, but all are now thought to be different limits of a theory called M-theory.
Since string theory incorporates all of the fundamental interactions, including gravity, many physicists hope that it fully describes our universe, making it a theory of everything. One of the goals of current research in string theory is to find a solution of the theory that is quantitatively identical with the standard model, with a small cosmological constant, containing dark matter and a plausible mechanism for cosmic inflation. It is not yet known whether string theory has such a solution, nor is it known how much freedom the theory allows to choose the details.
One of the challenges of string theory is that the full theory does not yet have a satisfactory definition in all circumstances. The scattering of strings is most straightforwardly defined using the techniques of perturbation theory, but it is not known in general how to define string theory nonperturbatively. It is also not clear as to whether there is any principle by which string theory selects its vacuum state, the spacetime configuration that determines the properties of our universe (see string theory landscape).
Strings.
The motion of a point-like particle can be described by drawing a graph of its position with respect to time. The resulting picture depicts the worldline of the particle in spacetime. In an analogous way, one can draw a graph depicting the progress of a "string" as time passes. The string, which looks like a small line by itself, will sweep out a two-dimensional surface known as the worldsheet. The different string modes (giving rise to different particles, such as the photon or graviton) appear as waves on this surface.
A closed string looks like a small loop, so its worldsheet will look like a pipe. An open string looks like a segment with two endpoints, so its worldsheet will look like a strip. In a more mathematical language, these are both Riemann surfaces, the strip having a boundary and the pipe none.
Strings can join and split. This is reflected by the form of their worldsheet, or more precisely, by its topology. For example, if a closed string splits, its worldsheet will look like a single pipe splitting into two pipes. This topology is often referred to as a "pair of pants" (see drawing at right). If a closed string splits and its two parts later reconnect, its worldsheet will look like a single pipe splitting to two and then reconnecting, which also looks like a torus connected to two pipes (one representing the incoming string, and the other representing the outgoing one). An open string doing the same thing will have a worldsheet that looks like an annulus connected to two strips.
In quantum mechanics, one computes the probability for a point particle to propagate from one point to another by summing certain quantities called probability amplitudes. Each amplitude is associated with a different worldline of the particle. This process of summing amplitudes over all possible worldlines is called path integration. In string theory, one computes probabilities in a similar way, by summing quantities associated with the worldsheets joining an initial string configuration to a final configuration. It is in this sense that string theory extends quantum field theory, replacing point particles by strings. As in quantum field theory, the classical behavior of fields is determined by an action functional, which in string theory can be either the Nambu–Goto action or the Polyakov action.
Branes.
In string theory and related theories such as supergravity theories, a "brane" is a physical object that generalizes the notion of a point particle to higher dimensions. For example, a point particle can be viewed as a brane of dimension zero, while a string can be viewed as a brane of dimension one. It is also possible to consider higher-dimensional branes. In dimension "p", these are called "p"-branes. The word brane comes from the word "membrane" which refers to a two-dimensional brane.
Branes are dynamical objects which can propagate through spacetime according to the rules of quantum mechanics. They have mass and can have other attributes such as charge. A "p"-brane sweeps out a ("p"+1)-dimensional volume in spacetime called its "worldvolume". Physicists often study fields analogous to the electromagnetic field which live on the worldvolume of a brane.
In string theory, D-branes are an important class of branes that arise when one considers open strings. As an open string propagates through spacetime, its endpoints are required to lie on a D-brane. The letter "D" in D-brane refers to the fact that we impose a certain mathematical condition on the system known as the Dirichlet boundary condition. The study of D-branes in string theory has led to important results such as the AdS/CFT correspondence, which has shed light on many problems in quantum field theory.
Branes are also frequently studied from a purely mathematical point of view since they are related to subjects such as homological mirror symmetry and noncommutative geometry. Mathematically, branes may be represented as objects of certain categories, such as the derived category of coherent sheaves on a Calabi–Yau manifold, or the Fukaya category.
Dualities.
In physics, the term "duality" refers to a situation where two seemingly different physical systems turn out to be equivalent in a nontrivial way. If two theories are related by a duality, it means that one theory can be transformed in some way so that it ends up looking just like the other theory. The two theories are then said to be "dual" to one another under the transformation. Put differently, the two theories are mathematically different descriptions of the same phenomena.
In addition to providing a candidate for a theory of everything, string theory provides many examples of dualities between different physical theories and can therefore be used as a tool for understanding the relationships between these theories.
S-, T-, and U-duality.
These are dualities between string theories which relate seemingly different quantities. Large and small distance scales, as well as strong and weak coupling strengths, are quantities that have always marked very distinct limits of behavior of a physical system in both classical and quantum physics. But strings can obscure the difference between large and small, strong and weak, and this is how these five very different theories end up being related. T-duality relates the large and small distance scales between string theories, whereas S-duality relates strong and weak coupling strengths between string theories. U-duality links T-duality and S-duality.
M-theory.
Before the 1990s, string theorists believed there were five distinct superstring theories: type I, type IIA, type IIB, and the two flavors of heterotic string theory (SO(32) and "E"8×"E"8). The thinking was that out of these five candidate theories, only one was the actual correct theory of everything, and that theory was the one whose low energy limit, with ten spacetime dimensions compactified down to four, matched the physics observed in our world today. It is now believed that this picture was incorrect and that the five superstring theories are related to one another by the dualities described above. The existence of these dualities suggests that the five string theories are in fact special cases of a more fundamental theory called M-theory.
Extra dimensions.
Number of dimensions.
An intriguing feature of string theory is that it predicts extra dimensions. In classical string theory the number of dimensions is not fixed by any consistency criterion. However, to make a consistent quantum theory, string theory is required to live in a spacetime of the so-called "critical dimension": we must have 26 spacetime dimensions for the bosonic string and 10 for the superstring. This is necessary to ensure the vanishing of the conformal anomaly of the worldsheet conformal field theory. Modern understanding indicates that there exist less trivial ways of satisfying this criterion. Cosmological solutions exist in a wider variety of dimensionalities, and these different dimensions are related by dynamical transitions. The dimensions are more precisely different values of the "effective central charge", a count of degrees of freedom that reduces to dimensionality in weakly curved regimes.
One such theory is the 11-dimensional M-theory, which requires spacetime to have eleven dimensions, as opposed to the usual three spatial dimensions and the fourth dimension of time. The original string theories from the 1980s describe special cases of M-theory where the eleventh dimension is a very small circle or a line, and if these formulations are considered as fundamental, then string theory requires ten dimensions. But the theory also describes universes like ours, with four observable spacetime dimensions, as well as universes with up to 10 flat space dimensions, and also cases where the position in some of the dimensions is described by a complex number rather than a real number. The notion of spacetime dimension is not fixed in string theory: it is best thought of as different in different circumstances.
Nothing in Maxwell's theory of electromagnetism or Einstein's theory of relativity makes this kind of prediction; these theories require physicists to insert the number of dimensions manually and arbitrarily, and this number is fixed and independent of potential energy. String theory allows one to relate the number of dimensions to scalar potential energy. In technical terms, this happens because a gauge anomaly exists for every separate number of predicted dimensions, and the gauge anomaly can be counteracted by including nontrivial potential energy into equations to solve motion. Furthermore, the absence of potential energy in the "critical dimension" explains why flat spacetime solutions are possible.
This can be better understood by noting that a photon included in a consistent theory (technically, a particle carrying a force related to an unbroken gauge symmetry) must be massless. The mass of the photon that is predicted by string theory depends on the energy of the string mode that represents the photon. This energy includes a contribution from the Casimir effect, namely from quantum fluctuations in the string. The size of this contribution depends on the number of dimensions, since for a larger number of dimensions there are more possible fluctuations in the string position. Therefore, the photon in flat spacetime will be massless—and the theory consistent—only for a particular number of dimensions.
When the calculation is done, the critical dimensionality is not four as one may expect (three axes of space and one of time).
The subset of X is equal to the relation of photon fluctuations in a linear dimension. Flat space string theories are 26-dimensional in the bosonic case, while superstring and M-theories turn out to involve 10 or 11 dimensions for flat solutions. In bosonic string theories, the 26 dimensions come from the Polyakov equation. Starting from any dimension greater than four, it is necessary to consider how these are reduced to four-dimensional spacetime.
Compact dimensions.
Two ways have been proposed to resolve this apparent contradiction. The first is to compactify the extra dimensions; i.e., the six or seven extra dimensions are so small as to be undetectable by present-day experiments.
To retain a high degree of supersymmetry, these compactification spaces must be very special, as reflected in their holonomy. A 6-dimensional manifold must have SU(3) structure, a particular case (torsionless) of this being SU(3) holonomy, making it a Calabi–Yau space, and a 7-dimensional manifold must have G2 structure, with G2 holonomy again being a specific, simple, case. Such spaces have been studied in attempts to relate string theory to the 4-dimensional Standard Model, in part due to the computational simplicity afforded by the assumption of supersymmetry. More recently, progress has been made constructing more realistic compactifications without the degree of symmetry of Calabi–Yau or G2 manifolds.
A standard analogy for this is to consider multidimensional space as a garden hose. If the hose is viewed from sufficient distance, it appears to have only one dimension, its length. Indeed, think of a ball just small enough to enter the hose. Throwing such a ball inside the hose, the ball would move more or less in one dimension; in any experiment we make by throwing such balls in the hose, the only important movement will be one-dimensional, that is, along the hose. However, as one approaches the hose, one discovers that it contains a second dimension, its circumference. Thus, an ant crawling inside it would move in two dimensions (and a fly flying in it would move in three dimensions). This "extra dimension" is only visible within a relatively close range to the hose, or if one "throws in" small enough objects. Similarly, the extra compact dimensions are only "visible" at extremely small distances, or by experimenting with particles with extremely small wavelengths (of the order of the compact dimension's radius), which in quantum mechanics means very high energies (see wave–particle duality).
Brane-world scenario.
Another possibility is that we are "stuck" in a 3+1 dimensional (three spatial dimensions plus one time dimension) subspace of the full universe. Properly localized matter and Yang–Mills gauge fields will typically exist if the sub-spacetime is an exceptional set of the larger universe. These "exceptional sets" are ubiquitous in Calabi–Yau "n"-folds and may be described as subspaces without local deformations, akin to a crease in a sheet of paper or a crack in a crystal, the neighborhood of which is markedly different from the exceptional subspace itself. However, until the work of Randall and Sundrum, it was not known that gravity can be properly localized to a sub-spacetime. In addition, spacetime may be stratified, containing strata of various dimensions, allowing us to inhabit the 3+1-dimensional stratum—such geometries occur naturally in Calabi–Yau compactifications. Such sub-spacetimes are D-branes, hence such models are known as brane-world scenarios.
Effect of the hidden dimensions.
In either case, gravity acting in the hidden dimensions affects other non-gravitational forces such as electromagnetism. In fact, Kaluza's early work demonstrated that general relativity in five dimensions actually predicts the existence of electromagnetism. However, because of the nature of Calabi–Yau manifolds, no new forces appear from the small dimensions, but their shape has a profound effect on how the forces between the strings appear in our four-dimensional universe. In principle, therefore, it is possible to deduce the nature of those extra dimensions by requiring consistency with the standard model, but this is not yet a practical possibility. It is also possible to extract information regarding the hidden dimensions by precision tests of gravity, but so far these have only put upper limitations on the size of such hidden dimensions.
Testability and experimental predictions.
Although a great deal of recent work has focused on using string theory to construct realistic models of particle physics, several major difficulties complicate efforts to test models based on string theory. The most significant is the extremely small size of the Planck length, which is expected to be close to the string length (the characteristic size of a string, where strings become easily distinguishable from particles). Another issue is the huge number of metastable vacua of string theory, which might be sufficiently diverse to accommodate almost any phenomena we might observe at lower energies.
String harmonics.
One unique prediction of string theory is the existence of "string harmonics". At sufficiently high energies, the string-like nature of particles would become obvious. There should be heavier copies of all particles, corresponding to higher vibrational harmonics of the string. It is not clear how high these energies are. In most conventional string models, they would be close to the Planck energy, which is 1014 times higher than the energies accessible in the newest particle accelerator, the LHC, making this prediction impossible to test with any particle accelerator in the near future. However, in models with large extra dimensions they could potentially be produced at the LHC, or at energies not far above its reach.
Cosmology.
String theory as currently understood makes a series of predictions for the structure of the Universe at the largest scales. Many phases in string theory have very large, positive vacuum energy. Regions of the Universe that are in such a phase will inflate exponentially rapidly in a process known as eternal inflation. As such, the theory predicts that most of the Universe is very rapidly expanding. However, these expanding phases are not stable, and can decay via the nucleation of bubbles of lower vacuum energy. Since our local region of the Universe is not very rapidly expanding, string theory predicts we are inside such a bubble. The spatial curvature of the "universe" inside the bubbles that form by this process is negative, a testable prediction. Moreover, other bubbles will eventually form in the parent vacuum outside the bubble and collide with it. These collisions lead to potentially observable imprints on cosmology. However, it is possible that neither of these will be observed if the spatial curvature is too small and the collisions are too rare.
Under certain circumstances, fundamental strings produced at or near the end of inflation can be "stretched" to astronomical proportions. These cosmic strings could be observed in various ways, for instance by their gravitational lensing effects. However, certain field theories also predict cosmic strings arising from topological defects in the field configuration.
Supersymmetry.
If confirmed experimentally, supersymmetry is often considered circumstantial evidence, because most consistent string theories are space-time supersymmetric. As with other physical theories, the existence of space-time supersymmetry is a desired feature addressing various issues we encounter in non-supersymmetric theories, like in the Standard Model. However, the absence of supersymmetric particles at energies accessible to the LHC will not actually disprove string theory, since the energy scale at which supersymmetry is broken could be well above the accelerator's range. This would make supersymmetric particles too heavy to be produced in relatively lower energies. On the other hand, there are fully consistent non-supersymmetric string-theories that can also provide phenomenologically relevant predictions.
AdS/CFT correspondence.
The anti-de Sitter/conformal field theory (AdS/CFT) correspondence is a relationship which says that string theory is in certain cases equivalent to a quantum field theory. More precisely, one considers string or M-theory on an anti-de Sitter background. This means that the geometry of spacetime is obtained by perturbing a certain solution of Einstein's equation in the vacuum. In this setting, it is possible to define a notion of "boundary" of spacetime. The AdS/CFT correspondence states that this boundary can be regarded as the "spacetime" for a quantum field theory, and this field theory is equivalent to the bulk gravitational theory in the sense that there is a "dictionary" for translating calculations in one theory into calculations in the other.
Examples of the correspondence.
The most famous example of the AdS/CFT correspondence states that Type IIB string theory on the product AdS5 × S5 is equivalent to "N" = 4 super Yang–Mills theory on the four-dimensional conformal boundary. Another realization of the correspondence states that M-theory on AdS4 × S7 is equivalent to the ABJM superconformal field theory in three dimensions. Yet another realization states that M-theory on AdS7 × S4is equivalent to the so-called (2,0)-theory in six dimensions.
Applications to quantum chromodynamics.
Since it relates string theory to ordinary quantum field theory, the AdS/CFT correspondence can be used as a theoretical tool for doing calculations in quantum field theory. For example, the correspondence has been used to study the quark–gluon plasma, an exotic state of matter produced in particle accelerators.
The physics of the quark–gluon plasma is governed by quantum chromodynamics, the fundamental theory of the strong nuclear force, but this theory is mathematically intractable in problems involving the quark–gluon plasma. In order to understand certain properties of the quark–gluon plasma, theorists have therefore made use of the AdS/CFT correspondence. One version of this correspondence relates string theory to a certain supersymmetric gauge theory called "N" = 4 super Yang–Mills theory. The latter theory provides a good approximation to quantum chromodynamics. One can thus translate problems involving the quark–gluon plasma into problems in string theory which are more tractable. Using these methods, theorists have computed the shear viscosity of the quark–gluon plasma. In 2008, these predictions were confirmed at the Relativistic Heavy Ion Collider at Brookhaven National Laboratory.
Applications to condensed matter physics.
In addition, string theory methods have been applied to problems in condensed matter physics. Certain condensed matter systems are difficult to understand using the usual methods of quantum field theory, and the AdS/CFT correspondence may allow physicists to better understand these systems by describing them in the language of string theory. Some success has been achieved in using string theory methods to describe the transition of a superfluid to an insulator.
Connections to mathematics.
In addition to influencing research in theoretical physics, string theory has stimulated a number of major developments in pure mathematics. Like many developing ideas in theoretical physics, string theory does not at present have a mathematically rigorous formulation in which all of its concepts can be defined precisely. As a result, physicists who study string theory are often guided by physical intuition to conjecture relationships between the seemingly different mathematical structures that are used to formalize different parts of the theory. These conjectures are later proved by mathematicians, and in this way, string theory has served as a source of new ideas in pure mathematics.
Mirror symmetry.
One of the ways in which string theory influenced mathematics was through the discovery of mirror symmetry. In string theory, the shape of the unobserved spatial dimensions is typically encoded in mathematical objects called Calabi–Yau manifolds. These are of interest in pure mathematics, and they can be used to construct realistic models of physics from string theory. In the late 1980s, it was noticed that given such a physical model, it is not possible to uniquely reconstruct a corresponding Calabi–Yau manifold. Instead, one finds that there are "two" Calabi–Yau manifolds that give rise to the same physics. These manifolds are said to be "mirror" to one another. The existence of this mirror symmetry relationship between different Calabi–Yau manifolds has significant mathematical consequences as it allows mathematicians to solve many problems in enumerative algebraic geometry. Today mathematicians are still working to develop a mathematical understanding of mirror symmetry based on physicists' intuition.
Vertex operator algebras.
In addition to mirror symmetry, applications of string theory to pure mathematics include results in the theory of vertex operator algebras. For example, ideas from string theory were used by Richard Borcherds in 1992 to prove the monstrous moonshine conjecture relating the monster group (a construction arising in group theory, a branch of algebra) and modular functions (a class of functions which are important in number theory).
History.
Early results.
Some of the structures reintroduced by string theory arose for the first time much earlier as part of the program of classical unification started by Albert Einstein. The first person to add a fifth dimension to a theory of gravity was Gunnar Nordström in 1914, who noted that gravity in five dimensions describes both gravity and electromagnetism in four. Nordström attempted to unify electromagnetism with his theory of gravitation, which was however superseded by Einstein's general relativity in 1919. Thereafter, German mathematician Theodor Kaluza combined the fifth dimension with general relativity, and only Kaluza is usually credited with the idea. In 1926, the Swedish physicist Oskar Klein gave a physical interpretation of the unobservable extra dimension—it is wrapped into a small circle. Einstein introduced a non-symmetric metric tensor, while much later Brans and Dicke added a scalar component to gravity. These ideas would be revived within string theory, where they are demanded by consistency conditions.
String theory was originally developed during the late 1960s and early 1970s as a never completely successful theory of hadrons, the subatomic particles like the proton and neutron that feel the strong interaction. In the 1960s, Geoffrey Chew and Steven Frautschi discovered that the mesons make families called Regge trajectories with masses related to spins in a way that was later understood by Yoichiro Nambu, Holger Bech Nielsen and Leonard Susskind to be the relationship expected from rotating strings. Chew advocated making a theory for the interactions of these trajectories that did not presume that they were composed of any fundamental particles, but would construct their interactions from self-consistency conditions on the S-matrix. The S-matrix approach was started by Werner Heisenberg in the 1940s as a way of constructing a theory that did not rely on the local notions of space and time, which Heisenberg believed break down at the nuclear scale. While the scale was off by many orders of magnitude, the approach he advocated was ideally suited for a theory of quantum gravity.
Working with experimental data, R. Dolen, D. Horn and C. Schmid developed some sum rules for hadron exchange. When a particle and antiparticle scatter, virtual particles can be exchanged in two qualitatively different ways. In the s-channel, the two particles annihilate to make temporary intermediate states that fall apart into the final state particles. In the t-channel, the particles exchange intermediate states by emission and absorption. In field theory, the two contributions add together, one giving a continuous background contribution, the other giving peaks at certain energies. In the data, it was clear that the peaks were stealing from the background—the authors interpreted this as saying that the t-channel contribution was dual to the s-channel one, meaning both described the whole amplitude and included the other.
The result was widely advertised by Murray Gell-Mann, leading Gabriele Veneziano to construct a scattering amplitude that had the property of Dolen-Horn-Schmid duality, later renamed world-sheet duality. The amplitude needed poles where the particles appear, on straight line trajectories, and there is a special mathematical function whose poles are evenly spaced on half the real line— the Gamma function— which was widely used in Regge theory. By manipulating combinations of Gamma functions, Veneziano was able to find a consistent scattering amplitude with poles on straight lines, with mostly positive residues, which obeyed duality and had the appropriate Regge scaling at high energy. The amplitude could fit near-beam scattering data as well as other Regge type fits, and had a suggestive integral representation that could be used for generalization.
Over the next years, hundreds of physicists worked to complete the bootstrap program for this model, with many surprises. Veneziano himself discovered that for the scattering amplitude to describe the scattering of a particle that appears in the theory, an obvious self-consistency condition, the lightest particle must be a tachyon. Miguel Virasoro and Joel Shapiro found a different amplitude now understood to be that of closed strings, while Ziro Koba and Holger Nielsen generalized Veneziano's integral representation to multiparticle scattering. Veneziano and Sergio Fubini introduced an operator formalism for computing the scattering amplitudes that was a forerunner of world-sheet conformal theory, while Virasoro understood how to remove the poles with wrong-sign residues using a constraint on the states. Claud Lovelace calculated a loop amplitude, and noted that there is an inconsistency unless the dimension of the theory is 26. Charles Thorn, Peter Goddard and Richard Brower went on to prove that there are no wrong-sign propagating states in dimensions less than or equal to 26.
In 1969, Yoichiro Nambu, Holger Bech Nielsen, and Leonard Susskind recognized that the theory could be given a description in space and time in terms of strings. The scattering amplitudes were derived systematically from the action principle by Peter Goddard, Jeffrey Goldstone, Claudio Rebbi, and Charles Thorn, giving a space-time picture to the vertex operators introduced by Veneziano and Fubini and a geometrical interpretation to the Virasoro conditions.
In 1970, Pierre Ramond added fermions to the model, which led him to formulate a two-dimensional supersymmetry to cancel the wrong-sign states. John Schwarz and André Neveu added another sector to the fermi theory a short time later. In the fermion theories, the critical dimension was 10. Stanley Mandelstam formulated a world sheet conformal theory for both the bose and fermi case, giving a two-dimensional field theoretic path-integral to generate the operator formalism. Michio Kaku and Keiji Kikkawa gave a different formulation of the bosonic string, as a string field theory, with infinitely many particle types and with fields taking values not on points, but on loops and curves.
In 1974, Tamiaki Yoneya discovered that all the known string theories included a massless spin-two particle that obeyed the correct Ward identities to be a graviton. John Schwarz and Joel Scherk came to the same conclusion and made the bold leap to suggest that string theory was a theory of gravity, not a theory of hadrons. They reintroduced Kaluza–Klein theory as a way of making sense of the extra dimensions. At the same time, quantum chromodynamics was recognized as the correct theory of hadrons, shifting the attention of physicists and apparently leaving the bootstrap program in the dustbin of history.
String theory eventually made it out of the dustbin, but for the following decade all work on the theory was completely ignored. Still, the theory continued to develop at a steady pace thanks to the work of a handful of devotees. Ferdinando Gliozzi, Joel Scherk, and David Olive realized in 1976 that the original Ramond and Neveu Schwarz-strings were separately inconsistent and needed to be combined. The resulting theory did not have a tachyon, and was proven to have space-time supersymmetry by John Schwarz and Michael Green in 1981. The same year, Alexander Polyakov gave the theory a modern path integral formulation, and went on to develop conformal field theory extensively. In 1979, Daniel Friedan showed that the equations of motions of string theory, which are generalizations of the Einstein equations of General Relativity, emerge from the Renormalization group equations for the two-dimensional field theory. Schwarz and Green discovered T-duality, and constructed two superstring theories—IIA and IIB related by T-duality, and type I theories with open strings. The consistency conditions had been so strong, that the entire theory was nearly uniquely determined, with only a few discrete choices.
First superstring revolution.
In the early 1980s, Edward Witten discovered that most theories of quantum gravity could not accommodate chiral fermions like the neutrino. This led him, in collaboration with Luis Alvarez-Gaumé to study violations of the conservation laws in gravity theories with anomalies, concluding that type I string theories were inconsistent. Green and Schwarz discovered a contribution to the anomaly that Witten and Alvarez-Gaumé had missed, which restricted the gauge group of the type I string theory to be SO(32). In coming to understand this calculation, Edward Witten became convinced that string theory was truly a consistent theory of gravity, and he became a high-profile advocate. Following Witten's lead, between 1984 and 1986, hundreds of physicists started to work in this field, and this is sometimes called the first superstring revolution.
During this period, David Gross, Jeffrey Harvey, Emil Martinec, and Ryan Rohm discovered heterotic strings. The gauge group of these closed strings was two copies of E8, and either copy could easily and naturally include the standard model. Philip Candelas, Gary Horowitz, Andrew Strominger and Edward Witten found that the Calabi–Yau manifolds are the compactifications that preserve a realistic amount of supersymmetry, while Lance Dixon and others worked out the physical properties of orbifolds, distinctive geometrical singularities allowed in string theory. Cumrun Vafa generalized T-duality from circles to arbitrary manifolds, creating the mathematical field of mirror symmetry. Daniel Friedan, Emil Martinec and Stephen Shenker further developed the covariant quantization of the superstring using conformal field theory techniques. David Gross and Vipul Periwal discovered that string perturbation theory was divergent. Stephen Shenker showed it diverged much faster than in field theory suggesting that new non-perturbative objects were missing.
In the 1990s, Joseph Polchinski discovered that the theory requires higher-dimensional objects, called D-branes and identified these with the black-hole solutions of supergravity. These were understood to be the new objects suggested by the perturbative divergences, and they opened up a new field with rich mathematical structure. It quickly became clear that D-branes and other p-branes, not just strings, formed the matter content of the string theories, and the physical interpretation of the strings and branes was revealed—they are a type of black hole. Leonard Susskind had incorporated the holographic principle of Gerardus 't Hooft into string theory, identifying the long highly excited string states with ordinary thermal black hole states. As suggested by 't Hooft, the fluctuations of the black hole horizon, the world-sheet or world-volume theory, describes not only the degrees of freedom of the black hole, but all nearby objects too.
Second superstring revolution.
In 1995, at the annual conference of string theorists at the University of Southern California (USC), Edward Witten gave a speech on string theory that in essence united the five string theories that existed at the time, and giving birth to a new 11-dimensional theory called M-theory. M-theory was also foreshadowed in the work of Paul Townsend at approximately the same time. The flurry of activity that began at this time is sometimes called the second superstring revolution.
During this period, Tom Banks, Willy Fischler, Stephen Shenker and Leonard Susskind formulated matrix theory, a full holographic description of M-theory using IIA D0 branes. This was the first definition of string theory that was fully non-perturbative and a concrete mathematical realization of the holographic principle. It is an example of a gauge-gravity duality and is now understood to be a special case of the AdS/CFT correspondence. Andrew Strominger and Cumrun Vafa calculated the entropy of certain configurations of D-branes and found agreement with the semi-classical answer for extreme charged black holes. Petr Hořava and Witten found the eleven-dimensional formulation of the heterotic string theories, showing that orbifolds solve the chirality problem. Witten noted that the effective description of the physics of D-branes at low energies is by a supersymmetric gauge theory, and found geometrical interpretations of mathematical structures in gauge theory that he and Nathan Seiberg had earlier discovered in terms of the location of the branes.
In 1997, Juan Maldacena noted that the low energy excitations of a theory near a black hole consist of objects close to the horizon, which for extreme charged black holes looks like an anti-de Sitter space. He noted that in this limit the gauge theory describes the string excitations near the branes. So he hypothesized that string theory on a near-horizon extreme-charged black-hole geometry, an anti-deSitter space times a sphere with flux, is equally well described by the low-energy limiting gauge theory, the N = 4 supersymmetric Yang–Mills theory. This hypothesis, which is called the AdS/CFT correspondence, was further developed by Steven Gubser, Igor Klebanov and Alexander Polyakov, and by Edward Witten, and it is now well-accepted. It is a concrete realization of the holographic principle, which has far-reaching implications for black holes, locality and information in physics, as well as the nature of the gravitational interaction. Through this relationship, string theory has been shown to be related to gauge theories like quantum chromodynamics and this has led to more quantitative understanding of the behavior of hadrons, bringing string theory back to its roots.
Criticisms.
Some critics of string theory say that it is a failure as a theory of everything. Notable critics include Peter Woit, Lee Smolin, Philip Warren Anderson, Sheldon Glashow, Lawrence Krauss, Carlo Rovelli and Bert Schroer. Some common criticisms include:
High energies.
It is widely believed that any theory of quantum gravity would require extremely high energies to probe directly, higher by orders of magnitude than those that current experiments such as the Large Hadron Collider can attain. This is because strings themselves are expected to be only slightly larger than the Planck length, which is twenty orders of magnitude smaller than the radius of a proton, and high energies are required to probe small length scales. Generally speaking, quantum gravity is difficult to test because gravity is much weaker than the other forces, and because quantum effects are controlled by Planck's constant h, a very small quantity. As a result, the effects of quantum gravity are extremely weak.
Number of solutions.
String theory as it is currently understood has a huge number of solutions, called string vacua, and these vacua might be sufficiently diverse to accommodate almost any phenomena we might observe at lower energies.
The vacuum structure of the theory, called the string theory landscape (or the anthropic portion of string theory vacua), is not well understood. String theory contains an infinite number of distinct meta-stable vacua, and perhaps 10520 of these or more correspond to a universe roughly similar to ours—with four dimensions, a high planck scale, gauge groups, and chiral fermions. Each of these corresponds to a different possible universe, with a different collection of particles and forces. What principle, if any, can be used to select among these vacua is an open issue. While there are no continuous parameters in the theory, there is a very large set of possible universes, which may be radically different from each other. It is also suggested that the landscape is surrounded by an even more vast swampland of consistent-looking semiclassical effective field theories, which are actually inconsistent.
Some physicists believe this is a good thing, because it may allow a natural anthropic explanation of the observed values of physical constants, in particular the small value of the cosmological constant. The argument is that most universes contain values for physical constants that do not lead to habitable universes (at least for humans), and so we happen to live in the "friendliest" universe. This principle is already employed to explain the existence of life on Earth as the result of a life-friendly orbit around the medium-sized sun among an infinite number of possible orbits (as well as a relatively stable location in the galaxy).
Background independence.
A separate and older criticism of string theory is that it is not manifestly background-independent — string theory describes perturbative expansions about fixed spacetime backgrounds which means that mathematical calculations in the theory rely on preselecting a background as a starting point. This is because, like many quantum field theories, much of string theory is still only formulated perturbatively, as a divergent series of approximations.
Although the theory, defined as a perturbative expansion on a fixed background, is not background independent, it has some features that suggest non-perturbative approaches would be background-independent—topology change is an established process in string theory, and the exchange of gravitons is equivalent to a change in the background. Since there are dynamic corrections to the background spacetime in the perturbative theory, one would expect spacetime to be dynamic in the nonperturbative theory as well since they would have to predict the same spacetime.
This criticism has been addressed to some extent by the AdS/CFT duality, which is believed to provide a full, non-perturbative definition of string theory in spacetimes with anti-de Sitter space asymptotics. Nevertheless, a non-perturbative definition of the theory in arbitrary spacetime backgrounds is still lacking. Some hope that M-theory, or a non-perturbative treatment of string theory (such as "background independent open string field theory") will have a background-independent formulation.

</doc>
<doc id="28307" url="http://en.wikipedia.org/wiki?curid=28307" title="Sin">
Sin

In Abrahamic contexts, sin is the act of violating God's will. Sin can also be viewed as anything that violates the ideal relationship between an individual and God; or as any diversion from the ideal order for human living. To sin has been defined as "to miss the mark".
Sins fall in a spectrum from minor errors to deadly misdeeds. The Catholic Church regards the least corrupt sins as venial sins—which are part of human living and carry immediate consequences on earth, and, if unrepented for, more painful purgation, assuming the person is destined to heaven, as it is written in the formation letter "Purgatory", "most of the early Fathers of the Church speak of a cleansing fire, though we cannot tell whether this means actual or spiritual fire." Conversely, sins of great evil are mortal sins—which bring the consequence of hell if they are not addressed either through an act of perfect contrition or going to confession about them.
Sins of careless living] are considered destructive and lead to greater sins. Another concept of sin deals with things that exist on Earth but not in [[Heaven]]. Food, for example, while a necessary good for the (health of the [[:wikt:temporal#Adjective|temporal]]) body, is not of ([[eternity|eternal]]) transcendental living and so, because the human being's fixation upon the temporal and its deceitful pleasures distracts and diverts human beings from righteousness, accordingly its "excessive" [[Gluttony|savouring]] is considered a sin.
Many Christians also categorize sin as an inevitable act that was passed down from generation to generation by the common ancestor, Adam. Believers in this doctrine of [[original sin]] hold that like a disease, sin is the curse that poisons the heart of every human thereafter; that human nature is weakened by original sin, and is therefore inclined to sin. Romans 3:22-24 states: "Even the justice of God, by faith of Jesus Christ, unto all and upon all them that believe in him: for there is no distinction: / For all have sinned, and do need the glory of God. / Being justified freely by his grace, through the redemption, that is in Christ Jesus,".
Etymology.
The word derives from "[[Old English]] "syn(n)", for original *"sunjō"... The stem may be related to that of Latin "sons", "sont-is" guilty. In Old English there are examples of the original general sense, ‘offence, wrong-doing, misdeed'". The Biblical terms translated from [[New Testament Greek]] (αμαρτία - amartia) and from Hebrew as "sin" or "syn" originate in [[archery]] and literally refer to missing the "gold" at the centre of a target, but hitting the target, i.e. error. (Archers call not hitting the target at all a "miss".)
Religions.
Bahá'í.
In the [[Bahá'í Faith]], humans are considered naturally good (perfect), fundamentally spiritual beings. Human beings were created because of God's immeasurable love. However, the Bahá'í teachings compare the human heart to a mirror, which, if turned away from the light of the sun (i.e. God), is incapable of receiving God's love.
Buddhism.
[[Buddhism]] does not recognize the idea behind sin, but believes in the principle of "[[Karma in Buddhism|karma]]", whereby [[Dukkha|suffering]] is the inevitable consequence of greed, anger, and delusion (known as the [[Three poisons (Buddhism)|Three poisons]]). While there is no direct Buddhist equivalent of the Abrahamic concept of sin, wrongdoing is recognized in Buddhism. The concept of [[Buddhist ethics]] is [[Consequentialism|consequentialist]] in nature and is not based upon duty towards any deity.
Karma is the direct result of the intention. Action is secondary. Karma whether good or bad is performed with Mind, Body and words would bring pleasant or unpleasant results.
Defilement in mind cause the Karma and Karma defiles the being. One needs to purify his being with [[Satipatthana Sutta|Four Satipatthanas]] to free oneself from the vicious circle. The purification reduces suffering and in the end one reaches [[Nirvana|"Nibbana"]], the ultimate purification. An enlightened being is free of all the suffering and karmas. He would never be born again.
Christianity.
In the [[Old Testament]], some sins were punishable by death in different forms, while most sins are forgiven by burnt offerings. [[Christianity|Christians]] consider the [[Mosaic covenant|Old Covenant]] to be fulfilled by the [[The gospel|Gospel]].
In the [[New Testament]] however, the forgiveness of sin is effected through repentance which involves confessing the sin. Sin is forgiven, when the sinner acknowledges, confesses, and repents for his sin. The unregenerate man is expected to confess his sins to God through repentance in order to be restored to right relationship with God. The unregenerate man has never before been in a favorable relationship with God. When, as a part of his salvation, he is forgiven, he enters into a union with God which abides forever. In the [[Epistle to the Romans]] 6:23, it is mentioned that "the wages of sin is death", which is commonly interpreted as, if one does not repent for his sins, such person will not merit [[Salvation (Christianity)|salvation]]. 
In [[Western Christianity]], sin is believed to alienate the sinner from [[God in Christianity|God]] even though He has extreme love for mankind. It has damaged and completely severed the relationship of humanity to God. That relationship can only be restored through acceptance of [[Christ|Jesus Christ]] and his death on the cross as a [[Satisfaction theory of atonement|satisfactory sacrifice]] for the sins of humanity. Humanity was destined for life with God when Adam disobeyed God. The Bible in [[John 3:16]] says "For God so loved the world, as to give his only begotten Son; that whosoever believeth in him, may not perish, but may have life everlasting."
In [[Eastern Christianity]], sin is viewed in terms of its effects on relationships, both among people and between people and God. Sin is seen as the refusal to follow God's plan and the desire to be "like God" (Genesis 3:5) and thus in direct opposition to God's will (see the account of [[Adam and Eve]] in the [[Book of Genesis]]).
[[Original sin]] is a Western concept that states that sin entered the human world through [[Adam and Eve]]'s sin in the [[Garden of Eden]] and that human beings have since lived with the consequences of this first sin. 
The snake who seduced Eve to eat of the fruit was punished by having it and its kind being made to crawl on the ground and God set an enmity between them and Eve's descendants (Genesis 3:14-15). Eve was punished by the pangs of childbirth and the sorrow of bringing about life that would eventually age, sicken and die (Genesis 3:16). The second part of the curse about being subordinate to Adam originates from her creation from one of Adam's ribs to be his helper (Genesis 2:18-25); the curse now clarifies that she must now obey her husband and desire only him. Adam was punished by having to work endlessly to feed himself and his family. The land would bring forth both thistles and thorns to be cleared and herbs and grain to be planted, nurtured, and harvested. The second part of the curse about his mortality is from his origin as red clay - he is from the land and he and his descendants would return to it when buried after death. When Adam's son Cain slew his brother Abel, he introduced murder into the world (Genesis 4:8-10). For his punishment, God banished him as a fugitive, but first marked him with a sign that would protect him and his descendants from harm (Genesis 4:11-16). 
One concept of sin deals with things that exist on Earth, but not in [[Heaven]]. Food, for example, while a necessary good for the (health of the [[Temporality|temporal]]) body, is not of ([[eternity|eternal]]) transcendental living and therefore its "excessive" [[Gluttony|savoring]] is considered a sin. The unforgivable sin (or [[eternal sin]]) is a sin that can never be forgiven; 
Matthew 12:30-32 :
" 30 He that is not with me, is against me: and he that gathereth not with me, scattereth. 31 And Therefore I say to you: Every sin and blasphemy shall be forgiven men, but the blasphemy of the Spirit shall not be forgiven. 32 And whosoever shall speak a word against the Son of man, it shall be forgiven him: but he that shall speak against the Holy Ghost, it shall not be forgiven him, neither in this world, nor in the world to come."
In [[Catholic Church|Catholic]] Christianity sins are classified into grave sins called [[mortal sin]]s and less serious sins called [[venial sin]]. Mortal sins cause one to lose salvation unless the sinner repents and venial sins require some sort of penance either on Earth or in [[Purgatory]].
Jesus was said to have paid double for the complete mass of sins past, present, and to come in future. Even inevitable sin from our weakness has already been cleansed.
The Lamb of God was and is God Himself and therefore sinless. In the Old Testament, [[Book of Leviticus|Leviticus]] 16:21 states that ‘the laying on of hands’ was the action that the High Priest Aaron was ordered to do yearly by God to take sins of Israel's nation onto a [[sacrificial lamb|spotless young lamb]].
Hinduism.
In [[Hinduism]], the term "sin" ("pāpa" in [[Sanskrit]]) is often used to describe actions that create negative [[karma]] by violating moral and ethical codes, which automatically brings negative consequences. This is similar to Abrahamic sin in the sense that pāpa is considered a crime against the laws of God, which is known as (1) [[Dharma]], or moral order, and (2) one's own self, but another term apradha is used for grave offences.
Islam.
[[Muslims]] see sin ("dhanb, thanb" ذنب) as anything that goes against the commands of God ([[Allah]]). [[Islam]] teaches that sin is an act and not a state of being. The [[Qur'an]] teaches that "the soul is certainly prone to [[evil]], unless the Lord does bestow His Mercy" and that even the [[Prophets of Islam|prophets]] do not [[absolve]] themselves of the [[blame]].#Redirect [[Template:Cite quran]] It is believed that [[Iblis]] (Devil) has a significant role in tempting humankind towards sin.
Sin is also defined in the hadith, a collection of [[Muhammad]]'s sayings. It is reported by An-Nawwas bin Sam'an: 
"The Prophet (Muhammad) said, "Piety is good manner, and sin is that which creates doubt and you do not like people to know it.""—[Muslim]
Wabisah bin Ma’bad reported: 
“I went to Messenger of Allah (SAWS) and he asked me: “Have you come to inquire about piety?” I replied in the affirmative. Then he said: “Ask your heart regarding it. Piety is that which contents the soul and comforts the heart, and sin is that which causes doubts and perturbs the heart, even if people pronounce it lawful and give you verdicts on such matters again and again.”—[Ahmad and Ad-Darmi
In Sunan al-Tirmidhi, a Hadith is narrated:
Allah's apostle said, "Every son of Adam sins, the best of the sinners are those who repent."—Sunan al-Tirmidhi,Hadith no. 2499
In Sahih Muslim, Abu Ayyub al-Ansari and Abu Huraira narrated:
Allah's apostle said," By Him in Whose Hand is my life, if you were not to commit sin, Allah would sweep you out of existence and He would replace (you by) those people who would commit sin and seek forgiveness from Allah, and He would have pardoned them."—Sahih Muslim, 
In Islam, there are several gradations of sin:
One may sincerely repent to God for the wrongs committed and seek forgiveness, as stated in the Quran, "Our Lord! Forgive us our sins, remove from us our iniquities, and take to Yourself our souls in the company of the righteous." (Al-Imran.193/ 3.193).
"Say O my slaves who have transgressed against their own souls despair not of the mercy of God, verily He forgives all sins, verily He is the oft-forgiving, most merciful."— Qur'an, Az-Zumar)
Judaism.
Judaism regards the violation of any of the 613 commandments as a sin. Judaism teaches that to sin is natural thing because there is no man that is perfect and everyone has an inclination to do evil "from his youth".(). The main thing is to try your best. Sin furthermore has many classifications and degrees. Some sins are punishable with death by the court, others with death by heaven, others with lashes, and others without such punishment, but no sins with willful intent go without consequence. Unintentional violations of the mitzvot are not considered as sins, since no one can be punished for something he did not know was wrong. "Sins by error" are considered as less severe sins. When the Temple yet stood in Jerusalem, people would offer sacrifices for their misdeeds. The atoning aspect of Karbanot is carefully circumscribed. For the most part, Karbanot only expiate such "sins by error", that is, sins committed because a person forgot that this thing was a sin. No atonement is needed for violations committed under duress or through lack of knowledge, and for the most part, Karbanot cannot atone for a malicious, deliberate sin. In addition, Karbanot have no expiating effect unless the person making the offering sincerely repents his or her actions before making the offering, and makes restitution to any person who was harmed by the violation.
All willful sin has consequence. The completely righteous suffer for their sins (by humiliation, poverty and suffering that God sends them) in this world and receive their reward in the world to come. Ihe in between (not complete righteous or complete wicked), repent their sins after death and thereafter join the righteous. And the complete wicked cannot correct their sins in this world and hence do not suffer them here, but after death. The very evil do not repent even at the gates of hell. Such people prosper in this world to receive their reward for any good deed, but cannot be cleansed by and hence cannot leave Gehinnom, because they do not or cannot repent. This world can therefore seem unjust where the righteous suffer, while the wicked prosper. Many great thinkers have contemplated this, but God's justice is long, precise and just. 
Shinto.
Evil deeds fall into two categories in Shinto: "amatsu tsumi", "the most pernicious crimes of all", and "kunitsu tsumi", "more commonly called misdemeanors".

</doc>
<doc id="28309" url="http://en.wikipedia.org/wiki?curid=28309" title="Sonic Youth">
Sonic Youth

Sonic Youth was an American rock band from New York City, formed in 1981. Founding members Thurston Moore (guitar, vocals), Kim Gordon (bass guitar, vocals, guitar) and Lee Ranaldo (guitar, vocals) remained together for the entire history of the band, while Steve Shelley (drums) followed a series of short-term drummers in 1985, and rounded out the core line-up. In their early career Sonic Youth were associated with the no wave art and music scene in New York City. Part of the first wave of American noise rock groups, the band carried out their interpretation of the hardcore punk ethos throughout the evolving American underground that focused more on the DIY ethic of the genre rather than its specific sound.
The band experienced relative commercial success and critical acclaim throughout their existence, continuing partly into the new millennium, including signing to major label DGC in 1990 and headlining the 1995 Lollapalooza festival. Sonic Youth have been praised for having "redefined what rock guitar could do", using a wide variety of unorthodox guitar tunings and preparing guitars with objects like drum sticks and screwdrivers to alter the instruments' timbre. The band is considered to be a pivotal influence on the alternative and indie rock movements.
In 1999 their music reached a new audience interested in 20th-century classical music and experimental music with the release of "", a double album of covers of avant-garde recordings that featured works by avant-garde classical composers such as John Cage, Yoko Ono, Steve Reich, Pauline Oliveros, George Maciunas, Cornelius Cardew, Nicolas Slonimsky and Christian Wolff as played by Sonic Youth along with several collaborators from the modern avant-garde music scene, such as Christian Marclay, William Winant, Wharton Tiers, Takehisa Kosugi and others.
In 2011 Ranaldo announced that the band was "ending for a while" following the separation of married couple Gordon and Moore. Thurston Moore updated and clarified the position in May 2014: "Sonic Youth is on hiatus. The band is a democracy of sorts, and as long as Kim and I are working out our situation, the band can’t really function reasonably." Gordon refers several times in her 2015 autobiography "Girl in a Band" to the band having "split up".
History.
Formation and early history: 1977–1981.
Shortly after guitarist Thurston Moore moved to New York City in early 1977, he formed a group, Room Tone, with his roommates, who would soon change their name to the Coachmen. After the breakup of the Coachmen, Moore began jamming with Stanton Miranda, whose band, CKM, featured Kim Gordon. Moore and Gordon formed a band, appearing under names like Male Bonding and Red Milk and the Arcadians, before settling on Sonic Youth just before June 1981. The name came from combining the nickname of MC5's Fred "Sonic" Smith with "Youth" from reggae artist Big Youth. Gordon later recalled that "as soon as Thurston came up with the name Sonic Youth, a certain sound that was more of what we wanted to do came about." The band played Noise Fest in June 1981 at New York's White Columns gallery, where Lee Ranaldo was playing as a member of Glenn Branca's electric guitar ensemble. Their performance impressed Moore, who described them as "the most ferocious guitar band that I had ever seen in my life", and he invited Ranaldo to join the band. The new threesome played three songs at the festival later in the week without a drummer. Each band member took turns playing the drums, until they met drummer Richard Edson.
Early releases: 1982–1985.
Branca signed Sonic Youth as the first act on his record label Neutral Records. In December 1981 the group recorded five songs in a studio in New York's Radio City Music Hall. The material was released as the "Sonic Youth (EP)" that, while largely ignored, was sent to a few key members of the US press, who gave it uniformly favorable reviews. After their first release, Edson quit the group for an acting career and was replaced by Bob Bert.
During their early days as part of the New York music scene, Sonic Youth formed a friendship with noisy New Yorkers Swans. The bands came to share the same rehearsal space, and Sonic Youth embarked on its first tour, a two-week journey through the southern United States starting in November 1982, supporting Swans. During a second tour with Swans of the Midwest the following month, tensions ran high and Moore constantly criticized Bert's drumming, which he felt was not "in the pocket". Bert was fired afterwards and replaced by Jim Sclavunos, who played drums on the band's first studio album, 1983's "Confusion Is Sex". Sonic Youth set up a two-week tour of Europe for the summer of 1983. Sclavunos, however, quit after only a few months. The group asked Bert to rejoin, and he agreed, on the condition that he would not be fired again after the tour's conclusion.
Sonic Youth found themselves well received in Europe, but the New York press largely ignored the local noise rock scene. Eventually, as the press began to take notice of the genre, Sonic Youth was grouped along with bands like Big Black, the Butthole Surfers and Pussy Galore under the "pigfucker" label by "Village Voice" music critic Robert Christgau. (Christgau saw these bands as sharing an abrasive, noisy and confrontational aesthetic.) Based on this classification, and on a negative live review by Christgau, a feud developed between Moore and the critic, with Moore renaming the song "Kill Yr Idols" to "I Killed Christgau With My Big Fucking Dick" before the two sorted out their differences amicably.
During another tour of Europe in 1984, Sonic Youth's disastrous London debut (where the band's equipment malfunctioned and Moore consequently destroyed the equipment onstage in frustration) actually resulted in rave reviews in "Sounds" and the "NME". By the time they returned to New York, they were so popular they played shows practically every week. That same year, Moore and Gordon were married, and Sonic Youth released "Bad Moon Rising", a self-described "Americana" album that served as a reaction to the state of the nation at the time. The album, recorded by Martin Bisi, was built around transitional pieces that Moore and Ranaldo had come up with in order to take up time onstage while the other guitarist was busy tuning his instrument; as a result, there are almost no breaks between the songs on the record, which feature walls of feedback and pounding rhythms. "Bad Moon Rising" featured an appearance by Lydia Lunch on the album's single "Death Valley '69", inspired by the Charles Manson Family murders. In contrast to their abrasive, atonal material of the time, the band considered the song relatively conventional. Due to a falling-out with Branca over disputed royalty payments from their Neutral releases, they were signed to Homestead Records by Gerard Cosloy and by Blast First in the UK (which founder Paul Smith created simply so he could distribute the band's records in Europe). While even the New York press ignored "Bad Moon Rising" upon its release, now viewing the band as too arty and pretentious, Sonic Youth was becoming quite critically acclaimed in the United Kingdom, where the new album had sold 5,000 copies in just six months.
Claiming he was bored with playing "Bad Moon Rising" live in its entirety for over a year, Bert quit the group and was replaced by Steve Shelley, formerly of the punk group The Crucifucks. The band was so impressed with Shelley's drumming after seeing him play live they hired him without an audition. Bert remained on good terms with the group; he and Shelley both appeared in the music video for "Death Valley '69", as Bert performed the drums on the song, but Shelley was the group's drummer when the video was made.
SST and Enigma: 1986–1989.
Sonic Youth had a long fascination with influential indie label SST Records. Ranaldo said, "It was the first record company we were on that we really would have given anything to be on." Sonic Youth eventually signed to the label in early 1986 and began recording "EVOL" with Martin Bisi in March of that year.
"EVOL" itself represented an evolution of sorts for the band: in addition to increasingly melodic material and the impact of new drummer Shelley's playing, the record also dealt with themes of celebrity, particularly with songs like "Madonna, Sean, and Me" (also known as "Expressway to Yr. Skull" and called "a classic" by Neil Young) and "Marilyn Moore". Signing to SST catapulted the band on to a national stage, something that did not happen to their peers in the New York underground. The mainstream music press subsequently began to take notice of the band. Robert Palmer of "The New York Times" declared that Sonic Youth was "making the most startlingly original guitar-based music since Jimi Hendrix" and even "People" praised "EVOL" as the "aural equivalent of a toxic waste dump." "EVOL" is also notable for a guest appearance by bass guitarist Mike Watt, a friend whom the band coaxed to come to New York after he was deeply depressed by the death of his bandmate, D. Boon.
On 1987's "Sister", Sonic Youth continued refining their blend of pop song structures with uncompromising experimentalism. Another loose concept album, "Sister" is partly inspired by the life and works of science fiction writer Philip K. Dick (the "sister" of the title was Dick's fraternal twin, who died shortly after her birth, and whose memory haunted Dick his entire life). "Sister" sold 60,000 copies and received very positive reviews, becoming the first Sonic Youth album to crack the Top 20 of the "Village Voice"'s Pazz & Jop critics poll.
Despite the critical success, the band was becoming increasingly dissatisfied with SST due to concerns about payment and other administrative practices. Sonic Youth decided to release their next record on Enigma Records, which was distributed by Capitol Records and partly owned by EMI. The 1988 double LP "Daydream Nation" was a critical success that earned Sonic Youth substantial acclaim. The album came in second on the "Village Voice" Pazz & Jop poll and topped the year-end album lists of the "NME", "CMJ" and "Melody Maker". In 2005, it was one of 50 recordings chosen that year by the Library of Congress to be added to the National Recording Registry. The lead single from the album, "Teen Age Riot", was the first song from the band to reach significant success, receiving heavy airplay in modern and college rock stations. A number of prominent music periodicals including "Rolling Stone" hailed "Daydream Nation" as one of the best albums of the decade and named Sonic Youth as the "Hot Band" in its "Hot" issue. Unfortunately, distribution problems arose and "Daydream Nation" was often difficult to find in stores. Moore considered Enigma a "cheap-jack Mafioso outfit" and the band began looking for a major label deal.
Major label career and alternative icons: 1990–1999.
In 1990, Sonic Youth released "Goo" (their first album for Geffen), which featured the single "Kool Thing" on which Chuck D from rap group Public Enemy guested. "Kool Thing" was later featured in the Hal Hartley film "Simple Men" and the video game "" and was made available as a paid download for the "Rock Band" video game. The record is considered much more accessible than their previous work.
In 1992, the band released "Dirty" on the DGC label. Their influence as tastemakers continued with their discovery of acclaimed skateboard video director Spike Jonze, who they recruited for the video for "100%", which also featured skateboarder turned actor Jason Lee. This song, along with the Gordon tune "JC", contains lyrical references to the murder of Joe Cole, a friend who worked with Black Flag as a roadie. The album features artwork by Los Angeles-based artist Mike Kelley. "Dirty" features a guest appearance by Ian MacKaye (Minor Threat, Fugazi) playing guitar on the track "Youth Against Fascism".
In 1993, the band contributed the track "Burning Spear" to the AIDS benefit album "No Alternative", produced by the Red Hot Organization.
In 1994, the band released "Experimental Jet Set, Trash and No Star", their best-charting release in the United States (until 2009's "The Eternal"), which peaked at No. 34 on the "Billboard" 200. The album was filled with low-key melodies and even produced a hit single, "Bull in the Heather". Moore and Gordon's daughter, Coco Hayley Gordon Moore, was born earlier in the year, and many of the songs from the album were never played live because there was never a full tour to support the album due to Gordon's pregnancy. In 1994, the band also released a cover of The Carpenters' 1971 hit "Superstar" for the tribute album "If I Were a Carpenter"; their version would later be featured in the 2007 film "Juno".
The band headlined the 1995 Lollapalooza festival with alternative rock groups Hole and Pavement. By that time, alternative rock had gained considerable mainstream attention, and the festival was parodied on "The Simpsons" 1996 episode "Homerpalooza", which featured voiceovers from the band. They also performed the final credits theme for that episode.
Gordon collaborated in Free Kitten, and started a clothing label X-Girl, based in Los Angeles. Ranaldo and Moore played with many experimental/noise musicians, including William Hooker, Nels Cline, Tom Surgal, Don Dietrich, Christian Marclay, DJ Spooky and Mission of Burma, among others. Shelley started up the Smells Like Records record label, as well as playing in backing bands for Chan Marshall (Cat Power) and Two Dollar Guitar. Thurston Moore also made several guest appearances on DJ Spooky's albums, which combined rock and hip hop.
From Sonic Youth's earliest days, Gordon had occasionally played guitar with the group. Around the time of "A Thousand Leaves" and "Washing Machine", she began playing guitar more frequently, resulting in a three-guitar and drums lineup. These songs were something of a shift for the group's sound, and would lead to the introduction of a fifth member a few years later.
The "Washing Machine" album began a shift in the band away from their punk roots, seeing them working with longer jam sections. Two tracks showed the new approach in full force – the title track "Washing Machine", which is just under 10 minutes long, and "The Diamond Sea", which is over 19 minutes long.
During the late 1990s and early 2000s, the band began releasing a series of highly experimental records on their own Hoboken, New Jersey-based label SYR. The music was mostly instrumental and improvised, and the album and track titles and even the liner notes and credits were in different languages: ' was in French, ' in Dutch, ' in Esperanto, "SYR5" in Japanese, ' in Lithuanian, ' in Arpitan and ' in Danish. "SYR3" was the first to feature Jim O'Rourke, who went on to become an official band member. Tracks from the SYR releases featured in their live sets in 1998, particularly "Anagrama" from "SYR1", and tracks from "SYR2" formed the basis of two tracks from "A Thousand Leaves".
Released in 1998, "A Thousand Leaves" has a dreamy, semi-improvised feel, and features extended jam sections on tracks such as "Wildflower Soul" and "Female Mechanic Now on Duty". The album also features two Ranaldo-led numbers, "Hoarfrost" and "Karen Koltrane". The only single to be released from this album, "Sunday", was accompanied by a video directed by Harmony Korine and starring Macaulay Culkin.
"" was subtitled "Goodbye, 20th Century" and featured works by avant-garde classical composers such as John Cage, Yoko Ono, Steve Reich, and Christian Wolff played by Sonic Youth along with several collaborators from the modern avant-garde music scene such as Christian Marclay, William Winant, Wharton Tiers, Takehisa Kosugi and others. The album received mixed reviews, but some critics praised the group's efforts at popularizing and reinterpreting the composers' works.
Later DGC period: 2000–2006.
On July 4, 1999, Sonic Youth's instruments, amps and gear were stolen in the middle of the night while on tour in Orange, California (see on Usenet). Forced to start from scratch with new instruments, they recorded "NYC Ghosts & Flowers" and opened for Pearl Jam during the east coast leg of their 2000 tour.
In 2001 Sonic Youth collaborated with French avant-garde singer and poet Brigitte Fontaine in Fontaine's album "Kékéland".
When the September 11, 2001 attacks occurred, several members of the band were blocks away; Jim at their NYC studio (Echo Canyon on Murray Street) and Ranaldo and his wife Leah nearby at home. After the attacks, they curated the first U.S. outing of the All Tomorrow's Parties music festival in L.A. The festival was originally scheduled for October, but it was delayed until March the following year due to the attacks.
In the summer of 2002, "Murray Street" was released; many critics heralded a "return to form for SY", seemingly revitalized by the addition of Jim O'Rourke, who became a full member during this period, playing bass guitar, guitar and occasionally synthesizer. It was during this period that the band were filmed for Scott Crary's documentary "Kill Your Idols", depicting Sonic Youth as a key influence upon the post-punk revival then happening in New York. This was followed in 2004 by the release of "Sonic Nurse", an album similar in sound and approach to its immediate predecessor that also received positive reviews. "Pattern Recognition", a song named after the 2003 William Gibson novel, finds the band once again using Gibson's work for inspiration. The band also showed their pop culture commentary and sense of humor with the track "Mariah Carey and the Arthur Doyle Hand Cream", a faster-tempo song sung by Gordon, which spoofed Carey's life, including her short-lived relationship with rapper Eminem, which originally appeared on a 2003 split 7" with Erase Errata (on the album cover, the reference to "Mariah Carey" in the title was replaced by "Kim Gordon" due to potential copyright issues.) "Sonic Nurse" had decent sales, in part due to performances on TV talk shows including "Late Night with Conan O'Brien" and "The Tonight Show with Jay Leno". The band was also slated to perform in 2004's Lollapalooza tour along with acts such as Pixies and The Flaming Lips, but the concert was canceled due to lackluster ticket sales. When the band toured later that year, they played extensively from their 1980s catalog.
On October 6, 2005, "LA CityBeat" reported that some of the gear stolen in 1999 was surprisingly recovered and that it might be used for recording of the next album, then tentatively titled "Sonic Life". The report also said that Jim O'Rourke might be leaving the band soon; his departure was confirmed by Lee Ranaldo in an interview with Pitchfork Media. In May 2006, the group announced on their website that ex-Pavement member Mark Ibold would play bass for the band on their upcoming tour.
"Rather Ripped" was released in Europe on June 5, 2006 and in the USA on June 13, 2006. Compared to previous Sonic Youth recordings, the album features many short, conventionally-structured, melodic songs and fewer feedback-fuelled left-field improvisations (the band's avant-garde tendencies nowadays have been largely exorcised through SYR releases and solo outings rather than band albums). Later that summer, Sonic Youth played the 2006 Bonnaroo Festival, as well as Lollapalooza, promoting the album. In December, "Rolling Stone" made it their number three Album of the Year 2006.
The band released "" in December 2006. It features tracks previously available only on vinyl, limited-release compilations, B-sides to international singles, and some material that had never before been released. This marked the band's final Geffen release.
Independent agents and signing to Matador: 2007–2011.
In April, 2007, the band became one of the earlier big-name rock bands to play China when they were brought on a China tour by Beijing and Shanghai based company Split Works.
In 2008, the band independently re-released "Master=Dik" for the first time on CD, exclusively at their online store. They also released two more editions to the SYR series, ' and '. "SYR7" was released on April 22, and "SYR8" was released July 28. On June 10, they also released a compilation album on Starbucks Music, called "Hits Are for Squares". The first fifteen tracks were selected by other celebrities, and track sixteen, "Slow Revolution", is a new recording by Sonic Youth.
Also in June, the band was the subject of an intensively researched biography, "Goodbye 20th Century: A Biography of Sonic Youth", written by music journalist David Browne. The book featured new interviews with the band as well as nearly one-hundred friends, family members and peers. It was published by Da Capo and included over sixty rare photos.
On August 30, 2008, the band premiered two new songs at the final McCarren Park Pool show. Thurston Moore stated that in November the band would start recording a new studio album. The band did not continue their contract with Geffen, being discontented at the way Geffen handled their last four or five albums. On September 8, it was confirmed by Matador's Matablog that Sonic Youth would release its sixteenth album (titled "The Eternal") in spring, 2009, on Matador Records. In December, it was also announced that the group had recently collaborated with John Paul Jones (of Led Zeppelin fame) on a piece that served as the soundtrack for a new Merce Cunningham Dance Company piece. This work was performed by the company on April 16–19, 2009, at the Brooklyn Academy of Music in celebration of Cunningham's 90th birthday. On February 12, 2009 the band revealed the cover art for "The Eternal" via their website and blog. The album, produced by John Agnello, was released on June 9. With the release, Matador Records also offered an exclusive live LP only available to those who preordered the album. The band scored and composed the soundtrack of the French thriller-drama "Simon Werner a Disparu", which premiered in May, 2010 as part of the Cannes International Film Festival. The soundtrack has been released in 2011 as "SYR9: Simon Werner a Disparu", the latest edition of the SYR series.
Band split (2011).
On October 14, 2011, Kim Gordon and Thurston Moore announced that they separated after 27 years of marriage through a statement by Matador. Matador also explained that plans for the band remained "uncertain", despite previously hinting that they would record new material later in the year.
In an interview on November 28, 2011, Lee Ranaldo said that Sonic Youth are "ending for a while". "I'm feeling optimistic about the future no matter what happens at this point", Ranaldo said. "It was a pretty good tour overall. I mean, there was a little bit of tiptoeing around and some different situations with the travelling – you know, they're not sharing a room any more or anything like that [...] It remains to be seen at this point what happens. I think they are certainly the last shows for a while and I guess I'd just leave it at that." Ranaldo also suggested there are no plans for Sonic Youth to record new material. "There's tons and tons of archival projects and things like that still going on," he said. "I'm just happy right now to let the future take its course."
In November 2013, Ranaldo said in response to the question of a possible reunion, "I fear not. Everybody is busy with their own projects, besides that Thurston and Kim aren't getting along together very well since their split. I think you can put a cross behind Sonic Youth, same as you can put it behind the names Mike Kelley and Lou Reed. Let them all rest in peace." In her 2015 autobiography "Girl in a Band", Gordon refers several times to the band having "split up" for good.
Musical style and influences.
Alternative tunings.
Sonic Youth's sound relied heavily on the use of alternative tunings. Scordatura on stringed instruments has been used for centuries and alternative guitar tunings had been used for decades in blues music, and to a limited degree in rock music (such as with Lou Reed's Ostrich guitar on "The Velvet Underground & Nico"). Azerrad writes that early in their career,
[Sonic Youth] could only afford cheap guitars, and cheap guitars "sounded" like cheap guitars. But with weird tunings or something jammed under a particular fret, those humble instruments could sound rather amazing – bang a drum stick on a cheap Japanese Stratocaster copy in the right tuning, crank the amplifier to within an inch of its life and it will sound like church bells.
The tunings were painstakingly developed by Moore and Ranaldo during the band's rehearsals; Moore once reported that the odd tunings were an attempt to introduce new sounds: "When you're playing in standard tuning all the time [...] things sound pretty standard." Rather than re-tune for every song, Sonic Youth generally used a particular guitar for one or two songs, and would take dozens of instruments on tour. This would be the source of much trouble for the band, as some songs rely on specific guitars that have been uniquely prepared.
Influences.
Besides The Stooges, Branca, Patti Smith, Wire, Public Image Ltd and French avant-gardist Brigitte Fontaine, another influence was 1980s-era hardcore punk; after seeing Minor Threat perform in May 1982, Moore declared them "the greatest live band I have ever seen". He also saw The Faith performing in 1981 and had a strong admiration towards their only two records, a split LP with fellow Washington, D.C. hardcore band Void and the EP "Subject to Change". While recognizing that their own music was very different from hardcore, Moore and Gordon, especially, were impressed by hardcore's speed and intensity, and by the nationwide network of musicians and fans. "It was great", said Moore, "the whole thing with slam dancing and stage diving, that was far more exciting than pogoing and spitting. [...] I thought hardcore was very musical and very radical."
Thurston Moore and Lee Ranaldo expressed on numerous occasions their admiration for the music of Joni Mitchell, such as this quote by Thurston Moore: "Joni Mitchell! I've used elements of her songwriting and guitar playing, and no one would ever know about it." Additionally, as with Sonic Youth, Joni Mitchell has always used a number of alternative tunings. The band named a song after her, "Hey Joni".
Members of the band have also maintained relationships with other avant-garde artists from other genres and even other media, drawing influence from the work of John Cage and Henry Cowell. For a 1988 John Peel Session, Sonic Youth covered three songs by The Fall and "Victoria" by The Kinks, also covered by The Fall. Sonic Youth has featured album art by several well-known avant-garde visual artists, such as Mike Kelley, Tony Oursler and Gerhard Richter, whose paintings from his "Candles" series was used as artwork on "Daydream Nation".
Musical instruments.
Sonic Youth's sound was generated by their vast collection of unique and exclusive instruments; from guitars altered to meet the needs of the unique tunings employed to effects and amps designed to around their whims, Sonic Youth used a wide array of custom instruments in creating their sound. The Sound Destruction Device is an example of an effect designed for them, in which a fuzz pedal with two gain stages and gate creates oscillating distortion sounds.

</doc>
<doc id="28313" url="http://en.wikipedia.org/wiki?curid=28313" title="SCSI">
SCSI

Small Computer System Interface (SCSI, ) is a set of standards for physically connecting and transferring data between computers and peripheral devices. The SCSI standards define commands, protocols and electrical and optical interfaces. SCSI is most commonly used for hard disk drives and tape drives, but it can connect a wide range of other devices, including scanners and CD drives, although not all controllers can handle all devices. The SCSI standard defines command sets for specific peripheral device types; the presence of "unknown" as one of these types means that in theory it can be used as an interface to almost any device, but the standard is highly pragmatic and addressed toward commercial requirements.
History.
SCSI was derived from "SASI", the "Shugart Associates System Interface", developed circa 1978 and publicly disclosed in 1981. A SASI controller provided a bridge between a hard disk drive's low-level interface and a host computer, which needed to read blocks of data. SASI controller boards were typically the size of a hard disk drive and were usually physically mounted to the drive's chassis. SASI, which was used in mini- and early microcomputers, defined the interface as using a 50-pin flat ribbon connector which was adopted as the SCSI-1 connector. SASI is a fully compliant subset of SCSI-1 so that many, if not all, of the then-existing SASI controllers were SCSI-1 compatible.
Larry Boucher is considered to be the "father" of SASI and SCSI due to his pioneering work first at Shugart Associates and then at Adaptec.
Until at least February 1982, ANSI developed the specification as "SASI" and "Shugart Associates System Interface;" however, the committee documenting the standard would not allow it to be named after a company. Almost a full day was devoted to agreeing to name the standard "Small Computer System Interface," which Boucher intended to be pronounced "sexy", but ENDL's Dal Allan pronounced the new acronym as "scuzzy" and that stuck.
A number of companies such as NCR Corporation, Adaptec and Optimem were early supporters of the SCSI standard. The NCR facility in Wichita, Kansas is widely thought to have developed the industry's first SCSI chip; it worked the first time.
The "small" part in SCSI is historical; since the mid-1990s, SCSI has been available on even the largest of computer systems.
Since its standardization in 1986, SCSI has been commonly used in the Amiga, Apple Macintosh and Sun Microsystems (now part of Oracle Corporation) computer lines and PC server systems. Apple started using Parallel ATA (also known as "IDE") for its low-end machines with the Macintosh Quadra 630 in 1994, and added it to its high-end desktops starting with the Power Macintosh G3 in 1997. Apple dropped on-board SCSI completely (in favor of IDE and FireWire) with the (Blue & White) Power Mac G3 in 1999, while still offering a PCI controller card as an option on up to the Power Macintosh G4 (AGP Graphics) models. Sun switched its lower-end range to Serial ATA (SATA). Commodore included a SCSI interface on the Amiga 3000/3000T systems and it was an add-on to previous Amiga 500/2000 models. Starting with the Amiga 600/1200/4000 systems Commodore switched to the IDE interface. SCSI has never been popular in the low-priced IBM PC world, owing to the lower cost and adequate performance of ATA hard disk standard. However, SCSI drives and even SCSI RAIDs became common in PC workstations for video or audio production.
Recent versions of SCSI—&#X200B;Serial Attached SCSI (SAS), SCSI-over-Fibre Channel Protocol (FCP), and USB Attached SCSI (UAS)—&#X200B;break from the traditional parallel SCSI standards and perform data transfer via serial communications. Although much of the SCSI documentation talks about the parallel interface, all modern development efforts use serial interfaces. Serial interfaces have a number of advantages over parallel SCSI, including higher data rates, simplified cabling, longer reach, and improved fault isolation. The primary reason for the shift to serial interfaces is the clock skew issue of high speed parallel interfaces, which makes the faster variants of parallel SCSI susceptible to problems caused by cabling and termination. iSCSI preserves the basic SCSI paradigm, especially the command set, almost unchanged, through embedding of SCSI-3 over TCP/IP, predominantly on Ethernet which is also of serial nature.
SCSI is popular on high-performance workstations, servers, and storage appliances. RAID subsystems on servers had almost always used some kind of SCSI hard disk drives (initially Parallel SCSI, recently SAS and Fibre Channel), though a number of manufacturers offer SATA-based RAID subsystems as a cheaper option. Moreover, SAS offers compatibility with SATA devices, what together with the existence of nearline SAS (NL-SAS) drives creates a much broader range of options for RAID subsystems. Instead of SCSI, modern desktop computers and notebooks typically use SATA interface for internal hard disk drives, and USB, eSATA, and FireWire connections for external devices.
Interfaces.
SCSI is available in a variety of interfaces. The first was parallel SCSI (also called SCSI Parallel Interface SPI), which uses a parallel bus design. From 2005 onwards, SPI was being replaced by Serial Attached SCSI (SAS), which uses a serial design but retains other aspects of the technology. Many other interfaces which do not rely on complete SCSI standards still implement the SCSI command protocol; others drop physical implementation entirely while retaining the SCSI architectural model. iSCSI, for example, uses TCP/IP as a transport mechanism. Most often, it is transported over Gigabit Ethernet or faster network links.
SCSI interfaces have often been included on computers from various manufacturers for use under Microsoft Windows, Mac OS, Unix, Commodore Amiga and Linux operating systems, either implemented on the motherboard or by the means of plug-in adaptors. With the advent of SAS and SATA drives, provision for parallel SCSI on motherboards was discontinued.
Parallel SCSI.
Initially, the "SCSI Parallel Interface" (SPI) was the only interface using the SCSI protocol. Its standardization started as a single-ended 8-bit bus in 1986, transferring up to 5 MB/s, and evolved into a low-voltage differential 16-bit bus capable of up to 320 MB/s. The last SPI-5 standard from 2003 also defined a 640 MB/s speed which failed to be realized.
Parallel SCSI specifications include several synchronous transfer modes for the parallel cable, and an asynchronous mode. The asynchronous mode is a classic request/acknowledge protocol, which allows systems with a slow bus or simple systems to also use SCSI devices. Faster synchronous modes are used more frequently.
Cabling.
SCSI Parallel Interface.
Internal parallel SCSI cables are usually ribbons, with two or more 50–, 68–, or 80–pin connectors attached. External cables are typically shielded (but may not be), with 50– or 68–pin connectors at each end, depending upon the specific SCSI bus width supported. The 80–pin Single Connector Attachment (SCA) is typically used for hot-pluggable devices
Fibre Channel.
Fibre Channel can be used to transport SCSI information units, as defined by the Fibre Channel Protocol for SCSI (FCP). These connections are hot-pluggable and are usually implemented with optical fiber.
Serial attached SCSI.
Serial attached SCSI (SAS) uses a modified Serial ATA data and power cable.
iSCSI.
iSCSI (Internet Small Computer System Interface) usually uses Ethernet connectors and cables as its physical transport, but can run over any physical transport capable of transporting IP.
SRP.
The SCSI RDMA Protocol (SRP) is a protocol that specifies how to transport SCSI commands over a reliable RDMA connection. This protocol can run over any RDMA-capable physical transport, e.g. InfiniBand or Ethernet when using RoCE or iWARP.
USB Attached SCSI.
USB Attached SCSI allows SCSI devices to use the Universal Serial Bus.
Automation/Drive Interface.
The Automation/Drive Interface − Transport Protocol (ADT) is used to connect removable media devices, such as tape drives, with the controllers of the libraries (automation devices)
in which they are installed. The ADI standard specifies the use of RS-422 for the physical connections. The second-generation ADT-2 standard defines iADT, use of the ADT protocol
over IP (Internet Protocol) connections, such as over Ethernet. The Automation/Drive Interface − Commands standards (ADC, ADC-2, and ADC-3) define SCSI commands for these installations.
SCSI command protocol.
In addition to many different hardware implementations, the SCSI standards also include an extensive set of command definitions. The SCSI command architecture was originally defined for parallel SCSI buses but has been carried forward with minimal change for use with iSCSI and serial SCSI. Other technologies which use the SCSI command set include the ATA Packet Interface, USB Mass Storage class and FireWire SBP-2.
In SCSI terminology, communication takes place between an initiator and a target. The initiator sends a command to the target, which then responds. SCSI commands are sent in a Command Descriptor Block (CDB). The CDB consists of a one byte operation code followed by five or more bytes containing command-specific parameters.
At the end of the command sequence, the target returns a status code byte, such as 00h for success, 02h for an error (called a Check Condition), or 08h for busy. When the target returns a Check Condition in response to a command, the initiator usually then issues a SCSI Request Sense command in order to obtain a key code qualifier (KCQ) from the target. The Check Condition and Request Sense sequence involves a special SCSI protocol called a Contingent Allegiance Condition.
There are 4 categories of SCSI commands: N (non-data), W (writing data from initiator to target), R (reading data), and B (bidirectional). There are about 60 different SCSI commands in total, with the most commonly used being:
Each device on the SCSI bus is assigned a unique SCSI identification number or ID. Devices may encompass multiple logical units, which are addressed by logical unit number (LUN). Simple devices have just one LUN, more complex devices may have multiple LUNs.
A "direct access" (i.e. disk type) storage device consists of a number of logical blocks, addressed by Logical Block Address (LBA). A typical LBA equates to 512 bytes of storage. The usage of LBAs has evolved over time and so four different command variants are provided for reading and writing data. The Read(6) and Write(6) commands contain a 21-bit LBA address. The Read(10), Read(12), Read Long, Write(10), Write(12), and Write Long commands all contain a 32-bit LBA address plus various other parameter options.
The capacity of a "sequential access" (i.e. tape-type) device is not specified because it depends, amongst other things, on the length of the tape, which is not identified in a machine-readable way. Read and write operations on a sequential access device begin at the current tape position, not at a specific LBA. The block size on sequential access devices can either be fixed or variable, depending on the specific device. Tape devices such as half-inch 9-track tape, DDS (4 mm tapes physically similar to DAT), Exabyte, etc., support variable block sizes.
Device identification.
On a parallel SCSI bus, a device (e.g. host adapter, disk drive) is identified by a "SCSI ID", which is a number in the range 0–7 on a narrow bus and in the range 0–15 on a wide bus. On earlier models a physical jumper or switch controls the SCSI ID of the initiator (host adapter). On modern host adapters (since about 1997), doing I/O to the adapter sets the SCSI ID; for example, the adapter often contains a BIOS program that runs when the computer boots up and that program has menus that let the operator choose the SCSI ID of the host adapter. Alternatively, the host adapter may come with software that must be installed on the host computer to configure the SCSI ID. The traditional SCSI ID for a host adapter is 7, as that ID has the highest priority during bus arbitration (even on a 16 bit bus).
The SCSI ID of a device in a drive enclosure that has a backplane is set either by jumpers or by the slot in the enclosure the device is installed into, depending on the model of the enclosure. In the latter case, each slot on the enclosure's back plane delivers control signals to the drive to select a unique SCSI ID. A SCSI enclosure without a back plane often has a switch for each drive to choose the drive's SCSI ID. The enclosure is packaged with connectors that must be plugged into the drive where the jumpers are typically located; the switch emulates the necessary jumpers. While there is no standard that makes this work, drive designers typically set up their jumper headers in a consistent format that matches the way that these switches implement.
Note that a SCSI target device (which can be called a "physical unit") is often divided into smaller "logical units." For example, a high-end disk subsystem may be a single SCSI device but contain dozens of individual disk drives, each of which is a logical unit. Further, a RAID array may be a single SCSI device, but may contain many logical units, each of which is a "virtual" disk—a stripe set or mirror set constructed from portions of real disk drives. The SCSI ID, WWN, etc. in this case identifies the whole subsystem, and a second number, the logical unit number (LUN) identifies a disk device (real or virtual) within the subsystem.
It is quite common, though incorrect, to refer to the logical unit itself as a "LUN." Accordingly, the actual LUN may be called a "LUN number" or "LUN id".
Setting the bootable (or first) hard disk to SCSI ID 0 is an accepted IT community recommendation. SCSI ID 2 is usually set aside for the floppy disk drive while SCSI ID 3 is typically for a CD-ROM drive.
In modern SCSI transport protocols, there is an automated process for the "discovery" of the IDs. The SSA initiator (normally the host computer through the 'host adaptor') "walk the loop" to determine what devices are connected and then assigns each one a 7-bit "hop-count" value. Fibre Channel – Arbitrated Loop (FC-AL) initiators use the LIP (Loop Initialization Protocol) to interrogate each device port for its WWN (World Wide Name). For iSCSI, because of the unlimited scope of the (IP) network, the process is quite complicated. These discovery processes occur at power-on/initialization time and also if the bus topology changes later, for example if an extra device is added.
Device Type.
While all SCSI controllers can work with read/write storage devices, i.e. disk and tape, some will not work with some other device types; older controllers are likely to be more limited, sometimes by their driver software, and more Device Types were added as SCSI evolved. Even CD-ROMs are not handled by all controllers. Device Type is a 5-bit field reported by a SCSI Inquiry Command; defined SCSI Peripheral Device Types include, in addition to many varieties of storage device, printer, scanner, communications device, and a catch-all "processor" type for devices not otherwise listed.
SCSI enclosure services.
In larger SCSI servers, the disk-drive devices are housed in an intelligent enclosure that supports SCSI Enclosure Services (SES). The initiator can communicate with the enclosure using a specialized set of SCSI commands to access power, cooling, and other non-data characteristics.
Bibliography.
</dl>
External links.
</dl>

</doc>
<doc id="28314" url="http://en.wikipedia.org/wiki?curid=28314" title="Super Nintendo Entertainment System">
Super Nintendo Entertainment System

The Super Nintendo Entertainment System (also known as the Super NES, SNES or Super Nintendo) is a 16-bit home video game console developed by Nintendo that was released in 1990 in Japan, 1991 in North America, 1992 in Europe and Australasia (Oceania), and 1993 in South America. In Japan, the system is called the Super Famicom (Japanese: スーパーファミコン, Hepburn: Sūpā Famikon, officially adopting the abbreviated name of its predecessor, the Family Computer), or SFC for short. In South Korea, it is known as the Super Comboy (슈퍼 컴보이) and was distributed by Hyundai Electronics. Although each version is essentially the same, several forms of regional lockout prevent the different versions from being compatible with one another.
The Super Nintendo Entertainment System is Nintendo's second home console, following the Nintendo Entertainment System (NES). The console introduced advanced graphics and sound capabilities compared with other consoles at the time. Additionally, development of a variety of enhancement chips (which were integrated on game circuit boards) helped to keep it competitive in the marketplace.
The SNES was a global success, becoming the best-selling console of the 16-bit era despite its relatively late start and the fierce competition it faced in North America and Europe from Sega's Genesis/Mega Drive console. The SNES remained popular well into the 32-bit era, and continues to be popular among fans, collectors, retro gamers, and emulation enthusiasts, some of whom are still making homebrew ROM images.
History.
To compete with the popular NES/Famicom, NEC launched the TurboGrafx-16 in 1987, and Sega followed suit with the Sega Genesis/Mega Drive in 1988. Both systems were built on 16-bit architectures and offered improved graphics and sound over the 8-bit NES. However, it took several years for Sega's system to become successful. Nintendo executives were in no rush to design a new system, but they reconsidered when they began to see their dominance in the market slipping.
Launch.
Designed by Masayuki Uemura, the designer of the original Famicom, the Super Famicom was released in Japan on Wednesday, November 21, 1990 for ¥25,000 (US$210). It was an instant success; Nintendo's initial shipment of 300,000 units sold out within hours, and the resulting social disturbance led the Japanese government to ask video game manufacturers to schedule future console releases on weekends. The system's release also gained the attention of the Yakuza, leading to a decision to ship the devices at night to avoid robbery.
With the Super Famicom quickly outselling its chief rivals, Nintendo reasserted itself as the leader of the Japanese console market. Nintendo's success was partially due to its retention of most of its key third-party developers from its earlier system, including Capcom, Konami, Tecmo, Square, Koei, and Enix.
On August 23, 1991, Nintendo released the Super Nintendo Entertainment System, a redesigned version of the Super Famicom, in North America for US$199. The SNES was released in the United Kingdom and Ireland in April 1992 for GB£150, with a German release following a few weeks later. Most of the PAL region versions of the console use the Japanese Super Famicom design, except for labeling and the length of the joypad leads. The Playtronic Super Nintendo in Brazil, although PAL, uses the North American design. Both the NES and SNES were released in Brazil in 1993 by Playtronic, a joint venture between the toy company Estrela and consumer electronics company Gradiente.
The SNES and Super Famicom launched with few games, but these games were well received in the marketplace. In Japan, only two games were initially available: "Super Mario World" and "F-Zero". In North America, "Super Mario World" launched as a bundle with the console, and other launch titles include "F-Zero", "Pilotwings" (both of which demonstrated the console's "Mode 7" pseudo-3D rendering capability), "SimCity", and "Gradius III".
Console wars.
The rivalry between Nintendo and Sega resulted in what has been described as one of the most notable console wars in video game history, in which Sega positioned the Genesis as the "cool" console, with more mature titles aimed at older gamers, and edgy advertisements that occasionally attacked the competition. Nintendo however, scored an early public relations advantage by securing the first console conversion of Capcom's arcade classic "Street Fighter II" for SNES, which took over a year to make the transition to Genesis. Despite the Genesis's head start, much larger library of games, and lower price point, the Genesis only represented an estimated 60% of the American 16-bit console market in June 1992, and neither console could maintain a definitive lead for several years. "Donkey Kong Country" is said to have helped establish the SNES's market prominence in the latter years of the 16-bit generation, and for a time, maintain against the PlayStation and Saturn. According to Nintendo, the company had sold more than 20 million SNES units in the U.S. According to a 2004 study of NPD sales data, the Sega Genesis was able to maintain its lead over the SNES in the American 16-bit console market.
Changes in policy.
During the NES era, Nintendo maintained exclusive control over titles released for the system—the company had to approve every game, each third-party developer could only release up to five games per year (but some third parties got around this by using different names, for example Konami's "Ultra Games" brand), those games could not be released on another console within two years, and Nintendo was the exclusive manufacturer and supplier of NES cartridges. However, competition from Sega's console brought an end to this practice; in 1991, Acclaim began releasing games for both platforms, with most of Nintendo's other licensees following suit over the next several years; Capcom (which licensed some games to Sega instead of producing them directly) and Square were the most notable holdouts.
The company continued to carefully review submitted titles, giving them scores using a 40-point scale and allocating Nintendo's marketing resources accordingly. Each region performed separate evaluations. Nintendo of America also maintained a policy that, among other things, limited the amount of violence in the games on its systems. One game, "Mortal Kombat", would challenge this policy. A surprise hit in arcades in 1992, "Mortal Kombat" features splashes of blood and finishing moves that often depict one character dismembering the other. Because the Sega Genesis version retained the gore while the SNES version did not, it outsold the SNES version by a ratio of three or four-to-one.
Game players were not the only ones to notice the violence in this game; US Senators Herb Kohl and Joe Lieberman convened a Congressional hearing on December 9, 1993 to investigate the marketing of violent video games to children. While Nintendo took the high ground with moderate success, the hearings led to the creation of the Interactive Digital Software Association and the Entertainment Software Rating Board, and the inclusion of ratings on all video games. With these ratings in place, Nintendo decided its censorship policies were no longer needed.
32-bit era and beyond.
While other companies were moving on to 32-bit systems, Rare and Nintendo proved that the SNES was still a strong contender in the market. In November 1994, Rare released "Donkey Kong Country", a platform game featuring 3D models and textures pre-rendered on SGI workstations. With its detailed graphics, fluid animation and high-quality music, "Donkey Kong Country" rivaled the aesthetic quality of games that were being released on newer 32-bit CD-based consoles. In the last 45 days of 1994, the game sold 6.1 million units, making it the fastest-selling video game in history to that date. This game sent a message that early 32-bit systems had little to offer over the SNES, and helped make way for the more advanced consoles on the horizon.
In October 1997, Nintendo released a redesigned model of the SNES (the SNS-101 model) in North America for US$99, which included the pack-in game "". Like the earlier redesign of the NES (the NES-101 model), the new model was slimmer and lighter than its predecessor, but it lacked S-Video and RGB output, and it was among the last major SNES-related releases in the region. A similarly redesigned Super Famicom Jr. was released in Japan at around the same time.
Nintendo ceased production of the SNES in 1999, about two years after releasing "Kirby's Dream Land 3" (its last first-party game for the system) on November 27, 1997, a year after releasing "Frogger" (its last third-party game for the system). In Japan, Nintendo continued production of the Super Famicom until September 25, 2003, and new games were produced until the year 2000, ending with the release of "Metal Slader Glory Director's Cut" on November 29, 2000.
Many popular SNES titles have since been ported to the Game Boy Advance, which has similar video capabilities. In 2005, Nintendo announced that SNES titles would be made available for download via the Wii and Wii U's Virtual Console service. On October 31, 2007, Nintendo of Japan announced that it would no longer repair Family Computer or Super Famicom systems due to an increasing shortage of the necessary parts.
Technical specifications.
The 16-bit design of the SNES incorporates powerful graphics and sound co-processors that allow tiling and simulated 3D effects, a palette of 32,768 colors, and high-quality 8-channel audio. These base platform features, plus the ability to dramatically extend them all through substantial chip upgrades inside of each cartridge, represent a leap over the 8-bit NES generation and some significant advantages over the competition such as the Sega Genesis.
Central processing unit.
The CPU is a Nintendo-custom 5A22 processor, based on a 16-bit 65c816 core. The CPU employs a variable bus speed depending on the memory region being accessed for each instruction cycle: the input clock is divided by 6, 8, or 12 to obtain the bus clock rate. Non-access cycles, most register accesses, and some general accesses use the divisor of 6. WRAM accesses and other general accesses use the divisor of 8. Only the controller port serial-access registers use the divisor of 12.
The chip has an 8-bit data bus, controlled by two address buses. The 24-bit "Bus A" is used for general accesses, while the 8-bit "Bus B" is used for support chip registers (mainly the video and audio processors). Normally only one bus is used at a time; however, the built-in direct memory access (DMA) unit places a read signal on one bus and a write signal on the other to achieve block transfer speeds of up to 2.68 MB/s.
The DMA unit has 8 independent channels, each of which can be used in two modes. General DMA transfers up to 64 kB in one shot, while H-blank DMA (HDMA) transfers 1–4 bytes at the end of each video scanline. HDMA is typically used to change video parameters to achieve effects such as perspective, split-screen, and non-rectangular windowing without tying up the main CPU.
The 5A22 also contains an 8-bit parallel I/O port (which is mostly unused in the SNES); controller port interface circuits, including both serial and parallel access to controller data; a 16-bit multiplication and division unit; and circuitry for generating non-maskable interrupts on V-blank and IRQ interrupts on calculated screen positions.
Video.
The graphics processing unit (GPU) consists of two separate but closely tied IC packages, which may be considered as a single entity. It also contains 64 kB of SRAM for storing video data (VRAM), 544 bytes of object attribute memory (OAM) for storing sprite data, and 256 × 15 bits of color generator RAM (CGRAM) for storing palette data. The VRAM is actually divided into two 32 kB sections with separate address and data buses, essentially for the necessary access patterns used by BG Mode 7. The GPU is clocked by the same signal as the CPU, and generates a pixel every two or four cycles. Both NTSC and PAL systems use the same GPU chips, with one pin per chip selecting NTSC or PAL operation.
Images may be output at 256 or 512 pixels horizontal resolution and 224, 239, 448, or 478 pixels vertically. Vertical resolutions of 224 or 239 are usually output in progressive scan, while 448 and 478 resolutions are interlaced. Colors are chosen from the 15-bit RGB color space, for a total of 32,768 possible colors. Graphics consist of up to 128 sprites and up to 4 background layers, all made up of combinations of 8×8 pixel "tiles". Most graphics use palettes stored in CGRAM, with color 0 of any palette representing transparency.
Sprites can be 8 × 8, 16 × 16, 32 × 32, or 64 × 64 pixels, each using one of eight 16-color palettes and tiles from one of two blocks of 256 in VRAM. Sprites may be flipped horizontally and vertically as a whole. Up to 32 sprites and 34 8 × 8 sprite tiles may appear on any one line; excess sprites or tiles would be dropped. Each sprite lies on one of 4 planes, however a lower-numbered sprite will always cover a higher-numbered sprite even if the latter is on a higher priority plane. This quirk is often used for complex clipping effects.
Background layers in most modes range from 32 x 32 to 64 × 64 tiles, each of size 8 x 8 or 16 x 16 pixels, with each tile on one of two planes ("foreground" and "background") and using one of 8 palettes. Tiles are taken from a per-layer set of up to 1024 (as VRAM permits) and can be flipped horizontally and vertically. Each layer may be scrolled both horizontally and vertically. The number of background layers and the size of the palettes depends on the mode:
Background layers may be individually pixelized, and layers and sprites can be individually clipped and combined by color addition or subtraction to generate more complex effects and greater color depths than can be specified directly.
The GPU may be instructed to "latch" the current pixel position at any time during image output, both by game software and by the device attached to controller port 2. The game software may then read back this latched position. The GPU may also be used for fast 16-bit by 8-bit signed multiplication.
Audio.
The audio subsystem consists of an 8-bit Sony SPC700, a 16-bit DSP, 64 kB of SRAM shared by the two chips, and a 64 byte boot ROM. The audio subsystem is almost completely independent from the rest of the system: it is clocked at a nominal 24.576 MHz in both NTSC and PAL systems, and can only communicate with the CPU via 4 registers on Bus B.
RAM is accessed at 3.072 MHz, with accesses multiplexed between the SPC700 (1⁄3) and the DSP (2⁄3). This RAM is used to store the SPC700 program and stack, the audio sample data and pointer table, and the DSP's echo buffer. The SPC700 runs programs (uploaded using the boot ROM program) to accept instructions and data from the CPU and to manipulate the DSP registers to generate the appropriate music and sound effects. The DSP generates a 16-bit waveform at 32 kHz by mixing input from 8 independent voices and an 8-tap FIR filter typically used for reverberation. Each voice can play its sample at a variable rate, with Gaussian interpolation, stereo panning, and ADSR, linear, non-linear, or direct volume envelope adjustment. The voice and FIR filter outputs are mixed both for direct output and for future input into the FIR filter. All audio samples are compressed using ADPCM and a , a method dubbed BRR.
Hardware on the cartridge, expansion port, or both can provide stereo audio data for mixing into the DSP's analog audio output before it leaves the console. Since the audio subsystem is mostly self-contained, the state of the audio subsystem can be connected to, or emulated on, a host computer. Its output may be saved as an SPC700 sound format (.SPC) file, or the audio subsystem can be emulated in a stand-alone manner to play back all game music except for a few games that constantly stream their samples from ROM. Custom cartridges or PC interfaces can be used to load and play .SPC files onto a real SNES SPC700 and DSP.
Onboard RAM.
The console contains 128 kB of DRAM. This is mapped to various segments of Bus A, and can also be accessed in a serial fashion via registers on Bus B. The video and audio subsystems contain additional RAM reserved for use by those processors.
Regional lockout.
Nintendo employed several types of regional lockout, including both physical and hardware incompatibilities.
On a physical level, the cartridges are shaped differently for different regions. North American cartridges have a rectangular bottom with inset grooves matching protruding tabs in the console, while other regions' cartridges are narrower with a smooth curve on the front and no grooves. The physical incompatibility can be overcome with use of various adapters, or through modification of the console.
Internally, a regional lockout chip (CIC) within the console and in each cartridge prevents PAL region games from being played on Japanese or North American consoles and vice versa. The Japanese and North American machines have the same region chip. The console CIC releases the reset signal to the rest of the system only after completing a handshake with the chip in the cartridge. This can be overcome through the use of adapters, typically by inserting the imported cartridge in one slot and a cartridge with the correct region chip in a second slot. Alternatively, disconnecting one pin of the console's lockout chip will prevent it from locking the console; hardware in later games can detect this situation, so it later became common to install a switch to reconnect the lockout chip as needed.
PAL consoles face another incompatibility when playing out-of-region cartridges: the NTSC video standard specifies video at 60 Hz while PAL operates at 50 Hz, resulting in approximately 16.7% slower gameplay. Additionally, PAL's higher resolution results in letterboxing of the output image. Some commercial PAL region releases exhibit this same problem and therefore can be played in NTSC systems without issue, while others will face a 20% speedup if played in an NTSC console. To mostly correct this issue, a switch can be added to place the SNES PPU into a 60 Hz mode supported by most newer PAL televisions. Later games will detect this setting and refuse to run, requiring the switch to be thrown only after the check completes.
Casing.
All versions of the SNES are predominantly gray, although the exact shade may differ. The original North American version, designed by Nintendo of America industrial designer Lance Barr (who previously redesigned the Famicom to become the NES), has a boxy design with purple sliding switches and a dark gray eject lever. The loading bay surface is curved, both to invite interaction and to prevent food or drinks from being placed on the console and spilling as had happened with the flat surfaced NES. The Japanese and European versions are more rounded, with darker gray accents and buttons. The North American SNS-101 model and the Japanese Super Famicom Jr. (the SHVC-101 model), all designed by Barr, are both smaller with a rounded contour; however, the SNS-101 buttons are purple where the Super Famicom Jr. buttons are gray. The European and American versions of the SNES controllers have much longer cables compared to the Japanese Super Famicom controllers.
All versions incorporate a top-loading slot for game cartridges, although the shape of the slot differs between regions to match the different shapes of the cartridges. The card-edge connector has 62 contacts; however, many cartridges only connect to the middle 46. All versions also incorporate two 7-pin controller ports on the front of the unit, and a plug for a power supply and a Nintendo-proprietary "MULTI OUT" A/V connector on the back. The MULTI OUT connector (later used on the Nintendo 64 and GameCube) can output composite video, S-Video and RGB signals, as well as RF with an external RF modulator. Original versions additionally include a 28-pin expansion port under a small cover on the bottom of the unit and a standard RF output with channel selection switch on the back; the redesigned models output composite video only, requiring an external modulator for RF.
The ABS plastic used in the casing of some older SNES and Super Famicom consoles is particularly susceptible to oxidization on exposure to air, likely due to an incorrect mixture of the stabilizing or flame retarding additives. This, along with the particularly light color of the original plastic, causes affected consoles to quickly become yellow; if the sections of the casing came from different batches of plastic, a "two-tone" effect results. The color can sometimes be restored with UV light and a hydrogen peroxide solution.
Game cartridge.
The cartridge media of the console is officially referred to as Game Pak in most Western regions, and as Cassette (カセット, Kasetto) in Japan and parts of Latin America. While the SNES can address 128 Mbit, only 117.75 Mbit are actually available for cartridge use. A fairly normal mapping could easily address up to 95 Mbit of ROM data (48 Mbit at FastROM speed) with 8 Mbit of battery-backed RAM. However, most available memory access controllers only support mappings of up to 32 Mbit. The largest games released ("Tales of Phantasia" and "Star Ocean") contain 48 Mbit of ROM data, while the smallest games contain only 2 Mbit.
Cartridges may also contain battery-backed SRAM to save the game state, extra working RAM, custom coprocessors, or any other hardware that will not exceed the maximum current rating of the console.
Peripherals.
The standard SNES controller adds two additional face buttons (X and Y) to the design of the NES iteration, arranging the four in a diamond shape, and introduces two shoulder buttons. The inclusion of six active buttons was made with the popularity of the Street Fighter arcade series in mind. It also features an ergonomic design by Lance Barr, later used for the NES-102 model controllers, also designed by Barr. The Japanese and PAL region versions incorporate the colors of the four action buttons into system's logo. The North American version's buttons are colored to match the redesigned console; the X and Y buttons are lavender with concave faces, and the A and B buttons are purple with convex faces. Several later consoles derive elements of their controller design from the SNES, including the PlayStation, Dreamcast, Xbox, and Wii Classic Controller.
Throughout the course of its life, a number of peripherals were released which added to the functionality of the SNES. Many of these devices were modeled after earlier add-ons for the NES: the Super Scope is a light gun functionally similar to the NES Zapper (though the Super Scope features wireless capabilities) and the Super Advantage is an arcade-style joystick with adjustable turbo settings akin to the NES Advantage. Nintendo also released the SNES Mouse in conjunction with its "Mario Paint" title. Hudson Soft, under license from Nintendo, released the Super Multitap, a multiplayer adapter for use with its popular series of "Bomberman" games. Some of the more unusual controllers include the one-handed ASCII Stick L5, the BatterUP baseball bat, and the TeeV Golf golf club.
While Nintendo never released an adapter for playing NES games on the SNES (though the instructions included a way to connect both consoles to the same TV by either daisy chaining the RF switches or using AV outputs for one or both systems), the Super Game Boy adapter cartridge allows games designed for Nintendo's portable Game Boy system to be played on the SNES. The Super Game Boy touted several feature enhancements over the Game Boy, including palette substitution, custom screen borders, and (for specially enhanced games) access to the SNES console. Japan also saw the release of the Super Game Boy 2, which added a communication port to enable a second Game Boy to connect for multiplayer games.
Like the NES before it, the SNES saw its fair share of unlicensed third-party peripherals, including a new version of the Game Genie cheat cartridge designed for use with SNES games. In general, Nintendo proved to be somewhat more tolerant of unlicensed SNES peripherals than they had been with NES peripherals.
Soon after the release of the SNES, companies began marketing backup devices such as the Super Wildcard, Super Pro Fighter Q, and Game Doctor. These devices were sold to create a backup of a cartridge, in the event that it would break. However, they could also be used to play copied ROM images that could be downloaded from BBSes and the Internet, or to create copies of rented video games, often violating copyright laws in many jurisdictions.
Japan saw the release of the Satellaview, a modem which attached to the Super Famicom's expansion port and connected to the St.GIGA satellite radio station. Users of the Satellaview could download gaming news and specially designed games, which were frequently either remakes of or sequels to older Famicom titles, released in installments. Satellaview signals were broadcast from April 23, 1995 through June 30, 2000. In the United States, the similar but relatively short-lived XBAND allowed users to connect to a network via a dial-up modem to compete against other players around the country.
During the SNES's life, Nintendo contracted with two different companies to develop a CD-ROM-based peripheral for the console to compete with Sega's CD-ROM based addon, Mega-CD. Ultimately, deals with both Sony and Philips fell through, (although a prototype console was produced by Sony) with Philips gaining the right to release a series of titles based on Nintendo franchises for its CD-i multimedia player and Sony going on to develop its own console based on its initial dealings with Nintendo (the PlayStation).
Enhancement chips.
As part of the overall plan for the SNES, rather than include an expensive CPU that would still become obsolete in a few years, the hardware designers made it easy to interface special coprocessor chips to the console (just like the MMC chips used for most NES games). This is most often characterized by 16 additional pins on the cartridge card edge. 
The Super FX is a RISC CPU designed to perform functions that the main CPU could not feasibly do. The chip was primarily used to create 3D game worlds made with polygons, texture mapping and light source shading. The chip could also be used to enhance 2D games.
The Nintendo fixed-point digital signal processor (DSP) chip allowed for fast vector-based calculations, bitmap conversions, both 2D and 3D coordinate transformations, and other functions. Four revisions of the chip exist, each physically identical but with different microcode. The DSP-1 version, including the later 1A and 1B bug fix revisions, is used most often; the DSP-2, DSP-3, and DSP-4 are used in only one title each.
Similar to the 5A22 CPU in the console, the SA-1 chip contains a 65c816 processor core clocked at 10 MHz, a memory mapper, DMA, decompression and bitplane conversion circuitry, several programmable timers, and CIC region lockout functionality.
In Japan, games could be downloaded for a lower price (than standard cartridges) from Nintendo Power kiosks onto special cartridges containing flash memory and a MegaChips MX15001TFC chip. The chip managed communication with the kiosks to download ROM images, and provided an initial menu to select which of the downloaded games would be played. Some titles were available both in cartridge and download form, while others were download only. The service was closed on February 8, 2007.
Many cartridges contain other enhancement chips, most of which were created for use by a single company in a few titles; the only limitations are the speed of the SNES itself to transfer data from the chip and the current limit of the console.
Emulation.
Like the NES before it, the SNES has retained interest among its fans even following its decline in the marketplace. It has continued to thrive on the second-hand market and through console emulation. The SNES has taken much the same revival path as the NES (see History of the Nintendo Entertainment System).
Emulation projects began with the initial release of VSMC in 1994, and Super Pasofami became the first working SNES emulator in 1996. During that time, two competing emulation projects—Snes96 and Snes97—merged to form a new initiative entitled Snes9x. In 1997, SNES enthusiasts began programming an emulator named ZSNES. These two have remained among the best-known SNES emulators, although development continues on others as well. In 2003, members of both the Snes9x and ZSNES teams and others began a push for exact emulation; this movement is now led by the development of higan by a developer named byuu.
Nintendo of America took the same stance against the distribution of SNES ROM image files and the use of emulators as it did with the NES, insisting that they represented flagrant software piracy. Proponents of SNES emulation cite discontinued production of the SNES constituting abandonware status, the right of the owner of the respective game to make a personal backup via devices such as the Retrode, space shifting for private use, the desire to develop homebrew games for the system, the frailty of SNES ROM cartridges and consoles, and the lack of certain foreign imports.
The SNES was one of the first systems to attract the attention of amateur fan translators: "Final Fantasy V" was the first major work of fan translation, and was completed in 1998.
Emulation of the SNES is now available on handheld units, such as Android devices, Apple's iPhone and iPad, Sony's PlayStation Portable (PSP), the Nintendo DS and Game Boy Advance, the Gizmondo, the Dingoo and the GP2X by GamePark Holdings, as well as PDAs. While individual games have been included with emulators on some GameCube discs, Nintendo's Virtual Console service for the Wii marks the introduction of officially sanctioned general SNES emulation, though SNES9x GX, a port of SNES9x, has been made for the Wii.
Legacy.
49.10 million SNES units were sold worldwide, with 23.35 million of those units sold in the Americas and 17.17 million in Japan. Although it could not quite repeat the success of the NES, which sold 61.91 million units worldwide, the SNES was the best-selling console of its era.
In 2007, GameTrailers named the SNES as the second-best console of all time in their list of top ten consoles that "left their mark on the history of gaming", citing its graphic, sound, and library of top-quality games. In 2015, they also named it the best Nintendo console of all time, saying, "The list of games we love from this console completely annihilates any other roster from the Big N." Technology columnist Don Reisinger proclaimed "The SNES is the greatest console of all time" in January 2008, citing the quality of the games and the console's dramatic improvement over its predecessor; fellow technology columnist Will Greenwald replied with a more nuanced view, giving the SNES top marks with his heart, the NES with his head, and the PlayStation (for its controller) with his hands. GamingExcellence also gave the SNES first place in 2008, declaring it "simply the most timeless system ever created" with many games that stand the test of time and citing its innovation in controller design, graphics capabilities, and game storytelling. At the same time, GameDaily rated it fifth of ten for its graphics, audio, controllers, and games. In 2009, IGN named the Super Nintendo Entertainment System the fourth best video game console, complimenting its audio and "concentration of AAA titles".
External links.
 Media related to at Wikimedia Commons

</doc>
<doc id="28319" url="http://en.wikipedia.org/wiki?curid=28319" title="Smalltalk">
Smalltalk

Smalltalk is an object-oriented, dynamically typed, reflective programming language. Smalltalk was created as the language to underpin the "new world" of computing exemplified by "human–computer symbiosis." It was designed and created in part for educational use, more so for constructionist learning, at the Learning Research Group (LRG) of Xerox PARC by Alan Kay, Dan Ingalls, Adele Goldberg, Ted Kaehler, Scott Wallace, and others during the 1970s.
The language was first generally released as Smalltalk-80. Smalltalk-like languages are in continuing active development, and have gathered loyal communities of users around them. ANSI Smalltalk was ratified in 1998 and represents the standard version of Smalltalk.
History.
There are a large number of Smalltalk variants. The unqualified word "Smalltalk" is often used to indicate the Smalltalk-80 language, the first version to be made publicly available and created in 1980.
Smalltalk was the product of research led by Alan Kay at Xerox Palo Alto Research Center (PARC); Alan Kay designed most of the early Smalltalk versions, which Dan Ingalls implemented. The first version, known as Smalltalk-71, was created by Kay in a few mornings on a bet that a programming language based on the idea of message passing inspired by Simula could be implemented in "a page of code." A later variant actually used for research work is now known as Smalltalk-72 and influenced the development of the Actor model. Its syntax and execution model were very different from modern Smalltalk variants.
After significant revisions which froze some aspects of execution semantics to gain performance (by adopting a Simula-like class inheritance model of execution), Smalltalk-76 was created. This system had a development environment featuring most of the now familiar tools, including a class library code browser/editor. Smalltalk-80 added metaclasses, to help maintain the "everything is an object" (except private instance variables) paradigm by associating properties and behavior with individual classes, and even primitives such as integer and boolean values (for example, to support different ways of creating instances).This was supposed to be the first object-oriented language.
Smalltalk-80 was the first language variant made available outside of PARC, first as Smalltalk-80 Version 1, given to a small number of firms (Hewlett-Packard, Apple Computer, Tektronix, and DEC) and universities (UC Berkeley) for "peer review" and implementation on their platforms. Later (in 1983) a general availability implementation, known as Smalltalk-80 Version 2, was released as an image (platform-independent file with object definitions) and a virtual machine specification. ANSI Smalltalk has been the standard language reference since 1998.
Two of the currently popular Smalltalk implementation variants are descendants of those original Smalltalk-80 images. Squeak is an open source implementation derived from Smalltalk-80 Version 1 by way of Apple Smalltalk. VisualWorks is derived from Smalltalk-80 version 2 by way of Smalltalk-80 2.5 and ObjectWorks (both products of ParcPlace Systems, a Xerox PARC spin-off company formed to bring Smalltalk to the market). As an interesting link between generations, in 2001 Vassili Bykov implemented Hobbes, a virtual machine running Smalltalk-80 inside VisualWorks. (Dan Ingalls later ported Hobbes to Squeak.)
During the late 1980s to mid-1990s, Smalltalk environments—including support, training and add-ons—were sold by two competing organizations: ParcPlace Systems and Digitalk, both California based. ParcPlace Systems tended to focus on the Unix/Sun microsystems market, while Digitalk focused on Intel-based PCs running Microsoft Windows or IBM's OS/2. Both firms struggled to take Smalltalk mainstream due to Smalltalk's substantial memory needs, limited run-time performance, and initial lack of supported connectivity to SQL-based relational database servers. While the high price of ParcPlace Smalltalk limited its market penetration to mid-sized and large commercial organizations, the Digitalk products initially tried to reach a wider audience with a lower price. IBM initially supported the Digitalk product, but then entered the market with a Smalltalk product in 1995 called VisualAge/Smalltalk. Easel introduced Enfin at this time on Windows and OS/2. Enfin became far more popular in Europe, as IBM introduced it into IT shops before their development of IBM Smalltalk (later VisualAge). Enfin was later acquired by Cincom Systems, and is now sold under the name ObjectStudio, and is part of the Cincom Smalltalk product suite.
In 1995, ParcPlace and Digitalk merged into ParcPlace-Digitalk and then rebranded in 1997 as ObjectShare, located in Irvine, CA. ObjectShare (NASDAQ: OBJS) was traded publicly until 1999, when it was delisted and dissolved. The merged firm never managed to find an effective response to Java as to market positioning, and by 1997 its owners were looking to sell the business. In 1999, Seagull Software acquired the ObjectShare Java development lab (including the original Smalltalk/V and Visual Smalltalk development team), and still owns VisualSmalltalk, although worldwide distribution rights for the Smalltalk product remained with ObjectShare who then sold them to Cincom. VisualWorks was sold to Cincom and is now part of Cincom Smalltalk. Cincom has backed Smalltalk strongly, releasing multiple new versions of VisualWorks and ObjectStudio each year since 1999.
Cincom, Gemstone and Object Arts, plus other vendors continue to sell Smalltalk environments. IBM has 'end of life'd VisualAge Smalltalk having in the late 1990s decided to back Java and it is, as of 2006[ [update]], supported by Instantiations, Inc. which has renamed the product VA Smalltalk and released several new versions. The open Squeak implementation has an active community of developers, including many of the original Smalltalk community, and has recently been used to provide the Etoys environment on the OLPC project, a toolkit for developing collaborative applications Croquet Project, and the Open Cobalt virtual world application. GNU Smalltalk is a free software implementation of a derivative of Smalltalk-80 from the GNU project. Last but not least Pharo Smalltalk (a fork of Squeak oriented towards research and use in commercial environments) a new and clean MIT licensed open source Smalltalk that brings fresh ideas and interest into the Smalltalk market and scene.
A significant development, that has spread across all current Smalltalk environments, is the increasing usage of two web frameworks, Seaside and AIDA/Web, to simplify the building of complex web applications. Seaside has seen considerable market interest with Cincom, Gemstone and Instantiations incorporating and extending it.
Influences.
Smalltalk was one of many object-oriented programming languages based on Simula. Smalltalk was also one of the most influential programming languages. Virtually all of the object-oriented languages that came after—Flavors, CLOS, Objective-C, Java, Python, Ruby, and many others—were all influenced by Smalltalk. Smalltalk was also one of the most popular languages with the Agile Methods, Rapid Prototyping, and Software Patterns communities. The highly productive environment provided by Smalltalk platforms made them ideal for rapid, iterative development.
Smalltalk emerged from a larger program of ARPA funded research that in many ways defined the modern world of computing. In addition to Smalltalk working prototypes of things such as hypertext, GUIs, multimedia, the mouse, telepresence, and the Internet were developed by ARPA researchers in the 1960s. Alan Kay (one of the inventors of Smalltalk) also described a tablet computer he called the Dynabook which was essentially a design for an iPad.
Smalltalk environments were often the first to develop what are now common object-oriented software design patterns. One of the most popular is the Model–view–controller pattern for User Interface design. The MVC pattern enables developers to have multiple consistent views of the same underlying data. It's ideal for software development environments, where there are various views (e.g., entity-relation, dataflow, object model, etc.) of the same underlying specification. Also, for simulations or games where the underlying model may be viewed from various angles and levels of abstraction.
In addition to the MVC pattern the Smalltalk language and environment were tremendously influential in the history of the Graphical User Interface (GUI) and the What You See Is What You Get (WYSIWYG) user interface, font editors, and desktop metaphors for UI design. The powerful built-in debugging and object inspection tools that came with Smalltalk environments set the standard for all the Integrated Development Environments, starting with Lisp Machine environments, that came after.
Object-oriented programming.
As in other object-oriented languages, the central concept in Smalltalk-80 (but not in Smalltalk-72) is that of an "object". An object is always an "instance" of a "class". Classes are "blueprints" that describe the properties and behavior of their instances. For example, a GUI's window class might declare that windows have properties such as the label, the position and whether the window is visible or not. The class might also declare that instances support operations such as opening, closing, moving and hiding. Each particular window object would have its own values of those properties, and each of them would be able to perform operations defined by its class.
A Smalltalk object can do exactly three things:
The state an object holds is always private to that object. Other objects can query or change that state only by sending requests (messages) to the object to do so. Any message can be sent to any object: when a message is received, the receiver determines whether that message is appropriate. Alan Kay has commented that despite the attention given to objects, messaging is the most important concept in Smalltalk: "The big idea is 'messaging'—that is what the kernel of Smalltalk/Squeak is all about (and it's something that was never quite completed in our Xerox PARC phase)."
Smalltalk is a "pure" object-oriented programming language, meaning that, unlike Java and C++, there is no difference between values which are objects and values which are primitive types. In Smalltalk, primitive values such as integers, booleans and characters are also objects, in the sense that they are instances of corresponding classes, and operations on them are invoked by sending messages. A programmer can change or extend (through subclassing) the classes that implement primitive values, so that new behavior can be defined for their instances—for example, to implement new control structures—or even so that their existing behavior will be changed. This fact is summarized in the commonly heard phrase "In Smalltalk everything is an object", which may be more accurately expressed as "all values are objects", as variables are not.
Since all values are objects, classes themselves are also objects. Each class is an instance of the "metaclass" of that class. Metaclasses in turn are also objects, and are all instances of a class called Metaclass. Code blocks—Smalltalk's way of expressing anonymous functions—are also objects.
Reflection.
Reflection is a term that computer scientists apply to software programs that have the capability to inspect their own structure, for example their parse tree or datatypes of input and output parameters. Reflection was first primarily a feature of interpreted languages such as Smalltalk and Lisp. The fact that statements are interpreted means that the programs have access to information created as they were parsed and can often even modify their own structure.
Reflection is also a feature of having a meta-model as Smalltalk does. The meta-model is the model that describes the language itself and developers can use the meta-model to do things like walk through, examine, and modify the parse tree of an object. Or find all the instances of a certain kind of structure (e.g., all the instances of the Method class in the meta-model).
Smalltalk-80 is a totally reflective system, implemented in Smalltalk-80 itself. Smalltalk-80 provides both structural and computational reflection. Smalltalk is a structurally reflective system whose structure is defined by Smalltalk-80 objects. The classes and methods that define the system are themselves objects and fully part of the system that they help define. The Smalltalk compiler compiles textual source code into method objects, typically instances of codice_1. These get added to classes by storing them in a class's method dictionary. The part of the class hierarchy that defines classes can add new classes to the system. The system is extended by running Smalltalk-80 code that creates or defines classes and methods. In this way a Smalltalk-80 system is a "living" system, carrying around the ability to extend itself at run time.
Since the classes are themselves objects, they can be asked questions such as "what methods do you implement?" or "what fields/slots/instance variables do you define?". So objects can easily be inspected, copied, (de)serialized and so on with generic code that applies to any object in the system.
Smalltalk-80 also provides computational reflection, the ability to observe the computational state of the system. In languages derived from the original Smalltalk-80 the current activation of a method is accessible as an object named via a pseudo-variable (one of the six reserved words), codice_2. By sending messages to codice_2 a method activation can ask questions like "who sent this message to me". These facilities make it possible to implement co-routines or Prolog-like back-tracking without modifying the virtual machine. The exception system is implemented using this facility. One of the more interesting uses of this is in the Seaside web framework which relieves the programmer of dealing with the complexity of a Web Browser's back button by storing continuations for each edited page and switching between them as the user navigates a web site. Programming the web server using Seaside can then be done using a more conventional programming style.
An example of how Smalltalk can use reflection is the mechanism for handling errors. When an object is sent a message that it does not implement, the virtual machine sends the object the codice_4 message with a reification of the message as an argument. The message (another object, an instance of codice_5) contains the selector of the message and an codice_6 of its arguments. In an interactive Smalltalk system the default implementation of codice_4 is one that opens an error window (a Notifier) reporting the error to the user. Through this and the reflective facilities the user can examine the context in which the error occurred, redefine the offending code, and continue, all within the system, using Smalltalk-80's reflective facilities.
Syntax.
Smalltalk-80 syntax is rather minimalist, based on only a handful of declarations and reserved words. In fact, only six "keywords" are reserved in Smalltalk: codice_8, codice_9, codice_10, codice_11, codice_12, and codice_2. These are actually called "pseudo-variables", identifiers that follow the rules for variable identifiers but denote bindings that the programmer cannot change. The codice_8, codice_9, and codice_10 pseudo-variables are singleton instances. codice_11 and codice_12 refer to the receiver of a message within a method activated in response to that message, but sends to codice_12 are looked up in the superclass of the method's defining class rather than the class of the receiver, which allows methods in subclasses to invoke methods of the same name in superclasses. codice_2 refers to the current activation record. The only built-in language constructs are message sends, assignment, method return and literal syntax for some objects. From its origins as a language for children of all ages, standard Smalltalk syntax uses punctuation in a manner more like English than mainstream coding languages. The remainder of the language, including control structures for conditional evaluation and iteration, is implemented on top of the built-in constructs by the standard Smalltalk class library. (For performance reasons, implementations may recognize and treat as special some of those messages; however, this is only an optimization and is not hardwired into the language syntax.)
The adage that "Smalltalk syntax fits on a postcard" refers to a code snippet by Ralph Johnson, demonstrating all the basic standard syntactic elements of methods:
Literals.
The following examples illustrate the most common objects which can be written as literal values in Smalltalk-80 methods.
Numbers. The following list illustrates some of the possibilities.
The last two entries are a binary and a hexadecimal number, respectively. The number before the 'r' is the radix or base. The base does not have to be a power of two; for example 36rSMALLTALK is a valid number equal to 80738163270632 decimal.
Characters are written by preceding them with a dollar sign:
Strings are sequences of characters enclosed in single quotes:
To include a quote in a string, escape it using a second quote:
Double quotes do not need escaping, since single quotes delimit a string:
Two equal strings (strings are equal if they contain all the same characters) can be different objects residing in different places in memory. In addition to strings, Smalltalk has a class of character sequence objects called Symbol. Symbols are guaranteed to be unique—there can be no two equal symbols which are different objects. Because of that, symbols are very cheap to compare and are often used for language artifacts such as message selectors (see below).
Symbols are written as # followed by a string literal. For example:
If the sequence does not include whitespace or punctuation characters,
this can also be written as:
Arrays:
defines an array of four integers.
Many implementations support the following literal syntax for ByteArrays:
defines a ByteArray of four integers.
And last but not least, blocks (anonymous function literals)
Blocks are explained in detail further in the text.
Many Smalltalk dialects implement additional syntaxes for other objects, but the ones above are the essentials supported by all.
Variable declarations.
The two kinds of variables commonly used in Smalltalk are instance variables and temporary variables. Other variables and related terminology depend on the particular implementation. For example, VisualWorks has class shared variables and namespace shared variables, while Squeak and many other implementations have class variables, pool variables and global variables.
Temporary variable declarations in Smalltalk are variables declared inside a method (see below). They are declared at the top of the method as names separated by spaces and enclosed by vertical bars. For example:
declares a temporary variable named index. Multiple variables may be declared within one set of bars:
declares two variables: index and vowels.
Assignment.
A variable is assigned a value via the ':=' syntax. So:
Assigns the string 'aeiou' to the previously declared vowels variable. The string is an object (a sequence of characters between single quotes is the syntax for literal strings), created by the compiler at compile time.
In the original Parc Place image, the glyph of the underscore character (_) appeared as a left-facing arrow (like in the 1963 version of the ASCII code). Smalltalk originally accepted this left-arrow as the only assignment operator. Some modern code still contains what appear to be underscores acting as assignments, hearkening back to this original usage. Most modern Smalltalk implementations accept either the underscore or the colon-equals syntax.
Messages.
The message is the most fundamental language construct in Smalltalk. Even control structures are implemented as message sends. Smalltalk adopts by default a synchronous, single dynamic message dispatch strategy (as contrasted to the asynchronous, multiple dispatch strategy adopted by some other object-oriented languages).
The following example sends the message 'factorial' to number 42:
In this situation 42 is called the message "receiver", while 'factorial' is the message "selector". The receiver responds to the message by returning a value (presumably in this case the factorial of 42). Among other things, the result of the message can be assigned to a variable:
"factorial" above is what is called a "unary message" because only one object, the receiver, is involved. Messages can carry additional objects as "arguments", as follows:
In this expression two objects are involved: 2 as the receiver and 4 as the message argument. The message result, or in Smalltalk parlance, "the answer" is supposed to be 16. Such messages are called "keyword messages". A message can have more arguments, using the following syntax:
which answers the index of character 'o' in the receiver string, starting the search from index 6. The selector of this message is "indexOf:startingAt:", consisting of two pieces, or "keywords".
Such interleaving of keywords and arguments is meant to improve readability of code, since arguments are explained by their preceding keywords. For example, an expression to create a rectangle using a C++ or Java-like syntax might be written as:
It's unclear which argument is which. By contrast, in Smalltalk, this code would be written as:
The receiver in this case is "Rectangle", a class, and the answer will be a new instance of the class with the specified width and height.
Finally, most of the special (non-alphabetic) characters can be used as what are called "binary messages". These allow mathematical and logical operators to be written in their traditional form:
which sends the message "+" to the receiver 3 with 4 passed as the argument (the answer of which will be 7). Similarly,
is the message ">" sent to 3 with argument 4 (the answer of which will be false).
Notice, that the Smalltalk-80 language itself does not imply the meaning of those operators. The outcome of the above is only defined by how the receiver of the message (in this case a Number instance) responds to messages "+" and ">".
A side effect of this mechanism is operator overloading. A message ">" can also be understood by other objects, allowing the use of expressions of the form "a > b" to compare them.
Expressions.
An expression can include multiple message sends. In this case expressions are parsed according to a simple order of precedence. Unary messages have the highest precedence, followed by binary messages, followed by keyword messages. For example:
is evaluated as follows:
The answer of the last message sent is the result of the entire expression.
Parentheses can alter the order of evaluation when needed. For example,
will change the meaning so that the expression first computes "3 factorial + 4" yielding 10. That 10 then receives the second "factorial" message, yielding 3628800. 3628800 then receives "between:and:", answering false.
Note that because the meaning of binary messages is not hardwired into Smalltalk-80 syntax, all of them are considered to have equal precedence and are evaluated simply from left to right. Because of this, the meaning of Smalltalk expressions using binary messages can be different from their "traditional" interpretation:
is evaluated as "(3 + 4) * 5", producing 35. To obtain the expected answer of 23, parentheses must be used to explicitly define the order of operations:
Unary messages can be "chained" by writing them one after another:
which sends "factorial" to 3, then "factorial" to the result (6), then "log" to the result (720), producing the result 2.85733.
A series of expressions can be written as in the following (hypothetical) example, each separated by a period. This example first creates a new instance of class Window, stores it in a variable, and then sends two messages to it.
If a series of messages are sent to the same receiver as in the example above, they can also be written as a "cascade" with individual messages separated by semicolons:
This rewrite of the earlier example as a single expression avoids the need to store the new window in a temporary variable. According to the usual precedence rules, the unary message "new" is sent first, and then "label:" and "open" are sent to the answer of "new".
Code blocks.
A block of code (an anonymous function) can be expressed as a literal value (which is an object, since all values are objects.) This is achieved with square brackets:
Where ":params" is the list of parameters the code can take. This means that the Smalltalk code:
can be understood as:
or expressed in lambda terms as:
and
can be evaluated as
Or in lambda terms as:
The resulting block object can form a closure: it can access the variables of its enclosing lexical scopes at any time. Blocks are first-class objects.
Blocks can be executed by sending them the "value" message (compound variations exist in order to provide parameters to the block e.g. 'value:value:' and 'valueWithArguments:').
The literal representation of blocks was an innovation which on the one hand allowed certain code to be significantly more readable; it allowed algorithms involving iteration to be coded in a clear and concise way. Code that would typically be written with loops in some languages can be written concisely in Smalltalk using blocks, sometimes in a single line. But more importantly blocks allow control structure to be expressed using messages and polymorphism, since blocks defer computation and polymorphism can be used to select alternatives. So if-then-else in Smalltalk is written and implemented as
Note that this is related to functional programming, where in patterns of computation (here selection) are abstracted into higher-order functions. For example, the message "select:" on a Collection is equivalent to the higher-order function filter on an appropriate functor.
Control structures.
Control structures do not have special syntax in Smalltalk. They are instead implemented as messages sent to objects. For example, conditional execution is implemented by sending the message ifTrue: to a Boolean object, passing as an argument the block of code to be executed if and only if the Boolean receiver is true.
The following code demonstrates this:
Blocks are also used to implement user-defined control structures, enumerators, visitors, pluggable behavior and many other patterns.
For example:
In the last line, the string is sent the message select: with an argument that is a code block literal. The code block literal will be used as a predicate function that should answer true if and only if an element of the String should be included in the Collection of characters that satisfy the test represented by the code block that is the argument to the "select:" message.
A String object responds to the "select:" message by iterating through its members (by sending itself the message "do:"), evaluating the selection block ("aBlock") once with each character it contains as the argument. When evaluated (by being sent the message "value: each"), the selection block (referenced by the parameter "aBlock", and defined by the block literal "[:aCharacter | aCharacter isVowel]"), answers a boolean, which is then sent "ifTrue:". If the boolean is the object true, the character is added to a string to be returned.
Because the "select:" method is defined in the abstract class Collection, it can also be used like this:
Classes.
This is a stock class definition:
Often, most of this definition will be filled in by the environment. Notice that this is actually a message to the "Object"-class to create a subclass called "MessagePublisher". In other words: classes are first-class objects in Smalltalk which can receive messages just like any other object and can be created dynamically at execution time.
Methods.
When an object receives a message, a method matching the message name is invoked. The following code defines a method publish, and so defines what will happen when this object receives the 'publish' message.
The following method demonstrates receiving multiple arguments and returning a value:
The method's name is codice_21. The return value is specified with the codice_22 operator.
Note that objects are responsible for determining dynamically at runtime which method to execute in response to a message—while in many languages this may be (sometimes, or even always) determined statically at compile time.
Instantiating classes.
The following code:
creates (and returns) a new instance of the MessagePublisher class. This is typically assigned to a variable:
However, it is also possible to send a message to a temporary, anonymous object:
Hello World example.
The Hello world program is used by virtually all texts to new programming languages as the first program learned to show the most basic syntax and environment of the language. For Smalltalk, the program is extremely simple to write. The following code, the message "show:" is sent to the object "Transcript" with the String literal 'Hello, world!' as its argument. Invocation of the "show:" method causes the characters of its argument (the String literal 'Hello, world!') to be displayed in the transcript ("terminal") window.
Note that a Transcript window would need to be open in order to see the results of this example.
Image-based persistence.
Most popular programming systems separate static program code (in the form of class definitions, functions or procedures) from dynamic, or run time, program state (such as objects or other forms of program data). They load program code when a program starts, and any prior program state must be recreated explicitly from configuration files or other data sources. Any settings the program (and programmer) does not explicitly save must be set up again for each restart. A traditional program also loses much useful document information each time a program saves a file, quits, and reloads. This loses details such as undo history or cursor position. Image based systems don't force losing all that just because a computer is turned off, or an OS updates.
Many Smalltalk systems, however, do not differentiate between program data (objects) and code (classes). In fact, classes are objects themselves. Therefore most Smalltalk systems store the entire program state (including both Class and non-Class objects) in an image file. The image can then be loaded by the Smalltalk virtual machine to restore a Smalltalk-like system to a prior state. This was inspired by FLEX, a language created by Alan Kay and described in his M.Sc. thesis.
Smalltalk images are similar to (restartable) core dumps and can provide the same functionality as core dumps, such as delayed or remote debugging with full access to the program state at the time of error. Other languages that model application code as a form of data, such as Lisp, often use image-based persistence as well. This method of persistence is powerful for rapid development because all the development information (e.g. parse trees of the program) is saved which facilitates debugging. However, it also has serious drawbacks as a true persistence mechanism. For one thing, developers may often want to hide implementation details and not make them available in a run time environment. For legal reasons as well as for maintenance reasons, allowing anyone to modify the program at run time inevitably introduces complexity and potential errors that would not be possible with a compiled system that does not expose source code in the run time environment. Also, while the persistence mechanism is easy to use it lacks the true persistence capabilities needed for most multi-user systems. The most obvious is the ability to do transactions with multiple users accessing the same database in parallel.
Level of access.
Everything in Smalltalk-80 is available for modification from within a running program. This means that, for example, the IDE can be changed in a running system without restarting it. In some implementations, the syntax of the language or the garbage collection implementation can also be changed on the fly. Even the statement codice_23 is valid in Smalltalk, although executing it is not recommended. When used judiciously, this level of flexibility allows for one of the shortest required times for new code to enter a production system. 
Just-in-time compilation.
Smalltalk programs are usually compiled to bytecode, which is then interpreted by a virtual machine or dynamically translated into machine-native code.

</doc>
<doc id="28320" url="http://en.wikipedia.org/wiki?curid=28320" title="Steve Biko">
Steve Biko

Stephen Bantu Biko (18 December 1946 – 12 September 1977) was an anti-apartheid activist in South Africa in the 1960s and 1970s.
A student leader, he later founded the Black Consciousness Movement which would empower and mobilize much of the urban black population. Since his death in police custody, he has been called a martyr of the anti-apartheid movement. While living, his writings and activism attempted to empower black people, and he was famous for his slogan "black is beautiful", which he described as meaning: "man, you are okay as you are, begin to look upon yourself as a human being".
Even though Biko was never a member of the African National Congress (ANC), the ANC has included him in the pantheon of struggle heroes, going as far as using his image for campaign posters in South Africa's first non-racial elections in 1994. Nelson Mandela said of Biko: "They had to kill him to prolong the life of apartheid."
Early life.
Biko was born to parents Mzingayi Mathew and Alice 'Mamcete' Biko in Ginsberg Township, in the present-day Eastern Cape province of South Africa. His father was a government clerk, while his mother did domestic work in surrounding white homes. The third of four children, Biko grew up with his older sister Bukelwa; his older brother Khaya; and his younger sister Nobandile. In 1950, at the age of four, Biko suffered the loss of his father who was studying law.
Biko was a Xhosa. In addition to Xhosa, he spoke fluent English and fairly fluent Afrikaans.
As a child, he attended Brownlee Primary School and Charles Morgan Higher Primary School. He was sent to Lovedale High School in 1964, a prestigious boarding school in Alice, Eastern Cape, where his older brother Khaya had previously been studying. During the apartheid era, with no freedom of association protection for non-white South Africans, Biko was expelled from Lovedale for his political views, and his brother arrested for his alleged association with Poqo (now known as the Azanian People's Liberation Army). After being expelled, he then attended and later graduated from St. Francis College, a Roman Catholic institution in Mariannhill, Natal.
He studied to be a doctor at the University of Natal Medical School.
Marriage and children.
Biko married Ntsiki Mashalaba in 1970. They had two children together: Nkosinathi, born in 1971, and Samora.
He also had two children with Dr Mamphela Ramphele, a prominent activist within the BCM: a daughter, Lerato, born in 1974, who died of pneumonia when she was only two months old, and a son, Hlumelo, who was born in 1978, after Biko's death.
Biko also had a daughter with Lorraine Tabane, named Motlatsi, born in May 1977.
Activism.
Biko was initially involved with the multiracial National Union of South African Students, but after he became convinced that Black, Indian and Coloured students needed an organization of their own, he helped found the South African Students' Organisation (SASO), whose agenda included political self-reliance and the unification of university students in a "black consciousness." In 1968 Biko was elected its first president. SASO evolved into the influential Black Consciousness Movement (BCM). Biko was also involved with the World Student Christian Federation.
In the early 1970s, Biko became a key figure in The Durban Moment. In 1972, he was expelled from the University of Natal because of his political activities and he became honorary president of the Black People's Convention. He was banned by the apartheid government in February 1973, meaning that he was not allowed to speak to more than one person at a time nor to speak in public, was restricted to the King William's Town magisterial district, and could not write publicly or speak with the media. It was also forbidden to quote anything he said, including speeches or simple conversations.
When Biko was banned, his movement within the country was restricted to the Eastern Cape, where he was born. After returning there, he formed a number of grassroots organizations based on the notion of self-reliance: Zanempilo, the Zimele Trust Fund (which helped support former political prisoners and their families), Njwaxa Leather-Works Project and the Ginsberg Education Fund.
In spite of the repression of the apartheid government, Biko and the BCM played a significant role in organising the protests that culminated in the Soweto Uprising of 16 June 1976. In the aftermath of the uprising, which was met with a heavy hand by the security forces, the authorities began to target Biko further.
Death and aftermath.
On 18 August 1977, Biko was arrested at a police roadblock under the Terrorism Act No 83 of 1967 and interrogated by officers of the Port Elizabeth security police including Harold Snyman and Gideon Nieuwoudt. This interrogation took place in the Police Room 619 of the Sanlam Building in Port Elizabeth. The interrogation lasted twenty-two hours and included torture and beatings resulting in a coma. He suffered a major head injury while in police custody at the Walmer Police Station, in a suburb of Port Elizabeth, and was chained to a window grille for a day.
On 11 September 1977, police loaded him in the back of a Land Rover, naked and restrained in manacles, and began the 1100 km drive to Pretoria to take him to a prison with hospital facilities. He was nearly dead owing to the previous injuries. He died shortly after arrival at the Pretoria prison, on 12 September. The police claimed his death was the result of an extended hunger strike, but an autopsy revealed multiple bruises and abrasions and that he ultimately succumbed to a brain hemorrhage from the massive injuries to the head, which many saw as strong evidence that he had been brutally clubbed by his captors. Then Donald Woods, a journalist, editor and close friend of Biko's, along with Helen Zille, later leader of the Democratic Alliance political party, exposed the truth behind Biko's death.
Because of his high profile, news of Biko's death spread quickly, publicizing the repressive nature of the apartheid government. His funeral was attended by over 10,000 people, including numerous ambassadors and other diplomats from the United States and Western Europe. The liberal white South African journalist Donald Woods, a personal friend of Biko, photographed his injuries in the morgue. Woods was later forced to flee South Africa for England. Donald Woods later campaigned against apartheid and further publicised Biko's life and death, writing many newspaper articles and authoring the book, "Biko", which was later turned into the film "Cry Freedom". Speaking at a National Party conference following the news of Biko's death then–minister of police, Jimmy Kruger said, "I am not glad and I am not sorry about Mr. Biko. It leaves me cold (Dit laat my koud). I can say nothing to you ... Any person who dies ... I shall also be sorry if I die."
After a 15-day inquest in 1978, a magistrate judge found there was not enough evidence to charge the officers with murder because there were no eyewitnesses. On 2 February 1978, based on the evidence given at the inquest, the attorney general of the Eastern Cape stated he would not prosecute. On 28 July 1979, the attorney for Biko's family announced that the South African government would pay them $78,000 in compensation for Biko's death.
The Truth and Reconciliation Commission, which was created following the end of minority rule and the apartheid system, reported that five former members of the South African security forces who had admitted to killing Biko were applying for amnesty. Their application was rejected in 1999.
On 7 October 2003, the South African justice ministry announced that the five policemen accused of killing Biko would not be prosecuted because the time limit for prosecution had elapsed and because of insufficient evidence.
A year after his death, some of his writings were collected and released under the title "I Write What I Like".
Influences and formation of ideology.
Like Frantz Fanon, Biko originally studied medicine, and, like Fanon, Biko developed an intense concern for the development of black consciousness as a solution to the existential struggles that shape existence, both as a human and as an African (see Négritude). Biko can thus be seen as a follower of Fanon and Aimé Césaire, in contrast to more multi-racialist ANC leaders such as Nelson Mandela after his imprisonment at Robben Island, and Albert Luthuli who were first disciples of Gandhi.
Biko saw the struggle for African consciousness as having two stages, "Psychological liberation" and "Physical liberation". The nonviolent influence of Gandhi and Martin Luther King, Jr. upon Biko is then suspect, as Biko knew that for his struggle to give rise to physical liberation, it was necessary that it exist within the political realities of the apartheid government, and Biko's nonviolence may be seen more as a tactic than a personal conviction.
Biko's relevance in the present.
In the present post-Apartheid South Africa, Biko is now revered across the political spectrum despite obvious ideological differences. Many of these people see Biko's philosophy as irrelevant after 1994. However, in 2004, he was voted 13th in the SABC3's Great South Africans.
However, many present-day social movements, activists, and academics continue to stress the relevance of Biko's black consciousness. This includes a strong critique of voting by writer and political activist Andile Mngxitama who has said that if Biko were alive today, he would not be supporting any political party, would not even vote, but would be marching with the social movements against government.
Tributes.
Biko is buried in the Ginsberg township cemetery, a place called the Steve Biko Garden of Remembrance in the Eastern Cape. 
Apart from Donald Woods's book called "Biko", his name has been honoured at several universities. Locally, the main Student Union buildings of the University of Cape Town are named in his honour and each year a commemorative Steve Biko lecture, open to all students, is delivered on the anniversary of his death. Internationally, the University of Manchester's student union, the Steve Biko Building, on the Oxford road campus, is named in his honour. Ruskin College, Oxford has a Biko House student accommodation. The bar at the University of Bradford was named after Biko until its closure in 2005. Numerous other venues in Students Unions around the United Kingdom also bear his name. The Santa Barbara Student Housing Cooperative has a house named after Steve Biko, themed to provide a safe, respectful space for people of colour. In London, streets in both Finsbury Park and Hounslow are named after him. At the University of California, Santa Cruz, there is a section of dormitories named "Biko House" located in the Oakes College Multicultural Theme Housing. The Steve Biko Institute was founded in Salvador, Brazil to support the education and pride of Black Brazilians. The Pretoria Academic Hospital was renamed the Steve Biko Academic Hospital in 2008. Durban University of Technology has acknowledged Steve Biko's contribution to South African Society by naming its largest campus after him. A bronze bust of Steve Biko was unveiled in Freedom Square on this campus as a tribute to him.
Further reading.
</dl>
External links.
</dl>

</doc>
<doc id="28321" url="http://en.wikipedia.org/wiki?curid=28321" title="Survivor">
Survivor

Survivor may refer to:

</doc>
<doc id="28323" url="http://en.wikipedia.org/wiki?curid=28323" title="Samhain">
Samhain

Samhain (pronounced or ]) is a Gaelic festival marking the end of the harvest season and the beginning of winter or the "darker half" of the year. It is celebrated from sunset on 31 October to sunset on 1 November, or about halfway between the autumn equinox and the winter solstice. It is one of the four Gaelic seasonal festivals, along with Imbolc, Beltane and Lughnasadh. Historically, it was widely observed throughout Ireland, and later the Isle of Man and Scotland. Kindred festivals were held at the same time of year in other Celtic lands; for example the Brythonic Calan Gaeaf (in Wales), Kalan Gwav (in Cornwall), and Kalan Goañv (in Brittany).
Samhain is mentioned in some of the earliest Irish literature and is known to have pre-Christian roots. Many important events in Irish mythology happen or begin on Samhain. It was the time when cattle were brought back down from the summer pastures and when livestock were slaughtered for the winter. As at Beltane, special bonfires were lit. These were deemed to have protective and cleansing powers and there were rituals involving them. Samhain (like Beltane) was seen as a liminal time, when the spirits or fairies (the Aos Sí) could more easily come into our world. Most scholars see the Aos Sí as remnants of the pagan gods and nature spirits. It was believed that the Aos Sí needed to be propitiated to ensure that the people and their livestock survived the winter. Offerings of food and drink were left for them. The souls of the dead were also thought to revisit their homes. Feasts were had, at which the souls of dead kin were beckoned to attend and a place set at the table for them. Mumming and guising were part of the festival, and involved people going door-to-door in costume (or in disguise), often reciting verses in exchange for food. The costumes may have been a way of imitating, or disguising oneself from, the Aos Sí. Divination rituals were also a big part of the festival and often involved nuts and apples. In the late 19th century, Sir John Rhys and Sir James Frazer suggested that it was the "Celtic New Year", and this view has been repeated by some other scholars.
In the 9th century, the Roman Catholic Church shifted the date of All Saints' Day to 1 November, while 2 November later became All Souls' Day. Over time, Samhain and All Saints'/All Souls' merged to create the modern Halloween. Historians have used the name 'Samhain' to refer to Gaelic 'Halloween' customs up until the 19th century.
Since the latter 20th century, Celtic neopagans and Wiccans have observed Samhain, or something based on it, as a religious holiday. Neopagans in the Southern Hemisphere often celebrate Samhain at the other end of the year (~30 April – 1 May).
Etymology.
In Modern Irish the name is "Samhain" ], in Scottish Gaelic "Samhainn/Samhuinn" ], and in Manx Gaelic "Sauin". These are also the names of November in each language, shortened from "Mí na Samhna" (Irish), "Mì na Samhna" (Scottish Gaelic) and "Mee Houney" (Manx). The night of 31 October (Halloween) is "Oíche Shamhna" (Irish), "Oidhche Shamhna" (Scottish Gaelic) and "Oie Houney" (Manx), all meaning "Samhain night". 1 November, or the whole festival, may be called "Lá Samhna" (Irish), "Là Samhna" (Scottish Gaelic) and "Laa Houney" (Manx), all meaning "Samhain day".
These names all come from the Old Irish "samain, samuin" or "samfuin" ] all referring to 1 November ("latha na samna": 'samhain day'), and the festival and royal assembly held on that date in medieval Ireland ("oenaig na samna": 'samhain assembly'). Its meaning is glossed as 'summer's end', and the frequent spelling with "f" suggests analysis by popular etymology as "sam" ('summer') and "fuin" ('end'). The Old Irish "sam" is from Proto-Indo-European (PIE) "*semo-"; cognates include Welsh "haf", Breton "hañv", English "summer" and Old Norse "sumar", all meaning 'summer', and the Sanskrit "sáma" ('season').
In 1907, Whitley Stokes suggested an etymology from Proto-Celtic "*samani" ('assembly'), cognate to Sanskrit "sámana", and Gothic "samana". J. Vendryes concludes that "samain" is unrelated to "*semo-" ('summer'), remarking that the Celtic 'end of summer' was in July, not November, as evidenced by Welsh "gorffennaf" ('July'). We would therefore be dealing with an Insular Celtic word for 'assembly', "*samani" or "*samoni", and a word for 'summer', "saminos" (from "*samo-": 'summer') alongside "samrad", "*samo-roto-".
Coligny calendar.
The Gaulish month name on the Coligny calendar is likely related to the words "Samhain" and "summer". A festival of some kind may have been held during the 'three nights of "Samonios"' (Gaulish "trinux[tion] samo[nii]"). The Gaulish calendar seems to have split the year into two-halves: the first beginning with the month and the second beginning with the month , which is related to the word for winter, PIE "*g'hei-men-" (Latin "hiems", Latvian "ziema", Lithuanian "žiema", Slavic "zima", Greek "kheimon", Hittite "gimmanza"), cf. Old Irish "gem-adaig" ('winter's night'). The lunations marking the middle of each half-year may also have been marked by festivals
History.
"Samain" or "Samuin" was the name of the "feis" or festival marking the beginning of winter in Gaelic Ireland. It is attested in some of the earliest Old Irish literature, from the 10th century onward. It was one of four Gaelic seasonal festivals: Samhain (~1 November), Imbolc (~1 February), Beltane (~1 May) and Lughnasadh (~1 August). Samhain and Beltane, at the witherward side of the year from each other, are thought to have been the most important. Sir James George Frazer wrote in "The Golden Bough: A Study in Magic and Religion" that 1 May and 1 November are of little importance to European crop-growers, but of great importance to herdsmen. It is at the beginning of summer that cattle are driven to the upland summer pastures and the beginning of winter that they are led back. Thus, Frazer suggests that halving the year at 1 May and 1 November dates from a time when the Celts were mainly a pastoral people, dependent on their herds. In medieval Ireland the festival marked the end of the season for trade and warfare and was an ideal date for tribal gatherings. These gatherings are a popular setting for early Irish tales.
In Irish mythology.
Irish mythology was originally a spoken tradition, but the tales were eventually written down by Christian monks in the Middle Ages, who are thought to have Christianized many of them. According to Irish mythology, Samhain (like Beltane) was a time when the doorways to the Otherworld opened, allowing the spirits and the dead to come into our world; but while Beltane was a summer festival for the living, Samhain "was essentially a festival for the dead." "The Boyhood Deeds of Fionn" says that the "sídhe" (fairy mounds or portals to the Otherworld) "were always open at Samhain." Like Beltane, Lughnasadh and Imbolc, Samhain also involved great feasts. Mythology suggests that drinking alcohol was part of the feast, and it is noteworthy that every tale that features drunkenness is said to take place at Samhain.
Many important events in Irish mythology happen or begin on Samhain. The invasion of Ulster that makes up the main action of the "Táin Bó Cúailnge" (Cattle Raid of Cooley) begins on Samhain. As cattle-raiding typically was a summer activity, the invasion during this off-season surprised the Ulstermen. The "Second Battle of Maighe Tuireadh" also begins on Samhain. The Morrígan (Morríghan) and The Dagda (Daghdha) meet and have sex before the battle against the Fomorians; in this way the Morrígan acts as a sovereignty figure and gives the victory to the Dagda's people, the Tuatha Dé Danann.
According to the "Dindsenchas" and "Annals of the Four Masters," which were written by Christian monks, Samhain in ancient Ireland was associated with the god Crom Cruach. The texts claim that King Tigernmas (Tighearnmhas) made offerings to Crom Cruach each Samhain, sacrificing a first-born child by smashing their head against a stone idol of the god. The "Four Masters" says that Tigernmas, with "three-fourths of the men of Ireland about him" died while worshiping Crom Cruach at Magh Slécht on Samhain. Other texts say that Irish kings Diarmait mac Cerbaill and Muirchertach mac Ercae both die a threefold death on Samhain, which may be linked to human sacrifice.
The Ulster Cycle contains many references to Samhain. In the 10th-century "Tochmarc Emire," or "The Wooing of Emer," Samhain is the first of the four "quarter days" of the year mentioned by the heroine Emer. The 12th century tales "Mesca Ulad" and "Serglige Con Culainn" begin at Samhain. In "Serglige Con Culainn," it is said that the festival of the Ulaidh at Samhain lasted a week: Samhain itself, and the three days before and after. They would gather on the Plain of Muirthemni where there would be meetings, games, and feasting. In "Aislinge Óengusa," or "The Dream of Óengus," it is when he and his bride-to-be switch from bird to human form, and in "Tochmarc Étaíne," or "The Wooing of Étaín," it is the day on which Óengus claims the kingship of Brú na Bóinne. In "Echtra Neraí," or "The Adventure of Nera," one Nera from Connacht undergoes a test of bravery on Samhain put forth by King Ailill. The prize is the king's own gold-hilted sword. To win it, a man must leave the warmth and safety of Ailill's hall and make their way through the night to a gallows where two prisoners had been hanged the day before, tie a twig around one man's ankle, and return. Others had been thwarted by the demons and spirits that harried them as they attempted the task, quickly coming back to Ailill's hall in shame. However, Nera fulfills the task and infiltrates the fairy mound, where he remains trapped until next Samhain. Taking etymology into consideration, it is interesting to note that the word for summer in the "Echtra Nerai" is "samraid."
The other cycles feature Samhain as well. The 14th century "Aided Chrimthainn maic Fidaig," or "The Killing of Crimthann mac Fidaig," tells how Mongfind (Mongfhionn) tried to kill her own brother Crimthann (the King of Munster) to make sure her son Brian succeeded to the throne. Mongfind offered Crimthann a poisoned drink at the Samhain feast, but he dared her to drink from it first. Having no other choice but to drink the poison, she died on the eve of Samhain, after which the festival came to be known as Mongfind's or Mongfhionn's Feast, "wherefore women and the rabble make petitions to her on "samain"-eve."
In the aforesaid "Boyhood Deeds of Fionn," the young Fionn Mac Cumhaill visits Tara where Aillen the Burner puts everyone to sleep at Samhain and burns the place. However, Fionn is able to stay awake and slays Aillen, and is made the head of the fianna.
Several sites in Ireland are especially linked to Samhain. A host of otherworldly beings was said to emerge from Oweynagat ("cave of the cats"), near Rathcroghan in County Roscommon, each Samhain. The Hill of Ward (or Tlachta) in County Meath is thought to have been the site of a great Samhain gathering and bonfire; the Iron Age ringfort is said to have been where the goddess or druid Tlachta died, giving birth to triplets that resulted from rape.
In "The Stations of the Sun: A History of the Ritual Year in Britain" (1996), Ronald Hutton writes: "No doubt there were [pagan] religious observances as well, but none of the tales ever portrays any." The only historic reference to religious rites is in the work of the "thoroughly unreliable" Geoffrey Keating (died 1644), who says that the druids of Ireland would gather on Tlachta on Samhain night to kindle a sacred fire. However, his source is unknown. Hutton says it may be that no religious rites are mentioned because, centuries after Christianization, the writers were left with no record of what they had been which they could have consulted.
The idea that, in Old Irish literature, Samhain is particularly associated with the supernatural is due to Jeffrey Gantz and others. Hutton criticises this as unfounded; he argues that the gatherings of royalty and warriors on Samhain are simply an ideal setting for such tales in the same way that many Arthurian tales are set at courtly gatherings at Christmas or Pentecost.
Historic customs.
Samhain was one of the four main festivals of the Gaelic calendar, marking the end of the harvest and beginning of winter. Traditionally, Samhain was a time to take stock of the herds and food supplies. Cattle were brought down to the winter pastures after six months in the higher summer pastures. It was also the time to choose which animals would need to be slaughtered for the winter. This custom is still observed by many who farm and raise livestock because it is when meat will keep since the freeze has come and also since summer grass is gone and free foraging is no longer possible. It is thought that some of the rituals associated with the slaughter have been transferred to other holidays. On St. Martin's Day (11 November) in Ireland, one of the animals was offered to Saint Martin, who may have taken the place of a god. At New Year in the Hebrides, people would circle their district sunwise dressed in a cowhide. A bit of the hide would be burnt and the smoke inhaled by each person. These customs were meant to keep away bad luck, and similar customs were found in other Celtic regions. The slaughter would be followed by feasting.
As at Beltane, bonfires were lit on hilltops at Samhain and there were rituals involving them. However, by the modern era, they only seem to have been common along Scotland's Highland Line, on the Isle of Man, in north and mid Wales, and in parts of Ulster heavily settled by Scots. F. Marian McNeill says that a force-fire (or need-fire) was once the usual way of lighting them, but notes that this gradually fell out of use. Likewise, only certain kinds of wood may once have been used, but later records show that many kinds of flammable material were burnt. It is suggested that the fires were a kind of imitative or sympathetic magic – they mimicked the Sun, helping the "powers of growth" and holding back the decay and darkness of winter. They may also have served to symbolically "burn up and destroy all harmful influences". Accounts from the 18th and 19th centuries suggest that the fires (as well as their smoke and ashes) were deemed to have protective and cleansing powers. In Moray, boys asked for bonfire fuel from each house in the village. When the fire was lit, "one after another of the youths laid himself down on the ground as near to the fire as possible so as not to be burned, and in such a position as to let the smoke roll over him. The others ran through the smoke and jumped over him". When the bonfire burnt down, they scattered the ashes, vying with each other who should scatter them most. Sometimes, two bonfires would be built side by side, and the people – sometimes with their livestock – would walk between them as a cleansing ritual. The bones of slaughtered cattle were said to have been cast upon bonfires. In the pre-Christian Gaelic world, cattle were the main form of wealth and were the center of agricultural and pastoral life.
People also took flames from the bonfire back to their homes. In northeastern Scotland, they carried burning fir around their fields to protect them, and on South Uist they did likewise with burning turf. In some places, people doused their hearth fires on Samhain night. Each family then solemnly re-lit its hearth from the communal bonfire, thus bonding the families of the village together. In the 17th century, Geoffrey Keating wrote that the druids of ancient Ireland would gather on Tlachta on Samhain night to kindle a sacred fire. From this, every bonfire in the land was lit, and from thence every home in the land relit their hearth, which had been doused that night. However, his source is unknown, and Ronald Hutton supposes that Keating had mistaken a Beltane custom for a Samhain one. Dousing the old fire and bringing in the new may have been a way of banishing evil, which was done at New Year festivals in many countries.
The bonfires were also used in divination rituals. In the late 18th century, in Ochtertyre, a ring of stones was laid round the fire to represent each person. Everyone then ran round it with a torch, "exulting". In the morning, the stones were examined and if any was mislaid it was said that the person for whom it was set would not live out the year. A similar custom was observed in north Wales and in Brittany. James Frazer says that this may come from "an older custom of actually burning them" (i.e. human sacrifice) or may have always been symbolic. Divination has likely been a part of the festival since ancient times, and it has survived in some rural areas. At household festivities throughout the Gaelic regions and Wales, there were many rituals intended to divine the future of those gathered, especially with regard to death and marriage. Seasonal foods such as apples and nuts were often used in these rituals. Apples were peeled, the peel tossed over the shoulder, and its shape examined to see if it formed the first letter of the future spouse's name. Nuts were roasted on the hearth and their behaviour interpreted – if the nuts stayed together, so would the couple. Egg whites were dropped in water, and the shapes foretold the number of future children. Children would also chase crows and divine some of these things from the number of birds or the direction they flew.
As noted earlier, Samhain was seen as a liminal time, when spirits or fairies (the "aos sí") could more easily come into our world. Many scholars see the "aos sí" as remnants of the pagan gods and nature spirits. At Samhain, it was believed that the "aos sí" needed to be propitiated to ensure that the people and their livestock survived the harsh winter. As such, offerings of food and drink have traditionally been left for the "aos sí". Portions of the crops might also be left in the ground for them. One custom—described a "blatant example" of a "pagan rite surviving into the Christian epoch"—was observed in the Outer Hebrides until the early 19th century. On 31 October, the locals would go down to the shore. One man would wade into the water up to his waist, where he would pour out a cup of ale and ask 'Seonaidh' ('Shoney'), whom he called "god of the sea", to bestow blessings on them. People also took special care not to offend the "aos sí" and sought to ward-off any who were out to cause mischief. They stayed near to home or, if forced to walk in the darkness, turned their clothing inside-out or carried iron or salt to keep them at bay. The souls of the dead were also thought to revisit their homes. Places were set at the dinner table or by the fire to welcome them. The belief that the souls of the dead return home on one night or day of the year seems to have ancient origins and is found in many cultures throughout the world. However, the souls of thankful kin could return to bestow blessings just as easily as that of a murdered person could return to wreak revenge.
Mumming and guising was a part of Samhain from at least the 16th century and was recorded in parts of Ireland, Scotland, Mann and Wales. It involved people going from house to house in costume (or in disguise), usually reciting songs or verses in exchange for food. The costumes may have been a way of imitating, or disguising oneself from, the "aos sí". S. V. Peddle writes that they "personify the old spirits of the winter, who demanded reward in exchange for good fortune". McNeill suggests that the ancient festival included people in masks or costumes representing these spirits and that the modern custom came from this. In Ireland, costumes were sometimes worn by those who went about before nightfall collecting for a Samhain feast. In parts of southern Ireland during the 19th century, the guisers included a hobby horse known as the "Láir Bhán" (white mare). A man covered in a white sheet and carrying a decorated horse skull (representing the "Láir Bhán") would lead a group of youths, blowing on cow horns, from farm to farm. At each they recited verses, some of which "savoured strongly of paganism", and the farmer was expected to donate food. If the farmer donated food he could expect good fortune from the 'Muck Olla'; not doing so would bring misfortune. This is akin to the "Mari Lwyd" (grey mare) procession in Wales, which takes place at Midwinter. In Wales the white horse is often seen as an omen of death. In some places, young people cross-dressed. In Scotland, young men went house-to-house with masked, veiled, painted or blackened faces, often threatening to do mischief if they were not welcomed. This was common in the 16th century in the Scottish countryside and persisted into the 20th. It is suggested that the blackened faces comes from using the bonfire's ashes for protection. Elsewhere in Europe, costumes, mumming and hobby horses were part of other yearly festivals. However, in the Celtic-speaking regions they were "particularly appropriate to a night upon which supernatural beings were said to be abroad and could be imitated or warded off by human wanderers".
Hutton writes: "When imitating malignant spirits it was a very short step from guising to playing pranks". Playing pranks at Samhain is recorded in the Scottish Highlands as far back as 1736 and was also common in Ireland, which led to Samhain being nicknamed "Mischief Night" in some parts. Wearing costumes at Halloween spread to England in the 20th century, as did the custom of playing pranks, though there had been mumming at other festivals. At the time of mass transatlantic Irish and Scottish immigration, which popularised Halloween in North America, Halloween in Ireland and Scotland had a strong tradition of guising and pranks. Trick-or-treating may have come from the custom of going door-to-door collecting food for Samhain feasts, fuel for Samhain bonfires and/or offerings for the "aos sí". Alternatively, it may have come from the All Saints/All Souls custom of collecting soul cakes.
The "traditional illumination for guisers or pranksters abroad on the night in some places was provided by turnips or mangel wurzels, hollowed out to act as lanterns and often carved with grotesque faces to represent spirits or goblins". They may have also been used to protect oneself from harmful spirits. These were common in parts of Ireland and the Scotland into the 20th century. They were also found in Somerset (see Punkie Night). In the 20th century they spread to other parts of England and became generally known as jack-o'-lanterns.
Celtic Revival.
During the late 19th and early 20th century Celtic Revival, there was an upswell of interest in Samhain and the other Celtic festivals. Sir John Rhys put forth that it had been the "Celtic New Year". He inferred it from contemporary folklore in Ireland and Wales, which he felt was "full of Hallowe'en customs associated with new beginnings". He visited Mann and found that the Manx sometimes called 31 October "New Year's Night" or "Hog-unnaa". The "Tochmarc Emire", written in the Middle Ages, reckoned the year around the four festivals at the beginning of the seasons, and put Samhain at the beginning of those. However, Hutton says that the evidence for it being the Celtic or Gaelic New Year's Day is flimsy. Rhys's theory was popularised by Sir James George Frazer, though at times he did acknowledge that the evidence is inconclusive. Frazer also put forth that Samhain had been the pagan Celtic festival of the dead and that it had been Christianized as All Saints and All Souls. Since then, Samhain has been popularly seen as the Celtic New Year and an ancient festival of the dead. The calendar of the Celtic League, for example, begins and ends at Samhain.
Related festivals.
In the Brythonic branch of the Celtic languages, Samhain is known as the 'calends of winter'. The Brythonic lands of Wales, Cornwall and Brittany held festivals on 31 October similar to the Gaelic one. In Wales it is "Calan Gaeaf", in Cornwall it is Allantide or "Kalan Gwav" and in Brittany it is "Kalan Goañv".
The Manx celebrate Hop-tu-Naa on 31 October, which is a celebration of the original New Year's Eve. The term is Manx Gaelic in origin, possibly from "Shogh ta'n Oie", meaning "this is the night". Traditionally, children dress as scary beings, carry turnips rather than pumpkins and sing an Anglicized version of "Jinnie the Witch" and may go from house to house asking for sweets or money.
All Saints' Day.
The Roman Catholic holy day of All Saints (or All Hallows) was introduced in the year 609, but was originally celebrated on 13 May. In 835, Louis the Pious switched it to 1 November in the Carolingian Empire, at the behest of Pope Gregory IV. However, from the testimony of Pseudo-Bede, it is known that churches in what are now England and Germany were already celebrating All Saints on 1 November at the beginning of the 8th century. Thus, Louis merely made official the custom of celebrating it on 1 November. James Frazer suggests that 1 November was chosen because it was the date of the Celtic festival of the dead (Samhain) – the Celts had influenced their English neighbours, and English missionaries had influenced the Germans. However, Ronald Hutton points out that, according to Óengus of Tallaght (d. ca. 824), the 7th/8th century church in Ireland celebrated All Saints on 20 April. He suggests that the 1 November date was a Germanic rather than a Celtic idea.
Over time, the night of 31 October came to be called All Hallows' Eve (or All Hallows' Even). Samhain influenced All Hallows' Eve and vice versa, and the two eventually morphed into the secular holiday known as Halloween.
Neopaganism.
Samhain and Samhain-based festivals are held by some Neopagans. As there are many kinds of Neopaganism, their Samhain celebrations can be very different despite the shared name. Some try to emulate the historic festival as much as possible. Other Neopagans base their celebrations on sundry unrelated sources, Gaelic culture being only one of the sources. Folklorist Jenny Butler describes how Irish pagans pick some elements of historic Samhain celebrations and meld them with references to the Celtic past, making a new festival of Samhain that is inimitably part of neo-pagan culture.
Neopagans usually celebrate Samhain on 31 October – 1 November in the Northern Hemisphere and 30 April – 1 May in the Southern Hemisphere, beginning and ending at sundown. Some Neopagans celebrate it at the astronomical midpoint between the autumn equinox and winter solstice (or the full moon nearest this point). In the Northern Hemisphere, this midpoint is when the ecliptic longitude of the Sun reaches 225 degrees. In 2013, this is on 7 November.
Celtic Reconstructionism.
Like other Reconstructionist traditions, Celtic Reconstructionist Pagans emphasise historical accuracy. They base their celebrations and rituals on traditional lore as well as research into the beliefs of the polytheistic Celts.
Celtic Reconstructionist Pagans (or CRs) often celebrate Samhain on the date of first frost, or when the last of the harvest is in and the ground is dry enough to have a bonfire. Some follow the old tradition of building two bonfires, which celebrants and livestock then walk or dance between as a ritual of purification. For CRs, it is a time when the dead are especially honoured. Though CRs make offerings at all times of the year, Samhain is a time when more elaborate offerings are made to specific ancestors. This may involve making a small shrine. Often there will be a meal, where a place for the dead is set at the table and they are invited to join. Traditional tales may be told and traditional songs, poems and dances performed. A western-facing door or window may be opened and a candle left burning on the windowsill to guide the dead home. Divination for the coming year is often done, whether in all solemnity or as games for the children. The more mystically inclined may also see this as a time for deeply communing with their deities, especially those seen as being particularly linked with this festival.
Wicca.
Wiccans celebrate a variation of Samhain as one of the yearly Sabbats of the Wheel of the Year. It is deemed by most Wiccans to be the most important of the four "greater Sabbats". Samhain is seen by some Wiccans as a time to celebrate the lives of those who have died, and it often involves paying respect to ancestors, family members, elders of the faith, friends, pets and other loved ones who have died. In some rituals the spirits of the dead are invited to attend the festivities. It is seen as a festival of darkness, which is balanced at the opposite point of the wheel by the spring festival of Beltane, which Wiccans celebrate as a festival of light and fertility.
Wiccans believe that at Samhain the veil between this world and the afterlife is at its thinnest point of the whole year, making it easier to communicate with those who have left this world.
Secondary sources.
</dl>
Further reading.
</dl>

</doc>
<doc id="28327" url="http://en.wikipedia.org/wiki?curid=28327" title="Stargate (film)">
Stargate (film)

Stargate (French: "Stargate, la porte des étoiles") is a 1994 French-American adventure science fiction film released through Metro-Goldwyn-Mayer (MGM) and Carolco Pictures. Created by Dean Devlin and Roland Emmerich, the film is the first release in the "Stargate" franchise. Directed by Roland Emmerich, the film stars Kurt Russell, James Spader, Jaye Davidson, Alexis Cruz, Mili Avital, and Viveca Lindfors. The plot centers on the premise of a "Stargate", an ancient ring-shaped device that creates a wormhole enabling travel to a similar device elsewhere in the universe. The film's central plot explores the theory of extraterrestrial beings having an influence upon human civilization.
The film had a mixed initial critical reception, earning both praise and criticism for its atmosphere, story, characters, and graphic content. Nevertheless, "Stargate" became a commercial success worldwide. Devlin and Emmerich gave the rights to the franchise to MGM when they were working on their 1996 film "Independence Day", and MGM retains the domestic television rights. The rights to the "Stargate" film are owned by StudioCanal, with Lions Gate Entertainment handling most distribution in international theatrical and worldwide home video releases as the MGM name and logo is removed from the packaging, trailer and credits of the film, although Rialto Pictures handles domestic distribution under license from StudioCanal.
Plot.
A massive metal ring with engraved cover stones is discovered in the sands of Giza, Egypt in 1928, by an archaeologist named Langford and his young daughter, Catherine. Much later, the elderly Catherine Langford offers Egyptologist and linguist Daniel Jackson the chance to translate the Egyptian hieroglyphs on the cover stones. Jackson accepts and travels to a US Air Force installation where he examines the stones. Special Operations Colonel Jack O'Neil arrives to take command of the project and he declares it "classified" before Jackson can begin his research.
Jackson deduces from the hieroglyphs the existence of a "stargate", a device used to travel to distant worlds. He discovers that the accompanying non-hieroglyphic symbols are star constellations used in a three-dimensional coordinate system. When selected in sequence on the metal ring, they create a stable wormhole to some other place in the galaxy. O'Neil leads a team with Jackson through the Stargate, and they find themselves inside a pyramid in the middle of a desert. The team cannot return home because the necessary coordinates are missing. Jackson, O'Neil, and the others explore the surrounding area and discover a mining operation run by humans. The miners assume that they are emissaries of their god Ra.
Jackson attempts communication with the locals using pantomime, and later realizes that they speak a modern dialect derived from Ancient Egyptian. The soldiers develop a friendship with local teenager Skaara and his friends, and Jackson is given the chieftain Kasuf's daughter Sha'uri as a gift. He initially rebuffs her, unaware that she is meant to be his wife, but they develop a friendship that blossoms into romance. Jackson guesses that Sha'uri may know the location of the cartouche containing the return coordinates for the Stargate. Jackson learns that the Egyptian god Ra was an alien lifeform who came to Earth seeking a cure for his impending death. Ra discovered that he could maintain a simpler Human body indefinitely, and he "possessed" the body of a human youth, enslaved the youth's people and transported some of them to another planet to mine the mineral on which all of his technology is based. The enslaved Humans on Earth eventually rebelled and expelled Ra, and buried the Stargate. Fearful of a similar rebellion on this planet, Ra outlawed reading and writing so the people would forget their origins. Jackson discovers six symbols of the return coordinates but the seventh symbol is missing.
At night, a pyramid shaped spacecraft descends over the pyramid. Returning to it the following morning, O'Neil and Jackson are captured and taken to Ra, who appears to be an androgynous human youth with glowing eyes. Ra reveals his intention to return to Earth an atomic bomb brought by O'Neil, its destructive power now enhanced 100-fold with the addition of the mined mineral. O'Neil tries to disarm the guards and kill Ra, but Jackson is killed and O'Neil and his team are imprisoned. Jackson is regenerated in a sarcophagus-like device and meets with Ra. Ra states that he will kill Jackson and everyone who has seen him unless Jackson kills the rest of the team to remind Kasuf's people that Ra is their true god.
Once Ra has the local people gathered before the pyramid, Skaara and his friends create a distraction while Jackson turns one of the guards' weapons on Ra. In the confusion, Jackson and O'Neil's team escape and take shelter in a cave with Skaara and the others. The next morning, Skaara draws a picture of the victory against Ra, and Jackson realizes that Skaara has drawn the seventh symbol needed to reactivate the Stargate.
O'Neil and Skaara's group attack and overpower the overseers of the mine and convince the people that their "gods" are human. With their help, O'Neil's team return to the Stargate to deactivate the bomb. Faced with open rebellion, Ra prepares his ship to leave and launches fighters to counter-attack. Sha'uri is killed in the battle, but Jackson takes her into the ship and resurrects her in Ra's sarcophagus device. Ra orders the augmented bomb be sent to Earth immediately. Ra's guard captain discovers O'Neil, and they fight. Jackson and Sha'uri are captured by Ra, but O'Neil overpowers the guard and activates a teleportation device. The beam decapitates the guard captain and sends the head to Ra, while retrieving Jackson and Sha'uri. As Ra's craft escapes the planet, O'Neil and Jackson teleport the bomb to Ra's ship. The bomb detonates, killing Ra and destroying the ship. Skaara's people celebrate their freedom and Jackson decides to remain on the planet with Sha'uri. O'Neil and the survivors of his team return to Earth.
Director's cut.
The Director's cut had several scenes which were cut from the theatrical film version. The first such scene took place immediately after the excavation of the Stargate in 1928 and showed petrified Horus guards near the cover stones; the producers had tried to introduce the idea that beings had attempted to come through the Stargate after its burial, but they cut the scene for time concerns.
Production.
Development.
The film was originally planned to play out in a chronological order, but when Devlin and Emmerich edited the film to tighten the narrative, they decided to change the first scene of the film into a flashback to show who the human host of Ra was before the aliens took him. Only Jaye Davidson's upper torso was filmed because Davidson had refused to take out his nipple rings. The first scene was a combination of model shots and a set in Yuma, Arizona where "" had been filmed. The scene of the excavation of the Stargate was also filmed in three days in Arizona. A golden look was achieved by filming near the time of sunset. To keep within the limit of the budget, the producers put stick figures with cloth in the distant desert to appear as humans. The original Stargate was painted black, but it looked like a giant tire so it was repainted silver at the last moment.
Daniel Jackson's lecture on his theories was filmed in a hotel in Los Angeles. The scene was originally much longer and delved more into the theories that aliens had built the Egyptian pyramids, but the scene was trimmed for time concerns for the release. The scenes with O'Neil at his house were the first scenes filmed with Kurt Russell; his hair was cut short afterwards. Russell requested his hair color to be brightened a little for the film. The fictional facility housing the Stargate was the largest set for the film, located in Long Beach, California. Egyptologist Stuart Tyson Smith joined production to make all Ancient Egyptian hieroglyphics and spoken language as accurate as possible.
Filming.
The mask of the pharaoh in the opening credits was made out of fiber glass and modeled in the workshop. The sequence used a motion-control camera to give better depth of field. The score of "Stargate" was composer David Arnold's first work on an American feature film. When Devlin and Emmerich first flew to London to meet with Arnold, they had not yet heard the score; hearing it, they felt "he had elevated the film to a whole other level". Arnold later interviewed the actors during principal photography, using the information to improve his score.
Visual effects.
Jeff Kleiser and Kleiser-Walczak Construction Co.'s visual effects team of 40 people created the look of the Stargate. They used self-written image-creation and compositing software, as well as commercial digital packages to create the Stargate, the morphing helmets worn by Ra and the Horus guards, and the cityscape of Nagada. Footprints in the sand were often digitally removed. The creation of the wormhole, which was fully digital, was one of the biggest challenges in the making of the film. The ripples had to be digitally composited to appear accurate and realistic. Scanning lasers were lined up parallel to the gate to illustrate the amount of body that passed the surface of the Stargate plane. Afterwards, the parts of the body that had or had not yet gone through the gate (depending of the side of filming) were obliterated with a digital matte - a process that removes unwanted components from an individual frame or sequence of frames. The use of computers generating a big 3D storyboard allowed Emmerich to try out different shooting angles before settling on one angle.
Music and soundtrack.
The soundtrack was composed by David Arnold, played by the Sinfonia of London and conducted by Nicholas Dodd. It was the second motion picture Arnold had composed and the first major motion picture. At the time of Stargate's production, David Arnold had recently started to work in a local video store in London. Once Arnold got the job, he spent several months in a hotel room working on the soundtrack, spending more time rewriting the music and improving it as delays were being created due to film companies trying to get the rights to release the film. According to Arnold "when I first read the script for StarGate, I knew what approach to take, which was to be as big and bold as possible," he kept on saying:
Release.
The film was released on October 28, 1994 in the United States and released internationally in December of the same year. In 1995 the film was released on VHS and as a Dolby Digital encoded laserdisc spanning two discs (three sides). The first DVD release was on June 18, 1997. The DVD format was re-released in October 1999 under the title "Stargate Special Edition". The film was released on Blu-ray format on August 29, 2006.
Critical reception.
"Stargate" has garnered mostly mixed reviews. In the Rotten Tomatoes main "T-Meter Critics" section, 48% of critics gave the film a positive review based on 40 reviews, with an average rating of 5.3 out of 10. At MRQE, which assigns a normalized rating out of 100 from most critics, the film holds a score of 64 based on 95 reviews. Out of Emmerich's 22 works, "Stargate" is his 3rd highest rated film.
Most of the negative reviews focused on the overuse of special effects, thinness of plot and excessive use of clichés with Roger Ebert going so far as to say, "the movie "Ed Wood", about the worst director of all time, was made to prepare us for "Stargate"". Ebert awarded the film one out of four stars, and even over ten years later "Stargate" remained on his list of most hated films. Mike DiBella from Allmovie said, "there simply isn't enough spectacle in "Stargate" to make up for its many flaws." The film peaked at number one on the "Billboard" chart "Top Video Rentals" on April 29, 1995. However the positive reviews stated that it was an "instant camp classic", and praised the film for its special effects and entertainment value, with Chris Hicks of the "Deseret News" calling it ""Star Wars" meets "Ben Hur"". Scott McKenzie from DVDactive said this about the film "it's a shame because the world created around the "Stargate" is compelling and detailed. It's almost enough to make me want to watch the TV series, but not quite." After the release of the movie, Emmerich and Devlin were sued by an Egyptology student, claiming he had written the story and given them the idea. The suit was later settled out of court.
Box office.
The film received a warmer reception from the public, grossing $71.5 million at the US box office and $125 million in the rest of the world. At the time, the film set a record for the highest-grossing opening weekend for a film released in the month of October.
Performance analysis.
In its first run, "Stargate" made more money than film industry insiders predicted, especially given its lukewarm reviews. Some regard it as Emmerich's breakthrough film. Stargate grossed over $16,651,000 in the United States during its opening week in October 1994. It was the 35th highest-grossing film opening in the US in October. From November 4–6, the film grossed around $12,368,700, declining 25%. The film would continue this decline until the end of November, when the film garnered $4,777,198, or an 8.2% rise. The week before that the film garnered around $4,413,420, a 45.6% decline. In its last week playing theatrically, the film garnered around $1,170,500 in the US.
Awards.
In 1995, "Stargate" was considered for various film awards worldwide. It won six of the ten awards it was nominated for.
Future.
Dean Devlin and Roland Emmerich always envisioned "Stargate" as the first part of a trilogy of films, but parts two and three were never developed. At Comic-Con 2006, 12 years after the original film was released, writer/producer Dean Devlin stated that he was in early discussions with rightsholders MGM about finally bringing the final two parts to the screen.
Sequels.
According to Devlin, the second film is intended to be set around 12 years after the original, with Daniel Jackson making a discovery that leads him back to Earth and to the uncovering of a new Stargate. The second movie would supposedly use a different mythology from the Egyptian one which formed the background to the original movie, with the third movie tying these together to reveal that "all mythologies are actually tied together with a common thread that we haven't recognized before." Devlin stated that he hoped to enlist original stars Kurt Russell (Col. Jack O'Neil) and James Spader (Dr. Daniel Jackson) for the sequels. The actors have reportedly expressed an interest in participating in the project.
The film trilogy would not directly tie into the "Stargate SG-1" series. According to Devlin, the relationship between the movie and the series is "we would just continue the mythology of the movie and finish that out. I think the series could still live on at the end of the third sequel. So we're going to try to not tread on their stories." Plans for sequels to the original film are unrelated to the development of straight-to-DVD movies made as sequels to "Stargate SG-1". Using some of Roland Emmerich's notes, Bill McCay wrote a series of five novels, continuing the story the original creators had envisioned, which involved the Earth-humans, the locals and the successors of Ra. According to Devlin, he and Emmerich had always planned to do three films with the potential for more, but MGM preferred to play out the television series first.
Television spin-offs.
The CD ROM "Secrets of Stargate", released after the film, shows how the special effects were made. The film included behind the scenes of the film and the showing interviews with the cast and the production members. Dean Devlin eventually gave Metro–Goldwyn–Mayer (MGM) the rights over the film, and author Bill McCay wrote a series of five novels based on Emmerich's notes, continuing the story the original creators had envisioned.
In 1996, MGM hired Brad Wright and Jonathan Glassner to create a spin-off television series. "Stargate SG-1" premiered on the American subscription channel Showtime on July 27, 1997 and ended its ten-season run in 2007. "Stargate SG-1" itself spawned the non-canon animated television series "Stargate Infinity" (2002–2003), and the live-action television series "Stargate Atlantis" (2004–2009) and "Stargate Universe" (2009–2011).
Differences from the series.
"SG-1" creators and executive producers Brad Wright and Jonathan Glassner altered the canon by introducing several new concepts during production of the "SG-1" and "Atlantis" series. Most notably, many characters were portrayed by different actors in the series, and names were spelled differently. Daniel Jackson was played by James Spader in the movie and by Michael Shanks in the series. Kurt Russell's character Jonathan "Jack" O'Neil, a rather humorless Colonel, is played by Richard Dean Anderson as Jonathan "Jack" O'Neill (with two L's) in "SG-1". French Stewart's character was named Lieutenant Louis Ferretti, in "SG-1", Brent Stait's character is named Major Louis Ferretti. The spelling of Daniel Jackson's wife changes from "Sha'uri" to "Sha're", O'Neill's wife from Sarah to Sara, (similarly, the name of O'Neil's son changes from "Tyler" in the film to "Charlie").
The Stargate Command setting was transferred from the fictional military facility located in Creek Mountain, to the Cheyenne Mountain military complex. The unnamed planet from the film was named Abydos in the series and the distance from Earth changed from millions of light-years away (in an entirely different galaxy, "the Kalium galaxy") to becoming the closest planet to Earth with a Stargate, residing in the same galaxy as Earth. Also in "SG-1", Stargate travel is limited to the Stargate network in the Milky Way galaxy (unless a tremendous amount of power is used to lengthen the subspace wormhole of a Stargate to another galaxy's Stargate). Ra was the last of an unnamed race in the film, being of a humanoid species with large black eyes and a lack of facial features. In "SG-1" however, Ra is one of many "Goa'uld System Lords," who are a race of parasitic eel-like creatures. There were also changes to the Stargate. The unique set of 39 Stargate symbols in the film were replaced with the concept of 38 symbols that are the same for each Stargate (Earth's symbols based on Earth's constellations), plus a single point of origin symbol that is unique to that individual gate. While the kawoosh effect in the movie was created by filming the actual swirl of water in a glass tube, and looked like a vortex on the back of the Gate; on the TV series this effect was completely created in CG by the Canadian visual effects company "Rainmaker." At the beginning of Season 9, the original movie wormhole sequence was substituted by a new sequence similar to the one already used on "Stargate Atlantis", but being blue as it was in the movie and SG-1, whereas in Atlantis it's green.
Reboot.
On September 5, 2013, during an interview with Digital Spy, Emmerich said that he and MGM are planning a new Stargate as a reboot with a trilogy. On May 29, 2014, it was announced that MGM and Warner Bros. are partnering together for a reboot of Stargate as a trilogy with Emmerich directing, Devlin producing and Nicolas Wright & James A. Woods writing.

</doc>
<doc id="28328" url="http://en.wikipedia.org/wiki?curid=28328" title="Sigismund">
Sigismund

Sigismund (variants: Sigmund, ) is a German proper name, meaning "protection through victory", from Old High German "sigu" "victory" + "munt" "hand, protection". Tacitus Latinises it "Segimundus". There appears to be an older form of the High German word "Sieg" (victory): "sigis", obviously Gothic and an inferred Germanic form, and there is a younger form: "sigi", which is Old Saxon or Old High German "sigu" (both from about 9th century). A 5th century Prince of Burgundy was known both as "Sigismund" and "Sigimund" (see Ernst Förstemann, "Altdeutsche Personennamen", 1906; Henning Kaufmann, "Altdeutsche Personennamen", Ergänzungsband,1968).
A Lithuanian name Žygimantas, meaning "wealth of (military) campaign", from Lithuanian "žygis" "campaign, march" + "manta" "goods, wealth" has been a substitution of the name "Sigismund" in the Lithuanian language, from which it was adopted by the Ruthenian language as Жыгімонт (such are the cases of Sigismund Kestutaitis, Sigismund Korybut, Sigismund I the Old, Sigismund II Augustus). The Polish spelling is Zygmunt.
Sigismund was the name of various European rulers:
Others named Sigismund include:
Sigismund may also refer to fictional characters:
Other things named Sigismund:

</doc>
<doc id="28329" url="http://en.wikipedia.org/wiki?curid=28329" title="Solomon">
Solomon

Solomon (; Hebrew: שְׁלֹמֹה,  "Shlomo",  "Šəlōmō" "Šlomo"; Syriac: ܫܠܝܡܘܢ "Shlemun"; Arabic: سُليمان‎ "Sulaymān", also colloquially: "Silimān" or "Slemān"; Greek: Σολομών "Solomōn"), also called Jedidiah (Hebrew יְדִידְיָהּ), was, according to the Bible (Book of Kings: 1 Kings 1–11; Book of Chronicles: 1 Chronicles 28–2, 2 Chronicles 1–9), Qur'an, and Hidden Words a king of Israel and the son of David. The conventional dates of Solomon's reign are circa 970 to 931 BC. He is described as the third king of the United Monarchy, which would break apart into the northern Kingdom of Israel and the southern Kingdom of Judah shortly after his death. Following the split, his patrilineal descendants ruled over Judah alone.
According to the Talmud, Solomon is one of the 48 prophets. In the Qur'an, he is considered a major prophet, and Muslims generally refer to him by the Arabic variant Sulayman, son of David.
The Hebrew Bible credits Solomon as the builder of the First Temple in Jerusalem. It portrays him as great in wisdom, wealth, and power, but ultimately as a king whose sins, including idolatry and turning away from Yahweh, led to the kingdom's being torn in two during the reign of his son Rehoboam. Solomon is the subject of many other later references and legends, most notably in the 1st-century apocryphal work known as the Testament of Solomon. In later years, in mostly non biblical circles, Solomon also came to be known as a magician and an exorcist, with numerous amulets and medallion seals dating from the Hellenistic period invoking his name.
Biblical account.
Childhood.
Solomon was born in Jerusalem, the second born child to David and his wife Bathsheba, widow of Uriah the Hittite. The first child (unnamed in that account), a son conceived adulterously during Uriah's lifetime, had died before Solomon was conceived. Solomon had three named full brothers through Bathsheba, Nathan, Shammua, and Shobab, besides six known older half-brothers through as many mothers.
Succession.
According to the biblical First Book of Kings, when David was old, "he could not get warm." "So they sought for a beautiful young woman throughout all the territory of Israel, and found Abishag the Shunammite, and brought her to the king. The young woman was very beautiful, and she was of service to the king and attended to him, but the king knew her not."
While David was in this state, his fourth son Adonijah, heir apparent to the throne after the death of his elder brothers Amnon and Absalom, acted to have himself declared king, but Bathsheba, a wife of David and Solomon's mother, along with the prophet Nathan, convinced David to proclaim Solomon king. Adonijah fled and took refuge at the altar, and received pardon for his conduct from Solomon on the condition that he show himself "a worthy man" ().
Adonijah asked to marry Abishag the Shunammite, but Solomon disallowed that, although Bathsheba now pleaded on Adonijah's behalf. He was then seized and put to death (1 Kings 2:13-25). As made clear in the earlier story of Absalom's rebellion, to possess the royal harem was in this society tantamount to claiming the throne; this applied even to a woman who had shared the bed of a king advanced in age, though she had no intimate relations with King David.
David's general Joab was killed, in accord with David's deathbed request to Solomon, because he had killed generals Abner and Amasa during a peace (2 Samuel 20:8–13; 1 Kings 2:5). David's priest Abiathar was exiled by Solomon because he had sided with Adonijah. Abiathar is a descendent of Eli, which has important prophetic significance (1 Kings 2:27). Shimei was confined to Jerusalem and killed three years later, when he went to Gath to retrieve some runaway servants, in part because he had cursed David when David's son Absalom rebelled against David (1 Kings 2:1–46).
Wisdom.
One of the qualities most ascribed to Solomon is his wisdom. The book of 1 Kings recounts how Solomon prays for wisdom:
And the king went to Gibeon to sacrifice there; for that was the great high place: a thousand burnt offerings did Solomon offer upon that altar. In Gibeon the Lord appeared to Solomon in a dream by night: and God said, Ask what I shall give thee. And Solomon said, Thou hast shewed unto thy servant David my father great mercy, according as he walked before thee in truth, and in righteousness, and in uprightness of heart with thee; and thou hast kept for him this great kindness, that thou hast given him a son to sit on his throne, as it is this day. And now, O Lord my God, thou hast made thy servant king instead of David my father: and I am but a little child: I know not how to go out or come in. And thy servant is in the midst of thy people which thou hast chosen, a great people, that cannot be numbered nor counted for multitude. Give therefore thy servant an understanding heart to judge thy people, that I may discern between good and bad: for who is able to judge this thy so great a people? (1 Kings 3:4–9)
"So God said to him, 'Since you have asked for this and not for long life or wealth for yourself, nor have asked for the death of your enemies but for discernment in administering justice, I will do what you have asked...'" (1 Kings 3:11–12). The Hebrew Bible also states that "The whole world sought audience with Solomon to hear the wisdom God had put in his heart." (1 Kings 10:24)
In one account, known as the Judgment of Solomon, two women came before Solomon to resolve a quarrel over which was the true mother of a baby. When Solomon suggested they should divide the living child in two with a sword, one woman said she would rather give up the child than see it killed. Solomon then declared the woman who showed compassion to be the true mother, and gave the baby to her.
Solomon is also noted as one of many authors of wisdom literature. The apocryphal/deuterocanonical Wisdom of Solomon, along with the Book of Sirach, "are the familiar personalities and the events of Israel's history combined with the wisdom tradition. Much of this literature, however, is attributed to Solomon." Solomon became a favorite author and contributor of different kinds of wisdom literature, "including not only the collections of Proverbs, but also of Ecclesiastes and the Song of Solomon and the later apocryphal book the Wisdom of Solomon."
Wives.
According to the Bible, Solomon had 700 wives and 300 concubines. The wives are described as foreign princesses, including Pharaoh's daughter and women of Moab, Ammon, Sidon and of the Hittites. In a subject called in art the "Idolatry of Solomon", the foreign wives are depicted as leading Solomon away from Yahweh toward idolatry because they worshiped gods other than Yahweh (). This forms part of the Power of Women topos in the Middle Ages and Renaissance, showing the dangers women posed to even the most virtuous men. The only wife mentioned by name is Naamah, who is described as the Ammonite. She was the mother of Solomon's successor, Rehoboam.
Relationship with Queen of Sheba.
In a brief, unelaborated, and enigmatic passage, the Hebrew Bible describes how the fame of Solomon's wisdom and wealth spread far and wide, so much so that the queen of Sheba decided that she should meet him. The queen is described as visiting with a number of gifts including gold, spices and precious stones. When Solomon gave her "all her desire, whatsoever she asked," she left satisfied ().
Whether the passage is simply to provide a brief token, foreign witness of Solomon's wealth and wisdom, or whether there is meant to be something more significant to the queen's visit is unknown; nevertheless the visit of the Queen of Sheba has become the subject of numerous stories.
Sheba is typically identified as Saba, a nation once spanning the Red Sea on the coasts of what are now Eritrea, Somalia, Ethiopia and Yemen, in Arabia Felix. In a Rabbinical account (e.g. Targum Sheni), Solomon was accustomed to ordering the living creatures of the world to dance before him (Rabbinical accounts say that Solomon had been given control over all living things by Yahweh), but one day upon discovering that the mountain-cock or hoopoe (Hebrew name: "shade") was absent, he summoned it to him, and the bird told him that it had been searching for somewhere new.
The bird had discovered a land in the east, exceedingly rich in gold, silver, and plants, whose capital was called "Kitor" and whose ruler was the Queen of Sheba, and the bird, on its own advice, was sent by Solomon to request the queen's immediate attendance at Solomon's court.
An Ethiopian account from the 14th century ("Kebra Nagast") maintains that the Queen of Sheba had sexual relations with King Solomon (of which the Biblical and Quranic accounts give no hint) and gave birth by the Mai Bella stream in the province of Hamasien, Eritrea. The Ethiopian tradition has a detailed account of the affair. The child was a son who went on to become Menelik I, King of Axum, and founded a dynasty that would reign as the first Jewish, then Christian Empire of Ethiopia for 2900+ years (less one usurpation episode, an interval of c. 133 years until a legitimate male heir regained the crown) until Haile Selassie was overthrown in 1974. Menelik was said to be a practicing Jew who was given a replica of the Ark of the Covenant by King Solomon; and, moreover, that the original was switched and went to Axum with him and his mother, and is still there, guarded by a single priest charged with caring for the artifact as his life's task.
The claim of such a lineage and of possession of the Ark has been an important source of legitimacy and prestige for the Ethiopian monarchy throughout the many centuries of its existence, and had important and lasting effects on Ethiopian culture as a whole. The Ethiopian government and church deny all requests to view the alleged ark.
Some classical-era Rabbis, attacking Solomon's moral character, have claimed instead that the child was an ancestor of Nebuchadnezzar II, who destroyed Solomon's temple some 300 years later.
Sins and punishment.
According to Solomon's "wives turned his heart after other gods", their own national deities, to whom Solomon built temples, thus incurring divine anger and retribution in the form of the division of the kingdom after Solomon's death ().
 describes Solomon's descent into idolatry, particularly his turning after Ashtoreth, the goddess of the Sidonians, and after Milcom, the abomination of the Ammonites. In , a king is commanded not to multiply horses or wives, neither greatly multiply to himself gold or silver. Solomon sins in all three of these areas. Solomon collects 666 talents of gold each year (), a huge amount of money for a small nation like Israel. Solomon gathers a large number of horses and chariots and even brings in horses from Egypt. Just as warns, collecting horses and chariots takes Israel back to Egypt. Finally, Solomon marries foreign women, and these women turn Solomon to other gods.
According to , it was because of these sins that "the Lord punishes Solomon by removing 10 of the 12 Tribes of Israel from the Israelites.
And the Lord was angry with Solomon, because his heart had turned away from the Lord, the God of Israel, who had appeared to him twice and had commanded him concerning this thing, that he should not go after other gods. But he did not keep what the Lord commanded. Therefore the Lord said to Solomon, "Since this has been your practice and you have not kept my covenant and my statutes that I have commanded you, I will surely tear the kingdom from you and will give it to your servant. Yet for the sake of David your father I will not do it in your days, but I will tear it out of the hand of your son. However, I will not tear away all the kingdom, but I will give one tribe to your son, for the sake of David my servant and for the sake of Jerusalem that I have chosen.
Enemies.
Near the end of his life, Solomon was forced to contend with several enemies, including Hadad of Edom, Rezon of Zobah, and one of his officials named Jeroboam who was from the tribe of Ephraim.
Death, succession of Rehoboam, and kingdom division.
According to the Hebrew Bible, Solomon died of natural causes at around 80 years of age. Upon Solomon's death, his son, Rehoboam, succeeded him as king. However, ten of the Tribes of Israel refused to accept him as king, causing the United Monarchy to split and form the northern Kingdom of Israel ruled by Jeroboam, while Rehoboam continued to reign in the southern Kingdom of Judah.
Jewish scriptures.
King Solomon is one of the central Biblical figures in Jewish heritage that have lasting religious, national and political aspects. As the builder of the First Temple in Jerusalem and last ruler of the united Kingdom of Israel before its division into the northern Kingdom of Israel and the southern Kingdom of Judah, Solomon is associated with the peak "golden age" of the independent Kingdom of Israel as well as a source of judicial and religious wisdom. According to Jewish tradition, King Solomon wrote three books of the Bible:
The Hebrew word "To Solomon" (which can also be translated as "by Solomon") appears in the title of two hymns in the book of Psalms ("Tehillim"), suggesting to some that Solomon wrote them.
Apocryphal texts.
Rabbinical tradition attributes the "Wisdom of Solomon" to Solomon, although this book was probably written in the 2nd century BC. In this work, Solomon is portrayed as an astronomer. Other books of wisdom poetry such as the "Odes of Solomon" and the "Psalms of Solomon" also bear his name. The Jewish historian Eupolemus, who wrote about 157 BC, included copies of apocryphal letters exchanged between Solomon and the kings of Egypt and Tyre.
The Gnostic "Apocalypse of Adam", which may date to the 1st or 2nd century, refers to a legend in which Solomon sends out an army of demons to seek a virgin who had fled from him, perhaps the earliest surviving mention of the later common tale that Solomon controlled demons and made them his slaves. This tradition of Solomon's control over demons appears fully elaborated in the early pseudographical work called the "Testament of Solomon" with its elaborate and grotesque demonology.
Historicity.
Historical evidence of King Solomon other than the biblical accounts is minimal. Josephus in "Against Apion", citing Tyrian court records and Menander, gives a specific year during which King Hiram I of Tyre sent materials to Solomon for the construction of the temple. However, no material evidence indisputably of Solomon's reign has been found. Yigael Yadin's excavations at Hazor, Megiddo, Beit Shean and Gezer uncovered structures that he and others have argued date from his reign, but others, such as Israel Finkelstein and Neil Silberman, argue that they should be dated to the Omride period, more than a century after Solomon.
According to Finkelstein and Silberman, authors of "The Bible Unearthed: Archaeology's New Vision of Ancient Israel and the Origin of Its Sacred Texts", at the time of the kingdoms of David and Solomon, Jerusalem was populated by only a few hundred residents or less, which is insufficient for an empire stretching from the Euphrates to Eilath. According to "The Bible Unearthed", archaeological evidence suggests that the kingdom of Israel at the time of Solomon was little more than a small city state, and so it is implausible that Solomon received tribute as large as 666 talents of gold per year. Although both Finkelstein and Silberman accept that David and Solomon were real kings of Judah about the 10th century BC, they claim that the earliest independent reference to the Kingdom of Israel is about 890 BC, and for Judah about 750 BC. They suggest that due to religious prejudice, the authors of the Bible suppressed the achievements of the Omrides (whom the Hebrew Bible describes as being polytheist), and instead pushed them back to a supposed golden age of Judaism and monotheists, and devotees of Yahweh. Some Biblical minimalists like Thomas L. Thompson go further, arguing that Jerusalem became a city and capable of being a state capital only in the mid-7th century. Likewise, Finkelstein and others consider the claimed size of Solomon's temple implausible.
These views are criticized by William G. Dever, and André Lemaire, among others. Lemaire states in "Ancient Israel: From Abraham to the Roman Destruction of the Temple" that the principal points of the biblical tradition of Solomon are generally trustworthy. Kenneth Kitchen agrees, arguing that Solomon ruled over a comparatively wealthy "mini-empire", rather than a small city-state, and considers 666 gold talents a modest amount of money. Kitchen calculates that over 30 years, such a kingdom might have accumulated up to 500 tons of gold, which is small compared to other examples, such as the 1,180 tons of gold that Alexander the Great took from Susa. Similarly Kitchen and others consider the temple of Solomon a reasonable and typically sized structure for the region at the time. Dever states "that we now have direct Bronze and Iron Age parallels for every feature of the 'Solomonic temple' as described in the Hebrew Bible".
The archaeological remains that are considered to date from the time of Solomon are notable for the fact that Canaanite material culture appears to have continued unabated; there is a distinct lack of magnificent empire, or cultural development – indeed comparing pottery from areas traditionally assigned to Israel with that of the Philistines points to the Philistines having been significantly more sophisticated. However there is a lack of physical evidence of its existence, despite some archaeological work in the area. This is not unexpected because the area was devastated by the Babylonians, then rebuilt and destroyed several times. Little archaeological excavation has been done around the area known as the Temple Mount, in what is thought to be the foundation of Solomon's Temple, because attempts to do so are met with protest by Muslims.
From a critical point of view, Solomon's building of a temple for Yahweh should not be considered an act of particular devotion to Yahweh because Solomon is also described as building places of worship for a number of other deities (). Some scholars and historians argue that Solomon's apparent initial devotion to Yahweh, described in passages such as his dedication prayer (), were written much later, after Jerusalem had become the religious centre of the kingdom, replacing locations such as Shiloh and Bethel. Some scholars believe that passages such as these in the Books of Kings were not written by the same authors who wrote the rest of the text, instead probably by the Deuteronomist. Such views have been challenged by other historians who maintain that there is evidence that these passages in Kings are derived from official court records at the time of Solomon and from other writings of that time that were incorporated into the canonical books of Kings.
Chronology.
The conventional dates of Solomon's reign derived from biblical chronology are from c. 970 to 931 BC. Regarding the Davidic dynasty to which King Solomon belongs, its chronology can be checked against datable Babylonian and Assyrian records at a few points, and these correspondences have allowed archeologists to date its kings in a modern framework. According to the most widely used chronology, based on that by Edwin R. Thiele, the death of Solomon and the division of his kingdom would have occurred in the spring of 931 BC.
Wealth.
According to the Hebrew Bible, the Israelite monarchy gained its highest splendour and wealth during Solomon's reign of 40 years. In a single year, according to , Solomon collected tribute amounting to 666 talents (39,960 pounds) of gold. Solomon is described as surrounding himself with all the luxuries and the grandeur of an Eastern monarch, and his government prospered. He entered into an alliance with Hiram I, king of Tyre, who in many ways greatly assisted him in his numerous undertakings.
For some years before his death, David was engaged in collecting materials for building a temple in Jerusalem as a permanent home for Yahweh and the Ark of the Covenant. Solomon is described as completing its construction, with the help of an architect, also named Hiram, and other materials, sent from King Hiram of Tyre.
After the completion of the temple, Solomon is described as erecting many other buildings of importance in Jerusalem. For 13 years, he was engaged in the building of a royal palace on Ophel (a hilly promontory in central Jerusalem). Solomon also constructed great works for the purpose of securing a plentiful supply of water for the city, and the Millo (Septuagint, "Acra") for the defense of the city. However, excavations of Jerusalem have shown a distinct lack of monumental architecture from the era, and remains of neither the Temple nor Solomon's palace have been found.
Solomon is also described as rebuilding cities elsewhere in Israel, creating the port of Ezion-Geber, and constructing Palmyra in the wilderness as a commercial depot and military outpost. Although the location of the port of Ezion-Geber is known, no remains have ever been found. More archaeological success has been achieved with the major cities Solomon is said to have strengthened or rebuilt, for example, Hazor, Megiddo and Gezer. These all have substantial ancient remains, including impressive six-chambered gates, and ashlar palaces, however it is no longer the scholarly consensus that these structures date to the time, according to the Bible, when Solomon ruled.
According to the Bible, during Solomon's reign, Israel enjoyed great commercial prosperity, with extensive traffic being carried on by land with Tyre, Egypt, and Arabia, and by sea with Tarshish, Ophir, and South India.
Religious views.
Judaism.
King Solomon sinned by acquiring many foreign wives and horses because he thought he knew the reason for the Biblical prohibition and thought it did not apply to him. When King Solomon married the daughter of the Egyptian Pharaoh, a sandbank formed which eventually formed the "great nation of Rome" – the nation that destroyed the Second Temple (Herod's Temple). Solomon gradually lost more and more prestige until he became like a commoner. Some say he regained his status while others say he did not. In the end however, he is regarded as a righteous king and is especially praised for his diligence in building the Temple.
Christianity.
Christianity has traditionally accepted the historical existence of Solomon, though some modern Christian scholars have also questioned at least his authorship of those biblical texts ascribed to him. Such disputes tend to divide Christians into traditionalist and modernist camps.
Of the two genealogies of Jesus given in the Gospels, Matthew mentions Solomon, but Luke does not. Some commentators see this as an issue that can be reconciled while others disagree. For instance, it has been suggested that Luke is using Joseph's genealogy and Matthew is using Mary's, but Darrell Bock states that this would be unprecedented, "especially when no other single woman appears in the line". Other suggestions include the use by one of the royal and the other of the natural line, one using the legal line and the other the physical line, or that Joseph was adopted.
Jesus makes reference to Solomon, using him for comparison purposes in his admonition against worrying about your life. This account is recorded in Matthew 6:29 and the parallel passage in Luke 12:27
In the Eastern Orthodox Church, Solomon is commemorated as a saint, with the title of "Righteous Prophet and King". His feast day is celebrated on the Sunday of the Holy Forefathers (two Sundays before the Great Feast of the Nativity of the Lord).
The staunchly Catholic King Philip II of Spain sought to model himself after King Solomon. Statues of King David and Solomon stand on either side of the entrance to the basilica of El Escorial, Philip's palace, and Solomon is also depicted in a great fresco at the center of El Escorial's library. Philip identified the warrior-king David with his own father Charles V, and himself sought to emulate the thoughtful and logical character which he perceived in Solomon. Moreover, Escorial's structure was inspired by that of Solomon's Temple.
Islam.
In Islamic tradition, Solomon is venerated as a prophet and a messenger of God, as well as a divinely appointed monarch, who ruled over the Kingdom of Israel. As in Judaism, Islam recognizes Solomon as the son of King David, who is also considered a prophet and a king in Islam. Islam attributes to Solomon the saying: "The beginning of wisdom is the fear of God" ("ra's al-hikmah makhafat Allah"). Islam tradition ascribes to Solomon a great level of wisdom and knowledge of the unseen, as well as the traditional sciences of cosmology. According to tradition, he knew the "language of the birds" ("kalam al-tayr"). Solomon was also known in the Islam to have other supernatural abilities (bestowed upon him by God) such as controlling the wind, ruling over the Jinn and talking to ants: "And to Solomon (We made) the wind (obedient): its early morning (stride) was a month's (journey), and its evening (stride) was a month's (journey); and We made a font of molten brass to flow for him; and there were Jinns that worked in front of him, by the leave of his Lord, and if any of them turned aside from Our command, We made him taste of the Penalty of the Blazing Fire". (34:12) and "At length, when they came to a (lowly) valley of ants, one of the ants said: "O ye ants, get into your habitations, lest Solomon and his hosts crush you (under foot) without knowing it." – So he smiled, amused at her speech; and he said: "O my Lord! So order me that I may be grateful for Thy favors, which Thou hast bestowed on me and on my parents, and that I may work the righteousness that will please Thee: and admit me, by Thy Grace, to the ranks of Thy righteous Servants."" (18–19:27). The Qur'an mentions Solomon 17 times.
Baha'i.
In the Bahá'í Faith, Solomon is regarded as one of the lesser prophets along with David, Isaiah, Jeremiah, Ezekiel, along with others. Baha'is see Solomon as a prophet who was sent by God to address the issues of his time. Baha'ullah wrote about Solomon in the Hidden Words. He also mentions Solomon in the Tablet of Wisdom, where he is depicted as a contemporary of Pythagoras.
Legends.
One Thousand and One Nights.
A well-known story in the collection "One Thousand and One Nights" describes a genie who had displeased King Solomon and was punished by being locked in a bottle and thrown into the sea. Since the bottle was sealed with Solomon's seal, the genie was helpless to free himself, until freed many centuries later by a fisherman who discovered the bottle. In other stories which are found in "One Thousand and One Nights", protagonists who had to leave their homeland and travel to the unknown places of the world saw signs which proved that Solomon had already been there. Sometimes, protagonists discovered Solomon's words which aimed to help those who were lost and unluckily reached those forbidden and deserted places.
Angels and magic.
According to the Rabbinical literature, on account of his modest request for wisdom only, Solomon was rewarded with riches and an unprecedented glorious realm, which extended over the upper world inhabited by the angels and over the whole of the terrestrial globe with all its inhabitants, including all the beasts, fowl, and reptiles, as well as the demons and spirits. His control over the demons, spirits, and animals augmented his splendor, the demons bringing him precious stones, besides water from distant countries to irrigate his exotic plants. The beasts and fowl of their own accord entered the kitchen of Solomon's palace, so that they might be used as food for him, and extravagant meals for him were prepared daily by each of his 700 wives and 300 concubines, with the thought that perhaps the king would feast that day in her house.
Seal of Solomon.
A magic ring called the "Seal of Solomon" was supposedly given to Solomon and gave him power over demons. The magical symbol said to have been on the Seal of Solomon which made it work is now better known as the "Star of David". Asmodeus, king of demons, was one day, according to the classical Rabbis, captured by Benaiah using the ring, and was forced to remain in Solomon's service. In one tale, Asmodeus brought a man with two heads from under the earth to show Solomon; the man, unable to return, married a woman from Jerusalem and had seven sons, six of whom resembled the mother, while one resembled the father in having two heads. After their father's death, the son with two heads claimed two shares of the inheritance, arguing that he was two men; Solomon decided that the son with two heads was only one man. The Seal of Solomon, in some legends known as the Ring of Aandaleeb, was a highly sought after symbol of power. In several legends, different groups or individuals attempted to steal it or attain it in some manner.
Solomon and Asmodeus.
One legend concerning Asmodeus goes on to state that Solomon one day asked Asmodeus what could make demons powerful over man, and Asmodeus asked to be freed and given the ring so that he could demonstrate; Solomon agreed but Asmodeus threw the ring into the sea and it was swallowed by a fish. Asmodeus then swallowed the king, stood up fully with one wing touching heaven and the other earth, and spat out Solomon to a distance of 400 miles. The Rabbis claim this was a divine punishment for Solomon's having failed to follow three divine commands, and Solomon was forced to wander from city to city, until he eventually arrived in an Ammonite city where he was forced to work in the king's kitchens. Solomon gained a chance to prepare a meal for the Ammonite king, which the king found so impressive that the previous cook was sacked and Solomon put in his place; the king's daughter, Naamah, subsequently fell in love with Solomon, but the family (thinking Solomon a commoner) disapproved, so the king decided to kill them both by sending them into the desert. Solomon and the king’s daughter wandered the desert until they reached a coastal city, where they bought a fish to eat, which just happened to be the one which had swallowed the magic ring. Solomon was then able to regain his throne and expel Asmodeus. The element of a ring thrown into the sea and found back in a fish's belly also appeared in Herodotus' account of Polycrates, the tyrant of Samos from c. 538 BC to 522 BC.
In another familiar version of the legend of the Seal of Solomon, Asmodeus disguises himself. In some myths, he's disguised as King Solomon himself, while in more frequently heard versions he's disguised as a falcon, calling himself Gavyn (Gavinn or Gavin), one of King Solomon’s trusted friends. The concealed Asmodeus tells travelers who have ventured up to King Solomon's grand lofty palace that the Seal of Solomon was thrown into the sea. He then convinces them to plunge in and attempt to retrieve it, for if they do they would take the throne as king.
Artifacts.
Other magical items attributed to Solomon are his key and his Table. The latter was said to be held in Toledo, Spain during Visigoth rule and was part of the loot taken by Tarik ibn Ziyad during the Umayyad Conquest of Iberia, according to Ibn Abd-el-Hakem's "History of the Conquest of Spain". The former appears in the title of the Lesser Key of Solomon, a grimoire whose framing story is Solomon capturing demons using his ring, and forcing them to explain themselves to him.
Angels.
Angels also helped Solomon in building the Temple; though not by choice. The edifice was, according to rabbinical legend, miraculously constructed throughout, the large heavy stones rising and settling in their respective places of themselves. The general opinion of the Rabbis is that Solomon hewed the stones by means of a "shamir", a mythical worm whose mere touch cleft rocks. According to Midrash Tehillim, the shamir was brought from paradise by Solomon's eagle; but most of the rabbis state that Solomon was informed of the worm's haunts by Asmodeus. The shamir had been entrusted by the prince of the sea to the mountain rooster alone, and the rooster had sworn to guard it well, but Solomon's men found the bird's nest, and covered it with glass. When the bird returned, it used the shamir to break the glass, whereupon the men scared the bird, causing it to drop the worm, which the men could then bring to Solomon.
In the Kabbalah.
Early adherents of the Kabbalah portray Solomon as having sailed through the air on a throne of light placed on an eagle, which brought him near the heavenly gates as well as to the dark mountains behind which the fallen angels "Uzza" and "Azzazel" were chained; the eagle would rest on the chains, and Solomon, using the magic ring, would compel the two angels to reveal every mystery he desired to know.
The palace without entrance.
According to one legend, while traveling magically, Solomon noticed a magnificent palace to which there appeared to be no entrance. He ordered the demons to climb to the roof and see if they could discover any living being within the building but the demons only found an eagle, which said that it was 700 years old, but that it had never seen an entrance. An elder brother of the eagle, 900 years old, was then found, but it also did not know the entrance. The eldest brother of these two birds, which was 1,300 years old, then declared it had been informed by its father that the door was on the west side, but that it had become hidden by sand drifted by the wind. Having discovered the entrance, Solomon found an idol inside that had in its mouth a silver tablet saying in Greek (a language not thought by modern scholars to have existed 1000 years before the time of Solomon) that the statue was of "Shaddad, the son of 'Ad", and that it had "reigned over a million cities, rode on a million horses, had under it a million vassals and slew a million warriors", yet it could not resist the angel of death.
Throne.
Solomon's throne is described at length in Targum Sheni, which is compiled from three different sources, and in two later Midrash. According to these, there were on the steps of the throne twelve golden lions, each facing a golden eagle. There were six steps to the throne, on which animals, all of gold, were arranged in the following order: on the first step a lion opposite an ox; on the second, a wolf opposite a sheep; on the third, a tiger opposite a camel; on the fourth, an eagle opposite a peacock, on the fifth, a cat opposite a cock; on the sixth, a sparrow-hawk opposite a dove. On the top of the throne was a dove holding a sparrow-hawk in its claws, symbolizing the dominion of Israel over the Gentiles. The first midrash claims that six steps were constructed because Solomon foresaw that six kings would sit on the throne, namely, Solomon, Rehoboam, Hezekiah, Manasseh, Amon, and Josiah. There was also on the top of the throne a golden candelabrum, on the seven branches of the one side of which were engraved the names of the seven patriarchs Adam, Noah, Shem, Abraham, Isaac, Jacob, and Job, and on the seven of the other the names of Levi, Kohath, Amram, Moses, Aaron, Eldad, Medad, and, in addition, Hur (another version has Haggai). Above the candelabrum was a golden jar filled with olive-oil and beneath it a golden basin which supplied the jar with oil and on which the names of Nadab, Abihu, and Eli and his two sons were engraved. Over the throne, twenty-four vines were fixed to cast a shadow on the king's head.
By a mechanical contrivance the throne followed Solomon wherever he wished to go. Supposedly, due to another mechanical trick, when the king reached the first step, the ox stretched forth its leg, on which Solomon leaned, a similar action taking place in the case of the animals on each of the six steps. From the sixth step the eagles raised the king and placed him in his seat, near which a golden serpent lay coiled. When the king was seated the large eagle placed the crown on his head, the serpent uncoiled itself, and the lions and eagles moved upward to form a shade over him. The dove then descended, took the scroll of the Law from the Ark, and placed it on Solomon's knees. When the king sat, surrounded by the Sanhedrin, to judge the people, the wheels began to turn, and the beasts and fowls began to utter their respective cries, which frightened those who had intended to bear false testimony. Moreover, while Solomon was ascending the throne, the lions scattered all kinds of fragrant spices. After Solomon's death, Pharaoh Shishak, when taking away the treasures of the Temple (I Kings xiv. 26), carried off the throne, which remained in Egypt until Sennacherib conquered that country. After Sennacherib's fall Hezekiah gained possession of it, but when Josiah was slain by Pharaoh Necho, the latter took it away. However, according to rabbinical accounts, Necho did not know how the mechanism worked and so accidentally struck himself with one of the lions causing him to become lame; Nebuchadnezzar, into whose possession the throne subsequently came, shared a similar fate. The throne then passed to the Persians, whose king Darius was the first to sit successfully on Solomon's throne after his death; subsequently the throne came into the possession of the Greeks and Ahasuerus.
Freemasonry.
Masonic rituals refer to King Solomon and the building of his Temple. Masonic Temples, where a Masonic Lodge meets, are an allegorical reference to King Solomon's Temple.

</doc>
<doc id="28330" url="http://en.wikipedia.org/wiki?curid=28330" title="Saul">
Saul

According to the Hebrew Bible, Saul (; Hebrew: שָׁאוּל, "Šāʼûl" ; "asked for, prayed for"; Greek: Σαούλ "Saoul"; Latin: "Saul"; Arabic: طالوت‎, "Ṭālūt") was the first king of a united Kingdom of Israel and Judah. He was anointed by the prophet Samuel and reigned from Gibeah. He fell on his sword (committing suicide) to avoid capture in the battle against the Philistines at Mount Gilboa, during which three of his sons were also killed. The succession to his throne was contested by Ish-bosheth, his only surviving son, and his son-in-law David, who eventually prevailed.
The oldest accounts of Saul's life and reign are found in the Books of Samuel in the Hebrew Bible. A similar yet different account is given in the Qur'an. The historicity of Saul's kingdom has been called into question by some historians.
Biblical account.
House of King Saul.
According to the Tanakh, Saul was the son of Kish, of the family of the Matrites, and a member of the tribe of Benjamin, one of the twelve Tribes of Israel. (; ; ; ) It appears that he came from Gibeah.
Saul married Ahinoam, daughter of Ahimaaz. They had four sons and two daughters. The sons were Jonathan, Abinadab, Malchishua and Ish-bosheth. Their daughters were named Merab and Michal.
Saul also had a concubine named Rizpah, daughter of Aiah, who bore him two sons, Armoni and Mephibosheth. ()
Saul offered Merab to David as a wife after his victory over Goliath, but David was not interested in the arrangement. () Saul then gave his other daughter Michal in marriage to David, () but when David became Saul's rival to the kingship, Saul gave Michal in marriage to Palti, son of Laish. ()
Saul died at the Battle of Mount Gilboa (; ), and was buried in Zelah, in the region of Benjamin. () Three of Saul's sons – Jonathan, and Abinadab, and Malchishua – died with him at Mount Gilboa (; ). Ish-bosheth became king of Israel, at the age of forty, but was killed by Bannah and Recab after hearing of Abner's death. () Michal was returned as a wife to David, but was not granted any children as she disgraced David later on.
Ish-bosheth reigned for two years and was killed by two of his own captains. () The only male descendant of Saul to survive was Mephibosheth, Jonathan's lame son, () who had been five when his father and grandfather Saul had died in battle. In time, he came under the protection of David. () Mephibosheth had a young son, Micah, () of whom nothing more is heard.
Armoni and Mephibosheth (Saul's sons with his concubine, Rizpah) were given by David along with the five sons of Merab (Saul's daughter) to the Gibeonites, who killed them. () Michal was childless. ()
Anointed as king.
Samuel's sons were dishonest and not trustworthy. The leaders of the Israelites feared that it would be disastrous if his sons were to be judge over them and requested that Samuel give them a king. Samuel resented this request and warned that, if he appointed a king over them, they would suffer from the dealings of the king. Meanwhile Saul, a young Israelite, was commanded by his father, Kish, to go and locate their lost donkeys. Saul obeyed, and Samuel saw him walking toward him. God revealed to Samuel that Saul would be the one anointed as the "first" King of Israel.
The Books of Samuel give three events in Saul's rise to the throne:
Saul among the prophets.
Having been anointed by Samuel, Saul is told of signs he will receive to know that he has been divinely appointed. The last of these signs is that Saul will be met by an ecstatic group of prophets leaving a "high place" and playing music on lyre, tambourine, and flutes. The signs come true (though the text skips the first two, suggesting that a portion of the text has been lost, or edited out for some reason), and Saul joins the ecstatic prophets, hence the phrase. ()
Saul sends men to pursue David, but when they meet a group of ecstatic prophets playing music on lyre, tambourine, and flute, they become possessed by a "prophetic state" and join in. Saul sends more men, but they too join the prophets. Eventually Saul himself goes, and also joins the prophets, hence the phrase. ()
Military victories.
Besides relieving the siege of Jabesh-Gilead, Saul conducted military campaigns against the: Moabites, Ammonites, Edomites, the kings of Zobah, Philistines, and Amalekites.
Rejection.
According to , Samuel had told Saul to wait for a week after which they would meet and he would give Saul further instructions. But as Samuel did not arrive after a week () and with the Israelites growing restless, Saul starts preparing for battle by offering sacrifices. Samuel arrives just as Saul finished offering the sacrifices, and reprimands Saul for not obeying his instructions.
After the battle with the Philistines was over, the text describes Samuel as having instructed Saul to kill all the Amalekites. Having forewarned the Kenites who were living among the Amalekites to leave, Saul goes to war and defeats the Amalekites. Saul kills all the men, women, children and poor quality livestock, but leaves alive the king and best livestock. When Samuel found out that Saul has not killed them all, he informs Saul that God has rejected him as king, because Saul was disobedient. When Samuel turns away, Saul grabs Samuel by his clothes. A piece off his garment tears off, and Samuel announces this as indicative of what will happen to Saul's kingdom. Samuel then kills the Amalekite king himself and leaves Saul for the last time.
Saul and David.
After Samuel tells Saul that God has rejected him as king, David, a son of Jesse, from the tribe of Judah, enters the story:
In the text, Saul's son Jonathan becomes David's dearest friend. Eventually, David becomes Jonathan's brother-in-law by Michal. Jonathan recognises David as the rightful king, and 1 Samuel 18 states "Jonathan made a covenant with David, because he loved him as his own soul." Jonathan even gives David his military clothes, symbolizing David's position as successor to Saul.
God makes David successful wherever Saul sends him. Therefore Saul sets David in charge of the army. After David returns from battle, the women heap praise upon him and refer to him as a greater military hero than Saul by singing "Saul has slain his thousands and David his tens of thousands" which makes him very angry and jealous, fearing David as a rival to the throne.
Another day, while David is playing the harp, Saul - possessed by an evil spirit - throws a spear at him but misses on two occasions. Saul removes David from the court and appoints him an officer, but David becomes increasingly successful, making Saul even more resentful of him. In return for being his champion, Saul offers his daughter Merob to David as a wife. But David is too humble to accept, so Merob is married to a different man. When Saul's other daughter Michal falls in love with David, Saul repeats the offer. Again David turns it down, claiming he lacks the wealth of a suitable husband. Saul persuades David that the bride price would only be 100 foreskins from the Philistines; he secretly hopes that David will be slain trying to achieve this. Instead, David obtains 200 foreskins and is consequently married to Michal.
The narrative continues as Saul plots against David, but Jonathan dissuades Saul from this course of action; he also tells David of it. Saul tries to have David killed during the night, but Michal helps him escape and tricks his pursuers by using a household idol to make it seem that David is still in bed. David flees to Jonathan, who was not living near Saul. Jonathan returns to Saul, hoping to discover his father's ultimate intent. While dining with Saul, Jonathan pretends that David has been called away to his brothers. But Saul sees through the ruse and castigates Jonathan for being David's protector; clearly, Saul wants David slain. The next day, Jonathan meets with David and tells him Saul's intent. The two friends say their goodbyes, and David flees into the countryside. Saul later marries Michal to another man.
Saul is later informed by his head shepherd, an Edomite named Doeg, that Ahimelech assisted David. A henchman is sought to kill Ahimelech and the other priests of Nob. None of Saul's henchmen are willing to do this, so Doeg offers to do it instead, killing 85 priests. Saul also kills every man, woman and child living in Nob.
David had already left Nob by this point and had amassed about 400 disaffected men including a group of outlaws. With these men David launches an attack on the Philistines at Keilah. Saul realises he could trap David and his men by laying the city to siege. Yet David hears about this and, having received divine counsel (via the Ephod), finds that the citizens of Keilah would betray him to Saul. He flees to Ziph. Saul discovers this and pursues David on two occasions:
Battle of Gilboa and the death of King Saul.
Despite the oaths of reconciliation, David made an alliance with the Philistines, becoming their vassal. Emboldened by this, the Philistines prepared to attack Israel, and Saul led out his army to face them at Mount Gilboa, but before the battle decided to consult the witch of Endor for advice. The witch, unaware of who he was, reminded Saul that the king (i.e. Saul himself) had made witchcraft a capital offence, but after being assured that Saul would not harm her, the witch conjures up the spirit of Samuel, who had previously died (1 Samuel 25:1; 28:3). Upon seeing Samuel's ghost, Saul fell with his face to the ground. Saul told him of the forthcoming battle with the Philistines and that God would not answer him anymore when he prayed, and asked for understanding. The ghost then told Saul that he would lose the battle and his life.
1 Samuel and 2 Samuel give conflicting accounts of Saul's death. In the former, Saul returned to face his enemies, and the Israelites were duly defeated. To escape torture, Saul then asked his armour bearer to kill him, but was forced to commit suicide by falling on his sword when the armour bearer refused. In 2 Samuel, Saul asks not his armour bearer but an Amalekite to deliver the "coup de grâce", or so the Amalekite boasts to David, hoping to gain a reward. Infuriated, David orders the Amalekite to be put to death as punishment for killing the anointed king.
When the Philistines found Saul's body, they decapitated it, along with those of his sons, and fastened the decapitated bodies to the wall of Beth-shan. They hung up Saul's armor in the house of Ashtaroth (an Ascalonian temple of the Canaanites). But the inhabitants of Jabesh-Gilead came out at night and rescued the bodies, and took them to Jabesh-gilead, where they cremated them and buried the bones.(1 Samuel 31:8-13). Later on, David took the bones of Saul together with the bones of Jonathan his son from Jabesh-gilead and buried them in Zela, in the tomb of his father (2 Samuel 21:12–14).
Biblical criticism.
There are several textual or narrative issues in the text, and plays on words, that biblical scholars have discussed.
The birth-narrative of the prophet Samuel is found at 1 Samuel 1-28. It describes how Samuel's mother Hannah requests a son from Yahweh, and dedicates the child to God at the shrine of Shiloh. The passage makes extensive play with the root-elements of Saul's name, and ends with the phrase "hu sa'ul le-Yahweh", "he is dedicated to Yahweh." Hannah names the resulting son Samuel, giving as her explanation, "because from God I requested him." Samuel's name, however, can mean "name of God," (or "Heard of God" or "Told of God") and the etymology and multiple references to the root of the name seems to fit Saul instead. The majority explanation for the discrepancy is that the narrative originally described the birth of Saul, and was given to Samuel in order to enhance the position of David and Samuel at the former king's expense.
In the Books of Samuel, Saul is not referred to as a king ("melech"), but rather as a “leader” or “commander” ("nagid") (; ). However (possibly representing an opposing literary strain), Saul is said to be made a "king" ("melech") at Gilgal (). Even David, before he was anointed king, was referred to only as a future "nagid", or military commander ().
Various authors have attempted to harmonize the two narratives regarding Saul's death. Josephus writes that Saul's attempted suicide was stalled because he was not able to run the sword through himself, and that he therefore asked the Amalekite to finish it. Later biblical criticism has posited that the story of Saul's death was redacted from various sources, although this view in turn has been criticized because it does not explain why the contradiction was left in by the redactors. But since 2 Samuel records only the Amalekite's report, and not the report of any other eye-witness, some scholars theorize that the Amalekite may have been lying to try to gain favor with David. On this view, 1 Samuel records what actually happened, while 2 Samuel records what the Amalekite "claims" happened.
Classical rabbinical views.
Two opposing views of Saul are found in classical rabbinical literature. One is based on the reverse logic that punishment is a proof of guilt, and therefore seeks to rob Saul of any halo which might surround him; typically this view is similar to the "republican source". The passage referring to Saul as "a choice young man, and goodly" (1 Samuel 9:2) is in this view interpreted as meaning that Saul was not good in every respect, but "goodly" only with respect to his personal appearance (Num. Rashi 9:28). According to this view, Saul is only a "weak branch" (Gen. Rashi 25:3), owing his kingship not to his own merits, but rather to his grandfather, who had been accustomed to light the streets for those who went to the "bet ha-midrash", and had received as his reward the promise that one of his grandsons should sit upon the throne (Lev. Rashi 9:2).
The second view of Saul makes him appear in the most favourable light as man, as hero, and as king. This view is similar to that of the "monarchical source". In this view it was on account of his modesty that he did not reveal the fact that he had been anointed king (1 Samuel 10:16; Meg. 13b); and he was extraordinarily upright as well as perfectly just. Nor was there any one more pious than he (M. Q. 16b; Ex. Rashi 30:12); for when he ascended the throne he was as pure as a child, and had never committed sin (Yoma 22b). He was marvelously handsome; and the maidens who told him concerning Samuel (cf 1 Samuel 9:11-13) talked so long with him that they might observe his beauty the more (Ber. 48b). In war he was able to march 120 miles without rest. When he received the command to smite Amalek (1 Samuel 15:3), Saul said: "For one found slain the Torah requires a sin offering [Deuteronomy 21:1-9]; and here so many shall be slain. If the old have sinned, why should the young suffer; and if men have been guilty, why should the cattle be destroyed?" It was this mildness that cost him his crown. And while Saul was merciful to his enemies, he was strict with his own people; when he found out that Avimelech, a kohen, had assisted David with finding food, Saul, in retaliation, killed the rest of the 85 kohanim of the family of Avimelech and the rest of his hometown, Nov. (; Num. Rashi 1:10) The fact that he was merciful even to his enemies, being indulgent to rebels themselves, and frequently waiving the homage due to him, was incredible as well as deceiving. But if his mercy toward a foe was a sin, it was his only one; and it was his misfortune that it was reckoned against him, while David, although he had committed much iniquity, was so favored that it was not remembered to his injury (Yoma 22b; M. Q. 16b, and Rashi ad loc.). In some respects Saul was superior to David, e.g., in having only one concubine {Rizpah}, while David had many. Saul expended his own substance for the war, and although he knew that he and his sons would fall in battle, he nevertheless went forward, while David heeded the wish of his soldiers not to go to war in person (2 Samuel 21:17; Lev. Rashi 26:7; Yalq., Sam. 138).
According to the Rabbis, Saul ate his food with due regard for the rules of ceremonial purity prescribed for the sacrifice (Yalq., l.c.), and taught the people how they should slay cattle (cf 1 Samuel 14:34). As a reward for this, God himself gave Saul a sword on the day of battle, since no other sword suitable for him was found (ibid 13:22). Saul's attitude toward David finds its excuse in the fact that his courtiers were all tale-bearers, and slandered David to him (Deut. Rashi 5:10); and in like manner he was incited by Doeg against the priests of Nob (1 Samuel 22:16-19; Yalq., Sam. 131) - this act was forgiven him, however, and a heavenly voice ("bat qol") was heard, proclaiming: "Saul is the chosen one of God" (Ber. 12b). His anger at the Gibeonites (2 Samuel 21:2) was not personal hatred, but was induced by zeal for the welfare of Israel (Num. Rashi 8:4). The fact that he made his daughter remarry (1 Samuel 25:44), finds its explanation in his (Saul's) view that her betrothal to David had been gained by false pretenses, and was therefore invalid (Sanhedrin 19b). During the lifetime of Saul there was no idolatry in Israel. The famine in the reign of David (cf 2 Samuel 21:1) was to punish the people, because they had not accorded Saul the proper honours at his burial (Num. Rashi 8:4). In Sheol, Samuel reveals to Saul that in the next world, Saul would dwell with Samuel, which is a proof that all has been forgiven him by God('Er. 53ba]
In Islam.
Muslims refer to Saul as Tālūt (Arabic: طالوت‎), and believe that (as in the Bible) he was the commander of Israel. According to the Qur'an, Saul was chosen by the prophet Samuel (not mentioned by name explicitly but rather as "a Prophet" of the Israelites) after being asked by the people of Israel for a king to lead them into war. The Israelites criticized Samuel for appointing Saul, lacking respect for Saul because he was not wealthy. Samuel rebuked the people for this and told them that Saul was far more favored than they were. Saul led the Israelites to victory over the army of Goliath, who was killed by David. Saul is not considered a prophet, but a divinely appointed king.
Name.
The name Tālūt has uncertain etymology. Unlike some other Qur'anic figures, the Arabic name is not similar to the Hebrew name ("Sha'ul"). According to Muslim exegetes, the name Tālūt means 'tall' (from the Arabic "tūl") and refers to the extraordinary stature of Saul, which would be consonant with the Biblical account. In explanation of the name, exegetes such as Tha'labi hold that at this time, the future king of Israel was to be recognised by his height; Samuel set up a measure, but no one in Israel reached its height except Tālūt (Saul).
Saul as the first king.
In the Qur'an, Israel demanded a king after the time of Moses. God appointed Saul as their king. Saul was distinguished by the greatness of his knowledge and of his physique; it was a sign of his role as king that God brought back the Ark of the Covenant for Israel. Saul tested his people at a river; whoever drank from it would not follow him in battle excepting one who takes [from it] in the hollow of his hand.[Quran ] Many drank but only the faithful ventured on. In the battle, however, David slew Goliath and was made the subsequent king of Israel.
The Qur'anic account differs slightly from the Biblical account in that in the Bible the sacred Ark was returned to Israel before Saul's accession, and the test by drinking water is made in the Hebrew Bible not by Saul but by Gideon.
Psychological analyses.
Accounts of Saul's behavior have made him a popular subject for speculation among modern psychiatrists. George Stein views the passages depicting Saul's ecstatic episodes as suggesting that Saul may have suffered from mania. Martin Huisman sees the story of Saul as illustrative of the role of stress as a factor in depression. Liubov Ben-Noun of Ben-Gurion University of the Negev, believes that passages referring to King Saul's disturbed behavior indicate he was afflicted by a mental disorder, and lists a number of possible conditions. However, Christopher C. H. Cook of the Department of Theology and Religion, Durham University, UK recommends caution in offering any diagnoses in relation to people who lived millennia ago.

</doc>
<doc id="28333" url="http://en.wikipedia.org/wiki?curid=28333" title="Samaria">
Samaria

Samaria (), or the Shomron (Hebrew: שֹׁמְרוֹן‎, "Šomron" "Šōmərôn"; Arabic: السامرة‎, "as-Sāmirah" – also known as جبال نابلس, "Jibāl Nāblus") is a name for the mountainous, central region of the ancient Levant, based on the borders of the biblical Northern Kingdom of Israel and especially the Israelite tribes of Ephraim and Manasseh. The name "Samaria" derives from the ancient city of Samaria, the capital of the Kingdom of Israel. In modern times, the territory is generally and almost universally known as part of the West Bank.
Jordan ceded its claim to the area to the Palestine Liberation Organization (PLO) in November 1988. In 1994, control of Areas 'A' (full civil and security control by the Palestinian Authority) and 'B' (Palestinian civil control and joint Israeli-Palestinian security control) were transferred by Israel to the Palestinian Authority. The Palestinian Authority did not recognize the term Samaria within its domain.
Etymology.
According to the Hebrew Bible, the name "Shomron" is derived from the individual [or clan] "Shemer", from whom Omri purchased the site for his new capital city (1 Kings 16:24). In modern times, Samaria was one of six administrative districts of the Mandatory Palestine. Following the occupation of the West Bank by Israel in 1967, the Israeli right began to refer to the territories by their biblical names and argued for their usage on historical, religious, nationalist and security grounds.
The fact that the mountain was called Shomeron when Omri bought it may indicate that an earlier etymology of the name may be "watch mountain". In the earlier cuneiform inscriptions, Samaria is designated under the name of "Bet Ḥumri" ("the house of Omri"); but in those of Tiglath-Pileser III and later it is called Samirin, after its Aramaic name.
Geography.
To the north, Samaria is bounded by the Jezreel Valley; to the east by the Jordan Rift Valley; to the west by the Carmel Ridge (in the north) and the Sharon plain (in the west); to the south by the Jerusalem mountains. In Biblical times, Samaria "reached from the [Mediterranean] sea to the Jordan Valley", including the Carmel Ridge and Plain of Sharon. The Samarian hills are not very high, seldom reaching the height of over 800 metres. Samaria's climate is more hospitable than the climate further south.
The mountain ranges in the south of the region continue into Judaea without a clear division.
History.
Ancient.
According to the Hebrew Bible, the region known as Samaria was captured by the Israelites from the Canaanites and was assigned to the Tribe of Joseph. After the death of King Solomon (c. 931 BCE), the northern tribes, including those of Samaria, separated from the southern tribes and established the separate Kingdom of Israel. Initially its capital was Tirzah until the time of king Omri (c.884 BCE), who built the city of Shomron and made it his capital.
In 726–722 BCE, the new king of Assyria, Shalmaneser V, invaded Canaan and besieged the city of Samaria. After an assault of three years, the city fell and much of its population was taken into captivity and deported. Little documentation exists for the period between the fall of Samaria and the end of the Assyrian Empire.
In the Bible, Samaria was condemned by the Hebrew prophets for its "ivory houses" and luxury palaces displaying pagan riches.
In 6 CE the region became part of the Roman province of Judaea, after the death of king Herod the Great.
Over time, the region has been controlled by numerous different civilizations, including Israelites, Babylonians, the classical Persian Empire, Ancient Greeks, Romans, Byzantines, Arabs, Crusaders, and Ottoman Turks.
Post–World War II.
The modern history of Samaria begins when the territory of Samaria, formerly part of the Ottoman Empire, was entrusted to the United Kingdom to administer in the aftermath of World War I as a Mandatory Palestine District of Samaria between 1918–1948.
As a result of the 1948 Arab–Israeli War, most of the territory was unilaterally incorporated as Jordanian-controlled territory and was administered as part of the West Bank (west of the Jordan river). The Jordanian-held West Bank came under the control of Israel during the 1967 Six-Day War. Jordan ceded its claims in the West Bank (except for certain prerogatives in Jerusalem) to the PLO in November 1988, later confirmed by the Israel–Jordan Treaty of Peace of 1994. In the 1994 Oslo accords, the Palestinian Authority was established and given responsibility for the administration over some of the territory of West Bank (Areas 'A' and 'B').
Samaria is one of several standard statistical districts utilized by the Israel Central Bureau of Statistics. "The Israeli CBS also collects statistics on the rest of the West Bank and the Gaza District. It has produced various basic statistical series on the territories, dealing with population, employment, wages, external trade, national accounts, and various other topics." The Palestinian Authority however use Nablus, Jenin, Tulkarm, Qalqilya, Salfit, Ramallah and Tubas governorates as administrative centres for the same region.
The Shomron Regional Council administers the Israeli population and settlements throughout the area. Israeli settlements in the West Bank are considered by the international community to be illegal under international law, but the Israeli government disputes this.
New Testament reference.
The New Testament mentions Samaria in Luke 17:11–20, in the miraculous healing of the ten lepers, which took place on the border of Samaria and Galilee. John 4:1–26 records Jesus' encounter at Jacob's well with the woman of Sychar, in which he declares himself to be the Messiah. In Acts 8:5–14, it is recorded that Philip went down to the city of Samaria and preached there. In the time of Jesus, "Iudaea" of the Romans was divided into the toparchies of Judea, Samaria, Galilee and the Paralia. Samaria occupied the centre of "Iudaea" (John 4:4). ("Iudaea" was later renamed "Syria Palaestina" in 135, following the Bar Kokhba revolt.) In the Talmud, Samaria is called the "land of the Cuthim".
Archaeology.
The ancient site of Samaria-Sebaste covers the hillside overlooking the modern Palestinian village of Sebastia on the eastern slope of the hill. Remains have been found from the Canaanite, Hellenistic, Herodian, Roman and Byzantine era.
Archaeological finds from Roman-era Sebaste, a site that was rebuilt and renamed by Herod the Great in 30 BCE, include a colonnaded street, a temple-lined acropolis and a lower city, where John the Baptist is believed to have been buried.
The Harvard excavation of Samaria, which began in 1908, was headed by Egyptologist George Andrew Reisner. The findings included Hebrew, Aramaic, cuneiform and Greek inscriptions, as well as pottery remains, coins, sculpture, figurines, scarabs and seals, faience, amulets, beads and glass. The joint British-American-Hebrew University excavation continued under J.W. Crowfoot in 1931–35, during which some of the chronology issues were resolved. The round towers lining the acropolis were found to be Hellenistic, the street of columns was dated to the 3–4th century, and 70 inscribed potsherds were dated to the early 8th century.
In 1908–35, remains of luxury furniture made of wood and ivory were discovered in Samaria, representing the Levant's most important collection of ivory carvings from the early first millennium BCE. Despite theories of their Phoenician origin, some of the letters serving as fitter's marks are in Hebrew.
Samaritans.
The Samaritans (Hebrew: Shomronim) are an ethnoreligious group named after and descended from ancient Semitic inhabitants of Samaria, since the Assyrian exile of the Israelites. Religiously, the Samaritans are adherents of Samaritanism, an Abrahamic religion closely related to Judaism. Based on the Samaritan Torah, Samaritans claim their worship is the true religion of the ancient Israelites prior to the Babylonian exile, preserved by those who remained in the Land of Israel. Their temple was built at Mount Gerizim in the middle of 5th century BC and was destroyed under the Macabbean (Judean) king John Hyrcanus late in 110 BC, although their descendants still worship among its ruins. The antagonism between Samaritans and Jews is important in understanding the Bible's New Testament stories of the "Samaritan woman at the well" and "Parable of the Good Samaritan".
Bibliography.
</dl>

</doc>
<doc id="28334" url="http://en.wikipedia.org/wiki?curid=28334" title="Sennacherib">
Sennacherib

Sennacherib (; Akkadian: Sîn-ahhī-erība, "Sîn has increased the brothers"), king of Assyria 705 BCE–681 BCE, is remembered for his military campaigns against Babylon and Judah and for his building programs, notably at his capital Nineveh.
The primary preoccupation of Sennacherib's reign was the so-called "Babylonian problem"–the refusal of the Babylonians to accept Assyrian rule–culminating in his destruction of the city in 689 BCE. Further campaigns were carried out in Syria-Palestine (notable for being recorded in the Bible's Books of Kings, in the mountains east of Assyria, against the kingdoms of Anatolia, and against the Arabs in the northern Arabian deserts. Sennacherib was also a notable builder–it was under him that Assyrian art reached its peak. His building projects included the beautification of Nineveh, a canal 50 kilometers long to bring water to the city, and the "Palace Without Rival", which included what may have been the prototype of the legendary Hanging Gardens of Babylon. 
Sennacherib was assassinated in obscure circumstances in 681 BCE, apparently by his eldest son (his designated successor, Esarhaddon, was the youngest). In Babylon his death was seen as divine punishment for the destruction of that city.
Background: the Neo-Assyrian empire, 911-612 BCE.
Assyria began as a Bronze Age city-state or small kingdom on the middle-Tigris. The kingdom collapsed at the end of the Bronze Age, but was reconstituted at the beginning of the Iron Age, and under Tiglath-pileser III and his sons Shalmaneser V and Sargon II (combined reigns 744–705 BCE), Assyria extended its rule over Mesopotamia, Anatolia and Syria-Palestine, making its capital Nineveh, one of the richest cities of the ancient world. The empire's rise aroused the fear and hatred of its neighbours, notably Babylon, Elam and Egypt, and the many smaller kingdoms of the region such as Judah. Any perceived weakness on the part of Assyria led inevitably to rebellion, particularly by the Babylonians. Solving the so-called "Babylonian problem" was Sennacherib's primary preoccupation.
The "Babylonian problem".
Sennacherib's grandfather Tiglath-pileser III had made himself king of Babylon, creating a dual monarchy in which the Babylonians retained a nominal independence. This arrangement was never accepted by powerful local leaders, particularly an important tribal chief named Marduk-apla-iddina (the Merodach-baladan of the Bible). Marduk-apla-iddina paid tribute to Tiglath-pileser, but when Tiglath-pileser's successor Shalmaneser V was overthrown by Sargon II (Sennacherib's father) he seized the opportunity to crown himself king of Babylon. The next thirty years saw a repeating pattern of Assyrian reconquest and renewed rebellion.
Sargon dealt with the Babylonian problem by cultivating the Babylonians; Sennacherib took a radically different approach, and there is little sign that he cared about Babylonian popular opinion or took part in the ceremonial duties expected of a Babylonian king, notably the New Year ritual. His relations, instead, were predominantly military, and culminated in his complete destruction of Babylon in 689 BCE. He destroyed the temples and the images of the gods , except for that of Marduk, the creator-god and divine patron of Babylon, which he took to Assyria. This caused consternation in Assyria itself, where Babylon and its gods were held in high esteem. Sennacherib attempted to justify his actions to his own countrymen through a campaign of religious propaganda. Among the elements of this campaign he commissioned a myth in which Marduk was put on trial before Ashur, the god of Assyria–the text is fragmentary but it seems Marduk is found guilty of some grave offense; he described his defeat of the Babylonian rebels in language of the Babylonian creation myth, identifying Babylon with the evil demon-goddess Tiamat and himself with Marduk; Ashur replaced Marduk in the New Year Festival; and in the temple of the festival he placed a symbolic pile of rubble from Babylon. In Babylon itself, Sennachrib's answer to the Babylonian problem sparked an intense hatred that would eventually lead to a war for independence and the destruction of Assyria.
Accession and military campaigns.
Accession.
Sennacherib was probably not the first-born son of Sargon II (his name implies a compensation for dead brothers), but he was groomed for royal succession and entrusted with administrative duties from an early age. Sargon died in battle, and ancient sources give three different years for Sennacherib's first reign-year—705 BCE, 704 BCE, and 703 BCE—suggesting that the succession was not smooth. The transition sparked uprisings in Syria-Palestine, where the Egyptians incited rebellion, and more seriously in Babylon, where Marduk-apla-iddina II assumed the throne and assembled a large army of Chaldeans, Aramaeans, Arabs and Elamites. 
Military campaigns in Mesopotamia and Syria-Palestine.
Sennacherib's first campaign began late in 703 BCE against Marduk-apla-iddina (now Marduk-apla-iddina II), who had once more taken the throne of Babylon. The rebellion was defeated, Marduk-apla-iddina fled, and Babylon was taken and the palace plundered, although the citizens were not harmed. A puppet king named Bel-ibni was placed on the throne and for the next two years Babylon was left in peace. 
In 701 BCE, Sennacherib turned from Babylonia to the western part of the empire, where Hezekiah of Judah, incited by Egypt and Marduk-apla-iddina, had renounced Assyrian allegiance. The rebellion involved various small states in the area: Sidon and Ashkelon were taken by force and a string of other cities and states, including Byblos, Ashdod, Ammon, Moab and Edom then paid tribute without resistance. Ekron called on Egypt for help but the Egyptians were defeated. Sennacherib then turned on Jerusalem, Hezekiah's capital. He besieged the city and gave its surrounding towns to Assyrian vassal rulers in Ekron, Gaza and Ashdod. There is no description of how the siege ended, but the annals record a list of booty sent from Jerusalem to Nineveh. Hezekiah remained on his throne as a vassal ruler. (The campaign is recorded with differences in the Assyrian records and in the biblical Books of Kings; there is general agreement that the Assyrian sources should be given priority). 
In 699 BCE, Bel-ibni, who had proved untrustworthy or incompetent as king of Babylon, was replaced by Sennacherib's eldest son, Ashur-nadin-shumi. Marduk-apla-iddina continued his rebellion with the help of Elam, and in 694 Sennacherib took a fleet of Phoenician ships down the Tigris River to destroy the Elamite base on the shore of the Persian Gulf, but while he was doing this the Elamites captured Ashur-nadin-shumi and put Nergal-ushezib, the son of Marduk-apla-iddina, on the throne of Babylon. Nergal-ushezib was captured in 693 BCE and taken to Nineveh, and Sennacherib attacked Elam again. The Elamite king fled to the mountains and Sennacherib plundered his kingdom, but when he withdrew the Elamites returned to Babylon and put another rebel leader, Mushezib-Marduk, on the Babylonian throne. Babylon eventually fell to the Assyrians in 689 BCE after a lengthy siege, and Sennacherib put an end to the "Babylonian problem" by utterly destroying the city and even the mound on which it stood by diverting the water of the surrounding canals over the site. (In fact the problem had not been solved: in 612 BCE a coalition of Babylonians and other enemies of Assyria sacked Nineveh, marking the end of the Assyrian empire).
Minor campaigns.
Sennacherib conducted minor campaigns on his borders, but without significantly adding to the empire. In 702 BCE and from 699 BCE until 697 BCE, he made several campaigns in the mountains east of Assyria, on one of which he received tribute from the Medes. In 696 BCE and 695 BCE, he sent expeditions into Anatolia, where several vassals had rebelled following the death of Sargon. Around 690 BCE, he campaigned in the northern Arabian deserts, conquering Dumat al-Jandal, where the queen of the Arabs had taken refuge.
Administration and building projects.
The Assyrian empire was divided into provinces, each provincial governor being responsible for matters such as the maintenance of roads and public buildings, and for the implementation of administrative policy. One major element of that policy was the massive deportation and redistribution of populations, which aimed to punish, prevent rebellion, and repopulate depopulated areas in order to maintain food production in the empire. As many as 4.5 million people may have been moved between 745 BCE and 612 BCE, and Sennacherib alone could have been responsible for displacing 470,000 people.
Sennacherib made Nineveh a truly magnificent city. He laid out new streets and squares and built within it the famous "palace without a rival", the plan of which has been mostly recovered and has overall dimensions of about 503 by 242 metres (1,650 ft × 794 ft). It comprised at least 80 rooms, many of which were lined with sculpture. A large number of cuneiform tablets were found in the palace. The solid foundation was made out of limestone blocks and mud bricks; it was 22 metres (72 ft) tall. In total, the foundation is made of roughly 2,680,000 cubic metres (3,505,308 cu yd) of brick (approximately 160 million bricks). The walls on top, made out of mud brick, were an additional 20 metres (66 ft) tall. Some of the principal doorways were flanked by colossal stone door figures weighing up to 30,000 kilograms (30 t); they included many winged lions or bulls with a man's head. These were transported 50 kilometres (31 mi) from quarries at Balatai and they had to be lifted up 20 metres (66 ft) once they arrived at the site, presumably by a ramp. There are also 3,000 metres (9,843 ft) of stone panels carved in bas-relief, that include pictorial records documenting every construction step including carving the statues and transporting them on a barge. One picture shows 44 men towing a colossal statue. The carving shows three men directing the operation while standing on the Colossus. Once the statues arrived at their destination, the final carving was done. Most of the statues weigh between 9,000 and 27,000 kilograms (19,842 and 59,525 lb).[9][10]
The stone carvings in the walls include many battle scenes, impalings and scenes showing Sennacherib's men parading the spoils of war before him. He also bragged about his conquests: he wrote of Babylon: "Its inhabitants, young and old, I did not spare, and with their corpses I filled the streets of the city." He later wrote about a battle in Lachish: "And Hezekiah of Judah who had not submitted to my yoke...him I shut up in Jerusalem his royal city like a caged bird. Earthworks I threw up against him, and anyone coming out of his city gate I made pay for his crime. His cities which I had plundered I had cut off from his land." [11]
At this time, the total area of Nineveh comprised about 7 square kilometres (1,730 acres), and fifteen great gates penetrated its walls. An elaborate system of eighteen canals brought water from the hills to Nineveh, and several sections of a magnificently constructed aqueduct erected by Sennacherib were discovered at Jerwan, about 65 kilometres (40 mi) distant.[12] The enclosed area had more than 100,000 inhabitants (maybe closer to 150,000), about twice as many as Babylon at the time, placing it among the largest settlements worldwide.
It is possible that the garden which Sennacherib built next to his palace, with its associated irrigation works, was the original Hanging Gardens of Babylon.
Death.
Sennacherib was assassinated in obscure circumstances in 681 BCE. An inscription by his youngest son and successor, Esarhaddon, describes how Esarhaddon heard that his brothers were fighting in the streets of Nineveh, hurried back with an army, defeated them all, and took the throne. The inscription does not mentioned that the brothers were fighting because one of them had just murdered Sennacherib, which is indicated in the Babylonian chronicles, the Bible, and in later Assyrian records. It seems that the murderer was a prince named Arda-Mulissi, the eldest son before Esarhaddon's appointment as heir; Esarhaddon's silence on the subject may have been to avoid a perception of instability among the people. To one Babylonian historian, Sennacherib's death at the hands of his sons was divine punishment for what the king had done to Babylon.

</doc>
<doc id="28338" url="http://en.wikipedia.org/wiki?curid=28338" title="Saaremaa">
Saaremaa

Saaremaa (]; Ösel in Swedish and German, Øsel in Danish and also, esp. traditionally, Osel in English) is the largest island in Estonia, measuring 2673 km2. The main island of Saare County, it is located in the Baltic Sea, south of Hiiumaa island, and belongs to the West Estonian Archipelago. The capital of the island is Kuressaare, which has about 15,000 inhabitants; the whole island has over 30,966 inhabitants.
Etymology.
The island is called "Saaremaa" in Estonian, and in Finnish "Saarenmaa" — literally "isle's land". In old Scandinavian sagas, Saaremaa is called "Eysysla" and in the Icelandic Sagas "Eysýsla", which means exactly the same as the name of the island in Estonian: "the district (land) of island". This is the origin of the island's name in Danish "Øsel", German and Swedish, "Ösel", Gutnish "Oysl", and in Latin, "Osilia". The name "Eysysla" appears sometimes together with "Adalsysla", "the big land", perhaps 'Suuremaa' or 'Suur Maa' in Estonian, which refers to mainland Estonia. In Latvian, the island is called "Sāmsala", which means "the island of Saami".
History.
According to archaeological finds, the territory of Saaremaa has been inhabited from at least . Sagas talk about numerous skirmishes between islanders and Vikings. Saaremaa was the wealthiest county of ancient Estonia and the home of notorious Estonian pirates, sometimes called the Eastern Vikings. The Chronicle of Henry of Livonia describes a fleet of sixteen ships and five hundred Osilians ravaging the area that is now southern Sweden, then belonging to Denmark. In 1206, King Valdemar II of Denmark built a fortress on the island but found no volunteers to man it. The Danes burned it themselves and left.
Probably around 1000, Gunnar Hámundarson from Iceland took part in a Viking raid at Eysýsla (Saaremaa). There he obtained his famous atgeir, by taking it from a man named Hallgrímur. Njáls saga tells the following:
"Thence they held on south to Denmark and thence east to Smálönd and had victory wherever they went. They did not come back in autumn. The next summer they held on to Rafala (Tallinn) and fell in there with sea-rovers, and fought at once, and won the fight. After that they steered east to Eysýsla (Saaremaa) and lay there somewhile under a ness. There they saw a man coming down from the ness above them; Gunnar went on shore to meet the man, and they had a talk. Gunnar asked him his name, and he said it was Tófi. Gunnar asked again what he wanted.
"Thee I want to see," says the man. "Two warships lie on the other side under the ness, and I will tell thee who command them: two brothers are the captains — one's name is Hallgrímur, and the other's Kolskeggur. I know them to be mighty men of war; and I know too that they have such good weapons that the like are not to be had. Hallgrímur has an atgeir which he had made by seething-spells; and this is what the spells say, that no weapon shall give him his death-blow save that atgeir. That thing follows it too that it is known at once when a man is to be slain with that atgeir, for something sings in it so loudly that it may be heard a long way off — such a strong nature has that atgeir in it."
In 1227, Saaremaa was conquered by the Livonian Brothers of the Sword during the Livonian Crusade but remained a hotbed of Estonian resistance. The crusaders founded the Bishopric of Ösel-Wiek there. When the Order was defeated by the Lithuanian army in the Battle of Saule in 1236, the Saaremaa islanders rebelled. The conflict was ended by a treaty that was signed by the Osilians and the Master of the Order. In the following year, the Sword-Brothers were absorbed into the Teutonic Order. As the crusaders' hold on Saaremaa got stronger, Christianity also became more established on the island, and to this day Saaremaa has a unique set of medieval churches in Kaarma, Karja, Kihelkonna, Muhu, Pöide, Püha and Valjala churches. The crusader's fortress Kuressaare Castle, known in German as Schloss Arensburg, was built by the Teutonic Order, beginning in 1380, for the bishops of Ösel-Wieck (Estonian: Saare-Lääne). It is one of the most well-preserved medieval castles in Estonia and bears testimony to the late Medieval Age.
During the 14th–16th centuries, and possibly earlier, local inhabitants started to expand across the Baltic Sea into surrounding areas thus establishing villages at Livonian coast.
Most of Saaremaa was ruled directly by the Bishopric of Ösel-Wiek, while some parts were enfeoffed to the Livonian Order. In 1559, the bishopric and Saaremaa were sold to Denmark, becoming part of Danish Estonia. From 1570 until 1645 the entire island was under Danish possession.
In 1645, Saaremaa was ceded from Denmark to Sweden by the Treaty of Brömsebro. In 1721, along with the rest of Livonia, Saaremaa (then known by its Swedish name of Ösel) was ceded to the Russian Empire by the Treaty of Nystad, becoming a part of the Governorate of Livonia.
In 1840 the first spa opened in Kuressaare (then known as Arensburg), and the town experienced renaissance and became a resort for Russians and Baltic Germans.
In World War I, the Estonian islands were conquered by Imperial German Army in October 1917 and remained occupied (Operation Albion) until the end of hostilities. Estonia became independent after the October Revolution and the collapse of the Russian Empire. As a result of the Molotov-Ribbentrop Pact, the new state was incorporated into the Soviet Union in June 1940 as the Estonian Soviet Socialist Republic. Most of the Baltic German population of the island was evacuated to Germany following the Pact. The island was occupied by Nazi Germany in 1941 (Operation Beowulf); German troops remained there until expelled by the Red Army in the Moonzund Landing Operation in October and November 1944. In 1946, Saaremaa was declared a restricted zone, closed to foreigners and to most mainland Estonians. It remained a restricted area until 1989.
Estonian independence was regained on 20 August 1991, in the dissolution of the Soviet Union.
Geography.
The island forms the main barrier between the Gulf of Riga and the Baltic Sea. To the south of it is the main passage out of the gulf, the Irbe Strait, next to Sõrve Peninsula, the southernmost portion of the island. In Medieval times islanders crossed the strait to form fishing villages on the Livonian coast, notably Pitrags. In those days it was easier and quicker to cross the strait towards nearby Kolka, Saunags or Mazirbe, than travel by horse large distances inland. The highest point on the island is 54 m above sea level. One particularly interesting feature found on the island is the Kaali crater. The island has lots of forested terrain. One of the symbols of the island is the juniper.
Nature.
More than 10,000 years ago the first parts of Saaremaa arose from the Baltic Ice Lake. The uplift of the Earth's crust is continuing even today, at 2 mm per year. The West Estonian islands are lowlying plains resting on limestone, their average elevation being about 15 m above sea level. Limestone has become denuded in a great number of places, resulting in cliffs, limestone pits and quarries at Mustjala, Ninase, Pulli, Üügu and Kaugatuma. Because of its mild maritime climate and a variety of soils, Saaremaa has a rich flora, illustrated by the fact that 80% of the plant species found in Estonia are represented here. Altogether 1200 species of vascular plants can be found in Saaremaa. About 120 of the local plant species are rare ones which have received special protection status. The most famous endemic species is Rhinanthus osiliensis, a rare little flower growing mostly in spring fens. Rare and beautiful flowers are widespread; out of the 36 species found in Estonia, 35 of them are found on Saaremaa and neighbouring islands. Over 40% of Saaremaa is covered with forests. They are mostly mixed forests but in some areas one can also find broad-leaved (deciduous) trees, which are relict plant communities of former milder climatic periods. Wooded meadows were still common in Saaremaa before World War II, but many of these unique natural complexes have gradually become overgrown and thus turned into the ordinary forest. The same is true for alvars (limestone areas covered with thin soil and stunted vegetation). Once a typical and exclusive landscape element in Saaremaa alvars are now in decline. Nature conservation planning for Saaremaa now includes protection of the largest and most unusual alvar areas.
Saaremaa has a wide variety of rare wildlife species, ranging from insects to seals. The smallest protected wildlife species include Cloude Apolle butterflies and Roman snails.
The coastal areas of Saaremaa are famous seal habitats. The gray seal which is common here can be found in three large permanent resting areas on the islets off the coast in the western and southern parts of Saaremaa. The local population of grey seal is slightly increasing. Ringed seals can also be encountered everywhere in the coastal waters of Saaremaa, but because of their timidity it has not been possible to make an estimation of their number. The islands lie within the East - Atlantic flyway, which is the migration path of waterfowl. This "bird road" connects northeastern Europe with Arctic regions and each year hundreds of thousands of migratory birds visit Saaremaa in spring and autumn. The barnacle goose, mute swan, whooper swan, eider, shelduck and a great many other bird species have been given protection status. But on the whole, the islands are somewhat poorer in wildlife species than the mainland. Neither mole, mink, nor otter can be found here, the lynx and the brown bear are but infrequent guests.
Kaali Meteorite.
Kaali is a small group of nine unique meteorite craters on Saaremaa. The largest of the craters measures 110 m in diameter and contains a small lake, known as "Kaali järv" ("Lake Kaali"). The meteor cluster had an impact velocity of 10 – and a mass of 20–80 tons. At the altitude of 5 – the meteor broke into pieces. The largest fragment produced the main crater with a depth of 22 m. Eight smaller craters with diameters ranging from 12 to and depths varying from 1 to are all within 1 km of the main crater. The age estimates of the crater vary, with 4000 ± 1000 BCE being a commonly accepted estimate, though other estimates suggest the explosion was as recent as 660 ± 85 BCE. The energy of the impact — about 80 TJ (20 kilotons of TNT), comparable with the Hiroshima bomb) — burned forests within a radius of 6 km. There are numerous legends related to the crater; these are summarized by Lennart Meri in his book "Hõbevalge".
Resources.
Dolomite, limestone, curative mud, mineral water, sand and gravel, ceramic clay are the major local minerals. Of these local resources the dolomite is perhaps the most famous above all.
Characteristics.
The majority of the population is Estonian (97%). The biggest minority nationality is Russian, comprising 2% of the inhabitants. Compared to the Republic of Estonia on the whole, the population of Saare County and particularly of Kuressaare town is younger, whereas the number of the retired people is considerably smaller. Saaremaa is located in the centre of the Baltic region with the most rapidly growing market in Europe containing 70 million consumers. Gates to the West include not only the newly reconstructed Kuressaare Airport and Roomassaare Port, the operation of modern ferries between Saaremaa and the mainland but also the rapid development of the telecommunications, highly important for the island. Saaremaa is a tourist destination, revisited by 35% of foreign and 95% of domestic tourists. Saaremaa has an entrepreneur-friendly, safe, and strain-free economic environment.
Transportation.
Saaremaa is reached by ferry from Virtsu on the Estonian mainland to Kuivastu on Muhu island, which is itself connected to Saaremaa by a causeway, the Väinatamm. Saaremaa can also be reached by ferry from Sõru on the island of Hiiumaa to Triigi. Both these routes are operated by Tuule Laevad. There are also passenger services from Roomassaare to the smaller island of Abruka. During many winters it is possible to drive to Saaremaa by an ice road between the mainland and Muhu or between Saaremaa and the island of Hiiumaa.
There are regular bus services from Tallinn, Pärnu and Tartu on the mainland, which use the ferry from Virtsu to Muhu.
There is an airport at Kuressaare with regular flights to Tallinn operated by Estonian Air. In the summer season there are regular servicee to Ruhnu and Pärnu operated by Luftverkehr Friesland Harle, and a twice weekly service to Stockholm operated by Estonian Air.
Historically there was a Soviet air base at Aste during the Cold War. There are plans to connect Saaremaa to the mainland either by the Saaremaa Bridge or Saaremaa Tunnel are being studied.
Sport.
FC Kuressaare compete in the first tier of Estonian football, the Meistriliiga. Saaremaa competes in the biannual Island Games.
There are three main international traditional sport events in Saaremaa:

</doc>
<doc id="28340" url="http://en.wikipedia.org/wiki?curid=28340" title="Single-shot">
Single-shot

Single-shot firearms are firearms that hold only a single round of ammunition, and must be reloaded after each shot. The history of firearms began with single-shot designs, and many centuries passed before multi-shot designs became commonplace. Single-shot designs are less complex than revolvers or magazine-fed firearms, and many single-shot designs are still produced by many manufacturers, in both cartridge- and non-cartridge varieties, from zip guns to the highest-quality shooting-match weapons.
History.
Pre-cartridge era.
Most firearms before the era of fixed cartridges were single-shot and muzzleloading, with the exception of the cap-and-ball revolvers, such as Samuel Colt's, which appeared shortly before the cartridge era.
Cartridge era.
Rifles.
Many of the early cartridge-fed rifles were single-shot designs, taking advantage of the strength and simplicity of single-shot actions. A good example is the "trapdoor" or Allin action used in early cartridge conversions of 1863 Springfield muzzleloading rifles. The conversion consisted of filing out (or later milling out) the rear of the barrel, and attaching a folding bolt, the "trapdoor", that flipped up and forwards to allow the cartridge to be loaded in the breech. Once loaded, the bolt was closed and latched in place, holding the round securely in place. The bolt contained a firing pin that used the existing percussion hammer, so no changes were required to the lock. After firing, the act of opening the bolt would partially extract the fired case from the chamber, allowing it to be removed. In 1866, the United States standardized on the .50-70 cartridge, chambered in trapdoor conversions of rifled muskets that had been used in the American Civil War. The trapdoor mechanism continued with the adoption of the Springfield 1873 rifle, chambered in the new .45-70 cartridge. The Springfield stayed in service until 1893, when it was replaced by the Krag-Jørgensen bolt-action rifle.
Another muzzleloader conversion similar in concept to the Allin action was the British Snider-Enfield, also introduced in 1866, which hinged to the side rather than forward. Unlike the US Army, which kept its trapdoors for decades, the British soon moved beyond the Snider to the more sophisticated dropping-block Martini action derived from the Peabody action. Martini-Henrys were the standard British rifles of the late Victorian era, and Martini-Enfield conversions continued in second-line service until the Second World War.
Single-shot rifles were the preferred tools of big-game hunters in the later 19th century. The buffalo hunters of the American West used Sharps, Remington and Springfield single-shots; ivory and trophy hunters in Africa and Asia used Martini and break-action "express rifles" and "elephant guns." These rifles were designed for very large black-powder cartridges, from military-issue .45-70 on up to the enormous .50-140 Sharps and .500 Express; early repeating actions were not capable of handling rounds of this power and physical size. The single-shot big-game rifle would only be displaced by bolt action repeaters firing high-velocity smokeless-powder cartridges in the early 20th century.
After the advent of high-powered repeating rifles, single-shot rifles were primarily used for target shooting matches, with the first official match shooting event, opening at Creedmoor, Long Island in 1872. From about 1872 until the U.S. entry into World War I (1917), target shooting with single-shot rifles was nearly as popular in America as golf is today. During that golden age of match shooting, the most popular target rifles were made by Bullard, Stevens, Remington, Maynard, Ballard, Farrow, and Winchester. Calibers used by some of these rifles during matches ranged from the .25/20, .32/40, .33, .35, .35-55, .38-55, .40-50, .40/70, and a host of .44's (.44/105, .44/77, etc.) for over-600-yard shooting at Creedmoor. But two calibers maintained consistency throughout their tenure during the single-shot era: the .32-40 and the .38-55 calibers. The minimum standard in the beginning of the sport had been 200 yard firing from the standing position (off-hand position). No rifle scopes, no bench rests, no prone (lying down on the front) positions, but shooting, as famed rifle barrel maker, "Harry Melville Pope" (1861–1950), once stated, "standing on his hind legs and shooting like a man." The .32-40 and .38-55 were able to buck the wind better at 200 yards, and not wear the rifleman out by heavy recoil, all while sustaining great accuracy. In the end though, it was the .32-40 single-shot rifle that became the dean of match shooters, as the recoil from the .38-55 took its toll after hundreds of rounds had been fired during a match.
In 1878, John Moses Browning patented arguably the greatest single-shot rifle ever produced: after Browning sold his design to Winchester it was brought out as the Model 1885 Winchester Single Shot Rifle. Although fewer than 200,000 Model 1885 Single Shots were built, it remained in production from 1885 to 1920.
Remington, Sharps, and Browning all made single-shot rifles using different actions, such as the rolling block and falling block. These rifles were originally chambered in large black-powder cartridges, such as .50-110, and were used for hunting large game, often bison. Later production rifles would be in popular smokeless powder cartridges, such as the .30-40 Krag.
Single-shot rifles co-existed for some time with the lever action rifle, but they began to fade out of manufacture with the advent of reliable bolt action rifles.
Pistols.
Single-shot pistols were less common, as the revolver was a fairly mature technology by the advent of cartridge arms, and cartridge conversions existed for the common models of revolver. Versions did exist, which usually fell into two categories: single-shot derringers, and target pistols, which were essentially single-shot rifle actions cut down to pistol size. The Remington Rolling Block is perhaps the most well known of these. As the era of single-shot rifles faded, so did these early single-shot pistols.
In 1907, J. Stevens Arms, a maker of inexpensive break-open single-shot rifles in pistol calibers, started making pistol versions of their rifles. This pistol was chambered in .22 Long Rifle and came with adjustable iron sights and grips designed for target shooting. These models were discontinued in 1939.
Shotguns.
Single-barrel shotguns have always been popular as an inexpensive alternative to double-barreled shotguns. Single shotguns are almost always break-open designs, like the double-barreled designs, but far less expensive since they do not require the precise aligning of parallel barrels. Single shotguns are also lightest, which can be an advantage if they are carried hunting, though it does mean they have the most felt recoil. Single shotguns are not widely used in shotgun sports, as most events require the ability to quickly fire two successive shots, which would require reloading a single-shot design while a target is in the air.
These simple shotguns are often referred to as a "kitchen door gun" or a "farm gun" due to its low cost as a self-defense weapon.
Types of single-shot cartridge actions.
Trapdoor actions.
The earliest metallic-cartridge breechloaders designed for general military issue began as conversions of muzzle-loading rifle-muskets. The upper rear portion of the barrel was filed or milled away and replaced by a hinged breechblock which opened upward to permit loading. An internal angled firing pin allowed the re-use of the rifle's existing side-hammer. The Allin action made by Springfield Arsenal in the US hinged forward; the Snider-Enfield used by the British opened to the side. Whereas the British quickly replaced the Snider with a dropping-block Peabody style Martini action, the US Army felt the trapdoor action to be adequate and followed its muzzleloader conversions with the new-production Springfield Model 1873, which was the principal longarm of the Indian Wars and was still in service with some units in the Spanish–American War.
Other trapdoor actions include the rare Confederate Tarpley carbine, the Austrian Wanzl, the Belgian Albini-Braendlin rifle and Terssen conversion (some of which were made from French 1777 pattern flintlocks!), the M1842/59/67 Swiss Milbank-Amsler, the M1859/67 Spanish Berdan, and the Colt-manufactured Russian Berdan Type I. All of these designs save the 1863 Tarpley date from the period 1865–1869, and all but the Tarpley and the Russian Berdan were conversions from muzzle-loaders.
Break actions.
Perhaps the most common type of single-shot action, usually found in shotguns, small pistols, and black-powder "elephant" guns, a break action connects the barrel assembly to the breechblock with a hinge. When a locking latch is released, the barrel assembly pivots away from the receiver, opening the breech and, at least on better firearms, partially extracting the spent cartridge.
Rolling block actions.
In a rolling block action the breechblock takes the form of a part-cylinder, with a pivot pin through its axis. The operator rotates or "rolls" the block to open and close the breech; it is a simple, rugged and reliable design. Rolling blocks are most often associated with firearms made by Remington in the later 19th century; in the Remington action the hammer serves to lock the breech closed at the moment of firing, and the block in turn prevents the hammer from falling with the breech open. An interesting variation of the rolling block was the Austrian M1867 Werndl-Holub, in which the pivot pin was parallel to the barrel and the block rotated sideways.
Dropping block actions.
These are actions wherein the breechblock lowers or "drops" into the receiver to open the breech, usually actuated by an underlever. There are two principal types of dropping block: the tilting block and the falling block.
Tilting block actions.
In a tilting or pivoting block action, the breechblock is hinged at the rear. When the lever is operated, the block tilts down and forward, exposing the chamber. The best-known pivoting block designs are the Peabody, the Peabody-Martini, and Ballard actions.
The original Peabody rifles, manufactured by the Providence Tool Company, used a manually cocked side-hammer. Swiss gunsmith Friedrich Martini devised an action that resembled the Peabody but incorporated a hammerless striker cocked by the operating lever with the same motion that pivoted the block. The 1871 Martini-Henry which replaced the "trapdoor" Snider-Enfield was the standard British Army rifle of the later Victorian era, and the Martini was also a popular action for civilian rifles.
Charles H. Ballard's self-cocking tilting-block action was produced by the Marlin Firearms Company from 1875, and earned a superlative reputation among long-range "Creedmoor" target shooters. Surviving Marlin Ballards are today highly prized by collectors, especially those mounted in the elaborate Swiss-style "Schützen" stocks of the day.
Falling block actions.
In a falling block action the block does not pivot, but rather slides vertically in a slot milled into the receiver. Falling blocks are among the strongest small-arm actions ever produced, and are also used in heavy artillery. Well-known falling block designs include the Sharps rifles and carbines, the Browning/Winchester Single Shot, the Farquharson rifle, and the modern Ruger No. 1.
Bolt actions.
Although bolt actions are usually associated with fixed or detachable box magazines, in fact the first general-issue military breechloader was a single-shot bolt action: the paper-cartridge Prussian Needle Gun of 1841. France countered in 1866 with its superior Chassepot rifle, also a paper-cartridge bolt action. The first metallic-cartridge bolt actions in general military service were the Berdan Type II introduced by Russia in 1870, the Mauser Model 1871, and a modified Chassepot, the Gras rifle of 1874; all these were single-shots.
Today most top-level smallbore match rifles are single-shot bolt actions.
Single-shot bolt actions in .22 caliber were also widely manufactured as inexpensive "boys' guns" in the earlier 20th century; and there have been a few single-shot bolt-action shotguns, usually in .410 bore.
Modern single-shots.
Although non-cartridge single-shot firearms are still made in hobbyist contexts (for example, replicas of antique guns), this discussion focuses on newer designs employing cartridges.
Pistols.
The modern era of single-shot firearms is most visible in the realm of pistols. Remington introduced the single-shot bolt-action XP-100 pistol in 1963, which heralded the era of high-performance, high-velocity pistols. The .221 Fireball cartridge lived up to its name by reaching velocities of 2700 ft/s (823 m/s) from a 10.5" (26.7 cm) barrel. Essentially a shortened .222 Remington, the compact .221 Fireball delivered accuracy exceeding many rifles, out to ranges unheard of for other handguns.
Even bigger than the XP-100, the 1967 introduction of the Thompson Center Arms Contender pistol changed handgun sports forever. The Contender was a break-open design that allowed barrels to be changed by the shooter in minutes. Available in calibers from .22 Long Rifle up to .45-70, and in barrel lengths of 8, 10, and 14 inches (20, 25, and 35.5 cm), the Contender could, in the right hands, handle any type of game, and delivered rifle-like accuracy to match the XP-100.
Many other manufacturers make single-shot pistols, most based on the bolt action rifle, with barrels generally ranging from 10 to 15 inches (25 to 38 cm). Single-shots dominate handgun metallic silhouette shooting, and single-shots are the most common handguns used for hunting.
Single-shot pistols have sometimes found popularity among insurgents, resistance fighters, and street gangs. The mass-produced, low-cost Liberator pistol of World War II, which was manufactured and distributed by U.S. forces to Allied Resistance forces and Guerrilla fighters as an assassination pistol, is the most common example of a mass-produced single-shot pistol. More than a million units were produced and distributed freely and many remain in private hands. A few varieties of zip guns could also be considered single-shot pistols. In recent years these improvised firearms have become more common in the hands of criminals and insurgents, especially when manufactured firearms are difficult to acquire.
Rifles.
Ruger.
In 1966, Sturm, Ruger introduced their first true rifle, Ruger No. 1, which uses a falling-block action and is available in a wide selection of calibers from .22 Hornet to .458 Winchester Magnum. The No. 1 has always been sought after by shooters who appreciate the compact size of a single-shot rifle, and the falling block action cuts about four inches off the length of the rifle for a given barrel length. From 1972 to 1987, Ruger also made a less expensive version of the #1, the #3. The #3, which sold for about half the price of a #1, used a simplified, non-locking lever for the falling block action, and came with an uncheckered stock.
Browning.
In 1985 Browning re-introduced the famous Winchester Model 1885 single-shot rifles in popular calibers, but under the Browning name. Although the Winchester Single Shot gained fame under the Winchester brand name, it was John Moses Browning that designed the rifle, selling the rights to Winchester in the early 1880s. The Browning Single Shot Rifle was in production from 1985 to 2001.
Cooper.
The majority of rifles made by Cooper are single-shot bolt-action rifles. Many of their rifles are specially crafted to suit long-range varmint hunting, where the accuracy of the single-shot action is helpful.
Remington.
Remington has once again made their No. 1 Rolling Block rifles available through their custom shop.
New England Firearms (H&R).
One of the most common single-action rifles would be the New England Firearms inexpensive break-open rifles, which are built on their 12 gauge break-open shotgun actions. The rifles however are made on a heat treated steel action, and the shotgun actions are not heat treated. Any rifle frame may accept rifle or shotgun barrels, the shotgun frames however are only safe for shotgun barrels. These were originally built by Harrington & Richardson starting in 1871. H&R was later acquired by NEF, and both are now part of the Marlin Firearms family. Rifles are sold both under the NEF and the H&R names. These rifles are quite accurate, and often less than half the price of a bolt action rifle in the same caliber.
Winchester.
In 2005, Winchester re-marketed their legendary Model 1885 Single Shot Rifle, under their "Limited Series" category. The modern calibers of .17 was offered in a Low Wall design, and the .243 and .30-06 were of the High Wall type. The most faithful of the reproductions are the "Traditional Hunter Limited Series" Model 1885 Single Shots, as they have the original style steel crescent butt plates, and folding steel tang rear sights, with full length octagon barrels. The Traditional Hunters are chambered in the 19th century calibers of .45-90 BPCR, .45-70, .405, and .38-55. Test firing of some of these Winchesters showed that they are high quality in construction, using the latest technology and modern steel, they are stronger and safer than their 19th century predecessors; and accuracy from their factory (non-custom) barrels were exceptionally good; especially at 200 yards.
Sharps.
Sharps rifles were a staple of the buffalo hunters in the late 19th century. Recently they have had a resurgence in popularity for hunting large game as well as historical firearms events and black-powder cartridge (BPCR) competitions. Much of the current popularity is due to the film Quigley Down Under that featured a Sharps Model 1874 rifle. The popularity of Cowboy action shooting has also had an impact on the availability of single-shot rifles, with many replicas of the old black-powder rifles, particularly the Sharps, now being available.
Barrett M99 .416.
The Barrett M99 .416 is a single-shot, bolt-action, bullpup sniper rifle. It is chambered in the .416 Barrett round and has 0.5 MOA accuracy at ranges that far exceed one mile. 
There is also another version of the M99 chambered in .50 BMG.

</doc>
<doc id="28341" url="http://en.wikipedia.org/wiki?curid=28341" title="Simon the Sorcerer">
Simon the Sorcerer

Simon the Sorcerer is an adventure game that was released by Adventure Soft on 2 January 1993 for Amiga and DOS formats. The game's name comes from the account of Simon the Sorcerer in Acts 8.
The game includes parodies of various popular books and fairy tales, including Rapunzel, The Lord of the Rings, The Chronicles of Narnia, Jack and the Beanstalk and the Three Billy Goats Gruff.
Simon is voiced in this game by Chris Barrie, known for his roles in "Red Dwarf" and "The Brittas Empire".
Plot.
The story begins with the protagonist, Simon, as an ordinary teenager. His dog, "Chippy", discovers a chest in the loft of his house containing a spellbook titled "Ye Olde Spellbooke". Simon throws the book onto the floor in contempt, but a portal opens above it. Chippy goes through the portal and Simon follows.
After entering the portal, Simon finds himself in another world. After escaping from some goblins who intended to eat him, he discovers that he has been brought on a quest to rescue the wizard "Calypso" from the evil sorcerer "Sordid".
Available versions.
Several different versions of this game were created.
PC Releases.
The first game, "Simon the Sorcerer", was released in 1993 for IBM PC compatibles running DOS on three 3.5" floppy disks in a large box styled with purple margins, with no speech and only sub-titles used throughout the game. It contained a 30-page black and white manual, which included the compass pictures required to pass the copy protection built into this release.
Two years later, just before the sequel was due to be released, the first game was re-released on PC CD-ROM. This new CD came without copy protection, in a jewel case, with a black & white inlay manual, along with colour inserts for both the front and rear. It was advertised with a new Full "Talkie" Soundtrack, which entirely replaced the original subtitles, frustrating some players, including those with hearing disabilities. The CD-ROM version of the sequel "" offers the option to switch between subtitles or the soundtrack.
Since its original release, the PC version of "Simon the Sorcerer" has remained in-print direct from Adventure Soft. Since then, the game has gained "The Original Adventure" as a subtitle, and comes in the same black packaging used by the sequel. The CD has also been updated, first to run on Windows 95/98 using DirectX and later Windows Me/2000/XP. The Windows version CDs introduced an on-disc PDF manual which replaced the jewel case and its inserts. A patch is available for download from Adventure Soft's site, to update older releases to run on Windows Me/2000/XP. Simon the Sorcerer - The Original Adventure has also been published with its sequel in a big box double pack, at a reduced price.
More recently, has re-released the latest versions of all five "Simon the Sorcerer" individual titles in DVD style cases, followed by a combination pack containing four titles, without "Simon the Sorcerer 3D", on one disc.
Amiga releases.
For the Amiga, the AGA A1200 version with 256-colour graphics was available on 9 double-density floppy disks. Shortly afterwards, a 64-colour Amiga 500 edition was created so that any Amiga could play it, and finally a CD32 version was released on CD with 256-colour graphics and voice acting. This was the first Amiga adventure game to feature full voice acting, but only on the CD version.
Other releases.
A 256-colour version of the game was released for the Acorn RISC OS platform on floppy disk, with a CD version including voice acting released later.
In 2009, the game has been re-released for the iPhone and is available via the App Store. This is the talkie version and contains two different control versions, either an original mouse pointer or by simply tapping the screen to select objects and commands.
Recently a new version titled '20th Anniversary Edition' released exclusively for Android using a new cover artwork. It was released on Aug. 26, 2013. This combined all 7 original languages releases, new hotspots-based touch controls with icons for actions, optional upscaling the graphics to HD and new game menus.
Notably, the original cover art depicts the "demonic robot" form which Sordid would take on in the second game in the series. This version of Sordid does not actually appear in the first game except for a cameo at the end, and even then only a large mechanical arm is seen dragging Simon through a portal back to the fantasy world. 
Probably because of this, the new '20th Anniversary Edition' only uses the hands from the original artwork, which are mostly covered with gloves that leaves just a small hint of the robotic hands beneath.
Reception.
The Amiga version of "Simon the Sorcerer" received generally high ratings. CU Amiga rated the game 90% and praised the high quality graphics and how much fun the game was to play. Amiga Computing gave the game a score of 89% and also praised the graphics. The magazine also enjoyed the puzzles and detail in the game. Both magazines compared the game to "" but also pointed out that it is not a copy and is a quality product. Game Rankings states the PC version of game has a rating of 86.3%. 

</doc>
<doc id="28343" url="http://en.wikipedia.org/wiki?curid=28343" title="South African Republic">
South African Republic

 |style="width:1.0em; padding:0 0 0 0.6em;"| - 
 |style="padding-left:0;text-align:left;"| 1857–1863
 |- class="mergedbottomrow"
 | style="width:1.0em; padding:0 0 0 0.6em;"|  -  ||style="padding-left:0;text-align:left;"| 1870 
 |  km² ( sq mi)
 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |- class="mergedbottomrow"
 |style="padding-left:0;text-align:left;"| 1870 est.
 |- class="mergedbottomrow"
 |colspan="2"| Density
 |style="white-space:nowrap;"| /km²  ( /sq mi)
 |  South Africa
The South African Republic (Dutch: "Zuid-Afrikaansche Republiek", ZAR), often referred to as the Transvaal and sometimes as the Republic of Transvaal, was an independent and internationally recognised country in Southern Africa from 1852 to 1902. The country defeated the British in what is often referred to as the First Boer War and remained independent until the end of the Second Boer War on 31 May 1902, when it was forced to surrender to the British. The territory of the ZAR became known after this war as the Transvaal Colony. After the outbreak of the First World War a small number of Boers staged the Maritz Rebellion and aligned themselves with the Central Powers in a failed gambit to regain independence.
Name and etymology.
Zuid-Afrikaansche Republiek (ZAR).
Constitutionally the name of the country was "Zuid-Afrikaansche Republiek" (South African Republic or ZAR). Many people also called the "ZAR Transvaal", in reference to the area over (or trans) the Vaal River including the British press and the press in Europe. In fact the name "Transvaal" was later so often used that later the British objected to the use of the real name (The South African Republic). The British pointed out that the Convention of Pretoria of 3 August 1881 referred to the 'Transvaal Territory' and that the Transvaal and the South African Republic did not have the same boundaries. However, in the London Convention dated 27 February 1884,:469–474 a subsequent treaty between Britain and the ZAR, Britain acquiesced and reverted to the use of the true name, "The South African Republic". 
Transvaal.
The name of the South African Republic was of such importance that on 1 September 1900 the British declared by special proclamation that the name of the South African Republic be changed:514 from "South African Republic" to "The Transvaal" and that the entire territory shall henceforth and forever be known as "The Transvaal". This proclamation was issued during the second boer war and whilst the ZAR was still an independent country.
On 31 May 1902, the Treaty of Vereeniging was signed, with the South African Government, Orange Free State Government and the British Government which also converted the ZAR into the Transvaal Colony. On 20 May 1903 an Inter Colonial Council:516 was established, to manage the colonies of the British Government. The name "Transvaal" was finally changed in 1994, when the ANC government broke up the Transvaal area and renamed the core, to "Gauteng".
History.
Early history.
In paleolithic times, between 2.2 to 3.3 million years ago, hominids lived within the geographic area of the ZAR. The earliest hominid bones, between 2.2 to 3.3 million years old, was discovered at Sterkfontein in 1994. In 1938 Paranthropus robustus bones were found at Kromdraai, and during 1947 several more examples of Australopithecus africanus were uncovered in Sterkfontein. The pastoral San People lived on the lands of Southern Africa and they were later joined by Bantu people from North Africa and then Europeans. The Bantu, who displaced the San, were themselves decimated and scattered by the internecine warfare known as the Mfecane which left most of the lands of the ZAR abandoned and vacant. The greater portion of the territory south of the twenty-second parallel of latitude was literally without any inhabitants. With the arrival of the Europeans and their defense of Matabele raids, the Bantu tribes inhabiting the mountains and deserts could settle on open country, make gardens and sleep in safety. The Europeans were masters and owners of the land, but in accordance with the ancient Dutch custom, they permitted each newly settled Bantu community to be governed by its own chief. The Europeans subjected the Bantu community to a kraal tax, which was fully accepted by the Bantu communities and loyally paid while the Europeans provided peace and security, according to historian George McCall Theal.:335
Formation.
The Zuid-Afrikaansche Republiek came into existence on 17 January 1852:357–359 when the United Kingdom signed the Sand River Convention treaty with about 40,000 Boer people, recognising their independence in the region to the north of the Vaal River.
The first president of the Zuid-Afrikaansche Republiek was Marthinus Wessel Pretorius, elected in 1857, son of Boer leader Andries Pretorius, who commanded the Boers to victory at the Battle of Blood River. The capital was established at Potchefstroom and later moved to Pretoria. The parliament was called the Volksraad and had 24 members.
Independence.
The South African Republic became fully independent on the 27 February 1884 when the London Convention was signed. The country independently also entered into various agreements with other foreign countries after that date. On 3 November 1884 the country signed a Postal convention with the government of the Cape Colony and later similarly with the Orange Free State.:477
Expansion.
On the November 1859:420–422 the independent Republic of Lijdenburg merged with the Zuid Afrikaansche Republiek. On 9 May 1887, burghers from the territories of Stellaland and Goosen:479 (sometimes referred to as Goshen) were granted rights to the ZAR franchise. On the 25th of July 1895 the burghers that took part in the battle at Zoutpansberg,:505 were granted citizenship of the ZAR.
Constitution and laws.
The constitution of the Zuid Afrikaansche Republiek has been referred to as legally interesting for its time. It contained provisions for the division between the political leadership and office bearers in government administration. The legal system consisted of higher and lower courts and had adopted a jury system. The laws were enforced by the South African Republic Police (Zuid-Afrikaansche Republiek Politie or ZARP) which were divided into Mounted Police (Rijdende Politie) and Foot Police. On 10 April 1902 the Magistrates Court powers were extended to increase the civil ceiling amounts and to expand criminal jurisdiction to include all criminal cases not punishable by death or banishment. Also established was a Municipal Government, Witwatersrand District court and the High Court of Transvaal.:515
Religion.
Initially the State and Church were not separated in the constitution of the ZAR. To be a citizen of the ZAR you had to be a member of the Dutch Reformed Church. In 1858 these clauses were altered in the constitution to allow for the Volksraad to approve other Dutch Christian churches.:358–359 The Reformed Church was approved by the Volksraad in 1858, which had the effect of allowing Paul Kruger, of the Gereformeerde Kerk to remain a citizen of the ZAR. The Bible itself was also often used to interpret the intention of legal documents. The Bible was also used to interpret a prisoner exchange agreement, reached in terms of the Sand River Convention, between a commando of the ZAR, led by Paul Kruger and a Commando of the Orange Free State. President Boshoff had issued a death sentence over two ZAR citizens, for treason. Paul Kruger argued with President Boshoff that the Bible said punishment does not mean a death sentence and at the prisoner exchange, it was agreed that the accused would be punished if found guilty. After double checking Commandant Paul Krugers Bible, President Boshoff commuted the sentences to lashes with a sjambok.
Citizenship.
Citizenship of the ZAR was legislated by the constitution as well as Law no 7 of 1882, as amended on 23 June 1890.:495 Citizenship was gained by being born in the republic or by naturalization. The voting age was 16 years. Persons not born in the Republic (Foreigners) could become citizens by taking the prescribed oath and procuring the letters of naturalization. The oath involved abandoning, discarding and renouncing all allegiance and subjugation towards foreign sovereignties and in particular their previous citizenship. Foreigners had to have been residing in the Republic for a period of two years, be of good character and have been accepted as member of the Dutch Reformed or Reformed Church. On 20 September 1893 the ZAR Constitution was amended so that two thirds of the Volksraad would have to agree to changes to the citizenship law. This proclamation, number 224, also changed Law no 7 with regards to voting.:501 All citizens who was born in the ZAR or whom obtained their franchise prior to 23 June 1890 would have the right to vote for both the first and second volksraad and in all other elections. Citizens who obtained their franchise through naturalization after 23 June 1890, would be able to vote in all elections, except those for the first Volksraad.
Racism.
The constitution promoted racialism as it treated European (white) people differently from Native (black) people. Although slavery was illegal in the constitution and foreigners (white and black) were both discriminated against, black foreigners had fewer rights than their white counterparts. Black and Asian foreigners could never become citizens of the ZAR, at this time in history, this was very similar to many other European countries as well as in the new world.
Discrimination on the basis of race was prevalent in the ZAR and black British subjects were forced to reside in ghettos outside cities with Asian and black races, whilst white races were free to live anywhere. One of the racist motivations often used by the ZAR Government was "sanitation and regard to public health necessitated that measure of segregation"
Language and culture.
Language.
The language spoken and written by the citizens of the ZAR was high Dutch. This high Dutch was carried over into the Transvaal Colony and later the Union of South Africa. Up to 1925, the high Dutch language was still in use. In fact there were four main languages: High Dutch, Low or South African Dutch (Afrikaans), High Afrikaans and English. After 1925, High Dutch was removed and only Afrikaans and English remained as official languages. 
On 3 October 1884 the Volksraad stated that they had reason to believe that in certain schools impure Dutch was being used. The Volksraad issued Proclamation 207 and compelled the Superintendent of Education to apply the language law enforcing the exclusive use of the Dutch Language.:477
On the 30 July 1888 the high Dutch language was declared the only language:481–482 to be used in the country, not only in government but also in schools, trade and general use. All other languages were declared "foreign". These changes to the ZAR laws made the use of all other foreign languages illegal in the ZAR. Use of any foreign language was subject to criminal penalty:483 and fine of 20 ZAR Pond for each offense. 
The British similarly had declared English to be the only language spoken in the Cape Colony some decades earlier to outlaw the Dutch Language. 
The discovery of gold in 1885 led to a major influx of foreigners. 
By 1896 the language of government and citizens remained Dutch but in many market places, shops and homes the English language was spoken.
Boer Wars.
War with Mapela and Makapaan, 1854.
Hendrik Potgieter was elected at the assembly of 1849, as Commandant General for life and it became necessary, to avoid strife, to appoint three commandants general, all possessing equal powers.:41 Commandant General A.W.J. Pretorius became Commandant General of the Potchefstroom and Rustenburg districts. 16 December 1852, Commandant General Potgieter passed away and his son, Piet Potgieter, was appointed in his stead as Commandant General of the Lydenburg and Zoutpansberg districts of the ZAR. There was some disputes over cattle which Mapela was raising on behalf of Potgieter and earlier Commandant Scholtz had confiscated a large amount of rifles, ammunition, rifle repair equipment and materials of war from the home of English missionary, Reverend Livingstone. Livingstone admitted to storing these for Secheli and by this he was acting in breach of the Sand River Convention of 1852, which prescribed that neither arms nor ammunition should be supplied to the natives.:40
In 1853, the brother of Hendrik Potgieter, Herman Potgieter was called to Mapela to come and cull the elephant population.:42 When Potgieter arrived, Maphela took Potgieter, his son, his groom and a few other burghers to show them where the elephants were. On the way, Mapela and hundreds of natives attacked the Potgieter party. They killed Andries Potgieter, the son of Herman Potgieter and then dragged Potgieter up a hill, where they proceeded to skin him alive. They stopped once they had torn the entrails from his body.:43 At the same time of these events, Makapaan attacked and killed an entire convoy of woman and children traveling to Pretoria. The two chiefs had concluded an agreement to murder all the Europeans in their respective districts:44 and to keep the cattle that they were raising for the Europeans. General Piet Potgieter set out with 100 men from Zoutpansberg and Commandant General Pretorius left Pretoria with 200 men. After the commandos met up, they first attacked Makapaan and the natives were driven back to their caves in the mountains where they lived before. The Boers held them at siege in their caves and eventually hundreds of women and children came out.
Orphan children of the native tribes were "ingeboekt" at "autorisatie voor den landrost" or translated into English, "booked in" strictly controlled by legal process, at appointed Boer families to look after them until they came of age.:47 (The administration was similar to the system of indentured workers, (which was simply another form of slavery) with the exception that children so registered had to be released at age 16) The commando would return all such children to the nearest landrost district, for registration and allocation to a Boer family. As there were slavers and other criminals dealing in children any burgher found in possession of an unregistered minor child was guilty of a criminal offense. These children were also often called "oorlams" in reference to being overly used to the Dutch culture, and in reference to a hand raised orphan sheep, or "hanslam". These children, even after their 16th birthday, and being free to come and go as they please, never re-connected with their own culture and own language and except for surviving and being cared for in terms of food and shelter, were basically forcefully divorced from their native tribe forever.
Among the casualties of this war was Commandant General Potgieter.:46 The natives were armed with rifles and were good shots. The general was killed by native sniper on the ridge of a trench and his body recovered by then commandant Paul Kruger whilst under heavy fire from the natives. What remained of the joint commando, now under command of General Pretorius focussed their attention on Mapela. By the time the commando had reached Mapela, the natives had fled. A few wagons, bloody clothes, chests and other goods were discovered at a kop near Mapela's town. Mapela and his soldiers escaped and with their rifles and ammunition intact and Mapela was only captured much later, in 1858.
Civil War, 1861–1864.
Commandant-General Schoeman did not accept the 20 September 1858 proclamation by the Volksraad, where the members of the Christelijk Gereformeerde Church, would be entitled to citizenship of the ZAR. Consequently, Paul Kruger was not accepted as a citizen and disallowed from political intercourse. Acting President van Rensburg called a special meeting of the general council of the Hervormde kerk (Dutch Reformed Church) which then voted in a special resolution to allow members of the Reformed Church access to the franchise.
Sekhukhune War of 1876.
In 1876, a war between the ZAR and the Bapedi broke out over cattle theft and land encroachment. The Volksraad declared war on the Pedi leader, Sekhukhune on 16 May 1876. The war only began in July 1876. The president of the ZAR, Burgers led an army of 2000 burghers and was joined by a strong force of Swazi warriors. The Swazis joined the war to aid Mampuru, who was ousted from his position of chieftain by Sekhukhune. One of the early battles occurred at Botsabelo Mission Station on 13 July 1876, against Johannes Dinkwanyane, who was Sekhukhune's brother. The Boer forces were led by Commandant Coetzee and accompanied by Swazi warriors. The Swazi warriors launched a surprise and successful attack while the Boers held back. Seeing this, the Swazis refused to hand over to the Boers any spoils from the battle, thereafter leaving and returning to Swaziland. Dinkwanyane's followers also surrendered after this campaign.
First Boer War, 1880–1881.
On 12 April 1877, Britain issued a proclamation called: "ANNEXATION OF THE S.A. REPUBLIC TO THE BRITISH EMPIRE":448–449 In the proclamation, the British claim that the country is unstable, ungovernable, bankrupt and facing civil war. The unsuccessful annexation did not suspend self-government and attempted to convert the ZAR into a British colony.:448–453
The Zuid Afrikaansche Republiek viewed this proclamation as an act of aggression,:454–455 and resisted. Instead of declaring war, the country decided to send a delegation to United Kingdom and the USA, to protest. This did not have any effect and the First Boer War formally broke out on 20 December 1880. The First Boer War was the first conflict since the American Revolution in which the British had been decisively defeated and forced to sign a peace treaty under unfavourable terms. It would see the introduction of the khaki uniform, marking the beginning of the end of the famous Redcoat. The Battle of Laing's Nek would be the last occasion where a British regiment carried its official regimental colours into battle. The Pretoria Convention of 1881 was signed on 3 August 1881 and ratified on 25 October 1881 by the Zuid Afrikaansche Republiek (where the Zuid-Afrikaansche Republiek is referred to by the name "Transvaal Territory"). The Pretoria Convention of 1881:456–457 was superseded in 1884 by the London Convention,:469–470 and in which the British suzerainty over the South African Republic, was relinquished. The British Government, in the London Convention, accepted the name of the country as The South African Republic. The convention was signed in duplicate, in London on 27 February 1884 by Hercules Robinson, S.JP. Kruger, S.J. Du Toit and N.J. Smit and later ratified by the South African Republic (Zuid-Afrikaansche Republiek) Volksraad.
In 1885 extremely rich gold reefs were discovered in the ZAR. The South African Republic burghers were farmers and not miners and much of the mining fell to immigrants. The immigrants were also referred to as "outlanders" (uitlanders). By 1897 the immigrants had invested over 300 000 000 British Pounds in the ZAR goldfields.
Second Boer War, 1899–1902.
Britain first attacked the independent country of South Africa in December 1895, the Jameson Raid. After that failed attack the British started building up massive amounts of troops and resources at the borders of the ZAR. Then they demanded voting rights for the 50,000 British nationals and the 10, 000 other nationals in South Africa, even though none of these nationals were at that time South African citizens. Kruger rejected the British demand and called for the withdrawal of British troops from the ZAR's borders. When the British refused, Kruger declared war against Britain. Britain received assistance from Australia, Canada and New Zealand as well as forces and citizens of colonies like the Colony of Natal and the Cape Colony.
The Second Boer War was a watershed for the British Army in particular and for the British Empire as a whole. The British used concentration camps where women and children were held without adequate food or medical care. The abhorrent conditions in these camps caused the death of 4,177 women and 22,074 children under sixteen; death rates were between 344 and 700 per 1000. There is #Redirect .
The Treaty of Vereeniging was signed on 31 May 1902. The treaty ended the existence of the ZAR and the Orange Free State as independent Boer republics and placed them within the British Empire. The Boers were promised eventual limited self-government, which was granted in 1906 and 1907. The Union of South Africa was established in 1910.
Political structure.
Divisions.
The country was divided into 17 districts: 
Flag.
The national flag of the ZAR featured three horizontal stripes of red, white, and blue (mirroring the Dutch national flag), with a vertical green stripe at the hoist, and was known as the "Vierkleur" (lit. "four colours"). The former national flag of South Africa (from 1927 to 1994) had, as part of a feature contained within its central white bar, a horizontal flag of the Transvaal Republic (ZAR).

</doc>
<doc id="28347" url="http://en.wikipedia.org/wiki?curid=28347" title="Sling (weapon)">
Sling (weapon)

A sling is a projectile weapon typically used to throw a blunt projectile such as a stone, clay, or lead "sling-bullet". It is also known as the shepherd's sling.
A sling has a small cradle or "pouch" in the middle of two lengths of cord. The "sling stone" is placed in the pouch. The middle finger or thumb is placed through a loop on the end of one cord, and a tab at the end of the other cord is placed between the thumb and forefinger. The sling is swung in an arc, and the tab released at a precise moment. This frees the projectile to fly to the target. The sling essentially works by extending the length of a human arm, thus allowing stones to be thrown much farther than they could be by hand.
The sling is inexpensive and easy to build. It has historically been used for hunting game and in combat. Film exists of Spanish Civil War combatants using slings to throw grenades over buildings into enemy positions on the opposite street. Today the sling interests sportsmen as a wilderness survival tool and as an improvised weapon.
The sling in antiquity.
Origins.
The sling is an ancient weapon known to Neolithic peoples around the Mediterranean, but is likely much older. It is possible that the sling was invented during the Upper Paleolithic at a time when new technologies such as the spear-thrower and the bow and arrow were emerging. With the exception of Australia, where spear throwing technology such as the woomera predominated, the sling became common all over the world, although it is not clear whether this occurred because of cultural diffusion or independent invention.
Archaeology.
Whereas sling-bullets are common finds in the archaeological record, slings themselves are rare. This is both because a sling's materials are biodegradable and because slings were lower-status weapons, rarely preserved in a wealthy person’s grave.
The oldest-known surviving slings—radiocarbon dated to ca. 2500 BC—were recovered from South American archaeological sites located on the coast of Peru. The oldest-known surviving North American sling—radiocarbon dated to ca. 1200 BC—was recovered from Lovelock Cave, Nevada.
The oldest known extant slings from the Old World were found in the tomb of Tutankhamen, who died about 1325 BC. A pair of finely plaited slings were found with other weapons. The sling was probably intended for the departed pharaoh to use for hunting game.
Another Egyptian sling was excavated in El-Lahun in Al Fayyum Egypt in 1914 by William Matthew Flinders Petrie, and now resides in the Petrie Museum of Egyptian Archaeology—Petrie dated it to about 800 BC. It was found alongside an iron spearhead. The remains are broken into three sections. Although fragile, the construction is clear: it is made of bast fibre (almost certainly flax) twine; the cords are braided in a 10-strand elliptical sennit and the cradle seems to have been woven from the same lengths of twine used to form the cords.
Ancient representations.
Representations of slingers can be found on artifacts from all over the ancient world, including Assyrian and Egyptian reliefs, the columns of Trajan and Marcus Aurelius, on coins and on the Bayeux Tapestry.
The oldest representation of a slinger in art may be from Çatalhöyük, from approximately 7,000 BC, though it is the only such depiction at the site, despite numerous depictions of archers.
Written history.
The sling is mentioned by Homer and by other Greek authors. Xenophon in his histroy of the retreat of the Ten Thousand, 401 BC, relates that the Greeks suffered severely from the slingers in the army of Artaxerxes II of Persia, while they themselves had neither cavalry nor slingers, and were unable to reach the enemy with their arrows and javelins. This deficiency was rectified when a company of 200 Rhodians, who understood the use of leaden sling-bullets, was formed. They were able, says Xenophon, to project their missiles twice as far as the Persian slingers, who used large stones.
Ancient authors seemed to believe, incorrectly, that sling-bullets could penetrate armour, and that lead projectiles, heated by their passage through the air, would melt in flight. In the first instance, it seems likely that the authors were indicating that slings could cause injury through armour by a percussive effect rather than by penetration. In the latter case we may imagine that they were impressed by the degree of deformation suffered by lead sling-bullet after hitting a hard target.
Various ancient peoples enjoyed a reputation for skill with the sling. Thucydides mentions the Acarnanians and Livy refers to the inhabitants of three Greek cities on the northern coast of the Peloponnesus as expert slingers. Livy also mentions the most famous of ancient skillful slingers: the people of the Balearic Islands. Of these people Strabo writes: "And their training in the use of slings used to be such, from childhood up, that they would not so much as give bread to their children unless they first hit it with the sling."
The late Roman writer Vegetius, in his work "De Re Militari", wrote:
According to description of Procopius, the sling had an effective range further than a Hun bow and arrow. In his book "Wars of Justinian", he recorded the felling of a Hun warrior by a slinger:
Biblical accounts.
The sling is mentioned in the Bible, which provides what is believed to be the oldest textual reference to a sling in the Book of Judges, 20:16. This text was thought to have been written about 1000 BC, but refers to events several centuries earlier.
The Bible provides a famous slinger account, the battle between David and Goliath from the First Book of Samuel 17:34-36, probably written in the 7th or 6th century BC, describing events having occurred around the 10th century BC. The sling, easily produced, was the weapon of choice for shepherds fending off animals. Due to this, the sling was a commonly used weapon by the Israelite militia. Goliath was a tall, well equipped and experienced warrior. In this account, the shepherd David convinces Saul to let him fight Goliath on behalf of the Israelites. Unarmoured and equipped only with a sling, 5 smooth rocks, and his staff; David defeats the champion Goliath with a well-aimed shot to the head.
Use of the sling is also mentioned in Second Kings 3:25, First Chronicles 12:2, and Second Chronicles 26:14 to further illustrate Israelite use.
Combat.
Ancient peoples used the sling in combat—armies included both specialist slingers and regular soldiers equipped with slings. As a weapon, the sling had several advantages; a sling bullet lobbed in a high trajectory can achieve ranges in excess of 400 m. Modern authorities vary widely in their estimates of the effective range of ancient weapons. A bow and arrow could also have been used to produce a long range arcing trajectory, but ancient writers repeatedly stress the sling's advantage of range. The sling was light to carry and cheap to produce; ammunition in the form of stones was readily available and often to be found near the site of battle. The ranges the sling could achieve with molded lead sling-bullets was only topped by the strong composite bow or, centuries later, the heavy English longbow, both at massively greater cost.
Caches of sling ammunition have been found at the sites of Iron Age hill forts of Europe; some 40,000 sling stones were found at Maiden Castle, Dorset. It is proposed that Iron Age hill forts of Europe were designed to maximise the effective defense of slingers.
The hilltop location of the wooden forts would have given the defending slingers the advantage of range over the attackers, and multiple concentric ramparts, each higher than the other, would allow a large number of men to create a hailstorm of stone. Consistent with this, it has been noted that defenses are generally narrow where the natural slope is steep, and wider where the slope is more gradual.
Construction.
A classic sling is braided from non-elastic material. The traditional materials are flax, hemp or wool; those of the Balearic islanders were said to be made from a type of rush. Flax and hemp resist rotting, but wool is softer and more comfortable.
Braided cords are used in preference to twisted rope, as a braid resists twisting when stretched. This improves accuracy.
The overall length of a sling can vary significantly; a slinger may have slings of different lengths, a longer sling being used when greater range is required. A length of about 61 to would be typical.
At the centre of the sling, a cradle or pouch is constructed. This may be formed by making a wide braid from the same material as the cords or by inserting a piece of a different material such as leather. The cradle is typically diamond shaped (although some take the form of a net,) and will fold around the projectile in use. Some cradles have a hole or slit that allows the material to wrap around the projectile slightly, thereby holding it more securely.
At the end of one cord (called the retention cord) a finger-loop is formed. At the end of the other cord (the release cord,) it is a common practice to form a knot or a tab. The release cord will be held between finger and thumb to be released at just the right moment, and may have a complex braid to add bulk to the end. This makes the knot easier to hold, and the extra weight allows the loose end of a discharged sling to be recovered with a flick of the wrist.
Polyester is an excellent material for modern slings, because it does not rot or stretch and is soft and free of splinters.
Modern slings are begun by plaiting the cord for the finger loop in the center of a double-length set of cords. The cords are then folded to form the finger-loop. The cords are plaited as a single cord to the pocket. The pocket is then plaited, most simply as another pair of cords, or with flat braids or a woven net. The remainder of the sling is plaited as a single cord, and then finished with a knot. Braided construction resists stretching, and therefore produces an accurate sling.
Ammunition.
The simplest projectile was a stone, preferably well-rounded. Suitable ammunition is frequently from a river. The size of the projectiles can vary dramatically, from pebbles massing no more than 50 g to fist-sized stones massing 500 g or more.
Projectiles could also be purpose-made from clay; this allowed a very high consistency of size and shape to aid range and accuracy. Many examples have been found in the archaeological record.
The best ammunition was cast from lead. Leaden sling-bullets were widely used in the Greek and Roman world. For a given mass, lead, being very dense, offers the minimum size and therefore minimum air resistance. In addition, leaden sling-bullets are small and difficult to see in flight.
In some cases, the lead would be cast in a simple open mould made by pushing a finger or thumb into sand and pouring molten metal into the hole. However, sling-bullets were more frequently cast in two part moulds. Such sling-bullets come in a number of shapes including an ellipsoidal form closely resembling an acorn - this could be the origin of the Latin word for a leaden sling-bullet: "glandes plumbeae" (literally leaden acorns) or simply "glandes" (meaning acorns, singular "glans").
Other shapes include spherical and (by far the most common) biconical, which resembles the shape of the shell of an almond nut or a flattened American football.
The ancients do not seem to have taken advantage of the manufacturing process to produce consistent results; leaden sling-bullets vary significantly. The reason why the almond shape was favoured is not clear: it is possible that there is some aerodynamic advantage, but it seems equally likely that there is some more prosaic reason, such as the shape being easy to extract from a mould, or the fact that it will rest in a sling cradle with little danger of rolling out.
Almond shaped leaden sling-bullets were typically about 35 mm long and about 20 mm wide, massing approximately 28 g. Very often, symbols or writings were moulded into lead sling-bullets. Many examples have been found including a collection of about 80 sling-bullets from the siege of Perusia in Etruria from 41 BC, to be found in the museum of modern Perugia. Examples of symbols include a stylised lightning bolt, a snake, and a scorpion - reminders of how a sling might strike without warning. Writing might include the name of the owning military unit or commander or might be more imaginative: "Take this," "Ouch," and even "For Pompey's backside" added insult to injury, whereas "dexai" ("take this" or "catch!") is merely sarcastic.
Julius Caesar writes in De bello Gallico, book 5, about clay shot being heated before slinging, so that it might set light to thatch.
The sling in medieval period.
Europe.
By the Middle Ages the shepherd's sling was largely militarily extinct outside the Iberian peninsula, where the Spanish and Portuguese infantry favoured it against light and agile Moorish troops; a sling projectile, while dangerous even against an armoured opponent, could be lethal against a light and unarmoured foe. The staff sling (see below) continued to be used in sieges and the sling was used as a part of large siege engines.
The sling continued in use for the hunting of game.
The Americas.
The sling was known throughout the Americas.
In the ancient Andean civilizations such as Inca Empire, slings were made from llama wool. These slings typically have a cradle that is long and thin and features a relatively long slit. Andean slings were constructed from contrasting colours of wool; complex braids and fine workmanship can result in beautiful patterns. Ceremonial slings were also made; these were large, non-functional and generally lacked a slit. To this day, ceremonial slings are used in parts of the Andes as accessories in dances and in mock battles. They are also used by llama herders; the animals will move away from the sound of a stone landing. The stones are not slung to hit the animals, but to persuade them to move in the desired direction.
The sling was also used in the Americas for hunting and warfare. One notable use was in Incan resistance against the conquistadors. These slings were apparently very powerful; in 1491: New Revelations of the Americas Before Columbus, historian Charles C. Mann quoted a conquistador as saying that an Incan sling "could break a sword in two pieces" and "kill a horse." Some slings spanned as much as 86 in long and weighed an impressive 14.4 oz.
Variants.
Staff sling.
The staff sling, also known as the stave sling, "fustibalus" (Latin), "fustibale" (French), consists of a staff (a length of wood) with a short sling at one end. One cord of the sling is firmly attached to the stave and the other end has a loop that can slide off and release the projectile. Staff slings are extremely powerful because the stave can be made as long as two meters, creating a powerful lever. Ancient art shows slingers holding staff slings by one end, with the pocket behind them, and using both hands to throw the staves forward over their heads.
The staff sling has a similar or superior range to the shepherd's sling, and can be as accurate in practiced hands. It is generally suited for heavier missiles and siege situations as staff slings can achieve very steep trajectories for slinging over obstacles such as castle walls. The staff itself can become a close combat weapon in a melee. The staff sling can throw heavy projectiles a much greater distance and at a higher arc than a hand sling. Staff slings were in use well into the age of gunpowder as grenade launchers, and were used in ship-to-ship combat to throw incendiaries.
Kestros.
The kestros (also known as the kestrosphendone, cestrus or cestrosphendone) is a sling weapon mentioned by Livy and Polybius. It seems to have been a heavy dart flung from a leather sling. It was invented in 168 BC and was employed by some of the Macedonian troops of King Perseus in Third Macedonian war.
Siege engines.
The trebuchet was a siege engine which uses the power of men pulling on ropes or the energy stored in a raised weight to rotate what was, again, a staff sling. It was designed so that, when the throwing arm of the trebuchet had swung forward sufficiently, one end of the sling would automatically become detached and release the projectile. Some trebuchets were small and operated by a very small crew; however, unlike the onager, it was possible to build the trebuchet on a gigantic scale: such giants could hurl enormous rocks at huge ranges. Trebuchets are, in essence, mechanised slings.
Slings today.
Classic woolen slings are still in use in the Middle East by Arab nomads and Bedouins to ward off jackals and hyenas. They were also used during the various Palestinian Intifadas against modern army personnel and riot police.
The sling is used today as a weapon primarily by protestors, to launch either stones or incendiary devices, such as Molotov cocktails. International Brigades used slings to throw grenades during the Spanish Civil War. Similarly, the Finns made use of sling-launched Molotov cocktails in the Winter War against Soviet tanks. Slings were also used in the 2008 disturbances in Kenya.
The sling is of interest to athletes who desire to break distance records; the best modern material is a polyester twine (trade name Dacron).
Traditional slinging is still practiced as it always has been in the Balearic Islands, and competitions and leagues are common. In the rest of the world, the sling is primarily a hobby weapon, and a growing number of people make and practice with them. In recent years 'slingfests' have been held in Wyoming, USA, in September 2007 and in Staffordshire, England, in June 2008.
According to the Guinness Book of World Records, the current record for the greatest distance achieved in hurling an object from a sling is 437.10 m, using a 129.5 cm long sling and a 52 g ovoid stone, set by Larry Bray in Loa, Utah, USA on 21 August 1981.
The principles of the sling may find use on a larger scale in the future; proposals exist for tether propulsion of spacecraft, which functionally is an oversized sling to propel a spaceship.
Sling methods.
A skillful throw requires just one rapid rotation. Some slingers will rotate the sling slowly once or twice to seat the projectile in the cradle.
One makes an overhand throw, using the sling to extend one's arm. The motion is similar to bowling a cricket ball. This is relatively accurate, instinctive and quite powerful. One faces 60 degrees away from the target, with one's non-throwing hand closest to the target: thus, imagining the thrower at the center of a large horizontal circle with the target at the 12 o'clock position, a right-handed thrower would orient one's body toward 2 o'clock, with the arm rotating vertically in the 12 o'clock plane. The coordinated motion is to move every part of the body, legs, waist, shoulders, arms, elbows and wrist in the direction of the target in order to add as much speed as possible to the stone. One releases the projectile near the top of the swing, where the projectile will proceed roughly parallel to the surface of the earth.
Another method of release said to be favoured by slingers firing into grouped or massed targets is an underhand throw. The motion is similar to that of throwing a softball. The trajectory arc is relatively high. The thrower stands 60 degrees away from the target, and takes one step forward from the trailing foot, letting the sling swing forward. Range is said to be increased with this method, sacrificing accuracy. Several historians have conjectured that this was the most commonly used method in ancient warfare due to its practicality.
There are also sideways releases, in which the swing goes around; however, these throws make it very easy to release the projectile at a slightly wrong time and miss the target.

</doc>
<doc id="28349" url="http://en.wikipedia.org/wiki?curid=28349" title="Stock car racing">
Stock car racing

Stock car racing is a form of automobile racing found mainly in the United States, Canada, New Zealand, Australia, United Kingdom, Mexico, Brazil and Argentina. Traditionally, races are run on oval tracks measuring approximately 0.25 to. NASCAR is the world's largest governing body for stock car racing, and its Sprint Cup Series is the de facto premier series of stock car racing. Top level races are 200 to in length.
Average speeds in the top classes are usually 70–80% of comparable levels of open-wheel racing at the same tracks. Some stock cars may reach speeds in excess of 200 mph at Speedway tracks, and well over 200 mph on Superspeedway tracks such as Daytona International Speedway and Talladega Superspeedway. These tracks have come to be known as "restrictor plate tracks", a name that is derived from the "restrictor plate" device that was designed to limit top speeds to approximately 192 mph on such tracks.
Stock cars.
A "stock car", in the original sense of the term, is described as an automobile that has not been modified from its original factory configuration. Later the term "stock car" came to mean any production-based automobile used in racing. This term is used to differentiate such a car from a "race car", a special, custom-built car designed only for racing purposes.
The actual degree to which the cars conform to standard model specs has changed over the years and varies from country to country. Today most American stock cars may superficially resemble standard American family sedans, but are in fact purpose-built racing machines built to a strict set of regulations governing the car design ensuring that the chassis, suspension, engine, etc. are architecturally identical on all vehicles. For example, NASCAR Sprint cup series now requires fuel injection.
The closest European equivalent to stock car racing is probably touring car racing. In the UK and New Zealand there is a racing formula called stock cars but the cars are markedly different from any road car one might see.
In Australia there was a formula that was quite similar to NASCAR called AUSCAR, but it has now closed down, and a form of touring cars has taken its place (this is known locally as "V8 supercars", with the Bathurst 1000 and Clipsal 500 featuring prominently).
Racecar-Euro Series began in 2009 and was sanctioned by NASCAR as a touring series in 2012, currently operating as the NASCAR Whelen Euro Series.
Classes.
There are several classes of stock car racing, each with slightly different rules, but the key intention of cars that look like production cars, but with near-identical specifications underneath, remains true.
Street Stock / Pure Stock.
'True' stock car racing, which consists of only street vehicles that can be bought by general public, is sometimes now called Street Stock, Pure Stock, Hobby Stock, Showroom Stock, or U-Car racing. In 1972, SCCA started its first showroom stock racing series, with a price ceiling on the cars of $3,000. Some modern showroom stock racing allows safety modifications done on showroom stock cars.
Super Stock.
Super Stock classes are similar to street stock, but allow for more modifications to the engine. Power output is usually in the range of 500–550 horsepower (373–410 kilowatts). Tire width is usually limited to 8 in.
Some entry level classes are called Street Stock, and are similar to what is often called Banger Racing in England.
Late Model.
Late Models are usually the highest class of stock cars in local racing. Rules for construction of a Late Model race car vary from region to region and even race track to race track. The most common variations (on paved tracks) include Super Late Models (SLM), Late Model Stock Car (LMSC), and Limited Late Models (LLM). A Late Model may be a custom built machine, or a heavily modified street car. Individual sanctioning bodies (like NASCAR, ACT, PASS, UARA, CRA, etc.) maintain their own Late Model rule books, and even individual racetracks can maintain their own rule books, meaning a Late Model that is legal in one series or at one track may not be legal at another without modifications. The national touring series, the NASCAR Late Model Sportsman Division, originated from local late model races in the east coast of the U.S. This division was later called the Busch Series, the Nationwide Series and the Xfinity Series as its title sponsor changed.
Early years.
In the 1920s, moonshine runners during the prohibition era would often have to outrun the authorities. To do so, they had to upgrade their vehicles and eventually started getting together with fellow runners and making runs together. They would challenge one another and eventually progressed to organized events in the early 1930s. The main problem racing faced was the lack of a unified set of rules among the different tracks. The racers could not race at different tracks because it was not legal for them to race there. When Bill France saw this problem, he set up a meeting at the Streamline Hotel in order to form an organization that would unify the rules.
When NASCAR was first formed by Bill France, Sr. in 1948 to regulate stock car racing in the U.S., there was a requirement that any car entered be made entirely of parts available to the general public through automobile dealers. Additionally, the cars had to be models that had sold more than 500 units to the public. This is referred to as "homologation". In NASCAR's early years, the cars were so "stock" that it was commonplace for the drivers to drive themselves to the competitions in the car that they were going to run in the race. While automobile engine technology had remained fairly stagnant in World War II, advanced aircraft piston engine development had provided a great deal of available data, and NASCAR was formed just as some of the improved technology was about to become available in production cars. Until the advent of the Trans-Am series in 1967, NASCAR homologation cars were the closest thing that the public could buy that was actually very similar to the cars that were winning the national races.
The 1949 Oldsmobile Rocket V-8 with a displacement of 303 cu.in. is widely recognized as the first postwar modern overhead valve (OHV) engine to become available to the public. The Oldsmobile was an immediate success in 1949 and 1950, and all the automobile manufacturers could not help noticing its higher sales of the Oldsmobile 88 to the buying public. The motto of the day became "Win on Sunday, sell on Monday". However, in spite of the fact that several competing engines were more advanced, the aerodynamic and low-slung Hudson Hornet managed to win in 1951, 1952, and 1953 with a 308 cu.in. (5.0 L) inline 6-cylinder that used an old-style flathead engine, proving there was more to winning than just a more powerful engine.
At the time, it typically took three years for a new design of car body or engine to end up in production and be available for NASCAR racing. Most cars sold to the public did not have a wide variety of engine choices, and the majority of the buying public at the time were not interested in the large displacement special edition engine options that would soon become popular. However, the end of the Korean War in 1953 started an economic boom, and then car buyers immediately began demanding more powerful engines.
Also in 1953, NASCAR recommended that the drivers add roll bars, but did not require them.
In 1955 Chrysler produced the C-300 with its 300 HP 331 cu in (5.4 L) OHV engine, which easily won in 1955 and 1956.
In 1957 several notable events happened. The Automobile Manufacturers Association (AMA) banned manufacturers from using race wins in their advertising and giving direct support to race teams, as they felt it led to reckless street racing. This forced manufacturers to become creative in producing race parts to help racers win. Race teams were often caught trying to use factory produced racing parts that were not really available to the public, though many parts passed muster by being labeled as heavy-duty "Police" parts. Car manufacturers wanted to appear compliant with the ban, but they also wanted to win.
NASCAR tracks at the time were mainly dirt tracks with modest barriers, and during the 1957 season a Mercury Monterey crashed into the crowd. This killed many spectators, and resulted in a serious overhaul of the safety rules which in turn prompted the building of larger more modern tracks. Also in 1957, Chevrolet sold enough of their new fuel injected engines to the public in order to make them available for racing (and Ford began selling superchargers as an option), but Bill France immediately banned fuel injection and superchargers from NASCAR before they could race. However, even without official factory support or the use of fuel injection, Buck Baker won in 1957 driving a small-block V-8 Chevrolet Bel-Air.
In 1961 Ford introduced the F1 390 in a low drag Galaxie "Starliner", but 1960 and '61 championships were won by drivers in 409-powered Chevrolet Impalas.
Pontiac introduced their "Super Duty" 421 in Catalinas that made use of many aluminum body parts to save weight, and the Pontiacs easily won in 1962.
Golden Age.
The desire from fans and manufacturers alike for higher performance cars within the restrictions of homologation meant that carmakers began producing limited production "special edition" cars based on high production base models. It also became apparent that manufacturers were willing to produce increasingly larger engines to remain competitive (Ford had developed a 483 they hoped to race). For the 1963 season NASCAR engines were restricted to using a maximum displacement of 7.0 Liters (427 cu.in.) and using only two valves per cylinder.
Also, even with heavy duty special editions sold to the public for homologation purposes, the race car rules were further modified, primarily in the interest of safety. This is because race drivers and their cars during this era were subjected to forces unheard of in street use, and require a far higher level of protection than is normally afforded by truly "stock" automobile bodies.
In 1963 Ford sold enough of their aerodynamic “sport-roof” edition Galaxies to the public so it would qualify as stock, and with the heavy-duty FE block bored and stroked to the new limit of 427, the top 5 finishers were all Ford. Chrysler had bored their 413 to create the “Max Wedge” 426, but it still could not compete with the Fords. GM's headquarters had genuinely tried to adhere to the 1957 ban, but their Chevrolet division had also constantly tried to work around it, because the other manufacturers had openly circumvented the ban. In 1963 GM gave in and openly abandoned compliance, and Chevy was allowed to produce the ZO6 427, but it did not immediately enjoy success.
Then, in 1964 the new Chrysler 426 Hemi engine so dominated the series in a Plymouth Belvedere "Sport Fury", the homologation rules were changed so that 1,000 of any engine and car had to be sold to the public to qualify as a stock part, instead of just 500. This made the 426 Hemi unavailable for the 1965 season.
In 1965 Ford adapted two single-overhead-cams to their FE 427 V8 to allow it to run at a higher RPM (called the Ford 427 Cammer). Ford started to sell "cammers" to the public to homologate it (mostly to dealer-sponsored privateer drag racers), but NASCAR changed the rules to specify that all NASCAR engines must use a single cam-in-block. But even without the Cammer, the Ford FE 427 won in 1965.
In 1966 Chrysler sold enough of the 426 Hemis to make it available again, and they put it in their new Dodge Charger which had a low-drag rear window that was radically sloped. It was called a "fast-back", and because of this David Pearson was the series champion that year with Richard Petty dominating 1967, winning 27 of 48 races (including 10 in a row) in the boxier Plymouth Belvedere.
The 1969 season featured the Dodge Daytona with a radical body shape change. This car exceeded 200 mph (321 km/h) which was a significant improvement over their competitors; 180 mph (289 km/h) was common at the time. Richard Petty could not come to contractual terms with Dodge before the 1969 season, but when he saw the Daytona, he demanded that Plymouth make something similar, but they declined (for the time being). He signed a lucrative deal with Ford, and they made the Torino "Talladega" which had enough aerodynamic body improvements that it gave the Torino a higher top speed with no other changes. NASCAR feared that these increasing speeds significantly surpassed the abilities of the tire technology of the day, and it would undoubtedly increase the number of gruesome wrecks that were occurring. As a result, the 1970 Homologation rules were changed so that one car for
every two U.S. dealers had to be built for sale to the public to qualify, hoping to delay the use of aero-bodies until tires could improve.
For the 1970 season Dodge raced the 1969 model Daytona, but Plymouth managed to build over 1,920 Plymouth Superbirds, which were almost identical to the Daytona. Petty came back to Plymouth in the 200+ mph Superbird, and Bobby Isaac won the season championship in a Daytona. NASCAR restricted "aero-cars" to maximum engine displacement of 305 cu.in. (approx. 5.0L) for 1971. Almost all teams switched to non-aero bodystyles. NASCAR eventually adopted a restrictor plate to limit top speeds for the 7.0L engine as teams switched to small-block 358 cu.in. (5.9L) engines.
Fans, drivers, and manufacturers alike demanded a complete revamping of the rules. NASCAR responded in a way that they hoped would make the cars safer and more equal, so the race series would be more a test of the drivers, rather than a test of car technology.
The era drew to a conclusion in the 1970s. 1972 brought so many rule changes, it has prompted many to consider this year as the start of the modern era of NASCAR racing. In addition, R.J. Reynolds (the tobacco conglomerate) took over as the major sponsor of NASCAR racing (changing the name to the "Winston Cup") and they made a significantly larger financial contribution than previous sponsors. Richard Petty's personal sponsorship with STP also set new, higher standards for financial rewards to driving teams. The sudden infusion of noticeably larger amounts of money changed the entire nature of the sport.
The 1973 oil crisis meant that large displacement special edition homologation cars of all makes were suddenly sitting unsold. Through the balance of the 1970s until 1992, the factory stock sheetmetal over a racing frame meant the cars looked very much like their street version counterparts. It can be said that 1993, with the addition of ground effect wrap-around type spoilers marked the beginning non-stock sheetmetal and from that point forward, stock cars were quickly allowed to differ greatly from anything available to the public. Modern racing "stock" cars are stock in name only, using a body template that is vaguely modeled after currently-available automobiles. The chassis, running gear, and other equipment have almost nothing to do with anything in ordinary automobiles. NASCAR and the auto manufacturers have become aware of this, and for 2013 each brand (Chevy, Dodge, Ford, and Toyota) have redesigned their racing sheetmetal to more resemble the street models of their cars.
Series.
The most prominent championship in stock car racing is the NASCAR Sprint Cup Series, named after its sponsor Sprint Nextel. It is the most popular racing series in the United States, drawing over 6 million spectators in 1997, an average live audience of over 190,000 people for each race.
The most famous event in the series is the Daytona 500, an annual 500 mi race at Daytona Beach, Florida. The series' second-biggest event is arguably The Brickyard 400, an annual 400 mi race held at the Indianapolis Motor Speedway, the legendary home of the Indianapolis 500, an open-wheeled race. NASCAR also operates the Xfinity Series, a stock car junior league, and the Camping World Truck Series, a junior league where pickup trucks are raced. Together the two car-based series (Sprint Cup and Xfinity Series) drew 8 million spectators in 1997, compared to 4 million for both American open-wheel series (CART and IRL), which merged in 2008 under the IRL banner. In 2002, 17 of the 20 US top sporting events in terms of attendance were stock car races. Only football drew more television viewers that year.
Besides NASCAR, there are a number of other national or regional stock-car sanctioning bodies in the United States. There are a few organizations that cater to these local short tracks. The Automobile Racing Club of America (ARCA), American Speed Association (ASA), Champion Racing Association (CRA), International Motor Contest Association (IMCA), United Auto Racing Association UARA, and United Speed Alliance Racing (USAR) all sanction their own forms of stock-car racing, on varying types of track, and with various levels of media coverage. The International Race of Champions (IROC) series used stock cars, but is usually perceived as being outside of the usual stock car racing scene because of its 'All-Star' design.
Internationally, stock car racing has not enjoyed the same success as within the United States. The NASCAR Canadian Tire Series enjoys generally strong car-counts using the base of the sport in Canada (the short-oval region of Southern Ontario). Brazil also has a successful stock car racing series, with starting grids of 40 or more cars, and four brands competing: Chevrolet, Mitsubishi, Volkswagen and Peugeot. Brazilian Stock Car also has two developing series. Despite the name, Brazilian stock car competitions are not held on oval tracks, thus they resemble more Touring car racing than Stock car racing the same can be said about Argentina's popular stock series, called Turismo Carretera.
Unsuccessful efforts have been made in Australia, South Africa, and Japan as well.
New Zealand.
Stockcar racing began in New Zealand during the 1950s, first race was at Aranui Speedway on November 27, 1954. It was brought to New Zealand after New Zealand Speedway riders witnessed the huge crowds that watched the races in Britain earlier that year. As with the UK, Stockcar racing in New Zealand is a very different form of racing than that of the USA. Stockcar racing is a full contact sport in New Zealand: as the rule book states, "contact is not only permitted, it is encouraged". 
Cars are built to an extremely rigid design and feature strong steel guards around almost the entire car. “Stockcars” are divided into three classes: Superstocks, Stockcars, Ministocks (Ministocks predominantly being a non-contact youth class). 
Superstocks are the top class and are typically powered by V8 engines up to 248 cubic inch which can produce over 500 bhp. The majority of races are of an individual nature however, unique to New Zealand stockcar racing is the team racing format. Typically teams racing consists of two teams of four cars each that work together to win the race. Teams normally protect their “runners” while attempting to eliminate the opposing team, the races can be decided by a points format or first across the finish line.
The class most resembling the North American form of stockcar racing are known as Saloon cars. Super Saloons are similar to dirt late models with the main differences being the bodies closer resemble production cars,use iron engines up to 434 cubic inch with no rear offset and run much larger sprintcar tyres on the rear.
Australia.
Stock car racing in the NASCAR mould (AUSCAR) had a following in Australia during the mid-late 1980s and through the 1990s, but with the advent of the V8 Supercars which took up the bulk of the competitors, sponsorship dollars on offer as well as major television time, the Australian Superspeedway series shut down after 2001.
The majority of the NASCAR and AUSCAR racing in Australia took place at the 1.801 km (1.119 mi), high-banked (24°) Calder Park Thunderdome in Melbourne. The Thunderdome, which was opened in 1987 and was built by multi-millionaire tyre retailer Bob Jane at a cost of A$54 million, was modelled on a scaled down version of the famous Charlotte Motor Speedway. Other tracks used included the ½ mile (805 metre) Speedway Super Bowl at the Adelaide International Raceway (also owned by Jane, this was the only paved oval track in Australia other than the Thunderdome, though with only 7° banking in the turns it was more of a traditional flat track), as well as road courses such as the Surfers Paradise Street Circuit (where the cars ran as a support category to the Gold Coast IndyCar Grand Prix), Oran Park in Sydney, and the famous Mount Panorama Circuit.
United Kingdom.
Stock, in the sense of cars appearing to be similar to conventional road vehicles, is represented in the UK (and Europe) by touring cars.
The term 'stock cars' in the UK refers to a specialised form of racing that bears little resemblance to any road car.
Stock car racing was brought to Britain in 1954. Taking place on existing greyhound or speedway tracks, the cars were mostly 'stock' cars from the 1930s with locked rear axle differentials and added armour. After the first couple of years 'specials' began to appear eventually making the 'stock' car name something of a misnomer. Since the early days of stock car racing in Britain the sport has developed into many different classes, from the destructive 'Banger' categories to the very sophisticated National Hot Rods. However, the name 'stock car' is usually reserved for that racing class which traces its roots back to these early days in 1950s, BriSCA F1 Stock Cars, which were previously known as "The Seniors" or "Senior Stock Cars". Despite the physical demands of this full-contact sport, many competitors have been racing for 20 and even 30 years. For the first 10 years of the sport, stock cars were either adapted from road cars, or bore the recognizable bodywork of road cars. By the 1970s, chassis and bodywork had evolved into very specialized forms.
The modern BriSCA Formula 1 Stock Cars are a highly sophisticated purpose built race car with race-tuned V-8 engines developing 650 bhp, quick change axles and gearboxes and biased and staggered chassis and braking set up for constant left turning. However large bumpers were mandatory with contact very much encouraged to remove opponents. The sport can be seen at venues throughout Britain and Mainland Europe. A downsized version of the BriSCA Formula 1 Stock Cars, the smaller BriSCA Formula 2 Stock Cars, previously known as "The Juniors" or "Junior Stock Cars", are also very popular. these cars are powered by the 2 litre Ford 'Pinto' engine. There are also many other formulas running on the oval tracks throughout a season that starts around March/Easter and continues to October/November.
In the 2008 World Final, held at Ipswich, Andy Smith raced to victory becoming the 2008 BriSCA F1 Stock Car World Champion for the second time in his career, taking the crown from brother Stuart Smith Jnr. 2009 also saw Andy Smith win again this time at Kings Lynns Norfolk Arena. 2010 saw Andy Smith win for a 3rd consecutive time at Coventry, the same venue as his 1st win in 2006. The 2011 World Championship took place at Northampton on September 10 with 2 Paul Harrison the winner of the Gold Roof. The 2012 World Championship held at Skegness was won by 217 Lee Fairhurst. The 2013 World Championship will be held at King's Lynn on Saturday 21 September.
In 2008, Ian Thompson Jr. became the first driver from Northern Ireland to win the Brisca F2 Stock Car World title since 1972 when he took the honours at Bristol in 2008. However, it was in controversial circumstances after first across the line Gordon Moodie (Thomson Jr's brother-in-law) was disqualified from the race after being found with carburetor irregularities at post race scrutineering. This irregularity has since been proven to be a manufacturing fault with the control of the driver but the governing body have refused to reinstate Gordon Moodie as the winner in the record books. In 2009 the World Championship winner was Micky Brennan and in 2010 the World Championship winner was John Fortune. The 2011 World Championship Final took place at Kings Lynns Norfolk Arena on Saturday 17 September with 871 Mark Simpson winner of the Gold Roof. In 2012, the World Championship was won again by 968 Micky Brennan this time held at Barford. The 2013 World Championship weekend will be held over 2 days of racing on 14/15 September at Smeatharpe near Honiton in Devon.
Another open wheeled stock car formula that races in the UK are Spedeworth Superstox. Licensed by Spedeworth, as opposed to BriSCA, Superstox are similar to Formula Two Stock Cars with the main visual difference being a smaller wing on the roof. These cars are also powered by the 2 litre Ford 'Pinto' engine. The 2010 World Championship Final held at Ipswich was won by Colin Aylward. The 2011 World Championship Final was held at Londons Wimbledon Stadium on Sunday 23 October and won by 151 Nick Smith. The 2012 World Championship was again held at Ipswich and won by Scot 177 Stuart Gilchrist. The 2013 World Championship will be held at Lochgelly in Fife, Scotland, with the date tbc.
Another form of UK stock car racing is Saloon Stock Cars, regulated by the Saloon Stock Car Association. This formula is based on heavily armoured Ford Sierra, Ford Mondeo, Vauxhall Vectra cars purposely reconstructed for this full contact class. The 2011 World Championship was held at Skegness in August with 677 Eddie Darby the winner of the Gold Roof for the next 12 months. The 2012 World Championship Final was held at Smeatharpe Raceway near Honiton in Devon in August 2012 and again won by 677 Eddie Darby. Other similar Stock Car classes are the 2 Litre Stock Cars licensed by Spedeworth and the 1300 Stock Cars licensed by several different promotors each to slightly differing rules although steps are currently being taken to standardise the specifications in order to make it a national class. The 2012 World Championship was won by 79 Barry Radcliffe at Ipswich. The 2013 World Championship will be held at King's Lynn on Saturday 17 August.
The Stock Car Speed Association "ASCAR" or "Days of Thunder" was a "NASCAR" style racing series based at Rockingham, United Kingdom, though the series did also race at the Lausitzring in Germany as well.
Career paths.
NASCAR stars take various paths to the highest stock car divisions. Some start racing on dirt surfaces but all end up racing on asphalt surfaces as they progress in their career. They frequently start in karting or in cars that are completely stock except for safety modifications. They generally advance through intermediate or advanced local-level divisions. The highest local division, asphalt late model racing, is generally considered a requirement to advance to the next step, regional and national touring series.
Dirt track drivers follow the same general path. Their highest divisions are less well-known national touring late model series such as the World of Outlaws Late Model Series and regional touring series.
Crossover drivers.
Some drivers have entered stock car racing after starting on a very different career path. The most famous might well be Mario Andretti, who is the only driver ever to win the Indianapolis 500 (1969), NASCAR's Daytona 500 (1967), and the Formula One World Championship (1978). Juan Pablo Montoya is the only other driver with wins in all 3 series, with an Indy 500 win (2000), 7 Formula One wins and 2 Sprint Cup wins (2007 and 2010). A.J. Foyt, with four Indianapolis 500 wins, seven IndyCar championships, and a victory in the 24 Hours of Le Mans on his resume, also won the Daytona 500 in 1972. Johnny Rutherford, a three-time winner at Indy, has the rare distinction of winning his first NASCAR start, a qualifying race for the 1963 Daytona 500. Dan Gurney, a leading 1960s Formula One driver and later one of the most successful constructors of Indy cars (as well as being Foyt's co-driver at Le Mans), excelled in NASCAR's road-course events, winning at Riverside five times between 1963 and 1968. A notable crossover oddity is the one-race NASCAR career of the colorful Formula One and sports car driver Innes Ireland: after retiring at the end of the 1966 season, he was invited by NASCAR czar Bill France to compete at Daytona, where he was running in the top ten when his engine blew on the 126th of 200 laps.
Montoya initially surprised the auto racing community by leaving F1, but he was quickly followed by other drivers. Open wheel stars like Sam Hornish Jr., Patrick Carpentier, Dario Franchitti, Jacques Villeneuve and A.J. Allmendinger all made the move to the Sprint Cup series, with varying degrees of success. Two-time Australian V8 Supercar Champion Marcos Ambrose has competed the Sprint Cup Series events since 2007.
Other drivers compete often in stock car racing but are well known for their success elsewhere. Ron Fellows and Boris Said are champion road racers and are often brought in by teams solely to compete in NASCAR's road course events. Robby Gordon is one of NASCAR's few remaining owner-drivers, but he is most famous for his numerous off-road championships and his 3 Baja 1000 wins.
Tracks.
Stock car races take place predominantly on oval tracks of 3 or 4 turns, with all turns to the left. Oval tracks are classified as "short track" (less than 1 mile), "intermediate" or "speedway" (1 to 2 miles) or "superspeedway" (over 2 miles). "Road courses" are any tracks having both left and right turns. Depending on the track, typical race speeds can vary from 90 mph at Martinsville to over 200 mph at Talladega. In 1987 Bill Elliott's 212.809 mph qualifying time at Talladega brought about a change at superspeedways (Daytona and Talladega). Such high speeds and Bobby Allison's car going airborne into the catch-fence and injuring fans forced NASCAR to implement power-reducing measures, one of which was the mandated implement of below carburetor restrictor plates. This later became known as restrictor plate racing.
Oval circuits differ from the rough terrain and sharp turns of Rally, and the complicated twists and turns of Formula One tracks that put up to 5 or 6 "g" of horizontal stress on the driver's body. Stock cars are much heavier than Formula One cars, and as a result they are generally slower. Additionally, they cannot produce the g-forces of an open wheel car. A stock car's weak handling with high power output places more emphasis on car control.
Tactics.
In contrast with most forms of racing, minor car-to-car contact is generally accepted in stock car racing. This may happen in the form of forcing another vehicle out of the way, or pushing a competing vehicle forward for mutual benefit. Stock cars are generally built to be tolerant of superficial damage to bodywork, where open wheel designs can experience severe issues with even slight spoiler damage.
External links.
United States
Argentina
Brazil
Canada
Mexico
South Africa
New Zealand
United Kingdom

</doc>
<doc id="28351" url="http://en.wikipedia.org/wiki?curid=28351" title="Secondary conversion">
Secondary conversion

In the sociology of religion, secondary conversion is the religious conversion of an individual that results from a relationship with another convert, rather than from any particular aspect of the new religion. For example, someone might join a religious group primarily because their spouse or partner has done so; such a person would be a secondary convert. Secondary converts are people who join a religion only because of a relationship with the other convert.
Secondary conversion can greatly expand a movement's influence, particularly after a conquest, such as the Muslim Moorish conquest of Spain and Catholic Spain's conquests in Latin America.

</doc>
