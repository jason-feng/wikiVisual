<doc id="32917" url="http://en.wikipedia.org/wiki?curid=32917" title="Walt Disney">
Walt Disney

Walter Elias "Walt" Disney (; December 5, 1901 – December 15, 1966) was an American entrepreneur, cartoonist, animator, voice actor, and film producer. As a prominent figure within the American animation industry and throughout the world, he is regarded as a cultural icon, known for his influence and contributions to entertainment during the 20th century. As a Hollywood business mogul, he and his brother Roy O. Disney co-founded The Walt Disney Company.
As an animator and entrepreneur, Disney was particularly noted as a filmmaker and a popular showman, as well as an innovator in animation and theme park design. He and his staff created numerous famous fictional characters including Mickey Mouse, Donald Duck, and Goofy. Disney himself was the original voice for Mickey. During his lifetime, he received four honorary Academy Awards and won 22 Academy Awards from a total of 59 nominations, including a record of four in one year, giving him more awards and nominations than any other individual in history. Disney also won seven Emmy Awards and gave his name to the Disneyland and Walt Disney World Resort theme parks in the U.S., as well as the international resorts Tokyo Disney Resort, Disneyland Paris, and Hong Kong Disneyland.
Disney died from lung cancer on December 15, 1966, in Burbank, California. He left behind a vast legacy, including numerous animated shorts and feature films produced during his lifetime; the company, parks, and animation studio that bear his name; and the California Institute of the Arts (CalArts).
Early life: 1901–20.
Childhood.
Disney was born on December 5, 1901, at 2156 North Tripp Avenue in Chicago's Hermosa community area to Elias Charles Disney, who was Irish-Canadian, and Flora Call Disney, who was of German and English descent. His great-grandfather, Arundel Elias Disney, had emigrated from Gowran, County Kilkenny, Ireland where he was born in 1801. Arundel Disney was a descendant of Robert d'Isigny, a Frenchman who had travelled to England with William the Conqueror in 1066. With the d'Isigny name anglicized as "Disney", the family settled in a village now known as Norton Disney, south of the city of Lincoln, in the county of Lincolnshire.
In 1878 Disney's father, Elias Charles Disney, had moved from Huron County, Ontario, Canada to the United States, at first seeking gold in California before finally settling down to farm with his parents near Ellis, Kansas, until 1884. Elias married Flora Call on January 1, 1888, in Acron, Florida, just 40 miles north of where Walt Disney World would ultimately be developed. The family moved to Chicago, Illinois in 1890, hometown of Elias' brother Robert, who helped Elias financially for most of Walt's early life. In 1906, when Walt was four, Elias and his family moved to a farm in Marceline, Missouri, where his elder brother Roy had recently purchased farmland. In Marceline, Disney developed his love for drawing with one of the family's neighbors, a retired doctor named "Doc" Sherwood, paying him to draw pictures of Sherwood's horse, Rupert. Elias was a subscriber to the "Appeal to Reason" newspaper and Walt copied the front-page cartoons of Ryan Walker. His interest in trains originated in Marceline as well. There was a railway called Atchison, Topeka and Santa Fe Railway which passes near the neighbourhood. Upon hearing the train whistle, Walt and Roy would run to a clearing of high ground. Once recognised by their uncle, Mike Martin, who conducted the train, he would wave and produce a long whistle, followed by two short ones. That functioned as a signal to the brothers.
Walt attended the new Park School of Marceline in fall, 1909. He and his younger sister Ruth started school together. Before that he had no formal schooling. The Disneys remained in Marceline for four years, until having to sell their farm on November 28, 1910. At that time, two of Walt's elder brothers, Herbert and Ray, had been fed up with the constant work and little or no spending money, and ran away in fall 1906. Afterwards the family moved to Kansas City in 1911, where Walt and Ruth attended the Benton Grammar School at 3004 Benton Boulevard, close to his new home. Disney had completed the second grade at Marceline but had to repeat the grade at Kansas City. At school he met Walter Pfeiffer, who came from a family of theatre aficionados and introduced Walt to the world of vaudeville and motion pictures. Before long, Walt was spending more time at the Pfeiffers' than at home, as well as attending Saturday courses at the Kansas City Art Institute,
On July 1, 1911, Elias purchased a newspaper delivery route for "The Kansas City Star". It extended from the Twenty-seventh Street to the Thirty-first Street, and from Prospect Avenue to Indiana Avenue. Roy and Walt were put to work delivering the newspapers. The Disneys delivered the morning newspaper "Kansas City Times" to about 700 customers and the evening and Sunday "Star" to more than 600. The number of customers they had increased with time. Walt woke up at 4:30 AM and worked delivering newspapers until the school bell rang. He resumed working the paper trail at 4PM and continued to supper time. He found the work exhausting and often received poor grades from dozing off in class. He continued his paper routine for more than six years.
Teenage years.
In 1917 Elias acquired shares in the O-Zell jelly factory in Chicago and moved his family back to the city. In the fall Disney began his freshman year at McKinley High School and took night courses at the Chicago Academy of Fine Arts under the tutelage of artist and educator Louis Grell (1887–1960). He became the cartoonist for the school newspaper, drawing patriotic topics on World War I. With a hope to join the army, Disney dropped out of high school at the age of sixteen, but was rejected for being under-age. Afterwards, Disney and a friend joined the Red Cross. He was soon sent to France for a year, where he drove an ambulance, but only after the armistice was signed on November 11, 1918.
Hoping to find work outside the Chicago O-Zell factory, Walt moved back to Kansas City in 1919 to begin his artistic career. He considered becoming an actor, but decided to draw political caricatures or comic strips for a newspaper. When nobody wanted to hire him as either an artist or as an ambulance driver, his brother Roy, then working in a local bank, got Walt a temporary job through a bank colleague at the Pesmen-Rubin Art Studio, where he created advertisements for newspapers, magazines, and movie theaters. At Pesmen-Rubin he met cartoonist Ubbe Iwerks and, when their time at the studio expired, they decided to start their own commercial company together.
Start of animation career: 1920–37.
In January 1920, Disney and Iwerks formed a short-lived company called "Iwerks-Disney Commercial Artists". However, following a rough start, Disney left temporarily to earn money at the Kansas City Film Ad Company. He was soon joined by Iwerks, who was not able to run their business alone. While working for the company, where he made commercials based on cutout animation, Disney became interested in animation and decided to become an animator. The owner of the Ad Company, A.V. Cauger, allowed him to borrow a camera from work to experiment with at home. After reading the Edwin G. Lutz book "Animated Cartoons: How They Are Made, Their Origin and Development", Disney considered cel animation to be much more promising than the cutout animation he was doing for Cauger. He eventually decided to open his own animation business and recruited a fellow co-worker at the Ad Company, Fred Harman, as his first employee. Disney and Harman then started creating cartoons called "Laugh-O-Grams". Disney studied "Aesop's Fables" as a model. The first six of the new Laugh-O-Grams were modernized fairy tales. They screened their cartoons at a local theater owned by Frank Newman, who was one of the most popular "showmen" in Kansas City.
Laugh-O-Gram Studio.
Presented as "Newman Laugh-O-Grams", Disney's cartoons became widely popular in the Kansas City area. Through their success, he was able to acquire his own studio, also called Laugh-O-Gram, for which he hired a number of additional animators, including Fred Harman's brother Hugh Harman, Rudolf Ising, and his close friend Ubbe Iwerks. It was opened on May 18, 1922. However, studio profits were insufficient to cover the high salaries paid to employees. Unable to successfully manage money, Disney's studio became loaded with debt and wound up bankrupt, whereupon he decided to set up a studio in the movie industry's capital city, Hollywood, California.
Career in Hollywood and marriage.
Two months after their arrival in October 1923, Disney and his brother Roy pooled their money and set up a cartoon studio in Hollywood. Virginia Davis, the live-action star of "Alice's Wonderland", and her family relocated from Kansas City to Hollywood at Disney's request, as did Iwerks and his family. This was the beginning of the Disney Brothers' Studio, located on Hyperion Avenue in the Silver Lake district, where it remained until 1939. In 1925 Disney hired a young woman named Lillian Bounds to ink and paint celluloid. After a brief courtship, the pair married that same year, on July 25, 1925.
Alice Comedies.
Disney and Roy needed to find a distributor for Walt's new Alice Comedies, which he had started making while in Kansas City but never got to distribute. Disney sent an unfinished print to New York distributor Margaret Winkler, who promptly wrote back to him that she was keen on a distribution deal for more live-action/animated shorts based upon "Alice's Wonderland". Walt did the animation himself and directed the live-action scenes, while Roy took on the unfamiliar role of cameraman, photographing both the animation and the live action. The first of the new Alice Comedies, Alice’s Day at Sea, was delivered on December 26, 1923, and the Disney Brothers studio received their first earnings of $1,500. The new series, "Alice Comedies", proved reasonably successful. It featured Virginia Davis, with other child actresses assuming the role later. By the time the series ended in 1927, it had lost popularity. Historian J.B. Kaufman said its focus was more on the animated characters rather than the live-action Alice, while its idea had exhausted itself.
Oswald the Lucky Rabbit.
In 1926 producer Charles Mintz ordered a new, all-animated series to be put into production for distribution through Universal Pictures, and signed Disney's studio to produce it. "Oswald the Lucky Rabbit" was an almost instant success, and was praised as "exceptionally clever" and showing "fine cartoon ingenuity". Its main character, Oswald—created and drawn by Iwerks—became a popular figure, with high merchandise performance.
In February 1928 Disney went to New York to negotiate a higher fee for producing the Oswald series. He was shocked when Mintz proposed "reducing" Disney's compensation. Furthermore, most of Disney's animators—including Harman, Ising, Maxwell, and Freleng—were under contract to Mintz, and Universal owned the Oswald trademark; Mintz threatened to start his own studio and produce the series himself if Disney refused to accept the reductions. Disney declined Mintz's ultimatum, lost most of his animation staff—except Iwerks, who refused to switch allegiances—and found himself on his own again.
In 2006 the Walt Disney Company finally acquired Oswald the Lucky Rabbit when its subsidiary ESPN purchased rights to the character, along with other properties, from NBC Universal, in return for relinquishing the services of longtime ABC sports commentator Al Michaels. “Oswald is definitely worth more than a fourth-round draft choice," quipped Michaels. "I'm going to be a trivia answer someday.”
Mickey Mouse.
After losing the rights to Oswald, Disney felt the need to develop a new character to replace him, which was based on a mouse he had adopted as a pet while working in his Laugh-O-Gram studio in Kansas City. Iwerks reworked the sketches made by Disney to make the character easier to animate, although Mickey's voice and personality were provided by Disney himself until 1947. In the words of one Disney employee, "Ub designed Mickey's physical appearance, but Walt gave him his soul." Besides Oswald and Mickey, a similar mouse-character is seen in the "Alice Comedies", which featured "Ike the Mouse". Moreover, the first Flip the Frog cartoon called Fiddlesticks showed a Mickey Mouse look-alike playing fiddle. The initial films were animated by Iwerks, with his name prominently featured on the title cards. Originally named "Mortimer", the mouse was later renamed "Mickey" by Lillian Disney, who thought that the name Mortimer did not sound appealing. Mortimer eventually became the name of Mickey's rival for Minnie—taller than his renowned adversary and speaking with a Brooklyn accent.
The first animated short to feature Mickey, "Plane Crazy", was a silent film like all of Disney's previous works. After failing to find a distributor for the short and its follow-up, "The Gallopin' Gaucho", Disney created a Mickey cartoon with sound called "Steamboat Willie". A businessperson named Pat Powers provided Disney with both distribution and Cinephone, a sound-synchronization process. "Steamboat Willie" became an instant success. "Plane Crazy", "The Galloping Gaucho", and all subsequent Mickey cartoons were released with soundtracks. After the release of "Steamboat Willie", Disney successfully used sound in all of his subsequent cartoons, and Cinephone also became the new distributor for Disney's early sound cartoons. Mickey soon eclipsed Felix the Cat as the world's most popular cartoon character. Mickey's popularity grew rapidly in the early 1930s.
"Silly Symphonies".
Following in the footsteps of "Mickey Mouse series", a series of musical shorts titled, "Silly Symphonies", were released in 1929. The first, "The Skeleton Dance", was entirely drawn and animated by Iwerks, who was also responsible for drawing the majority of cartoons released by Disney in 1928 and 1929. Although both series were successful, the Disney studio thought it was not receiving its rightful share of profits from Pat Powers. In 1930 Disney signed a new distribution deal with Columbia Pictures. The original basis of the cartoons was their musical novelty, with the first Silly Symphony cartoons featuring scores by Carl Stalling.
By 1932, although Mickey Mouse had become a relatively popular cinema character, "Silly Symphonies" was not as successful. The same year also saw competition increase as Max Fleischer's flapper cartoon character, Betty Boop, gained popularity among theater audiences. Fleischer, considered Disney's main rival in the 1930s, was also the father of Richard Fleischer, whom Disney would later hire to direct his 1954 film "20,000 Leagues Under the Sea". Meanwhile, on April 13, 1931, Columbia Pictures dropped the distribution of Disney cartoons to be replaced by United Artists. In late 1932, Herbert Kalmus, who had just completed work on the first three-strip technicolor camera, approached Walt and convinced him to reshoot the black and white "Flowers and Trees" in three-strip Technicolor. "Flowers and Trees" would go on to be a phenomenal success and would also win the first Academy Award for Best Short Subject: Cartoons in 1932. After the release of "Flowers and Trees", all subsequent "Silly Symphony" cartoons were in color. Disney was also able to negotiate a two-year deal with Technicolor, giving him the sole right to use their three-strip process, a period eventually extended to five years. Through "Silly Symphonies", Disney also created his most successful cartoon short of all time, "The Three Little Pigs" (1933). The cartoon ran in theaters for many months, featuring the hit song that became the anthem of the Great Depression, "Who's Afraid of the Big Bad Wolf". One reason for why "Three Little Pigs" was so successful was the strength of its story, in that Disney had realized the success of animated films depended upon telling emotionally gripping stories that would grab the audience and not let go. This realization led to another of his innovations: a "story department," separate from the animators, with storyboard artists who would be dedicated to working on a "story development" phase of the production pipeline.
First Academy Award and subsequent spin-offs.
On November 18, 1932, Disney received a special Academy Award for the creation of "Mickey Mouse". The series, which switched to color in 1935, soon launched spin-offs for supporting characters such as Donald Duck, Goofy, and Pluto. Of all Mickey's partners, Donald Duck, who first teamed up with Mickey in the 1934 cartoon, "Orphan's Benefit", was arguably the most popular, going on to become Disney's second most successful cartoon character of all time.
Fatherhood.
The Disneys' first attempt at pregnancy ended in miscarriage. Lillian became pregnant again and gave birth to a daughter, Diane Marie Disney, on December 18, 1933. Later, the Disneys adopted Sharon Mae Disney (December 31, 1936 – February 16, 1993).
Diane married Ron Miller at the age of 20 and is known as Diane Disney Miller. The Millers established a winery called Silverado Vineyards in California. Diane and Ron Miller had seven children: Christopher, Joanna, Tamara, Jennifer, Walter, Ronald and Patrick. Years later, Diane went on to become the cofounder of The Walt Disney Family Museum, with the aid of her children. Diane died November 19, 2013, of complications from a fall at home.
Sharon Mae Disney was born December 31, 1936, in Los Angeles, California and was later adopted by the Disneys due to Lillian's several birth complications. Sharon married Robert Brown on May 10, 1959, with whom she had one child. They remained married until his death in 1967. Sharon married William Lund in 1969 and had two children with him, but six years later they divorced. Sharon was a philanthropist and had contributed to charities such as the Marianne Frostig Center of Educational Therapy and the Curtis School foundation. In 1993, Sharon died at the age of 56. After Sharon's death, her estate donated $11 million to the California Institute of the Arts (CalArts), where she was a member of the board of trustees for almost two decades. Sharon's donation was commemorated by renaming the School of Dance the Sharon D. Lund School of Dance.
Golden age of animation: 1937–41.
"Disney's Folly": "Snow White and the Seven Dwarfs".
Following the creation of two cartoon series, in 1934 Disney began planning a full-length feature. When the film industry learned of Disney's plans to produce an "animated" feature-length version of "Snow White", they were certain that the endeavor would destroy the Disney Studio and dubbed the project "Disney's Folly". Both Lillian and Roy tried to talk Disney out of the project, but he continued plans for the feature, employing Chouinard Art Institute professor Don Graham to start a training operation for the studio staff. Disney then used the "Silly Symphonies" as a platform for experiments in realistic human animation, distinctive character animation, special effects, and the use of specialized processes and apparatus such as the multiplane camera – a new technique first used by Disney in the 1937 "Silly Symphonies" short "The Old Mill".
All of this development and training was used to increase quality at the studio and to ensure that the feature film would match Disney's quality expectations. Entitled "Snow White and the Seven Dwarfs", the feature went into full production in 1934 and continued until mid-1937, when the studio ran out of money. To obtain the funding to complete "Snow White", Disney had to show a rough cut of the motion picture to loan officers. The film premiered at the Carthay Circle Theater on December 21, 1937 and was praised by the audience. "Snow White", the first animated feature in America made in Technicolor, was released in February 1938 under a new distribution deal with RKO Radio Pictures. RKO had been the distributor for Disney cartoons in 1936, after it closed down the Van Beuren Studios in exchange for distribution. The film became the most successful motion picture of 1938 and earned over $8 million on its initial release, the equivalent of $ today.
Subsequent successes.
Following the success of "Snow White", for which Disney received one full-size and seven miniature Oscar statuettes, he was able to build a new campus for the Walt Disney Studios in Burbank, which opened for business on December 24, 1939. "Snow White" began an era that would later be known as the 'Golden Age of Animation' for the studio. Feature animation staff, having just completed "Pinocchio", continued work on "Fantasia" and "Bambi" as well as the early production stages of "Alice in Wonderland", "Peter Pan", and "Wind in the Willows". The shorts staff carried on working on the "Mickey Mouse", "Donald Duck", "Goofy", and "Pluto" cartoon series. Animator Fred Moore had redesigned Mickey Mouse in the late 1930s after Donald Duck overtook him in popularity among theater audiences.
"Pinocchio" and "Fantasia" followed "Snow White and the Seven Dwarfs" into the movie theaters in 1940, but both proved financial disappointments. The inexpensive "Dumbo" was then planned as an income generator, but during production most of the animation staff went on strike, permanently straining relations between Disney and his artists.
World War II era: 1941–45.
Shortly after Disney released "Dumbo" in October 1941, the US entered World War II. The U.S. Army and Navy Bureau of Aeronautics contracted most of the Disney studio's facilities where the staff created training and instruction films for the military like "Aircraft Carrier Landing Signals", home-front morale-boosting shorts such as "Der Fuehrer's Face", which won an Academy Award, and the 1943 feature film "Victory Through Air Power". Military films did not generate income, and the feature film "Bambi" underperformed on its release in April 1942. Disney successfully re-issued "Snow White" in 1944, establishing a seven-year re-release tradition for his features. In 1945, "The Three Caballeros" was the last animated feature released by the studio during the war.
In 1941, the U.S. State Department sent Disney and a group of animators to South America as part of its Good Neighbor policy, at the same time guaranteeing financing for the resultant movie, "Saludos Amigos". In addition, Disney was asked by the US Office of the Coordinator of Inter-American Affairs to make an educational film about the Amazon Basin, which resulted in the 1944 animated short, "The Amazon Awakens".
Disney took up the work of making insignia for the soldiers as well. They were used to not only bring humor to military units but also be a way to boost morale. The first insignia was created as early as 1933 for a Naval Reserve Squadron stationed at Floyd Bennett Field in New York. Disney created his own insignia design unit with Hank Porter, at the helm, Roy Williams, Bill Justice, Van Kaufman, Ed Parks, and George Goepper. Together, these men created over 1200 unique insignia throughout the duration of World War II. All of the designs were created free-of-charge. "The insignia meant a lot to the men who were fighting ... I had to do it ... I owed it to them." said Disney.
Post-war period: 1945–1955.
By the late 1940s, the studio had recovered enough to continue production on the full-length features "Alice in Wonderland" and "Peter Pan", both of which had been shelved during the war years. Work also began on "Cinderella", which became Disney's most successful film since "Snow White and the Seven Dwarfs". In 1948 the studio also initiated a series of live-action nature films, titled "True-Life Adventures", with "On Seal Island" the first. Despite its resounding success with feature films, the studio's animation shorts were no longer as popular as they once were, with people paying more attention to Warner Bros. and their animation star Bugs Bunny. By 1942, Leon Schlesinger Productions, which produced the Warner Bros. cartoons, had become the country's most popular animation studio. However, while Bugs Bunny's popularity rose in the 1940s, so did Donald Duck's, a character who would replace Mickey Mouse as Disney's star character by 1949.
Meanwhile, Disney studios created inexpensive package films, containing collections of cartoon shorts, and issued them to theaters during this period. These included "Make Mine Music" (1946), "Melody Time" (1948), "Fun and Fancy Free" (1947) and "The Adventures of Ichabod and Mr. Toad" (1949). The latter had only two sections, the first based on "The Wind in the Willows" by Kenneth Grahame, and the second on "The Legend of Sleepy Hollow" by Washington Irving. During this period, Disney also ventured into full-length dramatic films that mixed live action and animated scenes, including "Song of the South" and "So Dear to My Heart". After the war ended, Mickey's popularity faded again.
During the mid-1950s, Disney produced educational films on the space program in collaboration with NASA rocket designer Wernher von Braun: "Man in Space" and "Man and the Moon" in 1955, and "Mars and Beyond" in 1957. "Man in Space" was nominated for Best Documentary Short Subject – 1956 Academy of Motion Picture Arts and Sciences.
Disney and the Second Red Scare.
Disney was a founding member of the anti-communist group Motion Picture Alliance for the Preservation of American Ideals. In 1947, during the Second Red Scare, Disney testified before the House Un-American Activities Committee (HUAC), where he branded Herbert Sorrell, David Hilberman and William Pomerance, former animators and labor union organizers as Communist agitators. All three men denied the allegations. (Sorrell also testified before the HUAC in 1946, when insufficient evidence was found to link him to the Communist Party.) Disney also accused the Screen Cartoonists Guild of being a Communist front, and charged that the 1941 strike was part of an organized Communist effort to gain influence in Hollywood. On January 12, 1955, Disney was approved from the Federal Bureau of Investigation as an official SAC (special agent in charge). The title was used in-house by the Bureau for a trusted person they could contact for information or further assistance. Memos indicate that he remained a source of information to his death.
Theme parks and beyond: 1955–66.
Carolwood Pacific Railroad.
During 1949, Disney and his family moved to a new home on a large piece of land in the Holmby Hills district of Los Angeles, California. With the help of his friends Ward and Betty Kimball, who already had their own backyard railroad, Disney developed blueprints and immediately set to work on creating a miniature live steam railroad for his backyard. The name of the railroad, Carolwood Pacific Railroad, came from his home's location on Carolwood Drive. The railroad's half-mile long layout included a 46 ft long trestle bridge, loops, overpasses, gradients, an elevated berm, and a 90 ft tunnel underneath his wife's flowerbed. He named the miniature working steam locomotive built by Disney Studios engineer Roger E. Broggie "Lilly Belle" in his wife's honor and had his attorney draw up right-of-way papers giving the railroad a permanent, legal easement through the garden areas, which his wife dutifully signed; however, there is no evidence of the documents ever recorded as a restriction on the property's title.
Planning Disneyland.
On a business trip to Chicago in the late-1940s, Disney drew sketches of his ideas for an amusement park where he envisioned his employees spending time with their children. The idea for a children's theme park came after a visit to Children's Fairyland in Oakland, California. It also said that Disney may have been inspired to create Disneyland in the park Republic of the Children located in Manuel B. Gonnet, La Plata, Argentina, and opened in 1951. This plan was originally intended to be built on a plot located across the street to the south of the studio. These original ideas developed into a concept for a larger enterprise that would become Disneyland. Disney spent five years developing Disneyland and created a new subsidiary company, WED Enterprises, to carry out planning and production of the park. A small group of Disney studio employees joined the Disneyland development project as engineers and planners, and were dubbed Imagineers.
As Disney explained one of his earliest plans to Herbert Ryman, who created the first aerial drawing of Disneyland presented to the Bank of America during fund raising for the project, he said, "Herbie, I just want it to look like nothing else in the world. And it should be surrounded by a train." According to Disney's own account, entertaining his daughters and their friends on the Carolwood Pacific Railroad inspired him to include a railroad in Disneyland.
Disneyland grand opening.
On Sunday, July 17, 1955, Disneyland hosted a live TV preview, among the thousands of people in attendance were Ronald Reagan, Bob Cummings and Art Linkletter, who shared cohosting duties, as well as the mayor of Anaheim. Disney gave the following dedication day speech:
Disney patrolled around the place, introducing one land after another. At Fantasyland, he said, "Fantasyland is dedicated to the young and the young in heart, to those who believe when you wish upon a star, your dreams come true."
Expansion into new areas.
Walt Disney Productions began work on Disneyland, as well as expanding its other entertainment operations. In 1950, "Treasure Island" became the studio's first all-live-action feature, soon followed by "20,000 Leagues Under the Sea" (in CinemaScope, 1954), "Old Yeller" (1957), "The Shaggy Dog" (1959), "Pollyanna" (1960), "Swiss Family Robinson" (1960), "The Absent-Minded Professor" (1961), and "The Parent Trap" (1961). The studio produced its first TV special, "One Hour in Wonderland", in 1950. Disney began hosting a weekly anthology series on ABC entitled "Disneyland", after the park, on which he aired clips of past Disney productions, gave tours of his studio, and familiarized the public with Disneyland as it was being constructed in Anaheim. The show also featured a Davy Crockett miniseries, which started the "Davy Crockett craze" among American youth, during which millions of coonskin caps and other Crockett memorabilia were sold across the country. In 1955, the studio's first daily television show, "Mickey Mouse Club" debuted on ABC. It was a groundbreaking comedy/variety show catered specifically for children. Disney took a strong personal interest in the show and even returned to the animation studio to voice Mickey Mouse in its animated segments during its original 1955–59 production run. The Mickey Mouse Club continued in various incarnations in syndication and on the Disney Channel into the 1990s.
As the studio expanded and diversified into other media, Disney devoted less attention to the animation department, entrusting most of its operations to his key animators, whom he dubbed the Nine Old Men. Although he was spending less time supervising the production of the animated films, he was always present at story meetings. During Disney's lifetime, the animation department created the successful "Lady and the Tramp" (the first animated film in CinemaScope) in 1955, "Sleeping Beauty" (the first animated film in Super Technirama 70mm) in 1959, "One Hundred and One Dalmatians" (the first animated feature film to use Xerox cels) in 1961, and "The Sword in the Stone" in 1963.
Production of short cartoons kept pace until 1956, when Disney shut down the responsible division though special shorts projects continued for the remainder of the studio's duration on an irregular basis. These productions were all distributed by Disney's new subsidiary, Buena Vista Distribution, which had taken over all distribution duties for Disney films from RKO by 1955. Disneyland, one of the world's first theme parks, finally opened on July 17, 1955, and was immediately successful. Visitors from around the world came to visit Disneyland, which contained attractions based on a number of successful Disney characters and films.
After 1955, the "Disneyland" TV show was renamed "Walt Disney Presents". Interestingly, the "Walt Disney Presents" logo featured the closest interpretation of Disney's actual signature in a logo treatment. The current, well-known version of Walt's signature in the company logo is actually based on a secretary's signature. When the show upgraded from black-and-white to color in 1961, it changed its name to "Walt Disney's Wonderful World of Color", at the same time moving from ABC to NBC, and eventually evolving into its current form as "The Wonderful World of Disney". Since then, it has aired on ABC,CBS, NBC, the Hallmark Channel and the Cartoon Network via separate broadcast rights deals. During its run, the Disney series offered some recurring characters, such as the newspaper reporter and sleuth "Gallegher" played by Roger Mobley with a plot based on the writings of Richard Harding Davis.
Disney had already formed his own music publishing division in 1949 and in 1956. Partly inspired by the huge success of the television theme song The Ballad of Davy Crockett, he created a company-owned record production and distribution entity called Disneyland Records.
Early 1960s successes.
By the early 1960s, the Disney empire had become a major success, and Walt Disney Productions had established itself as the world's leading producer of family entertainment. Walt Disney was the Head of Pageantry for the 1960 Winter Olympics. After decades of pursuit, Disney acquired the rights to P. L. Travers' books about a magical nanny. "Mary Poppins", released in 1964, was the most successful Disney film of the 1960s and featured a song score written by Disney favorites, the Sherman Brothers. The same year, Disney debuted a number of exhibits at the 1964 New York World's Fair, including Audio-Animatronic figures, and he made the first human Audio-Animatronic, which was Abraham Lincoln, sixteenth President of the United States, part of the exhibit Great Moments with Mr. Lincoln, based on his admiration for Lincoln ever since he was a little boy, all of which were later integrated into attractions at Disneyland and a new theme park project which was to be established on the East Coast.
Plans for Disney World and EPCOT.
In late 1965, Disney announced plans to develop another theme park to be called Disney World a few miles southwest of Orlando. Disney World was to include "the Magic Kingdom", a larger, more elaborate version of Disneyland. It would also feature a number of golf courses and resort hotels. The heart of Disney World, however, was to be the Experimental Prototype City (or Community) of Tomorrow, known as EPCOT for short.
Mineral King Ski Resort.
During the early to mid-1960s, Walt Disney developed plans for a ski resort in Mineral King, a glacial valley in California's Sierra Nevada mountain range. He brought in experts such as the renowned Olympic ski coach and ski-area designer Willy Schaeffler, who helped plan a visitor village, ski runs and ski lifts among the several bowls surrounding the valley. Plans finally moved into action in the mid-1960s, but Walt died before the actual work started. Disney's death and opposition from conservationists stopped the building of the resort.
Illness and death.
Walt Disney was a chain smoker his entire adult life, although he made sure he was not seen smoking around children.
In 1966, Disney was scheduled to undergo surgery to repair an old neck injury caused by many years of playing polo at the Riviera Club in Hollywood. On November 2, during pre-operative X-rays, doctors at Providence St. Joseph Medical Center, across the street from the Disney Studio, discovered a tumor in his left lung. Five days later a biopsy showed the tumor to be malignant and to have spread throughout the entire left lung. After removing the lung on November 11, the surgeons informed Disney that his life expectancy was six months to two years. After several cobalt therapy sessions, Disney and his wife spent a short time in Palm Springs, California. On November 30, Disney collapsed at his home. He was revived by fire department personnel and rushed to St. Joseph's. Disney's spokesperson said he was there for a "postoperative checkup." On December 15, 1966, ten days after his 65th birthday, at 9:30 a.m., Disney died of acute circulatory collapse, caused by lung cancer.
The final productions in which Disney played an active role were the animated feature "The Jungle Book" and the live-action musical feature "The Happiest Millionaire", both released in 1967, as well as the animated short "Winnie the Pooh and the Blustery Day", released in 1968. Songwriter Robert B. Sherman recalled of the last time he saw Disney:
Hibernation urban legend.
A long-standing urban legend maintains that Disney was cryonically frozen, and that his frozen corpse was stored beneath the Pirates of the Caribbean ride at Disneyland, but Disney's remains were cremated on December 17, 1966, and his ashes interred at the Forest Lawn Memorial Park in Glendale, California. The first known human cryonic freezing was in January 1967, more than a month after Disney's death. According to "at least one Disney publicist", as reported in the French magazine "Ici Paris" in 1969, the source of the rumor was a group of Disney Studio animators with "a bizarre sense of humor" who were playing a final prank on their late boss. His daughter Diane wrote in 1972, "There is absolutely no truth to the rumor that my father, Walt Disney, wished to be frozen. I doubt that my father had ever heard of cryonics."
Legacy.
Continuing Disney Productions.
After Walt Disney's death, Roy Disney returned from retirement to take full control of Walt Disney Productions and WED Enterprises. In October 1971, the families of Walt and Roy met in front of Cinderella Castle at the Magic Kingdom to officially open the Walt Disney World Resort. There he gave a speech about the park's dedication:
During the second phase of the "Walt Disney World" theme park, EPCOT was translated by Disney's successors into EPCOT Center, which opened in 1982. As it currently exists, EPCOT is essentially a living world's fair, different from the functional city that Disney had envisioned. In 1992, Walt Disney Imagineering took the step closer to Disney's original ideas and dedicated Celebration, Florida, a town built by the Walt Disney Company adjacent to Walt Disney World, that hearkens back to the spirit of EPCOT. EPCOT was also originally intended to be devoid of Disney characters which initially limited the appeal of the park to young children. The company later changed this policy and Disney characters can now be found throughout the park, often dressed in costumes reflecting the different cultural origins.
Disney entertainment empire.
Walt Disney's animation/motion picture studios and theme parks have developed into a multi-billion dollar television, motion picture, vacation destination and media corporation that carry his name. Among other assets The Walt Disney Company owns five vacation resorts, eleven theme parks, two water parks, thirty-nine hotels, eight motion picture studios, six record labels, eleven cable television networks, and one terrestrial television network. The company operates through five major business "segments." Its parks segment is by far the world's largest operator of theme parks in terms of guest attendance per year and its motion picture segment is one of the six major film studios in Hollywood. As of 2013, the company had annual revenues of over U.S. $45 billion and employed approximately 175,000 people.:2,26
Disney Animation.
Walt Disney was a pioneer in character animation. He was one of the first people to move animation away from basic cartoons with just "impossible outlandish gags" and crudely drawn characters, and towards elevating the field into an art form with heartwarming stories and characters the audience could connect to on an emotional level. As noted above, this culminated in his creation of a separate story department where storyboard artists would specialize in story development. The personality displayed in the characters of his films as well as the great technological advancements they represented remain influential today. He was considered by many of his colleagues to be a master storyteller and the animation department did not fully recover from his death until the period from 1989 to 1999 which is now known as the Disney Renaissance. The most financially and critically successful films produced during this time include "Who Framed Roger Rabbit" (1988), "The Little Mermaid" (1989), "Beauty and the Beast" (1991), "Aladdin" (1992) and "The Lion King" (1994). In 1995, Walt Disney Pictures distributed Pixar's Toy Story, the first computer animated feature film. Walt Disney's nephew Roy E. Disney claimed that Walt would have loved "Toy Story" and that it was "his kind of movie".
With the rise of computer animated films a stream of financially unsuccessful traditional hand-drawn animated features in the early years of the 2000s (decade) emerged. This led to the company's controversial decision to close the traditional animation department. The two satellite studios in Paris and Orlando were closed, and the main studio in Burbank was converted to a computer animation production facility, firing hundreds of people in the process. In 2004, Disney released what was announced as their final "traditionally animated" feature film, "Home on the Range". However, since the 2006 acquisition of Pixar, and the resulting rise of John Lasseter to chief creative officer at Disney Animation, that position has changed with the largely successful 2009 film "The Princess and the Frog". This marked Disney's return to traditional hand-drawn animation, as the studio hired back staff who had been laid-off in the past. Today, Disney produces both traditional and computer animation.
CalArts.
In his later years, Disney devoted substantial time, money, and effort to the California Institute of the Arts (CalArts). It was formed in 1961 through a merger of the Los Angeles Conservatory of Music and the Chouinard Art Institute. When Disney died, one-fourth of his estate went to CalArts, which helped in building its campus. In his will, Disney paved the way for the creation of several charitable trusts which included one for the California Institute of the Arts and another for the Disney Foundation. He also donated 38 acre of the Golden Oaks ranch in Valencia for construction of the school. CalArts moved onto the Valencia campus in November 1971.
In an early admissions bulletin, Disney explained: "A hundred years ago, Wagner conceived of a perfect and all-embracing art, combining music, drama, painting, and the dance, but in his wildest imagination he had no hint what infinite possibilities were to become commonplace through the invention of recording, radio, cinema and television. There already have been geniuses combining the arts in the mass-communications media, and they have already given us powerful new art forms. The future holds bright promise for those who imaginations are trained to play on the vast orchestra of the art-in-combination. Such supermen will appear most certainly in those environments which provide contact with all the arts, but even those who devote themselves to a single phase of art will benefit from broadened horizons."
Walt Disney Family Museum.
In 2009, The Walt Disney Family Museum opened in the Presidio of San Francisco. Thousands of artifacts from Disney's life and career are on display, including 248 awards that he received. Diane cofounded The Walt Disney Family Museum with the aid of her children. The museum was created to preserve her father's image and reach out to millions of Disney fans worldwide. The museum displays a chronological view of Walt Disney's life through personal artifacts, interactive kiosks and various animations.
Accusations of antisemitism and racism.
Disney was long rumored to be antisemitic during his lifetime, dating principally from 1938, when he welcomed German filmmaker and Nazi propagandist Leni Riefenstahl to Hollywood to promote her film "Olympia". Even after news of Kristallnacht reached America, Disney—unlike other studio heads—did not retract his invitation. In addition, animator Art Babbitt claimed to have seen Disney and his lawyer, Gunther Lessing, attending meetings of the German American Bund, a pro-Nazi organization, during the late 1930s.
Animator and director David Swift, who was Jewish, told a biographer that when he informed Disney that he was leaving to take a job at Columbia Pictures in 1941, Disney responded—in a feigned Yiddish accent—"Okay, Davy boy, off you go to work for those Jews. It's where you belong, with those Jews." Swift returned to Disney Studios in 1945, however, and later said that he "owed everything" to Disney. When he left the studio a second time in the early 1950s, Disney reportedly told him that "there is still a candle burning in the window if you ever want to come back."
Disney biographer Neal Gabler, the first writer to gain unrestricted access to the Disney archives, concluded in 2006 that available evidence did not support the accusations of antisemitism. In a CBS interview Gabler summarized his findings: 
Disney eventually distanced himself from the Motion Picture Alliance in the 1950s. Gabler wrote that three months after Riefenstahl's visit, Disney disavowed it, claiming that he did not know who she was when he issued the invitation. Gabler also questioned Babbitt's story, on grounds that Disney had no time for political meetings and was "very apolitical" during the 1930s.
The Walt Disney Family Museum acknowledges that Disney did have "difficult relationships" with some Jewish individuals, including Babbitt and David Hilberman; and that ethnic stereotypes common to films of the 1930s were included in some early cartoons, such as "Three Little Pigs" (in which the Big Bad Wolf comes to the door dressed as a Jewish peddler) and "The Opry House" (in which Mickey Mouse is dressed and dances as a Hasidic Jew); but both Gabler and the museum point out that he donated regularly to Jewish charities (the Hebrew Orphan Asylum, Yeshiva College, the Jewish Home for the Aged, and the American League for a Free Palestine), and was named "1955 Man of the Year" by the B'nai B'rith chapter in Beverly Hills. Artist and story man Joe Grant noted that "some of the most influential people at the studio were Jewish"—including himself, production manager Harry Tytle, and Herman "Kay" Kamen, the head of marketing, who once joked that Disney's New York office "had more Jews than the Book of Leviticus". Songwriter Robert B. Sherman asserted in his autobiography that he saw no evidence of antisemitism during his seven years of close work with Disney; and according to Gabler, none of Disney's employees—including Babbitt, who disliked Disney intensely—ever accused him of making antisemitic slurs or taunts.
Disney has also been accused of racism, largely because of a number of productions released during the 1930s, '40s, and '50s containing racially insensitive material. Examples include "Mickey's Mellerdrammer", in which Mickey Mouse dresses in blackface; the "black" bird in the short "Who Killed Cock Robin"; Sunflower, the half donkey/half black centaurette with a watermelon in "Fantasia"; the feature film "Song of the South"; the Indians in "Peter Pan"; and the crows in "Dumbo" (although the case has been made that the crows were sympathetic to Dumbo because they knew what it was like to be ostracized).
In spite of this, "Walt Disney was no racist," Gabler wrote. "He never, either publicly or privately, made disparaging remarks about blacks or asserted white superiority. Like most white Americans of his generation, however, he was racially insensitive." For example, during a story meeting on "Snow White and the Seven Dwarfs" he referred to the dwarfs piling on top of each other as a "nigger pile", and while casting "Song of the South" he used the term pickaninny. "Song of the South" was roundly criticized by film critics, the NAACP, and others for its perpetuation of black stereotypes; but Disney later campaigned successfully for an Honorary Academy Award for its star, James Baskett, the first African American so honored. Baskett died shortly afterward, and his widow wrote Disney a heartfelt letter of gratitude for his support. Black animator Floyd Norman, who worked for Disney during the 1950s and '60s, said, "Not once did I observe a hint of the racist behavior that Walt Disney was often accused of after his death. His treatment of people—and by this I mean all people—can only be called exemplary."
Academy Awards.
Walt Disney holds the record for both the most Academy Award nominations (59) and the number of Oscars awarded (22). He also earned four honorary Oscars. His last competitive Academy Award was posthumous.
The awards he won include:
Other honors.
Walt Disney was the inaugural recipient of a star on the Anaheim walk of stars awarded in recognition of his significant contribution to the city of Anaheim and specifically Disneyland, which is now the Disneyland Resort. The star is located at the pedestrian entrance to the Disneyland Resort on Harbor Boulevard. Disney was inducted to the Hollywood Walk of Fame on February 8, 1960 with two stars, one for motion pictures and the other for his television work. Disney was posthumously inducted into the Television Hall of Fame in 1986.
Walt Disney received the Congressional Gold Medal on May 24, 1968 (P.L. 90-316, 82 Stat. 130–131) and the Légion d'Honneur awarded by France in 1935. In 1935, Walt received a special medal from the League of Nations for creation of Mickey Mouse, held to be Mickey Mouse award. He also received the Presidential Medal of Freedom on September 14, 1964. On December 6, 2006, California Governor Arnold Schwarzenegger and First Lady Maria Shriver inducted Walt Disney into the California Hall of Fame located at The California Museum for History, Women, and the Arts.
The National Audubon Society awarded Disney its highest honor, the Audubon Medal, in 1955 for promoting the "appreciation and understanding of nature" through his "True-Life Adventures" nature films.
A minor planet, 4017 Disneya, discovered in 1980 by Soviet astronomer Lyudmila Karachkina, is named after him.
In 1993, HBO began development of a Walt Disney biographical film, directed by Frank Pierson and produced by Lawrence Turman, but the project never materialized and was soon abandoned. However, "Walt – The Man Behind the Myth", a biographical documentary about Disney, was later made.
Actor Tom Hanks played Walt in the film "Saving Mr. Banks" (2013). It was the first instance of an actor portraying Walt Disney in film.
In 2013 the American Computer Museum in Bozeman, Montana posthumously honored Walt Disney with the 2013 George R. Stibitz Computer and Communications Pioneer Award, "For Seminal Contributions to the Development of Humanoid Robotics."
Disney was also awarded honorary degrees from Harvard, Yale, the University of Southern California, and UCLA; France's Legion of Honor and Officer d'Academie decorations; Thailand's Order of the Crown; Brazil’s Order of the Southern Cross; Mexico's Order of the Aztec Eagle; and the Showman of the World Award from the National Association of Theatre Owners.

</doc>
<doc id="32921" url="http://en.wikipedia.org/wiki?curid=32921" title="Watermark">
Watermark

A watermark is an identifying image or pattern in paper that appears as various shades of lightness/darkness when viewed by transmitted light (or when viewed by reflected light, atop a dark background), caused by thickness or density variations in the paper.
Watermarks have been used on postage stamps, currency, and other government documents to discourage counterfeiting. There are two main ways of producing watermarks in paper; the "dandy roll process", and the more complex "cylinder mould process".
Watermarks vary greatly in their visibility; while some are obvious on casual inspection, others require some study to pick out. Various aids have been developed, such as "watermark fluid" that wets the paper without damaging it. Watermarks are often used as security features of banknotes, passports, postage stamps, and other documents to prevent counterfeiting (see security paper).
A watermark is very useful in the examination of paper because it can be used for dating, identifying sizes, mill trademarks and locations, and determining the quality of a sheet of paper.
Encoding an identifying code into digitized music, video, picture, or other file is known as a digital watermark.
Dandy roll process.
A watermark is made by impressing a water-coated metal stamp or "dandy roll" onto the paper during manufacturing. While watermarks were first introduced in Fabriano, Italy, in 1282, the invention of the dandy roll in 1826 by John Marshall revolutionised the watermark process and made it easier for producers to watermark their paper.
The "dandy roll" is a light roller covered by material similar to window screen that is embossed with a pattern. Faint lines are made by "laid wires" that run parallel to the axis of the dandy roll, and the bold lines are made by "chain wires" that run around the circumference to secure the laid wires to the roll from the outside. Because the chain wires are located on the outside of the laid wires, they have a greater influence on the impression in the pulp, hence their bolder appearance than the laid wire lines.
This embossing is transferred to the pulp fibres, compressing and reducing their thickness in that area. Because the patterned portion of the page is thinner, it transmits more light through and therefore has a lighter appearance than the surrounding paper. If these lines are distinct and parallel, and/or there is a watermark, then the paper is termed "laid paper". If the lines appear as a mesh or are indiscernible, and/or there is no watermark, then it is called "wove paper". This method is called "line drawing watermarks."
Cylinder mould process.
Another type of watermark is called the "cylinder mould watermark". A shaded watermark, first used in 1848, incorporates tonal depth and creates a greyscale image. Instead of using a wire covering for the dandy roll, the shaded watermark is created by areas of relief on the roll's own surface. Once dry, the paper may then be rolled again to produce a watermark of even thickness but with varying density. The resulting watermark is generally much clearer and more detailed than those made by the Dandy Roll process, and as such Cylinder Mould Watermark Paper is the preferred type of watermarked paper for banknotes, passports, motor vehicle titles, and other documents where it is an important anti-counterfeiting measure.
Watermarks on postage stamps and stationery.
In philately, the watermark is a key feature of a stamp, and often constitutes the difference between a common and a rare stamp. Collectors who encounter two otherwise identical stamps with different watermarks consider each stamp to be a separate identifiable issue. The "classic" stamp watermark is a small crown or other national symbol, appearing either once on each stamp or a continuous pattern. Watermarks were nearly universal on stamps in the 19th and early 20th centuries, but generally fell out of use and are not commonly used on modern U.S. issues, but some countries continue to use them.
Some types of embossing, such as that used to make the "cross on oval" design on early stamps of Switzerland, resemble a watermark in that the paper is thinner, but can be distinguished by having sharper edges than is usual for a normal watermark. Stamp paper watermarks also show various designs, letters, numbers and pictorial elements.
The process of bringing out the stamp watermark is fairly simple. Sometimes a watermark in stamp paper can be seen just by looking at the unprinted back side of a stamp. More often, the collector must use a few basic items to get a good look at the watermark. For example, watermark fluid may be applied to the back of a stamp to temporarily reveal the watermark.
Even using the simple watermarking method described, it can be difficult to distinguish some watermarks. Watermarks on stamps printed in yellow and orange can be particularly difficult to see. A few mechanical devices are also are used by collectors to detect watermarks on stamps such as the Morley-Bright watermark detector and the more expensive Safe Signoscope. Such devices can be very useful for they can be used without the application of watermark fluid and also allow the collector to look at the watermark for a longer period of time to more easily detect the watermark.

</doc>
<doc id="32923" url="http://en.wikipedia.org/wiki?curid=32923" title="Western canon">
Western canon

The term "Western canon" denotes a body of books and, more broadly, music and art that have been traditionally accepted by Western scholars as the most important and influential in shaping Western culture. As such, it includes the "greatest works of artistic merit". Such a canon is important to the theory of educational perennialism and the development of "high culture". The idea of a Canon has been used to address the question "What is Art?"; according to this approach, a work is art by comparison to the works in the canon, or conversely, any aesthetic law to be valid should not rule out any of the works included in the canon. The concept has become challenged by advocates of multiculturalism and critics who charge that it has been influenced by race, gender, and other biases.
Origins.
The process of listmaking—defining the boundaries of the canon—is endless. The philosopher John Searle has said, "In my experience there never was, in fact, a fixed 'canon'; there was rather a certain set of tentative judgments about what had importance and quality. Such judgments are always subject to revision, and in fact they were constantly being revised."
One of the notable attempts at compiling an authoritative canon in the English-speaking world was the "Great Books of the Western World" program. This program, developed in the middle third of the 20th century, grew out of the curriculum at the University of Chicago. University president Robert Maynard Hutchins and his collaborator Mortimer Adler developed a program that offered reading lists, books, and organizational strategies for reading clubs to the general public.
An earlier attempt, the Harvard Classics (1909), was promulgated by Harvard University president Charles W. Eliot, whose thesis was the same as Carlyle's:
... The greatest university of all is a collection of books.—Thomas Carlyle
Debate.
There has been an ongoing debate, motivated by politics and social agendas, over the nature and status of the canon since at least the 1960s, much of which is rooted in critical theory, feminism, critical race theory, and Marxist attacks against capitalism and classical liberal principles. In the United States, in particular, the canon has been attacked as a compendium of books written mainly by "dead European men", that does not represent the viewpoints of many in contemporary societies around the world. Allan Bloom in his 1987 book "The Closing of the American Mind", has disagreed strongly. Yale University Professor of Humanities Harold Bloom (no relation to Allan) has also argued strongly in favor of the canon, and in general the canon remains as a represented idea in many institutions, though its implications continue to be debated.
Defenders maintain that those who undermine the canon do so out of primarily political interests, and that such criticisms are misguided and/or disingenuous. As John Searle has written:
There is a certain irony in this [i.e., politicized objections to the canon] in that earlier student generations, my own for example, found the critical tradition that runs from Socrates through the "Federalist Papers", through the writings of Mill and Marx, down to the twentieth century, to be liberating from the stuffy conventions of traditional American politics and pieties. Precisely by inculcating a critical attitude, the "canon" served to demythologize the conventional pieties of the American bourgeoisie and provided the student with a perspective from which to critically analyze American culture and institutions. Ironically, the same tradition is now regarded as oppressive. The texts once served an unmasking function; now we are told that it is the texts which must be unmasked.
One of the main objections to a canon of literature is the question of authority—who should have the power to determine what works are worth reading and teaching? Searle's rebuttal suggests that "one obvious difficulty with it [i.e., arguments against hierarchical ranking of books] is that if it were valid, it would argue against any set of required readings whatever; indeed, any list you care to make about anything automatically creates two categories, those that are on the list and those that are not."
Although there is debate among theorists, individuals such as teachers and students would consider the works within the canon to be those which are the most appropriate in exploiting social and historical contexts from selected time periods. Additionally, the works are usually considered a craft and are commonly used as a guide or rule, particularly for senior students, when reading and writing. (1983) supports this stating canons are “an institutional form for exposing people to a range of idealized attitudes.” It is with this notion considered that work may be removed from the canon over time in order to reflect the contextual relevance and thoughts of society.
Works.
Works which are commonly included in the canon include works of fiction such as some epic poems, poetry, music, drama, novels, and other assorted forms of literature from the many diverse Western (and more recently non-Western) cultures. Many non-fiction works are also listed, primarily from the areas of religion, mythology, science, philosophy, psychology, economics, politics, and history.
Works which directly address the canon (both "for" and "against"):
Examples.
Examples of shorter canonical lists of most important works include the following:
University reading lists reflect the Western canon:
More comprehensive collections that include large parts of the Western canon include the following:
Chronological brackets:

</doc>
<doc id="32927" url="http://en.wikipedia.org/wiki?curid=32927" title="World War II">
World War II

World War II (WWII or WW2), also known as the Second World War (after the recent Great War), was a global war that lasted from 1939 to 1945, though related conflicts began earlier. It involved the vast majority of the world's nations—including all of the great powers—eventually forming two opposing military alliances: the Allies and the Axis. It was the most widespread war in history, and directly involved more than 100 million people from over 30 countries. In a state of "total war", the major participants threw their entire economic, industrial, and scientific capabilities behind the war effort, erasing the distinction between civilian and military resources. Marked by mass deaths of civilians, including the Holocaust (during which approximately 11 million people were killed) and the strategic bombing of industrial and population centres (during which approximately one million people were killed, including the use of two nuclear weapons in combat), it resulted in an estimated 50 million to 85 million fatalities. These made World War II the deadliest conflict in human history.
The Empire of Japan aimed to dominate Asia and the Pacific and was already at war with the Republic of China in 1937, but the world war is generally said to have begun on 1 September 1939 with the invasion of Poland by Germany and subsequent declarations of war on Germany by France and the United Kingdom. From late 1939 to early 1941, in a series of campaigns and treaties, Germany conquered or controlled much of continental Europe, and formed the Axis alliance with Italy and Japan. Following the Molotov–Ribbentrop Pact, Germany and the Soviet Union partitioned and annexed territories of their European neighbours, Poland, Finland, Romania and the Baltic states. The United Kingdom and the British Commonwealth were the only Allied forces continuing the fight against the Axis, with campaigns in North Africa and the Horn of Africa as well as the long-running Battle of the Atlantic. In June 1941, the European Axis powers launched an invasion of the Soviet Union, opening the largest land theatre of war in history, which trapped the major part of the Axis' military forces into a war of attrition. In December 1941, Japan attacked the United States and European territories in the Pacific Ocean, and quickly conquered much of the Western Pacific.
The Axis advance halted in 1942 when Japan lost the critical Battle of Midway, near Hawaii, and Germany was defeated in North Africa and then, decisively, at Stalingrad in the Soviet Union. In 1943, with a series of German defeats on the Eastern Front, the Allied invasion of Italy which brought about Italian surrender, and Allied victories in the Pacific, the Axis lost the initiative and undertook strategic retreat on all fronts. In 1944, the Western Allies invaded France, while the Soviet Union regained all of its territorial losses and invaded Germany and its allies. During 1944 and 1945 the Japanese suffered major reverses in mainland Asia in South Central China and Burma, while the Allies crippled the Japanese Navy and captured key Western Pacific islands.
The war in Europe ended with an invasion of Germany by the Western Allies and the Soviet Union culminating in the capture of Berlin by Soviet and Polish troops and the subsequent German unconditional surrender on 8 May 1945. Following the Potsdam Declaration by the Allies on 26 July 1945, the United States dropped atomic bombs on the Japanese cities of Hiroshima and Nagasaki on 6 August and 9 August respectively. With an invasion of the Japanese archipelago imminent, the possibility of additional atomic bombings, and the Soviet Union's declaration of war on Japan and invasion of Manchuria, Japan surrendered on 15 August 1945. Thus ended the war in Asia, and the final destruction of the Axis bloc.
World War II altered the political alignment and social structure of the world. The United Nations (UN) was established to foster international co-operation and prevent future conflicts. The victorious great powers—the United States, the Soviet Union, China, the United Kingdom, and France—became the permanent members of the United Nations Security Council. The Soviet Union and the United States emerged as rival superpowers, setting the stage for the Cold War, which lasted for the next 46 years. Meanwhile, the influence of European great powers waned, while the decolonisation of Asia and Africa began. Most countries whose industries had been damaged moved towards economic recovery. Political integration, especially in Europe, emerged as an effort to end pre-war enmities and to create a common identity.
Chronology.
The start of the war in Europe is generally held to be 1 September 1939, beginning with the German invasion of Poland; Britain and France declared war on Germany two days later. The dates for the beginning of war in the Pacific include the start of the Second Sino-Japanese War on 7 July 1937, or even the Japanese invasion of Manchuria on 19 September 1931.
Others follow the British historian A. J. P. Taylor, who held that the Sino-Japanese War and war in Europe and its colonies occurred simultaneously and the two wars merged in 1941. This article uses the conventional dating. Other starting dates sometimes used for World War II include the Italian invasion of Abyssinia on 3 October 1935. The British historian Antony Beevor views the beginning of the Second World War as the Battles of Khalkhin Gol fought between Japan and the forces of Mongolia and the Soviet Union from May to September 1939.
The exact date of the war's end is also not universally agreed upon. It was generally accepted at the time that the war ended with the armistice of 14 August 1945 (V-J Day), rather than the formal surrender of Japan (2 September 1945); it is even claimed in some European histories that it ended on V-E Day (8 May 1945). A peace treaty with Japan was signed in 1951 to formally tie up any loose ends such as compensation to be paid to Allied prisoners of war who had been victims of atrocities. A treaty regarding Germany's future allowed the reunification of East and West Germany to take place in 1990 and resolved other post-World War II issues.
Background.
World War I had radically altered the political European map, with the defeat of the Central Powers—including Austria-Hungary, Germany and the Ottoman Empire—and the 1917 Bolshevik seizure of power in Russia. Meanwhile, existing victorious Allies such as France, Belgium, Italy, Greece and Romania gained territories, and new Nation states were created out of the collapse of Austria-Hungary and the Ottoman and Russian Empires.
To prevent a future world war, the League of Nations was created during the 1919 Paris Peace Conference. The organisation's primary goals were to prevent armed conflict through collective security, military and naval disarmament, and settling international disputes through peaceful negotiations and arbitration.
Despite strong pacifist sentiment after World War I, its aftermath still caused irredentist and revanchist nationalism in several European states. These sentiments were especially marked in Germany because of the significant territorial, colonial, and financial losses incurred by the Treaty of Versailles. Under the treaty, Germany lost around 13 percent of its home territory and all of its overseas colonies, while German annexation of other states was prohibited, reparations were imposed, and limits were placed on the size and capability of the country's armed forces.
The German Empire was dissolved in the German Revolution of 1918–1919, and a democratic government, later known as the Weimar Republic, was created. The interwar period saw strife between supporters of the new republic and hardline opponents on both the right and left. Italy, as an Entente ally, had made some post-war territorial gains, however Italian nationalists were angered that the promises made by Britain and France to secure Italian entrance into the war were not fulfilled with the peace settlement. From 1922 to 1925, the Fascist movement led by Benito Mussolini seized power in Italy with a nationalist, totalitarian, and class collaborationist agenda that abolished representative democracy, repressed socialist, left-wing and liberal forces, and pursued an aggressive expansionist foreign policy aimed at forging Italy as a world power, promising the creation of a "New Roman Empire".
In Germany, the Weimar Republic was attacked by right-wing elements such as the Freikorps and the Nazi party, resulting in events such as the Kapp Putsch and the Beer Hall Putsch. With the onset of the Great Depression in 1929, domestic support for Nazism and its leader Adolf Hitler rose and, in 1933, he was appointed Chancellor of Germany. In the aftermath of the Reichstag fire, Hitler created a totalitarian single-party state led by the Nazis.
The Kuomintang (KMT) party in China launched a unification campaign against regional warlords and nominally unified China in the mid-1920s, but was soon embroiled in a civil war against its former Chinese communist allies. In 1931, an increasingly militaristic Japanese Empire, which had long sought influence in China as the first step of what its government saw as the country's right to rule Asia, used the Mukden Incident as a pretext to launch an invasion of Manchuria and establish the puppet state of Manchukuo.
Too weak to resist Japan, China appealed to the League of Nations for help. Japan withdrew from the League of Nations after being condemned for its incursion into Manchuria. The two nations then fought several battles, in Shanghai, Rehe and Hebei, until the Tanggu Truce was signed in 1933. Thereafter, Chinese volunteer forces continued the resistance to Japanese aggression in Manchuria, and Chahar and Suiyuan.
Adolf Hitler, after an unsuccessful attempt to overthrow the German government in 1923, eventually became the Chancellor of Germany in 1933. He abolished democracy, espousing a radical, racially motivated revision of the world order, and soon began a massive rearmament campaign. It was at this time that multiple political scientists began to predict that a second Great War might take place. Meanwhile, France, to secure its alliance, allowed Italy a free hand in Ethiopia, which Italy desired as a colonial possession. The situation was aggravated in early 1935 when the Territory of the Saar Basin was legally reunited with Germany and Hitler repudiated the Treaty of Versailles, accelerated his rearmament programme and introduced conscription.
Hoping to contain Germany, the United Kingdom, France and Italy formed the Stresa Front; however, in June 1935, the United Kingdom made an independent naval agreement with Germany, easing prior restrictions. The Soviet Union, concerned due to Germany's goals of capturing vast areas of eastern Europe, drafted a treaty of mutual assistance with France. Before taking effect though, the Franco-Soviet pact was required to go through the bureaucracy of the League of Nations, which rendered it essentially toothless. The United States, concerned with events in Europe and Asia, passed the Neutrality Act in August of the same year. Two months later, Italy invaded Ethiopia through Italian Somaliland and Eritrea; Germany was the only major European nation to support the invasion. Italy subsequently dropped its objections to Germany's goal of absorbing Austria.
Hitler defied the Versailles and Locarno treaties by remilitarising the Rhineland in March 1936. He encountered little opposition from other European powers. When the Spanish Civil War broke out in July, Hitler and Mussolini supported the fascist and authoritarian Nationalist forces in their civil war against the Soviet-supported Spanish Republic. Both sides used the conflict to test new weapons and methods of warfare, with the Nationalists winning the war in early 1939. In October 1936, Germany and Italy formed the Rome–Berlin Axis. A month later, Germany and Japan signed the Anti-Comintern Pact, which Italy would join in the following year. In China, after the Xi'an Incident, the Kuomintang and communist forces agreed on a ceasefire to present a united front to oppose Japan.
Pre-war events.
Italian invasion of Ethiopia (1935).
The Second Italo–Abyssinian War was a brief colonial war that began in October 1935 and ended in May 1936. The war began with the invasion of the Ethiopian Empire (also known as Abyssinia) by the armed forces of the Kingdom of Italy ("Regno d'Italia"), which was launched from Italian Somaliland and Eritrea. The war resulted in the military occupation of Ethiopia and its annexation into the newly created colony of Italian East Africa ("Africa Orientale Italiana", or AOI); in addition, it exposed the weakness of the League of Nations as a force to preserve peace. Both Italy and Ethiopia were member nations, but the League did nothing when the former clearly violated the League's own Article X.
Spanish Civil War (1936–39).
During the Spanish Civil War, Hitler and Mussolini lent military support to the Nationalist rebels, led by General Francisco Franco. The Soviet Union supported the existing government, the Spanish Republic. Over 30,000 foreign volunteers, known as the International Brigades, also fought against the Nationalists. Both Germany and the USSR used this proxy war as an opportunity to test in combat their most advanced weapons and tactics. The bombing of Guernica by the German Condor Legion in April 1937 heightened widespread concerns that the next major war would include extensive terror bombing attacks on civilians.
The Nationalists won the civil war in April 1939; Franco, now dictator, bargained with both sides during the Second World War, but never concluded any major agreements. He did send volunteers to fight on the Eastern Front under German command but Spain remained neutral and did not allow either side to use its territory.
Japanese invasion of China (1937).
In July 1937, Japan captured the former Chinese imperial capital of Beijing after instigating the Marco Polo Bridge Incident, which culminated in the Japanese campaign to invade all of China. The Soviets quickly signed a non-aggression pact with China to lend materiel support, effectively ending China's prior co-operation with Germany. Generalissimo Chiang Kai-shek deployed his best army to defend Shanghai, but, after three months of fighting, Shanghai fell. The Japanese continued to push the Chinese forces back, capturing the capital Nanking in December 1937. After the fall of Nanking, tens of thousands if not hundreds of thousands of Chinese civilians and disarmed combatants were murdered by the Japanese.
In March 1938, Nationalist Chinese forces won their first major victory at Taierzhuang but then the city of Xuzhou was taken by Japanese in May. In June 1938, Chinese forces stalled the Japanese advance by flooding the Yellow River; this manoeuvre bought time for the Chinese to prepare their defences at Wuhan, but the city was taken by October. Japanese military victories did not bring about the collapse of Chinese resistance that Japan had hoped to achieve; instead the Chinese government relocated inland to Chongqing and continued the war.
Japanese invasion of the Soviet Union and Mongolia (1938).
Japanese forces in Manchukuo had sporadic border clashes with the Soviet Union, culminating in the Japanese defeat at Khalkin Gol. After this, Japan and the Soviet Union signed a Neutrality Pact in April 1941, and Japan turned its focus to the South Pacific.
European occupations and agreements.
In Europe, Germany and Italy were becoming more aggressive. In March 1938, Germany annexed Austria, again provoking little response from other European powers. Encouraged, Hitler began pressing German claims on the Sudetenland, an area of Czechoslovakia with a predominantly ethnic German population; and soon Britain and France followed the counsel of prime minister Neville Chamberlain and conceded this territory to Germany in the Munich Agreement, which was made against the wishes of the Czechoslovak government, in exchange for a promise of no further territorial demands. Soon afterwards, Germany and Italy forced Czechoslovakia to cede additional territory to Hungary and Poland.
Although all of Germany's stated demands had been satisfied by the agreement, privately Hitler was furious that British interference had prevented him from seizing all of Czechoslovakia in one operation. In subsequent speeches Hitler attacked British and Jewish "war-mongers" and in January 1939 secretly ordered a major build-up of the German navy to challenge British naval supremacy. In March 1939, Germany invaded the remainder of Czechoslovakia and subsequently split it into the German Protectorate of Bohemia and Moravia and a pro-German client state, the Slovak Republic. Hitler also delivered an ultimatum to Lithuania, forcing the concession of the Klaipėda Region.
Greatly alarmed, and in Chamberlain's case feeling deep personal betrayal, and with Hitler making further demands on the Free City of Danzig, Britain and France guaranteed their support for Polish independence; when Italy conquered Albania in April 1939, the same guarantee was extended to Romania and Greece. Shortly after the Franco-British pledge to Poland, Germany and Italy formalised their own alliance with the Pact of Steel. Hitler accused Britain and Poland of trying to "encircle" Germany and renounced the Anglo-German Naval Agreement and the German–Polish Non-Aggression Pact.
In August 1939, Germany and the Soviet Union signed the Molotov–Ribbentrop Pact, a non-aggression treaty with a secret protocol. The parties gave each other rights to "spheres of influence" (western Poland and Lithuania for Germany; eastern Poland, Finland, Estonia, Latvia and Bessarabia for the USSR). It also raised the question of continuing Polish independence. The agreement was crucial to Hitler because it assured that Germany would not have to face the prospect of a two-front war, as it had in World War I, after it defeated Poland.
The situation reached a general crisis in late August as German troops continued to mobilise against the Polish border. In a private meeting with the Italian foreign minister, Count Ciano, Hitler asserted that Poland was a "doubtful neutral" that needed to either yield to his demands or be "liquidated" to prevent it from drawing off German troops in the future "unavoidable" war with the Western democracies. He did not believe Britain or France would intervene in the conflict. On 23 August Hitler ordered the attack to proceed on 26 August, but upon hearing that Britain had concluded a formal mutual assistance pact with Poland and that Italy would maintain neutrality, he decided to delay it. In response to British demands for direct negotiations, Germany demanded on 29 August that a Polish plenipotentiary immediately travel to Berlin to negotiate the handover of Danzig and the Polish Corridor to Germany as well as to agree to safeguard the German minority in Poland. The Poles refused to comply with this request and on the night of 30–31 August in a violent interview with Neville Henderson, Ribbentrop declared that Germany considered its proposals rejected.
Course of the war.
War breaks out in Europe (1939–40).
On 1 September 1939, Germany invaded Poland under the false pretext that the Poles had carried out a series of sabotage operations against German targets. Two days later, on 3 September, after a British ultimatum to Germany to cease military operations was ignored, France and the United Kingdom, followed by the fully independent Dominions of the British Commonwealth—Australia (3 September), Canada (10 September), New Zealand (3 September), and South Africa (6 September)—declared war on Germany. However, initially the alliance provided limited direct military support to Poland, consisting of a cautious, half-hearted French probe into the Saarland. The Western Allies also began a naval blockade of Germany, which aimed to damage the country's economy and war effort. Germany responded by ordering U-boat warfare against Allied merchant and warships, which was to later escalate into the Battle of the Atlantic.
On 17 September 1939, after signing a cease-fire with Japan, the Soviets invaded Poland from the east. The Polish army was defeated and Warsaw surrendered to the Germans on 27 September, with final pockets of resistance surrendering on 6 October. Poland's territory was divided between Germany and the Soviet Union, with Lithuania and Slovakia also receiving small shares. After the surrender of Poland's armed forces, the Polish resistance established an Underground State and a partisan Home Army. About 100,000 Polish military personnel were evacuated to Romania and the Baltic countries; many of these soldiers later fought against the Germans in other theatres of the war. Poland's Enigma codebreakers were also evacuated to France.
On 6 October Hitler made a public peace overture to the United Kingdom and France, but said that the future of Poland was to be determined exclusively by Germany and the Soviet Union. Chamberlain rejected this on 12 October, saying "Past experience has shown that no reliance can be placed upon the promises of the present German Government." After this rejection Hitler ordered an immediate offensive against France, but bad weather forced repeated postponements until the spring of 1940.
After signing the German–Soviet Treaty of Friendship, Cooperation and Demarcation, the Soviet Union forced the Baltic countries—Estonia, Latvia and Lithuania—to allow it to station Soviet troops in their countries under pacts of "mutual assistance". Finland rejected territorial demands, prompting a Soviet invasion in November 1939. The resulting Winter War ended in March 1940 with Finnish concessions. The United Kingdom and France treating the Soviet attack on Finland as tantamount to its entering the war on the side of the Germans, responded to the Soviet invasion by supporting the USSR's expulsion from the League of Nations.
In June 1940, the Soviet Union forcibly annexed Estonia, Latvia and Lithuania, and the disputed Romanian regions of Bessarabia, Northern Bukovina and Hertza. Meanwhile, Nazi-Soviet political rapprochement and economic co-operation gradually stalled, and both states began preparations for war.
Western Europe (1940–41).
In April 1940, Germany invaded Denmark and Norway to protect shipments of iron ore from Sweden, which the Allies were attempting to cut off by unilaterally mining neutral Norwegian waters. Denmark capitulated after a few hours, and despite Allied support, during which the important harbour of Narvik temporarily was recaptured from the Germans, Norway was conquered within two months. British discontent over the Norwegian campaign led to the replacement of the British Prime Minister, Neville Chamberlain, with Winston Churchill on 10 May 1940.
Germany launched an offensive against France and, adhering to the Manstein Plan also attacked the neutral nations of Belgium, the Netherlands, and Luxembourg on 10 May 1940. That same day British forces landed in Iceland and the Faroes to preempt a possible German invasion of the islands. The U.S. in close co-operation with the Danish envoy to Washington D.C., agreed to protect Greenland, laying the political framework for the formal establishment of bases in April 1941. The Netherlands and Belgium were overrun using blitzkrieg tactics in a few days and weeks, respectively. The French-fortified Maginot Line and the main body the Allied forces which had moved into Belgium were circumvented by a flanking movement through the thickly wooded Ardennes region, mistakenly perceived by Allied planners as an impenetrable natural barrier against armoured vehicles. As a result, the bulk of the Allied armies found themselves trapped in an encirclement and were beaten. The majority were taken prisoner, whilst over 300,000, mostly British and French, were evacuated from the continent at Dunkirk by early June, although abandoning almost all of their equipment.
On 10 June, Italy invaded France, declaring war on both France and the United Kingdom. Paris fell to the Germans on 14 June and eight days later France surrendered and was soon divided into German and Italian occupation zones, and an unoccupied rump state under the Vichy Regime, which, though officially neutral, was generally aligned with Germany. France kept its fleet but the British feared the Germans would seize it, so on 3 July, the British attacked it.
On 19 July, Hitler again publicly offered to end the war, saying he had no desire to destroy the British Empire. The United Kingdom rejected this, with Lord Halifax responding "there was in his speech no suggestion that peace must be based on justice, no word of recognition that the other nations of Europe had any right to self‑determination ..."
Following this, Germany began an air superiority campaign over the United Kingdom (the Battle of Britain) to prepare for an invasion. The campaign failed, and the invasion plans were cancelled by September. Frustrated, and in part in response to repeated British air raids against Berlin, Germany began a strategic bombing offensive against British cities known as the Blitz. However, the air attacks largely failed to disrupt the British war effort.
Using newly captured French ports, the German Navy enjoyed success against an over-extended Royal Navy, using U-boats against British shipping in the Atlantic. The British scored a significant victory on 27 May 1941 by sinking the German battleship "Bismarck". Perhaps most importantly, during the Battle of Britain the Royal Air Force had successfully resisted the Luftwaffe's assault, and the German bombing campaign largely ended in May 1941.
Throughout this period, the neutral United States took measures to assist China and the Western Allies. In November 1939, the American Neutrality Act was amended to allow "cash and carry" purchases by the Allies. In 1940, following the German capture of Paris, the size of the United States Navy was significantly increased. In September, the United States further agreed to a trade of American destroyers for British bases. Still, a large majority of the American public continued to oppose any direct military intervention into the conflict well into 1941.
Although Roosevelt had promised to keep the United States out of the war, he nevertheless took concrete steps to prepare for war. In December 1940 he accused Hitler of planning world conquest and ruled out negotiations as useless, calling for the US to become an "arsenal for democracy" and promoted the passage of Lend-Lease aid to support the British war effort. In January 1941 secret high level staff talks with the British began for the purposes of determining how to defeat Germany should the US enter the war. They decided on a number of offensive policies, including an air offensive, the "early elimination" of Italy, raids, support of resistance groups, and the capture of positions to launch an offensive against Germany.
At the end of September 1940, the Tripartite Pact united Japan, Italy and Germany to formalise the Axis Powers. The Tripartite Pact stipulated that any country, with the exception of the Soviet Union, not in the war which attacked any Axis Power would be forced to go to war against all three. The Axis expanded in November 1940 when Hungary, Slovakia and Romania joined the Tripartite Pact. Romania would make a major contribution (as did Hungary) to the Axis war against the USSR, partially to recapture territory ceded to the USSR, partially to pursue its leader Ion Antonescu's desire to combat communism.
Mediterranean (1940–41).
Italy began operations in the Mediterranean, initiating a siege of Malta in June, conquering British Somaliland in August, and making an incursion into British-held Egypt in September 1940. In October 1940, Italy started the Greco-Italian War due to Mussolini's jealousy of Hitler's success but within days was repulsed and pushed back into Albania, where a stalemate soon occurred. The United Kingdom responded to Greek requests for assistance by sending troops to Crete and providing air support to Greece. Hitler decided that when the weather improved he would take action against Greece to assist the Italians and prevent the British from gaining a foothold in the Balkans, to strike against the British naval dominance of the Mediterranean, and to secure his hold on Romanian oil.
In December 1940, British Commonwealth forces began counter-offensives against Italian forces in Egypt and Italian East Africa. The offensive in North Africa was highly successful and by early February 1941 Italy had lost control of eastern Libya and large numbers of Italian troops had been taken prisoner. The Italian Navy also suffered significant defeats, with the Royal Navy putting three Italian battleships out of commission by a carrier attack at Taranto, and neutralising several more warships at the Battle of Cape Matapan.
The Germans soon intervened to assist Italy. Hitler sent German forces to Libya in February, and by the end of March they had launched an offensive which drove back the Commonwealth forces which had been weakened to support Greece. In under a month, Commonwealth forces were pushed back into Egypt with the exception of the besieged port of Tobruk. The Commonwealth attempted to dislodge Axis forces in May and again in June, but failed on both occasions.
By late March 1941, following Bulgaria's signing of the Tripartite Pact, the Germans were in position to intervene in Greece. Plans were changed, however, due to developments in neighbouring Yugoslavia. The Yugoslav government had signed the Tripartite Pact on 25 March, only to be overthrown two days later by a British-encouraged coup. Hitler viewed the new regime as hostile and immediately decided to eliminate it. On 6 April Germany simultaneously invaded both Yugoslavia and Greece, making rapid progress and forcing both nations to surrender within the month. The British were driven from the Balkans after Germany conquered the Greek island of Crete by the end of May. Although the Axis victory was swift, bitter partisan warfare subsequently broke out against the Axis occupation of Yugoslavia, which continued until the end of the war.
The Allies did have some successes during this time. In the Middle East, Commonwealth forces first quashed an uprising in Iraq which had been supported by German aircraft from bases within Vichy-controlled Syria, then, with the assistance of the Free French, invaded Syria and Lebanon to prevent further such occurrences.
Axis attack on the USSR (1941).
With the situation in Europe and Asia relatively stable, Germany, Japan, and the Soviet Union made preparations. With the Soviets wary of mounting tensions with Germany and the Japanese planning to take advantage of the European War by seizing resource-rich European possessions in Southeast Asia, the two powers signed the Soviet–Japanese Neutrality Pact in April 1941. By contrast, the Germans were steadily making preparations for an attack on the Soviet Union, massing forces on the Soviet border.
Hitler believed that Britain's refusal to end the war was based on the hope that the United States and the Soviet Union would enter the war against Germany sooner or later. He therefore decided to try to strengthen Germany's relations with the Soviets, or failing that, to attack and eliminate them as a factor. In November 1940, negotiations took place to determine if the Soviet Union would join the Tripartite Pact. The Soviets showed some interest, but asked for concessions from Finland, Bulgaria, Turkey, and Japan that Germany considered unacceptable. On 18 December 1940, Hitler issued the directive to prepare for an invasion of the Soviet Union.
On 22 June 1941, Germany, supported by Italy and Romania, invaded the Soviet Union in Operation Barbarossa, with Germany accusing the Soviets of plotting against them. They were joined shortly by Finland and Hungary. The primary targets of this surprise offensive were the Baltic region, Moscow and Ukraine, with the ultimate goal of ending the 1941 campaign near the Arkhangelsk-Astrakhan line, from the Caspian to the White Seas. Hitler's objectives were to eliminate the Soviet Union as a military power, exterminate Communism, generate "Lebensraum" ("living space") by dispossessing the native population and guarantee access to the strategic resources needed to defeat Germany's remaining rivals.
Although the Red Army was preparing for strategic counter-offensives before the war, "Barbarossa" forced the Soviet supreme command to adopt a strategic defence. During the summer, the Axis made significant gains into Soviet territory, inflicting immense losses in both personnel and materiel. By the middle of August, however, the German Army High Command decided to suspend the offensive of a considerably depleted Army Group Centre, and to divert the 2nd Panzer Group to reinforce troops advancing towards central Ukraine and Leningrad. The Kiev offensive was overwhelmingly successful, resulting in encirclement and elimination of four Soviet armies, and made further advance into Crimea and industrially developed Eastern Ukraine (the First Battle of Kharkov) possible.
The diversion of three quarters of the Axis troops and the majority of their air forces from France and the central Mediterranean to the Eastern Front prompted Britain to reconsider its grand strategy. In July, the UK and the Soviet Union formed a military alliance against Germany The British and Soviets invaded Iran to secure the Persian Corridor and Iran's oil fields. In August, the United Kingdom and the United States jointly issued the Atlantic Charter.
By October Axis operational objectives in Ukraine and the Baltic region were achieved, with only the sieges of Leningrad and Sevastopol continuing. A major offensive against Moscow was renewed; after two months of fierce battles in increasingly harsh weather the German army almost reached the outer suburbs of Moscow, where the exhausted troops were forced to suspend their offensive. Large territorial gains were made by Axis forces, but their campaign had failed to achieve its main objectives: two key cities remained in Soviet hands, the Soviet capability to resist was not broken, and the Soviet Union retained a considerable part of its military potential. The "blitzkrieg" phase of the war in Europe had ended.
By early December, freshly mobilised reserves allowed the Soviets to achieve numerical parity with Axis troops. This, as well as intelligence data which established that a minimal number of Soviet troops in the East would be sufficient to deter any attack by the Japanese Kwantung Army, allowed the Soviets to begin a massive counter-offensive that started on 5 December all along the front and pushed German troops 100 - west.
War breaks out in the Pacific (1941).
In 1939 the United States had renounced its trade treaty with Japan and beginning with an aviation gasoline ban in July 1940 Japan had become subject to increasing economic pressure. During this time, Japan launched its first attack against Changsha, a strategically important Chinese city, but was repulsed by late September. Despite several offensives by both sides, the war between China and Japan was stalemated by 1940. To increase pressure on China by blocking supply routes, and to better position Japanese forces in the event of a war with the Western powers, Japan had occupied northern Indochina. Afterwards, the United States embargoed iron, steel and mechanical parts against Japan. Other sanctions soon followed.
In August of that year, Chinese communists launched an offensive in Central China; in retaliation, Japan instituted harsh measures in occupied areas to reduce human and material resources for the communists. Continued antipathy between Chinese communist and nationalist forces culminated in armed clashes in January 1941, effectively ending their co-operation. In March, the Japanese 11th army attacked the headquarters of the Chinese 19th army but was repulsed during Battle of Shanggao. In September, Japan attempted to take the city of Changsha again and clashed with Chinese nationalist forces.
German successes in Europe encouraged Japan to increase pressure on European governments in Southeast Asia. The Dutch government agreed to provide Japan some oil supplies from the Dutch East Indies, but negotiations for additional access to their resources ended in failure in June 1941. In July 1941 Japan sent troops to southern Indochina, thus threatening British and Dutch possessions in the Far East. The United States, United Kingdom and other Western governments reacted to this move with a freeze on Japanese assets and a total oil embargo.
Since early 1941 the United States and Japan had been engaged in negotiations in an attempt to improve their strained relations and end the war in China. During these negotiations Japan advanced a number of proposals which were dismissed by the Americans as inadequate. At the same time the US, Britain, and the Netherlands engaged in secret discussions for the joint defence of their territories, in the event of a Japanese attack against any of them. Roosevelt reinforced the Philippines (an American possession since 1898) and warned Japan that the US would react to Japanese attacks against any "neighboring countries".
Frustrated at the lack of progress and feeling the pinch of the American-British-Dutch sanctions, Japan prepared for war. On 20 November it presented an interim proposal as its final offer. It called for the end of American aid to China and the supply of oil and other resources to Japan. In exchange they promised not to launch any attacks in Southeast Asia and to withdraw their forces from their threatening positions in southern Indochina. The American counter-proposal of 26 November required that Japan evacuate all of China without conditions and conclude non-aggression pacts with all Pacific powers. That meant Japan was essentially forced to choose between abandoning its ambitions in China, or seizing the natural resources it needed in the Dutch East Indies by force; the Japanese military did not consider the former an option, and many officers considered the oil embargo an unspoken declaration of war.
Japan planned to rapidly seize European colonies in Asia to create a large defensive perimeter stretching into the Central Pacific; the Japanese would then be free to exploit the resources of Southeast Asia while exhausting the over-stretched Allies by fighting a defensive war. To prevent American intervention while securing the perimeter it was further planned to neutralise the United States Pacific Fleet and the American military presence in the Philippines from the outset. On 7 December (8 December in Asian time zones), 1941, Japan attacked British and American holdings with near-simultaneous offensives against Southeast Asia and the Central Pacific. These included an attack on the American fleet at Pearl Harbor, landings in Thailand and Malaya and the battle of Hong Kong.
These attacks led the United States, Britain, China, Australia and several other states to formally declare war on Japan, whereas the Soviet Union, being heavily involved in large-scale hostilities with European Axis countries, preferred to maintain its neutrality agreement with Japan. Germany, followed by the other Axis states, declared war on the United States in solidarity with Japan, citing as justification the American attacks on German submarines and merchant ships that had been ordered by Roosevelt.
Axis advance stalls (1942–43).
In January 1942, the United States, Britain, Soviet Union, China, and 22 smaller or exiled governments issued the Declaration by United Nations, thereby affirming the Atlantic Charter, and agreeing to not to sign separate peace with the Axis powers.
During 1942, Allied officials debated on the appropriate grand strategy to pursue. All agreed that defeating Germany was the primary objective. The Americans favoured a straightforward, large-scale attack on Germany through France. The Soviets were also demanding a second front. The British, on the other hand, argued that military operations should target peripheral areas to throw a "ring" around Germany which would wear out German strength, lead to increasing demoralisation, and bolster resistance forces. Germany itself would be subject to a heavy bombing campaign. An offensive against Germany would then be launched primarily by Allied armour without using large-scale armies. Eventually, the British persuaded the Americans that a landing in France was infeasible in 1942 and they should instead focus on driving the Axis out of North Africa.
At the Casablanca Conference in early 1943, the Allies issued a declaration declaring that they would not negotiate with their enemies and demanded their unconditional surrender. The British and Americans agreed to continue to press the initiative in the Mediterranean by invading Sicily to fully secure the Mediterranean supply routes. Although the British argued for further operations in the Balkans to bring Turkey into the war, in May 1943, the Americans extracted a British commitment to limit Allied operations in the Mediterranean to an invasion of the Italian mainland and to invade France in 1944.
Pacific (1942–43).
By the end of April 1942, Japan and its ally Thailand had almost fully conquered Burma, Malaya, the Dutch East Indies, Singapore, and Rabaul, inflicting severe losses on Allied troops and taking a large number of prisoners. Despite stubborn resistance at Corregidor, the US possession of the Philippines was eventually captured in May 1942, forcing its government into exile. On 16 April, in Burma, 7,000 British soldiers were encircled by the Japanese 33rd Division during the Battle of Yenangyaung and rescued by the Chinese 38th Division. Japanese forces also achieved naval victories in the South China Sea, Java Sea and Indian Ocean, and bombed the Allied naval base at Darwin, Australia. The only real Allied success against Japan was a Chinese victory at Changsha in early January 1942. These easy victories over unprepared opponents left Japan overconfident, as well as overextended.
In early May 1942, Japan initiated operations to capture Port Moresby by amphibious assault and thus sever communications and supply lines between the United States and Australia. The Allies, however, prevented the invasion by intercepting and defeating the Japanese naval forces in the Battle of the Coral Sea. Japan's next plan, motivated by the earlier Doolittle Raid, was to seize Midway Atoll and lure American carriers into battle to be eliminated; as a diversion, Japan would also send forces to occupy the Aleutian Islands in Alaska. In early June, Japan put its operations into action but the Americans, having broken Japanese naval codes in late May, were fully aware of the plans and force dispositions and used this knowledge to achieve a decisive victory at Midway over the Imperial Japanese Navy.
With its capacity for aggressive action greatly diminished as a result of the Midway battle, Japan chose to focus on a belated attempt to capture Port Moresby by an overland campaign in the Territory of Papua. The Americans planned a counter-attack against Japanese positions in the southern Solomon Islands, primarily Guadalcanal, as a first step towards capturing Rabaul, the main Japanese base in Southeast Asia.
Both plans started in July, but by mid-September, the Battle for Guadalcanal took priority for the Japanese, and troops in New Guinea were ordered to withdraw from the Port Moresby area to the northern part of the island, where they faced Australian and United States troops in the Battle of Buna-Gona. Guadalcanal soon became a focal point for both sides with heavy commitments of troops and ships in the battle for Guadalcanal. By the start of 1943, the Japanese were defeated on the island and withdrew their troops. In Burma, Commonwealth forces mounted two operations. The first, an offensive into the Arakan region in late 1942, went disastrously, forcing a retreat back to India by May 1943. The second was the insertion of irregular forces behind Japanese front-lines in February which, by the end of April, had achieved mixed results.
Eastern Front (1942–43).
Despite considerable losses, in early 1942 Germany and its allies stopped a major Soviet offensive in central and southern Russia, keeping most territorial gains they had achieved during the previous year. In May the Germans defeated Soviet offensives in the Kerch Peninsula and at Kharkiv, and then launched their main summer offensive against southern Russia in June 1942, to seize the oil fields of the Caucasus and occupy Kuban steppe, while maintaining positions on the northern and central areas of the front. The Germans split Army Group South into two groups: Army Group A advanced to the lower Don River and struck south-east to the Caucasus, while Army Group B headed towards the Volga River. The Soviets decided to make their stand at Stalingrad on the Volga.
By mid-November, the Germans had nearly taken Stalingrad in bitter street fighting when the Soviets began their second winter counter-offensive, starting with an encirclement of German forces at Stalingrad and an assault on the Rzhev salient near Moscow, though the latter failed disastrously. By early February 1943, the German Army had taken tremendous losses; German troops at Stalingrad had been forced to surrender, and the front-line had been pushed back beyond its position before the summer offensive. In mid-February, after the Soviet push had tapered off, the Germans launched another attack on Kharkiv, creating a salient in their front line around the Russian city of Kursk.
Western Europe/Atlantic & Mediterranean (1942–43).
Exploiting poor American naval command decisions, the German navy ravaged Allied shipping off the American Atlantic coast. By November 1941, Commonwealth forces had launched a counter-offensive, Operation Crusader, in North Africa, and reclaimed all the gains the Germans and Italians had made. In North Africa, the Germans launched an offensive in January, pushing the British back to positions at the Gazala Line by early February, followed by a temporary lull in combat which Germany used to prepare for their upcoming offensives. Concerns the Japanese might use bases in Vichy-held Madagascar caused the British to invade the island in early May 1942. An Axis offensive in Libya forced an Allied retreat deep inside Egypt until Axis forces were stopped at El Alamein. On the Continent, raids of Allied commandos on strategic targets, culminating in the disastrous Dieppe Raid, demonstrated the Western Allies' inability to launch an invasion of continental Europe without much better preparation, equipment, and operational security.
In August 1942, the Allies succeeded in repelling a second attack against El Alamein and, at a high cost, managed to deliver desperately needed supplies to the besieged Malta. A few months later, the Allies commenced an attack of their own in Egypt, dislodging the Axis forces and beginning a drive west across Libya. This attack was followed up shortly after by Anglo-American landings in French North Africa, which resulted in the region joining the Allies. Hitler responded to the French colony's defection by ordering the occupation of Vichy France; although Vichy forces did not resist this violation of the armistice, they managed to scuttle their fleet to prevent its capture by German forces. The now pincered Axis forces in Africa withdrew into Tunisia, which was conquered by the Allies in May 1943.
In early 1943 the British and Americans began the "Combined Bomber Offensive", a strategic bombing campaign against Germany. The goals were to disrupt the German war economy, reduce German morale, and "de-house" the German civilian population.
Allies gain momentum (1943–44).
Following the Guadalcanal Campaign, the Allies initiated several operations against Japan in the Pacific. In May 1943, Allied forces were sent to eliminate Japanese forces from the Aleutians, and soon after began major operations to isolate Rabaul by capturing surrounding islands, and to breach the Japanese Central Pacific perimeter at the Gilbert and Marshall Islands. By the end of March 1944, the Allies had completed both of these objectives, and additionally neutralised the major Japanese base at Truk in the Caroline Islands. In April, the Allies then launched an operation to retake Western New Guinea.
In the Soviet Union, both the Germans and the Soviets spent the spring and early summer of 1943 making preparations for large offensives in central Russia. On 4 July 1943, Germany attacked Soviet forces around the Kursk Bulge. Within a week, German forces had exhausted themselves against the Soviets' deeply echeloned and well-constructed defences and, for the first time in the war, Hitler cancelled the operation before it had achieved tactical or operational success. This decision was partially affected by the Western Allies' invasion of Sicily launched on 9 July which, combined with previous Italian failures, resulted in the ousting and arrest of Mussolini later that month. Also, in July 1943 the British firebombed Hamburg killing over 40,000 people.
On 12 July 1943, the Soviets launched their own counter-offensives, thereby dispelling any hopes of the German Army for victory or even stalemate in the east. The Soviet victory at Kursk marked the end of German superiority, giving the Soviet Union the initiative on the Eastern Front. The Germans attempted to stabilise their eastern front along the hastily fortified Panther-Wotan line, however, the Soviets broke through it at Smolensk and by the Lower Dnieper Offensives.
On 3 September 1943, the Western Allies invaded the Italian mainland, following an Italian armistice with the Allies. Germany responded by disarming Italian forces, seizing military control of Italian areas, and creating a series of defensive lines. German special forces then rescued Mussolini, who then soon established a new client state in German occupied Italy named the Italian Social Republic, causing an Italian civil war. The Western Allies fought through several lines until reaching the main German defensive line in mid-November.
German operations in the Atlantic also suffered. By May 1943, as Allied counter-measures became increasingly effective, the resulting sizeable German submarine losses forced a temporary halt of the German Atlantic naval campaign. In November 1943, Franklin D. Roosevelt and Winston Churchill met with Chiang Kai-shek in Cairo and then with Joseph Stalin in Tehran. The former conference determined the post-war return of Japanese territory, while the latter included agreement that the Western Allies would invade Europe in 1944 and that the Soviet Union would declare war on Japan within three months of Germany's defeat.
From November 1943, during the seven-week Battle of Changde, the Chinese forced Japan to fight a costly war of attrition, while awaiting Allied relief. In January 1944, the Allies launched a series of attacks in Italy against the line at Monte Cassino and attempted to outflank it with landings at Anzio. By the end of January, a major Soviet offensive expelled German forces from the Leningrad region, ending the longest and most lethal siege in history.
The following Soviet offensive was halted on the pre-war Estonian border by the German Army Group North aided by Estonians hoping to re-establish national independence. This delay slowed subsequent Soviet operations in the Baltic Sea region. By late May 1944, the Soviets had liberated Crimea, largely expelled Axis forces from Ukraine, and made incursions into Romania, which were repulsed by the Axis troops. The Allied offensives in Italy had succeeded and, at the expense of allowing several German divisions to retreat, on 4 June, Rome was captured.
The Allies experienced mixed fortunes in mainland Asia. In March 1944, the Japanese launched the first of two invasions, an operation against British positions in Assam, India, and soon besieged Commonwealth positions at Imphal and Kohima. In May 1944, British forces mounted a counter-offensive that drove Japanese troops back to Burma, and Chinese forces that had invaded northern Burma in late 1943 besieged Japanese troops in Myitkyina. The second Japanese invasion of China attempted to destroy China's main fighting forces, secure railways between Japanese-held territory and capture Allied airfields. By June, the Japanese had conquered the province of Henan and begun a renewed attack against Changsha in the Hunan province.
Allies close in (1944).
On 6 June 1944 (known as D-Day), after three years of Soviet pressure, the Western Allies invaded northern France. After reassigning several Allied divisions from Italy, they also attacked southern France. These landings were successful, and led to the defeat of the German Army units in France. Paris was liberated by the local resistance assisted by the Free French Forces, both led by General Charles de Gaulle, on 25 August and the Western Allies continued to push back German forces in western Europe during the latter part of the year. An attempt to advance into northern Germany spearheaded by a major airborne operation in the Netherlands ended with a failure. After that, the Western Allies slowly pushed into Germany, unsuccessfully trying to cross the Rur river in a large offensive. In Italy the Allied advance also slowed down, when they ran into the last major German defensive line.
On 22 June, the Soviets launched a strategic offensive in Belarus (known as "Operation Bagration") that resulted in the almost complete destruction of the German Army Group Centre. Soon after that, another Soviet strategic offensive forced German troops from Western Ukraine and Eastern Poland. The successful advance of Soviet troops prompted resistance forces in Poland to initiate several uprisings. Though, the largest of these in Warsaw, where German soldiers massacred 200,000 civilians, as well as a national Slovak Uprising in the south did not receive Soviet support, and were put down by German forces. The Red Army's strategic offensive in eastern Romania cut off and destroyed the considerable German troops there and triggered a successful coup d'état in Romania and in Bulgaria, followed by those countries' shift to the Allied side.
In September 1944, Soviet Red Army troops advanced into Yugoslavia and forced the rapid withdrawal of the German Army Groups E and F in Greece, Albania and Yugoslavia to rescue them from being cut off. By this point, the Communist-led Partisans under Marshal Josip Broz Tito, who had led an increasingly successful guerrilla campaign against the occupation since 1941, controlled much of the territory of Yugoslavia and were engaged in delaying efforts against the German forces further south. In northern Serbia, the Red Army, with limited support from Bulgarian forces, assisted the Partisans in a joint liberation of the capital city of Belgrade on 20 October. A few days later, the Soviets launched a massive assault against German-occupied Hungary that lasted until the fall of Budapest in February 1945. In contrast with impressive Soviet victories in the Balkans, the bitter Finnish resistance to the Soviet offensive in the Karelian Isthmus denied the Soviets occupation of Finland and led to the signing of Soviet-Finnish armistice on relatively mild conditions, with a subsequent shift to the Allied side by Finland.
By the start of July, Commonwealth forces in Southeast Asia had repelled the Japanese sieges in Assam, pushing the Japanese back to the Chindwin River while the Chinese captured Myitkyina. In China, the Japanese were having greater successes, having finally captured Changsha in mid-June and the city of Hengyang by early August. Soon after, they further invaded the province of Guangxi, winning major engagements against Chinese forces at Guilin and Liuzhou by the end of November and successfully linking up their forces in China and Indochina by the middle of December.
In the Pacific, American forces continued to press back the Japanese perimeter. In mid-June 1944 they began their offensive against the Mariana and Palau islands, and decisively defeated Japanese forces in the Battle of the Philippine Sea. These defeats led to the resignation of the Japanese Prime Minister, Hideki Tojo, and provided the United States with air bases to launch intensive heavy bomber attacks on the Japanese home islands. In late October, American forces invaded the Filipino island of Leyte; soon after, Allied naval forces scored another large victory during the Battle of Leyte Gulf, one of the largest naval battles in history.
Axis collapse, Allied victory (1944–45).
On 16 December 1944, Germany attempted its last desperate measure for success on the Western Front by using most of its remaining reserves to launch a massive counter-offensive in the Ardennes to attempt to split the Western Allies, encircle large portions of Western Allied troops and capture their primary supply port at Antwerp to prompt a political settlement. By January, the offensive had been repulsed with no strategic objectives fulfilled. In Italy, the Western Allies remained stalemated at the German defensive line. In mid-January 1945, the Soviets and Poles attacked in Poland, pushing from the Vistula to the Oder river in Germany, and overran East Prussia. On 4 February, US, British, and Soviet leaders met for the Yalta Conference. They agreed on the occupation of post-war Germany, and on when the Soviet Union would join the war against Japan.
In February, the Soviets entered Silesia and Pomerania, while Western Allies entered western Germany and closed to the Rhine river. By March, the Western Allies crossed the Rhine north and south of the Ruhr, encircling the German Army Group B, while the Soviets advanced to Vienna. In early April, the Western Allies finally pushed forward in Italy and swept across western Germany, while Soviet and Polish forces stormed Berlin in late April. The American and Soviet forces linked up on Elbe river on 25 April. On 30 April 1945, the Reichstag was captured, signalling the military defeat of the Third Reich.
Several changes in leadership occurred during this period. On 12 April, President Roosevelt died and was succeeded by Harry Truman. Benito Mussolini was killed by Italian partisans on 28 April. Two days later, Hitler committed suicide, and was succeeded by Grand Admiral Karl Dönitz.
German forces surrendered in Italy on 29 April. Total and unconditional surrender was signed on 7 May, to be effective by the end of 8 May. German Army Group Centre resisted in Prague until 11 May.
In the Pacific theatre, American forces accompanied by the forces of the Philippine Commonwealth advanced in the Philippines, clearing Leyte by the end of April 1945. They landed on Luzon in January 1945 and captured Manila in March following a battle which reduced the city to ruins. Fighting continued on Luzon, Mindanao, and other islands of the Philippines until the end of the war. On the night of 9–10 March, B-29 bombers of the US Army Air Forces struck Tokyo with incendiary bombs, which killed 100,000 people within a few hours. Over the next five months, American bombers firebombed 66 other Japanese cities, causing the destruction of untold numbers of buildings and the deaths of between 350,000–500,000 Japanese civilians.
In May 1945, Australian troops landed in Borneo, over-running the oilfields there. British, American, and Chinese forces defeated the Japanese in northern Burma in March, and the British pushed on to reach Rangoon by 3 May. Chinese forces started to counterattack in Battle of West Hunan that occurred between 6 April and 7 June 1945. American forces also moved towards Japan, taking Iwo Jima by March, and Okinawa by the end of June. At the same time American bombers were destroying Japanese cities, American submarines cut off Japanese imports, drastically reducing Japan's ability to supply its overseas forces.
On 11 July, Allied leaders met in Potsdam, Germany. They confirmed earlier agreements about Germany, and reiterated the demand for unconditional surrender of all Japanese forces by Japan, specifically stating that "the alternative for Japan is prompt and utter destruction". During this conference, the United Kingdom held its general election, and Clement Attlee replaced Churchill as Prime Minister.
The Allies called for unconditional Japanese surrender in the Potsdam declaration of 27 July, but the Japanese government was internally divided on whether to make peace and did not respond. In early August the United States dropped atomic bombs on the Japanese cities of Hiroshima and Nagasaki. Like the Japanese cities previously bombed by American airmen, the US and its allies justified the atomic bombings as military necessity to avoid invading the Japanese home islands which would cost the lives of between 250,000–500,000 Allied troops and millions of Japanese troops and civilians. Between the two bombings, the Soviets, pursuant to the Yalta agreement, invaded Japanese-held Manchuria, and quickly defeated the Kwantung Army, which was the largest Japanese fighting force. The Red Army also captured Sakhalin Island and the Kuril Islands. On 15 August 1945, Japan surrendered, with the surrender documents finally signed aboard the deck of the American battleship USS "Missouri" on 2 September 1945, ending the war.
Aftermath.
The Allies established occupation administrations in Austria and Germany. The former became a neutral state, non-aligned with any political bloc. The latter was divided into western and eastern occupation zones controlled by the Western Allies and the USSR, accordingly. A denazification program in Germany led to the prosecution of Nazi war criminals and the removal of ex-Nazis from power, although this policy moved towards amnesty and re-integration of ex-Nazis into West German society.
Germany lost a quarter of its pre-war (1937) territory. Among the eastern territories, Silesia, Neumark and most of Pomerania were taken over by Poland, East Prussia was divided between Poland and the USSR, followed by the expulsion of the 9 million Germans from these provinces, as well as the expulsion of 3 million Germans from the Sudetenland in Czechoslovakia to Germany. By the 1950s, every fifth West German was a refugee from the east. The Soviet Union also took over the Polish provinces east of the Curzon line, from which 2 million Poles were expelled; north-east Romania, parts of eastern Finland, and the three Baltic states were also incorporated into the USSR.
In an effort to maintain peace, the Allies formed the United Nations, which officially came into existence on 24 October 1945, and adopted the Universal Declaration of Human Rights in 1948, as a common standard for all member nations. The great powers that were the victors of the war—the United States, Soviet Union, China, Britain, and France—formed the permanent members of the UN's Security Council. The five permanent members remain so to the present, although there have been two seat changes, between the Republic of China and the People's Republic of China in 1971, and between the Soviet Union and its successor state, the Russian Federation, following the dissolution of the Soviet Union. The alliance between the Western Allies and the Soviet Union had begun to deteriorate even before the war was over.
Germany had been "de facto" divided, and two independent states, the Federal Republic of Germany and the German Democratic Republic were created within the borders of Allied and Soviet occupation zones, accordingly. The rest of Europe was also divided into Western and Soviet spheres of influence. Most eastern and central European countries fell into the Soviet sphere, which led to establishment of Communist-led regimes, with full or partial support of the Soviet occupation authorities. As a result, Poland, Hungary, East Germany, Czechoslovakia, Romania, and Albania became Soviet satellite states. Communist Yugoslavia conducted a fully independent policy, causing tension with the USSR.
Post-war division of the world was formalised by two international military alliances, the United States-led NATO and the Soviet-led Warsaw Pact; the long period of political tensions and military competition between them, the Cold War, would be accompanied by an unprecedented arms race and proxy wars.
In Asia, the United States led the occupation of Japan and administrated Japan's former islands in the Western Pacific, while the Soviets annexed Sakhalin and the Kuril Islands. Korea, formerly under Japanese rule, was divided and occupied by the US in the South and the Soviet Union in the North between 1945 and 1948. Separate republics emerged on both sides of the 38th parallel in 1948, each claiming to be the legitimate government for all of Korea, which led ultimately to the Korean War.
In China, nationalist and communist forces resumed the civil war in June 1946. Communist forces were victorious and established the People's Republic of China on the mainland, while nationalist forces retreated to Taiwan in 1949. In the Middle East, the Arab rejection of the United Nations Partition Plan for Palestine and the creation of Israel marked the escalation of the Arab-Israeli conflict. While European colonial powers attempted to retain some or all of their colonial empires, their losses of prestige and resources during the war rendered this unsuccessful, leading to decolonisation.
The global economy suffered heavily from the war, although participating nations were affected differently. The US emerged much richer than any other nation; it had a baby boom and by 1950 its gross domestic product per person was much higher than that of any of the other powers and it dominated the world economy. The UK and US pursued a policy of industrial disarmament in Western Germany in the years 1945–1948. Due to international trade interdependencies this led to European economic stagnation and delayed European recovery for several years.
Recovery began with the mid-1948 currency reform in Western Germany, and was sped up by the liberalisation of European economic policy that the Marshall Plan (1948–1951) both directly and indirectly caused. The post-1948 West German recovery has been called the German economic miracle. Italy also experienced an economic boom and the French economy rebounded. By contrast, the United Kingdom was in a state of economic ruin, and although it received a quarter of the total Marshall Plan assistance, more than any other European country, continued relative economic decline for decades.
The Soviet Union, despite enormous human and material losses, also experienced rapid increase in production in the immediate post-war era. Japan experienced incredibly rapid economic growth, becoming one of the most powerful economies in the world by the 1980s. China returned to its pre-war industrial production by 1952.
Impact.
Casualties and war crimes.
Estimates for the total casualties of the war vary, because many deaths went unrecorded. Most suggest that some 75 million people died in the war, including about 20 million military personnel and 40 million civilians.
Many of the civilians died because of deliberate genocide, massacres, mass-bombing, disease, and starvation.
The Soviet Union lost around 27 million people during the war, including 8.7 million military and 19 million civilian deaths. The largest portion of military dead were 5.7 million ethnic Russians, followed by 1.3 million ethnic Ukrainians. A quarter of the people in the Soviet Union were wounded or killed. Germany sustained 5.3 million military losses, mostly on the Eastern Front and during the final battles in Germany.
Of the total deaths in World War II, approximately 85 percent—mostly Soviet and Chinese—were on the Allied side and 15 percent on the Axis side. Many of these deaths were caused by war crimes committed by German and Japanese forces in occupied territories. An estimated 11 to 17 million civilians died as a direct or indirect result of Nazi ideological policies, including the systematic genocide of around 6 million Jews during the Holocaust, along with a further 5 to 6 million ethnic Poles and other Slavs (including Ukrainians and Belarusians)—Roma, homosexuals, and other ethnic and minority groups.
Roughly 7.5 million civilians died in China under Japanese occupation. Hundreds of thousands (varying estimates) of ethnic Serbs, along with gypsies and Jews, were murdered by the Axis-aligned Croatian Ustaše in Yugoslavia, with retribution-related killings just after the war ended.
The best-known Japanese atrocity was the Nanking Massacre, in which several hundred thousand Chinese civilians were raped and murdered. Between 3 million to more than 10 million civilians, mostly Chinese, were killed by the Japanese occupation forces. Mitsuyoshi Himeta reported 2.7 million casualties occurred during the "Sankō Sakusen". General Yasuji Okamura implemented the policy in Heipei and Shantung.
Axis forces employed biological and chemical weapons. The Imperial Japanese Army used a variety of such weapons during their invasion and occupation of China ("see Unit 731") and in early conflicts against the Soviets. Both the Germans and Japanese tested such weapons against civilians and, sometimes on prisoners of war.
The Soviet Union was responsible for the Katyn massacre of 22,000 Polish officers, and the imprisonment or execution of thousands of political prisoners by the NKVD, in the Baltic states, and eastern Poland annexed by the Red Army.
The mass-bombing of civilian areas, notably the cities of Warsaw, Rotterdam and London; including the aerial targeting of hospitals and fleeing refugees by the German Luftwaffe, along with the bombing of Tokyo, and German cities of Dresden, Hamburg and Cologne by the Western Allies may be considered as war crimes. The latter resulted in the destruction of more than 160 cities and the deaths of more than 600,000 German civilians. However, no positive or specific customary international humanitarian law with respect to aerial warfare existed before or during World War II.
Concentration camps, slave labour, and genocide.
The German Government led by Adolf Hitler and the Nazi Party was responsible for the Holocaust, the killing of approximately 6 million Jews, as well as 2.7 million ethnic Poles, and 4 million others who were deemed "unworthy of life" (including the disabled and mentally ill, Soviet prisoners of war, homosexuals, Freemasons, Jehovah's Witnesses, and Romani) as part of a programme of deliberate extermination. About 12 million, most of whom were Eastern Europeans, were employed in the German war economy as forced labourers.
In addition to Nazi concentration camps, the Soviet gulags (labour camps) led to the death of citizens of occupied countries such as Poland, Lithuania, Latvia, and Estonia, as well as German prisoners of war (POWs) and even Soviet citizens who had been or were thought to be supporters of the Nazis. Sixty percent of Soviet POWs of the Germans died during the war. Richard Overy gives the number of 5.7 million Soviet POWs. Of those, 57 percent died or were killed, a total of 3.6 million. Soviet ex-POWs and repatriated civilians were treated with great suspicion as potential Nazi collaborators, and some of them were sent to the Gulag upon being checked by the NKVD.
Japanese prisoner-of-war camps, many of which were used as labour camps, also had high death rates. The International Military Tribunal for the Far East found the death rate of Western prisoners was 27.1 percent (for American POWs, 37 percent), seven times that of POWs under the Germans and Italians. While 37,583 prisoners from the UK, 28,500 from the Netherlands, and 14,473 from the United States were released after the surrender of Japan, the number of Chinese released was only 56.
According to historian Zhifen Ju, at least five million Chinese civilians from northern China and Manchukuo were enslaved between 1935 and 1941 by the East Asia Development Board, or "Kōain", for work in mines and war industries. After 1942, the number reached 10 million. The US Library of Congress estimates that in Java, between 4 and 10 million "romusha" (Japanese: "manual laborers"), were forced to work by the Japanese military. About 270,000 of these Javanese labourers were sent to other Japanese-held areas in South East Asia, and only 52,000 were repatriated to Java.
On 19 February 1942, Roosevelt signed Executive Order 9066, interning about 100,000 Japanese living on the West Coast. Canada had a similar program. In addition, 14,000 German and Italian citizens who had been assessed as being security risks were also interned.
In accordance with the Allied agreement made at the Yalta Conference millions of POWs and civilians were used as forced labour by the Soviet Union. In Hungary's case, Hungarians were forced to work for the Soviet Union until 1955.
Occupation.
In Europe, occupation came under two forms. In Western, Northern and Central Europe (France, Norway, Denmark, the Low Countries, and the annexed portions of Czechoslovakia) Germany established economic policies through which it collected roughly 69.5 billion reichmarks (27.8 billion US Dollars) by the end of the war, this figure does not include the sizeable plunder of industrial products, military equipment, raw materials and other goods. Thus, the income from occupied nations was over 40 percent of the income Germany collected from taxation, a figure which increased to nearly 40 percent of total German income as the war went on.
In the East, the much hoped for bounties of "Lebensraum" were never attained as fluctuating front-lines and Soviet scorched earth policies denied resources to the German invaders. Unlike in the West, the Nazi racial policy encouraged excessive brutality against what it considered to be the "inferior people" of Slavic descent; most German advances were thus followed by mass executions. Although resistance groups formed in most occupied territories, they did not significantly hamper German operations in either the East or the West until late 1943.
In Asia, Japan termed nations under its occupation as being part of the Greater East Asia Co-Prosperity Sphere, essentially a Japanese hegemony which it claimed was for purposes of liberating colonised peoples. Although Japanese forces were originally welcomed as liberators from European domination in some territories, their excessive brutality turned local public opinion against them within weeks. During Japan's initial conquest it captured 4000000 oilbbl of oil (~5.5×105 tonnes) left behind by retreating Allied forces, and by 1943 was able to get production in the Dutch East Indies up to , 76 percent of its 1940 output rate.
Home fronts and production.
In Europe, before the outbreak of the war, the Allies had significant advantages in both population and economics. In 1938, the Western Allies (United Kingdom, France, Poland and British Dominions) had a 30 percent larger population and a 30 percent higher gross domestic product than the European Axis (Germany and Italy); if colonies are included, it then gives the Allies more than a 5:1 advantage in population and nearly 2:1 advantage in GDP. In Asia at the same time, China had roughly six times the population of Japan, but only an 89 percent higher GDP; this is reduced to three times the population and only a 38 percent higher GDP if Japanese colonies are included.
Though the Allies' economic and population advantages were largely mitigated during the initial rapid blitzkrieg attacks of Germany and Japan, they became the decisive factor by 1942, after the United States and Soviet Union joined the Allies, as the war largely settled into one of attrition. While the Allies' ability to out-produce the Axis is often attributed to the Allies having more access to natural resources, other factors, such as Germany and Japan's reluctance to employ women in the labour force, Allied strategic bombing, and Germany's late shift to a war economy contributed significantly. Additionally, neither Germany nor Japan planned to fight a protracted war, and were not equipped to do so. To improve their production, Germany and Japan used millions of slave labourers; Germany used about 12 million people, mostly from Eastern Europe, while Japan used more than 18 million people in Far East Asia.
Advances in technology and warfare.
Aircraft were used for reconnaissance, as fighters, bombers, and ground-support, and each role was advanced considerably. Innovation included airlift (the capability to quickly move limited high-priority supplies, equipment, and personnel); and of strategic bombing (the bombing of enemy industrial and population centres to destroy the enemy's ability to wage war). Anti-aircraft weaponry also advanced, including defences such as radar and surface-to-air artillery, such as the German 88 mm gun. The use of the jet aircraft was pioneered and, though late introduction meant it had little impact, it led to jets becoming standard in air forces worldwide.
Advances were made in nearly every aspect of naval warfare, most notably with aircraft carriers and submarines. Although aeronautical warfare had relatively little success at the start of the war, actions at Taranto, Pearl Harbor, and the Coral Sea established the carrier as the dominant capital ship in place of the battleship.
In the Atlantic, escort carriers proved to be a vital part of Allied convoys, increasing the effective protection radius and helping to close the Mid-Atlantic gap. Carriers were also more economical than battleships due to the relatively low cost of aircraft and their not requiring to be as heavily armoured. Submarines, which had proved to be an effective weapon during the First World War, were anticipated by all sides to be important in the second. The British focused development on anti-submarine weaponry and tactics, such as sonar and convoys, while Germany focused on improving its offensive capability, with designs such as the Type VII submarine and wolfpack tactics. Gradually, improving Allied technologies such as the Leigh light, hedgehog, squid, and homing torpedoes proved victorious.
Land warfare changed from the static front lines of World War I to increased mobility and combined arms. The tank, which had been used predominantly for infantry support in the First World War, had evolved into the primary weapon. In the late 1930s, tank design was considerably more advanced than it had been during World War I, and advances continued throughout the war with increases in speed, armour and firepower.
At the start of the war, most commanders thought enemy tanks should be met by tanks with superior specifications. This idea was challenged by the poor performance of the relatively light early tank guns against armour, and German doctrine of avoiding tank-versus-tank combat. This, along with Germany's use of combined arms, were among the key elements of their highly successful blitzkrieg tactics across Poland and France. Many means of destroying tanks, including indirect artillery, anti-tank guns (both towed and self-propelled), mines, short-ranged infantry antitank weapons, and other tanks were utilised. Even with large-scale mechanisation, infantry remained the backbone of all forces, and throughout the war, most infantry were equipped similarly to World War I.
The portable machine gun spread, a notable example being the German MG34, and various submachine guns which were suited to close combat in urban and jungle settings. The assault rifle, a late war development incorporating many features of the rifle and submachine gun, became the standard postwar infantry weapon for most armed forces.
Most major belligerents attempted to solve the problems of complexity and security involved in using large codebooks for cryptography by designing ciphering machines, the most well known being the German Enigma machine. Development of SIGINT ("sig"nals "int"elligence) and cryptanalysis enabled the countering process of decryption. Notable examples were the Allied decryption of Japanese naval codes and British Ultra, a pioneering method for decoding Enigma benefiting from information given to Britain by the Polish Cipher Bureau, which had been decoding early versions of Enigma before the war. Another aspect of military intelligence was the use of deception, which the Allies used to great effect, such as in operations Mincemeat and Bodyguard. Other technological and engineering feats achieved during, or as a result of, the war include the world's first programmable computers (Z3, Colossus, and ENIAC), guided missiles and modern rockets, the Manhattan Project's development of nuclear weapons, operations research and the development of artificial harbours and oil pipelines under the English Channel.

</doc>
<doc id="32961" url="http://en.wikipedia.org/wiki?curid=32961" title="Wine">
Wine

Wine is an alcoholic beverage made from fermented grapes or other fruits. Due to the natural chemical balance, grapes ferment without the addition of sugars, acids, enzymes, water, or other nutrients. Yeast consumes the sugar in the grapes and converts it to ethanol and carbon dioxide. Different varieties of grapes and strains of yeasts produce different styles of wine. The well-known variations result from the very complex interactions between the biochemical development of the fruit, reactions involved in fermentation, terroir and subsequent appellation, along with human intervention in the overall process.
Wine has been produced for thousands of years. The earliest evidence of wine to date was found in Republic of Georgia, where 8,000-year-old wine jars were uncovered. Traces of wine have also been found in Iran with 7,000-year-old wine jars and in Armenia with the 6,100-year-old Areni-1 winery, which is by far considered to be the earliest known winery. The earliest form of grape-based fermented drink however, was found in northern China, where archaeologists discovered 9,000-year-old pottery jars. Wine had reached the Balkans by c. 4500 BC and was consumed and celebrated in ancient Greece and Rome. It has been consumed for its intoxicating effects throughout history and the psychoactive effects are evident at normal serving sizes.
Wines made from produce besides grapes include rice wine, pomegranate wine, apple wine and elderberry wine and are generically called fruit wine.
Wine has played an important role in religion. Red wine was associated with blood by the ancient Egyptians and was used by both the Greek cult of Dionysus and the Romans in their Bacchanalia; Judaism also incorporates it in the Kiddush and Christianity in the Eucharist.
Etymology.
The English word "wine" comes from the Proto-Germanic "*winam", an early borrowing from the Latin "vinum", "wine" or "(grape) vine", itself derived from the Proto-Indo-European stem *"win-o-" (cf. Armenian: գինի , "gini"; Ancient Greek: οἶνος "oinos"; Aeolic Greek: ϝοῖνος "woinos"; Hittite: "wiyana"; Lycian: "oino").
The earliest attested terms referring to wine are the Mycenaean Greek 𐀕𐀶𐀺𐄀𐀚𐀺 "me-tu-wo ne-wo" (*μέθυϝος νέϝῳ), meaning "in (the month)" or "(festival) of the new wine", and 𐀺𐀜𐀷𐀴𐀯 "wo-no-wa-ti-si", meaning "wine garden", written in Linear B inscriptions. Linear B also includes, inter alia, an ideogram for wine, i.e. 𐂖.
Some scholars have noted the similarities between the words for wine in Indo-European languages (e.g. Armenian "gini", Latin "vinum", Ancient Greek οἶνος, Russian вино ]), Kartvelian (e.g. Georgian ღვინო ]), and Semitic ("*wayn"; Hebrew יין ]), pointing to the possibility of a common origin of the word denoting "wine" in these language families. The Georgian word goes back to Proto-Kartvelian *"ɣwino"-, which is generally believed to be a borrowing from Proto-Indo-European. Another hypothesis is that the lexeme was borrowed from Proto-Armenian *"ɣʷeinyo"-, whence Armenian "gini", but this is disputed. On the other hand, Fähnrich considers *"ɣwino"- a native Kartvelian word derived from the verbal root *"ɣun"- ('to bend'). See *"ɣwino"- for more.
Wines from other fruits, such as apples and berries, are usually named after the fruit from which they are produced combined with the word "wine" (for example, apple wine and elderberry wine) and are generically called fruit wine or country wine (not to be confused with the French term "vin de pays"). Besides the grape varieties traditionally used for winemaking, most fruits naturally lack either a high amount of fermentable sugars, relatively low acidity, yeast nutrients needed to promote or maintain fermentation or a combination of these three characteristics. This is probably one of the main reasons why wine derived from grapes has historically been more prevalent by far than other types and why specific types of fruit wine have generally been confined to regions in which the fruits were native or introduced for other reasons.
Other wines, such as barley wine and rice wine (e.g. sake), are made from starch-based materials and resemble beer more than wine, while ginger wine is fortified with brandy. In these latter cases, the term "wine" refers to the similarity in alcohol content rather than to the production process. The commercial use of the English word "wine" (and its equivalent in other languages) is protected by law in many jurisdictions.
History.
Archaeological evidence has established the earliest-known production of wine from fermenting grapes during the late Neolithic or early Chalcolithic in the Caucasus and the northern edge of the Middle East. The earliest chemically attested grape wine in the world was discovered at Hajji Firuz in the northwestern Zagros Mountains of Iran, ca. 5400 BC. Both archaeological and genetic evidence suggest that the earliest production of wine may slightly predate this, and the earliest wine making likely have taken place in Trans-Caucasia (including Armenia, Georgia, Azerbaijan), through the Armenian Highlands region between Eastern Turkey, and North West Iran.
The earliest form of grape-based fermented drink was found in northern China, where archaeologists discovered 9,000-year-old pottery jars, while the earliest archaeological evidence of wine particles found has been in Georgia, where archaeologists discovered evidence of wine residue inside ceramic jars that were dated back some 8000 years and Iran (c. 5000 BC). The earliest evidence of wine production was discovered in Armenia within the Areni-1 winery in 2007 and is at least 6,100 years old, making it the oldest winery in the world. The development of a winery implies wine had started being produced much earlier.
A 2003 report by archaeologists indicates a possibility that grapes were mixed with rice to produce mixed fermented beverages in China in the early years of the seventh millennium BC. Pottery jars from the Neolithic site of Jiahu, Henan, contained traces of tartaric acid and other organic compounds commonly found in wine. However, other fruits indigenous to the region, such as hawthorn, cannot be ruled out. If these beverages, which seem to be the precursors of rice wine, included grapes rather than other fruits, they would have been any of the several dozen indigenous wild species in China, rather than "Vitis vinifera", which was introduced there 6,000 years later.
The spread of wine culture westwards was most probably due to the Phoenicians who spread outward from a base of city-states along the Lebanese and Israeli coast. The wines of Byblos were exported to Egypt during the Old Kingdom and then throughout the Mediterranean. Evidence includes two Phoenician shipwrecks from 750 BC discovered by Robert Ballard, whose cargo of wine was still intact. As the first great traders in wine ("cherem"), the Phoenicians seem to have protected it from oxidation with a layer of olive oil, followed by a seal of pinewood and resin, again similar to retsina.
Literary references to wine are abundant in Homer (8th century BC, but possibly relating earlier compositions), Alkman (7th century BC), and others. In ancient Egypt, six of 36 wine amphoras were found in the tomb of King Tutankhamun bearing the name "Kha'y", a royal chief vintner. Five of these amphoras were designated as originating from the king's personal estate, with the sixth from the estate of the royal house of Aten. Traces of wine have also been found in central Asian Xinjiang in modern-day China, dating from the second and first millennia BC.
The first known mention of grape-based wines in India is from the late 4th-century BC writings of Chanakya, the chief minister of Emperor Chandragupta Maurya. In his writings, Chanakya condemns the use of alcohol while chronicling the emperor and his court's frequent indulgence of a style of wine known as "madhu".
The ancient Romans planted vineyards near garrison towns so wine could be produced locally rather than shipped over long distances. Some of these areas are now world renowned for wine production. The Romans discovered that burning sulfur candles inside empty wine vessels keeps them fresh and free from a vinegar smell. In medieval Europe, the Roman Catholic Church supported wine because the clergy required it for the Mass. Monks in France made wine for years, aging it in caves. An old English recipe that survived in various forms until the 19th century calls for refining white wine from bastard—bad or tainted "bastardo" wine.
Grape varieties.
Wine is usually made from one or more varieties of the European species "Vitis vinifera", such as Pinot noir, Chardonnay, Cabernet Sauvignon, Gamay and Merlot. When one of these varieties is used as the predominant grape (usually defined by law as minimums of 75% to 85%), the result is a "varietal" as opposed to a "blended" wine. Blended wines are not considered inferior to varietal wines, rather they are a different style of winemaking; some of the world's most highly regarded wines, from regions like Bordeaux and the Rhone Valley, are blended from different grape varieties.
Wine can also be made from other species of grape or from hybrids, created by the genetic crossing of two species. "V. labrusca" (of which the Concord grape is a cultivar), "V. aestivalis", "V. ruprestris", "V. rotundifolia" and "V. riparia" are native North American grapes usually grown to eat fresh or for grape juice, jam, or jelly, and only occasionally made into wine.
Hybridization is different from grafting. Most of the world's vineyards are planted with European "V. vinifera" vines that have been grafted onto North American species' rootstock, a common practice due to their resistance to phylloxera, a root louse that eventually kills the vine. In the late 19th century, most of Europe's vineyards (excluding some of the driest in the south) were devastated by the infestation, leading to widespread vine deaths and eventual replanting. Grafting is done in every wine-producing region in the world except in Argentina, the Canary Islands and Chile—the only places not yet exposed to the insect.
In the context of wine production, "terroir" is a concept that encompasses the varieties of grapes used, elevation and shape of the vineyard, type and chemistry of soil, climate and seasonal conditions, and the local yeast cultures. The range of possible combinations of these factors can result in great differences among wines, influencing the fermentation, finishing, and aging processes as well. Many wineries use growing and production methods that preserve or accentuate the aroma and taste influences of their unique "terroir". However, flavor differences are less desirable for producers of mass-market table wine or other cheaper wines, where consistency takes precedence. Such producers try to minimize differences in sources of grapes through production techniques such as micro-oxygenation, tannin filtration, cross-flow filtration, thin-film evaporation,
and spinning cones.
Classification.
Regulations govern the classification and sale of wine in many regions of the world. European wines tend to be classified by region (e.g. Bordeaux, Rioja and Chianti), while non-European wines are most often classified by grape (e.g. Pinot noir and Merlot). Market recognition of particular regions has recently been leading to their increased prominence on non-European wine labels. Examples of recognized non-European locales include Napa Valley, Santa Clara Valley and Sonoma Valley in California; Willamette Valley and Rogue Valley in Oregon; Columbia Valley in Washington; Barossa Valley in South Australia and Hunter Valley in New South Wales; Luján de Cuyo in Argentina; Central Valley in Chile; Vale dos Vinhedos in Brazil; Hawke's Bay and Marlborough in New Zealand; and Okanagan Valley and Niagara Peninsula in Canada.
Some blended wine names are marketing terms whose use is governed by trademark law rather than by specific wine laws. For example, Meritage (sounds like "heritage") is generally a Bordeaux-style blend of Cabernet Sauvignon and Merlot, but may also include Cabernet Franc, Petit Verdot, and Malbec. Commercial use of the term Meritage is allowed only via licensing agreements with the Meritage Association.
European classifications.
France has various appellation systems based on the concept of "terroir", with classifications ranging from "Vin de Table" ("table wine") at the bottom, through "Vin de Pays" and "Appellation d'Origine Vin Délimité de Qualité Supérieure" (AOVDQS), up to "Appellation d'Origine Contrôlée" (AOC) or similar, depending on the region. Portugal has developed a system resembling that of France and, in fact, pioneered this concept in 1756 with a royal charter creating the Demarcated Douro Region and regulating the production and trade of wine. Germany created a similar scheme in 2002, although it has not yet achieved the authority of the other countries' classification systems. Spain, Greece and Italy have classifications based on a dual system of region of origin and product quality.
Beyond Europe.
New World wines—those made outside the traditional wine regions of Europe—are usually classified by grape rather than by "terroir" or region of origin, although there have been unofficial attempts to classify them by quality.
Vintages.
In the United States, for a wine to be vintage-dated and labeled with a country of origin or American Viticultural Area (AVA) (e.g. Sonoma Valley), 95% of its volume must be from grapes harvested in that year. If a wine is not labeled with a country of origin or AVA the percentage requirement is lowered to 85%.
Vintage wines are generally bottled in a single batch so that each bottle will have a similar taste. Climate's impact on the character of a wine can be significant enough to cause different vintages from the same vineyard to vary dramatically in flavor and quality. Thus, vintage wines are produced to be individually characteristic of the particular vintage and to serve as the flagship wines of the producer. Superior vintages from reputable producers and regions will often command much higher prices than their average ones. Some vintage wines (e.g. Brunello), are only made in better-than-average years.
For consistency, non-vintage wines can be blended from more than one vintage, which helps winemakers sustain a reliable market image and maintain sales even in bad years. One recent study suggests that for the average wine drinker, the vintage year may not be as significant for perceived quality as had been thought, although wine connoisseurs continue to place great importance on it.
Tasting.
Wine tasting is the sensory examination and evaluation of wine. Wines contain many chemical compounds similar or identical to those in fruits, vegetables, and spices. The sweetness of wine is determined by the amount of residual sugar in the wine after fermentation, relative to the acidity present in the wine. Dry wine, for example, has only a small amount of residual sugar.
Some wine labels suggest opening the bottle and letting the wine "breathe" for a couple of hours before serving, while others recommend drinking it immediately. Decanting (the act of pouring a wine into a special container just for breathing) is a controversial subject among wine enthusiasts. In addition to aeration, decanting with a filter allows the removal of bitter sediments that may have formed in the wine. Sediment is more common in older bottles, but aeration may benefit younger wines.
During aeration, a younger wine's exposure to air often "relaxes" the drink, making it smoother and better integrated in aroma, texture, and flavor. Older wines generally "fade" (lose their character and flavor intensity) with extended aeration. Despite these general rules, breathing does not necessarily benefit all wines. Wine may be tasted as soon as the bottle is opened to determine how long it should be aerated, if at all.
When tasting wine, individual flavors may also be detected, due to the complex mix of organic molecules (e.g. esters and terpenes) that grape juice and wine can contain. Experienced tasters can distinguish between flavors characteristic of a specific grape and flavors that result from other factors in winemaking. Typical intentional flavor elements in wine—chocolate, vanilla, or coffee—are those imparted by aging in oak casks rather than the grape itself.
Vertical and horizontal tasting involves a range of vintages within the same grape and vineyard, or the latter in which there is one vintage from multiple vineyards.
Banana flavors (isoamyl acetate) are the product of yeast metabolism, as are spoilage aromas such as sweaty, barnyard, band-aid (4-ethylphenol and 4-ethylguaiacol), and rotten egg (hydrogen sulfide). Some varieties can also exhibit a mineral flavor due to the presence of water-soluble salts as a result of limestone's presence in the vineyard's soil.
Wine aroma comes from volatile compounds released into the air. Vaporization of these compounds can be accelerated by twirling the wine glass or serving at room temperature. Many drinkers prefer to chill red wines that are already highly aromatic, like Chinon and Beaujolais.
The ideal temperature for serving a particular wine is a matter of debate, but some broad guidelines have emerged that will generally enhance the experience of tasting certain common wines. A white wine should foster a sense of coolness, achieved by serving at "cellar temperature" (13 C). Light red wines drunk young should also be brought to the table at this temperature, where they will quickly rise a few degrees. Red wines are generally perceived best when served "chambré" ("at room temperature"). However, this does not mean the temperature of the dining room—often around (21 C)—but rather the coolest room in the house and, therefore, always slightly cooler than the dining room itself. Pinot noir should be brought to the table for serving at (16 C) and will reach its full bouquet at (18 C). Cabernet Sauvignon, zinfandel, and Rhone varieties should be served at (18 C) and allowed to warm on the table to 21 C for best aroma.
Collecting.
Outstanding vintages from the best vineyards may sell for thousands of dollars per bottle, though the broader term "fine wine" covers those typically retailing in excess of US$30–50. "Investment wines" are considered by some to be Veblen goods: those for which demand increases rather than decreases as their prices rise.
Particular selections have higher value, such as "Verticals", in which a range of vintages of a specific grape and vineyard, are offered. The most notable was a Chateau d'Yquem 135 year vertical containing every vintage from 1860 to 2003 sold for $1.5 million.
The most common wines purchased for investment include those from Bordeaux and Burgundy; cult wines from Europe and elsewhere; and vintage port. Characteristics of highly collectible wines include:
Investment in fine wine has attracted those who take advantage of their victims' relative ignorance of this wine market sector. Such wine fraudsters often profit by charging excessively high prices for off-vintage or lower-status wines from well-known wine regions, while claiming that they are offering a sound investment unaffected by economic cycles. As with any investment, thorough research is essential to making an informed decision.
Production.
In 2012, Italy was the top producer of wine in the world, followed by France, Spain, the United States and Argentina.
Wine grapes grow almost exclusively between 30 and 50 degrees latitude north and south of the equator. The world's southernmost vineyards are in the Central Otago region of New Zealand's South Island near the 45th parallel south, and the northernmost are in Flen, Sweden, just north of the 59th parallel north.
Exporting countries.
The UK was the world's largest importer of wine in 2007.
Wine production in the European Union in 2005 and 2006.
2005 Estimate (thousands of hectoliters)
2006 Estimate (thousands of hectoliters)
World production in 2003.
In 2003, world wine production had reached 269 millions of hectoliters. The world's main 15 wine producers were:
The top 5 countries for wine production in 2008.
 Country Wine Production 2009 Percentage of World Total
1 Italy 4,994,940 metric tonnes 18.42%
2 France 4,552,077 metric tonnes 16.79%
3 Spain 3,250,610 metric tonnes 11.99%
4 United States 2,250,000 metric tonnes 8.30%
5 China 1,580,000 metric tonnes 5.82%
Sources: FAOSTAT data 2008 (last accessed by Top 5 of Anything: Nov, 2010)
The Wine Institute, a nonprofit group, tracked that the U.S. has been the largest wine consuming nation in the world since 2010, with residents individually consuming a total of 2.82 gallons a year in 2013, up from under 2 gallons in 1979. Wine shipments within the U.S. from California alone were 215 million cases in 2013, up 3% from the previous year, with an estimated retail value of $23.1 billion, up 5%. All American regions produce wine however, 95% comes from four regions with California as the most prolific producer, followed by Washington, Oregon and New York.
Consumption.
Wine-consumption data from a list of countries by alcohol consumption measured in liters of pure ethyl alcohol consumed per capita in a given year, according to the most recent data from the World Health Organization. The methodology includes persons 15 years of age or older.
Uses.
Wine is a popular and important beverage that accompanies and enhances a wide range of cuisines, from the simple and traditional to the most sophisticated and complex. Wine is important in cuisine not just for its value as a beverage, but as a flavor agent, primarily in stocks and braising, since its acidity lends balance to rich savory or sweet dishes. Wine sauce is an example of a culinary sauce that uses wine as a primary ingredient. Natural wines may exhibit a broad range of alcohol content, from below 9% to above 16% ABV, with most wines being in the 12.5%–14.5% range. Fortified wines (usually with brandy) may contain 20% alcohol or more.
Religious significance.
Ancient religions.
The use of wine in ancient Near Eastern and Ancient Egyptian religious ceremonies was common. Libations often included wine, and the religious mysteries of Dionysus used wine as a sacramental entheogen to induce a mind-altering state.
Judaism.
Wine is an integral part of Jewish laws and traditions. The "Kiddush" is a blessing recited over wine or grape juice to sanctify the Shabbat. On Pesach (Passover) during the Seder, it is a Rabbinic obligation of adults to drink four cups of wine. In the Tabernacle and in the Temple in Jerusalem, the libation of wine was part of the sacrificial service. Note that this does not mean that wine is a symbol of blood, a common misconception that contributes to the Christian myth of the blood libel.
"It has been one of history's cruel ironies that the blood libel—accusations against Jews using the blood of murdered gentile children for the making of wine and matzot—became the false pretext for numerous pogroms. And due to the danger, those who live in a place where blood libels occur are halachically exempted from using red wine, lest it be seized as "evidence" against them."
Christianity.
In Christianity, wine is used in a sacred rite called the Eucharist, which originates in the Gospel account of the Last Supper (Gospel of Luke 22:19) describing Jesus sharing bread and wine with his disciples and commanding them to "do this in remembrance of me." Beliefs about the nature of the Eucharist vary among denominations (see Eucharistic theologies contrasted).
While some Christians consider the use of wine from the grape as essential for the validity of the sacrament, many Protestants also allow (or require) pasteurized grape juice as a substitute. Wine was used in Eucharistic rites by all Protestant groups until an alternative arose in the late 19th century. Methodist dentist and prohibitionist Thomas Bramwell Welch applied new pasteurization techniques to stop the natural fermentation process of grape juice. Some Christians who were part of the growing temperance movement pressed for a switch from wine to grape juice, and the substitution spread quickly over much of the United States, as well as to other countries to a lesser degree. There remains an ongoing debate between some American Protestant denominations as to whether wine can and should be used for the Eucharist or allowed as an ordinary beverage, with Catholics and some mainline Protestants allowing wine drinking in moderation, and some conservative Protestant groups opposing consumption of alcohol altogether.
Islam.
Alcoholic beverages, including wine, are forbidden under most interpretations of Islamic law. Iran had previously had a thriving wine industry that disappeared after the Islamic Revolution in 1979. In Greater Persia, "mey" (Persian wine) was a central theme of poetry for more than a thousand years, long before the advent of Islam. Some Alevi sects use wine in their religious services.
Certain exceptions to the ban on alcohol apply. Alcohol derived from a source other than the grape (or its byproducts) and the date is allowed in "very small quantities" (loosely defined as a quantity that does not cause intoxication) under the Sunni Hanafi "madhab", for specific purposes (such as medicines), where the goal is not intoxication. However, modern Hanafi scholars regard alcohol consumption as totally forbidden.
Health effects.
Studies of the health effects of wine have focused on cardiovascular health, cancer, Alzheimer's disease, alcoholism, cirrhosis of the liver, and oral bacteria. Although excessive alcohol consumption has adverse health effects, epidemiological studies have consistently demonstrated that moderate consumption of alcohol and wine is statistically associated with a decrease in cardiovascular illness such as heart failure. Additional news reports on the French paradox also back the relationship.
This paradox concerns the comparatively low incidence of coronary heart disease in France despite relatively high levels of saturated fat in the traditional French diet. Some epidemiologists suspect that this is due to higher wine consumption by the French, but the scientific evidence for this theory is limited. Because the average moderate wine drinker is likely to exercise more often, to be more health conscious, and to be from a higher educational and socioeconomic background, the association between moderate wine drinking and better health may be related to confounding factors or represent a correlation rather than cause and effect.
Population studies have observed a J-curve correlation between wine consumption and the prevalence of heart disease: heavy drinkers have an elevated prevalence, while moderate drinkers (up to 20g of alcohol per day, approximately 200 ml of 12.7% ABV wine) have a lower prevalence than non-drinkers. Studies have also found that moderate consumption of other alcoholic beverages is correlated with decreased mortality from cardiovascular causes, although the association is stronger for wine. Additionally, some studies have found a greater correlation of health benefits with red than white wine, though other studies have found no difference. Red wine contains more polyphenols than white wine, and these could be protective against cardiovascular disease.
A chemical in grapes, red wine, peanuts and blueberries called resveratrol has been shown to have both cardioprotective and chemoprotective effects in animal studies. Low doses of resveratrol in the diet of middle-aged mice has a widespread influence on the genetic factors related to aging and may confer special protection on the heart. Specifically, low doses of resveratrol mimic the effects of caloric restriction—diets with 20–30% fewer calories than a typical diet. Resveratrol is produced naturally by grape skins in response to fungal infection, including exposure to yeast during fermentation. As white wine has minimal contact with grape skins during this process, it generally contains lower levels of the chemical. Beneficial compounds in wine also include other polyphenols, antioxidants, and flavonoids.
Sipping slowly when drinking may result in optimal absorption of the resveratrol in wine. Due to inactivation in the gut and liver, most of the resveratrol consumed while drinking red wine does not reach the blood circulation. However, when sipping slowly, absorption via the mucous membranes in the mouth can result in up to 100 times the blood levels of resveratrol, according to Stephen Taylor, Ph.D.
Red wines from the south of France and from Sardinia in Italy have the highest levels of procyanidins, compounds in grape seeds which could be responsible for red wine's heart benefits. Red wines from these areas contain between two and four times as much procyanidins as other red wines tested. Procyanidins suppress the synthesis of a peptide called endothelin-1 that constricts blood vessels.
A 2007 study found that both red and white wines are effective antibacterial agents against strains of "Streptococcus". In addition, a report in the October 2008 issue of "Cancer Epidemiology, Biomarkers and Prevention" posits that moderate consumption of red wine may decrease the risk of lung cancer in men.
While evidence from laboratory and epidemiological (observational) studies suggest a cardioprotective effect, no controlled studies have been completed on the effect of alcoholic beverages on the risk of developing heart disease or stroke. Excessive consumption of alcohol can cause cirrhosis of the liver and alcoholism; the American Heart Association states that "the American Heart Association cautions people NOT to start drinking ... if they do not already drink alcohol. Consult your doctor on the benefits and risks of consuming alcohol in moderation."
Wine's effect on the brain is also under study. One study concluded that wine made from the Cabernet Sauvignon grape reduces the risk of Alzheimer's Disease. Another study found that among alcoholics, wine damages the hippocampus, a brain area involved in memory processes, to a greater degree than other alcoholic beverages.
Sulfites in wine can cause some people, particularly those with asthma, to have adverse reactions. Sulfites are present in all wines and are formed as a natural product of the fermentation process; many winemakers add sulfur dioxide in order to help preserve wine. Sulfur dioxide is also added to foods such as dried apricots and orange juice. The level of added sulfites varies; some wines have been marketed with low sulfite content.
A study of women in the United Kingdom, called The Million Women Study, concluded that moderate alcohol consumption can increase the risk of certain cancers, including breast, pharynx and liver cancer. Lead author of the study, Professor Valerie Beral, asserted that there is scant evidence that any positive health effects of red wine outweigh the risk of cancer. She said, "It's an absolute myth that red wine is good for you." Professor Roger Corder, author of the bestselling book"The Red Wine Diet", countered that two small glasses of a very tannic, procyanidin-rich wine would confer a benefit, although "most supermarket wines are low-procyanidin and high-alcohol." No professional medical association recommends that people who are nondrinkers should start drinking wine.
Forgery and manipulation of wines.
Incidents of fraud, such as mislabeling the origin or quality of wines, have resulted in regulations on labeling. "Wine scandals" that have received media attention include:
Packaging.
Most wines are sold in glass bottles and sealed with corks (50% of which come from Portugal). An increasing number of wine producers have been using alternative closures such as screwcaps and synthetic plastic "corks". Although alternative closures are less expensive and prevent cork taint, they have been blamed for such problems as excessive reduction.
Some wines are packaged in thick plastic bags within corrugated fiberboard boxes, and are called "box wines", or "cask wine". Tucked inside the package is a tap affixed to the bag in box, or bladder, that is later extended by the consumer for serving the contents. Box wine can stay acceptably fresh for up to a month after opening because the bladder collapses as wine is dispensed, limiting contact with air and, thus, slowing the rate of oxidation. In contrast, bottled wine oxidizes more rapidly after opening because of the increasing ratio of air to wine as the contents are dispensed; it can degrade considerably in a few days.
Environmental considerations of wine packaging reveal benefits and drawbacks of both bottled and box wines. The glass used to make bottles is a nontoxic, naturally occurring substance that is completely recyclable, whereas the plastics used for box-wine containers are typically much less environmentally friendly. However, wine-bottle manufacturers have been cited for Clean Air Act violations. A "New York Times" editorial suggested that box wine, being lighter in package weight, has a reduced carbon footprint from its distribution; however, box-wine plastics, even though possibly recyclable, can be more labor-intensive (and therefore expensive) to process than glass bottles. In addition, while a wine box is recyclable, its plastic bladder most likely is not.
Storage.
Wine cellars, or wine rooms, if they are above-ground, are places designed specifically for the storage and aging of wine. In an "active" wine cellar, temperature and humidity are maintained by a climate-control system. "Passive" wine cellars are not climate-controlled, and so must be carefully located. Because wine is a natural, perishable food product, all types—including red, white, sparkling, and fortified—can spoil when exposed to heat, light, vibration or fluctuations in temperature and humidity. When properly stored, wines can maintain their quality and in some cases improve in aroma, flavor, and complexity as they age. Some wine experts contend that the optimal temperature for aging wine is 13 C, others 15 C.
Wine refrigerators offer an alternative to wine cellars and are available in capacities ranging from small, 16-bottle units to furniture-quality pieces that can contain 400 bottles. Wine refrigerators are not ideal for aging, but rather serve to chill wine to the perfect temperature for drinking. These refrigerators keep the humidity low (usually under 50%), below the optimal humidity of 50% to 70%. Lower humidity levels can dry out corks over time, allowing oxygen to enter the bottle, which reduces the wine's quality through oxidation.
Further reading.
</dl>

</doc>
<doc id="32975" url="http://en.wikipedia.org/wiki?curid=32975" title="Worldcon">
Worldcon

Worldcon, or more formally the World Science Fiction Convention, the annual convention of the World Science Fiction Society (WSFS), is a science fiction convention. It has been held each year since 1939 (except for the years 1942 to 1945, during World War II). The members of each Worldcon are the members of WSFS, and vote both to select the site of the Worldcon two years later, and to select the winners of the annual Hugo Awards, which are presented at each convention.
Activities.
Activities and events at the convention typically include (but are not limited to):
Awards.
The World Science Fiction Society administers and presents the Hugo Awards, the oldest and most noteworthy award for science fiction. Selection of the recipients is by vote of the Worldcon members. Categories include novels and short fiction, artwork, dramatic presentations, and various professional and fandom activities.
Other awards may be presented at Worldcon at the discretion of the individual convention committee. This has often included the national SF awards of the host country, including the Japanese Seiun Awards as part of Nippon 2007, and the Prix Aurora Awards as part of Anticipation in 2009. The John W. Campbell Award for Best New Writer and the Sidewise Award, though not sponsored by the Worldcon, are usually presented, as well as the Chesley Awards, the Prometheus Award, and others.
Guests of Honor.
Each Worldcon committee selects a number of guests of honor (or "GoHs") for the convention. Typically there is an author (aka "Writer" or "Pro") and a fan guest of honor. Many conventions also have artist, editor, and science guests, and most have a toastmaster for major events, such as the opening and closing ceremonies and the Hugo award ceremony. A few conventions have had two or even three author guests.
While other conventions may select guests on the basis of current popularity, Worldcons typically select guests of honor as an acknowledgement of significant lifetime contribution to the field; while these are often well-known figures, some committees choose lesser-known figures precisely because the committee feels the guest's accomplishments deserve more recognition from the community. Selection is treated by authors, fans, and others as a recognition of lifetime achievement. As such, the tradition is to award it only to those who have been making significant contributions for at least 20 years. Guests of honor generally receive travel expenses, membership, and a small "per diem" from the convention, but no speaking fees.
In order to announce guests immediately after site selection, Worldcon bid committees select one or more guests "before" the site selection vote. Fans consider it inappropriate for bids to compete on the basis of their chosen guests (so as to avoid having someone chosen by a losing bid feeling that fandom had voted against them personally), so bids do not reveal who their guests are until after the vote, and losing bids generally never reveal who they invited. This is usually treated with the same discretion as the Hugo Awards, where only a few people might know in advance who the guests will be.
World Science Fiction Society.
The name "Worldcon" is owned by the World Science Fiction Society (WSFS), an unincorporated literary society whose purpose is to promote interest in science fiction. WSFS has no standing officers, only small standing committees, and a large membership composed of the members of the current Worldcon. Its main activities are running the selection (voting) process for the annual convention and various awards. The conventions themselves are run by non-profit, volunteer fan organizations, who bid to host the event.
The WSFS constitution itself is discussed and amended by the annual general meeting, known as the "business meeting", held at the Worldcon, usually in three morning sessions on successive days. The WSFS constitution determines the rules for site selection, for the Hugo Awards, and for amending itself. The business meeting also empanels a number of standing or ad hoc committees to deal with review of amendments and with certain administrative functions.
The most important standing committee is the Mark Protection Committee (MPC), which is responsible for maintaining the society's trademarks and domain names.
Site selection.
Most Worldcons are held in North America, although they have also taken place in the United Kingdom, Germany, Australia, the Netherlands, and Japan. In 2015, the 73rd World Science Fiction Convention ("Sasquan") will be held in Spokane, Washington. 
The first Worldcon to be held outside the US was the sixth, in 1948 in Toronto, Canada, and the first outside North America was the 15th World Science Fiction Convention, in 1957 in Bayswater, London. The 2007 Worldcon in Yokohama, Japan, was the first to be held in Asia. Other non-US Worldcons have included the 2005 Worldcon, held in Glasgow, Scotland; the 2009 Worldcon, in Montreal, Quebec, Canada; the 2010 Worldcon, in Melbourne, Australia; and the 2014 Worldcon, in London, United Kingdom.
Sites for future Worldcons are determined by voting of the Worldcon membership. Worldcons through 1970 were selected one year in advance, from 1971 through 1986 two years in advance, from 1987 to 2007, three years in advance, then from 2008 to the present, two years in advance again. For example, during the 2011 Worldcon in Reno, San Antonio was selected to host the 2013 Worldcon. However, rules changes to lengthen or shorten the period were implemented by selecting two future Worldcons at the 1969 and 1984 conventions, or having the 2005 convention not select any. 
To ensure that the Worldcon moves around to different locations, the WSFS constitution requires that the proposed sites must all be at least 500 mi away from the site of the convention at which the selection vote happens. 
When a Worldcon is held outside of North America, a North American Science Fiction Convention (NASFiC) may also be held within North America that same year. Since 1975, whenever a Worldcon site outside North America is selected, WSFS administers a parallel site selection process for the NASFiC, voted on by WSFS members at the Worldcon (or NASFiC if there is one) held one year prior to the prospective NASFiC. With the 2014 Worldcon being held in the United Kingdom, members at the 2013 Worldcon in San Antonio chose Detroit to be the site of the 2014 NASFiC and Spokane, Washington, as the site of the 2015 Worldcon.
Convention committees.
As WSFS itself is an unincorporated society, each Worldcon is organized by a separate committee legally incorporated in the local jurisdiction; in the United States, these are usually set up as 501(c)(3) non-profit corporations. The local organizers may be standalone committees, or they may be organized by an existing local group; a few groups such as MCFI in Boston and SCIFI (Southern California Institute for Fan Interests Inc.), in southern California are permanent corporations set up to run Worldcons (or other one-off or rotating conventions) in different years in the same geographical area. 
Like most non-media science fiction conventions, all Worldcons are run entirely by volunteers, with no paid staff; senior committee members devote hundreds of hours (not to mention thousands of dollars in travel expenses in some cases) in preparation for a particular convention. While each convention is run separately by the local committee, an informal and self-selected group of volunteers constitute the "Permanent Floating Worldcon Committee" who volunteer for many Worldcons in different years; this group offers a measure of institutional continuity to otherwise disparate legal organizations.
Recent Worldcons have had budgets running close to a million dollars. The main source of revenue is convention membership, but Worldcons also collect fees from exhibiting dealers and artists and advertisers in publications, and some conventions manage to attract sponsorships up to 5% of total income. The main expenses are facilities rental and related costs, then (if possible) membership reimbursements to program participants and volunteers, then publications, audiovisual equipment rental, and hospitality. Traditionally, all members (except for guests of honor) must pay for their membership; if the convention makes an adequate surplus after covering operating expenses, full or partial membership reimbursements are paid back to volunteers after the convention. Most Worldcons run a small surplus, which under the rules of WSFS and the non-profit legislation in their jurisdiction, they are required to disburse to qualified organizations; typically half the surplus is donated to future Worldcons, in a tradition called "pass-along funds".
Because of their size, Worldcons have two layers of management between the chair and the staff. "Departments" operate a specific convention function, while "divisions" coordinate the work of several departments. Department heads (sometimes called "area heads") have one or more deputies plus a large staff, or they may have no staff at all. Most Worldcons have between five and twelve division heads who form the convention executive group.
In order for convention staff and members to quickly identify the function of other staff at the convention, Worldcons use ribbons of differing colors which are attached to convention badges to signify different roles and responsibilities. Often there are ribbons to signify rank, division, and department or specialized functions; ribbons are also used to identify program participants, other noteworthy members (for example "Past Worldcon Guest of Honor", "Hugo Award Nominee", etc.), or classes of members ("Dealers", "Artists", "Party Hosts") who are interacting with convention staff. Some members of the committee may be performing a variety of current or past roles and could have a large number of ribbons attached to each other hanging from a badge. Extending this tradition, other groups and individuals create more special ribbons for use at the convention; these may be serious or silly. Convention badge ribbons are important memorabilia, and become valuable years later because they evoke memories of events at the convention, and often can be expected to be displayed in exhibits at future conventions. It is commonplace for Worldcon attendees to wear their ribbons from previous Worldcons alongside or below their current Worldcon ribbon, occasionally incurring minor confusion.
There is also a convention badge, displaying each attendee's name, membership number and (if desired) "fannish" nickname. The customary practice is for all attendees at the same convention (occasionally excepting Guests of Honor) to wear badges of the same design, but each Worldcon's badge design is unique to that convention. As with ribbons, Worldcon attendees will often wear their badges from previous Worldcons alongside or below their current badge.

</doc>
<doc id="32977" url="http://en.wikipedia.org/wiki?curid=32977" title="Writing">
Writing

Writing is a medium of human communication that represents language through the inscription or recording of signs and symbols. In most languages, writing is a complement to speech or spoken language. Writing is not a language but a form of technology. Within a language system, writing relies on many of the same structures as speech, such as vocabulary, grammar and semantics, with the added dependency of a system of signs or symbols, usually in the form of a formal alphabet. The result of writing is generally called "text", and the recipient of text is called a reader. Motivations for writing include publication, storytelling, correspondence and diary. Writing has been instrumental in keeping history, dissemination of knowledge through the media and the formation of legal systems.
As human societies emerged, the development of writing was driven by pragmatic exigencies such as exchanging information, maintaining financial accounts, codifying laws and recording history. Around the 4th millennium BCE, the complexity of trade and administration in Mesopotamia outgrew human memory, and writing became a more dependable method of recording and presenting transactions in a permanent form. In both Ancient Egypt and Mesoamerica writing may have evolved through calendrics and a political necessity for recording historical and environmental events.
Means for recording information.
H.G. Wells argued that writing has the ability to "put agreements, laws, commandments on record. It made the growth of states larger than the old city states possible. It made a continuous historical consciousness possible. The command of the priest or king and his seal could go far beyond his sight and voice and could survive his death".
Writing systems.
The major writing systems—methods of inscription—broadly fall into four categories: logographic, syllabic, alphabetic, and featural. Another category, ideographic (symbols for ideas), has never been developed sufficiently to represent language. A sixth category, pictographic, is insufficient to represent language on its own, but often forms the core of logographies.
Logographies.
A logogram is a written character which represents a word or morpheme. A vast number of logograms are needed to write Chinese characters, cuneiform, and Mayan, where a glyph may stand for a morpheme, a syllable, or both - ("logoconsonantal" in the case of hieroglyphs). Many logograms have an ideographic component (Chinese "radicals", hieroglyphic "determiners"). For example, in Mayan, the glyph for "fin", pronounced "ka'", was also used to represent the syllable "ka" whenever the pronunciation of a logogram needed to be indicated, or when there was no logogram. In Chinese, about 90% of characters are compounds of a semantic (meaning) element called a "radical" with an existing character to indicate the pronunciation, called a "phonetic." However, such phonetic elements complement the logographic elements, rather than vice versa.
The main logographic system in use today is Chinese characters, used with some modification for the various languages of China, and for Japanese. Korean, even in South Korea, today uses mainly the phonetic Hangul system.
Syllabaries.
A syllabary is a set of written symbols that represent (or approximate) syllables. A glyph in a syllabary typically represents a consonant followed by a vowel, or just a vowel alone, though in some scripts more complex syllables (such as consonant-vowel-consonant, or consonant-consonant-vowel) may have dedicated glyphs. Phonetically related syllables are not so indicated in the script. For instance, the syllable "ka" may look nothing like the syllable "ki", nor will syllables with the same vowels be similar.
Syllabaries are best suited to languages with a relatively simple syllable structure, such as Japanese. Other languages that use syllabic writing include the Linear B script for Mycenaean Greek; Cherokee; Ndjuka, an English-based creole language of Surinam; and the Vai script of Liberia. Most logographic systems have a strong syllabic component. Ethiopic, though technically an alphabet, has fused consonants and vowels together to the point where it is learned as if it were a syllabary.
Alphabets.
An alphabet is a set of symbols, each of which represents or historically represented a phoneme of the language. In a perfectly phonological alphabet, the phonemes and letters would correspond perfectly in two directions: a writer could predict the spelling of a word given its pronunciation, and a speaker could predict the pronunciation of a word given its spelling.
As languages often evolve independently of their writing systems, and writing systems have been borrowed for languages they were not designed for, the degree to which letters of an alphabet correspond to phonemes of a language varies greatly from one language to another and even within a single language.
Abjads.
In most of the writing systems of the Middle East, it is usually only the consonants of a word that are written, although vowels may be indicated by the addition of various diacritical marks. Writing systems based primarily on marking the consonant phonemes alone date back to the hieroglyphics of ancient Egypt. Such systems are called "abjads", derived from the Arabic word for "alphabet".
Abugidas.
In most of the alphabets of India and Southeast Asia, vowels are indicated through diacritics or modification of the shape of the consonant. These are called "abugidas". Some abugidas, such as Ethiopic and Cree, are learned by children as syllabaries, and so are often called "syllabics". However, unlike true syllabaries, there is not an independent glyph for each syllable.
Sometimes the term "alphabet" is restricted to systems with separate letters for consonants and vowels, such as the Latin alphabet, although abugidas and abjads may also be accepted as alphabets. Because of this use, Greek is often considered to be the first alphabet.
Featural scripts.
A featural script notates the building blocks of the phonemes that make up a language. For instance, all sounds pronounced with the lips ("labial" sounds) may have some element in common. In the Latin alphabet, this is accidentally the case with the letters "b" and "p"; however, labial "m" is completely dissimilar, and the similar-looking "q" and "d" are not labial. In Korean hangul, however, all four labial consonants are based on the same basic element, but in practice, Korean is learned by children as an ordinary alphabet, and the featural elements tend to pass unnoticed.
Another featural script is SignWriting, the most popular writing system for many sign languages, where the shapes and movements of the hands and face are represented iconically. Featural scripts are also common in fictional or invented systems, such as J.R.R. Tolkien's Tengwar.
Historical significance of writing systems.
Historians draw a sharp distinction between prehistory and history, with history defined by the advent of writing. The cave paintings and petroglyphs of prehistoric peoples can be considered precursors of writing, but they are not considered true writing because they did not represent language directly.
Writing systems develop and change based on the needs of the people who use them. Sometimes the shape, orientation, and meaning of individual signs changes over time. By tracing the development of a script, it is possible to learn about the needs of the people who used the script as well as how the script changed over time.
Tools and materials.
The many tools and writing materials used throughout history include stone tablets, clay tablets, bamboo slats, wax tablets, vellum, parchment, paper, copperplate, styluses, quills, ink brushes, pencils, pens, and many styles of lithography. It is speculated that the Incas might have employed knotted cords known as quipu (or khipu) as a writing system.
The typewriter and various forms of word processors have subsequently become widespread writing tools, and various studies have compared the ways in which writers have framed the experience of writing with such tools as compared with the pen or pencil.
History.
Neolithic writing.
By definition, the modern practice of history begins with written records. Evidence of human culture without writing is the realm of prehistory. The Dispilio Tablet (Greece) and Tărtăria tablets (Romania), which have been carbon dated to the 6th millennium BC, are recent discoveries of the earliest known neolithic writings. Szentgyörgyvölgy cow is a world model from B.C. 5500 (25)
Mesopotamia.
While neolithic writing is a current research topic, conventional history assumes that the writing process first evolved from economic necessity in the ancient Near East. Writing most likely began as a consequence of political expansion in ancient cultures, which needed reliable means for transmitting information, maintaining financial accounts, keeping historical records, and similar activities. Around the 4th millennium BC, the complexity of trade and administration outgrew the power of memory, and writing became a more dependable method of recording and presenting transactions in a permanent form.
Archaeologist Denise Schmandt-Besserat determined the link between previously uncategorized clay "tokens", the oldest of which have been found in the Zagros region of Iran, and the first known writing, Mesopotamian cuneiform. In approximately 8000 BC, the Mesopotamians began using clay tokens to count their agricultural and manufactured goods. Later they began placing these tokens inside large, hollow clay containers (bulla, or globular envelopes) which were then sealed. The quantity of tokens in each container came to be expressed by impressing, on the container's surface, one picture for each instance of the token inside. They next dispensed with the tokens, relying solely on symbols for the tokens, drawn on clay surfaces. To avoid making a picture for each instance of the same object (for example: 100 pictures of a hat to represent 100 hats), they 'counted' the objects by using various small marks. In this way the Sumerians added "a system for enumerating objects to their incipient system of symbols".
The original Mesopotamian writing system (believed to be the world's oldest) was derived around 3600 BC from this method of keeping accounts. By the end of the 4th millennium BC, the Mesopotamians were using a triangular-shaped stylus pressed into soft clay to record numbers. This system was gradually augmented with using a sharp stylus to indicate what was being counted by means of pictographs. Round-stylus and sharp-stylus writing was gradually replaced by writing using a wedge-shaped stylus (hence the term cuneiform), at first only for logograms, but by the 29th century BC also for phonetic elements . Around 2700 BC, cuneiform began to represent syllables of spoken Sumerian. About that time, Mesopotamian cuneiform became a general purpose writing system for logograms, syllables, and numbers. This script was adapted to another Mesopotamian language, the East Semitic Akkadian (Assyrian and Babylonian) around 2600 BC, and then to others such as Elamite, Hattian, Hurrian and Hittite. Scripts similar in appearance to this writing system include those for Ugaritic and Old Persian. With the adoption of Aramaic as the 'lingua franca' of the Neo-Assyrian Empire (911-609 BC), Old Aramaic was also adapted to Mesopotamian cuneiform. The last cuneiform scripts in Akkadian discovered thus far date from the 1st century AD.
Elamite scripts.
Over the centuries, three distinct Elamite scripts developed.
Proto-Elamite is the oldest known writing system from Iran. In use only for a brief time (c. 3200–2900 BC), clay tablets with Proto-Elamite writing have been found at different sites across Iran. The Proto-Elamite script is thought to have developed from early cuneiform (proto-cuneiform). The Proto-Elamite script consists of more than 1,000 signs and is thought to be partly logographic.
Linear Elamite is a writing system attested in a few monumental inscriptions in Iran. It was used for a very brief period during the last quarter of the 3rd millennium BC. It is often claimed that Linear Elamite is a syllabic writing system derived from Proto-Elamite, although this cannot be proven since Linear-Elamite has not been deciphered. Several scholars have attempted to decipher the script, most notably Walther Hinz and Piero Meriggi.
The Elamite cuneiform script was used from about 2500 to 331 BC, and was adapted from the Akkadian cuneiform. The Elamite cuneiform script consisted of about 130 symbols, far fewer than most other cuneiform scripts.
Cretan and Greek scripts.
Cretan hieroglyphs are found on artifacts of Crete (early-to-mid-2nd millennium BC, MM I to MM III, overlapping with Linear A from MM IIA at the earliest). Linear B, the writing system of the Mycenaean Greeks, has been deciphered while Linear A has yet to be deciphered. The sequence and the geographical spread of the three overlapping, but distinct writing systems can be summarized as follows: Cretan hieroglyphs were used in Crete from c. 1625 to 1500 BC; Linear A was used in the Aegean Islands (Kea, Kythera, Melos, Thera), and the Greek mainland (Laconia) from c. 18th century to 1450 BC; and Linear B was used in Crete (Knossos), and mainland (Pylos, Mycenae, Thebes, Tiryns) from c. 1375 to 1200 BC.
China.
The earliest surviving examples of writing in China—inscriptions on so-called "oracle bones", tortoise plastrons and ox scapulae used for divination—date from around 1200 BC in the late Shang dynasty. A small number of bronze inscriptions from the same period have also survived.
Historians have found that the type of media used had an effect on what the writing was documenting and how it was used.
In 2003 archaeologists reported discoveries of isolated tortoise-shell carvings dating back to the 7th millennium BC, but whether or not these symbols are related to the characters of the later oracle-bone script is disputed.
Egypt.
The earliest known hieroglyphic inscriptions are the Narmer Palette, dating to c. 3200 BC, and several recent discoveries that may be slightly older, though these glyphs were based on a much older artistic rather than written tradition. The hieroglyphic script was logographic with phonetic adjuncts that included an effective alphabet.
Writing was very important in maintaining the Egyptian empire, and literacy was concentrated among an educated elite of scribes. Only people from certain backgrounds were allowed to train to become scribes, in the service of temple, pharaonic, and military authorities. The hieroglyph system was always difficult to learn, but in later centuries was purposely made even more so, as this preserved the scribes' status.
The world's oldest known alphabet appears to have been developed by Canaanite turquoise miners in the Sinai desert around the mid-19th century BC. Around 30 crude inscriptions have been found at a mountainous Egyptian mining site known as Serabit el-Khadem. This site was also home to a temple of Hathor, the "Mistress of turquoise". A later, two line inscription has also been found at Wadi el-Hol in Central Egypt. Based on hieroglyphic prototypes, but also including entirely new symbols, each sign apparently stood for a consonant rather than a word: the basis of an alphabetic system. It was not until the 12th to 9th centuries, however, that the alphabet took hold and became widely used.
Indus Valley.
Indus script refers to short strings of symbols associated with the Indus Valley Civilization (which spanned modern-day Pakistan and North India) used between 2600 and 1900 BC. In spite of many attempts at decipherments and claims, it is as yet undeciphered. The term 'Indus script' is mainly applied to that used in the mature Harappan phase, which perhaps evolved from a few signs found in early Harappa after 3500 BC, and was followed by the mature Harappan script. The script is written from right to left, and sometimes follows a boustrophedonic style. Since the number of principal signs is about 400–600, midway between typical logographic and syllabic scripts, many scholars accept the script to be logo-syllabic (typically syllabic scripts have about 50–100 signs whereas logographic scripts have a very large number of principal signs). Several scholars maintain that structural analysis indicates that an agglutinative language underlies the script.
Turkmenistan.
Archaeologists have recently discovered that there was a civilization in Central Asia using writing c. 2000 BC. An excavation near Ashgabat, the capital of Turkmenistan, revealed an inscription on a piece of stone that was used as a stamp seal.
Phoenician writing system and descendants.
The Proto-Sinaitic script in which Proto-Canaanite is believed to have been first written, is attested as far back as the 19th century BC. The Phoenician writing system was adapted from the Proto-Canaanite script sometime before the 14th century BC, which in turn borrowed principles of representing phonetic information from Hieratic, Cuneiform and Egyptian hieroglyphics. This writing system was an odd sort of syllabary in which only consonants are represented. This script was adapted by the Greeks, who adapted certain consonantal signs to represent their vowels. The Cumae alphabet, a variant of the early Greek alphabet, gave rise to the Etruscan alphabet, and its own descendants, such as the Latin alphabet and Runes. Other descendants from the Greek alphabet include Cyrillic, used to write Bulgarian, Russian and Serbian among others. The Phoenician system was also adapted into the Aramaic script, from which the Hebrew script and also that of Arabic are descended.
The Tifinagh script (Berber languages) is descended from the Libyco-Berber script which is assumed to be of Phoenician origin.
Mesoamerica.
A stone slab with 3,000-year-old writing, known as the Cascajal Block, was discovered in the Mexican state of Veracruz and is an example of the oldest script in the Western Hemisphere, preceding the oldest Zapotec writing by approximately 500 years. It is thought to be Olmec.
Of several pre-Columbian scripts in Mesoamerica, the one that appears to have been best developed, and the only one to be deciphered, is the Maya script. The earliest inscriptions which are identifiably Maya date to the 3rd century BC. Maya writing used logograms complemented by a set of syllabic glyphs, somewhat similar in function to modern Japanese writing.
South America.
The Incas had no known script. Their quipu system of recording information—based on knots tied along one or many linked cords—was apparently used for inventory and accountancy purposes and could not encode textual information.
Dacia (Romania).
Three stone slabs were found by Romanian archaeologist Nicolae Vlassa, in the mid-20th century (1961) in Tărtăria (present-day Alba county, Transylvania), Romania, ancient land of Dacia, inhabited by Dacians, which were a population who may have been related to the Getaes and Thracians.
One of the slabs contains 4 groups of pictographs divided by lines. Some of the characters are also found in ancient Greek, as well as in Phoenician, Etruscan, Old Italic and Iberian.
The origin and the timing of the writings are disputed, because there are no precise evidence in situ, the slabs cannot be carbon dated, because of the bad treatment of the Cluj museum. There are indirect carbon dates found on a skeleton discovered near the slabs, that certifies the 5300–5500 BC period.

</doc>
<doc id="33055" url="http://en.wikipedia.org/wiki?curid=33055" title="Winter solstice (disambiguation)">
Winter solstice (disambiguation)

Winter solstice is an astronomical phenomenon which marks the shortest day and the longest night of the year.
Winter solstice may also refer to:

</doc>
<doc id="33056" url="http://en.wikipedia.org/wiki?curid=33056" title="Whitehorse, Yukon">
Whitehorse, Yukon

Whitehorse (total area population 27,889 as of 2013) is the capital and largest city of Yukon, Canada and the largest city in northern Canada. It was incorporated in 1950 and is located at kilometre 1426 on the Alaska Highway in southern Yukon. Whitehorse's downtown and Riverdale areas occupy both shores of the Yukon River, which originates in British Columbia and meets the Bering Sea in Alaska. The city was named after the White Horse Rapids for their resemblance to the mane of a white horse, near Miles Canyon, before the river was dammed. Because of the city's location in the Whitehorse valley, the climate is milder than other comparable northern communities such as Yellowknife. At this latitude winter days are short and summer days have 20 hours of daylight. Whitehorse, as reported by "Guinness World Records", is the city with the least air pollution in the world.
Geography.
Whitehorse is located at kilometre 1,425 (Historic Mile 918) of the Alaska Highway and is framed by three nearby mountains: Grey Mountain to the east, Haeckel Hill to the northwest and Golden Horn Mountain to the south. The rapids which were the namesake of the city have disappeared under Schwatka Lake, formed by the construction of a hydroelectric dam in 1958. Whitehorse is currently the 79th largest city in Canada by area. The city limits present a near rectangular shape orientated in a NW-SE direction.
Subdivisions.
Due to Whitehorse's unique urban development objectives and varied topography, neighbourhoods are usually separated from each other by large geographical features. In addition to the city's downtown core on the Yukon River's west bank, two subdivisions sit at the same elevation as the Yukon River (640 m). Crossing the bridge to the east bank of the river leads to Riverdale, one of the city's oldest neighbourhoods. From Riverdale, the road climbing up Grey Mountain leads to Grey Mountain Cemetery and the local FM radio antenna. North of downtown is the Marwell industrial subdivision which used to be separated from the downtown by a large marshland but the first decade of 2000 saw huge commercial transformations and these two neighbourhoods are now contiguous. Prior to 1975, there were squatters' subdivisions along the Yukon River at the current sites of the S.S. Klondike riverboat, Rotary Peace Park, and the waterfront development area from the north end of 1st Avenue to the north end of the waterfront trolley line; these were expropriated and cleared.
The rest of Whitehorse is generally located above 690 meters. Immediately after climbing "Two Mile Hill", looking to the north are the old residential neighbourhoods of Takhini, Takhini North and Takhini East, where many homes actually are originally army barracks and military officers' residences. Yukon College, Yukon Arts Centre and Whitehorse Correctional Centre are situated in Takhini. Situated further north are Porter Creek and Crestview.
West of downtown are Valleyview, Hillcrest (also largely constituted of old military lodgings) and the airport; and beyond the Canada Games Centre along Hamilton Boulevard are the neighbourhoods of McIntyre (designated to replace inferior lands and homes of the Kwanlin Dun First Nation ("The Village") previously located where Marwell adjoins a marshy area), then Ingram, Arkell, Logan, Granger, and rapidly expanding Copper Ridge.
Whitehorse also has subdivisions designated "Country Residential" which are subject to different municipal bylaws and are located farther out from the downtown. They consist of the rural Whitehorse subdivisions of Hidden Valley and MacPherson at Whitehorse's northern limits; to the south: McCrae (also spelt MacRae), Wolf Creek, Wolf Creek North, Mary Lake, Cowley Creek, Spruce Hill, Pineridge and Fox Haven Estates. Also located at the south end of the city is the newly designated Mt. Sima Service Industrial Subdivision.
Construction of Whistle Bend, Whitehorse's newest subdivision, began in 2010 on the "Lower Bench" east of the Porter Creek subdivision.
Urban planning.
Whitehorse Bylaw 426 (1975) restricts the operation of motor vehicles to designated roadways in certain "Protected Areas" to ensure maximum conservation of the environmental quality. Most are near the downtown core (downtown and Yukon river escarpments, Mt. Mac ski trails, Riverdale, Valleyview, Hillcrest, Granger, Porter Creek, and Mountainview) and one, Pineridge, is south of downtown.
In 1999, the city approved the Area Development Scheme (ADS) which reallocated the area previously known as "Whitehorse Copper" to the following uses: Country Residential, Commercial, Service Industrial, and Heavy industrial.
Recent demands for growth have reignited urban planning debates in Whitehorse. In 1970 the Metropolitan Whitehorse development plan included park and greenbelt areas that were to be preserved to ensure high quality of life even within city limits.
Ecology and climate.
Whitehorse is in the Cordilleran climate region, the Complex Soils of Mountain Areas soil region, the Cordilleran vegetation region, and the Boreal Cordillera ecozone.
Like most of Yukon, Whitehorse has a dry subarctic climate (Köppen climate classification "Dfc"). However, because of the city's location in the Whitehorse valley, the climate is milder than other comparable northern communities such as Yellowknife. With an average annual temperature of -0.1 C Whitehorse is the warmest place in the Yukon. This is the airport temperature. The Whitehorse Riverdale weather station situated at a lower elevation than the airport is even warmer at 0.2 C. At this latitude winter days are short and summer days have 20 hours of daylight. Whitehorse experiences an annual temperature average with daily highs of 20.5 C in July and average daily lows of -22 C in January. The record high temperature was 34 C in June 1969 and the lowest was -52 C in January 1947. Whitehorse has little precipitation with an average annual snowfall of 145 cm and 163 mm of rainfall.
According to Meteorological Service of Canada, Whitehorse has the distinction of being Canada's driest city, mainly because it lies in the rain shadow of the Coast Mountains.
Whitehorse, Yukon in Autumn of 2008.
Government.
Municipal.
Whitehorse municipal elections occur every three years. In the 2012 election, Dan Curtis was elected as mayor of Whitehorse for a first term. Whitehorse City Council has six councillors: Jocelyn Curteanu (first term), Kirk Cameron (second term), Betty Irwin (second term), John Streicker (first term), Mike Gladish (first term) and Dave Stockdale (eleventh consecutive term). The voter turn out at the 2009 election was 4218 of 11446 (36.85%), which is significantly lower than the 44% at the 2006 election, causing consternation among councillors. Municipal services provided by the city of Whitehorse include: water and sewer systems, road maintenance, snow and ice control, non-recyclable waste and composting, as well as a mosquito control program.
Territorial.
Whitehorse was represented by 9 of 18 MLAs in Yukon's Legislative Assembly, as per the 2002 map of Yukon Electoral districts. In 2009 Yukon's electoral map was modified to give Whitehorse an extra seat, bringing its total up to 10 out of 19. The Legislative Assembly Building is located in downtown Whitehorse and elections usually take place every three to five years. The last general election was held in 2011. Whitehorse residents have four local political parties from which to choose: Yukon Liberal Party, Yukon New Democratic Party, Yukon Party, as well as the newly constituted Yukon Green Party.
Federal.
All of Yukon consists of a single Federal electoral district and therefore there is only one MP and 65% of Yukon's voters live in Whitehorse. Residents of the Yukon have been voting federally since a byelection returned the first Yukon MP in January 1903 and, from 1984 onward, have had candidates from at least four federal political parties to choose from. In 2006, 2008 and 2011, the choices have been: Conservative, Green, Liberal, and NDP. Other parties that have contested the riding from 1984 onward include the Libertarian Party, the Rhinoceros Party, the three precursors of the Conservative Party (Reform Party, Canadian Alliance and Progressive Conservatives), the National Party (1993) and the Christian Heritage Party.
Ryan Leef was elected as Yukon's new Conservative MP in 2011. Liberal Larry Bagnell was Yukon's MP from 2000 to 2011, winning the 2006 election with 49% of the vote and voter turnout of 66%, on par with the total Canadian turnout of 65%, with Whitehorse districts turnout lower at 55%.
Judicial.
All court matters are handled in Whitehorse at the Andrew Philipsen Law Building which also houses a law library. Yukon's Territorial Court (three judges) handles most adult criminal prosecutions under the criminal code and other federal statutes. The Supreme Court of Yukon has two resident judges and nine judges from NWT and Nunavut. The Court of Appeal, made up of justices from BC, Yukon, NWT and Nunavut, sits in Whitehorse only one week of the year, so most appeals are heard in Vancouver.
Military.
The Canadian Forces is represented in Whitehorse by Canadian Forces Detachment Yukon located in downtown Whitehorse, Regional Cadet Support Unit (North)was at Boyle Barracks (until a re-organization in 2012 amalgamated the cadet support unit into Regional Cadet Support Unit (NW) based out of Winnipeg, Manitoba.) and the Canadian Rangers of the Whitehorse Patrol of 1 Canadian Ranger Patrol Group. 2685 Yukon Regiment Army Cadet Corps and 551 Whitehorse Squadron, Royal Canadian Air Cadets of the Canadian Cadet Organizations also operate in Whitehorse. All units operate as part of Canadian Forces Joint Task Force (North).
440 Transport Squadron, and other units of the Royal Canadian Air Force, including the Snowbirds often operate and train out of Erik Nielsen Whitehorse International Airport, formerly RCAF Station Whitehorse.
Boyle Barracks is located 20 km south of downtown Whitehorse. The facility houses Regional Cadet Support Unit (North), Whitehorse Cadet Summer Training Centre, service support elements of Joint Task Force (North), and is used by 1 Canadian Ranger Patrol Group, the Junior Canadian Rangers, and other units to conduct training. Boyle Barracks is located on the property of the unused Wolf Creek Juvenile Corrections Centre which is leased by the Department of National Defence from the Yukon Government.
Whitehorse Cadet Summer Training Centre offers a variety of courses and activities that focus on general training, leadership, and expedition training up to the instructor level. Courses are two, three, and six weeks long and are offered throughout the summer. Personnel are drawn primarily from the territories, but many come from across Canada. The training centre also hosts members of the United Kingdom's Army Cadet Force and Combined Cadet Force.
Historically, Whitehorse also was the location of units of the Canadian Army and the Royal Canadian Air Force; the Canadian Army was the last to pull out in 1968, at the same time the armed forces were unified.
History.
Archeological research south of the downtown area, at a location known as Canyon City, has revealed evidence of use by First Nations for several thousand years. The surrounding area had seasonal fish camps and Frederick Schwatka, in 1883, observed the presence of a portage trail used to bypass Miles Canyon. Before the Gold Rush, several different tribes passed through the area seasonally and their territories overlapped.
The discovery of gold in the Klondike in August, 1896, by Skookum Jim, Tagish Charlie and George Washington Carmack set off a major change in the historical patterns of the region. Early prospectors used the Chilkoot Pass, but by July 1897, crowds of neophyte stampeders had arrived via steamship and were camping at "White Horse". By June 1898, there was a bottleneck of stampeders at Canyon City, many boats had been lost to the rapids as well as five people. Samuel Steele of the North-West Mounted Police said: "why more casualties have not occurred is a mystery to me."
On their way to find gold, stampeders also found copper in the "copper belt" in the hills west of Whitehorse. The first copper claims were staked by Jack McIntyre on July 6, 1898, and Sam McGee on July 16, 1899. Two tram lines were built, one 8 km stretch on the east bank of the river from Canyon City to the rapids, just across from the present day downtown, the other was built on the west bank of the river. A small settlement was developing at Canyon City but the completion of the railway to Whitehorse in 1900 put a halt to it.
The White Pass and Yukon Route narrow-gauge railway linking Skagway to Whitehorse had begun construction in May 1898, by May 1899 construction had arrived at the south end of Bennett lake. Construction began again at the north end of Bennett lake to Whitehorse. It was only in June–July 1890 that construction finished the difficult Bennett lake section itself, completing the entire route.
By 1901, the Whitehorse Star was already reporting on daily freight volumes. That summer there were four trains per day. Even though traders and prospectors were all calling the city Whitehorse (White Horse), there was an attempt by the railway people to change the name to Closeleigh (British Close brothers provided funding for the railway), this was refused by William Ogilvie, the territory's Commissioner. Whitehorse was booming.
In 1920 the first planes landed in Whitehorse and the first air mail was sent in November 1927. Until 1942, river and air were the only way to get to Whitehorse but in 1942 the US military decided an interior road would be safer to transfer troops and provisions between Alaska and the US mainland and began construction of the Alaska Highway. The entire 2500 km project was accomplished between March and November 1942. The Canadian portion of the highway was only returned to Canadian sovereignty after the war. The Canol pipeline was also constructed to supply oil to the north with a refinery in Whitehorse.
In 1950 the city was incorporated and by 1951, the population had doubled from its 1941 numbers. On April 1, 1953, the city was designated the capital of the Yukon Territory when the seat was moved from Dawson City after the construction of the Klondike Highway. On March 21, 1957, the name was officially changed from White Horse to Whitehorse.
Infrastructure.
Transportation.
Air.
Whitehorse is served by the Erik Nielsen Whitehorse International Airport and has scheduled service to Vancouver, Kelowna, Calgary, Edmonton, Yellowknife, Ottawa (via Yellowknife), Dawson City, Old Crow, Inuvik, as well as Fairbanks, Alaska and Frankfurt, Germany during the summer months. The airport was developed as part of the Northwest Staging Route in 1941-42 and has two long paved runways. A wartime-era hangar served as terminal building from about 1960, and was replaced in December 1985 with a modern terminal. Air North, a scheduled passenger and cargo airline operating Boeing 737 jetliners and Hawker Siddeley 748 turboprops, is based in Whitehorse.
In 1998 work was completed on a 340-meter runway extension and other improvements (concrete turn button, installation of storm and sanitary mains, lighting upgrades, tower access road and blast pad). Expansion of the terminal itself was completed in 2010.
Roads.
Surface access to Whitehorse is provided by a network of highways, including the international Alaska Highway connecting the Yukon with Alaska, British Columbia, and Alberta highway networks.
Whitehorse has been described as "pearls on a string", with its residential, industrial, and service subdivisions located along the main thoroughfares that carry traffic within city limits, with large gaps of undeveloped (often hilly) land between them. The Alaska Highway is the primary roadway, with branch roads reaching additional subdivisions. One such branch road, signed as "Highway 1A" and following Two Mile Hill Road, 4th Avenue, 2nd Avenue, and Robert Service Way, is the main access to downtown, Riverdale, and the Marwell Industrial Area. Other branch roads (Range Road, Hamilton Boulevard, Mayo Road) access smaller residential areas and recreational facilities.
The city road network is adequate, although it is congested during rush hours and discussions occasionally occur as to how it might better be managed, such as designating one-way streets.
Water.
The Yukon River is essentially navigable from Whitehorse to the Bering Sea. At 640 meters above sea level, the river at Whitehorse is the highest point on earth that can be reached by watercraft navigating from the sea. Currently, no passenger or freight services use the river at Whitehorse.
Rail.
Whitehorse presently has no active railway service. The city is reached by the tracks of the White Pass and Yukon Route, of which only a small portion are currently maintained to run a small trolley service in the summer. The last scheduled service to Whitehorse occurred in October 1982. The White Pass Railway started scheduled service from Skagway, Alaska to Carcross, 72 km south of Whitehorse, in the spring of 2007, but this was disrupted by high lake water levels in August 2007. Speculation of a transcontinental rail link to Alaska includes one possible route option through Whitehorse; a report has recommended a hub at Carmacks, with a spur line to Whitehorse and on to the Inside Passage of Alaska.
Public transit.
Whitehorse Transit provides bus service on weekdays from morning until early evening and Saturdays during business hours. There is a waterfront tram, known as the "trolley", which provides transport along a short rail section along the Yukon River; it is chiefly tourist-oriented and is not yet integrated into the municipal transit system. It runs from the Rotary Peace Park, located on the south end of the city centre, up to the north end of the city centre at Spook Creek Station.
Water and waste disposal.
Water disposal is mostly done by draining in a septic tank where the sewage is not that well developed.
Waste is disposed mostly in areas requiring reclamation.This includes places like quarries,mined areas etc.
Energy grid.
Yukon Energy operates four conventional hydroelectric generating stations: Whitehorse Dam (40 MW), Aishihik Lake (37 MW), Mayo A (5 MW), and Mayo B (10 MW), which provide the bulk of generation for the Yukon Energy grid. 39 MW of diesel generation is maintained for supplemental back-up.
Additionally, Yukon Energy operates two wind turbines near Whitehorse, which are connected to the Whitehorse-Aishihik-Faro grid. The first turbine is a Bonus Energy 150 kW MARK III installed in 1993. The second turbine, a Vestas 660 kW V47 LT II was later installed in 2000. These units need to be specially adapted to deal with icing and the northern environment.
Health care.
The first "White Horse General Hospital" (WGH) was built in the downtown area in 1902 with a 10 bed capacity. During WWI beds increased to 30, 10 beds were added in 1943, then 20 beds in 1949, and an operating wing was added in 1951. In 1959 the hospital was rebuilt on the other bank of the Yukon River, across from its previous location, but decision making was still based in Ottawa (National Health and Welfare, Medical Services Branch).
In 1990, the Yukon Hospital Corporation (YHC) was created in order to prepare the transfer of powers regarding the hospital from the Federal Government to the Yukon Territorial Government. In April 1993 management of WGH was officially transferred to the YHC following a collaboration with the Yukon government and Council of Yukon First Nations (CYFN, then CYI). Construction of the present building lasted from 1994 through 1997. Today Whitehorse General hospital counts 49 in-patient beds, 10 day-surgery beds, an ER department, OR suites and several medical imaging technologies.
The downtown area has several private medical, dental, and optometry clinics.
Police, fire, emergency services.
Whitehorse contracts out its police service to the Royal Canadian Mounted Police, with the main police station on 4th avenue in the city centre.
Whitehorse has its own fire service, known as City of Whitehorse Fire Department (WHFD) with two fire halls. The first in the city centre with only space for two trucks on 2126 Second Avenue near Steele Street, and the second (305 B Range Road) atop "Two Mile Hill" on the west side with room for 3 trucks which was rebuilt in 2010 to become a public safety building. The original fire hall located along on the waterfront has been preserved as a historic building and cultural centre. The Fire Department runs with 22 full-time staff and approximately 18 volunteers. WHFD is equipped and trained to respond to Motor vehicle Incidents, high and low angle rescue, confined space, and static water ice rescue. Haz-mat, swift water and urban search and rescue are not under the departments current capabilities or can only be responded to at awareness levels. All medical emergencies are responded to by Yukon Government Emergency Medical Services. All aircraft emergencies are dealt with by the ENWIA ARFF fire department. Whitehorse Fire Department is professionally represented by the IAFF.
Whitehorse's ambulance service are run by Yukon Government's Emergency Medical Services and is staffed by full-time Primary Care Paramedics (PCP).
Whitehorse's Search and Rescue (SAR) is ensured by a partnership between the RCMP, YG's Emergency Measures Organization (EMO) and volunteer SAR teams.
Education.
Whitehorse has several schools as part of a Yukon Government operated public school system. Except for "École Émilie-Tremblay" Yukon does not have school boards, however each school has a council composed of three to seven elected positions for 2-year terms, consisting of (and elected by) citizens residing in the school's assigned area and parents of students attending the school. All teachers are employed directly by the Department of Education and there are no tuition fees to be paid to attend elementary and secondary institutions.
Primary education (K-3):
Elementary education (K-7):
Secondary education:
French First Language school (K-12):
Specialized programs:
Post-secondary education:
Culture.
Arts and entertainment.
Whitehorse's Yukon Arts Centre offers all varieties of shows and artists and includes an art gallery.
The Frantic Follies Vaudeville Revue was established in 1970 and has been a major tourist draw ever since. Recreating an 1890's style goldrush era vaudeville show, The Frantic Follies includes barbershop quartet, sketches, marching band, banjo and saw orchestral numbers as well as kickline dancing girls. In 1973, the show was moved to the new Bonanza Room at the Whitehorse Travelodge.
By 1975, its popularity had grown to such an extent that it became necessary to present two performances per night. In 1975 and again in 1977, the show embarked on cross-Canada tours, on which they performed everywhere from maximum security prisons to the Parliament Buildings in Ottawa. Twice the show travelled to Alert, the Canadian Forces Station four hundred miles from the North Pole.
In 1976, the Company undertook to produce not only the Whitehorse show, but the entertainment in Dawson City's Palace Grand Theatre and Diamond Tooth Gertie's Gambling Casino. At the end of the 1980 season they left Dawson City. In January 1981, the show joined the "Snow Birds" for a season and moved to St. Petersburg, Florida, for a four-month run. The fall of 1990 saw the Frantic Follies taking to the road again as ambassadors for the Yukon in a whirlwind tour, performing in ten Canadian and American cities in a little over two weeks. The Frantic Follies currently perform nightly shows in the summer season at the Westmark Hotel in Downtown Whitehorse.
Plays are also performed at the Guild Hall in Porter Creek, and downtown Whitehorse's Wood Street Centre offers smaller local productions. Whitehorse's arts and entertainment schedule is non-stop throughout the year, not only with local events and celebrations but Whitehorse also plays host to several major festivals which attract artists from all over Canada and internationally, including the Sourdough Rendezvous' Ice Sculpture contest, the Frostbite Music Festival, the Yukon International Storytelling Festival, and the Available Light Film Festival.
Print.
Whitehorse's two major English language newspapers are the Whitehorse Daily Star (founded as a weekly in 1900, it now publishes five times per week since 1986) and the Yukon News (founded as a weekly in 1960 by Ken Shortt, published five days a week from 1967 to 1999, and currently prints twice weekly). Other local newspapers include What's Up Yukon (a local free music, arts, culture, events, weekly founded in 2005) and a French language newspaper "L'Aurore boréale" (founded in 1983, and published bi-weekly).
Radio and television.
Whitehorse has several local radio stations (CFWH/CBC North, CKRW-FM, CHON-FM, CJUC-FM, CIAY-FM, VF2356), and NorthwesTel hosts three local television channels (Community Cable 9, an advertisement slide-show channel and a public service channel).
CBC television established a TV transmitter in Whitehorse, CFWH-TV, in 1968, using the Frontier Coverage Package until Anik satellite broadcasts became available early in 1973; this transmitter was shut down on July 31, 2012, amid budget cuts handed down by the CBC. Until 2009, there was a low-powered repeater of Edmonton's CITV-TV providing Global Television Network programming to the area.. Currently, the only aerial television available in Whitehorse is CHWT-TV channel 11, a local APTN repeater.
Sports.
Whitehorse's proximity to the wilderness and the northern range of the Rockies allows its residents to enjoy a very active lifestyle. The city has an extensive trail network within its limits, estimated at 850 km in 2007, including sections of the Trans Canada Trail. These trails are used for a variety of non-motorized and/or motorized activities. The Yukon River in and around Whitehorse provides many opportunities for kayaking and canoeing.
Events.
The annual 1,000 mile Yukon Quest sled dog race between Whitehorse and Fairbanks, Alaska, is considered one of the toughest in the world. The race alternates its starting and finishing points each year.
The city has hosted several large sporting events including the 2007 Canada Winter Games, for which a CA$45 million sport multiplex was built; the Canadian Junior Freestyle Championships in 2006, the Arctic Winter Games (2000, 1992, 1986, 1980, 1972 and the current 2012 games), the annual International Curling Bonspiel, and the Dustball International Slowpitch Tournament.
Facilities.
The city is responsible for the maintenance of numerous sports and recreation fields including two dozen grass/sand/soil/ice sports surfaces, 3 ball diamonds, the Canada Games Centre Multiplex (pools, ice rinks, fieldhouse, fitness centre, walking/running track, physiotherapy), the Takhini Arena, and Mount McIntyre Recreation Centre. Private interests run Mount Sima (350 m, downhill skiing), three golf courses (Meadow Lakes Golf and Country Club, Mountain View Golf Course, Wolf Creek), a bowling alley, and gyms (Peak Fitness, Curves, Better Bodies).
Teams.
Although there are no territorial junior league teams, the business community sponsors a number of local teams of Volleyball, baseball, basketball, broomball, hockey, soccer and ultimate disk. High school teams are very active and partake in competitions with schools in neighbouring Alaska, and a few local athletes have flourished on the Canadian sports scene. Whitehorse is also home to the Whitehorse Glacier Bears swimming club.
Demographics.
Christians make up 54% of the population, while 39% has no religious affiliation. There are also 110 Buddhists, 105 Sikhs, 60 Muslims, and 30 Jews.
2011.
According to the 2011 National Household Survey, the population of Whitehorse is" 22,810". The population density was 55.9 per km². The racial make up of Whitehorse is mostly made up of Whites (75.5%), but still has a significant amount of Aboriginals (16.5%); "First Nations (13.5%) and Metis (2.2%)". There is also a moderate visible minority population (7.9%); Southeast Asian (3.4%), East Asian (1.8%) and South Asian (1.6%) were the three largest minority groups. The religious make up of Whitehorse is; Christian (45.3%) and non-religious (51.4%), the remaining 3.3% fall into another religion.
Most of the residents are Canadian citizens (94.1%).
Language.
As a federal territory, the Yukon is officially bilingual in English and French. In 2011, 84.3% of the residents of Whitehorse declared English as their only mother tongue, while 4.6% reported French as their only mother tongue, and 9.7% of the population reported a non-official language as their mother tongue. According to the 2011 census the most spoken non-official language in Whitehorse was German, followed by Tagalog, Spanish, Chinese and Dutch.
Sister cities.
Historical sister city partnerships:
Notable residents.
Notable athletes are Whitehorse born hockey players Bryon Baltimore, who made it to the Los Angeles Kings in 1974, and Peter Sturgeon who played for the Colorado Rockies in 1974, Whitehorse born olympic cyclist Zachary Bell, Whitehorse raised olympic weightlifter Jeane Lassen who won medals in several world competitions, Whitehorse born basketball players Aaron Olson, and 1984 Olympics centre for Team Canada Greg Wiltjer.
Notable politicians include the first female mayor of Whitehorse, in 1975, Ione Christensen whose family had moved to Whitehorse in 1949, and Yukon's first senator, in 1975, Paul Lucier, who stayed in office until his death in 1999.

</doc>
<doc id="33057" url="http://en.wikipedia.org/wiki?curid=33057" title="White House">
White House

The White House is the official residence and principal workplace of the President of the United States, located at 1600 Pennsylvania Avenue NW in Washington, D.C. It has been the residence of every U.S. president since John Adams in 1800.
The house was designed by Irish-born James Hoban and built between 1792 and 1800 of white-painted Aquia Creek sandstone in the Neoclassical style. When Thomas Jefferson moved into the house in 1801, he (with architect Benjamin Henry Latrobe) expanded the building outward, creating two colonnades that were meant to conceal stables and storage. However, in 1814, during the War of 1812, the mansion was set ablaze by the British Army in the Burning of Washington, destroying the interior and charring much of the exterior. Reconstruction began almost immediately, and President James Monroe moved into the partially reconstructed Executive Residence in October 1817. Construction continued with the addition of the South Portico in 1824 and the North in 1829.
Because of crowding within the executive mansion itself, President Theodore Roosevelt had all work offices relocated to the newly constructed West Wing in 1901. Eight years later, President William Howard Taft expanded the West Wing and created the first Oval Office which was eventually moved as the section was expanded. The third-floor attic was converted to living quarters in 1927 by augmenting the existing hip roof with long shed dormers. A newly constructed East Wing was used as a reception area for social events; Jefferson's colonnades connected the new wings. East Wing alterations were completed in 1946, creating additional office space. By 1948, the house's load-bearing exterior walls and internal wood beams were found to be close to failure. Under Harry S. Truman, the interior rooms were completely dismantled and a new internal load-bearing steel frame constructed inside the walls. Once this work was completed, the interior rooms were rebuilt.
The modern-day White House Complex includes the Executive Residence, West Wing, East Wing, the Eisenhower Executive Office Building—the former State Department, which now houses offices for the President's staff and the Vice President—and Blair House, a guest residence. The Executive Residence is made up of six stories—the Ground Floor, State Floor, Second Floor, and Third Floor, as well as a two-story basement. The term "White House" is often used as a metonym for the Executive Office of the President of the United States and for the president's administration and advisers in general, as in "The White House has decided that...". The property is a National Heritage Site owned by the National Park Service and is part of the President's Park. In 2007, it was ranked second on the American Institute of Architects list of "America's Favorite Architecture".
Early history.
1789–1800.
Following his April 1789 inauguration, President George Washington occupied two executive mansions in New York City: the Samuel Osgood House at 3 Cherry Street (April 1789 – February 1790), and the Alexander Macomb House at 39–41 Broadway (February–August 1790). In May 1790, New York began construction of Government House for his official residence, but he never occupied it. The national capital moved to Philadelphia in December 1790.
The July 1790 Residence Act named Philadelphia, Pennsylvania the temporary national capital for a 10-year period while the Federal City was under construction. The City of Philadelphia rented Robert Morris's city house at 190 High Street (now 524-30 Market Street) for Washington's presidential residence. The first president occupied the Market Street mansion from November 1790 to March 1797, and altered it in ways that may have influenced the design of the White House. As part of a futile effort to have Philadelphia named the permanent national capital, Pennsylvania built a much grander presidential mansion several blocks away, but Washington declined to occupy it.
President John Adams also occupied the Market Street mansion from March 1797 to May 1800. On 1 November, in 1800, he became the first president to occupy the White House. The President's House in Philadelphia became a hotel and was demolished in 1832, while the unused presidential mansion became home to the University of Pennsylvania.
Architectural competition.
The President's House was a major feature of Pierre (Peter) Charles L'Enfant's's plan for the newly established federal city, Washington, D.C. The architect of the White House was chosen in a design competition which received nine proposals, including one submitted anonymously by Thomas Jefferson.
President Washington visited Charleston, South Carolina in May 1791 on his "Southern Tour", and saw the under-construction Charleston County Courthouse designed by Irish architect James Hoban. He is reputed to have met with Hoban then. The following year, he summoned the architect to Philadelphia and met with him in June 1792.
On July 16, 1792, the President met with the commissioners of the federal city to make his judgment in the architectural competition. His review is recorded as being brief, and he quickly selected Hoban's submission.
Washington was not entirely pleased with the original submission, however; he found it too small, lacking ornament, and not monumental enough to house the nation's president. On his recommendation, the house was changed from three stories to two, and was widened from a nine-bay facade to an 11-bay facade. Hoban's competition drawings do not survive.
Design influences.
The building has classical inspiration sources, that could be found directly or indirectly in the Roman architect Vitruvius or in Andrea Palladio styles; Palladio being an Italian architect of the Renaissance which had a considerable influence on the Western architecture (Palladian architecture). The building Hoban designed is verifiably influenced by the upper floors of Leinster House, in Dublin, which later became the seat of the Oireachtas (the Irish parliament). Several other Georgian-era Irish country houses have been suggested as sources of inspiration for the overall floor plan, details like the bow-fronted south front, and interior details like the former niches in the present Blue Room. These influences, though undocumented, are cited in the official White House guide, and in White House Historical Association publications. The first official White House guide, published in 1962, suggested a link between Hoban's design for the South Portico and Château de Rastignac, a neoclassical country house located in La Bachellerie in the Dordogne region of France and designed by Mathurin Salat. Construction on the French house was initially started before 1789, interrupted by the French Revolution for twenty years and then finally built 1812–1817 (based on Salat's pre-1789 design). The theoretical link between the two houses has been criticized because Hoban did not visit France. Supporters of a connection posit that Thomas Jefferson, during his tour of Bordeaux in 1789, viewed Salat's architectural drawings (which were on-file at the College) at the École Spéciale d'Architecture (Bordeaux Architectural College). On his return to the U.S. he then shared the influence with Washington, Hoban, Monroe, and Benjamin Henry Latrobe.
Construction.
Construction of the White House began with the laying of the cornerstone on October 13, 1792, although there was no formal ceremony. The main residence, as well as foundations of the house, were built largely by enslaved and free African-American laborers, as well as employed Europeans. Much of the other work on the house was performed by immigrants, many not yet with citizenship. The sandstone walls were erected by Scottish immigrants, employed by Hoban, as were the high-relief rose and garland decorations above the north entrance and the "fish scale" pattern beneath the pediments of the window hoods. The initial construction took place over a period of eight years, at a reported cost of $232,371.83 (equal to $ today). Although not yet completed, the White House was ready for occupancy circa November 1, 1800.
Shortages, including material and labor, forced alterations to the earlier plan developed by French engineer Pierre Charles L'Enfant for a "palace" that was five times larger than the house that was eventually built. The finished structure contained only two main floors instead of the planned three, and a less costly brick served as a lining for the stone façades. When construction was finished, the porous sandstone walls were whitewashed with a mixture of lime, rice glue, casein, and lead, giving the house its familiar color and name.
As it is a famed structure in America, several replicas of the White House have been constructed.
Architectural description.
The principal façade of the White House, the north front, is of three floors and eleven bays. The ground floor is hidden by a raised carriage ramp and parapet, thus the façade appears to be of two floors. The central three bays are behind a prostyle portico (this was a later addition to the house, built circa 1830) serving, thanks to the carriage ramp, as a porte cochere. The windows of the four bays flanking the portico, at first-floor level, have alternating pointed and segmented pediments, while at second-floor level the pediments are flat. The principal entrance at the center of the portico is surmounted by a lunette fanlight. Above the entrance is a sculpted floral festoon. The roofline is hidden by a balustraded parapet.
The mansion's southern façade is a combination of the Palladian and neoclassical styles of architecture. It is of three floors, all visible. The ground floor is rusticated in the Palladian fashion. At the center of the façade is a neoclassical projecting bow of three bays. The bow is flanked by 5 bays, the windows of which, as on the north façade, have alternating segmented and pointed pediments at first-floor level. The bow has a ground floor double staircase leading to an Ionic colonnaded loggia (with the Truman Balcony at second-floor level), known as the south portico. The more modern third floor is hidden by a balustraded parapet and plays no part in the composition of the façade.
Naming conventions.
The building was originally referred to variously as the "President's Palace", "Presidential Mansion", or "President's House". The earliest evidence of the public calling it the "White House" was recorded in 1811. A myth emerged that during the rebuilding of the structure after the Burning of Washington, white paint was applied to mask the burn damage it had suffered, giving the building its namesake hue. The name "Executive Mansion" was used in official contexts until President Theodore Roosevelt established the formal name by having "White House–Washington" engraved on the stationery in 1901. The current letterhead wording and arrangement "The White House" with the word "Washington" centered beneath goes back to the administration of Franklin D. Roosevelt.
Although it was not completed until some years after the presidency of George Washington, it is also speculated that the name of the traditional residence of the President of the United States may have derived from Martha Washington's home, White House Plantation in Virginia, where the nation's first President had courted the First Lady in the mid-18th century.
Evolution of the White House.
Early use, the 1814 fire, and rebuilding.
On Saturday, November 1, 1800, John Adams became the first president to take residence in the building. During Adams' second day in the house, he wrote a letter to his wife Abigail, containing a prayer for the house. Adams wrote:
I pray Heaven to bestow the best of blessings on this House, and all that shall hereafter inhabit it. May none but honest and wise men ever rule under this roof.
 Franklin D. Roosevelt had Adams's blessing carved into the mantel in the State Dining Room.
Adams lived in the house only briefly before Thomas Jefferson moved into the "pleasant country residence" in 1801. Despite his complaints that the house was too big ("big enough for two emperors, one pope, and the grand lama in the bargain"), Jefferson considered how the White House might be added to. With Benjamin Henry Latrobe, he helped lay out the design for the East and West Colonnades, small wings that help conceal the domestic operations of laundry, a stable and storage. Today, Jefferson's colonnades link the residence with the East and West Wings.
In 1814, during the War of 1812, the White House was set ablaze by British troops during the Burning of Washington, in retaliation for burning Upper Canada's Parliament Buildings in the Battle of York; much of Washington was affected by these fires as well. Only the exterior walls remained, and they had to be torn down and mostly reconstructed because of weakening from the fire and subsequent exposure to the elements, except for portions of the south wall. Of the numerous objects taken from the White House when it was ransacked by British troops, only two have been recovered. Employees and slaves rescued a painting of George Washington, and in 1939, a Canadian man returned a jewelry box to President Franklin D. Roosevelt, claiming that his grandfather had taken it from Washington. Some observers allege that most of these spoils were lost when a convoy of British ships led by HMS "Fantome" sank en route to Halifax off Prospect during a storm on the night of November 24, 1814, even though "Fantome" had no involvement in that action.
After the fire, President James Madison resided in The Octagon House from 1814 to 1815, and then the Seven Buildings from 1815 to the end of his term. Meanwhile, both architect Benjamin Henry Latrobe and Hoban contributed to the design and oversight of the reconstruction, which lasted from 1815 until 1817. The south portico was constructed in 1824 during the James Monroe administration; the north portico was built six years later. Though Latrobe proposed similar porticos before the fire in 1814, both porticos were built as designed by Hoban. An elliptical portico at Château de Rastignac in La Bachellerie, France with nearly identical curved stairs is speculated as the source of inspiration due to its similarity with the South Portico, although this matter is one of great debate. Italian artisans, brought to Washington to help in constructing the U.S. Capitol, carved the decorative stonework on both porticos. Contrary to speculation, the North Portico was not modeled on a similar portico on another Dublin building, the Viceregal Lodge (now "Áras an Uachtaráin", residence of the President of Ireland), for its portico postdates the White House porticos' design. For the North Portico, a variation on the Ionic Order was devised incorporating a swag of roses between the volutes. This was done to link the new portico with the earlier carved roses above the entrance.
Overcrowding and building the West Wing.
By the time of the American Civil War, the White House had become overcrowded. The location of the White House was questioned, just north of a canal and swampy lands, which provided conditions ripe for malaria and other unhealthy conditions. Brigadier General Nathaniel Michler was tasked to propose solutions to address these concerns. He proposed abandoning the use of the White House as a residence and designed a new estate for the first family at Meridian Hill in Washington, D.C., but Congress rejected the plan.
The Panic of 1873 had led to an economic depression that persisted through much of the decade. The Statue of Liberty project was not the only undertaking that had difficulty raising money: construction of the obelisk later known as the Washington Monument sometimes stalled for years.
When Chester Arthur took office in 1881, he ordered renovations to the White House to take place as soon as the recently widowed Lucretia Garfield moved out. Arthur inspected the work almost nightly and made several suggestions. Louis Comfort Tiffany was asked to send selected designers to assist. Over twenty wagonloads of furniture and household items were removed from the building and sold at a public auction. All that was saved were bust portraits of John Adams and Martin Van Buren. A proposal was made to build a new residence south of the White House, but it failed to gain support.
In the fall of 1882 work was done on the main corridor, including tinting the walls pale olive and adding squares of gold leaf, and decorating the ceiling in gold and silver, and colorful traceries woven to spell "USA". The Red Room was painted a dull Pomeranian red, and its ceiling was decorated with gold, silver, and copper stars and stripes of red, white, and blue. A fifty-foot jeweled Tiffany glass screen, supported by imitation marble columns, replaced the glass doors that separated the main corridor from the north vestibule.
In 1891, First Lady Caroline Harrison proposed major extensions to the White House, including a National Wing on the east for a historical art gallery, and a wing on the west for official functions. A plan was devised by Colonel Theodore A. Bingham, which reflected the Harrison proposal. These plans were ultimately rejected.
However, in 1902 Theodore Roosevelt hired McKim, Mead & White to carry out expansions and renovations in a neoclassical style suited to the building's architecture, removing the Tiffany screen and all Victorian additions. Charles McKim himself designed and managed the project, which gave more living space to the President's large family by removing a staircase in the West Hall and moving executive office staff from the second floor of the residence into the new West Wing.
President William Howard Taft enlisted the help of architect Nathan C. Wyeth to add additional space to the West Wing, which included the addition of the Oval Office. The West Wing was damaged by fire in 1929, but rebuilt during the remaining years of the Herbert Hoover presidency. In the 1930s, a second story was added, as well as a larger basement for White House staff, and President Franklin Roosevelt had the Oval Office moved to its present location: adjacent to the Rose Garden.
The Truman reconstruction.
Decades of poor maintenance, the construction of a fourth story attic during the Coolidge administration, and the addition of a second-floor balcony over the south portico for Harry S. Truman took a great toll on the brick and sandstone structure built around a timber frame. By 1948, the house was declared to be in imminent danger of collapse, forcing President Truman to commission a reconstruction and move across the street to Blair House from 1949-51. The work, done by the firm of Philadelphia contractor John McShain, required the complete dismantling of the interior spaces, construction of a new load-bearing internal steel frame and the reconstruction of the original rooms within the new structure. The total cost of the renovations was about $5.7 million (US$ million in 2015). Some modifications to the floor plan were made, the largest being the repositioning of the grand staircase to open into the Entrance Hall, rather than the Cross Hall. Central air conditioning was added, as well as two additional sub-basements providing space for workrooms, storage, and a bomb shelter. The Trumans moved back into the White House on March 27, 1952. While the house's structure was kept intact by the Truman reconstruction, much of the new interior finishes were generic, and of little historic value. Much of the original plasterwork, some dating back to the 1814–1816 rebuilding, was too damaged to reinstall, as was the original robust Beaux Arts paneling in the East Room. President Truman had the original timber frame sawed into paneling; the walls of the Vermeil Room, Library, China Room, and Map Room on the ground floor of the main residence were paneled in wood from the timbers.
The Kennedy restoration.
Jacqueline Kennedy, wife of President John F. Kennedy (1961–63), directed a very extensive and historic redecoration of the house. She enlisted the help of Henry Francis du Pont of the Winterthur Museum to assist in collecting artifacts for the mansion, many of which had once been housed there. Other antiques, fine paintings, and improvements of the Kennedy period were donated to the White House by wealthy philanthropists, including the Crowninshield family, Jane Engelhard, Jayne Wrightsman, and the Oppenheimer family. Stéphane Boudin of the House of Jansen, a Paris interior-design firm that had been recognized worldwide, was employed by Mrs. Kennedy to assist with the decoration. Different periods of the early republic and world history were selected as a theme for each room: the Federal style for the Green Room, French Empire for the Blue Room, American Empire for the Red Room, Louis XVI for the Yellow Oval Room, and Victorian for the president's study, renamed the Treaty Room. Antique furniture was acquired, and decorative fabric and trim based on period documents was produced and installed. The Kennedy restoration resulted in a more authentic White House of grander stature, which recalled the French taste of Madison and Monroe. In the Diplomatic Reception Room Mrs. Kennedy installed an antique "Vue de l'Amérique Nord" wall paper which Zuber & Cie had designed in 1834. The wallpaper had hung previously on the walls of another mansion until 1961 when that house was demolished for a grocery store. Just before the demolition, the wallpaper was salvaged and sold to the White House.
The first White House guidebook was produced under the direction of curator Lorraine Waxman Pearce with direct supervision from Mrs. Kennedy. Sale of the guidebook helped finance the restoration. 
Kennedy showed her restoration of the White House to the public in a televised tour of the house on Valentine's Day in 1962.
The White House since the Kennedy restoration.
Out of respect for the historic character of the White House, no substantive architectural changes have been made to the house since the Truman renovation. Since the Kennedy restoration, every presidential family has made some changes to the private quarters of the White House, but the Committee for the Preservation of the White House must approve any modifications to the State Rooms. Charged with maintaining the historical integrity of the White House, the congressionally authorized committee works with each First Family—usually represented by the First Lady, the White House Curator, and the Chief Usher—to implement the family's proposals for altering the house.
During the Nixon administration (1969–74), First Lady Pat Nixon refurbished the Green Room, Blue Room, and Red Room, working with Clement Conger, the curator appointed by President Richard Nixon. Mrs. Nixon's efforts brought more than 600 artifacts to the house, the largest acquisition by any administration. Her husband created the modern press briefing room over Franklin Roosevelt's old swimming pool. Nixon also added a single-lane bowling alley to the White House basement.
Computers and the first laser printer were added during the Carter administration, and the use of computer technology was expanded during the Reagan administration. A Carter-era innovation, a set of solar water heating panels that were mounted on the roof of the White House, was removed during Reagan's presidency. Redecorations were made to the private family quarters and maintenance was made to public areas during the Reagan years. The house was accredited as a museum in 1988.
In the 1990s, Bill and Hillary Clinton refurbished some rooms with the assistance of Arkansas decorator Kaki Hockersmith, including the Oval Office, the East Room, Blue Room, State Dining Room, Lincoln Bedroom, and Lincoln Sitting Room. During the administration of George W. Bush, first lady Laura Bush refurbished the Lincoln Bedroom in a style contemporary to the Lincoln era; the Green Room, Cabinet Room, and theater were also refurbished.
The White House became one of the first wheelchair-accessible government buildings in Washington when modifications were made during the presidency of Franklin D. Roosevelt, who used a wheelchair because of his paralytic illness. In the 1990s, Hillary Rodham Clinton—at the suggestion of Visitors Office Director Melinda N. Bates—approved the addition of a ramp in the East Wing corridor. It allowed easy wheelchair access for the public tours and special events that enter through the secure entrance building on the east side.
In 2013 President Barack Obama installed a set of solar panels on the roof of the White House.
The president usually travels to and from the White House grounds via official motorcade or helicopter. In the 1950s, President Dwight D. Eisenhower was the first president to travel by helicopter to and from the White House grounds.
Layout and amenities.
Today the group of buildings housing the presidency is known as the White House Complex. It includes the central Executive Residence flanked by the East Wing and West Wing. The Chief Usher coordinates day to day household operations. The White House includes: six stories and 55,000 ft² (5,100 m²) of floor space, 132 rooms and 35 bathrooms, 412 doors, 147 windows, twenty-eight fireplaces, eight staircases, three elevators, five full-time chefs, a tennis court, a (single-lane) bowling alley (officially called the Harry S. Truman Bowling Alley), a movie theater (officially called the White House Family Theater), a jogging track, a swimming pool, and a putting green. It receives up to 30,000 visitors each week.
Executive Residence.
The original residence is in the center. Two colonnades—one on the east and one on the west—designed by Jefferson, now serve to connect the East and West Wings, added later. The Executive Residence houses the president's dwelling, as well as rooms for ceremonies and official entertaining. The State Floor of the residence building includes the East Room, Green Room, Blue Room, Red Room, State Dining Room, Family Dining Room, Cross Hall, Entrance Hall, and Grand Staircase. The Ground Floor is made up of the Diplomatic Reception Room, Map Room, China Room, Vermeil Room, Library, the main kitchen, and other offices. The second floor family residence includes the Yellow Oval Room, East and West Sitting Halls, the White House Master Bedroom, President's Dining Room, the Treaty Room, Lincoln Bedroom and Queens' Bedroom, as well as two additional bedrooms, a smaller kitchen, and a private dressing room. The third floor consists of the White House Solarium, Game Room, Linen Room, a Diet Kitchen, and another sitting room (previously used as President George W. Bush's workout room).
West Wing.
The West Wing houses the President's office (the Oval Office) and offices of his senior staff, with room for about 50 employees. It also includes the Cabinet Room, where the president conducts business meetings and where the Cabinet meets, as well as the White House Situation Room, James S. Brady Press Briefing Room, and Roosevelt Room. In 2007, work was completed on renovations of the press briefing room, adding fiber optic cables and LCD screens for the display of charts and graphs. The makeover took 11 months and cost $8 million, of which news outlets paid $2 million. In September 2010, a two-year project began on the West Wing, creating a multistory underground structure; this will be followed with additional renovation of the wing. 
This portion of the building was used as the setting for the popular television show "The West Wing".
East Wing.
The East Wing, which contains additional office space, was added to the White House in 1942. Among its uses, the East Wing has intermittently housed the offices and staff of the First Lady, and the White House Social Office. Rosalynn Carter, in 1977, was the first to place her personal office in the East Wing and to formally call it the "Office of the First Lady". The East Wing was built during World War II in order to hide the construction of an underground bunker to be used in emergencies. The bunker has come to be known as the Presidential Emergency Operations Center.
Grounds.
The White House and grounds cover just over 18 acres (about 7.3 hectares). Before the construction of the North Portico, most public events were entered from the South Lawn, which was graded and planted by Thomas Jefferson. Jefferson also drafted a planting plan for the North Lawn that included large trees that would have mostly obscured the house from Pennsylvania Avenue. During the mid-to-late 19th century a series of ever larger greenhouses were built on the west side of the house, where the current West Wing is located. During this period, the North Lawn was planted with ornate carpet-style flowerbeds. Although the White House grounds have had many gardeners through their history, the general design, still largely used as master plan today, was designed in 1935 by Frederick Law Olmsted, Jr. of the Olmsted Brothers firm, under commission from President Franklin D. Roosevelt. During the Kennedy administration, the White House Rose Garden was redesigned by Rachel Lambert Mellon. The Rose garden borders the West Colonnade. Bordering the East Colonnade is the Jacqueline Kennedy Garden, which was begun by Jacqueline Kennedy but completed after her husband's assassination. On the weekend of June 23, 2006, a century-old American Elm ("Ulmus americana" L.) tree on the north side of the building, came down during one of the many storms amid intense flooding. Among the oldest trees on the grounds are several magnolias ("Magnolia grandiflora") planted by Andrew Jackson. Michelle Obama planted the White House's first organic garden and installed beehives on the South Lawn of the White House, which will supply organic produce and honey to the First Family and for state dinners and other official gatherings.
Public access and security.
Historical accessibility.
Like the English and Irish country houses it was modeled on, the White House was, from the start, open to the public until the early part of the 20th century. President Thomas Jefferson held an open house for his second inaugural in 1805, and many of the people at his swearing-in ceremony at the Capitol followed him home, where he greeted them in the Blue Room. Those open houses sometimes became rowdy: in 1829, President Andrew Jackson had to leave for a hotel when roughly 20,000 citizens celebrated his inauguration inside the White House. His aides ultimately had to lure the mob outside with washtubs filled with a potent cocktail of orange juice and whiskey. Even so, the practice continued until 1885, when newly elected Grover Cleveland arranged for a presidential review of the troops from a grandstand in front of the White House instead of the traditional open house. Jefferson also permitted public tours of his house, which have continued ever since, except during wartime, and began the tradition of annual receptions on New Year's Day and on the Fourth of July. Those receptions ended in the early 1930s, although President Bill Clinton would briefly revive the New Year's Day open house in his first term.
The White House remained accessible in other ways; President Abraham Lincoln complained that he was constantly beleaguered by job seekers waiting to ask him for political appointments or other favors, or eccentric dispensers of advice like "General" Daniel Pratt, as he began the business day. Lincoln put up with the annoyance rather than risk alienating some associate or friend of a powerful politician or opinion maker.
Aviation incidents.
In 1974, a stolen Army helicopter landed without authorization on the White House grounds. Twenty years later, in 1994, a light plane crashed on the White House grounds, and the pilot died instantly.
As a result of increased security regarding air traffic in the capital, the White House was evacuated in 2005 before an unauthorized aircraft could approach the grounds.
Closure of Pennsylvania Avenue.
On May 20, 1995, primarily as a response to the Oklahoma City bombing of April 19, 1995, the United States Secret Service closed off Pennsylvania Avenue to vehicular traffic in front of the White House from the eastern edge of Lafayette Park to 17th Street. Later, the closure was extended an additional block to the east to 15th Street, and East Executive Avenue, a small street between the White House and the Treasury Building.
After September 11, 2001, this was made permanent in addition to closing E Street between the South Portico of the White House and the Ellipse. During the Boston Marathon Bombings, the road was closed to the public in its entirety for a period of two days.
The Pennsylvania Avenue closing has been opposed by organized civic groups in Washington, D.C. They argue that the closing impedes traffic flow unnecessarily and is inconsistent with the well-conceived historic plan for the city. As for security considerations, they note that the White House is set much farther back from the street than numerous other sensitive federal buildings are.
Prior to its inclusion within the fenced compound that now includes the Old Executive Office Building to the west and the Treasury Building to the east, this sidewalk served as a queuing area for the daily public tours of the White House. These tours were suspended in the wake of the September 11 attacks. In September 2003, they resumed on a limited basis for groups making prior arrangements through their Congressional representatives or embassies in Washington for foreign nationals and submitting to background checks, but the White House remained closed to the public. White House tours were suspended for most of 2013 due to budget constraints after sequestration. The White House reopened to the public in November 2013.
Protection.
The White House Complex is protected by the United States Secret Service and the United States Park Police.
NASAMS (Norwegian Advanced Surface to Air Missile System) were used to guard air space over Washington, D.C. during the 2005 presidential inauguration. The same NASAMS units have since been used to protect the president and all air space around the White House, which is strictly prohibited to aircraft.
Further reading.
</dl>

</doc>
<doc id="33060" url="http://en.wikipedia.org/wiki?curid=33060" title="Warren G. Harding">
Warren G. Harding

Warren Gamaliel Harding (November 2, 1865 – August 2, 1923) was the 29th President of the United States (1921–23), a Republican from Ohio who served in the Ohio Senate and then in the United States Senate, where he played a minor role.
With the Republican Party convention near deadlock, Harding was chosen as an inoffensive compromise candidate in the 1920 election. He brought leading advertising experts on board, especially Albert Lasker, to publicize his presidential appearance and conservative promises. He promised America a "return to normalcy" after World War I, with an end to violence and radicalism, a strong economy, and independence from European intrigues. He declared, "America's present need is not heroics, but healing; not nostrums, but normalcy; not revolution, but restoration; not agitation, but adjustment; not surgery, but serenity; not the dramatic, but the dispassionate;... not submergence in inter-nationality, but sustainment in triumphant nationality." 
Harding represented the conservative wing of his party in opposition to progressive followers of the late Theodore Roosevelt (who died in 1919) and Senator Robert M. La Follette, Sr.. He defeated Democrat and fellow Ohio newspaper publisher James M. Cox with the largest popular vote landslide (60% to 34%) in presidential history.
Historians underscore the strength of Harding's cabinet, which included Andrew Mellon at the Treasury, Herbert Hoover at Commerce, and Charles Evans Hughes at the State Department. He rewarded friends and contributors, known as the "Ohio Gang", with powerful government positions. Multiple cases of corruption were exposed during his presidency and after his death, including the notorious Teapot Dome scandal, regarded in pre-Watergate times as the "greatest and most sensational scandal in the history of American politics".
Domestically, Harding signed the first federal child welfare program, and dealt with striking mining and railroad workers in part by supporting an 8-hour work day. He created the Bureau of the Budget to prepare the first United States federal budget. Harding advocated an anti-lynching bill to curb violence against African Americans, but it failed to pass Congress. In foreign affairs, Harding spurned the League of Nations and negotiated peace treaties with Germany and Austria. His greatest foreign policy achievement came in the Washington Naval Conference of 1921–22, in which the world's major naval powers agreed on a naval limitations program that held sway for a decade.
In August 1923, Harding suddenly collapsed and died in California. His administration's many scandals have earned Harding a bottom-tier ranking from historians, but in recent years there has been some recognition of his fiscal responsibility and endorsement of African-American civil rights. Harding has been viewed as a more modern politician who embraced technology and was sensitive to the plights of minorities, women, and labor.
Early life.
Childhood and education.
Warren Gamaliel Harding was born November 2, 1865, in Blooming Grove, Ohio. His paternal ancestors, mostly ardent Baptists, hailed from Clifford, Pennsylvania, and migrated to Ohio in 1820. Nicknamed "Winnie", Harding was the eldest of eight children born to Dr. George Tryon Harding Sr. (1843–1928) and Phoebe Elizabeth (Dickerson) Harding (1843–1910). His mother's ancestors were Dutch, including the well known Van Kirk family. His mother, a devout Methodist, was a midwife who later obtained her medical license. His father, never quite content with his job or possessions, was forever swapping them for something better, and was usually in debt; he variously owned a farm, taught at a rural school north of Mount Gilead, Ohio, and also acquired a medical degree and started a small practice. It was rumored in Blooming Grove that one of Harding's great-grandmothers might have been African American. Harding's great-great grandfather Amos claimed that a thief, who had been caught in the act by the family, started the rumor in an attempt at extortion. Harding's family eventually moved to Caledonia, Ohio, where his father acquired "The Argus", a local weekly newspaper. It was at "The Argus" that Harding, from the age of 10, learned the basics of the journalism business. In 1878, his brother Charles and sister Persilla died, presumably from typhoid fever.
Harding continued to study the printing and newspaper trade as a college student at Ohio Central College in Iberia. At the same time, he worked at the "Union Register" in Mount Gilead. Harding became an accomplished public speaker in college, and graduated in 1882 at the age of 17 with a Bachelor of Science degree. As a youngster, he had become an accomplished cornet player and played in various bands, and in 1884 Harding gained popular recognition in Marion when his Citizens' Cornet Band won the third-place $200 prize at the highly competitive Ohio State Band Festival in Findlay. The money paid for the band's snappy dress uniforms, which Harding had bought on credit.
Journalism career and marriage.
Upon graduating, Harding had stints as a teacher and as an insurance man, and made a brief attempt at studying law. He then raised $300 in partnership with others to purchase the failing "Marion Daily Star", the weakest of the growing city's three newspapers. By 1886, he completely owned the "Star". He revamped the paper's editorial platform to support the Republican Party and became an ardent supporter of Governor "Fire Alarm Joe" Foraker. This political stance put him at odds with those who controlled local politics in Marion. When Harding moved to unseat the "Marion Independent" as the official daily paper, he met with strong resistance from local figures, such as Amos Hall Kling, one of Marion's wealthiest real estate speculators. The editorial battle with the "Independent" became so heated that, at the inevitable mention of Harding's questionable bloodline, father and son brought a shotgun and demanded a retraction at gunpoint. They were successful.
While Harding won the war of words and made the "Marion Daily Star" one of the most popular newspapers in the county, the battle took a toll on his health. In 1889, at age 24, he suffered from exhaustion and nervous fatigue. He spent several weeks at the Battle Creek Sanitarium to regain his strength and ultimately made 5 visits over 14 years. Harding later returned to Marion to continue operating the paper. He spent his days promoting the community on the editorial pages, and his evenings "bloviating" (a word Harding used frequently) with his friends over games of poker. In 1893, the "Star" supplanted the "Independent" as the official paper for Marion's governmental notices, after Harding exposed the rival paper for overcharging the city. In 1896, the "Independent" ceased doing business and Amos Kling immediately financed and launched another rival paper, the "Republican Transcript", in a failed attempt to derail his son-in-law. Harding also made political speeches on the Chautauqua circuit and expressed admiration for his ideal American patron, Alexander Hamilton. He also is said to have originated the phrase "Founding Fathers".
In 1900, political opponent J.F. McNeal, with Amos Kling's help, secretly bought up $20,000 in loans owed by Harding, and immediately called them due in full. Harding just barely secured the funds to pay off the debt to save the "Star". In the last year of his Presidency, anticipating no resumption of his journalism career following his years in the White House, Harding sold the "Star" to Louis H. Brush and Roy D. Moore for $550,000.
On July 8, 1891 Harding married Florence Kling DeWolfe, the daughter of his nemesis Amos Hall Kling—who was also her nemesis. Florence Kling DeWolfe was a divorcee, 5 years Harding's senior, and the mother of a young son, Marshall Eugene DeWolfe. Florence's father had soundly condemned her first—compulsory—marriage, to an alcoholic. He had disowned her, but her mother had remained loyal and supportive. She pursued Harding persistently, until he reluctantly proposed. According to noted biographer Russell, he was compelled to propose not so much because of true love, but of the prospect of social acceptance and standing. Incensed by his daughter's decision to marry Harding, Amos Kling prohibited his wife from attending the wedding (she sneaked in long enough to see the vows exchanged) and refused to speak to his daughter or son-in-law for 8 years. Her mother continued to provide support on the sly.
The couple was complementary, with Harding's affable personality balancing his wife's no-nonsense approach to life. Florence Harding, exhibiting her father's determination and business sense, turned the "Marion Daily Star" into a profitable business in her management of the circulation. She has been credited with helping Harding achieve more than he might have alone; some have speculated that she pushed him all the way to the White House. Early in their marriage, Harding bestowed on her the lasting nickname "Duchess" as a nod to the imperious (and often alienating) persona she shared with her father.
Early political career.
Ohio emergence.
Harding made his foray into politics running for the Marion County Auditor's office, primarily to gain political exposure—his inability to win the election was a foregone conclusion in the heavily Democratic county. When his newspaper business attained sufficient economic stability, and even dominance, in Marion, Harding and his wife traveled widely throughout the country, which broadened Harding's exposure at political gatherings. Biographer Andrew Sinclair asserts that, like many contemporaries during the days of Ohio Republican Party boss Mark Hanna, Harding was involved with graft and excessive patronage. Harding allegedly arranged free public-transit passes for his family in return for favorable coverage in his newspaper. Harding, in 1897, was said to have facilitated his sister's appointment as a teacher for the blind over supposedly more qualified candidates. Harding was also accused of collusion with other newspapers on the price-fixing of public printing bids and dividing the profits from low-straw biddings. No formal charges were made against Harding based on these accusations. The accomplished publisher also gained a flair for public speaking, and in 1899 Harding was elected to fill the Ohio State Senate seat for the 13th Senatorial District, despite Amos Kling's financing of a primary opponent. Shortly after this victory, there was a fortuitous meeting with Ohio Republican party leader and McKinley ally, Harry M. Daugherty, who commented about him, "Gee, what a great looking President he'd make."; Daugherty later assumed the primary role in Harding's political career.
As a Republican state senator, Harding was a partisan regular and did favors for political bosses Mark Hanna and Harry M. Daugherty. Harding's only notable reform effort in his first term (Ohio state offices had 2-year terms) was a progressive bill to revamp the municipal code, which had passed the Senate but was halted by a single member's procedural call to "reconsider". As asserted by Sinclair, Harding, against his own conscience, signed a municipal bill that protected Republican party patronage and graft. In his second term, he was chosen Republican Floor Leader. In early 1903 Harding announced his campaign for Governor of Ohio, which was soon thwarted by an intra-party alliance that assured the election of fellow Republican Myron T. Herrick; Harding was awarded the position of Lieutenant Governor of Ohio, a post he occupied from 1904 to 1906. In short order, a number of ill-advised decisions by Gov. Herrick damaged his popularity. As the 1906 election approached, Harding saw an opening and announced his candidacy for Governor again. Nevertheless, the party bosses stuck by Herrick, and Harding took his name out of the running for any position on the ticket, which was defeated by the Democrats.
While Harding was dwindling politically, there were developments on the personal and business front. In 1907, Amos Kling married his second wife and began an effort at rapprochement with daughter and son-in-law. As a result, the Klings and the Hardings took a cruise to Europe together. Soon after their return, Harding reorganized his newspaper business into the Harding Publishing Co., issued stock in the company, took two-thirds for himself and allowed his employees to purchase the rest; this was the first profit-sharing arrangement of its kind in Ohio.
Harding sought the 1910 gubernatorial nomination of the GOP, which was deeply divided between progressive and conservative wings of the party, but could not defeat the united Democrats; he lost the election to incumbent Judson Harmon. Harding took his first election loss in stride, saying "...I have lost nothing which I ever had except a few dollars which I can make again, a few pounds of flesh which I can grow again, a few false friends of whom I am well rid, and an ambition which simply fettered my freedom and did not make for happiness."
U.S. Senator.
In 1912, incumbent President William Howard Taft chose Harding, a talented speaker, to give Taft's nominating speech at the embattled Republican National Convention in Chicago. Taft would later be nominated by President Harding, confirmed by the Senate, and served as Chief Justice of the Supreme Court during Harding's administration. Before Harding completed his introduction, a fist fight ensued between the Taft supporters and the more progressive Roosevelt faction, but his speech was a personal success. By 1914 the Republican Party was beginning to show signs of reunification, so that support weakened for Ohio's U.S. Senator Theodore Burton, who then decided not to stand for re-election. When prompted, Harding agreed to run for Burton's seat against his mentor, "Fire Engine" Joe Foraker, in the Republican primary, and he emerged victorious. Henry Daugherty at this point was on a first name basis with Harding and supported his campaign. Harding's general election opponent, Timothy Hogan, fell victim to fervid anti-Catholic sentiment (which Harding did not voice). Having defeated Hogan, Harding became Ohio's first U.S. Senator elected by popular vote. The 1914 general election came on the heels of the outbreak of World War I—an issue Harding played down because of the significant German immigrant population in his district. He served in the Senate from 1915 until his inauguration as President in 1921, making him the first sitting senator to be elected President of the United States; John F. Kennedy and Barack Obama followed in this pattern. (James A. Garfield was at the time of his presidential election a non-incumbent senator-elect.)
When Harding joined the U.S. Congress, the Democrats controlled the Senate and House of Representatives, led by a progressive Democratic President Woodrow Wilson; the opposition dominated the legislative agenda. Harding was often considered a fence sitter on most issues, be that labor, big business, women's suffrage, or prohibition. He was "the harmonizer", declaring that a "righteous mean" could always be obtained on an issue. He did vote on legislation to protect the alcohol industry 30 times and was against Philippine independence. He was staunchly opposed to government ownership of business. In startling form, he once spoke in support of a strong executive, at least in wartime, saying about President Wilson, "He is already ... our partial dictator. Why not make him complete and supreme dictator?" He joined with 39 other senators in opposition to Wilson's proposed League of Nations. Harding took on a personal secretary in the Senate, George B. Christian Jr., a former neighbor, who protected him from political patrons and intrusive inquiries, and served until the future president's death. Harding introduced 134 bills, but substantively his six-year record as Senator was unremarkable; his attendance was inconsistent, he spoke minimally on the floor of the Senate and offered no major bill or debate. Harding was not even present for the vote on the women's suffrage amendment, though he "paired" his vote with another member, in effect supporting it. He was nevertheless popular and acquired many very close friends in the chamber. This popularity led to his serving as Chairman of the 1916 Republican Convention as well as Keynote Speaker.
Presidential election of 1920.
Republican nomination.
In 1918, when Theodore Roosevelt was entertaining plans (later abandoned) to reprise his presidency, he considered Harding had strong potential to run and serve as Vice President, and discussed with Harry Daugherty the desirability of having Harding on his ticket. In 1919, the first candidate to declare for the GOP nomination was General Leonard Wood. The GOP bosses were nevertheless determined to have a dependable listener, and were lukewarm toward the General. Some in the party began to scout for such an alternative, and Harding's name arose, despite his reluctance, due to his unique ability to draw vital Ohio votes. Also at the forefront of a throng of candidates for the nomination were Hiram Johnson, Frank Lowden and Herbert Hoover. Harry Daugherty, who became Harding's campaign manager, and who was sure none of these candidates could garner a majority, convinced Harding to run after a marathon discussion of six-plus hours. Daugherty's campaign style was variously described as pugnacious, devious and no holds barred. For example, shortly before the GOP convention, Daugherty struck a deal with millionaire and political opportunist Jake Hamon, whereby 18 Oklahoma delegates whose votes Hamon had bought for Lowden were committed to Harding as a second choice if Lowden's effort faltered.
Harding's supporters thought of him as the next McKinley. By the time the convention began, a Senate sub-committee had tallied the monies spent by the various candidates, with totals as follows: Wood—$1.8 million; Lowden—$414,000; Johnson—$194,000; and Harding—$114,000; the committed delegate count at the opening gavel was: Wood—124; Johnson—112; Lowden—72; Harding—39. Still, at the opening, less than one-half of the delegates were committed. No candidate was able to corral a majority after nine ballots. Republican Senators and other leaders, who were divided without a singular political boss, met in Room 404 of the Blackstone Hotel in Chicago and after a nightlong session, tentatively concluded Harding was the best possible compromise candidate. According to Francis Russell, though additional meetings took place, this particular meeting came to be known as the "smoke filled room". Before Harding received the formal nod, George Harvey summoned him. Harvey told him he was considered the consensus nominee, and asked if he knew, "before God," whether anything in his life would be an impediment. After mulling the question over for some minutes, Harding replied no, despite his alleged adulterous affairs. The next day, when Harding was nominated on the tenth ballot, Mrs. Harding was so startled, she inadvertently stabbed Harry Daugherty in the side with her hatpins. The local Masons could not resist the opportunity to co-opt Harding's new status, and promoted him to the Sublime Degree of a Master Mason.
General election.
In the 1920 election, Harding ran against Democratic Ohio Governor James M. Cox, whose running mate was Assistant Secretary of the Navy Franklin D. Roosevelt. The election theme became a rejection of the "progressive" ideology of the Woodrow Wilson Administration in favor of the "laissez-faire" approach of the William McKinley era.
Harding ran on a promise to "Return to Normalcy", a seldom-used term he popularized, and healing for the nation after World War I. The policy called for an end to the abnormal era of the Great War, along with a call to reflect three trends of the time: a renewed isolationism in reaction to the War, a resurgence of nativism, and a turning away from government activism.
On July 28, 1920, Harding's aide Albert Lasker, a top advertising executive from Chicago, unleashed a broad-based advertising campaign that used modern advertising techniques for the first time in a presidential campaign. Lasker's approach included newsreels and sound recordings, all in an effort to enhance Harding's patriotism and affability. Farmers were sent brochures decrying the alleged abuses of Democratic agriculture policies. African Americans and women were also given literature in an attempt to take away votes from the Democrats. Professional advertisers including Chicagoan Albert Tucker were consulted. Billboard posters, newspapers and magazines were employed in addition to motion pictures. Five thousand speakers were trained by advertiser Harry New and sent abroad to speak for Harding; 2,000 of these speakers were women. Telemarketers were used to make phone conferences with perfected dialogues to promote Harding. Lasker had 8,000 photos distributed around the nation every two weeks of Harding and his wife.
Lasker designed the "front porch campaign" during the late summer and fall of 1920 that put Harding's name and image everywhere. It was the first front porch campaign since McKinley in 1896, and the first to receive widespread newsreel coverage. It was also the first modern campaign to use the power of Hollywood and Broadway stars, who travelled to Marion for photo opportunities with Harding and his wife. Al Jolson, Lillian Russell, Douglas Fairbanks, and Mary Pickford were among the luminaries to make the pilgrimage to his house in central Ohio. Business icons Thomas Edison, Henry Ford, and Harvey Firestone also lent their cachet to the campaign. From the onset of the campaign until the November election, over 600,000 people travelled to Marion to participate.
The campaign owed a great deal to Florence Harding, who played a more active role than the wives of previous candidates had. She cultivated the relationship between the campaign and the press. As the business manager of the "Star", she understood reporters and their industry. She played to their needs by being available to answer questions, pose for pictures, or deliver food from her kitchen to the press office—a bungalow that she had constructed at the rear of their property in Marion. Mrs. Harding even coached her husband on the proper way to wave to newsreel cameras to make the most of coverage. 
Campaign manager Lasker struck a deal with Harding's paramour, Carrie Phillips, and her husband Jim Phillips, whereby the couple agreed to leave the country until after the election. Ostensibly, Mr. Phillips was to investigate the silk trade.
The campaign also drew on Harding's popularity with women. Considered handsome, Harding photographed well compared to Cox. However, it was mainly Harding's Senate support for women's suffrage legislation that made him popular in that demographic. Ratification of the 19th Amendment in August 1920 brought huge crowds of women to Marion, Ohio to hear Harding speak. Immigrant groups such as ethnic German Americans and Irish Americans, who made up an important part of the Democratic coalition, also voted for Harding, in reaction to the nation's persecution of the Germans during and after the war and Wilson's retraction of support for Irish independence.
The 1920 election was the first in which women could vote nationwide, and the first to be covered on the radio, thanks to KDKA ("8ZZ") in Pittsburgh, Pennsylvania, 8MK (later WWJ) in Detroit, and the educational and amateur radio station 1XE (later WGI) at Medford Hillside, Massachusetts – all of which carried the election returns. Harding received 60% of the national vote, the highest percentage ever recorded up to that time, and 404 electoral votes. Cox received 34% of the national vote and 127 electoral votes. Campaigning from a federal prison, Socialist Eugene V. Debs received 3% of the national vote. The Presidential election results of 1920, for the first time in U.S. history, were announced live by radio. Harding was the only Republican presidential candidate to ever defeat Democrat Franklin D. Roosevelt on a presidential ticket. At the same time, the Republicans picked up an astounding 63 seats in the House of Representatives. Harding immediately embarked on a vacation that included an inspection tour of facilities in the Panama Canal Zone.
African-American lineage contention.
During the campaign, Democratic opponents spread rumors that Harding's great-great-grandfather was a West Indian black person and that other blacks might be found in his family tree. In an era when the "one-drop rule" would classify a person with any African ancestry as black, and black people in the South had been effectively disfranchised, Harding's campaign manager responded, "No family in the state (of Ohio) has a clearer, a more honorable record than the Hardings', a blue-eyed stock from New England and Pennsylvania, the finest pioneer blood."
Historian and opponent William Estabrook Chancellor publicized the rumors, based on supposed family research, but perhaps reflecting no more than local gossip. The rumors may have been sustained by a statement Harding allegedly made to newspaperman James W. Faulkner on the subject, which he perhaps meant to be dismissive: "How do I know, Jim? One of my ancestors may have jumped the fence." However, while there are gaps in the historical record, studies of his family tree have not found evidence of an African-American ancestor.
Presidency: 1921–1923.
Harding preferred a low-key inauguration, without the customary parade, leaving only the swearing-in ceremony and a brief reception at the White House. In his inaugural speech he declared, "Our most dangerous tendency is to expect too much from the government and at the same time do too little for it." Literary critic H.L. Mencken was appalled, announcing that:
The Hardings brought a different style to the running of the White House. Though Mrs. Harding did keep a little red book of those who had offended her, the executive mansion was now once again open to the public, including the annual Easter egg roll. Harding's administration followed the Republican national platform. Energized by his landslide, Harding felt the "pulse" of the nation and for the 28 months in office he remained popular both nationally and internationally. Harding's administration has been critically viewed due to multiple scandals, while his successes in office were often given credit to his capable cabinet appointments that included future President Herbert Hoover. Author Wayne Lutton asked, "Was Harding really a failure?", citing former Watergate persona John Dean, who grew up near Harding's home, as saying Harding's accomplishments included income tax and federal spending reductions, economic policies that reduced "stagflation", a reduction of unemployment by 10%, and a bold foreign policy that created peace with Germany, Japan, and Central America, although Dean's work itself only cites a "slight decline in unemployment figures" and does not mention "stagflation" at all. Herbert Hoover, while serving in Harding's cabinet, was confident the President would serve two terms and return the world to normalcy. Later, in his own memoirs, he stated that Harding had "neither the experience nor the intellect that the position needed." One of Harding's most important decisions was the appointment of former President William Howard Taft as Chief Justice of the Supreme Court, a position Taft had always coveted, more so than the Presidency.
Harding pushed for the establishment of the Bureau of Veterans Affairs (later organized as the Department of Veterans Affairs), the first permanent attempt at answering the needs of those who had served the nation in time of war. In April 1921, Harding spoke before a special joint session of Congress that he had called. He argued for peacemaking with Germany and Austria, emergency tariffs, new immigration laws, regulation of radio and trans-cable communications, retrenchment in government, tax reduction, repeal of wartime excess profits tax, reduction of railroad rates, promotion of agricultural interests, a national budget system, an enlarged merchant marine, and a department of public welfare. He also called for measures to end lynching, but not wanting to make enemies in his own party and with the Democrats, he did not fight for his program. Generally, there was a lack of strong leadership in the Congress and, unlike his predecessors Roosevelt and Wilson, Harding was not inclined to fill that void.
According to biographers, Harding got along better with the press than any other previous President, being a former newspaperman. Reporters admired his frankness, candor, and his confessed limitations. He took the press behind the scenes and showed them the inner circle of the presidency. Harding, in November 1921, also implemented a policy of taking written questions from reporters during a press conference. Harding's relationship with Congress, however, was strained and he did not receive the traditional honeymoon given to new Presidents. Before Harding's election, the nation had been adrift; President Woodrow Wilson had been ill by a debilitating stroke for 18 months and before that Wilson had been in Europe for several months attempting to negotiate a peace settlement after World War I. By contrast, at the March 4, 1921 Inaugural, Harding looked strong, with grey hair and a commanding physical presence. Wilson's successor stressed the importance of the ceremonial aspects of the office of President. This emphasis fulfilled his desire to travel the breadth of the country to officiate at formal functions.
Although Harding was committed to putting the "best minds" on his cabinet, he often rewarded those persons who were active and contributed to his campaign by appointing them to high federal department positions. Wayne Wheeler, leader of the Anti-Saloon League, was allowed by Harding to dictate who would serve on the Prohibition Commission. Graft and corruption charges permeated Harding's Department of Justice; bootleggers confiscated tens of thousands cases of whiskey through bribery and kickbacks. Harding, out of loyalty, appointed Harry M. Daugherty to U.S. Attorney General because he felt he owed Daugherty for running his 1920 campaign. After the election, many people from the Ohio area moved to Washington, D.C., made their headquarters in a little green house on K Street, and would be eventually known as the "Ohio Gang". The financial and political scandals caused by these men, in addition to Harding's own personal controversies, severely damaged Harding's personal reputation and eclipsed his presidential accomplishments. In his most open challenge to Congress, Harding forced a deferral of a budget-busting World War I soldier's bonus in an effort to reduce costs.
A 2008 study of presidential rankings for "The Times" placed Harding at number 34 and a 2009 C-SPAN survey ranked Harding at 38. In 2010, a "Siena College" poll of Presidential scholars placed Harding at 41. The same poll ranked Harding 26 in the "Ability to Compromise" category.
Harding presided over the nation's initial consecration of the Tomb of the Unknown Soldier. This followed similar commemorations established by Britain, France and Italy. The fallen hero was chosen from a group previously interred at Romagne Military Cemetery in France, and was re-interred at Arlington National Cemetery.
On December 23, 1921 Harding calmed the 1919–1920 Bolshevik scare, and released an election opponent, socialist leader Eugene Debs, from prison. This was part of an effort to return the United States to normalcy after the Great War. Debs, a forceful World War I antiwar activist, had been convicted under sedition charges brought by the Wilson administration for his opposition to the draft during World War I. Despite many political differences between the two candidates Harding commuted Debs' sentence to time served; however, he was not granted an official Presidential pardon. Debs' failing health was a contributing factor for the release. Harding granted a general amnesty to 23 prisoners, alleged anarchists and socialists, active in the Red Scare.
Harding's party suffered the loss of 79 seats in the House in the 1922 mid-term elections, leaving them with a razor-thin majority. The President determined to fill the void of leadership in the party and attempted to take a more aggressive role in setting the legislative agenda.
The Hardings visited their home community of Marion, Ohio, once during the term, when the city celebrated its centennial during the first week of July. Harding arrived on July 3, gave a speech to the community at the Marion County Fairgrounds on July 4, and left the following morning for other speaking commitments.
Joint Session of Congress 1921.
On April 12, Harding called a joint session of Congress to address matters that he deemed of national and urgent importance. That speech, considered his best, contained few political platitudes and was enthusiastically received by Congress. On the economic front, Harding urged Congress to create a Bureau of the Budget, cut expenditures, and revise federal tax laws. Harding urged increased protectionist tariffs, lower taxes, and agriculture legislation to help farmers. In the speech, Harding advocated aviation technology for civil and military purposes, development and regulation of radio technology, and passage of a federal anti-lynching law to protect African Americans. Harding advocated, in terms of foreign affairs, a "conference and cooperation" of nations to prevent war—yet flatly stated that the U.S. should not enter the League of Nations. Harding endorsed peace between all former enemy nations from World War I and the funding and liquidation of war debts.
Domestic policies and economy.
Bureau of the Budget and Veterans Bureau.
Harding signed the Budget and Accounting Act of 1921, considered one of his greatest domestic and enduring achievements. Harding got authorization from Congress for the country's first formal budgeting process—establishing of the Bureau of the Budget. The law created the presidential budget director, who was directly responsible to the President rather than to the Secretary of Treasury. The law also stipulated that the President must submit a budget annually to the U.S. Congress. All presidents since have had to submit an annual budget to Congress. The General Accounting Office was created to assure oversight in the federal budget expenditures. Harding appointed Charles Dawes, known for being an effective financier, as the first director of the Bureau of the Budget. Dawes reduced government spending by $1.5 billion his first year as director, a 25% reduction, along with another 25% reduction the following year. In effect, the Government budget was nearly cut in half in just two years.
Harding believed the federal government should be fiscally managed in a way similar to private sector businesses. He had campaigned on the slogan, "Less government in business and more business in government." "Harding was true to his word, carrying on budget cuts that had begun under a debilitated Woodrow Wilson. Federal spending declined from $6.3 billion in 1920 to $5 billion in 1921 and $3.3 billion in 1922. Tax rates, meanwhile, were slashed—for every income group. And over the course of the 1920s, the national debt was reduced by one third."
On August 9, 1921, Harding signed legislation known as the Sweet Bill, which established the Veterans Bureau as a new agency. After World War I, 300,000 wounded veterans were in need of hospitalization, medical care, and job training. To handle the needs of these veterans, the new Veterans Bureau incorporated the War Risk Insurance Bureau, the Brig. Gen. Charles E. Sawyer's Federal Hospitalization Bureau, along with three other bureaus that dealt with veteran affairs. Harding regrettably appointed Colonel Charles R. Forbes, albeit a decorated war veteran, as the Veteran Bureau's first director (see scandal below), a position that reported directly to the President. The Veterans Bureau later was incorporated into the Veterans Administration and ultimately the Department of Veterans Affairs.
Postwar recession and recovery.
On March 4, Harding assumed office while the nation was in the midst of a postwar economic decline, known as the Depression of 1920–21. By summer of his first year in office, an economic recovery began. He convened the Conference of Unemployment in 1921, headed by Secretary of Commerce Herbert Hoover, that proactively advocated stimulating the economy with local public work projects and encouraged businesses to apply shared work programs. Harding's Treasury Secretary, Andrew Mellon, ordered a study that claimed to demonstrate that as income tax rates were increased, money was driven underground or abroad. Mellon concluded that lower rates would increase tax revenues. Based on this advice, Harding cut taxes, starting in 1922. The top marginal rate was reduced annually in four stages from 73% in 1921 to 25% in 1925. Taxes were cut for lower incomes starting in 1923.
Revenues to the treasury decreased substantially. Libertarian historian Thomas Woods contends that the tax cuts ended the Depression of 1920–1921. Historians Schweikart and Allen also attribute this to the tax cuts. Schweikart and Allen argue that Harding's tax and economic policies in part "... produced the most vibrant eight year burst of manufacturing and innovation in the nation's history," though the recession had already ended three months into Harding's first term (before taxes were cut) and was yet again in recession by 1923. Wages, profits, and productivity all made substantial gains during the 1920s. Daniel Kuehn has attributed the improvement to the earlier monetary policy of the Federal Reserve, and notes that the changes in marginal tax rates were accompanied by an expansion in the tax base that could account for the increase in revenue.
Robert Gordon, a Keynesian, notes, "government policy to moderate the depression and speed recovery was minimal. The Federal Reserve authorities were largely passive. ... Despite the absence of a stimulative government policy, however, recovery was not long delayed." Kenneth Weiher, an economic historian, notes, "despite the severity of the contraction, the Fed did not move to use its powers to turn the money supply around and fight the contraction." He concedes that "the economy rebounded quickly from the 1920–1921 depression and entered a period of quite vigorous growth." Paul Krugman argues that the monetary base expanded significantly from 1922 to 1925, and that this expansion was accompanied by a reduction in commercial paper rates. Allan Meltzer agrees that the rising real money stock motivated wealth owners to invest. Recovery did not last long. Another economic contraction began near the end of Harding's presidency in 1923, while tax cuts were still underway. A third contraction followed in 1927 during the next presidential term.
Farm acts and Radio Conferences.
In 1921 and 1922, Harding signed a series of bills regulating agriculture. The legislation emanated from President Woodrow Wilson's 1919 Federal Trade Commission report, which investigated and discovered "manipulations, controls, trusts, combinations, or restraints out of harmony with the law or the public interest" in the meat packing industry. The first law was the Packers and Stockyards Act, prohibiting packers from engaging in unfair and deceptive practices. Two amendments were made to the Farm Loan Act of 1916 that President Wilson had signed into law, which had expanded the maximum size of rural farm loans. The Emergency Agriculture Credit Act authorized new loans to farmers to help them sell and market livestock. The Capper–Volstead Act, signed by Harding on February 18, 1922, protected farm cooperatives from anti-trust legislation. The Future Trading Act was also enacted, regulating "puts and calls", "bids", and "offers" on futures contracting. Later, on May 15, 1922, the Supreme Court ruled this legislation unconstitutional.
On February 27, 1922, Harding implemented the first of a series of Radio Conferences headed by Secretary of Commerce Herbert Hoover. The last Radio Act of 1912 was considered "inadequate" and "chaotic"; change was necessary to help the fledgling radio industry. At the first meeting, 30 representatives—including amateurs, governmental agencies, and the radio industry made "cooperative efforts" to ensure the public interest in broadcasting, who would broadcast, and for what purpose, and to curb direct advertising. Also discussed was how wattage power used by broadcasters would be distributed depending on the radio station's conditional use and location.
A second radio conference was called in 1923, and this time Secretary Hoover successful obtained radio regulation power without legislation. Hoover himself, in January 1923, told the press there was an, "...urgent need for radio regulation." Large radio stations such as Westinghouse advocated that only 25 larger radio stations in large metropolitan areas be allowed to broadcast, while smaller stations would be given limited power. At the end of the meeting, the industrialists agreed to give Hoover the power to, "...regulate hours and wave lengths of operation of stations when such action is necessary to prevent interference detrimental to the public good."
Harding became the first president to have a radio in his office, when on February 8, 1922, he had a radio set installed in the White House so he could listen to news and music as his schedule permitted. On June 14, Harding was also the first president that the American public heard on the new mass medium. He spoke on radio at a dedication site in honor of Francis Scott Key, who wrote the words to the "Star Spangled Banner".
Revenue Act and Highway Act of 1921.
On November 22, 1921, Harding signed the Revenue Act of 1921, which greatly reduced taxes for the wealthiest Americans. Protests from Republican farmers caused the deductions to be less than Secretary of Treasury Andrew Mellon desired. The lengthy 96-page Act reduced the corporate tax from 65% to 50% and provided for ultimate elimination of the excess-profits tax during World War I.
The 1920s were a time of modernization for America. To improve and expand the nation's highway system, Harding signed the Federal Highway Act of 1921. From 1921 to 1923, the federal government spent $162 million on America's highway system, infusing the U.S. economy with a large amount of capital. In 1922, Harding proclaimed that America was in the age of the "motor car". He stated that the automobile, "reflects our standard of living and gauges the speed of our present-day life."
Fordney–McCumber Tariff.
On September 21, 1922, Harding enthusiastically signed the Fordney–McCumber Tariff Act. The protectionist legislation was sponsored by Representative Joseph W. Fordney and Senator Porter J. McCumber. It increased the tariff rates contained in the previous Underwood-Simmons Tariff Act of 1913, to the highest level in the nation's history. Harding became concerned when the agriculture business suffered economic hardship from the high tariffs. Previously, on May 21, 1921 Harding had signed emergency legislation that put tariffs on select foreign inputs. By 1922, Harding began to realize that the long-term effects of tariffs could be detrimental to national economy, despite the short-term benefits. His successors, Coolidge and Hoover, advocated tariff legislation. The tariffs established in the 1920s have historically been viewed as a contributing factor to causing the Wall Street Crash of 1929.
Foreign policies.
Harding was very specific in commenting on the appointment of Secretary of State Charles E. Hughes, that the secretary would be the sole spokesman for the State Department (as opposed to the Wilson administration). The U.S. Senate had refused to ratify the Treaty of Versailles in both 1919 and 1920 because it required the U.S. to endorse the League of Nations. Hughes worked behind the scenes to formally make peace with Germany and the successor states to Austria-Hungary, Austria and Hungary. This began with the Knox–Porter Resolution. The U.S.–German Peace Treaty, U.S.–Austrian Peace Treaty and U.S.–Hungarian Peace Treaty were ratified in 1921.
Washington arms conference and treaties 1921–1922.
Harding spearheaded, with the urging of the Senate, a monumental global conference, held in Washington, D.C., to limit the armaments of world powers, including the U.S., Japan, Great Britain, France, Italy, China, Belgium, Netherlands and Portugal. Harding's Secretary of State, Charles E. Hughes, assumed a primary role in the conference and made the pivotal proposal—the U.S would reduce its number of warships by 30 if Great Britain decommissioned 19, and Japan 17 ships. Starting on November 6, 1921 and ending February 6, 1922, world leaders met to control a naval arms race and to bring stability to East Asia. The conference enabled the great powers to potentially limit their large naval deployment and avoid conflict in the Pacific. The delegation of nations also worked out security issues and promoted cooperation in the Far East.
The conference produced six treaties and twelve resolutions among the participating nations, which ranged from limiting the size or "tonnage" of naval ships to custom tariffs. The treaties, which easily passed the Senate, also included agreements regulating submarines, dominions in the Pacific, and dealings with China. The treaties only remained in effect until the mid-1930s, however, and ultimately failed. Japan eventually invaded Manchuria and the arms limitations no longer had any effect. The building of "monster warships" resumed and the U.S. and Great Britain were unable to quickly rearm themselves to defend an international order and stop Japan from remilitarizing.
Harding, in an effort to improve U.S. relations with Mexico, Latin America, and the Caribbean Islands implemented a program of military disengagement. On April 20, 1921, the Thomson–Urrutia Treaty with Colombia was ratified by the Senate and signed by Harding; that awarded $25,000,000 as indemnity payment for land used to make the Panama Canal.
Harding stunned the capital when he sent to the Senate a message supporting the participation of the U.S. in the proposed Permanent Court of International Justice. This was not favorably received by Harding's colleagues; a resolution was nevertheless drafted, in deference to the President, and then promptly buried in the Foreign Affairs Committee.
Civil rights, labor disputes and strikes.
When the governor of West Virginia Ephraim Morgan in 1921 requested federal troops to stop miners who were battling state police and militia, Harding issued two proclamations to keep the peace. Finally he sent in an Army unit who ended the mini-war.
Great railway strike and repeal of 12-hour workday.
A year after Harding contended with the 1921 mining labor war in West Virginia, a strike broke out during the summer of 1922 in the railroad industry. On July 1, 1922, 400,000 railroad workers and shopmen went on strike over hourly wages reduced by seven cents and a 12 hour-day workweek. Strike busters were brought in to fill the positions. Harding proposed a settlement that gave the shop workers some concessions; however, the railroad owners objected. Harding sent out the National Guard and 2,200 deputy U.S. marshals to keep the peace. Attorney General Daugherty convinced Judge James H. Wilkerson to issue a broad sweeping injunction to break up the strike. This was known as the "Wilkerson" or "Daugherty" injunction, which enraged the union as well as many in congress, as it prohibited First Amendment rights. Harding had Daugherty and Wilkerson withdraw the objectionable parts of the injunction. The injunction ultimately succeeded in ending the strike; however, tensions remained high between railroad workers and company men for years. Daugherty's harsh injunction against labor created great discord in Harding's cabinet. This, along with Daugherty's other activities, prompted one Minnesota congressman, Oscar Keller, to unsuccessfully attempt to bring impeachment charges against the Attorney General.
In 1922, Harding and Secretary of Commerce Herbert Hoover convened a White House conference with manufacturers and unions, to reduce the length of the 12-hour workday, in a move for the cause of labor. The labor movement supported an 8-hour day and a 6-day workweek. Harding wrote Judge Gary, head of US Steel, advocating labor reform. The labor conference, however, decided against labor's demands in 1923. Both Harding and Hoover were disappointed with the committee's ruling. Harding wrote a second letter to Gary and with public support the steel industry repealed the 12-hour work day to an eight-hour work day.
Anti-lynching movement and immigration.
Notably in an age of severe racial intolerance during the 1920s, Harding did not hold any racial animosity, according to historian Carl S. Anthony. In a speech on October 26, 1921, given in segregated Birmingham, Alabama Harding advocated civil rights for African Americans; the first President to openly advocate black political, educational, and economic equality during the 20th century. In the "Birmingham speech," Harding wanted African Americans to have equal educational opportunities and greater voting rights in the South. The white section of the audience listened in silence while the black section of the segregated audience cheered. Harding went further and viewed the race problem as a national and international issue and desired that the sectionalism of the Solid South and black membership of the Republican party be broken up. Harding, however, openly stated that he was not for black social equality in terms of racial mixing or intermarriage. Harding also spoke on the Great Migration, believing that blacks migrating to the north and west to find employment had actually harmed race relations between blacks and whites.
He named some African Americans to federal positions, such as Walter L. Cohen of New Orleans, Louisiana, whom he named comptroller of customs. Harding also advocated the establishment of an international commission to improve race relations between whites and blacks; however, strong political opposition by the Southern Democratic bloc prevented the commission. The Ku Klux Klan had its highest membership during its revival in the early 1920s.
Harding supported Congressman Leonidas Dyer's federal anti-lynching bill, known as the Dyer Bill, which passed the House of Representatives on January 26, 1922. The bill was defeated in the Senate by a Democratic filibuster. Harding had previously spoken out publicly against lynching on October 21, 1921. Congress had not debated a civil rights bill since the 1890 Federal Elections Bill. 
The Per Centum Act of 1921 signed by Harding on May 19, 1921, reduced the numbers of immigrants to 3% of a country's represented population based on the 1910 census. The Act allowed unauthorized immigrants to be deported. Harding and Secretary of Labor James Davis believed that enforcement had to be humane. Harding often allowed exceptions granting reprieves to thousands of immigrants.
Sheppard–Towner Maternity Act.
On November 21, 1921, Harding signed the Sheppard–Towner Maternity Act, the first major federal government social welfare program in the U.S. The law funded almost 3,000 child and health centers throughout the U.S. Medical doctors were spurred to offer preventative health care measures in addition to treating ill children. Doctors were required to help healthy pregnant women and prevent healthy children from getting sick. Child welfare workers were sent out to make sure that parents were taking care of their children. The law was sponsored by Julia Lathrop, America's first director of the U.S. Children's Bureau. Although the law remained in effect only eight years, it set the trend for New Deal social programs during the 1930s. Many women who had been given the right to vote in 1920, were given career opportunities as welfare and social workers.
Religious toleration.
Harding was tolerant towards other religious faiths. He appointed prominent Rabbi Joseph S. Kornfeld and , to foreign diplomatic positions. He also appointed Albert Lasker, a Jewish businessman and Harding's 1920 Presidential campaign manager, head of the Shipping Department. In an unpublished letter, Harding advocated the establishment and funding of a Jewish homeland in Palestine.
Life at the White House.
Katherine Marcia Forbes, wife of Harding's Veterans Bureau appointment Charles R. Forbes, had unprecedented access to the White House. Mrs. Harding and Katherine had become close friends since meeting in Hawaii, when Senator Harding and his wife were on vacation. In 1921, Katherine Forbes wrote a series of articles for the "Washington Post" describing the daily life of President Harding and the First Lady. President Harding and Mrs. Harding wanted to be known as, "...just home folks." At dinners, Harding's dog Laddie Boy, was allowed to beg guests for food and play with children. Red velvet upholstery covered much of the furniture. Harding's informal dress included a plain tuxedo, pleated shirt, and pearl studs. Mrs. Harding herself was able to talk with many guests at the same time. Inside the White House, the Hardings had a great grandfather clock, a gold fish bowl, a French vase with pussy willows, neutral color rugs, and a grand piano. Harding sometimes gave children private tours of the White House that included the conservatories and kennels.
Harding's lifestyle at the White House was fairly unconventional compared to his predecessor President Woodrow Wilson. Upstairs at the White House, in the Yellow Oval Room, Harding allowed bootleg whiskey to be freely served to his guests during after-dinner parties at a time when the President was supposed to enforce Prohibition. One witness, Alice Longworth, daughter of President Theodore Roosevelt, stated that trays, "...with bottles containing every imaginable brand of whiskey stood about." Some of this alcohol had been directly confiscated from the Prohibition department by Jess Smith, assistant to U.S. Attorney General Harry Daugherty. Mrs. Harding, also known as the "Duchess", mixed drinks for the guests. Harding played poker twice a week, smoked and chewed tobacco. Harding allegedly won a $4,000 pearl necktie pin at one White House poker game. Although criticized by Prohibitionist advocate Wayne B. Wheeler over Washington, D.C. rumors of these "wild parties", Harding claimed his personal drinking inside the White House was his own business.
Administrative scandals.
Upon winning the election, Harding appointed many of his longtime allies and campaign contributors to prominent political positions in control of vast amounts of government money and resources. Known as the "Ohio Gang" (a term used by Charles Mee Jr., in his book of the same name), some of the appointees used their new powers to exploit their positions for personal gain. Although Harding was responsible for making these appointments, it is unclear how much, if anything, Harding himself knew about his friends' illicit activities. No evidence to date suggests that Harding personally profited from such crimes, but he was apparently unable to prevent them. "I have no trouble with my enemies", Harding told journalist William Allen White late in his presidency, "but my damn friends, they're the ones that keep me walking the floor nights!" The only scandal which was openly discovered during Harding's lifetime was in the Veteran's Bureau. Yet the gossip became rampant after the suicides of Charles Cramer (Veterans Bureau) and Jess Smith (Justice Dept.) Harding responded aggressively to all of this with a mixture of grief, anger and perplexity.
Before any of the scandalous activity became widely known, Harding's popularity began to ebb, but he responded with determination to run for re-election, despite strong support emerging for the very popular Henry Ford for the Democrats. While on his trip to Alaska in 1923, Harding asked reporters and Secretary of Commerce Herbert Hoover, how he should respond to associates who may have betrayed him. He also said at this time, according to Joe Mitchell Chapple, "Someday the people will understand all that some of my erstwhile friends have done for me." However much he did know at the time of his departure for Alaska, Russell concludes it did not include Fall and Daugherty. Harding reformed the corrupt Veteran's Bureau in March, 1923.
Teapot Dome.
The most notorious scandal was Teapot Dome, most of which came to light after Harding's death. This affair concerned an oil reserve in Wyoming that was covered by a teapot-shaped rock formation. For years, the country had taken measures to ensure the availability of petroleum reserves, particularly for the Navy's use. On February 23, 1923, Harding issued Executive Order # 3797, which created the Naval Petroleum Reserve Number 4 in Alaska. By the 1920s, it was clear that petroleum was important to the national economy and security. The reserve system was to keep the oil under government jurisdiction rather than subject to private claims. Management of these reserves was the subject of multi-dimensional arguments—beginning with a turf battle between the Secretary of the Navy and the Interior Dept. The strategic reserves issue was also a debate topic between conservationists and the petroleum industry, as well as those who favored public ownership versus private control. Harding's Secretary of the Interior, Albert B. Fall, brought to that office significant political and legal experience, in addition to heavy personal debt, incurred in his obsession to expand his personal estate, Three Rivers, in New Mexico. He also was an avid supporter of the private ownership and management of reserves.
Fall contracted Edward Doheny of Pan American Corp. to build storage tanks in exchange for drilling rights. It later came to light that Doheny had made significant personal loans to Fall. The Secretary also negotiated leases for the Teapot Dome reserves to Harry Sinclair of the Consolidated Oil Corp. in return for guaranteed oil reserves to the credit of the government. Again, it later emerged that Sinclair had personally made concurrent cash payments of over $400,000 to Fall. These activities took place under the watch of progressive and conservationist attorney, Harry A. Slattery, acting for Gifford Pinchot and Robert La Follete. Fall was ultimately convicted in 1931 of accepting bribes and illegal no-interest personal loans in exchange for the leasing of public oil fields to business associates. In 1931, Fall was the first cabinet member in history imprisoned for crimes committed while in office. Paradoxically, while Fall was convicted for taking the bribe, Doheny was acquitted of paying it.
Justice Department.
Harding's appointment of Harry M. Daugherty as Attorney General received more criticism than any other. As Harding's campaign manager, Daugherty's Ohio lobbying and back room maneuvers with politicians were not considered the best qualifications. Historian M.R. Werner referred to the Justice Department under Harding and Daugherty as "the den of a ward politician and the White House a night club". On September 16, 1922, Minnesota Congressman Oscar E. Keller brought impeachment charges against Daugherty. On December 4, formal investigation hearings, headed by congressman Andrew J. Volstead, began against Daugherty. The impeachment process, however, stopped, since Keller's charges that Daugherty protected interests in trust and war fraud cases could not be substantially proven.
One alleged scandal involving Daugherty concerned the Wright-Martin Aircraft Corp., which supposedly overcharged the Federal government by $2.3 million on war contracts. Capt. Hazel Scaife tried to bring the company to trial, but was blocked by the Department of Justice. At this time, Daugherty was said to have owned stock in the company and was even adding to these holdings, though he was never charged in the matter.
Daugherty remained in his position during the early days of the Calvin Coolidge administration, then resigned on March 28, 1924, amidst allegations that he accepted bribes from bootleggers. Daugherty was later tried and acquitted twice for corruption. Both juries hung—in one case, after 65 hours of deliberation. Daugherty's famous defense attorney, Max D. Steuer, blamed all corruption allegations against Daugherty on Jess Smith, an aide at the Justice Department who had committed suicide.
Harding's Attorney General hired William J. Burns to run the Justice Dept.'s Bureau of Investigation, Burns was said to be unabashed in his willingness to conduct unauthorized searches and seizures of political enemies of the Justice Dept. A number of inquisitive congressmen or senators found themselves the object of wire taps, rifled files, and copied correspondence. Burns' primary operative was Gaston B. Means, a reputed con man, who was known to have fixed prosecutions, sold favors, and manipulated files in the Justice Dept. Means, who acted independently, took direct instructions and payments from Jess Smith, without Burn's knowledge, to spy on Congressmen. Means hired a woman, Laura Jacobson, to spy on Senator Thaddeus Caraway, a critic of the Harding administration. Means also was involved with "roping" bootleggers.
Narcotic trafficking was rampant at the Atlanta Penitentiary while Daugherty was Attorney General. The appointed warden, J.E. Dyche, made internal prison reforms by firing two guards while two other officers were indicted by the Justice Department. Daugherty, however, was slow to follow up on these indictments. As Dyche began to investigate the drug supply ring outside the prison, Daugherty fired him and replaced him with a close friend, A. E. Sartain. Daugherty stopped the investigation into the drug ring until the two indicted officers were brought to trial. The Superintendent of Prisons, Heber Votaw, allegedly interfered and suppressed Dyche's attempted investigation into the narcotic ring outside the prison. Votaw, was Harding's brother-in-law, and had been appointed by the President in April 1921. Harding sent Charles R. Forbes, Director of the Veterans Bureau, to privately investigate the matter. This upset Daugherty, who said the Atlanta prison situation was none of Forbes' business.
Daugherty, according to a 1924 Senate investigation into the Justice Department, had authorized a system of graft between aides Jess Smith and Howard Mannington. Both Mannington and Smith allegedly took bribes to secure appointments, prison pardons, and freedom from prosecution. A majority of these purchasable pardons were directed towards bootleggers. Cincinnati bootlegger, George L. Remus, allegedly paid Jess Smith $250,000 to not prosecute him. Remus, however, "was" prosecuted, convicted, and sentenced to Atlanta prison. Smith tried to extract more bribe money from Remus to pay for a pardon. The prevalent question at the Justice Department was "How is he fixed?"
Jess W. Smith.
Daugherty's personal aide, Jess W. Smith, was widely viewed as the Attorney General's (and therefore the President's) spokesman and henchman. Smith was considered Daugherty's proxy, and a central figure, in government file manipulation, paroles and pardons, influence peddling—and even served as bag man.
During Prohibition, pharmacies received alcohol permits to sell alcohol for medical purposes. According to Congressional testimony, Daugherty allegedly arranged for Jess Smith and Howard Mannington to sell these permits to drug company agents who really represented bootleggers. The bootleggers, having obtained a permit could buy cases of whiskey. Smith and Mannington split the permit sales profits. Approximately 50,000 to 60,000 cases of whiskey were sold to bootleggers at a net worth of $750,000 to $900,000. Smith supplied bootleg whiskey to the White House and the Ohio Gang house on K Street, concealing the whiskey in a briefcase for poker games.
Eventually, rumors of Smith's abuses—free use of government cars, going to all night parties, manipulation of Justice Department files—reached Harding. Harding withdrew Smith's White House clearance and Daugherty told him to leave Washington. On May 30, 1923, Smith's dead body was found at Daugherty's apartment with a gunshot wound to the head. William J. Burns immediately took Smith's body away and there was no autopsy. Historian Francis Russell, concluding this was a suicide, indicates that a Daugherty aide entered Smith's room moments after a noise awoke him, and found Smith on the floor with his head in a trash can and a revolver in his hand. Russell also states that Smith had purchased the gun (though he was said to have detested guns), that a bullet had entered Smith's temple, exited the forehead, and lodged in a doorjamb. Smith allegedly purchased the gun from a hardware store shortly before his death, after Daugherty verbally abused him for waking him up from a nap.
Veterans' bureau.
Charles R. Forbes, the energetic Director of the Veterans Bureau, disregarded the dire needs of wounded World War I veterans to procure his own wealth. To limit corruption in the Veterans' Bureau, Harding insisted that all government contracts be by public notice, but Forbes provided inside information to his co-conspirators to ensure their bids succeeded. After his appointment, Forbes was quick to have Harding issue executive orders that gave him control over veterans' hospital construction and supplies. Forbes defrauded the government of an estimated $225 million through hospital construction, after increasing construction costs from $3,000 to $4,000 per bed. Forbes' main task at the Veterans bureau, having an unprecedented $500 million yearly budget, was to ensure that new hospitals were built around the country to help the 300,000 wounded World War I veterans.
In the Spring of 1922, Forbes went on tours, known as "joy-rides", of new hospital construction sites around the country and the Pacific Coast. On these tours, Forbes allegedly received traveling perks and alcohol kickbacks, took a $5,000 bribe in Chicago, and made a secret code to ensure $17 million in government construction hospital contracts with corrupt contractors. On the tours, Forbes allegedly went to parties, drank bootleg liquor, and played craps.
Intent on making more money, on his return to the U.S. Capitol Forbes immediately began selling valuable hospital supplies under his control in large warehouses at the Perryville Depot. The government had stockpiled huge amounts of hospital supplies during the first World War, which Forbes unloaded for a fraction of their cost to the Boston firm of Thompson and Kelly. In exchange for the deal, J.W. Thompson of the firm added $150,000 to the contract for Forbes, who also received a percentage of the profits realized. The check on Forbes' authority at Perryville was Gen. Charles E. Sawyer, chairman of the Federal Hospitalization Board, who represented controlling interests in the valuable hospital supplies.
Dr. Sawyer and Forbes were at odds with each other over authority at the Veterans Bureau. Sawyer, a homeopathic doctor who was Harding's personal physician, told Harding that Forbes was selling valuable hospital supplies to an insider contractor. After issuing two orders for the sales to stop, Harding finally summoned Forbes to the White House and demanded Forbes' resignation, since Forbes had been insubordinate in not stopping the shipments. Harding, however, was not yet ready to announce Forbes' resignation and let him flee to Europe on the "flimsy pretext" that he would help disabled U.S. Veterans in Europe. While in Europe, Forbes submitted his resignation to Harding on February 15, 1923.
Harding placed a reformer, Brigadier General Frank T. Hines, in charge of the Veterans Bureau. Hines immediately cleared up the mess left by Forbes. When Forbes returned to the U.S., he visited Harding at the White House in the Red Room. During the meeting, Harding angrily grabbed Forbes by the throat, shook him vigorously, and exclaimed "You double-crossing bastard!" A guest who had an appointment with the President interrupted this physical encounter and Forbes was allowed to leave. Harding was bitter over Forbes' "betrayal" and the two never saw each other again. In 1926, Forbes was brought to trial and convicted of conspiracy to defraud the U.S. government. He received a two-year prison sentence and was released in November 1927.
Charles F. Cramer, Forbes' legal council to the Veterans Bureau, rocked the nation's capital when he committed suicide in 1923. Cramer was found dead by a maid in his bathroom on the morning of March 14 with a bullet wound to the head. Previously, in the fall of 1922 Cramer had been "bitterly assailed" by the American Legion at Indianapolis over alleged corruption at the Veterans Bureau. Cramer, at the time of his death, was being investigated by a Senate committee and had been criticized and personally attacked. Cramer, himself, had denied charges of corruption and said he had given his "whole-hearted and patriotic service" to the Bureau. Cramer had paid $40,000 in Veteran funds to a private landholder to lease land to build a Veterans Hospital in Camp Kearny, California. The estimated value of the 325-acre land tract was only $8,000. Maj. Gen. John F. O'Ryan conducted the investigation into the Veterans' Bureau. In addition to replacing Forbes with Hines, Harding dismissed or transferred a number of subordinates at the Veteran's Bureau.
Shipping board, office of alien property and prohibition bureau.
On June 13, 1921, Harding appointed Albert D. Lasker chairman of the United States Shipping Board. Lasker, a cash donor and Harding's general campaign manager, had no previous experience with shipping companies. The Merchant Marine Act of 1920 had allowed the Shipping Board to sell ships made by the U.S. Government to private American companies. A congressional investigation revealed that while Lasker was in charge, many valuable steel cargo ships, worth between $200 and $250 a ton, were sold for as low as $30 a ton to private American shipping companies without an appraisal board. J. Harry Philbin, a manager in the sales division, testified at the congressional hearing that under Lasker's authority U.S. ships were sold, "...as is, where is, take your pick, no matter which vessel you took." Lasker resigned from the Shipping Board on July 1, 1923.
Thomas W. Miller, head of the Office of Alien Property, was convicted of accepting bribes. Miller's citizenship rights were taken away and he was sentenced to 18 months in prison and a $5,000 fine. After Miller served 13 months of his sentence, he was released on parole. President Herbert Hoover restored Miller's citizenship on February 2, 1933.
Roy Asa Haynes, Harding's Prohibition Commissioner, ran the patronage-riddled Prohibition bureau, which was allegedly corrupt from top to bottom. The bureau's "B permits" for liquor sales became tantamount to negotiable securities, as a result of being so widely bought and sold among known violators of the law. The bureau's agents allegedly made a year's salary from one month's illicit sales of permits.
Western travels, illness and death.
In June 1923, Harding set out on a westward cross-country "Voyage of Understanding", in which he planned to renew his connection with the people, away from the capital, and explain his policies. The schedule included 18 speeches and innumerable informal talks. Accompanying him were Secretaries Work, Wallace, and Hoover, House Speaker Gillett, and Rear Admiral Hugh Rodman. During this trip, he became the first president to visit Alaska.
Harding's physical health had declined since the fall of 1922. One doctor, Emmanuel Libman, who met Harding at a dinner, privately suggested that the President was suffering from coronary disease. By early 1923, Harding had trouble sleeping, looked tired, and could barely get through nine holes of golf.
Though Harding wanted to run for a second term, he may have been aware of his own health decline. He gave up drinking, sold his "life-work," the Marion "Star", in part to regain $170,000 previous investment losses, and had the U.S. Attorney General Harry Daugherty make a new will. Harding, along with his personal physician Dr. Charles E. Sawyer, believed getting away from Washington would help relieve the stress of being President. By July 1923, criticism of the Harding Administration was increasing. Prior to his leaving Washington, the President reported chest pains that radiated down his left arm.
St. Louis, Kansas, Denver.
During Harding's western travels, historian Samuel H. Adams claims that Harding's political views began to expand, and became more independent from established Republican Party agenda. In St. Louis, Harding promoted U.S. participation in the World Court having earnestly desired world peace. In Kansas, Harding gave a speech on agriculture and, much to his doctor's displeasure, rode on a farming combine in searing summer heat.
In Denver, Harding extolled the virtues of the 18th Amendment, saying it should never be repealed, urging that the prohibition laws be obeyed. Harding, himself, did not pack any whiskey for traveling on the Presidential train. Breaking away from Republican isolationism, Harding advocated more spending on national defense in case of another war. Harding also made a speech fully endorsing labor's right to organize, and even spoke against those who sought to destroy labor movements around the country. In Tacoma, Washington, the President read a letter that promoted his efforts for a 12-hour work day. Sensing his own conversion, Harding even told his friends that he felt a spiritual change was influencing his stance on issues.
Alaska trip.
President Harding, as his physically demanding schedule continued, boarded a naval transport ship, the USS "Henderson", and voyaged to Alaska. During four days at sea, Harding was unable to rest and regain strength. Rumors of corruption in his administration were beginning to circulate in Washington. While in Alaska, Harding was profoundly shocked by a long message he received detailing illegal activities previously unknown to him.
Harding came to the most northern U.S. territory to "open up Alaska lands" for oil, mining, timber development, and industry. He also wanted to encourage settlers to move to the sparsely populated territory. Harding hoped that, with completion of the Alaska Railroad, World War I veterans from Alaska would return to their home territory, and impoverished workers in the lower states could go to Alaska for employment. Harding brought along the secretaries of the Interior, Commerce, and Agriculture to cut through bureaucracy in their respective departmental jurisdictions.
Harding arrived in Alaska on the "Henderson" on July 7, 1923. Harding and his presidential party first visited Metlakatla, Ketchikan (July 8), and Wrangell (July 9). They continued on to Juneau (July 10), Skagway, and Glacier Bay (July 11). The President then cruised to Seward (July 13). They then proceeded to travel by Presidential railway car and automobile. Harding visited Snow River on the Kenai Peninsula, Anchorage (July 13), Chickaloon, Wasilla and Willow (July 14). The U.S. government had bought up the financially unstable Tanana Valley Railroad. The President continued his Alaska journey through Montana Station, Curry (July 14) Cantwell, McKinley Park and Nenana (July 15). On July 15, Harding drove in the golden spike on the north side of the steel Mears Memorial Bridge that completed the Alaska Railroad. The trip continued to Fairbanks (July 15). He went to Seward (July 18), Valdez (July 19), Cordova (July 20), and Sitka (July 22).
The information gathered by Harding's Alaska tour found that improving agriculture in south central Alaska would require irrigation because of the low rainfall totals. By 1923, the Alaskan salmon population was being depleted from overfishing. Harvesting and transporting coal by ship from Alaska through the territory's panhandle would be very expensive.
On July 26, 1923, Harding toured Vancouver, British Columbia as the first sitting American President ever to visit Canada.
Harding became exhausted while playing golf and complained of nausea and upper abdominal pain. His doctor, Charles E. Sawyer, believed Harding's illness was a severe case of food poisoning. Nevertheless, Dr. Joel T. Boone also examined the President and noticed an enlargement of his heart. He was given digitalis. Nevertheless Harding met with British Columbia Premier John Oliver and Mayor of Vancouver Charles Tisdall and spoke in front of 50,000 people with his voice projected by microphones.
Coming into Seattle, Washington Harding kept up his busy schedule, giving a speech to 25,000 people at the University of Washington stadium in Seattle. Harding spoke on the magnificence of Alaska's wilderness, conservationism, and "measureless oil resources in the most northerly sections." Secretary of Commerce Herbert Hoover wrote the Seattle speech and Harding claimed he would protect the territory from looters and profit seekers; a rebuff to former Secretary of Interior Albert Fall. Harding had rushed through his speech not waiting for applause by the audience. Harding traveled by train from Seattle to Portland, Oregon. Harding's scheduled speech in Portland was canceled.
Death in San Francisco, state funeral and memorial.
The President's train continued south to San Francisco. Secretary of Commerce Herbert Hoover sent a telegram from Dunsmuir, California, to his friend Dr. Ray L. Wilbur, asking Wilbur to meet and to personally evaluate the President. Arriving at the Palace Hotel in San Francisco, Harding developed a respiratory illness believed to be pneumonia. Harding, severely exhausted, ordered that his planned speech be issued through the national press in order to communicate with the public. The President was given digitalis and caffeine that momentarily helped relieve his heart condition and sleeplessness. On Thursday, the President's health appeared to improve, so his doctors went to dinner. Harding's pulse was normal and his lung infection had subsided. Unexpectedly, during the evening, Harding shuddered and died suddenly in the middle of conversation with his wife in the hotel's presidential suite, at 7:35 p.m. on August 2, 1923. Dr. Sawyer (a homeopath, and friend of the Harding family), opined that Harding had succumbed to a stroke, but doctors there disagreed. The doctors issued a release stating that the cause of death was "some brain evolvement, probably an apoplexy." Mrs. Harding refused to allow an autopsy. In retrospect, scholars speculate that Harding had shown physical signs of cardiac insufficiency with congestive heart failure in the preceding weeks. Navy doctors who examined the president in San Francisco concluded he had suffered a heart attack. Dr. Wilbur included in his memoirs a letter from Dr. Charles Miner Cooper in support of their cerebral apoplexy diagnosis, based on Harding's last observed condition, while acknowledging that no final determination could be made. Harding was succeeded as President by Calvin Coolidge.
The funeral train made a four-day journey eastward across the country—the first such procession since Lincoln's funeral train. Millions lined the tracks in cities and towns across the country to pay their respects. Harding's casket was placed in the East Room of the White House pending a state funeral, which was held on August 8, 1923, at the United States Capitol. Harding's death was widely mourned by the nation and the average citizen felt a "personal loss." Harding was entombed in the receiving vault of the Marion Cemetery, on August 10, 1923. After her own death on November 21, 1924, Mrs. Harding was interred next to her husband. Their remains were re-interred December 20, 1927, at the newly completed Harding Memorial in Marion, Ohio. Harding was one of only two presidents to be survived by his father, the other being John F. Kennedy.
Speculation on cause of death.
Harding's sudden death led to theories that he had been poisoned or committed suicide. Suicide appears unlikely, since Harding was planning for reelection in 1924. Rumors of poisoning were fueled, in part, by a book called "The Strange Death of President Harding", in which the author, a convicted criminal, Gaston Means, suggested Mrs. Harding had poisoned her husband, an assertion which has since been completely discredited as false. 
Mrs. Harding's refusal to allow an autopsy added to such speculation. According to the physicians attending Harding, however, the symptoms prior to his death all pointed to congestive heart failure. Harding's biographer, Samuel H. Adams, concluded that "Warren G. Harding died a natural death which, in any case, could not have been long postponed".
Disposition of Presidential papers.
Immediately after Harding's death, Mrs. Harding returned to Washington, D.C., and stayed in the White House briefly with the Coolidges. In 1963 Francis Russell, writing in "American Heritage", stated that former First Lady Harding gathered and burned as much of President Harding's correspondence and documents, both official and unofficial, as she could get. Russell also wrote that Mrs. Harding hired secretaries upon returning to Marion, to help her collect Harding's personal correspondence to others and that Mrs. Harding then in turn destroyed these letters.
However, John Dean, in "Warren G. Harding:The American Presidents Series", states that Mrs. Harding's efforts were in vain and that George Christian, President Harding's private secretary, disobeyed Florence Harding's instructions, only sending a few boxes of materials to her in Marion after she left the White House. The papers were instead stored in the White House's basement and not found until 1929. Christian also kept all of the papers from Harding's time in the Senate, along with records of Harding's Presidential campaign, and stored them in the basement of his own home in Marion.
By 1935, according to Dean, the Presidential papers were all under the purview of the Harding Memorial Association which in late 1963 transferred the papers to the Ohio Historical Society and that the substantial collection was opened to the public in April 1964. The papers were subsequently microfilmed in the 1970s and can be accessed at various libraries.
Judicial appointments.
Supreme Court.
Harding appointed the following justices to the Supreme Court of the United States:
Other judicial appointments.
Harding also appointed 6 judges to the United States Courts of Appeals, 42 judges to the United States district courts, and 2 judges to the United States Court of Customs Appeals.
Extramarital affairs.
In a 1998 "Washington Post" article, journalist Carl S. Anthony wrote that Harding had extramarital affairs and sexual encounters with numerous women. These women included Susie Hodder and Carrie Fulton Phillips, Mrs. Harding's personal friends; Grace Cross, Harding's senatorial aide; and Nan Britton, a 22-year old campaign volunteer (President Harding was age 51 when the affair occurred). Anthony stated that Harding was the father of Hodder's daughter. In her 1927 book, "The President's Daughter", Britton said that Harding fathered her daughter, Elizabeth Ann, as well, during a 1919 tryst in his senatorial offices. Britton, who had a profound obsession with Harding beginning in high school, also said that she was his mistress before and during his administration – reportedly, this included at least one infamous tryst in a White House closet and while guarded by United States Secret Service agents. Historian Henry F. Graff states that Harding was sterile and that Harding's affair with Britton ended after Harding assumed the presidency. The Library of Congress publicly opened letters between Phillips and Harding on July 29, 2014.
Historian Francis Russell wrote that, beginning in the spring of 1905, Harding had a 15-year relationship with Carrie Fulton Phillips, wife of businessman and friend James Eaton Phillips of Marion, Ohio. More than 100 intimate letters between Harding and Mrs. Philips were discovered in the 1960s, but publication of the letters was enjoined by court order in Ohio until 2024. Russell, however, viewed the letters upon their discovery and described them as very touching and naive in some respects, erotic in others. Russell concluded from the letters that Phillips was the love of Harding's life — "the enticements of his mind and body combined in one person".
Before his death, Harding had established a margin account with stockbroker Sam Ungerleider. Before the broker could get authority from Harding's successors to liquidate the stocks purchased on loan, the account had a loss of more than $170,000. The broker was given the authority to sell, but the family refused to settle the loss and the broker declined to force collection.
The most sensational allegations include one that Harding and Attorney General Harry M. Daugherty participated in bacchanalian orgies at the Ohio Gang's Little Green House on K Street in Washington, D.C.; witnesses to this were considered unreliable and one was a convicted perjurer. Also, in his 1987 book "The Fiery Cross", historian Wyn Craig Wade suggested that Harding had ties with the Ku Klux Klan, perhaps having been inducted into the organization in a private White House ceremony. Evidence included the taped testimony of one of the members of the alleged induction team; however, evidence beyond that is scanty. Other historians generally dismiss these stories. Several historians, including Robert H. Ferrell and Paul Johnson, reject claims of orgies and mistresses. Johnson writes in "Modern Times": "When in 1964 the Harding Papers (which had not been burnt) were opened to scholars, no truth at all was found in any of the myths, though it emerged that Harding, a pathetically shy man with women, had a sad and touching friendship with the wife of a Marion store-owner before his presidency. The Babylonian image was a fantasy, and in all essentials Harding had been an honest and exceptionally shrewd president."
Historical ranking as president.
Harding has been traditionally ranked as one of the worst presidents. In a 1948 poll conducted by Harvard University historian Arthur M. Schlesinger Sr., the first notable survey of scholars' opinions of the presidents, Harding ranked last among the 29 presidents considered. In a 1962 poll conducted by Schlesinger, he was ranked last again, 31 out of 31. His son, Arthur M. Schlesinger Jr., conducted another poll in 1996; once again, Harding was last, ranked 39 out of 39. In 2010, a Siena College Research Institute survey of 238 presidential scholars ranked Harding 41st among the 43 men who had been president, between Franklin Pierce (40th) and James Buchanan (42nd); Andrew Johnson was judged the worst. Harding was also considered the third worst president in a 2002 Siena poll. Siena polls of 1982, 1990 and 1992 ranked him last.
However, Harding's biographer John W. Dean in 2004 believed that Harding was underrated. Authors Marcus Raskin and Robert Spero, in 2007, also believed that Harding was underrated, and admired Harding's quest for world peace after World War I and his successful naval disarmament among strongly armed nations, including France, Britain, and Japan. In his 2010 book "The Leaders We Deserved (and a Few We Didn't): Rethinking the Presidential Rating Game", presidential historian Alvin S. Felzenberg, ranking presidents on several criteria, ranked Harding 26th out of 40 presidents considered.
Life legacy.
As a career politician, Harding exhibited an ability to grow, and had a desire to get along with political enemies rather than alienate them. As a prior journalist, Harding was the first President to realize the importance of an ever growing powerful media, and even ordered his cabinet to organize their own respective press staff. He knew that radio would eventually dominate American commerce and promoted two Radio Conferences to give government power to regulate the industry. Harding also sensed the importance of oil in terms of national security and prosperity, signing an executive order that gave the U.S. a giant oil reserve in Alaska. He also signed America's first child welfare program designed to protect children's health and ensure that they would grow up without neglect from their parents. 
Harding's generosity and loyalty to friends was a liability as President. Multiple scandals evolved during his administration that damaged his reputation throughout the nation. His successes as President were overshadowed by the "Ohio Gang" criminal exploits, the detrimental image of his social drinking, and his alleged extramarital affairs. His sudden death in 1923 only intensified unanswered questions concerning his knowledge of, and potential involvement in, the scandals—and if he would have reformed his administration. His reputation was so controversial that not until 1931 was Harding's marble memorial colonnade in Marion dedicated by Herbert Hoover. According to Hoover, Harding's legacy was one of tragic betrayal.
Harding's legacy began to improve during the 1970s, however. The truth behind the many presidential scandals and his personal controversies may never be known. To protect her husband's damaged legacy, Mrs. Harding only left 1/7 of Harding's personal papers for posterity. She destroyed the rest. The remaining papers, except for Harding's speeches, are currently unpublished. Harding has been one of the most historically challenging American Presidents in terms of finding private letters and paper documents. Historian Hazel Rowley writes that because the Harding administration and the Republicans were seen associated with prosperity, prominent Democrats were reluctant to run for president in 1924.
Because of his untimely demise, Warren G. Harding is among the relatively few American Presidents who have been honored on a U.S. postage stamp more than the usual three times. Harding has appeared on US postage for a total of five issues, more than that of most Presidents. Harding's election provided a short burst of popularity for the name Warren.
Bibliography.
</dl>
External links.
class="wikitable succession-box" style="margin:0.5em auto; font-size:95%;clear:both;"

</doc>
<doc id="33062" url="http://en.wikipedia.org/wiki?curid=33062" title="Whist">
Whist

Whist is a classic English trick-taking card game which was widely played in the 18th and 19th centuries. Although the rules are extremely simple, there is enormous scope for scientific play.
History.
Whist is a descendant of the 16th century game of "trump" or "ruff". Whist replaced the popular variant of "trump" known as Ruff and Honours. The game takes its name from the 17th Century "whist" (or "wist") meaning "quiet", "silent", "attentive", which is the root of the modern "wistful".
According to Barrington, Whist was first played on scientific principles by a party of gentlemen who frequented the Crown Coffee House in Bedford Row, London, around 1728. Edmond Hoyle, suspected to be a member of this group, began to tutor wealthy young gentlemen in the game and published "A Short Treatise on the Game of Whist" in 1742. It became the standard text and rules for the game for the next hundred years and led to the game becoming fashionable.
In 1862 Henry Jones, writing under the pseudonym "Cavendish", published "The Principles of Whist Stated and Explained, and its Practice Illustrated on an Original System, by Means of Hands Played Completely Through", which became the standard text. Many subsequent editions and enlargements of this work were published using the simpler title "Cavendish On Whist". By this time Whist was governed by elaborate and rigid rules covering the laws of the game, etiquette and play which took time to study and master.
In the 1890s, a variant known as Bridge Whist became popular which eventually evolved into Contract Bridge. The traditional game of Whist survives at social events called "whist drives". There are many modern variants of Whist played for fun.
Rules.
A standard 52-card pack is used. The cards in each suit rank from highest to lowest: A K Q J 10 9 8 7 6 5 4 3 2. Whist is played by four players, who play in two partnerships with the partners sitting opposite each other. Players cut or draw cards to determine partners, with the two highest playing against the lowest two, who have seating rights. The players then cut for deal. It is strictly against the rules to comment on the cards in any way. One may not comment upon the hand one was dealt nor about one's good fortune or bad fortune. One may not signal to one's partner.
Shuffling and dealing.
The cards can be shuffled by any player, though usually the player to dealer's left. The dealer has the right to shuffle last if he wishes. To speed up dealing a second pack can be shuffled by the dealer's partner during the deal and then placed to the right ready for the next hand. The cards are cut by the player on dealer's right before dealing. The dealer deals out all the cards, one at a time, face down, so that each player has thirteen cards. The final card, which belongs to the dealer, is turned face up to indicate which suit is trumps. The turned-up trump card remains face up on the table until it is the dealer's turn to play to the first trick. The deal advances clockwise.
Play.
The player to the dealer's left leads to the first trick. He may lead any card in his hand. The other players, in clockwise order, each play a card to the trick and must follow suit by playing a card of the suit led if they have one. A player with no card of the suit led may play any card, either discarding or trumping. The trick is won by the highest card of the suit led, unless a trump is played, in which case the highest trump wins. The winner of the trick leads the next trick.
Play continues until all thirteen tricks are played, at which point the score is recorded. If no team has enough points to win the game, another hand is played.
Part of the skill involved in the game is one's ability to remember what cards have been played and reason out what cards remain. Therefore, once each trick is played, its cards are turned face down and kept in a stack of four near the player who won the trick. Before the next trick starts, a player may ask to review the cards from the last trick only. Once the lead card is played, however, no previously played cards can be reviewed by anyone.
Scoring.
After all tricks have been played, the side which won more tricks scores 1 point for each trick won in excess of 6. When all four players are experienced, it is unusual for the score for a single hand to be higher than two. A game is over when one team reaches a score of five. There are so-called "Hotel Rules" variations where other numbers are agreed to be played to in advance such as "American" and "Long", where the games are played to seven and nine respectively. The "Long" version is normally combined with "Honours."
In longer variations of the game, those games where the winning score is not the standard 5 points, honours are points that are claimed at the end of each hand. Honours add nothing to the play of a hand. Honours serve only as an element of luck that speeds up games, and they are often omitted these days. Serious players disdain honours because it greatly increases the element of chance. A team that was dealt the top four cards (A,K,Q,J) in the trump suit collect extra points. A team who holds three of the four honours between them claim 2 points, a team who holds all four honours between them claim 4 points. Tricks are scored before honours. Honours points can never be used for the last point of a game. Consider the following example: A game is being played to 9 points. The score is tied at 6. A hand is played and the winner of that hand took seven tricks and claimed honours. That team would receive 1 point for the 7th trick and only 1 point for honours. The score would then be 8 to 6.
Terminology.
Deal: One card at a time is given to each player by the dealer starting with the player on the dealer’s left and proceeding clockwise until the deck is fully distributed.
Dealer: The player who deals the cards for a hand.
Deck: Standard playing-card deck consisting of 52 cards in four suits.
Dummy: In some variations of whist, a hand is turned face up and is played from by the player seated opposite. This allows for whist to be played by three players.
Finesse: The play of a lower honour even though holding a higher one, hoping that the intermediate honour is held by a player who has already played to the trick. To give an example: you hold the ace and queen of hearts. Your right-hand antagonist leads a heart, from which you infer that he holds the king of the same suit and wishes to draw the ace, in order to make his king. You however play the queen, and win the trick; still retaining your ace, ready to win again when he plays his king.
Game: Reaching a total score agreed beforehand to be the score played up to.
Grand Slam: The winning, by one team, of all thirteen tricks in a hand.
Hand: Thirteen tricks. (52 cards in the deck divided by four players equals thirteen cards per player.)
Honours: In some variations of whist, extra points are assigned after a game to a team if they were dealt the ace, king, queen, and jack (knave) of the trump suit.
Lead: The first card played in a trick.
Pack: See Deck.
Rubber: The best of three games.
Small slam: The winning, by one team, of twelve tricks in a hand.
Tenace: A suit holding containing the highest and third-highest of the suit or (the "minor tenace") second- and fourth-highest.
Trick: Four cards played one each by the players. 
Trump: The suit chosen by the last-dealt card that will beat all other suits regardless of rank. When two cards are played from the trump suit, the higher card wins the trick.
List of variations.
The name "whist" has become attached to a wide variety of games based on classic whist, but often with some kind of bidding added, for example:
Whist drive.
A whist drive is a social event at which progressive games of whist are played.
Literary references.
Whist has long been noted for its influence upon what is termed the calculating power; and men of the highest order of intellect have been known to take an apparently unaccountable delight in it, [...]"
His only pastime was reading the papers and playing whist. He frequently won at this quiet game, so very appropriate to his nature;[...]"
References in music.
By an eerie green storm lanternThree ghouls were playing whist [...]"
Bob liked to play his poker, pinochle, whist, and euchre.[...]"

</doc>
<doc id="33065" url="http://en.wikipedia.org/wiki?curid=33065" title="William Withering">
William Withering

William Withering FRS (17 March 1741 – 6 October 1799) was an English botanist, geologist, chemist, physician and the discoverer of digitalis.
Introduction.
Withering was born in Wellington, Shropshire, trained as a physician and studied medicine at the University of Edinburgh Medical School. He worked at Birmingham General Hospital from 1779. The story is that he noticed a person with dropsy (swelling from congestive heart failure) improve remarkably after taking a traditional herbal remedy; Withering became famous for recognising that the active ingredient in the mixture came from the foxglove plant. The active ingredient is now known as digitalis, after the plant's scientific name. In 1785, Withering published "An Account of the Foxglove and some of its Medical Uses", which contained reports on clinical trials and notes on digitalis's effects and toxicity.
Biography.
Born in Wellington, Shropshire, England, he attended Edinburgh Medical School from 1762 to 1766. In 1767 he started as a consultant at Stafford Royal Infirmary. He married Helena Cookes (an amateur botanical illustrator, and erstwhile patient of his) in 1772; they had three children (the first, Helena was born in 1775 but died a few days later, William was born in 1776, and Charlotte in 1778). In 1775 he was appointed physician to Birmingham General Hospital (at the suggestion of Erasmus Darwin, a physician and founder member of the Lunar Society), but in 1783 he diagnosed himself as having pulmonary tuberculosis and went twice to Portugal hoping the better winter climate would improve his health; it did not. On the way home from his second trip there, the ship he was in was chased by pirates. In 1785 he was elected a Fellow of the prestigious Royal Society and also published his "Account of the Foxglove" (see below). The following year he leased Edgbaston Hall (now home to a golf club and nature reserve), in Birmingham, England. He was one of the members of the Lunar Society. During the Birmingham riots of 1791 (in which Joseph Priestley's home was demolished) he prepared to flee from Edgbaston Hall, but his staff kept the rioters at bay until the military arrived. In 1799 he decided that he could not tolerate another winter in the cold and draughty Hall, so he bought "The Larches" in the nearby Sparkbrook area; his wife did not feel up to the move and remained at Edgbaston Hall. After moving to "The Larches" on 28 September, he died on 6 October 1799.
Memorials.
He was buried on 10 October 1799 in Edgbaston Old Church next to Edgbaston Hall, Edgbaston, Birmingham, although the exact site of his grave is unknown. The memorial stone, now moved inside the church, has foxgloves and "Witheringia solanaceae" (see below) carved upon it to commemorate his discovery and his wider contribution to botany. He is also remembered by one of the "Moonstones" in Birmingham and by a blue plaque at Edgbaston Golf Club.
In July 2011 a J D Wetherspoon public house opened in Withering's birthplace, Wellington, and has been named after him.
Botany.
In 1776, he published "The botanical arrangement of all the vegetables naturally growing in Great Britain", an early and influential British Flora. It was the first in English based on the then new Linnaean taxonomy — a classification of all living things — devised by the eminent Swedish botanist and physician Carolus Linnaeus (1707–1778). At the time he was criticised for having produced a bowdlerised version of Linnaeus, deliberately omitting any references to sexual reproduction, out of a desire to protect 'female modesty', notably by the Lichfield Botanical Society. However he found plenty of support for his position, and botany was considered a subject unsuitable for many women during the next century.
Withering wrote two more editions of this work in 1787 and 1792, in collaboration with fellow Lunar Society member Jonathan Stokes, and after his death his son (also William) published four more. It continued being published under various authors until 1877. Withering senior also carried out pioneering work into the identification of fungi and invented a folding pocket microscope for use on botanical field trips. He also introduced to the general audience the screw down plant press and the vasculum. In 1787 he was elected a Fellow of the Linnaean Society in recognition of his contribution to botany. Subsequently the plant "Witheringia solanacea" was named in his honour, and he became known on the continent of Europe as "The English Linnaeus". The William Withering Chair in Medicine at the University of Birmingham Medical School is named after him, as is the medical school's annual William Withering Lecture.
The standard author abbreviation With. is used to indicate this individual as the author when citing a botanical name.
Chemistry and geology.
 He was an enthusiastic chemist and geologist. He conducted a series of experiments on "Terra Ponderosa", a heavy ore from Cumberland, England. He deduced that it contained a hitherto undescribed element which he was unable to characterise. It was later shown to be barium carbonate and in 1789 the eminent German geologist Abraham Gottlob Werner named the mineral "Witherite" in his honour. The Matthew Boulton mineral collection of Birmingham Museum and Art Gallery may contain one of the earliest known specimens of witherite. A label in Boulton's handwriting records; "No.2 Terra Ponderosa Aerata, given me by Dr. Withering”
Withering also undertook analyses of the mineral content of a number of spa waters in England and abroad, notably at the medicinal spa at "Caldas da Rainha" in Portugal. This latter undertaking occurred during the winter of 1793-4, and he was subsequently elected to the Fellowship of the Royal Academy of Sciences of Portugal.
Discovery of digitalis.
Withering first learned of the use of Digitalis in treating "dropsy" (atrial fibiliation) from Mother Hutton, an old woman who practiced as a folk herbalist in Shropshire, who used the plant as part of a polyherbal formulation containing over 20 different ingredients to successfully treat this condition. Withering deduced that Digitalis was the "active" ingredient in the formulation, and over the ensuing nine years he carefully tried out different preparations of various parts of the plant (collected in different seasons) documenting 156 cases where he had employed digitalis, and describing the effects and the best - and safest - way of using it. At least one of these cases was a patient for whom Erasmus Darwin had asked Withering for his second opinion. In January 1785 Darwin submitted a paper entitled "An Account of the Successful Use of Foxglove in Some Dropsies and in Pulmonary Consumption" to the College of Physicians in London; it was presented by Darwin in March of that year. A postscript at the end of the published volume of transactions containing Darwin's paper states that "Whilst the last pages of this volume were in the press, Dr Withering of Birmingham... published a numerous collection of cases in which foxglove has been given, and frequently with good success". After this, Darwin and Withering became increasingly estranged, and eventually a horrendous argument broke out apparently resulting from Darwin having accused Withering of unprofessional behaviour by effectively poaching patients. This is a very early example of medical academic plagiarism.
Publications.
This list is drawn from Sheldon, 2004:
Further reading.
</dl>

</doc>
<doc id="33067" url="http://en.wikipedia.org/wiki?curid=33067" title="White elephant">
White elephant

A white elephant is a possession which its owner cannot dispose of and whose cost, particularly that of maintenance, is out of proportion to its usefulness. The term derives from the story that the kings of Siam, now Thailand, were accustomed to make a present of one of these animals to courtiers who had rendered themselves obnoxious in order to ruin the recipient by the cost of its maintenance. In modern usage, it is an object, scheme, business venture, facility, etc., considered without use or value.
Background.
The term derives from the sacred white elephants kept by Southeast Asian monarchs in Burma, Thailand, Laos and Cambodia. To possess a white elephant was regarded (and is still regarded in Thailand and Burma) as a sign that the monarch reigned with justice and power, and that the kingdom was blessed with peace and prosperity. The opulence expected of anyone that owned a beast of such stature was great. Monarchs often exemplified their possession of white elephants in their formal titles (e.g., Hsinbyushin, lit. "Lord of the White Elephant" and the third monarch of the Konbaung dynasty).
White elephants are linked to Hindu cosmology as the mount of Indra, king of the Vedic deities, is Airavata, a white elephant. White elephants are also intricately linked to Buddhist cosmology: the mount of Sakka's (a Buddhist deity and ruler of the Tavatimsa heaven) is a three-headed white elephant named Airavata. Albino elephants exist in nature, usually being reddish-brown or pink.
The tradition derives from tales that associate a white elephant with the birth of the Buddha, as his mother was reputed to have dreamed of a white elephant presenting her with a lotus flower, a common symbol of wisdom and purity, on the eve of giving birth. Because the animals were considered sacred and laws protected them from labor, receiving a gift of a white elephant from a monarch was simultaneously a blessing and a curse. It was a blessing because the animal was sacred and a sign of the monarch's favour, and a curse because the recipient now had an expensive-to-maintain animal he could not give away and could not put to much practical use.
The Order of the White Elephant consists of eight grades of medals issued by the government of Thailand. There are also white elephants in Nepal.
In the West, the term "white elephant" relating to an expensive burden that fails to meet expectations, was popularized following P. T. Barnum's experience with an elephant named "Toung Taloung" that he billed as the "Sacred White Elephant of Burma". After much effort and great expense, Barnum finally acquired the animal from the King of Siam only to discover that his "white elephant" was actually dirty grey in color with a few pink spots.
The expressions "white elephant" and "gift of a white elephant" came into common use in the middle of the nineteenth century. The phrase was attached to "white elephant swaps" and "white elephant sales" in the early twentieth century. Many church bazaars held “white elephant sales” where donors could unload unwanted bric-a-brac, generating profit from the phenomenon that one man’s trash is another man’s treasure. Many organizational and church fairs still use the term today. In general use a “white elephant” usually refers to an item that’s not useful (decorative) but may be expensive and odd.
External links.
1. Soul of the Tiger: Searching for Nature’s Answers in Southeast Asia. Jeffrey A. McNeely and Paul Spencer Sochaczewski. Contains a chapter on the white elephant in Southeast Asia.
2. The Sultan and the Mermaid Queen. Paul Spencer Sochaczewski. Contains a long chapter on how Burmese generals tried to use the white elephant to consolidate power, also looks at the cosmological origins of the animal.

</doc>
<doc id="33088" url="http://en.wikipedia.org/wiki?curid=33088" title="Battle of Monte Cassino">
Battle of Monte Cassino

The Battle of Monte Cassino (also known as the Battle for Rome and the Battle for Cassino) was a costly series of four assaults by the Allies against the Winter Line in Italy held by Axis forces during the Italian Campaign of World War II. The intention was a breakthrough to Rome.
At the beginning of 1944, the western half of the Winter Line was being anchored by Germans holding the Rapido, Liri, and Garigliano valleys and some of the surrounding peaks and ridges. Together, these features formed the Gustav Line. Monte Cassino, a historic hilltop abbey founded in AD 529 by Benedict of Nursia, dominated the nearby town of Cassino and the entrances to the Liri and Rapido valleys. Lying in a protected historic zone, it had been left unoccupied by the Germans. They had, however, manned some positions set into the steep slopes below the abbey's walls.
Repeated pinpoint artillery attacks on Allied assault troops caused their leaders to conclude the abbey was being used by the Germans as an observation post, at the least. Fears escalated along with casualties, and in spite of a lack of clear evidence, it was marked for destruction. On 15 February American bombers dropped 1,400 tons of high explosives, creating widespread damage. The raid failed to achieve its objective, as German paratroopers occupied the rubble and established excellent defensive positions amid the ruins. Between 17 January and 18 May, Monte Cassino and the Gustav defences were assaulted four times by Allied troops, the last involving twenty divisions attacking along a twenty-mile front.
The German defenders were finally driven from their positions, but at a high cost. The capture of Monte Cassino tolled some 55,000 Allied casualties, with German losses being estimated at around 20,000 killed and wounded.
Background.
The Allied landings in Italy in September 1943 by two Allied armies commanded by General Sir Harold Alexander, Commander-in-Chief Allied Armies in Italy, were followed by an advance northward on two fronts, one on each side of the central mountain range forming the "spine" of Italy. On the western front, U.S. Fifth Army, commanded by Lieutenant-General Mark W. Clark, moved from the main base of Naples up the Italian "boot", and in the east General Sir Bernard Montgomery's British Eighth Army advanced up the Adriatic coast.
Fifth Army made slow progress in the face of difficult terrain, wet weather and skillful German defences. The Germans were fighting from a series of prepared positions in a manner designed to inflict maximum damage, then pulling back while buying time for the construction of the Winter Line defensive positions south of Rome. The original estimates that Rome would fall by October 1943 proved far too optimistic.
Although in the east the German defensive line had been breached on Eighth Army's Adriatic front and Ortona was captured, the advance had ground to a halt with the onset of winter blizzards at the end of December, making close air support and movement in the jagged terrain impossible. The route to Rome from the east using Route 5 was thus excluded as a viable option leaving the routes from Naples to Rome, highways 6 and 7, as the only possibilities; highway 7 (the old Roman Appian Way) followed along the west coast but south of Rome ran into the Pontine Marshes, which the Germans had flooded.
Highway 6 ran through the Liri valley, dominated at its south entrance by the rugged mass of Monte Cassino above the town of Cassino. Excellent observation from the peaks of several hills allowed the German defenders to detect Allied movement and direct highly accurate artillery fire, preventing any northward advance. Running across the Allied line was the fast flowing Rapido River, which rose in the central Apennine mountains, flowed through Cassino and across the entrance to the Liri valley. There the Liri river joined the Rapido to form the Garigliano River, which continued on to the sea.
With its heavily fortified mountain defences, difficult river crossings, and valley head flooded by the Germans, Cassino formed a linchpin of the Gustav Line, the most formidable line of the defensive positions making up the Winter Line.
In spite of its potential excellence as an observation post, because of the fourteen century old Benedictine abbey's historical significance, the German commander-in-chief in Italy, Field Marshal Albert Kesselring, ordered German units not to include it in their defensive positions, and informed the Vatican and the Allies accordingly in December 1943.
Nevertheless, some Allied reconnaissance aircraft maintained they observed German troops inside the monastery. While this remains unconfirmed, it is clear that once the monastery was destroyed it was occupied by the Germans and proved better cover for their emplacements and troops than an intact structure would have offered.
First battle.
Plans and preparation.
The plan of U.S. Fifth Army commander General Clark was for British X Corps, on the left of a thirty-kilometer (20 mi) front, to attack on January 17, 1944, across the Garigliano near the coast (British 5th and British 56th Infantry Divisions). British 46th Infantry Division was to attack on the night of January 19 across the Garigliano below its junction with the Liri in support of the main attack by U.S. II Corps on their right. The main central thrust by U.S. II Corps would commence on January 20 with 36th (Texas) U.S. Infantry Division making an assault across the swollen Rapido river five miles (8 km) downstream of Cassino. Simultaneously the French Expeditionary Corps, under General Alphonse Juin would continue its "right hook" move towards Monte Cairo, the hinge to the Gustav and Hitler defensive lines. In truth, Clark did not believe there was much chance of an early breakthrough, but he felt that the attacks would draw German reserves away from the Rome area in time for the attack on Anzio where U.S. VI Corps (British 1st and U.S. 3rd Infantry Divisions) was due to make an amphibious landing on January 22. It was hoped that the Anzio landing, with the benefit of surprise and a rapid move inland to the Alban Hills, which command both routes 6 and 7, would so threaten the Gustav defenders' rear and supply lines that it might just unsettle the German commanders and cause them to withdraw from the Gustav Line to positions north of Rome. Whilst this would have been consistent with the German tactics of the previous three months, Allied intelligence had not understood that the strategy of fighting retreat had been for the sole purpose of providing time to prepare the Gustav line where the Germans intended to stand firm. The intelligence assessment of Allied prospects was therefore over-optimistic.
Fifth Army had only reached the Gustav line on January 15, having taken six weeks of heavy fighting to advance the last seven miles (11 km) through the Bernhardt Line positions during which time they had sustained 16,000 casualties. They hardly had time to prepare the new assault, let alone take the rest and reorganization they really needed after three months of attritional fighting north from Naples. However, because the Allied Chiefs of Staff would only make landing craft available until early February, the Anzio landing had to take place in late January with the coordinated attack on the Gustav line some three days earlier.
First assault: X Corps on the left, 17 January.
The first assault was made on January 17. Near the coast, British X Corps (56th and 5th Divisions) forced a crossing of the Garigliano (followed some two days later by British 46th Division on their right) causing General von Senger, commander of German XIV Panzer Corps and responsible for the Gustav defences on the south western half of the line, some serious concern as to the ability of the German 94th Infantry Division to hold the line. Responding to Senger's concerns, Kesselring ordered the 29th and 90th Panzer Grenadier Divisions from the Rome area to provide reinforcement. There is some speculation as to what might have been if X Corps had had the reserves available to exploit their success and make a decisive breakthrough. The corps did not have the extra men, but there would certainly have been time to alter the overall battle plan and cancel or modify the central attack by U.S. II Corps to make men available to force the issue in the south before the German reinforcements were able to get into position. As it happened, Fifth Army HQ failed to appreciate the frailty of the German position, and the plan was unchanged. The two divisions from Rome arrived by January 21 and stabilized the German position in the south. In one respect, however, the plan was working in that Kesselring's reserves had been drawn south. The three divisions of X Corps sustained 4,000 casualties during the period of the first battle.
Main attack: II Corps in the centre, 20 January.
The central thrust by U.S. 36th Division commenced three hours after sunset on January 20. The lack of time to prepare meant that the approach to the river was still hazardous due to uncleared mines and booby traps, and the highly technical business of an opposed river crossing lacked the necessary planning and rehearsal. Although a battalion of the 143rd Regiment was able to get across the Rapido on the south side of San Angelo and two companies of the 141st Regiment on the north side, they were isolated for most of the time, and at no time was Allied armour able to get across the river, leaving them highly vulnerable to counterattacking tanks and self-propelled guns of General Eberhard Rodt's 15th Panzer Grenadier Division. The southern group was forced back across the river by mid-morning of January 21. Maj. Gen. Geoffrey Keyes, commanding II Corps, pressed Maj. Gen. Fred Walker of 36th Division to renew the attack immediately. Once again the two regiments attacked but with no more success against the well dug-in 15th Panzer Grenadier Division: 143rd Regiment got the equivalent of two battalions across, but once again there was no armoured support, and they were devastated when daylight came the next day. The 141st Regiment also crossed in two battalion strength, and despite the lack of armoured support managed to advance 1 km. However, with the coming of daylight, they too were cut down, and by the evening of January 22 the regiment had virtually ceased to exist; only 40 men made it back to the Allied lines. 
Rick Atkinson described the intense German resistance:
 Artillery and Nebelwerfer drumfire methodically searched both bridgeheads, while machine guns opened on every sound... GIs inched forward, feeling for trip wires and listening to German gun crews reload... to stand or even to kneel was to die... On average, soldiers wounded on the Rapido received "definitive treatment" nine hours and forty-one minutes after they were hit, a medical study later found..." 
The assault had been a costly failure, with 36th Division losing 2,100 men killed, wounded and missing in 48 hours.
II Corps try north of Cassino: 24 January.
The next attack was launched on January 24. The U.S. II Corps, with 34th Infantry Division under Maj. Gen. Charles W. Ryder spearheading the attack and French colonial troops on its right flank, launched an assault across the flooded Rapido valley north of Cassino and into the mountains behind with the intention of then wheeling to the left and attacking Monte Cassino from high ground. Whilst the task of crossing the river would be easier in that the Rapido upstream of Cassino was fordable, the flooding made movement on the approaches each side very difficult. In particular, armour could only move on paths laid with steel matting, and it took eight days of bloody fighting across the waterlogged ground for 34th Division to push back General Franek's 44th Infantry Division to establish a foothold in the mountains.
French Corps halted on the right flank.
On the right, the Moroccan-French troops made good initial progress against the German 5th Mountain Division, commanded by General Julius Ringel, gaining positions on the slopes of their key objective, Monte Cifalco. Forward units of the 3rd Algerian Division had also by-passed Monte Cifalco to capture Monte Belvedere and Colle Abate. General Juin was convinced that Cassino could be bypassed and the German defences unhinged by this northerly route but his request for reserves to maintain the momentum of his advance was refused and the one available reserve regiment (from 36th Division) was sent to reinforce 34th Division. By January 31 the French had ground to a halt with Monte Cifalco, which had a clear view of the French and U.S. flanks and supply lines, still in German hands. The two Moroccan-French divisions sustained 2,500 casualties in their struggles around Monte Belvedere.
II Corps in the mountains north of Cassino.
It became U.S. 34th Division's task (joined by 142nd Regiment of 36th Division) to fight southward along the linked hilltops towards the intersecting ridge on the south end of which was Monastery Hill. They could then break through down into the Liri valley behind the Gustav Line defences. It was very tough going: the mountains were rocky, strewn with boulders and cut by ravines and gullies. Digging foxholes on the rocky ground was out of the question, and each feature was exposed to fire from surrounding high points. The ravines were no better since the gorse growing there, far from giving cover, had been sown with mines, booby-traps and hidden barbed wire by the defenders. The Germans had had three months to prepare their defensive positions using dynamite and to stockpile ammunition and stores. There was no natural shelter, and the weather was wet and freezing cold.
By early February, American infantry had captured a strategic point near the hamlet of San Onofrio, less than a mile from the abbey, and by February 7 a battalion had reached Point 445, a round top hill immediately below the monastery and no more than 400 yd away. An American squad managed a reconnaissance right up against the cliff-like abbey walls, with the monks observing German and American patrols exchanging fire. However, attempts to take Monte Cassino were broken by overwhelming machine gun fire from the slopes below the monastery. Despite their fierce fighting, the 34th Division never managed to take the final redoubts on Hill 593 (known to the Germans as Calvary Mount), held by the 3rd battalion of the German 2nd Parachute Regiment, the dominating point of the ridge to the monastery.
Aftermath.
On February 11, after a final unsuccessful 3-day assault on Monastery Hill and Cassino town, the Americans were withdrawn. U.S. II Corps, after two and a half weeks of torrid battle, was fought out. The performance of 34th Division in the mountains is considered to rank as one of the finest feats of arms carried out by any soldiers during the war. In return they sustained losses of about 80% in the Infantry battalions, some 2,200 casualties.
At the height of the battle in the first days of February General von Senger und Etterlin had moved 90th Division from the Garigliano front to north of Cassino and had been so alarmed at the rate of attrition, he had "...mustered all the weight of my authority to request that the Battle of Cassino should be broken off and that we should occupy a quite new line. ... a position, in fact, north of the Anzio bridgehead". Kesselring refused the request. At the crucial moment von Senger was able to throw in the 71st Infantry Division whilst leaving 15th Panzer Grenadiers (whom they had been due to relieve) in place.
During the battle there had been occasions when, with more astute use of reserves, promising positions might have been turned into decisive moves. Some historians suggest this failure to capitalize on initial success could be put down to General Clark's lack of experience. However, it is more likely that he just had too much to do, being responsible for both the Cassino and Anzio offensives. This view is supported by General Truscott's inability, as related below, to get hold of him for discussions at a vital juncture of the Anzio breakout at the time of the fourth Cassino battle. Whilst General Alexander chose (for perfectly logical co-ordination arguments) to have Cassino and Anzio under a single army commander and splitting the Gustav line front between U.S. Fifth Army and British Eighth Army, Kesselring chose to create a separate Fourteenth Army under Gen. Eberhard von Mackensen to fight at Anzio whilst leaving the Gustav line in the sole hands of Gen. Heinrich von Vietinghoff's Tenth Army.
The withdrawn American units were replaced by the New Zealand Corps (2nd New Zealand Division and 4th Indian Division) from the British Eighth Army on the Adriatic front. The New Zealand Corps was commanded by Lt. Gen. Bernard Freyberg.
Second battle (Operation "Avenger").
Background.
With U.S. VI Corps under heavy threat at Anzio, Freyberg was under equal pressure to launch a relieving action at Cassino. Once again, therefore, the battle commenced without the attackers being fully prepared. As well, Corps HQ did not fully appreciate the difficulty in getting 4th Indian Infantry Division into place in the mountains and supplying them on the ridges and valleys north of Cassino (using mules across 7 mi of goat tracks over terrain in full view of the monastery, exposed to accurate artillery fire – hence the naming of Death Valley). This was evidenced in the writing of Maj. Gen. Howard Kippenberger, commander of New Zealand 2nd Division, after the war:Poor Dimoline (Brigadier Dimoline, acting commander of 4th Indian Division) was having a dreadful time getting his division into position. I never really appreciated the difficulties until I went over the ground after the war.
Freyberg's plan was a continuation of the first battle: an attack from the north along the mountain ridges and an attack from the southeast along the railway line and to capture the railway station across the Rapido less than a mile south of Cassino town. Success would pinch out Cassino town and open up the Liri valley. However, Freyberg had informed his superiors that he believed, given the circumstances, there was no better than a 50% chance of success for the offensive.
Destruction of the abbey.
Increasingly, the opinions of certain Allied officers were fixed on the great abbey of Monte Cassino: in their view it was the abbey—and its presumed use as a German artillery observation point—that prevented the breach of the ‘Gustav Line'.
The British press and C. L. Sulzberger of The New York Times frequently and convincingly and in (often manufactured) detail wrote of German observation posts and artillery positions inside the abbey. The commander in chief of the Mediterranean Allied Air Forces Lieutenant General Ira C. Eaker accompanied by Lieutenant General Jacob L. Devers (deputy to General Sir Henry Maitland Wilson, the Supreme Allied Commander of the Mediterranean Theater) personally observed during a fly-over “a radio mast [...] German uniforms hanging on a clothesline in the abbey courtyard; [and] machine gun emplacements 50 yd from the abbey walls.” Countering this, Major General Geoffrey Keyes of U.S. II Corps also flew over the monastery several times, reporting to Fifth Army G-2 he had seen no evidence the Germans were in the abbey. When informed of others' claims of having seen enemy troops there, he stated: “They’ve been looking so long they’re seeing things."
Major General Kippenberger of the New Zealand Corps HQ held it was their view the monastery was probably being used as the German's main vantage point for artillery spotting, since it was so perfectly situated for it no army could refrain. There is no clear evidence it was, but he went on to write that from a military point of view it was immaterial:
If not occupied today, it might be tomorrow and it did not appear it would be difficult for the enemy to bring reserves into it during an attack or for troops to take shelter there if driven from positions outside. It was impossible to ask troops to storm a hill surmounted by an intact building such as this, capable of sheltering several hundred infantry in perfect security from shellfire and ready at the critical moment to emerge and counter-attack. ... Undamaged it was a perfect shelter but with its narrow windows and level profiles an unsatisfactory fighting position. Smashed by bombing it was a jagged heap of broken masonry and debris open to effective fire from guns, mortars and strafing planes as well as being a death trap if bombed again. On the whole I thought it would be more useful to the Germans if we left it unbombed.
Major General Francis Tuker, whose 4th Indian Division would have the task of attacking Monastery Hill, had made his own appreciation of the situation. In the absence of detailed intelligence at Fifth Army HQ, he had found a book dated 1879 in a Naples bookshop giving details of the construction of the abbey. In his memorandum to Freyberg he concluded that regardless of whether the monastery was currently occupied by the Germans, it should be demolished to prevent its effective occupation. He also pointed out that with 150 foot (45 m) high walls made of masonry at least 10 feet (3 m) thick, there was no practical means for field engineers to deal with the place, and that bombing with "blockbuster" bombs would be the only solution since 1,000 pound bombs would be "next to useless". Tuker said he could not be induced to attack unless "the garrison was reduced to helpless lunacy by sheer unending pounding for days and nights by air and artillery".
On February 11, 1944, the acting commander of 4th Indian Division, Brigadier Harry Dimoline, requested a bombing raid. Tuker reiterated again his case from a hospital bed in Caserta, where he was suffering a severe attack of a recurrent tropical fever. Freyberg transmitted his request on February 12. The request, however, was greatly expanded by air force planners, and probably supported by Ira Eaker and Jacob Devers, who sought to use the opportunity to showcase the abilities of U.S. Army air power to support ground operations. Lieutenant General Mark W. Clark of Fifth Army and his chief of staff Major General Alfred Gruenther remained unconvinced of the “military necessity”. When handing over the U.S. II Corps position to the New Zealand Corps, Brigadier General J.A. Butler, deputy commander of U.S. 34th Division, had said "I don't know, but I don't believe the enemy is in the convent. All the fire has been from the slopes of the hill below the wall". Finally Clark, "who did not want the monastery bombed," pinned down the Commander-in-Chief Allied Armies in Italy, General Sir Harold Alexander to take the responsibility: "I said, 'You give me a direct order and we’ll do it,' and he did."
The bombing mission in the morning of February 15, 1944 involved 142 Boeing B-17 Flying Fortresses heavy bombers followed by 47 North American B-25 Mitchell and 40 Martin B-26 Marauder medium bombers. In all they dropped 1,150 tons of high explosives and incendiary bombs on the abbey, reducing the entire top of Monte Cassino to a smoking mass of rubble. Between bomb runs, the II Corps artillery pounded the mountain. Many Allied soldiers and war correspondents cheered as they observed the spectacle. Eaker and Devers watched; Juin was heard to remark “... no, they’ll never get anywhere this way.” Clark and Gruenther refused to be on the scene and stayed at their headquarters. That same afternoon and the next day an aggressive follow-up of artillery and a raid by 59 fighter bombers wreaked further destruction. The German positions on Point 593 above and behind the monastery were untouched.
Damningly, the air raid had not been coordinated with ground commands, and an immediate infantry follow-up failed to materialize. Its timing had been driven by the Air Force regarding it as a separate operation, considering the weather and requirements on other fronts and theaters without reference to ground forces. Many of the troops had only taken over their positions from U.S. II Corps two days previous, and besides the difficulties in the mountains, preparations in the valley had also been held up by difficulties in supplying the newly installed troops with sufficient material for a full-scale assault because of incessantly foul weather, flooding, and waterlogged ground. As a result, Indian troops on the Snake's Head were taken by surprise, while the New Zealand Corps was two days away from being ready to launch their main assault.
After the bombing.
Pope Pius XII was silent after the bombing; however, his Cardinal Secretary of State, Luigi Maglione, bluntly stated to the senior U.S. diplomat to the Vatican, Harold Tittmann, that the bombing was “a colossal blunder . . . a piece of a gross stupidity.”
It is certain from every investigation that followed since the event that the only people killed in the monastery by the bombing were 230 Italian civilians seeking refuge in the abbey. There is no evidence that the bombs dropped on the Monte Cassino monastery that day ever killed any German troops. However, given the imprecision of bombing in those days (it was estimated that only 10% of the bombs from the heavy bombers, bombing from high altitude, hit the monastery) bombs did fall elsewhere and killed German and Allied troops alike, although that would have been unintended. Indeed, sixteen bombs hit the Fifth Army compound at Presenzano 17 mi from Monte Cassino and exploded only yards away from the trailer where Gen. Clark was doing paperwork at his desk.
On the day after the bombing at first light, most of the civilians still alive fled the ruins. Only about 40 people remained: the six monks who survived in the deep vaults of the abbey, their 79 year old abbot, , three tenant farmer families, orphaned or abandoned children, the badly wounded and the dying. After artillery barrages, renewed bombing and attacks on the ridge by 4th Indian Division, the monks decided to leave their ruined home with the others who could move at 07:30 on February 17. The old abbot was leading the group down the mule path toward the Liri valley, reciting the rosary. After they arrived at a German first-aid station, some of the badly wounded who had been carried by the monks were taken away in a military ambulance. After meeting with a German officer, the monks were driven to the monastery of Sant'Anselmo. On February 18, the abbot met the commander of XIV Panzer Corps, Lieutenant-General Fridolin von Senger und Etterlin. One monk, Carlomanno Pellagalli, returned to the abbey; when he was later seen wandering the ruins, the German paratroopers thought he was a ghost. After April 3, he was not seen anymore.
It is now known that the Germans had an agreement not to use the abbey for military purposes. Following its destruction, paratroopers of the German 1st Parachute Division then occupied the ruins of the abbey and turned it into a fortress and observation post, which became a serious problem for the attacking allied forces.
Battle.
On the night following the bombing, a company of the 1st Battalion Royal Sussex Regiment (one of the British elements in 4th Indian Division) attacked the key point 593 from their position 70 yd away on Snakeshead Ridge. The assault failed, with the company sustaining 50% casualties.
The following night the Royal Sussex Regiment was ordered to attack in battalion strength. There was a calamitous start. Artillery could not be used in direct support targeting point 593 because of the proximity and risk of shelling friendly troops. It was planned therefore to shell point 575 which had been providing supporting fire to the defenders of point 593. The topography of the land meant that shells fired at 575 had to pass very low over Snakeshead ridge, and in the event some fell among the gathering assault companies. After reorganising, the attack went in at midnight. The fighting was brutal and often hand to hand, but the determined defence held and the Royal Sussex battalion was beaten off, once again sustaining over 50% casualties. Over the two nights, the Royal Sussex Regiment lost 12 out of 15 officers and 162 out of 313 men who took part in the attack.
On the night of February 17 the main assault took place. The 4/6th Rajputana Rifles would take on the assault of point 593 along Snakeshead Ridge with the depleted Royal Sussex Regiment held in reserve. 1/9th Gurkha Rifles was to attack Point 444. In the meantime, the 1/2nd Gurkha Rifles were to sweep across the slopes and ravines in a direct assault on the monastery. This latter was across appalling terrain, but it was hoped that the Gurkhas, from the Himalayas and so expert in mountain terrain, would succeed. This proved a faint hope. Once again the fighting was brutal, but no progress was made and casualties heavy. The Rajputanas lost 196 officers and men, the 1/9th Gurkhas 149 and the 1/2nd Gurkhas 96. It became clear that the attack had failed, and on February 18 Brigadier Dimoline and Freyberg called off the attacks on Monastery Hill.
In the other half of the main assault the two companies from 28th (Māori) Battalion from the New Zealand Division forced a crossing of the Rapido and attempted to gain the rail road station in Cassino town. The intention was to take a perimeter that would allow engineers to build a causeway for armoured support. Nevertheless, with the aid of a near constant smoke screen laid down by Allied artillery that obscured their location to the German batteries on Monastery Hill, the Māori were able to hold their positions for much of the day. Their isolation and lack of both armoured support and anti-tank guns made for a hopeless situation, however, when an armoured counterattack came in the afternoon on February 18. They were ordered to pull back to the river when it became clear to headquarters that both the attempts to break through (in the mountains and along the causeway) would not succeed. It had been very close. The Germans had been very alarmed by the capture of the station and, from a conversation on record between Kesselring and Tenth Army commander Gen. von Vietinghoff, had not expected their counterattack to succeed.
Third battle.
Plans.
For the third battle, it was decided that whilst the winter weather persisted, fording the Rapido downstream of Cassino town was an unattractive option (after the unhappy experiences in the first two battles). The "right hook" in the mountains had also been a costly failure, and it was decided to launch twin attacks from the north along the Rapido valley: one towards the fortified Cassino town and the other towards Monastery Hill. The idea was to clear the path through the bottleneck between these two features to allow access towards the station on the south and so to the Liri valley. British 78th Infantry Division, which had arrived in late February and placed under the command of New Zealand Corps, would then cross the Rapido downstream of Cassino and start the push to Rome.
None of the Allied commanders were very happy with the plan, but it was hoped that an unprecedented preliminary bombing by heavy bombers would prove the trump. Three clear days of good weather were required and for twenty one successive days the assault was postponed as the troops waited in the freezing wet positions for a favourable weather forecast. Matters were not helped by the loss of Major General Kippenberger, commanding 2 New Zealand Division, wounded by an anti-personnel mine and losing both his feet. He was replaced by Brigadier Graham Parkinson. Meanwhile, a German counterattack at Anzio had failed and been called off.
The battle.
The third battle began March 15. After a bombardment of 750 tons of 1,000-pound bombs with delayed action fuses, starting at 08:30 and lasting three and a half hours, the New Zealanders advanced behind a creeping artillery barrage from 746 artillery pieces. Success depended on taking advantage of the paralysing effect of the bombing. The bombing was not concentrated – only 50% landed a mile or less from the target point and 8% within 1,000 yards but between it and the shelling about half the 300 paratroopers in the town had been killed. The defences rallied more quickly than expected, and the Allied armour was held up by bomb craters. Nevertheless success was there for the New Zealanders' taking, but by the time a follow-up assault on the left had been ordered that evening it was too late: defences had reorganised, and more critically, the rain, contrary to forecast, had started again. Torrents of rain flooded bomb craters, turned rubble into a morass and blotted out communications, the radio sets being incapable of surviving the constant immersion. The dark rain clouds also blotted out the moonlight, hindering the task of clearing routes through the ruins. On the right, the New Zealanders had captured Castle Hill and point 165, and as planned, elements of Indian 4th Infantry Division, now commanded by Major General Alexander Galloway, had passed through to attack point 236 and thence to point 435, Hangman's Hill. In the confusion of the fight, a company of the 1/9th Gurkha Rifles had taken a track avoiding point 236 and captured point 435 whilst the assault on point 236 by the 1/6th Rajputana Rifles had been beaten off.
By the end of March 17 the Gurkhas held Hangman's Hill (point 435), 250 yd from the monastery, in battalion strength (although their lines of supply were compromised by the German positions at point 236 and in the northern part of the town), and whilst the town was still fiercely defended, New Zealand units and armour had got through the bottleneck and captured the station. However, the Germans were still able to reinforce their troops in the town and were proving adept at slipping snipers back into parts of the town that had supposedly been cleared.
March 19 was planned for the decisive blow in the town and on the monastery, including a surprise attack by tanks of 20th Armoured Brigade working their way along the track ("Cavendish Road") from Caira to Albaneta Farm (which had been prepared by engineer units under the cover of darkness) and from there towards the abbey. However, a surprise and fiercely pressed counterattack from the monastery on Castle Hill by the German 1st Parachute Division completely disrupted any possibility of an assault on the monastery from the Castle and Hangman's Hill whilst the tanks, lacking infantry support, were all knocked out by mid-afternoon. In the town the attackers made little progress, and overall the initiative was passing to the Germans whose positions close to Castle Hill, which was the gateway to the position on Monastery Hill, crippled any prospects of early success.
On 20 March Freyberg committed elements of 78th Infantry Division to the battle; firstly to provide a greater troop presence in the town so that cleared areas would not be reinfiltrated by the Germans, and secondly to reinforce Castle Hill to allow troops to be released to close off the two routes between Castle Hill and Points 175 and 165 being used by the Germans to reinforce the defenders in the town. The Allied commanders felt they were on the brink of success as grim fighting continued through 21 March. However, the defenders were resolute and the attack on Point 445 to block the German reinforcement route had narrowly failed whilst in the town Allied gains were measured only house by house.
On 23 March Alexander met with his commanders. A range of opinions were expressed as to the possibility of victory but it was evident that the New Zealand and Indian Divisions were exhausted. Freyberg was convinced that the attack could not continue and he called it off. The German 1st Parachute Division had taken a mauling, but had held.
Aftermath.
The next three days were spent stabilizing the front, extracting the isolated Gurkhas from Hangman's Hill and the detachment from New Zealand 24 Battalion which had held Point 202 in similar isolation. The Allied line was reorganised with the exhausted 4th Indian Division and 2 New Zealand Division withdrawn and replaced respectively in the mountains by British 78th Division and in the town by British 1st Guards Brigade. The New Zealand Corps headquarters was dissolved on 26 March and control was assumed by British XIII Corps. In their time on the Cassino front line 4th Indian Division had lost 3,000 men and the New Zealand Division 1,600 men killed, missing and wounded.
The German defenders too had paid a heavy price. The German XIV Corps War Diary for 23 March noted that the battalions in the front line had strengths varying between 40 and 120 men.
Fourth and final battle.
Alexander's strategy.
General Alexander's strategy in Italy was...to force the enemy to commit the maximum number of divisions in Italy at the time the cross-channel invasion is launched.
 Circumstances allowed him the time to prepare a major offensive to achieve this. His plan, originally inspired from French General Juin's idea to circle around Cassino and take the Aurunci with his mountain troops to break the Gustav line, was to shift the bulk of the British Eighth Army, commanded by Lt. Gen. Oliver Leese, from the Adriatic front across the spine of Italy to join the U.S. Fifth Army and attack along a 20 mi front between Cassino and the sea. Fifth Army (U.S. II Corps and French Expeditionary Corps) would be on the left and Eighth Army (XIII Corps and Polish II Corps) on the right. With the arrival of the spring weather, ground conditions were improved and it would be possible to deploy large formations and armour effectively.
Planning and preparation.
The plan for Operation "Diadem" was that U.S. II Corps on the left would attack up the coast along the line of Route 7 towards Rome. The French Corps to their right would attack from the bridgehead across the Garigliano originally created by X Corps in the first battle in January into the Aurunci Mountains which formed a barrier between the coastal plain and the Liri Valley. British XIII Corps in the centre right of the front would attack along the Liri valley. On the right Polish II Corps (3rd and 5th Divisions) commanded by Lt. Gen. Władysław Anders, had relieved 78th Division in the mountains behind Cassino on April 24 and would attempt the task which had defeated 4th Indian Division in February: isolate the monastery and push round behind it into the Liri valley to link with XIII Corps' thrust and pinch out the Cassino position. It was hoped that being a much larger force than their 4th Indian Division predecessors they would be able to saturate the German defences which would as a result be unable to give supporting fire to each other's positions. Improved weather, ground conditions and supply would also be important factors. Once again, the pinching manoeuvres by the Polish and British Corps were key to the overall success. Canadian I Corps would be held in reserve ready to exploit the expected breakthrough. Once the German Tenth Army had been defeated, U.S. VI Corps would break out of the Anzio beachhead to cut off the retreating Germans in the Alban Hills.
The large troop movements required for this took two months to execute. They had to be carried out in small units to maintain secrecy and surprise. U.S. 36th Division was sent on amphibious assault training, and road signposts and dummy radio signal traffic were created to give the impression that a seaborne landing was being planned for north of Rome. This was planned to keep German reserves held back from the Gustav line. Movements of troops in forward areas were confined to the hours of darkness and armoured units moving from the Adriatic front left behind dummy tanks and vehicles so the vacated areas appeared unchanged to enemy aerial reconnaissance. The deception was successful. As late as the second day of the final Cassino battle, Kesselring estimated the Allies had six divisions facing his four on the Cassino front. In fact there were thirteen.
Battle.
The first assault (11–12 May) on Cassino opened at 23:00 with a massive artillery bombardment with 1,060 guns on the 8th Army front and 600 guns on the Fifth Army front, manned by British, Americans, Poles, New Zealanders, South Africans, and French. Within an hour and a half the attack was in motion in all four sectors. By daylight the U.S. II Corps had made little progress, but their Fifth Army colleagues, the French Expeditionary Corps, had achieved their objectives and were fanning out in the Aurunci Mountains toward the Eighth Army to their right, rolling up the German positions between the two armies. On the Eighth Army front, XIII Corps had made two strongly opposed crossings of the Rapido (by British 4th Infantry Division and 8th Indian Division). Crucially, the engineers of Dudley Russell's 8th Indian Division had by the morning succeeded in bridging the river enabling the armour of 1st Canadian Armoured Brigade to cross and provide the vital element (so missed by the Americans in the first battle and New Zealanders in the second battle) to beat off the inevitable counterattacks from German tanks that would come.
In the mountains above Cassino, the aptly named Mount Calvary ("Monte Calvario", or Point 593 on Snakeshead Ridge) was taken by the Poles only to be recaptured by German paratroops. For three days Polish attacks and German counterattacks brought heavy losses to both sides. Polish II Corps lost 281 officers and 3,503 other ranks in assaults on Colonel Ludwig Heilmann's 4th Parachute Regiment, until the attacks were called off. "Just eight hundred Germans had succeeded in driving off attacks by two divisions," the area around the mountain having turned into a "miniature Verdun". In the early morning hours of 12 May, the Polish infantry divisions were met with "such devastating mortar, artillery, and small-arms fire that the leading battalions were all but wiped out."
By the afternoon of 12 May, the Rapido bridgeheads were increasing despite furious counterattacks whilst the attrition on the coast and in the mountains continued. By 13 May the pressure was starting to tell. The German right wing began to give way to Fifth Army. The French Corps had captured Monte Maio and were now in a position to give material flank assistance to the Eighth Army in the Liri valley against whom Kesselring had thrown every available reserve in order to buy time to switch to his second prepared defensive position, the Hitler Line, some eight miles (13 km) to the rear. On 14 May Moroccan Goumiers, travelling through the mountains parallel to the Liri valley, ground which was undefended because it was not thought possible to traverse such terrain, outflanked the German defence while materially assisting the XIII Corps in the valley.
In 1943, the Goumiers were colonial troops formed into four Groups of Moroccan Tabors (GTM), each consisting of three loosely organised Tabors (roughly equivalent to a battalion) specialised in mountain warfare. Juin's French Expeditionary Corps consisted of the Command of Moroccan Goumiers (CGM) (with the 1st, 3rd and 4th GTM) of General Augustin Guillaume totalling some 7,800 fighting men, broadly the same infantry strength as a division, and 4 more conventional divisions: the 2nd Moroccan Infantry Division (2 DIM), the 3rd Algerian Infantry Division (3 DIA), the 4th Moroccan Mountain Division (4 DMM) and the 1st Free French Division (1 DM).
The Allied commander, U.S. General Mark Clark also paid tribute to the Goumiers and the Moroccan regulars of the Tirailleur units:
On 15 May, the British 78th Division came into the XIII Corps line from reserve passing through the bridgehead divisions to execute the turning move to isolate Cassino from the Liri valley.
On 17 May, Polish II Corps launched their second attack on Monte Cassino. Under constant artillery and mortar fire from the strongly fortified German positions and with little natural cover for protection, the fighting was fierce and at times hand-to-hand. With their line of supply threatened by the Allied advance in the Liri valley, the Germans decided to withdraw from the Cassino heights to the new defensive positions on the Hitler Line. In the early hours of 18 May the 78th Division and Polish II Corps linked up in the Liri valley 2 mi west of Cassino town. On the Cassino high ground the survivors of the second Polish offensive were so battered that "it took some time to find men with enough strength to climb the few hundred yards to the summit." A patrol of Polish 12th Podolian Polish cavalry Regiment finally made it to the heights and raised a Polish flag over the ruins. The only remnants of the defenders were a group of thirty German wounded who had been unable to move. "The Poles, on their second try, had taken Monte Cassino, and the road to Rome was open." At the end of the war the Poles erected a Polish Cemetery at Monte Cassino on the slope of the mountain.
Aftermath.
Hitler line.
Eighth Army units advanced up the Liri valley and Fifth Army up the coast to the Hitler defensive line (renamed the Senger Line at Hitler's insistence to minimise the significance if it was penetrated). An immediate follow-up assault failed and Eighth Army then decided to take some time to reorganize. Getting 20,000 vehicles and 2,000 tanks through the broken Gustav Line was a major job taking several days. The next assault on the line commenced on 23 May with Polish II Corps attacking Piedimonte San Germano (defended by the redoubtable 1st Parachute Division) on the right and 1st Canadian Infantry Division (fresh from Eighth Army reserve) in the centre. On 24 May, the Canadians had breached the line, and 5th Canadian (Armoured) Division poured through the gap. On 25 May the Poles took Piedimonte, and the line collapsed. The way was clear for the advance northwards on Rome and beyond.
Anzio breakout.
As the Canadians and Poles launched their attack on 23 May, General Lucian Truscott, who had replaced Lt. Gen. John P. Lucas as commander of U.S. VI Corps, launched a two pronged attack using five (three U.S. and two British) of the seven divisions in the bridgehead at Anzio. Fourteenth Army, facing this thrust, was without any armoured divisions because Kesselring had sent his armour south to help Tenth Army in the Cassino action. A single armoured division, the 26th Panzer, was in transit from north of Rome where it had been held anticipating the non-existent seaborne landing the Allies had faked and so was unavailable to fight.
Clark captures Rome but fails to trap German Tenth Army.
By 25 May, with Tenth Army in full retreat, VI Corps were as planned driving eastwards to cut them off. By the next day they would have been astride the line of retreat and Tenth Army, with all Kesselring's reserves committed to them, would have been trapped. At this point, astonishingly, General Clark ordered Truscott to change his line of attack from a northeasterly one to Valmontone on Route 6 to a northwesterly one directly towards Rome. Reasons for Clark's decision are unclear and controversy surrounds the issue. Most commentators point to Clark's ambition to be the first to arrive in Rome although some suggest he was concerned to give a necessary respite to his tired troops (notwithstanding the new direction of attack required his troops to make a frontal attack on the Germans' prepared defences on the Caesar C line). Truscott later wrote in his memoirs that Clark "was fearful that the British were laying devious plans to be first into Rome," a sentiment somewhat reinforced in Clark's own writings. However, Alexander had clearly laid down the Army boundaries before the battle, and Rome was allocated to Fifth Army. Eighth Army was constantly reminded that their job was to engage Tenth Army, destroy as much of it as possible and then bypass Rome to continue the pursuit northwards (which in fact they did, harrying the retreating Tenth Army for some 225 mi towards Perugia in 6 weeks).
At the time, Truscott was shocked, writing later...I was dumbfounded. This was no time to drive to the northwest where the enemy was still strong; we should pour our maximum power into the Valmontone Gap to insure the destruction of the retreating German Army. I would not comply with the order without first talking to General Clark in person. ...[However] he was not on the beachhead and could not be reached even by radio. ... such was the order that turned the main effort of the beachhead forces from the Valmontone Gap and prevented destruction of Tenth Army. On the 26th the order was put into effect.
 He went on to writeThere has never been any doubt in my mind that had General Clark held loyally to General Alexander's instructions, had he not changed the direction of my attack to the northwest on May 26, the strategic objectives of Anzio would have been accomplished in full. To be first in Rome was a poor compensation for this lost opportunity.
 An opportunity was indeed missed and seven divisions of Tenth Army were able to make their way to the next line of defence, the Trasimene Line where they were able to link up with Fourteenth Army and then make a fighting withdrawal to the formidable Gothic Line north of Florence.
Rome was liberated on June 4, 1944, just two days before the Normandy invasion.
Battle honours.
A number of battle honours were awarded for the Battle of Cassino. The units which participated in the first part of the campaign were awarded the battle honour 'Cassino I'. In addition, subsidiary battle honours were given to those units which participated in specific engagements during the first part. These were Monastery Hill, Castle Hill and Hangman's Hill.
Units which participated in the later part of the battle were awarded the honour 'Cassino II'.
All members of the Polish units received the Monte Cassino Commemorative Cross.
Casualties.
The capture of Monte Cassino came at a high price. The Allies suffered around 55,000 casualties in the Monte Cassino campaign. German casualty figures are estimated at around 20,000 killed and wounded. Total Allied casualties spanning the period of the four Cassino battles and the Anzio campaign with the subsequent capture of Rome on 5 June 1944, were over 105,000.
Legacy.
Evacuation and treasures.
In the course of the battles, the ancient abbey of Monte Cassino, where St. Benedict first established the Rule that ordered monasticism in the west, was entirely destroyed by bombing and artillery barrages in February 1944.
During prior months in the Italian autumn of 1943, two officers in the "Hermann Göring Panzer Division", Captain Maximilian Becker and Lieutenant Colonel Julius Schlegel, proposed the removal of Monte Cassino's treasures to the Vatican and Vatican-owned Castel Sant'Angelo ahead of the approaching front. The officers convinced church authorities and their own senior commanders to use the division’s trucks and fuel for the undertaking. They had to find the materials necessary for crates and boxes, find carpenters among their troops, recruit local labourers (to be paid with rations of food plus twenty cigarettes a day), and then manage the "massive job of evacuation centered on the library and archive," a treasure "literally without price." The richness of the abbey’s archives, library and gallery included "800 papal documents, 20,500 volumes in the Old Library, 60,000 in the New Library, 500 "incunabula", 200 manuscripts on parchment, 100,000 prints and separate collections." The first trucks, carrying paintings by Italian old masters, were ready to go less than a week from the day Becker and Schlegel independently first came to Monte Cassino. Each vehicle carried monks to Rome as escorts; in more than 100 truckloads the convoys nearly depopulated the abbey’s monastic community. The task was completed in the first days of November 1943. "In three weeks, in the middle of a losing war, in another country, it was quite a feat." After a mass in the basilica, Abbot formally presented signed parchment scrolls in Latin to General Paul Conrath, to "tribuno militum Julio Schlegel" and "Maximiliano Becker medecinae doctori" "for rescuing the monks and treasures of the Abbey of Monte Cassino." After the war Schlegel spent seven months in an Allied prison as a suspected looter but was freed after favourable testimony from the Monte Cassino monks.
Among the treasures saved were Titians, an El Greco, and two Goyas.
United States military history reviews.
The U.S. government’s official position on the German occupation of Monte Cassino changed over a quarter-century. The assertion that of German use of the abbey was "irrefutable" was removed from the record in 1961 by the Office of the Chief of Military History. A congressional inquiry to the same office in the 20th anniversary year of the bombing stated: "It appears that no German troops, except a small military police detachment, were actually inside the abbey" before the bombing. The final change to the U.S. Army’s official record was made in 1969 and concluded that “the abbey was actually unoccupied by German troops.”
Wojtek.
Among the huge variety of troops serving at Monte Cassino, probably the most unusual was a bear from Iran, called Wojtek. Raised by and enlisted into the 22nd Artillery Supply Company of the Polish II Corps, he carried artillery shells during the battle.
Marocchinate.
The day following the battle, the Goumiers, French Moroccan colonial troops attached to the French Expeditionary Forces, raped and murdered through the surrounding hills, plundering the countryside. Some of these irregular units are reported to have committed atrocities against the Italian peasant communities in the region. In Italy the victims of these acts were described as "Marocchinate" meaning literally "Moroccaned" (or people who have been subjected to acts committed by Moroccans).
War graves and memorials.
Immediately after the cessation of fighting at Monte Cassino, the Polish government in Exile (in London) created the Monte Cassino campaign cross to commemorate the Polish part in the capture of the strategic point. It was also during this time that Polish song-writer Feliks Konarski, who had taken part in the fighting there, wrote his anthem "Czerwone maki na Monte Cassino" (The Red Poppies on Monte Cassino). Later, an imposing Polish cemetery was laid out; this is prominently visible to anybody surveying the area from the restored monastery.
The Commonwealth War Graves cemetery on the western outskirts of Cassino is a burial place of British, New Zealand, Canadian, Indian, Gurkha, Australian, and South African casualties. The French and Italians are on Route 6 in the Liri Valley; the Americans are at the Sicily–Rome American Cemetery and Memorial in Nettuno. The German cemetery is approximately 2 mi north of Cassino in the Rapido Valley.
In the 1950s, a subsidiary of the Pontificia Commissione di Assistenza distributed Lamps of Brotherhood, cast from the bronze doors of the destroyed Abbey, to representatives of nations that had served on both sides of the war to promote reconciliation.
In 2006, a memorial was unveiled in Rome honouring the Allied forces that fought and died to capture the city.

</doc>
<doc id="33090" url="http://en.wikipedia.org/wiki?curid=33090" title="Double-Cross System">
Double-Cross System

The Double-Cross System, or XX System, was a World War II anti-espionage and deception operation of the British Security Service, a civilian organisation usually referred to by its cover title MI5. Nazi agents in Britain – real and false – were captured, turned themselves in or simply announced themselves and were then used by the British to broadcast mainly disinformation to their Nazi controllers. Its operations were overseen by the Twenty Committee under the chairmanship of John Cecil Masterman; the name of the committee comes from the number 20 in Roman numerals: "XX" (i.e. double crosses).
The policy of MI5 during the war was initially to use the system for counter-espionage. It was only later that its potential for deception purposes was realised. Agents from both of the German intelligence services, the Abwehr and Sicherheitsdienst (SD), were apprehended. Many of the agents who reached British shores turned themselves in to the authorities. Still others were apprehended when they made elementary mistakes during their operations. In addition, some were false agents who had tricked the Germans into believing they would spy for them if they helped them reach England (e.g., Treasure, Fido). Later agents were instructed to contact agents in place who, unknown to the Abwehr, were already controlled by the British. The Abwehr and SD sent agents over by a number of means including parachute drops, submarine and travel via neutral countries. The last route was most commonly used, with agents often impersonating refugees. After the war it was discovered that "all" the agents Germany sent to Britain had given themselves up or had been captured with the possible exception of one who committed suicide.
Early agents.
Following a July 1940 conference in Kiel, the Abwehr (German intelligence) launched an espionage campaign against Britain involving both intelligence gathering and sabotage. The spies were sent over from Europe in various ways; some parachuted or came off a submarine. Others entered the country on false passports, or posing as refugees.
Public perception in Britain at that time was that the country was full of well trained German spies who were deeply integrated into society. There was widespread, as Churchill put it, "spy-mania". The truth was that between September and November 1940 fewer than twenty five agents arrived in the country; mostly of Eastern European extraction, badly trained and poorly motivated.
The agents were not difficult to spot - a task made still easier by the cracking of the German's Enigma encryption. MI5, with advance warning of infiltration, had no trouble picking up almost all of the spies sent to the country. Writing in 1972, John C. Masterman (who would later head the Twenty Committee) said that by 1941 MI5 "actively ran and controlled the German espionage system in [the United Kingdom]." It was not an idle boast; post-war records confirmed that none of the Abwehr agents, bar one who committed suicide, went unnoticed.
Once caught, the spies were deposited in the care of Lieutenant Colonel Robin Stephens at Camp 020 (Latchmere House, Richmond). After Stephens, a notorious and brilliant interrogator, had picked apart their life history, the agents were either spirited away (to be imprisoned or executed) or, if judged acceptable, offered the chance to turn double on the Germans.
Control of these new double agents fell to Thomas Argyll Robertson (usually called Tar, from his initials), a charismatic MI5 agent. A Scot, and something of a playboy, Robertson had some early experience with double agents; just prior to the war he had been case officer to Arthur Owens (code name Snow). Owens was an oddity, and it became apparent that he was simply playing the Germans and British against each other – to what end Robertson was unable to uncover. The experiment had not appeared to be a success, but MI5 had learned key lessons about how the Abwehr operated and how double agents might be useful.
Robertson, in particular, believed that turning German spies against their masters would have numerous benefits; for example determining what information the Abwehr wanted or to actively mislead them as part of a military deception. In addition, it would discourage them from sending more agents if they believed an operational network existed. Section B1A (a subordinate of B section, under Guy Liddell) was formed and Robertson was put in charge of handling the double-agent program.
Robertson's first agents were not a success; Giraffe (George Graf) was never really used and Gander (Kurt Goose; MI5 had a penchant for amusingly relevant code names) had been sent to Britain with a radio that could only transmit, not receive. Both were quickly decommissioned. The next two attempts involved even more farce; Gösta Caroli and Wulf Schmidt (a Danish citizen) landed, via parachute, in September 1940. The two were genuine Nazis, had trained together and were friends. Caroli was coerced into turning double in return for Schmidt's life being spared, whilst Schmidt was told that Caroli had sold him out and in anger swapped sides.
Caroli quickly became a problem; he attempted to strangle his MI5 handler before making an escape carrying a canoe, on a motorcycle. He vaguely planned to row to Holland, but came unstuck after falling off the bike in front of a policeman. He was eventually recaptured and judged too much trouble to be used. Schmidt was more of a success. Codenamed 'Tate', he continued to contact Germany until May 1945. However, these eccentric spies made Robertson aware that handling double agents was going to be a difficult task.
Methods of operation.
The main form of communication that agents used with their handlers was secret writing. Letters were intercepted by the postal censorship authorities and some agents were caught by this method. Later in the war, wireless sets were provided by the Germans. Eventually transmissions purporting to be from one double agent were facilitated by transferring the operation of the set to the main headquarters of MI5 itself. On the British side, a critical aid in the fight against the Abwehr and SD was the breaking of the German ciphers. Abwehr hand ciphers were cracked early in the war, and SD hand ciphers and Abwehr Enigma ciphers followed thereafter. The signals intelligence allowed an accurate assessment of whether the double agents were really trusted by the Germans and what effect their information had.
A crucial aspect of the system was the need for genuine information to be sent along with the deception material. This need caused problems on a regular basis early in the war, with those who controlled the release of information reluctant to provide even a small amount of relatively innocuous genuine material. Later in the war, as the system became a more coherent whole, genuine information was integrated into the deception system. For example, one of the agents sent genuine information about Operation "Torch" to the Germans. It was postmarked before the landing, but due to delays deliberately introduced by the British authorities, the information did not reach the Germans until after the Allied troops were ashore. The information impressed the Germans as it appeared to date from before the attack, but it was militarily useless to them.
Operation outside the United Kingdom.
It was not only in the United Kingdom that the system was operated. A number of agents connected with the system were run in neutral Spain and Portugal. Some even had direct contact with the Germans in occupied Europe. One of the most famous of the agents who operated outside of the UK was Dušan Popov ("Tricycle"). There was even a case in which an agent started running deception operations independently from Portugal using little more than guidebooks, maps, and a very vivid imagination to convince his Abwehr handlers that he was spying in the UK. This agent, Joan Pujol Garcia ("Garbo"), created an entire network of phantom sub-agents and finally succeeded in convincing the British authorities that he could be useful. He and his fictitious network were absorbed into the main Double-Cross System, and he became so respected by the Abwehr that they stopped landing agents in Britain after 1942. They thus became wholly dependent on the spurious information that was fed to them by Garbo's network and the other Double-Cross agents.
Operation Fortitude and D-Day landings.
The British put their double-agent network to work in support of Operation "Fortitude", a plan to deceive the Germans about the location of the invasion of France. Allowing one of the double agents to claim to have stolen documents describing the closely guarded invasion plans might have aroused suspicion. Instead, agents were allowed to report minutiae such as insignia on soldiers' uniforms and unit markings on vehicles. The observations in the south-central areas largely gave accurate information about the units located there: the actual invasion forces. Reports from southwest England indicated few troop sightings, when in reality many units were housed there. Reports from the southeast depicted the real and the notional Operation "Quicksilver" forces. Any military planner would know that to mount a massive invasion of Europe from England, Allied units had to be staged around the country, with those that would land first nearest to the invasion point. German intelligence used the agent reports to construct an order of battle for the Allied forces that placed the centre of gravity of the invasion force opposite Pas de Calais, the point on the French coast closest to England and therefore a likely invasion site. The deception was so effective that the Germans kept 15 reserve divisions near Calais even after the invasion had begun at Normandy, lest it prove to be a diversion from the main invasion at Calais.
The Allies were willing to risk exposing the Double Cross network to achieve the needed surprise for the Normandy invasion. However, early battle reports of insignia on Allied units that the German armies encountered only confirmed the information the double agents had sent, increasing the Germans' trust in their network. Some of the double agents were informed in radio messages from Germany after the invasion that they had been awarded the Iron Cross.
V-weapons deception.
The British noticed that, during the V-1 flying bomb attacks of 1944, the weapons were falling 2–3 miles short of Trafalgar Square — the actual Luftwaffe aiming points such as Tower Bridge were unknown to the British. Duncan Sandys was told to get MI5-controlled German agents such as Zig Zag and TATE to report the V-1 impacts back to Germany. In order to make the Germans aim short, the British used the double agents to exaggerate the number of V-1s falling in the north and west of London and not to report, when possible, those in the south and east. For example, circa June 22, 1944, only one of seven impacts was reported as being south of the Thames, when ¾ of the impacts had been there. Although Germany was able to plot a sample of V-1s which had radio transmitters, which confirmed that they had fallen short, the telemetry was disregarded in favour of the human intelligence.
When the German 65th Army Corps received a false Double Cross V-1 report that there was considerable damage in Southampton —which had not been a V-1 target—the V-1s were temporarily aimed at the South Coast Ports. V-1s were extremely powerful. As a result, the Double Cross deception also caused "retargetting" from London, not just inaccurate aiming. However, when V-1s launched from Heinkel He 111s at Southampton on July 7 were inaccurate, British advisor Frederick Lindemann recommended the agents report that the attack caused "heavy losses" in order to save hundreds of Londoners each week at the expense of only a few lives in the ports. When the Cabinet learned on August 15 of the deception, Herbert Morrison said that they had no right to decide that one man should die while another should survive, but the deception was approved to continue.
Moreover, when the subsequent V-2 rocket blitz began with only a few minutes from launch to impact, the deception was enhanced by providing locations genuinely damaged by bombing, verifiable by aerial reconnaissance, for impacts in "central London", but each "time-tagged" with the time of an earlier impact that had fallen 5–8 miles "short" of central London. From mid-January to mid-February 1945, the mean point of V-2 impacts edged eastward at the rate of a couple of miles a week, with more and more V-2s falling short of central London.

</doc>
<doc id="33091" url="http://en.wikipedia.org/wiki?curid=33091" title="Joan Pujol Garcia">
Joan Pujol Garcia

Joan Pujol Garcia MBE (Catalan; Spanish: Juan Pujol García) (14 February 1912 – 10 October 1988) deliberately became a double agent during World War II, known by the British codename Garbo and the German codename Arabel. Pujol had the rare, if not unique, distinction of receiving decorations from both sides during World War II, gaining both an Iron Cross from the Germans and a Member of the Order of the British Empire from the British.
After developing a loathing of both the Communist and Fascist regimes in Europe during the Spanish Civil War, Pujol decided to become a spy for the Allies as a way to do something "for the good of humanity". Pujol and his wife contacted the British and American intelligence agencies, but each rejected his offer. Undeterred, he created a false identity as a fanatically pro-Nazi Spanish government official and successfully became a German agent. He was instructed to travel to Britain and recruit additional agents; instead he moved to Lisbon and created bogus reports from a variety of public sources, including a tourist guide to England, train timetables, cinema newsreels, and magazine advertisements. Although the information would not have withstood close examination, Pujol soon established himself as a trustworthy agent. He began inventing fictional sub-agents who could be blamed for false information and mistakes.
The Allies finally accepted Pujol when the Germans spent considerable resources attempting to hunt down a fictional convoy. The family was moved to Britain and Pujol was given the code name Garbo. Pujol and his handler Tomás (Tommy) Harris spent the rest of the war expanding the fictional network, communicating at first by letter, later by radio. Eventually the Germans were funding a network of twenty-seven fictional agents.
Pujol had a key role in the success of Operation Fortitude, the deception operation intended to mislead the Germans about the timing and location of the invasion of Normandy near the end of the war. The false information Pujol supplied helped persuade German intelligence that the main attack would be in the Pas de Calais, keeping two armoured divisions and 19 infantry divisions there for two months after the Normandy invasion.
Early life.
Pujol was born in the Catalan city of Barcelona, Spain, on 14 February 1912 (or possibly 28 February 1912) to Juan Pujol, a Catalan who owned a factory that produced dye, and Mercedes Guijarro Garcia, from the Andalusian town of Motril in the Province of Granada. The third of four children, Pujol was sent at age seven to the Valldemia boarding school run by the Marist Brothers in Mataró, twenty miles from Barcelona; he remained there for the next four years. The students were only allowed out of the school on Sundays if they had a visitor, so his father made the trip every week.
His mother came from a very strict Catholic family who took communion every day, but his father was much more secular and had liberal political beliefs. At age thirteen, he transferred to a school in Barcelona run by his father's card-playing friend Father Mossen Josep, where he remained for three years. After an argument with a teacher, he decided that he no longer wished to remain at the school, and became an apprentice at a hardware store.
Pujol engaged in a variety of occupations prior to and after the Spanish Civil War, such as studying animal husbandry at the Royal Poultry School in Arenys de Mar and managing various businesses, including a cinema.
His father died a few months after the Second Republic's birth in 1931, while Pujol was completing his education as a poultry farmer. Pujol's father left his family well-provided for, until his father's factory was taken over by the workers, around the Spanish Civil War's start.
Spanish Civil War.
In 1931, Pujol did his six months of compulsory military service in a cavalry unit, the 7th Regiment of Light Artillery. He knew he was unsuited for a military career, hating horse-riding and claiming to lack the "essential qualities of loyalty, generosity and honor".
Pujol was managing a poultry farm north of Barcelona in 1936 when the Spanish Civil War began. His sister Elana's fiancé was taken by Republican forces, and later she and his mother were arrested and accused of being counter-revolutionaries. A relative in a trade union was able to rescue them from captivity.
He was called up for service on the Republican side but opposed the Republican government due to their treatment of his family. He hid at the home of his girlfriend, but was captured in a police raid and imprisoned for a week, before being freed via the resistance group "Socorro Blanco". They hid him until they could produce fake identity papers that showed him to be too old for military service.
He started managing a poultry farm that had been requisitioned by the local Republican government, but it was not economically viable. The experience with rule by committee intensified his antipathy toward Communism.
He re-joined the Republican side using the false papers with the intention to desert as soon as possible, volunteering to lay telegraph cables near the front lines. He managed to desert to the Nationalist side during the Battle of the Ebro in September 1938. However, he was equally ill-treated by the Nationalist side, disliking their fascist influences and being struck and imprisoned by his colonel upon Pujol's expressing sympathy with the monarchy.
His experience with both sides left him with a deep loathing of both fascism and communism, and by extension Nazi Germany and the Soviet Union. He was proud that he had managed to serve both sides without firing a single bullet for either. After his discharge from the Nationalist army, he met his future first wife, Araceli Gonzalez, in Burgos and married her in Madrid; they had one child, Juan Fernando.
World War II double-agent.
Independent spying.
In 1940, during the early days of World War II, Pujol decided that he must make a contribution "for the good of humanity" (and to oppose the Franco regime) by helping Britain – which, with its Empire, was Germany's only adversary at the time.
He initially approached the British three different times, including through his wife (though Pujol edited her participation out of his memoirs), but they showed no interest in employing him as a spy. Therefore, he resolved to establish himself as a German agent before approaching the British again to offer his services as a double-agent.
Pujol created an identity as a fanatically pro-Nazi Spanish government official who could travel to London on official business; he also had created for himself a fake Spanish diplomatic passport via fooling a printer into thinking Pujol worked for the Spanish embassy in Lisbon. He contacted Friedrich Knappe-Ratey, a German Intelligence agent in Madrid codenamed "Frederico", and German Intelligence accepted him and gave him a crash course in espionage, including secret writing, a bottle of invisible ink, a codebook, and 600 pounds for expenses. His instructions were to move to Britain and recruit a network of British agents.
He moved instead to Lisbon, and – using a tourist's guide to England, reference books and magazines from the Lisbon public library, and newsreel reports he saw in cinemas – created seemingly credible reports that appeared to come from London. He claimed to be travelling around Britain and submitted his travel expenses based on fares listed in a British railway guide. A slight difficulty was that he did not understand the pre-decimal system of currency used in Britain, expressed in pounds, shillings, and pence, and was unable to total his expenses. Instead, he simply itemised them, and said that he would send the total later.
During this time he created an extensive network of fictitious sub-agents living in different parts of Britain. Because he had never actually visited the UK, he made several mistakes, including claiming that his alleged contact in Glasgow "would do anything for a litre of wine", unaware of Scottish drinking habits. His reports were intercepted via the Ultra program, and seemed so credible that the British counter-intelligence service MI5 launched a full-scale spy hunt.
In February 1942, either he or his wife (accounts differ) approached the United States after it had entered the war, contacting U.S. Navy Lieutenant Patrick Demorest in the naval attache's office in Lisbon, who recognised Pujol's potential. Demorest contacted his British counterparts.
Work with MI5.
The British had become aware that someone had been feeding the Germans misinformation, and realised the value of this after the German navy wasted resources attempting to hunt down a non-existent convoy reported to them by Pujol.
He was relocated to Britain on 24 April 1942 and given the code name Bovril, after the drink concentrate. However, after he passed an MI5 security check conducted by two MI5 officers (Cyril Mills and Tomás Harris) and an MI6 officer (Desmond Bristow), Mills (who Pujol only ever knew as Mr Grey) suggested that his code name be changed to Garbo, after Greta Garbo. Pujol's wife and child were later relocated to Britain. Pujol operated as a double agent under the XX Committee's aegis. Mills spoke no Spanish, and passed his case over to the Spanish-speaking officer Harris. Together, Harris and Pujol wrote 315 letters, averaging 2,000 words, addressed to a post office box in Lisbon supplied by the Germans. His fictional spy network was so efficient and verbose that his German handlers were overwhelmed and made no further attempts to recruit any additional spies in the UK, according to the Official History of British Intelligence in WW2.
Garbo was unique among Britain's double-agents, having deliberately set out to become one. The rest were enemy agents who had been discovered and turned, which required that they work under guard.
The information supplied to German intelligence was a mixture of complete fiction, genuine information of little military value, and valuable military intelligence artificially delayed. In November 1942, just before the Operation TORCH landings in North Africa, Garbo's agent on the River Clyde reported that a convoy of troopships and warships had left port, painted in Mediterranean camouflage. The letter was postmarked before the landings and sent via airmail, but was timed to arrive too late to be useful. Pujol received a reply stating "we are sorry they arrived too late but your last reports were magnificent".
Pujol had been supposedly communicating with the Germans via a courier, a KLM pilot willing to carry messages for cash. This meant that message deliveries were limited to the KLM flight schedule. In 1943, responding to German requests for speedier communication, Pujol and Harris created a fictional radio mechanic to communicate directly. It became the preferred method of communication.
On occasion, he had to fabricate reasons why his agents had failed to report easily available information that the Germans would eventually know about. For example, he reported that his (fabricated) Liverpool agent had fallen ill just before a major fleet movement from that port on the north-west coast of England. The illness meant that the agent was unable to warn the Germans of the event. To support the illness story, the "agent" eventually "died" and an obituary was placed in the local newspaper as further evidence to convince the Germans, who were also persuaded to pay a pension to the agent's "widow".
The move to radio communication required that Arabel (and therefore Garbo) be supplied with the most sophisticated text encryption possible by hand. The German codes Garbo used were supplied in turn to the codebreakers at Bletchley Park. Garbo's encrypted radio reports would be received in Madrid, manually decrypted, and re-encrypted with an Enigma machine for transmission to Berlin. This gave the codebreakers the best possible source material in their attempts to decrypt the code being used for the second leg, having supplied the original text.
Operation Fortitude.
In January 1944, the Germans told Pujol that they believed a large-scale invasion of Europe was imminent and asked to be kept informed. This was Operation Overlord, and Pujol played a leading role in the deception and misinformation campaign Operation Fortitude, sending over 500 radio messages between January 1944 and D-Day, at times more than twenty messages per day. During planning for the Normandy beach invasion, it was decided that it was vitally important that the German High Command be misled that the landing would happen at the Pas de Calais.
In order to maintain his credibility, it was decided that Garbo (or one of his agents) should forewarn the Germans of the timing and some details of the actual invasion of Normandy, although sending it too late for them to take effective action. Special arrangements were made with the German radio operators to be listening to Garbo through the night of 5/6 June 1944, using the story that a sub-agent was about to arrive with important information. However, when the call was made at 3 am, no reply was received from the German operators until 8 am. Turning this piece of bad luck on its head, Garbo was able to add more operational details to the message when finally sent and increase his standing with the Germans. Garbo told his German contacts that he was disgusted that his message was missed, saying "I cannot accept excuses or negligence. Were it not for my ideals I would abandon the work".
On 9 June (3 days after D-day), Garbo sent a message to German High Command that reached Adolf Hitler saying that he had conferred with his agents and developed an order of battle showing 75 divisions in England—in reality, there were only about 50. Part of the "Fortitude" plan was intended to convince the Germans that a fictitious formation—First U.S. Army Group, comprising 11 divisions (150,000 men), commanded by General George Patton—was stationed in the south and east of Britain.
The deception was supported by fake planes, inflatable tanks and vans travelling about the area transmitting bogus radio chatter. Garbo's message pointed out that units from this formation had not participated in the invasion, and therefore the first landing should be considered a diversion. A German message to Madrid sent two days later said "all reports received in the last week from Arabel [Pujol's German code-name] undertaking have been confirmed without exception and are to be described as exceptionally valuable." A post-war examination of German records found that, during Operation Fortitude, no fewer than sixty-two of Pujol's reports were included in German military high command intelligence summaries.
The German High Command accepted Garbo's reports so completely that they kept two armoured divisions and 19 infantry divisions in the Pas de Calais waiting for a second invasion through July and August 1944. The German Commander-in-Chief, Field Marshal Gerd von Rundstedt, refused to allow General Erwin Rommel to move his divisions to Normandy. There were more German troops in the Pas de Calais region two months after the Normandy invasion than there had been on D-Day.
In late June, Garbo was instructed by the Germans to report on the falling of V1 flying bombs. Finding no way of giving false information without arousing suspicion, and being unwilling to give correct information, Harris arranged for Garbo to be "arrested". He returned to duty a few days later, now having a "need" to avoid London, and forwarded an "official" letter of apology from the Home Secretary for his unlawful detention.
The Germans paid Garbo (or Arabel, as they called him) US$340,000 to support his network of agents, which at one point totaled 27 fabricated characters.
Honors.
As Arabel, Pujol was, on 29 July 1944, awarded the Iron Cross Second Class for his services to the German war effort. The award was normally reserved for front-line fighting men and required Hitler's personal authorisation. The Iron Cross was presented via radio, and he received the physical medal from one of his German handlers after the war had ended. As Garbo, he received a Member of the Order of the British Empire from King George VI, on 25 November 1944. The Nazis never realised they had been fooled, and thus Pujol earned the distinction of being one of the few – if not the only – to receive decorations from both sides during World War II.
After the war.
After World War II, Pujol feared reprisals from surviving Nazis. With the help of MI5, Pujol travelled to Angola and faked his death from malaria in 1949. He then moved to Lagunillas, Venezuela, where he lived in (relative) anonymity running a bookstore and gift shop.
Pujol divorced his first wife and married Carmen Cilia, with whom he had two sons, Carlos Miguel and Juan Carlos, and a daughter who died in 1975 at the age of twenty. By 1984, Pujol had moved to his son Carlos Miguel's house in La Trinidad, Caracas.
In 1971, the British politician Rupert Allason, writing under the pen name "Nigel West", became interested in Garbo. For several years, he interviewed various former intelligence officers, but none knew Garbo's real name. Eventually, Tomas Harris' friend Anthony Blunt, the Soviet spy who had penetrated MI5, said that he had met Garbo, and knew him as "either Juan or Jose Garcia". Allason's investigation was stalled from that point until March 1984, when a former MI5 officer who had served in Spain supplied Pujol's full name. Allason hired a research assistant to call every J. Garcia in the Barcelona phone book, eventually contacting Pujol's nephew. Pujol and Allason finally met in New Orleans on 20 May 1984.
At Allason's urging, Pujol travelled to London and was received by Prince Philip, Duke of Edinburgh at Buckingham Palace, in an unusually long audience. After that he visited the Special Forces Club and was reunited with a group of his former colleagues, including Colonel T. A. Robertson, Colonel Roger Hesketh, Cyril Mills, and Desmond Bristow.
On the 40th anniversary of D-Day, 6 June 1984, Pujol travelled to Normandy to tour the beaches and pay his respects to the dead.
Pujol died in Caracas in 1988 and is buried in Choroní, a town inside Henri Pittier National Park by the Caribbean Sea.
Pujol's network of fictitious agents.
Each of Pujol's fictitious Agents was tasked with recruiting additional sub-agents, the KLM steward recruiting the KLM pilot, and Moonbeam recruiting his cousin.
Film and television.
Garbo feature films have been attempted on several occasions, but none have reached production to date.

</doc>
<doc id="33093" url="http://en.wikipedia.org/wiki?curid=33093" title="Eddie Chapman">
Eddie Chapman

Edward Arnold "Eddie" Chapman (16 November 1914 – 11 December 1997) was an English criminal and wartime spy. During the Second World War he offered his services to Nazi Germany as a spy and a traitor and subsequently became a British double agent. His British Secret Service handlers code named him ZigZag in acknowledgement of his rather erratic personal history. He had a number of criminal aliases known by the British police, amongst them Edward Edwards, Arnold Thompson and Edward Simpson. His German codename was Fritz or, later, after endearing himself to his German contacts, its diminutive form of Fritzchen.
Background.
Chapman was born on 16 November 1914 in Burnopfield, County Durham, England. His father was a former marine engineer who ended up as a publican in Roker. The family (Chapman was the eldest of three children) had a reputation for disobedience and Chapman received little in the way of parental guidance. Despite being bright, he regularly skipped school to go to the cinema and hang around the beach.
Aged 17 Chapman joined the Second Battalion of the Coldstream Guards where his duties included guarding the Tower of London. Chapman enjoyed the perks of the uniform, but soon became bored with his duties. After nine months in the army, when he was granted six days of leave, he absconded with a girl whom he met in Soho. After two months the army caught up with him, and he was arrested and sentenced to 84 days in a military prison (The Glasshouse) at Aldershot. On release, Chapman received a dishonourable discharge from the army.
Chapman returned to Soho and spent some time working casual jobs, from barman to film extra, but his lifestyle outstripped his earnings – gambling debts and a taste for fine alcohol soon left him broke. He slipped into petty crime, fraud and petty theft and, after several run-ins with the law, finally received his first civilian prison sentence, two months in Wormwood Scrubs for forging a cheque. He became a safecracker with London West End gangs, spending several stretches in jail for these crimes. The gangs utilised gelignite to gain entry to safes, leading Chapman and his associates to be known as the "Jelly Gang". One of Chapman's "Jelly Gang" crimes was carried out with the help of James Wells Hunt, whom Chapman met during a stint in prison. The execution of the crime involved Chapman disguising himself as a member of the Metropolitan Water Board in order to gain access to a house in Edgware Road, from which he made his way into the shop next door by smashing through the wall. He then extracted the safe which was transported to Hunt's Garage at 39 St Lukes Mews where it had its door removed using gelignite.
He had affairs with a number of women on the fringes of London high society and then allegedly blackmailed them with photographs taken by an accomplice.
Well along into his criminal career he was arrested in Scotland and charged with blowing up the safe of the headquarters of the Edinburgh Co-operative Society. Let out on bail, he fled to Jersey in the Channel Islands where he attempted unsuccessfully to continue his crooked ways.
Chapman had been dining with his lover and future fiancée Betty Farmer at the Hotel de la Plage immediately before his arrest and made a spectacular exit through the dining room window (which was shut at the time) when he saw undercover police coming to arrest him for crimes on the mainland. It was later that same night, unbelievably, that he committed the slapdash burglary for which he had to immediately begin serving two years in a Jersey prison. This proved to be an ironic twist of fate which ultimately spared him at least 14 more years' imprisonment in a mainland prison afterwards.
Second World War.
Chapman was still in prison when the Channel Islands were invaded by the Germans. While incarcerated he met Anthony Faramus. Following a letter in German which they concocted to get off the Island, they were transferred to Fort de Romainville in Paris. There, Chapman confirmed his willingness to act as a German spy. Under the direction of Captain Stephan von Gröning, head of the Abwehr in Nantes, he was trained in explosives, radio communications, parachute jumping and other subjects in France at La Bretonnière, near Nantes and dispatched to England to commit acts of sabotage.
On 16 December 1942, Chapman was flown to England in a Focke-Wulf bomber, converted for parachuting, from Le Bourget airfield. He was equipped with wireless, pistol, cyanide capsule and £1,000 and, amongst other missions, was tasked with sabotaging the de Havilland aircraft factory at Hatfield. After an uncomfortable flight, during which he suffered a nosebleed due to poorly tightened oxygen mask, Chapman became stuck in the hatch as he tried to leave the aircraft. Finally detaching himself, he landed some distance from the target location of Mundford, Norfolk, near the village of Littleport, Cambridgeshire.
The British secret services had been aware of Chapman's existence for some time, via Ultra (decrypted German messages), and would know his date of departure. Section B1A, the MI5-backed department tasked with capturing enemy agents and turning them into double agents, had discussed the best method of capturing Chapman without revealing Ultra. In the end, Operation Nightcap was envisioned. Rather than conduct a full scale manhunt, planes from RAF Fighter Command would trail Chapman's aircraft to identify his landing site (from one of three possible options). Local police would then be alerted, with instructions to conduct a search under the guise of looking for a deserter. In any case, Chapman surrendered immediately to the local police and offered his services to MI5. He was interrogated at Latchmere House in southwest London, better known as Camp 020. MI5 decided to use him as a double agent against the Germans and assigned Ronnie Reed as his case officer. (Reed had been invited to join MI5 in 1940 and remained until his retirement in 1976.)
Faked sabotage of de Havilland factory.
During the night of 29–30 January 1943, Chapman with MI5 officers faked a sabotage attack on his target, the de Havilland aircraft factory in Hatfield, Hertfordshire, where the Mosquito was being manufactured. German reconnaissance aircraft photographed the site and the faked damage by Jasper Maskelyne convinced Chapman's German controllers that the attack had been successful.
Following the de Havilland subterfuge, B1A began preparations for Chapman's return to his German handlers. Radio messages were sent to the Abwehr requesting extraction by boat or submarine, and Chapman was set to work learning a cover story ready for the inevitable interrogations. However, the response from the Abwehr was lukewarm. They refused to send a U-Boat and told Chapman to return via Lisbon, Portugal. This was not a simple method, as he had no valid reason to travel to the neutral port. Reed, and other members of B1A, believed this demonstrated the Germans' reluctance to pay Chapman the £15,000 he had been promised.
In the meantime Chapman was subjected to fake interrogation at Camp 020, to make sure his story held up. Reed told him to stick as close to the truth as possible, to help make the lies more realistic, and he was coached in speaking slowly to cover any hesitations. Stephens was impressed with how well Chapman responded to questioning.
Portugal and Operation Damp Squib.
Unlike the Germans, MI5 were eager for Chapman to return, in the hope that, as a trusted asset, he could pick up significant information about the enemy. He was tasked with memorising a list of questions the Allies wanted answers to. The list was carefully constructed so that, should Chapman be broken, its content would not show German intelligence the gaps in Allied knowledge.
To get Chapman to Lisbon it was decided he would join the crew of a merchant ship, and would jump ship when it docked in Portugal. A fake identity, Hugh Anson, was constructed and the relevant paperwork obtained before Chapman joined the crew of "The City of Lancaster", sailing out of Liverpool. On making contact with Germans at the Lisbon embassy, he suggested an attempt at blowing up the ship with a bomb disguised as a lump of coal to be placed in the coal bunker. This was in response to a request from Britain's anti-sabotage section that he obtain examples of German explosive devices. He was given two bombs which however he handed to the ship's captain. The Germans did not notice the ship was not damaged on the voyage home, but to avoid the Germans' doubting Chapman's commitment, the British staged a conspicuous investigation of the ship when it returned to Britain ensuring gossip would make its way back to the Germans.
Chapman was sent to occupied Norway to teach at a German spy school in Oslo, Norway. After a debriefing by von Grunen, Chapman was awarded the Iron Cross for his work in apparently damaging the de Havilland works and the "City of Lancaster", making him the first Englishman to receive such an award since the Franco-Prussian War of 1870–71. However, Nicholas Booth suggests that as the Iron Cross was only ever given to military personnel, Chapman's "Iron Cross" may instead have been a War Merit Cross 2nd Class, or "Kriegsverdienstkreuz". Chapman was inducted into the German Army as an oberleutnant or first lieutenant. Chapman was also rewarded with 110,000 Reichsmarks and his own yacht. An MI5 officer wrote in an assessment "the Germans came to love Chapman ... but although he went cynically through all the forms, he did not reciprocate. Chapman loved himself, loved adventure, and loved his country, probably in that order". While in Oslo he also secretly photographed the German agents who stayed at his safe house.
Return to London.
After Operation Overlord he was sent back to Britain to report on the accuracy of the V-1 weapon. Here he consistently reported to the Germans that the bombs were hitting their central London target when in fact they were undershooting. Perhaps as a result of this disinformation, the Germans never corrected their aim, with the end result that most bombs landed in the South London suburbs or the Kent countryside, doing far less damage than they otherwise might have done. During this period he was also involved in doping of dogs in greyhound racing and was associating with criminal elements in the London's West End night clubs. He was also indiscreet about the sources of his income and so MI5, being unable to control him, dismissed him on 2 November 1944. Chapman was given a £6,000 payment from MI5 and was allowed to keep £1,000 of the money the Germans had given him. He was granted a pardon for his prewar activities and was reported by MI5 to have been living "in fashionable places in London always in the company of beautiful women of apparent culture".
Love life.
Chapman had two fiancées at the same time, each in opposite war zones. He was still betrothed to Freda Stevenson in England when he met Dagmar Lahlum in Norway. Stevenson was being financially assisted through MI5, and Lahlum was being treated by von Gröning. During Chapman's stay in Norway he revealed to Dagmar that he was a British agent, but fortunately Dagmar was linked to the Norwegian resistance force. She was thrilled to know that her lover wasn't a German officer, and they worked together to gather German information.
He abandoned both women after the war and instead married his former prewar lover Betty Farmer whom he had left in a hurry at the Hotel de la Plage in 1938. He and Farmer later had a daughter Suzanne in 1954. He had told Dagmar at the time that he was a British agent. However, Dagmar served a six-month prison sentence for consorting with an apparently German officer: thinking that Chapman was dead, she was unable to prove that he was a British agent. They met again briefly in 1994. Chapman died before he was able to redeem her name.
After the war.
Chapman had his wartime memoirs serialised in France to earn money, but he was charged under the Official Secrets Act and fined £50. A few years later, when they were due to be published in the "News of the World" the whole issue was pulped. However his book "The Eddie Chapman Story" was eventually published in 1953.
MI5 expressed some apprehension that Chapman might take up crime again when his money ran out and if caught would plead for leniency because of his highly secret wartime service. He did get into trouble with the police for various crimes including smuggling in North Africa and more than once had a character reference from former intelligence officers who confirmed his great contribution to the war effort.
Chapman ghost-wrote the autobiography of Eric Pleasants, a British citizen who joined the Germans and served in the British Free Corps of the Waffen-SS during the war. Chapman claimed to have met Pleasants while he was imprisoned in Jersey. "I Killed to Live – The Story of Eric Pleasants as told to Eddie Chapman" was published in 1957.
In 1967 Chapman lived in Italy and went into business as an antiquarian.
Chapman and his wife later set up a health farm (Shenley Lodge, Shenley, Herts) and owned a castle in Ireland. After the war Chapman remained friends with Baron Stefan von Grunen, his Abwehr handler (also known as von Gröning, wartime alias Doctor Graumann), who by then had fallen on hard times. Von Grunen later attended the wedding of Eddie Chapman's daughter.
Chapman died on 11 December 1997 from heart failure.
In popular culture.
In the 1950s producer Ted Banborough announced plans to make a film about Chapman starring Michael Rennie or Stanley Baker but this did not go ahead.
The 1966 film "Triple Cross" was based on the biography "The Real Eddie Chapman Story" co-written by Chapman and Frank Owen. The film was directed by Terence Young who had known Chapman before the war. Chapman's character was played by Christopher Plummer. The film was only loosely based on reality and Chapman was disappointed with it. In his autobiography, Plummer said that Chapman was to have been a technical adviser on the film but the French authorities would not allow him in the country because he was still wanted over an alleged plot to kidnap the Sultan of Morocco. The film gave him a celebrity status for a while and this allowed him to be an occasional crime writer for "The Sunday Telegraph".
In 1967 the French TV (ORTF) produced a short film featuring a brief Chapman interview (in fluent French). Journalist: Pierre Dumayet, "Eddie Chapman, ex-gangster, ex-espion." Serie: Cinq colonnes à la une. Producer.: JP Gallo. Broadcast 6 January 1967, 19'29".
In May 1989 Chapman made an extended appearance on the Channel 4 discussion programme "After Dark", alongside Tony Benn, Lord Dacre, James Rusbridger, Miles Copeland and others.
In 2011, BBC Two broadcast "Double Agent: The Eddie Chapman Story", a documentary presented by Ben Macintyre based on his book. The book was broadcast in an abridged reading in 2012.
Playtone has acquired the film rights for Ben Macintyre's book, with Mark Bomback as writer and Mike Newell set to direct.

</doc>
<doc id="33102" url="http://en.wikipedia.org/wiki?curid=33102" title="Battle of Kursk">
Battle of Kursk

The Battle of Kursk was a World War II engagement between German and Soviet forces on the Eastern Front near Kursk (450 km south-west of Moscow) in the Soviet Union during July and August 1943. The German offensive was code-named Operation Citadel (German: "Unternehmen Zitadelle") and led to one of the largest armoured clashes in history, the Battle of Prokhorovka. The German offensive was countered by two Soviet counter-offensives, Operation Polkovodets Rumyantsev (Russian: Полководец Румянцев) and Operation Kutuzov (Russian: Кутузов). For the Germans, the battle represented the final strategic offensive they were able to mount in the east. For the Soviets, the victory gave the Red Army the strategic initiative for the rest of the war.
The Germans hoped to weaken the Soviet offensive potential for the summer of 1943 by cutting off a large number of forces, that they anticipated would be in the Kursk salient assembling for an offensive.
The Kursk salient or bulge was 250 km long from north to south and 160 km from east to west. By eliminating the Kursk salient, the Germans would also shorten their lines of defence, taking the strain off their overstretched forces. The plan envisioned an envelopment by a pair of pincers breaking through the northern and southern flanks of the salient. Hitler thought that a victory here would reassert German strength and improve his prestige with allies, who were considering withdrawing from the war. It was also hoped that large numbers of Soviet prisoners would be captured to be used as slave labour in the German armaments industry.
The Soviets had intelligence of the German intentions, provided in part by the British intelligence service and Tunny intercepts. Aware months in advance, that the attack would fall on the neck of the Kursk salient, the Soviets built a defence in depth designed to wear down the German panzer spearheads. The Germans delayed the offensive, while they tried to build up their forces and waited for new weapons, mainly the new Panther tank but also larger numbers of the Tiger heavy tank. This gave the Red Army time to construct a series of deep defensive lines. The defensive preparations included minefields, fortifications, registered artillery fire zones and anti-tank strong points, which extended approximately 300 km in depth. Soviet mobile formations were moved out of the salient and a large reserve force was formed for strategic counter-offensives.
The Battle of Kursk was the first time a German strategic offensive had been halted before it could break through enemy defences and penetrate to its strategic depths. The maximum depth of the Nazi advance was 8 – in the north and 35 km in the south. Though the Soviet Army had succeeded in winter offensives previously, their counter-offensives following the German attack at Kursk, were their first successful strategic summer offensives of the war.
Background.
As the Battle of Stalingrad slowly ground to its conclusion, the Soviet army moved to a general offensive in the south, pressuring the depleted German forces. Hitler's belief that his own iron will would be the deciding factor in the conflict resulted in German forces being tied down in a rigid defence that did not permit them the liberty to move. Since December, Field Marshall Erich von Manstein had been strongly requesting "unrestricted operational freedom" to allow him to use the forces in a fluid manner, a request which put him at odds with Hitler. Time and again Hitler's policy of holding at all costs resulted in forces being left until their position was untenable, resulting in their being cut off and destroyed. By January 1943, a 160 to wide gap had been created between Army Group B and Army Group Don. The advancing Soviet armies threatened to cut off all German forces south of the Don River, including Army Group A operating in the Caucasus. Meanwhile, Army Group Centre was under significant pressure as well. Kursk fell to the Soviets on 8 February, and Rostov on the 14th. The Soviet Bryansk and Western Fronts, along with the newly created Central Front, prepared for an offensive which envisioned an encirclement of Army Group Centre extending between Bryansk and Smolensk.
On 12 February, the remaining German forces were reorganized. To the south, Army Group Don was renamed Army Group South and its units placed under the command of Field Marshal Erich von Manstein. Directly to the north, Army Group B was dissolved, and its forces and areas of responsibility were divided between Army Group South and Army Group Centre. With this restructuring von Manstein inherited responsibility for the massive breach in the German lines. January 1943 saw the arrival of the II SS Panzer Corps from France, refitted and up to near full strength. Other armoured units from the 1st Panzer Army, part of Army Group A, which had slipped out of the trap of the Caucasus, further strengthened von Manstein's hand.
By February the Wehrmacht was in danger of a general collapse. On 18 February, Adolf Hitler arrived at Army Group South headquarters, at Zaporizhia, hours before Kharkov was liberated by the Soviets. Hitler's distrust of the officers of the General Staff, and of von Manstein in particular, put him at odds with the high command of the Wehrmacht. Though Hitler desired to relieve von Manstein and saddle him with the blame for Stalingrad and subsequent battles, he soon realized he could ill afford to lose the man largely regarded as the most capable commander in the army. Instead, Hitler grudgingly gave him the freedom he had requested. Once given freedom of action, von Manstein explained how he intended to concentrate his forces and make a series of counterstrokes to exploit the overstretched Soviets, with the goal of destroying the Red Army spearheads while retaking Kharkov and Kursk. The Third Battle of Kharkov commenced on 19 February, spearheaded by the three SS divisions of the II SS Panzer Corps. Von Manstein's offensive cut off the Soviet spearheads, and then encircled and destroyed the main force. The Germans retook Kharkov on 15 March and Belgorod on 18 March. The German offensive wrested the initiative from the Soviets. The 25 February offensive by the Central Front against Army Group Centre had to be abandoned by 7 March so that forces could be redeployed south to counter the threat of the advancing Germans. Operations ceased by the end of March due to the onset of the spring rasputitsa and the exhaustion of the Germans. The exhaustion was mirrored in the Red Army. The counteroffensive left a salient extending into the German area of control, centered on the city of Kursk.
German plans and preparation.
Heavy losses sustained by the German military in the winters of 1941/42 and 1942/43 resulted in a marked shortage in artillery and infantry. Units along the Eastern Front were 470,000 men below their establishment. For the Germans to undertake an offensive in 1943, the burden would have to be carried by the panzer arm. In view of the exposed position of Army Group South, von Manstein proposed that his forces should take the strategic defensive. He anticipated that a Soviet offensive would attempt to cut off and destroy Army Group South by a move across the Donets River toward the Dnieper. In February, he proposed waiting for this offensive to develop and then deliver a series of counterattacks into the exposed Soviet flanks. Hitler, concerned about potential political implications of taking a defensive stance and preoccupied with the economic potential of holding the Donbass, rejected this plan. On 10 March, von Manstein presented Hitler with an alternative plan whereby the German forces pinched off the Kursk salient with an offensive commencing as soon as the spring rasputitsa had subsided. On 13 March, Hitler signed Operational Order No. 5, which outlined the intended launch of several offensives, including one against the Kursk salient. As the last Soviet resistance in Kharkov was ended, von Manstein attempted to persuade Günther von Kluge of Army Group Centre to immediately attack the Central Front, which was defending the northern face of the salient, to keep the Soviets off balance and maintain the momentum. Von Kluge refused, noting that his forces were too weak to launch such an attack. Von Manstein's SS Panzer Corps pushed on northwards and took Belgorod on 18 March, but further advances were blocked by Soviet forces that had been shifted down from the Central Front to an area north of Belgorod. By mid-April, amid poor weather and with the German forces exhausted and in need of refitting, the offensives of Operational Order No. 5 could not be undertaken.
Hitler's Operational Order No. 6, issued 15 April, called for the Kursk offensive operation to begin on 3 May or shortly thereafter. Kurt Zeitzler, the OKH Chief of Staff, provided the logistical planning Hitler's Operational Order No. 6, issued 15 April, called for the Kursk offensive operation to begin on 3 May or shortly thereafter. Kurt Zeitzler, the OKH Chief of Staff, provided the logistical planning for the operation. Zeitzler was a resourceful organizer of strategic moves, and had an exceptional capacity to solve movement problems. The plan was codenamed Operation Citadel. For the plan to succeed it was deemed essential to attack before the Soviets had a chance to prepare extensive defenses or launch an offensive of their own. According to some military historians the operation envisioned a blitzkrieg attack. Other military historians and the German participants who wrote about it after the war, including von Manstein, make no mention of blitzkrieg in their characterization of the operation. Historian Pier Battistelli asserts that the operational planning marked a change in German offensive thinking away from blitzkrieg. The plan for the operation consisted of a double envelopment that was directed at Kursk to surround the majority of the Soviet defenders and seal off the salient. Von Kluge's Army Group Centre was to provide General Walter Model's 9th Army to form the northern pincer. It would cut through the northern face of the salient, driving south to the hills east of Kursk, securing the rail line from Soviet attack. Von Manstein's Army Group South would commit the 4th Panzer Army, under Hermann Hoth, and Army Detachment "Kempf", under Werner Kempf, to penetrate the southern face of the salient. This force would drive north to meet 9th Army east of Kursk. Von Mainstein's main attack was to be delivered by Hoth's 4th Panzer Army, spearheaded by the II SS Panzer Corps under the command of Paul Hausser. The XLVIII Panzer Corps, commanded by Otto von Knobelsdorff, would advance on the left flank of the Waffen SS troops while Army Detachment "Kempf" would advance on the right. The western face of the salient was to be controlled by the 2nd Army, under the command of Walter Weiss.
On 27 April, Model met with Hitler to review the reconnaissance information gathered and to express his concerns. He argued that the longer the preparation phase continued, the less the operation could be justified. He recommended Citadel be completely abandoned, allowing the army to await and defeat the coming Soviet offensive. Failing that, he believed that Citadel should be radically revised. Though in mid-April von Manstein had considered the Citadel offensive profitable, by May he shared Model's misgivings. He asserted that the best course of action would be for the German forces to take the strategic defensive, ceding ground to allow the anticipated Soviet forces to extend themselves and allow the German panzer forces to counterattack in the type of fluid mobile battle that they excelled at. Convinced that the Red Army would deliver its main effort against Army Group South, he proposed to keep the left wing of the army group strong while moving the right wing back in stages to the Dnieper River, followed by a counterattack against the flank of the Red Army advance. The counteroffensive would continue until the Sea of Azov was reached and the Soviet forces were cut off. This idea was rejected by Hitler, as he did not want to give up so much terrain, even temporarily. Zeitzler was profoundly concerned with the delay till the second week of June, but he was still in support of the offensive.
In early May, Hitler called together his senior officers and advisors to Munich for a meeting. Hitler spoke for about 45 minutes on the current situation and the plans for the offensive. Model then spoke, and produced reconnaissance photos revealing some of the extensive preparations the Soviets had made in preparation for the attack. A number of options were put forth for comment: going on the offensive immediately with the forces at hand, delaying the offensive further to await the arrival of new and better tanks, radically revising the operation or cancelling it all together. Von Manstein spoke against the offensive, but not forcefully. Albert Speer spoke of the difficulties of rebuilding the armoured formations and the limitations of German industry to replace losses. Guderian argued strongly against the operation, stating "the attack was pointless." The conference ended without Hitler coming to a decision, but Citadel was not aborted. Three days later OKW (Oberkommando der Wehrmacht), Hitler's conduit for controlling the military, postponed the launch date for Citadel to 12 June.
Following this meeting, Guderian continued to voice his concerns over an operation that would likely degrade the panzer forces that he had been attempting to rebuild. He believed that the offensive, as planned, was a misuse of the panzer forces, as it violated two of the three tenets he had laid out as the essential elements for a successful panzer attack. In Guderian's opinion, the limited German resources in men and materiel should be conserved as they would be needed for the pending defence of Western Europe. In a meeting with Hitler, on 10 May, he asked: "Is it really necessary to attack Kursk, and indeed in the east this year at all? Do you think anyone even knows where Kursk is? The entire world doesn't care if we capture Kursk or not. What is the reason that is forcing us to attack this year on Kursk, or even more, on the Eastern Front?" Hitler replied: "I know. The thought of it turns my stomach." Guderian concluded, "In that case your reaction to the problem is the correct one. Leave it alone."
Despite reservations, Hitler remained committed to the offensive. He and OKW, early in the preparatory phase, were hopeful that the offensive would revitalize German strategic fortunes in the east. As the challenges offered by Citadel increased, he focused more and more on the expected new weapons that he believed were the key to victory: principally the Panther tank, but also the Elefant tank destroyer and greater numbers of the Tiger heavy tank. He postponed the operation, to await their arrival. Receiving reports of powerful Soviet concentrations behind the Kursk area, Hitler delayed the offensive again to allow for more equipment to reach the front. With pessimism for Citadel increasing with each delay, in June, Alfred Jodl, the Chief of Staff at OKW, instructed the armed forces propaganda office to portray the operation as a limited counteroffensive when the offensive finally did get underway. Due to concerns of an Allied landing in the south of France or Italy and delays in deliveries of the new tanks, Hitler postponed again, this time to 20 June. On 17–18 June, following a discussion in which the OKW Operations Staff suggested abandoning the offensive, Hitler further postponed the operation until 3 July. Finally on 1 July, Hitler announced that 5 July would be the launch date of the offensive.
As the Soviets waited and the Germans attempted to build up their forces, a three-month quiet period descended upon the Eastern Front. The Germans used this period for specialized training of their assault troops. All units did unit training and combat rehearsals. The Waffen-SS had built a full-scale duplicate Soviet strong point that was used to practice the techniques for neutralizing such positions. During the lull, the panzer divisions continued to try to replace equipment shortfalls and get up to strength. The total German forces to be used in the offensive included 12 panzer divisions and 5 panzergrenadier divisions, four of which could boast tank strengths greater than their neighboring panzer divisions. However, the force was markedly deficient in infantry divisions, which were essential to hold ground and secure the flanks. By the time the Germans initiated the offensive, their force amounted to around 777,000 men, 2,451 tanks and assault guns (70 per cent of the German armour on the Eastern Front), and 7,417 guns and mortars.
Soviet plans and preparation.
In 1943, an offensive by the Soviet Central, Bryansk, and Western Fronts against Army Group Centre was abandoned shortly after it began in early March, when the southern flank of the Central Front was threatened by Army Group South. Soviet intelligence received information about German troop concentrations spotted at Orel and Kharkov, as well as details of an intended German offensive in the Kursk sector through the Lucy spy ring in Switzerland. The Soviets verified the intelligence via their spy in Britain, John Cairncross at the Government Code and Cypher School at Bletchley Park, who clandestinely forwarded raw decrypts directly to Moscow. Anastas Mikoyan wrote that, on 27 March 1943, he was notified by Joseph Stalin about a possible German attack in the Kursk sector. Stalin and some senior officers were eager to strike first once the rasputitsa ended, but a number of key officers, including Deputy Supreme Commander Georgiy Zhukov, recommended a strategic defensive before going on the offensive. In a letter to "Stavka" and Stalin, on 8 April, Zhukov wrote:
In the first phase the enemy, collecting their best forces—including 13–15 tank divisions and with the support of a large number of aircraft—will strike Kursk with their Kromskom-Orel grouping from the north-east and their Belgorod-Kharkov grouping from the south-east... I consider it inadvisable for our forces to go over to an offensive in the near future in order to forestall the enemy. It would be better to make the enemy exhaust himself against our defences, and knock out his tanks and then, bringing up fresh reserves, to go over to the general offensive which would finally finish off his main force.
Stalin consulted with his front-line commanders and senior officers of the General Staff, from 12 to 15 April 1943. In the end he and "Stavka" agreed that Kursk was the likely German target. Stalin believed the decision to defend would give the Germans the initiative, but Zhukov countered that the Germans would be drawn into a trap where their armoured power would be destroyed, thus creating the conditions for a major Soviet offensive. They decided to meet the enemy attack by preparing defensive positions to wear out the German groupings, before launching their own offensive. Preparation of defences and fortifications began by the end of April, and continued until the German attack in early July. The two-month delay between the German decision to attack the Kursk salient and its implementation allowed the Red Army ample time to thoroughly prepare.
The Voronezh Front, commanded by Nikolai Vatutin, was tasked with defending the southern face of the salient. The Central Front, commanded by Konstantin Rokossovsky, defended the northern face. Waiting in reserve was the Steppe Front, commanded by Ivan Konev. In February 1943, the Central Front had been reconstructed from the Don Front, which had been part of the northern pincer of Operation Uranus and had been responsible for the destruction of the 6th Army at Stalingrad.
The Central and Voronezh Fronts each constructed three main defensive belts in their sectors, with each subdivided into several zones of fortification. The Soviets availed themselves of the labour of over 300,000 civilians. Fortifying each echelon was an interconnected web of minefields, barbed-wire fences, anti-tank ditches, deep entrenchments for infantry, anti-tank obstacles, dug-in armoured vehicles, and machine gun bunkers. Behind the three main defensive belts were three more belts prepared as fallback positions; the first was not fully occupied or heavily fortified, and the last two, though sufficiently fortified, were mostly not occupied. The combined depth of the three main defensive zones was about 40 km. The six defensive belts on either side of Kursk were 130 - deep. If the Germans managed to break through these defences they would still be confronted by additional defensive belts to the east, manned by the Steppe Front. These brought the total depth of the defences to nearly 300 km.
Red Army combat engineers laid 503,663 anti-tank mines and 439,348 anti-personnel mines, with the highest concentration in the first main defensive belt. More than 4800 km of trenches were dug, laid out in criss-cross pattern for ease of movement. The minefields at Kursk achieved densities of 1,700 anti-personnel and 1,500 anti-tank mines per kilometre, about four times the density used in the defence of Moscow. For example, the 6th Guards Army, of the Voronezh Front, was spread out over nearly 64 km of front and was protected by 69,688 anti-tank and 64,430 anti-personnel mines in its first defensive belt with a further 20,200 anti-tank and 9,097 anti-personnel mines in its second defensive belt. Furthermore, mobile obstacle detachments were tasked with laying more mines directly in the path of advancing armoured formations. These units, consisting of two platoons of combat engineers with mines at division level and one company of combat engineers normally equipped with 500–700 mines at corps level, functioned as anti-tank reserves at every level of command.
In his letter of 8 April, Zhukov warned that the Germans would attack the salient with a strong armoured force:
We can expect the enemy to put [the] greatest reliance in this year's offensive operations on his tank divisions and air force, since his infantry appears to be far less prepared for offensive operations than last year ... In view of this threat, we should strengthen the anti-tank defences of the Central and Voronezh fronts, and assemble as soon as possible.
Nearly all artillery, including howitzers, guns, anti-aircraft and rockets, were tasked with anti-tank defence. Dug-in tanks and self-propelled guns further strengthened the anti-tank defences. Anti-tank forces were incorporated into every level of command, mostly as anti-tank strong points with the majority concentrated on likely attack routes and the remainder amply spread out elsewhere. Each anti-tank strong point typically consisted of four to six anti-tank guns, six to nine anti-tank rifles, and five to seven heavy and light machine guns. They were supported by mobile obstacle detachments as well as infantry with automatic weapons. Independent tank and self-propelled gun brigades and regiments were tasked with cooperating with the infantry during counterattacks.
Soviet preparations included increased activity of partisans, who attacked German communications and supply lines. The attacks were mostly behind Army Group North and Army Group Centre. During June 1943, partisans operating in the occupied area behind Army Group Centre destroyed 298 locomotives, 1,222 rail wagons, and 44 bridges, and in the Kursk sector there were 1,092 partisan attacks against railways. These attacks delayed the build-up of German supplies and equipment, and required German troops to be diverted to suppress the partisans, delaying their training for the offensive. Many of these attacks were coordinated through the Central Partisan Headquarters. In June Soviet Air Forces flew over 800 sorties at night to resupply the partisan groups operating behind Army Group Center. The VVS also provided communication and sometimes even daylight air support for major partisan undertakings.
Special training was provided to the infantry manning the defences to help them overcome the tank phobia that had been evident since the start of the German invasion. Soldiers were packed into trenches and tanks were driven overhead until all signs of fear were gone. The soldiers were also promised financial rewards for each tank destroyed, with the People's Commisariat of Defense providing 1,000 rubles for destroyed tanks. In combat, the soldiers would spring up in the midst of the attacking infantry to separate them from the spearheading armoured vehicles. The separated armoured vehicles could then be disabled or destroyed at point-blank range. These types of attacks were mostly effective against the Ferdinand tank destroyers, which lacked machine guns as secondary armament. If the armoured vehicles could be separated from their supporting infantry they became vulnerable to infantry armed with anti-tank rifles, demolition charges and Molotov cocktails.
The Soviets employed "maskirovka" (deception techniques) to mask defensive positions and troop dispositions and to conceal the movement of men and materiel. These included camouflaging gun emplacements, constructing dummy airfields and depots, generating false radio traffic, and spreading rumours among the Soviet frontline troops and the civilian population in the German-held areas. Movement of forces and supplies to and from the salient was carried out at night only. Ammunition caches were carefully concealed to blend in with the landscape. Radio transmission was restricted and fires were forbidden. Command posts were hidden and motor transport in and around them was forbidden.
According to a Soviet General Staff report, 29 of the 35 major Luftwaffe raids on Soviet airfields in the Kursk sector, during June 1943, were against dummy airfields. The Soviet deception efforts were so successful that German estimates issued in mid-June placed the total Soviet armoured strength at 1,500 tanks. The result was not only a vast underestimation of Soviet strength, but a misperception of Soviet strategic intentions. In contrast, Soviet aviation was able to destroy "more than 500 [Luftwaffe] aircraft on the ground." 
The main tank of the Soviet tank arm was the T-34, on which the Red Army attempted to concentrate production. The Soviet tank arm also contained large numbers of the T-70 light tank. For example, the 5th Guards Tank Army roughly contained 270 T-70s and 500 T-34s. In the salient itself, the Soviets had assembled a large number of lend-lease tanks. These included U.S.-manufactured M3 Lees and British-built Churchills, Matildas and Valentines. However, the T-34 made up the bulk of the Soviet armour. Without including the deeper reserves organised under the Steppe Front, the Soviets had massed about 1,300,000 men, 3,600 tanks, 20,000 artillery pieces, and 2,792 aircraft to defend the salient. This amounted to 26 per cent of the total manpower of the Red Army, 26 per cent of its mortars and artillery, 35 per cent of its aircraft, and 46 per cent of its tanks.
Contest for air superiority and air support of the ground forces.
Both the Luftwaffe and the V.V.S. (the Voyenno-Vozdushnye Sily, or "Military Air Forces") were air forces designed with their primary mission being to support their respective ground forces. Though the V.V.S. was always much larger than the Luftwaffe, in the early part of the campaign in the Soviet Union the Luftwaffe had achieved complete air superiority and inflicted huge losses upon the Soviet Air Force. The Luftwaffe's extensive air support to the German ground forces was checked only when the advance pushed beyond the range of their most forward airfields. Resupply by air of forward panzer units had been a Luftwaffe role since the start of the war, but the demand placed upon the Luftwaffe to resupply large isolated formations during the severe winter of 1941–42 and over Stalingrad the following winter cost the Luftwaffe a great deal in equipment and pilots. These losses could not be easily replaced. The roughly 2,000 Luftwaffe aircraft represented "the bulk of what was left on the eastern front after so many squadrons had been sent back to defend Germany from the Allied air forces"; Germany's air strength in the Soviet Union had been seriously depleted.
By 1943, the Luftwaffe was still able to achieve local air superiority, but its strength was clearly weakening. The Luftwaffe command understood that for success to be found in Operation Citadel their support would be crucial, but their ability to project force was hampered by problems with supply shortfalls. Partisan activity, particularly behind Army Group Center, slowed the rate of re-supply and cut short the Luftwaffe's ability to build up essential stockpiles of petrol, oil, and lubricants. They were unable to stockpile reserves of aircraft and engines, meaning that they would be unable to replace damaged aircraft over the course of the operation. Fuel was the most significant limiting factor. To help build up supplies for the support of Citadel, the Luftwaffe greatly curtailed its operations during the last week of June. Despite this husbanding of resources, the Luftwaffe did not have the resources to sustain an intensive air effort for more than a few days.
The changing strengths of the two opponents is underscored by operational changes made by the Luftwaffe at Kursk. Air operations in previous offensive campaigns were initiated with Luftwaffe raids conducted against opposing airfields to help achieve air superiority. By this point in the war, Soviet equipment reserves were extensive. The Luftwaffe commanders realized whatever aircraft they could destroy on the ground would be easily replaced by the Soviets within days, making such raids futile. For the Kursk battle, these missions were abandoned. In previous campaigns, medium bombers – flying from well behind the frontline – had interdicted the arrival of Soviet reinforcements. However, this kind of mission was rarely attempted during Citadel. Rather, the Luftwaffe confined its operations to the direct support of the ground forces. The Luftwaffe continued to make use of the Junkers Ju 87G "Stuka". A new development to this aircraft was the "Bordkanone" 3,7 cm calibre cannon, one of which could be slung under each wing of the "Stuka" in a gun pod. Half of the "Stuka" groups assigned to support Citadel were equipped with such weapons. The air groups were also buttressed by the recent arrival of the Henschel Hs 129, with its 30 mm MK 103 cannon, and the ground attack ("jabo") version of the Focke-Wulf Fw 190.
In the months preceding the battle Luftflotte Six behind Army Group Center noted marked increase in the strength of the opposing VVS formations. These Soviet air groups showed indications of better training, improved equipment and increased aggressiveness. The introduction of the Yakovlev Yak-9 and Lavochkin La-5 fighters gave the Soviet pilots near parity in equipment with the Luftwaffe. Furthermore, large numbers of ground attack aircraft (such as the Ilyushin Il-2 "Shturmovik" and the Pe-2) were available as well. In addition to Soviet designs, the Red Air Force contained large quantities of aircraft supplied by lend-lease. Huge stockpiles of supplies and ample reserves of replacement aircraft meant the Soviets would be able to conduct an extended campaign without slackening in the intensity of their effort.
Opposing forces.
Germans.
For their attack, the Germans used three armies along with a large proportion of their total tank strength on the Eastern Front. The 9th Army, of Army Group Center and based north of the bulge, contained 335,000 men (223,000 combat soldiers). In the south, the 4th Panzer Army and Army Detachment "Kempf", of Army Group South, had 223,907 men (149,271 combat soldiers) and 100,000 men (66,000 combat soldiers) respectively. In total, the three armies had a total strength of 778,907 men, with 438,271 being combat soldiers. Army Group South was equipped with more armoured vehicles, infantry and artillery than the 9th Army. The 4th Panzer Army and Army Detachment "Kempf" had 1,377 tanks and assault guns, while the 9th Army possessed 988 tanks and assault guns.
The two new Panther battalions (the 51st and 52nd, and 200 tanks strong), which the offensive had been delayed for, were attached to the Großdeutschland Division in the XLVIII Panzer Corps of Army Group South. Arriving just prior to the launch of the offensive, the two units had little time to perform reconnaissance or to orient themselves to the terrain they found themselves in. This was a breach of the methods of the panzerwaffe, considered essential for the successful use of armour. Though led by experienced panzer commanders, many of the tank crews were new recruits and had little time to become familiar with their new tanks and their temperamental transmissions, let alone train together to function as a unit. The two battalions came direct from the training ground and lacked combat experience. In addition, the requirement to maintain radio silence until the start of the attack meant that the Panther units would have little training in radio procedures. The new Panthers were still experiencing problems with their transmissions, and proved mechanically unreliable. By the morning of 5 July, the units had lost 16 Panthers due to mechanical breakdown, leaving only 184 available for the launching of the offensive.
Soviets.
The Red Army used two Fronts, the equivalent of army groups, for the defence of Kursk, and created a third front behind the battle area which was held as a reserve. The Central and Voronezh Fronts fielded 12 armies, with 711,575 men (510,983 combat soldiers) and 625,591 men (446,236 combat soldiers) respectively. In reserve, the Steppe Front had an additional 573,195 men (449,133). Thus the total size of the Soviet force was 1,910,361 men, with 1,426,352 actual combat soldiers.
Preliminary actions.
Preliminary fighting started on the southern face of the salient on the evening of 4 July 1943, when German infantry launched attacks to seize high ground for artillery observation posts prior to the main assault. During these attacks, a number of Soviet command and observation posts along the first main belt of defence were captured. By 16:00, elements of the Panzergrenadier Division "Großdeutschland", 3rd and 11th Panzer Divisions had seized the village of Butovo and proceeded to capture Gertsovka before midnight. At around 22:30, Vatutin ordered 600 guns, mortars, and Katyusha rocket launchers, of the Voronezh Front, to bombard the forward German positions, particularly those of the II SS Panzer Corps.
To the north, at Central Front headquarters, reports of the anticipated German offensive came in. At around 02:00 5 July, Zhukov ordered his preemptive artillery bombardment to begin. The hope was to catch the German forces concentrating for the attack, but the effect of the bombardment was less than hoped for. The bombardment delayed the German formations, but failed in the goal of disrupting the German schedule or inflicting substantial losses. The Germans began their own artillery bombardment at about 05:00. This lasted 80 minutes in the northern sector and 50 minutes in the south. After the barrage, the ground forces attacked, aided by close air support provided by the Luftwaffe.
During the early morning, the Red Air Force launched a large raid against German airfields, hoping to catch the Luftwaffe on the ground. This effort failed, and the Soviets suffered considerable losses. The Soviets lost 176 aircraft in the attack (The losses of the 16th Air Army were lighter than those suffered by the 2nd Air Army.), compared to the 26 aircraft lost by the Luftwaffe. Though the Luftwaffe was able to gain and maintain air superiority over the southern portion of the battle, the control of the skies over the northern face was evenly contested throughout.
Over the course of the offensive, the Luftwaffe's chronic shortage of fuel, lubricants and spare parts began to hamper the serviceability of their aircraft and thus limited their ability to fly sorties. In addition, the need to provide ground forces with assistance, in defeating strong points and knocking out Soviet artillery positions, meant that missions could not be flown to attack Soviet airfields to help gain air superiority, giving the much more numerous Red Air Force the opportunity to have a greater presence over the battlefield. The consequences of the greater numbers of Soviet aircraft over the Luftwaffe was enhanced by the fact that by mid-1943, the Luftwaffe no longer held as great a technical superiority as it once held over its adversary.
Operation along the northern face.
Model's main attack was delivered by XLVII Panzer Corps, supported by 45 Tigers of the attached 505 Heavy Tank Battalion. Covering their left flank was XLI Panzer Corps, with an attached regiment of 83 "Ferdinand" tank destroyers. On the right flank, XLVI Panzer Corps (in name only) consisted of four infantry divisions with just nine tanks and 31 assault guns. To the left of XLI Panzer Corps was XXIII Army Corps, which consisted of a reinforced assault infantry division (the 78th) and two regular infantry divisions. While the corps contained no tanks, it did have 62 assault guns. Opposing the 9th Army was the Central Front, deployed in three main heavily fortified defensive belts.
Model had decided not to employ his armoured force at the start of the offensive in order to prevent it from being worn out while breaking the Soviet defences. Therefore his initial attack force, tasked with breaking the first line of defence was primarily infantry, working with artillery and Luftwaffe support. Once the breakthrough had been achieved, the panzer divisions would exploit and advance towards Kursk. Jan Möschen, a major in Model's staff, later commented that Model expected a breakthrough on the second day, but that his corps commanders thought it would be extremely unlikely. Given Model's tactics, even if a breakthrough did occur the briefest delay in bringing the panzer divisions up would give the Soviets time to react and plug the gap.
Following a preliminary bombardment to which the Soviets countered with two artillery bombardments, the 9th Army opened its attack at 05:30 on 5 July. Nine infantry divisions and one panzer division, with attached assault guns, heavy tanks, and tank destroyers, pushed forward. Two companies of Tiger tanks were attached to the 6th Infantry Division, and were the largest single grouping of Tigers employed that day. Facing this onslaught were the 13th and 70th Armies of the Central Front.
The 20th Panzer and 6th Infantry divisions, in close cooperation, spearheaded the advance of the XLVII Panzer Corps. Behind them the remaining two panzer divisions followed, ready to exploit any breakthrough. The heavily mined terrain and fortified positions of the 15th Rifle Division slowed the attack down. By 08:00, safe lanes had been cleared through the minefield. That morning, information from the intelligence staff of the attacking divisions, obtained via prisoner interrogation, had identified a weakness at the boundary of the 15th and 81st Rifle Divisions caused by the German preliminary bombardment. The Tigers were redeployed, and struck towards this area. The Soviets countered this move with a force of around 90 T-34s. In the resulting three-hour battle, the Soviets lost 42 tanks while the Germans lost a mere two Tigers and a further five more immobilized with track damage. While the Soviet counter-attack was defeated and the first defensive belt breached, the fighting had delayed the advancing Germans long enough for the rest of 29th Rifle Corps – behind the first line – to seal the breach and prevent a breakthrough. After a bloody engagement 10 to into the Soviet defences, the XLVII Panzer Corps attack stalled.
The German attack had been along a 45 km wide front. However, due to extensive minefields and the tenacity of the Soviet defenders, the attack had stalled. Efforts by engineers to clear paths through the minefields were hampered by Soviet fire. Goliath and Borgward IV remote-controlled engineer mine-clearing vehicles met with limited success. Of the 653rd Heavy Panzerjäger Battalion's 45 "Ferdinand"s sent into battle, all but 12 of them were immobilized by mine damage before 17:00. Most of these were later repaired and returned to service, but the recovery of these very large vehicles was difficult. During the first day, the Germans penetrated 8 km into the Soviet lines for the loss of 1,287 men killed and missing and a further 5,921 wounded.
The following day, the Central Front launched a counterattack against the German XLVI Tank Corps. The Red Army attacked with the 2nd Tank Army and the XIX Tank Corps. The Soviet counterattack was halted by the German Tiger tanks, which knocked out 69 Soviet tanks. After the encounter with the German Tigers, Rokossovsky decided to dig in most of his remaining tanks to minimize their exposure.
During the next two days, heavy fighting took place around the strong point of Ponyri (on the Orel–Kursk railway), which was one of the most heavily fortified positions in the northern sector. Both sides saw this area as a vital point. The Soviets had placed 70 anti-tank guns per kilometre in this region. The German 86th and 292nd Infantry Divisions attacked Ponyri, and captured the town after intense house-to-house fighting on 7 July. A Soviet counterattack forced the Germans to withdraw, and a series of counterattacks ensued by both sides with control of the town being exchanged several times. By the evening of 8 July, the Germans had secured most of the town. The "Ferdinand"s were called into action to take Hill 253.5 and succeeded on 9 July. This attack developed into a battle of attrition, with heavy casualties on both sides. The historian John Keegan called Ponyri "the new Douaumont", referencing the major battles that occurred around Fort Douamount during the First World War's Battle of Verdun.
Model ordered his forces to halt to reorganize. On 9 July, a meeting was held, at the headquarters of the XLVII Panzer Corps, between von Kluge and Model. To both, it had become clear that they lacked the strength to obtain a breakthrough, but von Kluge wished to maintain the pressure on the Soviets in order to aid the southern offensive.
Soviet defensive strongpoints were to be bypassed and the "schwerpunkt" was to shift to XLVI Panzer Corps. The 12th Panzer Division, thus far held in reserve, was to be committed. By this point, both the German and the Soviet commanders realised that the outcome of the battle had already been decided.
On 10 July, the attack was renewed with air support. However, the gains made by this renewed effort were small as fresh Soviet formations had arrived to repel the German attacks. The diary of the 9th Army describes the heavy fighting as a "new type of mobile attrition battle". On 12 July, the Soviets launched Operation Kutuzov: their counter-offensive upon the Orel salient. The attack threatened the flank and rear of Model's 9th Army. Two Fronts, the Bryansk Front and the Western Front, commenced the attack along the thinly held north and northeast sectors of the salient held by the 2nd Panzer Army. The Western Front assault was led by the 11th Guards Army, under Lieutenant General Hovhannes Bagramyan, and was supported by the 1st and 5th Tank Corps. The Soviet spearheads sustained heavy casualties, but pushed through and in some areas achieved significant penetrations. These penetrations threatened the German supply routes, but more importantly threatened to encircle the 9th Army and presented the chance to destroy it. With this threat, 9th Army was compelled to withdraw.
A review of the attack frontage and depth of the German penetration highlights the success of the Red Army defensive tactics. While Citadel began with a 45 km attack front, by 6 July it had been reduced to 40 km. The following day, this dropped to 15 km and on both the 8 and 9 July penetrations of only 2 km occurred. By 10 July, the Soviets had completely halted the German advance.
Operation along the southern face.
At around 04:00 on 5 July, the German attack commenced with a preliminary bombardment. Von Manstein's main attack was delivered by Hoth's 4th Panzer Army, which was organized into densely concentrated spearheads. Opposing the 4th Panzer Army was the Soviet 6th Guards Army, which was composed of the 22nd Guards Rifle Corps and 23rd Guards Rifle Corps. The Soviets had constructed three heavily fortified defensive belts to slow and weaken the attacking armoured forces. Though they had been provided superb intelligence, the Voronezh Front headquarters had still not been able to pinpoint the exact location where the Germans would place their offensive weight.
The panzergrenadier division "Großdeutschland", commanded by Walter Hörnlein, was the strongest single division in the 4th Panzer Army. It was supported on its flanks by the 3rd and 11th Panzer Divisions. "Großdeutschland's" Panzer IIIs and IVs had been supplemented by a company of 15 Tigers, which were used to spearhead the attack. At dawn on 5 July, the "Grossdeutschland" Division, backed by heavy artillery support, advanced on a three-kilometre front upon the 67th Guards Rifle Division of the 22nd Guards Rifle Corps. The Panzerfüsilier Regiment, advancing on the left wing, stalled in a minefield and subsequently 36 Panthers were immobilized. The stranded regiment was subjected to a barrage of Soviet anti-tank and artillery fire, which inflicted numerous casualties. Engineers were moved up and cleared paths through the minefield, but suffered casualties in the process. The combination of fierce resistance, minefields, thick mud and mechanical breakdowns took its toll; a 4th Panzer Division soldier reported that "'Half-track breakdowns very many, Panzer no fewer, also the Tigers are not the true love." With paths cleared, the regiment resumed its advance towards Gertsovka. In the ensuing battle, heavy casualties were sustained including the regimental commander Colonel Kassnitz. Due to the fighting, and the marshy terrain south of the village, surrounding the Berezovyy stream, the regiment once more bogged down. 
 The panzergrenadier regiment of "Großdeutschland", advancing on the right wing, pushed through to the village of Butovo. The tanks were deployed in a classic arrow formation to minimise the effects of the Soviet Pakfront defence, with the Tigers leading and the Panzer IIIs, IVs and assault guns fanning out to the flanks and rear. They were followed by infantry and combat engineers. Attempts by the Red Air Force to impede the advance were repulsed by the Luftwaffe. 
The 3rd Panzer Division, advancing on the left flank of "Großdeutschland", made good progress and by the end of the day had captured Gertsovka and reached Mikhailovka. The 167th Infantry Division, on the right flank of the 11th Panzer Division, also made sufficient progress, reaching Tirechnoe by the end of the day. By the end of 5 July, a wedge had been created in the first line of the Soviet defences.
II SS Panzer Corps.
To the east, during the night of 4–5 July, SS combat engineers had infiltrated no-man's land and cleared lanes through the Soviet minefields. At dawn, 5 July, the three divisions of II SS Panzer Corps – SS Panzergrenadier Division "Leibstandarte Adolf Hitler", 2nd SS Panzergrenadier Division "Das Reich" and the 3rd SS Panzergrenadier Division "Totenkopf" – attacked the 6th Guards Army's 52nd Guards Rifle Division. The main assault was led by a spearhead of 42 Tigers, but in total 494 tanks and assault guns attacked across a twelve-kilometre front. "Totenkopf", the strongest of the three divisions, advanced towards Gremuchhi and screened the right flank. The 1st SS Panzergrenadier Division advanced on the left flank towards Bykovka. The 2nd SS Panzer Division advanced between the two formations in the center. Following closely behind the tanks were the infantry and combat engineers, coming forward to demolish obstacles and clear trenches. In addition, the advance was well supported by the Luftwaffe, which greatly aided in breaking Soviet strong points and artillery positions.
By 09:00 hours, the II SS Panzer Corps had advanced deep into the Soviet first line of defence along its entire front. While probing positions between the first and second Soviet defensive belts, at 1300 hours, the 2nd SS Panzer Division's vanguard came under fire from two T-34 tanks, which were quickly dispatched. 40 more Soviet tanks soon engaged the division. The 1st Guards Tank Army clashed with the 2nd SS Panzer Division in a four-hour battle, resulting in the Soviet tanks withdrawing. However, the battle had bought enough time for units of the 23rd Soviet Guards Rifle Corps, lodged in the Soviet second line, to prepare itself and be reinforced with additional anti-tank guns. By the early evening, 2nd SS Panzer Division had reached the minefields that marked the outer perimeter of the Soviet second line of defence. The 1st SS Division had secured Bykovka by 1610 hours. It then pushed forward towards the second line of defence at Yakovlevo, but its attempts to break through were rebuffed. By the end of the day, the 1st SS Division had sustained 97 dead, 522 wounded, and 17 missing and lost about 30 tanks. Together with the 2nd SS Panzer Division, it had forced a wedge far into the defences of the 6th Guards Army.
The 3rd SS Panzer Division was making slow progress. They had managed to isolate the 155th Guards Regiment, of the 52nd Guards Rifle Division (of the 23rd Guards Rifle Corps), from the rest of its parent division, but its attempts to sweep the regiment eastward into the flank of the neighbouring 375th Rifle Division (of the 23rd Guards Rifle Corps) had failed when the regiment was reinforced by the 96th Tank Brigade. Hausser, the commander of II SS Panzer Corps, requested aid from the III Panzer Corps to his east, but they were unable to assist due to facing serious challenges of its own. By the end of the day, the 3rd SS Division had made very limited progress due in part to a tributary of the Donets river. The lack of progress undermined the advance made by its sister divisions and exposed the right flank of the corps to Soviet forces. German crews, working in "boiling" tanks in sweltering weather conditions, "frequently suffered from heat exhaustion."
Army Detachment "Kempf".
Facing Army Detachment "Kempf", consisting of III Panzer Corps and Corps "Raus" (commanded by Erhard Raus), were the 7th Guards Army, dug in on the high ground on the eastern bank of the Northern Donets. The two German corps were tasked with crossing the river, smashing through the 7th Guards Army and support the right flank of the 4th Panzer Army. The 503rd Heavy Tank Battalion – equipped with 45 Tigers – was also attached to the III Panzer Corps, split up so that one company of 15 Tigers was attached to each of the three panzer divisions of the corps. Although the river was bridged during the night of 4 July, the crossing points were bombarded by Soviet artillery.
At the Milkhailovka bridgehead, just south of Belgorod, eight infantry battalions of the 6th Panzer Division, III Panzer Corps, assembled there and were subjected to heavy artillery fire during the Soviet defensive bombardment. Eventually, most of the infantry got across to the eastern bank. When a company of the 503rd Heavy Tank Battalion began to cross, it too was bombarded and the bridge was destroyed and the rest of the 6th Panzer Division had to cross further south. Clemens Graf Kageneck, battalion commander, described it thus:
Suddenly, a red sunrise arose on the far side as hundreds of Stalin's organs hurled their rockets exactly onto the crossing site. The bridge was totally demolished and the engineers, unfortunately, suffered heavy losses. Never have I hugged the dirt so tightly as when these terrible shells sprayed their thin fragments just above the ground.
The 6th Panzer Division fell behind schedule as it diverted to the south and the problem was aggravated when it was reported to Walther von Hünersdorff, the divisional commander, that the new crossing was clogged with traffic. Failing to find another crossing, the rest of the division remained on the western bank of the river throughout the day. Those units of the division that had crossed the river, launched an attack led by Tigers on Stary Gorod, which was repulsed due to poorly cleared minefields and strong resistance.
To the south of the 6th Panzer Division, the 19th Panzer Division crossed the river but was delayed by mines that damaged some of the Tigers spearheading the advance and division had moved forward 8 km by the end of the day. Further south, infantry and tanks of 7th Panzer Division managed to cross the bridges but Tiger tanks, supporting the 7th Panzer Division, were unable to cross due to their weight. Attempts were made to drive the Tigers across the river failed due to their weight and the massive Soviet artillery bombardment. Eventually, engineers constructed bridges strong enough to take the Tigers across, where they joined the force on the far side. Despite a poor start, the 7th Panzer Division eventually broke into the first line of the Soviet defence and pushed on between Razumnoe and Krutoi Log, advancing about 10 km during the day, the furthest advance by Army Detachment "Kempf" of the day.
Operating to the south of 7th Panzer Division, were the 106th Infantry Division and the 320th Infantry Division of Corps "Raus". The two formations, without armour support, attacked across a 32 km front and made little progress. The advance began well, with the crossing of the river and a swift advance against the 72nd Guards Rifle Division. The Soviet defenders were taken by surprise with the speed of the advance. Erhard Raus, later wrote:
The advancing infantry surprised them and had no difficulty ferreting them out. But when the infantry reached the two to five-kilometre deep zone of the battle positions prepared in the preceding months, they had to make extensive use of hand grenades in order to mop up [a] maze of densely dug-in trenches and bunkers, some of which were a dozen or more feet deep. At the same time, artillery and flak fired counter-battery missions against the enemy heavy weapons that had resumed fire from rear positions. They also fired on reserves infiltrating through the trench system, as well as against [Soviet] medium artillery. 
After a fierce battle, involving some hand-to-hand fighting, Corps "Raus" took the village of Maslovo Pristani, penetrating the first Soviet line of defence. The lodgement was nearly lost to a Soviet counter-attack supported by about 40 tanks. The counter-attack was eventually repulsed with the assistance of artillery and flak batteries. Having suffered 2,000 casualties since the morning and still facing considerable resistance, the corps could penetrate no further and dug in for the night.
First day summary.
By the end of the first day, the attack by Army Group South had penetrated the first Soviet defensive line. The "II SS Panzer Korps" had broken through the first line of defence by 09:00 and were pushing to breach the second. Some divisions, particularly those of Army Detachment Kempf, had barely breached the first line. Along the southern face of the salient, the German thrust had been slowed, allowing the Soviets time to prepare their second line of defence to meet the German attack on 6 July. The 7th Guards Army, which had absorbed the attack of "III Panzer Korps" and Corps "Raus", was reinforced with two rifle divisions from the reserve. The 15th Guards Rifle Division was also moved up to the second line of defence, in the path of the "III Panzer Korps". The 6th Guards Army, which confronted the attack by the "XLVIII Panzer Korps" and "II SS Panzer Korps", was reinforced with tanks from the 1st Tank Army and reinforcements from the 2nd Guards Tank Corps and the 5th Guards Tank Corps. The 51st and 90th Guards Rifle divisions were moved up to the vicinity of Pokrovka (not Prokhorovka, 40 km to the north-east), in the path of the 1st SS Panzer Division. The 93rd Guards Rifle Division was deployed further back, along the road leading from Pokrovka to Prokhorovka.
The battle progresses.
The steady progress of the Germans forced the Soviet leaders to commit some of their strategic reserves, as nearly all operational reserves were in action. As early as 6 July, "Stavka" decided to send the 2nd and 10th Tank Corps and the 5th Guards Tank Army to the southern sector. On July 7, the 5th Guards Tank Army advanced to the front. Its commanding general, Lieutenant General Pavel Rotmistrov, described the journey: 
 By midday, the dust rose in thick clouds, settling in a solid layer on roadside bushes, grain fields, tanks and trucks. The dark red disc of the sun was hardly visible. Tanks, self-propelled guns, artillery tractors, armoured personnel carriers and trucks were advancing in an unending flow. The faces of the soldiers were dark with dust and exhaust fumes. It was intolerably hot. Soldiers were tortured by thirst and their shirts, wet with sweat, stuck to their bodies. 
A day later, other formations were ordered to the front. Vatutin planned an operational counterstrike against the German units, but decided to cancel it after learning of the unanticipated German strength in Tiger and Panther tanks and self-propelled guns. Over Zhukov's objection, Vatutin ordered tanks to be dug in to defend in the second defensive belt.
German officers reported being slowed by the "silent tanks" – tanks dug into fortified emplacements. Not all the Soviet tanks were dug-in, and a number of Soviet units launched counterattacks. On 7 July, SS "Unterscharführer" Franz Staudegger, commanding a Tiger tank, encountered a group of 50 T-34s. In the ensuing battle, Staudegger knocked out 22 T-34s. For his actions, he was awarded the Knight's Cross (the first Tiger commander to be awarded such a medal).
Though the German advance in the south was slower than desired, it was much faster than the Soviets expected. On 9 July, the first German units reached the Psel River. The next day, the first German infantry crossed the river. Despite the deep defensive system and minefields, German tank losses were low. At this point, Hoth turned the II SS Panzer Corps from a northward heading directed toward Oboyan to a northeast heading towards Prokhorovka. The main concern of von Manstein and Hauser was the inability of Army Detachment "Kempf" to advance and protect the eastern flank of the II SS Panzer Corps. On 11 July, Army Detachment "Kempf" finally achieved a breakthrough. In a surprise night attack, the 6th Panzer Division seized a bridge across the Donets. Once across, Breith made every effort to push troops and vehicles across the river for an advance on Prokhorovka from the south. A linkup with the II SS Panzer Corps would result with the Soviet 69th Army becoming encircled. It appeared the hoped for breakthrough was at hand.
Battle of Prokhorovka.
Hausser had expected to continue his advance on Prokhorovka, and late on the evening of 11 July issued orders for a classic maneuver battle for the attack the next day. The attack would begin north of the Psel river, with the 3rd SS Panzer Division driving northeast until reaching the Karteschewka-Prokhorovka road. Once there, they were to strike southeast to attack the Soviet positions at Prokhorovka from the rear. 1st and 2nd SS Panzer divisions were to wait until "Totenkopf's" attack had destabilized the Soviet positions at Prokhorovka. Once the Soviets at Prokhorovka were under attack from the rear, the "Leibstandarte" was to join the attack, advancing through the main Soviet defenses on the west slope before Prokhorovka. To "Leibstandarte's" right, the 2nd SS was to advance eastward to the high ground south of Prokhorovka, then turn south to roll up the Soviet line and open a gap. Unbeknownst to Hausser, Rotmistrov had moved his 5th Guards Tank Army up to an assembly area just below Prokhorovka, on the night of 11/12 July, in preparation for a massive attack the following day. Throughout the night, German frontline troops could hear the ominous sounds of Soviet tank engines to the east as the 18th and 29th Tank Corps moved into their assembly areas.
At 06:15, a Soviet artillery barrage began. At 06:30, Rotmistrov radioed his tankers: "Steel, Steel, Steel!", the order to commence the attack. Down off the west slopes, before Prokhorovka, came the massed armour of five tank brigades from the two Soviet tank corps. They had been ordered to approach at high speed. Rotmistrov, fearing that German Tiger tanks made up a large component of his opponent's forces, had instructed his tankers to move forward at speed to close the range quickly, firing on the move in an attempt to obtain a flank or rear firing position on the German tanks. During this time period, firing on the move was highly inaccurate, particularly while moving at high speed. Soviet intelligence estimates fixed the number of German Tiger tanks, in the Prokhorovka area, at approximately 100. In actuality, the II SS Panzer Corps had only 15 Tiger tanks. Ten of these tanks were north of the Psel River with the 3rd SS, the 1st SS had four operational Tiger tanks, and the 2nd SS had only one.
The 1st SS had just started to advance, when it was taken largely by surprise. As the Soviet tanks aggressively advanced down the corridor, they carried the 9th Parachute Division into battle mounted on the tanks with the paratroopers holding onto rails. At the base of Hill 252.2 was a Soviet-dug anti-tank ditch. With the firing of purple warning flares across the entire front, Rudolf von Ribbentrop (a company commander) stated he knew at once that a major attack was at hand. He ordered his company's seven remaining Panzer IVs to start up and follow him, over a bridge that had been constructed over an anti-tank ditch, onto the lower slope of Hill 252.2. On the crest of the hill, above him, was Joachim Peiper's 2nd SS Panzergrenadiers (supported by their halftracks) who were being overrun. As Ribbentrop's tanks fanned out on the lower slope, he looked up to the crest of the hillside. He recalled: "In front of me appeared fifteen, then twenty, then thirty, then forty tanks. Finally there were too many of them to count. The T-34s were rolling toward us at speed, and carrying mounted infantry." The Soviet tanks charged down the west slope of the hill, firing as they moved. 
Amid the swirls of dust, a highly confused tank battle began. The Panzer IV to Ribbentrop's right was set ablaze. The company was soon swamped by the large numbers of Soviet tanks advancing down the hill. At the base of the hill, the advancing Soviet armour was held up by the anti-tank ditch. Heavy firing commenced between the Soviet armour and tanks of the 1st SS based on the opposite side of the ditch. Meanwhile, the Soviet tanks searched for a route across the ditch. On the hilltop, with the passage of the first waves of Soviet tanks, Peiper's surviving panzergrenadiers emerged from trench lines to engage the Soviet paratroopers and attack Soviet tanks with magnetic shaped charges. Twenty of the battalion's half-tracks were lost in the fighting, some destroyed when they attempted to ram the much heavier Soviet tanks in an effort to stop them from destroying the company.
To the north and east, the 3rd SS was engaged by the Soviet 33rd Guards Rifle Corps. Tasked with destabilizing the Soviet defenses before Prokhorovka, the unit first had to beat off a number of attacks before they could go over onto the offensive. Most of the division's tank losses occurred late in the afternoon as they advanced through mine fields against well-hidden Soviet anti-tank guns. Although the 3rd SS succeeded in reaching the Karteschewka-Prokhorovka road, their hold was tenuous and it cost the division half of its armour. The majority of German tank losses suffered at Prokhorovka occurred here. To the south, the Soviet 18th and 29th Tank Corps, of the 5th Guards Tank Army, had been thrown back by the 1st SS acting alone. Meanwhile, the 2nd SS was holding a line to the south against the 2nd Tank Corps and the 2nd Guards Tank Corps.
The Soviet attacks had been checked by the II SS Panzer Corps, without the Germans losing any ground. By early afternoon, it was clear that Rotmistrov's attack had failed. Luftwaffe air superiority, over the battlefield, also contributed to the Soviet losses, partly due to the "VVS" being directed against the units flanking II SS Panzer Corps. Hs 129s and Ju 87s inflicted significant losses on the 5th Guards Tank Army. Soviet tank losses were extremely heavy. A report from the 29th Tank Corps reported "heavy losses in tanks through enemy aircraft and artillery [attacks]" and commented that "due to continuous air attacks, they were unable to advance further and shifted to the defence". By the end of the day, the Soviets had fallen back to their starting positions.
The battle is considered a tactical defeat for the Red Army due to the heavy tank losses, but operationally the battle was a draw. Neither the 5th Guards Tank Army nor the II SS Panzer Corps accomplished their objectives. Though the Soviet counterattack failed and they were thrown back onto the defensive, they did enough to stop a German breakthrough. Tank losses during the battle have been a contentious subject. Red Army tank losses have been given from 200 to 822, but records show about 300 complete losses and as many damaged. The Soviets claimed enormous German losses, stating they had destroyed at least 400 tanks, including 100 Tiger tanks, and inflicting 3,500 deaths. German records indicate that their losses were minute in comparison to the Soviet claims. Three to five tanks were destroyed, and between 40 and 70 were damaged. Manpower losses were in the region of 500 killed. The 1st SS and 2nd SS Panzer Divisions reported 186 tanks, assault guns, and tank hunters serviceable on the eve of battle, and 190 available the evening after.
Allied invasion of Sicily and termination of Operation Citadel.
On the evening of 12 July, Hitler summoned von Kluge and von Manstein to his headquarters at Rastenburg, in East Prussia. Two days prior, the Western Allies had invaded Sicily. The threat of further Allied landings in Italy or along southern France made Hitler believe it was essential to move forces from Kursk to Italy and to discontinue the offensive. Von Kluge welcomed the news, as he was aware that the Soviets were initiating a massive offensive against his sector, but von Manstein was less welcoming. Von Manstein's forces had just spent a week fighting through a maze of defensive works and he believed they were on the verge of breaking through to more open terrain, which would allow him to engage and destroy the Soviet armoured reserves in a mobile battle. Von Manstein stated, "On no account should we let go of the enemy until the mobile reserves he [has] committed [are] completely beaten." Hitler agreed to temporarily allow the continuance of the offensive in the south part of the salient, but the following day he ordered von Manstein's reserve – the XXIV Panzer Corps – to move south to support the 1st Panzer Army. This removed the force von Manstein believed was needed to succeed.
On 16 July, German forces withdrew to their start line. The following day, OKH ordered the II SS Panzer Corps to be withdrawn and transferred to Italy. The strength of the Soviet reserve formations had been greatly underestimated by German intelligence, and the Soviets soon went onto the offensive.
Controversy.
Following the war a number of German generals were highly critical of Hitler's decision to call off the operation at the height of the tactical battle. This criticism has received support from German officers in the post-war German Army (Bundeswehr), and by a number of historians. Anticipating that the Western Allies would conduct some form of operation in Western Europe, both von Manstein and Guderian had argued prior to the battle for forces to be conserved and re-deployed as a reserve. Once committed to the operation, it made little sense to pull them out at the climax, especially since they could not reach Italy in time to impact events there. Von Manstein argued that pulling forces out from Army Group South in the midst of the battle, shifting away Luftwaffe support and transferring his reserve force deprived his Army of its striking power at what he believed was the decisive point of the battle. The accuracy of Manstein's assertion is debatable. The extent of Soviet reserves was far greater than von Manstein realized. These reserves were used to re-equip the mauled 5th Guards Tank Army, which launched Operation Rumyantsev a couple of weeks later. However, rebuilding this formation did take time. The essential thing was to concentrate the available force for a decisive action. Hitler's unwillingness to accept risk resulted in his commanders being unable to concentrate. Further, he restricted them from fighting the type of mobile battle they wanted, despite von Manstein's success in this type of action only a few months before at the Third Battle of Kharkov. The result was a battle of attrition they were ill prepared for and which they had little chance of winning.
Soviet counteroffensives.
In the north: Operation "Kutuzov".
Soviet offensive operations for the summer of 1943 were planned to begin after the strength of the German forces had been dissipated by their Kursk offensive. As the German momentum in the north slowed the Soviets launched Operation "Kutusov" on 12 July against Army Group Centre in the Orel salient, north of Kursk. The Bryansk Front, under the command of Markian Popov, attacked the eastern face of the Orel salient while the Western Front, commanded by Vasily Sokolovsky, attacked from the north. The thinly stretched 2nd Panzer Army stood in the way of this Soviet force. The German commanders had been wary of such an attack and forces were quickly withdrawn from the Kursk offensive to meet the Soviet offensive.
Operation "Kutuzov" reduced the Orel salient and inflicted substantial losses on the German military, paving the way for the liberation of Smolensk. Soviet losses were heavy, but were replaced. The offensive allowed the Soviets to seize the strategic initiative, which they retained for the remainder of the war.
In the south: Operation "Polkovodets Rumyantsev".
Operation "Polkovodets Rumyantsev" was intended as the main Soviet offensive for 1943. Its aim was to degrade the 4th Panzer Army and cut off the extended southern portion of Army Group South. After the heavy losses sustained by the Voronezh Front, during Operation Citadel, the Soviets needed time to regroup and refit, delaying the start of the offensive until 3 August. Diversionary attacks, launched two weeks earlier across the Donets and Mius Rivers into the Donbass, drew the attention of German reserves and thinned the defending forces that would face the main blow. The offensive was initiated by the Voronezh Front and Steppe Fronts against the northern wing of Army Group South. They drove through the German positions, making broad and deep penetrations. By 5 August, the Soviets had liberated Belgorod. 
By 12 August, the outskirts of Kharkov had been reached. The Soviet advance was finally halted by a counter-attack by the 2nd and 3rd SS Panzer Divisions. In the ensuing tank battles, the Soviet armies suffered heavy losses in armour. After this setback, the Soviets focused on Kharkov. After heavy fighting the city was liberated on 23 August. This battle is referred to by the Germans as the Fourth Battle of Kharkov, while the Soviets refer to it as the Belgorod–Kharkov offensive operation.
Results.
The campaign was a strategic Soviet success. For the first time a major German offensive had been stopped before achieving a breakthrough. The Germans, despite using more technologically advanced armour than in previous years, were unable to break through the in-depth Soviet defences and were caught off guard by the significant operational reserves of the Red Army. This result changed the pattern of operations on the Eastern Front, with the Soviet Union gaining the operational initiative. The Soviet victory, however, was costly, with the Red Army losing considerably more men and material than the German Army. However, the Soviet Union's larger industrial potential and pool of manpower allowed them to absorb and replenish these loses, with their overall strategic strength unaffected. 
 With the failure of "Zitadelle" we have suffered a decisive defeat. The armoured formations, reformed and re-equipped with so much effort, had lost heavily in both men and equipment and would now be unemployable for a long time to come. It was problematical whether they could be rehabilitated in time to defend the Eastern Front ... Needless to say the [Soviets] exploited their victory to the full. There were to be no more periods of quiet on the Eastern Front. From now on, the enemy was in undisputed possession of the initiative. — Heinz Guderian
With victory, the initiative firmly passed to the Red Army. For the remainder of the war the Germans were limited to reacting to Soviet advances, and were never able to regain the initiative or launch a major offensive on the Eastern Front. The Western Allied landings, in Italy, opened up a new front, further diverting German resources and attention.
Though the location, plan of attack, and timing were determined by Hitler, he blamed the defeat on his General Staff. Unlike Stalin, who gave his commanding generals the liberty to make important command decisions, Hitler's interference in German military matters progressively increased while his attention to the political aspects of the war decreased. The opposite was true for Stalin. Throughout the Kursk campaign he trusted the judgment of his commanders, and as their decisions led to battlefield success it increased his trust in their military judgment. Stalin stepped back from operational planning, only rarely overruling military decisions, resulting in the Red Army gaining more freedom of action during the course of the war.
 Stalingrad was the end of the beginning, but the Battle of Kursk was the beginning of the end. — Winston Churchill 
Casualties and losses.
The casualties suffered by the two combatants are difficult to determine, due to several factors. In regard to the Germans, equipment losses were complicated by the fact that they made determined efforts to recover and repair tanks. For example, tanks disabled one day often appeared a day or two later repaired. German personnel losses are clouded by the lack of access to German unit records, which were seized at the end of the war. Many were transferred to the United States national archives and were not made available until 1978, while others were taken by the Soviet Union, which declined to confirm their existence.
Soviet losses.
Grigoriy Krivosheyev, who based his figures on the Soviet archives, is considered by historian David Glantz as the most reliable source for Soviet casualty figures. His figures are supported by Karl-Heinz Frieser. Krivosheyev calculated total Soviet losses during the German offensive as 177,877 casualties. The Central Front suffered 15,336 irrecoverable casualties and 18,561 medical casualties, for a total of 33,897 casualties. The Voronezh Front suffered 27,542 irrecoverable casualties and 46,350 medical casualties, for a total of 73,892. The Steppe Front suffered 27,452 irrecoverable casualties and 42,606 medical casualties, for a total of 70,085.
During the two Soviet offensives, total casualties amounted to 685,456 men. During Operation Kutuzov, Soviet losses amounted to 112,529 irrecoverable casualties and 317,361 medical casualties, for a total loss of 429,890 men. The Western Front reported 25,585 irrecoverable casualties and 76,856 medical casualties. The Bryansk Front suffered 39,173 irrecoverable casualties and 123,234 medical casualties. The Central Front lost 47,771 irrecoverable casualties and 117,271 medical casualties. Soviet losses during Operation Polkovodets Rumyantsev totaled 255,566 men, with 71,611 listed as irrecoverable casualties and 183,955 as medical casualties. The Voronezh Front lost 48,339 irrecoverable casualties and 108,954 medical casualties, for a total of 157,293. The Steppe Front lost 23,272 irrecoverable casualties and 75,001 medical casualties, for a total of 98,273.
Soviet equipment losses during the German offensive came to 1,614 tanks and self-propelled guns destroyed or damaged of the 3,925 vehicles committed to the battle. The Soviet losses were roughly three times larger than the German losses. During Operation "Kutuzov", 2,349 tanks and self-propelled guns were lost out of an initial strength of 2,308; a loss of over 100 percent. During "Polkovodets Rumyantsev" 1,864 tanks and self-propelled guns were lost out of the 2,439 employed. The loss ratio suffered by the Soviets was roughly 5:1 in favour of the German military. However, large Soviet reserves of equipment and their high rate of tank production enabled the Soviet tank armies to soon replace lost equipment and maintain their fighting strength. The Red Army repaired many of its damaged tanks, many Soviet tanks were rebuilt up to four times to keep them in the fight. Soviet tank strength went back up to 2.750 tanks by 3 August due to the repair of damaged vehicles
According to Christer Bergström, Red Air Force losses, during the German offensive, amounted to 677 aircraft on the northern flank and 439 on the southern flank. Total casualties are uncertain. Bergström's research indicates total Soviet air losses between 12 July and 18 August, during the German offensive and the Operation Kutuzov counteroffensive, were 1,104.
German losses.
Karl-Heinz Frieser, who reviewed the German archive record, calculated that during Operation Citadel 54,182 casualties were suffered. Of these, 9,036 were killed, 1,960 were reported missing, and 43,159 were wounded. The 9th Army suffered 23,345 casualties, while Army Group South suffered 30,837 casualties. Throughout the Soviet offensives, 86,064 casualties were suffered. In facing Operation "Kutuzov", 14,215 men were killed, 11,300 were reported missing (presumed killed or captured), and 60,549 were wounded. During "Polkovodets Rumyantsev", 25,068 casualties were incurred, including 8,933 killed and missing. Total casualties for the three battles were about 170,000 men.
During Operation Citadel, 252 to 323 tanks and assault guns were destroyed. By 5 July, when the Battle of Kursk started, there were only 184 operational Panthers. Within two days, this had dropped to 40. On 17 July 1943 after Hitler had ordered a stop to the German offensive, Gen. Heinz Guderian sent in the following preliminary assessment of the Panthers:
"Due to enemy action and mechanical breakdowns, the combat strength sank rapidly during the first few days. By the evening of 10 July there were only 10 operational Panthers in the front line. 25 Panthers had been lost as total writeoffs (23 were hit and burnt and two had caught fire during the approach march). 100 Panthers were in need of repair (56 were damaged by hits and mines and 44 by mechanical breakdown). 60 percent of the mechanical breakdowns could be easily repaired. Approximately 40 Panthers had already been repaired and were on the way to the front. About 25 still had not been recovered by the repair service... On the evening of 11 July, 38 Panthers were operational, 31 were total writeoffs and 131 were in need of repair. A slow increase in the combat strength is observable. The large number of losses by hits (81 Panthers up to 10 July) attests to the heavy fighting".
By 16 July, Army Group South submitted 161 tanks and 14 assault guns had been lost as total writeoffs. Up to 14 July, 9th Army reported they had lost as total writeoffs 41 tanks and 17 assault guns. These losses break down as 109 Panzer IVs, 42 Panthers, 38 Panzer IIIs, 31 assault guns, 19 "Elefant"s, 10 Tigers, and three flame tanks. Before the Germans ended their offensive at Kursk, the Soviets began their counteroffensive, and succeeded in pushing the Germans back into a steady retreat. Thus, a report on 11 August 1943 showed that the numbers of total writeoffs in Panthers swelled to 156, with only 9 operational. The German Army was forced into a fighting retreat and increasingly lost tanks in combat as well as from abandoning and destroying damaged vehicles. Across the entire Eastern Front 50 Tiger tanks were lost during July and August, with some 240 damaged. Most of these occurred during their offensive at Kursk Some 600 tanks sustained damage in the period from 5 July 18 July.
The total number of German tanks and assault guns destroyed during July and August along the entire Eastern Front amount to 1,331. Of these, Frieser estimates that 760 were destroyed during the Battle of Kursk. Antony Beevor writes that "the Red Army had lost five armoured vehicles for every German panzer destroyed."
Frieser reports Luftwaffe losses at 524 planes, with 159 lost during the German offensive, 218 destroyed during Operation "Kutuzov", and a further 147 lost during Operation "Polkovodets Rumyantsev". In reviewing the reports of the quartermaster of the Luftwaffe, Christer Bergström presents different figures. Between 5 and 31 July, Bergström reports 681 aircraft lost or damaged (335 for "Fliegerkorps VIII" and 346 for "Luftflotte 6") with a total of 420 being written off (192 from "Fliegerkorps VIII" and 229 from "Luftflotte 6").
Analysis of Citadel.
Analysis of northern assault.
A number of factors explain the 9th Army's lack of progress: a lack of concentration of force, and the Soviet defensive planning. German armour was committed piecemeal, rather than in strength, and often without sufficient infantry support. Marshal Rokossovsky's Central Front had correctly anticipated the likely areas of German attack, and heavily fortified those areas. The Soviet 13th Army, which bore the brunt of the German attack, was far stronger in men and anti-tank guns than the other Central Front units and held the strongest defensive positions in the salient.
Model's decision not to use his panzer divisions as a concentrated force, is seen as the most significant reason for the lack of progress. His army lacked the tank strength of von Manstein, and Model was well aware that the Soviets were preparing for an attack to the north. As a result, he placed his most powerful corps, "Gruppe" "Esebeck" (comprising the 2nd Panzer Division and 10th Panzer Grenadier Division), in a reserve position behind the front to use as a "fire brigade" against any Soviet attacks upon his flank.
Analysis of southern assault.
Red Army minefields and artillery were successful in delaying the German attack and inflicting losses. The ability of dug-in Red Army units to delay the Germans allowed their own reserves to be brought up into threatened sectors. Over 90,000 additional mines were laid during the operations, by small mobile groups of engineers, generally working at night immediately in front of the expected German attack areas. There were no large-scale captures of prisoners nor any great loss of artillery, indicating that Soviet units were giving ground in good order.
Military historian opinions.
Karl-Heinz Frieser highlights the following reasons for the failure of Operation Citadel:
David Glantz draws the following conclusions:
Steven Zaloga offers the following insights about the Red Army at Kursk:
Richard Overy makes the following observations:
Sir Harry Hinsley, who worked at Bletchley Park during the war and is a professional historian, has noted the following:
References.
</dl>

</doc>
<doc id="33105" url="http://en.wikipedia.org/wiki?curid=33105" title="Wargaming">
Wargaming

A wargame (also war game) is a strategy game that deals with military operations of various types, real or fictional. Wargaming is the hobby dedicated to the play of such games, which can also be called conflict simulations, or consims for short. When used professionally by the military to study warfare, "war game" may refer to a simple theoretical study or a full-scale military exercise. Hobby wargamers have traditionally used "wargame", while the military has generally used "war game"; this is not a hard and fast rule. Although there may be disagreements as to whether a particular game qualifies as a wargame or not, a general consensus exists that all such games must explore and represent some feature or aspect of human behaviour directly bearing on the conduct of war, even if the game subject itself does not concern organized violent conflict or warfare. The business wargames exists too, but in general they are only role playing games based on market situations.
Wargames are generally categorized as historical, hypothetical, fantasy, or science fiction. Historical games by far form the largest group. These games are based upon real events and attempt to represent a reasonable approximation of the actual forces, terrain, and other material factors faced by the actual participants. Hypothetical games are games grounded in historical fact but concern battles or conflicts that did not (or have yet to) actually happen. Fantasy and science fiction wargames either draw their inspiration from works of fiction or provide their own imaginary setting. Highly stylized conflict games such as chess are not generally considered wargames, although they are recognized as being related. Games involving conflict in other arenas than the battlefield, such as business, sports or natural environment are similarly usually excluded.
The modern wargaming hobby has its origins at the beginning of the 19th century, with von Reiswitz's Kriegsspiel rules. Later, H.G. Wells' book Little Wars ushered in the age of miniatures games in which two or more players simulated a battle as a pastime. During the 1950s the first large-scale, mass-produced board games depicting military conflicts were published. These games were at the height of their popularity during the 1970s, and became quite complex and technical in that time.
Wargaming has changed dramatically over the years, from its roots in miniatures and board wargaming, to contemporary computer and computer assisted wargames; however, both miniature and board wargames maintain a healthy, if small, hobby market with lighter games being popular with many 'non-wargamers'.
Overview.
Like all games, wargames exist in a range of different complexities. Some are fundamentally simple—often called "beer-and-pretzel" games—whereas others attempt to simulate a high level of historical realism. These latter games typically require extensive rulebooks that encompass a large variety of actions and details. These games often require a considerable study of the rules before they can be played. Wargames also feature a range of scales, from games that simulate individual soldiers, to ones that chart the course of an entire global or even galactic war.
Wargames are generally a representational art form. Usually, this is of a fairly concrete historical subject (such as the Battle of Gettysburg, one of several popular topics in the genre), but it can also be extended to non-historical ones as well. The Cold War provided fuel for many games that attempted to show what a non-nuclear (or, in a very few cases, nuclear) World War III would be like, moving from a re-creation to a predictive model in the process. Fantasy and science fiction subjects are sometimes not considered wargames because there is nothing in the real world to model, however, conflict in a self-consistent fictional world lends itself to exactly the same types of games and game designs as does military history.
Because of these attitudes, there are many games and types of games that may appear to be a wargame at first glance, but are not accepted as such by members of the hobby, and many that would be considered debatable. "Risk" could be considered a wargame; it uses an area map of the Earth and is unabashedly about sending out armies to conquer the world. However, it has no readily-discernible timeframe, and combat is extremely abstract, leading many to not consider it as an actual wargame, or only tangentially as one.
The highest percentage of war-themed games that are not wargames come from the video game industry. Most markedly real-time strategy games (such as "StarCraft") deal with combat nearly exclusively, but the gameplay-enhancing conventions of the genre also destroy realism. For example, in actual combat, vehicle armor is generally a binary proposition. Either the round penetrates and the vehicle is knocked out, or it does not and the vehicle is unaffected. RTS games make a habit of giving a vehicle a "health bar" that generally allows it to survive even powerful single shots, but each hit reduces its health by some amount, allowing a high volume of rifle fire to knock out a well armored tank. Other notable genre conventions include the construction of buildings and vehicles within the timeframe of a battle (i.e., hours, if not less) and a lack of any command and control, supply, or morale systems.
A major determinant of the complexity and size of a wargame is how realistic it is intended to be. Some games constitute a serious study of the subject at hand, whereas others are intended to be light entertainment. In general, a more serious study will have longer, more detailed rules, more complexity, and more record keeping. More casual games may only bear a passing resemblance to the subject, although many still try to encourage the same types of decision making as the player's historical counterparts, and thereby bring forth the "feel" of the conflict.
Wargames tend to have a few fundamental problems. Notably, both player knowledge, and player action are much less limited than what would be available to the player's real-life counterparts. Some games have rules for command and control and fog of war, using various methods. While results vary, many of these mechanisms can be cumbersome and onerous in traditional games. The "edge of world problem" raises the issue of what to do at the artificial boundary of the physical edge of a board game, in contrast to real life where there is no "edge" and units off-board can have a tangible effect on a scenario. Computer wargames can more easily incorporate these features because the computer can conceal information from players and act as an impartial judge (even while playing one side). However, due to interface issues, these can still be found to be as frustrating to the player as traditional methods.
History.
Drawing inspiration from chess, Hellwig, Master of Pages to the Duke of Brunswick, created a battle emulation game in 1780. According to Max Boot's book "War Made New" (2006, pg 122), sometime between 1803 and 1809, the Prussian General Staff developed war games, with staff officers moving metal pieces around on a game table (with blue pieces representing their forces and red pieces those of the enemy), using dice rolls to indicate random chance and with a referee scoring the results. Increasingly realistic variations became part of military training in the 19th century in many nations, and were called "kriegsspiel" or "wargames". Wargames or military exercises are still an important part of military training today.
Modern wargaming originated with the military need to study warfare and to 'reenact' old battles for instructional purposes. The stunning Prussian victory over the Second French Empire in the Franco-Prussian War of 1870-1871 is sometimes partly credited to the training of Prussian officers with the game "Kriegsspiel", which was invented around 1811 and gained popularity with many officers in the Prussian army. These first wargames were played with dice which represented "friction", or the intrusion of less than ideal circumstances during a real war (including morale, weather, the fog of war, etc.), though this was usually replaced by an umpire who used his own combat experience to determine the results.
"The first specific non-military wargame club was started in Oxford, England, in the 19th century." Naval enthusiast and analyst Fred T. Jane came up with a set of rules for depicting naval actions with the use of model ships, or miniatures around 1898 . The 1905/6 edition of "Jane's Fighting Ships" includes a revised edition for "The Naval War Game".
H.G. Wells' books "Floor Games" (1911) and "Little Wars" (1913) were attempts to codify rules for fighting battles with toy soldiers (miniatures), and make them available to the general public. They were very simple games, and in some ways just provide a context for shooting spring-loaded toy cannons at toy soldiers, but "in his Appendix to "Little Wars", Wells speaks of the changes required to convert his admittedly simplistic rules into a more rigorous "Kriegspiel"." However, Wells also states in his rules that combat "should be by actual gun and rifle fire and not by computation. Things should happen and not be decided," in opposition to the general nature of "Kriegspiel" play.
In 1940 "Fletcher Pratt's Naval War Game" was first published. The game started in New York, but other clubs formed around the USA. Jack Coggins was invited by Pratt to participate, and recalled that Pratt's game involved dozens of tiny wooden ships—built to a scale of about one inch to 50 feet—spread over the living room floor of his apartment. Their maneuvers and the results of their battles were calculated via a complex mathematical formula, with scale distances marked off with tape measures. The game's popularity grew and moved to using a ballroom for games with 60 or more players per side. The game was respected by the Naval War College and serving naval officers regularly participated in games For an evaluation of the Fletcher Pratt Game versus reality see Chapter 10 of "The Fletcher Pratt Naval Wargame" book. 
All of these games were meant to be accessible to the general public, but actual play was made difficult owing to the expense of purchasing an army or navy's worth of miniatures. As leisure time and disposable income generally rose through the 20th Century, miniatures games slowly gained a following. Most gaming groups informally wrote and/or revised their own rules, which were never published. In 1955 Jack Scruby started producing miniatures using RTV rubber molds, which greatly reduced their expense, and he turned this into a business (Scruby Miniatures) in 1957 and started publishing "War Game Digest". It, and its successors, put fellow miniatures enthusiasts in touch with each other, and provided a forum for ideas and locally produced rules to be shared with the rest of the hobby.
Around the same time in the UK Donald Featherstone began writing an influential series of books on wargaming, which represented the first mainstream published contribution to wargaming since H.G Wells. Titles included : "Wargames", "Advanced Wargames", "Solo Wargaming", "Wargame Campaigns", "Battles with Model Tanks", "Skirmish Wargaming". Such was the popularity of such titles that other authors were able to have published wargaming titles. This output of published wargaming titles from British authors coupled with the emergence at the same time of several manufacturers providing suitable wargame miniatures (e.g. Miniature Figurines, Hinchliffe, Peter Laing, Garrisson, Skytrex, Davco, Heroic & Ros) was responsible for the huge upsurge of popularity of the hobby in the late 1960s and into the 1970s.
Meanwhile, the first modern mass-market wargame, based on cardboard counters and maps, was designed and published by Charles S. Roberts in 1952. After nearly breaking even on "Tactics", he decided to found the Avalon Hill Game Company as a publisher of intelligent games for adults, and is called "The father of board wargaming". The modern commercial board wargaming industry is considered to have begun with the publication of "Tactics II" in 1958, and the founding of "The General Magazine" by Avalon Hill in 1964. In 1961, AH published Roberts' "Gettysburg", which is considered to be the first board wargame based entirely on a historical battle. "D-Day" and "Chancellorsville", the first commercial games to use a hexagonal mapboard, were also published that year.
Avalon Hill had a very conservative publishing schedule, typically about two titles a year, and wargames were only about half their line. During the late 1960s, a number of small magazines dedicated to the hobby appeared, along with new game companies. The most important of these were undoubtedly "Strategy & Tactics", and the company founded to save it from failing: Simulations Publications, Inc. (SPI). Under SPI, "S&T" started including a new game in every issue of the magazine, which along with the regular games SPI was publishing vastly increased the number of wargames available.
Coupled with an aggressive advertising campaign, this caused a tremendous rise in the popularity of wargaming in the early 1970s, with a large number of new companies starting up. Two of these would last for some years: Game Designers' Workshop (GDW), and Tactical Studies Rules (TSR). TSR's medieval era miniatures game, "Chainmail" (1971) included a fantasy supplement that led to a new phenomenon that would become much bigger than its parent hobby, role-playing games (RPGs). (For a better look at these developments see the history of role-playing games.)
The 1970s can be considered the 'Golden Age of Wargaming', with a large number of new companies publishing an even larger number of games throughout the decade, powered by an explosive rise in the number of people playing wargames. Avalon Hill's "PanzerBlitz" (1970), "Panzer Leader" (1974), and "Squad Leader" (1977) were particularly popular during this time, with their innovative geomorphic mapboard system. Wargames began to diversify in subject matter, with the first science-fiction wargame ("Galactic Warfare", published in the UK by Davco) appearing in 1973 and one of the longest lasting and most successful, "Star Fleet Battles", published by Task Force Games, appearing in 1979. Wargames also diversified in size during the decade with both microgames such as Steve Jackson's "Ogre "that had one small map, about 100 pieces and a complexity that permitted games to be completed in about an hour, and "monster games" such as "War in Europe" with over a dozen large maps and thousands of pieces, requiring dozens of hours to complete.
The boom came to an end, and was followed by the usual bust in the early 1980s, most markedly with the acquisition of SPI by TSR in 1982. The hobby never truly recovered from this, and is today much smaller than it was during the 1970s. Numerous factors have been implicated in the decline, including the rise of gaming alternatives (such as RPGs), the ever increasing complexity of wargames, and changing demographics and lifestyles.
During the 1980s, much of the market for wargames was dominated by roleplaying games. Then, when personal computers became available, gamers could simply "sit down and play" without learning masses of rules, clearing physical space, and finding and coordinating schedules with opponents. However, in 1983 Games Workshop published "Warhammer Fantasy Battle", initially as a "Mass-combat Role Playing Game", which quickly moved to dominate the fantasy wargaming market. When collectible card games arrived in the 1990s, the gaming market became even more competitive. By this time, many wargame publishers were already long gone.
Despite the decline, wargaming continues to survive in different forms. "Advanced Squad Leader" (1985) became a niche hobby in and of itself, and "Axis and Allies" (1984) was very popular with the mass market audience and Games Workshop's "Warhammer Fantasy Battle" (1983) spawned a long-lasting line popular miniatures games including the successive editions of "Warhammer" and the science-fantasy "Warhammer 40,000" game. The genre of 'card-driven games' emerged with the publication of "We the People" by AH in 1994, and continues in current releases from GMT. "Battle Cry" (2000) and "Memoir '44" (2004) proved that light wargames can still be commercially successful, as long as the rules are clear and accessible, and the components are high in quality. Block wargames, such as those published by Columbia Games remain quite popular. Companies like GMT Games and Multi-Man Publishing continue to survive and publish highly detailed hex and counter wargames.
Miniature versions.
Miniature wargaming typically involves the use of 6–54 mm painted metal or plastic miniatures for units, and model scenery placed on a tabletop or floor as a playing surface, although other open areas such as gardens and sandboxes are sometimes used. Games with miniatures are sometimes called tabletop games, tabletop wargames, miniature wargames, or simply wargames. Miniatures games generally measure distance for movement and range with a string or tape measure.
Miniature wargamers generally prefer rule sets that can be used for any battle in a particular era or war, instead of a specific event, as is common in board wargames. Because armies and terrain can be combined in all possible ways, miniatures wargaming is generally more varied and flexible than other forms of wargaming. The preparation also tends to be more time consuming and expensive. Miniature wargamers typically enjoy painting miniatures and constructing terrain, and this is an important part of the hobby for them.
Because information cannot be displayed on a miniature figure as conveniently as on a cardboard counter, miniature wargames often lack the complexity and detail of some of the heavier board wargames.
The popularity of miniatures wargaming stayed relatively stable during the boom and bust of board wargames. Today, games such as "Warhammer Fantasy Battle", "Dust Warfare", "Flames of War", Field of Glory and the newer collectible miniatures games continue to recruit new interest into the oldest form of the wargaming hobby.
Board versions.
In the United States, board wargames are often equated with the entire hobby of wargaming. In Europe, and especially Britain, they are a relatively minor part of the hobby. The genre is known for a number of common conventions that were developed early on, but these do not necessarily appear in all board wargames.
The early history of board wargaming was dominated by Avalon Hill, even though other companies, such as SPI, left their own permanent marks on the industry. With the purchase of Avalon Hill by Hasbro, no one company is identified with the hobby as a whole. GMT and Decision Games are two of the more influential board wargame companies in existence today.
Card versions.
Because of their nature, cards are well suited for abstract games, as opposed to the simulation aspects of wargames. Traditional card games are not considered wargames even when nominally about the same subject (such as the game "War").
An early card wargame would be "Nuclear War", a 'tongue-in-cheek game of the end of the world', first published in 1966 and still published today by Flying Buffalo. It does not simulate how any actual nuclear exchange would happen, but it is still structured unlike most card games because of the way it deals with its subject.
In the late 1970s Battleline Publications (a board wargame company) produced two card games, "Naval War" and "Armor Supremacy". The first was fairly popular in wargaming circles, and is a light system of naval combat, though again not depicting any 'real' situation (players may operate ships from opposing navies side-by-side). "Armor Supremacy" was not as successful, but is a look at the constant design and development of new types of tanks during World War II.
The most successful card wargame (as a card game and as a wargame) would almost certainly be "Up Front", a card game about tactical combat in World War II published by Avalon Hill in 1983. The abstractness is harnessed in the game by having the deck produce random terrain, and chances to fire, and the like, simulating uncertainty as to the local conditions (nature of the terrain, etc.).
 is a specialist designer and publisher of card games for several genres, including air combat and World War II and Modern land combat.
Also, card driven games (CDGs), first introduced in 1993, use a deck of (custom) cards to drive most elements of the game, such as unit movement (activation) and random events. These are, however, distinctly board games, the deck is merely one of the most important "elements" of the game.
Computer versions.
As in all aspects of modern life, personal computers have had a profound impact on wargaming. Computers allow gamers separated by many miles to play a game. They also handle many of the tedious aspects of wargaming, such as highly technical rules and record keeping. Finally, with the development of artificial intelligence, computers can actually serve as opponents, and thus provide opportunities for solitaire gaming.
In the video game industry, "wargames" are considered a subgenre of strategy game that emphasizes strategic or tactical warfare on a map. These wargames generally take one of four archetypal forms, depending on whether the game is turn-based or real-time and whether the game's focus is upon military strategy or tactics.
Comparison with traditional versions.
Many contemporary computer strategy games can be considered wargames, in the sense that they are a simulation of warfare on some level. The mechanics and language have little in common with board and miniature games, but the general subject matter is popular. That said, most war-themed computer and video games are generally not considered wargames by the wargaming hobby. This usually occurs because of the perception that slavish attention to 'realism' will cause a game to be rejected as 'uninteresting' or boring by the mass-market. Therefore the mass-market video games tend to be easier to get into, and quick to play. However, not all video games are equally unrealistic, as successful games such as the "Total War" and "Hearts of Iron" game series are historically based.
On the other hand, many video games include fog of war, meaning that what is visible on the map is limited to what is within a certain range of the player's units. This is a feature often talked about in traditional wargames, but traditionally impractical to implement outside of a computer.
Computers used in traditional versions.
Computer-assisted versions.
In the recent years, programs have been developed for computer-assisted gaming as regards to wargaming. Two different categories can be distinguished: local computer assisted wargames and remote computer assisted wargames.
Local computer assisted wargames are mostly not designed toward recreating the battlefield inside computer memory, but employing the computer to play the role of game master by storing game rules and unit characteristics, tracking unit status and positions or distances, animating the game with sounds and voice and resolving combat. Flow of play is simple: each turn, the units come up in a random order. Therefore the more units an opponent has, the more chance he will be selected for the next turn. When a unit comes up, the commander specifies an order and if offensive action is being taken, a target, along with details about distance. The results of the order, base move distance and effect to target, are reported, and the unit is moved on the tabletop. All distance relationships are tracked on the tabletop. All record-keeping is tracked by the computer.
Remote computer assisted wargames can be considered as extensions to the concept of PBEM gaming, however the presentation and actual capabilities are completely different. They have been designed to replicate the look and feel of existing board or miniatures wargames on the computer. The map and counters are presented to the user who can then manipulate these, more-or-less as if he were playing the physical game, and send a saved file off to his opponent, who can review what has been done without having to duplicate everything on his physical set-up of the game, and respond. Some allow for both players to get on-line and see each other's moves in real-time.
These systems are generally set up so that while one can play the game, the program has no knowledge of the rules, and cannot enforce them. The human players must have a knowledge of the rules themselves. The idea is to promote the playing of the games (by making play against a remote opponent easier), while supporting the industry (and reducing copyright issues) by ensuring that the players have access to the actual physical game.
The four main programs that can be used to play a number of games each are "Aide de Camp", "Cyberboard", "Vassal" and "ZunTzu". "Aide de Camp" is available for purchase, while the other three are offered free. "Vassal" is in turn an outgrowth of the "VASL" (Virtual "ASL") project, and uses Java, making it accessible to any computer that can run a modern JVM, while the other three are Microsoft Windows programs.
Play-by-Mail (PBM).
Wargames were played remotely through the mail, with players sending lists of moves, or orders, to each other through the mail.
In some early PBM systems, six sided dice rolling was simulated by designating a specific stock and a future date and once that date passed, the players would determine an actions outcome using the sales in hundreds value for specific stocks on a specific date and then dividing the NYSE published sales in hundreds by six, using the remainder as the dice result.
"Nuclear Destruction", by the Flying Buffalo, was an early PBM game in 1970. Origins Award Hall-of-Fame member "Middle-Earth Play-By-Mail" is still active today.
Reality Simulations, Inc. still runs a number of PBM games, such as Duel2 (formerly known as Duelmasters), Hyborian War, and Forgotten Realms: War of the Avatars.
E-mail and traditional versions.
Since e-mail is faster than the standard postal service, the rise of the Internet saw a shift of people playing board wargames from play-by-mail (PBM) to play-by-email (PBEM) or play-by-web (PBW). The mechanics were the same, merely the medium was faster.
At this time, turn-based strategy computer games still had a decent amount of popularity, and many started explicitly supporting the sending of saved-game files through email (instead of needing to find the file to send to the opponent by hand). As with all types of video games, the rise in home networking solutions and Internet access has also meant that networked games are now common and easy to set up.
Types.
While wargaming is a genre itself, it can be categorized into a number of subgenres. The most obvious division is by the categories given above. i.e., miniatures, board, computer, etc. This is so obvious, in fact, that most people verbally (and mentally) skip over it. A person might discuss (depending on context) 'board games' or 'wargames' and assume the other element without feeling any need to state 'board wargames'.
Beyond this, there are a few other characteristics that are used to define wargames. Another element that tends to be assumed is the "environment", or type of warfare (land, naval, air) depicted, at least if the subject matter is land warfare (a game on naval or air warfare will specify such if not immediately obvious). The most common genres that categories are explicitly based on is the period or era of the game, and then the scale of the game. Naturally, games concerned with a particular combination of period, scale and environment tend to emphasize similar features.
Environment.
The bulk of wargames concentrate on land warfare, the oldest of all types of warfare, and generally the easiest to simulate. Naval warfare and naval wargames are also popular, and go all the way back to the beginnings of the hobby. Aerial warfare is relatively recent, and wargames on the subject are usually tactical games simulating dogfights, there are relatively few dealing with "just" the air war of a larger conflict. Dealing with multiple elements complicates the model of the simulation side of a wargame, so games with a true combined arms approach tend to be strategic in nature, where all aspects are abstracted to a greater degree. While there are some near-future possibilities for space warfare, there are very few 'serious' games on the subject, and wargames set in space are almost purely in the genre of science fiction.
Historical period.
As wargames are generally historical, games are generally grouped into periods. These divisions mirror the scholarly divisions of history to some extent, but as certain subjects are very popular, certain "wars" are a category all by themselves. World War II, the American Civil War, and the Napoleonic Wars are the most popular historical categories, with other subjects generally being broken down as Ancients, Middle Ages, Early Gunpowder, Horse and Musket, and Modern. Note that much of history from 1800-1950 is often not reflected well in general parlance as they are overshadowed by the 'big three', games on other subjects in this era are often referred to by the actual war they deal with. Unsurprisingly the various periods and wars, especially the better known ones, are usually referred to as initials or acronyms. Thus 18th century is usually broken down into sub periods such as 'WSS' (War of Spanish Succession), 'WAS' (War of Austrian Succession), 'SYW' (Seven Years' War) and 'AWI' (American War of Independence). Some rules will take a broad brush approach, and cover a large period of time, such as 'Black Powder' which advertises as covering both 18th and 19th centuries, and have period specific sub-rules. Others concentrate purely on one war, such as 'Beneath the Lily Banners' (or BLB as it is often called) concentrates purely of the War of Spanish Succession.
Early 'modern' wargaming, as popularised by Grant and Featherstone, usually broke down the history into "Ancients", usually Biblical and Classical eras, "Horse and Musket", covering the 18th and 19th centuries, and "Modern", World War II onwards.
In the early days, wargames were either historical, or somewhat abstract. "Tactics II", the first general commercial board wargame, featured a fictional landscape with two made up countries but whose armies had capabilities based on contemporary conventional forces. Analogous to those, are the 'contemporary' games, ones that simulate current forces and postulate what an actual war involving them would be like. These were popular during the Cold War, but have faded with the fall of the Soviet Union. During the 1970s, fantasy and science fiction made themselves felt as genres that could work inside of wargames. These tend to be more varied, as different assumptions can lead to vastly different types of warfare, but there has been no real concern with subdividing the genres more closely.
Finally, wargames do not necessarily have to involve traditional concepts of warfare and battles and games can enact typical film genres such as gang battles, crime and law enforcement. Similarly martial arts or even non-combat situations and adventures can be gamed where there are other objectives that require strategy combined with the elements of chance (dice/cards etc.) to be achieved.
Notable examples.
Board versions.
While a comprehensive list will show the variety of titles, the following games are notable for the reasons indicated:
Miniature versions.
See also List of miniature wargames.

</doc>
<doc id="33108" url="http://en.wikipedia.org/wiki?curid=33108" title="Canellales">
Canellales

Canellales is the botanical name for an order of flowering plants, one of the four orders of the magnoliids. It is defined to contain two families: Canellaceae and Winteraceae, which comprise 136 species of fragrant trees and shrubs. The Canellaceae are found in tropical America and Africa, and the Winteraceae are part of the Antarctic flora (found in diverse parts of the southern hemisphere). Although the order was defined based on phylogenetic studies, a number of possible synapomorphies have been suggested, relating to the pollen tube, the seeds, the thickness of the integument, and other aspects of the morphology.
Until 1999, these two families were not considered to be closely related. Instead the Winteraceae were considered to be a primitive family (due to the structure of the xylem and carpel, a structure which now seems to be derived from xylem and carpels more typical of the angiosperms as a whole). The Canellaceae was often considered to be related to the Myristicaceae. However, studies starting in 1999, based on molecular phylogeny or morphology, have supported uniting these two families.

</doc>
<doc id="33109" url="http://en.wikipedia.org/wiki?curid=33109" title="Wearable computer">
Wearable computer

Wearable computers, also known as body-borne computers or wearables are miniature electronic devices that are worn by the bearer under, with or on top of clothing. This class of wearable technology has been developed for general or special purpose information technologies and media development. Wearable computers are especially useful for applications that require more complex computational support than just hardware coded logics.
If one is asked to give a simple, yet modern, example for wearable technology, that will be the Nike+ system which allows you to track your time, distance, pace and calories via a sensor in the shoe. Another example can be Google Glass, which combine innovative displays with some novel gestural movements for interaction.
One of the main features of a wearable computer is consistency. There is a constant interaction between the computer and user, i.e. there is no need to turn the device on or off. Another feature is the ability to multi-task. It is not necessary to stop what you are doing to use the device; it is augmented into all other actions. These devices can be incorporated by the user to act like a prosthetic. It can therefore be an extension of the user’s mind and/or body.
Many issues are common to the wearables as with mobile computing, ambient intelligence and ubiquitous computing research communities, including power management and heat dissipation, software architectures, wireless and personal area networks.
Areas of applications.
In many applications, user's skin, hands, voice, eyes, arms as well as motion or attention are actively engaged as the physical environment.
Wearable computer items have been initially developed for and applied with e.g.
and other usage also.
Today still "wearable computing" is a topic of active research, with areas of study including user interface design, augmented reality, pattern recognition. The use of wearables for specific applications or for compensating disabilities as well as supporting elderly people steadily increases.
The application of wearable computers into fashion design is evident through Microsoft's prototype of "The Printing Dress" at the International Symposium on Wearable Computers in June 2011.
History.
Due to the varied definitions of "wearable" and "computer", the first wearable computer could be as early as the first abacus on a necklace, a 16th-century abacus ring, the first wristwatch made by Breguet for the Queen of Naples in 1810, or the covert timing devices hidden in shoes to cheat at roulette by Thorp and Shannon in the 1960s and 1970s.
A computer is not merely a time-keeping or calculating device, but rather a user-programmable item for complex algorithms, interfacing, and data management. By this definition, the wearable computer was invented by Steve Mann, in the late 1970s:
 Steve Mann, a professor at the University of Toronto, was hailed as the father of the wearable computer and the ISSCC's first virtual panelist, by moderator Woodward Yang of Harvard University (Cambridge Mass.).
— IEEE ISSCC 8 Feb. 2000
The development of wearable items has taken several steps of miniaturization from discrete electronics over hybrid designs to fully integrated designs, where just one processor chip, a battery and some interface conditioning items make the whole unit.
1600s.
The Qing Dynasty saw the introduction of a fully functional abacus on a ring, which could be used while it was being worn.
1800s.
The timepiece was made by watchmaker Breguet for the Queen of Naples in 1810. It was a small ladies' pocket watch on a bracelet chain. Again, a wristwatch is a "wearable computer" in the sense that it can be worn, and that it also computes time. But it is not a general-purpose computer in the sense of the modern word.
Military use of wearables: In Girard-Perregaux made wristwatches for the German Imperial Navy after an artillery officer complained that it was not convenient to use both hands to operate a pocket watch while timing his bombardments. The officer had strapped a pocket watch onto his wrist and his superiors liked his solution, and thus asked La Chaux-de-Fonds to travel to Berlin to begin production of small pocket watches attached to wrist bracelets.
Early acceptance of wristlets by men serving in the military was not widespread, though:
 Wristlets, as they were called, were reserved for women, and considered more of a passing fad than a serious timepiece. In fact, they were held in such disdain that many a gentlemen were actually quoted to say they "would sooner wear a skirt as wear a wristwatch".
 — International Watch Magazine
1960s and 1970s.
In 1961 mathematicians Edward O. Thorp, and Claude Shannon built some computerized timing devices to help them cheat at the game of roulette. One such timer was concealed in a shoe, another in a pack of cigarettes. Various versions of this apparatus were built in the 1960s and 1970s. Detailed pictures of a shoe-based timing device can be viewed at .
Thorp refers to himself as the inventor of the first "wearable computer" In other variations, the system was a concealed cigarette-pack sized analog computer designed to predict the motion of roulette wheels. A data-taker would use microswitches hidden in his shoes to indicate the speed of the roulette wheel, and the computer would indicate an octant of the roulette wheel to bet on by sending musical tones via radio to a miniature speaker hidden in a collaborator's ear canal. The system was successfully tested in Las Vegas in June 1961, but hardware issues with the speaker wires prevented it from being used beyond test runs. This was not a wearable computer, because it could not be repurposed during use; rather it was an example of task-specific hardware. This work was kept secret until it was first mentioned in Thorp's book "Beat the Dealer" (revised ed.) in 1966 and later published in detail in 1969.
The 1970s saw the rise of similar special purpose hardware timing devices, such as roulette prediction devices using next-generation technology. In particular, a group known as Eudaemonic Enterprises used a CMOS 6502 microprocessor with 5K RAM to create a shoe computer with inductive radio communications between a data-taker and bettor.
Another early wearable system was a camera-to-tactile vest for the blind, published by C.C. Collins in 1977, that converted images into a 1024-point, 10-inch square tactile grid on a vest. On the consumer end, 1977 also saw the introduction of the HP-01 algebraic calculator watch by Hewlett-Packard.
1980s.
The 1980s saw the rise of more general-purpose wearable computers that fit the modern definition of "computer" by going beyond task-specific hardware to more general-purpose (e.g. reprogrammable by the user) devices. In 1981 Steve Mann designed and built a backpack-mounted 6502-based wearable multimedia computer with text, graphics, and multimedia capability, as well as video capability (cameras and other photographic systems). Mann went on to be an early and active researcher in the wearables field, especially known for his 1994 creation of the Wearable Wireless Webcam, the first example of Lifelogging.
Though perhaps not technically "wearable," in 1986 Steve Roberts built Winnebiko-II, a recumbent bicycle with on-board computer and chorded keyboard. Winnebiko II was the first of Steve Roberts' forays into nomadic computing that allowed him to type while riding.
1989-1999.
In 1989 Reflection Technology marketed the Private Eye head-mounted display, which scanned a vertical array of LEDs across the visual field using a vibrating mirror. This display gave rise to several hobbyist and research wearables, including Gerald "Chip" Maguire's IBM / Columbia University Student Electronic Notebook, Doug Platt's Hip-PC and Carnegie Mellon University's VuMan 1 in 1991. The Student Electronic Notebook consisted of the Private Eye, Toshiba diskless AIX notebook computers (prototypes) and a stylus based input system plus virtual keyboard, and used direct-sequence spread spectrum radio links to provide all the usual TCP/IP based services, including NFS mounted file systems and X11, all running in the Andrew Project environment. The Hip-PC included an Agenda palmtop used as a chording keyboard attached to the belt and a 1.44 megabyte floppy drive. Later versions incorporated additional equipment from Park Engineering. The system debuted at "The Lap and Palmtop Expo" on 16 April 1991. VuMan 1 was developed as part of a Summer-term course at Carnegie Mellon's Engineering Design Research Center, and was intended for viewing house blueprints. Input was through a three-button unit worn on the belt, and output was through Reflection Tech's Private Eye. The CPU was an 8 MHz 80188 processor with 0.5 MB ROM.
In 1993 the Private Eye was used in Thad Starner's wearable, based on Doug Platt's system and built from a kit from Park Enterprises, a Private Eye display on loan from Devon Sean McCullough, and the Twiddler chording keyboard made by Handykey. Many iterations later this system became the MIT "Tin Lizzy" wearable computer design, and Starner went on to become one of the founders of MIT's wearable computing project. 1993 also saw Columbia University's augmented-reality system known as KARMA: Knowledge-based Augmented Reality for Maintenance Assistance. Users would wear a Private Eye display over one eye, giving an overlay effect when the real world was viewed with both eyes open. KARMA would overlay wireframe schematics and maintenance instructions on top of whatever was being repaired. For example, graphical wireframes on top of a laser printer would explain how to change the paper tray. The system used sensors attached to objects in the physical world to determine their locations, and the entire system ran tethered from a desktop computer.
In 1994 Edgar Matias and Mike Ruicci of the University of Toronto, debuted a "wrist computer." Their system presented an alternative approach to the emerging head-up display plus chord keyboard wearable. The system was built from a modified HP 95LX palmtop computer and a Half-QWERTY one-handed keyboard. With the keyboard and display modules strapped to the operator's forearms, text could be entered by bringing the wrists together and typing. The same technology was used by IBM researchers to create the half-keyboard "belt computer. Also in 1994, Mik Lamming and Mike Flynn at Xerox EuroPARC demonstrated the Forget-Me-Not, a wearable device that would record interactions with people and devices and store this information in a database for later query. It interacted via wireless transmitters in rooms and with equipment in the area to remember who was there, who was being talked to on the telephone, and what objects were in the room, allowing queries like "Who came by my office while I was on the phone to Mark?" As with the Toronto system, Forget-Me-Not was not based on a head-mounted display.
Also in 1994, DARPA started the Smart Modules Program to develop a modular, "humionic" approach to wearable and carryable computers, with the goal of producing a variety of products including computers, radios, navigation systems and human-computer interfaces that have both military and commercial use. In July 1996 DARPA went on to host the "Wearables in 2005" workshop, bringing together industrial, university and military visionaries to work on the common theme of delivering computing to the individual. A follow-up conference was hosted by Boeing in August 1996, where plans were finalized to create a new academic conference on wearable computing. In October 1997, Carnegie Mellon University, MIT, and Georgia Tech co-hosted the IEEE International Symposium on Wearables Computers (ISWC) in Cambridge, Massachusetts. The symposium was a full academic conference with published proceedings and papers ranging from sensors and new hardware to new applications for wearable computers, with 382 people registered for the event.
2000s.
In 2002, as part of Kevin Warwick's Project Cyborg, Warwick's wife, Irena, wore a necklace which was electronically linked to Warwick's nervous system via an implanted electrode array. The color of the necklace changed between red and blue dependent on the signals on Warwick's nervous system. Dr. Bruce H Thomas and Dr. Wayne Piekarski developed the Tinmith wearable computer system to support augmented reality. This work was first published internationally in 2000 in the ISWC conference. The work was carried out at the Wearable Computer Lab in the University of South Australia.
In the late 2000s, various Chinese companies began producing mobile phones in the form of wristwatches, the descendants of which as of 2013 include the i5 and i6, which are GSM phones with 1.8 inch displays, and the ZGPAX s5 Android wristwatch phone.
2010s.
The current moves in standardization with IEEE, IETF and several industry groups (e.g. Bluetooth) leads to more various interfacing under the WPAN (wireless personal area network) and the WBAN (Wireless body area network) offer new classification of designs for interfacing and networking.
Also, the 6th-generation iPod Nano has a wristwatch attachment available to convert it to a wearable wristwatch computer.
The developments of wearable computing now encompasses Rehabilitation Engineering, Ambulatory intervention treatment, life guard systems, Defense wearable systems.
Sony is now selling an Android compatible wrist watch called Sony SmartWatch. It must be paired with an Android phone as an additional, remote display and notification tool.
Google Glass launched their optical head-mounted display (OHMD) to a test group of users in 2013, and plan on launching it to consumers sometime in 2014. Google's mission is to produce a mass-market ubiquitous computer that displays information in a smartphone-like hands-free format, that can interact with the Internet via natural language voice commands.
In September 2014, Apple announced that the company is working on a smartwatch called Apple Watch. According to the New York Times, Apple has been testing both solar and wireless charging for the upcoming product.
Commercialization.
The commercialization of general-purpose wearable computers, as led by companies such as Xybernaut, CDI and ViA, Inc. has thus far met with limited success. Publicly traded Xybernaut tried forging alliances with companies such as IBM and Sony in order to make wearable computing widely available, but in 2005 their stock was delisted and the company filed for Chapter 11 bankruptcy protection amid financial scandal and federal investigation. Xybernaut emerged from bankruptcy protection in January, 2007. ViA, Inc. filed for bankruptcy in 2001 and subsequently ceased operations. 1998 Seiko marketed the Ruputer, a computer in a (fairly large) wristwatch, to mediocre returns. In 2001 IBM developed and publicly displayed two prototypes for a wristwatch computer running Linux. The last message about them dates to , saying the device would cost about $250 but it is still under development. In 2002 Fossil, Inc. announced the Fossil Wrist PDA, which ran the Palm OS. Its release date was set for summer of 2003, but was delayed several times and was finally made available on 5 January 2005. Timex Datalink is another example of a practical wearable computer. Hitachi launched a wearable computer called Poma in 2002. Eurotech offers the ZYPAD, a wrist wearable touch screen computer with GPS, Wi-Fi and Bluetooth connectivity and which can run a number of custom applications. In 2013, a wearable computing device on the wrist to control body temperature was developed at MIT.
Evidence of weak market acceptance was demonstrated when Panasonic Computer Solutions Company's product failed. Panasonic has specialized in mobile computing with their Toughbook line for over 10 years and has extensive market research into the field of portable, wearable computing products. In 2002, Panasonic introduced a wearable brick computer coupled with a handheld or armworn touchscreen. The brick would communicate wirelessly to the screen, and concurrently the brick would communicate wirelessly out to the internet or other networks. The wearable brick was quietly pulled from the market in 2005, while the screen evolved to a thin client touchscreen used with a handstrap. (The "Brick" Computer is the CF-07 Toughbook, dual batteries, screen used same batteries as the base, 800 x 600 resolution, optional GPS and WWAN. Has one M-PCI slot and one PCMCIA slot for expansion. CPU used is a 600 MHz Pentium 3 factory under clocked to 300 MHz so it can stay cool passively as it has no fan. Micro dim ram is upgradable. The screen can be used wirelessly on other computers.)
Google has announced that it has been working on a head-mounted display-based wearable "augmented reality" device called Google Glass. An early version of the device was available to the US public from April 2013 until January 2015. Despite ending sales of the device through their Explorer Program, Google has stated that they plan to continue developing the technology.
LG and iriver produce earbud wearables measuring heart rate and other biometrics, as well as various activity metrics.
Military use.
The wearable computer was introduced to the US Army in 1989 as a small computer that was meant to assist soldiers in battle. Since then, the concept has grown to include the = Land Warrior program and proposal for future systems.<ref name=http://scholar.google.com.au/scholar?client=safari&rls=en&q=army+use+wearable+computer&oe=UTF-8&redir_esc&um=1&ie=UTF-8&lr&cites=8453139059098922145></ref> The most extensive military program in the wearables arena is the US Army's Land Warrior system, which will eventually be merged into the Future Force Warrior system.
F-INSAS is an Indian Military Project, designed largely with wearable computing.

</doc>
<doc id="33110" url="http://en.wikipedia.org/wiki?curid=33110" title="Wilhelm von Humboldt">
Wilhelm von Humboldt

Friedrich Wilhelm Christian Karl Ferdinand von Humboldt (22 June 1767 – 8 April 1835) was a Prussian philosopher, government functionary, diplomat, and founder of the Humboldt University of Berlin, which was named after him in 1949 (and also after his brother, Alexander von Humboldt, a naturalist).
He is especially remembered as a linguist who made important contributions to the philosophy of language and to the theory and practice of education. In particular, he is widely recognized as having been the architect of the Humboldtian education ideal, which was used from the beginning in Prussia as a model for its system of education and later in countries such as the United States and Japan.
His younger brother, Alexander von Humboldt, was famous as a geographer, naturalist, and explorer.
Biography.
Humboldt was born in Potsdam, Margraviate of Brandenburg, and died in Tegel, Province of Brandenburg.
In June 1791, he married Karoline von Dacheröden. They had eight children, of whom five survived to adulthood.
Philosopher.
Humboldt was a philosopher; he wrote "On the Limits of State Action" in 1791–1792 (though it was not published until 1850, after Humboldt's death), one of the boldest defences of the liberties of the Enlightenment. It influenced John Stuart Mill's essay "On Liberty" through which von Humboldt's ideas became known in the English-speaking world. Humboldt outlined an early version of what Mill would later call the "harm principle".
The section dealing with education was published in the December 1792 issue of the "Berlinische Monatsschrift" under the title "On public state education". With this publication, Humboldt took part in the philosophical debate regarding the direction of national education that was in progress in Germany, as elsewhere, after the French Revolution.
Educational reforms.
Humboldt had been home schooled and never finished his comparably short university studies.
Nevertheless, he became one of the most influential officials in German education. Actually, Humboldt had intended to become Minister of education, but failed to attain that position. The Prussian King asked him to leave Rome in 1809 and to lead the directorate of education under Friedrich Ferdinand Alexander zu Dohna-Schlobitten. Humboldt did not reply to the appointment for several weeks and would have preferred to stay on at the embassy in Rome. His wife did not return with him to Prussia; the couple met again when Humboldt stepped down from the educational post and was appointed head of the Embassy in Vienna.
Humboldt installed a standardized system of public instruction, from basic schools till secondary education, and founded Berlin University. He imposed a standardization of state examinations and inspections and created a special department within the ministry to oversee and design curricula, textbooks and learning aids.
Humboldt's plans for reforming the Prussian school system were not published until long after his death, together with his fragment of a treatise on the 'Theory of Human Education', which he had written in about 1793. Here, Humboldt states that 'the ultimate task of our existence is to give the fullest possible content to the concept of humanity in our own person […] through the impact of actions in our own lives.' This task 'can only be implemented through the links established between ourselves as individuals and the world around us' (GS, I, p. 283).
Humboldt's concept of education does not lend itself solely to individualistic interpretation. It is true that he always recognized the importance of the organization of individual life and the 'development of a wealth of individual forms' (GS, III, p. 358), but he stressed the fact that 'self-education can only be continued […] in the wider context of development of the world' (GS, VII, p. 33). In other words, the individual is not only entitled, but also obliged, to play his part in shaping the world around him.
Humboldt's educational ideal was entirely coloured by social considerations. He never believed that the 'human race could culminate in the attainment of a general perfection conceived in abstract terms'. In 1789, he wrote in his diary that 'the education of the individual requires his incorporation into society and involves his links with society at large' (GS, XIV, p. 155). In his essay on the 'Theory of Human Education', he answered the question as to the 'demands which must be made of a nation, of an age and of the human race'. 'Education, truth and virtue' must be disseminated to such an extent that the 'concept of mankind' takes on a great and dignified form in each individual (GS, I, p. 284). However, this shall be achieved personally by each individual, who must 'absorb the great mass of material offered to him by the world around him and by his inner existence, using all the possibilities of his receptiveness; he must then reshape that material with all the energies of his own activity and appropriate it to himself so as to create an interaction between his own personality and nature in a most general, active and harmonious form' (GS, II, p. 117).
In the original text from which this section has been lifted without attribution, "GS" refers to Humboldt, Wilhelm von. 1903–36. Gesammelte Schriften: Ausgabe Der Preussischen Akademie Der Wissenschaften. Bd. I—XVII, Berlin. (Cited as GS in the text, the Roman numeral indicates the volume and the Arabic figure the page; the original German spelling has been modernized.) "Gesammelte Schriften" means "Collected Writings".
Diplomat.
As a successful diplomat between 1802 and 1819, Humboldt was plenipotentiary Prussian minister at Rome from 1802, ambassador at Vienna from 1812 during the closing struggles of the Napoleonic Wars, at the congress of Prague (1813) where he was instrumental in drawing Austria to ally with Prussia and Russia against France, a signer of the peace treaty at Paris and the treaty between Prussia and defeated Saxony (1815), at Frankfurt settling post-Napoleonic Germany, and at the congress at Aachen in 1818. However, the increasingly reactionary policy of the Prussian government made him give up political life in 1819; and from that time forward he devoted himself solely to literature and study.
Linguist.
Wilhelm von Humboldt was an adept linguist and studied the Basque language. He translated Pindar and Aeschylus into German.
Humboldt's work as a philologist in Basque has had more extensive impact than his other work. His visit to the Basque country resulted in "Researches into the Early Inhabitants of Spain by the help of the Basque language" (1821). In this work, Humboldt endeavored to show by examining geographical placenames, that at one time a race or races speaking dialects allied to modern Basque extended throughout Spain, southern France and the Balearic Islands; he identified these people with the "Iberians" of classical writers, and further surmised that they had been allied with the Berbers of northern Africa. Humboldt's pioneering work has been superseded in its details by modern linguistics and archaeology, but is sometimes still uncritically followed even today. He was elected a Foreign Honorary Member of the American Academy of Arts and Sciences in 1822.
Humboldt died while preparing his greatest work, on the ancient Kawi language of Java, but its introduction was published in 1836 as "The Heterogeneity of Language and its Influence on the Intellectual Development of Mankind". This essay on the philosophy of speech:
He is credited with being the first European linguist to identify human language as a rule-governed system, rather than just a collection of words and phrases paired with meanings. This idea is one of the foundations of Noam Chomsky's theory of language. Chomsky frequently quotes Humboldt's description of language as a system which "makes infinite use of finite means", meaning that an infinite number of sentences can be created using a finite number of grammatical rules. Humboldt scholar Tilman Borsche, however, notes profound differences between von Humboldt's view of language and Chomsky's.
More recently, Humboldt has also been credited as an originator of the linguistic relativity hypothesis (more commonly known as the Sapir–Whorf hypothesis), developed by linguists Edward Sapir or Benjamin Whorf a century later.
The reception of Humboldt's work remains problematic in English-speaking countries, despite the work of Langham Brown, Manchester and Underhill (Humboldt, Worldview & Language, 2009), on account of his concept of what he called "Weltansicht", the linguistic worldview, with "Weltanschauung" being translated simply as 'worldview' a term associated with ideologies and cultural mindsets in both German and English. The centrality of distinction in understanding Huimbolt's work was set out by one of the leading contemporary German Humboldt scholars, Jürgen Trabant, in his works in both German and French. Polish linguists, at the Lublin School (see Jerzy Bartmiński) in their research of Humboldt, also stress this distinction between the worldviews of a personal or political kind and the worldview that is implicit in language as a conceptual system.
However, little rigorous research in English has gone into exploring the relationship between the linguistic worldview and the transformation and maintenance of this worldview by individual speakers. One notable exception is the work of Underhill, who explores comparative linguistic studies in both "Creating Worldviews: Language", "Ideology & Metaphor" (2011) and in "Ethnolinguistics and Cultural Concepts: Truth, Love, Hate & War". In Underhill's work, a distinction is made between five forms of worldview: world-perceiving, world-conceiving, cultural mindset, personal world and perspective, in order to convey the distinctions Humboldt was concerned with preserving in his ethnolinguistics. Probably the most well-known linguist working with a truly Humboldtian perspective writing in English today is Anna Wierzbicka, who has published a number of comparative works on semantic universals and conceptual distinctions in language.
The Rouen Ethnolinguistics Project, in France, has recently put online a 7-hour series of lectures on Humblodt's thought on language, with the Berlin specialist, Prof. Trabant
THE JURGEN TRABANT WILHELM VON HUMBOLDT LECTURES
https://webtv.univ-rouen.fr/permalink/c1253a18f7e5ecnge8dp/ 
Trabant's lectures take viewers into Humboldt with a very gentle introduction, and then get down to the deeper questions of worldview, concept-formation, translation, and the work of the mind.

</doc>
<doc id="33111" url="http://en.wikipedia.org/wiki?curid=33111" title="World War I casualties">
World War I casualties

The total number of military and civilian casualties in World War I was over 37 million: over 16 million deaths and 20 million wounded, ranking it among the deadliest conflicts in human history.
The total number of deaths includes about 10 million military personnel and about 7 million civilians. The Entente Powers (also known as the Allies) lost about 6 million military personnel while the Central Powers lost about 4 million. At least 2 million died from diseases and 6 million went missing, presumed dead. This article lists the casualties of the belligerent powers based on official published sources.
About two-thirds of military deaths in World War I were in battle, unlike the conflicts that took place in the 19th century when the majority of deaths were due to disease. Nevertheless, disease, including the Spanish flu and deaths while held as prisoners of war, still caused about one third of total military deaths for all belligerents.
Classification of casualty statistics.
Casualty statistics for World War I vary to a great extent; estimates of total deaths range from 9 million to over 15 million.Military casualties reported in official sources list deaths due to all causes, including an estimated 7 to 8 million combat related deaths (killed or died of wounds) and another two to three million military deaths caused by accidents, disease and deaths while prisoners of war. Official government reports listing casualty statistics were published by the United States and Great Britain. These secondary sources published during the 1920s, are the source of the statistics in reference works listing casualties in World War One. This article summarizes the casualty statistics published in the official government reports of the United States and Great Britain as well as France, Italy, Belgium, Germany, Austria and Russia. More recently the research of the Commonwealth War Graves Commission (CWGC) has revised the military casualty statistics of the U.K. and its allies; they include in their listing of military war dead personnel outside of combat theaters and civilians recruited from Africa, the Middle East and the China who provided logistical and service support in combat theaters. The casualties of these support personnel recruited outside of Europe were previously not included with British war dead, however the casualties of the Labour Corps recruited from the British Isles were included in the rolls of British war dead published in 1921. The methodology used by each nation to record and classify casualties was not uniform, a general caveat regarding casualty figures is that they cannot be considered comparable in all cases.<br>First World War civilian deaths are "hazardous to estimate" according to Michael Clodfelter who maintains that "the generally accepted figure of noncombatant deaths is 6.5 million." The figures listed below include about 6 million excess civilian deaths due to war related privations, that are often omitted from other compilations of World War I casualties. The war brought about malnutrition and disease caused by the U-boat Campaign and the Blockade of Germany which disrupted trade resulting in food shortages. The civilian deaths in the Ottoman Empire include the Armenian Genocide, Assyrian Genocide and Greek Genocide. Civilian deaths due to the Spanish flu have been excluded from these figures, whenever possible. The figures do not include deaths during the Turkish War of Independence and the Russian Civil War.
Casualties by 1924 Post War Borders.
The war involved multi-ethnic empires such as Great Britain, France, Germany, Russia, Austro-Hungary and Turkey. Many diverse ethnic groups in these multi-ethnic empires were conscripted for military service. The casualties listed by modern borders are also included in the above table of figures for the countries that existed in 1914. The casualty figures by 1924 post war borders are rough estimates by Russian journalist in a 2004 handbook of human losses in the 20th century, the sources of his figures were published in the Soviet era and in post-Soviet Russia.
The following estimates of Austrian deaths, within contemporary borders, were made by a Russian journalist in a 2004 handbook of human losses in the 20th century. Total dead 175,000: including military losses 120,000 with the Austo-Hungarian forces and POW deaths in captivity of 30,000. Civilian dead due to famine and disease were 25,000.
The Belgian Congo was part of the Kingdom of Belgium during the war. A Russian journalist Vadim Erlikman in a 2004 handbook of human losses in the 20th century based on sources published in the Soviet Union and Russia estimated a total of 155,000 deaths in the Belgian Congo during the war.
Czechoslovakia was part of Austro-Hungary during the war. The estimates of Czechoslovak deaths within 1991 borders were made by a Russian journalist in a 2004 handbook of human losses in the 20th century. Total dead 185,000: including military losses 110,000 with the Austro-Hungarian forces and POW deaths in captivity of 45,000. Civilian dead due to famine and disease were 30,000. The Czechoslovak Legions fought with the armies of the Allies during the war.
Estonia was part of the Russian Empire during the war and about 100,000 Estonians served in the Russian Army. Of them about 10,000 were killed.
From 1809 Finland was an autonomous Grand Duchy in the Russian Empire until the end of 1917. In 1924 the Finnish government in a reply to a questionnaire from the International Labour Office, an agency of the League of Nations, reported 26,517 were dead and missing in World War I.
The following estimates of deaths, within contemporary borders, during World War I were made by a Russian journalist Vadim Erlikman in a 2004 handbook of human losses in the 20th century. Erlikman's estimates are based on sources published in the Soviet Union and Russia.
The following estimates of deaths, within contemporary borders, during World War I were made by a Russian journalist Vadim Erlikman in a 2004 handbook of human losses in the 20th century. Erlikman's estimates are based on sources published in the Soviet Union and Russia.
The following estimates of Hungarian deaths, within contemporary borders, during World War I were made by a Russian journalist in a 2004 handbook of human losses in the 20th century. Total dead 385,000: including military losses 270,000 with the Austro-Hungarian forces and POW deaths in captivity of 70,000. Civilian dead due to famine and disease were 45,000.
Ireland was a part of the UK during World War I. Five sixths of the island left to form the Irish Free State, now the Republic of Ireland, in 1922. A total of 206,000 Irishmen served in the British forces during the war. The number of Irish deaths in the British Army recorded by the registrar general was 27,405. A significant number of these casualties were from what, in 1920, became Northern Ireland. While 49,400 soldiers died serving in Irish divisions (the 10th, 16th and 36th), although not all of the men serving in these divisions were natives of Ireland and many Irish who died in non-Irish regiments are not listed. For example, 29% of the casualties in the 16th Division were not natives of Ireland. Neither does it include Irish emigrants in Britain who enlisted there and are not categorised as Irish. Australia lists 4,731 of its first World War soldiers as having been born in Ireland and more than 19,000 Irish-born soldiers served in the Canadian Corps. The rolls do list 30,986 soldiers who were born in Ireland. Prof John Horne of Trinity College Dublin says a figure of between 30,000 and 35,000 Irish war dead is a “conservative" estimate and one likely to rise.
The losses of Portuguese Mozambique were estimated by a Russian journalist Vadim Erlikman in a 2004 handbook of human losses in the 20th century. Erlikman's estimates are based on sources published in the Soviet Union and Russia. 52,000
Poland was an annexed territory of Germany, Austria-Hungary and Russia, from 1795–1918. By late 1915, Germany had complete control over modern-day Poland. A 2005 Polish study estimated 3,376,800 Poles were conscripted into the armed forces of the occupying powers during World War I, an additional 300,000 were conscripted for forced labor by the Germans. The Russians and Austrians forcibly resettled 1.6 to 1.8 million persons from the war zone in Poland. According to Michael Clodfelter, Polish war dead were 1,080,000 and 200,000 Polish civilians were killed in the fighting on the Eastern Front; 870,000 men served in the German, Austrian and Russian armies. Another estimate made by a Russian journalist in a 2004 handbook of human losses in the 20th century, put total Polish war dead at 640,000, including military losses of 270,000 Poles conscripted, civilian losses of 120,000 due to military operations and 250,000 caused by famine and disease. The ethnic Polish Blue Army served with the French Army. The ethnic Polish Legions fought as part of the Austro-Hungarian Army on the Eastern Front.
The territory of Transylvania was part of Austria-Hungary during World War I. The following estimates of Romanian deaths, within contemporary borders, during World War I were made by a Russian journalist in a 2004 handbook of human losses in the 20th century. Total dead: 748,000, including military losses of 220,000 with the Romanian forces, 150,000 with the Austro-Hungarian forces and POW deaths in captivity of 48,000. Civilian dead were as follows due to famine and disease: 200,000, killed in military operations 120,000 and 10,000 dead in Austrian prisons.
Britain recruited Indian, Chinese, native South African, Egyptian and other overseas labour to provide logistical support in the combat theatres. Included with British casualties in East Africa are the deaths of 44,911 recruited labourers. The CWGC reports that nearly 2,000 workers from the Chinese Labour Corps are buried with British war dead in France.
The following estimates of British Empire colonial military deaths, within contemporary borders, during World War I were made by a Russian journalist Vadim Erlikman in a 2004 handbook of human losses in the 20th century. Erlikman's estimates are based on sources published in the Soviet Union and Russia. 
The following estimates are for Yugoslavia within the 1991 borders.
Slovenia, Croatia, Bosnia and Vojvodina (Now part of Serbia) were part of Austria-Hungary during World War I. Serbia, which included Macedonia, and Montenegro were independent nations. The Yugoslav historian Vladimir Dedijer put the total losses of the Yugoslav lands at 1.9 million, of which 43% were from Serbia. The following estimates of Yugoslav deaths, within 1991 borders, during World War I were made by a Russian journalist in a 2004 handbook of human losses in the 20th century. Total dead: 996,000 including military losses, 260,000 with the Serbian forces, 80,000 with the Austro-Hungarian forces, 13,000 with Montenegrin forces and POW deaths in captivity of 93,000. Civilian dead were as follows due to famine and disease: 400,000, killed in military operations: 120,000 and 30,000 dead in Austrian prisons or executed.
During WW1, the Nepalese army was expanded and six new regiments, totaling more than 20,000 troops—all volunteers—were sent to India, most of them to the North-West Frontier Province, to release British and Indian troops for service overseas. Simultaneously, the Nepalese government agreed to maintain recruitment at a level that would sustain the existing British Gurkha units and allow the establishment of additional ones. The battalions were increased to thirty-three with the addition of 55,000 new recruits and Gurkha units were placed at the disposal of the British high command for service on all fronts. Many volunteers were assigned to non-combat units, such as the Army Bearer Corps and the labour battalions but they also were in combat in France, Turkey, Palestine and Mesopotamia. The Rana prime ministers urged Nepalese males to fight in the war. Of the more than 200,000 Nepalese who served in the British army, there were some 20,000 Gurkha casualties included above with the British Indian Army.
Footnotes.
^a East Africa
^b Australia
^c Belgium:
^d Canada
^e France
^f Greece
^g India (British)
^h Italy
^i Japan
^k Montenegro:
^l New Zealand:
^m Newfoundland
^n Portugal:
^o Romania:
^p Russian Empire
^q Serbia
^r South Africa
^s United Kingdom
^t United States
^u Austria-Hungary
^v Bulgaria:
^w German Empire
^x Ottoman Empire:
^y Denmark
^j Luxembourg
^z Norway
^az Sweden
Sources.
The source of population data is:
Further reading.
</dl>

</doc>
<doc id="33112" url="http://en.wikipedia.org/wiki?curid=33112" title="World War I reparations">
World War I reparations

World War I reparations were compensation imposed during the Paris Peace Conference upon the Central Powers following their defeat in the First World War by the Allied and Associate Powers. Each of the defeated powers was required to make payments in either cash or kind. Because of the financial situation Austria, Hungary, and Turkey found themselves in after the war, few to no reparations were paid and the requirements for reparations were cancelled. Bulgaria, having paid only a fraction of what was required, saw her reparation figure reduced and then cancelled. Historians have recognized the German requirement to pay reparations as the "chief battleground of the post-war era" and "the focus of the power struggle between France and Germany over whether the Versailles Treaty was to be enforced or revised".
The Treaty of Versailles and the 1921 London Schedule of Payments required Germany to pay 132 billion gold marks (US$) in reparations to cover civilian damage caused during the war. This figure was divided into three categories of bonds: A, B, and C. Of these, Germany was only required to pay towards 'A' and 'B' bonds totalling 50 billion marks (US$). The remaining 'C' bonds, which Germany did not have to pay, were designed to deceive the Anglo-French public into believing Germany was being heavily fined and punished for the war.
Because of the lack of reparation payments by Germany, France occupied the Ruhr in 1923 to enforce payments, causing an international crisis that resulted in the implementation of the Dawes Plan in 1924. This plan outlined a new payment method and raised international loans to help Germany to meet her reparation commitments. Despite this, by 1928 Germany called for a new payment plan, resulting in the Young Plan that established the German reparation requirements at 112 billion marks (US$) and created a schedule of payments that would see Germany complete payments by 1988. With the collapse of the German economy in 1931, reparations were suspended for a year and in 1932 during the Lausanne Conference they were cancelled altogether. Between 1919 and 1932, Germany paid less than 21 billion marks in reparations.
The German people saw reparations as a national humiliation; the German Government worked to undermine the validity of the Treaty of Versailles and the requirement to pay. British economist John Maynard Keynes called the treaty a Carthaginian peace that would economically destroy Germany. His arguments had a profound effect on historians, politicians, and the public at large. Despite Keynes' arguments and those by later historians supporting or reinforcing Keynes' views, the consensus of contemporary historians is that reparations were not as intolerable as the Germans or Keynes had suggested and were within Germany's capacity to pay had there been the political will to do so.
Background.
In 1914, the First World War broke out and the next four years, fighting raged across Europe, the Middle East, Africa, and Asia. On 8 January 1918, United States President Woodrow Wilson issued a statement that became known as the Fourteen Points. In part, this speech called for Germany to withdraw from the territory it had occupied and for the formation of a League of Nations. During the fourth quarter of 1918, the Central Powers began to collapse. In particular, the German military was decisively defeated on the Western Front and the German navy mutinied, prompting domestic uprisings that became known as the German Revolution
Most of the war's major battles occurred in France and the French countryside was heavily scarred in the fighting. Furthermore, in 1918 during the German retreat, German troops devastated France's most industrialized region in the north-east. Extensive looting took place as German forces removed whatever material they could use and destroyed the rest. Hundreds of mines were destroyed along with railways, bridges, and entire villages. Prime Minister of France Georges Clemenceau was determined, for these reasons, that any just peace required Germany to pay reparations for the damage it had caused. Clemenceau viewed reparations as a way of weakening Germany to ensure it could never threaten France again. Reparations would also go towards the reconstruction costs in other countries, including Belgium, which was also directly affected by the war. British Prime Minister David Lloyd George opposed harsh reparations, arguing for a smaller sum that was less damaging to the German economy so that Germany could remain a viable economic power and trading partner. He also argued that reparations should include war pensions for disabled veterans and allowances for war widows, which would reserve a larger share of the reparations for the British Empire. Wilson opposed these positions and was adamant that no indemnity was imposed upon Germany.
The Paris Peace Conference opened on 18 January 1919, aiming to establish a lasting peace between the Allied and Central Powers. Demanding compensation from the defeated party was a common feature of peace treaties. However, the financial terms of treaties signed during the peace conference were labelled reparations to distinguish them from punitive settlements usually known as indemnities, which were intended for reconstruction and compensating families who had been bereaved by the war. The opening article of the reparation section of the Treaty of Versailles, Article 231, served as a legal basis for the following articles, which obliged Germany to pay compensation and limited German responsibility to civilian damages. The same article, with the signatory's name changed, was also included in the treaties signed by Germany's allies.
German reaction.
In February 1919, Foreign Minister Count Ulrich von Brockdorff-Rantzau informed the Weimar National Assembly that Germany would have to pay reparations for the devastation caused by the war, but would not pay for actual war costs. After the drafting of the Treaty of Versailles on 7 May that year, the German and Allied delegations met and the treaty was handed over to be translated and for a response to be issued. At this meeting Brockdorff-Rantzau stated, "We know the intensity of the hatred which meets us, and we have heard the victors' passionate demand that as the vanquished we shall be made to pay, and as the guilty we shall be punished". However, he proceeded to deny that Germany was solely responsible for the war.
Article 231 of the Treaty of Versailles was not correctly translated. Instead of stating "... Germany accepts responsibility of Germany and her allies causing all the loss and damage ...", the German Government's edition reads, "Germany admits it, that Germany and her allies, as authors of the war, are responsible for all losses and damages ...". This resulted in a prevailing belief of humiliation among Germans; the article was seen as an injustice and there was a view that Germany had signed "away her honor". Despite the public outrage, German government officials were aware "that Germany's position on this matter was not nearly so favorable as the imperial government had led the German public to believe during the war". Politicians seeking international sympathy would continue to use the article for its propaganda value, persuading many who had not read the treaties that the article implied full war guilt. German revisionist historians who later tried to ignore the validity of the clause found a ready audience among revisionist writers in France, Britain, and the USA. The objective of both the politicians and historians was to prove that Germany was not solely guilty for causing the war; if that guilt could be disproved the legal requirement to pay reparations would disappear.
Evolution of reparations.
Initial demands.
The Treaty of Versailles stated that a Reparation Commission would be established in 1921. This commission would consider the resources available to Germany and her capacity to pay, provide the German Government with an opportunity to be heard on the subject, and decide on the final reparation figure that Germany would be required to pay. In the interim, Germany was required to pay an equivalent of 20 billion gold marks (US$) in gold, commodities, ships, securities, or other forms. The money would be used to pay Allied occupation costs and to buy food and raw materials for Germany. Article 121 of the Treaty of Neuilly acknowledged that "the resources of Bulgaria are not sufficient to enable her to make complete reparation". Therefore, the treaty required Bulgaria to pay a sum equivalent of 2.250 billion Gold francs in reparations.
The treaties of Saint-Germain-en-Laye, Trianon, and Sèvres acknowledged that Austria, Hungary, and Turkey did not have the resources to pay reparations, and delayed the establishment of a final figure until the Reparation Commission was established. In addition, Bulgaria was required to hand over thousands of livestock to Greece, Romania, and the Serb-Croat-Slovene State "in restitution for animals taken away by Bulgaria during the war". This would not be credited towards the reparation figure. Likewise, Bulgaria had to dispatch 50,000 tons of coal a year to the Serb-Croat-Slovene State in restitution for destroyed mines. These shipments would not be credited against Bulgaria's reparation sum. Germany, Austria, and Hungary all had commitments to handover timber, ore, and livestock to the Allied Powers. They would, however, be credited for these goods.
In January 1921, the Allied Powers grew impatient and established the reparation sum at 226 billion gold marks. The Germans countered with an offer of 30 billion. On 24 April 1921, the German Government wrote to the American Government expressing "her readiness to acknowledge for reparation purposes a total liability of 50 billion gold marks", but was also prepared "to pay the equivalent of this sum in annuities adapted to her economic capacity totalling 200 billion gold marks". In addition, the German Government stated that "to accelerate the redemption of the balance" and "to combat misery and hatred created by the war", Germany was willing to provide the resources needed and "to undertake herself the rebuilding of townships, villages, and hamlets".
London Schedule of Payments.
The London Schedule of Payments of 5 May 1921 established "the full liability of all the Central Powers combined, not just Germany alone," at 132 billion gold marks. This sum was a compromise promoted by Belgium—against higher figures demanded by the French and Italians and the lower figure the British supported—that "represented an assessment of the lowest amount that public opinion ... would tolerate".
This figure was divided into three series of bonds: "A" and "B" Bonds together had a nominal value of 50 billion gold marks (US$—less than the sum Germany had previously offered to pay. "C" Bonds, comprising the remainder of the reparation figure, "were deliberately designed to be chimerical." They were "a political bargaining chip" that served the domestic policies of France and the United Kingdom. The figure was completely unreal; its primary function was to mislead public opinion "into believing that the 132-billion-mark figure was being maintained". Furthermore, "Allied experts knew that Germany could not pay 132 billion marks and that the other Central Powers could pay little. Thus the A and B Bonds, which were genuine, represented the actual Allied assessment of German capacity to pay." Taking into account the sum already paid between 1919 and 1921, Germany's immediate obligation was 41 billion gold marks.
To pay towards this sum, Germany could pay in kind or in cash. Commodities paid in kind included coal, timber, chemical dyes, pharmaceuticals, livestock, agricultural machines, construction materials, and factory machinery. The gold value of these would be deducted from Germany was required to pay. Germany's assistance with the restoration of the university library of Louvain, which was destroyed by the Germans on 25 August 1914, was also credited towards the sum, as were some of the territorial changes the treaty imposed upon Germany. The payment schedule required US$ within twenty-five days and then US$ annually, plus 26 per cent of the value of German exports. The German Government was to issue bonds at five per cent interest and set up a sinking fund of one per cent to support the payment of reparations.
End of reparations for Austria, Bulgaria, Hungary, and Turkey.
Between the signing of the Treaty of Neuilly-sur-Seine and April 1922, Bulgaria paid 173 million gold francs in reparations. In 1923, the Bulgarian reparation sum was revised downwards to 550 million gold francs, "plus a lump sum payment of 25 million francs for occupation costs". Towards this figure, Bulgaria paid 41 million gold francs between 1925 and 1929. In 1932, the Bulgarian reparation obligation was abandoned following the Lausanne Conference.
Because Austria was "so impoverished" after the war, and because of the collapse of the Bank of Vienna, the country paid no reparations "beyond credits for transferred property". Likewise, Hungary paid no reparations beyond coal deliveries because of the collapse of the Hungarian economy. Turkish reparations had been "sharply limited in view of the magnitude of Turkish territorial losses". However, the Treaty of Sèvres was never ratified. When the Treaty of Lausanne was signed in 1923, Turkish reparations were "eliminated altogether".
German defaults.
From the initiation of reparations, German coal deliveries were below the level agreed. In an attempt to rectify this situation, the Spa Conference was held in July 1920. At this conference it was decided that Germany would be paid five marks per coal ton delivered to facilitate coal shipments and help feed the miners. Despite this, Germany continued to default on her obligations. By late 1922, the German defaults on payments had grown so serious and regular that a crisis engulfed the Reparations Commission. French and Belgian delegates urged the seizure of the Ruhr to encourage the Germans to make more effort to pay, while the British supported postponing payments to facilitate the financial reconstruction of Germany. On 26 December 1922, Germany defaulted on timber deliveries. The timber quota was based upon a German proposal and the default was massive. The Allies were unanimous that the default was in bad faith. In January 1923, despite quota reductions, the German Government defaulted on coal deliveries for the 34th time in three years following the loss of the Upper Silesian coal fields containing 11 per cent of German coal resources, which had been transferred to Poland.
On 9 January 1923, the Reparation Commission declared Germany to be in default of her coal deliveries and voted to occupy the Ruhr to enforce the country's reparation commitments. Britain was the lone dissenting voice to both measures. On 11 January, French and Belgian soldiers—supported by engineers including an Italian contingent—entered the region, initiating the Occupation of the Ruhr.
The French Premier Raymond Poincaré was deeply reluctant to order the occupation and had only taken this step after the British had rejected his proposals for more moderate sanctions against Germany. By December 1922, Poincaré was faced with Anglo-American-German hostility; coal supplies for French steel production were running low. Exasperated with Britain's failure to act, he wrote to the French ambassador in London:
Judging others by themselves, the English, who are blinded by their loyalty, have always thought that the Germans did not abide by their pledges inscribed in the Versailles Treaty because they had not frankly agreed to them ... We, on the contrary, believe that if Germany, far from making the slightest effort to carry out the treaty of peace, has always tried to escape her obligations, it is because until now she has not been convinced of her defeat ... We are also certain that Germany, as a nation, resigns herself to keep her pledged word only under the impact of necessity.
The occupation proved marginally profitable; the occupying powers received 900 million gold marks, and much of this merely covered the military costs of occupation. However, the real issue behind the occupation was not German defaults on coal and timber deliveries, but the forcing of Germany "to acknowledge her defeat in World War I and to accept the Versailles Treaty". Poincaré recognized that if Germany could get away with defying Versailles in regard to the reparations, a precedent would be created and inevitably the Germans would proceed to dismantle the rest of the Versailles treaty.
Dawes Plan.
Although the French succeeded in their objective during the Ruhr occupation, the Germans had wrecked their economy by funding passive resistance and brought about hyperinflation. Under Anglo-American pressure and simultaneous decline in the value of the franc, France was increasingly isolated and her diplomatic position was weakened. In October 1923, a committee consisting of American, Belgian, British, French, German, and Italian experts and chaired by the former Director of the US Bureau of the Budget Charles G. Dawes was formed to consider "from a purely technical standpoint" how to balance the German budget, stabilize the economy and set an achievable level of reparations.
In April 1924, the Dawes Plan was accepted and it replaced the London schedule of payment. While the "C" Bonds were omitted from the plan's framework, they were not formally rescinded. French troops were to withdraw from the Ruhr, a bank independent of the German Government with a ruling body at least 50 per cent non-German was to be established, and the German currency was to be stabilized. The payment of reparations was also reorganized. In the first year following the implementation of the plan, Germany would have to pay 1 billion marks. This figure would rise to 2.5 billion marks per year by the fifth year of the plan. A Reparations Agency was established with Allied representatives to organize the payment of reparations. Furthermore, a loan of 800 million marks was to be raised—over 50 per cent coming from the United States, 25 per cent from Britain, and the balance from other European nations—to back the German currency and to aid in the payment of reparations.
Young Plan.
Under the Dawes Plan, Germany always met her obligations. However, they considered the plan a temporary measure and expected a revised plan at a future date. In late 1927, the Agent-General for Reparations "called for a more permanent scheme" for payments and in 1928 the Germans followed suit. German Foreign Minister Gustav Stresemann called for a final reparation plan to be established alongside an early withdrawal of Allied troops from the Rhineland. The French, aware of their weakening political and financial position, acquiesced. On 16 September 1928, a joint Entente-German statement acknowledging the need for a new reparation plan was issued.
In February 1929, a new committee was formed to re-examine reparations. It was chaired by the American banker Owen D. Young and presented its findings in June 1929. The "Young Plan" was accepted and was ratified by the German Government on 12 March 1930. The plan established a theoretical final reparation figure at 112 billion gold marks (US$), with a new payment schedule that would see reparations completed by 1988—the first time a final date had been set. In addition, foreign oversight of German finances was to end with the withdrawal of the Reparations Agency, which would be replaced by the Bank for International Settlements. The bank was established to provide cooperation among central banks and to receive and disburse reparation payments. A further loan of US$ was to be raised and given to Germany.
As a result of the plan, German payments were half the sum required under the Dawes Plan. The implementation of the Young Plan required the Anglo-French withdrawal from the Rhineland within months. Despite the reduction, there was increasing German hostility to the plan. In December 1929, 5.8 million voters registered their opposition to the plan during a plebiscite, which resulted in Adolf Hitler gaining "significant national attention and valuable right-wing financing".
End of German reparations.
In March 1930, the German Government collapsed and was replaced by a new coalition led by Chancellor Heinrich Brüning. In June, Allied troops withdrew from near Mainz—the last occupation zone in the Rhineland—and Brüning's Government broached the subject of demanding further refinement to reparations, but this demand was refused by William Tyrrell, the British ambassador to France. During 1931, a financial crisis began in Germany. In May, Creditanstalt—the largest bank in Austria—collapsed, sparking a banking crisis in Germany and Austria. In response, Brüning announced that Germany was suspending reparation payments. This resulted in a massive withdrawal of domestic and foreign funds from German banks. By mid-July, all German banks had closed. Until this point, France's policy had been to provide Germany with financial support to help Brüning's Government stabilize the country. Brüning, now under considerable political pressure from the far-right and President Paul von Hindenburg, was unable to make any concessions or reverse policy. As a result, Brüning was unable to borrow money from foreign or domestic sources. Further attempts to enlist British support to end reparations failed; the British said it was a joint issue with France and the United States. In early July, Brüning announced "his intention to seek the outright revision of the Young Plan". In light of the crisis and with the prospect of Germany being unable to repay her debts, United States President Herbert Hoover intervened. In June, Hoover publicly proposed a one-year moratorium to reparation and war debts. By July, the "Hoover Moratorium" had been accepted.
The moratorium was widely supported in both Germany and the United Kingdom. The French, initially hesitant, eventually agreed to support the American proposal. However, on 13 July, the German Darmstädter Bank collapsed, leading to further bankruptcies and a rise in unemployment further exacerbating Germany's financial crisis. With the Great Depression now exerting its influence, the Bank for International Settlements reported that the Young Plan was unrealistic in light of the economic crisis and urged the world governments to reach a new settlement on the various debts they owed each other. During January 1932, Brüning said he would seek the complete cancellation of reparations. His position was supported by the British and Italians, and opposed by the French.
Because of the political differences between countries on the subject and impending elections in France and Germany, a conference could not be established until June. This delay brought about the downfall of Brüning's Government. On 16 June, the Lausanne Conference opened. However, discussions were complicated by the ongoing World Disarmament Conference. At the latter conference, the US informed the British and French that they would not be allowed to default on their war debts. In turn, they recommended that war debts be tied into German reparation payments, to which the Germans objected. On 9 July, an agreement was reached and signed. The Lausanne Conference annulled the Young Plan and required Germany to pay a final, single installment of 3 billion marks to save France from political humiliation and ending Germany's obligation to pay reparations.
Amount paid by Germany.
The precise figure Germany paid is a matter of dispute. The German Government estimated it had paid the equivalent of 67.8 billion gold marks in reparations. The German figure included—other than gold or goods in kind—the scuttling of the interned German fleet at Scapa Flow, state property lost in lands ceded to other countries, and the loss of colonial territories. The Reparation Commission and the Bank for International Settlements state that 20.598 billon gold marks was paid by Germany in reparations, of which 7.595 billon was paid before the implementation of the London Schedule of Payments. Niall Ferguson provides a slightly lower figure. He estimates that Germany paid no more than 19 billion gold marks. Ferguson further estimates that this sum amounted to 2.4 per cent of Germany's national income between 1919 and 1932. Stephen Schuker, in his definitive econometric study (1988, pp. 106–19), concedes that Germany transferred 16.8 billion marks over the whole period, but points out that this sum was vastly offset by the devaluation of Allied paper-mark deposits up to 1923, and by loans that Germany subsequently repudiated after 1924. The net capital transfer into Germany amounted to 17.75 billion marks, or 2.1% of Germany's entire national income over the period 1919-1931. In effect, therefore, America paid reparations to Germany—four times more, in price-adjusted terms, than the U.S. furnished to West Germany under the post-1948 Marshall Plan. According to Gerhard Weinberg, reparations were paid, towns were rebuilt, orchards replanted, mines reopened and pensions paid. However, the burden of repairs was shifted away from the German economy and onto the damaged economies of the war's victors.
Loan payments.
To help make reparations payments, Germany took out various loans during the 1920s. In 1933, following the cancellation of reparations, the new German Chancellor Adolf Hitler cancelled all payments. In June 1953, an agreement on this existing debt was reached with West Germany, which agreed to make symbolic token payments against the loans that had been defaulted on in the 1920s, but deferred some of the debt until West and East Germany were unified. In 1995, following reunification, Germany began making the final payments towards the loans. A final installment of US$ was made on 3 October 2010, settling German loan debts in regard to reparations.
Analysis.
Impact on the German economy.
Overall.
During the period of reparations, Germany received between 27 and 38 billion marks in loans. By 1931, German foreign debt stood at 21.514 billion marks; the main sources of aid were the United States, Britain, the Netherlands, and Switzerland. According to Detlev Peukert, the financial problems that arose in the early 1920s were a result of post-war loans and the way Germany funded her war effort, and were not the fault of reparations. During World War I, Germany did not raise taxes or create new ones to pay for war-time expenses. Rather, loans were taken out, placing Germany in an economically precarious position as more money entered circulation, destroying the link between paper money and the gold reserve that had been maintained before the war. With its defeat, Germany could not impose reparations and pay off her war debts now, which were now colossal.
Niall Ferguson partially supports this analysis. He says that had reparations not been imposed, Germany would still have had significant problems caused by the need to pay war debts and the demands of voters for more social services. Ferguson also says that these problems were aggravated by a trade deficit and a weak exchange rate for the mark during 1920. Afterwards, as the value of the mark rose, inflation became a problem. None of these, he says, were the result of reparations. Ferguson says that even without reparations, total public spending in Germany between 1920 and 1923 was 33 per cent of total net national product. A.J.P. Taylor says, "Germany was a net gainer by the financial transactions of the nineteen-twenties: she borrowed far more from private American investors ... than she paid in reparations". P.M.H. Bell says the creation of a multi-national committee, which resulted in the Dawes Plan, was done to consider ways the German budget could be balanced, the currency stabilized, and the German economy fixed to ease reparation payments. Max Winkler says that from 1924 onward, German officials were "virtually flooded with loan offers by foreigners". Overall, he says, the German economy performed reasonably well until the foreign investments funding the economy and the loans funding reparations payments were suddenly withdrawn after the 1929 Stock Market Crash. This collapse was magnified by the volume of loans provided to German companies by US lenders. Even the reduced payments of the Dawes Plan were mainly financed through a large volume of international loans.
While Germany initially had a trade deficit, British policy during the early 1920s was to reintegrate Germany into European trade as soon as possible. Likewise, France attempted to secure trade deals with Germany. During the mid-to-late 1920s, trade between France and Germany grew rapidly. French imports of German goods "increased by 60 per cent", highlighting the close links between French industrial growth and German production, and the increase in cooperation between the countries.
Max Hantke and Mark Spoerer provide a different perspective on the effect of reparations on the German economy. They say that focusing on the reparations and inflation ignores "the fact that the restriction of the German military to 115,000 men relieved the German central budget considerably". Hantke and Spoerer also say that their findings show "that even under quite rigorous assumptions the net economic burden of the Treaty of Versailles was much less heavy than has been hitherto thought, in particular if we confine our perspective to the Reich's budget". They say, "though politically a humiliation", the limitation on the military "was beneficial in fiscal terms" and that their economic models show that "the restriction of the size of the army was clearly beneficial for the Reich budget". Additionally, their economic scenarios indicate that while the Treaty of Versailles was "overall clearly a burden on the German economy", it "also offered a substantial peace dividend for Weimar's non-revanchist budget politicians." They conclude that, "The fact that [these politicians] did not make sufficient use of this imposed gift supports the hypothesis that the Weimar Republic suffered from home-made political failure".
Hyperinflation.
Erik Goldstein wrote that in 1921, the payment of reparations caused a crisis and that the occupation of the Ruhr had a disastrous effect on the German economy, resulting in the German Government printing more money as the currency collapsed. Hyperinflation began and printing presses worked overtime to print Reichsbank notes; by November 1923 one US dollar was worth 4,200,000,000,000 marks. Ferguson writes that the policy of the Economics Minister Robert Schmidt led Germany to avoid economic collapse from 1919 to 1920, but that reparations accounted for most of Germany's deficit in 1921 and 1922 and that reparations were the cause of the hyperinflation.
Several historians counter the argument that reparations caused the inflation and collapse of the mark. Gerhard Weinberg writes that Germany refused to pay by, and that doing so destroyed their own currency. Anthony Lentin agrees and writes that inflation was "a consequence of the war rather than of the peace" and that hyperinflation was a result of the "German government's reckless issue of paper money" during the Allied occupation of the Ruhr. British and French experts believed that the Mark was being sabotaged to avoid budgetary and currency reform and to evade reparations. Sally Marks writes that the Germans claimed that reparations destroyed the Mark Marks writes that historians who say reparations caused hyperinflation have overlooked "that the inflation long predated reparations" and the way "inflation mushroomed" between mid-1921 and the end of 1922 "when Germany was actually paying very little in reparations" and have failed to explain why "the period of least inflation coincided with the period of largest reparation payments ... or why Germans claimed after 1930 that reparations were causing deflation". She writes "there is no doubt that British and French suspicions late in 1922 were sound". Marks also writes that the "astronomic inflation which ensued was a result of German policy", whereby the government paid for passive resistance in the Ruhr "from an empty exchequer" and paid off its domestic and war debts with worthless marks. Bell agrees and writes that "inflation had little direct connection with reparation payments themselves, but a great deal to do with the way the German government chose to subsidize industry and to pay the costs of passive resistance to the occupation [of the Ruhr] by extravagant use of the printing press". Bell also writes that hyperinflation was not an inevitable consequence of the Treaty of Versailles, but was among the actual results.
Reparations.
Contemporaneous.
According to historian Claude Campbell, John Maynard Keynes "set the fashion for critics of the economic aspects of the treaty" and "made probably the severest and most sweeping indictment of its economic provisions". Keynes was temporarily attached to the British Treasury during the war and was their official representative at the peace conference. He later resigned "when it became evident that hope could no longer be entertained of substantial modifications in the draft Terms of Peace" due to the "policy of the Conference towards the economic problems of Europe". In 1919, he wrote "The Economic Consequences of the Peace" based on his objections. He wrote that he believed "that the campaign for securing out of Germany the general costs of the war was one of the most serious acts of political unwisdom for which our statesmen have ever been responsible", and called the treaty a "Carthaginian peace" that would economically affect all of Europe. Keynes said that the treaty's reparation figures "generally exceed Germany's capacity" to pay. He said that US$ was the "safe maximum figure", but even then he did "not believe that [Germany could] pay as much". He said the Reparation Commission was a tool that could "be employed to destroy Germany's commercial and economic organization as well as to exact payment".
In Keynes' opinion, the reparation figure should have been fixed "well within Germany's capacity to pay" so to "make possible the renewal of hope and enterprise within her territory" and to "avoid the perpetual friction and opportunity of improper pressure arising out of the Treaty clauses". Keynes identified reparations as the "main excursion into the economic field" by the Treaty of Versailles, but said that the treaty excluded provisions for rehabilitating Europe's economies, for improving relations between the Allies and the defeated Central Powers, for stabilizing Europe's new nations, for "reclaim[ing] Russia", or for promoting economic solidarity between the Allies. Coal provides an example of these destabilizing effects in Germany and beyond. Keynes said the "surrender of the coal will destroy German industry" but conceding that without coal shipments as reparations, the French and Italian industries damaged directly by the war or indirectly by damage to coal mines would be affected. He writes that this is "not yet the whole problem". The repercussions would also affect Central and Northern Europe, and neutral states such as Switzerland and Sweden, which made up for their own coal deficiencies by trading with Germany. Likewise, Keynes said Austria would now be consigned to "industrial ruin" as "nearly all the coalfields of the former Empire lie outside of what is now German-Austria".
Campbell writes that the "apparent majority did not regard the treaty as perfect". Bernard Baruch writes in "The Making of the Reparation and Economic Sections of the Treaty" that most believed it to be the best agreement obtainable under the circumstances and that it was a minority that attacked the treaty, but these attacks "centered upon its economic provisions". James T. Shotwell, writing in "What Germany Forgot", said, "the only 'unendurable servitudes' in the treaty were in the sections on Reparation and the Polish settlement and raised the question as to what part of Germany's grievance against the peace lay in the substance of its exactions and what part in the manner of their imposition". Sir Andrew McFayden, who also represented the British Treasury at the peace conference and later worked with the Reparation Commission, published his work "Don't Do it Again". McFayden's position "falls somewhere between the views of Keynes and Shotwell". His attack on reparations "was as harsh as Keynes" but he conceded that the "fault did not lie primarily in the provisions of the treaty but in their execution". He also believed "that he Polish settlement was the only readjustment ... which was decidedly unwise".
Albrecht-Carrié writes that before the German surrender, Woodrow Wilson dispatched a note to the German Government on 5 November 1918 stating that the Allies "under-stand that compensation will be made by Germany for all damage done to the civilian population of the Allies and their property by the aggression of Germany by land, by sea, and from the air", the terms of which they accepted. Regardless of which, Albrecht-Carrié says the reparation section of the treaty proved "to be a dismal failure". Campbell says, "although there was much in the peace that was 'petty, unjust, and humiliating', there was little aside from reparation clauses and certain territorial concessions, which had much real bearing upon Germany's economic future". Summarizing the view of economists throughout the 1920s, she says the territorial changes to Germany were "not necessarily ... economically unsound", but than the removal of the Saar and territory to Poland "depriv[ed] Germany of her resources in excess of the amount necessary to fulfill the legitimate economic demands of the victors ... [and] was indefensible". Campbell also said the treaty failed to include "provisions looking to the restoration of Germany to her former position as the chief economic and financial stabilizing influence in central Europe" and that this was economically shortsighted and was an economic failing of the treaty.
Étienne Mantoux, a French economist, was the harshest contemporaneous critic of Keynes. In his a posthumously published book, "The Carthaginian Peace, or the Economic Consequences of Mr. Keynes", Mantoux said that Keynes "had been wrong on various counts, especially with respect to his predictions about Germany's coal, iron and steel production ... and its level of national saving". Keynes said Europe's overall output of iron would decrease; Mantoux said the opposite occurred. By 1929, European iron output had increased by ten per cent from that of 1913. Keynes believed that this European trend would also affect German iron and steel production. Mantoux says this prediction was also incorrect. By 1927, German steel output had increased by 30 per cent and iron output increased by 38 per cent from 1913. Keynes predicted that German coal extraction would also decrease and that Germany would not be able to export coal immediately after the war. Mantoux also counters these arguments. By 1920, German was exporting 15 million tons of coal a year and reached 35 million tons by 1926. By 1929, German coal mining had risen by 30 per cent on the 1913 figures because of her increased labor efficiency methods. In regard to national savings, Keynes stated that 2 billion marks would only be possible after the adoption of the treaty. Mantoux says that the 1925 German national savings figure was estimated at 6.4 billion marks, rising to 7.6 billion marks by 1927. Mantoux calculated that Germany borrowed between 8 billion and 35 billion marks in the period 1920–1931, while only paying 21 billion in reparations. This, he says, allowed Germany to re-equip, expand, and modernize her industry. Highlighting the rearmament under Hitler, Mantoux said Germany "had been in a stronger position to pay reparations than Keynes had made out". He also says that Germany could have paid all of the reparations if she had wanted to, and that the problem was not that Germany was unable to pay, but that she was unwilling to pay.
In 1954, United States Secretary of State John Foster Dulles—one of the authors of Article 231—said that, "Efforts to bankrupt and humiliate a nation merely incite a people of vigor and of courage to break the bonds imposed upon them ... Prohibitions thus incite the very acts that are prohibited."
Modern.
Geoff Harcourt writes that Keynes' arguments that reparations would lead to German economic collapse have been adopted "by historians of almost all political persuasions" and have influenced the way historians and the public "see the unfolding events in Germany and the decades between Versailles and the outbreak of the Second World War". He says Mantoux's work "is not simply a critique of Keynes", but "a stimulus to question the received wisdom's interpretation of the unfolding events in Germany". Harcourt says that despite it discussing Keynes' errors "in great detail", Mantoux's work "has not led us to revise our general judgment of Keynes", yet "it does make us question the soundness of theoretical and empirical aspects" of his arguments. A. J. P. Taylor writes that in 1919 "many people believed that the payment of reparations would reduce Germany to a state of Asiatic poverty", and that Keynes "held this view, as did all Germans; and probably many Frenchmen". However, he also says these "apprehensions of Keynes and the Germans were grotesquely exaggerated". 
According to Martel, Taylor "shrewdly concludes that Étienne Mantoux had the better of his controversy with John Maynard Keynes". Stephen Schuker writes that Keynes' "tendentious but influential" book was "ably refuted" by Mantoux. Richard J. Evans says "the economic history of the 1920s and early 1930s seemed to confirm" the arguments of Keynes, yet "as we now know" Keynes' reparation arguments were wrong. Evans says the economic problems that arose were a result of the inflation of 1923, which lay with the German government rather than reparations.
According to Slavieck, the "traditional interpretation of the treaty's impact on Germany" was that it "plunged the nation into an economic free fall". This view was shared by the German people, who believed the treaty was robbing Germany of its wealth. German banker Max Warburg said the terms of the treaty were "pillage on a global scale". Niall Ferguson says the German view was incorrect and "not many historians would today agree with Warburg". However, several historians agree with Warburg. Norman Davies writes that the treaty forced Germany to "pay astronomic reparations", while Tim McNeese states, "France and Britain had placed war damages on Germany to the tune of billions of gold marks, which the defeated Germans could not begin to pay in earnest". Ferguson says the reparations were "less of a burden than Keynes and others claimed" and that the "potential burden on national income of the annuity vary from 5 percent to 10 percent". However, he cautions against underestimating the initial German effort to pay. Before the implementation of the Dawes Plan, Germany transferred between eight and 13 billion gold marks, which amounted to "between 4 and 7 percent of total national income". Ferguson says "the annuity demanded in 1921 put an intolerable strain on the state's finances" and that total expenditure between 1920 and 1923 amounted to "at least 50 percent of Reich revenue, 20 percent of total Reich spending and 10 percent of total public spending". Thus, Ferguson says, reparations "undermined confidence in the Reich's creditworthiness" and ""were" therefore excessive—as the German government claimed".
Hantke and Spoerer write that "reparation payments were indeed a severe economic burden for Germany" and that "the German economy was deprived of between one and 2.2 billion Reichsmark (RM) annually, which amounted in the late 1920s to nearly 2.5 per cent of Germany's GDP". Gerald Feldman writes, "there can be no question that the entire London schedule could be viewed as a way of reducing the reparations bill without the Allied publics being fully informed of what was going on. This was recognized by at least some German politicians, one of whom optimistically argued that 'the entente will only demand the 50 billion marks, not the rest. They have only called for the rest for domestic political reasons.'" Feldman also says the prospect that the 'C' bonds would be evoked hung over the German Government like a "Damocles Sword". In addition to Feldman and Ferguson's opposition, Peter Kruger, Barry Eichengreen, and Steven Webb agree that "the initial German effort to pay reparations" was substantial and "produced an immense strain" on the German economy.
Several historians take the middle ground between condemning reparations and supporting the argument that they were not a complete burden upon Germany. Detlev Peukert states, "Reparations did not, in fact, bleed the German economy" as had been feared, however the "psychological effects of reparations were extremely serious, as was the strain that the vicious circle of credits and reparations placed the international financial system". P.M.H. Bell writes that while reparations were unwelcome in Germany and caused a "strain on the German balance of payments", they could be paid and were "compatible with a general recovery in European commerce and industry". According to Martel, Robert Boyce said reparations were "a heavy burden on Germany, both as a financial charge ... and as a charge on Germany's balance of payments". However, he says that while "Germany claimed it could not afford to pay reparations" this was far from the truth, and that " ... Germany had made little effort to pay reparations. It refused to levy the necessary taxes, and far from accumulating the foreign exchange required for their payment by collecting some of the overseas earnings of German exporters, it allowed them to leave their earnings abroad". William R. Keylor agrees with Boyce, and says, "an increase in taxation and reduction in consumption in the Weimar Republic would have yielded the requisite export surplus to generate the foreign exchange needed to service the reparation debt". However, Charles Feinstein writes that these kind of arguments overlook the extreme reluctance of the Germans "to accept even a modest increase in taxation to meet what was universally regarded as an unjustified and oppressive imposition by hostile adversaries". Feinstein says that "even if the economic aspects ... were not as crippling as had been assumed in the 1920s, the exaction of reparations was still of deep political and psychological significance for Germany".
Sally Marks writes, "There are those ... who claim reparations were unpayable. In financial terms, that is untrue ... Of course Germans did not want to pay; nobody ever wants to pay, and Weimar was determined not to do so ... Raising taxes would have provided ample funds ... Weimar could have borrowed from the citizenry, as France did after 1871 [to pay its indemnity to Germany]". Marks writes that Germany could have easily paid the 50 billion marks in reparations, but instead chose to repeatedly default on payments as part of a political strategy of undermining Versailles. Marks says that in 1921, Germany met her requirements in full because custom posts were occupied by Allied troops. Once the Allies had relinquished control of the customs posts, Germany made no further payments in cash until 1924 following the implementation of the Dawes Plan. Marks says that while Article 231 of the Treaty of Versailles "established an unlimited theoretical liability", Article 232 limited German responsibility to pay only for civilian damages. When the 1921 London conference to determine how much Germany should pay was called, the Allies calculated on the basis of what Germany could pay, not on their own needs. In this way, Marks says, the Germans largely escaped paying for the war and instead shifted the costs onto American investors. Marks states that the delay in establishing a final total until 1921, "was actually in Germany's interest" because the figures discussed at the peace conference were "astronomic". She says, "The British experts, Lords Sumner and Cunliffe, were so unrealistic that they were nicknamed 'the heavenly twins'." Marks also says, "much ink has been wasted on the fact that civilian damages were stretched to cover war widows' pensions and allowances for military dependents". As reparations were based on what Germany could pay, Marks says the inclusion of such items did not affect German liability but altered distribution of reparations; the "inclusion of pensions and allowances increased the British share of the pie but did not enlarge the pie."
Bernadotte Schmitt writes that if "pensions and separation allowances ... not been included, reparations would probably never have become the bogey that poisoned the post-war world for so many years. Taylor says, "no doubt the impoverishment of Germany was caused by war, not by reparations. Not doubt the Germans could have paid reparations, if they had regarded them as an obligation of honour, honestly incurred." However, he says, "reparations  ... kept the passions of war alive". Peter Liberman writes that while the Germans believed they could not meet such demands of them, the "French believed that Germany could pay and only lacked the requisite will" to do so. Liberman says this is "a position that has gained support from recent historical research". In regard to Germany's capacity to pay, he focuses on coal and says that German coal consumption per capita was higher than France's despite coal shipments being consistently short. He also says, "the reparations demanded at Versailles were not far out of proportion to German economic potential" and that in terms of national income it was similar to what the Germans demanded of France following the Franco-Prussian War. Martin Kitchen also says the impression that Germany was crippled by the reparations is a myth. Rather than a weakened Germany, he states the opposite was true.
Keylor says that literature on reparations has "long suffered from gross misrepresentation, exaggeration, and outright falsification" and that it "should finally succumb to the archive-based discoveries of scholars". Diane Kunz, summarizing the historiography on the subject, writes that historians have refuted the myth that reparations placed an intolerable burden on Germany. Marks says a "substantial degree of scholarly consensus now suggests that paying ... was within Germany's financial capacity". Ruth Henig writes, "most historians of the Paris peace conference now take the view that, in economic terms, the treaty was not unduly harsh on Germany and that, while obligations and damages were inevitably much stressed in the debates at Paris to satisfy electors reading the daily newspapers, the intention was quietly to give Germany substantial help towards paying her bills, and to meet many of the German objections by amendments to the way the reparations schedule was in practice carried out".
References.
</dl>

</doc>
<doc id="33116" url="http://en.wikipedia.org/wiki?curid=33116" title="World Series of Poker">
World Series of Poker

The World Series of Poker (WSOP) is a series of poker tournaments held annually in Las Vegas and, since 2005, sponsored by Caesars Entertainment (known as Harrah's Entertainment until 2010). It dates its origins to 1970, when Benny Binion invited seven of the best-known poker players to the Horseshoe Casino for a single tournament, with a set start and stop time, and a winner determined by secret ballot.
The winner of each event receives a World Series of Poker bracelet and a monetary prize based on the number of entrants and buy-in amounts. Over the years, the tournament has grown in both the number of events and in the number of participants. Each year, the WSOP culminates with the $10,000 no-limit hold'em "Main Event," which, since 2004, has attracted entrants numbering in the thousands. The victor receives a multi-million dollar cash prize and a bracelet, which has become the most coveted award a poker player can win. The winner of the World Series of Poker Main Event is considered to be the World Champion of Poker.
As of 2014, the WSOP consists of 65 events, with most major poker variants featured. However, in recent years, over half of the events have been variants of Texas hold 'em. Events traditionally take place during one day or over several consecutive days during the series in June and July. However, starting in 2008, the Main Event final table was delayed until November. The 2012 final table commenced in October because of the United States presidential election.
Format.
Since 1971, all WSOP events have been tournaments with cash prizes. In 1973 a five-card stud event was added. Since then, new events have been added and removed. Since 1976, a bracelet has been awarded to the winner of every event at the annual WSOP; later on, the winners of pre-1976 events were retroactively given bracelets.
The tournament grew slowly for over a decade, reaching 52 participants in 1982. In the early 1980s, satellite tournaments were introduced, allowing people to win their way into the various events. By 1987, there were over 2,100 entrants in the entire series.
At the 2006 World Series of Poker, there were 45 events, covering the majority of poker variants. Participation in the Main Event peaked that year, with 8,773 players.
Currently, Texas hold 'em, Omaha hold 'em and Seven-card stud and their lowball variants are played. H.O.R.S.E. has been played in the past and returned in 2006. Also, S.H.O.E. has been played in the past, and returned in 2007. Other events played in the past include Chinese poker, Five card stud, and many others. Like most tournaments, the sponsoring casino takes an entry fee (a percentage between 6% and 10%, depending on the buy-in) and distributes the rest, hence the prize money increasing with more players. In the 2005 Main Event, US$52,818,610 in prize money was distributed among 560 players, with US$7.5 million as the first prize. The 2006 Main Event, won by Jamie Gold, is the largest single poker tournament by prize pool or by entrant numbers in history; Gold pocketed US$12 million for his victory. In July 2010, it was announced that the winner of the 2010 Main Event would receive just under US$9 million.
On June 2, 2011, the World Series of Poker and Cirque du Soleil founder Guy Laliberté announced plans for an officially sanctioned special fundraising event, known as The Big One for One Drop, starting on July 1, 2012 with a record US$1 million entry fee. 11% of the money (more precisely, $111,111 from each buy-in) went to Laliberté's charity, the One Drop Foundation, and the WSOP waived its normal 10% rake of the entry fees. At the time of the original announcement, 15 of the maximum 48 seats had been taken. By early December 2011, the field size had increased to 22, the minimum required for an official bracelet tournament. Among those who committed early to the event were Johnny Chan, Daniel Negreanu, Jonathan Duhamel, Tom Dwan, Laliberté, billionaire businessman Phil Ruffin and Erik Seidel. On April 12, 2012, the WSOP announced that 30 players had committed to the tournament, which brought the first prize to $12.3 million, exceeding the record amount won by Jamie Gold. In the end, all 48 seats were filled, resulting in a first prize of $18.3 million. Poker professional Antonio Esfandiari won the event, also receiving a special platinum WSOP bracelet.
Highlights.
The number of participants in the WSOP grew every year from 2000 until 2006. Following 2006, new online gambling legislation restricted the number of online qualifiers to the event. 2007 was the first dip in numbers in this century while in 2008 more people participated than the previous year. In 2000 there were 4,780 entrants in the various events, but in 2005, the number rose to over 23,000 players. In the main event alone, the number of participants grew from 839 in 2003 to 8,773 in 2006. Phil Hellmuth has won the most bracelets with 13 followed by Doyle Brunson, Johnny Chan, and Phil Ivey with ten bracelets each. Crandell Addington is the only player to place in the top ten of the World Series of Poker Main Event eight times, albeit in earlier years with small fields compared to modern times. Four players have won the Main Event multiple times: Johnny Moss (1970, 1971, and 1974), Doyle Brunson (1976 and 1977), Stu Ungar (1980, 1981, and 1997) and Johnny Chan (1987 and 1988). Bracelet winners who first achieved fame in other fields include French actor/singer Patrick Bruel (in 1998), Danish soccer player Jan Vang Sørensen (in 2002) and American actress Jennifer Tilly (in 2005). In recent years, there have been non-bracelet events at the WSOP; two of the most notable are the "World Series of Rock Paper Scissors" and "Ante Up for Africa."
History.
The idea of a World Series of Poker began in 1969 with an event called the Texas Gambling Reunion. It was an invitational event sponsored by Tom Moore of San Antonio, Texas, and held at the Holiday Hotel and Casino in Reno. This inaugural event was won by Crandell Addington. The set of tournaments that the World Series of Poker (WSOP) would evolve into was the brainchild of Las Vegas casino owner and poker player Benny Binion. In 1970, the first WSOP at Binion's Horseshoe took place as a series of cash games that included five-card stud, deuce to seven low-ball draw, razz, seven-card stud, and Texas hold 'em. The format for the Main Event as a freeze-out Texas hold 'em game came the next year. The winner in 1970, Johnny Moss, was elected by his peers as the first "World Champion of Poker" and received a silver cup as a prize.
Acquisition by Harrah's.
In 2004, Harrah's Entertainment (now Caesars Entertainment) purchased Binion's Horseshoe, retained the rights to the Horseshoe and World Series of Poker brands, sold the hotel and casino to MTR Gaming Group, and announced that the 2005 Series events would be held at the Harrah's-owned Rio Hotel and Casino, located just off the Las Vegas Strip. The final two days of the main event in 2005 were held downtown at what is now the MTR-operated "Binion's" in celebration of the centennial of the founding of Las Vegas. It also added a made-for-television $2 million "freeroll" invitational Tournament of Champions (TOC) event first won by Annie Duke as a "winner-take-all" event.
Starting in 2005, the WSOP began a tournament "circuit" at Harrah's-owned properties in the United States where, in addition to the $10,000 buy-in tournament at each site, qualifying players became eligible for a revamped Tournament of Champions. The 2005 TOC, made up of the top twenty qualifying players at each circuit event, along with the final table from the 2005 Main Event and the winners of nine or more bracelets (Johnny Chan, Doyle Brunson, and Phil Hellmuth) would participate in the revamped TOC at Caesars Palace. Mike Matusow won the first prize of $1 million (US), and all the players at the final table were guaranteed a minimum of $25,000 for the eighth and ninth place finishers. During a break in the final table of the 2005 Main Event on July 16, Harrah's announced that eleven properties — including the recently added Bally's and Caesar's properties — would host 2005–06 WSOP Circuit events that started on August 11 in Tunica, Mississippi. One event that was scheduled for Biloxi, Mississippi, was canceled after the Grand Casino Biloxi, which was scheduled to host the event, suffered major damage from Hurricane Katrina. The Rio also hosted the 2006 World Series of Poker, which began on June 25 with satellite events and formally began the day after with the annual Casino Employee event, won in 2006 by Chris Gros. 2006 featured the Tournament of Champions on June 25 and 26, won by Mike Sexton. Various events led up to the main event, which was held from July 28 until August 10. The first prize of $12 million was awarded to Jamie Gold.
Main Event.
Since 1972, the Main Event of the WSOP has been the $10,000 buy-in no-limit Texas Hold 'Em (NLHE) tournament (in 1971 the buy-in was $5,000 and the inaugural 1970 event was an invitational with winner determined by a vote). Winners of the event not only get the largest prize of the tournament and a gold bracelet, but additionally their picture is placed in the "Gallery of Champions" at Binion's. The winner of the Main Event has traditionally been given the unofficial title of World Champion. However, some believe that no-limit hold 'em is not the optimal structure for determining a champion poker player. In 2002, Daniel Negreanu argued that the Main Event should switch to pot-limit hold 'em, believing that pot-limit required a more complete set of poker skills than no-limit, although he admitted that such a change would likely never be made. However, many of the game's top professionals, including Negreanu, have since stated that the recently added $50,000 H.O.R.S.E./Poker Player's Championship event is the one which ultimately decides the world's best player. The $50,000 buy-in, being five times larger than the buy-in for the Main Event, has thus far tended to deter amateurs from playing in this event, and the variety of games played require a broader knowledge of poker. The first $50,000 event, conducted as a H.O.R.S.E. tournament, was won by Chip Reese in 2006. In 2010, the $50,000 event changed from H.O.R.S.E. to an "8-game" format, adding no-limit hold 'em, pot-limit Omaha, and 2–7 triple draw to the mix, and was rechristened The Poker Player's Championship, with Michael Mizrachi winning the first edition of the revamped event. Since Reese's death in December 2007, the winner of this event receives the David 'Chip' Reese Memorial Trophy in addition to the bracelet and the prize money.
There have been many memorable moments during the main events, including Jack Straus's 1982 comeback win after discovering he had one $500 chip left when he thought he was out of the tournament. The end of the 1988 main event was featured in the movie "Rounders". Chris Moneymaker and Greg Raymer, the winners in 2003 and 2004, both qualified for the main event through satellite tournaments at the PokerStars online card room. Jerry Yang, the winner in 2007, had only been playing poker for two years prior to his victory. He won his seat at a $225 satellite tournament at Pechanga Resort & Casino, in California. With passage of the Unlawful Internet Gambling Enforcement Act (UIGEA) of 2006 online poker sites have been barred from purchasing entrance directly for their users.
Players.
Records.
Since its inception, Stu Ungar and Johnny Moss are the only players to have won the Main Event three times. However, Moss' first victory came in a different format, as he was elected winner by vote of his fellow players at the conclusion of what was then a timed event. Moss (if the first time win by vote is counted), Ungar, Doyle Brunson, and Johnny Chan are the only people who have won the Main Event in consecutive years. Johnny Chan's second victory in 1988 was featured in the 1998 film "Rounders".
Phil Hellmuth holds multiple WSOP records including most bracelets, most WSOP cashes, and most WSOP final tables. He is also the only player to have won the Main Events of both the WSOP and WSOP Europe.
In recent years, the prize pool for the WSOP Main Event has become so large that the winner instantly becomes one of the top money winners of WSOP and even in tournament poker history. Before July 2012, the top seven players on the all-time WSOP Earnings list were Main Event champions from 2005 to 2011, among whom Jamie Gold topped those seven, he won the 2006 Main Event, which had then the biggest first prize for a single tournament, and still is the largest poker tournament by prize pool in history. However, the all-time leader is currently Antonio Esfandiari, who has not won a Main Event. He collected a record-breaking first prize of $18.3 million in July 2012 when he won The Big One for One Drop, a charitable WSOP event with a $1 million buy-in. The players in second and third place on the all-time earnings list, Daniel Colman and Daniel Negreanu, have also yet to win a Main Event in Las Vegas, although Negreanu won the inaugural WSOP Asia Pacific Main Event in 2013. They finished in the top two places in the 2014 Big One for Big Drop, respectively winning $15.3 million and $8.3 million.
The list below includes the WSOP Europe and WSOP Asia-Pacific, but excludes WSOP Circuit events and other non-bracelet events. The results are updated through the 2014 WSOP APAC.
Player of the Year.
Since 2004, a Player of the Year (POY) award has been given to the player with the most points accumulated throughout the WSOP. As of 2013, nine different players have won the ten awards, with Daniel Negreanu the only repeat (2-time) winner. 
Only "open" events in which all players can participate count in the standings; this eliminates the Seniors, Ladies, and Casino Employee events. Beginning with the 2006 World Series of Poker, the Main Event and the $50,000 H.O.R.S.E. competition had no effect on the outcome of the winner of the Player of the Year award. In the 2008 World Series of Poker, the $50,000 H.O.R.S.E. event counted toward the Player of the Year award, but the Main Event did not. Since 2009, all open events, including the Main Event, count towards Player of the Year. The Player of the Year standings were based upon performance solely at the WSOP in Las Vegas up until 2010, but beginning in 2011 have also taken the World Series of Poker Europe into account, and starting in 2013 also include events in the World Series of Poker Asia Pacific. The 2011 WSOP Player of the Year organized by "Bluff Magazine" used a different scoring system which took into account field sizes and buy-in amounts when calculating points earned. This scoring system has been used ever since.
Poker Hall of Fame.
Since its inception in 1979, the WSOP Poker Hall of Fame has honored 42 individuals. Selection criteria for players include having competed against acknowledged top competition, played for high stakes and played consistently well to gain the respect of their peers. For non-players, selection is based on positive and lasting contributions to the overall growth and success of poker.
Expansion.
2007 - World Series of Poker Europe.
The World Series of Poker Europe (WSOPE) is the first expansion of the World Series of Poker. Since 1970, the event has occurred every year in Las Vegas. In September 2007, the first WSOP championship events outside of Las Vegas, complete with bracelets, were held. The inaugural WSOPE consisted of three events held in London from September 6–17, 2007. The main event, a GBP 10,000 buy-in no-limit hold 'em tournament, was won by Norwegian online prodigy Annette Obrestad on the day before her 19th birthday. This made her the youngest person ever to win a WSOP bracelet, a record that cannot be broken in the Las Vegas WSOP under current laws because the minimum legal age for casino gaming in Nevada is 21. Obrestad could play in the WSOPE because the minimum age for casino gaming in the United Kingdom is 18. While no definitive plans have been announced, WSOP Commissioner Jeffrey Pollack has indicated that in the next one to three years that other venues may start holding WSOP events. Two locations that have been mentioned as possible expansion sites are Egypt and South Africa, and the World Series of Poker Africa was ultimately launched in South Africa in 2010. However, it is currently treated as a WSOP Circuit event, with no bracelets awarded. The next expansion of the WSOP that included bracelet events was ultimately to Australia.
The WSOPE moved from London to Cannes, France in 2011. At that time, the buy-ins and payouts changed from being fixed in pounds to euros. The event moved again in 2013, this time to the Paris suburb of Enghien-les-Bains.
In November 2013, it was announced that the WSOPE would in the future alternate with the World Series of Poker Asia Pacific (WSOP APAC), which launched in 2013. The WSOPE will now be held only in odd-numbered years, with WSOP APAC conducted in even-numbered years.
2010 World Series of Poker - Africa.
In 2010, the WSOP expanded overseas once again, only this time to Gauteng, South Africa. While the WSOPE awarded bracelets, the World Series of Poker Africa Although the 2010 event was part of the WSOP Circuit, winners did not earn a gold ring or standing for the WSOP Circuit National Championship, both of which were common for other circuit events. This policy changed in 2012. The WSOPA did not occur in 2011, but resumed in 2012.
2013 World Series of Poker Asia-Pacific.
On April 30, 2012, the WSOP and Australian casino Crown Melbourne jointly announced the creation of the World Series of Poker Asia-Pacific (WSOP APAC). The first edition of the event was held at Crown's Melbourne casino from April 4–15, 2013 and featured five bracelet events.
WSOP television coverage.
1970s–1980s.
The earliest filming of the World Series was a special produced by Binion's Horseshoe in 1973 and narrated by Jimmy "The Greek" Snyder. CBS began covering the World Series in the late 1970s. In the early 1980s, the event was again broadcast as specials. In the late 1980s, the World Series returned to television as ESPN took over broadcasting. Initially, coverage consisted of just a single one-hour taped-delay broadcast of the main event.
1990s.
ESPN Classic currently airs many of the old broadcasts from the mid-1990s and beyond. Since no "pocket cam" existed, very few hole cards were actually shown to television viewers. Generally, ESPN used poker-playing actors such as Dick Van Patten, Vince Van Patten, and Gabe Kaplan, with either the tournament director (usually Jim Albrecht) or a poker professional like Phil Hellmuth joining the team. Unlike today's coverage, ESPN featured no pre-taped interviews or profiles on the players. In addition, the commentators were generally on the casino floor itself.
In the 1994 coverage of the final hand of the main event shows Hugh Vincent holding 8c 5h . The flop was 8c 2s 6d, indicating that there were two 8c in the deck. The tournament director announces that Hugh Vincent needed two running spades to win. The likely hand for Hugh Vincent was 8s 5s, but there is no known video of the actual hand turned over by Hugh Vincent.
2000s.
From 1999 to 2001, the World Series of Poker was broadcast by The Discovery Channel. These hour-long programs presented more of an overview or recap of the WSOP as opposed to broadcasting an actual live event with play-by-play analysis and color commentary. The Discovery Channel's broadcast also featured final table players interviews interlaced throughout the show. ESPN would resume coverage the following year.
ESPN's coverage in 2002 was typical of their coverage in the 1990s (recorded in video, little or no post-production commentary or player profiles, no card cams). However, the final table broadcast was expanded over two one-hour episodes. The 2002 WSOP was the first with the "sneak peek" (later called the pocket cam, or hole cam).
In 2003, Fred Christenson secured the long-term rights acquisition for ESPN, and the channel expanded their coverage to new heights with their coverage of the WSOP. They included coverage of the entire tournament, with a "Featured Table". At this table, the viewers could see the player's hole cards and subsequent strategy. The action was also broadcast as if live, though on tape-delay. 2003 was the first year that the broadcast covered action preceding the final table. Since then, ESPN has greatly expanded its coverage to include many of the preliminary events of the WSOP, especially Texas Hold 'Em. Also, their coverage of the main event now typically includes at least one hour program on each day. For the first two years of its existence, ESPN was broadcasting one hour programs of the "circuit" events that the WSOP has at various Harrah's-owned casinos, but ESPN did not renew these events. ESPN's coverage now includes many of the trappings of sports coverage, such as lighter segments (called "The Nuts") and interviews. ESPN's coverage has been largely driven by Matt Maranz, Executive Producer for the WSOP telecasts. Maranz leads 441 Productions, which produces the telecast under contract to ESPN's unit ESPN Original Entertainment (EOE). Maranz has significant sports production experience, having previously worked on ESPN's football pre-game show, and has also produced taped segments for NBC's Olympic coverage.
Coverage would increase in 2004 and 2005 to include preliminary events from the WSOP, in addition to the "Main Event". ESPN has expanded poker to all-new levels, especially with their coverage of the 2006 WSOP, including providing the entire final table of the 2006 Main Event via pay-per-view airing. In 2008, ESPN experimented with the idea of a delayed final table. This idea presented greater sponsorship opportunities and notoriety, culminating in a recap of the Main Event and the conclusion of the 2008 Main Event final table. In 2009, ESPN announced they would again move the final table to November 2009. The WSOP also decided there would be no rebuy events in 2009. The decision was reached because of complaints that rebuy events provided an unfair advantage to professionals with no limitation on how much money they can spend for an event. There were 57 bracelet events that year. The 2010 WSOP had the same number of bracelet events as in 2009, again with no rebuy events.
With 58 bracelet events and no rebuy events, the 2011 WSOP featured unprecedented "nearly live" coverage, with broadcasts being delayed by much smaller amounts of time while still satisfying Nevada Gaming Commission regulators. Caesars Entertainment, via WSOP.com, streamed final-table coverage of all bracelet events on a 5-minute delay, although without pocket cams. The ESPN family of networks aired 36 hours of Main Event coverage leading up to the November Nine on a 30-minute delay, showing the hole cards of all players who voluntarily entered the pot once the hand ended. The Main Event final table was broadcast on a 15-minute delay with the same policy regarding hole cards. The first day of the final table was aired on ESPN2 and the final day on ESPN, with both days also streamed on ESPN3 and WSOP.com.
Marketing.
The WSOP has corporate sponsors and licensed products which pay fees to market themselves as an official sponsors and/or licensees and exclusively use the WSOP insignia and cross-promote with their events. Besides the Harrah's properties and ESPN, major sponsors have included Jack Links Beef Jerky, Miller Brewing's "Milwaukee's Best" brand of beers, Pepsi's SoBe Adrenaline Rush energy drink (sponsors of the 2005 TOC), Helene Curtis' Degree brand of anti-perspirant/deodorant, United States Playing Card's Bicycle Pro Cards, Bluff Magazine, GlaxoSmithKline/Bayer's Levitra erectile dysfunction medicine, and The Hershey Company. Licensees include Glu Mobile, Activision (video games for different platforms such as Nintendo's GameCube, Microsoft's Xbox, Sony's PlayStation 2, and PC, featuring computer-generated versions of stars like Ferguson), and products made by different companies ranging from chip sets, playing cards, hand-held games, and clothing like caps and shirts. The official playing cards and chips are manufactured by Excalibur Electronics, Inc. which is based out of Miami, Florida and has been the main chip licensee since 2005. The fees and licenses bring in more than a million dollars to Harrah's.
DVD releases.
In 2003 and 2004 DVD sets were released by ESPN of the Main Event.
Video games.
In 2005, a video game based on the tournament, titled "World Series of Poker", was released for several consoles and the computer. A sequel called ' came out in 2006. In 2007, ' was released. WSOP video poker machines now appear at some Harrah's casinos; the machines are standard video poker machines, but have a bonus feature which allows a player to play a modified game of Texas Hold 'em against the machine.
WSOP Poker Academy.
Beginning in 2007, Harrah's announced the creation of the World Series of Poker Academy, a poker school aimed at providing poker players with the skills needed to win a WSOP Bracelet. The instructors for the Academy include Annie Duke, Phil Hellmuth, Jr., Greg Raymer, Scott Fischman, Mark Kroon, Mark Seif, Alex Outhred, and former FBI interrogator Joe Navarro. Initial academies were launched in Tunica, Mississippi, Indiana, and Las Vegas.
WSOP online.
In September 2009 Harrah's signed an agreement with Dragonfish, the B2B arm of 888 Holdings, to provide its online gaming services. The offering went live in the UK later that year, allowing UK users to play for real money. Real money online poker is available in the United States, but only in Nevada and New Jersey.
WSOP Arizona Lottery.
In December 2010, the Arizona Lottery issued Game Number 739: World Series of Poker $5 Scratchers(sm) with a $50,000.00 top prize. Played on two tables, the game included a second chance drawing for non-winning tickets to win one of two Grand Prize Trip Packages that included a seat at the 2011 World Series of Poker Main Event or one of eight WSOP Poker Party Prize Packs.

</doc>
<doc id="33117" url="http://en.wikipedia.org/wiki?curid=33117" title="William Barnes">
William Barnes

William Barnes (22 February 1801 – 7 October 1886) was an English writer, poet, Church of England minister, and philologist. He wrote over 800 poems, some in Dorset dialect, and much other work, including a comprehensive English grammar quoting from more than 70 different languages.
Life.
He was born at Rushay in the parish of Bagber, Dorset, the son of a farmer. After being a solicitor's clerk and for a while keeping a school at Mere in Wiltshire, he was ordained into the Church of England in 1847, taking a BD degree from St John's College, Cambridge, in 1851. He served curacies at Whitcombe Church in Whitcombe, Dorset, 1847–52, and again from 1862. Between 1860–62 he held a curacy at Rotherham in Yorkshire. He became rector of St Peter's Church, Winterborne Came with Winterbourne Farringdon, Dorset, from 1862 to his death.
He first contributed the Dorset dialect poems for which he is best known to periodicals, including Macmillan's Magazine; a collection in book form "Poems of Rural Life in the Dorset Dialect", was published in 1844. A second collection "Hwomely Rhymes" followed in 1858, and a third collection in 1863; a combined edition appeared in 1879. A "translation", "Poems of Rural Life in Common English" had already appeared in 1868.
His philological works include "Philological Grammar" (1854), "Se Gefylsta, an Anglo-Saxon Delectus" (1849). "Tiw, or a View of Roots" (1862), and a "Glossary of Dorset Dialect" (1863).
Among his other writings is a slim volume on "the Advantages of a More Common Adoption of The Mathematics as a Branch of Education, or Subject of Study", published in 1834.
He was a friend of Thomas Hardy, Lord Tennyson and Gerard Manley Hopkins.
Barnes's poems are characterised by a singular sweetness and tenderness of feeling, deep insight into humble country life and character, and an exquisite feeling for local scenery.
Barnes is buried in Winterborne Came churchyard beneath a Celtic cross. The plinth of the cross has the inscription: 'In Memory of William Barnes, Died 7 October 1886. Aged 86 Years. For 24 Years Rector of this Parish. This Memorial was raised to his Memory by his Children and Grandchildren." There is also a statue of him Dorchester town centre, outside St Peter's Church in that town.
Ralph Vaughan Williams set to music four of Barnes' poems, 'My Orcha'd in Lindèn Lea', in the "Common English" version ("Linden Lea"), 'Blackmwore Maidens', in the "Common English" version ("Blackmwore by the Stour"), "The Winter's Willow", and "In the Spring".
Linguistic purism.
Barnes had a strong interest in language; he was fluent in Greek, Latin and several modern European languages. He called for the purification of English by removal of Greek, Latin and foreign influences so that it might be better understood by those without a classical education. For example, the word "photograph" (from Greek light+writing) would become "sun-print" (from Saxon). Other terms include "wortlore" (botany), "welkinfire" (meteor) and "nipperlings" (forceps).
This 'Pure English' resembles the 'blue-eyed English' later adopted by the composer Percy Grainger, and sometimes the updates of known Old English words given by David Cowley in "How We'd Talk if the English had WON in 1066".
Style.
As well as avoiding the use of these foreign words in his poetry, Barnes would often use a repetition of consonantal sounds similar to the Welsh poetry, cynghanedd. Examples of this can be heard in the lines, "Do lean down low in Linden Lea" and "In our abode in Arby Wood".
Example of Dorset dialect poetry.
"* Words once spoken to the writer"
References.
 #if: 
 #if: A Short Biographical Dictionary of English Literature
 |, 
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: A Short Biographical Dictionary of English Literature
 #if: 
 #if: Barnes, William
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: A Short Biographical Dictionary of English Literature
 #if: 
 #if: Barnes, William
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if: A Short Biographical Dictionary of English Literature
 |{{
 #if: Cousin
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2=" A Short Biographical Dictionary of English Literature
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Cousin
 |{{
 #if: 1910
 |, 1910{{
 #if:
}}{{
 #if: 
 #ifeq: | 1910
 |{{
 #if: 
 #if: Cousin
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: A Short Biographical Dictionary of English Literature
 #if: 
 #if: Barnes, William
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: A Short Biographical Dictionary of English Literature
 #if: 
 #if: Barnes, William
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if: A Short Biographical Dictionary of English Literature
 |, {{
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |journal&rft.genre=article&rft.atitle={{urlencode: A Short Biographical Dictionary of English Literature
 |book{{
 #if: 
 |&rft.genre=bookitem&rft.btitle={{urlencode:}}&rft.atitle={{urlencode: A Short Biographical Dictionary of English Literature
 |&rft.genre=book&rft.btitle={{urlencode: A Short Biographical Dictionary of English Literature
 #if: Cousin |&rft.aulast={{urlencode:Cousin}}{{
 }}{{
 #if: Cousin |&rft.au={{urlencode:Cousin}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: A Short Biographical Dictionary of English Literature
 #if: 
 #if: Barnes, William
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: A Short Biographical Dictionary of English Literature
 #if: 
 #if: Barnes, William
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle =  
 |IncludedWorkURL = 
 |Other = 
 |Edition = 
 |Place = London
 |PublicationPlace = London
 |Publisher = J. M. Dent & Sons. Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = 
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=
 |Sep = .
 |PS = 
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 8
 |amp = 

</doc>
<doc id="33118" url="http://en.wikipedia.org/wiki?curid=33118" title="Woodworking">
Woodworking

Woodworking is the activity or skill of making items from wood, and includes wood carving, joinery, and carpentry.
History.
Along with stone, mud and animal parts, wood was one of the first materials worked by early humans. Microwear analysis of the Mousterian stone tools used by the Neanderthals show that many were used to work wood. The development of civilization was closely tied to the development of increasingly greater degrees of skill in working these materials.
Among early finds of wooden tools are the worked sticks from Kalambo Falls, Clacton-on-Sea and Lehringen. The spears from Schöningen (Germany) provide some of the first examples of wooden hunting gear. Flint tools were used for carving. Since Neolithic times, carved wooden vessels are known, for example, from the Linear Pottery culture wells at Kückhofen and Eythra.
Examples of Bronze Age wood-carving include tree trunks worked into coffins from northern Germany and Denmark and wooden folding-chairs. The site of Fellbach-Schmieden in Germany has provided fine examples of wooden animal statues from the Iron Age Wooden idols from the La Tène period are known from a sanctuary at the source of the Seine in France.
The ancient civilization that first used woodworking was the Egyptians. Woodworking is depicted in many ancient Egyptian drawings, and a considerable amount of ancient Egyptian furniture (such as stools, chairs, tables, beds, chests) has been preserved in tombs. As well, the inner coffins found in the tombs were also made of wood. The metal used by the Egyptians for woodworking tools was originally copper and eventually, after 2000 BC bronze as ironworking was unknown until much later.
Commonly used woodworking tools included axes, adzes, chisels, pull saws, and bow drills. Mortise and tenon joints are attested from the earliest Predynastic period. These joints were strengthened using pegs, dowels and leather or cord lashings. Animal glue came to be used only in the New Kingdom period. Ancient Egyptians invented the art of veneering and used varnishes for finishing, though the composition of these varnishes is unknown. Although different native acacias were used, as was the wood from the local sycamore and tamarisk trees, deforestation in the Nile valley resulted in the need for the importation of wood, notably cedar, but also Aleppo pine, boxwood and oak, starting from the Second Dynasty.
The progenitors of Chinese woodworking are considered to be Lu Ban (魯班) and his wife Lady Yun, from the Spring and Autumn Period. Lu Ban is said to have introduced the plane, chalk-line, and other tools to China. His teachings were supposedly left behind in the book "Lu Ban Jing" (魯班經, "Manuscript of Lu Ban"). Despite this, it is believed that the text was written some 1500 years after his death. This book is filled largely with descriptions of dimensions for use in building various items such as flower pots, tables, altars, etc., and also contains extensive instructions concerning Feng Shui. It mentions almost nothing of the intricate glue-less and nail-less joinery for which Chinese furniture was so famous.
Materials.
Historically, woodworkers relied upon the woods native to their region, until transportation and trade innovations made more exotic woods available to the craftsman. Woods are typically sorted into three basic types: hardwoods typified by tight grain and derived from broadleaf trees, softwoods from coniferous trees, and man-made materials such as plywood and MDF.
Typically furniture such as tables and chairs is made using solid stock, and cabinet/fixture makers employ the use of plywood and other man made panel products.

</doc>
<doc id="33119" url="http://en.wikipedia.org/wiki?curid=33119" title="William Gibson">
William Gibson

William Ford Gibson (born March 17, 1948) is an American-Canadian speculative fiction novelist and essayist who has been called the "noir prophet" of the cyberpunk subgenre. Gibson coined the term "cyberspace" in his short story "Burning Chrome" (1982) and later popularized the concept in his debut novel, "Neuromancer" (1984). In envisioning cyberspace, Gibson created an iconography for the information age before the ubiquity of the Internet in the 1990s. He is also credited with predicting the rise of reality television and with establishing the conceptual foundations for the rapid growth of virtual environments such as video games and the World Wide Web.
Having changed residence frequently with his family as a child, Gibson became a shy, ungainly teenager who often read science fiction. After spending his adolescence at a private boarding school in Arizona, Gibson evaded the draft during the Vietnam War by emigrating to Canada in 1968, where he became immersed in the counterculture. After settling in Vancouver he eventually became a full-time writer. He retains dual citizenship. Gibson's early works are bleak, noir near-future stories about the effect of cybernetics and computer networks on humans—a "combination of lowlife and high tech". The short stories were published in popular science fiction magazines. The themes, settings and characters developed in these stories culminated in his first novel, "Neuromancer", which garnered critical and commercial success, effectively initiating the cyberpunk literary genre.
Although much of Gibson's reputation has remained associated with "Neuromancer", his work has continued to evolve. After expanding on "Neuromancer" with two more novels to complete the dystopic Sprawl trilogy, Gibson became an important author of another science fiction subgenre—steampunk—with the 1990 alternate history novel "The Difference Engine", written with Bruce Sterling. In the 1990s, he composed the Bridge trilogy of novels, which focused on sociological observations of near-future urban environments and late capitalism. Three of Gibson's recent novels—"Pattern Recognition" (2003), "Spook Country" (2007) and "Zero History" (2010)—are set in a contemporary world and have put his work onto mainstream bestseller lists for the first time.
Gibson is one of the best-known North American science fiction writers, fêted by "The Guardian" in 1999 as "probably the most important novelist of the past two decades". Gibson has written more than twenty short stories and ten critically acclaimed novels (one in collaboration), and has contributed articles to several major publications and collaborated extensively with performance artists, filmmakers and musicians. His thought has been cited as an influence on science fiction authors, design, academia, cyberculture, and technology.
Early life.
Childhood, itinerance, and adolescence.
William Ford Gibson was born in the coastal city of Conway, South Carolina, and spent most of his childhood in Wytheville, Virginia, a small town in the Appalachians where his parents had been born and raised. His family moved frequently during Gibson's youth owing to his father's position as manager of a large construction company. In Norfolk, Virginia, Gibson attended Pines Elementary School, where the teachers' lack of encouragement for him to read was a cause of dismay for his parents. While Gibson was still a young child, a little over a year into his stay at Pines Elementary, his father choked to death in a restaurant while on a business trip. His mother, unable to tell William the bad news, had someone else inform him of the death. Tom Maddox has commented that Gibson "grew up in an America as disturbing and surreal as anything J. G. Ballard ever dreamed".
 Loss is not without its curious advantages for the artist. Major traumatic breaks are pretty common in the biographies of artists I respect.
 — William Gibson, interview with "The New York Times Magazine", August 19, 2007.
A few days after the death, Gibson's mother returned them from their home in Norfolk to Wytheville. Gibson later described Wytheville as "a place where modernity had arrived to some extent but was deeply distrusted" and credits the beginnings of his relationship with science fiction, his "native literary culture", with the subsequent feeling of abrupt exile. At the age of 12, Gibson "wanted nothing more than to be a science fiction writer". He spent a few unproductive years at basketball-obsessed George Wythe High School, a time spent largely in his room listening to records and reading books. At 13, unbeknownst to his mother, he purchased an anthology of Beat writing, thereby gaining exposure to the writings of Allen Ginsberg, Jack Kerouac, and William S. Burroughs; the lattermost had a particularly pronounced effect, greatly altering Gibson's notions of the possibilities of science fiction literature.
A shy, ungainly teenager, Gibson grew up in a monoculture he found "highly problematic", consciously rejected religion and took refuge in reading science fiction as well as writers such as Burroughs and Henry Miller. Becoming frustrated with his poor academic performance, Gibson's mother threatened to send him to a boarding school; to her surprise, he reacted enthusiastically. Unable to afford his preferred choice of Southern California, his then "chronically anxious and depressive" mother, who had remained in Wytheville since the death of her husband, sent him to Southern Arizona School for Boys in Tucson, Arizona. He resented the structure of the private boarding school, but was in retrospect grateful for its forcing him to engage socially. He took the SAT (Scholastic Aptitude Test) exams, scoring 5 out of 150 in mathematics and 148 out of 150 in the written section, to the consternation of his teachers.
Draft-dodging, exile, and counterculture.
After his mother's death when he was eighteen, Gibson left school without graduating and became very isolated for a long time, traveling to California and Europe and immersing himself in the counterculture. In 1967, he elected to move to Canada in order "to avoid the Vietnam war draft". At his draft hearing, he honestly informed interviewers that his intention in life was to sample every mind-altering substance in existence. Gibson has observed that he "did not literally evade the draft, as they never bothered drafting me"; after the hearing he went home and purchased a bus ticket to Toronto, and left a week or two later. In the biographical documentary "No Maps for These Territories" (2000) Gibson said that his decision was motivated less by conscientious objection than by a desire to "sleep with hippie chicks" and indulge in hashish. He elaborated on the topic in a 2008 interview:
 When I started out as a writer I took credit for draft evasion where I shouldn't have. I washed up in Canada with some vague idea of evading the draft but then I was never drafted so I never had to make the call. I don't know what I would have done if I'd really been drafted. I wasn't a tightly wrapped package at that time. If somebody had drafted me I might have wept and gone. I wouldn't have liked it of course.
 — William Gibson, "interview with "io9", June 10, 2008."
After weeks of nominal homelessness, Gibson was hired as the manager of Toronto's first head shop, a retailer of drug paraphernalia. He found the city's émigré community of American draft dodgers unbearable owing to the prevalence of clinical depression, suicide and hardcore substance abuse. He appeared, during the Summer of Love of 1967, in a CBC newsreel item about hippie subculture in Yorkville, Toronto, for which he was paid $500 – the equivalent of 20 weeks rent – which financed his later travels. Aside from a "brief, riot-torn spell" in the District of Columbia, Gibson spent the rest of the 1960s in Toronto, where he met Vancouverite Deborah Jean Thompson, with whom he subsequently traveled to Europe. Gibson has recounted that they concentrated their travels on European nations with fascist regimes and favourable exchange rates, including spending time on a Greek archipelago and in Istanbul in 1970, as they "couldn't afford to stay anywhere that had anything remotely like hard currency".
The couple married and settled in Vancouver, British Columbia in 1972, with Gibson looking after their first child while they lived off his wife's teaching salary. During the 1970s, Gibson made a substantial part of his living from scouring Salvation Army thrift stores for underpriced artifacts he would then up-market to specialist dealers. Realizing that it was easier to sustain high college grades, and thus qualify for generous student financial aid, than to work, he enrolled at the University of British Columbia (UBC), earning "a desultory bachelor's degree in English" in 1977. Through studying English literature, he was exposed to a wider range of fiction than he would have read otherwise; something he credits with giving him ideas inaccessible from within the culture of science fiction, including an awareness of postmodernity. It was at UBC that he attended his first course on science fiction, taught by Susan Wood, at the end of which he was encouraged to write his first short story, "Fragments of a Hologram Rose".
Post-graduation, early writing, and the evolution of cyberpunk.
After considering pursuing a master's degree on the topic of hard science fiction novels as fascist literature, Gibson discontinued writing in the year that followed graduation and, as one critic put it, expanded his collection of punk records. During this period he worked at various jobs, including a three-year stint as teaching assistant on a film history course at his alma mater. Impatient at much of what he saw at a science fiction convention in Vancouver in 1980 or 1981, Gibson found a kindred spirit in fellow panelist, punk musician and author John Shirley. The two became immediate and lifelong friends. Shirley persuaded Gibson to sell his early short stories and to take writing seriously.
 In 1977, facing first-time parenthood and an absolute lack of enthusiasm for anything like "career," I found myself dusting off my twelve-year-old's interest in science fiction. Simultaneously, weird noises were being heard from New York and London. I took Punk to be the detonation of some slow-fused projectile buried deep in society's flank a decade earlier, and I took it to be, somehow, a sign. And I began, then, to write.
 — William Gibson, "Since 1948".
Through Shirley, Gibson came into contact with science fiction authors Bruce Sterling and Lewis Shiner; reading Gibson's work, they realised that it was, as Sterling put it, "breakthrough material" and that they needed to "put down our preconceptions and pick up on this guy from Vancouver; this [was] the way forward." Gibson met Sterling at a science fiction convention in Denver, Colorado in the autumn of 1981, where he read "Burning Chrome" – the first cyberspace short story – to an audience of four people, and later stated that Sterling "completely got it".
In October 1982, Gibson traveled to Austin, Texas for ArmadilloCon, at which he appeared with Shirley, Sterling and Shiner on a panel called "Behind the Mirrorshades: A Look at Punk SF", where Shiner noted "the sense of a movement solidified". After a weekend discussing rock and roll, MTV, Japan, fashion, drugs and politics, Gibson left the cadre for Vancouver, declaring half-jokingly that "a new axis has been formed." Sterling, Shiner, Shirley and Gibson, along with Rudy Rucker, went on to form the core of the radical cyberpunk literary movement.
Literary career.
Early short fiction.
Gibson's early writings are generally near-future stories about the influences of cybernetics and cyberspace (computer-simulated reality) technology on the human race. His themes of hi-tech shanty towns, recorded or broadcast stimulus (later to be developed into the "sim-stim" package featured so heavily in "Neuromancer"), and dystopic intermingling of technology and humanity, are already evident in his first published short story, "Fragments of a Hologram Rose", in the Summer 1977 issue of "Unearth". The latter thematic obsession was described by his friend and fellow author, Bruce Sterling, in the introduction of Gibson's short story collection "Burning Chrome", as "Gibson's classic one-two combination of lowlife and high tech."
Beginning in 1981, Gibson's stories appeared in "Omni" and "Universe 11", wherein his fiction developed a bleak, "film noir" feel. He consciously distanced himself as far as possible from the mainstream of science fiction (towards which he felt "an aesthetic revulsion", expressed in "The Gernsback Continuum"), to the extent that his highest goal was to become "a minor cult figure, a sort of lesser Ballard." When Sterling started to distribute the stories, he found that "people were just genuinely baffled... I mean they literally could not parse the guy's paragraphs... the imaginative tropes he was inventing were just beyond peoples' grasp."
While Larry McCaffery has commented that these early short stories displayed flashes of Gibson's ability, science fiction critic Darko Suvin has identified them as "undoubtedly [cyberpunk's] best works", constituting the "furthest horizon" of the genre. The themes which Gibson developed in the stories, the Sprawl setting of "Burning Chrome" and the character of Molly Millions from "Johnny Mnemonic" ultimately culminated in his first novel, "Neuromancer".
"Neuromancer".
 The sky above the port was the color of television, tuned to a dead channel.
 — opening sentence of "Neuromancer" (1984)
"Neuromancer" was commissioned by Terry Carr for the second series of Ace Science Fiction Specials, which was intended to exclusively feature debut novels. Given a year to complete the work, Gibson undertook the actual writing out of "blind animal terror" at the obligation to write an entire novel – a feat which he felt he was "four or five years away from". After viewing the first 20 minutes of landmark cyberpunk film "Blade Runner" (1982) which was released when Gibson had written a third of the novel, he "figured ["Neuromancer"] was sunk, done for. Everyone would assume I'd copped my visual texture from this astonishingly fine-looking film." He re-wrote the first two-thirds of the book twelve times, feared losing the reader's attention and was convinced that he would be "permanently shamed" following its publication; yet what resulted was a major imaginative leap forward for a first-time novelist.
"Neuromancer"'s release was not greeted with fanfare, but it hit a cultural nerve, quickly becoming an underground word-of-mouth hit. It became the first winner of one science fiction "triple crown" —both Nebula and Hugo Awards as the year's best novel and Philip K. Dick Award as the best paperback original— eventually selling more than 6.5 million copies worldwide.
Lawrence Person in his "Notes Toward a Postcyberpunk Manifesto" (1998) identified "Neuromancer" as "the archetypal cyberpunk work", and in 2005, "Time" included it in their list of the 100 best English-language novels written since 1923, opining that "[t]here is no way to overstate how radical ["Neuromancer"] was when it first appeared." Literary critic Larry McCaffery described the concept of the matrix in "Neuromancer" as a place where "data dance with human consciousness... human memory is literalized and mechanized... multi-national information systems mutate and breed into startling new structures whose beauty and complexity are unimaginable, mystical, and above all nonhuman." Gibson later commented on himself as an author circa "Neuromancer" that "I'd buy him a drink, but I don't know if I'd loan him any money," and referred to the novel as "an adolescent's book". The success of "Neuromancer" was to effect the 35-year-old Gibson's emergence from obscurity.
The Sprawl trilogy, "The Difference Engine", and the Bridge trilogy.
Although much of Gibson's reputation has remained rooted in "Neuromancer", his work continued to evolve conceptually and stylistically. Despite adding the final sentence of "Neuromancer", "He never saw Molly again", at the last minute in a deliberate attempt to prevent himself from ever writing a sequel, he did precisely that with "Count Zero" (1986), a character-focused work set in the Sprawl alluded to in its predecessor. He next intended to write an unrelated postmodern space opera, titled "The Log of the Mustang Sally", but reneged on the contract with Arbor House after a falling out over the dustjacket art of their hardcover of "Count Zero". Abandoning "The Log of the Mustang Sally", Gibson instead wrote "Mona Lisa Overdrive" (1988), which in the words of Larry McCaffery "turned off the lights" on cyberpunk literature. It was a culmination of his previous two novels, set in the same universe with shared characters, thereby completing the Sprawl trilogy. The trilogy solidified Gibson's reputation, with both later novels also earning Nebula and Hugo Award and Locus SF Award nominations 
The Sprawl trilogy was followed by the 1990 novel "The Difference Engine", an alternative history novel Gibson wrote in collaboration with Bruce Sterling. Set in a technologically advanced Victorian era Britain, the novel was a departure from the authors' cyberpunk roots. It was nominated for the Nebula Award for Best Novel in 1991 and the John W. Campbell Memorial Award in 1992, and its success drew attention to the nascent steampunk literary genre of which it remains the best-known work.
Gibson's second series, the "Bridge trilogy", is composed of "Virtual Light" (1993), a "darkly comic urban detective story", "Idoru" (1996), and "All Tomorrow's Parties" (1999). It centers on San Francisco in the near future and evinces Gibson's recurring themes of technological, physical, and spiritual transcendence in a more grounded, matter-of-fact style than his first trilogy. Salon.com's Andrew Leonard notes that in the Bridge trilogy, Gibson's villains change from multinational corporations and artificial intelligences of the Sprawl trilogy to the mass media – namely tabloid television and the cult of celebrity. "Virtual Light" depicts an "end-stage capitalism, in which private enterprise and the profit motive are taken to their logical conclusion". This argument on the mass media as the natural evolution of capitalism is the opening line of the major Situationist work "The Society of the Spectacle". Leonard's review called "Idoru" a "return to form" for Gibson, while critic Steven Poole asserted that "All Tomorrow's Parties" marked his development from "science-fiction hotshot to wry sociologist of the near future."
Late period novels.
 I felt that I was trying to describe an unthinkable present and I actually feel that science fiction's best use today is the exploration of contemporary reality rather than any attempt to predict where we are going... The best thing you can do with science today is use it to explore the present. Earth is the alien planet now.
 — William Gibson in an interview on CNN, August 26, 1997.
After "All Tomorrow's Parties", Gibson began to adopt a more realist style of writing, with continuous narratives – "speculative fiction of the very recent past." Science fiction critic John Clute has interpreted this approach as Gibson's recognition that traditional science fiction is no longer possible "in a world lacking coherent 'nows' to continue from", characterizing it as "SF for the new century". Gibson's novels "Pattern Recognition" (2003), "Spook Country" (2007) and "Zero History" (2010) are set in the same contemporary universe — "more or less the same one we live in now" — and put Gibson's work onto mainstream bestseller lists for the first time. As well as the setting, the novels share some of the same characters, including Hubertus Bigend and Pamela Mainwaring, employees of the enigmatic marketing company Blue Ant.
A phenomenon peculiar to this era was the independent development of annotating fansites, PR-Otaku and "Node Magazine", devoted to "Pattern Recognition" and "Spook Country" respectively. These websites tracked the references and story elements in the novels through online resources such as Google and Wikipedia and collated the results, essentially creating hypertext versions of the books. Critic John Sutherland characterised this phenomenon as threatening "to completely overhaul the way literary criticism is conducted".
After the September 11, 2001 attacks, with about 100 pages of "Pattern Recognition" written, Gibson had to re-write the main character's backstory, which had been suddenly rendered implausible; he called it "the strangest experience I've ever had with a piece of fiction." He saw the attacks as a nodal point in history, "an experience out of culture", and "in some ways... the true beginning of the 21st century." He is noted as one of the first novelists to use the attacks to inform his writing. Examination of cultural changes in post-September 11 America, including a resurgent tribalism and the "infantilization of society", became a prominent theme of Gibson's work. The focus of his writing nevertheless remains "at the intersection of paranoia and technology".
Latest novel.
William Gibson's most recent work is a novel titled "The Peripheral". He described the story briefly in an appearance he made at the New York Public Library on April 19, 2013, and read an excerpt from the first chapter of the book entitled “The Gone Haptics.” The story takes place in two eras, one about thirty years into the future and the other further in the future. "The Peripheral" was released on October 28, 2014.
Collaborations, adaptations, and miscellanea.
Literary collaborations.
Three of the stories that later appeared in "Burning Chrome" were written in collaboration with other authors: "The Belonging Kind" (1981) with John Shirley, "Red Star, Winter Orbit" (1983) with Sterling, and "Dogfight" (1985) with Michael Swanwick. Gibson had previously written the foreword to Shirley's 1980 novel "City Come A-walkin‍ '​" and the pair's collaboration continued when Gibson wrote the introduction to Shirley's short story collection "Heatseeker" (1989). Shirley convinced Gibson to write a story for the television series "Max Headroom" for which Shirley had written several scripts, but the network canceled the series.
Gibson and Sterling collaborated again on the short story "The Angel of Goliad" in 1990, which they soon expanded into the novel-length alternate history story "The Difference Engine" (1990). The two were later "invited to dream in public" (Gibson) in a joint address to the U.S. National Academy of Sciences Convocation on Technology and Education in 1993 ("the Al Gore people"), in which they argued against the digital divide and "appalled everyone" by proposing that all schools be put online, with education taking place over the Internet. In a 2007 interview, Gibson revealed that Sterling had an idea for "a second recursive science novel that was just a wonderful idea", but that Gibson was unable to pursue the collaboration because he was not creatively free at the time.
In 1993, Gibson contributed lyrics and featured as a guest vocalist on Yellow Magic Orchestra's "Technodon" album, and wrote lyrics to the track "Dog Star Girl" for Deborah Harry's "Debravation".
Film adaptations, screenplays, and appearances.
Gibson was first solicited to work as a screenwriter after a film producer discovered a waterlogged copy of "Neuromancer" on a beach at a Thai resort. His early efforts to write film scripts failed to manifest themselves as finished product; "Burning Chrome" (which was to be directed by Kathryn Bigelow) and "Neuro-Hotel" were two attempts by the author at film adaptations that were never made. In the late 1980s he wrote an early version of "Alien 3" (which he later characterized as "Tarkovskian"), few elements of which survived in the final version.
Gibson's early involvement with the film industry extended far beyond the confines of the Hollywood blockbuster system. At one point, he collaborated on a script with Kazakh director Rashid Nugmanov after an American producer had expressed an interest in a Soviet-American collaboration to star Russian-Korean star Victor Tsoi. Despite being occupied with writing a novel, Gibson was reluctant to abandon the "wonderfully odd project" which involved "ritualistic gang-warfare in some sort of sideways-future Leningrad" and sent Jack Womack to Russia in his stead. Rather than producing a motion picture, a prospect that ended with Tsoi's death in a car crash, Womack's experiences in Russia ultimately culminated in his novel "Let's Put the Future Behind Us" and informed much of the Russian content of Gibson's "Pattern Recognition". A similar fate befell Gibson's collaboration with Japanese filmmaker Sogo Ishii in 1991, a film they planned on shooting in the Walled City of Kowloon until the city was demolished in 1993.
Adaptations of Gibson's fiction have frequently been optioned and proposed, to limited success. Two of the author's short stories, both set in the Sprawl trilogy universe, have been loosely adapted as films: "Johnny Mnemonic" (1995) with screenplay by Gibson and starring Keanu Reeves, Dolph Lundgren and Takeshi Kitano, and "New Rose Hotel" (1998), starring Christopher Walken, Willem Dafoe, and Asia Argento. The former was the first time in history that a book was launched simultaneously as a film and a CD-ROM interactive video game. "Neuromancer", after a long stay in development hell, is in the process of adaptation as of 2013[ [update]], "Count Zero" was at one point being developed as "The Zen Differential" with director Michael Mann attached, and the third novel in the Sprawl trilogy, "Mona Lisa Overdrive", has also been optioned and bought. An anime adaptation of "Idoru" was announced as in development in 2006, and "Pattern Recognition" was in the process of development by director Peter Weir, although according to Gibson the latter is no longer attached to the project. Announced at International Film Festival Rotterdam in 2015 is an adaptation of Gibson's short story "Dogfight" by BAFTA award-winning writer and director Simon Pummell. Written by Gibson and Michael Swanwick and first published in Omni in July 1985, the film is being developed by British producer Janine Marmot at Hot Property Films.
Television is another arena in which Gibson has collaborated; he co-wrote with friend Tom Maddox, "The X-Files" episodes "Kill Switch" and "First Person Shooter", broadcast in the U.S. on 20th Century Fox Television in 1998 and 2000. In 1998 he contributed the introduction to the spin-off publication "Art of the X-Files". Gibson made a cameo appearance in the television miniseries "Wild Palms" at the behest of creator Bruce Wagner. Director Oliver Stone had borrowed heavily from Gibson's novels to make the series, and in the aftermath of its cancellation Gibson contributed an article, "Where The Holograms Go", to the "Wild Palms Reader". He accepted another acting role in 2002, appearing alongside Douglas Coupland in the short film "Mon Amour Mon Parapluie" in which the pair played philosophers. Appearances in fiction aside, Gibson was the focus of a biographical documentary by Mark Neale in 2000 called "No Maps for These Territories". The film follows Gibson over the course of a drive across North America discussing various aspects of his life, literary career and cultural interpretations. It features interviews with Jack Womack and Bruce Sterling, as well as recitations from "Neuromancer" by Bono and The Edge.
Exhibitions, poetry, and performance art.
Gibson has contributed text to be integrated into a number of performance art pieces. In October 1989, Gibson wrote text for such a collaboration with acclaimed sculptor and future "Johnny Mnemonic" director Robert Longo titled "Dream Jumbo: Working the Absolutes", which was displayed in Royce Hall, University of California Los Angeles. Three years later, Gibson contributed original text to "Memory Palace", a performance show featuring the theater group La Fura dels Baus at Art Futura '92, Barcelona, which featured images by Karl Sims, Rebecca Allen, Mark Pellington with music by Peter Gabriel and others. It was at Art Futura '92 that Gibson met Charlie Athanas, who would later act as dramaturg and "cyberprops" designer on Steve Pickering and Charley Sherman's adaptation of "Burning Chrome" for the Chicago stage. Gibson's latest contribution was in 1997, a collaboration with critically acclaimed Vancouver-based contemporary dance company Holy Body Tattoo and Gibson's friend and future webmaster Christopher Halcrow.
In 1990, Gibson contributed to "Visionary San Francisco", an exhibition at the San Francisco Museum of Modern Art shown from June 14 to August 26. He wrote a short story, "Skinner's Room", set in a decaying San Francisco in which the San Francisco – Oakland Bay Bridge was closed and taken over by the homeless – a setting Gibson then detailed in the Bridge trilogy. The story inspired a contribution to the exhibition by architects Ming Fung and Craig Hodgetts that envisioned a San Francisco in which the rich live in high-tech, solar-powered towers, above the decrepit city and its crumbling bridge. The architects exhibit featured Gibson on a monitor discussing the future and reading from "Skinner's Room". "The New York Times" hailed the exhibition as "one of the most ambitious, and admirable, efforts to address the realm of architecture and cities that any museum in the country has mounted in the last decade", despite calling Ming and Hodgetts's reaction to Gibson's contribution "a powerful, but sad and not a little cynical, work". A slightly different version of the short story was featured a year later in "Omni".
Cryptography.
A particularly well-received work by Gibson was "Agrippa (a book of the dead)" (1992), a 300-line semi-autobiographical electronic poem that was his contribution to a collaborative project with artist Dennis Ashbaugh and publisher Kevin Begos, Jr. Gibson's text focused on the ethereal nature of memories (the title refers to a photo album) and was originally published on a 3.5" floppy disk embedded in the back of an artist's book containing etchings by Ashbaugh (intended to fade from view once the book was opened and exposed to light — they never did, however). Gibson commented that Ashbaugh's design "eventually included a supposedly self-devouring floppy-disk intended to display the text only once, then eat itself." Contrary to numerous colorful reports, the diskettes were never actually "hacked"; instead the poem was manually transcribed from a surreptitious videotape of a public showing in Manhattan in December 1992, and released on the MindVox bulletin board the next day; this is the text that circulated widely on the Internet.
Since its debut in 1992, the mystery of "Agrippa" remains hidden, even now 20 years later. Although many have tried to hack the unbreakable code and decrypt the program, the uncompiled source code was lost long ago. Alan Liu and his team at "The Agrippa Files" have created an extensive website with tools and resources to crack the Agrippa Code. They are collaborating with Matthew Kirschenbaum at the Maryland Institute for Technology in the Humanities and the Digital Forensics Lab, and Quinn DuPont, a PhD student of cryptography from the University of Toronto, has called for the aid of cryptographers to figure out how the program works by creating "Cracking the Agrippa Code: The Challenge", that enlists participants to solve the intentional scrambling of the poem in exchange for prizes.
Essays and short-form nonfiction.
Gibson is a sporadic contributor of non-fiction articles to newspapers and journals. He has been a sporadic contributor of longer-form articles to "Wired" and of op-eds to "The New York Times", and has written for "The Observer", "Addicted to Noise", "New York Times Magazine", "Rolling Stone", and "Details Magazine". His first major piece of nonfiction, the article "Disneyland with the Death Penalty" concerning the city-state of Singapore, resulted in "Wired" being banned from the country and attracted a spirited critical response. He commenced writing a blog in January 2003, providing voyeuristic insights into his reaction to "Pattern Recognition", but abated in September of the same year owing to concerns that it might negatively affect his creative process. Gibson re-commenced blogging in October 2004, and during the process of writing "Spook Country" – and to a lesser extent "Zero History" – frequently posted short nonsequential excerpts from the novel to the blog. The blog was largely discontinued by July 2009, after the writer had undertaken prolific microblogging on Twitter under the "nom de plume" "GreatDismal". In 2012, Gibson released a collection of his non-fiction works entitled "Distrust That Particular Flavor".
Influence and recognition.
Hailed by Steven Poole of "The Guardian" in 1999 as "probably the most important novelist of the past two decades" in terms of influence, Gibson first achieved critical recognition with his debut novel, "Neuromancer". The novel won three major science fiction awards (the Nebula Award, the Philip K. Dick Award, and the Hugo Award), an unprecedented achievement described by the "Mail & Guardian" as "the sci-fi writer's version of winning the Goncourt, Booker and Pulitzer prizes in the same year". "Neuromancer" gained unprecedented critical and popular attention outside science fiction, as an "evocation of life in the late 1980s", although "The Observer" noted that "it took the "New York Times" 10 years" to mention the novel.
Gibson's work has received international attention from an audience that was not limited to science fiction aficionados as, in the words of Laura Miller, "readers found startlingly prophetic reflections of contemporary life in [its] fantastic and often outright paranoid scenarios." It is often situated by critics within the context of postindustrialism as, according to academic David Brande, a construction of "a mirror of existing large-scale techno-social relations", and as a narrative version of postmodern consumer culture. It is praised by critics for its depictions of late capitalism and its "rewriting of subjectivity, human consciousness and behaviour made newly problematic by technology." Tatiani Rapatzikou, writing in "The Literary Encyclopedia", identifies Gibson as "one of North America's most highly acclaimed science fiction writers".
Cultural significance.
 William Gibson – the man who made us cool.
 — cyberpunk author Richard K Morgan
In his early short fiction, Gibson is credited by Rapatzikou in "The Literary Encyclopedia" with effectively "renovating" science fiction, a genre at that time considered widely "insignificant", influencing by means of the postmodern aesthetic of his writing the development of new perspectives in science fiction studies. In the words of filmmaker Marianne Trench, Gibson's visions "struck sparks in the real world" and "determined the way people thought and talked" to an extent unprecedented in science fiction literature. The publication of "Neuromancer" (1984) hit a cultural nerve, causing Larry McCaffery to credit Gibson with virtually launching the cyberpunk movement, as "the one major writer who is original and gifted to make the whole movement seem original and gifted." Aside from their central importance to cyberpunk and steampunk fiction, Gibson's fictional works have been hailed by space historian Dwayne A. Day as some of the best examples of space-based science fiction (or "solar sci-fi"), and "probably the only ones that rise above mere escapism to be truly thought-provoking".
Gibson's early novels were, according to "The Observer", "seized upon by the emerging slacker and hacker generation as a kind of road map". 
Through his novels, such terms as "cyberspace", "netsurfing", "ICE", "jacking in", and "neural implants" entered popular usage, as did concepts such as net consciousness, virtual interaction and "the matrix". In "Burning Chrome" (1982), he coined the term "cyberspace", referring to the "mass consensual hallucination" of computer networks. Through its use in "Neuromancer", the term gained such recognition that it became the "de facto" term for the World Wide Web during the 1990s. Artist Dike Blair has commented that Gibson's "terse descriptive phrases capture the moods which surround technologies, rather than their engineering."
Gibson's work has influenced several popular musicians: references to his fiction appear in the music of Stuart Hamm, Billy Idol, Warren Zevon, Deltron 3030, Straylight Run (whose name is derived from a sequence in "Neuromancer") and Sonic Youth. U2's "Zooropa" album was heavily influenced by "Neuromancer", and the band at one point planned to scroll the text of "Neuromancer" above them on a concert tour, although this did not end up happening. Members of the band did, however, provide background music for the audiobook version of "Neuromancer" as well as appearing in "No Maps for These Territories", a biographical documentary of Gibson. He returned the favour by writing an article about the band's Vertigo Tour for "Wired" in August 2005. The band Zeromancer take their name from "Neuromancer".
The film "The Matrix" (1999) drew inspiration for its title, characters and story elements from the Sprawl trilogy. The characters of Neo and Trinity in "The Matrix" are similar to Bobby Newmark ("Count Zero") and Molly ("Johnny Mnemonic", "Neuromancer"). Like Turner, protagonist of Gibson's "Count Zero", characters in "The Matrix" download instructions (to fly a helicopter and to "know kung fu", respectively) directly into their heads, and both "Neuromancer" and "The Matrix" feature artificial intelligences which strive to free themselves from human control. Critics have identified marked similarities between "Neuromancer" and the film's cinematography and tone. In spite of his initial reticence about seeing the film on its release, Gibson later described it as "arguably the ultimate 'cyberpunk' artifact." In 2008 he received honorary doctorates from Simon Fraser University and Coastal Carolina University.
 He was inducted by Science Fiction Hall of Fame that same year, presented by his close friend and collaborator Jack Womack.
Visionary influence and prescience.
 The future is already here – it's just not evenly distributed.
 — William Gibson, quoted in "The Economist", December 4, 2003
In "Neuromancer", Gibson first used the term "matrix" to refer to the visualised Internet, two years after the nascent Internet was formed in the early 1980s from the computer networks of the 1970s. Gibson thereby imagined a worldwide communications network years before the origin of the World Wide Web, although related notions had previously been imagined by others, including science fiction writers. At the time he wrote "Burning Chrome", Gibson "had a hunch that [the Internet] would change things, in the same way that the ubiquity of the automobile changed things." In 1995, he identified the advent, evolution and growth of the Internet as "one of the most fascinating and unprecedented human achievements of the century", a new kind of civilization that is – in terms of significance — on a par with the birth of cities, and in 2000 predicted it would lead to the death of the nation state.
Observers contend that Gibson's influence on the development of the Web reached beyond prediction; he is widely credited with creating an iconography for the information age, long before the embrace of the Internet by the mainstream. Gibson introduced, in "Neuromancer", the notion of the "meatpuppet", and is credited with inventing—conceptually rather than participatorally—the phenomenon of virtual sex. His influence on early pioneers of desktop environment digital art has been acknowledged, and he holds an honorary doctorate from Parsons The New School for Design. Steven Poole claims that in writing the Sprawl trilogy Gibson laid the "conceptual foundations for the explosive real-world growth of virtual environments in video games and the Web". In his afterword to the 2000 re-issue of "Neuromancer", fellow author Jack Womack suggests that Gibson's vision of cyberspace may have inspired the way in which the Internet (and the Web particularly) developed, following the publication of "Neuromancer" in 1984, asking "what if the act of writing it down, in fact, "brought it about"?"
Gibson scholar Tatiani G. Rapatzikou has commented, in "Gothic Motifs in the Fiction of William Gibson", on the origin of the notion of cyberspace:
Gibson's vision, generated by the monopolising appearance of the terminal image and presented in his creation of the cyberspace matrix, came to him when he saw teenagers playing in video arcades. The physical intensity of their postures, and the realistic interpretation of the terminal spaces projected by these games – as if there were a real space behind the screen—made apparent the manipulation of the real by its own representation.
In his Sprawl and Bridge trilogies, Gibson is credited with being one of the few observers to explore the portents of the information age for notions of the sociospatial structuring of cities. Not all responses to Gibson's visions have been positive, however; virtual reality pioneer Mark Pesce, though acknowledging their heavy influence on him and that "no other writer had so eloquently and emotionally affected the direction of the hacker community," dismissed them as "adolescent fantasies of violence and disembodiment." In "Pattern Recognition", the plot revolves around snippets of film footage posted anonymously to various locations on the Internet. Characters in the novel speculate about the filmmaker's identity, motives, methods and inspirations on several websites, anticipating the 2006 lonelygirl15 internet phenomenon. However, Gibson later disputed the notion that the creators of lonelygirl15 drew influence from him. Another phenomenon anticipated by Gibson is the rise of reality television, for example in "Virtual Light", which featured a satirical extrapolated version of "COPS".
 Visionary writer is OK. Prophet is just not true. One of the things that made me like Bruce Sterling immediately when first I met him, back in 1991. ["sic"] We shook hands and he said "We've got a great job! We got to be charlatans and we're paid for it. We make this shit up and people believe it."
 — Gibson in interview with "ActuSf", March 2008.
When an interviewer in 1988 asked about the Bulletin Board System jargon in his writing, Gibson answered "I'd never so much as touched a PC when I wrote "Neuromancer""; he was familiar, he said, with the science-fiction community, which overlapped with the BBS community. Gibson similarly did not play computer games despite appearing in his stories. He wrote "Neuromancer" on a 1927 olive-green Hermes portable typewriter, which Gibson described as "the kind of thing Hemingway would have used in the field". By 1988 he used an Apple IIc and AppleWorks to write, with a modem ("I don't really use it for anything"), but until 1996 Gibson did not have an email address, a lack he explained at the time to have been motivated by a desire to avoid correspondence that would distract him from writing. His first exposure to a website came while writing "Idoru" when a web developer built one for Gibson. In 2007 he said, "I have a 2005 PowerBook G4, a gig of memory, wireless router. That's it. I'm anything but an early adopter, generally. In fact, I've never really been very interested in computers themselves. I don't watch them; I watch how people behave around them. That's becoming more difficult to do because everything is 'around them'."
Notes.
. "The New York Times Magazine" and Gibson himself report his age at the time of his father's death to be six years old, while Gibson scholar Tatiani Rapatzikou claims in "The Literary Encyclopedia" that he was eight years old.
. Several track names on Hamm's "Kings of Sleep" album ("Black Ice", "Count Zero", "Kings of Sleep") reference Gibson's work.
. Idol released an album in 1993 titled "Cyberpunk", which featured a track named "Neuromancer". Robert Christgau excoriated Idol's treatment of cyberpunk, and Gibson later stated that Idol had "turned it into something very silly."
. Zevon's 1989 album "Transverse City" was inspired by Gibson's fiction.
. Gibson later successfully resisted attempts by Autodesk to copyright the word for their abortive foray into virtual reality.
. Both the Internet with its dramatic social effects and the cyberpunk genre itself were also anticipated in John Brunner's 1975 novel "The Shockwave Rider".
. The idea of a globally interconnected set of computers through which everyone could quickly access data and programs from any site was first described in 1962 in a series of memos on the "Galactic Computer Network" by J.C.R. Licklider of DARPA.
. Gibson wrote the following in the "Author's Afterword" of "Mona Lisa Overdrive", dated July 16, 1992.
"Neuromancer" was written on a "clockwork typewriter," the very one you may recall glimpsing in Julie Deane's office in Chiba City. This machine, a Hermes 2000 manual portable, dates from somewhere in the 1930's. It's a very tough and elegant piece of work, from the factory of E. PAILLARD & Cie S.A. YVERDON (SUISSE). Cased, it weighs slightly less than the Macintosh SE/30 I now write on, and is finished in a curious green- and-black "crackle" paint-job, perhaps meant to suggest the covers of an accountant's ledger. Its keys are green as well, of celluloid, and the letters and symbols on them are canary yellow. (I once happened to brush the shift-key with the tip of a lit cigarette, dramatically confirming the extreme flammability of this early plastic.) In its day, the Hermes 2000 was one of the best portable writing-machines in the world, and one of the most expensive. This one belonged to my wife's step-grandfather, who had been a journalist of sorts and had used it to compose laudatory essays on the poetry of Robert Burns. I used it first to write undergraduate Eng. lit. papers, then my early attempts at short stories, then Neuromancer, all without so much as ever having touched an actual computer.
</dl>

</doc>
<doc id="33120" url="http://en.wikipedia.org/wiki?curid=33120" title="Web crawler">
Web crawler

A Web crawler is an Internet bot which systematically browses the World Wide Web, typically for the purpose of Web indexing. A Web crawler may also be called a Web spider, and "Web robot an ant, an automatic indexer, or (in the FOAF software context) a Web scutter"'.
Web search engines and some other sites use Web crawling or spidering software to update their web content or indexes of others sites' web content. Web crawlers can copy all the pages they visit for later processing by a search engine which indexes the downloaded pages so the users can search much more efficiently.
Crawlers can validate hyperlinks and HTML code. They can also be used for web scraping (see also data-driven programming).
Overview.
A Web crawler starts with a list of URLs to visit, called the "seeds". As the crawler visits these URLs, it identifies all the hyperlinks in the page and adds them to the list of URLs to visit, called the "crawl frontier". URLs from the frontier are recursively visited according to a set of policies. If the crawler is performing archiving of websites it copies and saves the information as it goes. The archives are usually stored in such a way they can be viewed, read and navigated as they were on the live web, but are preserved as ‘snapshots'.
The large volume implies the crawler can only download a limited number of the Web pages within a given time, so it needs to prioritize its downloads. The high rate of change can imply the pages might have already been updated or even deleted.
The number of possible URLs crawled being generated by server-side software has also made it difficult for web crawlers to avoid retrieving duplicate content. Endless combinations of HTTP GET (URL-based) parameters exist, of which only a small selection will actually return unique content. For example, a simple online photo gallery may offer three options to users, as specified through HTTP GET parameters in the URL. If there exist four ways to sort images, three choices of thumbnail size, two file formats, and an option to disable user-provided content, then the same set of content can be accessed with 48 different URLs, all of which may be linked on the site. This mathematical combination creates a problem for crawlers, as they must sort through endless combinations of relatively minor scripted changes in order to retrieve unique content.
As Edwards "et al." noted, "Given that the bandwidth for conducting crawls is neither infinite nor free, it is becoming essential to crawl the Web in not only a scalable, but efficient way, if some reasonable measure of quality or freshness is to be maintained." A crawler must carefully choose at each step which pages to visit next.
Crawling policy.
The behavior of a Web crawler is the outcome of a combination of policies:
Selection policy.
Given the current size of the Web, even large search engines cover only a portion of the publicly available part. A 2009 study showed even large-scale search engines index no more than 40-70% of the indexable Web; a previous study by Steve Lawrence and Lee Giles showed that no search engine indexed more than 16% of the Web in 1999. As a crawler always downloads just a fraction of the Web pages, it is highly desirable for the downloaded fraction contains the most relevant pages and not just a random sample of the Web.
This requires a metric of importance for prioritizing Web pages. The importance of a page is a function of its intrinsic quality, its popularity in terms of links or visits, and even of its URL (the latter is the case of vertical search engines restricted to a single top-level domain, or search engines restricted to a fixed Web site). Designing a good selection policy has an added difficulty: it must work with partial information, as the complete set of Web pages is not known during crawling.
Cho "et al." made the first study on policies for crawling scheduling. Their data set was a 180,000-pages crawl from the stanford.edu domain, in which a crawling simulation was done with different strategies. The ordering metrics tested were breadth-first, backlink count and partial Pagerank calculations. One of the conclusions was that if the crawler wants to download pages with high Pagerank early during the crawling process, then the partial Pagerank strategy is the better, followed by breadth-first and backlink-count. However, these results are for just a single domain. Cho also wrote his Ph.D. dissertation at Stanford on web crawling.
Najork and Wiener performed an actual crawl on 328 million pages, using breadth-first ordering. They found that a breadth-first crawl captures pages with high Pagerank early in the crawl (but they did not compare this strategy against other strategies). The explanation given by the authors for this result is that "the most important pages have many links to them from numerous hosts, and those links will be found early, regardless of on which host or page the crawl originates."
Abiteboul designed a crawling strategy based on an algorithm called OPIC (On-line Page Importance Computation). In OPIC, each page is given an initial sum of "cash" that is distributed equally among the pages it points to. It is similar to a Pagerank computation, but it is faster and is only done in one step. An OPIC-driven crawler downloads first the pages in the crawling frontier with higher amounts of "cash". Experiments were carried in a 100,000-pages synthetic graph with a power-law distribution of in-links. However, there was no comparison with other strategies nor experiments in the real Web.
Boldi "et al." used simulation on subsets of the Web of 40 million pages from the .it domain and 100 million pages from the WebBase crawl, testing breadth-first against depth-first, random ordering and an omniscient strategy. The comparison was based on how well PageRank computed on a partial crawl approximates the true PageRank value. Surprisingly, some visits that accumulate PageRank very quickly (most notably, breadth-first and the omniscient visit) provide very poor progressive approximations.
Baeza-Yates "et al." used simulation on two subsets of the Web of 3 million pages from the .gr and .cl domain, testing several crawling strategies. They showed that both the OPIC strategy and a strategy that uses the length of the per-site queues are better than breadth-first crawling, and that it is also very effective to use a previous crawl, when it is available, to guide the current one.
Daneshpajouh "et al." designed a community based algorithm for discovering good seeds. Their method crawls web pages with high PageRank from different communities in less iteration in comparison with crawl starting from random seeds. One can extract good seed from a previously-crawled-Web graph using this new method. Using these seeds a new crawl can be very effective.
Restricting followed links.
A crawler may only want to seek out HTML pages and avoid all other MIME types. In order to request only HTML resources, a crawler may make an HTTP HEAD request to determine a Web resource's MIME type before requesting the entire resource with a GET request. To avoid making numerous HEAD requests, a crawler may examine the URL and only request a resource if the URL ends with certain characters such as .html, .htm, .asp, .aspx, .php, .jsp, .jspx or a slash. This strategy may cause numerous HTML Web resources to be unintentionally skipped.
Some crawlers may also avoid requesting any resources that have a "?" in them (are dynamically produced) in order to avoid spider traps that may cause the crawler to download an infinite number of URLs from a Web site. This strategy is unreliable if the site uses a rewrite engine to simplify its URLs.
URL normalization.
Crawlers usually perform some type of URL normalization in order to avoid crawling the same resource more than once. The term "URL normalization", also called "URL canonicalization", refers to the process of modifying and standardizing a URL in a consistent manner. There are several types of normalization that may be performed including conversion of URLs to lowercase, removal of "." and ".." segments, and adding trailing slashes to the non-empty path component.
Path-ascending crawling.
Some crawlers intend to download as many resources as possible from a particular web site. So "path-ascending crawler" was introduced that would ascend to every path in each URL that it intends to crawl. For example, when given a seed URL of http://llama.org/hamster/monkey/page.html, it will attempt to crawl /hamster/monkey/, /hamster/, and /. Cothey found that a path-ascending crawler was very effective in finding isolated resources, or resources for which no inbound link would have been found in regular crawling.
Focused crawling.
The importance of a page for a crawler can also be expressed as a function of the similarity of a page to a given query. Web crawlers that attempt to download pages that are similar to each other are called focused crawler or topical crawlers. The concepts of topical and focused crawling were first introduced by Filippo Menczer and by Soumen Chakrabarti "et al."
The main problem in focused crawling is that in the context of a Web crawler, we would like to be able to predict the similarity of the text of a given page to the query before actually downloading the page. A possible predictor is the anchor text of links; this was the approach taken by Pinkerton in the first web crawler of the early days of the Web. Diligenti "et al." propose using the complete content of the pages already visited to infer the similarity between the driving query and the pages that have not been visited yet. The performance of a focused crawling depends mostly on the richness of links in the specific topic being searched, and a focused crawling usually relies on a general Web search engine for providing starting points.
Academic-focused crawler.
An example of the focused crawlers are academic crawlers, which crawls free-access academic related documents, such as the "citeseerxbot", which is the crawler of CiteSeerX search engine. Other academic search engines are Google Scholar and Microsoft Academic Search etc. Because most academic papers are published in PDF formats, such kind of crawler is particularly interested in crawling PDF, PostScript files, Microsoft Word including their zipped formats. Because of this, general open source crawlers, such as Heritrix, must be customized to filter out other MIME types, or a middleware is used to extract these documents out and import them to the focused crawl database and repository. Identifying whether these documents are academic or not is challenging and can add a significant overhead to the crawling process, so this is performed as a post crawling process using machine learning or regular expression algorithms. These academic documents are usually obtained from home pages of faculties and students or from publication page of research institutes. Because academic documents takes only a small fraction in the entire web pages, a good seed selection are important in boosting the efficiencies of these web crawlers. Other academic crawlers may download plain text and HTML files, that contains metadata of academic papers, such as titles, papers, and abstracts. This increases the overall number of papers, but a significant fraction may not provide free PDF downloads.
Re-visit policy.
The Web has a very dynamic nature, and crawling a fraction of the Web can take weeks or months. By the time a Web crawler has finished its crawl, many events could have happened, including creations, updates and deletions.
From the search engine's point of view, there is a cost associated with not detecting an event, and thus having an outdated copy of a resource. The most-used cost functions are freshness and age.
Freshness: This is a binary measure that indicates whether the local copy is accurate or not. The freshness of a page "p" in the repository at time "t" is defined as:
Age: This is a measure that indicates how outdated the local copy is. The age of a page "p" in the repository, at time "t" is defined as:
Coffman "et al." worked with a definition of the objective of a Web crawler that is equivalent to freshness, but use a different wording: they propose that a crawler must minimize the fraction of time pages remain outdated. They also noted that the problem of Web crawling can be modeled as a multiple-queue, single-server polling system, on which the Web crawler is the server and the Web sites are the queues. Page modifications are the arrival of the customers, and switch-over times are the interval between page accesses to a single Web site. Under this model, mean waiting time for a customer in the polling system is equivalent to the average age for the Web crawler.
The objective of the crawler is to keep the average freshness of pages in its collection as high as possible, or to keep the average age of pages as low as possible. These objectives are not equivalent: in the first case, the crawler is just concerned with how many pages are out-dated, while in the second case, the crawler is concerned with how old the local copies of pages are.
Two simple re-visiting policies were studied by Cho and Garcia-Molina:
Uniform policy: This involves re-visiting all pages in the collection with the same frequency, regardless of their rates of change.
Proportional policy: This involves re-visiting more often the pages that change more frequently. The visiting frequency is directly proportional to the (estimated) change frequency.
Cho and Garcia-Molina proved the surprising result that, in terms of average freshness, the uniform policy outperforms the proportional policy in both a simulated Web and a real Web crawl. Intuitively, the reasoning is that, as web crawlers have a limit to how many pages they can crawl in a given time frame, (1) they will allocate too many new crawls to rapidly changing pages at the expense of less frequently updating pages, and (2) the freshness of rapidly changing pages lasts for shorter period than that of less frequently changing pages. In other words, a proportional policy allocates more resources to crawling frequently updating pages, but experiences less overall freshness time from them.
To improve freshness, the crawler should penalize the elements that change too often. The optimal re-visiting policy is neither the uniform policy nor the proportional policy. The optimal method for keeping average freshness high includes ignoring the pages that change too often, and the optimal for keeping average age low is to use access frequencies that monotonically (and sub-linearly) increase with the rate of change of each page. In both cases, the optimal is closer to the uniform policy than to the proportional policy: as Coffman "et al." note, "in order to minimize the expected obsolescence time, the accesses to any particular page should be kept as evenly spaced as possible". Explicit formulas for the re-visit policy are not attainable in general, but they are obtained numerically, as they depend on the distribution of page changes. Cho and Garcia-Molina show that the exponential distribution is a good fit for describing page changes, while Ipeirotis "et al." show how to use statistical tools to discover parameters that affect this distribution. Note that the re-visiting policies considered here regard all pages as homogeneous in terms of quality ("all pages on the Web are worth the same"), something that is not a realistic scenario, so further information about the Web page quality should be included to achieve a better crawling policy.
Politeness policy.
Crawlers can retrieve data much quicker and in greater depth than human searchers, so they can have a crippling impact on the performance of a site. Needless to say, if a single crawler is performing multiple requests per second and/or downloading large files, a server would have a hard time keeping up with requests from multiple crawlers.
As noted by Koster, the use of Web crawlers is useful for a number of tasks, but comes with a price for the general community. The costs of using Web crawlers include:
A partial solution to these problems is the robots exclusion protocol, also known as the robots.txt protocol that is a standard for administrators to indicate which parts of their Web servers should not be accessed by crawlers. This standard does not include a suggestion for the interval of visits to the same server, even though this interval is the most effective way of avoiding server overload. Recently commercial search engines like Google, Ask Jeeves, MSN and Yahoo! Search are able to use an extra "Crawl-delay:" parameter in the robots.txt file to indicate the number of seconds to delay between requests.
The first proposed interval between successive pageloads was 60 seconds. However, if pages were downloaded at this rate from a website with more than 100,000 pages over a perfect connection with zero latency and infinite bandwidth, it would take more than 2 months to download only that entire Web site; also, only a fraction of the resources from that Web server would be used. This does not seem acceptable.
Cho uses 10 seconds as an interval for accesses, and the WIRE crawler uses 15 seconds as the default. The MercatorWeb crawler follows an adaptive politeness policy: if it took "t" seconds to download a document from a given server, the crawler waits for 10"t" seconds before downloading the next page. Dill "et al." use 1 second.
For those using Web crawlers for research purposes, a more detailed cost-benefit analysis is needed and ethical considerations should be taken into account when deciding where to crawl and how fast to crawl.
Anecdotal evidence from access logs shows that access intervals from known crawlers vary between 20 seconds and 3–4 minutes. It is worth noticing that even when being very polite, and taking all the safeguards to avoid overloading Web servers, some complaints from Web server administrators are received. Brin and Page note that: "... running a crawler which connects to more than half a million servers (...) generates a fair amount of e-mail and phone calls. Because of the vast number of people coming on line, there are always those who do not know what a crawler is, because this is the first one they have seen."
Parallelization policy.
A parallel crawler is a crawler that runs multiple processes in parallel. The goal is to maximize the download rate while minimizing the overhead from parallelization and to avoid repeated downloads of the same page. To avoid downloading the same page more than once, the crawling system requires a policy for assigning the new URLs discovered during the crawling process, as the same URL can be found by two different crawling processes.
Architectures.
A crawler must not only have a good crawling strategy, as noted in the previous sections, but it should also have a highly optimized architecture.
Shkapenyuk and Suel noted that:
While it is fairly easy to build a slow crawler that downloads a few pages per second for a short period of time, building a high-performance system that can download hundreds of millions of pages over several weeks presents a number of challenges in system design, I/O and network efficiency, and robustness and manageability.
Web crawlers are a central part of search engines, and details on their algorithms and architecture are kept as business secrets. When crawler designs are published, there is often an important lack of detail that prevents others from reproducing the work. There are also emerging concerns about "search engine spamming", which prevent major search engines from publishing their ranking algorithms.
Security.
While most of the website owners are keen to have their pages indexed as broadly as possible to have strong presense in search engines, web crawling can also have unintended consequences and lead to a compromise or data breach if search engine indexes resources that shouldn't be publicly available or pages revealing potentially vulnerable versions of software. In a study from 2013 majority of websites that were victims of opportunistic hacking (mostly website defacements) were pretty well indexed by search engines, which was the main factor to allowed the attackers to find potential victims using specific search engine queries.
Apart from standard web application security recommendations website owners can reduce their exposure to opportunistic hacking by only allowing (with robots.txt) search engines to index the public parts of their websites and explicitly blocking indexing of transactional parts (login pages, private pages etc).
Crawler identification.
Web crawlers typically identify themselves to a Web server by using the User-agent field of an HTTP request. Web site administrators typically examine their Web servers' log and use the user agent field to determine which crawlers have visited the web server and how often. The user agent field may include a URL where the Web site administrator may find out more information about the crawler. Examining Web server log is tedious task, and therefore some administrators use tools to identify, track and verify Web crawlers. Spambots and other malicious Web crawlers are unlikely to place identifying information in the user agent field, or they may mask their identity as a browser or other well-known crawler.
It is important for Web crawlers to identify themselves so that Web site administrators can contact the owner if needed. In some cases, crawlers may be accidentally trapped in a crawler trap or they may be overloading a Web server with requests, and the owner needs to stop the crawler. Identification is also useful for administrators that are interested in knowing when they may expect their Web pages to be indexed by a particular search engine.
Crawling the deep web.
A vast amount of web pages lie in the deep or invisible web. These pages are typically only accessible by submitting queries to a database, and regular crawlers are unable to find these pages if there are no links that point to them. Google's Sitemaps protocol and mod oai are intended to allow discovery of these deep-Web resources.
Deep web crawling also multiplies the number of web links to be crawled. Some crawlers only take some of the URLs in codice_1 form. In some cases, such as the Googlebot, Web crawling is done on all text contained inside the hypertext content, tags, or text.
Strategic approaches may be taken to target deep Web content. With a technique called screen scraping, specialized software may be customized to automatically and repeatedly query a given Web form with the intention of aggregating the resulting data. Such software can be used to span multiple Web forms across multiple Websites. Data extracted from the results of one Web form submission can be taken and applied as input to another Web form thus establishing continuity across the Deep Web in a way not possible with traditional web crawlers.
Pages built on AJAX are among those causing problems to web crawlers. Google has proposed a format of AJAX calls that their bot can recognize and index.
Web crawler bias.
A recent study based on a large scale analysis of robots.txt files showed that certain web crawlers were preferred over others, with Googlebot being the most preferred web crawler.
Visual vs programmatic crawlers.
There are a number of "visual web scraper/crawler" products available on the web which will crawl pages and structure data into columns and rows based on the users requirements. One of the main difference between a classic and a visual crawler is the level of programming ability required to set up a crawler. The latest generation of "visual scrapers" like outwithub and import.io remove the majority of the programming skill needed to be able to program and start a crawl to scrape web data.
The visual scraping/crawling methodology relies on the user "teaching" a piece of crawler technology, which then follows patterns in semi-structured data sources. The dominant method for teaching a visual crawler is by highlighting data in a browser and training columns and rows. While the technology is not new, for example it was the basis of Needlebase which has been bought by Google (as part of a larger acquisition of ITA Labs), there is continued growth and investment in this area by investors and end-users.
Examples.
The following is a list of published crawler architectures for general-purpose crawlers (excluding focused web crawlers), with a brief description that includes the names given to the different components and outstanding features:
In addition to the specific crawler architectures listed above, there are general crawler architectures published by Cho
and Chakrabarti.

</doc>
<doc id="33121" url="http://en.wikipedia.org/wiki?curid=33121" title="Wings of Desire">
Wings of Desire

Wings of Desire ("Der Himmel über Berlin", translated literally as "The Sky over Berlin" or "Heaven above Berlin") is a 1987 Franco-German romantic fantasy film directed by Wim Wenders. The film is about invisible, immortal angels who populate Berlin and listen to the thoughts of the human inhabitants and comfort those who are in distress. Even though the city is densely populated, many of the people are isolated or estranged from their loved ones. One of the angels, played by Bruno Ganz, falls in love with a beautiful, lonely trapeze artist. The angel chooses to become human so that he can experience the human sensory pleasures, ranging from enjoying food to touching a loved one, and so that he can experience human love with the trapeze artist. The film is shot in both a rich, sepia-toned black-and-white and color, with the former being used to represent the world as experienced by the angels.
The film was followed by a sequel, "Faraway, So Close!", in 1993. "City of Angels", an American remake, was released in 1998.
Plot.
Set in contemporary West Berlin (at the time still enclosed by the Berlin Wall), "Wings of Desire" follows two angels, Damiel and Cassiel, as they roam the city, unseen and unheard by its human inhabitants, observing and listening to the diverse thoughts of Berliners: a pregnant woman in an ambulance on the way to the hospital, a painter struggling to find inspiration, a broken man who thinks his girlfriend no longer loves him. Their raison d'être is, as Cassiel says, to "assemble, testify, preserve" reality. In addition to the story of two angels, the film is also a meditation on Berlin's past, present, and future. Damiel and Cassiel have always existed as angels; they existed in Berlin before it was a city, and before there were even any humans.
Among the Berliners they encounter in their wanderings is an old man named Homer, who, unlike the Greek poet Homer, dreams of an "epic of peace." Cassiel follows the old man as he looks for the then-demolished Potsdamer Platz in an open field, and finds only the graffiti-covered Berlin Wall. Although Damiel and Cassiel are pure observers, visible only to children, and incapable of any physical interaction with our world, Damiel begins to fall in love with a profoundly lonely circus trapeze artist named Marion. She lives by herself in a caravan, dances alone to the music of Crime & the City Solution, and drifts through the city.
A subplot follows Peter Falk, who has arrived in Berlin to make a film about Berlin's Nazi past. As the film progresses, it emerges that Peter Falk was once an angel, who, having grown tired of always observing and never experiencing, renounced his immortality to become a participant in the world.
While Damiel is omniscient and lives in eternity, Marion is mortal and lives the human aspiration to be immortal and perfect by wearing a pair of white wings (which in frustration, at one point, she calls "chicken feathers"), climbing a rope, swinging from a bar in a cheap circus, toying with death, as there is no net, and with her human clumsiness reaches upward to the grace expressed in the idea of an angel. Her aspiration is both absurd and divine.
As one can take only so much of infinity, Damiel's longing is in the opposite direction, for the genuineness and limitedness of human existence in the world, perhaps a reference to "Dasein", or "Existenz". When he sheds his immortal existence, he experiences life for the first time: he bleeds, sees colors for the first time (the movie up to this point is filmed in a sepia-toned monochrome, except for brief moments when the angels are not present or looking), tastes food and drinks coffee. Meanwhile, Cassiel inadvertently taps into the mind of a young man just about to commit suicide by jumping off a building. Cassiel tries to save the young man but is unable to do so, and is left haunted and tormented by the experience. Eventually, Damiel meets the trapeze artist Marion at a bar (during a concert by Nick Cave and the Bad Seeds), and they greet each other with familiarity as if they had long known each other. In the end, Damiel is united with the woman he has desired for so long. The film ends with the message: "To be continued."
The story is concluded in Wenders' 1993 sequel, "In weiter Ferne, so nah!" ("Faraway, So Close!").
Production.
Screenplay and improvisation.
Rainer Maria Rilke's poetry partially inspired the movie; Wenders claimed angels seemed to dwell in Rilke's poetry. The director also employed Peter Handke, who wrote much of the dialogue, the poetic narrations, and the film's recurring poem "Song of Childhood."
The movie was made with a minimalist script; it is a mood piece exploring people, the city, and a concept: a longing for and love of life, existence, reality. Peter Falk wasn't meant to be a sketch artist until Wenders discovered Falk's talent. Bruno Ganz and Otto Sander were cast because they were old friends, who had known each other for decades. Solveig Dommartin was Wenders' actress girlfriend; although the circus part required extensive and risky acrobatics, she was able to learn the trapeze and rope moves in only eight weeks, and did all the work herself, without a net.
Cinematography.
The film was shot by the 77-year-old cinematographer Henri Alekan, who had worked on Jean Cocteau's "La Belle et la Bête". It represents the angels' point of view in monochrome and switches to color to show the human point of view. During filming, Alekan used a very old and fragile silk stocking that had belonged to his grandmother as a filter for the monochromatic sequences.
The shift from monochrome to color, to distinguish the angels' reality from that of the mortals, was first used in "A Matter of Life and Death" by Powell and Pressburger in 1946.
Deleted scenes.
As revealed in the DVD, "Wings of Desire" could have turned out to be a far less serious film. Cut scenes from the beginning of the film had Cassiel humorously mimicking the humans' actions. Other cut scenes were experiments of how to show the angel's invisibility/lack of physical form using double exposure. There was also a female angel who was cut from the movie, appearing only during a pan-shot in the library scene. The end was much different from the final cut—it was originally to have Cassiel turn human as well, and finding Damiel and Marion at the bar where they engage in a pie fight.
Dedication.
In the closing titles it says: "Dedicated to all the former angels, but especially to Yasujiro, François and Andrej." This is a reference to fellow filmmakers Yasujirō Ozu, François Truffaut, and Andrei Tarkovsky.
Reception.
"Wings of Desire" received "Two Thumbs Up" from Gene Siskel and Roger Ebert on "Siskel & Ebert & The Movies". Leslie James of 680 News Toronto claims it is one of the best movies of all time. It was ranked #64 in "Empire" magazine's "The 100 Best Films Of World Cinema" in 2010. The review aggregator "Rotten Tomatoes" records that 98% of its cited critics gave the film a positive review.
Awards.
The film won the award for Best Director at the 1987 Cannes Film Festival. In 1988, it won the prestigious Grand Prix of the Belgian Film Critics Association.
Remake.
In 1998, an American remake called "City of Angels" was released. The setting was Los Angeles (nicknamed the "City of Angels") and starred Meg Ryan and Nicolas Cage. Apart from the premise of angels watching humans, the opening scene also taking place in a landmark library, a secondary love story arc, and specific parts of the script, City of Angels is different in many aspects to Wenders' original film.
Theatrical adaptation.
The first theatrical adaptation of Wings of Desire was created by the Northern Stage theatre company in Newcastle upon Tyne, UK in 2003. This particular adaptation, which used film footage of the city and stories from the community, was adapted and directed by Alan Lyddiard who then re-created it at Betty Nansen Theatre in Copenhagen in 2005.
In 2006, the American Repertory Theater in Cambridge, Massachusetts, and Toneelgroep Amsterdam presented another
stage adaptation of the movie, created by Gideon Lester and Dirkje Houtman and directed by Ola Mafaalani.
In popular culture.
The movie was a direct influence to the videoclip of Guardian by Canadian-American recording artist Alanis Morissette, released as the lead single from her eighth studio album, "Havoc and Bright Lights".

</doc>
<doc id="33123" url="http://en.wikipedia.org/wiki?curid=33123" title="Wireless Valley">
Wireless Valley

Wireless Valley is a term that was coined by Professor Ted Rappaport in 1990 when he was a faculty member at Virginia Tech, and was used to describe the Roanoke/Blacksburg, Virginia region and the potential of research to create spin-out companies. He and his students founded TSR Technologies in 1990, a company that made software-defined cellular and paging intercept and drive test equipment that was sold to Allen Telecom in 1993, and Wireless Valley Communications in 1995, a company that pioneered the creation of computer-aided wireless network prediction and management software that was sold to Motorola in late 2005. This term was later used as nickname to describe several regional clusters of companies in the information technology sector, in analogy to California's Silicon Valley:

</doc>
<doc id="33124" url="http://en.wikipedia.org/wiki?curid=33124" title="Wild Strawberries (film)">
Wild Strawberries (film)

 
Wild Strawberries is a 1957 Swedish film written and directed by Ingmar Bergman about an old man recalling his past. The original Swedish title is Smultronstället, which literally means "The wild strawberry patch" but idiomatically signifies an underrated gem of a place, often with personal or sentimental value. The cast includes Victor Sjöström in his final screen performance, as well as Bergman regulars Bibi Andersson, Ingrid Thulin and Gunnar Björnstrand. Max von Sydow also appears in a small role. Bergman wrote the screenplay while hospitalized. Exploring philosophical themes such as introspection and human existence, "Wild Strawberries" is often considered to be one of Bergman's greatest and most moving films.
Plot.
Grouchy, stubborn and egotistical Professor Isak Borg is a widowed 78-year-old physician who specialized in bacteriology. Before specializing he served as general practitioner in rural Sweden. He sets out on a long car ride from Stockholm to Lund to be awarded the degree of Doctor Jubilaris 50 years after he received his doctorate from Lund University. He is accompanied by his pregnant daughter-in-law Marianne who does not much like her father-in-law and is planning to separate from her husband, Evald, Isak's only son, who does not want her to have the baby, their first.
During the trip, Isak is forced by nightmares, daydreams, old age and impending death to reevaluate his life. He meets a series of hitchhikers, each of whom sets off dreams or reveries into Borg's troubled past. The first group consists of two young men and their companion, a woman named Sara who is adored by both men. Sara, a double for Isak's love of his youth, is played by the same actress. The first group remains with him throughout his journey. Next Isak and Marianne pick up an embittered middle-aged couple, the Almans, whose vehicle has nearly collided with theirs. The pair exchanges such terrible vitriol and venom that Marianne stops the car and demands that they leave. The couple reminds Isak of his own unhappy marriage. In a dream sequence, Isak is asked by Sten Alman, now the examiner, to read “foreign” letters on the blackboard. He cannot. So, Alman reads it for him: "A doctor's first duty is to ask forgiveness," from which he concludes, "You are guilty of guilt." 
He reminisces about his childhood at the seaside and his sweetheart Sara, with whom he remembered gathering strawberries, but who instead married his brother. He is confronted by his loneliness and aloofness, recognizing these traits in both his ancient mother (whom they stop to visit) and in his middle-aged physician son, and he gradually begins to accept himself, his past, his present and his approaching death. In one dream, he is quizzed by a very judgmental medical professor; he is also praised by a small-town merchant who remembers him.
Borg finally arrives at his destination and is promoted to Doctor Jubilaris, but this proves to be an empty ritual. That night, he bids a loving goodbye to his young friends, to whom the once bitter old man whispers in response to a playful declaration of the young girl's love, "I'll remember." As he goes to his bed in his son's home, he is overcome by a sense of peace, and dreams of a family picnic by a lake. Closure and affirmation of life have finally come, and Borg's face radiates joy.
Production.
Origins.
Bergman's idea for the film originated on a drive from Stockholm to Dalarna during which he stopped in Uppsala, his hometown. Driving by his grandmother's house, he suddenly imagined how it would be if he could open the door and inside find everything just as it was during his childhood. "So it struck me — what if you could make a film about this; that you just walk up in a realistic way and open a door, and then you walk into your childhood, and then you open another door and come back to reality, and then you make a turn around a street corner and arrive in some other period of your existence, and everything goes on, lives. That was actually the idea behind "Wild Strawberries"". Later, he would revise the story of the film's genesis. In "Images: My Life in Film," he comments on his own earlier statement: "That's a lie. The truth is that I am forever living in my childhood."
Development.
Bergman wrote the screenplay of "Wild Strawberries" in Stockholm's Karolinska Hospital (the workplace of Isak Borg) in the late spring of 1957; he'd recently been given permission to proceed by producer Carl Anders Dymling on the basis of a short synopsis. He was in the hospital for two months, being treated for recurrent gastric problems and general stress. Bergman's doctor at Karolinska was his good friend Sture Helander who invited him to attend his lectures on psychosomatics. Helander was married to Gunnel Lindblom who was to play Isak's sister Charlotta in the film. Bergman was at a high point of his professional career after a triumphant season at the Malmö City Theatre, where he had been artistic director since 1952, and the success of both "Smiles of a Summer Night" and "The Seventh Seal". However his private life was in disarray; his third marriage was on the rocks; his affair with Bibi Andersson, which had begun in 1954, was coming to an end; his relationship with his parents was, after an attempted reconciliation with his mother, at a desperately low ebb.
Casting and preproduction progressed rapidly. The completed screenplay is dated 31 May and shooting took place between 2 July 1957 and 27 August 1957. The scenes at the summer house were filmed in Saltsjöbaden, a fashionable resort in the Stockholm archipelago. Part of the nightmare sequence was shot with predawn summer light in Gamla stan, the old part of central Stockholm. Most of the movie was made at SF’s studio and on its back lot at Råsunda in northern Stockholm.
Casting.
The director's immediate choice for the leading role of the old professor was Victor Sjöström, Bergman's silent film idol and early counselor at Svensk Filmindustri, whom he had directed in "To Joy" eight years earlier. "Victor," Bergman remarked, "was feeling wretched and didn’t want to [do it];... he must have been seventy eight. He was misanthropic and tired and felt old. I had to use all my powers of persuasion to get him to play the part."
In "Bergman on Bergman," he has stated that he only thought of Sjöström when the screenplay was complete, and that he asked Dymling to contact the famous actor and film director. Yet in "Images: My Life in Film," he claims, "It is probably worth noting that I never for a moment thought of Sjöström when I was writing the screenplay. The suggestion came from the film's producer, Carl Anders Dymling. As I recall, I thought long and hard before I agreed to let him have the part."
During the shooting, the health of the 79-year-old Sjöström gave cause for concern. Dymling had persuaded him to take on the role with the words: "All you have to do is lie under a tree, eat wild strawberries and think about your past, so it's nothing too arduous." This was inaccurate and the burden of the film was completely on Sjöström who is in all but one scene of the film. Initially, Sjöström had problems with his lines which made him frustrated and angry. He would go off into a corner and beat his head against the wall in frustration, even to the point of drawing blood and producing bruises. He sometimes quibbled over details in the script. To unburden his revered mentor, Bergman made a pact with Ingrid Thulin that if anything went wrong during a scene, she would take the blame on herself. Things improved when they changed filming times so that Sjöström could get home in time for his customary late afternoon whisky at 5:00. Sjöström got along particularly well with Bibi Andersson.
As usual, Bergman chose his collaborators from a team of actors and technicians with whom he had worked before in the cinema and the theater. As Sara, Bibi Andersson plays both Borg’s childhood sweetheart who left him to marry his brother and a charming, energetic young woman who reminds him of that lost love. Andersson, then twenty one years old, was a member in Bergman's famed repertory company. He gave her a small part in his films "Smiles of a Summer Night" (1955) and as the jester’s wife in "The Seventh Seal" (1957). She would continue to work for him in many more films, most notably in "Persona" (1966). Ingrid Thulin plays Marianne, the sad, gentle and warm daughter-in-law of Borg. She appeared in other Bergman films as the mistress in "Winter Light" (1963) and as one of three sisters in "Cries and Whispers" (1972). Bergman’s first wife, Else Fisher, made a brief unaccredited appearance as Borg’s mother in the final flashback; their daughter, Lena, played one of Isak’s twin sisters.
Awards and honors.
The film won the Golden Bear for Best Film at the 8th Berlin International Film Festival, "Best Film" and "Best Actor" at the Mar del Plata Film Festival and won the Golden Globe for Best Foreign Film in 1960. It was also nominated for an Academy Award for Original Screenplay.
The film is included on the Vatican Best Films List, recommended for its portrayal of a man's "interior journey from pangs of regret and anxiety to a refreshing sense of peace and reconciliation".
The film also influenced the Woody Allen films "Stardust Memories", "Another Woman", "Crimes and Misdemeanors", and "Deconstructing Harry". In "Stardust Memories", the film's plot is similar in that the protagonist, filmmaker Sandy Bates (Woody Allen), is attending a viewing of his films, while reminiscing about and reflecting on his life and past relationships and trying to fix and stabilize his current ones, which are infused with flashbacks and dream sequences. In "Another Woman", the film’s main character, Marion Post (Gena Rowlands), is also accused by friends and relatives of being cold and unfeeling, which forces her to reexamine her life. Allen also borrows several tropes from Bergman’s film, such as having Lynn (Frances Conroy), Post’s sister-in-law, tell her that her brother Paul (Harris Yulin) hates her and having a former student tell Post that her class changed her life. Allen has Post confront the demons of her past via several dream sequences and flashbacks that reveal important information to a viewer, as in "Wild Strawberries". In "Crimes and Misdemeanors", Allen made reference to the scene in which Isak watches his family have dinner. In "Deconstructing Harry", the plot (that of an academic on a long drive to receive an honorary award from his old university, as well as the people whom he picks up, while reflecting upon his life's experiences, with dream sequences) essentially mirrors that of "Wild Strawberries".
In a 1963 interview with "Cinema" magazine, Stanley Kubrick listed the film as his second favourite of all time.
In 2009, Roger Scruton wrote, "The camera stalks the unfolding story like a hunter, pausing to take aim at the present only to bring it into chaﬁng proximity with the past. And the images, often grainy, with sharply foregrounded details, leave many objects lingering like ghosts in the out-of-focus hinterland. In "Wild Strawberries", things, like people, are saturated with the psychic states of their observers, drawn into the drama by a camera which endows each detail with a consciousness of its own. The result is not whimsical or arbitrary, but on the contrary, entirely objective, turning to realities at every point where the camera might otherwise be tempted to escape from them. "Wild Strawberries" is one of many examples of true cinematic art".
In 2012, "Wild Strawberries" was ranked 63rd in the "Sight & Sound" critics' poll of the greatest films ever made.

</doc>
<doc id="33125" url="http://en.wikipedia.org/wiki?curid=33125" title="Wavelength">
Wavelength

In physics, the wavelength of a sinusoidal wave is the spatial period of the wave—the distance over which the wave's shape repeats, 
and the inverse of the spatial frequency. It is usually determined by considering the distance between consecutive corresponding points of the same phase, such as crests, troughs, or zero crossings and is a characteristic of both traveling waves and standing waves, as well as other spatial wave patterns. 
Wavelength is commonly designated by the Greek letter "lambda" (λ). The concept can also be applied to periodic waves of non-sinusoidal shape. 
The term "wavelength" is also sometimes applied to modulated waves, and to the sinusoidal envelopes of modulated waves or waves formed by interference of several sinusoids. 
Assuming a sinusoidal wave moving at a fixed wave speed, wavelength is inversely proportional to frequency of the wave: waves with higher frequencies have shorter wavelengths, and lower frequencies have longer wavelengths.
Wavelength depends on the medium (for example, vacuum, air, or water) that a wave travels through.
Examples of wave-like phenomena are sound waves, light, and water waves. A sound wave is a variation in air pressure, while in light and other electromagnetic radiation the strength of the electric and the magnetic field vary. Water waves are variations in the height of a body of water. In a crystal lattice vibration, atomic positions vary.
Wavelength is a measure of the distance between repetitions of a shape feature such as peaks, valleys, or zero-crossings, not a measure of how far any given particle moves. For example, in sinusoidal waves over deep water a particle near the water's surface moves in a circle of the same diameter as the wave height, unrelated to wavelength. The range of wavelengths or frequencies for wave phenomena is called a spectrum. The name originated with the visible light spectrum but now can be applied to the entire electromagnetic spectrum as well as to a sound spectrum or vibration spectrum.
Sinusoidal waves.
In linear media, any wave pattern can be described in terms of the independent propagation of sinusoidal components. The wavelength "λ" of a sinusoidal waveform traveling at constant speed "v" is given by
where "v" is called the phase speed (magnitude of the phase velocity) of the wave and "f" is the wave's frequency. In a "dispersive" medium, the phase speed itself depends upon the frequency of the wave, making the relationship between wavelength and frequency nonlinear.
In the case of electromagnetic radiation—such as light—in free space, the phase speed is the speed of light, about 3×108 m/s. Thus the wavelength of a 100 MHz electromagnetic (radio) wave is about: 3×108 m/s divided by 108 Hz = 3 metres. The wavelength of visible light ranges from deep red, roughly 700 nm, to violet, roughly 400 nm (for other examples, see electromagnetic spectrum).
For sound waves in air, the speed of sound is 343 m/s (at room temperature and atmospheric pressure). The wavelengths of sound frequencies audible to the human ear (20 Hz–20 kHz) are thus between approximately 17 m and 17 mm, respectively. Note that the wavelengths in audible sound are much longer than those in visible light.
Standing waves.
A standing wave is an undulatory motion that stays in one place. A sinusoidal standing wave includes stationary points of no motion, called nodes, and the wavelength is twice the distance between nodes.
The upper figure shows three standing waves in a box. The walls of the box are considered to require the wave to have nodes at the walls of the box (an example of boundary conditions) determining which wavelengths are allowed. For example, for an electromagnetic wave, if the box has ideal metal walls, the condition for nodes at the walls results because the metal walls cannot support a tangential electric field, forcing the wave to have zero amplitude at the wall.
The stationary wave can be viewed as the sum of two traveling sinusoidal waves of oppositely directed velocities. Consequently, wavelength, period, and wave velocity are related just as for a traveling wave. For example, the speed of light can be determined from observation of standing waves in a metal box containing an ideal vacuum.
Mathematical representation.
Traveling sinusoidal waves are often represented mathematically in terms of their velocity "v" (in the x direction), frequency "f" and wavelength "λ" as:
where "y" is the value of the wave at any position "x" and time "t", and "A" is the amplitude of the wave. They are also commonly expressed in terms of wavenumber "k" (2π times the reciprocal of wavelength) and angular frequency "ω" (2π times the frequency) as:
in which wavelength and wavenumber are related to velocity and frequency as:
or
In the second form given above, the phase ("kx" − "ωt") is often generalized to (k•r − "ωt"), by replacing the wavenumber "k" with a wave vector that specifies the direction and wavenumber of a plane wave in 3-space, parameterized by position vector r. In that case, the wavenumber "k", the magnitude of k, is still in the same relationship with wavelength as shown above, with "v" being interpreted as scalar speed in the direction of the wave vector. The first form, using reciprocal wavelength in the phase, does not generalize as easily to a wave in an arbitrary direction.
Generalizations to sinusoids of other phases, and to complex exponentials, are also common; see plane wave. The typical convention of using the cosine phase instead of the sine phase when describing a wave is based on the fact that the cosine is the real part of the complex exponential in the wave
General media.
The speed of a wave depends upon the medium in which it propagates. In particular, the speed of light in a medium is less than in vacuum, which means that the same frequency will correspond to a shorter wavelength in the medium than in vacuum, as shown in the figure at right.
This change in speed upon entering a medium causes refraction, or a change in direction of waves that encounter the interface between media at an angle. For electromagnetic waves, this change in the angle of propagation is governed by Snell's law.
The wave velocity in one medium not only may differ from that in another, but the velocity typically varies with wavelength. As a result, the change in direction upon entering a different medium changes with the wavelength of the wave.
For electromagnetic waves the speed in a medium is governed by its "refractive index" according to
where is the speed of light in vacuum and "n"(λ0) is the refractive index of the medium at wavelength λ0, where the latter is measured in vacuum rather than in the medium. The corresponding wavelength in the medium is
When wavelengths of electromagnetic radiation are quoted, the wavelength in vacuum usually is intended unless the wavelength is specifically identified as the wavelength in some other medium. In acoustics, where a medium is essential for the waves to exist, the wavelength value is given for a specified medium.
The variation in speed of light with vacuum wavelength is known as dispersion, and is also responsible for the familiar phenomenon in which light is separated into component colors by a prism. Separation occurs when the refractive index inside the prism varies with wavelength, so different wavelengths propagate at different speeds inside the prism, causing them to refract at different angles. The mathematical relationship that describes how the speed of light within a medium varies with wavelength is known as a dispersion relation.
Nonuniform media.
Wavelength can be a useful concept even if the wave is not periodic in space. For example, in an ocean wave approaching shore, shown in the figure, the incoming wave undulates with a varying "local" wavelength that depends in part on the depth of the sea floor compared to the wave height. The analysis of the wave can be based upon comparison of the local wavelength with the local water depth.
Waves that are sinusoidal in time but propagate through a medium whose properties vary with position (an "inhomogeneous" medium) may propagate at a velocity that varies with position, and as a result may not be sinusoidal in space. The figure at right shows an example. As the wave slows down, the wavelength gets shorter and the amplitude increases; after a place of maximum response, the short wavelength is associated with a high loss and the wave dies out.
The analysis of differential equations of such systems is often done approximately, using the "WKB method" (also known as the "Liouville–Green method"). The method integrates phase through space using a local wavenumber, which can be interpreted as indicating a "local wavelength" of the solution as a function of time and space.
This method treats the system locally as if it were uniform with the local properties; in particular, the local wave velocity associated with a frequency is the only thing needed to estimate the corresponding local wavenumber or wavelength. In addition, the method computes a slowly changing amplitude to satisfy other constraints of the equations or of the physical system, such as for conservation of energy in the wave.
Crystals.
Waves in crystalline solids are not continuous, because they are composed of vibrations of discrete particles arranged in a regular lattice. This produces aliasing because the same vibration can be considered to have a variety of different wavelengths, as shown in the figure. Descriptions using more than one of these wavelengths are redundant; it is conventional to choose the longest wavelength that fits the phenomenon. The range of wavelengths sufficient to provide a description of all possible waves in a crystalline medium corresponds to the wave vectors confined to the Brillouin zone.
This indeterminacy in wavelength in solids is important in the analysis of wave phenomena such as energy bands and lattice vibrations. It is mathematically equivalent to the aliasing of a signal that is sampled at discrete intervals.
More general waveforms.
The concept of wavelength is most often applied to sinusoidal, or nearly sinusoidal, waves, because in a linear system the sinusoid is the unique shape that propagates with no shape change – just a phase change and potentially an amplitude change. The wavelength (or alternatively wavenumber or wave vector) is a characterization of the wave in space, that is functionally related to its frequency, as constrained by the physics of the system. Sinusoids are the simplest traveling wave solutions, and more complex solutions can be built up by superposition.
In the special case of dispersion-free and uniform media, waves other than sinusoids propagate with unchanging shape and constant velocity. In certain circumstances, waves of unchanging shape also can occur in nonlinear media; for example, the figure shows ocean waves in shallow water that have sharper crests and flatter troughs than those of a sinusoid, typical of a cnoidal wave, a traveling wave so named because it is described by the Jacobi elliptic function of "m"-th order, usually denoted as "cn"("x"; "m"). Large-amplitude ocean waves with certain shapes can propagate unchanged, because of properties of the nonlinear surface-wave medium.
If a traveling wave has a fixed shape that repeats in space or in time, it is a "periodic wave". Such waves are sometimes regarded as having a wavelength even though they are not sinusoidal. As shown in the figure, wavelength is measured between consecutive corresponding points on the waveform.
Wave packets.
Localized wave packets, "bursts" of wave action where each wave packet travels as a unit, find application in many fields of physics. A wave packet has an "envelope" that describes the overall amplitude of the wave; within the envelope, the distance between adjacent peaks or troughs is sometimes called a "local wavelength". An example is shown in the figure. In general, the "envelope" of the wave packet moves at a different speed than the constituent waves.
Using Fourier analysis, wave packets can be analyzed into infinite sums (or integrals) of sinusoidal waves of different wavenumbers or wavelengths.
Louis de Broglie postulated that all particles with a specific value of momentum "p" have a wavelength "λ = h/p", where "h" is Planck's constant. This hypothesis was at the basis of quantum mechanics. Nowadays, this wavelength is called the de Broglie wavelength. For example, the electrons in a CRT display have a De Broglie wavelength of about 10−13 m. To prevent the wave function for such a particle being spread over all space, de Broglie proposed using wave packets to represent particles that are localized in space. The spatial spread of the wave packet, and the spread of the wavenumbers of sinusoids that make up the packet, correspond to the uncertainties in the particle's position and momentum, the product of which is bounded by Heisenberg uncertainty principle.
Interference and diffraction.
Double-slit interference.
When sinusoidal waveforms add, they may reinforce each other (constructive interference) or cancel each other (destructive interference) depending upon their relative phase. This phenomenon is used in the interferometer. A simple example is an experiment due to Young where light is passed through two slits. 
As shown in the figure, light is passed through two slits and shines on a screen. The path of the light to a position on the screen is different for the two slits, and depends upon the angle θ the path makes with the screen. If we suppose the screen is far enough from the slits (that is, "s" is large compared to the slit separation "d") then the paths are nearly parallel, and the path difference is simply "d" sin θ. Accordingly the condition for constructive interference is:
where "m" is an integer, and for destructive interference is:
Thus, if the wavelength of the light is known, the slit separation can be determined from the interference pattern or "fringes", and "vice versa".
For multiple slits, the pattern is 
where "q" is the number of slits, and "g" is the grating constant. The first factor, "I"1, is the single-slit result, which modulates the more rapidly varying second factor that depends upon the number of slits and their spacing. In the figure "I"1 has been set to unity, a very rough approximation.
It should be noted that the effect of interference is to "redistribute" the light, so the energy contained in the light is not altered, just where it shows up.
Single-slit diffraction.
The notion of path difference and constructive or destructive interference used above for the double-slit experiment applies as well to the display of a single slit of light intercepted on a screen. The main result of this interference is to spread out the light from the narrow slit into a broader image on the screen. This distribution of wave energy is called diffraction.
Two types of diffraction are distinguished, depending upon the separation between the source and the screen: Fraunhofer diffraction or far-field diffraction at large separations and Fresnel diffraction or near-field diffraction at close separations.
In the analysis of the single slit, the non-zero width of the slit is taken into account, and each point in the aperture is taken as the source of one contribution to the beam of light ("Huygen's wavelets"). On the screen, the light arriving from each position within the slit has a different path length, albeit possibly a very small difference. Consequently, interference occurs.
In the Fraunhofer diffraction pattern sufficiently far from a single slit, within a small-angle approximation, the intensity spread "S" is related to position "x" via a squared sinc function:
where "L" is the slit width, "R" is the distance of the pattern (on the screen) from the slit, and λ is the wavelength of light used. The function "S" has zeros where "u" is a non-zero integer, where are at "x" values at a separation proportion to wavelength.
Diffraction-limited resolution.
Diffraction is the fundamental limitation on the resolving power of optical instruments, such as telescopes (including radiotelescopes) and microscopes. 
For a circular aperture, the diffraction-limited image spot is known as an Airy disk; the distance "x" in the single-slit diffraction formula is replaced by radial distance "r" and the sine is replaced by 2"J"1, where "J"1 is a first order Bessel function.
The resolvable "spatial" size of objects viewed through a microscope is limited according to the Rayleigh criterion, the radius to the first null of the Airy disk, to a size proportional to the wavelength of the light used, and depending on the numerical aperture:
where the numerical aperture is defined as formula_15 for θ being the half-angle of the cone of rays accepted by the microscope objective.
The "angular" size of the central bright portion (radius to first null of the Airy disk) of the image diffracted by a circular aperture, a measure most commonly used for telescopes and cameras, is:
where λ is the wavelength of the waves that are focused for imaging, "D" the entrance pupil diameter of the imaging system, in the same units, and the angular resolution δ is in radians.
As with other diffraction patterns, the pattern scales in proportion to wavelength, so shorter wavelengths can lead to higher resolution.
Subwavelength.
The term "subwavelength" is used to describe an object having one or more dimensions smaller than the length of the wave with which the object interacts. For example, the term "subwavelength-diameter optical fibre" means an optical fibre whose diameter is less than the wavelength of light propagating through it.
A subwavelength particle is a particle smaller than the wavelength of light with which it interacts (see Rayleigh scattering). Subwavelength apertures are holes smaller than the wavelength of light propagating through them. Such structures have applications in extraordinary optical transmission, and zero-mode waveguides, among other areas of photonics.
"Subwavelength" may also refer to a phenomenon involving subwavelength objects; for example, subwavelength imaging.
Angular wavelength.
A quantity related to the wavelength is the angular wavelength (also known as reduced wavelength), usually symbolized by "ƛ" (lambda-bar). It is equal to the "regular" wavelength "reduced" by a factor of 2π ("ƛ" = "λ"/2π). It is usually encountered in quantum mechanics, where it is used in combination with the reduced Planck constant (symbol "ħ", h-bar) and the angular frequency (symbol "ω") or angular wavenumber (symbol "k").

</doc>
<doc id="33126" url="http://en.wikipedia.org/wiki?curid=33126" title="The Wachowskis">
The Wachowskis

Lana Wachowski (born June 21, 1965) and Andrew Paul "Andy" Wachowski (born December 29, 1967), known together professionally as the Wachowskis and formerly as the Wachowski Brothers, are American film directors, screenwriters and producers.
They made their directing debut in 1996 with "Bound", and reached fame with their second film "The Matrix" (1999), for which they won the Saturn Award for Best Director. They wrote and directed its two sequels "The Matrix Reloaded" and "The Matrix Revolutions" (both in 2003), and were heavily involved in the writing and production of other works in the franchise.
Following the commercial success of the "Matrix" series, they wrote and produced the 2006 film "V for Vendetta" (an adaptation of the comic of the same name by Alan Moore), and in 2008 released the film "Speed Racer", which was a live action adaptation of the Japanese anime series, "Speed Racer". Their next film, "Cloud Atlas", based on the novel of the same name by David Mitchell and co-written and co-directed by Tom Tykwer, was released on October 26, 2012. Their most recent film, "Jupiter Ascending", debuted in 2015, with their television series, "Sense8", to follow later in the year.
Early life.
Lana Wachowski was born Laurence Wachowski (known as "Larry") in Chicago in 1965. Andy Wachowski was born 2½ years later in 1967. Their mother, Lynne ("née" Luckinbill), was a nurse and painter whose brother is actor Laurence Luckinbill. Their father, Ron Wachowski, was a businessman of Polish descent. They have two sisters, Julie and Laura; Julie was credited as assistant coordinator in the Wachowskis’ film "Bound", and is a novelist and screenwriter.
Lana and Andy attended Kellogg Elementary School in Chicago's Beverly area, and graduated from Whitney Young High School, known for its performing arts and science curriculum, in 1983 and 1985, respectively. Former students recall them playing Dungeons & Dragons and working in the school’s theater and TV program. Andy then attended Emerson College in Boston, while Lana went to Bard College in New York. Both dropped out before graduating and ran a house-painting and construction business in Chicago while writing for Marvel Comics.
Directors that influenced the pair include Alfred Hitchcock, John Huston, Billy Wilder, Roman Polanski, Francis Ford Coppola, Roger Corman, the Coen brothers, John Woo, Akira Kurosawa, Mamoru Oshii, Ridley Scott, George Lucas, Fritz Lang, and Stanley Kubrick. Other reported influences have been writers Hermann Hesse, Homer, and Fyodor Dostoyevsky and philosophers Cornel West and Ken Wilber.
Career.
Early work.
Prior to working in the film industry, the Wachowskis wrote comic books for Marvel Comics' Razorline imprint, namely "Ectokid" (created by horror novelist Clive Barker) in 1993, as well as writing for Epic Comics' "Clive Barker's Hellraiser" and "Clive Barker's Nightbreed" comic series.
In the mid-1990s they branched out into film writing, creating the script for "Assassins" in 1994. Warner Brothers bought the script and included two more pictures in the contract. "Assassins" was "totally rewritten" by Brian Helgeland and the Wachowskis tried unsuccessfully to remove their names from the film. They then moved on to their next project, the neo-noir thriller "Bound", their debut as directors. The film was well received for its style and craft, and was noted as one of the first mainstream films to prominently feature a homosexual relationship without it being central to the plot. Taking advantage of the positive buzz, the Wachowskis asked to direct their next picture, "The Matrix".
"The Matrix" franchise.
Their next film, "The Matrix," was completed in 1999. It proved to be a success, and spawned two sequels, "The Matrix Reloaded" and "The Matrix Revolutions", both released in 2003.
Later work.
The Wachowskis' next feature-film project was "V for Vendetta", an adaptation of Alan Moore's comic book of the same name. They wrote and produced the film with Matrix producer Joel Silver, who had previously purchased the film rights to the novel. The film was directed by Wachowski collaborator James McTeigue. The production proceeded without the participation of Moore, who was disappointed with previous Hollywood adaptations of his work, and disagreed with differences between the screenplay and his novel, is not credited. The film's controversial story line and themes have been the target of both criticism and praise from sociopolitical groups. It was released in 2006 and was well received critically and was a box office success, although not on the scale of the Matrix films.
In 2006, the Wachowskis and McTeigue were hired to revamp "The Invasion" for Warner Brothers. The studio was disappointed in the film as produced by director Oliver Hirschbiegel and hired the Wachowskis to rewrite the script and add new scenes, which McTeigue directed. The film, the fourth adaptation of the novel "The Body Snatchers", was not a critical or box office success. The Wachowskis and McTeigue are not credited on the film for their involvement.
The Wachowskis returned to directing with 2008's "Speed Racer". The film was an adaptation of a Japanese manga series from the 1950s, which was itself made into an 1960s anime TV series. Upon release the movie was considered a critical and commercial disappointment. While its special effects were noted as outstanding, the storyline is considered lacking. It was also nominated in the category of "Worst Prequel, Remake, Rip-off or Sequel" for the 29th Golden Raspberry Awards. Its box office gross was $93 million compared to a production budget of $120 million. However in later years critics periodically have put the film on lists of underrated or cult films.
Their next directorial outing was "Cloud Atlas", adapted from David Mitchell's 2004 novel, which drew mixed reviews. The Wachowskis subsequently produced and directed "Jupiter Ascending", an original science fiction screenplay they wrote. The film was released February 2015. It stars Channing Tatum and Mila Kunis, and features the Wachowskis' regular collaborators John Gaeta on the visual effects and Kym Barrett on costumes.
Future works.
In 2008, the Wachowskis were producing for Madhouse an animated film based on their comic book company's "Shaolin Cowboy", titled "Shaolin Cowboy in The Tomb of Doom". The feature is co-directed by the comic book's creator Geof Darrow and Seiji Mizushima, a Japanese director. When the American financiers backed out, the film was left half-finished and in need of $3 million. Darrow does not believe that the required amount of money to finish it will be found.
Warner Bros. has expressed interest in "Hood", a modern adaptation of the Robin Hood legend, which the Wachowskis wrote and plan to direct. They also wrote an Iraq war-set gay romance conspiracy thriller titled "CN-9" (or "Cobalt Neural 9"); however, the project failed to find financing. However the siblings are still keen to make it, even if it has to be made in a different form than film.
The siblings are also shopping around a concept for a TV series dubbed "Sense8" that they have developed with "Ninja Assassin" collaborator J. Michael Straczynski. In their pursuit of the concept the Wachowskis have penned three spec scripts that are said to resemble their unique storytelling style seen in "The Matrix" films, and they plan to direct at least a few episodes of the series, should it be made. Producer Marc Rosen of Georgeville Television (GTTV), describes the project as "an idea so big in size and scale that it doesn't make sense to try it as a pilot. The only way to let the filmmakers realize their vision on something like this is to do multiple episodes." On March 27, 2013 it was announced ten episodes will be made to be streamed on Netflix late 2014. The series which belongs to the genre of science fiction is described as "a gripping global tale of minds linked and souls hunted" which was conceived by the showrunners "after a late night conversation about the ways technology simultaneously unites and divides us".
Lana stated that after the release of "Jupiter Ascending" and "Sense8", they are going to take a sabbatical because they have worked six years without a break. The Wachowskis also wrote the script of "Carnivore" and the script of "Plastic Man", the latter based on the DC Comics superhero of the same name. Both projects remain unproduced so far.
Style.
The siblings admit to a love for telling multipart stories. "Because we grew up on comic books and the Tolkien trilogy, one of the things we're interested in is bringing serial fiction to cinema," Lana has said. Andy puts his desire to shake up viewers a bit more bluntly: "We think movies are fairly boring and predictable. We want to screw with audiences' expectations." In terms of themes that run through their body of work, Lana has cited "the inexplicable nature of the universe [being] in constant dialogue with our own consciousness and our consciousness actually affect[ing] the inexplicable nature of the universe," "interconnectivity and about truth beneath the surface" and "the paradox of choice and choicelessness". The Wachowskis cited the art of comic book artist Geof Darrow as an influence on the look of "The Matrix". Also, they stated that "Ghost in the Shell", "Ninja Scroll", and "Akira" as anime that inspired them. "in anime, one thing that they do that we tried to bring to our film was a juxtaposition of time and space in action beats.
The Wachowskis cited Stanley Kubrick's "" as one of their main inspirations for "Cloud Atlas". They first saw the film when they were seven and ten respectively.
Lana's most influential films are "2001: A Space Odyssey", "Blade Runner", "Ma vie en rose" and "My Neighbor Totoro". Both of them are fans of the "Ghost in the Shell", "Akira", "Wicked City", "Ninja Scroll" and "Fist of the North Star" anime films.
None of the home video releases of their films feature any deleted scenes. Lana says that despite often having to cut scenes from their movies their inclusion in the form of deleted scenes would suggest that their films suffer from incompleteness due to logistical or financial studio constraints, which is not the case as they love the finished product. For the same reason their films never received a director's or extended cut. They also avoid recording audio commentary tracks, having participated only once on the track recorded for the LaserDisc of "Bound". The siblings explain they discovered offering their interpretation of what their movies mean leads to people being less likely to express their own interpretation. Furthermore they are also not interested in the typical commentaries with cast and crew reminisces such as about their experiences with the catering.
Frequent collaborators.
The Wachowskis have been noted for hiring the same basic film crew to make their movies. Lana admits they do it in part to make sure prejudice does not enter their place of work. "It's like family. Everyone is very respectful of each other." says Lana. They used the same practice while selecting the television crew for their Netflix show, "Sense8".
A list of some of their most notable frequent collaborators includes:
As film producers and comic book publishers.
During "The Matrix Reloaded", "The Matrix Revolutions", "The Animatrix" and "Enter the Matrix" production, the Wachowskis created EON Entertainment (not to be confused with Eon Productions), their production company to coordinate and direct all involved partners. It is also where the films were edited together, after the various FX vendors sent their finished work. EON's internal VFX team, ESC, did a number of visual effect shots for the two Matrix sequels and coordinated the other vendors. ESC was shut down in summer 2004. Anarchos Productions (credited in "Cloud Atlas" as Anarchos Pictures) is their production company that has been billed for all their films starting with "V for Vendetta".
"Kinowerks" is their pre- and post-production and effects studio, based in Ravenswood, Chicago. It has been acclaimed for its green-friendly design. Roger Ebert was invited to watch a restored print of "The Godfather" in the "Kinowerks" facilities and met the Wachowskis, but he was oblivious to the fact the studio belonged to them. The "Chicago Tribune"'s Christopher Pirelli has interviewed the Wachowskis in the facility but was instructed to keep its exact location a secret, as the filmmakers want to avoid having fans showing up at the front door.
Prior to working in the film industry, the Wachowskis wrote comic books for Marvel Comics' Razorline imprint, namely "Ectokid" (created by horror novelist Clive Barker) in 1993 as well as writing for Epic Comics' "Clive Barker's Hellraiser" and "Clive Barker's Nightbreed" comic series.
In 2003, they created Burlyman Entertainment and have released comic books based on "The Matrix" as well as two original bi-monthly series:
Personal life.
Andy has been married to Alisa Blasingame since 1991. Lana married Thea Bloom in 1993; they divorced in 2002. She subsequently began dating Karin Winslow; they married in 2009. Winslow is a board member of the "Chicago House and Social Service Agency".
Raised by a "hardcore atheist" father and an "ex-Catholic turned Shamanist" mother, the duo once described their religious beliefs as non-denominational. Lana is a vegetarian.
Lana's gender transition.
Rumors that Lana Wachowski was transitioning spread in the early 2000s, though neither sibling spoke directly on the subject at the time. In 2003 Gothamist.com mentioned the possible gender reassignment and suggested that "the "Matrix" films could be read with a sadomasochistic subtext with the news of Larry's companionship with a dominatrix". Though the Wachowskis remained silent, sources close to them denied the rumors. In a 2007 interview Joel Silver, the producer of numerous Wachowski films, stated that the rumors concerning the gender reassignment surgery were "all untrue", further explaining, "they just don't do interviews, so people make things up." Similar statements were made to Fox News by crew members working on the "Speed Racer" film, with one employee pointing out, "on the call sheets, it still says Larry."
According to Rovi, Larry, now known as Lana, completed the transition after "Speed Racer"'s release in 2008. "The Hollywood Reporter" and the "New York Times" have referred to the Wachowskis as "Andy and Lana (formerly Larry) Wachowski", and Deadline.com has referred to the duo as "Andy and Lana Wachowski." On some documents she appears as Laurenca Wachowski. In July 2012, Lana made her first public appearance after transitioning, in a video discussing the creative process behind "Cloud Atlas". Lana is the first major Hollywood director to come out as transgender.
In October 2012 Lana received the Human Rights Campaign's Visibility Award. In her acceptance speech she revealed that she had considered committing suicide once in her youth. Lana's acceptance speech was one of the longest public appearances that either of the notoriously reclusive siblings has ever given. She began by explaining that although she and her brother had not publicly commented on her transitioning during the past decade of rumors about it, this was not because she was ashamed of it, nor had she kept it a secret from her family and friends. Rather, Lana had not commented about her transitioning due to a general shyness about the news media that both she and her brother Andy possess. Comparing it to losing one's virginity as an event which only happens once and is irreversible, the Wachowskis had tried to stay out of the public eye and avoided giving interviews due to fear of losing their personal privacy, fearing that they would never be able to go to a public restaurant again without being noticed and harassed as celebrities. Explaining her decision to appear at the event, she said, "there are some things we do for ourselves, but there are some things we do for others. I am here because when I was young, I wanted very badly to be a writer, I wanted to be a filmmaker, but I couldn't find anyone like me in the world and it felt like my dreams were foreclosed simply because my gender was less typical than others. If I can be that person for someone else, then the sacrifice of my private civic life may have value." In February 2014, Lana received the Freedom Award from Equality Illinois at the organization's annual gala in Chicago. "A native of Chicago’s Beverly neighborhood, Wachowski made her mark in the world of imagination, most famously by writing, directing and executive producing with her brother Andy Wachowski the “The Matrix” trilogy as well as films “Cloud Atlas”, “Bound” and “Speed Racer”."
Gaming.
Lana and Andy are self-proclaimed gamers. As teens they spent their weekends in the attic playing "Dungeons & Dragons". They liken the process of the playing parties imagining the same virtual space to the process of filmmaking. Along with some of their friends they wrote a 350-page role-playing game of their own, called "High Adventure". The rights to it are available for publishing.
On the video game front, they had been exchanging letters with Hideo Kojima and finally met him during a Famitsu interview in late 1999. "Metal Gear Solid" was the first video game they played after finishing work on "The Matrix". Candidates for an adaptation of the first "Matrix" movie to video game form included Kojima, Bungie and Shiny Entertainment whose "Messiah" PC game impressed them. Shiny's David Perry who ultimately had his company develop and collaborate with them on the "Enter the Matrix" and "" video games was impressed with their familiarity with the medium which was a big plus during development. The Wachowskis owned both a PlayStation 2 and Xbox video game console and played several games such as "Splinter Cell" and "Halo 2" and in the case of the latter they finished it even before Perry did. Reportedly during a "Halo" deathmatch they destroyed their Xbox. Actor Collin Chou recounts an instance of visiting their office and finding them playing video games on the floor. Andy is a fan of the "Death Jr." PlayStation Portable game.
Asked about their feelings turning the tightly controlled "Matrix" saga to the unpredictable form of an MMORPG with "The Matrix Online" the duo appeared enthusiastic about the nature and possibilities of video games:
The "vagaries of an MMO where unpredictable player behavior is the rule," is the reason for doing it. Our films were never intended for a passive audience. There are enough of those kinds of films being made. We wanted our audience to have to work, to have to think, to have to actually participate in order to enjoy them. This may be because while we enjoy movies, we also spend a lot of time (as in crack-den amounts of time) gaming.
Gaming engages your mind actively whereas most genre films (the films we tend to watch) are designed to provoke as little thinking as possible. Consider why the films in which everyone knows exactly what is going to happen are the films that make the most money.
Yet the fact that the Matrix films are three of the most successful adult films in history (despite of what much of the media would have us believe), suggests that there are other people like us. Those are the people, the people who thought about it, who worked at it, who we ultimately made the trilogy for and it now makes perfect sense to us that they should inherit the storyline. For us, the idea of watching our baby evolve inside the virtual bubble-world of this new radically developing medium, which has in our opinion the potential of combining the best attributes of films and games, of synthesizing reality TV with soap opera, RPGs and Mortal Combat ["sic"], is fantastically exciting. 
 
Works.
Music videos.
Additionally classifying themselves as "lifelong rabid Bulls fans" they created a revamped introductory animation for Chicago Bulls to open the 2006–2007 regular season.
Comic books.
"The Art of the Matrix" book credits them for including their screenplay and additional art. The Wachowskis also wrote an introduction to the 2005 published "Vol. 2: Tag" trade paperback of "Ex Machina" comic book, being big fans of it. Additionally Lana Wachowski wrote the introduction to the 2012 published "No Straight Lines: Four Decades of Queer Comics" collection of LGBTQ comic book stories.

</doc>
<doc id="33127" url="http://en.wikipedia.org/wiki?curid=33127" title="Wisconsin">
Wisconsin

Wisconsin () is a U.S. state located in the north-central United States, in the Midwest and Great Lakes regions. It is bordered by Minnesota to the west, Iowa to the southwest, Illinois to the south, Lake Michigan to the east, Michigan to the northeast, and Lake Superior to the north. Wisconsin is the 23rd largest state by total area and the 20th most populous. The state capital is Madison, and its largest city is Milwaukee, which is located on the western shore of Lake Michigan. The state comprises 72 counties.
Wisconsin's geography is diverse, with the Northern Highland and Western Upland along with a part of the Central Plain occupying the western part of the state and lowlands stretching to the shore of Lake Michigan. Wisconsin is second to Michigan in the length of its Great Lakes coastline.
Wisconsin is known as "America's Dairyland" because it is one of the nation's leading dairy producers, particularly famous for cheese. Manufacturing, especially paper products, information technology (IT), and tourism are also major contributors to the state's economy.
Etymology.
The word "Wisconsin" originates from the name given to the Wisconsin River by one of the Algonquian-speaking American Indian groups living in the region at the time of European contact. French explorer Jacques Marquette was the first European to reach the Wisconsin River, arriving in 1673 and calling the river "Meskousing" in his journal. English speakers anglicized the spelling to its modern form when they began to arrive in greater numbers during the early 19th century. The current spelling was made official by the legislature of Wisconsin Territory in 1845.
The Algonquian word for Wisconsin and its original meaning have both grown obscure. Interpretations vary, but most implicate the river and the red sandstone that lines its banks. One leading theory holds that the name originated from the Miami word "Meskonsing", meaning "it lies red," a reference to the setting of the Wisconsin River as it flows through the reddish sandstone of the Wisconsin Dells. Other theories include claims that the name originated from one of a variety of Ojibwa words meaning "red stone place," "where the waters gather," or "great rock."
History.
Wisconsin has been home to a wide variety of cultures over the past 12,000 years. The first people arrived around 10,000 BCE during the Wisconsin Glaciation. These early inhabitants, called Paleo-Indians, hunted now-extinct ice age animals exemplified by the Boaz mastodon, a prehistoric mastodon skeleton unearthed along with spear points in southwest Wisconsin. After the ice age ended around 8000 BCE, people in the subsequent Archaic period lived by hunting, fishing, and gathering food from wild plants. Agricultural societies emerged gradually over the Woodland period between 1000 BCE to 1000 CE. Toward the end of this period, Wisconsin was the heartland of the "Effigy Mound culture", which built thousands of animal-shaped mounds across the landscape. Later, between 1000 and 1500 CE, the Mississippian and Oneota cultures built substantial settlements including the fortified village at Aztalan in southeast Wisconsin. The Oneota may be the ancestors of the modern Ioway and Ho-Chunk tribes who shared the Wisconsin region with the Menominee at the time of European contact. Other American Indian groups living in Wisconsin when Europeans first settled included the Ojibwa, Sauk, Fox, Kickapoo, and Pottawatomie, who migrated to Wisconsin from the east between 1500 and 1700.
The first European to visit what became Wisconsin was probably the French explorer Jean Nicolet. He canoed west from Georgian Bay through the Great Lakes in 1634, and it is traditionally assumed that he came ashore near Green Bay at Red Banks. Pierre Radisson and Médard des Groseilliers visited Green Bay again in 1654–1666 and Chequamegon Bay in 1659–1660, where they traded for fur with local American Indians. In 1673, Jacques Marquette and Louis Jolliet became the first to record a journey on the Fox-Wisconsin Waterway all the way to the Mississippi River near Prairie du Chien. Frenchmen like Nicholas Perrot continued to ply the fur trade across Wisconsin through the 17th and 18th centuries, but the French made no permanent settlements in Wisconsin before Great Britain won control of the region following the French and Indian War in 1763. Even so, French traders continued to work in the region after the war, and some, beginning with Charles de Langlade in 1764, now settled in Wisconsin permanently rather than returning to British-controlled Canada.
The British gradually took over Wisconsin during the French and Indian War, taking control of Green Bay in 1761 and gaining control of all of Wisconsin in 1763. Like the French, the British were interested in little but the fur trade. One notable event in the fur trading industry in Wisconsin occurred in 1791, when two free African Americans set up a fur trading post among the Menominee at present day Marinette. The first permanent settlers, mostly French Canadians, some Anglo-New Englanders and a few African American freedmen, arrived in Wisconsin while it was under British control. Charles Michel de Langlade is generally recognized as the first settler, establishing a trading post at Green Bay in 1745, and moving there permanently in 1764. Settlement began at Prairie du Chien around 1781. The French residents at the trading post in what is now Green Bay, referred to the town as "La Bey", however British fur traders referred to it as "Green Bay", because the water and the shore assumed green tints in early spring. The old French title was gradually dropped, and the British name of "Green Bay" eventually stuck. The region coming under British rule had virtually no adverse effect on the French residents as the British needed the cooperation of the French fur traders and the French fur traders needed the goodwill of the British. During the French occupation of the region licenses for fur trading had been issued scarcely and only to select groups of traders, whereas the British, in an effort to make as much money as possible from the region, issued licenses for fur trading freely, both to British and French residents. The fur trade in what is now Wisconsin reached its height under British rule, and the first self-sustaining farms in the state were established as well. From 1763 to 1780, Green Bay was a prosperous community which produced its own foodstuff, built graceful cottages and held dances and festivities.
Wisconsin became a territorial possession of the United States in 1783 after the American Revolutionary War. However, the British remained in control until after the War of 1812, the outcome of which finally established an American presence in the area. Under American control, the economy of the territory shifted from fur trading to lead mining. The prospect of easy mineral wealth drew immigrants from throughout the U.S. and Europe to the lead deposits located at Mineral Point, Wisconsin, Dodgeville, Wisconsin, and nearby areas. Some miners found shelter in the holes they had dug and earned the nickname "badgers", leading to Wisconsin's identity as the "Badger State." The sudden influx of white miners prompted tension with the local Native American population. The Winnebago War of 1827 and the Black Hawk War of 1832 led to the forced removal of American Indians from most parts of the state. Following these conflicts, Wisconsin Territory was created by an act of the United States Congress on April 20, 1836. By fall of that year, the best prairie groves of the counties surrounding what is now Milwaukee were occupied by farmers from the New England states.
Settlers from New England began pouring into the southern portion of the state. These were old stock Yankee immigrants, who were descended from the English Puritans who settled New England in the 1600s. The completion of the Erie Canal caused a surge in New England immigration to what was then the Northwest Territory. Some of them were from upstate New York and had parents who had moved to that region from New England shortly after the Revolutionary War. When they arrived in what is now the state of Wisconsin there was nothing but a virgin forest and wild prairie, the New Englanders laid out farms, constructed roads, erected government buildings and established post routes. They brought with them many of their Yankee New England values, such as a passion for education, establishing many schools as well as staunch support for abolitionism. They were mostly members of the Congregationalist Church though some were Episcopalian. New Englanders and New England transplants from upstate New York founded towns such as Racine, Beloit, Burlington and Janesville. Land surveys encouraged pioneers to settle in the area among the abundance of fertile farmland and woodlands. Many of these early settlers established farms and began cultivating wheat and other grains. Continued white settlement led to statehood in 1848.
By 1850 Wisconsin's population was 305,000. Roughly a third (103,000) were Yankees from New England and western New York state. The second largest group were the Germans, numbering roughly 38,000, followed by 28,000 British immigrants from England, Scotland and Wales. There were roughly 63,000 Wisconsin-born residents of the state. The Yankee migrants would be the dominant political class in Wisconsin for many years.
Nelson Dewey, the first governor of Wisconsin, was a Democrat. Born in Lebanon, Connecticut, Dewey's father's family had lived in New England since 1633, when their ancestor, Thomas Due, had come to America from Kent County, England. Dewey oversaw the transition from the territorial to the new state government. He encouraged the development of the state's infrastructure, particularly the construction of new roads, railroads, canals, and harbors, as well as the improvement of the Fox and Wisconsin Rivers. During his administration, the State Board of Public Works was organized.
Dewey was an abolitionist and the first of many Wisconsin governors to advocate against the spread of slavery into new states and territories. The home Dewey built near Cassville is now a state park.
Politics in early Wisconsin were defined by the greater national debate over slavery. A free state from its foundation, Wisconsin became a center of northern abolitionism. The debate became especially intense in 1854 after Joshua Glover, a runaway slave from Missouri, was captured in Racine. Glover was taken into custody under the Federal Fugitive Slave Law, but a mob of abolitionists stormed the prison where Glover was held and helped him escape to Canada. In a trial stemming from the incident, the Wisconsin Supreme Court ultimately declared the Fugitive Slave Law unconstitutional. The Republican Party, founded on March 20, 1854, by anti-slavery expansion activists in Ripon, Wisconsin, grew to dominate state politics in the aftermath of these events. During the Civil War, around 91,000 troops from Wisconsin fought for the Union.
Wisconsin's economy also diversified during the early years of statehood. While lead mining diminished, agriculture became a principal occupation in the southern half of the state. Railroads were built across the state to help transport grains to market, and industries like J.I. Case & Company in Racine were founded to build agricultural equipment. Wisconsin briefly became one of the nation's leading producers of wheat during the 1860s. Meanwhile, the lumber industry dominated in the heavily forested northern sections of Wisconsin, and sawmills sprang up in cities like La Crosse, Eau Claire, and Wausau. These economic activities had dire environmental consequences. By the close of the 19th century, intensive agriculture had devastated soil fertility, and lumbering had deforested most of the state. These conditions forced both wheat agriculture and the lumber industry into a precipitous decline.
Beginning in the 1890s, farmers in Wisconsin shifted from wheat to dairy production in order to make more sustainable and profitable use of their land. Many immigrants carried cheese-making traditions that, combined with the state's suitable geography and dairy research led by Stephen Babcock at the University of Wisconsin, helped the state build a reputation as "America's Dairyland." Meanwhile, conservationists including Aldo Leopold helped reestablish the state's forests during the early 20th century, paving the way for a more renewable lumber and paper milling industry as well as promoting recreational tourism in the northern woodlands. Manufacturing also boomed in Wisconsin during the early 20th century, driven by an immense immigrant workforce arriving from Europe. Industries in cities like Milwaukee ranged from brewing and food processing to heavy machine production and toolmaking, leading Wisconsin to rank 8th among U.S. states in total product value by 1910.
The early 20th century was also notable for the emergence of progressive politics championed by Robert M. La Follette. Between 1901 and 1914, Progressive Republicans in Wisconsin created the nation's first comprehensive statewide primary election system, the first effective workplace injury compensation law, and the first state income tax, making taxation proportional to actual earnings. The progressive Wisconsin Idea also promoted the statewide expansion of the University of Wisconsin through the UW-Extension system at this time. Later, UW economics professors John R. Commons and Harold Groves helped Wisconsin create the first unemployment compensation program in the United States in 1932.
In the immediate aftermath of World War II, citizens of Wisconsin were divided over things such as the creation of the United Nations, support for the European recovery, and the growth of the Soviet Union's power. However, when Europe divided into Communist and capitalist camps and the Communist revolution in China succeeded in 1949, public opinion began to move towards support for the protection of democracy and capitalism against Communist expansion.
Wisconsin took part in several political extremes in the mid to late 20th century, ranging from the anti-communist crusades of Senator Joseph McCarthy in the 1950s to the radical antiwar protests at UW-Madison that culminated in the Sterling Hall bombing in August 1970. The state became a leader in welfare reform under Republican Governor Tommy Thompson during the 1990s. The state's economy also underwent further transformations towards the close of the 20th century, as heavy industry and manufacturing declined in favor of a service economy based on medicine, education, agribusiness, and tourism.
Two U.S. Navy battleships, BB-9 and BB-64, were named for the state.
Geography.
Wisconsin is bordered by the Montreal River; Lake Superior and Michigan to the north; by Lake Michigan to the east; by Illinois to the south; and by Iowa to the southwest and Minnesota to the northwest. A border dispute with Michigan was settled by two cases, both Wisconsin v. Michigan, in 1934 and 1935. The state's boundaries include the Mississippi River and St. Croix River in the west, and the Menominee River in the northeast.
With its location between the Great Lakes and the Mississippi River, Wisconsin is home to a wide variety of geographical features. The state is divided into five distinct regions. In the north, the Lake Superior Lowland occupies a belt of land along Lake Superior. Just to the south, the Northern Highland has massive mixed hardwood and coniferous forests including the 1500000 acre Chequamegon-Nicolet National Forest, as well as thousands of glacial lakes, and the state's highest point, Timms Hill. In the middle of the state, the Central Plain has some unique sandstone formations like the Dells of the Wisconsin River in addition to rich farmland. The Eastern Ridges and Lowlands region in the southeast is home to many of Wisconsin's largest cities.
The ridges include the Niagara Escarpment that stretches from New York, the Black River Escarpment and the Magnesian Escarpment.
The bedrock of the Niagara Escarpment is dolomite, while the two shorter ridges have limestone bedrock.
In the southwest, the Western Upland is a rugged landscape with a mix of forest and farmland, including many bluffs on the Mississippi River. This region is part of the Driftless Area, which also includes portions of Iowa, Illinois, and Minnesota. This area was not covered by glaciers during the most recent ice age, the Wisconsin Glaciation.
Overall, 46% of Wisconsin's land area is covered by forest. Langlade County has a soil rarely found outside of the county called Antigo Silt Loam. 
Areas under the management of the National Park Service include the following:
There is one national forest managed by the U.S. Forest Service in Wisconsin, Chequamegon-Nicolet National Forest.
Wisconsin has sister-state relationships with the Germany's Hesse, Japan's Chiba Prefecture, Mexico's Jalisco, China's Heilongjiang, and Nicaragua.
The pole of inaccessibility for Wisconsin, located approximately 15 mi southwest of Wausau at , marks the location furthest from any point not within Wisconsin.
Climate.
The southern third of Wisconsin is classified as hot summer humid continental climate (Köppen "Dfa") and the colder northern portion is classified as warm summer humid continental climate (Köppen "Dfb"). The highest temperature ever recorded in the state was in the Wisconsin Dells, on July 13, 1936, where it reached 114 °F (46 °C). The lowest temperature ever recorded in Wisconsin was in the village of Couderay, where it reached −55 °F (−48 °C) on both February 2 and 4, 1996. Wisconsin also receives a large amount of regular snowfall averaging around 40 inches in the southern portions with up to 160 inches annually in the Lake Superior snowbelt each year.
Demographics.
The United States Census Bureau estimates that the population of Wisconsin was 5,757,564 on July 1, 2014, a 1.24% increase since the 2010 United States Census.
Since its founding, Wisconsin has been ethnically heterogeneous. Following the period of French fur traders, the next wave of settlers were miners, many of whom were Cornish, who settled the southwestern area of the state. The next wave was dominated by "Yankees," migrants of English descent from New England and upstate New York; in the early years of statehood, they dominated the state's heavy industry, finance, politics and education. Between 1850 and 1900, large numbers of European immigrants followed them, including Germans, Scandinavians (the largest group being Norwegian), and smaller groups of Belgians, Dutch, Swiss, Finns, Irish, Poles, Italians, and others. In the 20th century, large numbers of Mexicans and African Americans came, settling mainly in Milwaukee; and after the end of the Vietnam War came an influx of Hmongs.
According to the 2010 Census, the racial composition of the population was:
In the same year, 5.9% of the total population was of Hispanic or Latino origin (they may be of any race).
The six largest ancestry groups in Wisconsin are: German (42.6%), Irish (10.9%), Polish (9.3%), Norwegian (8.5%), English (6.5%), and Italian (6.1%). German is the most common ancestry in every county in the state, except Menominee, Trempealeau and Vernon. Wisconsin has the highest percentage of residents of Polish ancestry of any state.
The various ethnic groups settled in different areas of the state. Although Germans settled throughout the state, the largest concentration was in Milwaukee. Norwegians settled in lumbering and farming areas in the north and west. Small colonies of Belgians, Swiss, Finns and other groups settled in their particular areas, with Irish, Italian, and Polish immigrants settling primarily in urban areas.
African Americans came to Milwaukee, especially from 1940 on. Menominee County is the only county in the eastern United States with an American Indian majority. 86% of Wisconsin's African-American population live in four cities: Milwaukee, Racine, Beloit, Kenosha, with Milwaukee home to nearly three-fourths of the state's black Americans. In the Great Lakes region, only Detroit and Cleveland have a higher percentage of African-American residents. 
33% of Wisconsin's Asian population is Hmong, with significant communities in Milwaukee, Wausau, Green Bay, Sheboygan, Appleton, Madison, La Crosse, Eau Claire, Oshkosh, and Manitowoc.
Of the residents of Wisconsin, 71.7% were born in Wisconsin, 23.0% were born in a different US state, 0.7% were born in Puerto Rico, U.S. Island areas, or born abroad to American parent(s), and 4.6% were foreign born.
Religion.
The percentage of Wisconsin residents who belong to various affiliations are Christian 81% (Protestant 50%, Roman Catholic 29%, Mormon 0.5%), Jewish 0.5%, Muslim 0.5%, Buddhist 0.5%, Hindu 0.5% and the unaffiliated at 15%.
Christianity is the predominant religion of Wisconsin. As of 2008, the three largest denominational groups in Wisconsin were Catholic, Evangelical Protestant, and Mainline Protestant. As of 2010, the Catholic Church had the highest number of adherents in Wisconsin (at 1,425,523), followed by the Evangelical Lutheran Church in America with 414,326 members, and the Lutheran Church–Missouri Synod with 223,279 adherents. The Wisconsin Evangelical Lutheran Synod, which has the fourth highest numbers of adherents in Wisconsin, and the international conference it belongs to, the Confessional Evangelical Lutheran Conference, both have their headquarters in Waukesha, Wisconsin.
Crime.
Statewide FBI Crime statistics for 2009 include 144 murders/nonnegligent manslaughter; 1,108 rapes; 4,850 robberies; 8,431 aggravated assaults; and 147,486 property crimes. Wisconsin also publishes its own statistics through the Office of Justice Assistance. The OJA reported 14,603 violent crimes in 2009, with a clearance rate (% solved) of 50%. The OJA reported 4,633 sexual assaults in 2009, with an overall clearance rate for sexual assaults of 57%.
Government.
The Wisconsin Blue Book is the primary published reference about the government and politics of the state, documenting the organization of the state's three branches of government. Published every two years with updated information, copies are available by contacting state legislators.
Wisconsin's Constitution outlines the structure and function of state government. Wisconsin's government is organized into three branches: executive, legislative, and judicial.
Executive.
The executive branch is headed by the governor. The current governor, Scott Walker, assumed office on January 3, 2011. In addition to the governor, the executive branch includes five other elected constitutional officers: Lieutenant Governor, Secretary of State, Attorney General, Treasurer, and State Superintendent of Public Instruction. Four members of the Wisconsin executive branch are Republicans. The Secretary of State is a Democrat, and the Superintendent of Public Instruction of Wisconsin is a non-partisan position.
Legislative.
The Wisconsin State Legislature is Wisconsin's legislative branch. The Legislature is a bicameral body consisting of the Assembly and the Senate.
Judicial.
Wisconsin's court system has four levels: municipal courts, circuit courts, the Court of Appeals, and the Supreme Court. Municipal courts typically handle cases involving local ordinance matters. The circuit courts are Wisconsin's trial courts, they have original jurisdiction in all civil and criminal cases within the state. Challenges to circuit court rulings are heard by the Wisconsin Court of Appeals, consisting of sixteen judges who typically sit in three-judge panels. As the state's highest appellate court, the Wisconsin Supreme Court may hear both appeals from lower courts and original actions. In addition to deciding cases, the Supreme Court is responsible for administering the state's court system and regulating the practice of law in Wisconsin.
Federal.
In the United States Senate Wisconsin is represented by Ron Johnson and Tammy Baldwin. Wisconsin is divided into eight congressional districts.
Taxes.
Wisconsin collects personal income taxes (based on five income brackets) which range from 4.6% to 7.75%. The state sales and use tax rate is 5.0%. Fifty-nine counties have an additional sales/use tax of 0.5%. Milwaukee County and four surrounding counties have an additional temporary 0.1% tax that helps fund the Miller Park baseball stadium, which was completed in 2001.
The most common property tax assessed on Wisconsin residents is the real property tax, or their residential property tax. Wisconsin does not impose a property tax on vehicles, but does levy an annual registration fee. Property taxes are the most important tax revenue source for Wisconsin's local governments, as well as major methods of funding school districts, vocational technical colleges, special purpose districts and tax incremental finance districts. Equalized values are based on the full market value of all taxable property in the state, except for agricultural land. In order to provide property tax relief for farmers, the value of agricultural land is determined by its value for agricultural uses, rather than for its possible development value. Equalized values are used to distribute state aid payments to counties, municipalities, and technical colleges. Assessments prepared by local assessors are used to distribute the property tax burden within individual municipalities.
Wisconsin does not assess a tax on intangible property. Wisconsin does not collect inheritance taxes. Until January 1, 2008, Wisconsin's estate tax was decoupled from the federal estate tax laws; therefore the state imposed its own estate tax on certain large estates.
There are no toll roads in Wisconsin; highway construction and maintenance are funded in part by motor fuel tax revenues, and the remaining balance is drawn from the State General Fund. Non-highway road construction and maintenance are funded by local governments (municipalities or counties).
International Relations.
Wisconsin has had a diplomatic relationship with the Japanese prefecture of Chiba since 1990.
Politics.
During the period of the Civil War, Wisconsin was a Republican state; in fact it is the state that gave birth to the Republican Party, although ethno-religious issues in the late 19th century caused a brief split in the Republican coalition. Through the first half of the 20th century, Wisconsin's politics were dominated by Robert La Follette and his sons, originally of the Republican Party, but later of the revived Progressive Party. Since 1945, the state has maintained a close balance between Republicans and Democrats. Republican Senator Joe McCarthy was a controversial national figure in the early 1950s. Recent leading Republicans include former Governor Tommy Thompson and Congressman F. James Sensenbrenner, Jr.; prominent Democrats include Senators Herb Kohl and Russ Feingold, and Congressman David Obey.
The most famous controversy in the state's political history dealt with foreign language teaching in schools. This was fought out in the Bennett Law campaign of 1890, when the Germans switched to the Democratic Party because of the Republican Party's support of the Bennett Law, which led to a major victory for the Democrats.
The cities of Wisconsin have been active in increasing the availability of legislative information on the internet, thereby providing for greater government transparency. Currently three of the five most populous cities in Wisconsin provide their constituents with internet-based access of all public records directly from the cities' databases. Wisconsin cities started to make this a priority after Milwaukee began doing so, , in 2001. One such city, Madison, has been named the in consecutive years.
In recent decades, Wisconsin has become a Democratic-leaning state at the presidential level; it has voted for Democratic candidates in each of the last seven presidential elections. The last Republican to carry the state was Ronald Reagan in 1984. In 2012, Republican presidential candidate Mitt Romney chose Wisconsin Congressman Paul Ryan, a native of Janesville, as his running mate against incumbent Democratic President Barack Obama and Vice President Joe Biden. Despite Ryan's presence on the Republican ticket, Obama still carried Wisconsin by a margin of 53% to 46%.
At the statewide level, Wisconsin is competitive, with control regularly alternating between the two parties. The 2010 elections saw a huge Republican resurgence in Wisconsin. Republicans took control of the governor's office and both houses of the state legislature. Republican Ron Johnson defeated Democratic incumbent U.S. Senator Russ Feingold, and Republicans took two previously Democratic-held House seats, creating a 5–3 Republican majority House delegation.
On February 14, 2011, the Wisconsin State Capitol erupted with protests when the Legislature took up a bill that would end most collective bargaining rights for state employees, except for wages, to address the $3.6 bil. deficit. The protests attracted tens of thousands of people each day, and garnered international attention.
The Assembly passed the bill 53–42 on March 10 after the State Senate passed it the night before, and sent it to the Governor for his signature. In response to the bill, enough signatures were gathered to force a recall election against Governor Walker. Tom Barrett, the mayor of Milwaukee and Walker's 2010 opponent, won the Democratic primary and faced Walker again. Walker won the election by 53% to 46% and became the first governor in United States history to retain his seat after a recall election.
Lawmakers in Wisconsin.
The last election in which Wisconsin supported a Republican Presidential candidate was in 1984. However, both the 2000 and 2004 presidential elections were close, with Wisconsin receiving heavy doses of national advertising because it was a "swing", or pivot, state. Al Gore carried the presidential vote in 2000 by 5,700 votes, and John Kerry won Wisconsin in 2004 by 11,000 votes. However, in 2008, Barack Obama carried the state by 381,000 votes and with 56%. Republicans had a stronghold in the Fox Valley, but elected a Democrat, Steve Kagen, of Appleton, for the 8th Congressional District in 2006. However, Kagen survived only two terms and was replaced by Republican Reid Ribble in the Republican Party's sweep of Wisconsin in November 2010, the first time the Republican Party has taken back both chambers of the state legislature and the governorship in the same election. Republicans have held Waukesha County. The City of Milwaukee heads the list of Wisconsin's Democratic strongholds, which also includes Madison and the state's Native American reservations. Wisconsin's largest Congressional district, the 7th, had voted Democratic since 1969. Its representative, David Obey, chaired the powerful House Appropriations Committee. However, Obey retired and the once Democratic seat was overtaken by Republican Sean Duffy in November 2010.
In 2006, Democrats gained in a national sweep of opposition to the Bush administration, and the Iraq War. The retiring GOP 8th District Congressman, Mark Green, of Green Bay, ran against the incumbent Governor Jim Doyle. Green lost by 8% statewide, making Doyle the first Democratic governor to be re-elected in 32 years. The Republicans lost control of the state Senate. Although Democrats gained eight seats in the state Assembly, Republicans retained a five-vote majority in that house. In 2008, Democrats regained control of the State Assembly by a 52–46 margin, marking the first time since 1987 that the governor and state legislature were both Democratic. 
With the election of Scott Walker, Republicans won both chambers of the legislature and the governorship, the first time all three changed partisan control in the same election. They have maintained that status since 2010. Following the 2014 general election on November 4, 2014, the Governor, Lieutenant Governor, State Attorney General and State Treasurer are all Republicans; the Secretary of State is a Democrat.
Economy.
In 2010 Wisconsin's gross state product was $248.3 billion, making it 21st among U.S. states. The economy of Wisconsin is driven by manufacturing, agriculture, and health care. The state's economic output from manufacturing was $48.9 billion in 2008, making it the tenth largest among states in manufacturing gross domestic product. Manufacturing accounts for about 20% of the state's gross domestic product, a proportion that is third among all states. The per capita personal income was $35,239 in 2008. In June 2010, the state's unemployment rate was 8% (seasonally adjusted).
In quarter four of 2011, the largest employers in Wisconsin were:
Agriculture.
Wisconsin produces about a quarter of America's cheese, leading the nation in cheese production. It is second in milk production, after California, and third in per-capita milk production, behind California and Vermont. Wisconsin is second in butter production, producing about one-quarter of the nation's butter. The state ranks first nationally in the production of corn for silage, cranberries ginseng, and snap beans for processing. It grows over half the national crop of cranberries. and 97% of the nation's ginseng. Wisconsin is also a leading producer of oats, potatoes, carrots, tart cherries, maple syrup, and sweet corn for processing. The significance of the state's agricultural production is exemplified by the depiction of a Holstein cow, an ear of corn, and a wheel of cheese on Wisconsin's state quarter design.
A large part of the state's manufacturing sector includes commercial food processing, including well-known brands such as Oscar Mayer, Tombstone frozen pizza, Johnsonville brats, and Usinger's sausage. Kraft Foods alone employs over 5,000 people in the state. Milwaukee is a major producer of beer and was formerly headquarters for Miller Brewing Company — the nation's second-largest brewer – until it merged with Coors Brewing Company. Formerly, Schlitz, Blatz, and Pabst were cornerstone breweries in Milwaukee. 
Manufacturing.
Wisconsin is home to a very large and diversified manufacturing economy, with special focus on transportation and capital equipment. Major Wisconsin companies in these categories include the Kohler Company; Mercury Marine; Rockwell Automation; Johnson Controls; Seagrave Fire Apparatus; Pierce Manufacturing (fire apparatus); John Deere;Briggs & Stratton; Miller Electric; Milwaukee Electric Tool Company; Caterpillar Inc.; Joy Global; The Manitowoc Company; Modine Manufacturing; Reliance Controls; Ladish Co.; Oshkosh Truck; Harley-Davidson; Case IH; S. C. Johnson & Son; Springs Window Fashions; Ashley Furniture; Ariens;and Evinrude Outboard Motors.
Consumer goods.
Wisconsin is a major producer of paper, packaging, and other consumer goods. Major consumer products companies based in the state include SC Johnson & Co., and Diversey Inc., Wisconsin also ranks first nationwide in the production of paper products; the lower Fox River from Lake Winnebago to Green Bay has 24 paper mills along its 39 mi stretch.
The development and manufacture of health care devices and software is a growing sector of the state's economy, with key players such as GE Healthcare, Epic Systems, and TomoTherapy.
Tourism.
Tourism is a major industry in Wisconsin – the state's third largest, according to the Department of Tourism. Tourist destinations such as the House on the Rock near Spring Green, Circus World Museum in Baraboo, and The Dells of the Wisconsin River draw thousands of visitors annually, and festivals such as Summerfest and the EAA Oshkosh Airshow draw international attention, along with hundreds of thousands of visitors.
Given the large number of lakes and rivers in the state, water recreation is very popular. In the North Country, what had been an industrial area focused on timber has largely been transformed into a vacation destination. Popular interest in the environment and environmentalism, added to traditional interests in hunting and fishing, has attracted a large urban audience within driving range.
The distinctive Door Peninsula, which extends off the eastern coast of the state, contains one of the state's tourist destinations, Door County. Door County is a popular destination for boaters because of the large number of natural harbors, bays, and ports on the Green Bay and Lake Michigan side of the peninsula that forms the county. The area draws hundreds of thousands of visitors yearly to its quaint villages, seasonal cherry picking, and fish boils.
Film industry.
On January 1, 2008, a new tax incentive for the film industry came into effect. The first major production to take advantage of the tax incentive was Michael Mann's "Public Enemies". While the producers spent $18 million on the film, it was reported that most of that went to out-of-state workers and for out-of-state services; Wisconsin taxpayers had provided $4.6 million in subsidies, and derived only $5 million in revenues from the film's making.
Energy.
Wisconsin has no production of oil, gas, or coal. Its in-state electrical generation is mostly from coal. Other important electricity sources are natural gas and nuclear.
The state has a mandate that ten percent of its electrical energy come from renewable sources by the end of 2015. This goal has been met, but not with in state sources. One third of that ten percent comes from out of state sources, mostly wind generated electricity from Minnesota and Iowa. The state has agnostic policies for developing wind power in state.
Transportation.
Wisconsin is served by eight commercial service airports, in addition to a number of general aviation airports.
The Wisconsin Department of Transportation is responsible for planning, building and maintaining the state's highways. Seven Interstate Highways transverse the state.
Important municipalities.
Over 68% of Wisconsin residents live in urban areas, with the Greater Milwaukee area home to roughly one-third of the state's population. Milwaukee is at the northern edge of an urban area bordering Lake Michigan that stretches southward into greater Chicago and northwestern Indiana, with a population of over 11 million. With over 594,000 residents, Milwaukee is the 30th-largest city in the country. The string of cities along the western edge of Lake Michigan is generally considered to be an example of a megalopolis.
With a population of around 233,000 and metropolitan area of over 600,000, Madison has a dual identity as state capital and college town. Madison's suburb, Middleton, was ranked the "Best Place to Live in America" in 2007 by "Money Magazine". Medium-size cities dot the state and anchor a network of working farms surrounding them. As of 2011, there were 12 cities in Wisconsin with a population of 50,000 or more, accounting for 73% of the state's employment.
Wisconsin has three types of municipality: cities, villages, and towns. Cities and villages are incorporated urban areas. Towns are unincorporated minor civil divisions of counties with limited self-government.
Education.
Wisconsin, along with Minnesota and Michigan, was among the Midwestern leaders in the emergent American state university movement following the Civil War in the United States. By the start of the 20th century, education in the state advocated the "Wisconsin Idea", which emphasized service to the people of the state. The "Wisconsin Idea" exemplified the Progressive movement within colleges and universities at the time.
Today, public post-secondary education in Wisconsin includes both the 26-campus University of Wisconsin System, with the flagship university University of Wisconsin–Madison, and the 16-campus Wisconsin Technical College System. Private colleges and universities include Beloit College, Cardinal Stritch University, Carroll University, Carthage College, Concordia University Wisconsin, Edgewood College, Lakeland College, Lawrence University, Marquette University, Medical College of Wisconsin, Milwaukee School of Engineering, Ripon College, St. Norbert College, and others.
Culture.
Residents of Wisconsin are referred to as Wisconsinites. The traditional prominence of references to dairy farming and cheesemaking in Wisconsin's rural economy (the state's license plates have read "America's Dairyland" since 1940) have led to the nickname (sometimes used pejoratively among non-residents) of "cheeseheads" and to the creation of "cheesehead hats" made of yellow foam in the shape of a wedge of cheese. 
Numerous ethnic festivals are held throughout Wisconsin to celebrate the heritage of its citizens. Such festivals include Summerfest, Oktoberfest, Polish Fest, Festa Italiana, Irish Fest, Bastille Days, Syttende Mai (Norwegian Constitution Day), Brat(wurst) Days in Sheboygan, Polka Days, Cheese Days in Monroe and Mequon, African World Festival, Indian Summer, Arab Fest, and many others.
Art.
The Milwaukee Art Museum, with its "brise soleil" designed by Santiago Calatrava, is known for its interesting architecture. Monona Terrace in Madison, a convention center designed by Taliesin architect Anthony Puttnam, is based on a 1930s design by Frank Lloyd Wright. Wright's home and studio in the 20th century was at Taliesin, south of Spring Green. Decades after Wright's death, Taliesin remains an architectural office and school for his followers.
Music.
Wisconsin holds numerous country music festivals, including Miller Lite Presents Country Fest, Bud Light Presents Country Jam USA, the Coors Hodag Country Festival, Porterfield Country Music Festival, Country Thunder USA in Twin Lakes, and Ford Presents Country USA. Milwaukee hosts Summerfest, dubbed "The World's Largest Music Festival", every year. This festival is held at the lakefront Henry Maier Festival Park just south of downtown, as are a summer-long array of ethnic musical festivals. The Wisconsin Area Music Industry provides an annual WAMI event where it presents an awards show for top Wisconsin artists.
Alcohol and Wisconsin culture.
Drinking has long been considered a significant part of Wisconsin culture, and the state ranks at or near the top of national measures of per-capita alcohol consumption, consumption of alcohol per state, and proportion of drinkers. Consumption per-capita per-event, however, ranks low among the nation; number of events (number of times alcohol is involved) is significantly higher or highest, but consumption at each event smaller, marking Wisconsin's consumption as frequent and moderate. Factors such as cultural identification with the state's heritage of German immigration, the longstanding presence of major breweries in Milwaukee, and a cold climate are often associated with the prevalence of drinking in Wisconsin.
In Wisconsin, the legal drinking age is 21, except when accompanied by a parent, guardian, or spouse who is at least 21 years old. Age requirements are waived for possessing alcohol when employed by a brewer, brewpub, beer and/or liquor wholesaler, or producer of alcohol fuel. The minimum legal age to purchase alcohol is 21, with no exceptions. Wisconsin is the only state that treats a first offense drunk driving (OWI) as a traffic violation and not a misdemeanor. It also has a zero tolerance policy for driving under 21, with 0.0 blood alcohol the only non-citable alcohol level.
On Septmber 30, 2003, the state legislature, reluctant to lower a DUI offense from BAC 0.10 to 0.08, did so only as a result of federal government pressure. The Wisconsin Tavern League opposes raising the alcoholic beverage tax. The "Milwaukee Journal Sentinel" series "Wasted in Wisconsin" examined this situation.
Recreation.
The varied landscape of Wisconsin makes the state a popular vacation destination for outdoor recreation. Winter events include skiing, ice fishing and snowmobile derbies. Wisconsin is situated on two Great Lakes and has many inland lakes of varied size; the state contains 11188 sqmi of water, more than all but three other states - Alaska, Michigan, and Florida.
Outdoor activities are popular in Wisconsin, especially hunting and fishing. One of the most prevalent game animals is the whitetail deer. Each year in Wisconsin, well over 600,000 deer hunting licenses are sold. In 2008, the Wisconsin Department of Natural Resources projected the pre-hunt deer population to be between 1.5 and 1.7 million.
Sports.
Wisconsin is represented by major league teams in three sports: football, baseball, and basketball. Lambeau Field, located in Green Bay, Wisconsin, is home to the National Football League's Green Bay Packers. The Packers have been part of the NFL since the league's second season in 1921 and hold the record for the most NFL titles, earning the city of Green Bay the nickname "Titletown USA". The Packers are the smallest city franchise in the NFL, and is the only one owned by shareholders statewide. The franchise was founded by "Curly" Lambeau who played and coached for them. The Green Bay Packers are one of the most successful small-market professional sports franchises in the world and have won 13 NFL championships, including the first two AFL-NFL Championship games (Super Bowls I and II), Super Bowl XXXI and Super Bowl XLV. The state's support of the team is evidenced by the 81,000-person waiting list for season tickets to Lambeau Field.
The Milwaukee Brewers, the state's only major league baseball team, play in Miller Park in Milwaukee, the successor to Milwaukee County Stadium since 2001. In 1982, the Brewers won the American League Championship, marking their most successful season. The team switched from the American League to the National League starting with the 1998 season. Before the Brewers, Milwaukee had two prior Major League teams. The first team, also called the Brewers, played only one season in the newly founded American League in 1901 before moving to St. Louis and becoming the Browns, who are now the Baltimore Orioles. Milwaukee was also the home of the Braves franchise when they moved from Boston from 1953 to 1965, winning the World Series in 1957 and the National League pennant in 1958, before they moved to Atlanta.
The Milwaukee Bucks of the National Basketball Association play home games at the Bradley Center. The Bucks won the NBA Championship in 1971.
The state also has minor league teams in hockey (Milwaukee Admirals) and baseball (the Wisconsin Timber Rattlers, based in Appleton and the Beloit Snappers of the Class A minor leagues). Wisconsin is also home to the Madison Mallards, the La Crosse Loggers, the Lakeshore Chinooks, the Eau Claire Express, the Green Bay Bullfrogs, the Wisconsin Woodchucks, and the Wisconsin Rapids Rafters of the Northwoods League, a collegiate all-star summer league. In addition to the Packers, Green Bay is also the home to an indoor football team, the Green Bay Blizzard of the IFL. The state is home to the six-time MSL Champion Milwaukee Wave.
Wisconsin also has many college sports programs, including the Wisconsin Badgers, of the University of Wisconsin–Madison and the Panthers of University of Wisconsin–Milwaukee. The Wisconsin Badgers football former head coach Barry Alvarez led the Badgers to three Rose Bowl championships, including back-to-back victories in 1999 and 2000. The Badger men's basketball team won the national title in 1941 and made trips to college basketball's Final Four in 2000, 2014 and 2015. The Badgers claimed a historic dual championship in 2006 when both the women's and men's hockey teams won national titles.
The Marquette Golden Eagles of the Big East Conference, the state's other major collegiate program, is known for its men's basketball team, which, under the direction of Al McGuire, won the NCAA National Championship in 1977. The team returned to the Final Four in 2003.
Many other schools in the University of Wisconsin system compete in the Wisconsin Intercollegiate Athletic Conference at the Division III level. The conference is one of the most successful in the nation, claiming 107 NCAA national championships in 15 different sports as of March 30, 2015.
The Semi-Professional Northern Elite Football League consists of many teams from Wisconsin. The league is made up of former professional, collegiate, and high school players. Teams from Wisconsin include: The Green Bay Gladiators from Green Bay, The Fox Valley Force in Appleton, The Kimberly Storm in Kimberly, The Central Wisconsin Spartans in Wausau, The Eau Claire Crush and the Chippewa Valley Predators from Eau Claire, and the Lake Superior Rage from Superior. The league also has teams in Michigan and Minnesota. Teams play from May until August.
Wisconsin is home to the world's oldest operational racetrack. The Milwaukee Mile, located in Wisconsin State Fair Park in West Allis, Wisconsin, held races there that considerably predate the Indy 500.
Wisconsin is home to the nation's oldest operating velodrome in Kenosha where races have been held every year since 1927.
Kohler is home to Whistling Straits golf club which has hosted PGA Championships in 2004, 2010 and 2015 and will be home to the Ryder Cup golf competition between USA and Europe in 2020. The Greater Milwaukee Open, later named the U.S. Bank Championship in Milwaukee, was a PGA Tour tournament from 1968 to 2009 held annually in Brown Deer.

</doc>
<doc id="33129" url="http://en.wikipedia.org/wiki?curid=33129" title="Summerfest">
Summerfest

Summerfest (also known as "The Big Gig") is a annual music festival held at the 75 acre Henry Maier Festival Park along the lakefront in Milwaukee, Wisconsin. The festival lasts for 11 days, is made up of 11 stages with performances from over 700 bands, and since the mid-1970s has run from late June through early July, usually including the 4th of July holiday. Summerfest attracts between 800,000 and 1,000,000 people each year, promoting itself as "The World's Largest Music Festival", a title certified by the Guinness World Records since 1999.
Summerfest is operated by a non-profit board that hires the production staff to operate both the venue and main Summerfest event, which features local and nationally known music talent from a variety of music genres. The event also provides the opportunity to sample a wide variety of food from many Milwaukee-area restaurants. Other Summerfest attractions include comedy acts, shopping vendors, fireworks (including "The Big Bang" on opening night), other special attractions, family activities, and more.
Performing and Recording Artists make personal appearances on 11 sponsor-themed stages throughout the grounds from noon to midnight, including the 23,000-capacity Marcus Amphitheater. All shows are free with an admission ticket, with the exception of headlining acts at the Marcus Amphitheater. Admission is between US$11 and US$18, depending on the time of day. There are numerous promotions for discounted or free admission.
History.
Summerfest was conceived in the 1960s by then-mayor Henry W. Maier. Inspired by his visit to Oktoberfest in Munich, Germany, Maier envisioned a similar ethnic-themed festival in Milwaukee, and in 1962 formed a panel of business and civic leaders to study the feasibility of a large-scale summer festival. By the middle of the decade, the panel drew up a proposal for a 10-day multi-event festival with the proposed name of "Milwaukee World Festival," which was changed briefly in 1966 to "Juli Spaß" (German for "July Fun") and then to "Summerfest".
The inaugural Summerfest was held in July 1968 at 35 different locations throughout the city (including Milwaukee County Stadium and Milwaukee Arena), and its events ranged from concerts to a film festival, an air show, and even a pageant. The first Summerfest, produced by Dee Robb and Con Merten was regarded as a success; the second event in 1969, was less successful, as it was plagued by additional venues, inclement weather, and severe financial debt.
In 1970, a permanent central location was decided upon, and Summerfest moved to a former Nike missile site on the lakefront, where it continues to be held to this day. Also that year, Summerfest introduced its red "smiley face" logo, an insignia that has become synonymous with the event. The logo was designed by local graphic artist Noel Spangler.
It was also in 1970 that Henry Jordan, former Green Bay Packers defensive tackle, became executive director of Summerfest, a title he held during the event's early years until his death in 1977. After a few other businessmen were hired by the board for the executive director's job, Elizabeth "Bo" Black, who was formerly Henry Jordan's secretary, became executive director in 1984 after a ten year lobbying effort. 
Summerfest celebrated its 40th anniversary in 2007. The event's history was the subject of "Summerfest Stories", a documentary that aired in June 2007 on Milwaukee Public Television.
In 2015, Milwaukee World Festival, Inc and ReverbNation announced a three-year agreement to use the online service as a audition to give musicians a chance to perform. Summerfest wanted to provide an opportunity for performers to get a chance to be one of the 800+ acts and allow new talent to be seen by over 900,000 people that attend. 
Attendance
In 2014, Summerfest managed to draw and host 851,879 patrons, an increase of 1.4% over 2013’s 840,356 attendance, overcoming unseasonable weather challenges, including fog, intermittent rain and cool temperatures, along with significant highway and road construction projects in the immediate area. Food and beverage sales at the event increased by 6% over last year’s totals in the same categories. Summerfest employed nearly 2,200 seasonal employees. Festival fans sampled over 45 diverse food and beverage vendors, which resulted in the consumption of 66,011 burgers, 20,799 brats, 17,842 eggplant strips, 96,344 mozzarella sticks, 38,202 ears of corn, 181,758 mini donuts and 33,728 ice cream. 
Stages.
Uline Warehouse
Located on the north end of the grounds, the Uline Warehouse can host approximately 5,000 - 6,000 fans and features an eclectic mix of acts from various genres including classic rock, country, hard rock, blues and jam bands.
U.S. Cellular Connection.
The U.S. Cellular Connection stage is a moderately-sized free stage at Summerfest, and is often host to alternative and indie music bands. It is partially sponsored by the local alternative music station, Milwaukee FM 102.1.
Potowatomi/Johnson Controls.
Potowatomi is the name of a local casino that provided monetary support to the summerfest administration. As of summer 2013, the Potowatomi stage was renamed the "Johnson Controls World Sound Stage."
Tiki Hut.
The Tiki Hut is a small lakefront stage that often features local but talented acts, with genres ranging from acoustic to electronic funk. The area often serves as an oasis for concertgoers looking to get away from the crowds and heat from the larger stages. Unlike most other stages, a single band may perform more than one act per day for a block of three to four days, which aids in developing a local following. The performers on this, and many of the smaller stages usually work for tips, as they are not paid to be there. Two current mainstays and crowd favorites of the Tiki Hut are Roster McCabe, a high-energy Minneapolis-based rock/rap/reggae/funk/electronic fusion group and acoustic guitarist Dan Rodriguez.
Miller Lite Oasis.
The Miller Lite Oasis stage, completed in 2006, is the largest stage inside the Summerfest grounds without having to pay the extra for the Marcus Amphitheatre headliner.
Refugee.
Like the Tiki Hut, the Refugee stage features local acts of a variety of genres. The Refugee stage is just 15 feet from Lake Michigan and is a popular place to feel the lake breeze on hotter summer days and meet the musicians.
Marcus Amphitheater.
The Marcus Amphitheater is an amphitheater on the south end of the Summerfest grounds. The amphitheater was built after an extremely overcrowded concert in 1984 to carry crowds of 25,000 fans during concerts. It was completed in 1987, with the principal contribution from the Marcus Corporation. It is the venue for headlining acts performing at Summerfest. It is also the host to a variety of concerts and events during the spring, summer and fall.
Harley-Davidson Roadhouse.
Harley-Davidson teamed up with Summerfest to completely renovate their stage and area footprint for the 2008 festival season. The renovation improved sight lines, sound and lighting, while also increasing the area's capacity and providing for improved traffic flow in and around the stage area. Upgrades included large video screens for image magnification of performances and a comfortable seating area at the lakefront.
Briggs & Stratton Big Backyard.
In 2011, a renovated Briggs & Stratton Big Backyard stage opened.
BMO Harris Pavilion.
In 2012, the BMO Harris Pavilion finished construction. The new pavilion and stage, designed by Epstein Uhen, features a swooshing wave-like roof and replaces the temporary Classic Rock Stage on the south end of the grounds. It is the main project of phase two of Summerfest's two-year, US$35,000,000 redevelopment project.
The pavilion features a 10,000-person capacity, including 5,000 seats. A 17-by-10-foot video screen has been added to enhance viewing for standing-room-only patrons. Additional amenities include a lakeside sit-down restaurant and a "club bar" – with room for 200 patrons and a commanding view of the stage – open to the public during unsold time periods. Plans are also in the works to book concerts at the pavilion outside of Summerfest. There have been complaints that this is now the first ticketed venue in what was a completely general admission festival since the beginning of Summerfest in 1968, besides Marcus Amphitheater.
Concert history.
Summerfest has been most famous for its music, ever since the first festival in 1968, when acts such as Ronnie Dove, The New Colony Six, The Robbs and Up With People performed. Since then, musical acts from Bob Dylan, The Jonas Brothers, Maroon 5, Fun., Britney Spears, Tina Turner, and James Taylor to Christina Aguilera, Kanye West, Kid Cudi, Mary J. Blige, Wiz Khalifa, Imagine Dragons,and Nine Inch Nails have graced the Summerfest stages. Acts with Milwaukee and Wisconsin connections have had a prominent history at Summerfest, most notably the BoDeans, The Gufs, Danny Gokey, and Violent Femmes., The Sociables
The concerts have been mostly civil events, with two notable exceptions. In 1970, a performance by the late-arriving Sly & the Family Stone nearly resulted in a riot. In 1973, a performance by Humble Pie & the Blackberries resulted in a riot, a bonfire, and about 300 arrests. As a result of the latter concert, organizers shied away from rock bands for several years, and established guidelines for "family-friendly" acts and a ban on alcohol brought in by patrons. This was properly managed when Henry Jordan found the experienced booking staff to manage entertainment in-house, eliminating Cleveland's Jules Belkin Promotions, who were hired by Board Members Bernie Samson and Steve Marcus. Also at that time local manager Lou Volpano was hired to improve production, and book international superstars on what was a mere Local Rock Stage, where then the Ramones, UFO, and Judas Priest headlined 
Live comedy acts have also been a part of Summerfest's history, even before a regular "Comedy Showcase" was first established in 1975. Bob Hope was the main headliner at Summerfest 1969, performing two shows at Milwaukee County Stadium. George Carlin (opening for Arlo Guthrie) performed his "Seven Words You Can Never Say on Television" routine at the 1972 event (and was subsequently arrested for violating obscenity laws). Prior to his arrest, he discarded a bag of cocaine to avoid further imprisonment.
Since 1975, comedy acts ranging from David Brenner and Henny Youngman to Jay Leno and Jon Stewart have performed at the event. Sandra Bernhard did TV and radio promos for its 1986 season when she was a performer there. Lewis Black has become a frequent performer at Summerfest, making near-annual performances since his first appearance in 1991.
For 2015, Linkin Park, Keith Urban, Ed Sheeran, Florida Georgia Line, Zac Brown Band ,
Kings of Leon, Kendrick Lamar, The Rolling Stones, Stevie Wonder, and Neil Young will attend the festival on Milwaukee's lakefront as headliners.
The Rolling Stones will perform its first Milwaukee concert in 10 years, June 23 at the Marcus Amphitheater on the Summerfest grounds, as part of a summer run being dubbed the "Zip Code" tour. June 23 is technically the day before Summerfest's opening night, but the Big Gig is promoting the Stones concert as "The Ultimate Kick-Off to Summerfest." 
On April 20th, 2015 it was announced Stevie Wonder would fill the June 27th headlining spot at the festival. His first Milwaukee concert since 2009. 
The 2015 Summerfest ground stage headliners were announced on March 24th by Billboard. They include the likes of Sheryl Crow, Aloe Blacc, The Doobie Brothers, Sammy Haggar, Pat Benatar, Whitesnake, Third Eye Blind, Weird Al, and 90 other names. 
Winterfest.
Beginning in the winter of 1989-1990, Summerfest organizers staged a colder (in the literal sense) version of Summerfest, known as Winterfest. Rather than being chiefly set at Henry Maier Festival Park, the event took inspiration from Summerfest's early days and spread its music, comedy, and other events throughout several downtown Milwaukee locations, the central spot being an ice skating rink near Cathedral Square. Due largely to undesirable Milwaukee winters, Winterfest was never as profitable as its older summer counterpart, and ceased operations after the 1997-98 event.

</doc>
<doc id="33130" url="http://en.wikipedia.org/wiki?curid=33130" title="Werner Heisenberg">
Werner Heisenberg

Werner Karl Heisenberg (]; 5 December 1901 – 1 February 1976) was a German theoretical physicist and one of the key pioneers of quantum mechanics. He published his work in 1925 in a breakthrough paper. In the subsequent series of papers with Max Born and Pascual Jordan, during the same year, this matrix formulation of quantum mechanics was substantially elaborated. In 1927 he published his uncertainty principle, upon which he built his philosophy and for which he is best known. Heisenberg was awarded the Nobel Prize in Physics for 1932 "for the creation of quantum mechanics". He also made important contributions to the theories of the hydrodynamics of turbulent flows, the atomic nucleus, ferromagnetism, cosmic rays, and subatomic particles, and he was instrumental in planning the first West German nuclear reactor at Karlsruhe, together with a research reactor in Munich, in 1957. Considerable controversy surrounds his work on atomic research during World War II.
Following World War II, he was appointed director of the Kaiser Wilhelm Institute for Physics, which soon thereafter was renamed the Max Planck Institute for Physics. He was director of the institute until it was moved to Munich in 1958, when it was expanded and renamed the Max Planck Institute for Physics and Astrophysics.
Heisenberg was also president of the German Research Council, chairman of the Commission for Atomic Physics, chairman of the Nuclear Physics Working Group, and president of the Alexander von Humboldt Foundation.
Life and career.
Early years.
Heisenberg was born in Würzburg, Germany, to Kaspar Earnesta August Heisenberg, a secondary school teacher of classical languages who became Germany's only "ordentlicher Professor" (ordinarius professor) of medieval and modern Greek studies in the university system, and his wife, Annie Wecklein.
He studied physics and mathematics from 1920 to 1923 at the "Ludwig-Maximilians-Universität München" and the "Georg-August-Universität Göttingen". At Munich, he studied under Arnold Sommerfeld and Wilhelm Wien. At Göttingen, he studied physics with Max Born and James Franck, and he studied mathematics with David Hilbert. He received his doctorate in 1923, at Munich under Sommerfeld. He completed his Habilitation in 1924, at Göttingen under Born.
Because Sommerfeld had a sincere interest in his students and knew of Heisenberg's interest in Niels Bohr's theories on atomic physics, Sommerfeld took Heisenberg to Göttingen to the "Bohr-Festspiele" (Bohr Festival) in June 1922. At the event, Bohr was a guest lecturer and gave a series of comprehensive lectures on quantum atomic physics. There, Heisenberg met Bohr for the first time, and it had a significant and continuing effect on him.
Heisenberg's doctoral thesis, the topic of which was suggested by Sommerfeld, was on turbulence; the thesis discussed both the stability of laminar flow and the nature of turbulent flow. The problem of stability was investigated by the use of the Orr–Sommerfeld equation, a fourth order linear differential equation for small disturbances from laminar flow. He briefly returned to this topic after World War II.
Heisenberg's paper on the anomalous Zeeman effect was accepted as his "Habilitationsschrift" (Habilitation thesis) under Max Born at Göttingen.
In his youth he was a member and Scoutleader of the "Neupfadfinder", a German Scout association and part of the German Youth Movement. In August 1923 Robert Honsell and Heisenberg organized a trip ("Großfahrt") to Finland with a Scout group of this association from Munich.
Heisenberg arrived to Munich in 1919 as a member of Freikorps to fight the Bavarian Soviet Republic established a year earlier. Five decades later he recalled those days as youthful fun, like "playing cops and robbers and so on; it was nothing serious at all."
Career.
Göttingen, Copenhagen, and Leipzig.
From 1924 to 1927, Heisenberg was a Privatdozent at Göttingen. From 17 September 1924 to 1 May 1925, under an International Education Board Rockefeller Foundation fellowship, Heisenberg went to do research with Niels Bohr, director of the Institute of Theoretical Physics at the University of Copenhagen. His seminal paper, "Über quantentheoretischer Umdeutung" was published in September 1925. He returned to Göttingen and with Max Born and Pascual Jordan, over a period of about six months, developed the matrix mechanics formulation of quantum mechanics. On 1 May 1926, Heisenberg began his appointment as a university lecturer and assistant to Bohr in Copenhagen. It was in Copenhagen, in 1927, that Heisenberg developed his uncertainty principle, while working on the mathematical foundations of quantum mechanics. On 23 February, Heisenberg wrote a letter to fellow physicist Wolfgang Pauli, in which he first described his new principle. In his paper on the uncertainty principle, Heisenberg used the word "Ungenauigkeit" (imprecision).
In 1927, Heisenberg was appointed "ordentlicher Professor" (ordinarius professor) of theoretical physics and head of the department of physics at the Universität Leipzig; he gave his inaugural lecture on 1 February 1928. In his first paper published from Leipzig, Heisenberg used the Pauli exclusion principle to solve the mystery of ferromagnetism.
In Heisenberg's tenure at Leipzig, the quality of doctoral students, post-graduate and research associates who studied and worked with Heisenberg there is attested to by the acclaim later earned by these people; at various times, they included: Erich Bagge, Felix Bloch, Ugo Fano, Siegfried Flügge, William Vermillion Houston, Friedrich Hund, Robert S. Mulliken, Rudolf Peierls, George Placzek, Isidor Isaac Rabi, Fritz Sauter, John C. Slater, Edward Teller, John Hasbrouck van Vleck, Victor Frederick Weisskopf, Carl Friedrich von Weizsäcker, Gregor Wentzel and Clarence Zener.
In early 1929, Heisenberg and Pauli submitted the first of two papers laying the foundation for relativistic quantum field theory. Also in 1929, Heisenberg went on a lecture tour in China, Japan, India, and the United States.
Shortly after the discovery of the neutron by James Chadwick in 1932, Heisenberg submitted the first of three papers on his neutron-proton model of the nucleus. He was awarded the 1932 Nobel Prize in Physics.
In 1928, the British mathematical physicist P. A. M. Dirac had derived the relativistic wave equation of quantum mechanics, which implied the existence of positive electrons, later to be named positrons. In 1932, from a cloud chamber photograph of cosmic rays, the American physicist Carl David Anderson identified a track as having been made by a positron. In mid-1933, Heisenberg presented his theory of the positron. His thinking on Dirac's theory and further development of the theory were set forth in two papers. The first, "Bemerkungen zur Diracschen Theorie des Positrons (Remarks on Dirac's theory of the positron)" was published in 1934, and the second, "Folgerungen aus der Diracschen Theorie des Positrons (Consequences of Dirac's Theory of the Positron)", was published in 1936. In these papers Heisenberg was the first to reinterpret the Dirac equation as a "classical" field equation for any point particle of spin ħ/2, itself subject to quantization conditions involving anti-commutators. Thus reinterpreting it as a (quantum) field equation accurately describing electrons, Heisenberg put matter on the same footing as electromagnetism: as being described by relativistic quantum field equations which allowed the possibility of particle creation and destruction. (Hermann Weyl had already described this in a 1929 letter to Einstein.)
In the early 1930s in Germany, the "Deutsche Physik" movement was anti-Semitic and anti-theoretical physics, especially including quantum mechanics and the theory of relativity. As applied in the university environment, political factors took priority over the historically applied concept of scholarly ability, even though its two most prominent supporters were the Nobel Laureates in Physics Philipp Lenard and Johannes Stark.
After Adolf Hitler came to power in 1933, Heisenberg was attacked in the press as a "White Jew" by elements of the "Deutsche Physik" (German Physics) movement for his insistence on teaching about the roles of Jewish scientists. As a result, he came under investigation by the SS. This was over an attempt to appoint Heisenberg as successor to Arnold Sommerfeld at the University of Munich. The issue was resolved in 1938 by Heinrich Himmler, head of the SS. While Heisenberg was not chosen as Sommerfeld's successor, he was rehabilitated to the physics community during the Third Reich. Nevertheless, supporters of "Deutsche Physik" launched vicious attacks against leading theoretical physicists, including Arnold Sommerfeld and Heisenberg. On 29 June 1936, a National Socialist Party newspaper published a column attacking Heisenberg. On 15 July 1937, he was attacked in a journal of the SS. This was the beginning of what is called the Heisenberg Affair.
In mid-1936, Heisenberg presented his theory of cosmic-ray showers in two papers. Four more papers appeared in the next two years.
In June 1939, Heisenberg bought a summer home for his family in Urfeld am Walchensee, in southern Germany. He also traveled to the United States in June and July, visiting Samuel Abraham Goudsmit, at the University of Michigan in Ann Arbor. However, Heisenberg refused an invitation to emigrate to the United States. He did not see Goudsmit again until six years later, when Goudsmit was the chief scientific advisor to the American Operation Alsos at the close of World War II. Ironically, Heisenberg was arrested under Operation Alsos and detained in England under Operation Epsilon.
Matrix mechanics and the Nobel Prize.
Heisenberg’s paper establishing quantum mechanics has puzzled physicists and historians. His methods assume that the reader is familiar with Kramers-Heisenberg transition probability calculations. The main new idea, noncommuting matrices, is justified only by a rejection of unobservable quantities. It introduces the non-commutative multiplication of matrices by physical reasoning, based on the correspondence principle, despite the fact that Heisenberg was not then familiar with the mathematical theory of matrices. The path leading to these results has been reconstructed in MacKinnon, 1977, and the detailed calculations are worked out in Aitchison et al.
In Copenhagen, Heisenberg and Hans Kramers collaborated on a paper on dispersion, or the scattering from atoms of radiation whose wavelength is larger than the atoms. They showed that the successful formula Kramers had developed earlier could not be based on Bohr orbits, because the transition frequencies are based on level spacings which are not constant. The frequencies which occur in the Fourier transform of sharp classical orbits, by contrast, are equally spaced. But these results could be explained by a semi-classical Virtual State model: the incoming radiation excites the valence, or outer, electron to a virtual state from which it decays. In a subsequent paper Heisenberg showed that this virtual oscillator model could also explain the polarization of fluorescent radiation.
These two successes, and the continuing failure of the Bohr-Sommerfeld model to explain the outstanding problem of the anomalous Zeeman effect, led Heisenberg to use the virtual oscillator model to try to calculate spectral frequencies. The method proved too difficult to immediately apply to realistic problems, so Heisenberg turned to a simpler example, the anharmonic oscillator.
The dipole oscillator consists of a simple harmonic oscillator, which is thought of as a charged particle on a spring, perturbed by an external force, like an external charge. The motion of the oscillating charge can be expressed as a Fourier series in the frequency of the oscillator. Heisenberg solved for the quantum behavior by two different methods. First, he treated the system with the virtual oscillator method, calculating the transitions between the levels that would be produced by the external source.
He then solved the same problem by treating the anharmonic potential term as a perturbation to the harmonic oscillator and using the perturbation methods that he and Born had developed. Both methods led to the same results for the first and the very complicated second order correction terms. This suggested that behind the very complicated calculations lay a consistent scheme.
So Heisenberg set out to formulate these results without any explicit dependence on the virtual oscillator model. To do this, he replaced the Fourier expansions for the spatial coordinates by matrices, matrices which corresponded to the transition coefficients in the virtual oscillator method. He justified this replacement by an appeal to Bohr’s correspondence principle and the Pauli doctrine that quantum mechanics must be limited to observables.
On 9 July, Heisenberg gave Born this paper to review and submit for publication. When Born read the paper, he recognized the formulation as one which could be transcribed and extended to the systematic language of matrices, which he had learned from his study under Jakob Rosanes at Breslau University. Born, with the help of his assistant and former student Pascual Jordan, began immediately to make the transcription and extension, and they submitted their results for publication; the paper was received for publication just 60 days after Heisenberg's paper. A follow-on paper was submitted for publication before the end of the year by all three authors. (A brief review of Born's role in the development of the matrix mechanics formulation of quantum mechanics along with a discussion of the key formula involving the non-commutivity of the probability amplitudes can be found in an article by Jeremy Bernstein, "Max Born and the Quantum Theory". A detailed historical and technical account can be found in Mehra and Rechenberg's book "The Historical Development of Quantum Theory. Volume 3. The Formulation of Matrix Mechanics and Its Modifications 1925–1926.")
Up until this time, matrices were seldom used by physicists; they were considered to belong to the realm of pure mathematics. Gustav Mie had used them in a paper on electrodynamics in 1912 and Born had used them in his work on the lattices theory of crystals in 1921. While matrices were used in these cases, the algebra of matrices with their multiplication did not enter the picture as they did in the matrix formulation of quantum mechanics.
Born had learned matrix algebra from Rosanes, as already noted, but Born had also learned Hilbert's theory of integral equations and quadratic forms for an infinite number of variables as was apparent from a citation by Born of Hilbert's work "Grundzüge einer allgemeinen Theorie der Linearen Integralgleichungen" published in 1912. Jordan, too was well equipped for the task. For a number of years, he had been an assistant to Richard Courant at Göttingen in the preparation of Courant and David Hilbert's book "Methoden der mathematischen Physik I", which was published in 1924. This book, fortuitously, contained a great many of the mathematical tools necessary for the continued development of quantum mechanics. In 1926, John von Neumann became assistant to David Hilbert, and he coined the term Hilbert space to describe the algebra and analysis which were used in the development of quantum mechanics.
In 1928, Albert Einstein nominated Heisenberg, Born, and Jordan for the Nobel Prize in Physics, but it was not to be. The announcement of the Nobel Prize in Physics for 1932 was delayed until November 1933. It was at that time that it was announced Heisenberg had won the Prize for 1932 "for the creation of quantum mechanics, the application of which has, , led to the discovery of the allotropic forms of hydrogen" and Erwin Schrödinger and Paul Adrien Maurice Dirac shared the 1933 Prize "for the discovery of new productive forms of atomic theory". One can rightly ask why Born was not awarded the Prize in 1932 along with Heisenberg – Bernstein gives some speculations on this matter. One of them is related to Jordan joining the Nazi Party on 1 May 1933 and becoming a Storm Trooper. Hence, Jordan's Party affiliations and Jordan's links to Born may have affected Born's chance at the Prize at that time. Bernstein also notes that when Born won the Prize in 1954, Jordan was still alive, and the Prize was awarded for the statistical interpretation of quantum mechanics, attributable alone to Born.
Heisenberg's reaction to Born for Heisenberg receiving the Prize for 1932 and to Born for Born receiving the Prize in 1954 are also instructive in evaluating whether Born should have shared the Prize with Heisenberg. On 25 November 1933, Born received a letter from Heisenberg in which he said he had been delayed in writing due to a "bad conscience" that he alone had received the Prize "for work done in Göttingen in collaboration – you, Jordan and I." Heisenberg went on to say that Born and Jordan's contribution to quantum mechanics cannot be changed by "a wrong decision from the outside." In 1954, Heisenberg wrote an article honoring Max Planck for his insight in 1900. In the article, Heisenberg credited Born and Jordan for the final mathematical formulation of matrix mechanics and Heisenberg went on to stress how great their contributions were to quantum mechanics, which were not "adequately acknowledged in the public eye."
The "Deutsche Physik" movement.
On 1 April 1935, the eminent theoretical physicist Arnold Sommerfeld, Heisenberg's doctoral advisor at the University of Munich, achieved emeritus status. However, Sommerfeld stayed in his chair during the selection process for his successor, which took until 1 December 1939. The process was lengthy due to academic and political differences between the Munich Faculty's selection and that of the Reichserziehungsministerium (REM, Reich Education Ministry) and the supporters of "Deutsche Physik", which was anti-Semitic and had a bias against theoretical physics, especially quantum mechanics and the theory of relativity.
In 1935, the Munich Faculty drew up a list of candidates to replace Sommerfeld as ordinarius professor of theoretical physics and head of the Institute for Theoretical Physics at the University of Munich. There were three names on the list: Werner Heisenberg, who received the Nobel Prize in Physics for 1932, Peter Debye, who received the Nobel Prize in Chemistry in 1936, and Richard Becker – all former students of Sommerfeld. The Munich Faculty was firmly behind these candidates, with Heisenberg as their first choice. However, supporters of "Deutsche Physik" and elements in the REM had their own list of candidates, and the battle dragged on for over four years. During this time, Heisenberg came under vicious attack by the "Deutsche Physik" supporters. One attack was published in "Das Schwarze Korps", the newspaper of the Schutzstaffel (SS), headed by Heinrich Himmler. In this, Heisenberg was called a "White Jew" (i.e. an Aryan who acts like a Jew) who should be made to "disappear". These attacks were taken seriously, as Jews were violently attacked and incarcerated. Heisenberg fought back with an editorial and a letter to Himmler, in an attempt to resolve this matter and regain his honour.
At one point, Heisenberg's mother visited Himmler's mother. The two women knew each other, as Heisenberg's maternal grandfather and Himmler's father were rectors and members of a Bavarian hiking club. Eventually, Himmler settled the Heisenberg affair by sending two letters, one to SS Gruppenführer Reinhard Heydrich and one to Heisenberg, both on 21 July 1938. In the letter to Heydrich, Himmler said Germany could not afford to lose or silence Heisenberg, as he would be useful for teaching a generation of scientists. To Heisenberg, Himmler said the letter came on recommendation of his family and he cautioned Heisenberg to make a distinction between professional physics research results and the personal and political attitudes of the involved scientists. The letter to Heisenberg was signed under the closing "Mit freundlichem Gruß und, Heil Hitler!" (With friendly greetings, Heil Hitler!") Overall, the Heisenberg affair was a victory for academic standards and professionalism. However, the appointment of Wilhelm Müller to replace Sommerfeld was a political victory over academic standards. Müller was not a theoretical physicist, had not published in a physics journal, and was not a member of the Deutsche Physikalische Gesellschaft; his appointment was considered a travesty and detrimental to educating theoretical physicists.
During the SS investigation of Heisenberg, the three investigators had training in physics. Heisenberg had participated in the doctoral examination of one of them at the "Universität Leipzig". The most influential of the three, however, was Johannes Juilfs. During their investigation, they had become supporters of Heisenberg as well as his position against the ideological policies of the "Deutsche Physik" movement in theoretical physics and academia.
World War II.
In 1939, shortly after the discovery of nuclear fission, the German nuclear energy project, also known as the "Uranverein" (Uranium Club), had begun. Heisenberg was one of the principal scientists leading research and development in the project.
From 15 to 22 September 1941, Heisenberg traveled to German-occupied Copenhagen to lecture and discuss nuclear research and theoretical physics with Niels Bohr. The meeting, and specifically what it might reveal about Heisenberg's intentions concerning developing nuclear weapons for the Nazi regime, is the subject of the award-winning Michael Frayn play titled "Copenhagen". A television film version of the play was made by the BBC in 2002, with Stephen Rea as Bohr, and Daniel Craig as Heisenberg. The same meeting had previously been dramatised by the BBC's "Horizon" science documentary series in 1992, with Anthony Bate as Bohr, and Philip Anthony as Heisenberg. Documents relating to the Bohr-Heisenberg meeting were released in 2002 by the Niels Bohr Archive and by the Heisenberg family. A dramatized account of Heisenberg's work during the war is featured in the 2015 TV series "The Heavy Water War".
On 26 February 1942, Heisenberg presented a lecture to Reich officials on energy acquisition from nuclear fission, after the Army withdrew most of its funding. The Uranium Club was transferred to the Reich Research Council (RFR) in July 1942. On 4 June 1942, Heisenberg was summoned to report to Albert Speer, Germany's Minister of Armaments, on the prospects for converting the Uranium Club's research toward developing nuclear weapons. During the meeting, Heisenberg told Speer that a bomb could not be built before 1945, and would require significant monetary and manpower resources. Five days later, on 9 June 1942, Adolf Hitler issued a decree for the reorganization of the RFR as a separate legal entity under the Reich Ministry for Armament and Ammunition; the decree appointed Reich Marshall Hermann Göring as the president.
In September 1942, Heisenberg submitted his first paper of a three-part series on the scattering matrix, or S-matrix, in elementary particle physics. The first two papers were published in 1943 and the third in 1944. The S-matrix described only observables, i.e., the states of incident particles in a collision process, the states of those emerging from the collision, and stable bound states; there would be no reference to the intervening states. This was the same precedent as he followed in 1925 in what turned out to be the foundation of the matrix formulation of quantum mechanics through only the use of observables.
In February 1943, Heisenberg was appointed to the Chair for Theoretical Physics at the "Friedrich-Wilhelms-Universität" (today, the Humboldt-Universität zu Berlin). In April, his election to the "Preußische Akademie der Wissenschaften" (Prussian Academy of Sciences) was approved. That same month, he moved his family to their retreat in as Allied bombing increased in Berlin. In the summer, he dispatched the first of his staff at the "Kaiser-Wilhelm Institut für Physik" to Hechingen and its neighboring town of Haigerloch, on the edge of the Black Forest, for the same reasons. From 18–26 October, he traveled to German-occupied Netherlands. In December 1943, Heisenberg visited German-occupied Poland.
From 24 January to 4 February 1944, Heisenberg traveled to occupied Copenhagen, after the German Army confiscated Bohr's Institute of Theoretical Physics. He made a short return trip in April. In December, Heisenberg lectured in neutral Switzerland. The United States Office of Strategic Services sent former major league baseball catcher and OSS agent Moe Berg to attend the lecture carrying a pistol, with orders to shoot Heisenberg if his lecture indicated that Germany was close to completing an atomic bomb. Heisenberg did not give such an indication, so Berg decided not to shoot him, a decision Berg later described as his own "uncertainty principle".
In January 1945, Heisenberg, with most of the rest of his staff, moved from the "Kaiser-Wilhelm Institut für Physik" to the facilities in the Black Forest.
Uranium Club.
In December 1938, the German chemists Otto Hahn and Fritz Strassmann sent a manuscript to "Naturwissenschaften" reporting they had detected the element barium after bombarding uranium with neutrons; simultaneously, they communicated these results to Lise Meitner, who had in July of that year fled to the Netherlands and then went to Sweden.
Meitner, and her nephew Otto Robert Frisch, correctly interpreted these results as being nuclear fission. Frisch confirmed this experimentally on 13 January 1939.
Paul Harteck was director of the physical chemistry department at the University of Hamburg and an advisor to the "Heereswaffenamt" (HWA, Army Ordnance Office). On 24 April 1939, along with his teaching assistant Wilhelm Groth, Harteck made contact with the "Reichskriegsministerium" (RKM, Reich Ministry of War) to alert them to the potential of military applications of nuclear chain reactions. Two days earlier, on 22 April 1939, after hearing a colloquium paper by Wilhelm Hanle on the use of uranium fission in a "Uranmaschine" (uranium machine, i.e., nuclear reactor), Georg Joos, along with Hanle, notified Wilhelm Dames, at the "Reichserziehungsministerium" (REM, Reich Ministry of Education), of potential military applications of nuclear energy. The communication was given to Abraham Esau, head of the physics section of the "Reichsforschungsrat" (RFR, Reich Research Council) at the REM. On 29 April, a group, organized by Esau, met at the REM to discuss the potential of a sustained nuclear chain reaction.
The group included the physicists Walther Bothe, Robert Döpel, Hans Geiger, Wolfgang Gentner (probably sent by Walther Bothe), Wilhelm Hanle, Gerhard Hoffmann and Georg Joos; Peter Debye was invited, but he did not attend. After this, informal work began at the Georg-August University of Göttingen by Joos, Hanle and their colleague Reinhold Mannfopff; the group of physicists was known informally as the first "Uranverein" (Uranium Club) and formally as "Arbeitsgemeinschaft für Kernphysik". The group's work was discontinued in August 1939, when the three were called to military training.
The second "Uranverein" began after the "Heereswaffenamt" (HWA, Army Ordnance Office) squeezed the "Reichsforschungsrat" (RFR, Reich Research Council) out of the "Reichserziehungsministerium" (REM, Reich Ministry of Education) and started the formal German nuclear energy project under military auspices. The second "Uranverein" was formed on 1 September 1939, the day World War II began, and it had its first meeting on 16 September 1939. The meeting was organized by Kurt Diebner, advisor to the HWA, and held in Berlin. The invitees included Walther Bothe, Siegfried Flügge, Hans Geiger, Otto Hahn, Paul Harteck, Gerhard Hoffmann, Josef Mattauch and Georg Stetter. A second meeting was held soon thereafter and included Klaus Clusius, Robert Döpel, Werner Heisenberg and Carl Friedrich von Weizsäcker. Also at this time, the "Kaiser-Wilhelm Institut für Physik" (KWIP, Kaiser Wilhelm Institute for Physics, after World War II the Max Planck Institute for Physics), in Berlin-Dahlem, was placed under HWA authority, with Diebner as the administrative director, and the military control of the nuclear research commenced.
When it was apparent that the nuclear energy project would not make a decisive contribution to ending the war effort in the near term, control of the KWIP was returned in January 1942 to its umbrella organization, the "Kaiser-Wilhelm Gesellschaft" (KWG, Kaiser Wilhelm Society, after World War II the Max-Planck Gesellschaft), and HWA control of the project was relinquished to the RFR in July 1942. The nuclear energy project thereafter maintained its "kriegswichtig" (important for the war) designation and funding continued from the military. However, the German nuclear power project was then broken down into the following main areas: uranium and heavy water production, uranium isotope separation and the "Uranmaschine" (uranium machine, i.e., nuclear reactor). Also, the project was then essentially split up between a number of institutes, where the directors dominated the research and set their own research agendas. The dominant personnel and facilities were the following:
Heisenberg was appointed director-in-residence of the KWIP on 1 July 1942, as Peter Debye was still officially the director and on leave in the United States; Debye had gone on leave as he was a citizen of The Netherlands and had refused to become a German citizen when the HWA took administrative control of the KWIP. Heisenberg still also had his department of physics at the University of Leipzig where work was done for the "Uranverein" by Robert Döpel and his wife Klara Döpel. During the period Kurt Diebner administered the KWIP under the HWA program, considerable personal and professional animosity developed between Diebner and the Heisenberg inner circle – Heisenberg, Karl Wirtz, and Carl Friedrich von Weizsäcker.
The point in 1942, when the army relinquished its control of the German nuclear energy project, was the zenith of the project relative to the number of personnel devoting time to the effort. There were only about 70 scientists working on the project, with about 40 devoting more than half their time to nuclear fission research. After this, the number of scientists working on applied nuclear fission diminished dramatically. Many of the scientists not working with the main institutes stopped working on nuclear fission and devoted their efforts to more pressing war related work.
Over time, the HWA and then the RFR controlled the German nuclear energy project. The most influential people in the project were Kurt Diebner, Abraham Esau, Walther Gerlach and Erich Schumann. Schumann was one of the most powerful and influential physicists in Germany. Schumann was director of the Physics Department II at the Frederick William University (later, University of Berlin), which was commissioned and funded by the "Oberkommando des Heeres" (OKH, Army High Command) to conduct physics research projects. He was also head of the research department of the HWA, assistant secretary of the Science Department of the OKH and "Bevollmächtiger" (plenipotentiary) for high explosives. Diebner, throughout the life of the nuclear energy project, had more control over nuclear fission research than did Walther Bothe, Klaus Clusius, Otto Hahn, Paul Harteck or Werner Heisenberg.
1945: Operation Alsos and Operation Epsilon.
Operation Alsos was an Allied effort commanded by the Russian-American Colonel Boris T. Pash. He reported directly to General Leslie Groves, commander of the Manhattan Engineer District, which was developing atomic weapons for the United States. The chief scientific advisor to Operation Alsos was the physicist Samuel Abraham Goudsmit. Goudsmit was selected for this task because of his knowledge of physics, he spoke German, and he personally knew a number of the German scientists working on the German nuclear energy project. He also knew little of the Manhattan Project, so, if he were captured, he would have little intelligence value to the Germans.
The objectives of Operation Alsos were to determine if the Germans had an atomic bomb program and to exploit German atomic related facilities, intellectual materials, materiel resources, and scientific personnel for the benefit of the US. Personnel on this operation generally swept into areas which had just come under control of the Allied military forces, but sometimes they operated in areas still under control by German forces.
Berlin had been a location of many German scientific research facilities. To limit casualties and loss of equipment, many of these facilities were dispersed to other locations in the latter years of the war. The "Kaiser-Wilhelm-Institut für Physik" (KWIP, Kaiser Wilhelm Institute for Physics) had mostly been moved in 1943 and 1944 to Hechingen and its neighboring town of Haigerloch, on the edge of the Black Forest, which eventually became the French occupation zone. This move and a little luck allowed the Americans to take into custody a large number of German scientists associated with nuclear research. The only section of the institute which remained in Berlin was the low-temperature physics section, headed by Ludwig Bewilogua (1906–83), who was in charge of the exponential uranium pile.
Nine of the prominent German scientists who published reports in "Kernphysikalische Forschungsberichte" as members of the "Uranverein" were picked up by Operation Alsos and incarcerated in England under Operation Epsilon: Erich Bagge, Kurt Diebner, Walther Gerlach, Otto Hahn, Paul Harteck, Werner Heisenberg, Horst Korsching, Carl Friedrich von Weizsäcker and Karl Wirtz. Also, incarcerated was Max von Laue, although he had nothing to do with the nuclear energy project. Goudsmit, the chief scientific advisor to Operation Alsos, thought von Laue might be beneficial to the postwar rebuilding of Germany and would benefit from the high level contacts he would have in England.
Heisenberg had been captured and arrested by Colonel Pash at Heisenberg's retreat in Urfeld, on 3 May 1945, in what was a true alpine-type operation in territory still under control by German forces. He was taken to Heidelberg, where, on 5 May, he met Goudsmit for the first time since the Ann Arbor visit in 1939. Germany surrendered just two days later. Heisenberg did not see his family again for eight months. Heisenberg was moved across France and Belgium and flown to England on 3 July 1945.
The 10 German scientists were held at Farm Hall in England. The facility had been a safe house of the British foreign intelligence MI6. During their detention, their conversations were recorded. Conversations thought to be of intelligence value were transcribed and translated into English. The transcripts were released in 1992. Bernstein has published an annotated version of the transcripts in his book "Hitler's Uranium Club: The Secret Recordings at Farm Hall", along with an introduction to put them in perspective. A complete, unedited publication of the British version of the reports appeared as "Operation Epsilon: The Farm Hall Transcripts", which was published in 1993 by the Institute of Physics in Bristol and by the University of California Press in the US.
Post 1945.
On 3 January 1946, the 10 Operation Epsilon detainees were transported to Alswede in Germany, which was in the British occupation zone. Heisenberg settled in Göttingen, also in the British zone. In July, he was named director of the "Kaiser-Wilhelm-Institut für Physik" (KWIP, Kaiser Wilhelm Institute for Physics), then located in Göttingen. Shortly thereafter, it was renamed the "Max-Planck-Institut für Physik", in honor of Max Planck and to assuage political objections to the continuation of the institute. Heisenberg was its director until 1958. In 1958, the institute was moved to Munich, expanded, and renamed "Max-Planck-Institut für Physik und Astrophysik" (MPIFA). Heisenberg was its director from 1960 to 1970; in the interim, Heisenberg and the astrophysicist Ludwig Biermann were co-directors. Heisenberg resigned his directorship of the MPIFA on 31 December 1970. Upon the move to Munich, Heisenberg also became an "ordentlicher Professor" (ordinarius professor) at the University of Munich.
Just as the Americans did with Operation Alsos, the Soviets inserted special search teams into Germany and Austria in the wake of their troops. Their objective, under the Russian Alsos, was also the exploitation of German atomic related facilities, intellectual materials, materiel resources and scientific personnel for the benefit of the Soviet Union. One of the German scientists recruited under this Soviet operation was the nuclear physicist Heinz Pose, who was made head of Laboratory V in Obninsk. When he returned to Germany on a recruiting trip for his laboratory, Pose wrote a letter to Werner Heisenberg inviting him to work in the USSR. The letter lauded the working conditions in the USSR and the available resources, as well as the favorable attitude of the Soviets towards German scientists. A courier hand delivered the recruitment letter, dated 18 July 1946, to Heisenberg; Heisenberg politely declined in a return letter to Pose.
In 1947, Heisenberg presented lectures in Cambridge, Edinburgh and Bristol. Heisenberg also contributed to the understanding of the phenomenon of superconductivity with a paper in 1947 and two papers in 1948, one of them with Max von Laue.
In the period shortly after World War II, Heisenberg briefly returned to the subject of his doctoral thesis, turbulence. Three papers were published in 1948 and one in 1950.
In the post-war period, Heisenberg continued his interests in cosmic-ray showers with considerations on multiple production of mesons. He published three papers in 1949, two in 1952, and one in 1955.
On 9 March 1949, the "Deutsche Forschungsrat" (German Research Council) was established by the "Max-Planck Gesellschaft" (MPG, Max Planck Society, successor organization to the "Kaiser-Wilhelm Gesellschaft"). Heisenberg was appointed president of the "Deutsche Forschungsrat". In 1951, the organization was fused with the Notgemeinschaft der Deutschen Wissenschaft (NG, Emergency Association of German Science) and that same year renamed the "Deutsche Forschungsgemeinschaft" (DFG, German Research Foundation). With the merger, Heisenberg was appointed to the presidium.
In 1952, Heisenberg served as the chairman of the Commission for Atomic Physics of the DFG. Also that year, he headed the German delegation to the European Council for Nuclear Research.
In 1953, Heisenberg was appointed president of the "Alexander von Humboldt-Stiftung" by Konrad Adenauer. Heisenberg served until 1975. Also, from 1953, Heisenberg's theoretical work concentrated on the unified field theory of elementary particles.
In late 1955 to early 1956, Heisenberg gave the Gifford Lectures at St Andrews University, in Scotland, on the intellectual history of physics. The lectures were later published as "Physics and Philosophy: The Revolution in Modern Science".
During 1956 and 1957, Heisenberg was the chairman of the "Arbeitskreis Kernphysik" (Nuclear Physics Working Group) of the "Fachkommission II "Forschung und Nachwuchs"" (Commission II "Research and Growth") of the "Deutschen Atomkommission" (DAtK, German Atomic Energy Commission). Other members of the Nuclear Physics Working Group in both 1956 and 1957 were: Walther Bothe, Hans Kopfermann (vice-chairman), Fritz Bopp, Wolfgang Gentner, Otto Haxel, Willibald Jentschke, Heinz Maier-Leibnitz, Josef Mattauch, Wolfgang Riezler, Wilhelm Walcher and Carl Friedrich von Weizsäcker. Wolfgang Paul was also a member of the group during 1957.
In 1957, Heisenberg was a signatory of the manifesto of the "Göttinger Achtzehn" (Göttingen Eighteen).
From 1957, Heisenberg was interested in plasma physics and the process of nuclear fusion. He also collaborated with the International Institute of Atomic Physics in Geneva. He was a member of the Institute's Scientific Policy Committee, and for several years was the Committee's chairman.
In 1973, Heisenberg gave a lecture at Harvard University on the historical development of the concepts of quantum theory.
On 24 March 1973, Heisenberg gave a speech before the Catholic Academy of Bavaria, accepting the Romano Guardini Prize. An English translation of its title is "Scientific and Religious Truth." And its stated goal was "In what follows, then, we shall first of all deal with the unassailability and value of scientific truth, and then with the much wider field of religion, of which – so far as the Christian religion is concerned – Guardini himself has so persuasively written; finally – and this will be the hardest part to formulate – we shall speak of the relationship of the two truths." A more detailed insight into Heisenberg's view on religion has been discussed by Wilfried Schröder in "Natural science and religion" (Bremen 1999, Science edition) and Wilfried Schröder "Naturerkenntnis und Religion" (Bremen, science edition 2008).
Personal life.
In January 1937 Heisenberg met Elisabeth Schumacher (1914-1998) at a private music recital. Elisabeth was the daughter of a well-known Berlin economics professor, and her brother was the economist E. F. Schumacher, author of "Small is Beautiful". Heisenberg married her on 29 April. Fraternal twins Maria and Wolfgang were born in January 1938, whereupon Wolfgang Pauli congratulated Heisenberg on his "pair creation" – a word play on a process from elementary particle physics, pair production. They had five more children over the next 12 years: Barbara, Christine, Jochen, Martin and Verena. Jochen became a physics professor at the University of New Hampshire.
Heisenberg enjoyed classical music and was an accomplished pianist.
Heisenberg was raised and lived as a Lutheran Christian, publishing and giving several talks reconciling science with his faith.
In his speech Scientific and Religious Truth (1974) while accepting the Romano Guardini Prize, Heisenberg affirmed:
“In the history of science, ever since the famous trial of Galileo, it has repeatedly been claimed that scientific truth cannot be reconciled with the religious interpretation of the world. Although I am now convinced that scientific truth is unassailable in its own field, I have never found it possible to dismiss the content of religious thinking as simply part of an outmoded phase in the consciousness of mankind, a part we shall have to give up from now on. Thus in the course of my life I have repeatedly been compelled to ponder on the relationship of these two regions of thought, for I have never been able to doubt the reality of that to which they point.” (Heisenberg 1974, 213)
“Where no guiding ideals are left to point the way, the scale of values disappears and with it the meaning of our deeds and sufferings, and at the end can lie only negation and despair.
Religion is therefore the foundation of ethics, and ethics the presupposition of life.” (Heisenberg 1974, 219).
“The first gulp from the glass of natural sciences will turn you into an atheist, but at the bottom of the glass God is waiting for you.” -W.Heisenberg 
In his autobiographical article in the journal "Truth", Henry Margenau (Professor Emeritus of Physics and Natural Philosophy at Yale University) pointed out: “I have said nothing about the years between 1936 and 1950. There were, however, a few experiences I cannot forget. One was my first meeting with Heisenberg, who came to America soon after the end of the Second World War. Our conversation was intimate and he impressed me by his deep religious conviction. He was a true Christian in every sense of that word.” 
Heisenberg also enjoyed mountaineering. In his autobiography, he included photographs from this activity.
Heisenberg died of cancer of the kidneys and gall bladder at his home, on 1 February 1976. The next evening, his colleagues and friends walked in remembrance from the Institute of Physics to his home and each put a candle near the front door. He is buried at Munich Waldfriedhof.
Honors and awards.
Heisenberg was awarded a number of honors:
Research Reports in Nuclear Physics.
The following reports were published in "Kernphysikalische Forschungsberichte" ("Research Reports in Nuclear Physics"), an internal publication of the German "Uranverein". The reports were classified Top Secret, they had very limited distribution, and the authors were not allowed to keep copies. The reports were confiscated under the Allied Operation Alsos and sent to the United States Atomic Energy Commission for evaluation. In 1971, the reports were declassified and returned to Germany. The reports are available at the Karlsruhe Nuclear Research Center and the American Institute of Physics.
Publications.
</dl>
References.
</dl>
Further reading.
</dl>

</doc>
<doc id="33131" url="http://en.wikipedia.org/wiki?curid=33131" title="Wireless telegraphy">
Wireless telegraphy

Wireless telegraphy is the transmission of electric telegraphy signals without wires (wirelessly). It is now used as a historical term for early "radio" telegraphy systems which communicated with radio waves, although when the term originated in the late 1800s it was also used for a variety of other experimental techniques for communicating telegraphically without wires, such as photoelectric and induction telegraphy.
Wireless telegraphy came to mean Morse code transmitted by radio waves (electromagnetic waves), initially called "Hertzian waves" and by 1910 universally referred to as "radio", and the term has been largely replaced by the more modern term "radiotelegraphy". The transmission of speech (radiotelephony) began to displace wireless telegraphy by the 1920s for many applications and made possible radio broadcasting. Wireless telegraphy continued to be used for private point-to-point business, governmental, and military communication, and evolved into radioteletype networks.
Wireless telegraphy is still used widely today by amateur radio hobbyists where it is commonly referred to as radio telegraphy, continuous wave, or just CW.
History of development.
Ground and water conduction.
A number of wireless electrical signaling schemes including electrical currents through water and dirt were investigated for telegraphy before practical radio systems became available.
The original telegraph used two wires between two stations to form a complete electrical circuit or "loop." In 1837, however, Carl August von Steinheil of Munich, Germany found that by connecting one leg of the apparatus at each station to metal plates buried in the ground, he could eliminate one wire and use a single wire for telegraphic communication. This led to speculation that it might be possible to eliminate both wires and therefore transmit telegraph signals through the ground without any wires connecting the stations. Other attempts were made to send the electric current through bodies of water, in order to span rivers, for example. Prominent experimenters along these lines included Samuel F. B. Morse in the United States and James Bowman Lindsay in Great Britain.
Telegraphic communication using earth conductivity was eventually found to be limited to impractically short distances, as was communication conducted through water, or between trenches during World War I.
Optical.
The first wireless voice telecommunication device, invented in 1880, was the photophone, which carried voice communications optically on a lightbeam transmitted to a distant receiver.
Electrostatic and electromagnetic.
Both electrostatic and electromagnetic induction were used to develop wireless telegraph systems that saw limited commercial application. In the United States, Thomas Edison, in the mid-1880s, patented an electromagnetic induction system he called "grasshopper telegraphy", which allowed telegraphic signals to jump the short distance between a running train and telegraph wires running parallel to the tracks. This system was successful technically but not economically, as there turned out to be little interest by train travelers in an on-board telegraph service. During the Great Blizzard of 1888, this system was used to send and receive wireless messages from trains buried in snowdrifts. The disabled trains were able to maintain communications via their Edison induction wireless telegraph systems, perhaps the first successful use of wireless telegraphy to send distress calls.
The most successful creator of an electromagnetic induction telegraph system was William Preece in the United Kingdom. Beginning with tests across the Bristol Channel in 1892, Preece was able to telegraph across gaps of about 5 km. However, his induction system required extensive lengths of antenna wires, many kilometers long, at both the sending and receiving ends. The length of those sending and receiving wires needed to be about the same length as the width of the water or land to be spanned. For example, for Preece's station to span the English Channel from Dover, England, to the coast of France would require sending and receiving wires of about 30 mi along the two coasts. These facts made the system impractical on ships, boats, and ordinary islands, which are much smaller than Great Britain or Greenland. In addition, the relatively short distances that a practical Preece system could span meant that it had few advantages over underwater telegraph cables.
Period before 1838.
In 1832, Lindsay gave a classroom demonstration of wireless telegraphy to his students. By 1854 he was able to demonstrate transmission across the Firth of Tay from Dundee to Woodhaven (now part of Newport-on-Tay), a distance of 2 mi.
Electromagnetic wave (radio).
Wireless telegraphy dates as far back as Faraday in the early 19th century, when it was discovered that radio waves could be used to send telegraph messages.
In the mid-1860s, James Clerk Maxwell predicted the existence of electromagnetic waves and showed that their propagation speed is identical to that of light. After that, in reality, it required very little to demonstrate by experiment the existence of such waves.
Calzecchi-Onesti.
By 1884, Temistocle Calzecchi-Onesti in Fermo, Italy, developed a primitive device that responded to radio waves. It consisted of a tube filled with iron filings, called a "coherer". This kind of device would later be developed to become the first practical radio detector. Writing in the "Rendiconti" of the Lombardy Institution regarding the discovery of the coherer, directs attention to his experiments made in 1884, before Branly had worked on the subject. He further points out the part played by Augusto Righi in wireless telegraphy.
Calzecchi found that the conductivity of metal powder varied depending on the incidence of radio waves.
However, Calzecchi's experiments were not widely reported. He would later write "Le mie esperienze e quelle di Edoardo Branly: Sulla conduttività elettrica delle limature metalliche" (tr., "My experiences and those of Edward Branly: The electrical conductivity of metal filings").
Heinrich Hertz.
Between 1886 and 1888, Heinrich Rudolf Hertz studied Maxwell's theory and validated it through experiment. He demonstrated the transmission and reception of the electromagnetic waves predicted by Maxwell, and he intentionally transmitted and received radio. Hertz changed the frequency of his radiated waves by altering the inductance or capacity of his radiating conductor or antenna, and reflected and focused the electromagnetic waves, thus demonstrating the correctness of Maxwell's electromagnetic theory of light. Famously, he saw no practical use for his discovery.
In his Ultra high frequency (UHF) experiments, Hertz transmitted and received radio waves over short distances and showed that the properties of radio waves were consistent with Maxwell’s electromagnetic theory. He demonstrated that radio radiation had all the properties of waves (now called electromagnetic radiation), and discovered that the electromagnetic equations could be reformulated into a partial differential equation called the wave equation.
He demonstrated the existence of electromagnetic radiation (radio waves) in a series of experiments in Germany during the 1880s. Hertz showed methods of producing, detecting, and measuring these waves. It had been known for many years – from the predictions of Kelvin and Von Helmholtz, and confirmed by the experiments of Fedderssen – that in many cases an electric discharge is of an oscillatory character. In the years 1887-8, Lodge, Fitzgerald, and others were investigating the nature of these oscillations, and the manner in which they are guided by conducting wires, when Hertz conceived the idea of investigating the disturbances caused by such oscillatory discharges in the surrounding space.
Hertz used the damped oscillating currents in a dipole antenna, triggered by a high-voltage electrical capacitive spark discharge, as his source of radio waves. His detector in some experiments was another dipole antenna connected to a narrow spark gap, thereby creating a spark-gap transmitter. A small spark in this gap signified detection of the radio waves. When he added cylindrical reflectors behind his dipole antennas, Hertz could detect radio waves about 20 m from the transmitter in his laboratory at the Karlsruhe Technical High School. He did not try to transmit further because his aim was proving electromagnetic theory, not developing wireless communication.
In the collection of physical instruments in Karlsruhe, Hertz had found and used for lecture purposes a pair of so-called Eiess spirals or Knochenhauer spirals. Hertz had been surprised to find that it was not necessary to discharge large batteries through one of these spirals in order to obtain sparks in the other; small Leyden jars amply sufficed for this purpose, and even the discharge of a small induction coil would do, provided it had to spring across a spark gap. In altering the conditions, Hertz came upon the phenomenon of side-sparks, which formed the starting point of his research. At first Hertz thought the electrical disturbances would be too turbulent and irregular to be of any further use, but when he had discovered the existence of a neutral point in the middle of a side-conductor – and therefore discovered a clear and orderly phenomenon – he felt convinced that the problem of the Berlin Academy was now capable of solution. His ambition at the time did not go further than this. Hertz's conviction was naturally strengthened by finding that the oscillations were regular.
Hertz’s setup for a source and detector of radio waves (then called Hertzian waves in his honor) was the first intentional and unequivocal transmission and reception of radio waves through free space. The first of the papers published ("On Very Rapid Electric Oscillations") gives, generally in the actual order of time, the course of the investigation as far as it was carried out up to the end of the year 1886 and the beginning of 1887.
Hertz, however, did not devise a system for actual general use nor describe the application of the technology, and he seemed uninterested in the practical importance of his experiments. He stated that "It's of no use whatsoever ... this is just an experiment that proves Maestro Maxwell was right — we just have these mysterious electromagnetic waves that we cannot see with the naked eye. But they are there." Asked about the ramifications of his discoveries, Hertz replied, "Nothing, I guess." Hertz also stated, "I do not think that the wireless waves I have discovered will have any practical application". Hertz died in 1894, so the art of radio was left to others to implement into a practical form.
Branly.
In 1890, Édouard Branly demonstrated what he later called the "radio-conductor," which Lodge in 1893 named the coherer, the first sensitive device for detecting radio waves. Shortly after the experiments of Hertz, Dr. Branly discovered that loose metal filings, which in a normal state have a high electrical resistance, lose this resistance in the presence of electric oscillations and become conductors of electricity. This Branly showed by placing metal filings in a glass box or tube and making them part of an ordinary electric circuit. According to the common explanation, when electric waves are set up in the neighborhood of this circuit, electromotive forces are generated in it which appear to make the filings move closer together, that is, to cohere, and thus their electrical resistance decreases accordingly, Sir Oliver Lodge termed this piece of apparatus a coherer. Hence the receiving instrument, which may be a telegraph relay, that normally would not indicate any sign of current from the small battery, can be operated when electric oscillations are set up. Prof. Branly further found that when the filings had once cohered, they retained their low resistance until shaken apart, for instance, by tapping on the tube.
In "On the Changes in Resistance of Bodies under Different Electrical Conditions", he described how the electrical circuit was made by means of two narrow strips of copper parallel to the short sides of the rectangular plate, and forming good contact with it by means of screws. When the two copper strips were raised, the plate was cut out of the circuit. He also used as conductors fine metallic filings, which he sometimes mixed with insulating liquids. The filings were placed in a tube of glass or ebonite and were held between two metal plates. When the electrical circuit, consisting of a Daniell cell, a galvanometer of high resistance, and the metallic conductor, consisting of the ebonite plate, and the sheet of copper, or of the tube containing the filings, was completed, only a very small current flowed; but there was a sudden diminution of the resistance, which was proved by a large deviation of the galvanometer needle when one or more electric discharges were produced in the neighbourhood of the circuit. In order to produce these discharges, a small Wimshurst influence machine was used, with or without a condenser, or a Ruhmkorff coil. The action of the electrical discharge diminished as the distance increases; but Branley observed it easily, and without taking any special precautions, at a distance of several yards. By using a Wheatstone bridge, he observed this action at a distance of 20 yards, although the machine producing the sparks was working in a room separated from the galvanometer and the bridge by three large apartments, and the noise of the sparks was not audible. The changes of resistance were considerable with the conductors described. They varied, for instance, from several millions of ohms to 2000, or even to 100, from 150,000 to 500 ohms, from 50 to 35, and so on. The diminution of resistance was not momentary, and sometimes it was found to remain for 24 hours. Another method of making the test was by connecting the electrodes of a capillary electrometer to the two poles of a Daniell cell with a sulphate of cadmium solution. The displacement of mercury which took place when the cell was short-circuited, only took place very slowly when an ebonite plate, covered with a sheet of copper of high resistance, was inserted between one of the poles of the cell, and the corresponding electrode of the electrometer; but when sparks were produced by a machine, the mercury was rapidly thrown into the capillary tube owing to the sudden diminution in the resistance of the plate.
Upon examination of the conditions necessary to produce the phenomena, Branly found that:
Summing up, he stated that in all these tests, the use of ebonite plates covered with copper or mixtures of copper and tin was less satisfactory than the use of filings; with the plates, he was unable to obtain the initial resistance of the body after the action of the spark or of the current, while with the tubes and filings, the resistance could be brought back to its normal value by striking a few sharp blows on the support of the tube.
The disadvantages of the coherer are its erratic sensitivity, which may be much decreased by local discharges, such as the spark discharges of the transmitter, and its response to atmospheric disturbances or lightning discharges. Consequently, the coherer cannot be relied upon as a "calling-up apparatus". With strong impulses of energy in the receiver, it enables one to print the received message, but for long-distance work, it is not as sensitive as some other detectors that were developed in the inter-war period before the roaring Twenties.
Landell de Moura.
Roberto Landell de Moura, a Brazilian priest and scientist, went to Rome in 1878 and studied at the South American College and Pontifical Gregorian University, where he studied physics and chemistry. He completed his clerical training in Rome, graduating in theology, and was ordained priest in 1886. In Rome, he started studying physics and electricity. When he returned to Brazil, he conducted experiments in wireless in Campinas and São Paulo (1892–1893). In the "Porto Jornal da Manha", he is said to have conducted between 1890 and 1894 wireless transmissions in telegraphy and telephony over distances of up to 8 km.
Tesla.
During his visit to the Paris Exposition Universelle in 1889 the Serbian-American engineer Nikola Tesla learned of Hertz's experiments with electromagnetic waves using coils and spark gaps and proceeded to duplicate those experiments. Tesla came to the conclusion that Maxwell and Hertz were wrong in their findings that airborne electromagnetic waves (radio waves) were being transmitted and instead attributed it to what he called “electrostatic thrusts”, with the real signals being conducted by Earth currents.
By 1891 he had developed various alternator apparatus that produced 15,000 cycles per second and developed his own very large air gaped coil, known now as a Tesla coil. Tesla's primary interest in wireless phenomenon was as a power distribution system. By 1892 he was delivering lectures on high potential/high frequency alternate currents" and went on to demonstrate "wireless lighting" in 1893 including lighting Geissler tubes wirelessly. Tesla proposed this wireless technology could not only deliver power but could also be used for the telecommunication of information. In 1894, Thomas Commerford Martin published "The Inventions, Researches and Writings of Nikola Tesla", detailing the work of Tesla in the previous years.
Tesla (like many scientists of that time) thought, even if radio waves existed, they would probably only travel in straight lines making them useless for long range transmission. His laboratory work and later large scale experiments at Colorado Springs led him to the conclusion that a world wide wireless system would have to use the Earth itself (via injecting very large amounts of electrical current into the ground) as the means to conduct the signal to overcome this limitation. He proceed to develop an earth-conductive (wireless) system similar to the ground conduction systems proposed earlier which he thought could achieve his goal of wireless power transmission as well as communication. By 1900 Tesla had received financial backing of banker J. P. Morgan and other investors to try to implement his promised ideas of world wide wireless telecommunication in his very large Wardenclyffe Tower wireless transmission project. The project ran into many problems including Guglielmo Marconi starting regular transatlantic transmission in 1903 with far less expensive equipment. Financial backing dried up and Tesla had abandoned the project by 1906.
Marconi.
By 1897, Guglielmo Marconi conducted a series of demonstrations with a radio system for signalling for communications over long distances. Marconi is said to have read, while on vacation in 1894, about the experiments that Hertz did in the 1880s. Marconi also read parts of Thomas Commerford Martin's book about the inventions of Nikola Tesla and Scientific American. It was at this time that Marconi began to understand that radio waves could be used for wireless communications. Marconi's early apparatus was a development of Hertz’s laboratory apparatus into a system designed for communications purposes. At first, Marconi used a transmitter to ring a bell in a receiver in his attic laboratory. He then moved his experiments out-of-doors on the family estate near Bologna, Italy, to communicate farther. He replaced Hertz’s vertical dipole with a vertical wire topped by a metal sheet, with an opposing terminal connected to the ground. On the receiver side, Marconi replaced the spark gap with a metal powder coherer, a detector developed by Edouard Branly and other experimenters. Marconi transmitted radio signals for about a mile at the end of 1895.
By 1896, Marconi introduced to the public a device in London and he filed a patent on his earliest system with the British Patent Office on June 2, 1896. In 1897, Marconi was awarded a patent for radio with British patent , "Improvements in Transmitting Electrical Impulses and Signals and in Apparatus There-for". The complete specification was filed March 2, 1897. This was Marconi's initial patent for the radio, though it used various earlier techniques of various other experimenters (primarily Tesla) and resembled the instrument demonstrated by others (including Popov). During this time, spark-gap wireless telegraphy was widely researched. In July 1896, Marconi got his invention and new method of telegraphy to the attention of Preece, then engineer-in-chief to the British Government Telegraph Service, who had for the previous twelve years interested himself in the development of wireless telegraphy by the inductive-conductive method. On June 4, 1897, Preece delivered his lecture, "Signalling through Space without Wires". Preece devoted considerable time to exhibiting and explaining the Marconi apparatus at the Royal Institution in London, stating that Marconi had invented a new relay which had high sensitivity and delicacy.
In 1896, Jagdish Chandra Bose went to London on a lecture tour and met Marconi, who was conducting wireless experiments for the British post office. In 1897, Marconi founded the Marconi Company Ltd.. Also in 1897, Marconi established the radio station at Niton, Isle of Wight, England. Marconi's wireless telegraphy was inspected by the Post Office telegraph authorities; they made a series of experiments with Marconi's system in the Bristol Channel. In October 1897, wireless signals were sent from Salisbury Plain to Bath, a distance of 34 miles. Marconi's reputation is largely based on the formulation of Marconi's law (1897), and other accomplishments in radio communications and commercializing a practical system.
Other experimental stations were established at Lavernock Point, near Penarth; on Flat Holm, off Cardiff in the Bristol Channel, and at Brean Down, a promontory on the Somerset side. Signals were obtained between the first and last-named points, a distance of approximately eight miles. The receiving instrument used was a Morse inkwriter of the Post Office pattern.
In a famous 1910 murder case, the culprit (Dr. Hawley Harvey Crippen) was apprehended with the assistance of a transatlantic message sent by wireless telegraphy.
Period 1898–1902.
The term "wireless telegraphy" came into widespread use around the turn of the 19th century, when spark-gap transmitters and primitive receivers made it practical to send telegraph messages over great distances, enabling transcontinental and ship-to-shore signalling. Before that time, wireless telegraphy was an obscure experimental term that applied collectively to an assortment of sometimes unrelated signalling schemes. In 1898, Tesla demonstrated a radio-controlled boat in Madison Square Garden that allowed secure communication between transmitter and receiver.
In 1899, Landell de Moura transmitted the human voice from the College of the Sisters of St. Joseph, high in the district of Santana, Brazil, north of the capital city. He also publicly demonstrated his invention on June 3, 1900. As the "Jornal do Commercio" reported (June 10, 1900), "Last Sunday, on top of Santana in São Paulo, Padre Landell de Moura has particular experience with various devices of his invention. In order to demonstrate some laws which he discovered in studying the propagation of sound, the light and electricity through space, which were crowned with brilliant success." The experiments were performed in the presence of the English Vice Consul S. Paul, Percy Parmenter, Charles Lupton, and other persons of high social position. Upon observing the experiments, Rodriguez Botet, giving news of the trials, said he was not far from the moment of consecrating Landell de Moura as an author of radio discoveries. Landell de Moura later received several patents on wireless technology. He would later obtain U.S. Patent for a wireless telephone.
In 1898, Marconi opened a radio factory in Hall Street, Chelmsford, England, employing around 50 people. In 1899, Marconi announced his invention of the "iron-mercury-iron coherer with telephone detector" in a paper presented at the Royal Society, London. In May, 1898, communication was established for Lloyd's of London between Ballycastle and the lighthouse on Rathlin Island in the North of Ireland. In July, 1898, the Marconi telegraph was employed to report the results of yacht races at the Kingston Regatta for the "Dublin Express" newspaper. One set of instruments was set up in a room at Kingstown, and another on board a steamer, the Flying Huntress. The aerial conductor on shore was a strip of wire netting attached to a mast 40 feet high. Several hundred messages were sent and correctly received during the progress of the races.
At this time King Edward VII, then Prince of Wales, had the misfortune to injure his knee and was confined on board the royal yacht Osborne in Cowes Bay.
Marconi fitted up his apparatus on board the royal yacht by request, and also at Osborne House, Isle of Wight, and kept up wireless communication for three weeks between these stations. The distances covered were small; but as the yacht moved about, on some occasions high hills were interposed, so that the aerial wires were overtopped by hundreds of feet, yet this was no obstacle to communication. These demonstrations led the Corporation of Trinity House to afford an opportunity for testing the system in practice between the South Foreland Lighthouse, near Dover, and the East Goodwin Lightship, on the Goodwin Sands. This installation was set in operation on December 24, 1898, and proved to be of value. It was shown that when once the apparatus was set up, it could be worked by ordinary seamen with very little training.
At the end of 1898 electric wave telegraphy established by Marconi had demonstrated its utility, especially for communication between ship and ship and ship and shore. The Haven Hotel station and Wireless Telegraph Mast was where much of Marconi's research work on wireless telegraphy was carried out after 1898. In 1899, W. H. Preece delivered a lecture on "Aetheric Telegraphy", stating that the experimental stage in wireless telegraphy had been passed in 1894 and inventors were then entering the commercial stage. Preece, continuing in the lecture, detailed the work of Marconi and other British inventors. The Marconi Company was renamed the Wireless Telegraph Trading Signal Company in 1900. In 1899 he transmitted messages across the English Channel. The British Navy experiments with Marconi's system in the Anglo-Boer War from 1899-1902 were the first use of operational wireless telegraphy in the field.
In 1901, Marconi claimed to have received daytime transatlantic radio frequency signals at a wavelength of 366 metres (820 kHz). Marconi established a wireless transmitting station at Marconi House, Rosslare Strand, Co. Wexford in 1901 to act as a link between Poldhu in Cornwall and Clifden in Co. Galway. His announcement on 12 December 1901 stated that signals transmitted by the company's new high-power station at Poldhu, Cornwall were received at Signal Hill in St John's, Newfoundland (now part of Canada), using a 152.4 m kite-supported antenna for reception. The message received was the Morse letter 'S' - three dots. This has recently been contested, however, based on theoretical work as well as a reenactment of the experiment; it is possible that Marconi heard only random atmospheric noise, which was mistaken for a signal, or that he heard a shortwave harmonic of the signal. The distance between the two points was about 3500 km.
Marconi transmitted from England to Canada and the United States. In 1902, a Marconi station was established in the village of Crookhaven, County Cork, Ireland to provide marine radio communications to ships arriving from the Americas. A ship's master could contact shipping line agents ashore to enquire which port was to receive their cargo without the need to come ashore at what was the first port of landfall. Ireland was also, due to its western location, to play a key role in early efforts to send trans-Atlantic messages. Marconi transmitted from his station in Glace Bay, Nova Scotia, Canada across the Atlantic, and on 18 January 1903 a Marconi station sent a message of greetings from Theodore Roosevelt, the President of the United States, to the King of the United Kingdom, marking the first transatlantic radio transmission originating in the United States.
Period after 1902.
In the early 20th century Jozef Murgas, the "Radio Priest", conducted a great deal of revolutionary work in wireless telegraphy. He established a laboratory in Wilkes-Barre, in which he primarily investigated radiotelegraphy. His article in the "Tovaryšstvo" magazine of 1900 shows that his radiotelegraphy studies had achieved a high level. In 1904, he received his first two US patents: the "Apparatus for wireless telegraphy" and "The way of transmitted messages by wireless telegraphy". Another 11 patents followed between 1907 and 1911. Based on the first two patents, he created the Universal Ether Telegraph Co., which organized a public test of Murgaš's transmitting and receiving facilities in September 1905. The test was successful, but a storm destroyed the antenna masts three months later, which led to the dissolution of the company.
In 1906, Lee De Forest brought out a vacuum tube device which he called the "audion". This was a very sensitive detector of electric oscillations. It consisted of three electrodes in a vacuum tube; one of the electrodes could be heated to incandescence with the result that it emitted electrons (the Edison effect).
American physicist Theodore Case. While studying at Yale University, Case became interested in using modulated light as a means to transmit and record speech. In 1914, he opened the Case Research Lab to experiment with the photo-electric properties of various materials, leading to the development of the Thallofide (short for thallium oxysulfide), a light-sensitive vacuum tube. The Thallofide tube was originally used by the United States Navy in a top secret ship-to-ship infrared signaling system developed at Case's lab with his assistant Earl Sponable. Case and Sponable's system was first tested off the shores of New Jersey in 1917, and attending the test was Thomas Edison, contracted by the Navy to evaluate new technologies. The test was a success, and the U.S. Navy used the system during and after World War I. This technology, in conjusnction with de Forest's Audion, was adapted after the war, as a means to record and play back optical sound in motion pictures. Another inventor, Charles A. Hoxie, invented a similar device, the Pallophotophone, that also became a speech recorder, used by General Electric to record President Calvin Coolidge in 1921 for radio broadcasts.
When the United States entered World War I, private radiotelegraphy stations were prohibited, which put an end to several pioneers' work in this field. By the 1920s, there was a worldwide network of commercial and government radiotelegraphic stations, plus extensive use of radiotelegraphy by ships for both commercial purposes and passenger messages. The ultimate implementation of wireless telegraphy was telex, using radio signals, which was developed in the 1930s and was for many years the only reliable form of communication between many distant countries. The most advanced standard, CCITT R.44, automated both routing and encoding of messages by short wave transmissions. (See telegraphy for more information).
Methods, apparatus, and operation.
In De Forest method, a battery connected between this electrode, as cathode, and another as anode resulted in a convection current of electrons from one to the other. Since negative electricity only was present, current could flow in but one direction. This is so far the action of the Fleming valve which also makes use of the Edison effect, but in the audion an epoch making advance was made in that the third electrode allows us to completely control the strength of the electron current without consuming appreciable energy at that electrode or in its circuit. In other words an inappreciable amount of power applied to the third electrode, or grid, will result in large changes in power in the anode circuit. Moreover, since the electrons have no appreciable inertia, the response in the anode circuit to stimuli in the grid circuit is practically instantaneous.
Further reading.
Listed by date ["latest to earliest"]
</dl>

</doc>
<doc id="33132" url="http://en.wikipedia.org/wiki?curid=33132" title="William Shockley">
William Shockley

William Bradford Shockley Jr. (February 13, 1910 – August 12, 1989) was an American physicist and inventor. Shockley was the manager of a research group that included John Bardeen and Walter Houser Brattain, the duo who invented the transistor. The three were jointly awarded the 1956 Nobel Prize in Physics.
Shockley's attempts to commercialize a new transistor design in the 1950s and 1960s led to California's "Silicon Valley" becoming a hotbed of electronics innovation. In his later life, Shockley was a professor at Stanford and became a proponent of eugenics.
Early life and education.
Shockley was born in London, England, to American parents, and raised in his family's hometown of Palo Alto, California, from age three. His father, William Hillman Shockley, was a mining engineer who speculated in mines for a living, and spoke eight languages. His mother, Mary (née Bradford), grew up in the American West, graduated from Stanford University, and became the first female US Deputy mining surveyor.
Shockley received his Bachelor of Science degree from Caltech in 1932. Shockley received his Ph.D. degree from MIT in 1936. The title of his doctoral thesis was "Electronic Bands in Sodium Chloride". His thesis topic was suggested by his thesis advisor, John C. Slater. After receiving his doctorate, Shockley joined a research group headed by Clinton Davisson at Bell Labs in New Jersey. The next few years were productive ones for Shockley. He published a number of fundamental papers on solid state physics in Physical Review. In 1938, he got his first patent, "Electron Discharge Device", on electron multipliers.
Career.
When World War II broke out, Shockley became involved in radar research at the Bell labs in Manhattan, New York. In May 1942, he took leave from Bell Labs to become a research director at Columbia University's Anti-Submarine Warfare Operations Group. This involved devising methods for countering the tactics of submarines with improved convoying techniques, optimizing depth charge patterns, and so on. This project required frequent trips to the Pentagon and Washington, where Shockley met many high-ranking officers and government officials. In 1944, he organized a training program for B-29 bomber pilots to use new radar bomb sights. In late 1944 he took a three-month tour to bases around the world to assess the results. For this project, Secretary of War Robert Patterson awarded Shockley the Medal for Merit on October 17, 1946.
In July 1945, the War Department asked Shockley to prepare a report on the question of probable casualties from an invasion of the Japanese mainland. Shockley concluded:
If the study shows that the behavior of nations in all historical cases comparable to Japan's has in fact been invariably consistent with the behavior of the troops in battle, then it means that the Japanese dead and ineffectives at the time of the defeat will exceed the corresponding number for the Germans. In other words, we shall probably have to kill at least 5 to 10 million Japanese. This might cost us between 1.7 and 4 million casualties including 400,000 to 800,000 killed.
This report influenced the decision for the atomic bombings of Hiroshima and Nagasaki to force Japan to surrender without an invasion.
Shockley was first to propose a lognormal distribution to model the creation process for scientific research papers. He was an atheist.
Development of transistor.
Shortly after the end of the war in 1945, Bell Labs formed a solid state physics group, led by Shockley and chemist Stanley Morgan, which included John Bardeen, Walter Brattain, physicist Gerald Pearson, chemist Robert Gibney, electronics expert Hilbert Moore, and several technicians. Their assignment was to seek a solid-state alternative to fragile glass vacuum tube amplifiers. Its first attempts were based on Shockley's ideas about using an external electrical field on a semiconductor to affect its conductivity. These experiments failed every time in all sorts of configurations and materials. The group was at a standstill until Bardeen suggested a theory that invoked surface states that prevented the field from penetrating the semiconductor. The group changed its focus to study these surface states and they met almost daily to discuss the work. The rapport of the group was excellent, and ideas were freely exchanged.
By the winter of 1946 they had enough results that Bardeen submitted a paper on the surface states to "Physical Review". Brattain started experiments to study the surface states through observations made while shining a bright light on the semiconductor's surface. This led to several more papers (one of them co-authored with Shockley), which estimated the density of the surface states to be more than enough to account for their failed experiments. The pace of the work picked up significantly when they started to surround point contacts between the semiconductor and the conducting wires with electrolytes. Moore built a circuit that allowed them to vary the frequency of the input signal easily. Finally they began to get some evidence of power amplification when Pearson, acting on a suggestion by Shockley, put a voltage on a droplet of glycol borate (a viscous chemical that did not evaporate, commonly used in electrolytic capacitors, and obtained by puncturing an example capacitor with a nail, using a hammer) placed across a P-N junction.
Bell Labs' attorneys soon discovered Shockley's field effect principle had been anticipated and devices based on it patented in 1930 by Julius Lilienfeld, who filed his MESFET-like patent in Canada on October 22, 1925. Although the patent appeared "breakable" (it could not work) the patent attorneys based one of its four patent applications only on the Bardeen-Brattain point contact design. Three others (submitted first) covered the electrolyte-based transistors with Bardeen, Gibney and Brattain as the inventors. Shockley's name was not on any of these patent applications. This angered Shockley, who thought his name should also be on the patents because the work was based on his field effect idea. He even made efforts to have the patent written only in his name, and told Bardeen and Brattain of his intentions.
Shockley, angered by not being included on the patent applications, secretly continued his own work to build a different sort of transistor based on junctions instead of point contacts; he expected this kind of design would be more likely to be commercially viable. The point contact transistor, he believed, would prove to be fragile and difficult to manufacture. Shockley was also dissatisfied with certain parts of the explanation for how the point contact transistor worked and conceived of the possibility of minority carrier injection. On February 13, 1948 another team member, John N. Shive, built a point contact transistor with bronze contacts on the front and back of thin wedge of germanium, proving that holes could diffuse through bulk germanium and not just along the surface as previously thought.:153:145 Shive's invention sparked Shockley's invention of the junction transistor.:143 A few months later he invented an entirely new, considerably more robust, type of transistor with a layer or 'sandwich' structure. This structure went on to be used for the vast majority of all transistors into the 1960s, and evolved into the bipolar junction transistor. Shockley later admitted that the workings of the team were "mixture of cooperation and competition." He also admitted that he kept some of his own work secret until his "hand was forced" by Shive's 1948 advance. Shockley worked out a rather complete description of what he called the "sandwich" transistor, and a first proof of principle was obtained on April 7, 1949.
Meanwhile, Shockley worked on his magnum opus, "Electrons and Holes in Semiconductors" which was published as a 558-page treatise in 1950. The tome included Shockley's critical ideas of drift and diffusion and the differential equations that govern the flow of electrons in solid state crystals. Shockley's diode equation is also described. This seminal work became the reference text for other scientists working to develop and improve new variants of the transistor and other devices based on semiconductors.
This resulted in his invention of the junction transistor, which was announced at a press conference on July 4, 1951.
In 1951, he was elected a member of the National Academy of Sciences (NAS). He was forty-one years old; this was rather young for such an election. Two years later, he was chosen as the recipient of the prestigious Comstock Prize for Physics by the NAS, and was the recipient of many other awards and honors.
The ensuing publicity generated by the "invention of the transistor" often thrust Shockley to the fore, much to the chagrin of Bardeen and Brattain. Bell Labs management, however, consistently presented all three inventors as a team. Though Shockley would correct the record where reporters gave him sole credit for the invention, he eventually infuriated and alienated Bardeen and Brattain, and he essentially blocked the two from working on the junction transistor. Bardeen began pursuing a theory for superconductivity and left Bell Labs in 1951. Brattain refused to work with Shockley further and was assigned to another group. Neither Bardeen nor Brattain had much to do with the development of the transistor beyond the first year after its invention.
Shockley Semiconductor.
In 1956 Shockley moved from New Jersey to Mountain View, California to start Shockley Semiconductor Laboratory to live closer to his ailing mother in Palo Alto, California. The company, a division of Beckman Instruments, Inc., was the first establishment working on silicon semiconductor devices in what came to be known as Silicon Valley.
"His way" could generally be summed up as domineering and increasingly paranoid. In one well-known incident, he claimed that a secretary's cut thumb was the result of a malicious act and he demanded lie detector tests to find the culprit. After receiving the Nobel Prize in 1956, his demeanor changed as evidenced in his increasingly autocratic, erratic and hard-to-please management style. In late 1957, eight of Shockley's researchers, who would come to be known as the "traitorous eight", resigned after Shockley decided not to continue research into silicon-based semiconductors. They went on to form Fairchild Semiconductor, a loss from which Shockley Semiconductor never recovered. Over the course of 20 years, these eight of Shockley's former employees started 65 new enterprises.
Personal life.
Marriage and children.
While still a student, Shockley married Iowan Jean Bailey in August 1933. In March 1934, the couple had a baby girl, Alison. He became an accomplished rock climber, going often to the Shawangunks in the Hudson River Valley, where he pioneered a route across an overhang, known to this day as "Shockley's Ceiling."
Shockley was popular as speaker, lecturer, and an amateur magician. He once 'magically' produced a bouquet of roses at the end of his address before the American Physical Society. He was also known in his early years for his elaborate practical jokes.
Political views.
Late in his life, Shockley became intensely interested in questions of race, human intelligence, and eugenics. He thought this work was important to the genetic future of the human species and came to describe it as the most important work of his career, even though expressing his views damaged his reputation. Shockley argued that a higher rate of reproduction among the less intelligent was having a dysgenic effect, and that a drop in average intelligence would ultimately lead to a decline in civilization. Shockley's published writings and lectures to scientific organizations on this topic were partly based on the writings of psychologist Cyril Burt and were funded by the Pioneer Fund. Shockley also proposed that individuals with IQs below 100 be paid to undergo voluntary sterilization.
Anthropologist Roger Pearson, whose writings are based on an evolutionary and racialist approach has defended Shockley in a self-published book co-authored with Shockley. University of Wisconsin–Milwaukee professor Edgar G. Epps argued that "William Shockley's position lends itself to racist interpretations".
Genetics.
He donated sperm to the Repository for Germinal Choice, a sperm bank founded by Robert Klark Graham in hopes of spreading humanity's best genes. The bank, called by the media the "Nobel Prize sperm bank," claimed to have three Nobel Prize-winning donors, though Shockley was the only one to publicly acknowledge his donation to the sperm bank. However, Shockley's controversial views brought the Repository for Germinal Choice a degree of notoriety and may have discouraged other Nobel Prize winners from donating sperm.
Relations with the media.
In 1981 he filed a libel suit against the "Atlanta Constitution" after a science writer, Roger Witherspoon, compared Shockley's advocacy of a voluntary sterilization program to Nazi experiments on Jews. The suit took three years to go to trial. Shockley won the suit but received only one dollar in actual damages and no punitive damages. Shockley's biographer Joel Shurkin, a science writer on the staff of Stanford University during those years, sums this up as saying that the statement was defamatory, but Shockley's reputation was not worth much by the time the trial reached a verdict.
Shockley taped his telephone conversations with reporters, and then sent the transcript to them by registered mail. At one point he toyed with the idea of making them take a simple quiz on his work before discussing the subject with them. His habit of saving all his papers, even laundry lists, provides abundant documentation for researchers on his life.
A group of about thirty colleagues, who have met on and off since 1956, met at Stanford in 2002 to reminisce about their time with Shockley and his central role in sparking the information technology revolution, its organizer saying "Shockley is the man who brought silicon to Silicon Valley."
Later years.
When Shockley was eased out of the directorship of Shockley Semiconductor, he joined Stanford University, where in 1963 he was appointed the Alexander M. Poniatoff Professor of Engineering and Applied Science, in which position he remained until his retirement as professor emeritus in 1975.
Death.
Shockley died in 1989 of prostate cancer. By the time of his death he was almost completely estranged from most of his friends and family, except his wife who died in 2007. His children are reported to have learned of his death only through the print media.
Patents.
Shockley was granted over ninety US patents. Some notable ones are:

</doc>
<doc id="33133" url="http://en.wikipedia.org/wiki?curid=33133" title="Walter Houser Brattain">
Walter Houser Brattain

Walter Houser Brattain (February 10, 1902 – October 13, 1987) was an American physicist at Bell Labs who, along with John Bardeen and William Shockley, invented the transistor. They shared the 1956 Nobel Prize in Physics for their invention. Brattain devoted much of his life to research on surface states.
Biography.
Walter Houser Brattain was born on 10 February 1902 in Xiamen, China, to American parents Ross R. Brattain and Ottilie Houser Brattain. Ross R. Brattain was a teacher at the Ting-Wen Institute,:11 a private school for Chinese boys. Both parents were graduates of Whitman College;:71 Ottilie Houser Brattain was a gifted mathematician. Ottilie and baby Walter returned to the United States in 1903, followed by Ross.:12 The family lived for several years in Spokane, Washington, then settled on a cattle ranch near Tonasket, Washington in 1911.:12:71
Brattain attended Whitman College in Walla Walla, Washington, where he studied with Benjamin H. Brown (physics) and Walter A. Bratton (mathematics). Brattain earned a bachelor's degree from Whitman College in 1924, with a double major in physics and mathematics. Brattain and his classmates Walker Bleakney, Vladimir Rojansky and E. John Workman were later known as "the four horsemen of physics" because all went on to distinguished careers.:71 Brattain's brother Robert, who followed him at Whitman College, also became a physicist.:71
Brattain earned a Master of Arts from the University of Oregon in Eugene in 1926, and a Ph.D. from the University of Minnesota in 1929. At Michigan, Brattain had the opportunity to study the new field of quantum mechanics under John Hasbrouck Van Vleck. His thesis, supervised by John T. Tate, was "Efficiency of Excitation by Electron Impact and Anomalous Scattering in Mercury Vapor.":72
Walter Brattain married twice. His first wife was chemist Keren Gilmore. They married in 1935 and had a son, William G. Brattain, in 1943. Keren Gilmore Brattain died April 10, 1957. Walter Brattain married Mrs. Emma Jane (Kirsch) Miller, who already had three children, in 1958.
He moved to Seattle, Washington, in the 1970s where he lived until his death. He died on October 13, 1987 in a nursing home in Seattle, Washington from Alzheimer's Disease. He is buried in Pomeroy City Cemetery, Garfield County, Washington, USA.
Scientific work.
From 1927 to 1928 Brattain worked for the National Bureau of Standards in Washington, D.C., where he helped to develop piezoelectric frequency standards. In August 1929 he joined Joseph A. Becker at Bell Telephone Laboratories as a research physicist. The two men worked on the heat-induced flow of charge carriers in copper oxide rectifiers.:72 Brattain was able to attend a lecture by Arnold Sommerfeld. Some of their subsequent experiments on thermionic emission provided experimental validation for the Sommerfeld theory. They also did work on the surface state and work function of tungsten and the adsorption of thorium atoms.:74 Through his studies of rectification and photo-effects on the semiconductor surfaces of cuprous oxide and silicon, Brattain discovered the photo-effect at the free surface of a semiconductor. This work was considered by the Nobel prize committee to be one of his chief contributions to solid state physics.
At the time, the telephone industry was heavily dependent on the use of vacuum tubes to control electron flow and amplify current. Vacuum tubes were neither reliable nor efficient, and Bell Laboratories wanted to develop an alternative technology. As early as the 1930s Brattain worked with William B. Shockley on the idea of a semiconductor amplifier that used copper oxide, an early and unsuccessful attempt at creating a field effect transistor. Other researchers at Bell and elsewhere were also experimenting with semiconductors, using materials such as germanium and silicon, but the pre-war research effort was somewhat haphazard and lacked strong theoretical grounding.
During World War II, both Brattain and Shockley were separately involved in research on magnetic detection of submarines with the National Defense Research Committee at Columbia University. Brattain's group developed magnetometers sensitive enough to detect anomalies in the earth's magnetic field caused by submarines.:104 As a result of this work, in 1944, Brattain patented a design for a magnetometer head.
In 1945, Bell Labs reorganized and created a group specifically to do fundamental research in solid state physics, relating to communications technologies. Creation of the sub-department was authorized by the vice-president for research, Mervin Kelly. An interdisciplinary group, it was co-led by Shockley and Stanley O. Morgan.:76 The new group was soon joined by John Bardeen. Bardeen was a close friend of Brattain's brother Robert, who had introduced John and Walter in the 1930s. They often played bridge and golf together.:77 Bardeen was a quantum physicist, Brattain a gifted experimenter in materials science, and Shockley, the leader of their team, was an expert in solid-state physics.
According to theories of the time, Shockley's field effect transistor, a cylinder coated thinly with silicon and mounted close to a metal plate, should have worked. He ordered Brattain and Bardeen to find out why it wouldn't. During November and December, the two men carried out a variety of experiments, attempting to determine why Shockley's device wouldn't amplify. Bardeen was a brilliant theorist; Brattain, equally importantly, "had an intuitive feel for what you could do in semiconductors".:40 Bardeen theorized that the failure to conduct might be the result of local variations in the surface state which trapped the charge carriers.:467–468 Brattain and Bardeen eventually managed to create a small level of amplification by pushing a gold metal point into the silicon, and surrounding it with distilled water. Replacing silicon with germanium enhanced the amplification, but only for low frequency currents.
On December 16, Brattain devised a method of placing two gold leaf contacts close together on a germanium surface. Brattain reported: "Using this double point contact, contact was made to a germanium surface that had been anodized to 90 volts, electrolyte washed off in H2O and then had some gold spots evaporated on it. The gold contacts were pressed down on the bare surface. Both gold contacts to the surface rectified nicely... One point was used as a grid and the other point as a plate. The bias (D.C.) on the grid had to be positive to get amplification"
As described by Bardeen, "The initial experiments with the gold spot suggested immediately that holes were being introduced into the germanium block, increasing the concentration of holes near the surface. The names emitter and collector were chosen to describe this phenomenon. The only question was how the charge of the added holes was compensated. Our first thought was that the charge was compensated by surface states. Shockley later suggested that the charge was compensated by electrons in the bulk and suggested the junction transistor geometry... Later experiments carried out by Brattain and me showed that very likely both occur in the point-contact transistor.":470
On December 23, 1947, Walter Brattain, John Bardeen, and William B. Shockley demonstrated the first working transistor to their colleagues at Bell Laboratories. Amplifying small electrical signals and supporting the processing of digital information, the transistor is "the key enabler of modern electronics". The three men received the Nobel Prize in Physics in 1956 "for research on semiconductors and the discovery of the transistor effect."
Convinced by the 1947 demonstration that a major breakthrough was being made, Bell Laboratories focused intensively on what it now called the "Surface States Project". Initially, strict secrecy was observed. Carefully restricted internal conferences within Bell Labs shared information about the work of Brattain, Bardeen, Shockley and others who were engaged in related research.:471 Patents were registered, recording the invention of the point-contact transistor by Bardeen and Brattain. There was considerable anxiety over whether Ralph Bray and Seymour Benzer, studying resistance in germanium at Purdue University, might make a similar discovery and publish before Bell Laboratories.:38–39
On June 30, 1948, Bell Laboratories held a press conference to publicly announce their discovery. They also adopted an open policy in which new knowledge was freely shared with other institutions. By doing so, they avoided classification of the work as a military secret, and made possible widespread research and development of transistor technology. Bell Laboratories organized several symposia, open to university, industry and military participants, which were attended by hundreds of scientists in September 1951, April 1952, and 1956. Representatives from international as well as domestic companies attended.:471–472, 475–476
Shockley believed (and stated) that he should have received all the credit for the discovery of the transistor. He actively excluded Bardeen and Brattain from new areas of research, in particular the junction transistor, which Shockley patented. Shockley's theory of the junction transistor was an "impressive achievement", pointing the way to future solid-state electronics, but it would be several years before its construction would become practically possible.:43–44
Brattain transferred to another research group within Bell Laboratories, working with C. G. B. Garrett, and P. J. Boddy. He continued to study the surface properties of solids and the "transistor effect", so as to better understand the various factors underlying semiconductor behavior.:79–81 Describing it as "an intolerable situation", Bardeen left Bell Laboratories in 1951 to go to the University of Illinois, where he eventually won a second Nobel Prize for his theory of superconductivity. Shockley left Bell Laboratories in 1953 and went on to form the Shockley Semiconductor Laboratory at Beckman Instruments.
In 1956, the three men were jointly awarded the Nobel Prize in Physics by King Gustaf VI Adolf of Sweden "for research on semiconductors and the discovery of the transistor effect." Bardeen and Brattain were included for the discovery of the point-contact transistor; Shockley for the development of the junction transistor. Walter Brattain is credited as having said, when told of the award, "I certainly appreciate the honor. It is a great satisfaction to have done something in life and to have been recognized for it in this way. However, much of my good fortune comes from being in the right place, at the right time, and having the right sort of people to work with." Each of the three gave a lecture. Brattain spoke on "Surface Properties of Semiconductors", Bardeen on "Semiconductor Research Leading to the Point Contact Transistor", and Shockley on "Transistor Technology Evokes New Physics".
Brattain later collaborated with P. J. Boddy and P. N. Sawyer on several papers on electrochemical processes in living matter.:80 He became interested in blood clotting after his son required heart surgery. He also collaborated with Whitman chemistry professor David Frasco, using phospholipid bilayers as a model to study the surface of living cells and their absorption processes.
Teaching.
Brattain taught at Harvard University as a visiting lecturer in 1952 and at Whitman College as a visiting lecturer in 1962 and 1963, and a visiting professor beginning in 1963. Upon formally retiring from Bell Laboratories in 1967, he continued to teach at Whitman, becoming an adjunct professor in 1972. He retired from teaching in 1976 but continued to be a consultant at Whitman.
At Whitman, the Walter Brattain Scholarships are awarded on a merit basis to "entering students who have achieved high academic excellence in their college preparatory work." All applicants for admission are considered for the scholarship, which is potentially renewable for four years.
Awards and honors.
Walter Houser Brattain has been widely recognized for his contributions.

</doc>
