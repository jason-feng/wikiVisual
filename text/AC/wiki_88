<doc id="40142" url="http://en.wikipedia.org/wiki?curid=40142" title="Botulism">
Botulism

Botulism (Latin, "botulus", a sausage) is a rare and potentially fatal illness caused by a toxin produced by the bacteria "Clostridium botulinum". The disease begins with weakness, trouble seeing, feeling tired, and trouble speaking. This may then be followed by weakness of the arms, chest muscles, and legs. The disease does not usually affect consciousness or cause a fever.
Botulism can occur in a few different ways. The bacterial spores that cause it are common in both soil and water. They produce botulinum toxin when exposed to low oxygen levels and certain temperatures. Foodborne botulism happens when food containing the toxin is eaten. Infant botulism happens when the bacteria develops in the intestines and releases toxin. Typically this only happens in children less than six months of age as after that protective mechanisms develop. Wound botulism is found most often among those who inject street drugs. In this situation spores enter a wound and, in the absence of oxygen, release toxin. It is not passed directly between people. The diagnosis is confirmed by finding the toxin or bacteria in the person in question.
Prevention is primarily by proper food preparation. The toxin is destroyed by heating to more than 85 °C for longer than 5 minutes. It is not recommended to give honey to children who are less than one year of age due to the risk with this food. Treatment is with an antitoxin. In those who lose their ability to breathe on their own, mechanical ventilation, potentially for months may be required. Antibiotics may be used for wound botulism. Death occurs in 5 to 10% of people. Botulism can affect many other animals.
Signs and symptoms.
The muscle weakness of botulism characteristically starts in the muscles supplied by the cranial nerves. A group of twelve nerves controls eye movements, the facial muscles and the muscles controlling chewing and swallowing. Double vision, drooping of both eyelids, loss of facial expression and swallowing problems may therefore occur, as well as In addition to affecting the voluntary muscles, it can also cause disruptions in the autonomic nervous system. This is experienced as a dry mouth and throat (due to decreased production of saliva), postural hypotension (decreased blood pressure on standing, with resultant lightheadedness and risk of blackouts), and eventually constipation (due to decreased peristalsis). Some of the toxins (B and E) also precipitate nausea and vomiting.
difficulty with talking. The weakness then spreads to the arms (starting in the shoulders and proceeding to the forearms) and legs (again from the thighs down to the feet).
Severe botulism leads to reduced movement of the muscles of respiration, and hence problems with gas exchange. This may be experienced as dyspnea (difficulty breathing), but when severe can lead to respiratory failure, due to the buildup of unexhaled carbon dioxide and its resultant depressant effect on the brain. This may lead to coma and eventually death if untreated.
Clinicians frequently think of the symptoms of botulism in terms of a classic triad: bulbar palsy and descending paralysis, lack of fever, and clear senses and mental status ("clear sensorium").
Infant botulism.
Infant botulism (also referred to as floppy baby syndrome) was first recognized in 1976, and is the most common form of botulism in the United States. There were 17 diagnosed cases of infant botulism in the United States in 2013. Infants are susceptible to infant botulism in the first year of life, with more than 90% of cases occurring in infants younger than six months. Infant botulism results from the ingestion of the "C. botulinum" spores, and subsequent colonization of the small intestine. The infant gut may be colonized when the composition of the intestinal microflora (normal flora) is insufficient to competitively inhibit the growth of "C. botulinum" and levels of bile acids (which normally inhibit clostridial growth) are lower than later in life.
The growth of the spores releases botulinum toxin, which is then absorbed into the bloodstream and taken throughout the body, causing paralysis by blocking the release of acetylcholine at the neuromuscular junction. Typical symptoms of infant botulism include constipation, lethargy, weakness, difficulty feeding and an altered cry, often progressing to a complete descending flaccid paralysis. Although constipation is usually the first symptom of infant botulism, it is commonly overlooked.
Honey is the only known dietary reservoir of "C. botulinum" spores linked to infant botulism. For this reason honey should "not" be fed to infants less than one year of age. Other cases of infant botulism are thought to be caused by acquiring the spores from the natural environment. "Clostridium botulinum" is a ubiquitous soil-dwelling bacterium. Many infant botulism patients have been demonstrated to live near a construction site or an area of soil disturbance.
Infant botulism has been reported in 49 of 50 US states, and cases have been recognized in 26 countries on five continents.
Complications.
Infant botulism has no long-term side effects, but can be complicated by nosocomial adverse events. The case fatality rate is less than 1% for hospitalized infants with botulism.
Botulism can result in death due to respiratory failure. However, in the past 50 years, the proportion of patients with botulism who die has fallen from about 50% to 7% due to improved supportive care. A patient with severe botulism may require mechanical ventilation (breathing support through a ventilator) as well as intensive medical and nursing care, sometimes for several months. Patients who survive an episode of botulism poisoning may have fatigue and shortness of breath for years and long-term therapy may be needed to aid their recovery.
Cause.
"C. botulinum" is an anaerobic, Gram positive, spore-forming rod. Botulinum toxin is one of the most powerful known toxins: about one microgram is lethal to humans. It acts by blocking nerve function (neuromuscular blockade) through inhibition of the excitatory neurotransmitter acetylcholine's release from the presynaptic membrane of neuromuscular junctions in the somatic nervous system. This causes paralysis. Advanced botulism can cause respiratory failure by paralysing the muscles of the chest; this can progress to respiratory arrest.
In all cases, illness is caused by the botulinum toxin produced by the bacterium "C. botulinum" in anaerobic conditions, and not by the bacterium itself. The pattern of damage occurs because the toxin affects nerves that fire (depolarise) at a higher frequency first.
Four main modes of entry for the toxin are known.
Infants.
The most common form in Western countries is infant botulism. This occurs in small children who are colonized with the bacterium during the early stages of their lives. The bacterium then releases the toxin into the intestine, which is absorbed into the bloodstream. The consumption of honey during the first year of life has been identified as a risk factor for infant botulism; it is a factor in a fifth of all cases. The adult form of infant botulism is termed "adult intestinal toxemia", and is exceedingly rare.
Food.
Improperly preserved food is the most common cause of food-borne botulism. Fish that has been pickled without the salinity or acidity of brine that contains acetic acid and high sodium levels, as well as smoked fish stored at too high a temperature, presents a risk, as does improperly canned food. Infants under one year should not be fed honey, a natural source of botulinum bacteria, as bacteria in the gut are not sufficiently developed.
Foodborne botulism results from contaminated food in which "C. botulinum" spores have been allowed to germinate in low-oxygen conditions. This typically occurs in home-canned food substances and fermented uncooked dishes. Given that multiple people often consume food from the same source, it is common for more than a single person to be affected simultaneously. Symptoms usually appear 12–36 hours after eating, but can also appear within 2 hours to 10 days.
Wound.
Wound botulism results from the contamination of a wound with the bacteria, which then secrete the toxin into the bloodstream. This has become more common in intravenous drug users since the 1990s, especially people using black tar heroin and those injecting heroin into the skin rather than the veins.
Inhalation.
Isolated cases of botulism have been described after inhalation by laboratory workers and after cosmetic use of inappropriate strengths of Botox.
Mechanism.
The toxin is the protein botulinum toxin produced under anaerobic conditions (where there is no oxygen) by the bacterium "Clostridium botulinum".
"Clostridium botulinum" is a large anaerobic Gram-positive bacillus that forms subterminal endospores.
There are eight serological varieties of the bacterium denoted by the letters A to H. The toxin from all of these acts in the same way and produces similar symptoms: the motor nerve endings are prevented from releasing acetylcholine, causing flaccid paralysis and symptoms of blurred vision, ptosis, nausea, vomiting, diarrhea and/or constipation, cramps, and respiratory difficulty.
Botulinum toxin is broken into 8 neurotoxins (labeled as types A, B, C [C1, C2], D, E, F & G), which are antigenically and serologically distinct but structurally similar. Human botulism is caused mainly by types A, B, E, and (rarely) F. Types C and D cause toxicity only in other animals.
In October 2013, scientists released news of the discovery of type H, the first new botulism neurotoxin found in forty years. However, further information about type H has not been disclosed because of its potential for abuse as a lethal bioweapon and lack of a known antitoxin.
Some types produce a characteristic putrefactive smell and digest meat (types A and some of B and F); these are said to be proteolytic; type E and some types of B, C, D and F are nonproteolytic and can go undetected because there is no strong odor associated with them.
When the bacteria are under stress, they develop spores, which are inert. Their natural habitats are in the soil, in the silt that comprises the bottom sediment of streams, lakes and coastal waters and ocean, while some types are natural inhabitants of the intestinal tracts of mammals (e.g., horses, cattle, humans), and are present in their excreta. The spores can survive in their inert form for many years.
Toxin is produced by the bacteria when environmental conditions are favourable for the spores to replicate and grow, but the gene that encodes for the toxin protein is actually carried by a virus or phage that infects the bacteria. Unfortunately, little is known about the natural factors that control phage infection and replication within the bacteria.
The spores require warm temperatures, a protein source, an anaerobic environment, and moisture in order to become active and produce toxin. In the wild, decomposing vegetation and invertebrates combined with warm temperatures can provide ideal conditions for the botulism bacteria to activate and produce toxin that may affect feeding birds and other animals. Spores are not killed by boiling, but botulism is uncommon because special, rarely obtained conditions are necessary for botulinum toxin production from C. botulinum spores, including an anaerobic, low-salt, low-acid, low-sugar environment at ambient temperatures.
Botulinum inhibits the release within the nervous system of acetylcholine, the chemical that produces a bridge across synapses, where nerve cell axons and dendrites connect with each other. All forms of botulism lead to paralysis that typically starts with the muscles of the face and then spreads towards the limbs. In severe forms, botulism leads to paralysis of the breathing muscles and causes respiratory failure. In light of this life-threatening complication, all suspected cases of botulism are treated as medical emergencies, and public health officials are usually involved to identify the source and take steps to prevent further cases from occurring.
Diagnosis.
For infant botulism, diagnosis should be made on clinical grounds. Confirmation of the diagnosis is made by testing of a stool or enema specimen with the mouse bioassay.
Physicians may consider diagnosing botulism if the patient's history and physical examination suggest botulism. However, these clues are often not enough to allow a diagnosis. Other diseases such as Guillain-Barré syndrome, stroke, and myasthenia gravis can appear similar to botulism, and special tests may be needed to exclude these other conditions. These tests may include a brain scan, cerebrospinal fluid examination, nerve conduction test (electromyography, or EMG), and an edrophonium chloride (Tensilon) test for myasthenia gravis. A definite diagnosis can be made if botulinum toxin is identified in the food, stomach or intestinal contents, vomit or feces. The toxin is occasionally found in the blood in peracute cases. Botulinum toxin can be detected by a variety of techniques, including enzyme-linked immunosorbent assays (ELISAs), electrochemiluminescent (ECL) tests and mouse inoculation or feeding trials. The toxins can be typed with neutralization tests in mice. In toxicoinfectious botulism, the organism can be cultured from tissues. On egg yolk medium, toxin-producing colonies usually display surface iridescence that extends beyond the colony.
Prevention.
Although the botulinum toxin is destroyed by thorough cooking over the course of a few minutes, the spore itself is not killed by the temperatures reached with normal sea-level-pressure boiling, leaving it free to grow and again produce the toxin when conditions are right.
A recommended prevention measure for infant botulism is to avoid giving honey to infants less than 12 months of age, as botulinum spores are often present. In older children and adults the normal intestinal bacteria suppress development of "C. botulinum".
While commercially canned goods are required to undergo a "botulinum cook" in a pressure cooker at 121 °C for 3 minutes, and so rarely cause botulism, there have been notable exceptions such as the 1978 Alaskan salmon outbreak and the 2007 Castleberry's Food Company outbreak. Foodborne botulism is the rarest form though, accounting for only around 15% of cases (US) and has more frequently been from home-canned foods with low acid content, such as carrot juice, asparagus, green beans, beets, and corn. However, outbreaks of botulism have resulted from more unusual sources. In July 2002, fourteen Alaskans ate "muktuk" (whale meat) from a beached whale, and eight of them developed symptoms of botulism, two of them requiring mechanical ventilation.
Other, but much rarer sources of infection (about every decade in the US) include garlic or herbs stored covered in oil without acidification, chili peppers, improperly handled baked potatoes wrapped in aluminum foil, tomatoes, and home-canned or fermented fish.
When canning or preserving food at home, attention should be paid to hygiene, pressure, temperature, refrigeration and storage. When making home preserves, only acidic fruit such as apples, pears, stone fruits and berries should be bottled. Tropical fruit and tomatoes are low in acidity and must have some acidity added before they are bottled.
Oils infused with fresh garlic or herbs should be acidified and refrigerated. Potatoes which have been baked while wrapped in aluminum foil should be kept hot until served or refrigerated. Because the botulism toxin is destroyed by high temperatures, home-canned foods are best boiled for 10 minutes before eating. Metal cans containing food in which bacteria, possibly botulinum, are growing may bulge outwards due to gas production from bacterial growth; such cans should be discarded.
Any container of food which has been heat-treated and then assumed to be airtight which shows signs of not being so, e.g., metal cans with pinprick holes from rust or mechanical damage, should also be discarded. Contamination of a canned food solely with "C. botulinum" may not cause any visual defects (e.g. bulging). Only sufficient thermal processing during production should be used as a food safety control.
Vaccine.
There is a vaccine but its usefulness is unclear as it is associated with significant adverse effects. As of 2013 there are efforts ongoing to develop a better vaccine.
Treatment.
The primary treatment of botulism is with an antitoxin (human botulinum immunoglobulin) and supportive care.
The respiratory failure due to paralysis may require a person to be on a ventilator for weeks, plus intensive medical and nursing care. After several weeks, the paralysis slowly improves. If diagnosed early, foodborne and wound botulism can be treated by inducing passive immunity with a horse-derived antitoxin, which blocks the action of the toxin circulating in the blood.
This can prevent people from worsening, but recovery still takes many weeks. Physicians may try to remove contaminated food still in the digestive tract by inducing vomiting and/or by using enemas. Wounds should be treated, usually surgically, to remove the source of the toxin-producing bacteria. Good supportive care in a hospital is the mainstay of therapy for all forms of botulism.
Each case of food-borne botulism is a potential public health emergency in that it is necessary to identify the source of the outbreak, and to ensure that all persons exposed to the toxin have been identified and that no contaminated food remains.
Antitoxin.
A number of botulinum antitoxins are available for treatment of wound and foodborne botulism. Human derived botulinum immune globulin is effective in infant botulism. Other antitoxins are less well supported by evidence.
Trivalent (A,B,E) botulinum antitoxin is derived from equine sources utilizing whole antibodies (Fab & Fc portions). In the United States, this antitoxin is available from the local health department via the CDC. The second antitoxin, heptavalent (A,B,C,D,E,F,G) botulinum antitoxin, is derived from "despeciated" equine IgG antibodies which have had the Fc portion cleaved off leaving the F(ab')2 portions. This less immunogenic antitoxin is effective against all known strains of botulism where not contraindicated.
Prognosis.
Death occurs in 5 to 10% of people who are affected.
Infant botulism has no long-term side effects, but can be complicated by nosocomial adverse events. The case fatality rate is less than 1% for hospitalized infants with botulism.
Between 1910 and 1919 the death rate from botulism was 70% in the United States, dropping to 9% in the 1980s and 2% in the early 1990s, mainly because of the development of artificial respirators. Up to 60% of botulism cases are fatal if left untreated. Other sources report that, in the U.S., the overall mortality rate is about 7.5%, but the mortality rate among adults over 60 is 30%. The mortality rate for wound botulism is about 10%. The infant botulism mortality rate is about 1.3%.
Epidemiology.
Globally, botulism is fairly rare. Between 1990 and 2000, the Centers for Disease Control reported 263 individual cases from 160 foodborne botulism events in the United States with a case-fatality rate of 4%. Thirty-nine percent (103 cases and 58 events) occurred in Alaska, all of which were attributable to traditional Alaska aboriginal foods. In the lower 49 states, home-canned food was implicated in 70 (91%) events with canned asparagus being the most numerous cause. Two restaurant-associated outbreaks affected 25 persons. The median number of cases per year was 23 (range 17–43), the median number of events per year was 14 (range 9–24). The highest incidence rates occurred in Alaska, Idaho, Washington, and Oregon. All other states had an incidence rate of 1 case per ten million people or less.
The number of cases of food borne and infant botulism has changed little in recent years, but wound botulism has increased because of the use of black tar heroin, especially in California.
Clostridium botulinum has been associated with one outbreak linked to venison jerky. The investigation done of this outbreak showed that toxin could be repeatedly demonstrated in the jerky, but the organism was only isolated once. It was never isolated from any of the raw materials used to make the jerky and no conclusions were drawn as to how the organism came to produce toxin within the product.
Outbreak in the US.
All data regarding botulism antitoxin releases and laboratory confirmation of cases in the US are recorded annually by the Centers for Disease Control and Prevention and published on their website.
Between March 31 and April 6, 1977, 59 individuals developed type B botulism. All ill persons had eaten at the same Mexican restaurant and all had consumed a hot sauce made with improperly home-canned jalapeño peppers, either by adding it to their food, or by eating a nacho that had had hot sauce used in its preparation. 
The full clinical spectrum (mild symptomatology with neurologic findings through life-threatening ventilatory paralysis) of type B botulism was documented.
In April 1994, the largest outbreak of botulism in the United States since 1978 occurred in El Paso, Texas. Thirty persons were affected; 4 required mechanical ventilation. All ate food from a Greek restaurant. The attack rate among persons who ate a potato-based dip was 86% (19/22) compared with 6% (11/176) among persons who did not eat the dip (relative risk [RR] Å 13.8; 95% confidence interval [CI], 7.6–25.1). The attack rate among persons who ate an eggplant-based dip was 67% (6/9) compared with 13% (24/189) among persons who did not (RR Å 5.2; 95% CI, 2.9–9.5). Botulism toxin type A was detected from patients and in both dips. Toxin formation resulted from holding aluminum foil-wrapped baked potatoes at room temperature, apparently for several days, before they were used in the dips. Food handlers should be informed of the potential hazards caused by holding foil-wrapped potatoes at ambient temperatures after cooking.
One person died and at least 23 more were hospitalized in Ohio after a botulism outbreak linked to a church potluck in April 2015.
On July 2, 1971, the U.S. Food and Drug Administration (FDA) released a public warning after learning that a New York man had died and his wife had become seriously ill due to botulism after eating a can of Bon Vivant vichyssoise soup.
Outbreak in the UK.
The largest recorded outbreak of foodborne botulism in the United Kingdom occurred in June 1989. A total of 27 patients were affected; one patient died. Twenty-five of the patients had eaten one brand of hazelnut yogurt in the week before the onset of symptoms. This yogurt contained hazelnut conserve sweetened with aspartame rather than sugar. Control measures included the cessation of all yogurt production by the implicated producer, the withdrawal of the firm's yogurts from sale, the recall of cans of the hazelnut conserve, and advice to the general public to avoid the consumption of all hazelnut yogurts.
Castleberry's Food Company outbreak.
Beginning in late June 2007, 8 people contracted botulism poisoning by eating canned food products produced by Castleberry's Food Company in its Augusta, Georgia plant. It was later identified that the Castleberry's plant had serious production problems on a specific line of retorts that had under-processed the cans of food. These issues included broken cooking alarms, leaking water valves and inaccurate temperature devices, all the result of poor management of the company.
All of the victims were hospitalized and placed on mechanical ventilation. The Castleberry's Food Company outbreak was the first instance of botulism in commercial canned foods in the United States in over 30 years.
Other species.
Botulism can occur in many vertebrates and invertebrates. Botulism has been reported in rats, mice, chicken, frogs, toads, goldfish, aplysia, squid, crayfish, drosophila, leeches, etc.
Death from botulism is common in waterfowl; an estimated 10,000 to 100,000 birds die of botulism annually. In some large outbreaks, a million or more birds may die. Ducks appear to be affected most often. Botulism also affects commercially raised poultry. In chickens, the mortality rate varies from a few birds to 40% of the flock.
Botulism seems to be relatively uncommon in domestic mammals; however, in some parts of the world, epidemics with up to 65% mortality are seen in cattle. The prognosis is poor in large animals that are recumbent. 
In cattle, the symptoms may include drooling, restlessness, uncoordination, urine retention, dysphagia, and sternal recumbency. Laterally recumbent animals are usually very close to death. In sheep, the symptoms may include drooling, a serous nasal discharge, stiffness, and incoordination. Abdominal respiration may be observed and the tail may switch on the side. As the disease progresses, the limbs may become paralyzed and death may occur.
Phosphorus-deficient cattle, especially in southern Africa, are inclined to ingest bones and carrion containing clostridial toxins and consequently suffer "lame sickness" or "lamsiekte".
A recent study has demonstrated an effective vaccine against cattle botulism associated with Clostridium botulinum serotypes C and D.
The clinical signs in horses are similar to cattle. The muscle paralysis is progressive; it usually begins at the hindquarters and gradually moves to the front limbs, neck, and head. Death generally occurs 24 to 72 hours after initial symptoms and results from respiratory paralysis. Some foals are found dead without other clinical signs.
Domestic dogs may develop systemic toxemia after consuming C. botulinum type C exotoxin or spores within bird carcasses or other infected meat but are generally resistant to the more severe effects of Clostridium botulinum type C.
Symptoms include flaccid muscle paralysis; dogs with breathing difficulties will require more intensive care monitoring. Muscle paralysis can lead to death due to cardiac and respiratory arrest.
Pigs are relatively resistant to botulism. Reported symptoms include anorexia, refusal to drink, vomiting, pupillary dilation, and muscle paralysis.
In poultry and wild birds, flaccid paralysis is usually seen in the legs, wings, neck and eyelids. Broiler chickens with the toxicoinfectious form may also have diarrhea with excess urates.

</doc>
<doc id="40145" url="http://en.wikipedia.org/wiki?curid=40145" title="Witenagemot">
Witenagemot

The Witenagemot (Old English witena gemōt ] modern English "meeting of wise men"), also known as the Witan (more properly the title of its members) was a political institution in Anglo-Saxon England which operated from before the 7th century until the 11th century. The witenagemots did not represent the political will of all England: before the unification of England in the 10th century, separate witenagemots were convened by the Kings of Essex, Kent, Mercia, Northumbria, Sussex and Wessex. The Witenagemot was an assembly of the ruling class whose primary function was to advise the king and whose membership was composed of the most important noblemen in England, both ecclesiastic and secular. The institution is thought to represent an aristocratic development of the ancient Germanic general assemblies, or folkmoots. In England, by the 7th century, these ancient folkmoots had developed into convocations of the land's most powerful and important people, including ealdormen, thegns, and senior clergy, to discuss matters of both national and local importance.
Terminology.
The terms 'Witan' and 'Witenagemot' are increasingly avoided by modern historians, although few would go as far as Geoffrey Hindley, who described 'witenagemot' as an "essentially Victorian" coinage. "The Blackwell Encyclopaedia of Anglo-Saxon England" prefers 'King's Council', but adds that it was known in Old English as the 'witan'. John Maddicott regarded the word witan with suspicion, even though it is used in sources such as the "Anglo-Saxon Chronicle":
For these reasons, in his study of the origins of the English parliament, he generally preferred the more neutral word 'assembly'. He described 'witena gemot' as a rare eleventh century usage, with only nine pre-Conquest examples, mainly in the crisis of 1051-52. Patrick Wormald was also sceptical, describing 'witena-gemot' as "a word always rare and unattested before 1035".
Constitution and limitations.
Despite historians' best efforts to find in it some permanence of character, the exact nature of the witenagemot remains "essentially vague, fluctuating, and incoherent." Nevertheless, there is much direct evidence of the witan's various activities. Knowledge about who made up the witan and who was present at their meetings is provided mainly by lists of witnesses to charters, or grants of land, which were concocted at the witenagemots. Reference to the witan's "acta" or official decisions are also preserved in law codes.
The first recorded act of a witenagemot was the law code issued by King Æthelberht of Kent ca. 600, the earliest document which survives in sustained Old English prose; however, the witan was certainly in existence long before this time. Altogether, about 2000 charters and 40 law codes survive which attest to the workings of the various meetings of the witan, of which there are around 300 recorded.
These documents clearly indicate that the witan was composed of the nation's highest echelon of both ecclesiastical and secular officers. Present on the ecclesiastical side were archbishops, bishops, and abbots, and occasionally also abbesses and priests; on the secular side ealdormen (or "eorls" in the latter centuries) and thegns. Members of the royal family were also present, and the king presided over the entire body.
In his investigation into Anglo-Saxon institutions, H. M. Chadwick wrote: I have not thought it necessary to discuss at length the nature of the powers possessed by the council [i.e. the witenagemot], for .. there can be little hope of arriving at any definite conclusions on this subject. Indeed it seems at least doubtful whether the functions of the council were ever properly defined.
Similarly, in his study of the witenagemots, Felix Liebermann stated that "its functions and power differ .. considerably at various times." Still, he was able to give a relatively detailed description of its constitution:From the time of Ine the Witan was composed of the aristocratic "élite" created by monarchy. The king, generally indeed advised by the existing nobility, conferred prelatures and ealdormanries, with both of which a seat in the national assembly [i.e. the witenagemot] was legally or practically connected. Members of the royal family, ladies not excepted, were present at many gemots. The king alone raised a man to the position of a gesith, a thane, a provincial or local reeve, a court officer or a royal chaplain, one of which titles seems to have been the indispensable qualification for a vote. .. as no periodicity of the assembly was fixed, the king determined when and where it was to meet, for the most part choosing places under his immediate control; he presided, spoke first, put his questions, proposed his bills, and finally dismissed the witan.
The witan was noted by contemporary sources as having the singular power to "ceosan to cyninge", 'to choose the king' from amongst the (extended) royal family. Nevertheless, at least until the 11th century, royal succession generally followed the "ordinary system of primogeniture." Chadwick interpreted these facts as proof that the so-called election of the king by the witan merely amounted to formal recognition of the deceased king's natural successor. But Liebermann was generally less willing than Chadwick to see the witan's significance as buried under the weight of the royal prerogative:The influence of the king, or at least of kingship, on the constitution of the assembly seems, therefore, to have been immense. But on the other hand he (the king) was elected by the witan .. He could not depose the prelates or ealdormen, who held their office for life, nor indeed the hereditary thanes. .. At any rate, the king had to get on with the highest statesmen appointed by his predecessor, though possibly disliked by him, until death made a post vacant that he could fill with a relation or a favourite, not, however, without having a certain regard to the wishes of the aristocracy.
Liebermann's more subtle position seems to be vindicated by testimony from abbot Ælfric of Eynsham, the leading homilist of the late 10th century, who wrote:No man can make himself king, but the people has the choice to choose as king whom they please; but after he is consecrated as king, he then has dominion over the people, and they cannot shake his yoke off their necks.
In addition to having a role in the 'election' of English Kings, it is often held that the witenagemots had the power to depose an unpopular king. However, there are only two occasions when this probably happened, in 757 and 774 with the depositions of kings Sigeberht of Wessex and Alhred of Northumbria respectively.
The witan's powers are illustrated by the following event. In the year 1013 King Æthelred II fled the country from Sweyn Forkbeard, who then had the witan proclaim him king. Within a few weeks, however, Sweyn died and Æthelred was called back to England by the witan. According to the "Anglo-Saxon Chronicle", the witan would only receive him back under the condition that he promise to rule better than he had. Æthelred did so, and was reinstated as King of England. His nickname of the 'Unræd' or 'Unready' means ill-advised, indicating that contemporaries regarded those who sat in the witan as in part responsible for the failure of his reign.
Though in general the witan were recognized as the king's closest advisors and policy-makers, various witan also operated in other capacities; there are mentions of "þeodwitan", 'people's witan', "Angolcynnes witan", 'England's witan', and an Anglo-Saxon Archbishop of York, Wulfstan II, wrote that "it is incumbent on bishops, that venerable witan always travel with them, and dwell with them, at least of the priesthood; and that they may consult with them .. and who may be their counsellors at every time." 
Even when summoned explicitly by kings, the witenagemots did not represent the political will of all England: before the unification of England in the 10th century, separate witenagemots were convened by the Kings of Essex, Kent, Mercia, Northumbria, Sussex and Wessex. Indeed, even after Wessex became the dominant power in England, supplanting the other kingdoms, local witans continued to meet until as late as 1067. In his work on Alfred the Great, historian David Sturdy argues that the witan did not embody modern notions of a 'national institution' or a 'democratic' body:Victorian notions of a national 'witan' are crazy dreams without foundation, myths of a 'democratic parliament' that never was.
Function and legacy.
Witans would advise on the administration and organization of the kingdom, dealing with issues such as taxation, jurisprudence and both internal and external security. The witenagemot was in many ways different from the future Parliament, it had substantially different powers and some major limitations, such as a lack of a fixed procedure, schedule, or meeting place. The witan could seek to prevent autocracy and carry on government during interregnums, but ultimately the witenagemot answered to the king. It only assembled when he summoned it, and its assembling without his approval could be considered treason. The witenagemot was more an advisory council. In some cases, weak kings (such as Ethelred the Unready) were dependent on the witenagemot, while others used it as simply a group of advisers.
Though no set date was ever in use, witenagemots met at least once a year, and commonly more often. There was no single seat of a witenagemot, it being held where the king was, who typically had no single fixed court either. Witenagemots are known to have met in at least 116 locations, including Amesbury, Calne, Cheddar, Gloucester, London and Winchester. The meeting places were often on royal estates, but some witenagemots were convened in the open at prominent rocks, hills, meadows and famous trees.
The best-known examples of the questionable advice given by the English witenagemot are when on January 5, 1066 it approved the succession to the kingship of Harold Godwinson (Harold Godwin) following the death of Edward the Confessor, and 50 years earlier, in 1016, it had approved the splitting of the kingdom between the Saxon Edmund II and the Danish king Canute.
This arrangement ended when the Normans invaded in 1066, replacing the witenagemot with the "curia regis", or king's court. However, in a sign of the witenagemot's enduring legacy, the "curia regis" continued to be dubbed a "witan" by chroniclers until as late as the 12th century.
Origin.
It is generally accepted that the English witenagemot had its origins in ancient Germanic assemblies summoned to witness royal grants of land. Yet whatever their status in the 5th and 4th centuries, the nature of these assemblies in England was irrevocably changed when Christianity was introduced, circa 600. Hereafter, church and state were "inseparably intertwined," and this was reflected in the strong ecclesiastical element in the witan's membership and concerns; records of decisions made by witan encompass ecclesiastical and secular jurisdictions alike.

</doc>
<doc id="40147" url="http://en.wikipedia.org/wiki?curid=40147" title="Divorce">
Divorce

Divorce (or the dissolution of marriage) is the termination of a marital union, the canceling and/or reorganizing of the legal duties and responsibilities of marriage, thus dissolving the bonds of matrimony between a married couple under the rule of law of the particular country and/or state.
Divorce should not be confused with annulment, which declares the marriage null and void; with legal separation or "de jure" separation (a legal process by which a married couple may formalize a "de facto" separation while remaining legally married) or with "de facto separation" (a process where the spouses informally stop cohabiting). Reasons for divorce vary, from insufficient sex and lack of independence to a personality clash.
Divorce laws vary considerably around the world, but in most countries it requires the sanction of a court or other authority in a legal process. The legal process of divorce may also involve issues of alimony (spousal support), child custody, child visitation / access, parenting time, child support, distribution of property, and division of debt. In most countries monogamy is required by law, so divorce allows each former partner to marry another; where polygyny is legal but polyandry is not, divorce allows the woman to marry a new husband.
Divorce can be a stressful experience, affecting finances, living arrangements, household jobs, schedules, parenting and the outcomes of children of the marriage as they face each stage of development from childhood to adulthood. Such children may be deeply affected.
The only countries that do not allow divorce are the Philippines and the Vatican City, an ecclesiastical state, which has no procedure for divorce. Countries that have relatively recently legalized divorce are Italy (1970), Portugal (1975), Brazil (1977), Spain (1981), Argentina (1987), Paraguay (1991), Colombia (1991* ) Ireland (1996), Chile (2004) and Malta (2011).
Overview.
Divorce grounds vary significantly from country to country. Marriage may be seen as a contract, a status, or a combination of these. Where it is seen as a contract, the refusal or inability of one spouse to perform the obligations stipulated in the contract may constitute a ground for divorce for the other spouse. In contrast, in some countries (such as Sweden, Finland, Australia, New Zealand), divorce is purely no fault. Many jurisdictions offer both the option of a "no fault" divorce as well as an "at fault" divorce. This is the case, for example, in many US states (see Grounds for divorce (United States)).
Though divorce laws vary between jurisdictions, there are two basic approaches to divorce: fault based and no-fault based. However, even in some jurisdictions that do not require a party to claim fault of their partner, a court may still take into account the behavior of the parties when dividing property, debts, evaluating custody, shared care arrangements and support. In some jurisdictions one spouse may be forced to pay the attorney's fees of another spouse.
Laws vary as to the waiting period before a divorce is effective. Also, residency requirements vary. However, issues of division of property are typically determined by the law of the jurisdiction in which the property is located.
In Europe, divorce laws differ from country to country, reflecting differing legal and cultural traditions.
In some countries, particularly (but not only) in some former communist countries, divorce can only be obtained on one single general ground of "irretrievable breakdown of the marriage" (or a similar formulation). Yet, what constitutes such a "breakdown" of the marriage is interpreted very differently from jurisdiction to jurisdiction, ranging from very liberal interpretations (e.g. Netherlands) to quite restrictive ones (e.g., in Poland, there must be an "irretrievable and complete disintegration of matrimonial life," but there are many restrictions to granting a divorce). Separation constitutes a ground of divorce in some European countries (in Germany, e.g., a divorce is granted on the basis of a 1-year separation if both spouses consent, or 3-year separation if only one spouse consents). Note that "separation" does not necessarily mean separate residences - in some jurisdictions, living in the same household but leading a separate life (e.g., eating, sleeping, socializing, etc. separately) is sufficient to constitute "de facto" separation; this is explicitly stated, e.g., in the family laws of Latvia.
Divorce laws are not static; they often change reflecting evolving social norms of societies. In the 21st century, many European countries have made changes to their divorce laws, in particular by reducing the length of the necessary periods of separation, e.g., Scotland in 2006 (1 or 2 years from the previous 2 or 5 years); France in 2005 (2 years from the previous 6 years), Switzerland in 2005 (2 years from the previous 4 years), Greece in 2008 (2 years from the previous 4 years). Some countries have completely overhauled their divorce laws, such as Spain in 2005, and Portugal in 2008. A new divorce law also came into force in September 2007 in Belgium, creating a new system that is primarily no-fault. Bulgaria also modified its divorce regulations in 2009. In Italy, however, the divorce laws still remain traditionally based, with divorce's being a relatively complicated and lengthy process.
Austria is another European country where the divorce law remains conservative.
The liberalization of divorce laws is not without opposition, particularly in the United States. Indeed, in the US, certain conservative and religious organizations are lobbying for laws which restrict divorce. In 2011, in the US, the Coalition for Divorce Reform was established, describing itself as an organization "dedicated to supporting efforts to reduce unnecessary divorce and promote healthy marriages."
Law.
Types of divorce.
In some jurisdictions, the courts will seldom apply principles of fault, but might willingly hold a party liable for a breach of a fiduciary duty to his or her spouse (for example, see Family Code Sections 720 and 1100 of the California Family Code). Grounds for divorce differs from state to state in the U.S. Some states have no-fault divorce; some states require a declaration of fault on the part of one partner or both; some state allow either method.
In most jurisdictions, a divorce must be certified (or ordered by a Judge) by a court of law to come into effect. The terms of the divorce are usually determined by the courts, though they may take into account prenuptial agreements or post-nuptial agreements, or simply ratify terms that the spouses may have agreed to privately (this is not true in the United States, where agreements related to the marriage typically have to be rendered in writing to be enforceable). In absence of agreement, a contested divorce may be stressful to the spouses.
In some other countries,#redirect when the spouses agree to divorce and to the terms of the divorce, it can be certified by a non-judiciary administrative entity. The effect of a divorce is that both parties are free to marry again.
Contested divorce.
Contested divorces mean that one of several issues are required to be heard by a judge at trial level—this is more expensive, and the parties will have to pay for a lawyer's time and preparation. In such a divorce the spouses are not able to agree on issues for instance child custody and division of marital assets. In such situations, the litigation process takes longer to conclude. The judge controls the outcome of the case. Less adversarial approaches to divorce settlements have recently emerged, such as mediation and collaborative divorce settlement, which negotiate mutually acceptable resolution to conflicts. This principle in the United States is called 'Alternative Dispute Resolution' and has gained popularity.
At-fault divorce.
Before the late 1960s, nearly all countries that permitted divorce required proof by one party that the other party had committed an act incompatible to the marriage. This was termed "grounds" for divorce (popularly called "fault") and was the only way to terminate a marriage. Most jurisdictions around the world still require such proof of fault. In the United States, no-fault divorce is available in all 50 states, as is the case with Australia, New Zealand, Canada and other Western countries.
Fault-based divorces can be contested; evaluation of offenses may involve allegations of collusion of the parties (working together to get the divorce), or condonation (approving the offense), connivance (tricking someone into committing an offense), or provocation by the other party. Contested fault divorces can be expensive, and not usually practical as eventually most divorces are granted. Comparative rectitude is a doctrine used to determine which spouse is more at fault when both spouses are guilty of breaches.
The grounds for a divorce which a party could raise and need to prove included 'desertion,' 'abandonment,' 'cruelty,' or 'adultery.' The requirement of proving a ground was revised (and withdrawn) by the terms of 'no-fault' statutes, which became popular in many Western countries in the late 1960s and early 1970s. In 'no-fault' jurisdictions divorce can be obtained either on a simple allegation of 'irreconcilable differences,' 'irretrievable break-down', or 'incompatibility' with respect to the marriage relationship, or on the ground of de facto separation.
Summary divorce.
A summary (or simple) divorce, available in some jurisdictions, is used when spouses meet certain eligibility requirements, or can agree on key issues beforehand.
Key factors:
No-fault divorce.
Some Western jurisdictions have a no-fault divorce system, which requires no allegation or proof of fault of either party. The barest of assertions suffice. For example, in countries that require "irretrievable breakdown", the mere assertion that the marriage has broken down will satisfy the judicial officer. In other jurisdictions requiring irreconcilable differences, the mere allegation that the marriage has been irreparable by these differences is enough for granting a divorce. Courts will not inquire into facts. A "yes" is enough, even if the other party vehemently says "no".
The application can be made by either party or by both parties jointly.
In jurisdictions adopting the 'no-fault' principle in divorce proceedings, some courts may still take into account the behavior of the parties when dividing property, debts, evaluating custody, and support—facts that almost always have considerable weight in fault proceedings. In custody cases, courts might consider factors that may appear like 'fault' based issues but are really related to protection of the child or children. These may include but are not limited to one or both parent's substance abuse, history of violence, cruelty, instability, neglect or endangerment.
Uncontested divorce.
It is estimated that upwards of 95% of divorces in the U.S. are "uncontested", because the two parties are able to come to an agreement (either with or without lawyers/mediators/collaborative counsel) about the property, children, and support issues. When the parties can agree and present the court with a fair and equitable agreement, approval of the divorce is almost guaranteed. If the two parties cannot come to an agreement, they may ask the court to decide how to split property and deal with the custody of their children. Though this may be necessary, the courts would prefer parties come to an agreement prior to entering court.
Where the issues are not complex and the parties are cooperative, a settlement often can be directly negotiated between them. In the majority of cases, forms are acquired from their respective state websites and a filing fee is paid to the state. Most U.S. states charge between $175 and $350 for a simple divorce filing. Collaborative divorce and mediated divorce are considered uncontested divorces.
Because of additional requirements that must be met, most military divorces are typically uncontested.
In the United States, many state court systems are experiencing an increasing proportion of "pro se" ("i.e.," litigants represent themselves without a lawyer) in divorce cases. In San Diego, for example, the number of divorce filings involving at least one self-representing litigant rose from 46% in 1992 to 77% in 2000, and in Florida from 66% in 1999 to 73% in 2001. Urban courts in California report that approximately 80% of the new divorce filings are filed "pro se."
Collaborative divorce.
Collaborative divorce is a method for divorcing couples to come to agreement on divorce issues. In a collaborative divorce, the parties negotiate an agreed resolution with the assistance of attorneys who are trained in the collaborative divorce process and in mediation, and often with the assistance of a neutral financial specialist and/or divorce coach(es). The parties are empowered to make their own decisions based on their own needs and interests, but with complete information and full professional support.
Once the collaborative divorce starts, the lawyers are disqualified from representing the parties in a contested legal proceeding, should the collaborative law process end prematurely. Most attorneys who practice collaborative divorce claim that it can be more cost-effective than other divorce methods, "e.g.," going to court. Expense, they say, has to be looked at under the headings of financial and emotional. Also, the experience of working collaboratively tends to improve communication between the parties, particularly when collaborative coaches are involved, and the possibility of going back to court post-separation or divorce is minimized. In the course of the collaboration, should the parties not reach any agreements, any documents or information exchanged during the collaborative process cannot be used in court except by agreement between the parties.
Neither can any of the professional team retained in the course of the collaboration be brought to court. Essentially, they have the same protections as in mediation. There are two exceptions: 1) Any affidavit sworn in the course of the collaboration and vouching documentation attaching to same and 2) any interim agreement made and signed off in the course of the collaboration or correspondence relating thereto. The parties are in control of the time they are prepared to give their collaboration. Some people need a lot of time to complete, whereas others will reach solutions in a few meetings. Collaborative practitioners offer a tightly orchestrated model with meetings scheduled in advance every two weeks, and the range of items to be discussed apportioned in advance of signing up as well as the more open ended process, the clients decide.
Mediated divorce.
Divorce mediation is an alternative to traditional divorce litigation. In a divorce mediation session, a mediator facilitates the discussion between the two parties by assisting with communication and providing information and suggestions to help resolve differences. At the end of the mediation process, the separating parties have typically developed a tailored divorce agreement that can be submitted to the court. Mediation sessions can include either party's attorneys, a neutral attorney, or an attorney-mediator who can inform both parties of their legal rights, but does not provide advice to either, or can be conducted with the assistance of a facilitative or transformative mediator without attorneys present at all. Some mediation companies, such as Wevorce, also pair clients with counselors, financial planners and other professionals to work through common mediation sticking points. Divorce mediators may be attorneys who have experience in divorce cases, or they may be professional mediators who are not attorneys, but who have training specifically in the area of family court matters. Divorce mediation can be significantly less costly, both financially and emotionally, than litigation. The adherence rate to mediated agreements is much higher than that of adherence to court orders.
Polygamy and divorce.
Polygamy is a significant structural factor governing divorce in countries where this is permitted. Little-to-no analysis has been completed to explicitly explain the link between marital instability and polygamy which leads to divorce. The frequency of divorce rises in polygamous marriages compared to monogamous relationships. Within polygamous unions, differences in conjugal stability are found to occur by wife order. There are 3 main mechanisms through which polygamy affects divorce: economic restraint, sexual satisfaction, and childlessness. Many women escape economic restraint through divorcing their spouses when they are allowed to initiate a divorce.
Effects of divorce.
Some of the effects associated with divorce include academic, behavioral, and psychological problems. Although this may not always be true, studies suggest that children from divorced families are more likely to exhibit such behavioral issues than those from non-divorced families.
Divorce and relationships.
Research done at Northern Illinois University on Family and Child Studies suggests that divorce of couples experiencing high conflict can have a positive effect on families by reducing conflict in the home. There are, however, many instances when the parent-child relationship may suffer due to divorce. Financial support is many times lost when an adult goes through a divorce. The adult may be obligated to obtain additional work to maintain financial stability. In turn, this can lead to a negative relationship between the parent and child; the relationship may suffer due to lack of attention towards the child as well as minimal parental supervision
Studies have also shown that parental skills decrease after a divorce occurs; however, this effect is only a temporary change. “A number of researchers have shown that a disequilibrium, including diminished parenting skills, occurs in the year following the divorce but that by two years after the divorce re-stabilization has occurred and parenting skills have improved”
Some couples choose divorce even when one spouse's desire to remain married is greater than the other spouse's desire to obtain a divorce. In economics this is known as the Zelder Paradox, and is more common with marriages that have produced children, and less common with childless couples.
In an American Psychological Association study of parents’ relocation after a divorce, researchers found that a move has a long-term effect on children. In the first study conducted amongst 2,000 college students on the effects of parental relocation relating to their children's well-being after divorce, researchers found major differences. In divorced families in which one parent moved, the students received less financial support from their parents compared with divorced families in which neither parent moved. These findings also imply other negative outcomes for these students, such as more distress related to the divorce and did not feel a sense of emotional support from their parents. Although the data suggests negative outcomes for these students whose parents relocate after divorce, there is insufficient research that can alone prove the overall well-being of the child A newer study in the "Journal of Family Psychology" found that parents who move more than an hour away from their children after a divorce are much less well off than those parents who stayed in the same location
Effects of divorce on children.
Psychological.
Divorce is associated with diminished psychological well-being in children and adult offspring of divorced parents, including greater unhappiness, less satisfaction with life, weaker sense of personal control, anxiety, depression, and greater use of mental health services. A preponderance of evidence indicates that there is a causal effect between divorce and these outcomes.
Children of divorced parents are also more likely to experience conflict in their own marriages, and are more likely to experience divorce themselves. They are also more likely to be involved in short-term cohabiting relationships, which often dissolve before marriage.
According to Nicholas Wall, former President of the Family Division of the English High Court, "People think that post-separation parenting is easy – in fact, it is exceedingly difficult, and as a rule of thumb my experience is that the more intelligent the parent, the more intractable the dispute. There is nothing worse, for most children, than for their parents to denigrate each other. Parents simply do not realize the damage they do to their children by the battles they wage over them. Separating parents rarely behave reasonably, although they always believe that they are doing so, and that the other party is behaving unreasonably."
Although not the intention of most parents, putting children in the middle of conflict is particularly detrimental. Examples of this are asking children to carry messages between parents, grilling children about the other parent's activities, and putting the other parent down in front of the children. High-conflict divorce or custody cases can experience varying forms of Parental Alienation. The Family Courts often consider Parental Alienation as a form of child abuse. Specific examples of Parental Alienation include brainwashing the child to cease their relationship with the other parent, telling the child that the other parent does not love them, teaching the child to call another adult by a parental name in effort to replace the other parent, limiting communication between the child and the other parent, and limiting quality time between the child and the other parent. If evidence reveals that a parent is actively alienating the child from their other parent, their case for custody can be severely damaged.
Poorly managed conflict between parents increases children's risk of behavior problems, depression, substance abuse and dependence, poor social skills, and poor academic performance. Fortunately, there are approaches by which divorce professionals can help parents reduce conflict. Options include mediation, collaborative divorce, coparent counseling, and parenting coordination.
Children begin to be affected 2-4 years before the separation or divorce even occurs. This time period before the separation tends to be more detrimental for the children than the actual divorce or separation. This can be due to parental conflict and anticipation of a divorce, and decreased parental contact. Many couples believe that by separating, or becoming legally divorced that they are helping their children, and in situations of extreme parental conflict of abuse it most likely will be beneficial. Arkes, Jeremy. “The Temporal Effects of Divorces and Separations on Children’s Academic Achievement and Problem behavior”, Journal of Divorce and Remarriage.
22 December 2014. Web. 22 April 2015. http://dx.doi.org/10.1080/10502556.2014.972204
Exposure to marital conflict and instability, most often has negative consequences for children. Several mechanisms are likely to be responsible. First, observing overt conflict between parents is a direct stressor for children. Observational studies reveal that children react to inter-parental conflict with fear, anger, or the inhibition of normal behavior. Preschool children – who tend to be egocentric – may blame themselves for marital conflict, resulting in feelings of guilt and lowered self-esteem. Conflict between parents also tends to spill over and negatively affect the quality of parents' interactions with their children. Researchers found that the associations between marital conflict and children's externalizing and internalizing problems were largely mediated by parents' use of harsh punishment and parent-child conflict. Furthermore, modeling verbal or physical aggression, parents "teach" their children that disagreements are resolved through conflict rather than calm discussion. As a result, children may not learn the social skills (such as the ability to negotiate and reach compromises) that are necessary to form mutually rewarding relationships with peers.
Girls and boys deal with divorce differently, for instance girls who initially show signs of adapting well, later suffer from anxiety in romantic relationships with men. Studies also showed that girls who were separated from their fathers at a younger age tended to be more angry toward the situation as they aged, anger and sadness were also observed at common feeling in adolescents who had experienced parental divorce.
 Rappaport, Sol R. "Deconstructing the Impact of Divorce on Children." Family Law Quarterly 47.3 (2013): 353-77. ProQuest.Web. 27 Apr. 2015.
http://search.proquest.com.une.idm.oclc.org/pqcentral/docview/1490970659/B43704203B9B4D59PQ/5?accountid=12756
Academic and socioeconomic.
Children who have experienced a divorce frequently have lower academic achievement than children from non-divorced families
In a review of family and school factors related to adolescents’ academic performance, it noted that a child from a divorced family is two times more likely to drop out of high school than a child from a non-divorced family. These children from divorced families may also be less likely to attend college, resulting in the discontinuation of their academic career.
Many times academic problems are associated with those children from single-parent families. Studies have shown that this issue may be directly related to the economical influence of divorce. A divorce may result in the parent and children moving to an area with a higher poverty rate and a poor education system all due to the financial struggles of a single parent.
Children of divorced parents also achieve lower levels of socioeconomic status, income, and wealth accumulation than children of continuously married parents. These outcomes are associated with lower educational achievement.
Young men or women between the ages of 7 and 16 who had experienced the divorce of their parents were more likely than youths who had not experienced the divorce of their parents to leave home because of friction, to cohabit before marriage, and to parent a child before marriage.
Divorce often leads to worsened academic achievement in children ages 7-12. The most heightened negative effect being reading test scores. These negative effects tend to persist, and even escalate after the divorce or separation occurs. Arkes, Jeremy. “The Temporal Effects of Divorces and Separations on Children’s Academic Achievement and Problem behavior”, Journal of Divorce and Remarriage. 22 December 2014. Web. 22 April 2015. http://dx.doi.org/10.1080/10502556.2014.972204
Divorce amongst the elderly.
According to a "New York Times" article, “More Americans Rejecting Marriage in 50s and Beyond”, in the past 20 years, the divorce rate has increased over 50% amongst the baby boomers. More and more adults are staying single and according to an analysis of census data conducted at Bowling Green State University in Ohio, they say the divorce numbers will continue to rise. Baby boomers that remain unmarried are five times more likely to live in poverty compared to those who are married. According to the statistics, they will also be three times as likely to receive food stamps, public assistance or disability payments.
Sociologists believe that the rise in the number of older Americans who are not married is a result of factors such as longevity and economics. Women, especially, are becoming more and more financially independent which allows them to feel more secure with being alone. In previous generations, being divorced or single was seen differently now. This has resulted in less pressure for baby boomers to marry or stay married.
Statistics.
Asia.
In Japan, divorces were on a generally upward trend from the 1960s until 2002 when they hit a peak of 290,000. Since then, both the number of divorces and the divorce rate have declined for six years straight. In 2010, the number of divorces totaled 251,000, and the divorce rate was 1.99 (per 1,000 population).
Europe.
One study estimated that legal reforms accounted for about 20% of the increase in divorce rates in Europe between 1960 and 2002.
North America.
United States.
On average, first marriages that end in divorce last about eight years. Of the first marriages for women from 1955 to 1959, about 79% marked their 15th anniversary, compared with only 57% for women who married for the first time from 1985 to 1989. The median time between divorce and a second marriage was about three and a half years.
In 2009, the divorce rate declined.
A 1995 study found a wide range of factors correlating with the divorce rate including frequency of sex, wealth, race, and religious commitment.
In 2001, marriages between people of different faiths were three times more likely to be divorced than those of the same faith. In a 1993 study, members of two mainline Protestant religions had a 20% chance of being divorced in 5 years; a Catholic and an Evangelical, a 33% chance; a Jew and a Christian, a 40% chance.
A study by the Barna Group, that conducts polls of interest to Christians, reports that a higher divorce rate was associated with infrequent church attendance.
Success in marriage has been associated with higher education and higher age. 81% of college graduates, over 26 years of age, who wed in the 1980s, were still married 20 years later. 65% of college graduates under 26, who married in the 1980s, were still married 20 years later. 49% of high school graduates under 26 years old, who married in the 1980s, were still married 20 years later. 2.9% of adults age 35–39 without a college degree divorced in the year 2009, compared with 1.6% with a college education. A population study found that in 2004 and 2008, liberal-voting states have lower rates of divorce than conservative-voting states, possibly because people in liberal states tend to wait longer before getting married. An analysis of this study found it to be misleading due to sampling at an aggregate level. It revealed that when sampling the same data by individuals, Republican leaning voters are less likely to have a divorce or extramarital affair than Democrat leaning voters and independents.
The National Center for Health Statistics reports that from 1975 to 1988 in the U.S., in families with children present, wives file for divorce in approximately two-thirds of cases. In 1975, 71.4% of the cases were filed by women, and in 1988, 65% were filed by women.
It is estimated that upwards of 95% of divorces in the U.S. are "uncontested", because the two parties are able to come to an agreement without a hearing (either with or without lawyers/mediators/collaborative counsel) about the property, children, and support issues.
A 2011 study found a 1% increase in the unemployment rate correlated with a 1% decrease in the divorce rate, presumably because more people were financially challenged to afford the legal proceedings.
Oceania.
In Australia, nearly every third marriage ends in divorce. After reaching a peak divorce rate of 2.7 per 1000 residents in 2001, the Australian rate declined to 2.3 per 1000 in 2007.
Divorce of same-sex married couples (United States).
Some states permit same-sex marriage. For same-sex couples in the United States, divorce law is in its infancy and is less than clear on how such unions may be legally dissolved in another state. For example, if a same-sex couple is married in a state that recognizes gay marriage but returns to reside in a state that does not, they might find themselves in a situation where their own state, in failing to recognize their union will also fail to enable them to divorce. In addition, splitting up the couple's financial resources may prove to be legally difficult and well as determining which spouse is entitled to the custody of their children.
Rights of spouses to custody of children.
Upon dissolution of a same-sex marriage, legal questions remain as to the rights of spouses to custody of the biological children of their spouses. Unresolved legal questions abound in this area.
Child custody policies include several guidelines that determine with whom the child lives following divorce, how time is divided in joint custody situations, and visitation rights. The most frequently applied custody guideline is the ‘‘best interests of the child’’ standard, which takes into account the parents’ preferences, the child’s preferences, the interactions between parents and children, children’s adjustment, and all family members’ mental and physical health.
Same-sex divorce in a state that does not recognize same-sex marriage.
Since same-sex marriages are not recognized in a multitude of states, couples who are married in states that do recognize same-sex marriages will find themselves in a position of being precluded from dissolving their marriages in the states in which they live. When this happens, legal questions will remain unanswered as to which state laws will be applicable to determine the rights of each divorcing partner. In addition, special problems will present themselves when same-sex couples cannot be divorced in states that do recognize same sex marriage because they are not residents of such states.
History.
Greco-Roman culture.
The ancient Athenians liberally allowed divorce, but the person requesting divorce had to submit the request to a magistrate, and the magistrate could determine whether the reasons given were sufficient.
Divorce was rare in early Roman culture but as their empire grew in power and authority Roman civil law embraced the maxim, "matrimonia debent esse libera" ("marriages ought to be free"), and either husband or wife could renounce the marriage at will. Though civil authority rarely intervened in divorces, social and familial taboos guaranteed that divorce occurred only after serious circumspection. The Christian emperors Constantine and Theodosius restricted the grounds for divorce to grave cause, but this was relaxed by Justinian in the sixth century.
Medieval Europe.
After the fall of the Roman Empire, familial life was regulated more by ecclesiastical authority than civil authority. By the ninth or tenth century, the divorce rate had been greatly reduced under the influence of the Church, which considered marriage a sacrament instituted by God and Christ indissoluble by mere human action.
Although divorce, as known today, was generally prohibited after the tenth century, separation of husband and wife and the annulment of marriage were well-known. What is today referred to as "separate maintenance" (or "legal separation") was termed "divorce a mensa et thoro" ("divorce from bed-and-board"). The husband and wife physically separated and were forbidden to live or cohabit together; but their marital relationship did not fully terminate. Civil courts had no power over marriage or divorce. The grounds for annulment were determined by Church authority and applied in ecclesiastical courts. Annulment was for canonical causes of impediment existing at the time of the marriage. "For in cases of total divorce, the marriage is declared null, as having been absolutely unlawful ab initio." The Church held that the sacrament of marriage produced one person from two, inseparable from each other: "By marriage the husband and wife are one person in law: that is, the very being of legal existence of the woman is suspended during the marriage or at least incorporated and consolidated into that of the husband: under whose wing, protection and cover, she performs everything." Since husband and wife became one person upon marriage, that oneness could only be annulled if the parties improperly entered into the marriage initially.
Secularisation in Europe.
After the Reformation, marriage came to be considered a civil contract in the new Protestant regions of Europe, and on that basis civil authorities gradually asserted their power to decree a "divortium a vinculo matrimonii", or "divorce from all the bonds of marriage".
Since no precedents existed defining the circumstances under which marriage could be dissolved, civil courts heavily relied on the previous determinations of the ecclesiastic courts and freely adopted the requirements set down by those courts. As the civil courts assumed the power to dissolve marriages, courts still strictly construed the circumstances under which they would grant a divorce, and considered divorce to be contrary to public policy. Because divorce was considered to be against the public interest, civil courts refused to grant a divorce if evidence revealed any hint of complicity between the husband and wife to divorce, or if they attempted to manufacture grounds for a divorce. Divorce was granted only because one party to the marriage had violated a sacred vow to the "innocent spouse". If both husband and wife were guilty, "neither would be allowed to escape the bonds of marriage".
Eventually, the idea that a marriage could be dissolved in cases in which one of the parties violated the sacred vow gradually allowed expansion of the grounds upon which divorce could be granted from those grounds which existed at the time of the marriage to grounds which occurred after the marriage, but which exemplified violation of that vow, such as abandonment, adultery, or "extreme cruelty". An exception to this trend was the Anglican Church, which maintained the doctrine of marital indissolubility.
During the English Civil War, the Puritans briefly passed a law that divested marriage of all sacrament, leaving it as a secular contract that could be broken. John Milton wrote four divorce tracts from 1643–1645 that argued for the legitimacy of divorce on grounds of spousal incompatibility. His ideas were ahead of their time; arguing for divorce at all, let alone a version of no-fault divorce, was extremely controversial and religious figures sought to ban his tracts. In 1670 a precedent was first set with an Act of Parliament allowing Lord John Manners to divorce his wife, Lady Anne Pierpon, and until the passage of the Matrimonial Causes Act 1857, divorce could only be obtained through a specific Act of Parliament.
The move towards secularisation and liberalisation was reinforced by the individualistic and secular ideals of the Enlightenment. The Enlightened absolutist, King Frederick II ("the Great") of Prussia enshrined a new divorce law in 1752, in which marriage was declared to be a purely private concern, allowing divorce to be granted on the basis of mutual consent. This new system heavily influenced the law in neighbouring Austria under Emperor Joseph II, where it was applied to all non-Catholic Imperial subjects. Divorce was legalised in France after the French revolution on a similar basis, although the legal order of the ancien regime was reinstated at the Bourbon restoration of 1816. The trend in Europe throughout the 19th century, was one of increased liberalisation; by the mid-19th century divorce was generally granted by civil courts in the case of adultery.
In Britain before 1857 wives were under the economic and legal protection of their husbands, and divorce was almost impossible. It required a very expensive private act of Parliament costing perhaps £200, of the sort only the richest could possibly afford. It was very difficult to secure divorce on the grounds of adultery, desertion, or cruelty. The first key legislative victory came with the Matrimonial Causes Act of 1857, which passed over the strenuous opposition of the highly traditional Church of England. The new law made divorce a civil affair of the courts, rather than a Church matter, with a new civil court in London handling all cases. The process was still quite expensive, at about £40, but now became feasible for the middle class. A woman who obtained a judicial separation took the status of a "feme sole," with full control of her own civil rights. Additional amendments came in 1878, which allowed for separations handled by local justices of the peace. The Church of England blocked further reforms until the final breakthrough came with the Matrimonial Causes Act 1973.
Divorce rates increased markedly during the twentieth century in developed countries, as social attitudes towards family and sex changed dramatically. Among the nations in which divorce has become commonplace are the United States, Canada, Australia, Germany, New Zealand, Scandinavia, and the United Kingdom.
Japan.
In the Edo Period (1603–1868), only husbands could divorce their wives by writing letters of divorce. But actually, their relatives or marriage arrangers often kept these letters and tried to restore the marriages. It was not allowed for wives to divorce their husbands. Some wives were able to gain sanctuary in certain Shinto "divorce temples" for several years, and were able to obtain a divorce thereby. In 19th century Japan, at least one in eight marriages ended in divorce.
There are four types of divorce in Japan: Divorce by agreement in which the divorce is mutual, divorce by mediation which happens in family court, divorce by decision of family court that takes place when a couple cannot complete a divorce through mediation, and divorce by judgment of district court.
India.
On an all-India level, the Special Marriage Act was passed in 1954, is an inter-religious marriage law permitting Indian nationals to marry and divorce irrespective of their religion or faith. The Hindu Marriage Act, in 1955 which legally permitted divorce to Hindus and other communities who chose to marry under these acts. The Indian Divorce Act 1869 is the law relating to the divorce of person professing the Christian religion. Divorce can be sought by a husband or wife on grounds including adultery, cruelty, desertion for two years, religious conversion, mental abnormality, venereal disease, and leprosy. Divorce is also available based on mutual consent of both the spouses, which can be filed after at least one year of separated living. Mutual consent divorce can not be appealed, and the law mandates a minimum period of six months (from the time divorce is applied for) for divorce to be granted. While a Muslim husband can unilaterally bring an end to the marriage by pronouncing talaq, Muslim women must go to court, claiming any of the grounds provided under the Dissolution of Muslim Marriage Act.
Official figures of divorce rates are not available, but it has been estimated that 1 in 100 or another figure of 11 in 1,000 marriages in India end up in divorce.
Various communities are governed by specific marital legislation, distinct to Hindu Marriage Act, and consequently have their own divorce laws:
An amendment to the marriage laws to allow divorce based on "irretrievable breakdown of marriage" (as alleged by one of the spouses) is under consideration in India. In June 2010, the Union Cabinet of India approved the Marriage Laws (Amendment) Bill 2010, which, if cleared by Parliament, would establish "irretrievable breakdown" as a new ground for divorce. Under the proposed amendment, the court before proceeding to the merits of the case must be satisfied by the evidences produced that parties have been living apart for a continuous period of not less than three years immediately preceding the presentation of the petition.
Islam.
In Islamic law and marital jurisprudence, divorce is referred to as "talaq". Khula is the right of a woman in Islam to divorce or separate from her husband. The triple talaq is a mechanism for divorce which exists in Sunni sect of Islam while rejected by the Shia sect. Talaq (conflict) deals with the relationship between religious and secular systems for terminating the marriage in the conflict of laws.
According to Yossef Rapoport, in the 15th century, the rate of divorce was higher than it is today in the modern Middle East, which has generally low rates of divorce. In 15th century Egypt, Al-Sakhawi recorded the marital history of 500 women, the largest sample on marriage in the Middle Ages, and found that at least a third of all women in the Mamluk Sultanate of Egypt and Syria married more than once, with many marrying three or more times. According to Al-Sakhawi, as many as three out of ten marriages in 15th century Cairo ended in divorce. In the early 20th century, some villages in western Java and the Malay peninsula had divorce rates as high as 70%.
The Philippines.
Divorce as a means of terminating marriage is illegal for all Filipinos except Filipino Muslims. There is only civil annulment after a lengthy legal separation. The process is costly and long. There are many legally married couples in extramarital relations, even without a divorce law.
Code of Muslim Personal Laws of the Philippines, known as Presidential Decree (PD) No. 1083,Title II- Marriage and Divorce,Chapter 3-Divorce allows for divorce recognized by the state. There are 2 sharia courts that are part of the Philippines Judiciary that hear these cases.
On July 27, 2010, Gabriela Women's Party filed in Congress House Bill No 1799, or the Divorce Bill of the Philippines, as one of many attempts to introduce pro-divorce legislation. Senator Pia Cayetano has filed a separate divorce bill in the Philippines Senate.
Causes of divorce.
An annual study in the UK by management consultants Grant Thornton, estimates the main proximal causes of divorce based on surveys of matrimonial lawyers.
The main causes in 2004 were:
According to this survey, husbands engaged in extramarital affairs in 75% of cases; wives in 25%. In cases of family strain, wives' families were the primary source of strain in 78%, compared to 22% of husbands' families. Emotional and physical abuse were more evenly split, with wives affected in 60% and husbands in 40% of cases. In 70% of workaholism-related divorces it was husbands who were the cause, and in 30%, wives. The 2004 survey found that 93% of divorce cases were petitioned by wives, very few of which were contested. 53% of divorces were of marriages that had lasted 10 to 15 years, with 40% ending after 5 to 10 years. The first 5 years are relatively divorce-free, and if a marriage survives more than 20 years it is unlikely to end in divorce.
Social scientists study the causes of divorce in terms of underlying factors that may possibly motivate divorce. One of these factors is the age at which a person gets married; delaying marriage may provide more opportunity or experience in choosing a compatible partner. Wage, income, and sex ratios are other such underlying factors that have been included in analyses by sociologists and economists.
Cohabitation prior to marriage is associated with higher divorce rates, which is called the cohabitation effect. Evidence suggests that this is partly due to selection (people more likely to divorce being more likely to cohabit, and cohabiting couples being more likely to marry with low levels of commitment) as well as the effect of cohabitation itself on the marital union. There is a consensus among researchers that both of these factors explain the cohabitation effect.
One of the biggest divorce settlements reported to date, is that of English financier Sir Chris Hohn who was asked to pay £337m to his American wife Jamie Cooper-Hohn after a High Court ruling.
Religion and divorce.
 Illustration parodying the divorce proceedings of Anna Gould (an American heiress and socialite) and Boni de Castellane (a French nobleman) in 1906 in Paris, France. Boni de Castellane then sought an annulment from the Vatican so that he could be free to remarry in the Church. The annulment case was not finally settled until 1924, when the highest Vatican tribunal upheld the validity of the marriage and denied the annulment.
In some countries (commonly in Europe and North America), the government defines and administers marriages and divorces. While ceremonies may be performed by religious officials on behalf of the state, a civil marriage and thus, civil divorce (without the involvement of a religion) is also possible. Due to differing standards and procedures, a couple can be legally unmarried, married, or divorced by the state's definition, but have a different status as defined by a religious order. Other countries use religious law to administer marriages and divorces, eliminating this distinction. In these cases, religious officials are generally responsible for interpretation and implementation.
Islam allows divorce, and it can be initiated by either the husband or the wife. However, the initiations are subject to certain conditions and waiting periods, which are meant to force the initiating party to reconsider.
Dharmic religions do not allow divorce. Christian views of divorce vary, with Catholic teaching allowing only annulment, but most other denominations discouraging but allowing divorce. Jewish views of divorce differ, with Reform Judaism considering civil divorces adequate. Conservative and Orthodox Judaism require that the husband grant his wife a divorce in the form of a "get".
The Millet System, where each religious group regulates its own marriages and divorces, is still present in varying degrees in some post−Ottoman countries like Iraq, Syria, Jordan, Lebanon, Israel, the Palestinian Authority, Egypt, and Greece. Several countries use sharia (Islamic law) to administrate marriages and divorces for Muslims. Thus, Marriage in Israel is administered separately by each religious community (Jews, Christians, Muslims, and Druze), and there is no provision for interfaith marriages other than marrying in another country. For Jews, marriage and divorce are administered by Orthodox rabbis. Partners can file for divorce either in rabbinical court or Israeli civil court.
Gender and divorce.
According to a study published in the American Law and Economics Review, women have filed slightly more than two-thirds of divorce cases in the United States. This trend is mirrored in the UK where a recent study into web search behavior found that 70% of divorce inquiries were from women. These findings also correlate with the Office for National Statistics publication "Divorces in England and Wales 2012 which reported that divorce petitions from women outnumber those from men by 2 to 1.
Regarding divorce settlements, according to the 2004 Grant Thornton survey in the UK, women obtained a better or considerably better settlement than men in 60% of cases. In 30% of cases the assets were split 50-50, and in only 10% of cases did men achieve better settlements (down from 24% the previous year). The report concluded that the percentage of shared residence orders would need to increase in order for more equitable financial divisions to become the norm.
Some jurisdictions give unequal rights to men and women when filing for divorce.
For couples to Conservative or Orthodox Jewish law (which by Israeli civil law includes all Jews in Israel), the husband must grant his wife a divorce through a document called a "get". If the man refuses, the woman can appeal to a court or the community to pressure the husband. A woman whose husband refuses to grant the get or who is missing is called an agunah, is still married, and therefore cannot remarry. Under Orthodox law, children of an extramarital affair involving a married Jewish woman are considered "mamzerim" (illegitimate) and cannot marry non-"mamzerim".
Further reading.
</dl>
External links.
"This article incorporates text from the United States National Library of Medicine (), which is in the public domain."

</doc>
<doc id="40148" url="http://en.wikipedia.org/wiki?curid=40148" title="Harold Godwinson">
Harold Godwinson

Harold II (or Harold Godwinson; Old English: "Harold Godƿinson"; 1022 – 14 October 1066) was the last Anglo-Saxon King of England. Harold reigned from 6 January 1066 until his death at the Battle of Hastings on 14 October, fighting the Norman invaders led by William the Conqueror during the Norman conquest of England. His death marked the end of Anglo-Saxon rule over England.
Harold was a powerful earl and member of a prominent Anglo-Saxon family with ties to King Cnut. Upon the death of Edward the Confessor in January 1066, the "Witenagemot" convened and chose Harold to succeed; he was crowned in Westminster Abbey. In late September he successfully repelled an invasion by rival claimant Harald Hardrada of Norway, before marching his army back south to meet William the Conqueror at Hastings some two weeks later.
Family background.
Harold was a son of Godwin (1001-1053), the powerful Earl of Wessex, and of Gytha Thorkelsdóttir, sister-in-law of King Cnut the Great of England and Denmark. Gytha's brother was Ulf Jarl, who married Cnut's sister Estrith (ca 1015/1016). This made Ulf the son-in-law of King Sweyn Forkbeard (died 1014); Ulf and Estrith's son would become King Sweyn II of Denmark in 1047. Godwin was the son of Wulfnoth, probably a "thegn" and a native of Sussex. Godwin remained an earl throughout the remainder of Cnut's reign, one of only two earls to survive to the end of Cnut's reign. On Cnut's death in 1035, Godwin originally supported Harthacnut instead of Cnut's initial successor Harold Harefoot, but managed to switch sides in 1037, although not without becoming involved in the 1036 murder of Alfred Aetheling, half brother of Harthacnut and younger brother of the later King Edward the Confessor. When Harold Harefoot died (1040), Harthacnut became King of England and Godwin's power was imperiled by his earlier involvement in Alfred's murder, but an oath and large gift secured the new king's favour for Godwin. Harthacnut's death in 1042 likely involved Godwin in a role as kingmaker, helping to secure the English throne for Edward the Confessor. In 1045 Godwin reached the height of his power when the new king married Godwin's daughter Edith.
Godwin and Gytha had several children - six sons: Sweyn, Harold, Tostig, Gyrth, Leofwine and Wulfnoth; and three daughters: Edith of Wessex (originally named Gytha but renamed Ealdgyth (or Edith) when she married King Edward the Confessor), Gunhild and Ælfgifu. The birthdates of the children are unknown, but Sweyn was the eldest and Harold was the second son. Harold was aged about 25 in 1045, which makes his birth year around 1020.
Powerful nobleman.
Edith married Edward on 23 January 1045, and around that time Harold became Earl of East Anglia. Harold is called "earl" when he appears as a witness in a will, that may date to 1044, but by 1045 Harold regularly appears as an earl in documents. One reason for his appointment to East Anglia may have been a need to defend against the threat from King Magnus the Good of Norway. It is possible that Harold led some of the ships from his earldom that were sent to Sandwich in 1045 against Magnus. Sweyn, Harold's elder brother, had been named an earl in 1043. It was also around the time that Harold was named an earl that he began a relationship with Edith, who appears to have been the heiress to lands in Cambridgeshire, Suffolk and Essex, lands in Harold's new earldom. The relationship was a form of marriage that was not blessed or sanctioned by the Church, known as "more Danico", or "in the Danish manner", and was accepted by most laypeople in England at the time. Any children of such a union were considered legitimate. Harold likely entered the relationship in part to secure support in his new earldom.
In 1047 Harold's elder brother Sweyn was exiled after abducting the abbess of Leominster. Sweyn's lands were divided between Harold and a cousin, Beorn. In 1049, Harold was in command of a ship or ships that were sent with a fleet to aid the German Emperor Henry III against Baldwin V, Count of Flanders, who was in revolt against Henry. During this campaign, Sweyn returned to England and attempted to secure a pardon from the king, but Harold and Beorn refused to return any of their lands, and Sweyn, after leaving the royal court, took Beorn hostage and later killed him.
When in 1051 Earl Godwin was sent into exile, Harold accompanied his father and helped him to regain his position a year later. Then Godwin died in 1053, and Harold succeeded him as Earl of Wessex (the southern third of England). This arguably made him the most powerful figure in England after the king.
In 1058, Harold also became Earl of Hereford and replaced his late father as the focus of opposition to growing Norman influence in England under the restored monarchy (1042–66) of Edward the Confessor, who had spent more than 25 years in exile in Normandy. He led a series of successful campaigns (1062–63) against Gruffydd ap Llywelyn of Gwynedd, the ruler of Wales. This conflict ended with Gruffydd's defeat and death in 1063.
Harold in northern France.
In 1064, Harold apparently was shipwrecked at Ponthieu. There is much speculation about this voyage. The earliest post-conquest Norman chroniclers report that King Edward had previously sent Robert, Archbishop of Canterbury, to appoint as his heir Edward's maternal kinsman, William of Normandy, and that at this later date Harold was sent to swear fealty. Scholars disagree as to the reliability of this story. William, at least, seems to have believed he had been offered the succession, but there must have been some confusion either on William's part or perhaps by both men, since the English succession was neither inherited nor determined by the reigning monarch. Instead the Witenagemot, the assembly of the kingdom's leading notables, would convene after a king's death to select a successor. Other acts of Edward are inconsistent with his having made such a promise, such as his efforts to return his nephew Edward the Exile, son of king Edmund Ironside, from Hungary in 1057. Later Norman chroniclers suggest alternative explanations for Harold's journey: that he was seeking the release of members of his family who had been held hostage since Godwin's exile in 1051, or even that he had simply been travelling along the English coast on a hunting and fishing expedition and had been driven across the Channel by an unexpected storm. There is general agreement that he left from Bosham, and was blown off course, landing at Ponthieu. He was captured by Guy I, Count of Ponthieu, and was then taken as a hostage to the count's castle at Beaurain, 24.5 km up the River Canche from its mouth at what is now Le Touquet. Duke William arrived soon afterward and ordered Guy to turn Harold over to him. Harold then apparently accompanied William to battle against William's enemy, Conan II, Duke of Brittany. While crossing into Brittany past the fortified abbey of Mont Saint-Michel, Harold is recorded as rescuing two of William's soldiers from quicksand. They pursued Conan from Dol-de-Bretagne to Rennes, and finally to Dinan, where he surrendered the fortress's keys at the point of a lance. William presented Harold with weapons and arms, knighting him. The Bayeux Tapestry, and other Norman sources, then record that Harold swore an oath on sacred relics to William to support his claim to the English throne. After Edward's death, the Normans were quick to point out that in accepting the crown of England, Harold had broken this alleged oath.
The chronicler Orderic Vitalis wrote of Harold that he "was very tall and handsome, remarkable for his physical strength, his courage and eloquence, his ready jests and acts of valour. But what were these gifts to him without honour, which is the root of all good?"
Due to a doubling of taxation by Tostig in 1065 that threatened to plunge England into civil war, Harold supported Northumbrian rebels against his brother, Tostig, and replaced him with Morcar. This strengthened his acceptability as Edward's successor, but fatally split his own family, driving Tostig into alliance with King Harald Hardrada ("Hard Ruler") of Norway.
Marriages and children.
For some twenty years Harold was married "More danico" (Latin: "in the Danish manner") to Edith the Fair (Edith Swannesha) and had at least six children with her. The marriage was widely accepted by the laity, although Edith was considered Harold's mistress by the clergy.
According to Orderic Vitalis, Harold was at some time betrothed to Adeliza, a daughter of William, Duke of Normandy, later William the Conqueror; if so, the betrothal never led to marriage.
About January 1066, Harold married Edith (or Ealdgyth), daughter of Ælfgar, Earl of Mercia, and widow of the Welsh prince Gruffydd ap Llywelyn. Edith had two sons—possibly twins—named Harold and Ulf (born around November 1066), both of whom survived into adulthood and probably lived out their lives in exile.
After her husband's death, Edith is said to have fled for refuge to her brothers, Edwin, Earl of Mercia and Morcar of Northumbria, but both men made their peace with King William initially before rebelling and losing their lands and lives. Edith may have fled abroad (possibly with Harold's mother, Gytha, or with Harold's daughter, Gytha). Harold's sons, Godwine and Edmund, fled to Ireland and then invaded Devon, but were defeated by Brian of Brittany.
Reign as king.
At the end of 1065 King Edward the Confessor fell into a coma without clarifying his preference for the succession. He died on 5 January 1066, according to the "Vita Ædwardi Regis", but not before briefly regaining consciousness and commending his widow and the kingdom to Harold's "protection". The intent of this charge remains ambiguous, as is the Bayeux Tapestry, which simply depicts Edward pointing at a man thought to represent Harold. When the Witenagemot convened the next day they selected Harold to succeed, and his coronation followed on 6 January, most likely held in Westminster Abbey; though no evidence from the time survives to confirm this. Although later Norman sources point to the suddenness of this coronation, the reason may have been that all the nobles of the land were present at Westminster for the feast of Epiphany, and not because of any usurpation of the throne on Harold's part.
In early January 1066, hearing of Harold's coronation, Duke William II of Normandy began plans to invade England, building 700 warships and transports at Dives-sur-Mer on the Normandy coast. Initially, William could not get support for the invasion but, claiming that Harold had sworn on sacred relics to support his claim to the throne after having been shipwrecked at Ponthieu, William received the Church's blessing and nobles flocked to his cause. In anticipation of the invasion, Harold assembled his troops on the Isle of Wight, but the invasion fleet remained in port for almost seven months, perhaps due to unfavourable winds. On 8 September, with provisions running out, Harold disbanded his army and returned to London. On the same day Harald Hardrada of Norway, who also claimed the English crown joined Tostig and invaded, landing his fleet at the mouth of the Tyne.
The invading forces of Hardrada and Tostig defeated the English earls, Edwin of Mercia and Morcar of Northumbria, at the Battle of Fulford near York on 20 September 1066. They in turn were defeated and slain by Harold's army five days later at the Battle of Stamford Bridge, Harold having led his army north on a forced march from London in four days and having caught them by surprise. According to Snorri Sturluson, before the battle a man bravely rode up to Harald Hardrada and Tostig and offered Tostig his earldom if he would but turn on Harald Hardrada. When Tostig asked what his brother Harold would be willing to give Harald Hardrada for his trouble, the rider replied that he would be given seven feet of ground as he was taller than other men. Harald Hardrada was impressed with the rider and asked Tostig his name. Tostig replied that the rider was none other than Harold Godwinson. According to Henry of Huntingdon, "Six feet of ground or as much more as he needs, as he is taller than most men", was Harold's response. It is, however, unknown whether this conversation ever took place.
Battle of Hastings.
On 12 September William's fleet sailed. Several ships sank in storms, and the fleet was forced to take shelter at Saint-Valery-sur-Somme and wait for the wind to change. On 27 September the Norman fleet finally set sail for England, arriving, it is believed, the following day at Pevensey on the coast of East Sussex. Harold's army marched 241 miles (386 kilometres) to intercept William, who had landed perhaps 7000 men in Sussex, southern England. Harold established his army in hastily built earthworks near Hastings. The two armies clashed at the Battle of Hastings, at Senlac Hill (near the present town of Battle) close by Hastings on 14 October, where after nine hours of hard fighting and probably less than 30 minutes from victory, Harold was killed and his forces routed. His brothers Gyrth and Leofwine were also killed in the battle.
Death.
The account of the battle, "Carmen de Hastingae Proelio" ("Song of the Battle of Hastings"), said to have been written shortly after the battle by Guy, Bishop of Amiens, says that Harold was killed by four knights, probably including Duke William, and his body brutally dismembered. Amatus of Montecassino's "L'Ystoire de li Normant" ("History of the Normans"), written thirty years after the battle of Hastings, is the first report of Harold being shot in the eye with an arrow. Later accounts reflect one or both of these two versions. A figure in the panel of the Bayeux Tapestry with the inscription "Harold Rex Interfectus Est" (Harold the King is killed) is depicted gripping an arrow that has struck his eye, but some historians have questioned whether this man is intended to be Harold, or if Harold is intended as the next figure lying to the right almost prone, being mutilated beneath a horse's hooves. Etchings made of the Tapestry in the 1730s show the standing figure with differing objects. Benoît's 1729 sketch shows only a dotted line indicating stitch marks without any indication of fletching (all other arrows in the Tapestry are fletched). Bernard de Montfaucon's 1730 engraving has a solid line resembling a spear being held overhand matching the manner of the figure to the left. Stothard's 1819 water-colour drawing has, for the first time, a fletched arrow in the figure's eye. Although not apparent in the earlier depictions, the Tapestry today has stitch marks indicating the fallen figure once had an arrow in its eye. It has been proposed that the second figure once had an arrow added by over-enthusiastic nineteenth-century restorers that was later unstitched. A further suggestion is that both accounts are accurate, and that Harold suffered first the eye wound, then the mutilation, and the Tapestry is depicting both in sequence.
Burial and legacy.
The account of the contemporary chronicler William of Poitiers, states that the body of Harold was given to William Malet for burial:
"The two brothers of the King were found near him and Harold himself, stripped of all badges of honour, could not be identified by his face but only by certain marks on his body. His corpse was brought into the Duke's camp, and William gave it for burial to William, surnamed Malet, and not to Harold's mother, who offered for the body of her beloved son its weight in gold. For the Duke thought it unseemly to receive money for such merchandise, and equally he considered it wrong that Harold should be buried as his mother wished, since so many men lay unburied because of his avarice. They said in jest that he who had guarded the coast with such insensate zeal should be buried by the seashore".
Another source states that Harold's widow, Edith Swannesha, was called to identify the body, which she did by some private mark known only to her. Harold's strong association with Bosham, his birthplace, and the discovery in 1954 of an Anglo-Saxon coffin in the church there, has led some to suggest it as the place of King Harold's burial. A request to exhume a grave in Bosham church was refused by the Diocese of Chichester in December 2003, the Chancellor having ruled that the chances of establishing the identity of the body as Harold's were too slim to justify disturbing a burial place. A prior exhumation had revealed the remains of a man, estimated at up to 60 years of age from photographs of the remains, lacking a head, one leg and the lower part of his other leg, a description consistent with the fate of the king as recorded in the Carmen. The poem also claims Harold was buried by the sea, which is consistent with William of Poitiers' account and with the identification of the grave at Bosham Church that is only yards from Chichester Harbour and in sight of the English Channel.
There were legends of Harold's body being given a proper funeral years later in his church of Waltham Holy Cross in Essex, which he had refounded in 1060. Legends grew up that Harold had not died at Hastings but instead fled England or that he later ended his life as a hermit at Chester or Canterbury.
Harold's son Ulf, along with Morcar and two others, were released from prison by King William as he lay dying in 1087. Ulf threw his lot in with Robert Curthose, who knighted him, and then disappeared from history. Two of Harold's other sons, Godwine and Edmund, invaded England in 1068 and 1069 with the aid of Diarmait mac Máel na mBó. They raided Cornwall as late as 1082, but died in obscurity in Ireland.
References.
</dl>

</doc>
<doc id="40149" url="http://en.wikipedia.org/wiki?curid=40149" title="Godwin, Earl of Wessex">
Godwin, Earl of Wessex

Godwin of Wessex (Old English: "Godƿin") (1001 – 15 April 1053) was one of the most powerful earls in England under the Danish king Cnut the Great and his successors. Cnut made him the first Earl of Wessex. Godwin was the father of King Harold Godwinson and Edith of Wessex, wife of King Edward the Confessor.
Rise to power.
Godwin's father was probably Wulfnoth Cild, who was a thegn of Sussex. His origin is unknown but 'Cild' normally refers to a man of rank. In 1009 Wulfnoth was accused of unknown crimes at a muster of Æthelred the Unready's fleet and fled with twenty ships; the ships sent to pursue him were destroyed in a storm. Godwin was probably an adherent of Æthelred's eldest son, Æthelstan, who left him an estate when he died in 1014. This estate in Compton, Sussex, had once belonged to Godwin’s father. Although he is now always thought of as connected with Wessex, Godwin had probably been raised in Sussex, not Wessex and was probably a native of Sussex.
After Cnut seized the throne in 1016, Godwin's rise was rapid. By 1018 he was an earl, probably of eastern Wessex, and then by around 1020 of all Wessex. Between 1019 and 1023 he accompanied Cnut on an expedition to Denmark, where he distinguished himself, and shortly afterwards married Gytha, the sister of the Danish earl, Ulf, who was married to Cnut's sister, Estrid.
Height of power: support of Harold.
On 12 November 1035, Cnut died. His kingdoms were divided among three rival rulers. Harold Harefoot, Cnut's illegitimate son with Ælfgifu of Northampton, seized the throne of England. Harthacnut, Cnut's legitimate son with Emma of Normandy, reigned in Denmark. Norway rebelled under Magnus the Noble. In 1035, the throne of England was reportedly claimed by Alfred Ætheling, younger son of Emma of Normandy and Æthelred the Unready, and half-brother of Harthacnut. Godwin is reported to have either captured Alfred himself or to have deceived him by pretending to be his ally and then surrendering him to the forces of Harold Harefoot. Either way Alfred was blinded and soon died at Ely.
In 1040, Harold Harefoot died and Godwin supported the accession of his half-brother Harthacnut to the throne of England. When Harthacnut himself died in 1042 Godwin supported the claim of Æthelred's last surviving son Edward the Confessor to the throne. Edward had spent most of the previous thirty years in Normandy. His reign restored the native royal house of Wessex to the throne of England.
Later conflicts, decline, and death.
Despite his alleged responsibility for the death of Edward's brother Alfred, Godwin secured the marriage of his daughter Edith (Eadgyth) to Edward in 1045. As Edward drew advisors, nobles and priests from his former place of refuge in a bid to develop his own power base, Godwin soon became the leader of opposition to growing Norman influence. After a violent clash between the people of Dover and the visiting Eustace II, Count of Boulogne, Edward's brother-in-law, Godwin was ordered to punish the people of Dover (as he and Leofric, Earl of Mercia had done in Worcester, in Leofric's own earldom). This time, however, Godwin refused, choosing to champion his own countrymen against a (visiting) foreign ruler and his own king. Edward saw this as a test of power, and managed to enlist the support of Siward, Earl of Northumbria and Earl Leofric. Godwin and his sons were exiled from the kingdom in September 1051. However, they returned the following year with an armed force, which gained the support of the navy, burghers, and peasants, so compelling Edward to restore his earldom. This however set a precedent to be followed by a rival earl some years later, and then by Godwin's own son, Tostig, in 1066.
On 15 April 1053 Godwin died suddenly, after collapsing during a royal banquet at Winchester. Some colourful accounts claim that he choked on a piece of bread while denying any disloyalty to the king. However this appears to be later Norman propaganda. Contemporary accounts indicate that he just had a sudden illness, possibly a stroke.
His son Harold succeeded him as Earl of Wessex, an area then covering roughly the southernmost third of England. With the death of Earl Siward (1055) and later Earl Ælfgar (1062), the children of Godwin were poised to assume sole control. Tostig was helped into the earldom of Northumbria, thus controlling the north. The Mercian earl was sidelined, especially after Harold and Tostig broke the Welsh-Mercian alliance in 1063. Harold later succeeded Edward the Confessor and became King of England in his own right in 1066. At this point, both Harold's remaining brothers in England were earls in their own right, Harold was himself king and in control of Wessex, and he had married the sister of Earl Edwin of Mercia and Morcar, Earl of Northumbria (who had replaced Tostig). Godwin's family looked set to inaugurate a new royal dynasty, but instead Harold was overthrown and killed in the Norman Conquest.
In popular culture.
Godwin has been portrayed by Torin Thatcher in the film "Lady Godiva of Coventry" (1955) and by Bill Wallis in an episode of the British educational TV series "Historyonics" entitled "1066" (2004). Godwin is also the lead character of Justin Hill's novel, Shieldwall (2011).

</doc>
<doc id="40151" url="http://en.wikipedia.org/wiki?curid=40151" title="Alappuzha district">
Alappuzha district

Alappuzha (  ) (Malayalam: ആലപ്പുഴ) is one of the 14 districts in the state of Kerala in India. It was formed as Alleppey District on August 17, 1957. The name of the district was officially changed to Alappuzha in 1990. The district is a widely known tourist destination and is well known for its coir factories. Most of Kerala's coir industries are situated in and around Alappuzha.
The district is also known for its communist traditions. It is home to the Punnapra-Vayalar uprising against the British and also the revolt against the Feudal raj. Alappuzha is strongly connected by waterways to various other parts of Kerala, including the famous tourist destination, Kumarakom.
History.
The present town owes its existence to Raja Kesavadas in the second half of the 18th century but the district of Alappuzha figures in classical literature. Kuttanad, the rice bowl of Kerala, was well-known from the early periods of the Sangam age. History says Alappuzha had trade relations with ancient Greece and Rome in B.C and in the Middle Ages. 
Early members of the Chera dynasty had their home in Kuttanad and were called Kuttuvans. There is archaeological evidence of the early period of the district, such as stone inscriptions and monuments, in temples and caves, as well as in literary works such as "Unnuneeli Sandesam". The famous literary work of this period was ‘Ascharya Choodamani’ a Sanskrit drama written by Sakthibhadra who was a scholar of Chengannur grammar. The kingdom of Chempakasseri was at its zenith during the reign of Pooradam Thirunal Devanarayana, a great scholar and a poet who was the author of ‘Vedantha Retnamala’, a commentary on the first verse of Bhagavat Geetha. It is said that Sreekrishna Swami temple, at Ambalappuzha was constructed and the idol of Lord Krishna installed during that time. It is believed that Melpathur Narayana Bhattathiri, Neelakanta Deekshithar and Kumaran Namboothiri were eminent scholars who patronized his court.
In the 17th century the Portuguese power declined and the Dutch had a predominant position in the principalities of this district. The church located at Kokkamangalam or Kokkothamangalam was one of the seven churches founded by St.Thomas, one of the twelve disciples of Jesus Christ. The picturesque CSI Christ Church in Alappuzha town was built in 1818 by the first CMS (Church Missionary Society) missionary to India, Rev. Thomas Norton. It was the first Anglican Church to be established in the erstwhile state of Travancore.
It was at that time Maharaja Marthandavarma, the ‘Maker of modern Travancore’ interfered in the political affairs of those principalities. Marthandavarma Maharaja had a remarkable role in the internal progress of the district. The Krishnapuram Palace, which is now a protected monument of the State Archaeology Department, was constructed during that period. It was at that time that the great and talented poet Kunjan Nambiar was installed in the court. He was known as the ‘Maker of modern Alleppey’ and played a key role in making Alappuzha a premier port town of Travancore.
During the reign of Balaramavarma Maharaja, Velu Thampi Dalava took keen interest in the development of the town and port. He brought the whole area of the island Pathiramanal under coconut cultivation and large tracts under paddy cultivation. The role of Velu Thampi Dalava in the development of Alappuzha is worth mentioning. In the 19th century the district attained progress in all spheres.
The first modern factory for the manufacture of coir mats and mattings was also established in 1859 at Alappuzha. The town Improvement Committee was set up in 1894.
This district had a prominent role in the freedom struggle of the country. The campaign for the eradication of untouchability was organized much earlier in this district by T.K. Madhavan, a fearless journalist and in 1925 the approach roads to the temples, especially in Ambalappuzha Sree Krishna Swami temple were thrown open to the Hindus of all castes. The district also witnessed the ‘Nivarthana’ movement which was started as a protest against the constitutional repression in 1932. The first political strike in Kerala was held at Alappuzha in 1938.
Geography.
Alappuzha is on a landmass between the broad Arabian sea and a network of rivers flowing into it.
Panchayats.
The panchayats in the district are:
Municipalities.
The municipalities in the district are:
Vehicle registration.
Following are the vehicle registrations in Alappuzha District:
Old structure:-
Following are the old registration numbers in Alappuzha District:-
Demographics.
According to the 2011 census, Alappuzha district has a population of 2,121,943, roughly equal to the nation of Namibia or the US state of New Mexico. This gives it a ranking of 216th in India (out of a total of 640). The district has a population density of 1501 PD/sqkm . Its population growth rate over the decade 2001-2011 was 0.61%. Alappuzha has a sex ratio of 1100 females for every 1000 males, and a literacy rate of 96.26%.
In the 2001 Indian Census, the Hindu population is 69.08%, Christian 20.94, and Muslim 9.86.
It has the highest population density among all districts of the state. It is 29.46% urbanized, and is the smallest district in Kerala.
Culture.
"Snake boat races" are the most significant traditional event in Alleppey. These spectacular regattas are usually held between August and October, and involve long thin boats powered by up to 120 oarsmen. The most famous snake boat race is the Nehru Trophy Boat Race.
Chemmeen was filmed in two villages in Alappuzha. In the opening credits, a written statement in Malayalam thanks the people of both villages.
Tourism.
The name Alappuzha is derived from 'Aal(Sea)+ puzhai(River-mouth)(The joining place of a river and the sea)' (Malayalam/Tamil ). Alappuzha is one of the most important tourist centres in the state, with a large network of inland canals earning it the sobriquet "Venice of the East". These large networks of canals provide Alleppey its lifeline. Alappuzha was one of the busiest centers of trade in the past with one of the best-known ports along the Malabar coast. Even today it retains its charm as the center for Coir carpet industries and prawn farming. Alappuzha, the ideal headquarters for backwater tourism as well as for visits to the lovely church filled town of Kottayam, and the town of Aranmula, are famous for their historic Aranmula Snake Boat Race which is an annual event. Chengannur in Alappuzha is the nearest railway station to Sabarimala. The Krishnapuram Palace is in Kayamkulam. The Buddha idol, Saradamandiram are the main attraction of Mavelikkara. The Buddha statue is in a seated posture, resembling Padmasana. A feature common to the idols is that hair has not been engraved on the head. Studies by the Archaeology Department have not been able to explain the absence of hair which is common in Buddha statues of the Gandhara and Mathura tradition. The head has markings resembling a headgear. Though the department has made a pagoda-like structure for the statue, no information on the idol is available to tourists who visit the area. Local people in the area light lamps before the idol. The idol at Mavelikara is 4 ft high and is perhaps, the biggest. The engravings on the head resemble a helmet of Greek statues. The mark of a sacred thread is visible on the body. Another feature is the marking of a shawl on one shoulder. Here the Archaeological Department has put up a board specifying the age of the statue. Saradamandiram was the residence of Keralapanini.
Alappuzha is also known for its snake-boat races held on the second Saturday of August, every year. This competition; the Nehru boat race takes its name from India's first prime minister Jawaharlal Nehru, which was inaugurated in 1952. It is excitement all around as snake-boats, each manned by over a hundred oarsmen, cut through the waters like wind. The event is a tremendous success with tourists and the local population alike.
The boat cruise along the backwaters of Alappuzha gives one a first hand experience of the lifestyle; toddy tapping, fishing for small fry, Coir-making, prawn farming etc., which remains more or less unchanged over the years.
The latest addition to Alappuzha is the which features countless arts and artifacts. Revi Karunakaran was the architect of a modern Coir industry that still employs more than 500,000 people in the state of Kerala. The objects featured at the Museum were collected by his family over three generations and features unique artistic pieces from all parts of the world.
Alappuzha, the district headquarters, is a town with picturesque canals, backwaters and lagoons, was described as the "Venice of the East" by Lord Curzon.
Kuttanadu.
Kuttanad or Kuttanadu is an area of Alappuzha District, densely covered with waterways. Kuttanad is famous because of its paddy fields and farmers dedicated to the growth of paddy. It was once called the "Keralathinte Nellara", which means "rice bowl of Kerala". Many factors such as expense, labor shortage etc. seriously affected the agriculture in this region. Many former rice fields are now used for other crops which require much lesser investment. Kuttanadu is the birthplace of literary legend Thakazhi Sivasankara Pillai.
Festivals.
Chettikulangara Bharani is the most important festival in Alappuzha district. The festival is one among the important temple festivals of Kerala. A Chettikulagara Bhagavathi Temple, a temple dedicated to the Goddess Bhagavathi is about four kilometers from Mavelikkara. The festival occurs on the Bharani asterism in February/March. The main rituals of the festival are the 'Kuthiyottam' and 'Kettukazcha'. The 'Kuthiyottam' features a procession of young boys who have observed rigorous ritual penance. Traditional drums, music and glittering ornamental parasols accompany this procession of boys who dance in a trance.
'Chirappu Mahotsavam' is a big occasion at Mullackal Temple in December. Christmas comes in between the festival and Alappuzha town is a really happening place at the time. The streets are full of wandering markets and entertainment ventures like circuses and exhibitions. The streets are be crowded throughout the month and there is be a 'Shiveli' or the magnificent display of nine Tuskers accompanied by the 'Chenda' and the 'Panchavadyam' music.
Padanilam Sivarathri is another important religious event in Alappuzha district. This festival is held every year in the Padanilam Parabrahma Temple. The temple is situated in the small town of Padanilam. Padanilam is situated 'about 16 km from Mavelikkara town. This place can also be called the festival Village of Alappuzha because Padanilam witnesses a large number of festivals every year including vrischika mahotsavam and irupathiyetttamonam. Padanilam is a place of religious unity.
A grand annual festival is celebrated at the unique Nagaraja Temple in October/November. Another festival celebrated by the temple is a one-day Thaipooyan Kavadi. The famous Chandanakudam is celebrated at the Kidangam-Parampu Temple during December every year. Kottamkulangara Temple in Alappuzha has two festive seasons in February and March, because of the two deities with separate flag masts in the same compound wall.
The famous Kandamangalam Rajarajeshwari Temple is located in Kadakkarappally, Cherthala 1 km west of Thankey junction on NH 47. The annual festival comes in March–April. Chikkara, offering of children to the mother goddess during the festival, is the major attraction. The Chamanju Valathu of children starts on the 2nd day of the festival and lasts till the 8th day. Procession named Thalappoli start on the flag-hoisting day itself. The holy bath (Aarattu) of the goddess is held in a pool within the temple compound on the 10th day of festival. Elephant processions, fireworks, stage shows, etc. are major events that attract thousands of devotees and others.
The churches here celebrate grand annual feasts. The 'Arthunkal Perunnal' feast is celebrated at the Arthunkal Church. The famous regatta forms part of many festivals here in many places. The annual Vallam Kali (Nehru Trophy Boat Race) is held in the backwaters in the month of September associated with the Onam festival. The main attraction is the Chundan Vallam (Snake Boat) race, in which a number of contestants are in the running for the famous Prime Minister's trophy, a trophy donated by Jawaharlal Nehru, the first Prime Minister of India. Another important celebration in Alappuzha is the "Beach Festival", held from December 30 to January 2. The annual festival conducted in Champakulam "Valiya Palli" is another big festival.

</doc>
<doc id="40156" url="http://en.wikipedia.org/wiki?curid=40156" title="Khlysts">
Khlysts

Khlysts or Khlysty (Хлысты in Russian) was an underground sect from late 17th to early 20th century that split off the Russian Orthodox Church and belonged to the Spiritual Christians (духовные христиане) tendency.
Definition.
'Khlyst', the name commonly applied to them, is a distortion of the name they used; the original name was the invented word Христововеры (Khristovovery, "Christ-believers") or Христы (Khristy); their critics corrupted the name, mixing it with the word хлыст (khlyst), meaning "a whip".
It is also possible that the word 'Khlysty' is related to the Greek word 'χιλιασταί' (=millennialists, chiliasts; pronounced 'khiliasté'), or with "klyster", meaning "one that purges". Millennialism has many different branches and sects and their teachings have common points with those of the Khlysty.
History.
It is said to have been founded by a peasant, Daniil Filippovich, (or Filippov), of Kostroma. The Khlysty renounced priesthood, holy books and veneration of the saints (excluding the Theotokos). They believed in a possibility of direct communication with the Holy Spirit and of His embodiment in living people. Curiously enough, they allowed their members to attend Orthodox churches. The central idea of Khlystys' ideology was to practice asceticism. Khlysty practiced the attainment of divine grace for sin in ecstatic rituals (called "радéния", or radeniya) that were rumored to sometimes turn into sexual orgies.
Flagellation was also rumored, possibly due to the similarity of their name to the word for "whip".
Secret Khlysty cells existed throughout pre-revolutionary Russia (with approximately 40,000 followers in total); they were most common in the factories of the Perm district. Each cell was normally led by a male and a female leader, who were called the "Christ" and the "Mother of God" respectively. The cells themselves were referred to as 'Arks' among members and messages were carried between them clandestinely in order to facilitate communication. They were often subject to persecution and perceived as a subversive element by the nineteenth century Russian authorities and ecclesiastical bodies.
Rasputin.
In 1910, Grigori Rasputin was accused of having been a Khlyst by Sofia Ivanovna Tyutcheva, a governess of the Grand Duchesses of Russia, after being horrified that Rasputin was allowed access by the Tsar to the nursery of the Grand Duchesses, when the four girls were in their nightgowns.
C.L. Sulzberger, in his book "The Fall of Eagles", says that Rasputin "adopted the philosophy (if not proven membership)," of the Khlysts. Sulzberger goes on to say the Khlysts', "...foremost idea was that salvation could be attained only by total repentance and that this became far more achievable for one who had truly transgressed. 'Sin in order that you may obtain forgiveness,' was the practical side of the Khlysty."
Rasputin's daughter contested these claims, writing that her father investigated but ultimately rejected the sect.
Soviet era.
The number of cells dropped drastically in the Soviet times. However, a few secluded Khlysty communities existed in Soviet Russia in Tambov, Kuibyshev, Orenburg and Northern Caucasus and in Soviet Ukraine.

</doc>
<doc id="40157" url="http://en.wikipedia.org/wiki?curid=40157" title="Russian Orthodox Church">
Russian Orthodox Church

The Russian Orthodox Church (ROC; Russian: Русская Православная Церковь, "Russkaya Pravoslavnaya Tserkov"), alternatively legally known as the Moscow Patriarchate (Russian: Московский Патриархат, Moskovskiy Patriarkhat), also known in English as the "Orthodox Christian Church of Russia", is one of the autocephalous Eastern Orthodox churches, in full communion with other Eastern Orthodox churches. The ROC officially ranks fifth in the Orthodox order of precedence, right under the four ancient Greek Patriarchates of the Greek Orthodox Church, those of Constantinople, Alexandria, Antioch, and Jerusalem. The Primate of the ROC is the Patriarch of Moscow and all Rus'.
The ROC currently claims its exclusive jurisdiction over the Orthodox Christians, irrespective of their ethnic background, who reside in the former member republics of the USSR, excluding Georgia and Armenia, although this claim is disputed in such countries as Estonia and Moldova and consequently parallel canonical Orthodox jurisdictions exist in those: Estonian Apostolic Orthodox Church and Metropolis of Bessarabia, respectively. It also exercises ecclesiastical jurisdiction over the autonomous Church of Japan and the Orthodox Christians resident in the People's Republic of China. The ROC branches in Belarus, Estonia, Latvia, Moldova and Ukraine since the 1990s enjoy various degrees of self-government, albeit short of the status of formal ecclesiastical autonomy. In Ukraine, ROC (represented by the Ukrainian Orthodox Church) has tensions with schismatic groups supported by the current government, while it enjoys the position of numerically dominant religious organisation.
The ROC should not be confused with the Orthodox Church in America (OCA), another autocephalous Orthodox Church (since 1970, albeit not universally recognised in this status), that traces its existence in North America to the time of the Russian missionaries in Alaska (then part of the Russian Empire) in the late 18th century, and still largely adheres to the ROC liturgical tradition.
The ROC should also not be confused with the Russian Orthodox Church Outside Russia (also known as the Russian Orthodox Church Abroad, or ROCOR), headquartered in New York, the U.S.A. The ROCOR was instituted in the 1920s by Russian communities outside then Communist Russia, which refused to recognize the authority of the Moscow Patriarchate then "de facto" headed by Metropolitan Sergius Stragorodsky. The two Churches reconciled on May 17, 2007; the ROCOR is now a self-governing part of the Russian Orthodox Church.
History.
The Kievan period.
The Christian community that evolved to what is now known as the Russian Orthodox Church is traditionally said to have been founded by the Apostle Andrew, who is thought to have visited Scythia and Greek colonies along the northern coast of the Black Sea. According to one of the legends, Andrew reached the future location of Kiev and foretold the foundation of a great Christian city. The spot where he reportedly erected a cross is now marked by St. Andrew's Cathedral.
By the end of the first millennium AD, eastern Slavic lands started to come under the cultural influence of the Eastern Roman Empire. In 863–69, the Byzantine Greek monks Saint Cyril and Saint Methodius, both from Greek Macedonia, translated parts of the Bible into Old Church Slavonic language for the first time, paving the way for the Christianization of the Slavs and Slavicized peoples of Eastern Europe, the Balkans, and Southern Russia. There is evidence that the first Christian bishop was sent to Novgorod from Constantinople either by Patriarch Photius or Patriarch Ignatios, circa 866–67 AD.
By the mid-10th century, there was already a Christian community among Kievan nobility, under the leadership of Byzantine Greek priests, although paganism remained the dominant religion. Princess Olga of Kiev was the first ruler of Kievan Rus to convert to Christianity, either in 945 or 957. Her grandson, Vladimir the Great, made Kievan Rus' a Christian state.
As a result of the Christianization of Kievan Rus' in 988, Prince Vladimir I of Kiev officially adopted Byzantine Greek Rite Christianity — the religion of the Eastern Roman Empire — as the state religion of Kievan Rus'. This date is often considered the official birthday of the Russian Orthodox Church. Thus, in 1988, the Church celebrated its millennial anniversary. It therefore traces its apostolic succession through the Patriarch of Constantinople. 
The Kievan church was a junior metropolitanate of the Patriarchate of Constantinople and the Ecumenical patriarch appointed the metropolitan, who usually was a Greek, who governed the Church of Rus'. The Metropolitan's residence was originally located in Kiev itself, the capital of the medieval Russian state.
Transfer of the see to Moscow. "De facto" independence of the Moscow Church.
As Kiev was losing its political, cultural, and economical significance due to the Mongol invasion, Metropolitan Maximus moved to Vladimir in 1299; his successor, Metropolitan Peter moved the residence to Moscow in 1325.
Following the tribulations of the Mongol invasion, the Russian Church was pivotal in the survival and life of the Russian state. Despite the politically motivated murders of Mikhail of Chernigov and Mikhail of Tver, the Mongols were generally tolerant and even granted tax exemption to the Church. Such holy figures as Sergius of Radonezh and Metropolitan Alexis helped the country to withstand years of Tatar oppression, and to expand both economically and spiritually. The Trinity monastery founded by Sergius of Radonezh became the setting for the flourishing of spiritual art, exemplified by the work of Andrey Rublev, among others. The followers of Sergius founded four hundred monasteries, thus greatly extending the geographical extent of the Grand Duchy of Moscow.
In 1439, at the Council of Florence, some Orthodox hierarchs from Byzantium as well as Metropolitan Isidore, who represented the Russian Church, signed a union with the Roman Church, whereby the Eastern Church would recognise the primacy of the Pope. However, the Moscow Prince Vasili II rejected the act of the Council of Florence brought to Moscow by Isidore in March 1441. Isidore was in the same year removed from his position as an apostate and expelled from Moscow. The Russian metropolitanate remained effectively vacant for the next few years due largely to the dominance of Uniates in Constantinople then. In December 1448, Jonas, a Russian bishop, was installed by the Council of Russian bishops in Moscow as Metropolitan of Kiev and All Russia (with permanent residence in Moscow) without the consent from Constantinople. This occurred five years prior to the fall of Constantinople in 1453 and, unintentionally, signified the beginning of an effectively independent church structure in the Moscow (North-Eastern Russian) part of the Russian Church. Subsequently, there developed a theory in Moscow that saw Moscow as the Third Rome, the legitimate successor to Constantinople, and the Primate of the Moscow Church as head of all the Russian Church. Meanwhile, the newly established in 1458 Russian Orthodox (initially Uniate) metropolitanate in Kiev (then in the Grand Duchy of Lithuania and subsequently in the Polish–Lithuanian Commonwealth) continued under the jurisdiction of the Ecumenical See until 1686, when it was transferred to the jurisdiction of Moscow.
The reign of Ivan III and his successor was plagued by a number of heresies and controversies. One party, led by Nil Sorsky and Vassian Kosoy, called for the secularisation of monastic properties. They were opposed by the influential Joseph of Volotsk, who defended ecclesiastical ownership of land and property. The sovereign's position fluctuated, but eventually he threw his support to Joseph. New sects sprang up, some of which showed a tendency to revert to Mosaic law: for instance, the archpriest Aleksei converted to Judaism after meeting a certain Zechariah the Jew.
In the 1540s, Metropolitan Macarius codified Russian hagiography and convened a number of church synods, which culminated in the Hundred Chapter Council of 1551. This Council unified church ceremonies and duties throughout the Moscow Church. At the demand of the church hierarchy, the government lost its jurisdiction over ecclesiastics. Reinforced by these reforms, the Moscow Church felt powerful enough to occasionally challenge the policies of the tsar. Metropolitan Philip, in particular, decried the abuses of Ivan the Terrible, who eventually engineered his deposition and murder.
Autocephaly and schism.
During the reign of Tsar Fyodor I his brother-in-law Boris Godunov contacted the Ecumenical Patriarch, who "was much embarrassed for want of funds," with a view to establishing a patriarchal see in Moscow. As a result of Godunov's efforts, Metropolitan Job of Moscow became in 1589 the first Patriarch of Moscow and All Rus', making the Russian Church autocephalous. The four other patriarchs have recognized the Moscow Patriarchate as one of the five honourable Patriarchates. During the next half a century, when the tsardom was weak, the patriarchs (notably Hermogenes and Philaret) would help run the state along with (and sometimes instead of) the tsars.
At the urging of the Zealots of Piety, in 1652 Patriarch Nikon resolved to centralize power that had been distributed locally, while conforming Russian Orthodox rites and rituals to those of the Greek Orthodox Church, as interpreted by pundits from the Kiev Ecclesiastical Academy. For instance he insisted that Russian Christians cross themselves with three fingers, rather than the then-traditional two. This aroused antipathy among a substantial section of believers, who saw the changed rites as heresy, although the extent to which these changes can be regarded as minor or major ritual significance remains open to debate. After the implementation of these innovations at the church council of 1666–1667, the Church anathematized and suppressed those who acted contrary to them with the support of Muscovite state power. These traditionalists became known as "Old Believers" or "Old Ritualists".
Although Nikon's far-flung ambitions of steering the country to a theocratic form of government precipitated his defrocking and exile, Tsar Aleksey deemed it reasonable to uphold many of his innovations. During the Schism of the Russian Church, the Old Ritualists were separated from the main body of the Orthodox Church. Archpriest Avvakum Petrov and many other opponents of the church reforms were burned at the stake, either forcibly or voluntarily. Another prominent figure within the Old Ritualists' movement, Boyarynya Morozova, was starved to death in 1675. Others escaped from the government persecutions to Siberia and other inhospitable lands, where they would live in semi-seclusion until modern times.
Peter the First.
With the ascension of Emperor Peter the Great to the throne of Russia (1682–1725), with his radical modernization of Russian government, army, dress and manners, Russia became a formidable political power.
Expansion.
In the late 17th and early 18th centuries, the Russian Orthodox Church experienced a vast geographic expansion. In the following two centuries, missionary efforts stretched out across Siberia into Alaska, then into California, which would become part of the United States. Eminent people on that missionary effort included St. Innocent of Irkutsk and St. Herman of Alaska. In emulation of Stephen of Perm, they learned local languages and translated gospels and hymns. Sometimes those translations required the invention of new systems of transcription.
In the aftermath of the Treaty of Pereyaslav, the Ottomans (supposedly acting on behalf of the Russian regent Sophia Alekseyevna) pressured the Patriarch of Constantinople into transferring the Metropoly of Kiev from the jurisdiction of Constantinople to that of Moscow. The controversial transfer brought millions of faithful and half a dozen dioceses under the pastoral and administrative care of the Patriarch of Moscow and all Rus', leading to the significant Ukrainian domination of the Russian Orthodox Church, which continued well into the 18th century, with Theophanes Prokopovich, Epiphanius Slavinetsky, Stephen Yavorsky and Demetrius of Rostov being among the most notable representatives of this trend.
In 1700, after Patriarch Adrian's death, Peter the Great prevented a successor from being named, and in 1721, following the advice of Feofan Prokopovich, Archbishop of Pskov, the Holy and Supreme Synod was established under Archbishop Stephen Yavorsky to govern the church instead of a single primate. This was the situation until shortly after the Russian Revolution of 1917, at which time the Local Council (more than half of its members being lay persons) adopted the decision to restore the Patriarchy. On November 5 (according to the Julian calendar) a new patriarch, Tikhon, was named through casting lots.
The late 18th century saw the rise of "starchestvo" under Paisiy Velichkovsky and his disciples at the Optina Monastery. This marked a beginning of a significant spiritual revival in the Russian Church after a lengthy period of modernization, personified by such figures as Demetrius of Rostov and Platon of Moscow. Aleksey Khomyakov, Ivan Kireevsky and other lay theologians with Slavophile leanings elaborated some key concepts of the renovated Orthodox doctrine, including that of "sobornost". The resurgence of Eastern Orthodoxy was reflected in Russian literature, an example is the figure of Starets Zosima in Fyodor Dostoyevsky's "Brothers Karamazov".
Fin-de-siècle religious renaissance.
During the final decades of the imperial order in Russia many educated Russians sought to return to the church and tried to bring their faith back to life. No less evident were non-conformist paths of spiritual searching known as "God-Seeking". Writers, artists and intellectuals in large numbers were drawn to private prayer, mysticism, spiritualism, theosophy and Eastern religions. A fascination with primitive feeling, with the unconscious and the mythic was apparent, along with visions of coming catastrophes and redemption.
In 1909, a volume of essays appeared under the title "Vekhi" ("Milestones" or "Landmarks"), authored by a group of leading left-wing intellectuals, including Sergei Bulgakov, Peter Struve and former Marxists. They bluntly repudiated the materialism and atheism that had dominated the thought of the intelligentsia for generations as leading inevitably to failure and moral disaster. The essays created a sensation.
It is possible to see a similarly renewed vigor and variety in religious life and spirituality among the lower classes, especially after the upheavals of 1905. Among the peasantry there was widespread interest in spiritual-ethical literature and non-conformist moral-spiritual movements, an upsurge in pilgrimage and other devotions to sacred spaces and objects (especially icons), persistent beliefs in the presence and power of the supernatural (apparitions, possession, walking-dead, demons, spirits, miracles and magic), the renewed vitality of local "ecclesial communities" actively shaping their own ritual and spiritual lives, sometimes in the absence of clergy, and defining their own sacred places and forms of piety. Also apparent was the proliferation of what the Orthodox establishment branded as "sectarianism", including both non-Orthodox Christian denominations, notably Baptists, and various forms of popular Orthodoxy and mysticism.
Russian revolution.
In 1914 there were 55,173 Russian Orthodox churches and 29,593 chapels, 112,629 priests and deacons, 550 monasteries and 475 convents with a total of 95,259 monks and nuns in Russia. 
The year 1917 was a major turning point in Russian history, and also the Russian Orthodox Church. The Russian empire was dissolved and the Tsarist government - which had granted the Church numerous privileges - was overthrown. After a few months of political turmoil, the Bolsheviks took power in October 1917 and declared a separation of church and state. Thus the Russian Orthodox Church found itself without official state backing for the first time in its history. One of the first decrees of the new Communist government (issued in January 1918) declared freedom from "religious and anti-religious propaganda". This led to a marked decline in the power and influence of the Church. The Church was also caught in the crossfire of the Russian Civil War that began later the same year, and many leaders of the Church supported what would ultimately turn out to be the losing side (the White movement).
The Russian Orthodox Church supported the White Army in the Russian Civil War (see White movement) after the October Revolution. This may have further strengthened the Bolshevik antipathy against the church. Actually as early as 1905, Lenin, leader of the Bolshevik party, berated religion in Novaya Zhizn in 1905 "... Religion is opium for the people. Religion is a sort of spiritual booze, in which the slaves of capital drown their human image, their demand for a life more or less worthy of man..."
Even before the end of the civil war and the establishment of the Soviet Union, the Russian Orthodox Church came under pressure from the secular Communist government. The Soviet government stood on a platform of antireligion, viewing the church as a "counter-revolutionary" organization and an independent voice with a great influence in society. While the Soviet Union officially claimed religious tolerance, in practice the government discouraged organized religion and did much to remove religious influence from Soviet society.
Under Communist rule.
After the October Revolution of November 7, 1917, the officially proclaimed objective of the Soviet Union was to unite all of the people of the world in a communist state free of "capitalist exploitation" (see Communist International). With such a view of the world any ethnic heritage closely tied to traditional religion and its clergy was targeted by Soviet authorities.
The Soviet Union was the first state to have elimination of religion as an ideological objective. Toward that end, the Communist regime confiscated church property, ridiculed religion, harassed believers, and propagated atheism in schools. Actions toward particular religions, however, were determined by State interests, and most organized religions were never outlawed.
It is alleged that Orthodox priests and believers were variously tortured and sent to prison camps, labour camps or mental hospitals. Many Orthodox (along with people of other faiths) were also subjected to psychological punishment or torture and mind control experimentation in order to force them give up their religious convictions.
Thousands of churches and monasteries were taken over by the government and either destroyed or converted to secular use. It was impossible to build new churches. Practising Orthodox Christians were restricted from prominent careers and membership in communist organizations (the party, the Komsomol). Anti-religious propaganda was openly sponsored and encouraged by the government, which the Church was not given an opportunity to publicly respond to. The government youth organization, the Komsomol, encouraged its members to vandalize Orthodox Churches and harass worshippers. Seminaries were closed down, and the church was restricted from using the press.
The history of Orthodoxy (and other religions) under Communism was not limited to this story of repression and secularization. Bolshevik policies toward religious belief and practice tended to vacillate over time between, on the one hand, a utopian determination to substitute secular rationalism for what they considered to be an unmodern, "superstitious" worldview and, on the other, pragmatic acceptance of the tenaciousness of religious faith and institutions. In any case, religious beliefs and practices did persist, not only in the domestic and private spheres but also in the scattered public spaces allowed by a state that recognized its failure to eradicate religion and the political dangers of an unrelenting culture war.
In August 1917, following the collapse of the tsarist government, a council of the Russian Orthodox church reestablished the patriarchate and elected the metropolitan Tikhon, the former Metropolitan of All America and Canada, as patriarch. But the new Soviet government soon declared the separation of church and state and also nationalized all church-held lands. These administrative measures were followed by brutal state-sanctioned persecutions that included the wholesale destruction of churches, as well as the arrest and execution of many clerics. The Russian Orthodox church was further weakened in 1922, when the Renovated Church, a reform movement supported by the Soviet government, seceded from Patriarch Tikhon's church (also see the Josephites and the Russian True Orthodox Church), restored a Holy Synod to power, and brought division among clergy and faithful.
In the first five years after the Bolshevik revolution, 28 bishops and 1,200 priests were executed.
Stalin era.
The main target of the anti-religious campaign in the 1920s and 1930s was the Russian Orthodox Church, which had the largest congregation. Nearly all of its clergy, and many of its believers, were shot or sent to labor camps. Theological schools were closed, and church publications were prohibited.
The sixth sector of the OGPU, led by Yevgeny Tuchkov, began aggressively arresting and executing bishops, priests, and devout worshippers, such as Metropolitan Veniamin in Petrograd in 1922 for refusing to accede to the demand to hand in church valuables (including sacred relics). In the time between 1927 and 1940, the number of Orthodox Churches in the Russian Republic fell from 29,584 to less than 500. Between 1917 and 1935, 130,000 Orthodox priests were arrested. Of these, 95,000 were put to death. Many thousands of victims of persecution became recognized in a special canon of saints known as the "new martyrs and confessors of Russia".
In January 1918 Patriarch Tikhon proclaimed anathema to the Bolsheviks (without explicitly naming them), which further antagonized relations. When Tikhon died in 1925, Soviet authorities forbade patriarchal elections to be held. Patriarchal "locum tenens" (acting Patriarch) Metropolitan Sergius (Stragorodsky, 1887–1944), going against the opinion of a major part of the church's parishes, in 1927 issued a declaration accepting the Soviet authority over the church as legitimate, pledging the church's cooperation with the government and condemning political dissent within the church. By this declaration Sergius granted himself authority that he, being a deputy of imprisoned Metropolitan Peter and acting against his will, had no right to assume according to the XXXIV Apostolic canon, which led to a split with the Russian Orthodox Church Outside of Russia abroad and the Russian True Orthodox Church (Russian Catacomb Church) within the Soviet Union, as they allegedly remained faithful to the Canons of the Apostles, declaring the part of the church led by Metropolitan Sergius schism, sometimes coined "Sergianism". Due to this canonical disagreement it is disputed which church has been the legitimate successor to the Russian Orthodox Church that had existed before 1925.
With aid from the Methodist Church, two Russian Orthodox seminaries were reopened. Moreover, in the 1929 elections, the Orthodox Church attempted to formulate itself as a full-scale opposition group to the Communist Party, and attempted to run candidates of its own against the Communist candidates. Article 124 of the 1936 Soviet Constitution officially allowed for freedom of religion within the Soviet Union, and along with initial statements of it being a multi-candidate election, the Church again attempted to run its own religious candidates in the 1937 elections. However the support of multicandidate elections was retracted several months before the elections were held and in neither 1929 nor 1937 were any candidates of the Orthodox Church elected.
After Nazi Germany's attack on the Soviet Union in 1941, Joseph Stalin revived the Russian Orthodox Church to intensify patriotic support for the war effort. On September 4, 1943, Metropolitans Sergius, Alexy and Nikolay had a meeting with Stalin and received a permission to convene a council on September 8, 1943, which elected Sergius Patriarch of Moscow and all the Rus'. This is considered by some as violation of the XXX Apostolic canon, as no church hierarch could be consecrated by secular authorities. A new patriarch was elected, theological schools were opened, and thousands of churches began to function. The Moscow Theological Academy Seminary, which had been closed since 1918, was re-opened.
Between 1945 and 1959 the official organization of the church was greatly expanded, although individual members of the clergy were occasionally arrested and exiled. The number of open churches reached 25,000. By 1957 about 22,000 Russian Orthodox churches had become active. But in 1959 Nikita Khrushchev initiated his own campaign against the Russian Orthodox Church and forced the closure of about 12,000 churches. By 1985 fewer than 7,000 churches remained active. Members of the church hierarchy were jailed or forced out, their places taken by docile clergy, many of whom had ties with the KGB. This decline was evident from the dramatic decay of many of the abandoned churches and monasteries that were previously common in even the smallest villages from the pre-revolutionary period.
Persecution under Khrushchev.
A new and widespread persecution of the church was subsequently instituted under the leadership of Nikita Khrushchev and Leonid Brezhnev. A second round of repression, harassment and church closures took place between 1959 and 1964 when Nikita Khrushchev was in office.
The Church and the government remained on unfriendly terms until 1988. In practice, the most important aspect of this conflict was that openly religious people could not join the Communist Party of the Soviet Union, which meant that they could not hold any political office. However, among the general population, large numbers remained religious.
Some Orthodox believers and even priests took part in the dissident movement and became prisoners of conscience. The Orthodox priests Gleb Yakunin, Sergiy Zheludkov and others spent years in Soviet prisons and exile for their efforts in defending freedom of worship. Among the prominent figures of that time were Father Dmitri Dudko and Father Aleksandr Men. Although he tried to keep away from practical work of the dissident movement intending to better fulfil his calling as a priest, there was a spiritual link between Fr Aleksandr and many of the dissidents. For some of them he was a friend, for others - a godfather, for many (including Yakunin) - spiritual father.
By 1987 the number of functioning churches in the Soviet Union had fallen to 6893 and the number of functioning monasteries to just 18. In 1987 in the Russian SFSR, between 40% and 50% of newborn babies (depending on the region) were baptized. Over 60% of all deceased received Christian funeral services.
Glasnost and evidence of KGB links.
Beginning in the late 1980s, under Mikhail Gorbachev, the new political and social freedoms resulted in many church buildings being returned to the church, to be restored by local parishioners. A pivotal point in the history of the Russian Orthodox Church came in 1988 - the millennial anniversary of the Baptism of Kievan Rus'. Throughout the summer of that year, major government-supported celebrations took place in Moscow and other cities; many older churches and some monasteries were reopened. An implicit ban on religious propaganda on state TV was finally lifted. For the first time in the history of the Soviet Union, people could see live transmissions of church services on television.
Gleb Yakunin, a critic of the Moscow Patriarchate who was one of those who briefly gained access to the KGB archive documents in the early 1990s, argued that the Moscow Patriarchate was "practically a subsidiary, a sister company of the KGB". Critics charge that the archives showed the extent of active participation of the top ROC hierarchs in the KGB efforts overseas. George Trofimoff, the highest-ranking US military officer ever indicted for, and convicted of, espionage by the United States and sentenced to life imprisonment on September 27, 2001, had been "recruited into the service of the KGB" by Igor Susemihl (a.k.a. Zuzemihl), a bishop in the Russian Orthodox Church (subsequently, a high-ranking hierarch - the ROC Metropolitan Iriney of Vienna, who died in July 1999).
Konstanin Kharchev, former chairman of Soviet Council on Religious Affairs, explained: "Not a single candidate for the office of bishop or any other high-ranking office, much less a member of Holy Synod, went through without confirmation by the Central Committee of the CPSU and the KGB". Professor Nathaniel Davis points out: "If the bishops wished to defend their people and survive in office, they had to collaborate to some degree with the KGB, with the commissioners of the Council for Religious Affairs, and with other party and governmental authorities.". Patriarch Alexy II, acknowledged that compromises were made with the Soviet government by bishops of the Moscow Patriarchate, himself included, and publicly repented of these compromises 
Post-Soviet recovery and problems.
Under Patriarch Aleksey II (1990–2008).
Metropolitan Alexy (Ridiger) of Leningrad, ascended the patriarchal throne in 1990 and presided over the partial return of Orthodox Christianity to Russian society after 70 years of repression, transforming the ROC to something resembling a state religion; some 15,000 churches had been re-opened or built by the end of his reign. The Russian Church also sought to fill the ideological vacuum left by the end of communism and even, in the opinion of some analysts, became "a separate branch of power".
In August 2000 the ROC adopted its Basis of the Social Concept and in July 2008 its Basic Teaching on Human Dignity, Freedom and Rights.
Under Patriarch Aleksey, there were difficulties in the relationship between the Russian Orthodox Church and the Vatican, especially since 2002, when Pope John Paul II created a Catholic diocesan structure for Russian territory. The leaders of the Russian Church saw this action as a throwback to prior attempts by the Vatican to proselytize the Russian Orthodox faithful to become Roman Catholic. This point of view was based upon the stance of the Russian Orthodox Church (and the Eastern Orthodox Church) that the Church of Rome is in schism, after breaking off from the Orthodox Church. The Roman Catholic Church, on the other hand, while acknowledging the primacy of the Russian Orthodox Church in Russia, believed that the small Roman Catholic minority in Russia, in continuous existence since at least the 18th century, should be served by a fully developed church hierarchy with a presence and status in Russia, just as the Russian Orthodox Church is present in other countries (including constructing a cathedral in Rome, near the Vatican). 
There occurred strident conflicts with the Ecumenical Patriarchate, most notably over the Orthodox Church in Estonia in the mid-1990s, which resulted in unilateral suspension of eucharistic relationship between the churches by the ROC. The tension lingered on and could be observed at the meeting in Ravenna in early October 2007 of participants in the Orthodox-Catholic Dialogue: the representative of the Moscow Patriarchate, Bishop Hilarion Alfeyev, walked out of the meeting due to the presence of representatives from the Estonian Apostolic Orthodox Church which is in the jurisdiction of the Ecumenical Patriarchate. At the meeting, prior to the departure of the Russian delegation, there were also substantive disagreements about the wording of a proposed joint statement among the Orthodox representatives. After the departure of the Russian delegation, the remaining Orthodox delegates approved the form which had been advocated by the representatives of the Ecumenical Patriarchate. The Ecumenical See's representative in Ravenna said that Hilarion's position "should be seen as an expression of authoritarianism whose goal is to exhibit the influence of the Moscow Church. But like last year in Belgrade, all Moscow achieved was to isolate itself once more since no other Orthodox Church followed its lead, remaining instead faithful to Constantinople."
Canon Michael Bourdeaux, former president of the Keston Institute, said in January 2008 that "the Moscow Patriarchate acts as though it heads a state church, while the few Orthodox clergy who oppose the church-state symbiosis face severe criticism, even loss of livelihood." Such a view is backed up by other observers of Russian political life. Clifford J. Levy of "The New York Times" wrote in April 2008: «Just as the government has tightened control over political life, so, too, has it intruded in matters of faith. The Kremlin's surrogates in many areas have turned the Russian Orthodox Church into a de facto official religion, warding off other Christian denominations that seem to offer the most significant competition for worshipers. <...> This close alliance between the government and the Russian Orthodox Church has become a defining characteristic of Mr. Putin's tenure, a mutually reinforcing choreography that is usually described here as working "in symphony".»
Throughout Patriarch Alexy's reign, the massive-scale program of costly restoration of re-opened churches and monasteries (as well as the construction of new ones) was criticized for having eclipsed the church's principal mission of evangelizing.
On 5 December 2008, the day of Patriarch Alexy's death, the "Financial Times" said: "While the church had been a force for liberal reform under the Soviet Union, it soon became a center of strength for conservatives and nationalists in the post-communist era. Alexei's death could well result in an even more conservative church."
Under Patriarch Kirill.
On January 27, 2009, the ROC Local Council (the 2009 Pomestny Sobor) elected Metropolitan Kirill of Smolensk Patriarch of Moscow and All Rus; with 508 votes out of 700.) He was enthroned on February 1, 2009.
In 2010 news broke of a child abuse scandal involving a monastery in the city of Vladimir, where children are said to have been "hit multiple times, forced to do agricultural labor from 3 a.m. till 10 p.m. with 30-minute breaks for breakfast and lunch".
In February 2011 the official spokesman of the Synodal Department of the Patriarchate denied reports that the Church was about to merge with the Russian State. He said, "The Russian Church has never in its history been so independent of the state as it is now. It treasures this independence. However, it also treasures the dialogue that it has with the modern state. No doubt, this dialogue cannot be called easy, but it can be called constructive". At a conference at the Moscow State University on September 2012 Patriarch Kirill said church is not interested in obtaining state powers or even a state status "as in certain European countries".
Structure and organization.
Overview.
The ROC constituent parts in other than the Russian Federation countries of its exclusive jurisdiction such as Ukraine, Belarus et al., are legally registered as separate legal entities in accordance with the relevant legislation of those independent states.
Ecclesiastiacally, the ROC is organized in a hierarchical structure. The lowest level of organization, which normally would be a single ROC building and its attendees, headed by a priest who acts as Father superior (Russian: настоятель, "nastoyatel"), constitute a parish (Russian: приход, "prihod"). All parishes in a geographical region belong to an eparchy (Russian: епархия — equivalent to a Western diocese). Eparchies are governed by bishops (Russian: епископ, episcop or архиерей, archiereus). There are 261 Russian Orthodox eparchies worldwide (June 2012).
Further, some eparchies may be organized into exarchates (currently the Belorussian exarchate), and since 2003 into metropolitan districts (митрополичий округ), such as the ROC eparchies in Kazakhstan and the Central Asia (Среднеазиатский митрополичий округ).
Since the early 1990s, the ROC eparchies in some newly independent states of the former USSR enjoy the status of self-governing Churches within the Moscow Patriarchate (which status, according to the ROC legal terminology, is distinct from the ″autonomous″ one): the Estonian Orthodox Church of Moscow Patriarchate, Latvian Orthodox Church, Moldovan Orthodox Church, Ukrainian Orthodox Church, the last one being virtually fully independent in administrative matters. Similar status, since 2007, is enjoyed by the Russian Orthodox Church Outside of Russia (previously fully independent and deemed schismatic by the ROC). The Chinese Orthodox Church and the Japanese Orthodox Churches were granted full autonomy by the Moscow Patriarchate, but this autonomy is not universally recognized.
Smaller eparchies are usually governed by a single bishop. Larger eparchies, exarchates, and self-governing Churches are governed by a Metropolitan archbishop and sometimes also have one or more bishops assigned to them.
The highest level of authority in the ROC is vested in the Local Council ("Pomestny Sobor"), which comprises all the bishops as well as representatives from the clergy and laypersons. Another organ of power is the Bishops' Council ("Архиерейский Собор"). In the periods between the Councils the highest administrative powers are exercised by the Holy Synod of the Russian Orthodox Church, which includes seven permanent members and is chaired by the Patriarch of Moscow and All Russia, Primate of the Moscow Patriarchate.
Although the Patriarch of Moscow enjoys extensive administrative powers, unlike the Pope, he has no direct canonical jurisdiction outside the , nor does he have single-handed authority over matters pertaining to faith as well as issues concerning the entire Orthodox Christian community such as the Catholic-Orthodox split.
Orthodox Church in America (OCA).
Russian traders settled in Alaska during the 18th century. In 1740, a Divine Liturgy was celebrated on board a Russian ship off the Alaskan coast. In 1794, the Russian Orthodox Church sent missionaries — among them Saint Herman of Alaska—to establish a formal mission in Alaska. Their missionary endeavors contributed to the conversion of many Alaskan natives to the Orthodox faith. A diocese was established, whose first bishop was Saint Innocent of Alaska. The headquarters of this North American Diocese of the Russian Orthodox Church was moved from Alaska to California around the mid-19th century.
It was moved again in the last part of the same century, this time to New York. This transfer coincided with a great movement of Greek-Catholics to the Orthodox Church in the East of the United States. This movement, which increased the numbers of Orthodox Christians in America, resulted from a conflict between John Ireland, the politically powerful Roman Catholic Archbishop of Saint Paul, Minnesota; and Alexis Toth, an influential Ruthenian Catholic priest of St. Mary's church in Minneapolis. Archbishop Ireland's refusal to accept Fr. Toth's credentials as a priest induced Fr. Toth to convert St. Mary's to the Orthodox Church, and further resulted in the conversion of tens of thousands of other Greek-Catholics in North America to the Orthodox Church under his guidance and inspiration. For this reason, Ireland is sometimes ironically remembered as the "Father of the Orthodox Church in America". These Greek-Catholics were received into Orthodoxy into the existing North American diocese of the Russian Orthodox Church. At the same time large numbers of Greeks and other Orthodox Christians were also immigrating to America. At this time all Orthodox Christians in North America were united under the "omophorion" (church authority and protection) of the Patriarch of Moscow, through the Russian Church's North American diocese. The unity was not merely theoretical, but was a reality, since there was then no other diocese on the continent. Under the aegis of this diocese, which at the turn of the 20th century was ruled by Bishop (and future Patriarch) Tikhon, Orthodox Christians of various ethnic backgrounds were ministered to, both non-Russian and Russian; a Syro-Arab mission was established under the episcopal leadership of Saint Raphael of Brooklyn, who was the first Orthodox bishop to be consecrated in America.
In 1920 Patriarch Tikhon issued an "ukase" (decree) that "dioceses" of the Church of Russia that were cut off from the governance of the highest Church authority (i.e. the Holy Synod and the Patriarch) should be managed independently until such time as normal relations with the highest Church authority could be resumed; and on this basis, the North American diocese of the Russian Orthodox Church (known as the "Metropolia") continued to exist in a "de facto" autonomous mode of self-governance. The financial hardship that beset the North American diocese as the result of the Russian Revolution resulted in a degree of administrative chaos, with the result that other national Orthodox communities in North America turned to the churches in their respective homelands for pastoral care and governance.
A group of bishops who had left Russia in the wake of the Russian Civil War gathered in Sremski-Karlovci, Yugoslavia, and adopted a pro-monarchist stand. The group further claimed to speak as a synod for the entire "free" Russian church. This group, which to this day includes a sizable portion of the Russian emigration, was formally dissolved in 1922 by Patriarch Tikhon, who then appointed metropolitans Platon and Evlogy as ruling bishops in America and Europe, respectively. Both of these metropolitans continued to entertain relations intermittently with the synod in Karlovci.
Between the World Wars the Metropolia coexisted and at times cooperated with an independent synod later known as Russian Orthodox Church Outside Russia (ROCOR), sometimes also called the Russian Orthodox Church Abroad. The two groups eventually went their separate ways. ROCOR, which moved its headquarters to North America after the Second World War, claimed but failed to establish jurisdiction over all parishes of Russian origin in North America. The Metropolia, as a former diocese of the Russian Church, looked to the latter as its highest church authority, albeit one from which it was temporarily cut off under the conditions of the communist regime in Russia.
After World War II the Patriarchate of Moscow made unsuccessful attempts to regain control over these groups. After resuming communication with Moscow in early 1960s, and being granted autocephaly in 1970, the Metropolia became known as the Orthodox Church in America. However, recognition of this autocephalous status is not universal, as the Ecumenical Patriarch (under whom is the Greek Orthodox Archdiocese of America) and some other jurisdictions have not officially accepted it. The reasons for this are complex; nevertheless the Ecumenical Patriarch and the other jurisdictions remain in communion with the OCA. The Patriarchate of Moscow thereby renounced its former canonical claims in the United States and Canada; it also acknowledged an autonomous church established in Japan that same year.
Russian Orthodox Church Outside Russia (ROCOR).
Russia's Church was devastated by the repercussions of the Bolshevik Revolution. One of its effects was a flood of refugees from Russia to the United States, Canada, and Europe. The Revolution of 1918 severed large sections of the Russian church—dioceses in America, Japan, and Manchuria, as well as refugees in Europe—from regular contacts with the main church.
Based on an "ukase" (decree) issued by Patriarch Tikhon, which stated that "dioceses" of the Church of Russia that were cut off from the governance of the highest Church authority (i.e. the Holy Synod and the Patriarch) should be managed independently until such time as normal relations with the highest Church authority could be resumed, the Russian Orthodox Church Outside of Russia was established; by bishops who had left Russia in the wake of the Russian Civil War. They first met in Constantinople, and then moved to Sremski-Karlovci, Yugoslavia. After World War II, they moved their headquarters to New York City, New York, where it remains to this day.
On December 28, 2006, it was officially announced that the Act of Canonical Communion would finally be signed between the ROC and ROCOR. The signing took place on the May 17, 2007, followed immediately by a full restoration of communion with the Moscow Patriarchate, celebrated by a Divine Liturgy at the Cathedral of Christ the Saviour in Moscow, at which the Patriarch of Moscow and All Russia Alexius II and the First Hierarch of ROCOR concelebrated for the first time.
Under the Act, the ROCOR remains a self-governing entity within the Church of Russia. It is independent in its administrative, pastoral, and property matters. It continues to be governed by its Council of Bishops and its Synod, the Council's permanent executive body. The First-Hierarch and bishops of the ROCOR are elected by its Council and confirmed by the Patriarch of Moscow. ROCOR bishops participate in the Council of Bishops of the entire Russian Church.
In response to the signing of the act of canonical communion, Bishop Agafangel and parishes and clergy in opposition to the Act broke communion with ROCOR, and established ROCA, or the Russian Orthodox Church Abroad. Some others opposed to the Act have joined themselves to other Greek Old Calendarist groups.
Currently both the OCA and ROCOR, since 2007, are in communion with the ROC.
Self-governing branches of ROC.
The Russian Orthodox Church has four levels of self-government.
Belarusian Orthodox Church.
The Belarusian Orthodox Church is part of the Russian Orthodox Church.
Worship and practices.
Canonization.
In accordance with the practice of the Orthodox Church, a particular hero of faith can initially be canonized only at a local level within local churches and eparchies. Such rights belong to the ruling hierarch and it can only happen when the blessing of the patriarch is received. The task of believers of the local eparchy is to record descriptions of miracles, to create the hagiography of a saint, to paint an icon, as well as to compose a liturgical text of a service where the saint is glorified. All of this is sent to the Synodal Commission for canonization which decides whether to canonize the local hero of faith or not. Then the patriarch gives his blessing and the local hierarch performs the act of canonization at the local level. However, the liturgical texts in honor of a saint are not published in all Church books but only in local publications. In the same way these saints are not yet glorified and venerated by the whole Church, only locally. When the glorification of a saint exceeds the limits of an eparchy, then the patriarch and Holy Synod decides about their canonization on the Church level. After receiving the Synod’s support and the patriarch’s blessing, the question of glorification of a particular saint on the scale of the entire Church is given for consideration to the Local Council of the Russian Orthodox Church.
In the period following the revolution, and during the communist persecutions up to 1970, no canonizations took place. Only in 1970 did the Holy Synod made a decision to canonize a missionary to Japan, Nicholas Kasatkin (1836–1912). In 1977, St. Innocent of Moscow (1797–1879), the Metropolitan of Siberia, the Far East, the Aleutian Islands, Alaska, and Moscow was also canonized. In 1978 it was proclaimed that the Russian Orthodox Church had created a prayer order for Meletius of Kharkov, which practically signified his canonization because that was the only possible way to do it at that time. Similarly, the saints of other Orthodox Churches were added to the Church calendar: in 1962 St. John the Russian, in 1970 St. Herman of Alaska, in 1993 Silouan the Athonite, the elder of Mount Athos, already canonized in 1987 by the Ecumenical Patriarchate of Constantinople. In the 1980s the Russian Orthodox Church re-established the process for canonization; a practice that had ceased for half a century.
In 1989 the Holy Synod Established the Synodal Commission for canonization. The 1990 Local Council of the Russian Orthodox Church gave an order for the Synodal Commission for Canonisation to prepare documents for canonization of new martyrs who had suffered from the 20th century communist repressions. In 1991 it was decided that a local commission for canonization would be established in every eparchy which would gather the local documents and would send them to the Synodal Commission. Its task was to study the local archives, collect memories of believers, record all the miracles that are connected with addressing the martyrs. In 1992 the Church established 25 January as a day when it venerates the new 20th century martyrs of faith. The day was specifically chosen because on this day in 1918 the Metropolitan of Kiev Vladimir (Bogoyavlensky) was killed, thus becoming the first victim of communist terror among the hierarchs of the Church.
During the 2000 Council of the Russian Orthodox Church, the greatest general canonization in the history of the Orthodox Church took place: not only regarding the number of saints but also as in this canonization, all unknown saints were mentioned. There were 1,765 canonized saints known by name and others unknown by name but "known to God".
Icon painting.
The use and making of icons entered Kievan Rus' following its conversion to Orthodox Christianity in AD 988. As a general rule, these icons strictly followed models and formulas hallowed by Byzantine art, led from the capital in Constantinople. As time passed, the Russians widened the vocabulary of types and styles far beyond anything found elsewhere in the Orthodox world. Russian icons are typically paintings on wood, often small, though some in churches and monasteries may be much larger. Some Russian icons were made of copper. Many religious homes in Russia have icons hanging on the wall in the "krasny ugol", the "red" or "beautiful" corner. There is a rich history and elaborate religious symbolism associated with icons. In Russian churches, the nave is typically separated from the sanctuary by an iconostasis (Russian "ikonostas", иконостас), or icon-screen, a wall of icons with double doors in the centre. Russians sometimes speak of an icon as having been "written", because in the Russian language (like Greek, but unlike English) the same word ("pisat"', писать in Russian) means both to paint and to write. Icons are considered to be the Gospel in paint, and therefore careful attention is paid to ensure that the Gospel is faithfully and accurately conveyed. Icons considered miraculous were said to "appear." The "appearance" (Russian: "yavlenie", явление) of an icon is its supposedly miraculous discovery. "A true icon is one that has 'appeared', a gift from above, one opening the way to the Prototype and able to perform miracles".
Ecumenism and interfaith relations.
In May 2011, Hilarion Alfeyev, the Metropolitan of Volokolamsk and head of external relations for the Moscow Patriarchate of the Russian Orthodox Church, stated that Orthodox and Evangelical Christians share the same positions on "such issues as abortion, the family, and marriage" and desires "vigorous grassroots engagement" between the two Christian communions on such issues.
The Metropolitan also believes in the possibility of peaceful coexistence between Islam and Christianity as the two religions have never had religious wars in Russia. Alfeyev stated that the Russian Orthodox Church "disagrees with atheist secularism in some areas very strongly" and "believes that it destroys something very essential about human life."
The Russian Orthodox Church today has ecclesiastical missions in Jerusalem and some other countries around the world.
Numerical strength.
The ROC is often said to be the largest of the Eastern Orthodox churches in the world. Including all the autocephalous churches under its supervision, its adherents number more than 150 million worldwide — about half of the 300 million estimated adherents of the Eastern Orthodox Church. Among Christian churches, the Russian Orthodox Church is second only to the Roman Catholic Church in terms of numbers of followers. Within Russia the results of a 2007 VTsIOM poll indicated that about 75% of the population considered themselves Orthodox Christians. Up to 65% of ethnic Russians as well as Russian-speakers belonging to other ethnic groups from Russia (Ossetians, Caucasus Greeks etc.) and a similar percentage of Belarusians and Ukrainians identify themselves as "Orthodox". However, according to a poll published by the highly respected church related journal Pravmir in December 2012, only 41% of the Russian population identifies itself with the Russian Orthodox Church. Pravmir also published a 2012 poll by the respected Levada organization VTsIOM indicating that 74% of Russians consider themselves Orthodox. According to figures released on March 2, 2011, the Church had 164 dioceses, 217 bishops, and 30,675 parishes served by 28,934 priests and 3,625 deacons. There were 805 monasteries and 30 theological schools. 

</doc>
<doc id="40158" url="http://en.wikipedia.org/wiki?curid=40158" title="Berchtesgaden">
Berchtesgaden

Berchtesgaden (]) is a municipality in the German Bavarian Alps. It is located in the south district of Berchtesgadener Land in Bavaria, near the border with Austria, some 30 km south of Salzburg and 180 km southeast of Munich. To the south of the city the Berchtesgaden National Park stretches along three parallel valleys.
Berchtesgaden is often associated with the Watzmann, at 2,713 m the third-highest mountain in Germany (after Zugspitze and Hochwanner), which is renowned in the rock climbing community for its "Ostwand" (East Face), and a deep glacial lake by the name of Königssee (5.2 km²). Another notable peak is the Kehlstein mountain (1,835 m) with its "Kehlsteinhaus" ("Eagle's Nest"), which offers spectacular views to its visitors.
Geography.
Berchtesgaden's neighbouring towns are Bischofswiesen, Marktschellenberg, Ramsau and Schönau am Königssee.
The municipality counts the following villages which are ("Ortsteil"): Am Etzerschlößl, Anzenbach, Hintergern, Metzenleiten, Mitterbach, Oberau, Obergern, Obersalzberg, Resten, Unterau, Untersalzberg I, Untersalzberg II and Vordergern.
Etymology.
Berchtesgaden, Upper Bavaria (Achental), earlier "Perchterscadmen", "Perhtersgadem", "Berchirchsgadem", "Berchtoldesgadem"; the word underwent a Latin distortion of Old High German "parach", Romance "bareca" 'hay shed'. After the basic meaning was forgotten, they added a variant word of Old High German "gadem" ‘room, one-room hut’, implying the same meaning: ‘hay shed’. Cf. Old High German "muosgadem" ‘spice room’. There was a folk etymology that supported a derivation based on the legendary figure of Mrs. ("Frau") Perchta, Berchta, a woman (Holle < Holda ‘well disposed, dear’) with good and bad changing features, who was venerated on "Perchtertag" (= Three Kings Day) and at Shrovetide was sworn to during the Perchta procession.
History.
First ever historical note dates back to 1102 and it mentions the area because of its rich salt deposits. Much of Berchtesgaden's wealth has been derived from its salt mines, the first of which started operations in 1517. The town served as independent "Fürstpropstei" until the "Reichsdeputationshauptschluss" in 1803. During the Napoleonic wars, Berchtesgaden changed hands a few times, such as in 1805 under the Treaty of Pressburg, when the area was ceded to Austria. Salzburg was always interested in Berchtesgaden , and French troops occupied the area a short time. Berchtesgaden came under Bavarian rule in 1810 and became instantly popular with the Bavarian royal family, the House of Wittelsbach, who often visited Königssee and maintained a royal hunting residence in the former Augustine monastery (still today used by Franz, Duke of Bavaria). Nascent tourism started to evolve and a number of artists came to the area, which reportedly gave rise to "Malereck" (literally "painter's corner") on the shore of Königssee in nearby Ramsau bei Berchtesgaden. The most famous author who lived in Berchtesgaden was Ludwig Ganghofer.
Nazis in Berchtesgaden.
The area of Obersalzberg was purchased by the Nazis in the 1920s for their senior leaders to enjoy. Hitler's mountain residence, the "Berghof", was located here. Berchtesgaden and its environs ("Stanggass") were fitted to serve as an outpost of the German "Reichskanzlei" office (Imperial Chancellery), which sealed the area's fate as a strategic objective for Allied forces in World War II. Some typical Third Reich buildings in Berchtesgaden include the railway station, that had a reception area for Hitler and his guests, and the post office next to the railway station. The Berchtesgadener Hof Hotel was a hotel where famous visitors stayed, such as Eva Braun, Erwin Rommel, Joseph Goebbels and Heinrich Himmler, as well as Neville Chamberlain and David Lloyd George. The hotel was demolished in 2006. There is a museum on the spot now, called "Haus der Berge".
The Obersalzberg.
A number of other relics of the Nazi era can still be found in the area, although only a few of them are still well preserved. There is the "Kehlsteinhaus" (nicknamed "Eagle's Nest" by a French diplomat), which was built as a present for Hitler's 50th birthday in 1939. The remnants of homes of former Nazi leaders—such as Adolf Hitler, Hermann Göring and Martin Bormann—were all demolished in the early postwar years.
The "Platterhof" was retained and served as a holiday and recreation retreat (Armed Forces Recreation Centers) for the American military. It was known as the General Walker Hotel. It was demolished in 2000. The only remaining fully intact buildings are the former SS HQ at Hotel Zum Türken, Albert Speer's house and the "Kehlsteinhaus". A small part of the "Platterhof" is also still there. The information centre on the mountain is the former guesthouse Höher Göll. It has an entrance to the Obersalzberg bunker system.
Post war era.
After the war, Obersalzberg became a military zone and most of its buildings were requisitioned by the US Army. "Hotel Platterhof" was rebuilt and renamed the "General Walker Hotel" in 1952. It served as an integral part of the US Armed Forces Recreation Centers for the duration of the Cold War and beyond. The "Berghof" was demolished in 1953.
In 1995, 50 years after the end of World War II and five years after German reunification, the AFRC Berchtesgaden was turned over to Bavarian authorities to facilitate military spending reductions mandated within the Base Realignment and Closure program by the United States Congress and the Pentagon during the administration of US President Bill Clinton. The General Walker Hotel was demolished shortly thereafter. Its ruins, along with the remnants of the "Berghof", were removed in 1996 to make room for a new bus station serving the bus line to the "Kehlsteinhaus" and for the new InterContinental Hotel Resort. The former guest house "Höher Göll" now serves a new documentation centre. It is the first German museum of its kind to chronicle the entire span of World War II in one spot.
Berchtesgaden today.
In 1972, local government reform united the then independent municipalities of Salzberg, Maria Gern and Au (consisting of Oberau and Unterau) under the administration of the town of Berchtesgaden. Another suggested reform uniting all remaining five municipalities in the Berchtesgaden valley (Bischofswiesen, Ramsau, Marktschellenberg and Schönau) failed to gain enough popular support; it passed in Berchtesgaden but failed everywhere else.
The Berchtesgaden National Park was established in 1978 and has gradually become one of Berchtesgaden's largest draws. Mass tourism is confined to a few popular spots, which gives alternative, nature-seeking tourists plenty of space to find peace and quiet in the park. Major tourist draws are the Königssee, the salt mine (with a sound and light show inaugurated in 2007), the "Kehlsteinhaus" and the new "Dokumentationszentrum Obersalzberg".
Recreational and competitive sports have grown in importance. Although Berchtesgaden's ski slopes are not among the largest in the Alps, they can easily accommodate everyone; from beginners to very competitive skiers and boarders. The Königssee bobsleigh, luge, and skeleton track has hosted ski-running and a number of international bobsleigh, luge, and skeleton events and competitions. Berchtesgaden's most famous sports personality is Georg Hackl, a multiple Olympic medal winner. The city is home to the International Luge Federation (FIL).
Unlike the northern part of Berchtesgadener Land and the Salzburg area, Berchtesgaden has virtually no manufacturing industry.
Berchtesgaden Central Station is connected by the Salzburg–Berchtesgaden railway to the Rosenheim–Salzburg railway at Freilassing.

</doc>
<doc id="40163" url="http://en.wikipedia.org/wiki?curid=40163" title="Darmstadtium">
Darmstadtium

Darmstadtium is a chemical element with symbol Ds and atomic number 110. It is an extremely radioactive synthetic element. The most stable known isotope, darmstadtium-281, has a half-life of approximately 10 seconds. Darmstadtium was first created in 1994 by the GSI Helmholtz Centre for Heavy Ion Research near the city of Darmstadt, Germany, after which it was named.
In the periodic table, it is a d-block transactinide element. It is a member of the 7th period and is placed in the group 10 elements, although no chemical experiments have yet been carried out to confirm that it behaves as the heavier homologue to platinum in group 10. Darmstadtium is calculated to have similar properties to its lighter homologues, nickel, palladium, and platinum.
History.
Discovery.
Darmstadtium was first created on November 9, 1994, at the Institute for Heavy Ion Research (Gesellschaft für Schwerionenforschung) in Darmstadt, Germany, by Peter Armbruster and Gottfried Münzenberg, under the direction of Sigurd Hofmann. The team bombarded a lead-208 target with accelerated nuclei of nickel-62 in a heavy ion accelerator and detected a single atom of the isotope darmstadtium-269:
In the same series of experiments, the same team also carried out the reaction using heavier nickel-64 ions. During two runs, 9 atoms of 271Ds were convincingly detected by correlation with known daughter decay properties:
The IUPAC/IUPAP Joint Working Party (JWP) recognised the GSI team as discoverers in their 2001 report.
Naming.
The name "Darmstadtium" (Ds) was suggested by the GSI team in honor of the city of Darmstadt, where the element was discovered. The GSI team originally also considered naming the element "wixhausium", after the suburb of Darmstadt known as Wixhausen where the element was discovered, but eventually decided on "darmstadtium". The new name was officially recommended by IUPAC on August 16, 2003.
Isotopes.
Darmstadtium has no stable or naturally-occurring isotopes. Several radioactive isotopes have been synthesized in the laboratory, either by fusing two atoms or by observing the decay of heavier elements. Eight different isotopes of darmstadtium have been reported with atomic masses 267, 269–271, 273, 277, 279, and 281, although darmstadtium-267 is unconfirmed. Three darmstadtium isotopes, darmstadtium-270, darmstadtium-271, and darmstadtium-281, have known metastable states (although that of darmstadtium-281 is unconfirmed). Most of these decay predominantly through alpha decay, but some undergo spontaneous fission.
Stability and half-lives.
All darmstadtium isotopes are extremely unstable and radioactive; in general, the heavier isotopes are more stable than the lighter. The most stable known darmstadtium isotope, 281Ds, is also the heaviest known darmstadtium isotope; it has a half-life of 11 seconds, although a metastable state, 281mDs, has been reported to have a longer half-life of about 3.7 minutes. The isotope 279Ds has a half-life of 0.18 seconds respectively. The remaining six isotopes and two metastable states have half-lives between 1 microsecond and 70 milliseconds. Some unknown isotopes in this region, such as 272Ds, 274–276Ds, and 280Ds, are predicted to also have rather long half-lives of a few seconds. Before its discovery, 277Ds was predicted to also have a long half-life of around 5 seconds; however, it has since been found to have a very short half-life of only 5.7 milliseconds.
The undiscovered isotope 284Ds has been predicted to be the most stable towards beta decay; however, no known darmstadtium isotope has been observed to undergo beta decay. Theoretical calculation in a quantum tunneling model reproduces the experimental alpha decay half-life data for the known darmstadtium isotopes. It also predicts that the undiscovered isotope 294Ds, which has a magic number of neutrons (184), would have an alpha decay half-life on the order of 311 years: exactly the same approach as for this latter case also predicts a ~3,500 year half life for the non-neutronically magic 293Ds isotope, however.
Predicted properties.
Chemical.
Darmstadtium is the eighth member of the 6d series of transition metals. Since copernicium (element 112) has been shown to be a transition metal, it is expected that all the elements from 104 to 112 would form a fourth transition metal series, with darmstadtium as part of the platinum group metals and a noble metal. Calculations on its ionization potentials and atomic and ionic radii are similar to that of its lighter homologue platinum, thus implying that darmstadtium's basic properties will resemble those of the other group 10 elements, nickel, palladium, and platinum.
Prediction of the probable chemical properties of darmstadtium has not received much attention recently. Darmstadtium is expected to be a noble metal. Based on the most stable oxidation states of the lighter group 10 elements, the most stable oxidation states of darmstadtium are predicted to be the +6, +4, and +2 states; however, the neutral state is predicted to be the most stable in aqueous solutions. In comparison, only palladium and platinum are known to show the maximum oxidation state in the group, +6, while the most stable states are +4 and +2 for both nickel and palladium. It is further expected that the maximum oxidation states of elements from bohrium (element 107) to darmstadtium (element 110) may be stable in the gas phase but not in aqueous solution. Darmstadtium hexafluoride (DsF6) is predicted to have very similar properties to its lighter homologue platinum hexafluoride (PtF6), having very similar electronic structures and ionization potentials. It is also expected to have the same octahedral molecular geometry as PtF6. Other predicted darmstadtium compounds are darmstadtium carbide (DsC) and darmstadtium tetrachloride (DsCl4), both of which are expected to behave like their lighter homologues.
Physical and atomic.
Darmstadtium is expected to be a solid under normal conditions and to crystallize in the body-centered cubic structure, unlike its lighter congeners which crystallize in the face-centered cubic structure, because it is expected to have different electron charge densities from them. It should be a very heavy metal with a density of around 34.8 g/cm3. In comparison, the densest known element that has had its density measured, osmium, has a density of only 22.61 g/cm3. This results from darmstadtium's high atomic weight, the lanthanide and actinide contractions, and relativistic effects, although production of enough darmstadtium to measure this quantity would be impractical, and the sample would quickly decay.
The outer electron configuration of darmstadtium is calculated to be 6d87s2, which obeys the Aufbau principle and does not follow platinum's outer electron configuration of 5d96s1. This is due to the relativistic stabilization of the 7s2 electron pair over the whole seventh period, so that none of the elements from 104 to 112 are expected to have electron configurations violating the Aufbau principle. The atomic radius of darmstadtium is expected to be around 132 pm.
Experimental chemistry.
Unambiguous determination of the chemical characteristics of darmstadtium has yet to have been established due to the short half-lives of darmstadtium isotopes and a limited number of likely volatile compounds that could be studied on a very small scale. One of the few darmstadtium compounds that are likely to be sufficiently volatile is darmstadtium hexafluoride (DsF6), as its lighter homologue platinum hexafluoride (PtF6) is volatile above 60 °C and therefore the analogous compound of darmstadtium might also be sufficiently volatile; a volatile octafluoride (DsF8) might also be possible. For chemical studies to be carried out on a transactinide, at least four atoms must be produced, the half-life of the isotope used must be at least 1 second, and the rate of production must be at least one atom per week. Even though the half-life of 281Ds, the most stable confirmed darmstadtium isotope, is 11 seconds, long enough to perform chemical studies, another obstacle is the need to increase the rate of production of darmstadtium isotopes and allow experiments to carry on for weeks or months so that statistically significant results can be obtained. Separation and detection must be carried out continuously to separate out the darmstadtium isotopes and automated systems can then experiment on the gas-phase and solution chemistry of darmstadtium as the yields for heavier elements are predicted to be smaller than those for lighter elements; some of the separation techniques used for bohrium and hassium could be reused. However, the experimental chemistry of darmstadtium has not received as much attention as that of the heavier elements from copernicium to livermorium.
The more neutron-rich darmstadtium isotopes are the most stable and are thus more promising for chemical studies; however, they can only be produced indirectly from the alpha decay of heavier elements, and indirect synthesis methods are not favourable for chemical studies. The more neutron-rich isotopes 276Ds and 277Ds might be produced directly in the reaction between thorium-232 and calcium-48, but the yield is expected to be low. Furthermore, this reaction has already been tested without success, and more recent experiments that have successfully synthesized 277Ds using indirect methods show that it has a short half-life of 5.7 ms, not long enough to perform chemical studies.

</doc>
<doc id="40166" url="http://en.wikipedia.org/wiki?curid=40166" title="Broca's area">
Broca's area

Broca's area or the Broca area or is a region in the frontal lobe of the left hemisphere (the "dominant hemisphere") of the hominid brain with functions linked to speech production.
Language processing has been linked to Broca's area since Pierre Paul Broca reported impairments in two patients. They had lost the ability to speak after injury to the posterior inferior frontal gyrus of the brain. Since then, the approximate region he identified has become known as Broca's area, and the deficit in language production as Broca's aphasia, also called expressive aphasia. Broca's area is now typically defined in terms of the pars opercularis and pars triangularis of the inferior frontal gyrus, represented in Brodmann's cytoarchitectonic map as areas 44 and 45 of the dominant hemisphere. Studies of chronic aphasia have implicated an essential role of Broca's area in various speech and language functions. Further, fMRI studies have also identified activation patterns in Broca's area associated with various language tasks. However, slow destruction of the Broca's area by brain tumors can leave speech relatively intact suggesting its functions can shift to nearby areas in the brain.
Structure.
Broca's area is often identified by visual inspection of the topography of the brain either by macrostructural landmarks such as sulci or by the specification of coordinates in a particular reference space. The currently used Talairach and Tournoux atlas projects Brodmann's cytoarchitectonic map onto a template brain. Because Brodmann's parcelation was based on subjective visual inspection of cytoarchitectonic borders and also Brodmann analyzed only one hemisphere of one brain, the result is imprecise. Further, because of considerable variability across brains in terms of shape, size, and position relative to sulcal and gyral structure, a resulting localization precision is limited.
Nevertheless, Broca's area in the left hemisphere and its homologue in the right hemisphere are designations usually used to refer to pars triangularis (PTr) and pars opercularis (POp) of the inferior frontal gyrus. The PTr and POp are defined by structural landmarks that only probabilistically divide the inferior frontal gyrus into anterior and posterior cytoarchitectonic areas of 45 and 44, respectively, by Brodmann's classification scheme.
Area 45 receives more afferent connections from prefrontal cortex, the superior temporal gyrus, and the superior temporal sulcus, compared to area 44, which tends to receive more afferent connections from motor, somatosensory, and inferior parietal regions.
The differences between area 45 and 44 in cytoarchitecture and in connectivity suggest that these areas might perform different functions. Indeed, recent neuroimaging studies have shown that the PTr and Pop, corresponding to areas 45 and 44, respectively, play different functional roles in the human with respect to language comprehension and action recognition/understanding.
Function.
Language comprehension.
For a long time, it was assumed that the role of Broca's area was more devoted to language production than language comprehension. However, recent evidence demonstrates that Broca's area also plays a significant role in language comprehension. Patients with lesions in Broca's area who exhibit agrammatical speech production also show inability to use syntactic information to determine the meaning of sentences. Also, a number of neuroimaging studies have implicated an involvement of Broca's area, particularly of the pars opercularis of the left inferior frontal gyrus, during the processing of complex sentences. Further, it has recently been found in functional magnetic resonance imaging (fMRI) experiments involving highly ambiguous sentences result in a more activated inferior frontal gyrus. Therefore, the activity level in the inferior frontal gyrus and the level of lexical ambiguity are directly proportional to each other, because of the increased retrieval demands associated with highly ambiguous content.
Action recognition and production.
Recent experiments have indicated that Broca's area is involved in various cognitive and perceptual tasks. One important contribution of Brodmann's area 44 is also found in the motor-related processes. Observation of meaningful hand shadows resembling moving animals activates frontal language area, demonstrating that Broca's area indeed plays a role in interpreting action of others. An activation of BA 44 was also reported during execution of grasping and manipulation.
Speech-associated gestures.
It has been speculated that because speech-associated gestures could possibly reduce lexical or sentential ambiguity, comprehension should improve in the presence of speech-associated gestures. As a result of improved comprehension, the involvement of Broca's area should be reduced.
Many neuroimaging studies have also shown activation of Broca's area when representing meaningful arm gestures. A recent study has shown evidence that word and gesture are related at the level of translation of particular gesture aspects such as its motor goal and intention. This finding that aspects of gestures are translated in words within Broca's area also explains language development in terms of evolution. Indeed, many authors have proposed that speech evolved from a primitive communication that arose from gestures. (See below.)
Speaking without Broca's area.
The essential role of the Broca's area in speech production has been questioned since it can be destroyed while leaving language nearly intact. In one case of a computer engineer, a slow-growing glioma tumor was removed. The tumor and the surgery destroyed the left inferior and middle frontal gyrus, the head of the caudate nucleus, the anterior limb of the internal capsule, and the anterior insula. However, there were minimal language problems three months after removal and the individual returned to his professional work. These minor problems include the inability to create syntactically complex sentences including more than two subjects, multiple causal conjunctions, or reported speech. These were explained by researchers as due to working memory problems. They also attributed his lack of problems to extensive compensatory mechanisms enabled by neural plasticity in the nearby cerebral cortex and a shift of some functions to the homologous area in the right hemisphere.
Damage to Broca's area is commonly associated with telegraphic like speech made up of functional vocabulary. For example, a person with Broca's aphasia may say something like, "Drive, store. Mom." meaning to say, "My mom drove me to the store today". Therefore, the content of the information is correct, but the grammar and fluidity of the sentence is missing.
Clinical significance.
Stuttering.
Various studies have shown that the Broca's area is underactive in people who stutter.Maguire et al. 1994, Maguire etal, 1997.
Aphasia.
Aphasia is an acquired language disorder affecting all modalities such as writing, reading, speaking, and listening and results from brain damage. It is often a chronic condition that creates changes in all areas of one's life.
Expressive aphasia vs. other aphasias.
Patients with expressive aphasia, also known as Broca's aphasia, are individuals who know "what they want to say, they just cannot get it out". They are typically able to comprehend words, and sentences with a simple syntactic structure (see above), but are more or less unable to generate fluent speech. Other symptoms that may be present include problems with fluency, articulation, word-finding, word repetition, and producing and comprehending complex grammatical sentences, both orally and in writing.
This specific group of symptoms distinguishes those who have expressive aphasia from individuals with other types of aphasia. There are several distinct "types" of aphasia, and each type is characterized by a different set of language deficits. Although those who have expressive aphasia tend to retain good spoken language comprehension, other types of aphasia can render patients completely unable to understand any language at all, unable to understand any spoken language (auditory verbal agnosia), whereas still other types preserve language comprehension, but with deficits. People with expressive aphasia may struggle less with reading and writing (see alexia) than those with other types of aphasia. Although individuals with expressive aphasia tend to have a good ability to self-monitor their language output (they "hear what they say" and make corrections), other types of aphasics can seem entirely unaware of their language deficits.
In the classical sense, expressive aphasia is the result of injury to Broca's area; it is often the case that lesions in specific brain areas cause specific, dissociable symptoms, although case studies show there is not always a one-to-one mapping between lesion location and aphasic symptoms. The correlation between damage to certain specific brain areas (usually in the left hemisphere) and the development of specific types of aphasia makes it possible to deduce (albeit very roughly) the location of a suspected brain lesion based only on the presence (and severity) of a certain type of aphasia, though this is complicated by the possibility that a patient may have damage to a number of brain areas and may exhibit symptoms of more than one type of aphasia. The examination of lesion data in order to deduce which brain areas are essential in the normal functioning of certain aspects of cognition is called the deficit-lesion method; this method is especially important in the branch of neuroscience known as aphasiology. Cognitive science - to be specific, cognitive neuropsychology - are branches of neuroscience that also make extensive use of the deficit-lesion method.
History.
In a recent study, the preserved brains of both Leborgne and Lelong (patients of Broca) were reinspected using high-resolution volumetric MRI. The purpose of this study was to scan the brains in three dimensions and to identify the extent of both cortical and subcortical lesions in more detail. The study also sought to locate the exact site of the lesion in the frontal lobe in relation to what is now called Broca's area with the extent of subcortical involvement.
Broca's patients.
Leborgne (Tan).
Leborgne was a patient of Broca's. Almost completely unable to produce any words or phrases, he was able to repetitively produce only the word "tan". After his death, a lesion was discovered on the surface the left frontal lobe.
Lelong.
Lelong was another patient of Broca's. He also exhibited reduced productive speech. He could only say five words, 'yes,' 'no,' 'three,' 'always,' and 'lelo' (a mispronunciation of his own name). At autopsy, a lesion was also found in the same region of lateral frontal lobe as in Leborgne. These two cases led Broca to believe that speech was localized to this particular area.
MRI findings.
Examination of the brains of Broca's two historic patients with high-resolution MRI has produced several interesting findings. First, the MRI findings suggest that other areas besides Broca's area may also have contributed to the patients' reduced productive speech. This finding is significant because it has been found that, though lesions to Broca's area alone can possibly cause temporary speech disruption, they do not result in severe speech arrest. Therefore, there is a possibility that the aphasia denoted by Broca as an absence of productive speech also could have been influenced by the lesions in the other region. Another interesting finding is that the region, which was once considered to be critical for speech by Broca, is not precisely the same region as what is now known as Broca's area. This study provides further evidence to support the claim that language and cognition are far more complicated than once thought and involve various networks of brain regions.
Evolution of language.
The pursuit of a satisfying theory that addresses the origin of language in humans has led to the consideration of a number of evolutionary "models." These models attempt to show how modern language might have evolved, and a common feature of many of these theories is the idea that vocal communication was initially used to complement a far more dominant mode of communication through gesture. Human language might have evolved as the "evolutionary refinement of an implicit communication system already present in lower primates, based on a set of hand/mouth goal-directed action representations."
"Hand/mouth goal-directed action representations" is another way of saying "gestural communication", "gestural language", or "communication through body language." The recent finding that Broca's area is active when people are observing others engaged in meaningful action is evidence in support of this idea. It was hypothesized that a precursor to the modern Broca's area was involved in translating gestures into abstract ideas by interpreting the movements of others as meaningful action with an intelligent purpose. It is argued that over time the ability to predict the intended outcome and purpose of a set of movements eventually gave this area the capability to deal with truly abstract ideas, and therefore (eventually) became capable of associating sounds (words) with abstract meanings. The observation that frontal language areas are activated when people observe Hand Shadows is further evidence that human language may have evolved from existing neural substrates that evolved for the purpose of gesture recognition. The study, therefore, claims that Broca's area is the "motor center for speech", which assembles and decodes speech sounds in the same way it interprets body language and gestures. Consistent with this idea is that the neural substrate that regulated motor control in the common ancestor of apes and humans was most likely modified to enhance cognitive and linguistic ability. Studies of speakers of American Sign Language and English suggest that the human brain recruited systems that had evolved to perform more basic functions much earlier; these various brain circuits, according to the authors, were tapped to work together in creating language.
Another recent finding has showed significant areas of activation in subcortical and neocortical areas during the production of communicative manual gestures and vocal signals in chimpanzees. Further, the data indicating that chimpanzees intentionally produce manual gestures as well as vocal signals to communicate with humans suggests that the precursors to human language are present at both the behavioral and neuronanatomical levels. More recently, the neocortical distribution of activity-dependent gene expression in marmosets provided direct evidence that the ventrolateral prefrontal cortex, which comprises Broca's area in humans and has been associated with auditory processing of species-specific vocalizations and orofacial control in macaques, is engaged during vocal output in a New World monkey. These findings putatively set the origin of vocalization-related neocortical circuits to at least 35 million years ago, when the Old and New World monkey lineages split.

</doc>
<doc id="40168" url="http://en.wikipedia.org/wiki?curid=40168" title="ATF">
ATF

ATF may refer to:

</doc>
<doc id="40171" url="http://en.wikipedia.org/wiki?curid=40171" title="Lead(II) azide">
Lead(II) azide

Lead azide (Pb(N3)2) is an inorganic compound. More so than other azides, Pb(N3)2 is explosive. It is used in detonators to initiate secondary explosives. In a commercially usable form, it is a white to buff powder.
Preparation and handling.
Lead azide is prepared by metathesis between sodium azide and lead nitrate. Dextrin can be added to the solution to stabilize the precipitated product. The solid is not very hygroscopic, and water does not reduce its impact sensitivity. It is normally shipped in a dextrinated solution that lowers its sensitivity. When protected from humidity, it is completely stable in storage. An alternative method involves dissolving lead acetate in a sodium azide solution.
Production History.
Lead azide in its pure form was first prepared by Theodor Curtius in 1891. Due to sensitivity and stability concerns, the dextrinated form of lead azide (MIL-L-3055) was developed in the 1920s and 1930s with large scale production by DuPont Co beginning in 1932. Detonator development during World War II resulted in the need for a form of lead azide with a more brisant output. RD-1333 lead azide (MIL-DTL-46225), a version of lead azide with sodium carboxymethylcellulose as a precipitating agent, was developed to meet that need. The Vietnam War saw an accelerated need for lead azide and it was during this time that Special Purpose Lead Azide (MIL-L-14758) was developed; the US government also began stockpiling lead azide in large quantities. After the Vietnam War, the use of lead azide dramatically decreased; due to the size of the US stockpile, the manufacture of lead azide in the US ceased completely by the early 1990s. In the 2000s, concerns about the age and stability of stockpiled lead azide led the US government to investige methods to dispose of its stockpiled lead azide and obtain new manufacturers.
Explosive characteristics.
Lead azide is highly sensitive and usually handled and stored under water in insulated rubber containers. It will explode after a fall of around 150 mm (6 in) or in the presence of a static discharge of 7 millijoules. Its detonation velocity is around 5180 m/s.
Ammonium acetate and sodium dichromate are used to destroy small quantities of lead azide.
Lead azide reacts with copper, zinc, cadmium, or alloys containing these metals to form other azides. For example, copper azide is even more explosive and too sensitive to be used commercially.
Lead azide was a component of the six .22 caliber Devastator rounds fired from a Röhm RG-14 revolver by John Hinckley, Jr. in his assassination attempt on U.S. President Ronald Reagan on March 30, 1981. The rounds consisted of lead azide centers with lacquer-sealed aluminum tips designed to explode upon impact.

</doc>
<doc id="40172" url="http://en.wikipedia.org/wiki?curid=40172" title="Botulinum toxin">
Botulinum toxin

Botulinum toxin (BTX) is a neurotoxic protein produced by the bacterium "Clostridium botulinum" and related species. It is also produced commercially for medical, cosmetic, and research use. There are two main commercial types: botulinum toxin type A and botulinum toxin type B.
Infection with the bacterium may result in a potentially fatal disease called botulism. Botulinum is the most acutely lethal toxin known, with an estimated human median lethal dose (LD50) of 1.3–2.1 ng/kg intravenously or intramuscularly and 10–13 ng/kg when inhaled. 
Botulinum toxin type A and B is used in medicine for, among others, upper motor neuron syndrome, focal hyperhidrosis, blepharospasm, strabismus, chronic migraine and bruxism. It is also widely used in cosmetic treatments. The U.S. Food and Drug Administration requires a boxed warning stating that when locally administered the toxin may spread from the injection site to other areas of the body, causing symptoms similar to those of botulism poisoning. The warning was the result of deaths associated with its uses. The commercial form is marketed under the brand name Botox, among others.
Uses.
Medical uses.
Botulinum toxin is used for a number of medical problems. When injected in small amounts, it can effectively weaken a muscle for a period of three to four months.
It is used in the treatment of spasms and dystonias.
The conditions approved for treatment with botulinum toxin include:
Other adult uses of botulinum toxin type A include:
Uses of botulinum toxin type A in children include:
Emerging uses for botulinum toxin type A include chronic musculoskeletal pain.
Cosmetic.
In cosmetic applications, injection of botulinum toxin can be used to prevent development of wrinkles by paralyzing facial muscles. Following treatment, visible results of Botox Cosmetic are usually seen within 3–5 days, however it can take up to 2 weeks to see full results.
Adverse effects.
Off-target effects.
Off-target, or side effects, that have been reported are consistent with the mechanism of the protein toxin's function, and its known modes of action; there are, consequently, two major areas of off-target effects: allergic reaction, and paralysis of the wrong muscle group.
Adverse events or reactions from cosmetic use include facial paralysis resulting in inappropriate facial expression, drooping eyelid, and double vision, bruising, swelling, or redness at the site of injection, headaches, dysphagia, flu-like syndromes, blurred vision, dry mouth, fatigue, and allergic reactions. Cosmetic treatments are of limited duration; they can be as short as six weeks, but can last from 2–3 months; hence paralysis side-effects can have the same durations. The results of inappropriate facial expression, drooping eyelid, and double vision are foremost, but the list extends to uneven smiling, and loss of the ability to close ones eyes; at least in some cases, these effects are reported to dissipate in the weeks after treatment. Bruising at the site of injection is not a side effect of the toxin but rather of the mode of administration, and is reported as preventable if the clinician applies pressure to the injection site; when it occurs, it is reported in specific cases to last 7–11 days. When injecting the masseter muscle of the jaw, loss of muscle function can result in a loss or reduction of power to chew solid foods.
Individuals who are pregnant, have egg allergies, or a neuromuscular disorder are advised to avoid botulinum toxin drugs, and breastfeeding mothers are advised to consult their doctors.
The psychological and emotional consequences associated with cosmetic treatments is not yet well documented, and reports are not yet consistent. A study of treatment of glabellar lines with consequent reduction of ability to frown correlated with a "more positive mood[s]", while a study on the treatment of "crow's feet" or "laughter lines" suggested the opposite effect as a consequence of the impact of the treatment on the patient's ability to smile.
Poisoning.
If the symptoms of botulism are diagnosed early, an equine antitoxin, use of enemas, and extracorporeal removal of the gut contents can be used to treat the food-borne illness. Wound infections can be treated surgically. Information regarding methods of safe canning, and public education about the disease are methods of prevention. Tests to detect botulism include a brain scan, a nerve conduction test, and a tensilon test for myasthenia gravis to differentiate botulism from other diseases that manifest in the same way. Electromyography can be used to differentiate myasthenia gravis and Guillain-Barré syndrome, diseases that botulism often mimics. Toxicity testing of serum specimens, wound tissue cultures, and toxicity testing, and stool specimen cultures are the best methods for identifying botulism. Laboratory tests of the patient's serum or stool, which are then injected into mice, are also indicative of botulism. The faster way to detect botulinum toxin in people, however, is using the mass spectrometer technology, because it reduces testing time to three or four hours and at the same time can identify the type of toxin present.
The case fatality rate for botulinum poisoning between 1950 and 1996 was 15.5%, down from about 60% over the previous 50 years. Death is generally secondary to respiratory failure due to paralysis of the respiratory muscles, so treatment consists of antitoxin administration and artificial ventilation until the neurotoxins are excreted or metabolised. If initiated on time, these treatments are quite effective, although antisera can not affect toxin polypeptides that have already entered cells. Occasionally, functional recovery may take several weeks to months or more.
Two primary botulinum antitoxins are available for treatment of botulism.
Links to deaths.
The FDA has formally linked complications from use of botulinum drug products to patient deaths. In September 2005, the "Journal of American Academy of Dermatology" communicated information from the FDA reporting 28 deaths between 1989 and 2003 associated with the use of botulinum toxin products, though none attributed to cosmetic use.
In January 2008, a petition filed by Public Citizen with the FDA requested regulatory action concerning the possible spread of the effects of botulinum toxin injectable products, including Botox and Myobloc, from the site of injection to other parts of the body.
On February 8, 2008, the FDA announced its conclusion that this class of drugs had "been linked in some cases to adverse reactions, including respiratory failure and death, following treatment of a variety of conditions using a wide range of doses," due to its ability to spread to areas distant from the site of the injection. The communication was a result of ongoing FDA safety reviews of the on-market product, and found adverse reactions associated with uses that were both FDA-approved and non-approved, the most severe being in children with cerebral palsy treated for limb spasticity (not approved for either adult or pediatric use).
On April 30, 2009, based on a continuing safety evaluation of on-market botulinum toxin products, the FDA reported its conclusion that the prescribing information for Botox, Botox Cosmetic, and Myobloc must be updated to ensure their continued safe use. On July 31, 2009, FDA, under the authorities granted by the Food and Drug Administration Amendments Act of 2007, approved revisions to the prescribing information (see following).
Further, on April 30, the FDA announced an update to its mandatory boxed warnings for four on-market products—Botox, Botox Cosmetic, Myobloc, and Dysport—and on July 31, it approved revisions to the prescribing information for the four drugs. In the revisions, it made clear that the effects of botulinum toxin may spread from the area of injection to other body areas, causing symptoms similar to those of botulism, including potentially life-threatening swallowing and breathing difficulties resulting in patient death. Most accumulated adverse reactions were again reported for pediatric palsy patients (off-label use, see above), though adverse reaction reports were also fielded for adult patients involved in both approved and unapproved uses; the FDA emphasized that at "recommended/approved doses" there were few serious adverse reactions for common, standard treatments for focal hyperhidrosis, blepharospasm, or strabismus, or for cosmetic/dermatologic treatments, e.g., for glabellar lines (i.e., when label instructions were followed). The FDA further emphasized that the activity units of each product do not interconvert, specifically that "different botulinum toxin products are not interchangeable, because the units used to measure the products are different," and required a change in the established drug names of older drugs, from:
doing so to "emphasize the differing dose to potency ratios of [each of] these products."
A further FDA communication aimed at health care professionals reiterated the approved drugs for each adult indication:
These have been extended, through later announcement, to include:
which is defined for patients having a history of migraine, and experiencing a headache on most days of the month."
In the 2009 communication to professionals, the FDA reiterated the foregoing adverse reaction observations and the possibility of "unexpected loss of strength or muscle weakness," leading to:
and that "swallowing and breathing difficulties can be life-threatening" (i.e., that there have been "deaths related to the effects of spread of botulinum toxin"). The communication to professionals reiterated that pediatric spasticity patients were at greatest risk from existing treatment practices, but also that approved and lower doses used to treat cervical dystonia and adult spasticity were also seen among the "cases of toxin spread," so that in all cases of drug administration, patients and their caregivers needed to:"Pay close attention for any signs or symptoms of adverse events. [and] Seek immediate medical attention… [in the case of] difficulty swallowing or talking, trouble breathing, or muscle weakness…"
and that these events may occur "as late as several weeks after treatment."
Warning labels.
In January 2009, the Canadian government warned that botulinum toxin products can have the adverse effect of spreading to other parts of the body, which could cause muscle weakness, swallowing difficulties, pneumonia, speech disorders and breathing problems.
In April 2009, the FDA updated its mandatory boxed warning cautioning that the effects of the botulinum toxin may spread from the area of injection to other areas of the body, causing symptoms similar to those of botulism, and that these adverse reactions, which were more likely in cases ignoring approved use guidance and label directions, could result in patient death (see above).
Mechanism of effect.
The toxin produced by Clostridum species is a two-chain protein composed of a 100-kDa heavy chain polypeptide joined via disulfide bond to a 50-kDa light chain polypeptide. The eight serologically distinct toxin types possessing different tertiary structures and significant sequence divergence are designated A to G; six of the eight have subtypes, and five further subtypes of target molecules of botulinum A have been described. The A, B, and E serotypes cause human botulism, with the activities of types A and B enduring longest "in vivo" (from several weeks to months).
The terminals of specific axons must internalize the toxin to cause paralysis, and the heavy chain of the toxins is implicated in targeting the toxin to such axon terminals; following the attachment of the toxin heavy chain to proteins on the surface of the terminals, toxin molecules enter the neurons by endocytosis. The light chain, which has zinc metalloprotease activity, is released from the endocytotic vesicles and reaches the cytoplasm. Specific serotypes of the toxin cleave "synaptosomal-associated protein (25 kDa)" (SNAP-25), a protein from the "soluble N-ethylmaleimide-sensitive factor attachment receptor "(SNARE) family involved in vesicle fusion and mediating release of neurotransmitter, in particular acetylcholine, from axon endings. Cleavage of the SNARE proteins inhibits release of acetylcholine. Hence, botulinum toxins A, B, and E specifically cleave SNAREs, preventing "neurosecretory vesicles" from docking/fusing with the interior surface of the plasma membrane of the nerve synapse, and so block release of neurotransmitter. In inhibiting acetylcholine release, nerve impulses are blocked, causing the flaccid (sagging) paralysis of muscles characteristic of botulism (in contrast to the distinct spastic paralysis seen in tetanus).
History.
In the nineteenth century, Justinus Kerner described botulinum toxin as a "sausage poison" and "fatty poison" (from Latin "botulus" meaning "sausage"), because the bacterium that produces the toxin often caused poisoning by growing in improperly handled or prepared meat products. Kerner, a physician, first conceived a possible therapeutic use of botulinum toxin, and coined the name botulism. In 1897, Emile van Ermengem found the producer of the botulin toxin was a bacterium, which he named "Clostridium botulinum." P.T. Snipe and Hermann Sommer purified the toxin for the first time In 1928. In 1949, Arnold Burgen's group experimentally discovered that botulinum toxin blocks neuromuscular transmission through decreased acetylcholine release.
Society and culture.
Economics.
As of 2013, it is the most common cosmetic operation, with 6.3 million procedures in the United States, according to the American Society of Plastic Surgeons. Qualifications for Botox injectors vary by county, state and country. Botox cosmetic providers include dermatologists, plastic surgeons, aesthetic spa physicians, dentists, nurse practitioners, nurses and physician assistants. The global market for botulinum toxin products, driven by their cosmetic applications, is forecast to reach $2.9 billion by 2018; they are a component of the facial aesthetics market that is forecast to reach $4.7 billion ($2 billion in the U.S.) in the same timeframe.
Bioterrorism.
Botulinum toxin has been recognized as a potential agent for use in bioterrorism. It can be absorbed through the eyes, mucous membranes, respiratory tract, or non-intact skin.
The effects of botulinum toxin are different from those of nerve agents involved insofar in that botulism symptoms develop relatively slowly (over several days), while nerve agent effects are generally much more rapid and can be instantaneous. Evidence suggests that nerve exposure (simulated by injection of atropine and pralidoxime) will increase mortality by enhancing botulin toxin's mechanism of toxicity.
With regard to detection, current protocols using NBC detection equipment (such as M-8 paper or the ICAM) will not indicate a "positive" when samples containing botulinum toxin are tested. To confirm a diagnosis of botulinum toxin poisoning, therapeutically or to provide evidence in death investigations, botulinum toxin may be quantitated by immunoassay of human biological fluids; serum levels of 12–24 mouse LD50 units per milliliter have been detected in poisoned patients.
Brand names.
Botulinum toxin A is marketed under the brand names Botox (marketed by Allergan), Dysport (marketed by Ipsen), and Xeomin (marketed by Merz Pharma). Botulinum toxin B is marketed under the brand name Myobloc (marketed by Solstice Neurosciences).
In the United States, botulinum toxin products are manufactured by a variety of companies, for both therapeutic and cosmetic use. Allergan, Inc., a principal U.S. supplier through their Botox products, reported in its company materials in 2011 that it could "supply the world's requirements for 25 indications approved by Government agencies around the world" with less than one gram of raw botulinum toxin. Myobloc or Neurobloc, a botulinum toxin type B product, is produced by Solstice Neurosciences, a subsidiary of US WorldMeds. Dysport, a therapeutic formulation of the type A toxin manufactured by Galderma in the United Kingdom, is licensed for the treatment of focal dystonias and certain cosmetic uses in the U.S. and worldwide.
After the three primary U.S. manufacturers, there many reports of other sources of production. Xeomin, manufactured in Germany by Merz, is also available for both therapeutic and cosmetic use in the U.S. Lanzhou Institute of Biological Products in China is reported to manufacture a BTX-A product; BTX-A is also sold as Lantox and Prosigne on the global market. Neuronox, a BTX-A product, was introduced by Medy-Tox Inc. of South Korea in 2009; Neuronox is also markets as Siax in the U.S.
Toxin production.
Botulism toxins are produced by bacteria of the genus "Clostridium," namely "Clostridium botulinum", "C. butyricum, C. baratii" and "C. argentinense," which are widely distributed, including in soil and dust. As well, the bacteria can be found inside homes on floors, carpet, and countertops even after cleaning. Some food products such as honey can contain amounts of the bacteria.
Food-borne botulism results, indirectly, from ingestion of food contaminated with Clostridium spores, where exposure to an anaerobic environment allows the spores to germinate, after which the bacteria can multiply and produce toxin. Critically, "it is ingestion of toxin rather than spores or vegetative bacteria" that causes botulism. Botulism is nevertheless known to be transmitted through canned foods not cooked correctly before canning or after can opening, and so is preventable. Infant botulism cases arise chiefly as a result of environmental exposure and are therefore more difficult to prevent. Infant botulism arising from consumption of honey can be prevented by eliminating honey from diets of children less than 12 months old.
Therapeutic and weaponisable forms of the toxin are sourced from strains of "Clostriudium" where both the growth and toxin isolation are under specialized conditions.
Organism and toxin susceptibilities.
Proper refrigeration at temperatures below 3 °C (38 °F) retards the growth of "Clostridium botulinum". The organism is also susceptible to high salt, high oxygen, and low pH levels. The toxin itself is rapidly destroyed by heat, such as in thorough cooking. The spores that produce the toxin are heat-tolerant and will survive boiling water for an extended period of time.
The botulinum toxin is denatured and thus deactivated at temperatures greater than 80 C. As a zinc metalloprotease (see below), the toxin's activity is also susceptible, post-exposure, to inhibition by protease inhibitors, e.g., zinc-coordinating hydroxamates.
Research.
Alan Scott and Edward Schantz were the first to work on a standardized botulinum toxin preparation for therapeutic purposes, beginning in the late 1960s. Scott, working at Smith-Kettlewell Institute in 1963, used botulinum toxin type A (BTX-A) in monkey experiments. In 1980, Scott used BTX-A in a first human treatments of blepharospasm ("uncontrollable blinking") and strabismus, a condition in which the eyes are not properly aligned with each other ("crossed eyes"). In 1993, Scott, P.J. Pasricha, and colleagues showed botulinum toxin could be used for the treatment of achalasia, a spasm of the lower esophageal sphincter. In 1994, K.O. Bushara and D.M. Park were the first to demonstrate a non-muscular use of BTX-A in humans, with a demonstration that injections could inhibit conditions resulting in sweating.
Blepharospasm and strabismus.
In the early 1980s, university-based ophthalmologists in the USA and Canada further refined the use of botulinum toxin as a therapeutic agent. By 1985, a scientific protocol of injection sites and dosage had been empirically determined for treatment of blepharospasm and strabismus. Side effects in treatment of this condition were deemed to be rare, mild and treatable. The beneficial effects of the injection lasted only 4–6 months. Thus, blepharospasm patients required re-injection two or three times a year.
In 1986, Scott's micromanufacturer and distributor of Botox was no longer able to supply the drug because of an inability to obtain product liability insurance. Patients became desperate, as supplies of Botox were gradually consumed, forcing him to abandon patients who would have been due for their next injection. For a period of four months, American blepharospasm patients had to arrange to have their injections performed by participating doctors at Canadian eye centers until the liability issues could be resolved.
In December 1989, Botox, manufactured by Allergan, Inc., was approved by the US Food and Drug Administration (FDA) for the treatment of strabismus, blepharospasm, and hemifacial spasm in patients over 12 years old.
Botox has not been approved for any pediatric use. It has, however, been used off-label by physicians for several conditions. including spastic conditions in pediatric patients with cerebral palsy, a therapeutic course that has resulted in patient deaths. In the case of treatment of infantile esotropia in patients younger than 12 years of age, several studies have yielded differing results.
Cosmetic.
The cosmetic effect of BTX-A on wrinkles was originally documented by a plastic surgeon from Sacramento, California, Richard Clark, and published in the journal "Plastic and Reconstructive Surgery" in 1989. Canadian husband and wife ophthalmologist and dermatologist physicians, JD and JA Carruthers, were the first to publish a study on BTX-A for the treatment of glabellar frown lines in 1992. Similar effects had reportedly been observed by a number of independent groups (Brin, and the Columbia University group under Monte Keen.) After formal trials, on April 12, 2002, the FDA announced regulatory approval of botulinum toxin type A (Botox Cosmetic) to temporarily improve the appearance of moderate-to-severe frown lines between the eyebrows (glabellar lines). Subsequently, cosmetic use of botulinum toxin type A has become widespread. The results of Botox Cosmetic can last up to four months and may vary with each patient. The US Food and Drug Administration approved an alternative product-safety testing method in response to increasing public concern that LD50 testing was required for each batch sold in the market.
Upper motor neuron syndrome.
BTX-A is now a common treatment for muscles affected by the upper motor neuron syndrome (UMNS), such as cerebral palsy, for muscles with an impaired ability to effectively lengthen. Muscles affected by UMNS frequently are limited by weakness, loss of reciprocal inhibition, decreased movement control and hypertonicity (including spasticity). In January 2014, Botulinum toxin was approved by UK's Medicines and Healthcare Products Regulatory Agency (MHRA) for the treatment of ankle disability due to lower limb spasticity associated with stroke in adults. Joint motion may be restricted by severe muscle imbalance related to the syndrome, when some muscles are markedly hypertonic, and lack effective active lengthening. Injecting an overactive muscle to decrease its level of contraction can allow improved reciprocal motion, so improved ability to move and exercise.
Sweating.
As noted, Bushara and Park were the first to demonstrate a nonmuscular use of BTX-A while treating patients with hemifacial spasm at England in 1993, showing that botulinum toxin injections inhibit sweating, and so are useful in treating hyperhidrosis (excessive sweating). BTX-A has since been approved for the treatment of severe primary axillary hyperhidrosis (excessive underarm sweating of unknown cause), which cannot be managed by topical agents.
Cervical dystonia.
BTX-A is commonly used to treat cervical dystonia, but it can become ineffective after a time. Botulinum toxin type B (BTX-B) received FDA approval for treatment of cervical dystonia on December 21, 2000. Trade names for BTX-B are Myobloc in the United States, and Neurobloc in the European Union.
Chronic migraine.
Onabotulinumtoxin A (trade name Botox) received FDA approval for treatment of chronic migraines on October 15, 2010. The toxin is injected into the head and neck to treat these chronic headaches. Approval followed evidence presented to the agency from two studies funded by Allergan, Inc. showing a very slight improvement in incidence of chronic migraines for migraine sufferers undergoing the Botox treatment.
Since then, several randomized control trials have shown botulinum toxin type A to improve headache symptoms and quality of life when used prophylactically for patients with chronic migraine who exhibit headache characteristics consistent with: pressure perceived from outside source, shorter total duration of chronic migraines (<30 years), "detoxification" of patients with coexisting chronic daily headache due to medication overuse, and no current history of other preventive headache medications.

</doc>
<doc id="40173" url="http://en.wikipedia.org/wiki?curid=40173" title="8th century BC">
8th century BC

The 8th century BC started the first day of 800 BC and ended the last day of 701 BC. The 8th century BC was a period of great changes in civilizations. In Egypt, the 23rd and 24th dynasties led to rule from Nubia in the 25th Dynasty. The Neo-Assyrian Empire reaches the peak of its power, conquering the Kingdom of Israel as well as nearby countries.
Greece colonizes other regions of the Mediterranean Sea and Black Sea. Rome is founded in 753 BC, and the Etruscan civilization expands in Italy. The 8th century BC is conventionally taken as the beginning of Classical Antiquity, with the first Olympiad set at 776 BC, and the epics of Homer dated to between 750 to 650 BC.
Iron Age India enters the later Vedic period. Vedic ritual is annotated in many priestly schools in Brahmana commentaries, and the earliest Upanishads mark the beginning of Vedanta philosophy.
Significant persons.
Although many human societies were literate at this time, some of the individuals mentioned below must be considered legendary rather than historical.
Sovereign states.
See: List of sovereign states in the 8th century BC.

</doc>
<doc id="40174" url="http://en.wikipedia.org/wiki?curid=40174" title="9th century BC">
9th century BC

The 9th century BC started the first day of 900 BC and ended the last day of 801 BC. It was a period of great change for several civilizations. In Africa, Carthage is founded by the Phoenicians. In Egypt, a severe flood covers the floor of Luxor temple, and years later, a civil war starts.
It is the beginning of the Iron Age in Central Europe, with the spread of the Proto-Celtic Hallstatt culture, and the Proto-Celtic language.
Sovereign States.
See: List of sovereign states in the 9th century BC.

</doc>
<doc id="40176" url="http://en.wikipedia.org/wiki?curid=40176" title="Joseph Priestley">
Joseph Priestley

Joseph Priestley FRS (; 24 March [O.S. 13 March] 1733 – 6 February 1804) was an 18th-century English theologian, Dissenting clergyman, natural philosopher, chemist, educator, and Liberal political theorist who published over 150 works. He is usually credited with the discovery of oxygen, having isolated it in its gaseous state, although Carl Wilhelm Scheele and Antoine Lavoisier also have a claim to the discovery.
During his lifetime, Priestley's considerable scientific reputation rested on his invention of soda water, his writings on electricity, and his discovery of several "airs" (gases), the most famous being what Priestley dubbed "dephlogisticated air" (oxygen). However, Priestley's determination to defend phlogiston theory and to reject what would become the chemical revolution eventually left him isolated within the scientific community.
Priestley's science was integral to his theology, and he consistently tried to fuse Enlightenment rationalism with Christian theism. In his metaphysical texts, Priestley attempted to combine theism, materialism, and determinism, a project that has been called "audacious and original". He believed that a proper understanding of the natural world would promote human progress and eventually bring about the Christian Millennium. Priestley, who strongly believed in the free and open exchange of ideas, advocated toleration and equal rights for religious Dissenters, which also led him to help found Unitarianism in England. The controversial nature of Priestley's publications combined with his outspoken support of the French Revolution aroused public and governmental suspicion; he was eventually forced to flee, in 1791, first to London, and then to the United States, after a mob burned down his home and church. He spent the last ten years of his life living in Northumberland County, Pennsylvania.
A scholar and teacher throughout his life, Priestley also made significant contributions to pedagogy, including the publication of a seminal work on English grammar, books on history, and he prepared some of the most influential early timelines. These educational writings were some of Priestley's most popular works. It was his metaphysical works, however, that had the most lasting influence: leading philosophers including Jeremy Bentham, John Stuart Mill, and Herbert Spencer credit them among the primary sources for utilitarianism.
Early life and education (1733–55).
Priestley was born to an established English Dissenting family (i.e. they did not conform to the Church of England) in Birstall, near Batley in the West Riding of Yorkshire. He was the oldest of six children born to Mary Swift and Jonas Priestley, a finisher of cloth. To ease his mother's burdens, Priestley was sent to live with his grandfather around the age of one. He returned home, five years later, after his mother died. When his father remarried in 1741, Priestley went to live with his aunt and uncle, the wealthy and childless Sarah and John Keighley, 3 mi from Fieldhead. Because Priestley was precocious—at the age of four he could flawlessly recite all 107 questions and answers of the Westminster Shorter Catechism—his aunt sought the best education for the boy, intending him for the ministry. During his youth, Priestley attended local schools where he learned Greek, Latin, and Hebrew.
Around 1749, Priestley became seriously ill and believed he was dying. Raised as a devout Calvinist, he believed a conversion experience was necessary for salvation, but doubted he had had one. This emotional distress eventually led him to question his theological upbringing, causing him to reject election and to accept universal salvation. As a result, the elders of his home church, the Independent Upper Chapel of Heckmondwike, refused him admission as a full member.
Priestley's illness left him with a permanent stutter and he gave up any thoughts of entering the ministry at that time. In preparation for joining a relative in trade in Lisbon, he studied French, Italian, and German in addition to Aramaic, and Arabic. He was tutored by the Reverend George Haggerstone, who first introduced him to higher mathematics, natural philosophy, logic, and metaphysics through the works of Isaac Watts, Willem 's Gravesande, and John Locke.
Daventry Academy.
Priestley eventually decided to return to his theological studies and, in 1752, matriculated at Daventry, a Dissenting academy. Because he had already read widely, Priestley was allowed to skip the first two years of coursework. He continued his intense study; this, together with the liberal atmosphere of the school, shifted his theology further leftward and he became a Rational Dissenter. Abhorring dogma and religious mysticism, Rational Dissenters emphasised the rational analysis of the natural world and the Bible.
Priestley later wrote that the book that influenced him the most, save the Bible, was David Hartley's "Observations on Man" (1749). Hartley's psychological, philosophical, and theological treatise postulated a material theory of mind. Hartley aimed to construct a Christian philosophy in which both religious and moral "facts" could be scientifically proven, a goal that would occupy Priestley for his entire life. In his third year at Daventry, Priestley committed himself to the ministry, which he described as "the noblest of all professions".
Needham Market and Nantwich (1755–61).
Robert Schofield, Priestley's major modern biographer, describes his first "call" in 1755 to the Dissenting parish in Needham Market, Suffolk, as a "mistake" for both Priestley and the congregation. Priestley yearned for urban life and theological debate, whereas Needham Market was a small, rural town with a congregation wedded to tradition. Attendance and donations dropped sharply when they discovered the extent of his heterodoxy. Although Priestley's aunt had promised her support if he became a minister, she refused any further assistance when she realised he was no longer a Calvinist. To earn extra money, Priestley proposed opening a school, but local families informed him that they would refuse to send their children. He also presented a series of scientific lectures titled "Use of the Globes" that was more successful.
Priestley's Daventry friends helped him obtain another position and in 1758 he moved to Nantwich, Cheshire; this time there was happier. The congregation cared less about Priestley's heterodoxy and he successfully established a school. Unlike many schoolmasters of the time, Priestley taught his students natural philosophy and even bought scientific instruments for them. Appalled at the quality of the available English grammar books, Priestley wrote his own: "The Rudiments of English Grammar" (1761). His innovations in the description of English grammar, particularly his efforts to dissociate it from Latin grammar, led 20th-century scholars to describe him as "one of the great grammarians of his time". After the publication of "Rudiments" and the success of Priestley's school, Warrington Academy offered him a teaching position in 1761.
Warrington Academy (1761–1767).
In 1761, Priestley moved to Warrington and assumed the post of tutor of modern languages and rhetoric at the town's Dissenting academy, although he would have preferred to teach mathematics and natural philosophy. He fitted in well at Warrington, and made friends quickly. On 23 June 1762, he married Mary Wilkinson of Wrexham. Of his marriage, Priestley wrote:
This proved a very suitable and happy connexion, my wife being a woman of an excellent understanding, much improved by reading, of great fortitude and strength of mind, and of a temper in the highest degree affectionate and generous; feeling strongly for others, and little for herself. Also, greatly excelling in every thing relating to household affairs, she entirely relieved me of all concern of that kind, which allowed me to give all my time to the prosecution of my studies, and the other duties of my station.
On 17 April 1763, they had a daughter, whom they named Sarah after Priestley's aunt.
Educator and historian.
All of the books Priestley published while at Warrington emphasised the study of history; Priestley considered it essential for worldly success as well as religious growth. He wrote histories of science and Christianity in an effort to reveal the progress of humanity and, paradoxically, the loss of a pure, "primitive Christianity".
In his "Essay on a Course of Liberal Education for Civil and Active Life" (1765), "Lectures on History and General Policy" (1788), and other works, Priestley argued that the education of the young should anticipate their future practical needs. This principle of utility guided his unconventional curricular choices for Warrington's aspiring middle-class students. He recommended modern languages instead of classical languages and modern rather than ancient history. Priestley's lectures on history were particularly revolutionary; he narrated a providentialist and naturalist account of history, arguing that the study of history furthered the comprehension of God's natural laws. Furthermore, his millennial perspective was closely tied to his optimism regarding scientific progress and the improvement of humanity. He believed that each age would improve upon the previous and that the study of history allowed people to perceive and to advance this progress. Since the study of history was a moral imperative for Priestley, he also promoted the education of middle-class women, which was unusual at the time. Some scholars of education have described Priestley as the most important English writer on education between the 17th-century John Locke and the 19th-century Herbert Spencer. "Lectures on History" was well received and was employed by many educational institutions, such as New College at Hackney, Brown, Princeton, Yale, and Cambridge. Priestley designed two "Charts" to serve as visual study aids for his "Lectures". These charts are in fact timelines; they have been described as the most influential timelines published in the 18th century. Both were popular for decades, and the trustees of Warrington were so impressed with Priestley's lectures and charts that they arranged for the University of Edinburgh to grant him a Doctor of Law degree in 1764.
History of Electricity.
The intellectually stimulating atmosphere of Warrington, often called the "Athens of the North" (of England) during the 18th century, encouraged Priestley's growing interest in natural philosophy. He gave lectures on anatomy and performed experiments regarding temperature with another tutor at Warrington, his friend John Seddon. Despite Priestley's busy teaching schedule, he decided to write a history of electricity. Friends introduced him to the major experimenters in the field in Britain—John Canton, William Watson, and the visiting Benjamin Franklin—who encouraged Priestley to perform the experiments he wanted to include in his history. In the process of replicating others' experiments, Priestley became intrigued by unanswered questions and was prompted to undertake experiments of his own design. (Impressed with his "Charts" and the manuscript of his history of electricity, Canton, Franklin, Watson, and Richard Price nominated Priestley for a fellowship in the Royal Society; he was accepted in 1766.)
In 1767, the 700-page "The History and Present State of Electricity" was published to positive reviews. The first half of the text is a history of the study of electricity to 1766; the second and more influential half is a description of contemporary theories about electricity and suggestions for future research. Priestley reported some of his own discoveries in the second section, such as the conductivity of charcoal and other substances and the continuum between conductors and non-conductors. This discovery overturned what he described as "one of the earliest and universally received maxims of electricity", that only water and metals could conduct electricity. This and other experiments on the electrical properties of materials and on the electrical effects of chemical transformations demonstrated Priestley's early and ongoing interest in the relationship between chemical substances and electricity. Based on experiments with charged spheres, Priestley was among the first to propose that electrical force followed an inverse-square law, similar to Newton's law of universal gravitation. However, he did not generalise or elaborate on this, and the general law was enunciated by French physicist Charles-Augustin de Coulomb in the 1780s.
Priestley's strength as a natural philosopher was qualitative rather than quantitative and his observation of "a current of real air" between two electrified points would later interest Michael Faraday and James Clerk Maxwell as they investigated electromagnetism. Priestley's text became the standard history of electricity for over a century; Alessandro Volta (who later invented the battery), William Herschel (who discovered infrared radiation), and Henry Cavendish (who discovered hydrogen) all relied upon it. Priestley wrote a popular version of the "History of Electricity" for the general public titled "A Familiar Introduction to the Study of Electricity" (1768). He marketed the book with his brother Timothy, but unsuccessfully.
Leeds (1767–73).
Perhaps prompted by Mary Priestley's ill health, or financial problems, or a desire to prove himself to the community that had rejected him in his childhood, Priestley moved with his family from Warrington to Leeds in 1767, and he became Mill Hill Chapel's minister. Two sons were born to the Priestleys in Leeds: Joseph junior on 24 July 1768 and William three years later. Theophilus Lindsey, a rector at Catterick, Yorkshire, became one of Priestley's few friends in Leeds, of whom he wrote: "I never chose to publish any thing of moment relating to theology, without consulting him." Although Priestley had extended family living around Leeds, it does not appear that they communicated. Schofield conjectures that they considered him a heretic. Each year Priestley travelled to London to consult with his close friend and publisher, Joseph Johnson, and to attend meetings of the Royal Society.
Minister of Mill Hill Chapel.
When Priestley became its minister, Mill Hill Chapel was one of the oldest and most respected Dissenting congregations in England; however, during the early 18th century the congregation had fractured along doctrinal lines, and was losing members to the charismatic Methodist movement. Priestley believed that by educating the young, he could strengthen the bonds of the congregation.
In his magisterial three-volume "Institutes of Natural and Revealed Religion" (1772–74), Priestley outlined his theories of religious instruction. More importantly, he laid out his belief in Socinianism. The doctrines he explicated would become the standards for Unitarians in Britain. This work marked a change in Priestley's theological thinking that is critical to understanding his later writings—it paved the way for his materialism and necessitarianism (the belief that a divine being acts in accordance with necessary metaphysical laws).
Priestley's major argument in the "Institutes" was that the only revealed religious truths that could be accepted were those that matched one's experience of the natural world. Because his views of religion were deeply tied to his understanding of nature, the text's theism rested on the argument from design. The "Institutes" shocked and appalled many readers, primarily because it challenged basic Christian orthodoxies, such as the divinity of Christ and the miracle of the Virgin Birth. Methodists in Leeds penned a hymn asking God to "the Unitarian fiend expel / And chase his doctrine back to Hell." Priestley wanted to return Christianity to its "primitive" or "pure" form by eliminating the "corruptions" which had accumulated over the centuries. The fourth part of the "Institutes", "An History of the Corruptions of Christianity", became so long that he was forced to issue it separately in 1782. Priestley believed that the "Corruptions" was "the most valuable" work he ever published. In demanding that his readers apply the logic of the emerging sciences and comparative history to the Bible and Christianity, he alienated religious and scientific readers alike—scientific readers did not appreciate seeing science used in the defence of religion and religious readers dismissed the application of science to religion.
Religious controversialist.
Priestley engaged in numerous political and religious pamphlet wars. According to Schofield, "he entered each controversy with a cheerful conviction that he was right, while most of his opponents were convinced, from the outset, that he was willfully and maliciously wrong. He was able, then, to contrast his sweet reasonableness to their personal rancor", but as Schofield points out Priestley rarely altered his opinion as a result of these debates. While at Leeds he wrote controversial pamphlets on the Lord's Supper and on Calvinist doctrine; thousands of copies were published, making them some of Priestley's most widely read works.
Priestley founded the "Theological Repository" in 1768, a journal committed to the open and rational inquiry of theological questions. Although he promised to print any contribution, only like-minded authors submitted articles. He was therefore obliged to provide much of the journal's content himself (this material became the basis for many of his later theological and metaphysical works). After only a few years, due to a lack of funds, he was forced to cease publishing the journal. He revived it in 1784 with similar results.
Defender of Dissenters and political philosopher.
Many of Priestley's political writings supported the repeal of the Test and Corporation Acts, which restricted the rights of Dissenters. They could not hold political office, serve in the armed forces, or attend Oxford and Cambridge unless they subscribed to the Thirty-nine Articles of the Church of England. Dissenters repeatedly petitioned Parliament to repeal the Acts, arguing that they were being treated as second-class citizens.
Priestley's friends, particularly other Rational Dissenters, urged him to publish a work on the injustices experienced by Dissenters; the result was his "Essay on the First Principles of Government" (1768). An early work of modern liberal political theory and Priestley's most thorough treatment of the subject, it—unusually for the time—distinguished political rights from civil rights with precision and argued for expansive civil rights. Priestley identified separate private and public spheres, contending that the government should only have control over the public sphere. Education and religion, in particular, he maintained, were matters of private conscience and should not be administered by the state. Priestley's later radicalism emerged from his belief that the British government was infringing upon these individual freedoms.
Priestley also defended the rights of Dissenters against the attacks of William Blackstone, an eminent legal theorist, whose "Commentaries on the Laws of England" (1765–69) had become the standard legal guide. Blackstone's book stated that dissent from the Church of England was a crime and that Dissenters could not be loyal subjects. Furious, Priestley lashed out with his "Remarks on Dr. Blackstone's Commentaries" (1769), correcting Blackstone's interpretation of the law, his grammar (a highly politicised subject at the time), and history. Blackstone, chastened, altered subsequent editions of his "Commentaries": he rephrased the offending passages and removed the sections claiming that Dissenters could not be loyal subjects, but he retained his description of Dissent as a crime.
Natural philosopher: electricity, "Optics", and soda water.
Although Priestley claimed that natural philosophy was only a hobby, he took it seriously. In his "History of Electricity", he described the scientist as promoting the "security and happiness of mankind". Priestley's science was eminently practical and he rarely concerned himself with theoretical questions; his model was Benjamin Franklin. When he moved to Leeds, Priestley continued his electrical and chemical experiments (the latter aided by a steady supply of carbon dioxide from a neighbouring brewery). Between 1767 and 1770, he presented five papers to the Royal Society from these initial experiments; the first four papers explored coronal discharges and other phenomena related to electrical discharge, while the fifth reported on the conductivity of charcoals from different sources. His subsequent experimental work focused on chemistry and pneumatics.
Priestley published the first volume of his projected history of experimental philosophy, "The History and Present State of Discoveries Relating to Vision, Light and Colours" (referred to as his "Optics"), in 1772. He paid careful attention to the history of optics and presented excellent explanations of early optics experiments, but his mathematical deficiencies caused him to dismiss several important contemporary theories. Furthermore, he did not include any of the practical sections that had made his "History of Electricity" so useful to practising natural philosophers. Unlike his "History of Electricity", it was not popular and had only one edition, although it was the only English book on the topic for 150 years. The hastily written text sold poorly; the cost of researching, writing, and publishing the "Optics" convinced Priestley to abandon his history of experimental philosophy.
Priestley was considered for the position of astronomer on James Cook's second voyage to the South Seas, but was not chosen. Still, he contributed in a small way to the voyage: he provided the crew with a method for making soda water, which he erroneously speculated might be a cure for scurvy. He then published a pamphlet with "Directions for Impregnating Water with Fixed Air" (1772). Priestley did not exploit the commercial potential of soda water, but others such as J. J. Schweppe made fortunes from it. In 1773, the Royal Society recognised Priestley's achievements in natural philosophy by awarding him the Copley Medal.
Priestley's friends wanted to find him a more financially secure position. In 1772, prompted by Richard Price and Benjamin Franklin, Lord Shelburne wrote to Priestley asking him to direct the education of his children and to act as his general assistant. Although Priestley was reluctant to sacrifice his ministry, he accepted the position, resigning from Mill Hill Chapel on 20 December 1772, and preaching his last sermon on 16 May 1773.
Calne (1773–80).
In 1773, the Priestleys moved to Calne and a year later Lord Shelburne and Priestley took a tour of Europe. According to Priestley's close friend Theophilus Lindsey, Priestley was "much improved by this view of mankind at large". Upon their return, Priestley easily fulfilled his duties as librarian and tutor. The workload was intentionally light, allowing him time to pursue his scientific investigations and theological interests. Priestley also became a political adviser to Shelburne, gathering information on parliamentary issues and serving as a liaison between Shelburne and the Dissenting and American interests. When the Priestleys' third son was born on 24 May 1777, they named him Henry at the lord's request.
Materialist philosopher.
Priestley wrote his most important philosophical works during his years with Lord Shelburne. In a series of major metaphysical texts published between 1774 and 1780—"An Examination of Dr. Reid's Inquiry into the Human Mind" (1774), "Hartley's Theory of the Human Mind on the Principle of the Association of Ideas" (1775), "Disquisitions relating to Matter and Spirit" (1777), "The Doctrine of Philosophical Necessity Illustrated" (1777), and "Letters to a Philosophical Unbeliever" (1780)—he argues for a philosophy that incorporates four concepts: determinism, materialism, causation, and necessitarianism. By studying the natural world, he argued, people would learn how to become more compassionate, happy, and prosperous.
Priestley strongly suggested that there is no mind-body duality, and put forth a materialist philosophy in these works; that is, one founded on the principle that everything in the universe is made of matter that we can perceive. He also contended that discussing the soul is impossible because it is made of a divine substance, and humanity cannot perceive the divine. Despite his separation of the divine from the mortal, this position shocked and angered many of his readers, who believed that such a duality was necessary for the soul to exist.
Responding to Baron d'Holbach's "Système de la Nature" (1770) and David Hume's "Dialogues Concerning Natural Religion" (1779) as well as the works of the French "philosophers", Priestley maintained that materialism and determinism could be reconciled with a belief in God. He criticised those whose faith was shaped by books and fashion, drawing an analogy between the scepticism of educated men and the credulity of the masses.
Maintaining that humans had no free will, Priestley argued that what he called "philosophical necessity" (akin to absolute determinism) is consonant with Christianity, a position based on his understanding of the natural world. Like the rest of nature, man's mind is subject to the laws of causation, Priestley contended, but because a benevolent God created these laws, the world and the people in it will eventually be perfected. Evil is therefore only an imperfect understanding of the world.
Although Priestley's philosophical work has been characterised as "audacious and original", it partakes of older philosophical traditions on the problems of free will, determinism, and materialism. For example, the 17th-century philosopher Baruch Spinoza argued for absolute determinism and absolute materialism. Like Spinoza and Priestley,
Leibniz argued that human will was completely determined by natural laws;
however, unlike them, Leibniz argued for a "parallel universe" of immaterial objects (such as human souls) so arranged by God that its outcomes agree exactly with those of the material universe.
Leibniz
and Priestley
share an optimism that God has chosen the chain of events benevolently; however, Priestley believed that the events were leading to a glorious Millennial conclusion, whereas for Leibniz the entire chain of events was optimal in and of itself, as compared with other conceivable chains of events.
Founder of Unitarianism.
When Priestley's friend Theophilus Lindsey decided to found a new Christian denomination that would not restrict its members' beliefs, Priestley and others hurried to his aid. On 17 April 1774, Lindsey held the first Unitarian service in Britain, at the newly formed Essex Street Chapel in London; he had even designed his own liturgy, of which many were critical. Priestley defended his friend in the pamphlet "Letter to a Layman, on the Subject of the Rev. Mr. Lindsey's Proposal for a Reformed English Church" (1774), claiming that only the form of worship had been altered, not its substance, and attacking those who followed religion as a fashion. Priestley attended Lindsey's church regularly in the 1770s and occasionally preached there. He continued to support institutionalised Unitarianism for the rest of his life, writing several "Defenses" of Unitarianism and encouraging the foundation of new Unitarian chapels throughout Britain and the United States.
Experiments and Observations on Different Kinds of Air.
Priestley's years in Calne were the only ones in his life dominated by scientific investigations; they were also the most scientifically fruitful. His experiments were almost entirely confined to "airs", and out of this work emerged his most important scientific texts: the six volumes of "Experiments and Observations on Different Kinds of Air" (1774–86). These experiments helped repudiate the last vestiges of the theory of four elements, which Priestley attempted to replace with his own variation of phlogiston theory. According to that 18th-century theory, the combustion or oxidation of a substance corresponded to the release of a material substance, "phlogiston".
Priestley's work on "airs" is not easily classified. As historian of science Simon Schaffer writes, it "has been seen as a branch of physics, or chemistry, or natural philosophy, or some highly idiosyncratic version of Priestley's own invention". Furthermore, the volumes were both a scientific and a political enterprise for Priestley, in which he argues that science could destroy "undue and usurped authority" and that government has "reason to tremble even at an air pump or an electrical machine".
Volume I of "Experiments and Observations on Different Kinds of Air" outlined several discoveries: "nitrous air" (nitric oxide, NO); "vapor of spirit of salt", later called "acid air" or "marine acid air" (anhydrous hydrochloric acid, HCl); "alkaline air" (ammonia, NH3); "diminished" or "dephlogisticated nitrous air" (nitrous oxide, N2O); and, most famously, "dephlogisticated air" (oxygen, O2) as well as experimental findings that showed plants revitalised enclosed volumes of air, a discovery that would eventually lead to the discovery of photosynthesis. Priestley also developed a "nitrous air test" to determine the "goodness of air". Using a pneumatic trough, he would mix nitrous air with a test sample, over water or mercury, and measure the decrease in volume—the principle of eudiometry. After a small history of the study of airs, he explained his own experiments in an open and sincere style. As an early biographer writes, "whatever he knows or thinks he tells: doubts, perplexities, blunders are set down with the most refreshing candour." Priestley also described his cheap and easy-to-assemble experimental apparatus; his colleagues therefore believed that they could easily reproduce his experiments. Faced with inconsistent experimental results, Priestley employed phlogiston theory. This, however, led him to conclude that there were only three types of "air": "fixed", "alkaline", and "acid". Priestley dismissed the burgeoning chemistry of his day. Instead, he focused on gases and "changes in their sensible properties", as had natural philosophers before him. He isolated carbon monoxide (CO), but apparently did not realise that it was a separate "air".
Discovery of oxygen.
In August 1774 he isolated an "air" that appeared to be completely new, but he did not have an opportunity to pursue the matter because he was about to tour Europe with Shelburne. While in Paris, however, Priestley managed to replicate the experiment for others, including French chemist Antoine Lavoisier. After returning to Britain in January 1775, he continued his experiments and discovered "vitriolic acid air" (sulphur dioxide, SO2).
In March he wrote to several people regarding the new "air" that he had discovered in August. One of these letters was read aloud to the Royal Society, and a paper outlining the discovery, titled "An Account of further Discoveries in Air", was published in the Society's journal "Philosophical Transactions". Priestley called the new substance "dephlogisticated air", which he made in the famous experiment by focusing the sun’s rays on a sample of mercuric oxide. He first tested it on mice, who surprised him by surviving quite a while entrapped with the air, and then on himself, writing that it was "five or six times better than common air for the purpose of respiration, inflammation, and, I believe, every other use of common atmospherical air". He had discovered oxygen gas (O2).
Priestley assembled his oxygen paper and several others into a second volume of "Experiments and Observations on Air", published in 1776. He did not emphasise his discovery of "dephlogisticated air" (leaving it to Part III of the volume) but instead argued in the preface how important such discoveries were to rational religion. His paper narrated the discovery chronologically, relating the long delays between experiments and his initial puzzlements; thus, it is difficult to determine when exactly Priestley "discovered" oxygen. Such dating is significant as both Lavoisier and Swedish pharmacist Carl Wilhelm Scheele have strong claims to the discovery of oxygen as well, Scheele having been the first to isolate the gas (although he published after Priestley) and Lavoisier having been the first to describe it as purified "air itself entire without alteration" (that is, the first to explain oxygen without phlogiston theory).
In his paper "Observations on Respiration and the Use of the Blood", Priestley was the first to suggest a connection between blood and air, although he did so using phlogiston theory. In typical Priestley fashion, he prefaced the paper with a history of the study of respiration. A year later, clearly influenced by Priestley, Lavoisier was also discussing respiration at the Académie des sciences. Lavoisier's work began the long train of discovery that produced papers on oxygen respiration and culminated in the overthrow of phlogiston theory and the establishment of modern chemistry.
Around 1779 Priestley and Shelburne had a rupture, the precise reasons for which remain unclear. Shelburne blamed Priestley's health, while Priestley claimed Shelburne had no further use for him. Some contemporaries speculated that Priestley's outspokenness had hurt Shelburne's political career. Schofield argues that the most likely reason was Shelburne's recent marriage to Louisa Fitzpatrick—apparently, she did not like the Priestleys. Although Priestley considered moving to America, he eventually accepted Birmingham New Meeting's offer to be their minister.
Both Priestley and Shelburne's families upheld their Unitarian faith for generations. 
In December 2013, it was reported that Sir Christopher Bullock - the direct descendant of Shelburne's brother, Thomas Fitzmaurice (MP), had married his wife, Lady Bullock, née Barbara May Lupton, at London's Unitarian Essex Church in 1917. Barbara Lupton was the second cousin of Olive Middleton, née Lupton - the great grandmother of Catherine, Duchess of Cambridge. In 1914, Olive and Noel Middleton had married at Leeds' Mill Hill Chapel, which Priestly, as its minister, had once guided towards Unitarianism.
Birmingham (1780–91).
In 1780 the Priestleys moved to Birmingham and spent a happy decade surrounded by old friends, until they were forced to flee in 1791 by religiously motivated mob violence in what became known as the Priestley Riots. Priestley accepted the ministerial position at New Meeting on the condition that he be required to preach and teach only on Sundays, so that he would have time for his writing and scientific experiments. As in Leeds, Priestley established classes for the youth of his parish and by 1781, he was teaching 150 students. Because Priestley's New Meeting salary was only 100 guineas, friends and patrons donated money and goods to help continue his investigations. He was elected a Foreign Honorary Member of the American Academy of Arts and Sciences in 1782.
Chemical Revolution.
Many of the friends that Priestley made in Birmingham were members of the Lunar Society, a group of manufacturers, inventors, and natural philosophers who assembled monthly to discuss their work. The core of the group included men such as the manufacturer Matthew Boulton, the chemist and geologist James Keir, the inventor and engineer James Watt, and the botanist, chemist, and geologist William Withering. Priestley was asked to join this unique society and contributed much to the work of its members. As a result of this stimulating intellectual environment, he published several important scientific papers, including "Experiments relating to Phlogiston, and the seeming Conversion of Water into Air" (1783). The first part attempts to refute Lavoisier's challenges to his work on oxygen; the second part describes how steam is "converted" into air. After several variations of the experiment, with different substances as fuel and several different collecting apparatuses (which produced different results), he concluded that air could travel through more substances than previously surmised, a conclusion "contrary to all the known principles of hydrostatics". This discovery, along with his earlier work on what would later be recognised as gaseous diffusion, would eventually lead John Dalton and Thomas Graham to formulate the kinetic theory of gases.
In 1777, Antoine Lavoisier had published "Réflexions sur le phlogistique pour servir de suite à la théorie de la combustion et de la calcination", the first of what proved to be a series of attacks on phlogiston theory; it was against these attacks that Priestley responded in 1783. While Priestley accepted parts of Lavoisier's theory, he was unprepared to assent to the major revolutions Lavoisier proposed: the overthrow of phlogiston, a chemistry based conceptually on elements and compounds, and a new chemical nomenclature. Priestley's original experiments on "dephlogisticated air" (oxygen), combustion, and water provided Lavoisier with the data he needed to construct much of his system; yet Priestley never accepted Lavoisier's new theories and continued to defend phlogiston theory for the rest of his life. Lavoisier's system was based largely on the "quantitative" concept that mass is neither created nor destroyed in chemical reactions (i.e., the conservation of mass). By contrast, Priestley preferred to observe "qualitative" changes in heat, color, and particularly volume. His experiments tested "airs" for "their solubility in water, their power of supporting or extinguishing flame, whether they were respirable, how they behaved with acid and alkaline air, and with nitric oxide and inflammable air, and lastly how they were affected by the electric spark."
By 1789, when Lavoisier published his "Traité Élémentaire de Chimie" and founded the "Annales de Chimie", the new chemistry had come into its own. Priestley published several more scientific papers in Birmingham, the majority attempting to refute Lavoisier. Priestley and other Lunar Society members argued that the new French system was too expensive, too difficult to test, and unnecessarily complex. Priestley in particular rejected its "establishment" aura. In the end, Lavoisier's view prevailed: his new chemistry introduced many of the principles on which modern chemistry is founded.
Priestley's refusal to accept Lavoisier's "new chemistry"—such as the conservation of mass—and his determination to adhere to a less satisfactory theory has perplexed many scholars. Schofield explains it thus: "Priestley was never a chemist; in a modern, and even a Lavoisierian, sense, he was never a scientist. He was a natural philosopher, concerned with the economy of nature and obsessed with an idea of unity, in theology and in nature." Historian of science John McEvoy largely agrees, writing that Priestley's view of nature as coextensive with God and thus infinite, which encouraged him to focus on facts over hypotheses and theories, prompted him to reject Lavoisier's system. McEvoy argues that "Priestley's isolated and lonely opposition to the oxygen theory was a measure of his passionate concern for the principles of intellectual freedom, epistemic equality and critical inquiry." Priestley himself claimed in the last volume of "Experiments and Observations" that his most valuable works were his theological ones because they were "superior [in] dignity and importance".
Defender of English Dissenters and French revolutionaries.
Although Priestley was busy defending phlogiston theory from the "new chemists", most of what he published in Birmingham was theological. In 1782 he published the fourth volume of his "Institutes", "An History of the Corruptions of Christianity", describing how he thought the teachings of the early Christian church had been "corrupted" or distorted. Schofield describes the work as "derivative, disorganized, wordy, and repetitive, detailed, exhaustive, and devastatingly argued". The text addresses issues ranging from the divinity of Christ to the proper form for the Lord's Supper. Priestley followed up in 1786 with the provocatively titled book, "An History of Early Opinions concerning Jesus Christ, compiled from Original Writers, proving that the Christian Church was at first Unitarian". Thomas Jefferson would later write of the profound effect that these two books had on him: "I have read his Corruptions of Christianity, and Early Opinions of Jesus, over and over again; and I rest on them ... as the basis of my own faith. These writings have never been answered." Although a few readers such as Jefferson and other Rational Dissenters approved of the work, it was harshly reviewed because of its extreme theological positions, particularly its rejection of the Trinity.
In 1785, while Priestley was engaged in a pamphlet war over "Corruptions", he also published "The Importance and Extent of Free Enquiry", claiming that the Reformation had not really reformed the church. In words that would boil over into a national debate, he challenged his readers to enact change:
Let us not, therefore, be discouraged, though, for the present, we should see no great number of churches professedly unitarian ... We are, as it were, laying gunpowder, grain by grain, under the old building of error and superstition, which a single spark may hereafter inflame, so as to produce an instantaneous explosion; in consequence of which that edifice, the erection of which has been the work of ages, may be overturned in a moment, and so effectually as that the same foundation can never be built upon again ...
Although discouraged by friends from using such inflammatory language, Priestley refused to back down from his opinions in print and he included it, forever branding himself as "Gunpowder Joe". After the publication of this seeming call for revolution in the midst of the French Revolution, pamphleteers stepped up their attacks on Priestley and he and his church were even threatened with legal action.
In 1787, 1789, and 1790, Dissenters again tried to repeal the Test and Corporation Acts. Although initially it looked as if they might succeed, by 1790, with the fears of revolution looming in Parliament, few were swayed by appeals to equal rights. Political cartoons, one of the most effective and popular media of the time, skewered the Dissenters and Priestley. In Parliament, William Pitt and Edmund Burke argued against the repeal, a betrayal that angered Priestley and his friends, who had expected the two men's support. Priestley wrote a series of "Letters to William Pitt" and "Letters to Burke" in an attempt to persuade them otherwise, but these publications only further inflamed the populace against him.
Dissenters such as Priestley who supported the French Revolution came under increasing suspicion as scepticism regarding the revolution grew. In its propaganda against "radicals", Pitt's administration used the "gunpowder" statement to argue that Priestley and other Dissenters wanted to overthrow the government. Burke, in his famous "Reflections on the Revolution in France" (1790), tied natural philosophers, and specifically Priestley, to the French Revolution, writing that radicals who supported science in Britain "considered man in their experiments no more than they do mice in an air pump". Burke also associated republican principles with alchemy and insubstantial air, mocking the scientific work done by both Priestley and French chemists. He made much in his later writings of the connections between "Gunpowder Joe", science, and Lavoisier—who was improving gunpowder for the French in their war against Britain. Paradoxically, a secular statesman, Burke, argued against science and maintained that religion should be the basis of civil society, whereas a Dissenting minister, Priestley, argued that religion could not provide the basis for civil society and should be restricted to one's private life.
Birmingham riots of 1791.
The animus that had been building against Dissenters and supporters of the American and French Revolutions exploded in July 1791. Priestley and several other Dissenters had arranged to have a celebratory dinner on the anniversary of the storming of the Bastille, a provocative action in a country where many disapproved of the French Revolution and feared that it might spread to Britain. Amid fears of violence, Priestley was convinced by his friends not to attend. Rioters gathered outside the hotel during the banquet and attacked the attendees as they left. The rioters moved on to the New Meeting and Old Meeting churches—and burned both to the ground. Priestley and his wife fled from their home; although their son William and others stayed behind to protect their property, the mob overcame them and torched Priestley's house "Fairhill" at Sparkbrook, destroying his valuable laboratory and all of the family's belongings. Twenty-six other Dissenters’ homes and three more churches were burned in the three-day riot. Priestley spent several days hiding with friends until he was able to travel safely to London. The carefully executed attacks of the "mob" and the farcical trials of only a handful of the "leaders" convinced many at the time—and modern historians later—that the attacks were planned and condoned by local Birmingham magistrates. When George III was eventually forced to send troops to the area, he said: "I cannot but feel better pleased that Priestley is the sufferer for the doctrines he and his party have instilled, and that the people see them in their true light."
Hackney (1791–94).
Unable to return to Birmingham, the Priestleys eventually settled in Lower Clapton, a district in Hackney, Middlesex where he gave a series of lectures on history and natural philosophy at the Dissenting academy, the New College at Hackney. Friends helped the couple rebuild their lives, contributing money, books, and laboratory equipment. Priestley tried to obtain restitution from the government for the destruction of his Birmingham property, but he was never fully reimbursed. He also published "An Appeal to the Public on the Subject of the Riots in Birmingham" (1791), which indicted the people of Birmingham for allowing the riots to occur and for "violating the principles of English government".
The couple's friends urged them to leave Britain and emigrate to either France or the new United States, even though Priestley had received an appointment to preach for the Gravel Pit Meeting congregation. Priestley was minister between 1793 and 1794 and the sermons he preached there, particularly the two Fast Sermons, reflect his growing millenarianism, his belief that the end of the world was fast approaching. After comparing Biblical prophecies to recent history, Priestley concluded that the French Revolution was a harbinger of the Second Coming of Christ. Priestley's works had always had a millennial cast, but after the beginning of the French Revolution, this strain increased. He wrote to a younger friend that while he himself would not see the Second Coming, his friend "may probably live to see it ... It cannot, I think be more than twenty years [away]."
Daily life became more difficult for the family: Priestley was burned in effigy along with Thomas Paine; vicious political cartoons continued to be published about him; letters were sent to him from across the country, comparing him to the devil and Guy Fawkes; tradespeople feared the family's business; and Priestley's Royal Academy friends distanced themselves. As the penalties became harsher for those who spoke out against the government, Priestley examined options for removing himself and his family from England.
Joseph Priestley's son William was presented to the French Assembly and granted letters of naturalization on 8 June 1792. Priestley learned about it from the "Morning Chronicle". A decree of 26 August 1792 by the French National Assembly conferred French citizenship on Joseph Priestley and others who had "served the cause of liberty" by their writings. Priestley accepted French citizenship, considering it "the greatest of honours". In the French National Convention election on 5 September 1792, Joseph Priestley was elected to the French National Convention by at least two departments, (Orne and Rhône-et-Loire). However, he declined the honor, on the grounds that he was not fluent in French.
As relations between England and France worsened, however, a removal to France became impracticable. Following the declaration of war of February 1793, and the Aliens Bill of March 1793, which forbade correspondence or travel between England and France, William Priestley left France for America. Joseph Priestley's sons Harry and Joseph chose to leave England for America in August 1793. Finally Priestley himself followed with his wife, boarding the "Sansom" at Gravesend on 7 April 1793. Five weeks after Priestley left, William Pitt's administration began arresting radicals for seditious libel, resulting in the famous 1794 Treason Trials.
Pennsylvania (1794–1804).
The Priestleys arrived in New York City in 1794, where they were fêted by various political factions vying for Priestley's endorsement. Priestley declined their entreaties, hoping to avoid political discord in his new country. Before travelling to a new home in the backwoods of Northumberland County, Pennsylvania, at Point township (now Northumberland borough), Dr and Mrs Priestley lodged in Philadelphia, where Priestley gave a series of sermons, which led to the founding of the First Unitarian Church of Philadelphia. Priestley turned down an opportunity to teach chemistry at the University of Pennsylvania.
Priestley's son Joseph Priestley Jr. was a leading member of a consortium that had purchased 300,000 acres of virgin woodland between the forks of Loyalsock Creek, which they intended to lease or sell in 400 acre plots, with payment deferred to seven annual instalments, with interest. His brothers, William and Henry bought a 284-acre plot of woodland, which they attempted to transform into a farm, later called "Fairhill", felling and uprooting trees; making lime to sweeten the soil by building their own lime kilns. Henry Priestley died 11 December 1795, possibly of malaria which he may have contracted after landing at New York. Mary Priestley's health, already poor, deteriorated further; although William's wife, Margaret Foulke-Priestley moved in with the couple to nurse Mary twenty-four hours a day, Mary Priestley died 17 September 1796.
Dr Priestley now moved in with his elder son, Joseph Jr., and wife Elizabeth Ryland-Priestley. Thomas Cooper, whose son, Thomas Jr., was living with the Priestleys, was a frequent visitor.
Since his arrival in America, Priestley had continued to defend his Christian Unitarian beliefs; now, falling increasingly under the influence of Thomas Cooper and Elizabeth Ryland-Priestley, he was unable to avoid becoming embroiled in political controversy. In 1798, when, in response to the Pinckney affair, a belligerent President Adams sought to enlarge the navy and mobilise the militia into what Priestley and Cooper saw as a 'standing army', Priestley published an anonymous newspaper article: "Maxims of political arithmetic", which attacked Adams, defended free trade, and advocated a form of Jeffersonian isolationism. In the same year, a small package, addressed vaguely: "Dr Priestley in America," was seized by the Royal Navy on board a neutral Danish boat. It was found to contain three letters, one of which was signed by the radical printer John Hurford Stone. These intercepted letters were published in London, and copied in numerous papers in America. One of the letters was addressed to "MBP", with a note: "I inclose a note for our friend MBP—but, as ignorant of the name he bears at present among you, I must beg you to seal and address it." This gave the intercepted letters a tinge of intrigue. Fearful lest they be taken as evidence of him being a 'spy in the interest of France', Priestley sent a clumsy letter to numerous newspaper editors, in which he naively named "MBP" (Member of the British Parliament) as Mr. Benjamin Vaughan, who "like me, thought it necessary to leave England, and for some time is said to have assumed a feigned name." William Cobbett, in his "Porcupine's Gazette", 20 August 1798, added that Priestley "has told us who Mr MBP is, and has confirmed me in the opinion of their both being spies in the interest of France."
Joseph Priestley Jr., left on a visit to England at Christmas 1798, not returning until August 1800. In his absence, his wife Elizabeth Ryland-Priestley and Thomas Cooper became increasing close, collaborating in numerous political essays. Priestley allowed himself to fall too heavily under Elizabeth and Cooper's influences, even helping hawk a seditious handbill Thomas Cooper had printed, around Point township, and across the Susquehanna at Sunbury. In September 1799, William Cobbett printed extracts from this handbill, asserting that: "Dr Priestley has taken great pains to circulate this address, has travelled through the country for the purpose, and is in fact the patron of it." He challenged Priestley to "clear himself of the accusation" or face prosecution." Barely a month later, in November and December 1799, Priestley stepped forward in his own defence, with his "Letters to the inhabitants of Northumberland".
Priestley’s son, William, now living in Philadelphia, was increasingly embarrassed by his father's actions. He confronted his father, expressing John and Benjamin Vaughan’s unease, his own wife's concerns about Elizabeth Ryland-Priestley's dietary care, and his own concerns at the closeness of Elizabeth Ryland-Priestley and Thomas Cooper's relationship, and their adverse influence on Dr Priestley; but this only led to a further estrangement between William and his sister-in-law. When, a while later, Priestley's household suffered a bout of food poisoning, perhaps from puking sickness or a bacterial infection, Elizabeth Ryland-Priestley, falsely accused William of having poisoned the family's flour. Although this spiteful and ridiculous allegation has attracted the attention of some modern historians, it has been proven to be utterly without foundation.
Priestley continued the educational projects that had always been important to him, helping to establish the "Northumberland Academy" and donating his library to the fledging institution. He exchanged letters regarding the proper structure of a university with Thomas Jefferson, who used this advice when founding the University of Virginia. Jefferson and Priestley became close, and when he had completed his "General History of the Christian Church", he dedicated it to President Jefferson, writing that "it is now only that I can say I see nothing to fear from the hand of power, the government under which I live being for the first time truly favourable to me."
Priestley tried to continue his scientific investigations in America with the support of the American Philosophical Association. He was hampered by lack of news from Europe; unaware of the latest scientific developments, Priestley was no longer on the forefront of discovery. Although the majority of his publications focused on defending phlogiston theory, he also did some original work on spontaneous generation and dreams. Despite Priestley's reduced scientific output, his presence stimulated American interest in chemistry.
By 1801, Priestley had become so ill that he could no longer write or experiment. He died on the morning of 6 February 1804, aged seventy and was buried at Riverview Cemetery in Northumberland, Pennsylvania.
Priestley's epitaph reads:
Legacy.
By the time he died in 1804, Priestley had been made a member of every major scientific society in the Western world and he had discovered numerous substances. The 19th-century French naturalist George Cuvier, in his eulogy of Priestley, praised his discoveries while at the same time lamenting his refusal to abandon phlogiston theory, calling him "the father of modern chemistry [who] never acknowledged his daughter". Priestley published more than 150 works on topics ranging from political philosophy to education to theology to natural philosophy. He led and inspired British radicals during the 1790s, paved the way for utilitarianism, and helped found Unitarianism. A wide variety of philosophers, scientists, and poets became associationists as a result of his redaction of David Hartley's "Observations on Man", including Erasmus Darwin, Coleridge, William Wordsworth, John Stuart Mill, Alexander Bain, and Herbert Spencer. Immanuel Kant praised Priestley in his "Critique of Pure Reason" (1781), writing that he "knew how to combine his paradoxical teaching with the interests of religion". Indeed, it was Priestley's aim to "put the most 'advanced' Enlightenment ideas into the service of a rationalized though heterodox Christianity, under the guidance of the basic principles of scientific method".
Considering the extent of Priestley's influence, relatively little scholarship has been devoted to him. In the early 20th century, Priestley was most often described as a conservative and dogmatic scientist who was nevertheless a political and religious reformer. In a historiographic review essay, historian of science Simon Schaffer describes the two dominant portraits of Priestley: the first depicts him as "a playful innocent" who stumbled across his discoveries; the second portrays him as innocent as well as "warped" for not understanding their implications better. Assessing Priestley's works as a totality has been difficult for scholars because of his wide-ranging interests. His scientific discoveries have usually been divorced from his theological and metaphysical publications to make an analysis of his life and writings easier, but this approach has been challenged recently by scholars such as John McEvoy and Robert Schofield. Although early Priestley scholarship claimed that his theological and metaphysical works were "distractions" and "obstacles" to his scientific work, scholarship published in the 1960s, 1970s, and 1980s maintained that Priestley's works constituted a unified theory. However, as Schaffer explains, no convincing synthesis of his work has yet been expounded. More recently, in 2001, historian of science Dan Eshet has argued that efforts to create a "synoptic view" have resulted only in a rationalisation of the contradictions in Priestley's thought, because they have been "organized around philosophical categories" and have "separate[d] the producers of scientific ideas from any social conflict".
Priestley has been remembered by the towns in which he served as a reforming educator and minister and by the scientific organisations he influenced. Two educational institutions have been named in his honour—Priestley College in Warrington and Joseph Priestley College in Leeds (now part of Leeds City College)—and an asteroid, 5577 Priestley, discovered in 1986 by Duncan Waldron. In Birstall, the Leeds City Square, and in Birmingham, he is memorialised through statues, and plaques commemorating him have been posted in Birmingham, Calne and Warrington. Also, since 1952 Dickinson College has presented the Priestley Award to a scientist who makes "discoveries which contribute to the welfare of mankind". The main undergraduate chemistry laboratories at the University of Leeds were refurbished as part of a £4m refurbishment plan in 2006 and renamed as the Priestley Laboratories in his honour as a prominent chemist from Leeds.
In addition to the plaque in Calne, Wiltshire commemorating Priestley's discovery of Oxygen, Dr's Pond, a local wildlife habitat was so named in honor of Dr Joseph Priestly and the work he carried out whilst in the town.
Additional recognition for Priestley's work is marked by a National Historic Chemical Landmark designation for his discovery of oxygen, made on 1 August 1994, at the Priestley House in Northumberland, Penn., by the American Chemical Society. Similar international recognition was made on 7 August 2000, at Bowood House in Wiltshire, UK.
References.
Primary materials.
</dl>
Biographies.
The most exhaustive biography of Priestley is Robert Schofield's recent two-volume work; several one-volume treatments exist, all somewhat older: Gibbs, Holt and Thorpe. Graham and Smith focus on Priestley's life in America and Uglow and Jackson both discuss Priestley's life in the context of other developments in science.
</dl>
Secondary materials.
</dl>

</doc>
<doc id="40177" url="http://en.wikipedia.org/wiki?curid=40177" title="550s BC">
550s BC


</doc>
<doc id="40178" url="http://en.wikipedia.org/wiki?curid=40178" title="7th millennium BC">
7th millennium BC

During the 7th millennium BC, agriculture spreads from Anatolia to the Balkans.
World population was essentially stable at around 5 million people, living mostly scattered around the globe in small hunter-gatherer bands. In the agricultural communities of the Middle East, the cow was domesticated and use of pottery became common, spreading to Europe and South Asia, and the first metal (gold and copper) ornaments were made.

</doc>
<doc id="40179" url="http://en.wikipedia.org/wiki?curid=40179" title="6th millennium BC">
6th millennium BC

During the 6th millennium BC, agriculture spread from the Balkans to Italy and Eastern Europe, and also from Mesopotamia to Egypt. World population was essentially stable at numbers ranging between approximately 5 and 7 million.

</doc>
<doc id="40180" url="http://en.wikipedia.org/wiki?curid=40180" title="Bessemer process">
Bessemer process

The Bessemer process was the first inexpensive industrial process for the mass-production of steel from molten pig iron prior to the open hearth furnace. The key principle is removal of impurities from the iron by oxidation with air being blown through the molten iron. The oxidation also raises the temperature of the iron mass and keeps it molten.
Related decarburizing with air processes had been used outside of Europe for hundreds of years, but not on an industrial scale. The process has existed since the 11th century in East Asia, where the scholar Shen Kuo describes its use in the Chinese iron and steel industry. In the 17th century, accounts by European travelers detailed its possible use by the Japanese. The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856. The process was also claimed to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back this claim up.
The process using a basic refractory lining is known as the "basic Bessemer process" or Gilchrist-Thomas process after the discoverer Sidney Gilchrist Thomas.
Details.
Oxidation.
The oxidation process removes and skims off impurities such as silicon, manganese, and carbon in the form of oxides. These oxides either escape as gas or form a solid slag. The refractory lining of the converter also plays a role in the conversion—the clay lining is used in the "acid Bessemer", in which there is low phosphorus in the raw material. Dolomite is used when the phosphorus content is high in the alkaline Bessemer (limestone or magnesite linings are also sometimes used instead of dolomite)—this is also known as a "Gilchrist-Thomas converter", named after its inventor, Sidney Gilchrist Thomas. In order to give the steel the desired properties, other substances could be added to the molten steel when conversion was complete, such as spiegeleisen (a ferromanganese alloy).
Managing the process.
When the required steel has been formed, it is poured out into ladles and then transferred into moulds while the lighter slag is left behind. The conversion process, called the "blow", is completed in around twenty minutes. During this period the progress of the oxidation of the impurities is judged by the appearance of the flame issuing from the mouth of the converter: the modern use of photoelectric methods of recording the characteristics of the flame has greatly aided the blower in controlling the final quality of the product. After the blow, the liquid metal is recarburized to the desired point and other alloying materials are added, depending on the desired product.
A Bessemer converter can treat a "heat," the term for a batch of hot metal, of 5 to 30 tonnes at a time. They usually are operated in pairs; one being blown while another being filled or tapped.
Predecessor processes.
Before the Bessemer process, Western Europe and the United States relied on the puddling process to reduce the carbon content of white cast iron (refined pig iron), converting it to wrought iron. It was possible to make low-quality puddled steel, but the process was difficult to control and quality varied. High-quality steel was made by the reverse process of adding carbon to carbon-free wrought iron, usually imported from Sweden. The manufacturing process, called the cementation process, consisted of heating bars of wrought iron together with charcoal for periods of up to a week in a long stone box. This produced blister steel. The blister steel was then put in a crucible with wrought iron and melted, producing crucible steel. Up to 3 tons of expensive coke was burnt for each ton of steel produced. Such steel when rolled into bars was sold at £50 to £60 (approximately £3,390 to £4,070 in 2008) a long ton. The most difficult and work-intensive part of the process, however, was the production of wrought iron done in finery forges in Sweden.
This process was refined in the 18th century with the introduction of Benjamin Huntsman's crucible steel-making techniques, which added an additional three hours firing time and required additional large quantities of coke. In making crucible steel the blister steel bars were broken into pieces and melted in small crucibles each containing 20 kg or so. This produced higher quality crucible steel but increased the cost. The Bessemer process reduced the time needed to make steel of this quality to about half an hour while requiring only the coke needed to melt the pig iron initially. The earliest Bessemer converters produced steel for £7 a long ton, although it initially sold for around £40 a ton.
History.
A system akin to the Bessemer process has existed since the 11th century in East Asia. Economic historian Robert Hartwell writes that the Chinese of the Song Dynasty innovated a "partial decarbonization" method of repeated forging of cast iron under a cold blast. Sinologist Joseph Needham and historian of metallurgy Theodore A. Wertime have described the method as a predecessor to the Bessemer process of making steel. This process was first described by the prolific scholar and polymath government official Shen Kuo (1031–1095) in 1075 when he visited Cizhou. Hartwell states that perhaps the earliest center where this was practiced was the great iron-production district along the Henan-Hebei border during the 11th century. In 1740 Benjamin Huntsman developed the crucible technique for steel manufacture, at his workshop in the district of Handsworth in Sheffield. This process had an enormous impact on the quantity and quality of steel production.
The Japanese may have made use of the Bessemer process, which was observed by European travelers in the 17th century. The adventurer Johan Albrecht de Mandelslo describes the process in a book published in English in 1669. He writes, "They have, among others, particular invention for the melting of iron, without the using of fire, casting it into a tun done about on the inside without about half a foot of earth, where they keep it with continual blowing, take it out by ladles full, to give it what form they please." According to historian Donald Wagner, Madelslo did not personally visit to Japan, so his description of the process is likely derived from the accounts of other Europeans who had traveled to Japan. Wagner believes there is a possibility that the Japanese process is similar to the Bessemer process, but cautions that alternative explanations are also plausible.
In the early 1850s, the American inventor William Kelly experimented with a method similar to the Bessemer process. Wagner writes that Kelly may have been inspired by techniques introduced by Chinese ironworkers hired by Kelly in 1854. When Bessemer's patent for the process was reported by "Scientific American", Kelly responded by writing a letter to the magazine. In the letter, Kelly states that he had previously experimented with the process and claimed that Bessemer knew of Kelly's discovery. He wrote that "I have reason to believe my discovery was known in England three or four years ago, as a number of English puddlers visited this place to see my new process. Several of them have since returned to England and may have spoken of my invention there."
Sir Henry Bessemer described the origin of his invention in his autobiography written in 1890. During the outbreak of the Crimean War, many English industrialists and inventors became interested in military technology. According to Bessemer, his invention was inspired by a conversation with Napoleon III in 1854 pertaining to the steel required for better artillery. Bessemer claimed that it "was the spark which kindled one of the greatest revolutions that the present century had to record, for during my solitary ride in a cab that night from Vincennes to Paris, I made up my mind to try what I could to improve the quality of iron in the manufacture of guns." At the time steel was used to make only small items like cutlery and tools, but was too expensive for cannons. Starting in January 1855 he began working on a way to produce steel in the massive quantities required for artillery and by October he filed his first patent related to the Bessemer process. He patented the method a year later in 1856.
According to his autobiography Bessemer was working with an ordinary reverberatory furnace but during a test, some pieces of pig iron were jostled off the side of the ladle, and were left above the ladle in the furnace's heat. When Bessemer went to push them into the ladle, he found that they were steel shells: the hot air alone had converted the outsides of the iron pieces to steel. This crucial discovery led him to completely redesign his furnace so that it would force high-pressure air through the molten iron using special air pumps. Intuitively this would seem to be folly because it would cool the iron. Instead, the oxygen in the forced air ignited silicon and carbon impurities in the iron, starting a positive feedback loop. As the iron became hotter, more impurities burned off, making the iron even hotter and burning off more impurities, producing a batch of hotter, purer, molten iron, which converts to steel more easily.
Bessemer licensed the patent for his process to four ironmasters, for a total of £27,000, but the licensees failed to produce the quality of steel he had promised—it was "rotten hot and rotten cold", according to his friend, William Clay—and he later bought them back for £32,500. His plan had been to offer the licenses to one company in each of several geographic areas, at a royalty price per ton that included a lower rate on a proportion of their output in order to encourage production, but not so large a proportion that they might decide to reduce their selling prices. By this method he hoped to cause the new process to gain in standing and market share.
He realised that the technical problem was due to impurities in the iron and concluded that the solution lay in knowing when to turn off the flow of air in his process so that the impurities were burned off but just the right amount of carbon remained. However, despite spending tens of thousands of pounds on experiments, he could not find the answer. Certain grades of steel are sensitive to the 78% nitrogen which was part of the air blast passing through the steel.
Bessemer was sued by the patent purchasers who couldn't get it to work. In the end Bessemer set up his own steel company because he knew how to do it, even though he could not convey it to his patent users. Bessemer's company became one of the largest in the world and changed the face of steel making.
The solution was first discovered by English metallurgist Robert Forester Mushet, who had carried out thousands of experiments in the Forest of Dean. His method was to first burn off, as far as possible, "all" the impurities and carbon, then reintroduce carbon and manganese by adding an exact amount of spiegeleisen. This had the effect of improving the quality of the finished product, increasing its malleability—its ability to withstand rolling and forging at high temperatures and making it more suitable for a vast array of uses.
The first company to license the process was the Manchester firm of W & J Galloway, and they did so before Bessemer announced it at Cheltenham in 1856. They are not included in his list of the four to whom he refunded the license fees. However, they subsequently rescinded their license in 1858 in return for the opportunity to invest in a partnership with Bessemer and others. This partnership began to manufacture steel in Sheffield from 1858, initially using imported charcoal pig iron from Sweden. This was the first commercial production.
Sidney Gilchrist Thomas, a Londoner with a Welsh father, was an industrial chemist who decided to tackle the problem of phosphorus in iron, which resulted in the production of low grade steel. Believing that he had discovered a solution, he contacted his cousin, Percy Gilchrist, who was a chemist at the Blaenavon ironworks. The manager at the time, Edward Martin, offered Sidney equipment for large-scale testing and helped him draw up a patent that was taken out in May, 1878. Sidney Gilchrist Thomas's invention consisted of using dolomite or sometimes limestone linings for the Bessemer converter rather than clay, and it became known as the 'basic' Bessemer rather than the 'acid' Bessemer process. An additional advantage was that the processes formed more slag in the converter, and this could be recovered and used very profitably as a phosphate fertilizer.
Patent battles.
Patents of such value did not escape criticism, and invalidity was urged against them on various grounds. But Bessemer was able to maintain them intact without litigation, though he found it advisable to buy up the rights of one patentee.
In the case of Robert Forester Mushet, he was assisted by the patent being allowed to lapse in 1859 through non-payment of fees. Mushet's procedure was not essential and Bessemer proved this in 1865 by exhibiting a series of steel samples made using his process alone, but the value of the procedure was shown by its near universal adoption in conjunction with the Bessemer process. Whether or not Mushet's patents could have been sustained is not known, but in 1866 Robert Mushet's 16-year-old daughter travelled to London to confront Henry Bessemer at his offices, arguing that Bessemer's success was based on the results of her father’s work. Bessemer decided to pay Mushet an annual pension of £300, a very considerable sum, which he paid for 25 years.
In 1866, Bessemer also provided finance for Zerah Colburn, the American locomotive engineer and journalist, to start a new weekly engineering newspaper called "Engineering" based in Bedford Street, London. It was not until many years later that the name of Colburn's benefactor was revealed. Prior to the launch of "Engineering", Colburn, through the pages of "The Engineer", had given support to Bessemer's work on steel and steelmaking.
Importance.
The Bessemer process revolutionized steel manufacture by decreasing its cost, from £40 per long ton to £6–7 per long ton, along with greatly increasing the scale and speed of production of this vital raw material. The process also decreased the labor requirements for steel-making. Prior to its introduction, steel was far too expensive to make bridges or the framework for buildings and thus wrought iron had been used throughout the Industrial Revolution. After the introduction of the Bessemer process, steel and wrought iron became similarly priced, and some users, primarily railroads, turned to steel. Quality problems, such as brittleness caused by nitrogen in the blowing air, prevented Bessemer steel from being used for many structural applications. Open-hearth steel was suitable for structural applications.
Steel greatly improved the productivity of railroads. Steel rails lasted ten times longer than iron rails. Steel rails, which became heavier as prices fell, could carry heavier locomotives, which could pull longer trains. Steel rail cars were longer and were able to increase the freight to car weight from 1:1 to 2:1.
As early as 1895 in the UK it was being noted that the heyday of the Bessemer process was over and that the open hearth method predominated. The "Iron and Coal Trades Review" said that it was "in a semi-moribund condition. Year after year, it has not only ceased to make progress, but it has absolutely declined." It has been suggested, both at that time and more recently, that the cause of this was the lack of trained personnel and investment in technology rather than anything intrinsic to the process itself. For example, one of the major causes of the decline of the giant ironmaking company Bolckow Vaughan of Middlesbrough was its failure to upgrade its technology. The basic process, the Thomas-Gilchrist process, remained longer in use, especially in Continental Europe, where iron ores were of high phosphorus content and open hearth process was not able to remove all phosphorus; almost all inexpensive construction steel in Germany was produced with this method in the 1950s and 1960s. It was eventually superseded by basic oxygen steelmaking.
The Bessemer Process in the United States.
While visiting Europe to obtain information on shipbuilding, armor, and armaments from 1862 to 1863, Alexander Lyman Holley visited Bessemer's Sheffield works, and expressed interest in licensing the process for use in the US. Upon returning to the US, Holley met with the famous inventor John Ericsson, who referred Holley to a pair of businessmen who had helped him build the Civil War ironclad USS Monitor, John F. Winslow and John Augustus Griswold. With Winslow and Griswold's support, Holley returned to England in 1863, and paid Bessemer £10,000 to license the technology. The trio began setting up a mill in Troy, New York in 1865. The factory contained a number of Holley's innovations that greatly improved productivity over Bessemer's factory in Sheffield, and the owners gave a successful public exhibition in 1867. The Troy factory attracted the attention of the Pennsylvania Railroad, who wanted to use the new process to manufacture steel rail, and ended up funding Holley's second mill as part of its Pennsylvania Steel subsidiary. Between 1866 and 1877, the partners were able to license a total of 11 Bessemer steel mills. One of the investors they attracted was Andrew Carnegie, who saw great promise in the new steel technology after a visit to Bessemer in 1872, and saw it as a useful adjunct to his existing businesses, the Keystone Bridge Company and the Union Iron Works. Holley built the new steel mill for Carnegie, and continued to improve and refine the process. The new mill, known as the Edgar Thomson Steel Works, opened in 1875, and started the growth of the United States as a major world steel producer.
Obsolescence.
In the U.S., commercial steel production using this method stopped in 1968. It was replaced by processes such as the basic oxygen (Linz-Donawitz) process, which offered better control of final chemistry. The Bessemer process was so fast (10–20 minutes for a heat) that it allowed little time for chemical analysis or adjustment of the alloying elements in the steel. Bessemer converters did not remove phosphorus efficiently from the molten steel; as low-phosphorus ores became more expensive, conversion costs increased. The process permitted only limited amount of scrap steel to be charged, further increasing costs, especially when scrap was inexpensive. Use of electric arc furnace technology competed favourably with the Bessemer process resulting in its obsolescence.
Basic oxygen steelmaking is essentially an improved version of the Bessemer process (decarburization by blowing oxygen as gas into the heat rather than burning the excess carbon away by adding oxygen carrying substances into the heat). The advantages of pure oxygen blast over air blast was known to Henry Bessemer, but the 19th century technology was not advanced enough to allow for the production of the large quantities of pure oxygen to make it economically feasible for use.
External links.
 "" in "Popular Science Monthly" Volume 19, October 1881

</doc>
<doc id="40181" url="http://en.wikipedia.org/wiki?curid=40181" title="9th millennium BC">
9th millennium BC

The 9th millennium BC marks the beginning of the Neolithic period.
Agriculture spread throughout the Fertile Crescent and use of pottery became more widespread. Larger settlements like Jericho arose along salt and flint trade routes. Northern Eurasia was resettled as the glaciers of the last glacial maximum retreated. World population was at a few million people, likely below 5 million.

</doc>
<doc id="40182" url="http://en.wikipedia.org/wiki?curid=40182" title="Photomontage">
Photomontage

Photomontage is the process and the result of making a composite photograph by cutting and joining two or more photographs into a new image. Sometimes the resulting composite image is photographed so that a final image may appear as a seamless photographic print. A similar method, although one that does not use film, is realized today through image-editing software. This latter technique is referred to by professionals as "compositing", and in casual usage is often called "photoshopping", due to a particular software often used. A composite of related photographs to extend a view of a single scene or subject would not be labeled as a montage.
History.
Author Oliver Grau in his book, "Virtual Art: From Illusion to Immersion", notes that the creation of artificial immersive virtual reality, arising as a result of technical exploitation of new inventions, is a long-standing human practice throughout the ages. Such environments as dioramas were made of composited images.
The first and most famous mid-Victorian photomontage (then called combination printing) was "The Two Ways of Life" (1857) by Oscar Rejlander, followed shortly thereafter by the images of photographer Henry Peach Robinson such as "Fading Away" (1858). These works actively set out to challenge the then-dominant painting and theatrical tableau vivants.
Fantasy photomontage postcards were popular in the Victorian and Edwardian periods. The preeminent producer in this period was the Bamforh Company, in Holmfirth, West Yorkshire, and New York. The high point of its popularity came, however, during World War I, when photographers in France, Great Britain, Germany, Austria, and Hungary produced a profusion of postcards showing soldiers on one plane and lovers, wives, children, families, or parents on another. Many of the early examples of fine-art photomontage consist of photographed elements superimposed on watercolours, a combination returned to by (e.g.) George Grosz in about 1915. He was part of the Dada movement in Berlin, which was instrumental in making montage into a modern art-form. They first coined the term "photomontage" at the end of World War I, around 1918 or 1919.
The other major exponents of photomontages were John Heartfield, Hannah Höch, Kurt Schwitters, Raoul Hausmann, and Johannes Baader. Individual photographs combined together to create a new subject or visual image proved to be a powerful tool for the Dadists protesting World War I and the interests that they believed inspired the war. Photomontage survived Dada and was a technique inherited and used by European Surrealists such as Salvador Dalí. Its influence also spread to Japan where avant-garde painter Harue Koga produced photomontage-style paintings based on images culled from magazines. The world's first retrospective show of photomontage was held in Germany in 1931. A later term coined in Europe was, "photocollage", which usually referred to large and ambitious works that added typography, brushwork, or even objects stuck to the photomontage.
Parallel to the Germans, Russian Constructivist artists such as El Lissitzky, Alexander Rodchenko, and the husband-and-wife team of Gustav Klutsis and Valentina Kulagina created pioneering photomontage work as propaganda, such as the journal USSR in Construction, for the Soviet government. In the education sphere, media arts director Rene Acevedo and Adrian Brannan have left their mark on art classrooms the world over.
Following his exile to Mexico in the late 1930s, Spanish Civil War activist and montage artist, Joseph Renau, compiled his acclaimed, "Fata Morgana USA: the American Way of Life", a book of photomontage images highly critical of Americana and North American "consumer culture". His contemporary, Lola Alvarez Bravo, experimented with photomontage on life and social issues in Mexican cities.
In Argentina during the late 1940s, the German exile, Grete Stern, began to contribute photomontage work on the theme of "Sueños" (Dreams), as part of a regular psychoanalytical article in the magazine, "Idilio".
The pioneering techniques of early photomontage artists were co-opted by the advertising industry from the late 1920s onward. The American photographer Alfred Gescheidt, while working primarily in advertising and commercial art in the 1960s and 1970s, used photomontage techniques to create satirical posters and postcards.:139
Techniques.
Other methods for combining images are also called photomontage, such as Victorian "combination printing", the printing of more than one negative on a single piece of printing paper (e.g. O. G. Rejlander, 1857), front-projection and computer montage techniques. Much as a collage is composed of multiple facets, artists also combine montage techniques. A series of black and white "photomontage projections" by Romare Bearden (1912–1988) is an example. His method began with compositions of paper, paint, and photographs put on boards measuring 8½ × 11 inches. Bearden fixed the imagery with an emulsion that he then applied with hand roller. Subsequently, he photographed and enlarged them. The nineteenth century tradition of physically joining multiple images into a composite and photographing the results prevailed in press photography and offset lithography until the widespread use of digital image editing.
Contemporary photograph editors in magazines now create "paste-ups" digitally. Creating a photomontage has, for the most part, become easier with the advent of computer software such as Adobe Photoshop, Paint Shop Pro, Corel Photopaint, Pixelmator, Paint.NET, or GIMP. These programs make the changes digitally, allowing for faster workflow and more precise results. They also mitigate mistakes by allowing the artist to "undo" errors. Yet some artists are pushing the boundaries of digital image editing to create extremely time-intensive compositions that rival the demands of the traditional arts. The current trend is to create images that combine painting, theatre, illustration, and graphics in a seamless photographic whole.
Ethical issues.
A photomontage may contain elements at once real and imaginary. Combined photographs and digital manipulations may set up a conflict between aesthetics and ethics – for instance, in fake photographs that are presented to the world as real news. For example, in the United States, the National Press Photographers Association (NPPA) has set out a Code of Ethics promoting the accuracy of published images, advising that photographers "do not manipulate images ... that can mislead viewers or misrepresent subjects."
Scrapbooking.
Photomontage also may be present in the scrapbooking phenomenon, in which family images are pasted into scrapbooks and a collage created along with paper ephemera and decorative items.
Digital art scrapbooking employs a computer to create simple collage designs and captions. The amateur scrapbooker can turn home projects into professional output, such as CDs, DVDs, displays on television, uploads to a website for viewing, or assemblies into one or more books for sharing.
Photograph manipulation.
Photograph manipulation refers to alterations made to an image. Often, the goal of photograph manipulation is to create another 'realistic' image. This has led to numerous political and ethical concerns, particularly in journalism.

</doc>
<doc id="40183" url="http://en.wikipedia.org/wiki?curid=40183" title="10th century BC">
10th century BC

The 10th century BC started the first day of 1000 BC and ended the last day of 901 BC. This period followed the Bronze Age collapse in the Near East, and the century saw the Early Iron Age take hold there. The Greek Dark Ages which had come about in 1200 BC continued. The Neo-Assyrian Empire is established towards the end of the 10th century BC. In Iron Age India, the Vedic period is ongoing. In China, the Zhou Dynasty is in power. The European Bronze Age continued with Urnfield culture. Japan was inhabited by an evolving hunter-gatherer society during the Jomon period.
Events.
Late 10th century BC: 
Sovereign States.
See: List of sovereign states in the 10th century BC.
References.
 

</doc>
<doc id="40186" url="http://en.wikipedia.org/wiki?curid=40186" title="8th millennium BC">
8th millennium BC

In the 8th millennium BC, agriculture became widely practised in the Fertile Crescent and Anatolia. 
Pottery became widespread (with independent development in Central America) and animal husbandry (pastoralism) spread to Africa and Eurasia. World population was approximately 5 million.

</doc>
<doc id="40187" url="http://en.wikipedia.org/wiki?curid=40187" title="Conjugate acid">
Conjugate acid

A conjugate acid, within the Brønsted–Lowry acid–base theory, is a species formed by the reception of a proton (H+), by a base—in other words, the base with a hydrogen ion added to it. On the other hand, a conjugate base is merely what is left after an acid has donated a proton in a chemical reaction. Hence, a conjugate base is a species formed by the removal of a proton from an acid.
In summary, this can be represented as the following chemical reaction:
Johannes Nicolaus Brønsted and Martin Lowry introduced the Brønsted–Lowry theory,
which proposed that any compound that can transfer a proton to any other compound is an acid, and the compound that accepts the proton is a base. A proton is a nuclear particle with a unit positive electrical charge; it is represented by the symbol H+ because it constitutes the nucleus of a hydrogen atom.
Acid-base reactions.
In an acid-base reaction, an acid plus a base reacts to form a conjugate base plus a conjugate acid:
Conjugates are formed when an acid loses a hydrogen proton or a base gains a hydrogen proton. Refer to the following figure:
We say that the water molecule is the conjugate acid of the hydroxide ion after the latter received the hydrogen proton donated by ammonium. On the other hand, ammonia is the conjugate base for the acid ammonium after ammonium has donated a hydrogen ion towards the production of the water molecule. We can also refer to OH- as a conjugate base of H2O, since the water molecule donates a proton towards the production of NH4+ in the reverse reaction, which is the predominating process in nature due to the strength of the base NH3 over the hydroxide ion. Based on this information, it is clear that the terms "Acid", "Base", "conjugate acid", and "conjugate base" are not fixed for a certain chemical species; but are interchangeable according to the reaction taking place.
Strength of conjugates.
The strength of a conjugate acid is directly proportional to its dissociation constant. If a conjugate acid is strong, its dissociation will have a higher equilibrium constant and the products of the reaction will be favored. The strength of a conjugate base can be seen as the tendency of the species to "pull" hydrogen protons towards itself. If a conjugate base is classified as strong, it will "hold on" to the hydrogen proton when in solution and its acid will not dissociate. 
If a chemical species is classified as a weak acid, its conjugate base will be strong in nature. This can be observed in ammonia's (relatively strong base) reaction with water. The reaction proceeds until most of the ammonia has been transformed to ammonium. This shift to the right in the chemical equilibrium of the reaction means that ammonium does not dissociate easily in water (weak acid), and its conjugate base is stronger than the hydroxide ion.
On the other hand, if a species is classified as a strong acid, its conjugate base will be weak in nature. An example of this case would be the dissociation of Hydrochloric acid HCl in water. Since HCl is a strong acid (it dissociates to a great extent), its conjugate base (Cl-) will be a weak conjugate base. Therefore, in this system, most H+ will be in the form of a Hydronium ion H3O+ instead of attached to a Cl anion and the conjugate base will be weaker than a water molecule.
To summarize, the stronger the acid or base, the weaker the conjugate and vice versa.
Identifying conjugate acid-base pairs.
The acid and conjugate base as well as the base and conjugate acid are known as conjugate pairs. When finding a conjugate acid or base, it is important to look at the reactants of the chemical equation. In this case, the reactants are the acids and bases, and the acid corresponds to the conjugate base on the product side of the chemical equation; as does the base to the conjugate acid on the product side of the equation.
To identify the conjugate acid, look for the pair of compounds that are related. The acid-base reaction can be viewed in a before and after sense. The before is the reactant side of the equation, the after is the product side of the equation. The conjugate acid in the after side of an equation gains a hydrogen ion, so in the before side of the equation the compound that has one less hydrogen ion of the conjugate acid is the base. The conjugate base in the after side of the equation lost a hydrogen ion, so in the before side of the equation the compound that has one more hydrogen ion of the conjugate base is the acid.
Consider the following acid-base reaction:
Nitric acid (HNO3) is an "acid" because it donates a proton to the water molecule and its "conjugate base" is nitrate (NO3-). The water molecule acts as a base because it receives the Hydrogen Proton and its conjugate acid is the hydronium ion (H3O+).
Applications.
One use of conjugate acids and bases lies in buffering systems, which include a buffer solution. In a buffer, a weak acid and its conjugate base (in the form of a salt), or a weak base and its conjugate acid are used in order to limit the pH change during a titration process. Buffers have both organic and non-organic chemical applications; for instance, besides buffers being used in lab processes, our blood acts as a buffer to maintain pH. The most important buffer in our bloodstream is the carbonic acid-bicarbonate buffer, which prevents drastic pH changes when CO2 is introduced. This functions as such:
Furthermore, here is a table of common buffers.
 
A second common application with an organic compound would be the production of a buffer with acetic acid. If acetic acid, a weak acid with the formula CH3COOH, was made into a buffer solution, it would need to be combined with its conjugate base CH3COO- in the form of a salt. The resulting mixture is called an acetate buffer, consisting of aqueous CH3COOH and aqueous CH3COONa. Acetic acid, along with many other weak acids, serve as useful components of buffers in different lab settings, each useful within their own pH range.
An example with an inorganic compound would be the medicinal use of lactic acid’s conjugate base known as lactate in Lactated Ringer's solution and Hartmann's solution. Lactic acid has the formula C3H6O6 and its conjugate base is used in intravenous fluids that consist of sodium and potassium cations along with lactate and chloride anions in solution with distilled water. These fluids are commonly isotonic in relation to human blood and are commonly used for spiking up the fluid level in a system after severe blood loss due to trauma, surgery, or burn injury.
Table of acids and their conjugate bases.
Tabulated below are several examples of acids and their conjugate bases; notice how they differ by just one proton (H+ ion). Acid strength decreases and conjugate base strength increases down the table.
Table of bases and their conjugate acids.
In contrast, here is a table of bases and their conjugate acids. Similarly, base strength decreases and conjugate acid strength increases down the table.
References.
 

</doc>
<doc id="40189" url="http://en.wikipedia.org/wiki?curid=40189" title="Founding of Rome">
Founding of Rome

The founding of Rome can be investigated through archaeology, but traditional stories handed down by the ancient Romans themselves explain the earliest history of their city in terms of legend and myth. The most familiar of these myths, and perhaps the most famous of all Roman myths, is the story of Romulus and Remus, the twins who were suckled by a she-wolf. This story had to be reconciled with a dual tradition, set earlier in time, the one that had the Trojan refugee Aeneas escape to Italy and found the line of Romans through his son Iulus, the namesake of the Julio-Claudian dynasty.
Founding myths.
Aeneas.
The national epic of mythical Rome, the "Aeneid" of Virgil, tells the story of how the Trojan prince Aeneas came to Italy. The "Aeneid" was written under Augustus, who claimed ancestry through Julius Caesar from the hero and his mother Venus. According to the "Aeneid", the survivors from the fallen city of Troy banded together under Aeneas, underwent a series of adventures around the Mediterranean Sea, including a stop at newly founded Carthage under the rule of Queen Dido, and eventually reached the Italian coast. The Trojans were thought to have landed in an area between modern Anzio and Fiumicino, southwest of Rome: probably at Laurentum, or in other versions, at Lavinium, a place named for Lavinia, the daughter of King Latinus, whom Aeneas married. This started a series of armed conflicts with Turnus over the marriage of Lavinia. Before the arrival of Aeneas, Turnus was engaged to Lavinia, who then married Aeneas, starting the war. Aeneas won the war and killed Turnus. The Trojans won the right to stay and to assimilate with the local peoples. The young son of Aeneas, Ascanius, also known as Iulus, went on to found Alba Longa and the line of Alban kings who filled the chronological gap between the Trojan saga and the traditional founding of Rome in the 8th century BC.
Toward the end of this line, King Procas was the father of Numitor and Amulius. At Procas' death, Numitor became king of Alba Longa, but Amulius captured him and sent him to prison; he also forced the daughter of Numitor, Rhea Silvia, to become a virgin priestess among the Vestals. For many years Amulius was then the king. The tortuous nature of the chronology is indicated by Rhea Silvia's ordination among the Vestals, whose order was traditionally said to have been founded by the successor of Romulus, Numa Pompilius.
Romulus and Remus.
The myth of Aeneas, Greek in origin, had to be reconciled with the Italian myth of Romulus and Remus, who, taken as historical figures, would have been born around 771 BC. They were purported to be sons of Rhea Silvia and Mars, the god of war. Because of a prophecy that they would overthrow their great-uncle Amulius, who had overthrown Silvia's father Numitor, they were, in the manner of many mythological heroes, abandoned at birth; in this case, on the Tiber River by servants who took pity on the infants, despite their orders. The twins were nurtured by a she-wolf until a shepherd named Faustulus found and took Romulus and Remus as his sons. Faustulus and his wife, Acca Larentia, raised the children. When Remus and Romulus became adults, they killed Amulius and restored Numitor. They decided to establish a city; however, they quarreled, and Romulus killed his brother. Thus Rome began with a fratricide, a story that was later taken to represent the city's history of internecine political strife and bloodshed.
Date.
During the Roman Republic, several dates were given for the founding of the city between 753 BC and 728 BC. Finally, under the Roman Empire, the date suggested by Marcus Terentius Varro, 753 BC, was agreed upon, but in the Fasti Capitolini the year given was 752. Although the proposed years varied, all versions agreed that the city was founded on April 21, the day of the festival sacred to Pales, goddess of shepherds; in her honour, Rome celebrated the "Par ilia" (or "Palilia"). (The Roman a.u.c. calendar, however, begins with Varro's dating of 753 BC.)
According to legend, the foundation of Rome took place 438 years after the capture of Troy (1182 BC), according to Velleius Paterculus (VIII, 5). It took place "shortly" before an eclipse of the sun; some have identified this eclipse as the one observed at Rome on June 25, 745 BC, which had a magnitude of 50.3%. Varro may have used the consular list with its mistakes, calling the year of the First consuls "245 a.u.c.".
According to Lucius Tarrutius of Firmum, Romulus was conceived on the 23rd day of the Egyptian month Choiac, during a total eclipse of the sun. This eclipse occurred on June 15, 763 BC, with a magnitude of 62.5% at Rome. He was born on the 21st day of the month of Thoth. The first day of Thoth fell on 2 March in that year (Prof. E. J. Bickerman, 1980: 115), That implies that Rhea Silvia's pregnancy lasted for 281 days. Rome was founded on the ninth day of the month Pharmuthi, which was April 21, as universally agreed. The Romans add that, about the time Romulus started to build the city, an eclipse of the Sun was observed by Antimachus, the Teian poet, on the 30th day of the lunar month. This eclipse (see above) had a magnitude of 54.6% at Teos, Asia Minor. Romulus vanished in the 54th year of his life, on the Nones of Quintilis (July), on a day when the Sun was darkened. The day turned into night, which sudden darkness was believed to be an eclipse of the Sun. It occurred on July 17, 709 BC, with a magnitude of 93.7%. (All these eclipse data have been calculated by Prof. Aurél Ponori-Thewrewk, retired director of the Planetarium of Budapest.) Plutarch placed it in the 37th year from the foundation of Rome, on the fifth of our month July, then called "Quintiles", on "Caprotine Nones". Livy (I, 21) also states that Romulus ruled for 37 years. He was slain by the Senate or disappeared in the 38th year of his reign. Most of these have been recorded by Plutarch ("Lives of Romulus", "Numa Pompilius" and "Camillus"), Florus (Book I, I), Cicero ("The Republic VI", 22: Scipio's Dream), Dio (Dion) Cassius and Dionysius of Halicarnassus (L. 2). Dio, in his Book I of his "Roman History", confirms these data by telling that Romulus was in his 18th year of age when he founded Rome. Therefore, three eclipse records indicate that Romulus reigned from 746 BC to 709 BC. Surprisingly this is very close to the calculation of the founding given by Rome's first native historical writer, Quintus Fabius Pictor, who wrote that Rome was founded in the first year of the eighth Olympiad, 747 BC (Dionysius of Halicarnassus, "Book 1", ch. 74,2).
Recent discoveries on Palatine Hill in Rome have offered the date of Rome's founding. Chief among these is a series of fortification walls on the north slope of Palatine Hill that can be dated to the middle of the 8th century BC, when legend says that Romulus plowed a furrow ("sulcus") around the Palatine Hill in order to mark the boundary of his new city. The remains of the wall and other evidence like it have been discovered by the Excavations of Andrea Carandini.
The name of Rome.
The name of the city is generally considered to refer to Romulus, but there are other hypotheses. Jean-Jacques Rousseau suggested Greek "ῥώμη" ("rhōmē"), meaning "strength, vigor". Another hypothesis refers the name to Roma, who supposedly was the daughter of Aeneas or Evander. The Basque scholar Manuel de Larramendi thought that the origin was the Basque word "orma" (modern Basque "horma""), meaning "wall". A modern theory of etymology holds that the name of the city (and perhaps the city itself, though this cannot be proven) is of Etruscan origin, deriving from "rumon", "river".:106
The name "Romulus" is probably a back-formation; that is, the name "Romulus" was derived from the word "Rome". The suffix "-ulus" is masculine and a diminutive, so "Romulus" means "the little boy from Rome."
Archaeology.
The original Italian people inhabited the Alban Hills. They later moved down into the valleys, which provided better land for agriculture. The area around the Tiber river was particularly advantageous and offered notable strategic resources: the river was a natural border on one side, and the hills could provide a safe defensive position on the other side. This position would also have enabled the Latins to control the river and the commercial and military traffic on it from the natural observation point at Isola Tiberina. Moreover, road traffic could be controlled since Rome was at the intersection of the principal roads to the sea coming from Sabinum (in the northeast) and Etruria (to the northwest).
The development of the town is presumed to have started from the development of separate small villages, located at the tops of hills, that eventually accreted to form Rome. In any case, the location that was to become the city of Rome was inhabited by Latin settlers from various regions, farmers and pastoralists, as evidenced by differences in pottery and burial techniques.:107
Although recent studies suggest that the Quirinal hill was very important in ancient times, the first hill to be inhabited seems to have been the Palatine (therefore confirming the legend), which is also at the center of ancient Rome. Its three peaks, the minor hills ("Cermalus" or "Germalus", "Palatium", and "Velia"), were united with the three peaks of the Esquiline ("Cispius", "Fagutal", and "Oppius"), and then villages on the Caelian Hill and Suburra.
These hills had expressive names. The Caelian Hill was also called "Querquetulanus", from "quercus" (oak), and "Fagutal"" (pointing to beech-woods, from "fagus" meaning "beech"). Recent discoveries revealed that the "Germalus" on the northern part of the Palatine was the site of a village (dated to the 9th century BC) with circular or elliptic dwellings. It was protected by a clay wall (perhaps reinforced with wood), and it is likely that this is where Rome was really founded.
The territory of this federation was surrounded by a sacred border called the "pomerium", which enclosed the so-called "Roma quadrata" (Square Rome). This was extended with the inclusion of the Capitoline Hill and Tiber Island when Rome became an "oppidum", or fortified town. The Esquiline still was a satellite village that would be included at the time of the Servian expansion of Rome.
Festivals for the "Septimontium" (literally "of the seven hills"), on December 11, were in the past considered related to the foundation. However, because April 21 is the only date for Rome's foundation upon which all the legends agree, it has been recently argued that Septimontium celebrated the first federations among Roman hills: a similar federation was, in fact, celebrated by the Latins at Cave, Italy, or at Monte Cavo (in "Castelli").
Later commemoration.
During the Italian Renaissance, a group of humanists affiliated with the Roman Academy formed a sodality to pursue antiquarian interests, celebrating the "birthday of Rome" annually on April 20. In 1468, the Academy had been suppressed by Pope Paul II for fomenting "republicanism, paganism, and conspiracy", but the sodality was reinstated about ten years later under Sixtus IV as the "Societas Literatorum S. Victoris in Esquiliis" ("Literary Society of Saint Victor on the Esquiline"). The reformed group placed itself under the new patronage of the saints Victor, Fortunatus, and Genesius, "whose feast day was conveniently proven to coincide with the Palilia". Organized by Pomponio Leto, their "Palilia" featured speeches, a communal meal, and a poetry competition.

</doc>
<doc id="40195" url="http://en.wikipedia.org/wiki?curid=40195" title="Telecommunications in Azerbaijan">
Telecommunications in Azerbaijan

Telecommunications in Azerbaijan provides information about television, radio, fixed and mobile telephones, and the Internet in Azerbaijan.
The Azerbaijan economy has been markedly stronger in recent years and, not surprisingly, the country has been making progress in developing ICT sector. Nonetheless, it still faces problems. These include poor infrastructure and an immature telecom regulatory regime. The Ministry of Communications and Information Technologies of Azerbaijan (MCIT), as well as being an operator through its role in Aztelekom, is both a policy-maker and regulator.
Telephones.
Telephone system.
Azerbaijan's telephone system is a combination of old Soviet era technology used by Azerbaijani citizens and small- to medium-size commercial establishments, and modern cellular telephones used by an increasing middle class, large commercial ventures, international companies, and most government officials; the average citizen waits on a 200,000-person list for telephone service; Internet and e-mail service are available in all major cities and some remote towns.
<br>"general assessment:"' inadequate; requires considerable expansion and modernization; teledensity of 15 main lines per 100 persons is low; mobile-cellular penetration is increasing and is currently about 50 telephones per 100 persons.
<br>"domestic:" local - the majority of telephones are in Baku or other industrial centers - about 700 villages still do not have public telephone service; intercity; all long distance service must use Azertel's (Ministry of Communications) lines; satellite service connects Baku to a modern switch in its separated enclave of Nakhchivan Autonomous Republic.
<br>"international:" the old Soviet system of cable and microwave is still serviceable; satellite service between Baku and Turkey provides access to 200 countries; additional satellite providers supply services between Baku and specific countries; Azerbaijan is a signator of the Trans-Asia-Europe Fiber-Optic Line (TAE); their lines are not laid but a Turkish satellite and a microwave link between Azerbaijan and Iran could provide Azerbaijan worldwide access
Mobile phone.
As of June 2014, Azerbaijan has 11.0 million subscribers in total, and a 107% penetration rate.
There are three major mobile phone operators currently in Azerbaijan: Azercell, Bakcell and Azerfon. Azercell, Bakcell and Azerfon offer 2G, 3G and 4G services. All three networks are widely modern and reliable with shops located in major towns and cities where one can purchase a sim card or get assistance if needed. Most unlocked mobile phones are able to be used on roaming however network charges apply. Azercell, Bakcell and Azerfon are often recommended to tourists due to the variety of tariffs available and the help available in a variety of languages. Other mobile phone operators include Aztelekom, AzEuroTel, Caspian Telecom and Catel Eurasiacom.
As of June 2014, approximately 95% of all main lines are digitized and provide excellent quality services for the region. The remaining 5% is in modernization process.
International system.
Azerbaijan is connected to the Trans-Asia-Europe (TAE) fiber-optic cable providing international connectivity to the rest of the World. Additionally the old Soviet system by microwave radio relay and landline connections to other countries of the Commonwealth of Independent States is still available, and by satellite earth stations. The main backbones of Azerbaijani networks are made by E3 or STM-1 lines via microwave units across whole country with many passive retranslations.
Radio.
As of 2014, Azerbaijan has 9 AM stations, 17 FM stations, and one shortwave station. Additionally, there are approximately 4,350,000 radios in existence. Primary network provider is the Ministry of Communications and Information Technologies of Azerbaijan (MCIT). According to MCIT, the FM radio penetration rate is 97% according to 2014 data.
Television.
Azerbaijan has a total of 47 television channels, of which 4 are public television channels and 43 are private television channels of which 12 are national television channels and 31 regional television channels. According to the Ministry of Communications and Information Technologies of Azerbaijan (MCIT), the television penetration rate is 99% according to 2014 data. The penetration rate of cable television in Azerbaijan totaled 28.1% of households in 2013, from a study by the State Statistical Committee of the Azerbaijan Republic. Almost 39% of the cable television subscriber base is concentrated in major cities. The penetration rate is 59.1% in the city of Baku.

</doc>
<doc id="40196" url="http://en.wikipedia.org/wiki?curid=40196" title="Transport in Azerbaijan">
Transport in Azerbaijan

The transport in Azerbaijan involves air traffic, waterways and railroads. All transportation services in Azerbaijan except for oil and gas pipelines are regulated by the Ministry of Transportation of Azerbaijan Republic.
Railways.
There are 2932 km of rail tracks out of which only 2117 km are in common carrier service and 810 km are industrial lines. 240 km of rail tracks were occupied by Armenia between 1988 and 1994 and due to Armenian occupation, the railway link between Nakhichevan and Azerbaijan proper has been broken since 1991.
Of the 2932 km of rail tracks, 72% or 2117 km are single track and 28% or 815 km are double track.
Of the total exploitation length of route 43% or 1272 km are electrified at 3 kV (3,000 V) DC.
About 38% of the length of the railway routes or 1126 km are equipped with full automatic blocks and 16% or 479 km are equipped with centralized dispatchers.
The railways has 176 stations, 2 of which, Bilajari and Shirvan are completely automated, 12 stations have container courts with adapted mechanisms and machines, 3 stations – Keşlə, Ganja and Khirdalan are able to supply high cargo containers.
In freight traffic, the exportation of oil from the oil wells from Baku at the Caspian Sea to the Georgian port of Batumi at the Black Sea, forms an important share of the rail transport in Azerbaijan.
The freight market share of the Azerbaijan State Railway was 21% in 1999. The freight market share of the railways are also expected to rise rapidly with completion of the Kars–Tbilisi–Baku railway. Much of the rail track and rolling stock is in need of repair or replacement.
The national network has no high-speed lines and is not served by high-speed trains.
<br>"Total:" 2932 km (2010)
<br>"Country comparison to the world:" 57
<br>"Broad gauge:" gauge
Kars-Tbilisi-Baku Railway Project Timeline.
2008.
The Russian-Georgian-Ossetian conflict (2008 South Ossetia war) and environmental problems delayed the project, which was originally to be completed by 2010 but is now scheduled for completion by 2012.
Metro System.
Currently the only metro system in Azerbaijan is the Baku Metro, located in Baku, the country's capital.
New plans to open metro systems in the most populated and developed cities of Azberbaijan were unveiled. Sumgayit, Nakhchivan and Ganja all plan to have subway systems in the future.
Roadways.
There are about 25,000 kilometers of roads in Azerbaijan, serving domestic cargo traffic and giving access to international main highways. Highways are mostly in fair condition and need an upgrade to international standards in a view to accommodate growing transit traffic. Main and rural roads are in poor condition and in urgent need of rehabilitation and maintenance. The total vehicle fleet in Azerbaijan was about 517,000 in 2004, with about 49 private passenger cars per 1,000 inhabitants, which is quite low compared to European benchmarks but rapidly increasing due to the fast economic growth. Road transport accounted for 54% of all freight in 2003, up from about 48% in 1999.
Main highways carrying international traffic are the Baku-Alat-Ganja-Qazakh-Georgian Border corridor (Azerbaijani section of TRACECA corridor) with a length of 503 km and the so-called North-South Transport Corridor that stretches out from the Russian to the Iranian border along 521 km. Road connections are disrupted with Armenia because of the unresolved conflict regarding the possession of the Nagorno-Karabakh. Travel between mainland and the detached exclave of Nakhichevan is made by air or by road through Iran. Nakhichevan has a 9-kilometre strategic border with Turkey.
<br>"Total:" 59,141 km
<br>"Country comparison to the world:" 75
<br>"Paved:" 29,210 km
<br>"Unpaved:" 29,931 km (2004)
Pipelines.
Baku is the centre of a major oil- and gas-producing region, and major long-distance pipelines radiate from the region's oil fields to all neighboring areas. Pipelines are generally high capacity lines and have diameters of either 1,020 or 1,220 millimeters. The main petroleum pipeline was completed in 2005 under American pressure to limit Russian and Iranian influence in the area. It runs from Baku via Tbilisi to Ceyhan in Turkey, therefore the acronym BTC pipeline. It made partly obsolete the old Soviet pipeline pumping crude oil from the onshore and offshore Caspian fields near Baku west across Azerbaijan and Georgia to the port of Batumi, where the oil is either exported in its crude form or processed at Batumi's refinery. Two natural gas lines parallel the old petroleum line as far as Tbilisi, where they turn north across the Caucasus Mountains to join the grid of natural gas pipelines that supply cities throughout Russia and Eastern Europe.
Condensate 1 km; gas 3,361 km; oil 1,424 km (2008)
Ports and harbours.
Sea and water cargo transportation have vital importance for Azerbaijan, especially in regions where road and rail connections are disputed. Azerbaijan has direct maritime connections only with other Caspian littoral states (Iran, Kazakhstan, Russia, and Turkmenistan). However, the Volga-Don canal provides a maritime access to the high seas. The main activity is transport of cargo, mainly of oil and oil products. Shipping regions are Caspian, Black, Mediterranean and Marmara Seas. The main shipping company owes 72 ships, 37 of which are tankers (including 1 water-carrier).
Baku International Marine Trade Port is the largest port on the Caspian Sea. Its ferry terminal underwent a major reconstruction supported by a US$16.2 million loan from EBRD. It is now able to handle 30 million tons of freight a year. The Caspian Sea provides vital transport links with other countries and is being used to ship oil until various pipeline projects are completed.
In 2014 Azberbaijan stated it would seek to ease transportation on the Caspian Sea due increased demand by its neighboring states.
On June 4, 2004 the Ministry of Transportation of the Republic of Azerbaijan established the Maritime Administration. As the regulatory authority in maritime transport, its functions include participating in the formulation of state policy, regulating transport demand of goods and passengers and for other types of maritime transport services, as well as implementing state programs, concepts and projects for the development of maritime transport.
Merchant marine.
"Total:" 89 ships 
<br>"Country comparison to the world:" 52
<br>"Ships by type:" cargo 26, passenger 2, passenger/cargo 9, petroleum tanker 46, roll on/roll off 3, specialized tanker 3
<br>"Registered in other countries:" 3 (Malta 2, Panama 1) (2008)
Airports.
There are regular flights between Azerbaijan and former Soviet countries, UK, Germany, France, Austria, Italy, Israel, Iran, Turkey, UAE, China, Georgia and has a cargo flights in UAE, Turkey, Luxembourg, Germany, China, Kyrgyzstan Afghanistan and Iraq. The national airline is Azerbaijan Airlines (AZAL). There are 5 international airports located in Baku, Ganja, Nakhchivan, Lenkaran, Zaqatala. Heydar Aliyev International Airport in Baku reopened in 1999 after a US$64 million upgrading and extension financed by Turkish company Enka. The airport can now handle 1,600 passengers an hour. The new runways are also able to serve jumbojets. The complete overhaul of the international airport in Nakhchivan has been completed in May 2004. The US$32 million reconstruction project of Ganja Airport has been launched by the Government and was completed by mid-2006. In 2008, two more airports were opened in Azerbaijan. The Lankaran International Airport is located in southern part of Azerbaijan, Zaqatala Airport is in the north-west of Azerbaijan territory.
Airports: 25 (2008)
<br>"Country comparison to the world:" 110
Airports - with paved runways.
"Total:" 27
<br>"Over 3,047 m:" 2
<br>"2,438 to 3,047 m:" 6
<br>"1,524 to 2,437 m:" 13
<br>"914 to 1,523 m:" 4
<br>"Under 914 m:" 2 (2008)
Airports - with unpaved runways.
"Total:" 8
<br>"914 to 1,523 m:" 1
<br>"Under 914 m:" 7 (2008)
Heliports.
"Total:" 1 (2007)

</doc>
<doc id="40197" url="http://en.wikipedia.org/wiki?curid=40197" title="Vapor pressure">
Vapor pressure

Vapor pressure or equilibrium vapour pressure is defined as the pressure exerted by a vapor in thermodynamic equilibrium with its condensed phases (solid or liquid) at a given temperature in a closed system. The equilibrium vapor pressure is an indication of a liquid's evaporation rate. It relates to the tendency of particles to escape from the liquid (or a solid). A substance with a high vapor pressure at normal temperatures is often referred to as "volatile".
The vapor pressure of any substance increases non-linearly with temperature according to the Clausius–Clapeyron relation. The atmospheric pressure boiling point of a liquid (also known as the normal boiling point) is the temperature at which the vapor pressure equals the ambient atmospheric pressure. With any incremental increase in that temperature, the vapor pressure becomes sufficient to overcome atmospheric pressure and lift the liquid to form vapor bubbles inside the bulk of the substance. Bubble formation deeper in the liquid requires a higher pressure, and therefore higher temperature, because the fluid pressure increases above the atmospheric pressure as the depth increases.
The vapor pressure that a single component in a mixture contributes to the total pressure in the system is called partial pressure. For example, air at sea level, and saturated with water vapor at 20 °C, has partial pressures of about 2.3 kPa of water, 78 kPa of nitrogen, 21 kPa of oxygen and 0.9 kPa of argon.
Measurement and units.
Vapor pressure is measured in the standard units of pressure. The International System of Units (SI) recognizes pressure as a derived unit with the dimension of force per area and designates the pascal (Pa) as its standard unit. One pascal is one newton per square meter (N·m−2 or kg·m−1·s−2).
Experimental measurement of vapor pressure is a simple procedure for common pressures between 1 and 200 kPa. Most accurate results are obtained near the boiling point of substances and large errors result for measurements smaller than . Procedures often consist of purifying the test substance, isolating it in a container, evacuating any foreign gas, then measuring the equilibrium pressure of the gaseous phase of the substance in the container at different temperatures. Better accuracy is achieved when care is taken to ensure that the entire substance and its vapor are at the prescribed temperature. This is often done, as with the use of an isoteniscope, by submerging the containment area in a liquid bath.
Estimating vapor pressures with Antoine equation.
The Antoine equation is a mathematical expression of the relation between the vapor pressure and the temperature of pure liquid or solid substances. The basic form of the equation is:
and it can be transformed into this temperature-explicit form:
where: formula_3 is the absolute vapor pressure of a substance<br>
A simpler form of the equation with only two coefficients is sometimes used:
which can be transformed to:
Sublimations and vaporizations of the same substance have separate sets of Antoine coefficients, as do components in mixtures. Each parameter set for a specific compound is only applicable over a specified temperature range. Generally, temperature ranges are chosen to maintain the equation's accuracy of a few up to 8-10 percent. For many volatile substances, several different sets of parameters are available and used for different temperature ranges. The Antoine equation has poor accuracy with any single parameter set when used from a compound's melting point to its critical temperature. Accuracy is also usually poor when vapor pressure is under 10 Torr because of the limitations of the apparatus used to establish the Antoine parameter values.
The Wagner Equation gives "one of the best" fits to experimental data but is quite complex. It expresses reduced vapor pressure as a function of reduced temperature.
Relation to boiling point of liquids.
As a general trend, vapor pressures of liquids at ambient temperatures increase with decreasing boiling points. This is illustrated in the vapor pressure chart (see right) that shows graphs of the vapor pressures versus temperatures for a variety of liquids.
For example, at any given temperature, methyl chloride has the highest vapor pressure of any of the liquids in the chart. It also has the lowest normal boiling point (−24.2 °C), which is where the vapor pressure curve of methyl chloride (the blue line) intersects the horizontal pressure line of one atmosphere (atm) of absolute vapor pressure.
Although the relation between vapor pressure and temperature is non-linear, the chart uses a logarithmic vertical axis to produce slightly curved lines, so one chart can graph many liquids. A nearly straight line is obtained when the logarithm of the vapor pressure is plotted against 1/(T+230) where T is the temperature in degrees Celsius. The vapor pressure of a liquid at its boiling point equals the pressure of its surrounding environment.
Liquid mixtures.
Raoult's law gives an approximation to the vapor pressure of mixtures of liquids. It states that the activity (pressure or fugacity) of a single-phase mixture is equal to the mole-fraction-weighted sum of the components' vapor pressures:
where p tot is the mixture's vapor pressure, i is one of the components of the mixture and Χi is the mole fraction of that component in the liquid mixture. The term piΧi is the partial pressure of component i in the mixture. Raoult's Law is applicable only to non-electrolytes (uncharged species); it is most appropriate for non-polar molecules with only weak intermolecular attractions (such as London forces).
Systems that have vapor pressures higher than indicated by the above formula are said to have positive deviations. Such a deviation suggests weaker intermolecular attraction than in the pure components, so that the molecules can be thought of as being "held in" the liquid phase less strongly than in the pure liquid. An example is the azeotrope of approximately 95% ethanol and water. Because the azeotrope's vapor pressure is higher than predicted by Raoult's law, it boils at a temperature below that of either pure component.
There are also systems with negative deviations that have vapor pressures that are lower than expected. Such a deviation is evidence for stronger intermolecular attraction between the constituents of the mixture than exists in the pure components. Thus, the molecules are "held in" the liquid more strongly when a second molecule is present. An example is a mixture of trichloromethane (chloroform) and 2-propanone (acetone), which boils above the boiling point of either pure component.
The negative and positive deviations can be used to determine thermodynamic activity coefficients of the components of mixtures.
Solids.
Equilibrium vapor pressure can be defined as the pressure reached when a condensed phase is in equilibrium with its own vapor. In the case of an equilibrium solid, such as a crystal, this can be defined as the pressure when the rate of sublimation of a solid matches the rate of deposition of its vapor phase. For most solids this pressure is very low, but some notable exceptions are naphthalene, dry ice (the vapor pressure of dry ice is 5.73 MPa (831 psi, 56.5 atm) at 20 degrees Celsius, which causes most sealed containers to rupture), and ice. All solid materials have a vapor pressure. However, due to their often extremely low values, measurement can be rather difficult. Typical techniques include the use of thermogravimetry and gas transpiration.
There are a number of methods for calculating the sublimation pressure (i.e., the vapor pressure) of a solid. One method is to estimate the sublimation pressure from extrapolated liquid vapor pressures (of the supercooled liquid), if the heat of fusion is known, by using this particular form of the Clausius–Clapeyron relation:
with:
This method assumes that the heat of fusion is temperature-independent, ignores additional transition temperatures between different solid phases, and it gives a fair estimation for temperatures not too far from the melting point. It also shows that the sublimation pressure is lower than the extrapolated liquid vapor pressure (Δ"H"m is positive) and the difference grows with increased distance from the melting point.
Boiling point of water.
Like all liquids, water boils when its vapor pressure reaches its surrounding pressure. In nature, the atmospheric pressure is lower at higher elevations and water boils at a lower temperature. The boiling temperature of water for atmospheric pressures can be approximated by the Antoine equation:
or transformed into this temperature-explicit form:
where the temperature formula_17 is the boiling point in degrees Celsius and the pressure formula_18 is in Torr.
Dühring's rule.
Dühring's rule states that a linear relationship exists between the temperatures at which two solutions exert the same vapor pressure.
Examples.
The following table is a list of a variety of substances ordered by increasing vapor pressure (in absolute units).
Estimating vapor pressure from molecular structure.
Several empirical methods exist to estimate liquid vapor pressure from molecular structure for organic molecules. Some examples are SIMPOL, the method of Moller et al., and EVAPORATION.
Meaning in meteorology.
In meteorology, the term "vapor pressure" is used to mean the partial pressure of water vapor in the atmosphere, even if it is not in equilibrium, and the "equilibrium vapor pressure" is specified otherwise. Meteorologists also use the term "saturation vapor pressure" to refer to the equilibrium vapor pressure of water or brine above a flat surface, to distinguish it from equilibrium vapor pressure, which takes into account the shape and size of water droplets and particulates in the atmosphere.

</doc>
<doc id="40202" url="http://en.wikipedia.org/wiki?curid=40202" title="12th century BC">
12th century BC

Overview.
The 12th century BC is the period from 1200 to 1101 BC. 
Sovereign States.
See: List of sovereign states in the 12th century BC.

</doc>
<doc id="40203" url="http://en.wikipedia.org/wiki?curid=40203" title="Hubble Space Telescope">
Hubble Space Telescope

The Hubble Space Telescope (HST) is a space telescope that was launched into low Earth orbit in 1990, and remains in operation. With a 2.4 m mirror, Hubble's four main instruments observe in the near ultraviolet, visible, and near infrared spectra. The telescope is named after the astronomer Edwin Hubble.
Hubble's orbit outside the distortion of Earth's atmosphere allows it to take extremely high-resolution images with negligible background light. Hubble has recorded some of the most detailed visible-light images ever, allowing a deep view into space and time. Many Hubble observations have led to breakthroughs in astrophysics, such as accurately determining the rate of expansion of the universe.
Although not the first space telescope, Hubble is one of the largest and most versatile, and is well known as both a vital research tool and a public relations boon for astronomy. The HST was built by the United States space agency NASA, with contributions from the European Space Agency, and is operated by the Space Telescope Science Institute. The HST is one of NASA's Great Observatories, along with the Compton Gamma Ray Observatory, the Chandra X-ray Observatory, and the Spitzer Space Telescope.
Space telescopes were proposed as early as 1923. Hubble was funded in the 1970s, with a proposed launch in 1983, but the project was beset by technical delays, budget problems, and the "Challenger" disaster. When finally launched in 1990, Hubble's main mirror was found to have been ground incorrectly, compromising the telescope's capabilities. The optics were corrected to their intended quality by a servicing mission in 1993.
Hubble is the only telescope designed to be serviced in space by astronauts. After launch by Space Shuttle "Discovery" in 1990, four subsequent Space Shuttle missions repaired, upgraded, and replaced systems on the telescope. A fifth mission was canceled on safety grounds following the "Columbia" disaster. However, after spirited public discussion, NASA administrator Mike Griffin approved one final servicing mission, completed in 2009. The telescope is still operating as of 2015[ [update]], and may last until 2020. Its scientific successor, the James Webb Space Telescope (JWST), is scheduled for launch in 2018.
Conception, design and aim.
Proposals and precursors.
In 1923, Hermann Oberth—considered a father of modern rocketry, along with Robert H. Goddard and Konstantin Tsiolkovsky—published "Die Rakete zu den Planetenräumen" ("The Rocket into Planetary Space"), which mentioned how a telescope could be propelled into Earth orbit by a rocket.
The history of the Hubble Space Telescope can be traced back as far as 1946, to the astronomer Lyman Spitzer's paper "Astronomical advantages of an extraterrestrial observatory". In it, he discussed the two main advantages that a space-based observatory would have over ground-based telescopes. First, the angular resolution (the smallest separation at which objects can be clearly distinguished) would be limited only by diffraction, rather than by the turbulence in the atmosphere, which causes stars to twinkle, known to astronomers as seeing. At that time ground-based telescopes were limited to resolutions of 0.5–1.0 arcseconds, compared to a theoretical diffraction-limited resolution of about 0.05 arcsec for a telescope with a mirror 2.5 m in diameter. Second, a space-based telescope could observe infrared and ultraviolet light, which are strongly absorbed by the atmosphere.
Spitzer devoted much of his career to pushing for the development of a space telescope. In 1962, a report by the US National Academy of Sciences recommended the development of a space telescope as part of the space program, and in 1965 Spitzer was appointed as head of a committee given the task of defining scientific objectives for a large space telescope.
Space-based astronomy had begun on a very small scale following World War II, as scientists made use of developments that had taken place in rocket technology. The first ultraviolet spectrum of the Sun was obtained in 1946, and the National Aeronautics and Space Administration (NASA) launched the Orbiting Solar Observatory (OSO) to obtain UV, X-ray, and gamma-ray spectra in 1962. An orbiting solar telescope was launched in 1962 by the United Kingdom as part of the Ariel space program, and in 1966 NASA launched the first Orbiting Astronomical Observatory (OAO) mission. OAO-1's battery failed after three days, terminating the mission. It was followed by OAO-2, which carried out ultraviolet observations of stars and galaxies from its launch in 1968 until 1972, well beyond its original planned lifetime of one year.
The OSO and OAO missions demonstrated the important role space-based observations could play in astronomy, and in 1968, NASA developed firm plans for a space-based reflecting telescope with a mirror 3 m in diameter, known provisionally as the Large Orbiting Telescope or Large Space Telescope (LST), with a launch slated for 1979. These plans emphasized the need for manned maintenance missions to the telescope to ensure such a costly program had a lengthy working life, and the concurrent development of plans for the reusable space shuttle indicated that the technology to allow this was soon to become available.
Quest for funding.
The continuing success of the OAO program encouraged increasingly strong consensus within the astronomical community that the LST should be a major goal. In 1970, NASA established two committees, one to plan the engineering side of the space telescope project, and the other to determine the scientific goals of the mission. Once these had been established, the next hurdle for NASA was to obtain funding for the instrument, which would be far more costly than any Earth-based telescope. The U.S. Congress questioned many aspects of the proposed budget for the telescope and forced cuts in the budget for the planning stages, which at the time consisted of very detailed studies of potential instruments and hardware for the telescope. In 1974, public spending cuts led to Congress deleting all funding for the telescope project.
In response to this, a nationwide lobbying effort was coordinated among astronomers. Many astronomers met congressmen and senators in person, and large scale letter-writing campaigns were organized. The National Academy of Sciences published a report emphasizing the need for a space telescope, and eventually the Senate agreed to half of the budget that had originally been approved by Congress.
The funding issues led to something of a reduction in the scale of the project, with the proposed mirror diameter reduced from 3 m to 2.4 m, both to cut costs and to allow a more compact and effective configuration for the telescope hardware. A proposed precursor 1.5 m space telescope to test the systems to be used on the main satellite was dropped, and budgetary concerns also prompted collaboration with the European Space Agency. ESA agreed to provide funding and supply one of the first generation instruments for the telescope, as well as the solar cells that would power it, and staff to work on the telescope in the United States, in return for European astronomers being guaranteed at least 15% of the observing time on the telescope. Congress eventually approved funding of US$36 million for 1978, and the design of the LST began in earnest, aiming for a launch date of 1983. In 1983 the telescope was named after Edwin Hubble, who made one of the greatest scientific breakthroughs of the 20th century when he discovered that the universe is expanding.
Construction and engineering.
Once the Space Telescope project had been given the go-ahead, work on the program was divided among many institutions. Marshall Space Flight Center (MSFC) was given responsibility for the design, development, and construction of the telescope, while Goddard Space Flight Center was given overall control of the scientific instruments and ground-control center for the mission. MSFC commissioned the optics company Perkin-Elmer to design and build the Optical Telescope Assembly (OTA) and Fine Guidance Sensors for the space telescope. Lockheed was commissioned to construct and integrate the spacecraft in which the telescope would be housed.
Optical Telescope Assembly (OTA).
Optically, the HST is a Cassegrain reflector of Ritchey–Chrétien design, as are most large professional telescopes. This design, with two hyperbolic mirrors, is known for good imaging performance over a wide field of view, with the disadvantage that the mirrors have shapes that are hard to fabricate and test. The mirror and optical systems of the telescope determine the final performance, and they were designed to exacting specifications. Optical telescopes typically have mirrors polished to an accuracy of about a tenth of the wavelength of visible light, but the Space Telescope was to be used for observations from the visible through the ultraviolet (shorter wavelengths) and was specified to be diffraction limited to take full advantage of the space environment. Therefore its mirror needed to be polished to an accuracy of 10 nanometers, or about 1/65 of the wavelength of red light. On the long wavelength end, the OTA was not designed with optimum IR performance in mind—for example, the mirrors are kept at stable (and warm, about 15 °C) temperatures by heaters. This limits Hubble's performance as an infrared telescope.
Perkin-Elmer intended to use custom-built and extremely sophisticated computer-controlled polishing machines to grind the mirror to the required shape. However, in case their cutting-edge technology ran into difficulties, NASA demanded that PE sub-contract to Kodak to construct a back-up mirror using traditional mirror-polishing techniques. (The team of Kodak and Itek also bid on the original mirror polishing work. Their bid called for the two companies to double-check each other's work, which would have almost certainly caught the polishing error that later caused such problems.) The Kodak mirror is now on permanent display at the National Air and Space Museum. An Itek mirror built as part of the effort is now used in the 2.4 m telescope at the Magdalena Ridge Observatory.
Construction of the Perkin-Elmer mirror began in 1979, starting with a blank manufactured by Corning from their ultra-low expansion glass. To keep the mirror's weight to a minimum it consisted of inch-thick top and bottom plates sandwiching a honeycomb lattice. Perkin-Elmer simulated microgravity by supporting the mirror from the back with 130 rods that exerted varying amounts of force. This ensured that the mirror's final shape would be correct and to specification when finally deployed. Mirror polishing continued until May 1981. NASA reports at the time questioned Perkin-Elmer's managerial structure, and the polishing began to slip behind schedule and over budget. To save money, NASA halted work on the back-up mirror and put the launch date of the telescope back to October 1984. The mirror was completed by the end of 1981; it was washed using 2,400 gallons (9,100 L) of hot, deionized water and then received a reflective coating of 65 nm-thick aluminum and a protective coating of 25 nm-thick magnesium fluoride.
Doubts continued to be expressed about Perkin-Elmer's competence on a project of this importance, as their budget and timescale for producing the rest of the OTA continued to inflate. In response to a schedule described as "unsettled and changing daily", NASA postponed the launch date of the telescope until April 1985. Perkin-Elmer's schedules continued to slip at a rate of about one month per quarter, and at times delays reached one day for each day of work. NASA was forced to postpone the launch date until March and then September 1986. By this time, the total project budget had risen to US$1.175 billion.
Spacecraft systems.
The spacecraft in which the telescope and instruments were to be housed was another major engineering challenge. It would have to withstand frequent passages from direct sunlight into the darkness of Earth's shadow, which would cause major changes in temperature, while being stable enough to allow extremely accurate pointing of the telescope. A shroud of multi-layer insulation keeps the temperature within the telescope stable, and surrounds a light aluminum shell in which the telescope and instruments sit. Within the shell, a graphite-epoxy frame keeps the working parts of the telescope firmly aligned. Because graphite composites are hygroscopic, there was a risk that water vapor absorbed by the truss while in Lockheed's clean room would later be expressed in the vacuum of space; the telescope's instruments would be covered in ice. To reduce that risk, a nitrogen gas purge was performed before launching the telescope into space.
While construction of the spacecraft in which the telescope and instruments would be housed proceeded somewhat more smoothly than the construction of the OTA, Lockheed still experienced some budget and schedule slippage, and by the summer of 1985, construction of the spacecraft was 30% over budget and three months behind schedule. An MSFC report said that Lockheed tended to rely on NASA directions rather than take their own initiative in the construction.
Initial instruments.
When launched, the HST carried five scientific instruments: the Wide Field and Planetary Camera (WF/PC), Goddard High Resolution Spectrograph (GHRS), High Speed Photometer (HSP), Faint Object Camera (FOC) and the Faint Object Spectrograph (FOS). WF/PC was a high-resolution imaging device primarily intended for optical observations. It was built by NASA's Jet Propulsion Laboratory, and incorporated a set of 48 filters isolating spectral lines of particular astrophysical interest. The instrument contained eight charge-coupled device (CCD) chips divided between two cameras, each using four CCDs. Each CCD has a resolution of 0.64 megapixels. The "wide field camera" (WFC) covered a large angular field at the expense of resolution, while the "planetary camera" (PC) took images at a longer effective focal length than the WF chips, giving it a greater magnification.
The GHRS was a spectrograph designed to operate in the ultraviolet. It was built by the Goddard Space Flight Center and could achieve a spectral resolution of 90,000. Also optimized for ultraviolet observations were the FOC and FOS, which were capable of the highest spatial resolution of any instruments on Hubble. Rather than CCDs these three instruments used photon-counting digicons as their detectors. The FOC was constructed by ESA, while the University of California, San Diego, and Martin Marietta Corporation built the FOS.
The final instrument was the HSP, designed and built at the University of Wisconsin–Madison. It was optimized for visible and ultraviolet light observations of variable stars and other astronomical objects varying in brightness. It could take up to 100,000 measurements per second with a photometric accuracy of about 2% or better.
HST's guidance system can also be used as a scientific instrument. Its three Fine Guidance Sensors (FGS) are primarily used to keep the telescope accurately pointed during an observation, but can also be used to carry out extremely accurate astrometry; measurements accurate to within 0.0003 arcseconds have been achieved.
Ground support.
The Space Telescope Science Institute (STScI) is responsible for the scientific operation of the telescope and the delivery of data products to astronomers. STScI is operated by the Association of Universities for Research in Astronomy (AURA) and is physically located in Baltimore, Maryland on the Homewood campus of Johns Hopkins University, one of the 39 US universities and seven international affiliates that make up the AURA consortium. STScI was established in 1981 after something of a power struggle between NASA and the scientific community at large. NASA had wanted to keep this function in-house, but scientists wanted it to be based in an academic establishment. The Space Telescope European Coordinating Facility (ST-ECF), established at Garching bei München near Munich in 1984, provided similar support for European astronomers until 2011, when these activities were moved to the European Space Astronomy Centre.
One rather complex task that falls to STScI is scheduling observations for the telescope. Hubble is in a low-Earth orbit to enable servicing missions, but this means that most astronomical targets are occulted by the Earth for slightly less than half of each orbit. Observations cannot take place when the telescope passes through the South Atlantic Anomaly due to elevated radiation levels, and there are also sizable exclusion zones around the Sun (precluding observations of Mercury), Moon and Earth. The solar avoidance angle is about 50°, to keep sunlight from illuminating any part of the OTA. Earth and Moon avoidance keeps bright light out of the FGSs, and keeps scattered light from entering the instruments. If the FGSs are turned off, however, the Moon and Earth can be observed. Earth observations were used very early in the program to generate flat-fields for the WFPC1 instrument. There is a so-called continuous viewing zone (CVZ), at roughly 90° to the plane of Hubble's orbit, in which targets are not occulted for long periods. Due to the precession of the orbit, the location of the CVZ moves slowly over a period of eight weeks. Because the limb of the Earth is always within about 30° of regions within the CVZ, the brightness of scattered earthshine may be elevated for long periods during CVZ observations.
Hubble orbits in the upper atmosphere at an altitude of approximately 569 km and an inclination of 28.5°. The position along its orbit changes over time in a way that is not accurately predictable. The density of the upper atmosphere varies according to many factors, and this means that Hubble's predicted position for six weeks' time could be in error by up to 4000 km. Observation schedules are typically finalized only a few days in advance, as a longer lead time would mean there was a chance that the target would be unobservable by the time it was due to be observed.
Engineering support for HST is provided by NASA and contractor personnel at the Goddard Space Flight Center in Greenbelt, Maryland, 48 km south of the STScI. Hubble's operation is monitored 24 hours per day by four teams of flight controllers who make up Hubble's Flight Operations Team.
"Challenger" disaster, delays, and eventual launch.
By early 1986, the planned launch date of October that year looked feasible, but the "Challenger" accident brought the U.S. space program to a halt, grounding the Space Shuttle fleet and forcing the launch of Hubble to be postponed for several years. The telescope had to be kept in a clean room, powered up and purged with nitrogen, until a launch could be rescheduled. This costly situation (about $6 million per month) pushed the overall costs of the project even higher. This delay did allow time for engineers to perform extensive tests, swap out a possibly failure-prone battery, and make other improvements. Furthermore, the ground software needed to control Hubble was not ready in 1986, and in fact was barely ready by the 1990 launch.
Eventually, following the resumption of shuttle flights in 1988, the launch of the telescope was scheduled for 1990. On April 24, 1990, shuttle mission STS-31 saw "Discovery" launch the telescope successfully into its planned orbit.
From its original total cost estimate of about US$400 million, the telescope had by now cost over $2.5 billion to construct. Hubble's cumulative costs up to this day are estimated to be several times higher still, roughly US$10 billion as of 2010.
Flawed mirror.
Within weeks of the launch of the telescope, the returned images indicated a serious problem with the optical system. Although the first images appeared to be sharper than those of ground-based telescopes, Hubble failed to achieve a final sharp focus and the best image quality obtained was drastically lower than expected. Images of point sources spread out over a radius of more than one arcsecond, instead of having a point spread function (PSF) concentrated within a circle 0.1 arcsec in diameter as had been specified in the design criteria.
Analysis of the flawed images showed that the cause of the problem was that the primary mirror had been ground to the wrong shape. Although it was probably the most precisely figured mirror ever made, with variations from the prescribed curve of only 10 nanometers, at the perimeter it was too flat by about 2,200 nanometers (2.2 micrometers). This difference was catastrophic, introducing severe spherical aberration, a flaw in which light reflecting off the edge of a mirror focuses on a different point from the light reflecting off its center.
The effect of the mirror flaw on scientific observations depended on the particular observation—the core of the aberrated PSF was sharp enough to permit high-resolution observations of bright objects, and spectroscopy of point sources was only affected through a sensitivity loss. However, the loss of light to the large, out of focus halo severely reduced the usefulness of the telescope for faint objects or high-contrast imaging. This meant that nearly all of the cosmological programs were essentially impossible, since they required observation of exceptionally faint objects. NASA and the telescope became the butt of many jokes, and the project was popularly regarded as a white elephant. For instance, in the 1991 comedy "", Hubble was pictured with the "Titanic", the "Hindenburg", and the Edsel. Nonetheless, during the first three years of the Hubble mission, before the optical corrections, the telescope still carried out a large number of productive observations of less demanding targets. The error was well characterized and stable, enabling astronomers to partially compensate for the defective mirror by using sophisticated image processing techniques such as deconvolution.
Origin of the problem.
A commission headed by Lew Allen, director of the Jet Propulsion Laboratory, was established to determine how the error could have arisen. The Allen Commission found that the main null corrector, a testing device used to achieve a properly shaped non-spherical mirror, had been incorrectly assembled—one lens was out of position by 1.3 mm. During the initial grinding and polishing of the mirror, Perkin-Elmer analyzed its surface with two conventional null correctors. However, for the final manufacturing step (figuring), they switched to a custom-built null corrector, designed explicitly to meet very strict tolerances. The incorrect assembly of the device resulted in the mirror being ground very precisely but to the wrong shape. There was one later opportunity to catch the error, since for technical reasons a few of the final tests needed to use the two conventional null correctors. These tests correctly reported spherical aberration, but were dismissed since the reflective null corrector was considered more accurate.
The commission blamed the failings primarily on Perkin-Elmer. Relations between NASA and the optics company had been severely strained during the telescope construction, due to frequent schedule slippage and cost overruns. NASA found that Perkin-Elmer did not review or supervise the mirror construction adequately, did not assign its best optical scientists to the project (as it had for the prototype), and in particular did not involve the optical designers in the construction and verification of the mirror. While the commission heavily criticized Perkin-Elmer for these managerial failings, NASA was also criticized for not picking up on the quality control shortcomings, such as relying totally on test results from a single instrument.
Design of a solution.
The design of the telescope had always incorporated servicing missions, and astronomers immediately began to seek potential solutions to the problem that could be applied at the first servicing mission, scheduled for 1993. While Kodak had ground a back-up mirror for Hubble, it would have been impossible to replace the mirror in orbit, and too expensive and time-consuming to bring the telescope back to Earth for a refit. Instead, the fact that the mirror had been ground so precisely to the wrong shape led to the design of new optical components with exactly the same error but in the opposite sense, to be added to the telescope at the servicing mission, effectively acting as "spectacles" to correct the spherical aberration.
The first step was a precise characterization of the error in the main mirror. Working backwards from images of point sources, astronomers determined that the conic constant of the mirror as built was −1.01390±0.0002, instead of the intended −1.00230. The same number was also derived by analyzing the null corrector used by Perkin-Elmer to figure the mirror, as well as by analyzing interferograms obtained during ground testing of the mirror.
Because of the way the HST's instruments were designed, two different sets of correctors were required. The design of the Wide Field and Planetary Camera 2, already planned to replace the existing WF/PC, included relay mirrors to direct light onto the four separate charge-coupled device (CCD) chips making up its two cameras. An inverse error built into their surfaces could completely cancel the aberration of the primary. However, the other instruments lacked any intermediate surfaces that could be figured in this way, and so required an external correction device.
The Corrective Optics Space Telescope Axial Replacement (COSTAR) system was designed to correct the spherical aberration for light focused at the FOC, FOS, and GHRS. It consists of two mirrors in the light path with one ground to correct the aberration. To fit the COSTAR system onto the telescope, one of the other instruments had to be removed, and astronomers selected the High Speed Photometer to be sacrificed. By 2002, all of the original instruments requiring COSTAR had been replaced by instruments with their own corrective optics. COSTAR was removed and returned to Earth in 2009 where it is exhibited at the National Air and Space Museum. The area previously used by COSTAR is now occupied by the Cosmic Origins Spectrograph.
Servicing missions and new instruments.
Hubble was designed to accommodate regular servicing and equipment upgrades. Five servicing missions (SM 1, 2, 3A, 3B, and 4) were flown by NASA space shuttles, the first in December 1993 and the last in May 2009. Servicing missions were delicate operations that began with maneuvering to intercept the telescope in orbit and carefully retrieving it with the shuttle's mechanical arm. The necessary work was then carried out in multiple tethered spacewalks over a period of four to five days. After a visual inspection of the telescope, astronauts conducted repairs, replaced failed or degraded components, upgraded equipment, and installed new instruments. Once work was completed, the telescope was redeployed, typically after boosting to a higher orbit to address the orbital decay caused by atmospheric drag.
Servicing Mission 1.
After the problems with Hubble's mirror were discovered, the first servicing mission assumed greater importance, as the astronauts would need to do extensive work to install corrective optics. The seven astronauts for the mission were trained to use about a hundred specialized tools. SM1 flew aboard "Endeavour" in December 1993, and involved installation of several instruments and other equipment over ten days.
Most importantly, the High Speed Photometer was replaced with the COSTAR corrective optics package, and WFPC was replaced with the Wide Field and Planetary Camera 2 (WFPC2) with an internal optical correction system. The solar arrays and their drive electronics were also replaced, as well as four gyroscopes in the telescope pointing system, two electrical control units and other electrical components, and two magnetometers. The onboard computers were upgraded, and Hubble's orbit was boosted.
On January 13, 1994, NASA declared the mission a complete success and showed the first sharper images. At the time, the mission was one of the most complex, involving five long extra-vehicular activity periods. Its success was a boon for NASA, as well as for the astronomers with a more capable space telescope.
Servicing Mission 2.
Servicing Mission 2, flown by "Discovery" in February 1997, replaced the GHRS and the FOS with the Space Telescope Imaging Spectrograph (STIS) and the Near Infrared Camera and Multi-Object Spectrometer (NICMOS), replaced an Engineering and Science Tape Recorder with a new Solid State Recorder, and repaired thermal insulation. NICMOS contained a heat sink of solid nitrogen to reduce the thermal noise from the instrument, but shortly after it was installed, an unexpected thermal expansion resulted in part of the heat sink coming into contact with an optical baffle. This led to an increased warming rate for the instrument and reduced its original expected lifetime of 4.5 years to about 2 years.
Servicing Mission 3A.
Servicing Mission 3A, flown by "Discovery", took place in December 1999, and was a split-off from Servicing Mission 3 after three of the six onboard gyroscopes had failed. The fourth failed a few weeks before the mission, rendering the telescope incapable of performing scientific observations. The mission replaced all six gyroscopes, replaced a Fine Guidance Sensor and the computer, installed a Voltage/temperature Improvement Kit (VIK) to prevent battery overcharging, and replaced thermal insulation blankets. The new computer is 20 times faster, with six times more memory, than the DF-224 it replaced. It increases throughput by moving some computing tasks from the ground to the spacecraft, and saves money by allowing the use of modern programming languages.
Servicing Mission 3B.
Servicing Mission 3B flown by "Columbia" in March 2002 saw the installation of a new instrument, with the FOC (the last original instrument) being replaced by the Advanced Camera for Surveys (ACS). This meant that COSTAR was no longer required, since all new instruments had built-in correction for the main mirror aberration. The mission also revived NICMOS by installing a closed-cycle cooler and replaced the solar arrays for the second time, providing 30 percent more power.
Servicing Mission 4.
Plans called for Hubble to be serviced in February 2005, but the "Columbia" disaster in 2003, in which the orbiter disintegrated on re-entry into the atmosphere, had wide-ranging effects on the Hubble program. NASA Administrator Sean O'Keefe decided that all future shuttle missions had to be able to reach the safe haven of the International Space Station should in-flight problems develop. As no shuttles were capable of reaching both HST and the ISS during the same mission, future manned service missions were canceled. This decision was assailed by numerous astronomers, who felt that Hubble was valuable enough to merit the human risk. HST's planned successor, the James Webb Telescope (JWST), is not expected to launch until at least 2018. A gap in space-observing capabilities between a decommissioning of Hubble and the commissioning of a successor is of major concern to many astronomers, given the significant scientific impact of HST. The consideration that JWST will not be located in low Earth orbit, and therefore cannot be easily upgraded or repaired in the event of an early failure, only makes these concerns more acute. On the other hand, many astronomers felt strongly that the servicing of Hubble should not take place if the expense were to come from the JWST budget.
In January 2004, O'Keefe said he would review his decision to cancel the final servicing mission to HST due to public outcry and requests from Congress for NASA to look for a way to save it. The National Academy of Sciences convened an official panel, which recommended in July 2004 that the HST should be preserved despite the apparent risks. Their report urged "NASA should take no actions that would preclude a space shuttle servicing mission to the Hubble Space Telescope". In August 2004, O'Keefe asked Goddard Space Flight Center to prepare a detailed proposal for a robotic service mission. These plans were later canceled, the robotic mission being described as "not feasible". In late 2004, several Congressional members, led by Senator Barbara Mikulski, held public hearings and carried on a fight with much public support (including thousands of letters from school children across the country) to get the Bush Administration and NASA to reconsider the decision to drop plans for a Hubble rescue mission.
The nomination in April 2005 of a new NASA Administrator with an engineering rather than accounting background, Michael D. Griffin, changed the situation, as Griffin stated he would consider a manned servicing mission. Soon after his appointment Griffin authorized Goddard to proceed with preparations for a manned Hubble maintenance flight, saying he would make the final decision after the next two shuttle missions. In October 2006 Griffin gave the final go-ahead, and the 11-day mission by "Atlantis" was scheduled for October 2008. Hubble's main data-handling unit failed in September 2008, halting all reporting of scientific data until its back-up was brought online on October 25, 2008. Since a failure of the backup unit would leave the HST helpless, the service mission was postponed to incorporate a replacement for the primary unit.
Servicing Mission 4, flown by "Atlantis" in May 2009, was the last scheduled shuttle mission for HST. SM4 installed the replacement data-handling unit, repaired the ACS and STIS systems, installed improved nickel hydrogen batteries, and replaced other components. SM4 also installed two new observation instruments—Wide Field Camera 3 (WFC3) and the Cosmic Origins Spectrograph (COS)—and the Soft Capture and Rendezvous System, which will enable the future rendezvous, capture, and safe disposal of Hubble by either a crewed or robotic mission. The work accomplished during SM4 rendered the telescope fully functional, and it remains so as of 2015[ [update]].
Major projects.
Since the start of the program, a number of research projects have been carried out, some of them almost solely with Hubble, others coordinated facilities such as Chandra X-ray Observatory and ESO's Very Large Telescope. Although the Hubble observatory is nearing the end of its life, there are still major projects scheduled for it. One example is the upcoming Frontier Fields program, inspired by the results of Hubble's deep observation of the galaxy cluster Abell 1689.
Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey.
In an August 2013 press release, CANDELS was referred to as "the largest project in the history of Hubble". The survey "aims to explore galactic evolution in the early Universe, and the very first seeds of cosmic structure at less than one billion years after the Big Bang." The CANDELS project site describes the survey's goals as the following:
The Cosmic Assembly Near-IR Deep Extragalactic Legacy Survey is designed to document the ﬁrst third of galactic evolution from z = 8 to 1.5 via deep imaging of more than 250,000 galaxies with WFC3/IR and ACS. It will also find the first Type Ia SNe beyond z > 1.5 and establish their accuracy as standard candles for cosmology. Five premier multi-wavelength sky regions are selected; each has multi-wavelength data from Spitzer and other facilities, and has extensive spectroscopy of the brighter galaxies. The use of ﬁve widely separated ﬁelds mitigates cosmic variance and yields statistically robust and complete samples of galaxies down to 109 solar masses out to z ~ 8.
Frontier Fields program.
The program, officially named "Hubble Deep Fields Initiative 2012", is aimed to advance the knowledge of early galaxy formation by studying high-redshift galaxies in blank fields with the help of gravitational lensing to see the "faintest galaxies in the distant universe." The Frontier Fields web page describes the goals of the program being:
Public use.
Anyone can apply for time on the telescope; there are no restrictions on nationality or academic affiliation, but funding for analysis is only available to US institutions. Competition for time on the telescope is intense, with about one-fifth of the proposals submitted in each cycle earning time on the schedule.
Calls for proposals are issued roughly annually, with time allocated for a cycle lasting about one year. Proposals are divided into several categories; "general observer" proposals are the most common, covering routine observations. "Snapshot observations" are those in which targets require only 45 minutes or less of telescope time, including overheads such as acquiring the target. Snapshot observations are used to fill in gaps in the telescope schedule that cannot be filled by regular GO programs.
Astronomers may make "Target of Opportunity" proposals, in which observations are scheduled if a transient event covered by the proposal occurs during the scheduling cycle. In addition, up to 10% of the telescope time is designated "director's discretionary" (DD) time. Astronomers can apply to use DD time at any time of year, and it is typically awarded for study of unexpected transient phenomena such as supernovae.
Other uses of DD time have included the observations that led to views of the Hubble Deep Field and Hubble Ultra Deep Field, and in the first four cycles of telescope time, observations that were carried out by amateur astronomers.
Amateur observations.
The first director of STScI, Riccardo Giacconi, announced in 1986 that he intended to devote some of his director discretionary time to allowing amateur astronomers to use the telescope. The total time to be allocated was only a few hours per cycle but excited great interest among amateur astronomers.
Proposals for amateur time were stringently reviewed by a committee of amateur astronomers, and time was awarded only to proposals that were deemed to have genuine scientific merit, did not duplicate proposals made by professionals, and required the unique capabilities of the space telescope. Thirteen amateur astronomers were awarded time on the telescope, with observations being carried out between 1990 and 1997. One such study was "Transition Comets—UV Search for OH". The very first proposal, "A Hubble Space Telescope Study of Posteclipse Brightening and Albedo Changes on Io", was published in "Icarus", a journal devoted to solar system studies. A second study from another group of amateurs was also published in "Icarus". After that time, however, budget reductions at STScI made the support of work by amateur astronomers untenable, and no additional amateur programs have been carried out.
20th and 25th anniversaries.
The Hubble Space Telescope celebrated its 20th anniversary in space on April 24, 2010. To commemorate the occasion, NASA, ESA, and the Space Telescope Science Institute (STScI) released an image from the Carina Nebula.
To commemorate Hubble's 25th anniversary in space on April 24, 2015, STScI released images of the Westerlund 2 cluster, located about 20000 ly away in the constellation Carina, through its Hubble 25 website. The European Space Agency created a dedicated 25th anniversary page on its website.
Scientific results.
Key projects.
In the early 1980s, NASA and STScI convened four panels to discuss Key Projects. These were projects that were both scientifically important and would require significant telescope time, which would be explicitly dedicated to each project. This guaranteed that these particular projects would be completed early, in case the telescope failed sooner than expected. The panels identified three such projects: 1) a study of the nearby intergalactic medium using quasar absorption lines to determine the properties of the intergalactic medium and the gaseous content of galaxies and groups of galaxies; 2) a medium deep survey using the Wide Field Camera to take data whenever one of the other instruments was being used and 3) a project to determine the Hubble Constant within ten percent by reducing the errors, both external and internal, in the calibration of the distance scale.
Important discoveries.
Hubble has helped resolve some long-standing problems in astronomy, as well as raising new questions. Some results have required new theories to explain them. Among its primary mission targets was to measure distances to Cepheid variable stars more accurately than ever before, and thus constrain the value of the Hubble constant, the measure of the rate at which the universe is expanding, which is also related to its age. Before the launch of HST, estimates of the Hubble constant typically had errors of up to 50%, but Hubble measurements of Cepheid variables in the Virgo Cluster and other distant galaxy clusters provided a measured value with an accuracy of ±10%, which is consistent with other more accurate measurements made since Hubble's launch using other techniques.
While Hubble helped to refine estimates of the age of the universe, it also cast doubt on theories about its future. Astronomers from the High-z Supernova Search Team and the Supernova Cosmology Project used ground-based telescopes and HST to observe distant supernovae and uncovered evidence that, far from decelerating under the influence of gravity, the expansion of the universe may in fact be accelerating. The cause of this acceleration remains poorly understood; the most common cause attributed is dark energy.
The high-resolution spectra and images provided by the HST have been especially well-suited to establishing the prevalence of black holes in the nuclei of nearby galaxies. While it had been hypothesized in the early 1960s that black holes would be found at the centers of some galaxies, and work in the 1980s identified a number of good black hole candidates, it fell to work conducted with Hubble to show that black holes are probably common to the centers of all galaxies. The Hubble programs further established that the masses of the nuclear black holes and properties of the galaxies are closely related. The legacy of the Hubble programs on black holes in galaxies is thus to demonstrate a deep connection between galaxies and their central black holes.
The collision of Comet Shoemaker-Levy 9 with Jupiter in 1994 was fortuitously timed for astronomers, coming just a few months after Servicing Mission 1 had restored Hubble's optical performance. Hubble images of the planet were sharper than any taken since the passage of Voyager 2 in 1979, and were crucial in studying the dynamics of the collision of a comet with Jupiter, an event believed to occur once every few centuries.
Other discoveries made with Hubble data include proto-planetary disks (proplyds) in the Orion Nebula; evidence for the presence of extrasolar planets around Sun-like stars; and the optical counterparts of the still-mysterious gamma ray bursts. HST has also been used to study objects in the outer reaches of the Solar System, including the dwarf planets Pluto and Eris.
A unique window on the Universe enabled by Hubble are the Hubble Deep Field, Hubble Ultra-Deep Field, and Hubble Extreme Deep Field images, which used Hubble's unmatched sensitivity at visible wavelengths to create images of small patches of sky that are the deepest ever obtained at optical wavelengths. The images reveal galaxies billions of light years away, and have generated a wealth of scientific papers, providing a new window on the early Universe. The Wide Field Camera 3 improved the view of these fields in the infrared and ultraviolet, supporting the discovery of some of the most distant objects yet discovered, such as MACS0647-JD.
The non-standard object SCP 06F6 was discovered by the Hubble Space Telescope in February 2006. During June and July 2012, US astronomers using Hubble discovered a tiny fifth moon moving around icy Pluto.
In March 2015, researchers announced that measurements of aurorae around Ganymede revealed that the moon has an subsurface ocean. Using Hubble to study the motion of its aurorae, the researchers determined that a large saltwater ocean was helping to suppress the interaction between Jupiter's magnetic field and that of Ganymede. The ocean is estimated to be 100 km deep, trapped beneath a 150 km ice crust.
Impact on astronomy.
Many objective measures show the positive impact of Hubble data on astronomy. Over 9,000 papers based on Hubble data have been published in peer-reviewed journals, and countless more have appeared in conference proceedings. Looking at papers several years after their publication, about one-third of all astronomy papers have no citations, while only 2% of papers based on Hubble data have no citations. On average, a paper based on Hubble data receives about twice as many citations as papers based on non-Hubble data. Of the 200 papers published each year that receive the most citations, about 10% are based on Hubble data.
Although the HST has clearly helped astronomical research, its financial cost has been large. A study on the relative astronomical benefits of different sizes of telescopes found that while papers based on HST data generate 15 times as many citations as a 4 m ground-based telescope such as the William Herschel Telescope, the HST costs about 100 times as much to build and maintain.
Deciding between building ground- versus space-based telescopes is complex. Even before Hubble was launched, specialized ground-based techniques such as aperture masking interferometry had obtained higher-resolution optical and infrared images than Hubble would achieve, though restricted to targets about 108 times brighter than the faintest targets observed by Hubble. Since then, advances in adaptive optics have extended the high-resolution imaging capabilities of ground-based telescopes to the infrared imaging of faint objects. The usefulness of adaptive optics versus HST observations depends strongly on the particular details of the research questions being asked. In the visible bands, adaptive optics can only correct a relatively small field of view, whereas HST can conduct high-resolution optical imaging over a wide field. Only a small fraction of astronomical objects are accessible to high-resolution ground-based imaging; in contrast Hubble can perform high-resolution observations of any part of the night sky, and on objects that are extremely faint.
Hubble data.
Transmission to Earth.
Hubble data was initially stored on the spacecraft. When launched, the storage facilities were old-fashioned reel-to-reel tape recorders, but these were replaced by solid state data storage facilities during servicing missions 2 and 3A. About twice daily, the Hubble Space Telescope radios data to a satellite in the geosynchronous Tracking and Data Relay Satellite System (TDRSS), which then downlinks the science data to one of two 60-foot (18-meter) diameter high-gain microwave antennas located at the White Sands Test Facility in White Sands, New Mexico. From there they are sent to the Space Telescope Operations Control Center at Goddard Space Flight Center, and finally to the Space Telescope Science Institute for archiving. Each week, HST downlinks approximately 120 gigabytes of data.
Color images.
All images from Hubble are monochrome, but each camera incorporates a wide variety of filters that may be used. Color images are created by combining separate monochrome images taken through different filters. This process can also create false-color versions of images including infrared and ultraviolet channels, where infrared is typically rendered as a deep red and ultraviolet is rendered as a deep blue.
Archives.
All Hubble data is eventually made available via the Mikulski Archive for Space Telescopes at STScI, CADC and ESA/ESAC. Data is usually proprietary—available only to the principal investigator (PI) and astronomers designated by the PI—for one year after being taken. The PI can apply to the director of the STScI to extend or reduce the proprietary period in some circumstances.
Observations made on Director's Discretionary Time are exempt from the proprietary period, and are released to the public immediately. Calibration data such as flat fields and dark frames are also publicly available straight away. All data in the archive is in the FITS format, which is suitable for astronomical analysis but not for public use. The Hubble Heritage Project processes and releases to the public a small selection of the most striking images in JPEG and TIFF formats.
Pipeline reduction.
Astronomical data taken with CCDs must undergo several calibration steps before they are suitable for astronomical analysis. STScI has developed sophisticated software that automatically calibrates data when they are requested from the archive using the best calibration files available. This 'on-the-fly' processing means that large data requests can take a day or more to be processed and returned. The process by which data are calibrated automatically is known as 'pipeline reduction', and is increasingly common at major observatories. Astronomers may if they wish retrieve the calibration files themselves and run the pipeline reduction software locally. This may be desirable when calibration files other than those selected automatically need to be used.
Data analysis.
Hubble data can be analyzed using many different packages. STScI maintains the custom-made Space Telescope Science Data Analysis System (STSDAS) software, which contains all the programs needed to run pipeline reduction on raw data files, as well as many other astronomical image processing tools, tailored to the requirements of Hubble data. The software runs as a module of IRAF, a popular astronomical data reduction program.
Outreach activities.
It has always been important for the Space Telescope to capture the public's imagination, given the considerable contribution of taxpayers to its construction and operational costs. After the difficult early years when the faulty mirror severely dented Hubble's reputation with the public, the first servicing mission allowed its rehabilitation as the corrected optics produced numerous remarkable images.
Several initiatives have helped to keep the public informed about Hubble activities.
In the United States, outreach efforts are coordinated by the Space Telescope Science Institute (STScI) Office for Public Outreach, which was established in 2000 to ensure that U.S. taxpayers saw the benefits of their investment in the space telescope program. To that end, STScI operates the HubbleSite.org website. The Hubble Heritage Project, operating out of the STScI, provides the public with high-quality images of the most interesting and striking objects observed. The Heritage team is composed of amateur and professional astronomers, as well as people with backgrounds outside astronomy, and emphasizes the aesthetic nature of Hubble images. The Heritage Project is granted a small amount of time to observe objects which, for scientific reasons, may not have images taken at enough wavelengths to construct a full-color image.
Since 1999, the leading Hubble outreach group in Europe has been the Hubble European Space Agency Information Centre (HEIC). This office was established at the Space Telescope European Coordinating Facility in Munich, Germany. HEIC's mission is to fulfill HST outreach and education tasks for the European Space Agency. The work is centered on the production of news and photo releases that highlight interesting Hubble results and images. These are often European in origin, and so increase awareness of both ESA's Hubble share (15%) and the contribution of European scientists to the observatory. ESA produces educational material, including a videocast series called Hubblecast designed to share world-class scientific news with the public.
The Hubble Space Telescope has won two Space Achievement Awards from the Space Foundation, for its outreach activities, in 2001 and 2010.
There is a replica of the Hubble Space Telescope on the courthouse lawn in Marshfield, Missouri, the hometown of namesake Edwin P. Hubble.
Future.
Equipment failure.
Past servicing missions have exchanged old instruments for new ones, both avoiding failure and making possible new types of science. Without servicing missions, all of the instruments will eventually fail. In August 2004, the power system of the Space Telescope Imaging Spectrograph (STIS) failed, rendering the instrument inoperable. The electronics had originally been fully redundant, but the first set of electronics failed in May 2001. This power supply was fixed during servicing mission 4 in May 2009. Similarly, the Advanced Camera for Surveys (ACS) main camera primary electronics failed in June 2006, and the power supply for the backup electronics failed on January 27, 2007. Only the instrument's Solar Blind Channel (SBC) was operable using the side-1 electronics. A new power supply for the wide angle channel was added during SM 4, but quick tests revealed this did not help the high resolution channel.
HST uses gyroscopes to stabilize itself in orbit and point accurately and steadily at astronomical targets. Normally, three gyroscopes are required for operation; observations are still possible with two, but the area of sky that can be viewed would be somewhat restricted, and observations requiring very accurate pointing are more difficult. There are further contingency plans for observations with just one gyro, but if all gyros fail, continued scientific observations will not be possible. In 2005, it was decided to switch to two-gyroscope mode for regular telescope operations as a means of extending the lifetime of the mission. The switch to this mode was made in August 2005, leaving Hubble with two gyroscopes in use, two on backup, and two inoperable. One more gyro failed in 2007. By the time of the final repair mission, during which all six gyros were replaced (with two new pairs and one refurbished pair), only three gyros were still working. Engineers are confident that they have identified the root causes of the gyro failures, and the new models should be much more reliable.
Orbital decay.
Hubble orbits the Earth in the extremely tenuous upper atmosphere, and over time its orbit decays due to drag. If it is not re-boosted, it will re-enter the Earth's atmosphere within some decades, with the exact date depending on how active the Sun is and its impact on the upper atmosphere. If Hubble were to descend in a completely uncontrolled re-entry, parts of the main mirror and its support structure would probably survive, leaving the potential for damage or even human fatalities. In 2013, deputy project manager James Jeletic projected that Hubble could survive into 2020. Based on solar activity and atmospheric drag, or lack thereof, a natural atmospheric reentry for Hubble will occur between 2030 and 2040.
NASA's original plan for safely de-orbiting Hubble was to retrieve it using a space shuttle. Hubble would then have most likely been displayed in the Smithsonian Institution. This is no longer possible since the space shuttle fleet has been retired, and would have been unlikely in any case due to the cost of the mission and risk to the crew. Instead NASA considered adding an external propulsion module to allow controlled re-entry. Ultimately NASA installed the Soft Capture and Rendezvous System, to enable deorbit by either a crewed or robotic mission.
Successors.
There is no direct successor to Hubble as an ultraviolet and visible-light space telescope, as near-term space telescopes do not duplicate Hubble's wavelength coverage (near-ultraviolet to near-infrared wavelengths), instead concentrating on the farther infrared bands. These bands are preferred for studying high redshift and low-temperature objects, objects generally older and farther away in the universe. These wavelengths are also difficult or impossible to study from the ground, justifying the expense of a space-based telescope. Large ground-based telescopes can image some of the same wavelengths as Hubble, sometimes challenge HST in terms of resolution by using adaptive optics (AO), have much larger light-gathering power, and can be upgraded more easily, but cannot yet match Hubble's excellent resolution over a wide field of view with the very dark background of space.
Plans for a Hubble successor materialized as the Next Generation Space Telescope project, which culminated in plans for the James Webb Space Telescope (JWST), the formal successor of Hubble. Very different from a scaled-up Hubble, it is designed to operate colder and farther away from the Earth at the L2 Lagrangian point, where thermal and optical interference from the Earth and Moon are lessened. It is not engineered to be fully serviceable (such as replaceable instruments), but the design includes a docking ring to enable visits from other spacecraft. A main scientific goal of JWST is to observe the most distant objects in the universe, beyond the reach of existing instruments. It is expected to detect stars in the early Universe approximately 280 million years older than stars HST now detects. The telescope is an international collaboration between NASA, the European Space Agency, and the Canadian Space Agency since 1996, and is planned for launch on an Ariane 5 rocket. Although JWST is primarily an infrared instrument, its coverage extends down to 600 nm wavelength light, or roughly orange in the visible spectrum. A typical human eye can see to about 750 nm wavelength light, so there is some overlap with the longest visible wavelength bands, including orange and red light.
A complementary telescope, looking at even longer wavelengths than Hubble or JWST, was the European Space Agency's Herschel Space Observatory, launched on May 14, 2009. Like JWST, Herschel was not designed to be serviced after launch, and had a mirror substantially larger than Hubble's, but observed only in the far infrared and submillimeter. It needed helium coolant, of which it ran out on April 29, 2013.
Further concepts for advanced 21st-century space telescopes include the Advanced Technology Large-Aperture Space Telescope, a conceptualized 8- to 16-meter (320- to 640-inch) optical space telescope that if realized could be a more direct successor to HST, with the ability to observe and photograph astronomical objects in the visible, ultraviolet, and infrared wavelengths, with substantially better resolution than Hubble or the Spitzer Space telescope. This effort is being planned for the 2025–2035 time frame.
Existing ground-based telescopes, and various proposed Extremely Large Telescopes, can exceed the HST in terms of sheer light-gathering power and diffraction limit due to larger mirrors, but other factors affect telescopes. In some cases, they may be able to match or beat Hubble in resolution by using adaptive optics. However, AO on large ground-based reflectors will not make Hubble and other space telescopes obsolete. Most AO systems sharpen the view over a very narrow field—Lucky Cam, for example, produces crisp images just 10" to 20" wide, whereas Hubble's cameras are super sharp across a 2½' (150") field. Furthermore, space telescopes can study the heavens across the entire electromagnetic spectrum, most of which is blocked by Earth's atmosphere. Finally, the background sky is darker in space than on the ground, because air absorbs solar energy during the day and then releases it at night, producing a faint—but nevertheless discernible—airglow that washes out low-contrast astronomical objects.
References.
Bibliography.
</dl>
External links.
Listen to this article ()
This audio file was created from a revision of the "Hubble Space Telescope" article dated 2006-05-29, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="40205" url="http://en.wikipedia.org/wiki?curid=40205" title="Foreign relations of Albania">
Foreign relations of Albania

Albanian foreign policy since its independence has maintained a policy of complementarism by trying to have friendly relations with all countries. Albania is a member of more than 48 different international organizations including the United Nations, the Council of Europe, the North Atlantic Treaty Organization, the Organisation of Islamic Cooperation., the Organization for Security and Cooperation in Europe, the International Monetary Fund, the World Trade Organization and La Francophonie.
The main objectives of Albanian foreign policy are:
The main factors defining Albanian foreign policy consist of geopolitical location, population, economic crisis, and ties with Albanian diaspora throughout the world.
Albania has concentrated on maintaining good relations with its Balkan neighbours, gaining access to European-Atlantic security institutions, and securing close ties with the United States.
On 14 January 2011, Albania signed a pact with Italy for a corporal foreign strategy.
The government of Albania is very concerned with developments in neighboring Kosovo, particularly in the post-Dayton agreement period. Although the region is claimed by Serbia to be a Serbian province, Albania recognized Kosovo’s declaration of independence on 18 February 2008.
After the fall of the Albanian communist regime in 1991, relations between Greece and Albania became increasingly strained because of widespread allegations of mistreatment by Albanian authorities of the Greek ethnic minority in southern Albania and of the Albanian communities in northern Greece. A wave of Albanian illegal economic migrants to Greece exacerbated tensions. The crisis in Greek–Albanian relations reached its peak in late August 1994, when an Albanian court sentenced five members (a sixth member was added later) of the ethnic Greek political party "Omonia" to prison terms on charges of undermining the Albanian state. Greece responded by freezing all EU aid to Albania, and sealing its border with Albania. In December 1994, however, Greece began to permit limited EU aid to Albania, while Albania released two of the "Omonia" defendants and reduced the sentences of the remaining four.
There are still other impending issues in the relations between the two countries, regarding many Albanian workers in Greece who have not received legal papers despite promises by the Greek government. In 1996, the two countries signed a Treaty of Peace and Friendship and discussed the issues of the status of Albanian refugees in Greece and education in the mother tongue for the ethnic Greek minority in southern Albania.
Today, as result of very frequent high-level contacts between the governments and the parliaments, relations between the two countries are regarded as cordial. Greece is a staunch supporter of the Euro-Atlantic integration of the Republic of Albania. Since Albania's NATO entry in May 2009, the Albanian-Greek relations have been developing on all fronts, and especially after the election victory of Edi Rama in 2013, with the Albanian Chief of Foreign Policy, Ralf Gjoni, describing the diplomatic relations between two countries as "excellent". Greece today is Albania's most important European Union ally and NATO partner. At the Albanian government’s request, about 250 Greek military personnel are stationed in Albania to assist with the training and restructuring of the Albanian Armed Forces, as part of the NATO programme. Big projects currently in running between the two countries include the touristic development of the Ionian coastline shared between the two countries, and the Trans Adriatic Pipeline (TAP), which helped boosting the relations of the two countries even further.
Tirana’s relations with the Republic of Macedonia remain friendly, despite occasional incidents involving ethnic Albanians there. Tirana has repeatedly encouraged the Albanian minority’s continued participation in its government.
During the 1990s, after the fall of communism, at the onset of democratic reforms, there were vast waves of illegal immigration from the Albanian ports to Italy. This strained relations between the countries somewhat as Italy had to avert a humanitarian crisis. The tensions reached a peak when an Italian coast guard ship allegedly rammed and sank an Albanian ship carrying 120–130, 75 of whom drowned, on 28 March 1997. Eventually the two countries began joint operations aimed at stopping illegal smuggling operations. Italy has also provided financial assistance to Albania to help its ailing economy.
International disputes.
The Albanian government supports protection of the rights of ethnic Albanians outside of its borders but has downplayed them to further its primary foreign policy goal of regional cooperation; Albanian majority in Kosovo seeks full recognition of the declared independence from Serbia; Albanians in the Republic of Macedonia claim discrimination in education, access to public-sector jobs, and representation in government. A handful of Albanian troops have participated in the US-led invasions and occupations of Iraq and Afghanistan. Albanian policy is very favorable to that of the United States.
Foreign aid.
Through FY 1998, the United States committed approximately US$300 million to Albania’s economic and political transformation and to address humanitarian needs. At the time, this figure comprised about 10% of all bilateral and multilateral assistance offered since 1991. Italy ranks first in bilateral assistance and Germany third. The European Union (EU) has given about US$800 million since 1991 and pledged US$175 million in 1996–99. 
In FY 1999, the United States was to provide $30 million through the Support for East European Democracy (SEED) Act, up from $27 million the previous year. The U.S. also was to provide an agricultural commodities grant of $10 million. 
The $30 million Albanian-American Enterprise Fund (AAEF), launched in 1994, is actively making debt and equity investments in local businesses. AAEF is designed to harness private sector efforts to assist in the economic transformation. U.S. assistance priorities include promotion of agricultural development and a market economy, advancement of democratic institutions (including police training), and improvements in quality of life. The SEED funding request for Albania for FY 2000 was $25 million.
International organization participation.
The Republic of Albania is member in these international organizations.
External links.
 This article incorporates public domain material from websites or documents of the (Background Notes
 This article incorporates public domain material from websites or documents of the .

</doc>
<doc id="40207" url="http://en.wikipedia.org/wiki?curid=40207" title="Albanian Armed Forces">
Albanian Armed Forces

The Albanian Armed Forces (AAF) (Albanian: "Forcat e Armatosura të Republikës së Shqipërisë" (FARSH)) were formed after the declaration of independence in 1912. Today it consists of: the General Staff, the Albanian Land Force, the Albanian Air Force and the Albanian Naval Force.
Missions and duties.
According to the Albanian Constitution, the Albanian Armed Forces are charged to:
History.
On 4 December 1912 Albanian Prime Minister Ismail Qemali and his government formed the Albanian National Army. Its first Chief in Command was Lieutenant Colonel Ali Shefqet Shkupi
The Royal Albanian Army (Albanian: "Ushtria Mbretërore Shqiptare") was the army of King Zogu from 1928 until 1939. Its commander-in-chief was King Zog; its commander General Xhemal Aranitasi; its Chief of Staff was General Gustav von Myrdacz. The army was mainly financed by Italy.
On 7 April 1939, Italian troops invaded the country, and captured it in six days.
Cold War.
After the Second World War, Albania became a Soviet-aligned country. The ranks and the structure of the Albanian Armed Forces were organized based on the Soviet concepts, thus increasing the political control of the State-Party over the Armed Forces. One of the defining characteristics of civilian-military relations during this period was the effort of the civilian leadership to ensure the loyalty of the military to the communist system's values and institutions.
Like all other branches of the state, the military was subjugated to Communist Party control. All high-ranking military officers and most of the lower and middle ranks were members of the Communist Party—and had loyalties to it. The system was re-enforced by the establishment of Party cells within the military and extensive communist political education alongside soldiers’ military training, by the political commissars. To further increase its political control, the Albanian Communist Party enlarged the conscription system, thus enlisting in the Armed Forces personnel dedicated to the military career from the Albanian rural areas.
The State and Party went even further, starting from 1 May 1966, military ranks were abolished following the example of the Chinese People's Liberation Army, heavily influenced by Maoism during the years of the Cultural Revolution, and thus adopting strategic concepts related to forms of guerrilla war (Vietnam War doctrine). The military were still organized during this period into their basic structure forms, but the role of the military commander was insignificant with respect to the commanding role of the political commissars. In 1991 the rank system was reestablished under President Ramiz Alia.
During all these years, Sigurimi which was the Albanian secret service during that period and was formed upon the KGB structure, was responsible for the execution, the imprisonment and deportation of more than 600 Officers from the Armed Forces, by completely neutralizing the Armed Forces ability to start a coup d'état. Initially the communist purge concentrated on the military personnel graduated by the Western Military Academies (mainly from Italy 1927–1939), extended later on to the officers graduated in Soviet Union (after the Albanian abandon of the Warsaw Pact in 1961). As the communist regime collapsed in Albania during 1990, there was a real fear that the armed forces might intervene to halt the collapse of communism by force. In the event, the armed forces stood by as the regime of which they had been a part disintegrated.
During the 1980s, Albania had reduced the number of infantry brigades from eight to four. It had shifted to fully manned units from its prior reliance on the mobilisation of reserve soldiers to flesh out a larger number of units manned at a lower level. Each brigade had three infantry battalions and one lightly equipped artillery battalion. Armoured forces consisted of one tank brigade. Artillery forces were increased from one to three regiments during the 1980s, and six battalions of coastal artillery were maintained at strategic points along the Adriatic Sea littoral.
Post 1991 history.
In 1992, the Library of Congress estimated that the ground forces had about 35,000 men, or about three-quarters of all armed forces personnel. Because the strength of the ground forces was sufficient to man only about two divisions, brigades of approximately 3,000 soldiers became the largest army formation. In 1991 four infantry brigades constituted the bulk of combat units in the ground forces.
During the civilian riots in 1997, the political attempts by the government to use the Armed Forces to crush the rebellion were soon demonstrated to be a failure, following a total disintegration of the Armed Forces and the looting of the military facilities by the civilian population.
Albania sheltered many thousands of Kosovar refugees during the 1999 conflict, and allowed NATO to provide logistical assistance for Kosovo Force (KFOR) troops through Communications Zone West headquartered in Durrës. Albania was part of the International Stabilization Force (SFOR) serving in Bosnia (then EU mission "ALTHEA"), and Albanian peacekeepers are part of the International Security Assistance Force in Afghanistan, ISAF and the international stabilization force in Iraq. Albania has been a steadfast supporter of U.S. policy in Iraq, and one of only four nations to contribute troops to the combat phase of Operation Enduring Freedom.
Increasing the military budget was one of the most important conditions for NATO integration. Military spending has generally been lower than 1.5% since 1996 only to peak in 2009 at 2% and fall again to 1.5%.
There was an incident in 2002 in Albania where it was discovered, in a cluster of mountain bunkers, 16 tons of primitive, undocumented chemical weapon agents that Albania had forgotten about.
In December 2006, the Armed Forces adopted a new structure based on the Joint warfare concept. It had three main Commands: the "Joint Forces Command", the "Joint Support Command" and the "Training and Doctrine Command". The Albanian Joint Forces Command (AJFC) consists of the Rapid Reaction Brigade, the Commando Regiment, the Navy Brigade, the Air Brigade and the Area Support Brigade. The Albanian Joint Support Command provides support and logistical functions to all AAF units. The Albanian Training and Doctrine Command was established as the main educational and training provider for the Albanian Armed Forces. The final number of personnel will be 13,800 (including 2,000 civilians). However this new structure lasted a little more than 3 years and on April 2010 returned to its classic and current form.
In March 2008 the problem of massive amounts of excess ammunition stockpiled in Albania became known to the public through the tragic consequences of the explosion of an ammunition depot (the 2008 Tirana explosions).
The Albanian Land Force or Albanian Army consists of the Rapid Reaction Brigade, a Commando Regiment, and the Area Support Brigade. Part of the structure of the Albanian Commando Regiment is the Special Operations Battalion (BOS). The Albanian Army is mostly supported by the United States, Germany, the Netherlands, Italy, the United Kingdom, Greece, Turkey, Switzerland, Denmark and Belgium.
The Albanian Navy performs mainly Coast Guard duties, and recently the Albanian parliament has approved some amendments to the articles of the actual Law on the Coast Guard in Albania, in order to improve the necessary legal framework due to efforts at European Union-NATO integration. Since February 2008, Albania participates officially in NATO's Operation Active Endeavor in the Mediterranean.
Albania became a full member of the North Atlantic Treaty Organization on 1 April 2009.
Albania hosts an international fair on security and defense called the Albanian Military Exhibition (ALMEX) where different security industries can present their products and services for the regional market.
Modernization.
After several major re-equipment programs, in 2001 the Albanian Armed Forces launched a 10-year reform program to become technologically advanced and fully professional by 2011. The new armed forces consists of about 14,500 troops including 2,000 civilians, trained to NATO standards. The same radical reform is being implemented on surplus equipment, including airplanes, tanks, helicopters, artillery equipment, navy vessels, SALW and ammunition. Albania started an ambitious destruction program. However, Albania is still dealing with a huge amount of surplus and obsolete ammunition, a direct result of the country's long isolation and ethnic tensions in the area. The Albanian Ministry of Defense estimates such quantity up to 85,000 tons, but it is expected to increase up to 104,000 tons due to the ongoing downsizing process of the AAF.
In 2004 U.S. President George W. Bush authorized the use of Nunn-Lugar Cooperative Threat Reduction program funds for projects in Albania, marking the first time such funds were authorized for use outside the former Soviet Union. With this funding the U.S. assisted the Government of Albania with the destruction of a stockpile of chemical warfare agents left over from the communist regime (Category 1, Total amount 16.7 tons). The final cost of the project was US$48 million and was officially completed on 10 July 2007.
On 3 April 2006, the final contract for the delivery of 12 "Bölkow-Blom MBB" BO-105 lightweight twin-engine multi-role helicopters to the Republic of Albania was signed in Tirana between the Albanian Ministry of Defense and Eurocopter "Deutschland GmbH". According to the Albanian Government, six of the BO-105 helicopters are designated for the Albanian Air Brigade, four for the Ministry of Interior and the remaining two for the Albanian Ministry of Health.
Albania has recently acquired 4 Eurocopter AS532 Cougar helicopters and has 2 more EC 145 on order as of 2015. Also, since 2008 four Damen Stan 4207 patrol vessels have been commissioned in the Navy, 3 of them have been constructed in Albania.
On 16 July 2014, The Albanian Defense Minister declared that within 2014 the Albanian Motorized Infantry Battalion will be fully combat ready and also equipped with modern NATO equipment. This will be the first unit in the Albanian Armed Forces to not have the AK 47 in its inventory. Instead the M4 carbine will act as its standard battle rifle.

</doc>
<doc id="40208" url="http://en.wikipedia.org/wiki?curid=40208" title="Transport in Albania">
Transport in Albania

Transport in Albania had been rather undeveloped during the Communist period (between 1945 and 1990), after which the country has had to make significant investment into transport infrastructure.
History.
Since antiquity, the area of modern Albania served as a crossroad of important caravan routes such as the Roman Via Egnatia linking the Adriatic with Byzantium (later Constantinople). Afterwards during World War I, occupying forces opened up new road sections mainly in the mountainous areas of the country. In King Zog's period, further road construction took place for instance at Krraba Pass between Tirana and Elbasan. The total length of Albania's roads more than doubled in the first three decades after World War II, and by the 1980s almost all of the country's remote mountain areas were connected, either by dirt or paved roads, with the capital city of Tirana, and ports on the Adriatic and Ionian Sea. Private car ownership was not allowed and the only vehicles circulating were state-owned trucks, agricultural and official's vehicles, buses, motorcycles, and bicycles. The country's roads, however, were generally narrow, poorly marked, pocked with holes, and in the early 1990s often crowded with pedestrians and people riding mules, bicycles, and horse-drawn carts.
After 1947, a significant infrastructure undertaking was the construction of the country's rail network as Albania was considered as the only state in Europe not to have standard rail service. By 1987, 677 km of railway were constructed in total linking the main urban and industrial centers for the first time since the end of World War II. Train transport was the main public transportation method until 1990. After the collapse of Communism, the network fell into disregard, operating with second-hand carriages in a constant precarious state.
Post-Communism.
Central government funding of local road maintenance effectively ended in 1991, and the breakdown of repair vehicles because of a lack of spare parts threatened to close access to some remote areas. A group of Greek construction companies signed a protocol with the Albanian government in July 1990 to build a 200 kilometer road across the southern part of the country, extending from the Albanian-Greek border to Durrës. The project was scheduled to last four years and cost US$500 million. Despite the poor quality of Albania's roads, most of the country's freight was conveyed over them in a fleet of about 15,000 trucks. According to official figures, in 1987 Albania's roadways carried about 66 percent of the country's total freight tonnage.
Up until 1991, the total number of cars in Albania was between 5000 to 7000. In 1991, the Albanian government lifted the decades-old ban on private-vehicle ownership. As a result, car imports numbered about 1,500 per month. Traffic in the capital remained light, but traffic lights and other control devices were urgently needed to deal with the multiplying number of privately owned cars. Albanian entrepreneurs also imported used Greek buses and started carrying passengers on intercity routes that did not exist or had been poorly serviced during the communist era.
The population is known for owning a large fleet of German cars. In particular, Mercedes Benz vehicles are widely preferred not only for their status symbol, but also for their durability on rural roads where half of the population resides, and the cheap price for buying used ones. Mercedes Benz cars were owned by Enver Hoxha and reportedly favored by his officials, giving the brand a foothold even before private ownership of cars was legalized. 
Air pollution has become a pressing concern as the number of cars has increased to over 300,000 in the capital Tirana. These are mostly 1990s and early 2000s diesel cars, while it is widely believed that the fuel used in Albania contains larger amounts of sulfur and lead than in the European Union. Albania is probably one of the few countries in Europe where vehicles imported from the United States, and from left hand traffic jurisdictions (for example the United Kingdom) can be found on the streets without any modifications brought from expats living abroad.
Since the beginning of the transition, foreign donors have funded no less than ten urban transport plans and studies for Tirana, prepared mainly by foreign consultants (in some cases invited by the City, in others hired directly by the donor organization). In most cases, the principal recommendation of these studies was to strengthen the public transport sector.
Highways, Expressways or Freeways.
<br>"country comparison to the world:" 118
After the fall of communism in 1991, Albania began to revamp its primitive road infrastructure by building the first highway in Albania, SH2 connecting Tirane with Durres. Since the 2000s, main roadways have drastically improved, though lacking standards in design and road safety. This involved the construction of new roadways and the putting of contemporary signs. However, some state roads continue to deteriorate from lack of maintenance while others remain unfinished.
The biggest road project in the history of Albania is the construction of the Rrëshen-Kalimash dual carriageway from 2007 to 2010 linking Albania with Kosovo and part of the A1 Motorway. The segment involved the carving of a mountainous terrain, and the construction of a 5.6 km long tunnel and dozens of bridges. In October 2010, Prime Minister Sali Berisha announced plans to build several major highways.
At present, major cities are linked with either new single/dual carriageways or well maintained roads. There is a dual carriageway connecting the port city of Durrës with Tirana, Vlorë, and partially Kukës. In fact, there are three official motorway segments in Albania: Thumanë-Milot-Rrëshen-Kalimash (A1), Levan-Vlorë (A2), and partly Tirane-Elbasan (A3). Most rural segments continue to remain in bad conditions as their reconstruction has only begun in the late 2000s by the Albanian Development Fund .
The major priority of the government in 2014 is the completion of unfinished roadways due to lack of funding. Another major priority is the completion of the Arbër Highway ("Rruga e Arbërit") linking Tirana with the city of Debar (Republic of Macedonia) through the current SH6. Eventually, this "superstradë" will become part of European corridor 8 linking Albania with the Republic of Macedonia and Greece. Another objective is the completion of the Tirana-Elbasan Highway Motorway (Autostradë) including the Krrabe Tunnel. Other important goals are the launch of toll highways, and the construction of the Southern Axis of Albania ("Boshti i Jugut") passing across central and southern Albania. The completion of the Eastern Ring of Albania ("Unaza Lindore") passing through Valbonë, Kukës, Krumë, Bulqizë and Librazhd is also a priority. In the mountainous areas, roads can be windy with numerous serpentines and hairpins. When all corridors are completed, Albania will have an estimated 759 kilometers of highway linking it with its neighbors.
Despite considerable investments, some dual carriageways are partially up to either motorway or state road standards as they are badly configured, contain unfinished overpasses, uncontrolled access points, lack of fencing and either misplaced or missing road signs, inadequate entry and exit ramps, and are indiscriminately used by animals, mopeds, agricultural vehicles, and pedestrians.
Road system.
A new road system has been introduced in the last decade and is classified as follows:
All roads are property of Albanian Road Authority ("Autoriteti Rrugor Shqiptar", former Drejtoria e Përgjithshme e Rrugëve) and maintained by Ndërmarrja Shtetërore Rruga-Ura. The government plans to create some toll highways in the near future. Albanian bitumen from Selenicë in Southern Albania is well known for its quality as it has been used on some European motorways.
Under Construction.
In recent years, a major road construction spree took place on the main state roads of Albania, including improving road signage, planting of trees, and greening projects. Works on most highways are mostly completed, though they remained unfinished between 2011 and 2013 as per lack of funds.
2006 - present.
Below is a list of main roadways undergoing construction works in the last decade. Most works are completed as of 2015, though some are still underway:
International Routes.
Albania is the only country in Europe not participating in the E-road network most probably from its still unfinished road network and long isolation. However in 2006, Albania joined the E-road cooperation but did not ratify the AGR (European Agreement on Main International Traffic Arteries) treaty. As a result, the following routes only formally pass through the country. Thus, information in parentheses is tentative:
Public transport and driving in Albania.
Public transport in Albania is mainly characterized by the use of "furgons", the equivalent of minibuses, vans or shuttles identifiable by yellow plates. They are convenient but do not follow fixed schedules, and are not usually equipped with A/C. Prices can be negotiated with the driver before departing. Bus transport is also available but they are usually older and slow. Tirana, the capital city does not have yet a central bus station. Minibuses and buses drop off and pick up passengers from various fixed places around the city and on route, while stopping for coffee breaks along the way. 
Despite the perceived negative connotation to driving in Albania, most vehicles manage not to get into accidents by simply exercising common sense, and following their own way through the chaotic traffic. The law of the strongest fully applies on the Albanian roads. In cities, traffic is slow thus more secure than in rural areas. Expect reckless driving such as hair-raising overtaking even on turns, driving on the wrong side of the road, stopping on highways by the road side, uncontrolled crossing of cars, horse-drawn carts and pedestrians, and complete ignoring of stop signs and right of way at intersections. Albanian drivers are prone to using visual and acoustic aids regularly such as honking, headlight flashing, or high beams at night. Daytime running lamps must be activated outside urban areas. 
It is strongly recommended to have an up-to-date GPS, as many new roads have been recently added to the Albanian road network. In case the GPS does not work, its good to have an alternative paper or internet-based map. Street names on the ground do not always coincide with maps, as the current address system has only recently been introduced. In the mountains, some roads can be narrow and windy with hairpins/serpentines and missing guardrails. Drivers are encouraged to check engine liquid levels to avoid overheating in the summer months. Some roads still have few road signs or misleading ones. Its strongly advised to always keep a spare tire.
As vehicles more than doubled in recent years, traffic fatalities have increased especially in a country where private car ownership was banned until the early 1990s. Some experts also attribute the increase to the above road structural problems, lack of buckling up, the use of alcohol, excessive speed, and unaccustomed drivers such as expats returning home. In an effort to curb such a phenomenon, mobile police patrols have been deployed, road signage improved, and speed radars installed on major roadways and city intersections.
Railways.
Total: 447 km
<br>"country comparison to the world:" 120
Standard gauge: 447 km gauge (2006)
Railway links with neighbouring countries:
Waterways.
Albania's main seaports are Durrës, Vlorë, Sarandë, and Shëngjin. By 1983 there was regular ferry, freight, and passenger services from Durrës to Trieste, Italy. In 1988 ferry service was established between Sarandë and the Greek island of Corfu. A regular lake ferry linked the Macedonian town of Ohrid with Pogradec. The estimated total displacement of Albania's merchant fleet was 56,000 tons in 1986. The limited capacity of the wharves at Durrës caused severe bottlenecks in the distribution of foreign food aid in 1991. As of 2011, the Port of Durrës is undergoing major renovations.
Ferry services within Albania:
Pipelines.
The construction of 1.2 billion dollar AMBO pipeline was planned to begin in 2007. This would connect the port of Burgas in Bulgaria with the port of Vlora in Albania. It is expected to ship 750000 oilbbl to 1000000 oilbbl of crude oil each day. However, the Trans Adriatic Pipeline seems more likely to get started.
Merchant Marine.
<br>"country comparison to the world:" 91
Airways.
In 1977 Albania's government signed an agreement with Greece, opening the country's first air links with non-communist Europe. As a result, Olympic Airways was the first non-communist airline to fly into Albania. By 1991 Tirana had air links with many major European cities, including Paris, Rome, Zürich, Vienna, and Budapest. Tirana was served by a small airport, Tirana International Airport Nënë Tereza, located twenty-eight kilometers from the capital at the village of Rinas. Albania had no regular domestic air service. A Franco-Albanian joint venture launched Albania's first private airline, Ada Air, in 1991. The company offered flights in a thirty-six-passenger airplane four days each week between Tirana and Bari, Italy, and a charter service for domestic and international destinations.
As of 2007 Albania has only one international airport: Tirana International Airport Nënë Tereza. The airport is linked to 29 destinations by 14 airlines. It has seen a dramatic rise in terms of passenger numbers and aircraft movements since the early 1990s. In December 2007 it served over 1 million passengers and had 43 landings and takeoffs per day.
Airports.
Tirana International Airport is the only international airport in Albania. In 2005, TIA was given to an American-German consortium for a 20-year concession period. Despite the considerable modernization of the airport, prices are among the highest in Europe as per the monopoly over Albanian airspace, and limited carrier choices. As a result, low cost carriers are discouraged from entering the Albanian market, while neighboring countries offer much lower prices from their primary and secondary airports.
A number of regional airports have been renovated but are not operational. In 2014, it was announced that a new airport would be built in Southern Albania in the future. Kukës Airport was opened in 2008, making this the second civilian airport in Albania. A local news paper announced on March 16, 2007 that the Italian government would help rebuild the airport in Gjirokastër. The airport would be dual functional, both a civilian and military airport. Currently there are two feasibility studies being conducted for airports in Vlora and Korça. The plan for Saranda Airport was completed however there is no known investor willing to put in money at the time.
Total paved runways.
3
Gjadër/Gramsh
Kuçovë
Kukës
Tiranë/Rinas
External links.
Government.
 This article incorporates public domain material from the document .

</doc>
<doc id="40210" url="http://en.wikipedia.org/wiki?curid=40210" title="Telecommunications in Albania">
Telecommunications in Albania

Telecommunications in Albania include radio, television, fixed and mobile telephones, and the Internet.
History.
Until 1990, Albania was one of the world's most isolated and controlled countries, and installation and maintenance of a modern system of international and domestic telecommunications was precluded. Callers previously needed operator assistance even to make domestic long-distance calls.
Albania's telephone density was the lowest in Europe, at 1.4 units for every 100 inhabitants. Tirana accounted for about 13,000 of the country's 42,000 direct lines; Durrës, the main port city, ranked second with 2,000 lines; the rest were concentrated in Shkodër, Elbasan, Vlorë, Gjirokastër, and other towns. At one time, each village had a telephone but during the land redistribution of the early 1990s peasants knocked out service to about 1,000 villages by removing telephone wire for fencing. Most of Albania's telephones were obsolete, low-quality East European models, some dating from the 1940s; workers at a Tirana factory assembled a small number of telephones from Italian parts.
In the early 1990s, Albania had 240 microwave circuits to Italy and 180 to Greece carrying international calls. The Albanian telephone company had also installed two U-20 Italtel digital exchanges. The exchange in Tirana handled international, national, and local calls; the Durrës exchange handled only local calls. Two United States firms handled direct-dial calls from the United States to Tirana. At present the land lines are overloaded and it is difficult to receive a telephone number. As a result, the number of mobile phones has skyrocketed in the bigger cities. 
Radio and television.
The state broadcaster in Albania, Radio Televizioni Shqiptar (RTSh, Albanian Radio and TV), operates national radio and television networks. It has competition from scores of privately owned stations. According to a 2002 survey the broadcaster with the largest audience is TV Klan.
Television is the most influential medium. Many Albanian's watch Italian and Greek stations via terrestrial reception. 
The BBC World Service (103.9 MHz in the capital, Tirana), Deutsche Welle, Radio France Internationale, and the Voice of America are available.
Internet.
Internet broadband services were initiated in 2005, but growth has been slow. Internet cafes are popular in Tirana and have started to spread outside the capital. 
Eutelsat satellite broadband is being used to provide free public Internet access in rural Albanian post offices, schools, and local government offices.
Internet censorship and surveillance.
There are no government restrictions on access to the Internet or reports that the government monitors e-mail or Internet chat rooms without appropriate legal authority. The constitution provides for freedom of speech and press, and the government generally respects these rights in practice. However, there are reports that the government and businesses influence and pressure the media. The constitution and law prohibit arbitrary Interference with privacy, family, home, or correspondence, and the government generally respects these prohibitions in practice.

</doc>
<doc id="40211" url="http://en.wikipedia.org/wiki?curid=40211" title="Economy of Albania">
Economy of Albania

The economy of Albania has undergone a transition from its Communist past into an open-market economy since the early 1990s. The country is rich in natural resources, and the economy is mainly bolstered by agriculture, food processing, lumber, oil, cement, chemicals, mining, basic metals, hydro power, tourism, textile industry, and petroleum extraction. As of 2014, exports seem to gain momentum and have increased 300% from 2008, although their contribution to the gross domestic product is still moderate (the export of products per capita as of 2014 is around $1,100 ).
History.
The collapse of communism in Albania came later and was more chaotic than in other Eastern European countries and was marked by a mass exodus of refugees to Italy and Greece in 1991 and 1992. The country attempted to transition to autarky, but this eventually failed badly. Attempts at reform began in earnest in early 1992 after real GDP fell by more than 50% from its peak in 1989. Albania currently suffers from high organised crime and corruption rates.
The democratically elected government that assumed office in April 1992 launched an ambitious economic reform program to halt economic deterioration and put the country on the path toward a market economy. Key elements included price and exchange system liberalization, fiscal consolidation, monetary restraint, and a firm income policy. These were complemented by a comprehensive package of structural reforms including privatization, enterprise, and financial sector reform, and creation of the legal framework for a market economy and private sector activity. Most agriculture, state housing, and small industry were privatized. This trend continued with the privatization of transport, services, and small and medium-sized enterprises. In 1995, the government began privatizing large state enterprises. After reaching a low point in the early 1990s, the economy slowly expanded again, reaching its 1989 level by the end of the decade.
Macro-economic trends.
This is a chart of Gross Domestic Product (GDP) of Albania in national currency (million leks) and in US dollars based on Purchasing Power Parity (PPP) from estimates by the International Monetary Fund.
For purchasing power parity comparisons, the US dollar is exchanged at 49 leks (2007 estimate). Mean wages were $3.83 per manhour in 2009.
Albania is a middle income country by Western European standards, with GDP per capita greater than the several countries in the region. . According to Eurostat, Albania's GDP per capita (expressed in PPS – Purchasing Power Standards) stood at 35 percent of the EU average in 2008. Unemployment rate of 13.3% is considerably lower than many countries in Balkans, For Example, Serbia has an unemployment rate of 24%.
Results of Albania's efforts were initially encouraging. Led by the agricultural sector, real GDP grew by an estimated 11% in 1993, 8% in 1994, and more than 8% in 1995, with most of this growth in the private sector. Annual inflation dropped from 25% in 1991 to single-digit numbers. The Albanian currency, the lek, stabilized. Albania became less dependent on food aid. The speed and vigour of private entrepreneurial response to Albania's opening and liberalizing was better than expected. Beginning in 1995, however, progress stalled, with negligible GDP growth in 1996 and a 9% contraction in 1997. A weakening of government resolve to maintain stabilization policies in the election year of 1996 contributed to renewal of inflationary pressures, spurred by the budget deficit which exceeded 12%. Inflation approached 20% in 1996 and 50% in 1997. The collapse of financial pyramid schemes in early 1997 – which had attracted deposits from a substantial portion of Albania's population – triggered severe social unrest which led to more than 1,500 deaths, widespread destruction of property, and an 8% drop in GDP. The lek initially lost up to half of its value during the 1997 crisis, before rebounding to its January 1998 level of 143 to the dollar. The new government, installed in July 1997, has taken strong measures to restore public order and to revive economic activity and trade.
Albania is currently undergoing an intensive macroeconomic restructuring regime with the International Monetary Fund and the World Bank. The need for reform is profound, encompassing all sectors of the economy. In 2000, the oldest commercial bank, Banka Kombetare Tregtare/BKT was privatized. In 2004, the largest commercial bank in Albania—then the Savings Bank of Albania—was privatised and sold to Raiffeisen Bank of Austria for US$124 million. . Macroeconomic growth has averaged around 5% over the last five years and inflation is low and stable. The government has taken measures to curb violent crime, and recently adopted a fiscal reform package aimed at reducing the large gray economy and attracting foreign investment. The economy is bolstered by annual remittances from abroad representing about 15% of GDP, mostly from Albanians residing in Greece and Italy; this helps offset the towering trade deficit. The agricultural sector, which accounts for over half of employment but only about one-fifth of GDP, is limited primarily to small family operations and subsistence farming because of lack of modern equipment, unclear property rights, and the prevalence of small, inefficient plots of land. Energy shortages because of a reliance on hydropower, and antiquated and inadequate infrastructure contribute to Albania's poor business environment and lack of success in attracting new foreign investment. The completion of a new thermal power plant near Vlore has helped diversify generation capacity, and plans to improve transmission lines between Albania and Montenegro and Kosovo would help relieve the energy shortages. Also, with help from EU funds, the government is taking steps to improve the poor national road and rail network, a long-standing barrier to sustained economic growth.
Reforms have been taken especially since 2005. In 2009, Albania was the only country in Europe, together with San Marino and Liechtenstein, to have economic growth; Albanian GDP real growth was 3.7%. Year after year, the tourism sector has gained a growing share in the country's GDP.
Data published as of July 2012 by the National Institute of Statistics, INSTAT, show the economy contracted by 0.2 per cent in the first quarter of the year - a downturn blamed mainly on the eurozone debt crisis.
External trade.
However, reforms are constrained by limited administrative capacity and low income levels, which make the population particularly vulnerable to unemployment, price fluctuation, and other variables that negatively affect income. The economy continues to be bolstered by remittances of some 20% of the labour force that works abroad, mostly in Greece and Italy. These remittances supplement GDP and help offset the large foreign trade deficit. Most agricultural land was privatized in 1992, substantially improving peasant incomes. In 1998, Albania recovered the 8% drop in GDP of 1997 and pushed ahead by 7% in 1999. International aid has helped defray the high costs of receiving and returning refugees from the Kosovo conflict. Large-scale investment from outside is still hampered by poor infrastructure; lack of a fully functional banking system; untested or incompletely developed investment, tax, and contract laws; and an enduring mentality that discourages initiative.
Oil and gas.
Albania has the second largest oil deposits in the Balkans (after Romania) and the largest onshore oil reserves in Europe.
Albania's crude output amounted to more than 1.2 million tonnes in 2013, including 1.06 million by Canada's Bankers Petroleum, 87,063 tonnes from Canada's Stream Oil and 37,406 tonnes by Albpetrol on its own. Three foreign firms produced the rest.
Statistics.
Macroeconomic indicators.
GDP (PPP): $32.259 billion (2015)
GDP per capita (PPP): $11.700 (2015)
<br>"country comparison to the world:" 95
GDP - real growth rate: 3.5% (2011)
<br>"country comparison to the world:" 109
Inflation: 3.5% (2010)
<br>"country comparison to the world:" 114
Unemployment: 13.3% (2010 est)
<br>"country comparison to the world:" 141
Industry.
Industrial production growth rate: 3% (2010 est.)
<br>"country comparison to the world:" 113
Agriculture.
Products: wheat, maize, potatoes, vegetables, fruits, sugar beets, grapes; meat, dairy products
Foreign trade.
Exports: $3.1 billion (2014 est.)
<br>"country comparison to the world:" 121
Imports: $5.8 billion (2014 est.)
<br>"country comparison to the world:" 120
Import partners: Italy 45.6%, Greece 7.8%, Turkey 7.4%, Germany 5.6%, Switzerland 5%, China 4.2% (2014)
Remittances: $600 million (2014 est.)
Current account balance: -$1.704 billion (2014 est.)
<br>"country comparison to the world:" 152
Foreign exchange reserves: $2.479 billion (2008)
<br>"country comparison to the world:" 103
Energy.
Electricity – production: 5.201 billion kWh (2009)
<br>"country comparison to the world:" 113
Electricity – production by source:
Electricity
<br>"country comparison to the world:" 102
Oil
<br>"country comparison to the world:" 94
<br>"country comparison to the world:" 107
Natural gas
<br>"country comparison to the world:" 84
<br>"country comparison to the world:" 108
<br>"country comparison to the world:" 100

</doc>
<doc id="40212" url="http://en.wikipedia.org/wiki?curid=40212" title="Harry Turtledove">
Harry Turtledove

Harry Norman Turtledove (born June 14, 1949) is an American novelist, best known for his works in several genres, including that of alternate history, historical fiction, fantasy, and science fiction.
Early life and education.
Turtledove was born in Los Angeles, California, and grew up in the nearby city of Gardena, California. His paternal grandparents, who were Jewish Romanian immigrants, had first settled in Winnipeg, Canada, before moving to California. He was educated in local public schools in early life.
After dropping out during his freshman year at Caltech, Turtledove attended UCLA, from completing his undergraduate degree to receiving a Ph.D. in Byzantine history in 1977. His dissertation was titled "The Immediate Successors of Justinian: A Study of the Persian Problem and of Continuity and Change in Internal Secular Affairs in the Later Roman Empire During the Reigns of Justin II and Tiberius II Constantine (AD 565–582)".
Career.
In 1979, Turtledove published his first two novels, "Wereblood" and "Werenight", under the pseudonym "Eric G. Iverson." Turtledove later explained that his editor at Belmont Tower did not think people would believe the author's real name was "Turtledove" and came up with something more Nordic. He continued to use the "Iverson" name until 1985. Another early pseudonym was "Mark Gordian."
That year he published "Herbig-Haro" and "And So to Bed" under his real name. Turtledove has recently begun publishing historical novels under the pseudonym "H.N. Turteltaub" ("Turteltaube" means turtle dove in Yiddish). He published three books as Dan Chernenko (the Scepter of Mercy series).
Throughout the late 1970s and early 1980s, Turtledove worked as a technical writer for the Los Angeles County Office of Education. In 1991, he left the LACOE and turned to writing full-time. From 1986 to 1987, he served as the Treasurer for the Science Fiction Writers of America.
He has written several works in collaboration, including "The Two Georges" with Richard Dreyfuss, "Death in Vesunna" with his first wife, Betty Turtledove (pen-name, Elaine O'Byrne); "Household Gods" with Judith Tarr; and others with Susan Shwartz, S.M. Stirling, and Kevin R. Sandes.
Turtledove won the Homer Award for Short Story in 1990 for "Designated Hitter," the John Esten Cooke Award for Southern Fiction in 1993 for "The Guns of the South", and the Hugo Award for Novella in 1994 for "Down in the Bottomlands." "Must and Shall" was nominated for the 1996 Hugo Award and Nebula Award for Best Novelette; it received an honorable mention for the 1995 Sidewise Award for Alternate History. "The Two Georges" also received an honorable mention for the 1995 Sidewise Award for Alternate History.
His "Worldwar" series received a Sidewise Award for Alternate History Honorable Mention in 1996. In 1998, his novel, "How Few Remain," won the Sidewise Award for Alternate History. He won his second Sidewise Award in 2003 for his novel "Ruled Britannia".
On August 1, 1998, Turtledove was named honorary Kentucky Colonel while Guest of Honor at Rivercon XXIII in Louisville, Kentucky. His "The Gladiator" was the co-winner of the 2008 Prometheus Award.
Turtledove served as the toastmaster for Chicon 2000, the 58th World Science Fiction Convention.
He is married to mystery and science fiction writer Laura Frankos. His brother-in-law is fantasy author Steven Frankos. He and Laura have three daughters: Alison, Rachel, and Rebecca.
"Master of Alternate History".
Publisher's Weekly dubbed Turtledove "The Master of Alternate History". Within that genre, he is known for creating original alternate history scenarios, such as survival of the Byzantine Empire or an alien invasion in the middle of the Second World War. In addition, he has been credited with giving original treatment to alternate themes previously dealt with by many others, such as the 'victory of the South' in the American Civil War or of Nazi Germany in the Second World War. His novels have been credited with bringing alternate history into the mainstream. He bases his alternate history in scenes of military combat and warfare.
Bibliography.
Writing as H.N. Turteltaub.
"Hellenic Traders".
Historical fiction about two cousins, traveling merchants in the 4th-century BC Mediterranean.
Writing as Harry Turtledove.
"Videssos".
Set in a world analogous to the Byzantine Empire.
"Worldwar"/"Colonization".
Incorporates elements of both science fiction and alternate history. In "Worldwar," aliens invade in the middle of the World War II in 1942. The Colonization trilogy deals with the course of history a generation after the initial series, as the humans and aliens work to share Earth. "Homeward Bound" follows a human spaceship that travels to the aliens' home world.
"Southern Victory".
The Confederacy wins the American Civil War in 1862 with the help of the United Kingdom and France. It operates as an independent nation into the mid-20th century. (The name above is used by fans; the overall series has no official title.)
"Darkness".
A fantasy series about global war in a world related to medieval Europe, where magic exists. Many plot elements are analogous to elements of World War II, with kingdoms and sorceries that are comparable to the historical nations and technologies.
"War Between the Provinces".
This fantasy series is based heavily on the American Civil War, except magic exists, the roles of the North and South have been reversed, and blond-haired serfs are featured rather than slaves.
"Crosstime Traffic".
Travel between parallel timelines has become possible in the late 21st century. This is a young-adult fiction series; it includes no racial slurs, profanity or sex.
"Days of Infamy".
The Japanese gain the initiative in the Pacific War by invading and occupying Hawaii.
"Atlantis".
A trilogy which describes a world where the American eastern coast from the tip of Florida to Nova Scotia breaks away from the mainland around 85 million years and has an island biota similar to New Zealand's. It was discovered in 1452 by a French fisherman named Francois Kersauzon and named Atlantis. This eighth continent becomes a focal point in a gradually diverging timeline. Two short stories, "Audubon in Atlantis" and "The Scarlet Band", have been set in this milieu.
"Opening Atlantis" was nominated for the 2009 Prometheus Award.
"Opening of the World".
A trilogy describing a fantasy world in which inhabitants of an Iron Age empire explore a land uncovered by a receding glacier.
"The War That Came Early".
An hexalogy describing an alternate World War II which begins in 1938 over Czechoslovakia. The first volume, "Hitler's War", was released in hardcover in 2009 without a series title. 
"Supervolcano".
A trilogy where the Yellowstone supervolcano erupts at some unspecified point in the future, and covers the decade following the Eruption.
"The Hot War".
A series set in an alternate 1950s in which General MacArthur ignites a nuclear war that nearly destroys the planet and will focus as much on the rebuilding efforts and brushfire wars in the aftermath as on the nuclear conflict itself.

</doc>
<doc id="40213" url="http://en.wikipedia.org/wiki?curid=40213" title="Sidewise Award for Alternate History">
Sidewise Award for Alternate History

The Sidewise Awards for Alternate History were established in 1995 to recognize the best alternate history stories and novels of the year.
The awards take their name from the 1934 short story "Sidewise in Time" by Murray Leinster, in which a strange storm causes portions of Earth to swap places with their analogs from other timelines.
The awards were created by Steven H Silver, Evelyn C. Leeper, and Robert B. Schmunk. Over the years, the number of judges has fluctuated between three and eight, including judges in the UK and South Africa.
Each year, two awards are presented, usually at the World Science Fiction Convention. The Short-Form award is presented to a work under 60,000 words in length. The Long-Form award may be presented to a work longer than 60,000 words, including both novels and complete series. At their discretion, the judges may also elect to recognize an individual or work with a Special Achievement Award in recognition of works that were published prior to the award's inception.

</doc>
<doc id="40214" url="http://en.wikipedia.org/wiki?curid=40214" title="Murray Leinster">
Murray Leinster

Murray Leinster (June 16, 1896 – June 8, 1975) was a nom de plume of William Fitzgerald Jenkins, an award-winning American writer of science fiction and alternate history. He wrote and published more than 1,500 short stories and articles, 14 movie scripts, and hundreds of radio scripts and television plays.
Writing career.
Leinster was born in Norfolk, Virginia, the son of George B. Jenkins and Mary L. Jenkins. His father was an accountant. Although both parents were born in Virginia, the family lived in Manhattan in 1910, according to the 1910 Federal Census.
He began his career as a freelance writer before World War I; he was two months short of his 20th birthday when his first story, "The Foreigner", appeared in the May 1916 issue of H. L. Mencken's literary magazine "The Smart Set". Over the next three years, Leinster published ten more stories in the magazine. During and after World War I, he began appearing in pulp magazines like "Argosy", "Snappy Stories", and "Breezy Stories". He continued to appear regularly in "Argosy" into the 1950s. When the pulp magazines began to diversify into particular genres in the 1920s, Leinster followed suit, selling jungle stories to "Danger Trails", westerns to "West" and "Cowboy Stories", detective stories to "Black Mask" and "Mystery Stories", horror stories to "Weird Tales", and even romance stories to "Love Story Magazine" under the pen name Louisa Carter Lee.
Leinster's first science fiction story, "The Runaway Skyscraper", appeared in the February 22, 1919 issue of "Argosy", and was reprinted in the June 1926 issue of Hugo Gernsback's first science fiction magazine, "Amazing Stories". In the 1930s, he published several science fiction stories and serials in "Amazing" and "Astounding Stories" (the first issue of "Astounding" included his story "Tanks"). He continued to appear frequently in other genre pulps such as "Detective Fiction Weekly" and "Smashing Western", as well as "Collier's Weekly" beginning in 1936 and "Esquire" starting in 1939.
Leinster is credited with the invention of parallel universe stories. Four years before Jack Williamson's "The Legion of Time" came out, Leinster published his "Sidewise in Time" in the June 1934 issue of "Astounding". Leinster's vision of extraordinary oscillations in time ('sidewise in time') had a long-term impact on other authors, for example Isaac Asimov's "Living Space", "The Red Queen's Race", and "The End of Eternity".
Leinster's 1945 novella "First Contact" is also credited as one of the first (if not the first) instances of a universal translator in science fiction.
Leinster was one of the few science fiction writers from the 1930s to survive in the John W. Campbell era of higher writing standards, publishing over three dozen stories in "Astounding" and "Analog" under Campbell's editorship. The last story by Leinster in "Analog" was "Quarantine World" in the November 1966 issue, thirty-six years after his appearance in the premier January 1930 issue.
Murray Leinster's 1946 short story "A Logic Named Joe" contains one of the first descriptions of a computer (called a "logic") in fiction. In the story, Leinster was decades ahead of his time in imagining the Internet. He envisioned logics in every home, linked through a distributed system of servers (called "tanks"), to provide communications, entertainment, data access, and commerce; one character says that "logics are civilization."
After World War II, when both his name and the pulps had achieved a wider acceptance, he would use either "William Fitzgerald", "Fitzgerald Jenkins" or "Will F. Jenkins" as names on stories when "Leinster" had already sold a piece to a particular issue.
Leinster continued publishing in the 1950s and 1960s, appearing in "Galaxy Magazine" and "The Magazine of Fantasy and Science Fiction", as well as "The Saturday Evening Post". He won a Hugo Award for his 1956 story "Exploration Team".
Leinster's career also included popular tie-in fiction based on several science fiction TV series: An episodic 1960 novel, "Men into Space", was derived from the series' basic concepts, but Leinster had little knowledge of the series' actual content, and none of the book episodes bear any relationship to the filmed episodes. (This odd phenomenon was not uncommon in the pre-VCR era. In the effort to rush a book onto the shelves to coincide with the airing of a new TV series, the commissioned novelist often had only limited source material to work from, such as a series "writer's bible", some production photos and perhaps a pilot script.) "Men Into Space" was followed, seven years later, by two original novels based on "The Time Tunnel" (1967); and three based on "Land of the Giants" (1968–69). (The novels based on "The Time Tunnel" may have been the first "meta" tie-ins in history, wherein an author wrote novels based on a filmed property based in turn on that author's own work. Leinster's wholly original earlier novel, published in 1964 by Pyramid as "Time Tunnel" [as opposed to "The Time Tunnel"], features a wormhole connecting the years 1904 and 1964. It depicts an alternate history in which Napoleon establishes a permanent rule in Europe. The rights to the novel were bought by 20th Century Fox, and the subsequent series was produced by Irwin Allen. Though the series was only very loosely based on the 1964 book, the same publisher, Pyramid, having secured the tie-in publication rights, returned to Leinster for novels set within the series' storytelling universe. Leinster, however, reinvented the origin story and interpreted the series' concept and characters in his own way, setting a precedent with which Pyramid books would continue, when commissioning tie-in series based on other TV dramas, by other writers — among them the first two "The Invaders" novels by Keith Laumer and "The Mod Squad" by Richard Deming — throughout the 60s.)
Personal life.
During World War I, Leinster served with the Committee of Public Information and the United States Army (1917–1918). In 1921, he married Mary Mandola, who was born in New York to Italian parents. The two had four daughters. During World War II, he served in the Office of War Information.
Legal action against Paramount Pictures.
In 2000, Leinster's heirs sued Paramount Pictures over the film "", claiming that as the owners of the rights to Leinster's 1945 short story "First Contact", it infringed their trademark in the term. The U.S. District Court for the Eastern District of Virginia granted Paramount's motion for summary judgment and dismissed the suit. The court found that regardless of whether Leinster's story first coined the phrase, it had since become a generic and therefore unprotectable term that described the genre of science fiction in which humans first encounter alien species. Even if the title was instead "descriptive"—a category of terms higher than "generic" that may be protectable—there was no evidence that the title had the required association in the public's mind (known as "secondary meaning") such that its use would normally be understood as referring to Leinster's story. The Second Circuit Court of Appeals affirmed the lower court's dismissal without comment.
Other endeavors.
Leinster was also an inventor under his real name of William F. Jenkins, best known for the front projection process used in special effects. 
Bibliography.
Novels.
Far East.
"Sword of Kings", John Long, 1933.
Romance.
as Louisa Carter Lee

</doc>
<doc id="40216" url="http://en.wikipedia.org/wiki?curid=40216" title="John Morton (cardinal)">
John Morton (cardinal)

John Morton (c. 1420 – 15 September 1500) was an English prelate who served as Archbishop of Canterbury from 1486 to 1500. He was elevated to the cardinalate in 1493.
Life.
Born in Dorset, he was educated at Balliol College, Oxford. He was made canon of Sarum in 1458, rector of St. Dunstan's (in the West), archdeacon of Norwich circa 1460, archdeacon of Winchester in 1474, canon of Wells from 1475 to 1478, archdeacon of Berkshire in 1476 and archdeacon of Norfolk in 1477. He was appointed Master of the Rolls from 1472 to 1479.
In February 1477, he was sent by the Yorkist King Edward IV, together with Sir John Donne, as ambassador to the French court. After serving a short spell in 1478 as Archdeacon of Leicester he was appointed Bishop of Ely by King Edward on 8 August 1479 and he was consecrated on 31 January 1479. Morton was an important foe of the Yorkist regime of King Richard III and spent some time in captivity in Brecknock castle. After the dynastic change to the Tudors in 1485, Henry VII made him Archbishop of Canterbury on 6 October 1486, and appointed him Lord Chancellor of England in 1487. In 1493 he was appointed Cardinal priest of the church of St. Anastasia in Rome by Pope Alexander VI. He built the "Old Palace" of Hatfield House where Elizabeth I spent much of her girlhood.
As Lord Chancellor, Morton was tasked with restoring the royal estate, depleted by Edward IV. By the end of Henry VII's reign, the king's frugality, and Morton's tax policy, carried out by Edmund Dudley and Richard Empson, had replenished the treasury. Morton gave a statement, later known as 'Morton's Fork', that no one was to be exempted from taxes: "If the subject is seen to live frugally, tell him because he is clearly a money saver of great ability, he can afford to give generously to the King. If, however, the subject lives a life of great extravagance, tell him he, too, can afford to give largely, the proof of his opulence being evident in his expenditure."
Morton died at Knole House, Kent, on 15 September 1500. His monument was placed in the south-east part of Canterbury Cathedral's crypt, with an effigy and an arch decorated with angels, cardinal's caps, and tun barrels inscribed with MOR (a pun on his name, Mor-ton). However, this monument is a cenotaph since his actual body was buried in the crypt's central chapel of the Virgin Mary, according to his wishes.
Morton, More, and the history of Richard III.
Morton was a mentor of the young Sir Thomas More. More served as a page in Morton's house, acted in revels at Morton's court at Knole House, the archiepiscopal palace, and later mentioned him in his work "Utopia". Although most scholars credit More with authoring the "History of King Richard III", they debate the issue of the original authorship. Morton is believed by many to be the originator of the account that More rewrote. Modern-day enthusiasts of King Richard III thereby accuse Morton of inventing the account whereby Richard murdered Edward V and his brother Richard, Duke of York and committed other crimes attributed to him.
Armorials.
Rev. James Bentham wrote in 1771 concerning the arms of Bishop Morton:
"The Arms given him in "Anglia Sacra", p. 673, are not sufficiently explicit; they should be thus blasoned: "Quarterly gules and ermine on the 1st and 4th a goat's head erased argent". And this agrees with his arms carved various times on the noble Tower of Wisbeche Church, and as they were formerly in a window of Linton Church in Cambridgeshire, as I have it in a manuscript of church notes taken above a century ago. However these accord not with those for our bishop in his own cathedral twice, viz. in the east window of the north aisle of the presbytery, and in another window of the same aisle, where they are still remaining, and are thus blasoned: "Quarterly gules and ermine, on the 1st and 4th three goat's heads erased argent, attired or".

</doc>
<doc id="40217" url="http://en.wikipedia.org/wiki?curid=40217" title="Niccolò de Romanis">
Niccolò de Romanis

Niccolò de Romanis (died 1218) was an Italian cardinal and Papal legate. He was Bishop of Frascati from either 1204 or 1205 and Grand penitentiary. He was closely associated with Pope Honorius III as administrator and diplomat. Dean of the College of Cardinals from 1211.
Legate to England.
In 1207, Pope Innocent III placed the kingdom of England under an Interdict as the result of actions taken by King John (1199–1215) culminating in a debate over the appointment for a successor to the Archbishop of Canterbury. The Interdict would stand until 1213 when John finally accepted Innocent's choice of Stephen Langton as Archbishop of Canterbury. Nicholas acted as Innocent's main negotiator throughout the Interdict, arriving in September 1213 in order to settle its lifting.
He deposed the corrupt Roger Norreys at Evesham Abbey, and finally at Penwortham Abbey. He also intervened at Bardney Abbey to depose the abbot, and put out Ralph de Arundel, abbot of Westminster.
He attempted to mediate between John and his barons, taking up the issue of sheriffs, and trying to fulfil his papal brief to calm factions.
At Oxford.
During the time the Interdict was in effect, a scholar at Oxford was accused in 1209 of raping a woman. When the burghers couldn't find the scholar, they hanged three of his friends in retaliation for his crime. The school at Oxford protested by abandoning the city and scattering to other schools throughout England, possibly setting up a facility in Cambridge.
On October 1, 1213, while Nicholas de Romanis was working to bring about the end of the Interdict, the citizens of Oxford sent him a letter asking him to resolve their problems with the scholars who had taught there. de Romanis agreed to help, visiting the city twice, in November 1213 and May 1214. On June 20, 1214, de Romanis's actions resulted in the issuance of the Charter for the University of Oxford.
Among other items, the citizens agreed to charge fixed rates for student housing and food, an annual payment to the school, the right of the school to judge anyone associated with the school and the creation of a Chancellor for the University.

</doc>
<doc id="40221" url="http://en.wikipedia.org/wiki?curid=40221" title="Richard J. Daley">
Richard J. Daley

Richard Joseph Daley (May 15, 1902 – December 20, 1976) was an American politician who was the Mayor of Chicago for 21 years (1955-1976) and chairman of the Cook County Democratic Central Committee for 23 years, holding both positions until his death in office in 1976. Daley was Chicago's third consecutive mayor from the working-class, heavily Irish American Bridgeport neighborhood on Chicago's South Side, where he lived his entire life. He is remembered for doing much to avoid the declines that some other "rust belt" cities like Cleveland, Buffalo and Detroit experienced during the same period. He had a strong base of support in Chicago's Irish Catholic community, and he was treated by national politicians such as Lyndon B. Johnson as a pre-eminent Irish American, with special connections to the Kennedy family. He played a major role in the history of the Democratic Party, especially with his support of John F. Kennedy in 1960 and of Hubert Humphrey in 1968. Daley is the father of Richard M. Daley, also a former mayor of Chicago, William M. Daley, a former United States Secretary of Commerce, and John P. Daley, a member of the Cook County Board of Commissioners. While many members of Mayor Daley's administration were charged with corruption and convicted, Daley was never formally charged with corruption.
Early life.
Richard J. Daley was born in Bridgeport, a working-class neighborhood of Chicago. He was the only child of Michael and Lillian (Dunne) Daley, whose families had both arrived from the Old Parish area, near Dungarvan, County Waterford, Ireland during the Great Famine. Daley would later state that his wellsprings were his religion, his family, his neighborhood, the Democratic Party, and his love of the city. His father was a sheet metal worker with a reserved demeanor. Michael's father, James E. Daley, was a butcher born in New York, while his mother, Delia Gallagher Daley, was an Irish immigrant. Richard's mother was outgoing and outspoken. Before women obtained the right to vote in 1920, Lillian Daley was an active Suffragette, participating in marches. Mrs. Daley often brought her son to them. She hoped her son's life would be more professionally successful than that of his parents. Prior to his mother's death, Daley had won the Democratic nomination for Cook County sheriff. Lillian Daley wanted more than this for her son, telling a friend, "I didn't raise my son to be a policeman."
Daley attended the elementary school of his parish, Nativity of Our Lord, and De La Salle Institute (where he learned clerical skills) and took night classes at DePaul University College of Law to earn a Juris Doctor in 1933. As a young man, his jobs included selling newspapers and making deliveries for a door to door peddler; Daley worked in Chicago's Union stock yards (the conditions of which were made infamous in Upton Sinclair's novel The Jungle) to pay his law school expenses. He spent his free time at the Hamburg Athletic Club, an athletic, social and political organization near his home. Hamburg and similar clubs were funded, at least in part, by Democratic politicians. Daley made his mark there, not in sports, but in organization as the club manager. At age 22, he was elected president of the club and served in that office until 1939. Although he practiced law with partner William J. Lynch, he dedicated the majority of his time to his political career.
Political career.
Early career.
Daley's career in politics began when he became a Democratic precinct captain; although he was a lifelong Democrat, Daley was first elected to the Illinois House of Representatives as a Republican in 1936. This was a matter of political opportunism and the peculiar setup for legislative elections in Illinois at the time, which allowed Daley to take the place on the ballot of the recently deceased Republican candidate David Shanahan. After his election, Daley quickly moved back to the Democratic side of the aisle in 1938, when he was elected to the Illinois State Senate. In 1939, Illinois State Senator William "Botchy" Connors remarked "You couldn't give that guy a nickel, that's how honest he is."
Daley was appointed by Governor Adlai Stevenson as head of the Illinois Department of Finance. Daley suffered his only political defeat in 1946, when he lost a bid to become Cook County sheriff. Daley then made a successful run for Cook County Clerk and held that position prior to being elected Chicago's mayor. In the late 1940s, Daley became Democratic Ward Committeeman of the 11th Ward, a post he retained until his death. First elected mayor in 1955 with a modest victory margin of 125,179 votes, Daley was re-elected to that office five times and had been mayor for 21 years at the time of his death. Through those 21 years, the Illinois license plate on his car remained "125 179". During his administration, Daley ruled the city with an iron hand and dominated the political arena of the city and, to a lesser extent, that of the entire state.
Daley met Eleanor "Sis" Guilfoyle at a local ball game. He courted "Sis" for six years, during which time he finished law school and was established in his legal profession. They were married on June 17, 1936, and lived in a modest brick bungalow at 3536 South Lowe Avenue in the heavily Irish-American neighborhood of Bridgeport, just blocks from his birthplace. They had three daughters and four sons, in that order. Their eldest son, Richard M. Daley, was elected mayor of Chicago in 1989, and served in that position until his retirement in 2011. The youngest son, William M. Daley, served as White House Chief of Staff under President Barack Obama and as US Secretary of Commerce under President Bill Clinton. Another son, John P. Daley, is a member of the Cook County Board of Commissioners. The other progeny have stayed out of public life. Michael Daley is a partner in the law firm Daley & George, and Patricia (Daley) Martino and Mary Carol (Daley) Vanecko are teachers, as was Eleanor, who died in 1998.
Major construction during his terms in office resulted in O'Hare International Airport, the Sears Tower, McCormick Place, the University of Illinois at Chicago campus, numerous expressways and subway construction projects, and other major Chicago landmarks. O'Hare was a particular point of pride for Daley, with he and his staff regularly devising occasions to celebrate it. Daley contributed to John F. Kennedy's narrow, 8,000 vote victory in Illinois in 1960. A PBS documentary entitled "Daley" explained that Mayor Daley and JFK potentially stole the 1960 election by stuffing ballot boxes and rigging the vote in Chicago. Although often quoted as fact, this repeated claim is impossible. Kennedy won with 303 electoral college votes and needed only 269, meaning Nixon would have lost even had he won Illinois' 27 votes. Had Nixon won Illinois' 27 electoral votes, he would have had 246 electoral votes while Kennedy would have had 276. 
In 1966, SCLC's James Bevel and Martin Luther King, Jr. took the Civil Rights Movement north and encouraged racial integration of Chicago's neighborhoods, such as Marquette Park. Daley called for a "summit conference" and signed an agreement with King and other community leaders to foster open housing. The public agreement itself was without legal standing and ignored. SCLC's efforts in Chicago contributed to the passage of the Fair Housing Act two years later.
1968 and later career.
The year 1968 was a momentous year for Daley. In April, Daley was castigated by many for his sharp rhetoric in the aftermath of rioting that took place after Martin Luther King, Jr.'s assassination. Displeased with what he saw as an over-cautious police response to the rioting, Daley chastised police superintendent James B. Conlisk and subsequently related that conversation at a City Hall press conference as follows:
This statement generated significant controversy. Daley's supporters deluged his office with grateful letters and telegrams (nearly 4,500 according to "Time" magazine), and it has been credited for Chicago's being one of the cities least affected by the riots. But others were appalled. Rev. Jesse Jackson, for example, called it "a fascist's response." The Mayor later backed away from his words in an address to the City Council, saying:
In August, the 1968 Democratic National Convention was held in Chicago. Intended to showcase Daley's achievements to national Democrats and the news media, the proceedings during the convention instead garnered notoriety for the mayor and city, descending into verbal outbursts on the part of politicians, and a circus for the media. With the nation divided by the Vietnam War and with the assassinations of King and Robert F. Kennedy earlier that year serving as backdrop, the city became a battleground for anti-Vietnam war protesters who vowed to shut down the convention. In some cases, confrontations between protesters and police turned violent, with images of this violence broadcast on national television. Later, anti-war activists Abbie Hoffman, Jerry Rubin, and three other members of the "Chicago Seven" were convicted of crossing state lines with the intent of inciting a riot as a result of these confrontations, though the convictions were overturned on appeal.
At the convention itself, Sen. Abraham A. Ribicoff (D-Conn.), went off-script during his speech nominating George McGovern, saying, "And with George McGovern as President of the United States, we wouldn’t have to have Gestapo tactics in the streets of Chicago. And with George McGovern as president, we wouldn't have to have a National guard." Ribicoff, with his voice shaking, then said: "How hard it is to speak the truth, when we know the problems that are facing this nation", for which some in the crowd booed Ribicoff. Ribicoff also tried to introduce a motion to shut down the convention and move it to another city. Many conventioneers applauded Ribicoff's remarks but an indignant Mayor Daley tried to shout down the speaker. As television cameras focused on Daley, lip-readers throughout America claimed to have observed him shouting, "Fuck you, you Jew son of a bitch." Defenders of the mayor would later claim that he was calling Ribicoff a faker, a charge denied by Daley and refuted by Mike Royko's reporting. A federal commission, led by local attorney, party activist Dan Walker, investigated the events surrounding the convention and described them as a "police riot." Daley defended his police force with the following statement, which was also a slip of the tongue: "The confrontation was not caused by the police. The confrontation was caused by those who charged the police. Gentlemen, let's get this thing straight, once and for all. The policeman is not here to create disorder. The policeman is here to preserve disorder."
Public opinion polls conducted after the convention demonstrated that the majority of Americans supported the Mayor's tactics. Daley was historically re-elected for the fifth time in 1971. However, many have argued this was due to a lack of formidable opposition rather than Daley's own popularity. In 1972, Democratic nominee George McGovern threw Daley out of the Democratic National Convention, replacing his delegation with one led by Jesse Jackson. This event arguably marked a downturn in Daley's power and influence within the Democratic Party but, given his public standing, McGovern later made amends by putting Daley loyalist (and Kennedy in-law) Sargent Shriver on his ticket. In January 1973, former Illinois Racing Board Chairman William S. Miller testified that Daley had "induced" him to bribe Illinois Governor Otto Kerner.
Death and funeral.
On December 20, 1976, Daley suffered a massive heart attack while visiting his doctor's office and died at the age of 74. His services and funeral Mass took place in the church he attended from his childhood, Nativity of Our Lord. He is buried in Holy Sepulchre Cemetery in Worth Township, southwest of Chicago. Daley was known by many Chicagoans as "Da Mare" ("The Mayor"), "Hizzoner" ("His Honor"), and "The Man on Five" (his office was on the fifth floor of City Hall). Since Daley's death and the subsequent election of son Richard as mayor in 1989, the first Mayor Daley has become known as "Boss Daley," "Old Man Daley," "Papa Bear," or "Daley Senior" to residents of Chicago.
Speaking style.
Daley, who never lost his blue-collar Chicago accent, was known for often mangling his syntax and other verbal gaffes. Daley made one of his most memorable verbal missteps in 1968, while defending what the news media reported as police misconduct during that year's violent Democratic Convention, stating, "Gentlemen, get the thing straight once and for all– the policeman isn't there to create disorder, the policeman is there to "preserve" disorder." One veteran City Hall reporter supposedly said to a new member of the press corps, "Report what he means, not what he says."
Legacy.
A poll of 160 historians, political scientists and urban experts ranked Daley as the sixth best mayor in American history. Daley's ways may not have been democratic, but his defenders have argued that he got positive things done for Chicago which a non-boss would have been unable to do. While detractors point out that he did nothing to integrate what had then become known as the most segregated city in the nation, others argue that he was acting on behalf of his constituency, who did not want an integrated Chicago. On the 50th anniversary of Daley's first 1955 swearing-in, several dozen Daley biographers and associates met at the Chicago Historical Society. Historian Michael Beschloss called Daley "the pre-eminent mayor of the 20th century." Chicago journalist Elizabeth Taylor said, "Because of Mayor Daley, Chicago did not become a Detroit or a Cleveland." Many feel that by revitalizing the downtown area and firmly fixing the middle-class in place in the city limits, Daley probably did save Chicago from declining to the extent of the average Rust Belt city. Robert Remini pointed out that while other cities were in fiscal crisis in the 1960s and 1970s, "Chicago always had a double-A bond rating." According to Chicago folksinger Steve Goodman, "no man could inspire more love, more hate."
Daley's twenty-one-year tenure as mayor is memorialized in the following:

</doc>
<doc id="40222" url="http://en.wikipedia.org/wiki?curid=40222" title="Richard M. Daley">
Richard M. Daley

Richard Michael Daley (born April 24, 1942) is an American politician and former Mayor of Chicago, Illinois. Daley was elected mayor in 1989 and was re-elected five times until declining to run for a seventh term. At 22 years, he was the longest serving Chicago mayor, surpassing the tenure of his father, Richard J. Daley. Mayor Daley took over the Chicago Public Schools, developed tourism, oversaw the construction of Millennium Park, increased environmental efforts and the rapid development of the city's central business district downtown and adjacent near North, near South and near West sides. Daley expanded employee benefits to same-sex partners of City workers, and advocated for gun control. Daley was a national leader in privatization and the lease and sale of public assets to private corporations. Daley was criticized when family, personal friends, and political allies seemed to disproportionately benefit from city contracting. Mayor Daley took office in a City with regular annual budget surpluses and left the City with massive structural deficits. His budgets ran up the largest deficits in Chicago history. Prior to serving as mayor, Daley served in the Illinois Senate and then as the Cook County State's Attorney. Police use of force was an issue in Daley's tenures as State's Attorney and Mayor.
Early and personal life.
Richard M. Daley is the fourth of seven children and eldest son of Richard J. and Eleanor Daley, the late Mayor and First Lady of Chicago. Daley was raised in Bridgeport, a historically Irish-American neighborhood located on Chicago's South Side.
Daley is a brother of William M. Daley, former White House Chief of Staff and former United States Secretary of Commerce under President Bill Clinton; John P. Daley, a commissioner on the Cook County Board of Commissioners and chairman of the Board's Finance Committee; and Michael Daley, an attorney with Daley & Georges, a law firm founded by their father Richard J. Daley, that specializes in zoning law and is often hired by developers to help get zoning changes through City Hall. Daley was married to Margaret "Maggie" Corbett until her death on Thanksgiving Day, November 24, 2011 after a decade-long battle with metastatic breast cancer, which had spread to her bones and liver; Maggie Daley Park in the Chicago Loop commemorates her. They have four children: Nora, Patrick, Elizabeth and Kevin, all born at Mercy Hospital and Medical Center in Chicago. Their second son, Kevin, died at age two of complications from spina bifida in 1981.
Daley graduated from De La Salle Institute high school in Chicago and obtained his bachelor's degree from Providence College in Providence, Rhode Island in 1964. In 1962, at age 19, home on Christmas break, Daley was ticketed for running a stop sign at Huron and Rush, and the "Chicago Sun-Times" headline was "Mayor's Son Gets Ticket, Uses No Clout," with a subhead reading "Quiet Boy."
Sources conflict on Daley's military record. The only book-length biography of Daley makes no mention of military service. A 1995 profile in the "Chicago Sun-Times" stated that Daley served in the United States Marine Corps Reserve from 1961 to 1967, while a 1996 profile in "People Magazine" cited 1960 to 1964. A civilian website for Marines and their families found no military record for Daley.
Daley earned a Juris Doctor degree from DePaul University. He passed the Illinois Bar Examination on his third try. Daley later reflected, "I flunked the bar exam twice. I had to keep studying harder and harder and harder. I passed it the third time." Daley never tried a case. Daley was elected to his first party office as a delegate to the 1969 Illinois Constitutional Convention. After his father died in 1976, Daley succeeded his father as the 11th Ward Democratic committeeman, a party post, until succeeded in the post by his brother John P. Daley in 1980. With John P. Daley holding the post from 1980 to the present, a Daley has held the post of 11th Ward Committeeman for 60 years.
Illinois State Senate (1972–1980).
With the support of the Democratic political organization, Daley was elected to the Illinois Senate, serving from 1972 to 1980. State Senator Daley rarely spoke to reporters and didn't hold a news conference for six years. Daley chaired the Senate judiciary committee. Daley was named one of Illinois' ten worst state legislators by "Chicago Magazine" "for arrogance, for sharklike qualities, for living off his father's name, and for pulling puppet strings attached to some of the worst members of the Senate." He was considered "too shrewd to be one of the worst, but he controls so many of the worst senators that he belongs on the list to represent all of them." After the Spring 1975 state legislative session, Chicago Democrat Dawn Clark Netsch, who served with Daley as Illinois Constitutional Convention delegates and as State Senators, blamed "dirty little Richie" for frustrating her good government legislative agenda in the state legislature.
Cook County State's Attorney (1981–1989).
Daley challenged incumbent Republican Bernard Carey for Cook County State's Attorney. Democratic Mayor Jane Byrne endorsed Alderman Edward M. Burke in the Democratic primary, and after Daley prevailed in the primary, endorsed Carey in the general election. Daley prevailed and served from 1981 to 1989.
Police torture reported to Daley, 1982.
In February 1982, Andrew Wilson was arrested for the murder of two Chicago police officers. Wilson was taken to Area 2 detective headquarters on the South Side for interrogation under Chicago Police Detective Jon Burge. Dr. John Raba, Medical Director of Cermak Health Services, the prison hospital in the Cook County Hospital system, examined Wilson, determined Wilson had been tortured, and complained in writing to then Chicago Police Superintendent Richard Brzeczek:
I examined Mr. Andrew Wilson on Feb. 15 & 16, 1982. He had multiple bruises, swellings and abrasions on his face and head. His right eye was battered and had a superficial laceration. Andrew Wilson had several linear blisters on his right thigh, right cheek and anterior chest which were consistent with radiator burns. He stated he'd been cuffed to a radiator and pushed into it. He also stated that electrical shocks had been administered to his gums, lips and genitals. All these injuries occurred prior to his arrival at the Jail. There must be a thorough investigation of this alleged brutality.
Brzeczek forwarded the letter to State's Attorney Daley. Daley never replied, and charges were never brought against any officers. Daley's prosecutors convicted Wilson and his brother Jackie of murder, and Andrew Wilson was sentenced to death. On April 2, 1987 the Illinois Supreme Court overturned the convictions, ruling that Wilson was forced to confess involuntarily after being beaten by police.
First campaign for Mayor, 1983: challenge to Jane Byrne.
In November, 1982, Daley announced his first campaign for mayor. The candidates in the three-way Democratic primary, which included incumbent Mayor Jane Byrne, a former protegée of his father, and Congressman Harold Washington, held a series of four televised debates. Daley finished third. Many of Richard J.'s political allies blamed Richard M. for splitting the white vote, enabling Washington to become Chicago's first black mayor.
Second campaign for Mayor, 1989: challenge to Eugene Sawyer.
On November 25, 1987, Mayor Washington died in office of a heart attack. On December 2, 1987, the Chicago City Council appointed Alderman Eugene Sawyer as mayor until a special election for the remaining two years of the term could be held in 1989. Daley announced his candidacy on December 6, 1988, saying
Let's face it: we have a problem in Chicago. The name-calling and politics at City Hall are keeping us from tackling the real issues ... I may not be the best speaker in town, but I know how to run a government and how to bring people together.
Rahm Emanuel worked for the Daley campaign as a fundraiser, David Axelrod as campaign strategist, William Daley as chief strategist, and Forrest Claypool as a campaign aide. Among four Daley campaign appearances on a Sunday shortly before the primary was a rally of Polish Highlanders at 4808 S. Archer Ave. In a videotaped television newscast, it appeared that Daley said, "You want a white mayor to sit down with everybody." Sawyer said he was "shocked." Daley explained, "It was my standard stump speech. I'm not maybe the best speaker in town, but I have never used the word [white]." That Friday, the campaign watchdog group CONDUCT censured Daley and commended Sawyer for his "rejection of racially inflammatory comments."
Daley defeated Sawyer in the primary. In the 1989 general election, Daley faced Republican candidate Edward Vrdolyak, a former Democratic alderman who had opposed Mayor Washington, and Alderman Timothy C. Evans, the candidate of the newly created Harold Washington Party. After winning the general election on April 4, 1989, Daley was inaugurated as Mayor of Chicago on April 24, 1989, his 47th birthday, at a ceremony in Orchestra Hall.
Mayor of Chicago (1989–2011).
First term (1989–1991).
Daley presided over the most docile City Council since his father. One of the new mayor's first acts was to arrogate the City Council's power to approve city contracts, a right aldermen exercised under former Mayors Washington and Sawyer. Daley's first budget proposal, the 1990 budget, included $3 billion in spending, $50 million more than 1989, featured a $25 million reduction in the property tax levy, extended Mayor Sawyer's hiring freeze, piloted recycling, and privatized the City's tow truck fleet. Daley became the first Chicago Mayor to lead Chicago's Gay and Lesbian Pride Parade, at the 20th annual parade on Sunday, June 26, 1989. On August 22, 1990, Daley told reporters that "people are getting hurt in drive-by shoot-a-longs." In December 1990 Amnesty International issued a report "Allegations of Police Torture in Chicago, Illinois" calling for a full inquiry into allegations that some Chicago police officers tortured criminal suspects between 1972 and 1984.
Second term (1991–1995).
On April 2, 1991 Daley was re-elected to a second term (his first full, four-year term), with 70.7% of the vote, over African American civil rights attorney and Appellate Judge R. Eugene Pincham. Questioned about the city's rising homicide rate on September 10, 1991, Daley said "The more killing and homicides you have, the more havoc it prevents."
Brawl at Daley home in Michigan.
On the weekend of March 1–2, 1992, Daley and his wife arranged for 16-year-old son Patrick to stay with relatives while they attended a family event in New York. Patrick told the relatives he was staying with friends, drove his father's new sports utility vehicle to the Daley second home in Grand Beach, Michigan and threw a party Saturday night without parental consent or adult supervision. Someone asked two Filipino and two white youths to leave, racial epithets were exchanged, and a fistfight broke out. Patrick fetched Richard J. Daley's shotgun from the house and gave it to his cousin, who was aged 17. A youth was seriously injured when a juvenile struck him in the head with a baseball bat. On Monday a sobbing Mayor Daley read a statement at a City Hall press conference, pausing repeatedly as he tried to maintain his composure,
I am very disappointed, as any parent would be, after his son held a party in their home while his parents were away. I am more deeply distressed for the welfare of the young man who was injured in this fight.
Patrick pleaded guilty to misdemeanor charges of furnishing alcohol to minors and disturbing the peace and was sentenced to six months' probation, 50 hours of community service in Grand Beach, fined $1,950 and ordered to pay restitution to his parents for property damage. His cousin pleaded guilty to aiming a firearm without malice and was fined $1,235. Sixteen other youths were charged with juvenile and adult offenses. The injured youth recovered.
Third term (1995–1999).
Daley took control of the Chicago Public School system in 1995 and appointed Paul Vallas. When Vallas left the post to run for governor, Daley chose the relatively obscure Arne Duncan, now the U.S. Secretary of Education, to lead the district. On March 19, 1997, the Chicago City Council adopted the Domestic Partners Ordinance, which made employee benefits available to same-sex partners of City employees. Daley said it was an issue of fairness.
Daley's floor leader in City Council resigns.
The first major public corruption scandal of Daley's tenure as mayor involved the circumstances of the resignation of his City Council floor leader, Alderman Patrick Huels, in October 1997. Daley, Huels, and another close friend Michael Tadin grew up within two blocks on S. Emerald Avenue in Bridgeport. Huels attended De La Salle Institute, the same high school attended by Daley, his father, and Michael Bilandic. Huels worked for the city's Public Works Department as a laborer and tree trimmer, then as an administrative assistant in the Environment Department, and then as a City Council investigator. He answered phones for the 11th Ward Democratic organization, and was its secretary for several years. When Mayor Richard J. Daley died, 11th Ward Alderman Bilandic was named acting mayor, and Huels, then 26, replaced Bilandic as alderman. Huels chaired the Council's Transportation Committee and became Mayor Richard J. Daley's floor leader. In the summer of 2007, in reaction to ongoing indictments and convictions of aldermen, Daley and Huels shepherded a package of ethics reforms through City Council. Huels owned a security firm, SDI Security, Inc. along with his wife and his brother, a Chicago police lieutenant. In the mid-1990s, the firm had about 390 full-time employees and was grossing $7 million a year. Huels was president and a director, and Council Finance Committee Chairman Alderman Edward M. Burke (14th) was secretary. Huels and Burke authorized $633,971 in legal consulting fees from their respective Council committees to attorney Michael A. Pedicone, a long-time officer of SDI. In March 1995 the Internal Revenue Service placed a lien on SDI for $326,951 and in June 1996 for $997,382 for failing to pay payroll taxes, including money withheld from its employees' pay checks.
In 1970, after high school, Tadin went to work for Marina Cartage; within a decade, he owned the company, and over the next 15 years expanded it from 20 trucks to 150. Between 1992 and 1997, the city paid Marina Cartage and another Tadin company $49 million for supplying the city with snow removal and other heavy equipment and operators. Tadin earned millions of dollars by buying land cheaply, then leasing or selling it to the city. Marina Cartage used Huels' SDI Security services since 1992. In 1995, with Huels' support, the City Council approved a tax reduction which halved the assessment on a new $4.5 million headquarters and trucking terminal for Marina Cartage at 4450 S. Morgan in Huels' ward, a tax savings of as much as $80,000 per year. In 1996, with Huels' support, the City Council approved a $1.1 million direct grant for the construction of the facility. Weeks later, Tadin created a new company which was used to originate a $1.25 million bailout loan to SDI. Daley said Huels "did the right thing resigning" and claimed no knowledge of Huels' business dealings. "I don't get into people's private lives. I am not into that," Daley said. Daley announced an executive order and new ethics legislation, saying:
The goal of this executive order is to help address questions about favoritism in city contracting by preventing conflicts of interest, or even the appearance of such conflicts. ... There should be a level playing field, where no one has an advantage - or a disadvantage - in obtaining city contracts, simply because they know me or anyone else in government. ... Under the steps I'm taking today and recommending to the City Council, the public can easily learn everything there is to know about a city contract: who is involved, who will benefit and whether the city is paying a fair price. I and every other city official must be prepared to defend every contract on its merits.
Fourth term (1999–2003).
On February 23, 1999, Daley won re-election to a fourth term with 68.9 percent of the vote over challenger U.S. Congressman Bobby Rush. In August 1999, prompted by police excessive-force incidents in Chicago, New York and other cities, the U.S. affiliate of Amnesty International issued a report "Race, Rights & Brutality: Portraits of Abuse in the USA," that called on federal officials to better document excessive-force cases and to pursue prosecutions of the officers involved. In October 1999 the organization issued a report "Summary of Amnesty International's concerns on police abuse in Chicago" which expressed concerns including improper interrogation tactics, excessive force, shootings of unarmed suspects, and the detention and interrogation of children.
The Duff family formed a janitorial services company, Windy City Maintenance Inc., one month after Daley's inauguration. Bruce DuMont, president of the Museum of Broadcast Communications, said that Daley recommended that Dumont's wife Kathy Osterman, then director of the Mayor's Office of Special Events, award city contracts to Duff family companies. Daley denied steering contracts to the Duffs, and said he would "look into" the allegations, while stopping short of promising to do so, saying "I don't promise. That's the wrong word to use. You know ... promising, promising. We do look into it, yes." In September 2003 a federal investigation led to indictments of Patricia Green Duff, her sons John M. Duff and James Duff, and others on charges they won nearly $100 million in city contracts through the city's set-aside program by misrepresenting their companies as women- and minority-owned. John M. Duff pleaded guilty to 33 counts of racketeering, fraud and other charges on January 10, 2004. A 1978 state law designed by Illinois Democrats gave the Mayor the power to appoint to fill vacancies in the City Council rather than holding special elections, and by 2002 more than a third of the Council's 50 aldermen were initially appointed by Daley. The Council became even more of a rubber stamp than in Richard J. Daley's terms. In the 18 months from January 12, 2000 to June 6, 2001, only 13 votes in the Council were divided, less than one a month. 32 aldermen supported the mayor 90-100% of the time and another 14 80-89% of the time.
Fifth term (2003–2007).
On February 26, 2003, Daley took 78.5% of the vote to prevail over challenger Reverend Paul Jakes Jr. Daley endorsed same-sex marriage, saying on February 18, 2004 he would have "no problem" with Cook County issuing marriage licenses to gay couples. "Time" magazine in its April 25, 2005 issue named Daley as the best out of five mayors of large cities in the United States, and characterized Daley as having "imperial" style and power. In May 2006 in Geneva, Switzerland the United Nations Committee Against Torture released a report which noted the "limited investigation and lack of prosecution" into allegations of torture in Areas 2 and 3 of the Chicago Police Department and called on American authorities to "promptly, thoroughly and impartially" investigate the allegations, and provide the committee with more information.
Daley orders demolition of Meigs Field.
A long-standing agreement between the city and state required the city to maintain and operate Meigs Field, a small, downtown, lakefront airport on Northerly Island used by general aviation aircraft and helicopters, until 2011 or turn it over to the state. On September 12, 1996, the City Council approved Daley's plan to convert the airport into a park, and the state began planning to take over operation of the airport. Fresh off a 2003 re-election mandate, one of Daley's first major acts was ordering the demolition of Meigs Field. On Sunday night, March 30, 2003, shortly before midnight, transport trucks carrying construction equipment moved onto Meigs with Chicago Police escort. By early Monday morning, city crews excavated six large X's into the only runway. The city's 50 aldermen, Illinois Governor Rod Blagojevich, the Federal Aviation Administration and the Department of Homeland Security were not consulted on the plan. The demolition of the runway trapped planes. In the days following, many of those aircraft were able to take off using the taxiway.
"To do this any other way would have been needlessly contentious," Daley explained at a news conference Monday morning. Daley argued that the airport was a threat to Chicago's high-rise cityscape and its high profile skyscrapers, such as the Sears Tower and the John Hancock Center. Daley criticized the Federal Aviation Administration, saying "Now, think of that; Mickey and Minnie have it. I mean, I can't believe that. They get it first before we get it?", referring to the post-9/11 air space restrictions in place over Orlando, Florida. "The signature act of Richard Daley's 22 years in office was the midnight bulldozing of Meigs Field," according to "Chicago Tribune" columnist Eric Zorn. "He ruined Meigs because he wanted to, because he could," "Chicago Tribune" columnist John Kass wrote of Daley. "The issue is Daley's increasingly authoritarian style that brooks no disagreements, legal challenges, negotiations, compromise or any of that messy give-and-take normally associated with democratic government," the "Chicago Tribune" editorialized. The Federal Aviation Administration cited the City for failure to comply with federal law requiring thirty-day advance notice to the FAA of plans for an airport closure. The city was fined $33,000, the maximum allowable. The city paid the fine and repaid $1 million in misspent federal airport development grants. Daley defended his actions by claiming that the airport was abandoned, in spite of the fact that the Chicago Fire Department had several helicopters based on the field at the time, in addition to the dozens of private aircraft left stranded.
Hired Truck Program scandal.
The $40 million-a-year Hired Truck program was the biggest scandal of Daley's first 15 years as Mayor. The Hired Truck Program hired private truck companies to do city work. A six-month investigation by the "Chicago Sun-Times" resulted in a three-day series of articles in January 2004 that revealed some participating companies were being paid for doing little or no work, had American Mafia connections or were tied to city employees, or paid bribes to get into the program. Between 1996 and 2004, companies in the Hired Truck Program gave more than $800,000 in campaign contributions to various politicians, including Daley, House Speaker Michael Madigan, and Governor Rod Blagojevich; Daley received at least $108,575 and his brother John Daley and his ward organization more than $47,500.
Mark Gyrion, Daley's second cousin, was a superintendent of garages for the City's Water Management Department, and among his duties was deciding when City-owned trucks should be sold for scrap. Gyrion's mother-in-law's firm, Jacz Transportation, participated in the Hired Truck Program, receiving about $1 million between 1998 and 2004. Jacz Transportation bought a truck three days after the city sold it to a Franklin Park dealership and then leased it back to the city. Gyrion was accused of failing to disclose his mother-in-law's role in the Hired Truck Program and the transfer of the truck. Gyrion was fired and Jacz Transportation was one of 13 truck companies suspended from the Hired Truck program. About 35% of the 70 firms in the program were suspended or referred to the city's Inspector General. The program was overhauled in 2004, and phased out in 2005.
Daley patronage chief among officials convicted of fraud.
On July 5, 2006, Robert Sorich, formally, director of the Mayor's Office of Intergovernmental Affairs and, informally, Daley's patronage chief, and Timothy McCarthy, Sorich's aide, were each convicted on two counts of mail fraud connected to rigging blue-collar city jobs and promotions. Sorich's best friend, former Streets and Sanitation official Patrick Slattery was convicted of one count of mail fraud. A former Streets and Sanitation managing deputy commissioner was found guilty of lying to federal agents about political hiring. Sorich, McCarthy and Slattery lived in the Bridgeport neighborhood in 11th Ward, the Daley family's home neighborhood and ward. "I've never known them to be anything but hard working, and I feel for them at this difficult time," Daley said. "It is fair criticism to say I should have exercised greater oversight to ensure that every worker the city hired, regardless of who recommended them, was qualified and that proper procedures were always followed," Daley admitted a few days later. Weeks later, David Axelrod, a Democratic political consultant whose clients included Daley, defended patronage in an op-ed in the "Chicago Tribune".
Daley son concealed city contracting.
Mayor Daley's son Patrick R. Daley was an MBA student at the University of Chicago Graduate School of Business working as an unpaid intern at Cardinal Growth, a Chicago venture capital firm, when he profited from two Cardinal Growth ventures formed to win city contracts while concealing his role. Patrick's cousin, and Mayor Daley's nephew, is Robert G. Vanecko. In June 2003, Patrick and Vanecko formed a Delaware company, MSS Investors LLC, and invested $65,000 each. MSS Investors LLC in turn purchased a 5% stake in Municipal Sewer Services, a Cardinal Growth venture. Patrick and Vanecko failed to disclosed their ownership stake in Municipal Sewer Services as required by city ethics ordinances. Brunt Brothers Transfer Inc. was one of the largest black-owned contractors in the Hired Truck program. Municipal Sewer Services partnered with Brunt Brothers Transfer Inc. in their bid for City sewer-inspection contracts. Five months after Patrick and Vanecko became owners, Municipal Sewer Services' city contract was extended by $3 million, the first of two no-bid contract extensions, totalled an additional 23 months and $4 million. Patrick and Vanecko cashed out their initial investment after about a year as the federal investigation into the Hired Truck program advanced. Patrick and Vanecko got a $13,114 "tax distribution" in December 2004. Patrick, then 29 and a recent University of Chicago MBA graduate, enlisted in the US Army. The day after the Mayor's son's and nephew's hidden involvement in the city contract was disclosed by the "Chicago Sun-Times", Daley spoke at a Chicago police recruit graduation ceremony, then left for Fort Bragg, North Carolina to see his son deployed. Before departing, Mayor Daley read a statement to reporters, his voice cracking, fighting back tears,
I did not know about [Patrick's] involvement in this company. As an adult, he made that decision. It was a lapse in judgement for him to get involved with this company. I wish he hadn't done it. I know the expectations for elected officials, their families, are very high - rightfully so - especially for me. ... Patrick is a very good son. I love him. Maggie and I are very proud of him. I hope you respect I have nothing more to say on this.
Mayor Daley also said he didn't know if there were other city contracts involving the younger Daley. The city's Inspector General and federal authorities began investigations in December 2007. Patrick and Vanecko hired criminal defense attorneys. Municipal Sewer Services LLC folded in April 2008. In January 2011, Anthony Duffy, the president of Municipal Sewer Services, was charged with three counts of mail fraud in conjunction with minority-contracting and Jesse Brunt and his company, Brunt Brothers Transfer Inc., were indicted on three counts of mail fraud. Patrick and Vanecko were not charged.
In 2005, Concourse Communications, another Cardinal Growth venture, signed a city contract for airport wi-fi service at city-owned O'Hare and Midway airports. For years, the Daley administration maintained that Patrick had no financial stake in the deal. Concourse disclosed its investors to the city, as required, but Patrick was not reported. Patrick lined up investors for Concourse. On June 27, 2006, nine months after Concourse signed the contract, Concourse was sold at a 33% profit to Boingo Wireless Inc. for $45 million. On June 30, 2006, Patrick received the first of five payments totalling $708,999. On December 3, 2007, shortly after Patrick received the last of those payments, Mayor Daley's press secretary, Jacquelyn Heard said Patrick Daley "has no financial interest with the wi-fi contract at O'Hare." The "Chicago Sun-Times" editorialized, "... the conflict of interest was blatant."
Park Grill contracting scandal.
 In 2003 an operating company included over 80 investors, including some of Mayor Daley's friends and neighbors won, under controversial circumstances, a lucrative contract to operate the Park Grill, the only restaurant in the new Millennium Park. In 2005 Daley criticized the deal, saying that the city wanted to renegotiate the pact. The "Chicago Sun-Times" dubbed the Park Grill the "Clout Cafe" and included the contract award process in a year-end review of 2005 Daley administration scandals. The contract was never renegotiated, and after Daley announced he would not seek a seventh term, the owners of the Park Grill sought to sell. Deposed in August, 2013 in Mayor Rahm Emanuel's administration's lawsuit to renegotiate the contract, former Mayor Daley responded "I don't recall" 139 times.
Long-term leases of public infrastructure.
In January 2006, Skyway Concession Company, a joint venture between the Australian Macquarie Infrastructure Group and Spanish Cintra Concesiones de Infraestructuras de Transporte S.A., paid the City $1.83 billion for rights to operate the Chicago Skyway and collect tolls for 99 years. The deal was the first of its kind in the U.S. In December 2006, Morgan Stanley paid Chicago $563 million for a 99-year lease of the city's parking garages. "I'm the one who started talking about leasing public assets. No other city has done this in America," Daley recalled in 2009. Pulitzer Prize-winning commentator George F. Will wrote of the deals in the "Washington Post",
Unfortunately, Daley's theory -- that it can be better to get a sum X immediately, rather than getting over many years a sum Y that is substantially larger than X -- assumes something that cannot be assumed. It assumes that governments will prudently husband sudden surges of revenue from the lease or sale of assets.
Sixth term (2007–2011).
On February 6, 2008, the Chicago City Council approved, by a 41–6 vote, an increase in the city's real estate transfer tax to fund the Chicago Transit Authority. Presiding over the meeting, Daley harshly chastized the dissenting aldermen. On March 15, 2010, Daley appointed two aldermen on the same day, bringing to 19 the number of alderman initially appointed by Daley.
More long-term leases of public infrastructure.
In September 2008, Chicago accepted a $2.52 billion bid on a 99-year lease of Midway International Airport to a group of private investors, but the deal fell through due to the collapse of credit markets during the 2008–2012 global recession. In 2008, as Chicago struggled to close a growing budget deficit, the city agreed to a 75-year, $1.16 billion deal to lease its parking meter system to an operating company created by Morgan Stanley. Daley said the "agreement is very good news for the taxpayers of Chicago because it will provide more than $1 billion in net proceeds that can be used during this very difficult economy." The agreement quadrupled rates, in the first year alone, while the hours which people have to pay for parking were broadened from 9 am–6 pm to 8 am–9 pm, and from Monday through Saturday to every day of the week. Additionally, the city agreed to compensate the new owners for loss of revenue any time any road with parking meters is closed by the city for anything from maintenance work to street festivals. In three years, the proceeds from the lease were all but spent.
Failed Olympic bid.
In 2007 Daley entered into ten-year contracts with the city's labor unions to preclude labor unrest as Chicago launched a bid to host the 2016 Summer Olympic Games. For months in 2009, Daley promoted the economic benefits of the proposal to the city and its corporate community. Many thought the games would be a capstone of Daley's career. On October 2, 2009, in a major disappointment for Daley, Chicago was the first of four finalists to be eliminated during selection ceremonies in Copenhagen. According to a March 2011 report from the city's Office of the Inspector General,
By signing a 10-year (contract) with the Teamsters (and with over 30 other unions representing city employees), the current administration and City Council unduly hamstrung not only the current management of city government, but the next six years of management as well, a period that extends well beyond the elected terms of the incoming administration and City Council.
Gun control.
"If it was up to me, no one except law enforcement officers would own a handgun. But I understand that's impractical," Daley told attendees at a conference of gun control advocates in Washington D.C. in 1998, during his third term. Daley was a member of the Mayors Against Illegal Guns Coalition, an organization formed in 2006 and co-chaired by New York City Mayor Michael Bloomberg and Boston Mayor Thomas Menino. On January 17, 2006, during Daley's fifth term, at a joint press conference with Illinois Governor Rod Blagojevich calling for a statewide ban on semi-automatic assault weapons, Daley said, "If we are really to make the progress that we want, we have to keep the most dangerous weapons that are right here off of our streets."
The US Supreme Court took up "McDonald v. Chicago", 561 U.S. 3025, 130 S.Ct. 3020 (2010), which challenged handgun bans in the Chicago and in the neighboring suburb of Oak Park. In May 2010, Daley held a press conference to address gun control and a pending possible adverse decision in "McDonald v. Chicago". After Mick Dumke, a reporter for the "Chicago Reader", questioned the effectiveness of the city's handgun ban, Daley picked up a rifle with a bayonet from a display table of confiscated weapons and told him, "If I put this up your butt, you'll find out how effective it is. Let me put a round up your, you know." The remark placed first in a 2010 online poll of "Chicago Tribune" readers.
On June 28, 2010, the US Supreme Court held, in a 5–4 decision in "McDonald v. Chicago", that the Second Amendment to the United States Constitution was incorporated under the Fourteenth Amendment, thus protecting the right of an individual to "keep and bear arms" from local governments, and all but declared Mayor Jane Byrne's 1982 handgun ban unconstitutional. That afternoon, at a press conference concerning the gun ban, Daley said,
"We'll publicly propose a new ordinance very soon...As a city we must continue to stand up ... and fight for a ban on assault weapons ... as well as a crackdown on gun shops ... We are a country of laws not a nation of guns."
Daley called a special meeting of the City Council for four days later, and the Council approved a gun control ordinance revised to include City firearms licences.
Daley budget deficits and fund draw-downs.
Daley came into office in a city with revenue-generating assets, manageable debt and flush pension funds, but he left behind a city with a structural deficit that Mayor-elect Rahm Emanuel estimated at $1.2 billion when under-funded pension funds were included. The Daley administration's expenditures exceeded revenues by hundreds of millions of dollars a year. In August 2010, Fitch Ratings downgraded the city's bond credit rating, citing the administration's use of reserve funds for general operating expenses and under-funding of its pension funds, and noted that the city faced rising fixed operating costs yet lacked plans for new revenue. Wall Street analysts noted that the Daley administration began drawing on the city's reserves as early as 2006, before the 2008–2012 global recession. "While there had been sound economic growth in years prior to 2008, there were still sizable fund balance drawdowns in both 2006 and 2007," Fitch wrote. The city's budgets continued to increase even after the recession began, to more than $6 billion a year, and, when under-funded city employee pension funds were included, the city's annual deficit exceeded $1 billion. In January 2011, Moody's Investors Service downgraded to a "negative" outlook some of the revenue bonds issued for the $15 billion O'Hare Modernization Program and related infrastructure projects, citing the city's plan to postpone repayment of interest and principal on some construction bonds.
In his annual budget address in City Council Chambers on October 15, 2008, Daley proposed a 2009 budget totaling $5.97 billion, including not filling 1,350 vacancies on the 38,000 employee city payroll and $150 million in new revenue from a then-obscure parking meter lease deal to help erase a $469 million budget shortfall. The Daley administration employed an in-house staff of more than 50 public relations officers across City departments at a cost of $4.7 million, and millions more on seven private public relations firms. "It's worth it", Daley said. On the first day of City Council hearings on Daley's 2009 budget proposal, several aldermen questioned the administration's public relations spending. On November 4, 2008, Jacquelyn Heard, the mayor's press secretary, said the city would halt spending on 10 public relations contracts that could have paid as much as $5 million each.
In his annual budget address on October 21, 2009, Daley projected a deficit for 2009 of more than $520 million. Daley proposed a 2010 budget totaling $6.14 billion, including spending $370 million from the $1.15 billion proceeds from the parking meter lease. In his annual budget address on October 13, 2010, Daley projected a deficit for 2010 of $655 million, the largest in city history. Daley proposed a 2011 budget totaling $6.15 billion, including spending all but $76 million of what remained of the parking meter lease proceeds, and received a standing ovation from aldermen.
Daley declines to run for seventh term.
Daley's approval rating was at an all-time low of 35% by late 2009. On September 7, 2010, Daley announced that he would not seek a seventh term. "I've always believed that every person, especially public officials, must understand when it's time to move on. For me, that time is now," Daley said. On December 26, 2010, Daley surpassed his father as Chicago's longest-serving mayor. Daley chaired his final city council meeting on Wednesday morning, May 11, 2011 and his term ended May 16, 2011. Daley was succeeded by Rahm Emanuel.
Daley was supported by Chicago's traditionally Republican business community. He came under criticism for focusing city resources on the development of businesses downtown, the North, Near South, and Near West Sides, while neglecting neighborhoods in the other areas of the city; in particular the needs of low-income residents. According to "Chicago Tribune" columnist Steve Chapman, "Daley lasted 22 years in office partly because he resolved to ingratiate himself with black Chicagoans. He appointed blacks to high positions, stressed his commitment to provide services to all neighborhoods, tore down public housing projects, and pushed reform of the minority-dominated public schools." Daley focused on Chicago as a tourist destination as opposed to a manufacturing base, improved and expanded parkland, added flower planters along many primary streets, and oversaw the creation of Millennium Park on what had previously been an abandoned train yard. He spearheaded the conversion of Navy Pier into a popular tourist destination. Daley supported immigration reform, and green building initiatives, for which he was presented with an Honor Award from the National Building Museum in 2009 as a "visionary in sustainability." Chicago avoided some of the most severe economic contractions of other midwest Rust Belt cities such as Detroit and Cleveland.
Post-mayoral career.
Days after leaving office, the University of Chicago appointed Daley a "distinguished senior fellow" at the Harris School of Public Policy. The five-year, part-time appointment includes responsibility for coordinating a guest lecture series. Weeks after leaving office, Daley joined the international law firm Katten Muchin Rosenman LLP, one of the law firms to which he had awarded no-bid legal work as Mayor. Katten Muchin Rosenman LLP had negotiated the city's much-criticized long-term lease of its parking meters, and also the city's leases of the Chicago Skyway and City parking garages. Daley joined an exclusive speakers bureau, the Harry Walker Agency, that pays tens of thousands of dollars an appearance. Daley joined the board of directors of The Coca-Cola Company. Daley is a managing principal of Tur Partners LLC, an investment firm, where Daley's son, Patrick Daley, is a principal. "The National Law Journal" included Daley in its 2013 list of "The 100 Most Influential Lawyers in America," based on "his political connections — the best in Chicago."
Other.
Daley was inducted into the Chicago Gay and Lesbian Hall of Fame in 2006 as a Friend of the Community.
External links.
Listen to this article ()
This audio file was created from a revision of the "Richard M. Daley" article dated 2005-07-22, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="40224" url="http://en.wikipedia.org/wiki?curid=40224" title="Wrigley Field">
Wrigley Field

Wrigley Field is a stadium located in Chicago, Illinois, United States, and the home ballpark of the Chicago Cubs. It was built in 1914 as Weeghman Park for the Chicago Federal League baseball team, the Chicago Whales. The Cubs played their first game at Weeghman Park on April 20, 1916, defeating the Cincinnati Reds 7–6 in eleven innings. In November 1918, Weeghman resigned as team president. Chewing gum magnate William Wrigley, Jr. acquired complete control of the Cubs by 1921. It was called Cubs Park from 1920 through 1926, before officially becoming Wrigley Field for the 1927 season.
Located in the north side community area of Lakeview, Wrigley Field sits on an irregular block bounded by Clark (west) and Addison (south) Streets and Waveland (north) and Sheffield (east) Avenues. Wrigley Field is nicknamed "The Friendly Confines", a phrase popularized by "Mr. Cub", Hall of Famer Ernie Banks. The current capacity is 40,929, making Wrigley Field the 10th-smallest actively used ballpark. It is the oldest National League ballpark, the second-oldest active major league ballpark (after Fenway Park on April 20, 1912), and the only remaining Federal League park.
Wrigley Field is known for its ivy-covered brick outfield wall, the unusual wind patterns off Lake Michigan, the iconic red marquee over the main entrance, the hand-turned scoreboard, and for being the last major league park to have lights installed for play after dark, with lighting installed in 1988. The area surrounding the ballpark contains residential streets, in addition to bars, restaurants and other establishments, and is called Wrigleyville. Between 1921 and 1970, it was also the home of the Chicago Bears of the National Football League. It hosted the second annual National Hockey League Winter Classic between the Chicago Blackhawks and the Detroit Red Wings, on January 1, 2009.
History.
Charles A. Weeghman hired Zachary Taylor Davis as architect for the park, which was ready for baseball by the date of the home opener on April 23, 1914. In late 1915, Weeghman's Federal League folded. The resourceful Weeghman formed a syndicate including the chewing gum manufacturer William Wrigley Jr. to buy the Chicago Cubs from Charles P. Taft for about $500,000. Weeghman immediately moved the Cubs from the dilapidated West Side Grounds to his two-year-old park.
In 1918, Wrigley acquired the controlling interest in the club. In November 1926, he renamed the park "Wrigley Field".
In 1927, an upper deck was added, and in 1937, Bill Veeck, the son of the club president, planted ivy vines against the outfield walls.
Although Wrigley Field has been the home of the Cubs since 1916, it has yet to see the Cubs win a World Series, even though it has hosted several (1929, 1932, 1935, 1938, and 1945, the last time the Cubs appeared in a World Series). The last World Series win by the Cubs (1908) happened while the Cubs called West Side Park home.
Renovation.
The Ricketts family has been aggressively pursuing a Wrigley Field renovation since buying the team and the stadium in 2009. Their current plan, revealed during the annual Cubs Convention in January 2013, calls for a $575-million, privately funded rehabilitation of the stadium to be completed over the course of five years. The proposal is vast, and includes planned improvements to, among other things, the stadium's facade, infrastructure, restrooms, concourses, suites, press box, bullpens, and clubhouses, as well as the addition of restaurants, patio areas, batting tunnels, a 5,700-square-foot jumbotron, and an adjacent hotel, plaza, and office-retail complex.
After months of negotiations between the team, local Alderman Tom Tunney, and Chicago Mayor Rahm Emanuel, the plan obtained the endorsements of both the city's Landmarks Commission and Plan Commission before receiving final approval by the Chicago City Council in July 2013. To help fund the project, the team intends to more than double the amount of advertising signage in and around the stadium to about 51,000 square feet, including additional signage to be placed beyond the outfield walls – a move that is opposed by many owners of the rooftop clubs that surround the stadium who worry that such signs may obstruct their sightlines. Before work on the project can begin, the team wants the rooftop owners to agree not to pursue legal action challenging the construction and has continued to negotiate privately with them – offering to reduce the size and number of signs to be built – in order to gain their assent. After the team could not come to terms with the rooftop owners who have a lease with the team until 2023 in exchange for paying 17 percent of the gross revenues, the team in May 2014 said that it would pursue the original 2013 plan to modify the park.
Renovation begins.
The long-awaited "1060 Project", a $575 million Wrigley Field four-year renovation project, started Monday, September 29, 2014. The bleachers in both outfields have been expanded and the stadium's footprint extends further onto both Waveland and Sheffield Avenues. A 3,990 sq. ft. Jumbotron scoreboard has been added to the left field bleachers and additional new outfield signs are to be installed along with a 2,400 square foot video scoreboard in right field. The parking lots along Clark Street have been excavated for future underground players' locker rooms and lounges.
100th Anniversary.
During the 2014 season, the Chicago Cubs celebrated the 100th Anniversary of Wrigley Field throughout the season. Each decade was represented during ten homestands throughout the season. The April 23rd game, the 100th Anniversary, featured the Cubs playing the Arizona Diamondbacks in a throw back game. Each team represented one of the teams which played in the inaugural game at the stadium. The Cubs wore the uniforms of the Chicago Federals, the original occupants of the stadium and Diamondbacks wore uniforms representing the Kansas City Packers whom the Federals played on April 23, 1914.
Features.
Wrigley Field follows the jewel box design of ballparks that was popular in the early part of the 20th century. The two recessed wall areas, or ""wells", located both in left and right field, give those areas a little more length than if the wall were to follow the contour from center field. It is also in those wells, when cross winds are blowing, that balls have a habit of bouncing in all sorts of interesting directions. In addition, there is a long chain-link fence strip running the entire length of the outfield wall, the base of which is about two feet feet down from the top of the wall and the top of which projects out at an angle, primarily used to keep fans from falling out of the bleacher area and onto the field of play, which is about seven to ten feet below the top of the wall. Called "The basket"", by players and fans alike, the rules of the field state that any ball landing within the basket is ruled a home run, making the distance to hit a home run in Wrigley Field actually shorter than the location of the outfield wall.
Ivy-covered outfield walls.
The ballpark is famous for its outfield walls which are covered by ivy. In the first weeks of the baseball season, the ivy has not leafed out, and all that is visible are the vines on which it grows. However, as the baseball season progresses further into spring, the ivy grows thick and green, disguising the hard brick surface of the outfield wall.
Many times a ball has been lost in the ivy when hit towards the outfield fences. An outfielder will signal that a ball is lost by raising his hands. When this occurs, the umpires will call time and may rule the play a ground-rule double. If instead the outfielder opts to try to find the ball in the ivy, the ball remains live and any baserunners may advance. Although the ivy appears to "pad" the bricks, it is of little practical use in this regard. There have been occasions of fielders being injured when slamming into the wall while pursuing a fly ball.
The ivy that covers the outfield wall is a combination of Boston Ivy and Japanese Bittersweet, which can endure the harsh Chicago winters better than its English cousin. The ivy was planted in 1937 by the Cubs General Manager Bill Veeck, as part of Cubs owner P.K. Wrigley's beautification plan for the bleachers, which had been rebuilt during the 1937 season. Veeck reportedly got the idea of ivy on the walls from Perry Stadium in Indianapolis.
Wrigley is now the only professional ballpark with an ivy covered outfield wall. Several now-demolished ballparks featured ivy in the playing area, including Forbes Field, Wrigley Field's namesake in Los Angeles, and Bush Stadium in Indianapolis. Bush Stadium still stands, but hasn't hosted baseball in 15 years. After the Indianapolis Indians moved to Victory Field, a race track took its place and the race track owners stripped the ivy off the walls. Omaha's Rosenblatt Stadium, the former home of the College World Series as well as minor league baseball, had an ivy-covered brick wall that was replaced with a padded wall. Some ballparks feature ivy on out-of-play walls, especially as a covering for the batter's eye behind the center field fence.
On April 7, 2013, Total Pro Sports voted Wrigley Field the Best Place to Catch a Game in 2013, owing the award primarily to its architecture and ivy-coated fields.
Dimensions.
The distances from home plate to various points in the outfield have remained essentially unchanged since the bleachers were remodeled during the 1937 season. They were originally marked by wooden numbers cut from plywood, painted white, and placed in gaps where the ivy was not allowed to grow. Since the early 1980s, the numbers have been painted directly on the bricks, in yellow. Although the power-alley dimensions are relatively cozy, the foul lines are currently the deepest in the major leagues.
It is 355 feet (108.2 m) to the notch in the wall just beyond the left field foul pole. The point where the bleacher wall begins to curve inward in left-center field, one of the two "wells", is an unmarked 357 feet (108.8 m). The front part of the left-center "well" is the closest point in the outfield, about 360 feet. The marked left-center field distance is 368 feet (112.2 m). It is closer to true center field than its right-center counterpart is. True center field is unmarked and is about 390 feet. The center field marker, which is to the right of true center field and in the middle of the quarter-circle defining the center field area, is 400 feet (121.9 m). That is the deepest point in the outfield. Right-center field is 368 feet (112.2 m). The notch of the right-center "well" is an unmarked 363 feet (110.6 m). The right field foul line is 353 feet (107.6 m). The backstop is listed in media sources as 60.5 feet (18.4 m) behind home plate. Although that distance is standard, the relatively small foul ground area in general gives an advantage to batters.
Rooftop seats.
Old-time ballparks were often surrounded by buildings that afforded a "freebie" look at the game for enterprising souls. In most venues, the clubs took steps to either extend the stands around, or to build spite fences to block the view. Perhaps the most notorious of these was the one at Shibe Park in Philadelphia, which caused a rift between the residents and the team that never healed. The Cubs themselves had built a high fence along the outfield at West Side Park, to hide the field from flats whose back porches were right next to the outer fence of the ballpark.
But at Wrigley it was different. The flat rooftops of the apartment buildings across Waveland and Sheffield, which pre-date the ballpark, were often populated with a reasonable number of fans having cookouts while enjoying the game for free. The Cubs tolerated it quietly until the 1990s, when some owners of those apartments began building little bleacher sections, and charging people to watch the games. The Cubs management became very vocal in expressing their displeasure, threatening legal action. In 2003 they went so far as to line the screens that top the outer walls with opaque strips, to block the best exterior sight lines. That was the closest thing to a spite fence that Wrigley had seen. Therefore the bleachers are sometimes called "The Spiteless Fence" as well as "The Ivy Wall".
This led to meetings and to a peaceful settlement among the various parties. The building owners agreed to share a portion of their proceeds with the Cubs, and the Cubs obtained permission from the city to expand the ballpark's own bleachers out over the sidewalks and do some additional construction on the open area of the property to the west, bordered by Clark and Waveland, and to close the remnant of Seminary Avenue that also existed on the property. The rooftop seats are now effectively part of the ballpark's seating area, although they are not included in the seating capacity figure.
Some of the rooftops have become legendary in their own right. The Lakeview Baseball Club, which sits across Sheffield Avenue (right-field) from the stadium displays a sign that reads, "Eamus Catuli!" (roughly Latin for "Let's Go Cubs!"—"catuli" translating to "whelps", the nearest Latin equivalent), flanked by a counter indicating the Cubs' long legacy of futility. The counter is labeled "AC", for "Anno Catuli", or "In the Year of the Cubs". The first two digits indicate the number of years since the Cubs' last division championship as of the end of the previous season (2008), the next two digits indicate the number of years since the Cubs won the National League Pennant (1945), and the last three digits indicate the number of years since their last World Series win (1908).
Today, Wrigley rooftops have become a unique alternative venue to watch baseball games. Many rooftop venues feature bleachers, open bar, specialty food items, and a unique game-day atmosphere, although the quality of the view can vary depending on the specific rooftop location.
Owners of 15 of the rooftop locations have a deal with the team lasting until 2023 to pay the team 17 percent of their gross revenue. The owners threatened suit in 2013 when the team announced plans to renovate the ball field and potentially disrupt the sight lines. When the roof owners did not agree to a scaled down plan for renovations of Wrigley, the Cubs owners announced in May 2014 plans to attempt to implement the original 2013 plan for renovations even if it meant battling the issue in court. Cubs owner Ricketts said Wrigley has "the worst player facilities in Major League Baseball...I am saying it is the time to invest in Wrigley Field and do the things that our competitors do." 
Unusual wind patterns.
In April and May the wind often comes off Lake Michigan (less than a mile to the east), which means a northeast wind "blowing in" to knock down potential home runs and turn them into outs. In the summer, however, or on any warm and breezy day, the wind often comes from the south and the southwest, which means the wind is "blowing out" and has the potential to turn normally harmless fly balls into home runs. A third variety is the cross-wind, which typically runs from the left field corner to the right field corner and causes all sorts of interesting havoc. Depending on the direction of the wind, Wrigley can either be one of the friendliest parks in the major leagues for pitchers or among the worst. This makes Wrigley one of the most unpredictable parks in the Major Leagues.
Many Cubs fans check their nearest flag before heading to the park on game days for an indication of what the game might be like; this is less of a factor for night games, however, because the wind does not blow as hard after the sun goes down.
With the wind blowing "in", pitchers can dominate, and no-hitters have been tossed from time to time, though none recently; the last two occurred near the beginning and the end of the 1972 season, by Burt Hooton and Milt Pappas respectively. In the seventh inning of Ken Holtzman's first no-hitter, on August 19, 1969, Hank Aaron of the Atlanta Braves hammered one that looked like it was headed for Waveland, but the wind caught it just enough for left fielder Billy Williams to leap up and snare it.
With the wind blowing "out", some true tape-measure home runs have been hit by well-muscled batters. Sammy Sosa and Dave "Kong" Kingman broke windows in the apartment buildings across Waveland Avenue several times. Glenallen Hill put one on a rooftop. Batters have occasionally slugged it into, or to the side of, the first row or two of the "upper deck" of the center field bleachers. Sosa hit the roof of the center field camera booth on the fly during the NLCS against the Florida Marlins, some 450 feet away.
But the longest blast was probably hit by Dave Kingman on a very windy day in 1976 while with the Mets. According to local legend, that day, Kingman launched a bomb that landed on the third porch roof on the east (center field) side of Kenmore Avenue, some 550 feet away.
No batter has ever hit the center field scoreboard, however it has been hit by a different kind of ball: a golf ball, hit by Sam Snead, using a two iron.
No matter the weather, many fans congregate during batting practice and games on Waveland Avenue, behind left field, and Sheffield Avenue, behind right field, for a chance to catch a home run ball.
Some people also believe that the unpredictable and quick-changing wind current at Wrigley is a major reason why the team has not won a championship in over 100 years. Cubs players may swing the bat one way on one day and get a result far different than they would on a different day. Imagine what this does to a player's psyche and batting technique. Similarly, fielders may have trouble reading where the ball will land because of the wind current. This problem belongs mostly to the Cubs as opposed to another team because the Cubs play in Wrigley more often than does any other team. Additionally, most modern parks are built with aerodynamic modifications in mind, and so the Cubs are at a competitive disadvantage. The goat curse has often been cited as a reason why the Cubs have not won a championship in a long while. Perhaps, however, the effect from the changing wind currents is the real, scientifically-based reason why this old-wives tale seems to be coming true.
Hand-turned scoreboard.
Along with Fenway Park, Wrigley is one of the last parks to maintain a hand-turned scoreboard. Unlike the home of the Red Sox, the scoreboard at Wrigley is mounted above the centerfield bleachers, rather than at ground level, making it harder to hit during play. No players have hit the current scoreboard, although several have come close. The scoreboard was installed in 1937, when Bill Veeck installed the new bleachers. The scoreboard has remained in place ever since, and it has only seen minor modifications. The clock was added in 1941, a fifth row of scores was added to each side in 1961, and later, a sixth. A set of light stands facing onto the scoreboard was added in 1988 with the introduction of night games. An electronic message board was also added below the scoreboard.
The scoreboard is still manually operated, with scores coming in through a computer (a ticker tape machine was used in the past); a number turner watches the score changes closely and updates scores by manually replacing the numbers from within the scoreboard. The scoreboard is made out of sheet steel. The numbers that are placed into the inning windows are steel, painted forest green, and numbered with white numerals. The box for the game playing at Wrigley uses yellow numerals for the current inning. The clock, which sits at the top center of the scoreboard, has never lost time in its 71-year existence. Standing over the clock are three flagpoles, one for each division in the National League. There are 15 flags, one for each National League team, and their order on the flagpoles reflects the current standings. The entrance to the scoreboard is a trap-door on the bottom. On the reverse of the scoreboard, visible from the CTA elevated trains, is a blue pennant, with the words ""Chicago Cubs", in white outlined in red neon. The scoreboard was extensively rehabilitated for the 2010 season.
In 2010, the Cubs toyed with the idea of adding a video screen to the stadium, but the hand-turned scoreboard cannot be moved due to the park's landmark status. The landmark status also prohibits even simple facelifts such as adding two more games on either side (there are 15 teams in both the National and American leagues) of the 12-game, 24-team scoreboard (reflecting MLB from 1969 to 1976), so up to three games (1 NL, 1 AL, and the interleague) each day cannot be posted. Most Cubs players support the addition of a video board, and work on a new video board slated for the 2015 season began at the end of the 2014 season.
Those games may eventually be part of the auxiliary video board currently on the right field that may also be added in left field also.
It was announced March 21, 2013, that Alderman Tom Tunney wants to demolish the scoreboard to clear the sky view for nearby residents, who watch games from their rooftops. “Demolishing the landmark old scoreboard has never been part of any plan discussed or envisioned by the Ricketts family,” said Dennis Culloton, a spokesman for Tom Ricketts, the Cubs chairman.
Main entry marquee.
Directly over the main entrance to the stadium stands the most familiar icon of the exterior of the ballpark, a large red, art deco style marquee, painted in white letters to read "Wrigley Field, Home of Chicago Cubs"". The marquee was installed circa 1934. On March 23, 1960, the Cubs decided to paint their iconic Wrigley Field Marquee a flashier color. It had been green since it was installed in the 1930s. The sign was blue until the 1960s, and originally used changeable letters similar to the scoreboard to announce upcoming games. It originally read "Home of "the" Cubs" but was changed to "Home of Chicago Cubs" by 1939. This was also changed during football season to reflect the Chicago Bears. In 1982, the two line announcement board was replaced with an electronic message board and a backlit advertising panel was added below (this is now solid red). The marquee utilizes red neon lights at night, showing the familiar ""Wrigley Field"" in red, as the rest of the sign is in darkness. The marquee is so iconic with the park, that the owners of the park, both past, and present, have used the marquee in some way as the park's trademark of sorts: even the CTA platform that services Wrigley Field (the CTA Addison St. station,) has an image of the marquee painted on a wall announcing the destination, rather than simply marking it with black block letters. The marquee was painted purple to accommodate the Northwestern Wildcats who played as the home team against the Illinois Fighting Illini in football in November 2010.
Lights.
The Cubs were a hold-out against night games for decades, not installing lights at Wrigley until 1988 (after baseball officials announced that the park would be prohibited from hosting any future post-season games without lights). Before then, all games at Wrigley were played during the day. Night games are still limited in number by agreement with the city council. In 1942, then-owner Philip K. Wrigley had planned to install lights, but instead, the lights and stands were scrapped for the World War II effort. In the late 1980s, however, Cubs management insisted that the team was in danger of leaving Wrigley if lights weren't installed, and Major League Baseball threatened to make the Cubs play postseason "home" games at Busch Stadium in St. Louis.
The 1984 World Series was scheduled to start in the National League park. But Major League Baseball actually had a contingency plan to instead start the World Series in the American League park in the event that the Chicago Cubs won the National League Championship Series against the San Diego Padres. This would have allowed the Wrigley Field-hosted (i.e. daytime) games to be held over the weekend. In return, only one prime time game (Game 3 on Friday) would have been lost. Wrigley Field wouldn't have lights installed until four years later. To put things in proper perspective, had the Cubs advanced to the Series instead of the Padres, the Detroit Tigers would have hosted Games 1–2, and 6–7 (on Tuesday and Wednesday nights), while the Cubs would have hosted Games 3–5 (on Friday, Saturday and Sunday), with all three games in Chicago starting no later than 1:30 p.m. Central Time. Since the Padres wound up winning the 1984 NLCS, these plans proved moot.
After 5,687 consecutive day games played by the Cubs at Wrigley, the lights were finally lit on August 8, 1988, for a game with the Philadelphia Phillies. That game was rained out after three and a half innings, and the first official night game took place the following evening against the New York Mets, a game which the Cubs won 6-4.
The All-American Girls Professional Baseball League's first All-Star Game during the 1943 midseason, was played under temporary lights at Wrigley Field, between two teams composed of South Bend Blue Sox and Rockford Peaches players versus Kenosha Comets and Racine Belles players. It was also the first night game ever played in the historic ballpark (July 1, 1943).
Stadium usage.
Baseball.
Weeghman Park's first tenant was the Federal League team, the Chicago Whales, from 1914 to 1915.
Weeghman Park / Cubs Park / Wrigley Field has served as the home baseball park for Major League Baseball's Chicago Cubs franchise since 1916.
Football.
The Chicago Bears of the National Football League played at Wrigley Field from 1921 to 1970 before relocating to Soldier Field. The team had transferred from Decatur, and retained the name "Staleys" for the 1921 season. They renamed themselves the "Bears" in order to identify with the baseball team, a common practice in the NFL in those days. Wrigley Field once held the record for the most NFL games played in a single stadium with 365 regular season NFL games, but this record was surpassed in September 2003 by Giants Stadium in New Jersey, thanks to its dual-occupancy by the New York Giants and New York Jets. The game played between the Jets and Miami Dolphins on September 14, 2003 was the 366th regular season NFL game at Giants Stadium breaking Wrigley's regular season record. The 50 seasons the Bears spent at Wrigley Field had been an NFL record until 2006 when Lambeau Field duplicated this feat by hosting the Green Bay Packers for the 50th season, and broke it in 2007.
Initially the Bears worked with the stands that were there. Eventually they acquired a large, portable bleacher section that spanned the right and center field areas and covered most of the existing bleacher seating and part of the right field corner seating. This "East Stand" raised Wrigley's football capacity to about 47,000, or a net gain of perhaps 9,000 seats over normal capacity. After the Bears left, this structure would live on for several years as the "North Stand" at Soldier Field, until it was replaced by permanent seating.
The football field ran north-to-south, i.e. from left field to the foul side of first base. The remodeling of the bleachers made for a very tight fit for the gridiron. In fact, the corner of the south end zone was literally in the visiting baseball team's dugout, which was filled with pads for safety, and required a special ground rule that sliced off that corner of the end zone. The end zone was also shorter than the north, as the south end zone was eight yards, compared to the regulation ten yards. One corner of the north end line ran just inches short of the left field wall. There is a legend that Bronko Nagurski, the great Bears fullback, steamrolled through the line, head down, and ran all the way through that end zone, smacking his leather-helmeted head on the bricks. He went back to the bench and told Coach "Papa Bear" George Halas, "That last guy gave me quite a lick!" That kind of incident prompted the Bears to hang some padding in front of the wall.
The Bears are second only to the Packers in total NFL championships, and all but one of those (their only Super Bowl championship) came during their tenure at Wrigley. After a half-century, they found themselves compelled to move, because the NFL wanted every one of its stadiums to seat at least 50,000 as a result of the AFL–NFL merger. The Bears had one experimental game at Dyche Stadium (now Ryan Field) on the Northwestern University campus in 1970, but otherwise continued at Wrigley until their transfer to the lakefront ended their five-decades run on the north side. One remnant of the Bears' time at Wrigley was uncovered during the off-season 2007–2008 rebuilding of the playing field: the foundations for the goal posts. Five NFL championship games were played at Wrigley Field; 1933, 1937, 1941, 1943 and 1963.
The Northwestern Wildcats and the Illinois Fighting Illini played a college football game at Wrigley Field on November 20, 2010. It was the first football game at Wrigley Field since 1970 and the first collegiate football game at Wrigley Field since 1938 when the DePaul Blue Demons played its regular games at Wrigley. The field used an east–west field configuration (third base to right field). In order to keep the playing field at regulation size, the safety clearances for each end zone to the walls in the field were considerably less than normal. In particular, the east (right field) end zone came under scrutiny as its end zone was wedged extremely close to the right field wall (as close as one foot in some areas), forcing the goal posts to be hung from the right field wall in order to fit. Despite extra padding provided in these locations, it was decided that all offensive plays for both teams play to the west end zone, where there was more safety clearance. The east end zone could still be used on defensive and special teams touchdowns, as well as defensive safeties; and, in fact, there was one interception run back for an eastbound touchdown. Big Ten Commissioner Jim Delany said that as late as three days before the game, he had only been apprised that the situation wasn't "anything other than tight." When he had a chance to fully vet the situation, however, he concluded that the space surrounding the east end zone was smaller than the minimum of six feet stipulated in NCAA rules, and it would have been too great of a risk to allow offensive plays to be run toward that end zone. The Fighting Illini won the game 48-27 taking home the Land of Lincoln Trophy, which was introduced in 2009.
Other events.
The Chicago Sting of the North American Soccer League (NASL) used Wrigley, along with Comiskey Park, for their home matches during the late 1970s and early 1980s. The Sting hosted the San Diego Sockers on August 25, 1979 at Wrigley when the Bears were using Soldier Field. Unlike the Bears' American football layout, the soccer pitch ran east-to-west, from right field to the foul territory on the third-base side. Soccer returned to Wrigley Field in July 2012, when Italian club A.S. Roma played Poland's Zagłębie Lubin in a friendly match.
On January 1, 2009, the National Hockey League played its 2009 Winter Classic in The Friendly Confines pitting two "Original Six" teams - the host Chicago Blackhawks and the visiting Detroit Red Wings - in an outdoor ice hockey game. The rink ran across the field from first base to third base with second base being covered by roughly the center of the rink. The attendance for this game was 40,818. The Red Wings won 6–4.
In recent years Wrigley Field has been opened on a limited basis to popular concerts, not without some controversy. Local neighborhood groups have expressed concerns about the impact of concert crowds and noise on the surrounding residential neighborhood, particularly in 2009 when three concerts were added to the schedule, one conflicting with an annual neighborhood festival.
On July 19, 2013, the American band Pearl Jam played at Wrigley. The show became the fastest concert to sell-out at Wrigley Field. The show was interrupted for more than two hours due to the threat of lightning.
On July 20, 2013 Jason Aldean performed a sold-out show at the park during his 2013Night Train Tour. Also Kelly Clarkson was added to the bill for the historic night along with Jake Owen and Thomas Rhett
On July 19, 2014 Blake Shelton performed his first stadium show at the park during his 2014 Ten Times Crazier Tour with The Band Perry, Neal McCoy & Dan + Shay as openers.
List of concerts at Wrigley Field
Traditions and mainstays.
Corporate sponsorship.
Wrigley Field shares its name with the Wrigley Company, as the park was named for its then-owner, William Wrigley Jr., the CEO of the Wrigley Company. As early as the 1920s, before the park became officially known as Wrigley Field, the scoreboard was topped by the elf-like "Doublemint Twins", posed as a pitcher and a batter. There were also ads painted on the bare right field wall early in the ballpark's history, prior to the 1923 remodeling which put bleachers there. After that, the Doublemint elves were the only visible in-park advertising. The elves were removed permanently in 1937 when the bleachers and scoreboard were rebuilt. It would be about 44 years before in-park advertising would reappear.
Wrigley Field has been a notable exception to the recent trend of selling corporate naming rights to sporting venues. The Tribune Company, who owned the park from 1981 to 2009, chose not to rename the ballpark, utilizing other ways to bring corporate sponsorship into the ballpark.
During the mid-1980s, Anheuser-Busch placed Budweiser and Bud Light advertisements beneath the center field scoreboard. Bud Light became the sponsor of the rebuilt bleachers in 2006.
In the early 2000s, following the trend of many ballparks, a green-screen chroma key board was installed behind home plate, in the line of sight of the center field TV camera, to allow electronic "rotating" advertisements visible only to the TV audiences. By 2006, the board was set up to allow advertisements to be both physical and electronic (thus they can be seen in both live and replay shots).
In 2007, the first on-field advertising appeared since the park's early days. Sporting goods firm Under Armour placed its logo on the double-doors between the ivy on the outfield wall, in left-center and right-center fields. Advertisements were also placed in the dugouts, originally for Sears department stores, then Walter E. Smithe furniture and now State Farm insurance.
Corporate sponsorship has not been limited to the park itself. Wrigley Field is famous for its view of the neighborhood buildings across Waveland and Sheffield Avenues. In addition to spectators standing or sitting on the apartment roofs, corporate sponsors have frequently taken advantage of those locations as well. In the earliest days of Weeghman Park, one building across Sheffield Avenue advertised a local hangout known as Bismarck Gardens (later called the Marigold Gardens after World War I). That same building has since advertised for the Torco Oil Company, Southwest Airlines, and the Miller Brewing Company.
A building across from deep right-center field was topped by a neon sign for Baby Ruth candy beginning in the mid-1930s and running for some 40 years. That placement by the Chicago-based Curtiss Candy Company, coincidentally positioned in the line of sight of "Babe Ruth's called shot", proved fortuitous when games began to be televised in the 1940s—the sign was also in the line of sight of the ground level camera behind and to the left of home plate. The aging sign was eventually removed in the early 1970s.
Another long-standing venue for a sign is the sloping roof of a building behind left-center field. Unsuitable for the bleachers that now decorate many of those buildings, that building's angling roof has been painted in the form of a large billboard since at least the 1940s. In recent years it has borne a bright-red Budweiser sign and, beginning in 2009, an advertisement for Horseshoe Casino. Other buildings have carried signs sponsoring beers, such as Old Style (when it was a Cubs broadcasting sponsor) and Miller; and also WGN-TV, which has telecast Cubs games since April 1948.
For 2008 and 2009, the Cubs worked out an agreement with the Chicago Board Options Exchange to allow the CBOE to auction some 70 box seat season tickets and award naming rights to them.
For the 2009 season, The Chicago Cubs announced that the renovated restaurant space in the southeast corner of Wrigley Field, formerly known as the Friendly Confines Cafe, will now be known as the Captain Morgan Club.
On October 27, 2009, Thomas S. Ricketts officially took over 95% ownership of the Chicago Cubs, Wrigley Field and 20% ownership of Comcast SportsNet Chicago. The Tribune will retain 5% ownership. Ricketts, however, has expressed no interest in selling the naming rights to Wrigley Field, preferring that it retain the name it has used since 1926.
Win flag.
Beginning in the days of P.K. Wrigley and the 1937 bleacher/scoreboard reconstruction, a flag with either a "W" or an "L" has flown from atop the scoreboard masthead, indicating the day's result. In case of a doubleheader that is split, both flags are flown. The ritual of raising flags after a game is decades-old.
Past Cubs media guides show that the original flags were blue with a white "W" and white with a blue "L", the latter coincidentally suggesting "surrender". In 1978, blue and white lights were mounted atop the scoreboard, to further denote wins and losses.
The flags were replaced in the early 1980s, and the color schemes were reversed with the "win flag" being white with a blue W, and the "loss flag" the opposite. In 1982, the retired number of Ernie Banks was flying on a foul pole, as white with blue numbers, in 1987, the retired number of Billy Williams joined Banks, the two flags were positioned from the foul poles, Banks from left field, and Williams from right field. Later on, the team retired numbers for Ron Santo, Ryne Sandberg, Ferguson Jenkins and Greg Maddux, with Jenkins and Maddux both using the same number (31).
Keeping with tradition, fans are known to bring win flags to home and away games, and displaying them after a Cubs win. Flags are also sold at the ballpark. On April 24, 2008 the Cubs flew an extra white flag displaying "10,000" in blue, along with the win flag, as the 10,000th win in team history was achieved on the road the previous night. Alongside the tradition of the "W" and "L" flags, the song "Go Cubs Go" is sung after each home win.
Take Me Out to the Ball Game.
The tradition of singing "Take Me Out to the Ball Game" at Cubs home games began when Hall of Fame announcer Harry Caray arrived in 1982 (he had sung it the preceding 7 years as a broadcaster for the White Sox), and it has remained a Wrigley Field staple. After Caray's death, the tradition of a guest conductor began, with former baseball players, other sports stars, actors, and other celebrities invited to sing during the Seventh Inning Stretch. Among the best-known guests have been former Cubs second baseman Ryne Sandberg, former pitcher Mike Krukow, former longtime Cubs first baseman Mark Grace, former Houston Rockets star Tracy McGrady, Chicago Blackhawks forwards Jonathan Toews and Patrick Kane, Chicago Bears quarterback Jay Cutler, comedian Jay Leno, NASCAR driver Jeff Gordon, singers Ozzy Osbourne and Eddie Vedder, boxer and actor Mr. T, actor and lifelong Cub fan Gary Sinise, actors Tom Arnold, James Belushi, and Bill Murray, and WWE wrestler/Chicago native CM Punk.
Popular culture.
Wrigley Field had a brief cameo in the movie "The Blues Brothers" (1980), starring John Belushi and Dan Aykroyd as Jake and Elwood Blues. Elwood listed 1060 W. Addison as his fake home address on his Illinois driver's license, tricking the police and later the Nazis listening on police radio into heading for Wrigley Field. "The Natural" (1984), starring Robert Redford, had a scene set at Wrigley but was actually filmed at All-High Stadium in Buffalo, New York. All other baseball action scenes in that movie were shot in Buffalo, at the since-demolished War Memorial Stadium.
During Cubs games, fans will often stand outside the park on Waveland Avenue, waiting for home run balls hit over the wall and out of the park. However, as a tradition, Cubs fans inside and sometimes even outside the park will promptly throw any home run ball hit by an opposing player back onto the field of play, a ritual depicted in the 1977 stage play, "Bleacher Bums", and in the 1993 film, "Rookie of the Year".
The ballpark was featured in a scene in "Ferris Bueller's Day Off", where the outside marquee read "Save Ferris". Many scenes from "Rookie of the Year" were filmed at Wrigley Field. The director, John Hughes, originally wanted to film at Comiskey Park (he was a White Sox fan) but the team was out of town during filming. Later, the film "The Break-Up" would use Wrigley Field as the setting for its opening scene. An early 1990s film about Babe Ruth had the obligatory scene in Wrigley Field about the "called shot" (the ballpark also doubled as Yankee Stadium for the film). A scoreboard similar to the one existing in 1932 was used, atop an ivy wall (though that did not exist until later in the decade).
The ballpark was used for the establishing tryouts scene in "A League of Their Own" (1992). This film was a Hollywood account of the 1940s women's baseball league which Cubs owner P.K. Wrigley championed during World War II. Garry Marshall (older brother of the film's director Penny Marshall) has a cameo as "Walter Harvey", Wrigley's fictional alter ego. The sign behind the scoreboard was temporarily redone to read "Harvey Field", and filming was split between Wrigley and Cantigny Park near Wheaton, IL.
Many television series have made featured scenes set in Wrigley Field, including "ER", "Crime Story", "Chicago Hope", "Prison Break", "Perfect Strangers", and "My Boys". Also, the animated comedy "Family Guy" featured a scene at Wrigley Field that parodied the Steve Bartman incident. In an episode of "The Simpsons" titled "He Loves to Fly and He D'ohs", upon arriving in Chicago, Homer walks past a number of famous Chicago landmarks, including Wrigley Field, followed by a generic-looking stadium bearing the name "Wherever the White Sox play". In 2007, the band Nine Inch Nails created a promotional audio skit, which involved Wrigley Field being the target of disgruntled war veteran's terrorist attack.
The late-1970s comedy stage play "Bleacher Bums" was set in the right field bleachers at Wrigley. The video of the play was also set on a stage, with bleachers suggesting Wrigley's layout, rather than in the actual ballpark's bleachers. The tradition of throwing opposition home run balls back was explained by Dennis Franz's character: "If someone hands you some garbage, you have to throw it back at them!"
A dog park in the Wrightwood Neighbors section of Lincoln Park is named Wiggly Field (1997).
The stadium was also featured on the popular Travel Channel television show "Great Hotels", starring Samantha Brown. She attended a game during a visit to Chicago.
Chicago folk singer Steve Goodman featured Wrigley Field as the setting for his popular Cubs lament "A Dying Cub Fan's Last Request", extolling both the trials of the Cubs and the place Wrigley Field holds in Cub fans' hearts. After his untimely death from leukemia, Goodman's ashes were in fact scattered at Wrigley Field as described in the lyrics.
The Statler Brothers' 1981 song "Don't Wait On Me" referred to a then-implausible situation: "When the lights go on at Wrigley Field". However, after lights were installed, the line was changed to "When they put a dome on Wrigley Field" for their 1989 "Live-Sold Out" album.
A few brief shots of Wrigley Field appear in the 1949 movie "It Happens Every Spring". It is also seen on the History Channel's show "Life After People."
The stadium made a brief appearance in the open for the first episode of "The Tonight Show with Conan O'Brien", with Conan rushing through the turnstiles while running from New York (where his previous show, "Late Night with Conan O'Brien", was taped) to Los Angeles (where his new show was taped, until his role as host ended on January 22, 2010) and then running onto the field while being chased by Cubs security. The route O'Brien takes is somewhat misleading, as he is shown running south on Michigan Avenue past the Tribune Tower before arriving at Wrigley Field, which is well north of the Tribune Tower.
In the movie "", a terrorist turns off all the electricity at the stadium for a few minutes to demonstrate how hackers could penetrate city electrical systems.
An overgrown Wrigley Field is shown in the new television series "Revolution" (2012)
On the Sonic Youth live album "Smart Bar Chicago 85" the band introduce the final song, 'Making The Nature Scene', as being about 'Tripping on Acid at Wrigley Field'.
There is a sociologist and demographer called Elizabeth Wrigley-Field who is currently teaching at Columbia University, N.Y. She has her name from her parents (her mother was a Wrigley, her father a Field) but they called her simply Field, so she had to take legal steps to change her name to Wrigley-Field.
A panoramic view of Wrigley Field from the upper deck.
Accessibility and transportation.
The Red Line stop at Addison is less than one block east of Wrigley Field. (The stadium was originally built for proximity to the train tracks.) At the conclusion of games, the scoreboard operator raises to the top of the center field scoreboard either a white flag with a blue "W" to signify a Cubs victory or a blue flag with a white "L" for a loss. This is done to show the outcome of the game to passengers on passing "L" trains, and also to anyone passing by the park. Interestingly, the basic flag color was once the exact opposite of the colors used today (the rationale being that white is the traditional color for surrender). In addition to rail service, the CTA provides several bus routes which service Wrigley. CTA bus routes #22 Clark, #152 Addison and #154 Wrigley Field Express all provide access to the ballpark. Pace also operates the #282 Schaumburg-Wrigley Field Express from Woodfield Mall in Schaumburg and the #779 Yorktown-Wrigley Field Express from Yorktown Shopping Center in Lombard. Biking to the field is also a popular alternative. As Halsted, Addison, and Clark streets all have designated biking lanes, getting to the field via bicycle is a widely used way to avoid hectic pre- and postgame traffic; Wrigley Field offers a complimentary bike check program to accommodate for them. Cyclists may check their bikes up to 2 hours before games at the bike racks off of Waveland Ave, and may pick up their bikes up to one hour after games end.
Parking in the area remains scarce, but that does not seem to bother fans who want to come to this baseball mecca, which has drawn more than 3 million fans every year from 2004 until 2011 averaging to a near-sellout every day of the season, even with many weekday afternoon games. The little parking that "is" available around the park can go for as much as $100 per space. To partially alleviate this problem, the Cubs sponsor a parking shuttle service from the nearby DeVry University campus at Belmont and Western as part of their agreement with local neighborhood groups.
Commemorative stamps.
In 2001, a series of commemorative postage stamps on the subject of baseball parks was issued by the U.S. Postal Service. Most of them were engravings taken from old colorized postcards, including the illustration of Wrigley Field. In the case of Wrigley, the famous scoreboard was sliced off, presumably to hide the original postcard's banner containing the park's name. It may also be observed that the original black-and-white aerial photo, presumably from the 1945 World Series, was taken from nearly the identical spot as the photo of the 1935 Series, allowing a comparison before and after the 1937 alterations to the bleachers. The stamp and its sources also provide a rare look at the center field bleachers filled with spectators, a practice which was later discontinued due to the risk to batters, who might lose the flight of a pitch amidst the white shirts. This led to the development of darker backgrounds to the pitchers mounds.
External links.
class="wikitable succession-box collapsible autocollapse" style="margin: 0 auto 0 auto; font-size:95%;clear:both;"
Events and tenants

</doc>
<doc id="40225" url="http://en.wikipedia.org/wiki?curid=40225" title="George IV of the United Kingdom">
George IV of the United Kingdom

George IV (George Augustus Frederick; 12 August 1762 – 26 June 1830) was King of the United Kingdom of Great Britain and Ireland and of Hanover following the death of his father, George III, on 29 January 1820, until his own death ten years later. From 1811 until his accession, he served as Prince Regent during his father's final mental illness.
George IV led an extravagant lifestyle that contributed to the fashions of the Regency era. He was a patron of new forms of leisure, style and taste. He commissioned John Nash to build the Royal Pavilion in Brighton and remodel Buckingham Palace, and Sir Jeffry Wyattville to rebuild Windsor Castle. He was instrumental in the foundation of the National Gallery and King's College London.
His charm and culture earned him the title "the first gentleman of England", but his poor relationship with both his father and his wife, Caroline of Brunswick, and his dissolute way of life, earned him the contempt of the people and dimmed the prestige of the monarchy. He even forbade Caroline to attend his coronation and introduced the unpopular Pains and Penalties Bill in a desperate, unsuccessful attempt to divorce her.
For most of George's regency and reign, Lord Liverpool controlled the government as Prime Minister, with little help from George. His ministers found his behaviour selfish, unreliable and irresponsible. At all times he was much under the influence of favourites. Taxpayers were angry at his wasteful spending at a time when Britons were fighting in the Napoleonic Wars. He did not provide national leadership in time of crisis, nor act as a role model for his people. Liverpool's government presided over Britain's ultimate victory, negotiated the peace settlement, and attempted to deal with the social and economic malaise that followed. After Liverpool's retirement, George was forced to accept Catholic emancipation despite opposing it. His only child, Princess Charlotte of Wales, died before him in 1817 and so he was succeeded by his younger brother, William.
Early life.
George was born at St James's Palace, London, on 12 August 1762, the first child of King George III of the United Kingdom and Queen Charlotte. As the eldest son of a British sovereign, he automatically became Duke of Cornwall and Duke of Rothesay at birth; he was created Prince of Wales and Earl of Chester a few days later. On 18 September of the same year, he was baptised by Thomas Secker, Archbishop of Canterbury. His godparents were the Duke of Mecklenburg-Strelitz (his maternal uncle, for whom the Duke of Devonshire, Lord Chamberlain, stood proxy), the Duke of Cumberland (his twice-paternal great-uncle) and the Dowager Princess of Wales (his paternal grandmother). George was a talented student, and quickly learned to speak French, German and Italian in addition to his native English.
At the age of 18 he was given a separate establishment, and in dramatic contrast with his prosaic, scandal-free father, threw himself with zest into a life of dissipation and wild extravagance involving heavy drinking and numerous mistresses and escapades. He was a witty conversationalist, drunk or sober, and showed good, but grossly expensive, taste in decorating his palace. The Prince turned 21 in 1783, and obtained a grant of £60,000 (equivalent to £ today) from Parliament and an annual income of £50,000 (equivalent to £ today) from his father. It was far too little for his needs – the stables alone cost £31,000 a year. He then established his residence in Carlton House, where he lived a profligate life. Animosity developed between the Prince and his father, who desired more frugal behaviour on the part of the heir apparent. The King, a political conservative, was also alienated by the Prince's adherence to Charles James Fox and other radically inclined politicians.
Soon after he reached the age of 21, the Prince became infatuated with Maria Fitzherbert. She was a commoner, six years his elder, twice widowed, and a Roman Catholic. Despite her complete unsuitability, the Prince was determined to marry her. This was in spite of the Act of Settlement 1701, which barred the spouse of a Catholic from succeeding to the throne, and the Royal Marriages Act 1772, which prohibited his marriage without the consent of the King, which would never have been granted.
Nevertheless, the couple went through a marriage ceremony on 15 December 1785 at her house in Park Street, Mayfair. Legally the union was void, as the King's consent was not granted (and never even requested). However, Fitzherbert believed that she was the Prince's canonical and true wife, holding the law of the Church to be superior to the law of the State. For political reasons, the union remained secret and Fitzherbert promised not to reveal it.
The Prince was plunged into debt by his exorbitant lifestyle. His father refused to assist him, forcing him to quit Carlton House and live at Fitzherbert's residence. In 1787, the Prince's political allies proposed to relieve his debts with a parliamentary grant. The Prince's relationship with Fitzherbert was suspected, and revelation of the illegal marriage would have scandalised the nation and doomed any parliamentary proposal to aid him. Acting on the Prince's authority, the Whig leader Charles James Fox declared that the story was a calumny. Fitzherbert was not pleased with the public denial of the marriage in such vehement terms and contemplated severing her ties to the Prince. He appeased her by asking another Whig, Richard Brinsley Sheridan, to restate Fox's forceful declaration in more careful words. Parliament, meanwhile, granted the Prince £161,000 (equivalent to £ today) to pay his debts and £60,000 (equivalent to £ today) for improvements to Carlton House.
Regency crisis of 1788.
In the summer of 1788 the King's mental health deteriorated, possibly as the result of the hereditary disease porphyria. He was nonetheless able to discharge some of his duties and to declare Parliament prorogued from 25 September to 20 November. During the prorogation he became deranged, posing a threat to his own life, and when Parliament reconvened in November the King could not deliver the customary speech from the throne during the State Opening of Parliament. Parliament found itself in an untenable position: according to long-established law it could not proceed to any business until the delivery of the King's Speech at a State Opening.
Although arguably barred from doing so, Parliament began debating a Regency. In the House of Commons, Charles James Fox declared his opinion that the Prince of Wales was automatically entitled to exercise sovereignty during the King's incapacity. A contrasting opinion was held by the Prime Minister, William Pitt the Younger, who argued that, in the absence of a statute to the contrary, the right to choose a Regent belonged to Parliament alone. He even stated that, without parliamentary authority "the Prince of Wales had no more right ... to assume the government, than any other individual subject of the country." Though disagreeing on the principle underlying a Regency, Pitt agreed with Fox that the Prince of Wales would be the most convenient choice for a Regent.
The Prince of Wales—though offended by Pitt's boldness—did not lend his full support to Fox's approach. The Prince of Wales's brother, Prince Frederick, Duke of York, declared that George would not attempt to exercise any power without previously obtaining the consent of Parliament. Following the passage of preliminary resolutions Pitt outlined a formal plan for the Regency, suggesting that the powers of the Prince of Wales be greatly limited. Among other things, the Prince of Wales would not be able either to sell the King's property or to grant a peerage to anyone other than a child of the King. The Prince of Wales denounced Pitt's scheme, declaring it a "project for producing weakness, disorder, and insecurity in every branch of the administration of affairs." In the interests of the nation, both factions agreed to compromise.
A significant technical impediment to any Regency Bill involved the lack of a speech from the throne, which was necessary before Parliament could proceed to any debates or votes. The speech was normally delivered by the King, but could also be delivered by royal representatives known as Lords Commissioners; but no document could empower the Lords Commissioners to act unless the Great Seal of the Realm was affixed to it. The Seal could not be legally affixed without the prior authorisation of the Sovereign. Pitt and his fellow ministers ignored the last requirement and instructed the Lord Chancellor to affix the Great Seal without the King's consent, as the act of affixing the Great Seal in itself gave legal force to the Bill. This legal fiction was denounced by Edmund Burke as a "glaring falsehood", as a "palpable absurdity", and even as a "forgery, fraud". The Duke of York, described the plan as "unconstitutional and illegal." Nevertheless, others in Parliament felt that such a scheme was necessary to preserve an effective government. Consequently on 3 February 1789, more than two months after it had convened, Parliament was formally opened by an "illegal" group of Lords Commissioners. The Regency Bill was introduced, but before it could be passed the King recovered. The King declared retroactively that the instrument authorising the Lords Commissioners to act was valid.
Marriage and mistresses.
The Prince of Wales's debts continued to climb, and his father refused to aid him unless he married his cousin Princess Caroline of Brunswick. In 1795, the Prince of Wales acquiesced; and they were married on 8 April 1795 at the Chapel Royal, St James's Palace. The marriage, however, was disastrous; each party was unsuited to the other. The two were formally separated after the birth of their only child, Princess Charlotte, in 1796, and remained separated thereafter. The Prince of Wales remained attached to Maria Fitzherbert for the rest of his life, despite several periods of estrangement.
George's mistresses included Mary Robinson, an actress who was bought off with a generous pension when she threatened to sell his letters to the newspapers; Grace Elliott, the divorced wife of a physician; and Frances Villiers, Countess of Jersey, who dominated his life for some years. In later life, his mistresses were the Marchioness of Hertford and the Marchioness Conyngham, who were both married to aristocrats.
George was rumoured to have fathered several illegitimate children. James Ord (born 1786)—who moved to the United States and became a Jesuit priest—was reportedly his son by Fitzherbert. The King, late in life, told a friend that he had a son who was a naval officer in the West Indies, whose identity has been tentatively established as Captain Henry A. F. Hervey (1786–1824), reportedly George's child by the songwriter Lady Anne Lindsay (later Barnard), a daughter of the 5th Earl of Balcarres. Other reported offspring include Major George Seymour Crole, the son of theatre manager's daughter Eliza Crole or Fox; William Hampshire, the son of publican's daughter Sarah Brown; and Charles "Beau" Candy, the son of a Frenchwoman with that surname. Anthony Camp, Director of Research at the Society of Genealogists, has dismissed the claims that George IV was the father of Ord, Hervey, Hampshire and Candy as fictitious.
The problem of the Prince of Wales's debts, which amounted to the extraordinary sum of £630,000 (equivalent to £ today) in 1795, was solved (at least temporarily) by Parliament. Being unwilling to make an outright grant to relieve these debts, it provided him an additional sum of £65,000 (equivalent to £ today per annum). In 1803, a further £60,000 (equivalent to £ today) was added, and the Prince of Wales's debts of 1795 were finally cleared in 1806, although the debts he had incurred since 1795 remained.
In 1804, a dispute arose over the custody of Princess Charlotte, which led to her being placed in the care of the King, George III. It also led to a Parliamentary Commission of Enquiry into Princess Caroline's conduct after the Prince of Wales accused her of having an illegitimate son. The investigation cleared Caroline of the charge but still revealed her behaviour to have been extraordinarily indiscreet.
Regency.
In late 1810, George III was once again overcome by his malady following the death of his youngest daughter, Princess Amelia. Parliament agreed to follow the precedent of 1788; without the King's consent, the Lord Chancellor affixed the Great Seal of the Realm to letters patent naming Lords Commissioners. The letters patent lacked the Royal Sign Manual, but were sealed by request of resolutions passed by both Houses of Parliament. The Lords Commissioners appointed by the letters patent, in the name of the King, then signified the granting of Royal Assent to a bill that became the Regency Act of 1811. Parliament restricted some of the powers of the Prince Regent (as the Prince of Wales became known). The constraints expired one year after the passage of the Act. The Prince of Wales became Prince Regent on 5 February 1811.
The Regent let his ministers take full charge of government affairs, playing a far lesser role than his father. The principle that the crown accepts as prime minister the person supported by a majority in the House of Commons, whether the king personally favours him or not, became established. His governments, with little help from the Regent, presided over British policy. One of the most important political conflicts facing the country concerned Catholic emancipation, the movement to relieve Roman Catholics of various political disabilities. The Tories, led by the Prime Minister, Spencer Perceval, were opposed to Catholic emancipation, while the Whigs supported it. At the beginning of the Regency, the Prince of Wales was expected to support the Whig leader, William Grenville, 1st Baron Grenville. He did not, however, immediately put Lord Grenville and the Whigs into office. Influenced by his mother, he claimed that a sudden dismissal of the Tory government would exact too great a toll on the health of the King (a steadfast supporter of the Tories), thereby eliminating any chance of a recovery.
In 1812, when it appeared highly unlikely that the King would recover, the Prince of Wales again failed to appoint a new Whig administration. Instead, he asked the Whigs to join the existing ministry under Perceval. The Whigs, however, refused to co-operate because of disagreements over Catholic emancipation. Grudgingly, the Prince of Wales allowed Perceval to continue as Prime Minister.
On 10 May 1812, Perceval was assassinated by John Bellingham. The Prince Regent was prepared to reappoint all the members of the Perceval ministry under a new leader. The House of Commons formally declared its desire for a "strong and efficient administration", so the Prince Regent then offered leadership of the government to Richard Wellesley, 1st Marquess Wellesley, and afterwards to Francis Rawdon-Hastings, 2nd Earl of Moira. He doomed the attempts of both to failure, however, by forcing each to construct an all party ministry at a time when neither party wished to share power with the other. Possibly using the failure of the two peers as a pretext, the Prince Regent immediately reappointed the Perceval administration, with Robert Jenkinson, 2nd Earl of Liverpool, as Prime Minister.
The Tories, unlike Whigs such as Earl Grey, sought to continue the vigorous prosecution of the war in Continental Europe against the powerful and aggressive Emperor of the French, Napoleon I. An anti-French alliance, which included Russia, Prussia, Austria, Britain and several smaller countries, defeated Napoleon in 1814. In the subsequent Congress of Vienna, it was decided that the Electorate of Hanover, a state that had shared a monarch with Britain since 1714, would be raised to a kingdom, known as the Kingdom of Hanover. On 30 December 1814, the Prince Regent signed and ratified the Treaty of Ghent which ended the War of 1812 with the United States. Napoleon returned from exile in 1815, but was defeated at the Battle of Waterloo by Arthur Wellesley, 1st Duke of Wellington, brother of Marquess Wellesley.
During this period George took an active interest in matters of style and taste, and his associates such as the dandy Beau Brummell and the architect John Nash created the Regency style. In London Nash designed the Regency terraces of Regent's Park and Regent Street. George took up the new idea of the seaside spa and had the Brighton Pavilion developed as a fantastical seaside palace, adapted by Nash in the "Indian Gothic" style inspired loosely by the Taj Mahal, with extravagant "Indian" and "Chinese" interiors.
Reign.
When George III died in 1820, the Prince Regent, then aged 57, ascended the throne as George IV, with no real change in his powers. By the time of his accession, he was obese and possibly addicted to laudanum.
George IV's relationship with his wife Caroline had deteriorated by the time of his accession. They had lived separately since 1796, and both were having affairs. In 1814, Caroline left the United Kingdom for continental Europe, but she chose to return for her husband's coronation, and to publicly assert her rights as queen consort. However, George IV refused to recognise Caroline as Queen, and commanded British ambassadors to ensure that monarchs in foreign courts did the same. By royal command, Caroline's name was omitted from the Book of Common Prayer, the liturgy of the Church of England. The King sought a divorce, but his advisors suggested that any divorce proceedings might involve the publication of details relating to the King's own adulterous relationships. Therefore, he requested and ensured the introduction of the Pains and Penalties Bill, under which Parliament could have imposed legal penalties without a trial in a court of law. The bill would have annulled the marriage and stripped Caroline of the title of Queen. The bill proved extremely unpopular with the public, and was withdrawn from Parliament. George IV decided, nonetheless, to exclude his wife from his coronation at Westminster Abbey, on 19 July 1821. Caroline fell ill that day and died on 7 August; during her final illness she often stated that she thought she had been poisoned.
George's coronation was a magnificent and expensive affair, costing about £243,000 (approximately £ in 2015; for comparison, his father's coronation had only cost about £10,000, less than a twentieth of George IV's). Despite the enormous cost, it was a popular event. In 1821 the King became the first monarch to pay a state visit to Ireland since Richard II of England. The following year he visited Edinburgh for "one and twenty daft days". His visit to Scotland, organised by Sir Walter Scott, was the first by a reigning British monarch since the mid-17th century.
George IV spent most of his later reign in seclusion at Windsor Castle, but he continued to intervene in politics. At first it was believed that he would support Catholic emancipation, as he had proposed a Catholic Emancipation Bill for Ireland in 1797, but his anti-Catholic views became clear in 1813 when he privately canvassed against the ultimately defeated Catholic Relief Bill of 1813. By 1824 he was denouncing Catholic emancipation in public. Having taken the coronation oath on his accession, George now argued that he had sworn to uphold the Protestant faith, and could not support any pro-Catholic measures. The influence of the Crown was so great, and the will of the Tories under Prime Minister Lord Liverpool so strong, that Catholic emancipation seemed hopeless. In 1827, however, Lord Liverpool retired, to be replaced by the pro-emancipation Tory George Canning. When Canning entered office, the King, hitherto content with privately instructing his ministers on the Catholic Question, thought it fit to make a public declaration to the effect that his sentiments on the question were those of his revered father, George III.
Canning's views on the Catholic Question were not well received by the most conservative Tories, including the Duke of Wellington. As a result the ministry was forced to include Whigs. Canning died later in that year, leaving Frederick Robinson, 1st Viscount Goderich, to lead the tenuous Tory-Whig coalition. Lord Goderich left office in 1828, to be succeeded by the Duke of Wellington, who had by that time accepted that the denial of some measure of relief to Roman Catholics was politically untenable. George was never as friendly with Wellington as he had been with Canning and chose to annoy the Duke by pretending to have fought at Waterloo disguised as a German general. With great difficulty Wellington obtained the King's consent to the introduction of a Catholic Relief Bill on 29 January 1829. Under pressure from his fanatically anti-Catholic brother, the Duke of Cumberland, the King withdrew his approval and in protest the Cabinet resigned "en masse" on 4 March. The next day the King, now under intense political pressure, reluctantly agreed to the Bill and the ministry remained in power. Royal Assent was finally granted to the Catholic Relief Act on 13 April.
Decline and death.
George's heavy drinking and indulgent lifestyle had taken their toll on his health by the late 1820s. Through huge banquets and copious amounts of alcohol, he had become obese, making him the target of ridicule on the rare occasions that he appeared in public. By 1797 his weight had reached 17 st, and by 1824 his corset was made for a waist of 50 in. He suffered from gout, arteriosclerosis, peripheral edema ("dropsy"), and possibly porphyria. In his last years, he spent whole days in bed and suffered spasms of breathlessness that would leave him half-asphyxiated. By December 1828, like his father, he was almost completely blind from cataracts, and was suffering from such severe gout in his right hand and arm that he could no longer sign documents. In mid-1829, Sir David Wilkie reported the King "was wasting away frightfully day after day", and had become so obese that he looked "like a great sausage stuffed into the covering". The King took laudanum to counteract severe bladder pains, which left him in a drugged and mentally handicapped state for days on end.
By the spring of 1830, George's imminent end was apparent. Attacks of breathlessness due to dropsy forced him to sleep upright in a chair, and doctors frequently tapped his abdomen to drain excess fluid. He was admired for clinging doggedly to life despite his obvious decline. He dictated his will in May and became very devout in his final months, confessing to an archdeacon that he repented of his early dissolute life, but hoped mercy would be shown to him as he had always tried to do the best for his subjects. At about half-past three in the morning of 26 June 1830 at Windsor Castle, he reportedly called out "Good God, what is this?", clasped his page's hand and said "my boy, this is death", after which he died. An autopsy conducted by his physicians revealed he had died from upper gastrointestinal bleeding resulting from the rupture of a blood vessel in his stomach (gastric varices). A large tumour "the size of an orange" was found attached to his bladder, and he had an enlarged heart surrounded by a large fat deposit and heavily calcified heart valves. He was buried in St George's Chapel, Windsor Castle, on 15 July.
His only legitimate child, Princess Charlotte of Wales, had died from post-partum complications in 1817, after delivering a still-born son. The second son of George III, Prince Frederick, Duke of York and Albany, had died childless in 1827, so the succession passed to the third son of George III, Prince William, Duke of Clarence, who reigned as William IV.
Legacy.
George's last years were marked by increasing physical and mental decay and withdrawal from public affairs. Privately a senior aide to the King confided to his diary: "A more contemptible, cowardly, selfish, unfeeling dog does not exist ... There have been good and wise kings but not many of them ... and this I believe to be one of the worst." On his death "The Times" captured elite opinion succinctly: "There never was an individual less regretted by his fellow-creatures than this deceased king. What eye has wept for him? What heart has heaved one throb of unmercenary sorrow? ... If he ever had a friend – a devoted friend in any rank of life – we protest that the name of him or her never reached us." George IV was described as the "First Gentleman of England" on account of his style and manners. He possessed many good qualities; he was bright, clever, and knowledgeable. However, his laziness and gluttony led him to squander much of his talent. "The Times" wrote, he would always prefer "a girl and a bottle to politics and a sermon".
The Regency period saw a shift in fashion that was largely determined by George. After political opponents put a tax on wig powder, he abandoned wearing a powdered wig in favour of natural hair. He wore darker colours than had been previously fashionable as they helped to disguise his size, favoured pantaloons and trousers over knee breeches because they were looser, and popularised a high collar with neck cloth because it hid his double chin. His visit to Scotland in 1822 led to the revival, if not the creation, of Scottish tartan dress as it is known today.
During the political crisis caused by Catholic emancipation, the Duke of Wellington said that George was "the worst man he ever fell in with his whole life, the most selfish, the most false, the most ill-natured, the most entirely without one redeeming quality", but his eulogy delivered in the House of Lords called George "the most accomplished man of his age" and praised his knowledge and talent. Wellington's true feelings probably lie somewhere between these two extremes; as he said later, George was "a magnificent patron of the arts ... the most extraordinary compound of talent, wit, buffoonery, obstinacy, and good feeling—in short a medley of the most opposite qualities, with a great preponderence of good—that I ever saw in any character in my life."
There are many statues of George IV, a large number of which were erected during his reign. In the United Kingdom, they include a bronze statue of him on horseback by Sir Francis Chantrey in Trafalgar Square and another outside the Royal Pavilion in Brighton.
In Edinburgh, "George IV Bridge" is a main street linking the Old Town High Street to the north over the ravine of the Cowgate, designed by the architect Thomas Hamilton in 1829 and completed in 1835. King's Cross, now a major transport hub sitting on the border of Camden and Islington in north London, takes its name from a short-lived monument erected to George IV in the early 1830s. A square and a neighbouring park in St Luke's, Islington, are also named after George IV.
Titles, styles, honours and arms.
Titles and styles.
Under the Act of Parliament that instituted the Regency, the Prince's formal title as Regent was "Regent of the United Kingdom of Great Britain and Ireland". The simplified style ""His Royal Highness" The Prince Regent" was more common even in official documents. George IV's official style as King of the United Kingdom was "George the Fourth, by the Grace of God, of the United Kingdom of Great Britain and Ireland King, Defender of the Faith". While heir apparent and before his accession as king, he was also the Crown Prince of Hanover.
Arms.
As Prince of Wales, George Augustus bore the royal arms (with an inescutcheon of Gules plain in the Hanoverian quarter), differenced by a label of three points Argent. The arms included the royal crest and supporters but with the single arched coronet of his rank, all charged on the shoulder with a similar label. His arms followed the change in the royal arms in 1801, when the Hanoverian quarter became an inescutcheon and the French quarter was dropped altogether. The 1816 alteration did not affect him as it only applied to the arms of the King.
As king his arms were those of his two kingdoms, the United Kingdom and Hanover, superimposed: Quarterly, I and IV Gules three lions passant guardant in pale Or (for England); II Or a lion rampant within a double tressure flory-counter-flory Gules (for Scotland); III Azure a harp Or stringed Argent (for Ireland); overall an escutcheon tierced in pall reversed (for Hanover), I Gules two lions passant guardant Or (for Brunswick), II Or a semy of hearts Gules a lion rampant Azure (for Lüneburg), III Gules a horse courant Argent (for Westphalia), overall an inescutcheon Gules charged with the crown of Charlemagne Or, the whole escutcheon surmounted by a crown.

</doc>
<doc id="40226" url="http://en.wikipedia.org/wiki?curid=40226" title="Rocket sled">
Rocket sled

A rocket sled is a test platform that slides along a set of rails, propelled by rockets. 
As its name implies, a rocket sled does not use wheels. Instead, it has sliding pads, called "slippers", which are curved around the head of the rails to prevent the sled from flying off the track. The rail cross-section profile is that of a Vignoles rail, commonly used for railroads.
A rocket sled holds the land-based speed record for a vehicle, at Mach 8.5.
Usage.
A rocket sled is reported to have been used in the closing days of World War II by the Germans to launch a winged A4b strategic rocket from an underground tunnel on March 16, 1945.
Rocket sleds were used extensively by the United States early in the Cold War to accelerate equipment considered too experimental (hazardous) for testing directly in piloted aircraft. The equipment to be tested under high acceleration or high airspeed conditions was installed along with appropriate instrumentation, data recording and telemetry equipment on the sled. The sled was then accelerated according to the experiment's design requirements for data collection along a length of isolated, precisely level and straight test track.
Testing ejection seat systems and technology prior to their use in experimental or operational aircraft was a common application of the rocket sled at Holloman Air Force Base. Perhaps the most famous, the tracks at Edwards Air Force Base were used to test missiles, supersonic ejection seats, aircraft shapes and the effects of acceleration and deceleration on humans. The rocket sled track at Edwards Air Force Base was dismantled and used to extend the track at Holloman Air Force Base, taking it to almost 10 miles in length.
Unmanned rocket sleds continue to be used to test missile components without requiring costly live missile launches. A world speed record of Mach 8.5 (6,416 mph / 10,325 km/h) was achieved by a four-stage rocket sled at Holloman Air Force Base on April 30, 2003.
Murphy's law first received public attention during a press conference about rocket sled testing.

</doc>
<doc id="40228" url="http://en.wikipedia.org/wiki?curid=40228" title="Archeology in Algeria">
Archeology in Algeria

Algeria is rich in prehistoric memorials of human occupation, especially in megalithic remains, of which nearly every known kind has been found in the country. Numerous flints of palaeolithic type have been discovered, notably at Tlemcen and Kolea. Near Djelfa, in the Great Atlas, and at Mechra-Sfa ("ford of the flat stones"), a peninsula in the valley of the river Mina not far from Tiaret, are vast numbers of megalithic monuments. Notable among the prehistoric cultures of the area is the Capsian culture, whose shell-mounds are found throughout the north.
In the Qabr-er-Rumia-- "grave of the Roman lady," "Roman" being used by the Arabs to designate strangers of Christian origin—the Madghacen, and the Jedars, Algeria possesses a remarkable series of sepulchral monuments.
The Qabr-er-Rumia-- best known by its French name, "Tombeau de la Chrétienne", tradition making it the burial-place of Florinda, "la Cava Rumía", the beautiful and unfortunate daughter of Count Julian—is near Kolea, and is known to be the tomb of the Mauretanian king Juba II and of his wife Cleopatra Selene, daughter of Mark Antony and Cleopatra, queen of Egypt. It is built on a hill 756 ft above the sea. A circular stone building surmounted by a pyramid rests on a lower platform, 209 ft square. Originally the monument was about 130 ft in height, but it has been wantonly damaged. Its height is now 100 ft: the cylindrical portion 36 ft, the pyramid 64 ft The base, 198 ft in diameter, is ornamented with 60 engaged Ionic columns. The capitals of the columns have disappeared, but their design is preserved among the drawings of James Bruce, the African traveller. In the centre of the tomb are two vaulted chambers, reached by a spiral passage or gallery 6+1/2 ft, about the same height, and 489 ft. The sepulchral chambers are separated by a short passage, and are cut off from the gallery by stone doors made of a single slab which can be moved up and down by levers, like a portcullis. The larger of the two chambers is 142 ft long by 11 ft broad and 11 ft high. The other chamber is somewhat smaller. The tomb was early violated, probably in search of treasure. In 1555 Salah Rais, pasha of Algiers, set men to work to pull it down, but the records say that the attempt was given up because big black wasps came from under the stones and stung them to death. At the end of the 18th century Baba Mahommed tried in vain to batter down the tomb with artillery. In 1866 it was explored by order of the emperor Napoleon III, the work being carried out by Adrien Berbrugger and Oscar Maccarthy.
Madghacen is a monument similar to the Qabr-er-Rumia, but older. It was built about 150 B.C. as the burial-place of the Numidian kings, and is situated 35 mi southwest of Constantine. The form is that of a truncated cone, placed on a cylindrical base, 196 ft in diameter. It is 60 ft high. The columns encircling the cylindrical portion are stunted and much broader at the base than the top; the capitals are Doric. Many of the columns, 60 in number, have been much damaged. When the sepulchral chamber was opened in 1873 by Bauchetet, a French engineer officer, clear evidence was found that at some remote period the tomb had been rifled and an attempt made to destroy it by fire.
The Jedars (Arabic "walls" or "buildings") is the name given to a number of sepulchral monuments placed on hill-tops. A rectangular or square podium is in each case surmounted by a pyramid. The tombs date from the 5th to the 7th century of the Christian era, and lie in two distinct groups between Tiaret and Frenda. Frenda, which has largely preserved its old Berber character, has numerous dolmens and prehistoric rock sculptures close by.
Algeria contains many Roman remains besides those mentioned and is also rich in monuments of Saracenic art. For a description of the chief antiquities see the separate town articles, including, besides those already cited, Lambessa, Tebessa, Tipasa and Timgad.

</doc>
<doc id="40229" url="http://en.wikipedia.org/wiki?curid=40229" title="Geography of Algeria">
Geography of Algeria

Algeria comprises 2,381,741 square kilometers of land, more than four-fifths of which is desert, in northern Africa, between Morocco and Tunisia. It is the largest country in Africa. Its Arabic name, Al Jazair (the islands), derives from the name of the capital Algiers ("Al Jazair" in Arabic), after the small islands formerly found in its harbor. It has a long Mediterranean coastline, most of which is more properly termed the Alboran Sea, which is the westernmost element of the Mediterranean Sea. The northern portion, an area of mountains, valleys, and plateaus between the Mediterranean Sea and the Sahara Desert, forms an integral part of the section of North Africa known as the Maghreb. This area includes Morocco, Tunisia, and the northwestern portion of Libya known historically as Tripolitania.
Geographic coordinates: 
Size and boundaries.
Land boundaries:<br>
"total:" 6,764 km<br>
"border countries:" Libya 989 km, Mali 1,359 km, Mauritania 460 km, Morocco 1,900 km, Niger 951 km, Tunisia 1,034 km, Western Sahara 41 km
Area - comparative: roughly 3.5 times the size of Texas and twice the size of Ontario
Coastline: 998 km
Maritime claims:<br>
"exclusive fishing zone:" 32 -<br>
"territorial sea:" 12 nmi
Geographic regions.
Tell Atlas, High Plateaus and the Saharan Atlas.
Stretching from the Moroccan border the Tell Atlas, including the Djebel Babor formation, is the dominant northwestern mountain range. Stretching more than 600 kilometers eastward from the Moroccan border, the high plateau area (often referred to by the French name "Hautes Plaines" or "Hauts Plateaux") consist of undulating, steppe-like plains lying between the Tell and Saharan Atlas ranges. The elevation averages between 1,100 and 1,300 meters in elevation in the west, dropping to 400 meters in the east. The climate is so dry that these plains are sometimes thought of as part of the Sahara. The plateau are is covered by alluvial debris formed when the mountains eroded. An occasional ridge projects through the alluvial cover to interrupt the monotony of the landscape.
Higher and more continuous than the Tell Atlas, the Sahara Atlas range is formed of three massifs: the Ksour Range near the Moroccan border, the Amour Range, and the Ouled-Naïl Range south of Algiers. The mountains, which receive more rainfall than those of the High Plateaus, include some good grazing land. Watercourses on the southern slopes of these massifs disappear into the desert but supply the wells of numerous oases along the northern edge of the desert, of which Biskra, Laghouat, and Béchar are the most prominent.
Northeastern Algeria.
Eastern Algeria consists of a massive area extensively dissected into mountains, plains, and basins. It differs from the western portion of the country in that its prominent topographic features do not parallel the coast. In its southern sector, the steep cliffs and long ridges of the Aurès Mountains create an almost impenetrable refuge that has played an important part in the history of the Maghrib since Roman times. Near the northern coast, the Petite Kabylie Mountains are separated from the Grande Kabylie range at the eastward limits of the Tell by the Soummam River. The coast is predominantly mountainous in the far eastern part of the country, but limited plains provide hinterlands for the port cities of Bejaïa, Skikda, and Annaba. In the interior of the region, extensive high plains mark the region around Sétif and Constantine; these plains were developed during the French colonial period as the principal centers of grain cultivation. Near Constantine, salt marshes offer seasonal grazing grounds to seminomadic sheep herders.
The Sahara.
The Algerian portion of the Sahara extends south of the Saharan Atlas for 1,500 kilometers to the Niger and Mali frontiers. The desert is an otherworldly place, scarcely considered an integral part of the country. Far from being covered wholly by sweeps of sand, however, it is a region of great diversity. Immense areas of sand dunes called areg (sing., erg) occupy about one-quarter of the territory. The largest such region is the Grand Erg Oriental (Great Eastern Erg), where enormous dunes two to five meters high are spaced about 40 meters apart. Much of the remainder of the desert is covered by rocky platforms called humud (sing., hamada), and almost the entire southeastern quarter is taken up by the high, complex mass of the Ahaggar and Tassili n'Ajjer highlands, some parts of which reach more than 2,000 meters. Surrounding the Ahaggar are sandstone plateaus, cut into deep gorges by ancient rivers, and to the west a desert of pebbles stretches to the Mali frontier.
The desert consists of readily distinguishable northern and southern sectors, the northern sector extending southward a little less than half the distance to the Niger and Mali frontiers. The north, less arid than the south, supports most of the few persons who live in the region and contains most of the desert's oases. Sand dunes are the most prominent features of this area's topography, but between the desert areas of the Grand Erg Oriental and the Grand Erg Occidental (Great Western Erg) and extending north to the Atlas Saharien are plateaus, including the Tademaït and a complex limestone structure called the M'zab where the Mozabite Berbers have settled. The southern zone of the Sahara is almost totally arid and is inhabited only by the Tuareg nomads and, recently, by oil camp workers. Barren rock predominates, but in some parts of Ahaggar and Tassili n'Ajjer alluvial deposits permit garden farming.
Climate and hydrology.
Northern Algeria is in the temperate zone and enjoys a mild, Mediterranean climate. It lies within approximately the same latitudes as southern California and has somewhat similar climatic conditions. Its broken topography, however, provides sharp local contrasts in both prevailing temperatures and incidence of rainfall. Year-to-year variations in climatic conditions are also common.
In the Tell, temperatures in summer average between 21 and and in winter drop to 10 to. Winters are not cold, but the humidity is high and houses are seldom adequately heated. In eastern Algeria, the average temperatures are somewhat lower, and on the steppes of the High Plateaus winter temperatures hover only a few degrees above freezing. A prominent feature of the climate in this region is the sirocco, a dusty, choking south wind blowing off the desert, sometimes at gale force. This wind also occasionally reaches into the coastal Tell.
In Algeria only a relatively small corner of the Sahara lies across the Tropic of Cancer in the torrid zone, but even in winter, midday desert temperatures can be very hot. After sunset, however, the clear, dry air permits rapid loss of heat, and the nights are cool to chilly. Enormous daily ranges in temperature are recorded.
Rainfall is fairly abundant along the coastal part of the Tell, ranging from 400 to annually, the amount of precipitation increasing from west to east. Precipitation is heaviest in the northern part of eastern Algeria, where it reaches as much as 1000 mm in some years. Farther inland the rainfall is less plentiful. Prevailing winds that are easterly and northeasterly in summer change to westerly and northerly in winter and carry with them a general increase in precipitation from September to December, a decrease in the late winter and spring months, and a near absence of rainfall during the summer months.
Terrain.
Clearing of land for agricultural use and cutting of timber over the centuries have severely reduced the once bountiful forest wealth. Forest fires have also taken their toll. In the higher and wetter portions of the Tell Atlas, cork oak and Aleppo pine grow in thick soils. At lower levels on thinner soils, drought-resistant shrubs predominate. The grapevine is indigenous to the coastal lowlands, and grasses and scrub cover the High Plateaus. On the Saharan Atlas, little survives of the once extensive forests of Atlas cedar that have been exploited for fuel and timber since antiquity.
The forest reserves in Algeria were severely reduced during the colonial period. In 1967 it was calculated that the country's forested area extended over no more than 24,000 square kilometres of terrain, of which 18,000 km2 were overgrown with brushwood and scrub. By contrast, woodlands in 1830 had covered 50,000 km2. In the mid-1970s, however, the government embarked on a vast reforestation program to help control erosion, which was estimated to affect 100,000 cubic meters of arable land annually. Among projects was one to create a barrage vert (green barrier) more or less following the ridge line of the Saharan Atlas and extending from Morocco to the Tunisian frontier in a zone 1,500 kilometers long and up to twenty kilometers wide.
The barrage vert consists principally of Aleppo pine, a species that can thrive in areas of scanty rainfall. It is designed to restore a damaged ecological balance and to halt the northern encroachment of the Sahara. By the early 1980s, the desert had already penetrated the hilly gap between the Saharan Atlas and the Aurès Mountains as far as the town of Bou Saâda, a point well within the High Plateaus region. The barrage vert project was ended in the late 1980s because of lack of funds.
Statistics.
Elevation extremes:<br>
"lowest point:" Chott Melrhir -40 m
"highest point:" Mount Tahat 3,003 m
Extreme Points<br>
"Northernmost Point" - Cap Bougaroûn, Skikda province<br>
"Easternmost Point" - Tripoint with Libya and Niger, Tamanghasset province<br>
"Southernmost Point" - unnamed location on the border with Mali, Adrar province<br>
"Westernmost Point" - N/A
Natural resources: petroleum, natural gas, iron ore, phosphates, uranium, lead, zinc
Land use:<br>
"arable land:" 3.71%
"permanent crops:" 0.39%<br>
"other:" 96.45% (2012)
Irrigated land: 5,694 km2 (2003)
Total renewable water resources: 11.67 km3 (2011)
Freshwater withdrawal (domestic/industrial/agricultural) <br>
"total:" 5.72 km3/yr (22%/13%/65%)<br>
"per capita:" 182 m3/yr (2005)
Natural hazards: mountainous areas subject to severe earthquakes; mudslides and floods in rainy season
Environment - current issues: soil erosion from overgrazing and other poor farming practices; desertification; dumping of raw sewage, petroleum refining wastes, and other industrial effluents is leading to the pollution of rivers and coastal waters; Mediterranean Sea, in particular, becoming polluted from oil wastes, soil erosion, and fertilizer runoff; inadequate supplies of potable water
Environment - international agreements:
"party to:" Biodiversity, Climate Change, Desertification, Endangered Species, Environmental Modification, Hazardous Wastes, Law of the Sea, Ozone Layer Protection, Ship Pollution, Wetlands signed, but not ratified: Nuclear Test Ban
Protected areas.
Algeria has a number of protected areas including National Parks and nature reserves. An example of such a protected area is the Djebel Babor Nature Reserve within the Djebel Babor Mountains; the Djebel Babor is also one of the few relict habitats for the endangered Barbary Macaque, "Macaca sylvanus".
The National Parks in Algeria are: Ahaggar, Belezma, Chréa, Djurdjura, El Kala, Gouraya, Tassili n'Ajjer, Taza, Théniet El Had, and Tlemcen.
Extreme points.
This is a list of the extreme points of Algeria, the points that are farther north, south, east or west than any other location.

</doc>
<doc id="40231" url="http://en.wikipedia.org/wiki?curid=40231" title="Politics of Algeria">
Politics of Algeria

Politics of Algeria takes place in a framework of a presidential republic, whereby the President of Algeria is head of state while the Prime Minister of Algeria is the head of government, and of a multi-party system. Executive power is exercised by the government. Legislative power is vested in both the government and the two chambers of parliament, the People's National Assembly and the Council of the Nation. Algeria has a long history of revolution and regime change, making the political climate dynamic and often in a state of transformation. The country is currently a constitutional republic with a democratically elected government, though the military, in practice, remain major powerbrokers along with "a select group" of unelected civilians. These “décideurs” are reportedly known to Algerians as “le pouvoir” (“the power”), make major decisions, including who should be president. Since the early 1990s, a shift from a socialist to a free market economy has been ongoing with official support.
History.
The civil war resulted in more than 100,000 deaths since 1991. Although the security situation in the country has greatly improved, addressing the underlying issues which brought about the political turmoil of the 1990s remains the government's major task. The government officially lifted the state of emergency declared in 1999.
Constitution.
Under the 1976 Constitution (as modified 1979, and amended in 1988, 1989, and 1996) Algeria is a multi-party state. All parties must be approved by the Ministry of the Interior. To date, Algeria has had more than 40 legal political parties. According to the Constitution, no political association may be formed if it is "based on differences in religion, language, race, gender, or region."
Informal power.
While many sources agree that the real power in Algeria is not held by its constitutional organs, they differ as to who/what does. According to the Economist magazine, the military, are major powerbrokers along with "a select group" of unelected civilians. These “décideurs” are reportedly known to Algerians as “le pouvoir” (“the power”), make major decisions, including who should be president. Adam Nossiter of the New York Times states "Algerian politics is still dominated" by men from the ruling party, the FLN, while Moroccan-Italian journalist Anna Mahjar-Barducci, writing in Haaretz, insists the FLN "is a group of apparatchiks constantly fighting each other when they're not tending to the businesses ... with which they have rewarded themselves from their positions of power". According to her real power is held by "the military's Department of Intelligence and Security (DRS)."
Executive branch.
The head of state is the President of the republic, who is elected to a 5-year term, renewable once (changed by the 2008 Constitution to an infinite mandate). Algeria has universal suffrage. The President is the head of the Council of Ministers and of the High Security Council. He appoints the Prime Minister who also is the head of government. The Prime Minister appoints the Council of Ministers.
Parliament of Algeria.
People's National Assembly.
The People's National Assembly has less power relative to the executive branch than many parliaments and has been described as "rubber-stamping" laws proposed by the president.
As of 2012 there were 462 seats in parliament. In the May 2012 election the government reported a 42.9% turnout, though the BBC reported that correspondents saw "only a trickle of voters" at polling places. In that election 44 political parties participated with the ruling National Liberation Front winning more than any other group—220 seats—and an alliance of moderate Islamists coming in second with 66 seats. The Islamists disputed the results.
Political parties and elections.
In keeping with its amended Constitution, the Algerian Government espouses participatory democracy and free-market competition. The government has stated that it will continue to open the political process and encourage the creation of political institutions. More than 40 political parties, representing a wide segment of the population, are currently active in Algerian national politics. The most recent legislative election was 2007. President Bouteflika has pledged to restructure the state as part of his overall reform efforts. However, no specifics are yet available as to how such reforms would affect political structures and the political process itself.
In the 2002 elections, there were 17,951,127 eligible voters, and 8,288,536 of them actually voted which made a turn out of 46.17%. Out of the ballots cast, there were 867,669 void ballots according to the Interior ministry and 7,420,867 which went to the various candidates.
Legislative elections.
The most recent legislative election now is the 2012 one:
Administrative divisions.
Algeria is divided into 48 wilaya (province) headed by walis (governors) who report to the Minister of Interior. Each wilaya is further divided into daïras, themselves divided in communes. The wilayas and communes are each governed by an elected assembly.
Media.
Algeria has more than 30 daily newspapers published in French and Arabic, with a total publication run of more than 1.5 million copies. Although relatively free to write as they choose, in 2001, the government amended the penal code provisions relating to defamation and slander, a step widely viewed as an effort to rein in the press. Government monopoly of newsprint and advertising is seen as another means to influence the press, although it has permitted newspapers to create their own printing distribution networks..
See also List of Algerian newspapers.
Future Concerns.
Population growth and associated problems—unemployment and underemployment, inability of social services to keep pace with rapid urban migration, inadequate industrial management and productivity, a decaying infrastructure—continue to plague Algerian society. Increases in the production and prices of oil and gas over the past decade have led to a budgetary surplus of close to $20 billion[Citation Needed]. The government began an economic reform program in 1993 which focuses on macroeconomic stability and structural reform. These reforms are aimed at liberalizing the economy, making Algeria competitive in the global market, and meeting the needs of the Algerian people.
International organization participation.
AU, ABEDA, AfDB, AFESD, AL, AMF, AMU, ECA, FAO, G-15, G-19, G-24, G-77, IAEA, IBRD, ICAO, ICFTU, ICRM, IDA, IDB, IFAD, IFC, IFRCS, IHO, ILO, IMF, International Maritime Organization, Inmarsat, Intelsat, Interpol, IOC, IOM (observer), ISO, ITU, MONUC, NAM, OAPEC, OAS (observer), OIC, OPCW, OPEC, OSCE (partner), UN, UNCTAD, UNESCO, UNHCR, UNIDO, UNWTO, UPU, WCL, WCO, WHO, WIPO, WMO, WTO (applicant)

</doc>
<doc id="40232" url="http://en.wikipedia.org/wiki?curid=40232" title="Steve Goodman">
Steve Goodman

Steven Benjamin Goodman (July 25, 1948 – September 20, 1984) – known as Steve Goodman – was an American folk music singer-songwriter from Chicago. Goodman was diagnosed with leukemia while attending college, and he set out to make the most of the time he had left to write music. Hearing a report that the Illinois Central Railroad was planning to eliminate, for lack of riders, a well-loved train that ran from Chicago to New Orleans, Goodman, a prolific writer, penned "City of New Orleans," a song made popular by Arlo Guthrie and Willie Nelson, for which Goodman won his first Grammy Award posthumously in 1985, with a second Grammy awarded to him in 1988 for "Unfinished Business". Steven Goodman is survived by his wife and three daughters.
Personal life.
Born on Chicago's North Side to a middle-class Jewish family, Goodman began writing and performing songs as a teenager, after his family had moved to the near north suburbs. He graduated from Maine East High School in Park Ridge, Illinois in 1965, where he was a classmate of Hillary Rodham Clinton. In the fall of 1965, he entered the University of Illinois and pledged Sigma Alpha Mu (Sammies) fraternity where he, Ron Banyon, and Steve Hartmann formed a popular rock cover band, "The Juicy Fruits". He left college after one year to pursue his musical career. In the early spring of 1967 Goodman went to New York, staying for a month in a Greenwich Village brownstone across the street from the Cafe Wha? where Goodman performed regularly during his brief stay there. Returning to Chicago he intended to restart his education but he dropped out again to pursue his musical dream full-time after discovering the cause of his continuous fatigue was actually leukemia, the disease that was present during the entirety of his recording career, until his death in 1984. In 1968 Goodman began performing at the Earl of Old Town in Chicago and attracted a following.
By 1969, Goodman was a regular performer in Chicago, while attending Lake Forest College. During this time Goodman supported himself by singing advertising jingles.
In September 1969 he met Nancy Pruter (sister of R&B writer Robert Pruter), who was attending college while supporting herself as a waitress. They were married in February 1970. Though he experienced periods of remission, Goodman never felt that he was living on anything other than borrowed time, and some critics, listeners and friends have said that his music reflects this sentiment. His wife Nancy, writing in the liner notes to the posthumous collection "No Big Surprise", characterized him this way:
"Basically, Steve was exactly who he appeared to be: an ambitious, well-adjusted man from a loving, middle-class Jewish home in the Chicago suburbs, whose life and talent were directed by the physical pain and time constraints of a fatal disease which he kept at bay, at times, seemingly by willpower alone . . . Steve wanted to live as normal a life as possible, only he had to live it as fast as he could . . . He extracted meaning from the mundane."
Musical career.
Goodman's songs first appeared on "Gathering at The Earl of Old Town", an album produced by Chicago record company Dunwich in 1971. As a close friend of Earl Pionke, the owner of the folk music bar, Goodman performed at The Earl dozens of times, including customary New Year's Eve concerts. He also remained closely involved with Chicago's Old Town School of Folk Music, where he had met and mentored his good friend, John Prine.
Later in 1971, Goodman was playing at a Chicago bar called the Quiet Knight as the opening act for Kris Kristofferson. Kristofferson, impressed with Goodman, introduced him to Paul Anka, who brought Goodman to New York to record some demos. 
These resulted in Goodman signing a contract with Buddah Records.
All this time, Goodman had been busy writing many of his most enduring songs, and this avid songwriting would lead to an important break for him. While at the Quiet Knight, Goodman saw Arlo Guthrie, and asked to sit in and play a song for him. Guthrie grudgingly agreed, on the condition that Goodman buy him a beer first; Guthrie would listen to Goodman for as long as it took Guthrie to drink the beer. Goodman played "City of New Orleans", which Guthrie liked enough that he asked to record it.
Guthrie's version of Goodman's song became a Top-20 hit in 1972, and provided Goodman with enough financial and artistic success to make his music a full-time career. The song, about the Illinois Central's "City of New Orleans" train, would become an American standard, covered by such musicians as Johnny Cash, Judy Collins, Chet Atkins, Lynn Anderson, and Willie Nelson, whose recorded version earned Goodman a posthumous Grammy Award for Best Country Song in 1985. A French translation of the song, "Salut Les Amoureux", was recorded by Joe Dassin in 1973. A Dutch singer, Gerard Cox, heard the French version while on holiday and translated it into Dutch, titled "'t Is Weer Voorbij Die Mooie Zomer" ("The summer has come to an end"). It reached number one on the Dutch Top 40 in December 1973 and has become a classic which is still played on Dutch radio. 
Lyrically, the French and Dutch versions bear no resemblance to Goodman's original lyrics. According to Goodman, the song was inspired by a train trip he and his wife took from Chicago to Mattoon, Illinois. According to the liner notes on the Steve Goodman anthology " No Big Surprise " ... " City of New Orleans " was written while on the campaign trail with Senator Edmund Muskie.
In 1974, singer David Allan Coe achieved considerable success on the country charts with Goodman's and John Prine's "You Never Even Called Me by My Name", a song which good-naturedly spoofed stereotypical country music lyrics. Prine refused to take a songwriter's credit of the song, although Goodman bought Prine a jukebox as a gift from his publishing royalties.
Goodman's success as a recording artist was more limited. Although he was known in folk circles as an excellent and influential songwriter, his albums received more critical than commercial success. One of Goodman's biggest hits was a song he didn't write – "The Dutchman", written by Michael Peter Smith. He reached a wider audience as the opening act for Steve Martin while Martin was at the height of his stand-up popularity.
During the mid- and late seventies, Goodman became a regular guest on Easter Day on Vin Scelsa's radio show in New York City. Scelsa's personal recordings of these sessions eventually led to an album of selections from these appearances, "The Easter Tapes".
In 1977, Goodman performed on the Tom Paxton live album "New Songs From the Briarpatch" (Vanguard Records), which contained some of Paxton's topical songs of the 1970s, including "Talking Watergate" and "White Bones of Allende", as well as a song dedicated to Mississippi John Hurt entitled "Did You Hear John Hurt?"
During the fall of 1979, Goodman was hired to write and perform a series of topical songs for National Public Radio. Although Goodman and Jethro Burns recorded eleven songs for the series, only five of them, "The Ballad of Flight 191" about a plane crash, "Daley's Gone", "Unemployed", "The Twentieth Century is Almost Over", and "The Election Year Rag", were used on the air before the series was cancelled.
Goodman wrote and performed many humorous songs about Chicago, including three about the Chicago Cubs: "A Dying Cub Fan's Last Request", "When the Cubs Go Marching In" and "Go, Cubs, Go" (which has frequently been played on Cubs' broadcasts and at Wrigley Field after Cubs wins.) He wrote "Go, Cubs, Go" out of spite after then GM Dallas Green called "A Dying Cub Fan's Last Request" too depressing. The Cubs songs grew out of his fanatical devotion to the team, which included many clubhouse and on-field visits with Cubs players. He wrote other songs about Chicago, including "The Lincoln Park Pirates", about the notorious Lincoln Towing Service, and "Daley's Gone", about Mayor Richard J. Daley. Another comic highlight is "Vegematic", about a man who falls asleep while watching late-night TV and dreams he ordered many products that he saw on infomercials. He could also write serious songs, most notably "My Old Man", a tribute to Goodman's father, Bud Goodman, a used car salesman and World War II veteran.
Goodman won his second Grammy, for Best Contemporary Folk Album, in 1988 for "Unfinished Business", a posthumous album on his Red Pajamas Records label.
Many fans become aware of Goodman's work through other artists such as Jimmy Buffett. Buffett has recorded several of Goodman's songs, including "Banana Republics" and "Woman Goin' Crazy on Caroline Street".
Death.
On September 20, 1984, Goodman died of leukemia at the University of Washington Medical Center in Seattle, Washington. He had anointed himself with the tongue-in-cheek nickname "Cool Hand Leuk" (other nicknames included "Chicago Shorty" and "The Little Prince") during his illness. He was 36.
Four days after Goodman's death, the Chicago Cubs clinched the Eastern Division title in the National League for the first time ever, earning them their first post-season appearance since 1945, three years before Goodman's birth. Eight days later, on October 2, the Cubs played their first post-season game since the 1945 World Series. Goodman had been asked to sing "The Star-Spangled Banner" before it; Jimmy Buffett filled in, and dedicated the song to Goodman. Today, the Chicago Cubs plays "Go, Cubs, Go" at the conclusion of every home game win, a song Goodman wrote for his beloved team.
In April 1988, some of Goodman's ashes were scattered at Wrigley Field, the home of the Chicago Cubs. He was survived by his wife and three daughters.
Legacy.
In 2006, Goodman's daughter, Rosanna, issued "My Old Man", an album of a variety of artists covering her father's songs.
Interest in Goodman's career had a resurgence in 2007 with the publication of a biography by Clay Eals, "". The same year, the Chicago Cubs began playing Goodman's 1984 song "Go, Cubs, Go" after each home game win. When the Cubs made it to the playoffs, interest in the song and Goodman resulted in several newspaper articles about Goodman. Illinois Lieutenant Governor Pat Quinn declared October 5, 2007, Steve Goodman Day in the state. In 2010, Illinois Representative Mike Quigley introduced a bill renaming the Lakeview post office on Irving Park Road in honor of Goodman. The bill was signed by President Barack Obama on August 3, 2010.

</doc>
<doc id="40233" url="http://en.wikipedia.org/wiki?curid=40233" title="Madness (band)">
Madness (band)

Madness are an English ska band from Camden Town, London, that formed in 1976. One of the most prominent bands of the late 1970s and early 1980s 2 Tone ska revival, they continue to perform with their most recognised line-up of seven members.
Madness achieved most of their success in the early to mid-1980s. Both Madness and UB40 spent 214 weeks on the UK singles charts over the course of the decade, holding the record for most weeks spent by a group in the 1980s UK singles charts. However, Madness achieved this in a shorter time period (1980–1986).
Madness have had 15 singles reach the UK top ten, one UK number one single ("House of Fun") and two number ones in Ireland, "House of Fun" and "Wings of a Dove".
Career.
1976–1978: Formation.
The core of the band formed as The North London Invaders in 1976, and included Mike Barson (Monsieur Barso) on keyboards and vocals, Chris Foreman (Chrissy Boy) on guitar and Lee Thompson (Kix) on saxophone and vocals. They later recruited John Hasler on drums and Cathal Smyth (better known as Chas Smash) on bass guitar. Later in the year, they were joined by lead vocalist Dikron Tulane.
This six-piece line-up lasted until part way through 1977, when Graham McPherson (better known as Suggs) took over the lead vocals after seeing the band perform in a friend's garden. Dikron went on to be an actor under the name Dikran Tulaine. Smyth, who left after an argument with Mike Barson, was replaced by Gavin Rodgers, Barson's girlfriend's brother. McPherson was kicked out of the band for too often choosing to watch Chelsea instead of rehearsing. Thompson left the band after Barson criticised his saxophone playing.
By 1978, the band had allowed McPherson to return, after filling in temporarily for Hasler (who had taken over vocals when McPherson was removed). Thompson returned after patching things up with Barson, and Daniel Woodgate (Woody) and Mark Bedford (Bedders) also joined the band, on drums, replacing Garry Dovey, and bass guitar, replacing Gavin Rodgers, respectively. After briefly changing their name to Morris and the Minors, the band renamed itself as Madness in 1979, paying homage to one of their favourite songs by ska/reggae artist Prince Buster. The band remained a sextet until late 1979, when Chas Smash rejoined and officially became the seventh member of Madness as a backing vocalist and dancer.
1979–1981: Early success.
In 1979, the band recorded the Lee Thompson composition "The Prince". The song, like the band's name, paid homage to their idol, Prince Buster. The song was released through 2 Tone Records, the label of The Specials founder Jerry Dammers. The song was a surprise hit, peaking in the UK music charts at number 16. A performance of "The Prince" on popular UK music show "Top of the Pops" helped Madness gain public recognition. Madness then toured with fellow 2 Tone bands The Specials and The Selecter, before recording their debut album.
That debut album, "One Step Beyond..." was released by Stiff Records. The album included a re-recording of "The Prince" and its B-side "Madness", and the band's second and third singles: "One Step Beyond" and "My Girl". The title song was a cover of the B-side of the 1960s Prince Buster hit "Al Capone". "One Step Beyond..." stayed in the British charts for 78 weeks, peaking at number 2. After the release of "My Girl", the band felt that they had exhausted the material from "One Step Beyond...", and did not want to release any more singles from the album. However, Dave Robinson, head of Stiff Records, disagreed. Eventually, a compromise was made, and the band decided to release an EP featuring one album track and three new tracks. The result was the "Work Rest and Play" EP, which was headlined by the song "Night Boat to Cairo", from the "One Step Beyond" album. The EP reached number 6 in the UK singles chart.
Live recordings of Madness performances as well as those by other 2 Tone bands were used in the documentary film and soundtrack album "Dance Craze".
In 1980, the band's second album, "Absolutely" reached number 2 in the UK album charts. "Absolutely" spawned some of the band's biggest hits, most notably "Baggy Trousers", which peaked at number 3 in the UK singles chart. "Embarrassment" reached number 4 in the charts, and the instrumental song "Return of the Los Palmas 7" climbed to number 7. Although the album reviews were generally less enthusiastic than those of "One Step Beyond...", they were mostly positive. Robert Christgau gave the album a favourable B- grade, but "Rolling Stone" awarded the album just one out of five stars. "Rolling Stone" was particularly scathing of the ska revival in general, stating that ""The Specials" wasn't very good" and Madness were simply "the Blues Brothers with English accents".
A drama-documentary film entitled "Take It or Leave It" was released in 1981, featuring the band members playing themselves in a re-creation of their early days to the then-current period.
1981–1983: Change of direction.
In 1981, the band's third studio album, "7", reached number 5 in the UK album charts and contained three hit singles: "Grey Day" (no. 4, April 1981), "Shut Up" (no. 7, September 1981), and "Cardiac Arrest" (no. 14, February 1982). In an article in 1979, Chris Foreman explained that the band's music would move with the times, and change styles as time goes on. This was shown to be the case, as unlike the two ska-filled, fast-paced albums that preceded it, "7" was something of a change in direction. Suggs' vocal performance changed significantly, and his strong accent from the previous albums had been watered down. The album strayed from the ska-influenced sound of "One Step Beyond..." and "Absolutely", and moved towards a pop sound; a trend that continued with subsequent albums.
Near the end of 1981, Madness released one of their most recognised songs: a cover of Labi Siffre's 1971 hit "It Must Be Love". The song climbed to number 4 in the UK, and in 1983, the song peaked at number 33 in the US charts. In 1982, Madness released their only number 1 hit to date, "House of Fun", which they played live on the 1980s series "The Young Ones", and also reached number 1 in the album charts with their first compilation, "Complete Madness".
In November 1982, they released their fourth studio album, "The Rise & Fall", which was well received in the UK, but did not get an American release. Instead, many of its songs were included on the US compilation "Madness", including "Our House", which was their most internationally successful single to date. "Our House" reached number 5 in the UK music charts and number 7 in the US charts; it was also performed live on "The Young Ones". Many reviewers compared "The Rise & Fall" to The Kinks' "Village Green Preservation Society", and it is at times retrospectively considered a concept album. The album also featured "Primrose Hill", which was more similar to The Beatles song "Strawberry Fields Forever", containing similar psychedelic imagery and a layered arrangement.
1983–1986: Decline and breakup.
In 1983, their single "Wings of a Dove" peaked at number 2 in the UK charts, followed by "The Sun & The Rain" (no. 5, November 1983). Their following album, "Keep Moving", peaked at number 6 in the UK album charts, and two singles from that album reached the top 20 in the UK music charts. The album received some good reviews, with "Rolling Stone" magazine giving the album four out of five stars, applauding the band's changing sound. This was an improvement as the last album reviewed by the magazine, "Absolutely", was heavily criticised.
On 5 October 1983 the band were rehearsing and discussing a possible television series, which was being written for them by Ben Elton and Richard Curtis. Barson then informed the band that he would not be able to take part, as he was tired of the music business and wanted to spend more time with his wife. They had recently relocated to Amsterdam. Barson agreed to finish recording the album "Keep Moving", he left after playing for the last time with the band at the Lyceum Ballroom on 21 December 1983. After leaving the band James Mackie took Barson's place appearing with Madness on the US hit television show "Saturday Night Live" on 14 April 1984. After leaving the band, Barson returned to the UK for the filming of two music videos as he'd played on the tracks, "Michael Caine" and "One Better Day". He officially left the band in June 1984, following the release of "One Better Day". The six remaining members left Stiff Records and formed their own label, Zarjazz Records, which was a sub-label of Virgin Records. In 1985, the label released the band's sixth album, "Mad Not Mad". Barson's keyboard parts were filled by synthesisers and Steve Nieve joined the band to take his place. In later years, frontman Suggs described the album as a "polished turd". The album reached number 16 in the UK charts, which was the band's lowest position on the album charts to date. Despite the poor chart showing, the album was listed as number 55 in NME's "All Time 100 Albums". The singles for the album fared even worse, with "Yesterday's Men" peaking at number 18 in the UK charts. The subsequent singles, "Uncle Sam" and "Sweetest Girl", failed to make the top 20, which was a first for Madness singles.
Madness were not only running their own Zarjazz Records label at the time, but also had their own recording studio, Liquidator Studios. The studio is still located on Caledonian Road in North London, in what was once the premises of their fan club office. They built a 24 track professional studio in the basement. The first floor has always been an office and chill out area, while a room upstairs is used for song mixing. The band have recorded a number of demos and b-sides at Liquidator, as well as The Madness album in 1988. Other acts to use the studio include Feargal Sharkey, The Farm, Apollo 440, The Potato 5, The Nutty Boys, The Deltones and The Butterfield 8. The studio is still regularly used by musicians, including members of Madness themselves.
The band then attempted to record a new album, and 11 demo tracks were recorded. However, "musical differences" arose between band members, and in September 1986, the band announced that they were to split. Barson rejoined the band for a farewell single, "(Waiting For) The Ghost Train", but did not appear in the music video. The band officially split following the release of the single, which reached a high of number 18 in the UK. In 1988, four members of the band – Suggs, Chas Smash, Lee Thompson and Chris Foreman – continued under the name The Madness. After one self-titled album and two singles that failed to make the top 40, the band split.
1992–2003: Reunion and "Our House" musical.
Towards the end of 1991, "It Must Be Love" was re-released and eventually reached number 6 in the UK singles chart in February 1992. Following that, the singles compilation "Divine Madness" was released and peaked at number 1 in the album charts. Madness then announced plans for a reunion concert, Madstock!, which was held at Finsbury Park, London on 8 and 9 August of that year. The original lineup reunited, performing together for the first time since Barson left the band in 1984. Over 75,000 fans attended the weekend festival, and the dancing of the crowd caused some nearby tower blocks to noticeably shake as they resonated with the frequency of the music.
Subsequent to the Finsbury Park comeback, a live album was released, and the associated single, "The Harder They Come" (a cover of Jimmy Cliff's 1973 song) reached number 44 in the UK, with the album reaching number 22.
The band continued to reunite for annual UK Christmas season tours and held three more Madstock! festivals; in 1994, 1996 and 1998. Also in 1998, Madness returned to America for their first tour there since 1984. The live album "Universal Madness" was recorded at the Universal Amphitheatre in L.A. and released the following year. In 1999, Madness released their first studio album since 1986, entitled "Wonderful". The album reached number 17 in the UK album charts, and the lead single, "Lovestruck", gave the band their first new top 10 hit in the UK since 1983. Neither of the two subsequent singles from the album, "Johnny The Horse" and "Drip Fed Fred", entered the top 40 of the UK charts.
From 28 October 2002 to 16 August 2003, a musical based on Madness songs, "Our House", ran at the Cambridge Theatre in London. Madness played a role in the executive production of the show, and Suggs played a role in the production for a period of time, playing the central character's father. It won an Olivier Award for best new musical of 2003, and the performance was released on DVD on 1 November 2004. There was also a previous musical based on Madness songs, "One Step Beyond!", written by Alan Gilbey. The musical had a brief run at the Theatre Royal Stratford East in 1993 and a run at Putney Arts Theatre, London in 2012.
2004–2010: The Dangermen and The Liberty of Norton Folgate.
In 2004, the band played a series of low-key concerts as The Dangermen, performing covers of classic reggae and ska songs. A lot of the songs were those played by the band when they were first forming, and the band performed the songs as a celebration of their 25th anniversary.
This led to the release of the album "The Dangermen Sessions Vol. 1" on V2 Records in August 2005. During the sessions which produced the album, in mid-2005, guitarist Chris Foreman announced his departure, citing "the petty, time consuming bollocks that goes on in the band" as his reason for leaving. The band completed the album without him, and on release, it peaked at no. 11 in the UK album charts, which was the band's highest studio album chart position in 21 years. Although two singles were released, neither was a major success in the UK. The more successful of the two, "Shame & Scandal", reached number 38, but was more successful in France where it peaked at number 12. "Girl Why Don't You?" did not chart and the band left the V2 record label shortly after. At this time, Kevin Burdett joined as the band's guitarist for live appearances and also appeared in the videos for both 'Sorry' and 'NW5' in early 2007.
The six remaining original members of Madness began working on their first original album in seven years.
In March 2007, the non-LP single "Sorry" was released on the band's own record label Lucky 7 Records, peaking in the UK charts at number 23. The single included a version featuring UK hip hop artists Sway DaSafo and Baby Blue.
The new Madness song "NW5" (then still titled "NW5 (I Would Give You Everything)") and a re-recorded version of "It Must Be Love" were featured in the German film "Neues vom Wixxer" in. The two songs were released in Germany as a double A-Side, and both of them were turned into music, which – besides members of the film's cast – featured Suggs, Chas Smash, Woody and stand-in guitarist Kevin Burdette. A re-recorded version of 'NW5' was released as a single on 14 January 2008 in the UK reaching no. 24 – this recording featured original Madness guitarist Chris Foreman, who had re-joined the band in time for the 2006 Christmas tour, but had not participated in the original recording of the song.
In June 2008, Madness showcased the majority of their new album "The Liberty of Norton Folgate" at London's Hackney Empire for 3 nights. The Hackney Empire performances were recorded and sold to fans as they left the show on USB wristbands. Madness played two dates in December 2008, firstly in Manchester on 18 December, and secondly a return gig to The O2 in London on the 19th.
In December 2008 the band also announced that for their 30th anniversary in 2009, they would be staging a 5th Madstock festival in London's Victoria Park on 17 July 11 years after the last Madstock concert. It was originally rumoured that the newly reformed The Specials would make an appearance after finishing their reunion tour. However, this did not occur, although original Specials keyboardist Jerry Dammers – who was not part of the reunion line-up – was announced as a support act with The Spatial AKA Orchestra shortly before the festival. Dammers would support Madness again during their 2009 Christmas tour, when he opened each night with a DJ set.
Through late March and early April 2009 the band played a series of festival and separate headlining dates across Australia. The lead-up single from their latest album, entitled "Dust Devil", was released on 11 May on Lucky 7 Records. Alfie Allen and Jaime Winstone co-starred in the music video. The single charted at No. 64 on the UK singles charts and at No. 1 on the UK Independent charts on 17 May 2009.
The new album, entitled "The Liberty of Norton Folgate" was released a week later, on 18 May 2009. It charted at No. 5 in the UK album charts. The band continued to play various festivals, including Pinkpop, Splendour, and Glastonbury. On 27 September 2009, the band also played a free concert on a closed-off Regent Street in association with Absolute Radio.
On Friday 28 August, Madness played the Rock en Seine festival near Paris, on the same night where Oasis brothers Noel and Liam Gallagher engaged in a physical altercation, resulting in the split of the band. As Oasis cancelled their headlining slot, Madness, even though having played earlier in the evening, were asked to replace them. They accepted the invitation and both of their sets during the festival were said to have been well received.
As in previous years, the band embarked on a Christmas tour of the UK (also playing one concert in Dublin), playing at various medium-sized venues. Bassist Mark Bedford was absent and replaced by Graham Bush for the tour – according to Madness guitarist Chris Foreman, Bedford is taking some time off from the band and has not specified a return date yet.
Some members of the band appeared in Catherine Tate's "Nan's Christmas Carol". They first posed as carol singers, then played 'Baggy Trousers' over the credits. On 18 January 2010, Madness released a fourth single, Forever Young, from "The Liberty of Norton Folgate". The single failed to chart.
During an interview with RTÉ 2fm radio host Dave Fanning on 24 May 2010, drummer Daniel Woodgate stated that the members of the band are currently finalising songs for the follow-up to "The Liberty of Norton Folgate". The band hope to be able to start recording the album later on in 2010.
In September 2010, Madness were awarded the 'Idol award' at the Q Awards in London. Guitarist Chris Foreman, stated in his acceptance speech that Madness were recording a new album.
Madness toured the UK throughout November and December 2010 with their final show at London's Earl's Court, where they played a new song from their upcoming album. However, two concerts, in Hull and Sheffield were cancelled due to the extreme weather conditions caused by heavy snowfall, although they were later rescheduled for 5 and 6 February 2011 respectively.
2011–present: Oui Oui Si Si Ja Ja Da Da.
In June 2011, the band performed at Meltdown Festival at the Royal Festival Hall, curated by inspiration Ray Davies, who also introduced the band on stage. The concert served as the premiere of three new songs – "1978", "Can't Keep a Good Thing Down" and "Death of a Rude Boy".
The summer of 2012 saw two notable performances. In June, the band performed at the Queen's Diamond Jubilee concert at Buckingham Palace. The band performed "Our House" and "It Must Be Love" from the roof of the palace with accompanying animations projected onto the palace front.Later, in August, the band was the first to perform at the closing ceremony of the London Olympic Games. Departed bass player Mark 'Bedders' Bedford rejoined the band for both performances. In August 2012, Madness released "Death of a Rude Boy" as a free teaser track from their new album. 
Madness' 10th studio album "Oui Oui Si Si Ja Ja Da Da" was released on 29 October 2012 and entered the UK album charts at no.10. In January 2013 the album re-entered the chart at no. 16 on the back of the airplay success of the single 'Never Knew Your Name'.
From the start of 2013 Mark Bedford increased his performances with the band building to his full-time return to the group, which meant a close to the 4 years Graham 'Bushers' Bush had spent with the band.
On 22 March 2013 the band performed outside the BBC Television Centre in a live broadcast for BBC Four. This was followed by "Goodbye Television Centre", a celebration of 50 years of the television centre, marking the closure of the grade II listed building and the last show to be broadcast from it.
Following that the band was the closing act to the new year celebration of 2014 in Dublin, Ireland.
On 22 March 2014 Suggs confirmed to music-news.com that Madness were writing a new album which he stated " the band plan to record in the summer and release by the end of 2014 ".
In October 2014, Cathal Smyth, aka Chas Smash, took a break from Madness to pursue a solo career. His solo album, "A Comfortable Man" will be released on May 11, 2015. Madness is continuing with just 6 members.
Associated acts.
The Fink Brothers.
The Fink Brothers were a short-lived alter ego created by Madness members Suggs and Chas Smash, working under the aliases Angel and Ratty Fink.
The Madness.
The Madness was in fact a line-up of Madness without Mark Bedford, Daniel Woodgate and Mike Barson, active between 1988 and 1989. Formed by Suggs, Chas Smash, Lee Thompson and Chris Foreman in 1988, they distinguished this line-up from the previous Madness line-up only by adding the word "The" to the band's name. The Guinness Book of British Hit Singles and many on-line discographies consider this band to be the same as "Madness". Lee Thompson and Chris Foreman also alluded to this view on their album "Crunch!", which was dedicated to "the good ship Madness and all who sailed in her (1979 to 1989)".
The Nutty Boys.
The Nutty Boys were Lee Thompson and Chris Foreman of Madness. The name "The Nutty Boys" was actually the name of their album, while the new band was called "Crunch!". The posters for their first concert mistakenly listed the band as "The Nutty Boys" instead of "Crunch!", and the name accidentally stuck. While the members of the band Madness were nicknamed "The Nutty Boys" as a whole, this section lists only the work released by Thompson and Foreman under "The Nutty Boys" name in the early 1990s.
Crunch!
Crunch! were also Lee Thompson and Chris Foreman. At this point, the band formally corrected the earlier mistake and officially adopted their original name of "Crunch".
Collaborations.
Madness collaborated with Elvis Costello in 1983 on a version of their song "Tomorrow's (Just Another Day)". It was released as a bonus track to the 12" copy of the single. In later years, Barson stated that Costello's "Watching the Detectives" was the main influence on the song "My Girl". For "Wonderful" in 1999, Ian Dury laid down vocals on the track "Drip Fed Fred" which was released as the last single from the album. It was to be Ian's last recording before his death. Ill health prevented Dury from actively promoting the single, although he did appear on the National Lottery Show, but for a later performance on TFI Friday, the song was reworked to incorporate Phill Jupitus on vocals. Live, Madness have collaborated with artists such as UB40 and Prince Buster, notably at their first Madstock concert. They have also played live frequently with members of the other 2 Tone bands, such as The Specials. In May 2008, Suggs and Carl performed live with Pet Shop Boys at London's Heaven collaborating on a new composition of My Girl. A few days afterwards, Pet Shop Boys posted their own version of the track on their official website.
In late 2010, the band collaborated in the "Cage Against The Machine" project, in which numerous artists performed John Cage's "4′33″" for a charity single intended to prevent the winner of The X Factor claiming the Christmas Number 1. The title refers to the previous year's successful campaign to get Rage Against The Machine's "Killing In The Name Of" to chart above X Factor winner Joe McElderry.
Lyrical themes.
Frequent themes in Madness' songs included childhood memories (e.g., "Baggy Trousers", and "Our House") and petty crime (e.g., "Shut Up", and "Deceives the Eye"). Although Madness were seen by some as somewhat of a humorous band with catchy, bouncy songs, many of their songs took a darker tone (such as the singles "Grey Day" and "Tomorrow's (Just Another Day)") and they sometimes tackled what were, at the time, controversial issues in their lyrics. "Embarrassment" (from the "Absolutely" album) was written by Lee Thompson, and reflected the unfolding turmoil following the news that his teenage sister had become pregnant and was carrying a black man's child. Madness discussed animal testing in the song "Tomorrow's Dream". The band criticised the National Health Service in "Mrs. Hutchinson", which told the story of a woman who, after several misdiagnoses and mistreatment, became terminally ill. The story was based on the experiences of Mike Barson's mother. Madness' final single prior to disbanding, "(Waiting For) The Ghost Train", commented on apartheid in South Africa.
Skinhead controversy.
Early in their career, Madness were linked to skinheads; members of a British working-class subculture that the media often stereotyped as racist (although many skinheads, including the original generation, are non-racist or anti-racist). Not only was Madness, along with other 2 Tone bands, popular with skinheads, but it was said that the band members themselves were associated with the subculture.
The band's relationship with the skinheads varied at times. Barson was particularly displeased with the band's skinhead association, often finding it disappointing that so many were present at performances. Prior to becoming a full member of the band, Chas Smash had been involved in fights with skinheads at performances. In one particular incident on 18 November 1979, Madness were supported by Red Beans and Rice, who featured a black lead singer, and the band was prevented from completing the performance due to the racist chants from certain members of the skinhead filled audience. Suggs later came on stage to show his displeasure at their behaviour, but this did not stop much of the audience from Nazi saluting at the end of the show.
In a 1979 "NME" interview, Smash was quoted as saying, "We don't care if people are in the NF as long as they're having a good time". This added to speculation that Madness were a racist band supporting the National Front, although the band members denied those allegations, and Smash responded to the "NME" article in the song "Don't Quote Me on That". Eventually, band members denied their skinhead roots.
Awards.
The band's first notable musical award came in 1983 when Chris Foreman and Cathal Smyth won an "Ivor Novello Award" for "Best Song" for the international hit "Our House". Madness received another "Ivor Novello Award" 17 years later for an "Outstanding Song Collection". In 2005, they were awarded the MOJO "Hall of Fame" Award, notably for being 'an artist's artist'. As of 2007, a campaign is taking place by fans of Madness for the band to be awarded a Brit award. Many fans and critics feel they have been overlooked over their past 30 years in the music industry. In July 2009, Madness were awarded the 'Silver Clef' Icon Award. In September 2010, Madness were awarded the 'Idol Award' at the 2010 Q Awards in London.
Members.
Members of the classic lineup are listed in bold.

</doc>
<doc id="40234" url="http://en.wikipedia.org/wiki?curid=40234" title="Magnetic mirror">
Magnetic mirror

A magnetic mirror is a configuration of magnetic field lines in which a charged particle is reflected from a high density magnetic field to low density magnetic field. This mirror effect will only occur for particles within a limited range of velocity and angle of approach. Magnetic mirrors are made of specialized electromagnets designed to create a highly inhomogeneous field. Large magnetic mirrors have been used experimentally as a means of plasma confinement. One major application being researched is to confine the hot, electrically charged plasma inside a fusion reactor to generate fusion power. A category of experimental fusion reactors called mirror machines confine plasma within a magnetic field between two magnetic mirrors. The largest to be built was the Mirror Fusion Test Facility (MFTF) in 1986.
A charged particle moving within a region of magnetic field experiences a Lorentz force that causes it to move in a helical (corkscrew) path along a magnetic field line. The radius of the circle that the particle describes is called the radius of gyration or gyroradius. If it enters a region of denser magnetic field lines, a field gradient, the combination of the radial component of the fields and the azimuthal motion of the particle results in a force pointed against the gradient, in the direction of lower magnetic field. It is this force that can reflect the particle, causing it to decelerate and reverse direction.
History.
The concept of magnetic-mirror plasma confinement was proposed in mid-1950s independently by Gersh Budker at the Kurchatov Institute, Russia and Richard F. Post at the Lawrence Livermore National Laboratory. The first small-scale open magnetic plasma trap machine ("probkotron") was built in 1959 at the Budker Institute of Nuclear Physics in Novosibirsk, Russia.
By the late 1960s, magnetic mirror confinement was considered a viable technique for producing fusion energy. In the United States, еfforts were initially funded under the United States Atomic Energy Commissions' Project Sherwood. A machine design was first published in 1967. The concept was advocated by Richard F. Post, Kenneth Fowler, Fred Coensgen and many others at the Lawrence Livermore National Laboratory. As a result of advocacy, the cold war, and the 1970s energy crisis a massive magnetic mirror program was funded by the U.S. federal government.
This program resulted in a series of large magnetic mirror devices including: 2X, Baseball I, Baseball II, the Tandem Mirror Experiment, the Tandem mirror experiment upgrade, the Mirror Fusion Test Facility and the MFTF-B. These machines were built and tested at Livermore from the late 60's to the mid 80's. A number of institutions collaborated on these machines, conducting experiments. These included the Institute for Advanced Study and the University of Wisconsin–Madison. The last machine, the Mirror Fusion Test Facility was 372 million dollars, at that time, the most expensive project in Livermore history. It opened on February 21, 1986 and was promptly shut down. The reason given was to balance the United States federal budget. This program was supported from within the Carter and early Reagan administrations by Edwin E. Kintner, a U.S. Navy captain, under Alvin Trivelpiece. Kintner resigned in 1982 complaining that the federal government had not provided the resources needed for the research.
The concept had a number of technical challenges including maintaining the non-Maxwellian velocity distribution. This meant that instead of many high energy ions hitting one another, the ion energy spread out into a bell curve. The ions then thermalized, leaving most of the material too cold to fuse. Collisions also scattered the charged particles so much that they could not be contained. Lastly, velocity space instabilities contributed to the escape of the plasma.
Magnetic mirrors play an important role in other types of magnetic fusion energy devices such as tokamaks, where the toroidal magnetic field is stronger on the inboard side than on the outboard side. The resulting effects are known as neoclassical. Magnetic mirrors also occur in nature. Electrons and ions in the magnetosphere, for example, will bounce back and forth between the stronger fields at the poles, leading to the Van Allen radiation belts.
Mathematical derivation.
The mirror effect can be shown mathematically. Assume adiabatic invariance of the magnetic moment, i.e. that the particle's magnetic moment and total energy do not change. Adiabatic invariance is lost when a particle occupies a null point or zone of no magnetic field. The magnetic moment can be expressed as:
It is assumed that μ will remain constant while the particle moves into the denser magnetic field. Mathematically, for this to happen the velocity perpendicular to the magnetic field formula_2 must also rise. Meanwhile the total energy of the particle formula_3 can be expressed as:
In regions with no electric field, if the total energy remains constant then the velocity parallel to the magnetic field must drop. If it can go negative then there is a motion repelling the particle from the dense fields.
Mirror ratios.
Magnetic mirrors themselves have a mirror ratio this is expressed mathematically as:
At the same time, particles within the mirror have a pitch angle. This is the angle between the particles' velocity vector and the magnetic field vector. Surprisingly, the particles with the small pitch angle can escape the mirror. These particles are said to be in the loss cone. The reflected particles meet the following criteria:
Where formula_7 is the particle velocity perpendicular to the magnetic field and formula_8 is the particle speed.
This result was surprising because it was expected that heavier and faster particles, or those with less electric charge, would be harder to reflect. It was also expected that smaller magnetic field would reflect less particles. However, the gyroradius in those circumstances is also larger, so that the radial component of the magnetic field seen by the particle is also larger. It is true that the minimum volume and magnetic energy is larger for the case of fast particles and weak fields, but the mirror ratio required remains the same.
Adiabatic Invariance.
The properties of magnetic mirrors can be derived using the adiabatic invariance of magnetic flux under changes in magnetic field strength. As the field gets stronger, the velocity increases proportionally to the square root of B, and the kinetic energy is proportional to B. This can be thought of as an effective potential binding the particle.
Magnetic bottles.
A magnetic bottle is two magnetic mirrors placed close together. For example, two parallel coils separated by a small distance, carrying the same current in the same direction will produce a magnetic bottle between them. Unlike the full mirror machine which typically had many large rings of current surrounding the middle of the magnetic field, the bottle typically has just two rings of current. Particles near either end of the bottle experience a magnetic force towards the center of the region; particles with appropriate speeds spiral repeatedly from one end of the region to the other and back. Magnetic bottles can be used to temporarily trap charged particles. It is easier to trap electrons than ions, because electrons are so much lighter This technique is used to confine very hot plasmas with temperatures of the order of 106 K.
In a similar way, the Earth's non-uniform magnetic field traps charged particles coming from the sun in doughnut shaped regions around the earth called the "Van Allen radiation belts", which were discovered in 1958 using data obtained by instruments aboard the Explorer 1 satellite.
Biconic cusps.
If one of the poles in the magnetic bottle is reversed, it becomes a biconic cusp, which can also hold charged particles. Biconic cusps were first studied by Harold Grad at the Courant Institute, studies reveal the presence of different types of particles inside a Biconic cusp.

</doc>
<doc id="40236" url="http://en.wikipedia.org/wiki?curid=40236" title="Emma of Normandy">
Emma of Normandy

Emma of Normandy (c. 985 – 6 March 1052) was a queen consort of England, Denmark and Norway. She was the daughter of Richard I, Duke of Normandy, and his second wife, Gunnora. Through her marriages to Æthelred the Unready (1002-1016) and Cnut the Great (1017-1035), she became the Queen Consort of England, Denmark, and Norway. She was the mother of three sons, Edward the Confessor, Alfred, and Harthacnut, as well as two daughters, Goda of England, and Gunhilda of Denmark. Even after her husbands' deaths Emma remained in the public eye, and continued to participate actively in politics. As Anne J. Duggan notes, Emma is the "first of the early medieval queens" portrayed visually and she is the central figure within the "Encomium Emmae Reginae", a critical source for the history of early 11th-century English politics.
Marriage to Æthelred II.
In an attempt to pacify Normandy, King Æthelred of England married Emma in 1002. Viking raids on England were often based in Normandy in the late 10th century, and this marriage was intended to unite against the Viking threat. Upon their marriage, Emma was given the Anglo-Saxon name of Ælfgifu, which was used for formal and official matters, and became queen of England. She received properties of her own in Winchester, Rutland, Devonshire, Suffolk, and Oxfordshire, as well as the city of Exeter.
Æthelred and Emma had two sons, Edward the Confessor and Alfred, and a daughter, Goda of England(or Godgifu).
When King Sweyn Forkbeard of Denmark invaded and conquered England in 1013, Emma and her children were sent to Normandy, where Æthelred joined soon after. They returned to England after Sweyn’s death in 1014.
Emma and Æthelred’s marriage ended with Æthelred’s death in London in 1016. Æthelred’s oldest son from his first marriage, Æthelstan, had been heir apparent until his death in June 1014. Emma’s sons had been ranked after all of the sons from his first wife, the oldest of whom was Edmund Ironside. Emma made an attempt to get her oldest son, Edward, recognized as heir. Although this movement was supported by Æthelred’s chief advisor, Eadric Streona, it was opposed by Edmund Ironside, Æthelred’s second oldest son, and his allies, who eventually revolted against his father.
In 1015, Cnut, the son of Sweyn Forkbeard, invaded England. He was held out of London until the deaths of Æthelred and Edmund in April and November 1016, respectively. Queen Emma attempted to maintain Anglo-Saxon control of London until her marriage to Cnut was arranged. Some scholars believe that the marriage saved her sons' lives, as Cnut tried to rid himself of rival claimants, but spared their lives.
Marriage to Cnut.
Cnut gained control of most of England after he defeated Edmund Ironside on 18 October at the Battle of Assandun, after which they agreed to divide the kingdom, Edmund taking Wessex and Cnut the rest of the country. Edmund died shortly afterwards on 30 November, and Cnut became the king of all England. At the time of their marriage, Emma's sons from her marriage to Æthelred were sent to live in Normandy under the tutelage of her brother. At this time Emma became queen of England, and later of Denmark, and Norway.
Emma was not particularly active in the first years of Cnut's reign. However, she became more active in 1020, when she began to befriend clergy on the European continent, as well as taking the role of patroness to the church. She developed a close relationship with Ælfsige of Peterborough, who advised her on many spiritual matters throughout her life. Her close relationship with clergy and the church strengthened her husband's claim to the throne as a Christian king.
The "Encomium Emmae Reginae" suggests in its second book that Emma and Cnut's marriage, though intended as a political strategy, became an affectionate marriage.
During their marriage, Emma and Cnut had a son, Harthacnut, and a daughter, Gunhilda.
Death and burial.
After her death in 1052 Emma was interred alongside Cnut and Harthacnut in the Old Minster, Winchester before being transferred to the new cathedral built after the Norman Conquest. During the English Civil War, their remains were disinterred and scattered about the Cathedral floor by parliamentary forces. In 2012 the "Daily Mail" reported that Bristol University archaeologists "will use the latest DNA techniques...to identify and separate the jumbled bones"
Conspiracy regarding the death of Alfred.
In 1036, Alfred Aetheling and Edward the Confessor, Emma's sons with Æthelred, returned to England from their exile in Normandy in order to visit their mother. During their time in England, they were supposed to be protected by Harthacnut. However, Harthacnut was involved with his kingdom in Denmark. Alfred was captured and blinded by holding a hot iron to his eyes. He later died from his wounds.
Edward escaped attack, and returned to Normandy. He returned after his place on the throne had been secured.
"Encomium Emmae Reginae" places the blame of Alfred’s capture, torture, and murder completely on Harold Harefoot, thinking he intended to rid himself of two more potential claimants to the English throne by killing Edward and Alfred. Some scholars make the argument that it could have been Godwin, Earl of Wessex, who was traveling with Alfred and Edward as their protector in passage.
Harthacnut and Edward the Confessor’s coordinated reign.
Harthacnut, Cnut’s son, succeeded the throne of Denmark after the death of his father in 1035. Five years later, he and his brother, Edward the Confessor, shared the throne of England, after the death of Harold, Harthacnut’s half brother. Their reign was short, lasting only two years before Harthacnut’s own demise.
Emma played a role in this coordinated reign by being a common tie between the two kings. The "Encomium of Queen Emma" suggests that she herself may have had a significant role, even being an equal role in this co-leadership of the English kingdom.
Emma's progeny.
Emma's issue with Æthelred the Unready were:
Her issue with Cnut the Great were
Emma as queen.
As Pauline Stafford notes Emma is the “first of the early medieval queens” to be depicted through contemporary portraiture. To that end, Emma is the central figure within the "Encomium Emmae Reginae" (incorrectly titled "Gesta Cnutonis Regis" during the later Middle Ages) a critical source for the study of English succession in the 11th century. During the reign of Æthelred, Emma most likely served as little more than a figurehead a physical embodiment of the treaty between the English and her Norman father. However, her influence increased exponentially under Cnut. Until 1043, writes Stafford, Emma “was the richest woman in England…and held extensive lands in the East Midlands and Wessex” Emma’s authority was not simply tied to landholdings—which fluctuated greatly from 1036 to 1043—she also wielded significant sway over the ecclesiastical offices of England.
The "Encomium Emmæ Reginae" or "Gesta Cnutonis Regis".
The "Encomium" is divided into three parts, the first of which deals with Sweyn Forkbeard and his conquest of England. The second focuses on Cnut and relates the defeat of Æthelred, his marriage to Emma, and his kingship. The third address the events after Cnut’s death; Emma's involvement in the seizing of the royal treasury, and the treachery of Earl Godwin. It begins by addressing Emma, "May our Lord Jesus Christ preserve you, O Queen, who excel all those of your sex in the amiability of your way of life." Emma is "the most distinguished woman of her time for delightful beauty and wisdom."
Scholarly debate.
This flattery, writes Elizabeth M. Tyler, is “part of a deliberate attempt to intervene, on Emma’s behalf, in the politics of the Anglo-Danish court” a connotation which an 11th-century audience would have understood. This proves to be a direct contrast to earlier evaluations of the text, such as the introduction to the 1998 reprint of Alistair Campbell’s 1949 edition in which Simon Keynes remarks: 
... While the modern reader who expects the Encomium to provide a portrait of a great and distinguished queen at the height of her power will be disappointed, and might well despair of an author who could suppress, misrepresent, and garble what we know or think to have been the truth Felice Lifshitz, in her seminal study of the "Encomium" comments:…To Alistair Campbell and to see C.N.L. Brooke the omission was explicable as a matter of ‘artistic necessity’ and of Emma’s personal vanity…both scholars subscribed to the older view, which afforded the Encomium only literary significance as a panegyric to individual or dynasty, but saw no political import.
Manuscripts.
Prior to May 2008 only one copy of the "Encomium" was believed to exist. However, a late 14th-century compendium was discovered in the Devon Record Office, where it had languished since the 1960s. According to a report by the UK Arts Council, “The most significant item [within the text] for British history is the Encomium Emma Reginae ... It is highly probable that the present manuscript represents the most complete witness to the revised version of the Encomium.” The manuscript was put up for auction in December 2008, and purchased for £600,000 (5.2 million Danish kroner) on behalf of the Royal Library of Denmark. Unlike the "Liber Vitae" the compendium does not contains any images of Emma.
The New Minster Liber Vitae, currently housed at the British Library, was completed in 1030, shortly before Cnut’s death in 1035. The frontispiece depicts “King Cnut and Queen Emma presenting a cross to the altar of New Minster, Winchester” Stafford in her visual exegesis of the portrait states, “it is not clear whether we should read it as a representation of a powerful women or a powerless one” In one portrait, each facet of Emma’s role as sovereign is displayed; that of a dutiful wife and influential queen.
Emma is also depicted in a number of later medieval texts, such as the 13th-century "Life of Edward the Confessor" (Cambridge University Library MS. Ee.3.59) and a 14th-century roll "Genealogy of the English Kings, Genealogical Chronicle of the English Kings."
Bibliography.
See also "Encomium Emmae" (for the "Encomium Emmae Reginae" or "Gesta Cnutonis Regis" in honour of Queen Emma)

</doc>
<doc id="40238" url="http://en.wikipedia.org/wiki?curid=40238" title="Herbert Putnam">
Herbert Putnam

George Herbert Putnam (20 September 1861 – 14 August 1955) was an American librarian. He was the eighth (and also the longest-serving) Librarian of Congress from 1899 to 1939. He implemented his vision of a universal collection with strengths in every language, especially from Europe and Latin America.
Biography.
George Herbert Putnam was born in New York City at 107 East Seventeenth Street, the sixth son and tenth child of Victorine and George Palmer Putnam. The father, one-time collector of internal revenue in New York by appointment of Abraham Lincoln, was the founder of a well known publishing house, known previously as the Putnam Publishing house, but now known as G. P. Putnam's Sons.
In 1886, Herbert Putnam married Charlotte Elizabeth Munroe of Cambridge, Massachusetts, and together they had two daughters, Shirley and Brenda Putnam. Brenda Putnam grew up to become a celebrated sculptor in the early 20th century, highly known for her “children, cherubs, and garden ornaments.” 
Throughout Herbert Putnam’s career, he was described by his colleagues as maintaining “an impenetrable dignity…formal manner, invariable gracious and cordial, covered shyness and a deep reserve. He had few intimates, even among his closest colleagues, but he was fond of good company and good conversation” as well being “painfully modest, a family man who had an unreciprocated view of his staff as family.” 
He died at his home in Woods Hole, Massachusetts, on August 14, 1955.
Early career.
After graduating magna cum laude from Harvard University in 1883, Putnam spent the following year at Columbia University Law School. Eventually, however, his interest in administrative work led him to the Minneapolis Athenaeum where he served as librarian in 1887, until it merged into the Minneapolis Public Library in 1888. Putnam was elected city librarian of the Minneapolis Public Library at that time and served while simultaneously being admitted to the Minnesota bar of Law. According to the Honorable Lawrence Lewis of Colorado at a Tribute for Putnam in 1939, Putnam at this time “modernized antiquated methods, revised the charging records of books on loan, inaugurated a new system of cataloging and classification, opened the alcoves to readers, [and] insisted that ‘there are two great problems of library management – one to get the books for the readers, the other to get the readers to the books.’” 
In 1891, Putnam resigned his Minneapolis post due to his mother-in-law’s ill health, and promptly returned to Boston to be near her. Putnam “was admitted to the Suffolk bar, and practiced law in Boston until the 18th of February 1895” when he was appointed Librarian of the Boston Public Library. During his tenure at the Boston Public Library “there were 9 branches and 12 delivery stations. At the end of his four years there were 10 branches, 5 minor branches, called ‘reading rooms,’ and 56 deposit stations…the library grew from a total of 610,375 volumes at the close of 1894 to 716,050 at the close of 1898.” Another contribution made by Putnam towards the Boston Public Library was the addition of a room devoted to juveniles, “believed to have been the first room wholly devoted to the service of children in any of the larger libraries of the country.” 
Library of Congress.
Induction.
Putnam’s activities with the American Library Association led him to join with Justin Winsor and Melvil Dewey as official delegates to the International Conference of Librarians in London in 1897 When Winsor died shortly thereafter, Putnam served the remainder of his term as President of the ALA. When John Russell Young died in January 1899, President William McKinley asked requested Congress to appoint Putnam. He was officially confirmed December 12, 1899.
The systemization of a public institution.
Upon the confirmation of Putnam to his appointed duty of Librarian of Congress, one daunting task Putnam faced from the onset was the sheer volume of materials that had to be reorganized for the newly opened Thomas Jefferson Building – the newly appointed library for the Library of Congress. However, Putnam was well aware of what needed to be done. “In October 1899 Putnam requested a $190,000 increase in the budget for fiscal 1901. If Congress consented, the 1899 LC budget would nearly double and that for 1900 would be increased by 60 percent. Declaring that the collections were deficient in many respects, [Putnam] asked for $50,000 to purchase new material, more than twice the 1899 appropriation. In summation, the first task of Putnam's administration was to organize all materials of the Library of Congress so they may be used efficiently by the public.
Putnam’s request was granted by the United States Congress, and thus an appropriation bill was passed on April 17th, 1900. Although Putnam’s administration would need time in order to collect, organize, and disseminate all of the material within the Library of Congress’ collection, the task was completed with enormous success. “By 1924 the first objective had been won with – 1) All spaces in the building duly differentiated and equipped for specialized, as well as general, uses. 
2) The specialized material installed in appropriate cases. 
3) A scheme of classification, systematic and elastic, with an appropriate nomenclature. 
4) Adoption of processes of cataloging, including forms of entry, now standardized for American libraries. 
5) Actual application of the classification and cataloging to a large portion of the collection of printed books.” 
Putnam during this time also introduced a new system of classifying books that continues to this day, known as the Library of Congress Classification. He also established an interlibrary loan system, and expanded the Library of Congress's role and relationships with other libraries, through the provision of centralized services. He was elected an Associate Fellow of the American Academy of Arts and Sciences in 1902.
War-time service.
In July 1916, “former LC staff member Elizabeth West, director of the Carnegie Library of San Antonio, Texas, suggested to Putnam that the Library of Congress cooperate with other libraries to send books to American soldiers.” 
Initially, Putnam was not interested in the wholesale distribution of books to American troops simply due to the lack of interest. However, when attention arose that the British War Library Service in London were performing similar duties to their troops, measures were quickly devised by Putnam, the ALA, and Congress to enact such a program to the American military branches. “Aided by a grant of $320,000 from the Carnegie Corporation, the War Service built thirty-six libraries, completing the majority by February 1918. But with so much invested in buildings, little money remained for books or administration…Putnam took the matter up directly with the War Department and obtained assurances that the government would provide utilities. He appealed to ALA members to donate books and volunteer for service, and by June 1918 the association had purchased 300,000 books, sent 1,349,000 gift books to camps, and distributed 500,000 magazines.” In the time after World War I, the services of the Library of Congress towards the war effort provided a new outlook for the American public on the possibilities of what a successful library could accomplish. In other words, the contributions made by the Library of Congress in that time gave “librarians ‘a new conception of what a truly national library could be' and added one more item ‘to the long list of benefits for which American libraries have to thank the Library and the Librarian, of Congress.” 
Retirement.
Herbert Putnam’s administration as Librarian of Congress lasted for forty years, from 1899 until 1939. It was clear Putnam was not willing to withdraw completely from the world of librarianship, stating “I would willingly surrender the administration, if that course would serve the interest of the library and I could feel assured as to my successor.” Putnam provided the suggestion of “Librarian Emeritus” be developed as his new official title, with an honorarium of one-half of his original salary. On October 1, 1939, Putnam retired as the 8th Librarian of Congress with that title, and he “continued to contribute to the Library, keeping regular office hours for the next 15 years.” 
Herbert Putnam was succeeded in 1939 by Archibald MacLeish, who served from 1939 until 1944.

</doc>
<doc id="40239" url="http://en.wikipedia.org/wiki?curid=40239" title="Geosynchronous orbit">
Geosynchronous orbit

A geosynchronous orbit (sometimes abbreviated GSO) is an orbit around the Earth with an orbital period of one sidereal day, intentionally matching the Earth's sidereal rotation period (approximately 23 hours 56 minutes and 4 seconds). The synchronization of rotation and orbital period means that, for an observer on the surface of the Earth, an object in geosynchronous orbit returns to exactly the same position in the sky after a period of one sidereal day. Over the course of a day, the object's position in the sky traces out a path, typically in the form of an analemma, whose precise characteristics depend on the orbit's inclination and eccentricity.
A special case of geosynchronous orbit is the geostationary orbit, which is a circular geosynchronous orbit at zero inclination (that is, directly above the equator). A satellite in a geostationary orbit appears stationary, always at the same point in the sky, to ground observers. Popularly or loosely, the term "geosynchronous" may be used to mean geostationary. Specifically, geosynchronous Earth orbit (GEO) may be a synonym for "geosynchronous equatorial orbit", or "geostationary Earth orbit". Communications satellites are often given geostationary orbits, or close to geostationary, so that the satellite antennas that communicate with them do not have to move, but can be pointed permanently at the fixed location in the sky where the satellite appears.
A semi-synchronous orbit has an orbital period of 1/2 sidereal day, i.e., 11 h 58 min. Relative to the Earth's surface it has twice this period, and hence appears to go around the Earth once every day. Examples include the Molniya orbit and the orbits of the satellites in the Global Positioning System.
Orbital characteristics.
Circular Earth geosynchronous orbits have a radius of 42164 km. All Earth geosynchronous orbits, whether circular or elliptical, have the same semi-major axis. In fact, orbits with the same period always share the same semi-major axis:
where "a" is the semi-major axis, "P" is the orbital period, and "μ" is the geocentric gravitational constant, equal to 398600.4418 km3/s2.
In the special case of a geostationary orbit, the ground track of a satellite is a single point on the equator. In the general case of a geosynchronous orbit with a non-zero inclination or eccentricity, the ground track is a more or less distorted figure-eight, returning to the same places once per sidereal day.
Geostationary orbit.
A geostationary orbit (GEO) is a circular geosynchronous orbit in the plane of the Earth's equator with a radius of approximately 42164 km (measured from the center of the Earth). A satellite in such an orbit is at an altitude of approximately 35786 km above mean sea level. It maintains the same position relative to the Earth's surface. If one could see a satellite in geostationary orbit, it would appear to hover at the same point in the sky, i.e., not exhibit diurnal motion, while the Sun, Moon, and stars would traverse the heavens behind it. The theoretical basis for this novel phenomenon of the sky goes back to Newton's theory of motion and gravity. In that theory, the existence of a geostationary satellite is made possible because the Earth rotates (with respect to an inertial frame in which Newton's laws of motion and gravity hold). However, as a practical device, the geostationary satellite owes much for its realisation to Arthur C. Clarke who proposed it during the 20th century and in whose honour the orbit is called a Clarke orbit. Such orbits are useful for telecommunications satellites.
A perfectly stable geostationary orbit is an ideal that can only be approximated. In practice the satellite drifts out of this orbit because of perturbations such as the solar wind, radiation pressure, variations in the Earth's gravitational field, and the gravitational effect of the Moon and Sun, and thrusters are used to maintain the orbit in a process known as station-keeping.
Other geosynchronous orbits.
Elliptical geosynchronous orbits can be and are designed for communications satellites in order to keep the satellite within view of its assigned ground stations or receivers. A satellite in an elliptical geosynchronous orbit appears to oscillate in the sky from the viewpoint of a ground station, tracing an analemma (figure 8) in the sky. Satellites in highly elliptical orbits must be tracked by steerable ground stations.
The Infrared Space Observatory was in a highly-elliptical geosynchronous orbit with an orbital height of apogee 70,600 km and perigee 1,000 km. It was controlled by two ground stations.
The Quasi-Zenith Satellite System (QZSS), is a proposed three-satellite regional time transfer system and enhancement for GPS covering Japan.
An active geosynchronous orbit is a hypothetical orbit that could be maintained if forces other than gravity were also used, such as a solar sail. Such a statite could be geosynchronous in an orbit different (higher, lower, more or less elliptical, or some other path) from the conic section orbit dictated by the laws of gravity.
A further form of geosynchronous orbit is proposed for the theoretical space elevator, in which one end of the structure is tethered to the ground, maintaining a shorter orbital period than by gravity alone if under tension.
Other related orbit types are:
Other synchronous orbits.
Synchronous orbits can only exist for bodies that have a fixed surface (e.g. moons, rocky planets). Without such a surface (e.g. gas giants, black holes) there is no fixed point an orbit can be said to synchronise with. No synchronous orbit will exist if the body rotates so slowly that the orbit would be outside its Hill sphere, or so quickly that it would be inside the body. Large bodies which are held together by gravity cannot rotate that quickly since they would fly apart, so the last condition only applies to small bodies held together by other forces, e.g. smaller asteroids. Most inner moons of planets have synchronous rotation, so their synchronous orbits are, in practice, limited to their leading and trailing (L4 and L5) Lagrange points, as well as the L1 and L2 Lagrange points, assuming they do not fall within the body of the moon. Objects with chaotic rotations (such as exhibited by Hyperion) are also problematic, as their synchronous orbits change unpredictably.
History.
At the end of 1928, the Austro-Hungarian rocket engineer Herman Potočnik set out a plan for a breakthrough into space and the establishment of a permanent human presence there. He conceived a space station in detail and was the first person to calculate the geostationary orbit, on which the station would orbit the Earth.
Author Arthur C. Clarke is credited with proposing the notion of using a geostationary orbit for communications satellites. The orbit is also known as the Clarke Orbit. Together, the collection of artificial satellites in these orbits is known as the Clarke Belt.
The first communications satellite placed in a geosynchronous orbit was Syncom 2, launched in 1963. However, it was in an inclined orbit, still requiring the use of moving antennas. The first communications satellite placed in a geostationary orbit was Syncom 3. Geostationary orbits have been in common use ever since, in particular for satellite television.
Geostationary satellites also carry international telephone traffic but they are being replaced by fiber optic cables in heavily populated areas and along the coasts of less developed regions, because of the greater bandwidth available and lower latency, due to the inherent disconcerting delay in communicating via a satellite in such a high orbit. It takes electromagnetic waves about a quarter of a second to travel from one end to the other end of the link. Thus, two parties talking via satellite are subject to about a half second delay in a round-trip message/response sequence.
Although many populated land locations on the planet now have terrestrial communications facilities (microwave, fiber-optic), even undersea, with more than sufficient capacity, telephone and Internet access is still available only via satellite in many places in Africa, Latin America, and Asia, as well as isolated locations that have no terrestrial facilities, such as Canada's Arctic islands, Antarctica, the far reaches of Alaska and Greenland, and ships at sea.

</doc>
<doc id="40243" url="http://en.wikipedia.org/wiki?curid=40243" title="Edward the Confessor">
Edward the Confessor

Edward the Confessor (between 1003 and 1005 – 5 January 1066), son of Æthelred the Unready and Emma of Normandy, was one of the last Anglo-Saxon kings of England and is usually regarded as the last king of the House of Wessex, ruling from 1042 to 1066.
Edward has traditionally been seen as unworldly and pious, and his reign is notable for the disintegration of royal power in England and the advance in power of the Godwin family. His biographers, Frank Barlow and Peter Rex, dispute this, picturing him as a successful king, who was energetic, resourceful and sometimes ruthless, but whose reputation has been unfairly tarnished by the Norman conquest shortly after his death. Other historians regard this positive picture as only partly true, and not at all in the later part of his reign. In the view of Richard Mortimer, the return of the Godwins from exile in 1052 "meant the effective end of his exercise of power". The difference in his level of activity from the earlier part of his reign "implies a withdrawal from affairs".
Edward succeeded Cnut the Great's son Harthacnut, restoring the rule of the House of Wessex after the period of Danish rule since Cnut conquered England in 1016. When Edward died in 1066 he was succeeded by Harold Godwinson, who was defeated and killed in the same year by the Normans under William the Conqueror at the Battle of Hastings.
Edward is called Confessor, the name for someone believed to have lived a saintly life but who was not a martyr, in Latin "S. Eduardus Confessor rex Anglorum", as opposed to "S. Eduardus Martyr rex Anglorum".
He was canonised in 1161 by Pope Alexander III, and is commemorated on 13 October by both the Church of England and the Roman Catholic Church in England and Wales. Saint Edward was one of the national saints of England until King Edward III adopted Saint George as patron saint in about 1350.
Early years and exile.
Edward was the seventh son of Æthelred the Unready, and the first by his second wife, Emma of Normandy. Edward was born between 1003 and 1005 in Islip, Oxfordshire, and is first recorded as a 'witness' to two charters in 1005. He had one full brother, Alfred, and a sister, Godgifu. In charters he was always listed behind his older half-brothers, showing that he ranked behind them.
During his childhood England was the target of Viking raids and invasions under Sweyn Forkbeard and his son, Cnut. Following Sweyn's seizure of the throne in 1013, Emma fled to Normandy, followed by Edward and Alfred, and then by Æthelred. Sweyn died in February 1014, and leading Englishmen invited Æthelred back on condition that he promised to rule 'more justly' than before. Æthelred agreed, sending Edward back with his ambassadors. Æthelred died in April 1016, and he was succeeded by Edward's older half brother Edmund Ironside, who carried on the fight against Sweyn's son, Cnut. According to Scandinavian tradition, Edward fought alongside Edmund; as Edward was at most thirteen years old at the time, the story is disputed. Edmund died in November 1016, and Cnut became undisputed king. Edward then again went into exile with his brother and sister; his mother had no taste for the sidelines, and in 1017 she married Cnut. In the same year Cnut had Edward's last surviving elder half-brother, Eadwig, executed, leaving Edward as the leading Anglo-Saxon claimant to the throne.
Edward spent a quarter of a century in exile, probably mainly in Normandy, although there is no evidence of his location until the early 1030s. He probably received support from his sister Godgifu, who married Drogo of Mantes, count of Vexin in about 1024. In the early 1030s Edward witnessed four charters in Normandy, signing two of them as king of England. According to the Norman chronicler, William of Jumièges, Robert I, Duke of Normandy attempted an invasion of England to place Edward on the throne in about 1034, but it was blown off course to Jersey. He also received support for his claim to the throne from a number of continental abbots, particularly Robert, abbot of the Norman abbey of Jumièges, who was later to become Edward's Archbishop of Canterbury. Edward was said to have developed an intense personal piety during this period, but modern historians regard this as a product of the later medieval campaign for his canonisation. In Frank Barlow's view "in his lifestyle would seem to have been that of a typical member of the rustic nobility". He appeared to have a slim prospect of acceding to the English throne during this period, and his ambitious mother was more interested in supporting Harthacnut, her son by Cnut.
Cnut died in 1035, and Harthacnut succeeded him as king of Denmark. It is unclear whether he was intended to have England as well, but he was too much occupied in defending his position in Denmark to come to England to make good any claim. It was therefore decided that his elder half-brother, Harold Harefoot should act as regent, while Emma held Wessex on Harthacnut's behalf. In 1036 Edward and his brother Alfred separately came to England. Emma later claimed that they came in response to a letter inviting them to visit her that was forged by Harold, but historians believe that she probably did invite them in an effort to counter Harold's growing popularity. Alfred was captured by Godwin, Earl of Wessex who turned him over to Harold Harefoot. He had Alfred blinded by forcing red-hot pokers into his eyes to make him unsuitable for kingship, and Alfred died soon after as a result of his wounds. The murder is thought to be the source of much of Edward's later hatred for the Earl and one of the primary reasons for Godwin's banishment in autumn 1051. Edward is said to have fought a successful skirmish near Southampton, and then retreated back to Normandy. He thus showed his prudence, but he had some reputation as a soldier in Normandy and Scandinavia.
In 1037 Harold was accepted as king, and the following year he expelled Emma, who retreated to Bruges. She then summoned Edward and demanded his help for Harthacnut, but he refused as he had no resources to launch an invasion, and disclaimed any interest for himself in the throne. Harthacnut, his position in Denmark now secure, did plan an invasion, but Harold died in 1040, and Harthacnut was able to cross unopposed with his mother to take the English throne.
In 1041, Harthacnut invited Edward back to England, probably as heir because he knew he had not long to live. The 12th century Quadripartitus, in an account regarded as convincing by historian John Maddicott, states that he was recalled by the intervention of Bishop Ælfwine of Winchester and Earl Godwin. Edward met "the thegns of all England" at Hursteshever, probably Hurst Head, a shingle spit opposite the Isle of Wight which was the site of the later Hurst Castle. There he was received as king in return for his oath that he would continue the laws of Cnut. According to the "Anglo-Saxon Chronicle" Edward was sworn in as king alongside Harthacnut, but a diploma issued by Harthacnut in 1042 describes him as the king's brother.
Early reign.
Following Harthacnut's death on 8 June 1042, Godwin, the most powerful of the English earls, supported Edward, who succeeded to the throne. The "Anglo-Saxon Chronicle" describes the popularity he enjoyed at his accession – "before he [Harthacnut] was buried, all the people chose Edward as king in London." Edward was crowned at the cathedral of Winchester, the royal seat of the West Saxons, on 3 April 1043.
Edward complained that his mother had "done less for him than he wanted before he became king, and also afterwards". In November 1043 he rode to Winchester with his three leading earls, Leofric of Mercia, Godwin and Siward of Northumbria, to deprive her of her property, possibly because she was holding on to treasure which belonged to the king. Her adviser, Stigand, was deprived of his bishopric of Elmham in East Anglia. However, both were soon restored to favour. Emma died in 1052.
Edward's position when he came to the throne was weak. Effective rule required keeping on terms with the three leading earls, but loyalty to the ancient house of Wessex had been eroded by the period of Danish rule, and only Leofric was descended from a family which had served Æthelred. Siward was probably Danish, and although Godwin was English, he was one of Cnut's new men, married to Cnut's former sister-in-law. However, in his early years Edward restored the traditional strong monarchy, showing himself, in Frank Barlow's view, "a vigorous and ambitious man, a true son of the impetuous Æthelred and the formidable Emma."
In 1043 Godwin's eldest son Sweyn was appointed to an earldom in the south-west midlands, and on 23 January 1045 Edward married Godwin's daughter Edith. Soon afterwards, her brother Harold and her Danish cousin Beorn Estrithson, were also given earldoms in southern England. Godwin and his family now ruled subordinately all of Southern England. However, in 1047 Sweyn was banished for abducting the Abbess of Leominster. In 1049 he returned to try to regain his earldom, but this was said to have been opposed by Harold and Beorn, probably because they had been given Sweyn's land in his absence. Sweyn murdered his cousin Beorn and went again into exile, and Edward's nephew, Ralph was given Beorn's earldom, but the following year Sweyn's father was able to secure his reinstatement.
The wealth of Edward's lands exceeded that of the greatest earls, but they were scattered among the southern earldoms. He had no personal powerbase, and he does not seem to have attempted to build one. In 1050–51 he even paid off the fourteen foreign ships which constituted his standing navy and abolished the tax raised to pay for it. However in ecclesiastical and foreign affairs he was able to follow his own policy. King Magnus of Norway aspired to the English throne, and in 1045 and 1046, fearing an invasion, Edward took command of the fleet at Sandwich. Beorn's elder brother, Sweyn of Denmark "submitted himself to Edward as a son", hoping for his help in his battle with Magnus for control of Denmark, but in 1047 Edward rejected Godwin's demand that he send aid to Sweyn, and it was only Magnus's death in October that saved England from attack and allowed Sweyn to take the Danish throne.
Modern historians reject the traditional view that Edward mainly employed Norman favourites, but he did have foreigners in his household, including a few Normans, who became unpopular. Chief among them was Robert, abbot of the Norman abbey of Jumièges, who had known Edward from the 1030s and came to England with him in 1041, becoming bishop of London in 1043. According to the "Vita Edwardi", he became "always the most powerful confidential adviser to the king".
The crisis of 1051–1052.
In ecclesiastical appointments, Edward and his advisers showed a bias against candidates with local connections, and when the clergy and monks of Canterbury elected a relative of Godwin as Archbishop of Canterbury in 1051, Edward rejected him and appointed Robert of Jumièges, who claimed that Godwin was in illegal possession of some archiepiscopal estates. In September Edward was visited by his brother-in-law, Godgifu's second husband, Eustace, count of Boulogne. His men caused an affray in Dover, and Edward ordered Godwin as earl of Kent to punish the town's burgesses, but he took their side and refused. Edward seized the chance to bring his over-mighty earl to heel. Archbishop Robert accused Godwin of plotting to kill the king, just as he had killed his brother Alfred in 1036, while Leofric and Siward supported the king and called up their vassals. Sweyn and Harold called up their own vassals, but neither side wanted a fight, and Godwin and Sweyn appear to have each given a son as hostage, who were sent to Normandy. The Godwins' position disintegrated as their men were not willing to fight the king. When Stigand, who was acting as intermediary, conveyed the king's jest that Godwin could have his peace if he could restore Alfred and his companions alive and well, Godwin and his sons fled, going to Flanders and Ireland. Edward repudiated Edith and sent her to a nunnery, perhaps because she was childless, and Archbishop Robert urged her divorce.
Sweyn went on pilgrimage to Jerusalem (dying on his way back), but Godwin and his other sons returned with an army following a year later, and received considerable support, while Leofric and Siward failed to support the king. Both sides were concerned that a civil war would leave the country open to foreign invasion. The king was furious, but he was forced to give way and restore Godwin and Harold to their earldoms, while Robert of Jumièges and other Frenchmen fled, fearing Godwin's vengeance. Edith was restored as queen, and Stigand, who had again acted as an intermediary between the two sides in the crisis, was appointed Archbishop of Canterbury in Robert's place. Stigand retained his existing bishopric of Winchester, and his pluralism was to be a continuing source of dispute with the pope. Edward's nephew, Earl Ralph, who had been one of his chief supporters in the crisis of 1051–52, may have received Sweyn's marcher earldom of Hereford at this time.
Later reign.
Until the mid-1050s Edward was able to structure his earldoms so as to prevent the Godwins becoming dominant. Godwin himself died in 1053 and although Harold succeeded to his earldom of Wessex, none of his other brothers were earls at this date. His house was then weaker than it had been since Edward's succession, but a succession of deaths in 1055–57 completely changed the picture. In 1055 Siward died but his son was considered too young to command Northumbria, and Harold's brother, Tostig was appointed. In 1057 Leofric and Ralph died, and Leofric's son Ælfgar succeeded as Earl of Mercia, while Harold's brother Gyrth succeeded Ælfgar as Earl of East Anglia. The fourth surviving Godwin brother, Leofwine, was given an earldom in the south-east carved out of Harold's territory, and Harold received Ralph's territory in compensation. Thus by 1057 the Godwin brothers controlled all of England subordinately apart from Mercia. It is not known whether Edward approved of this transformation or whether he had to accept it, but from this time he seems to have begun to withdraw from active politics, devoting himself to hunting, which he pursued each day after attending church.
In the 1050s, Edward pursued an aggressive, and generally successful, policy in dealing with Scotland and Wales. Malcolm Canmore was an exile at Edward's court after Macbeth killed his father, Duncan I, and seized the Scottish throne. In 1054 Edward sent Siward to invade Scotland. He defeated Macbeth, and Malcolm, who had accompanied the expedition, gained control of southern Scotland. By 1058 Malcolm had killed Macbeth in battle and taken the Scottish throne. In 1059 he visited Edward, but in 1061 he started raiding Northumbria with the aim of adding it to his territory.
In 1053 Edward ordered the assassination of the south Welsh prince Rhys ap Rhydderch in reprisal for a raid on England, and Rhys's head was delivered to him. In 1055 Gruffydd ap Llywelyn established himself as the ruler of all Wales, and allied himself with Ælfgar of Mercia, who had been outlawed for treason. They defeated Earl Ralph at Hereford, and Harold had to collect forces from nearly all of England to drive the invaders back into Wales. Peace was concluded with the reinstatement of Ælfgar, who was able to succeed as Earl of Mercia on his father's death in 1057. Gruffydd swore an oath to be a faithful under-king of Edward. Ælfgar appears to have died in 1062 and his young son Edwin was allowed to succeed as Earl of Mercia, but Harold then launched a surprise attack on Gruffydd. He escaped, but when Harold and Tostig attacked again the following year, he retreated and was killed by Welsh enemies. Edward and Harold were then able to impose vassallage on some Welsh princes.
In October 1065 Harold's brother, Tostig, the earl of Northumbria, was hunting with the king when his thegns in Northumbria rebelled against his rule, which they claimed was oppressive, and killed some 200 of his followers. They nominated Morcar, the brother of Edwin of Mercia, as earl, and invited the brothers to join them in marching south. They met Harold at Northampton, and Tostig accused Harold before the king of conspiring with the rebels. Tostig seems to have been a favourite with the king and queen, who demanded that the revolt be suppressed, but neither Harold nor anyone else would fight to support Tostig.
Edward was forced to submit to his banishment, and the humiliation may have caused a series of strokes which led to his death. He was too weak to attend the dedication of his new church at Westminster, which was then still incomplete, on 28 December.
Edward probably entrusted the kingdom to Harold and Edith shortly before he died on 5 January 1066. On 6 January he was buried in Westminster Abbey, and Harold was crowned on the same day.
The succession.
Starting as early as William of Malmesbury in the early 12th century, historians have puzzled over Edward's intentions for the succession. One school of thought supports the Norman case that Edward always intended William the Conqueror to be his heir, accepting the medieval claim that Edward had already decided to be celibate before he married, but most historians believe that he hoped to have an heir by Edith at least until his quarrel with Godwin in 1051. William may have visited Edward during Godwin's exile, and he is thought to have promised William the succession at this time, but historians disagree how seriously he meant the promise, and whether he later changed his mind.
Edmund Ironside's son, Edward Ætheling, had the best claim to be considered Edward's heir. He had been taken as a young child to Hungary, and in 1054 Bishop Ealdred of Worcester visited the Holy Roman Emperor, Henry III to secure his return, probably with a view to becoming Edward's heir. The exile returned to England in 1057 with his family, but died almost immediately. His son Edgar, who was then about five years old, was brought up at the English court. He was given the designation Ætheling, meaning throneworthy, which may mean that Edward considered making him his heir, and he was briefly declared king after Harold's death in 1066. However, Edgar was absent from witness lists of Edward's diplomas, and there is no evidence in the Domesday Book that he was a substantial landowner, which suggests that he was marginalised at the end of Edward's reign.
After the mid-1050s, Edward seems to have withdrawn from affairs as he became increasingly dependent on the Godwins, and may have become reconciled to the idea that one of them would succeed him. The Normans claimed that Edward sent Harold to Normandy in about 1064 to confirm the promise of the succession to William. The strongest evidence comes from a Norman apologist, William of Poitiers. According to his account, shortly before the Battle of Hastings, Harold sent William an envoy who admitted that Edward had promised the throne to William but argued that this was over-ridden by his deathbed promise to Harold. In reply, William did not dispute the deathbed promise, but argued that Edward's prior promise to him took precedence.
In Richard Baxter's view, Edward's "handling of the succession issue was dangerously indecisive, and contributed to one of the greatest catastrophes to which the English have ever succumbed."
Westminster Abbey.
Edward's Norman sympathies are most clearly seen in the major building project of his reign, Westminster Abbey, the first Norman Romanesque church in England. This was commenced between 1042 and 1052 as a royal burial church, consecrated on 28 December 1065, completed after his death in about 1090, and demolished in 1245 to make way for Henry III's new building, which still stands. It was very similar to Jumièges Abbey, which was built at the same time. Robert of Jumièges must have been closely involved in both buildings, although it is not clear which is the original and which the copy.
Edward does not appear to have been interested in books and associated arts, but his abbey played a vital role in the development of English Romanesque architecture, showing that he was an innovating and generous patron of the church.
Canonisation.
Edward the Confessor was the first Anglo-Saxon and the only king of England to be canonised, but he was part of a tradition of (uncanonised) English royal saints, such as Eadburh of Winchester, a daughter of Edward the Elder, Edith of Wilton, a daughter of Edgar the Peaceful, and King Edward the Martyr. With his proneness to fits of rage and love of hunting Edward is regarded by most historians as an unlikely saint, and his canonisation as political, although some argue that his cult started so early that it must have had something credible to build on.
Edward displayed a worldly attitude in his church appointments. When he appointed Robert of Jumièges as Archbishop of Canterbury in 1051, he chose the leading craftsman Spearhafoc to replace Robert as Bishop of London. Robert refused to consecrate him, saying that the pope had forbidden it, but Spearhafoc occupied the bishopric for several months with Edward's support. After the Godwins fled the country, Edward expelled Spearhafoc, who fled with a large store of gold and gems which he had been given to make Edward a crown. Stigand was the first archbishop of Canterbury not to be a monk in almost a hundred years, and he was said to have been excommunicated by several popes because he held Canterbury and Winchester in plurality. Several bishops sought consecration abroad because of the irregularity of Stigand's position. Edward usually preferred clerks to monks for the most important and richest bishoprics, and he probably accepted gifts from candidates for bishoprics and abbacies. However, his appointments were generally respectable. When Odda of Deerhurst died without heirs in 1056, Edward seized lands which Odda had granted to Pershore Abbey and gave them to his Westminster foundation; the historian Ann Williams observes that "the Confessor did not in the eleventh century have the saintly reputation which he later enjoyed, largely through the efforts of the Westminster monks themselves".
After 1066 there was a subdued cult of Edward as a saint, possibly discouraged by the early Norman abbots of Westminster, which gradually increased in the early twelfth century. Osbert of Clare, the prior of Westminster Abbey, then started to campaign for Edward's canonisation, aiming to increase the wealth and power of the Abbey. By 1138, he had converted the Vita Ædwardi, the life of Edward commissioned by his widow, into a conventional saint's life. He seized on an ambiguous passage which might have meant that their marriage was chaste, perhaps to give the idea that Edith's childlessness was not her fault, to claim that Edward had been celibate. In 1139 Osbert went to Rome to petition for Edward's canonisation with the support of King Stephen, but he lacked the full support of the English hierarchy and Stephen had quarrelled with the church, so Pope Innocent II postponed a decision, declaring that Osbert lacked sufficient testimonials of Edward's holiness.
In 1159 there was a disputed election to the papacy, and Henry II's support helped to secure recognition of Pope Alexander III. In 1160 a new abbot of Westminster, Laurence, seized the opportunity to renew Edward's claim. This time, it had the full support of the king and the English hierarchy, and a grateful pope issued the bull of canonisation on 7 February 1161, the result of a conjunction of the interests of Westminster Abbey, King Henry II and Pope Alexander III He was called 'Confessor' as the name for someone who was believed to have lived a saintly life but was not a martyr.
In the 1230s King Henry III became attached to the cult of Saint Edward, and he commissioned a new life by Matthew Paris. Henry also constructed a grand new tomb for Edward in a rebuilt Westminster Abbey in 1269.
Until about 1350, Edmund the Martyr, Gregory the Great and Edward the Confessor were regarded as English national saints, but Edward III preferred the more war-like figure of St George, and in 1348 he established the Order of the Garter with St George as its patron. It was located at Windsor Castle, and its chapel of St Edward the Confessor was re-dedicated to St George, who was acclaimed in 1351 as patron of the English race. Edward was never a popular saint, but he was important to the Norman dynasty, which claimed to be the successor of Edward as the last legitimate Anglo-Saxon king.
The shrine of Saint Edward the Confessor in Westminster Abbey remains where it was after the final translation of his body to a chapel east of the sanctuary on 13 October 1269 by Henry III. The day of his translation, 13 October (his first translation had also been on that date in 1163), is regarded as his feast day, and each October the Abbey holds a week of festivities and prayer in his honour. For some time the Abbey had claimed that it possessed a set of coronation regalia that Edward had left for use in all future coronations. Following Edward's canonisation, these were regarded as holy relics, and thereafter they were used at all English coronations from the 13th century until the destruction of the regalia by Oliver Cromwell in 1649.
13 October is an optional feast day for Edward the Confessor for the Catholic Church of England and Wales, and the Church of England's calendar of saints designates it as a Lesser Festival. He is regarded as a patron saint of difficult marriages.
Appearance and character.
The "Vita Ædwardi Regis" states "[H]e was a very proper figure of a man—of outstanding height, and distinguished by his milky white hair and beard, full face and rosy cheeks, thin white hands, and long translucent fingers; in all the rest of his body he was an unblemished royal person. Pleasant, but always dignified, he walked with eyes downcast, most graciously affable to one and all. If some cause aroused his temper, he seemed as terrible as a lion, but he never revealed his anger by railing.". This, as the historian Richard Mortimer notes, 'contains obvious elements of the ideal king, expressed in flattering terms - tall and distinguished, affable, dignified and just.'
In popular culture.
Edward is depicted as the central saint of the Wilton Diptych (c. 1395–99), a devotional piece made for Richard II, but now in the collection of the National Gallery. The reverse of the piece carries Edward's arms; and Richard's badge of a white hart. The panel painting dates from the end of the 14th century.
In Act 3, Scene VI of Shakespeare's "Macbeth" (c. 1603–06) Lennox refers to Edward as "the most pious Edward," and in Act 4, Scene III, Malcolm describes his powers of healing those afflicted with "the evil", or scrofula.
He is the central figure in Alfred Duggan's 1960 historical novel "The Cunning of the Dove".
He is featured in Sara Douglass' novel "God's Concubine".
On screen he has been portrayed by Eduard Franz in the film "Lady Godiva of Coventry" (1955), George Howe in the BBC TV drama series "Hereward the Wake" (1965), Donald Eccles in the two-part BBC TV play "Conquest" (1966; part of the series "Theatre 625"), Brian Blessed in "Macbeth" (1997), based on the Shakespeare play (although he does not appear in the play itself), and Adam Woodroffe in an episode of the British TV series "Historyonics" entitled "1066" (2004). In 2002, he was portrayed by Lennox Greaves in the "Doctor Who" audio adventure "Seasons of Fear".

</doc>
<doc id="40244" url="http://en.wikipedia.org/wiki?curid=40244" title="Open Systems Interconnection">
Open Systems Interconnection

Open Systems Interconnection (OSI) is an effort to standardize computer networking that was started in 1977 by the International Organization for Standardization (ISO), along with the ITU-T.
History.
Prior to OSI, networking was largely either government-sponsored (ARPANET in the US, CYCLADES in France) or vendor-developed and proprietary standards (such as the System network architecture (SNA) of IBM and DECnet of Digital Equipment Corporation). A Experimental Packet Switched system in the UK circa 1973,
Criticism.
The OSI protocol suite that was specified as part of the project was considered by many, such as computer scientist Andrew S. Tanenbaum, to be too complicated and inefficient, and to a large extent unimplementable. Taking the "forklift upgrade" approach to networking, it specified eliminating all existing protocols and replacing them with new ones at all layers of the stack. This made implementation difficult, and was resisted by many vendors and users with significant investments in other network technologies. In addition, the protocols included so many optional features that many vendors' implementations were not interoperable.
Although the OSI model is often still referred to, the Internet's TCP/IP protocol suite is used in lieu of the OSI protocols. TCP/IP's pragmatic approach to computer networking and two independent implementations of simplified protocols made it a practical standard. Some protocols and specifications in the OSI stack remain in use, one example being IS-IS, which was specified for OSI as ISO/IEC 10589:2002 and adapted for Internet use (with TCP/IP) as RFC 1142.

</doc>
<doc id="40245" url="http://en.wikipedia.org/wiki?curid=40245" title="Halotolerance">
Halotolerance

Halotolerance is the adaptation of living organisms to conditions of high salinity. Halotolerant species tend to live in areas such as hypersaline lakes, coastal dunes, saline deserts, salt marshes, and inland salt seas and springs. Halophiles are organisms that live in highly saline environments, and require the salinity to survive, while halotolerant organisms (belonging to different domains of life) can grow under saline conditions, but do not require elevated concentrations of salt for growth. Halophytes are salt-tolerant higher plants. Halotolerant microorganisms are of considerable biotechnological interest.
Applications.
Fields of scientific research relevant to halotolerance include biochemistry, molecular biology, cell biology, physiology, ecology, and genetics.
An understanding of halotolerance can be applicable to areas such as arid-zone agriculture, xeriscaping, aquaculture (of fish or algae), bioproduction of desirable compounds (such as phycobiliproteins or carotenoids) using seawater to support growth, or remediation of salt-affected soils. In addition, many environmental stressors involve or induce osmotic changes, so knowledge gained about halotolerance can also be relevant to understanding tolerance to extremes in moisture or temperature.
Goals of studying halotolerance include increasing the agricultural productivity of lands affected by soil salination or where only saline water is available. Conventional agricultural species could be made more halotolerant by gene transfer from naturally halotolerant species (by conventional breeding or genetic engineering) or by applying treatments developed from an understanding of the mechanisms of halotolerance. In addition, naturally halotolerant plants or microorganisms could be developed into useful agricultural crops or fermentation organisms.
Cellular functions.
Tolerance of high salt conditions can be obtained through several routes. High levels of salt entering the plant can trigger ionic imbalances which cause complications in respiration and photosynthesis, leading to reduced rates of growth, injury and death in severe cases. To be considered tolerant of saline conditions, the protoplast must show methods of balancing the toxic and osmotic effects of the increased salt concentrations. Halophytic vascular plants can survive on soils with salt concentrations around 6%, or up to 20% in extreme cases. Tolerance of such conditions is reached through the use of stress proteins and compatible cytoplasm osmotic solutes.
To exist in such conditions, halophytes tend to be subject to the uptake of high levels of salt into their cells, and this is often required to maintain an osmotic potential lower than that of the soil to ensure water uptake. High salt concentrations within the cell can be damaging to sensitive organelles such as the chloroplast, so sequestration of salt is seen. Under this action, salt is stored within the vacuole to protect such delicate areas. If high salt concentrations are seen within the vacuole, a high concentration gradient will be established between the vacuole and the cytoplasm, leading to high levels of energy investment to maintain this state. Therefore, the accumulation of compatible cytoplasmic osmotic solutes can be seen to prevent this situation from occurring. Amino Acids such as proline accumulate in halophytic Brassica species, quaternary ammonium bases such as Glycine Betaine and sugars have been shown to act in this role within halophytic members of Chenopodiaceae and members of Asteraceae show the buildup of cyclites and soluble sugars. The buildup of these compounds allow for the balancing of the osmotic effect while preventing the establishment of toxic concentrations of salt or requiring the maintenance of high concentration gradients
Bacterial halotolerance.
The extent of halotolerance varies widely amongst different species of bacteria. A number of cyanobacteria are halotolerant; an example location of occurrence for such cyanobacteria is in the Makgadikgadi Pans, a large hypersaline lake in Botswana.
Fungal halotolerance.
Fungi from habitats with high concentration of salt are mostly halotolerant (i.e. they do not require salt for growth) and not halophilic. Halophilic fungi are a rare exception. Halotolerant fungi constitute a relatively large and constant part of hypersaline environment communities, such as those in the solar salterns. Well studied examples include the yeast "Debaryomyces hansenii "and black yeasts "Aureobasidium pullulans" and "Hortaea werneckii". The latter can grow in media without salt, as well as in almost saturated NaCl solutions. To emphasize this unusually wide adaptability, some authors describe "H. werneckii "as "extremely halotolerant".

</doc>
<doc id="40247" url="http://en.wikipedia.org/wiki?curid=40247" title="Pulsed inductive thruster">
Pulsed inductive thruster

Pulsed inductive thrusters (or PITs) are a form of ion thruster, used in spacecraft propulsion. It is an electromagnetic plasma accelerator and has demonstrated efficiency greater than 50%. A PIT uses perpendicular electric and magnetic fields to accelerate a propellant. A nozzle releases a puff of gas (usually ammonia or argon) which spreads across a flat induction coil of wire about 1 meter across. A bank of capacitors releases a pulse of electric current lasting 10 microseconds into the coil, generating a radial magnetic field. This induces a circular electrical field in the gas, ionizing it and causing the ions to revolve in the opposite direction as the original pulse of current. Because their motion is perpendicular to the magnetic field, the ions are accelerated out into space.
Unlike an electrostatic ion thruster, PIT requires no electrodes (which are susceptible to erosion) and its power can be scaled up simply by increasing the number of pulses per second. A 1-megawatt system would pulse 200 times per second.

</doc>
<doc id="40248" url="http://en.wikipedia.org/wiki?curid=40248" title="Variable Specific Impulse Magnetoplasma Rocket">
Variable Specific Impulse Magnetoplasma Rocket

The Variable Specific Impulse Magnetoplasma Rocket (VASIMR) is an electromagnetic thruster for spacecraft propulsion. It uses radio waves to ionize and heat a propellant, and magnetic fields to accelerate the resulting plasma to generate thrust. It is one of several types of spacecraft electric propulsion systems.
The method of heating plasma used in VASIMR was originally developed as a result of research into nuclear fusion. VASIMR is intended to bridge the gap between high-thrust, low-specific impulse propulsion systems and low-thrust, high-specific impulse systems. VASIMR is capable of functioning in either mode. Costa Rican–born American scientist and former NASA astronaut Franklin Chang Díaz created the VASIMR concept and has been working on its development since 1977.
VASIMRs are manufactured by the Ad Astra Rocket Company, headquartered in the city of Houston, Texas, United States.
Design and operation.
The Variable Specific Impulse Magnetoplasma Rocket, sometimes referred to as the Electro-thermal Plasma Thruster or Electro-thermal Magnetoplasma Rocket, uses radio waves to ionize and heat propellant, which generates plasma that is accelerated using magnetic fields to generate thrust. This type of engine is electrodeless and as such belongs to the same electric propulsion family (while differing in the method of plasma acceleration) as the electrodeless plasma thruster, the microwave arcjet, or the pulsed inductive thruster class. It can also be seen as an electrodeless version of an arcjet, able to reach higher propellant temperature by limiting the heat flux from the plasma to the structure. Neither type of engine has any electrodes. This is advantageous in that it eliminates problems with electrode erosion that cause rival designs of ion thrusters to have relatively shorter life expectancy. Furthermore, since every part of a VASIMR engine is magnetically shielded and does not come into direct contact with plasma, the potential durability of this engine design is greater than other ion/plasma engine designs.
VASIMR can be most basically thought of as a convergent-divergent nozzle for ions and electrons. The propellant (a neutral gas such as argon or xenon) is first injected into a hollow cylinder surfaced with electromagnets. Upon entry into the engine, the gas is first heated to a “cold plasma” by a helicon RF antenna (also known as a “coupler”) which bombards the gas with electromagnetic waves, stripping electrons off the argon or xenon atoms and leaving plasma consisting of ions and loose electrons to continue down the engine compartment. By varying the amount of energy dedicated to RF heating and the amount of propellant delivered for plasma generation VASIMR is capable of generating either low-thrust, high–specific impulse exhaust or relatively high-thrust, low–specific impulse exhaust. The second phase is a strong electromagnet positioned to compress the ionized plasma in a similar fashion to a convergent-divergent nozzle that compresses gas in traditional rocket engines.
A second coupler, known as the Ion Cyclotron Heating (ICH) section, emits electromagnetic waves in resonance with the orbits of ions and electrons as they travel through the engine. Resonance of the waves and plasma is achieved through a reduction of the magnetic field in this portion of the engine which slows down the orbital motion of the plasma particles. This section further heats the plasma to temperatures upwards of 1,000,000 kelvin—about 173 times the temperature of the Sun’s surface.
Motion of ions and electrons through the engine can be approximated by lines parallel to the engine walls; however, the particles actually orbit those lines at the same time that they are traveling linearly through the engine. The final, diverging, section of the engine contains a steadily expanding magnetic field which forces the ions and electrons into steadily lengthening spiral orbits in order to eject from the engine parallel and opposite to the direction of motion at speeds of up to 50,000 m/s, propelling the rocket forward through space.
Benefits and drawbacks of design.
In contrast with usual cyclotron resonance heating processes, in VASIMR ions are immediately ejected through the magnetic nozzle, before they have time to achieve thermalized distribution. Based on novel theoretical work in 2004 by Arefiev and Breizman of UT-Austin, virtually all of the energy in the ion cyclotron wave is uniformly transferred to ionized plasma in a single-pass cyclotron absorption process. This allows for ions to leave the magnetic nozzle with a very narrow energy distribution, and for significantly simplified and compact magnet arrangement in the engine.
VASIMR does not use electrodes; instead, it magnetically shields plasma from most of the hardware parts, thus eliminating electrode erosion—a major source of wear and tear in ion engines. Compared to traditional rocket engines with very complex plumbing, high performance valves, actuators and turbopumps, VASIMR eliminates practically all moving parts from its design (apart from minor ones, like gas valves), maximizing its long term durability.
However, some new problems emerge, like interaction with strong magnetic fields and thermal management. The relatively large power at which VASIMR operates generates a lot of waste heat, which needs to be channeled away without creating thermal overload and undue thermal stress on materials used.
Powerful superconducting electromagnets, employed to contain hot plasma, generate tesla-range magnetic fields. They can present problems with other on board devices and also can produce unwanted torque by interacting with the magnetosphere. To counter this latter effect, the VF-200 will consist of two 100 kW thruster units packaged together, with the magnetic field of each thruster oriented in opposite directions in order to make a zero-torque magnetic quadrupole.
Research and development.
The first VASIMR experiment was conducted at MIT starting in 1983 on the magnetic mirror plasma device. Important refinements were introduced to the rocket concept in 1990s, including the use of the "helicon" plasma source, which replaced the initial plasma gun originally envisioned and made the rocket completely "electrodeless"—an extremely desirable feature to assure reliability and long life. A new patent was granted in 2002.
In 1995, the Advanced Space Propulsion Laboratory (ASPL) was founded at NASA Johnson Space Center, Houston in the building of Sonny Carter Training Facility. The magnetic mirror device was brought from MIT. The first plasma experiment in Houston was conducted using a microwave plasma source. The collaboration with University of Houston, University of Texas at Austin, Rice University and other academic institutions was established.
In 1998, the first helicon plasma experiment was performed at the ASPL. The decision was made regarding the official name of VASIMR and VASIMR experiment (VX). VX-10 in 1998 ran up to 10 kW helicon discharge, VX-25 in 2002 ran up to 25 kW and VX-50—up to 50 kW of RF plasma discharge. In March, 2000, the VASIMR group was given a Rotary National Award for Space Achievement / Stellar Award. By 2005 major breakthroughs were obtained at the ASPL including full and efficient plasma production, and acceleration of the plasma ions in the second stage of the rocket. The VASIMR engine model VX-50 proved to be capable of 0.5 N of thrust. Published data on the VX-50 engine, capable of processing 50 kW of total radio frequency power, showed ICRF (second stage) efficiency to be 59% calculated as: 90% "N"A coupling efficiency × 65% "N"B ion speed boosting efficiency. It was hoped that the overall efficiency of the engine could be increased by scaling up power levels.
Ad Astra Rocket Company (AARC) was incorporated in Delaware on January 14, 2005. On June 23, 2005, Ad Astra and NASA signed the first Space Act Agreement to privatize the VASIMR Technology. On July 8, 2005, Franklin Chang Díaz retired from NASA after 25 years of service. Ad Astra’s Board of Directors was formed and Dr. Díaz took the helm as chairman and CEO on July 15, 2005. In July, 2006, AARC opened the Costa Rica subsidiary in the city of Liberia at the campus of Earth University. In December 2006, AARC-Costa Rica performed first plasma experiment on the VX-CR device utilizing helicon ionization of argon.
The 100 kilowatt VASIMR experiment was successfully running by 2007 and demonstrated efficient plasma production with an ionization cost below 100 eV. VX-100 plasma output was tripled over the prior record of the VX-50. In the same year, the AARC moved out from the NASA facility to its own building in Webster, TX.
Model VX-100 was expected to have the "N"B ion speed boosting efficiency of 80%. There were, however, additional (smaller) efficiency losses related to the conversion of DC electric current to radio frequency power and also to the superconducting magnets' auxiliary equipment energy consumption. By comparison, 2009 state-of-the-art, proven ion engine designs such as NASA's HiPEP operated at 80% total thruster/PPU energy efficiency.
Development of the 200 kW engine.
On October 24, 2008 the company announced that the plasma generation aspect of the VX-200 engine—helicon first stage or solid-state high frequency power transmitter—had reached operational status. The key enabling technology, solid-state DC-RF power-processing, has become very efficient reaching up to 98% efficiency. The helicon discharge uses 30 kWe of radio waves to turn argon gas into plasma. The remaining 170 kWe of power is allocated for passing energy to, and acceleration of, plasma in the second part of the engine via ion cyclotron resonance heating.
Based on data released from previous VX-100 testing, it was expected that the VX-200 engine would have a system efficiency of 60–65% and thrust level of 5 N. Optimal specific impulse appeared to be around 5,000s using low cost argon propellant. One of the remaining untested issues was potential vs. actual thrust; that is, whether the hot plasma actually detached from the rocket. Another issue is waste heat management. About 60% of input energy ends up as useful kinetic energy. A large portion of the remaining 40% will be secondary ionizations cost from plasma crossing magnetic field lines and exhaust divergence. A significant portion of that 40% would end up as waste heat (see energy conversion efficiency). Managing and rejecting that waste heat is critical to allowing for continuous operation of the VASIMR engine.
Between April and September 2009, tests were performed on the VX-200 prototype with fully integrated 2-tesla superconducting magnets. They successfully expanded the power range of the VASIMR up to its full operational capability of 200 kW.
During November 2010, long duration, full power firing tests were performed with the VX-200 engine reaching the steady state operation for 25 seconds thus validating basic design characteristics.
Results presented to NASA and academia in January 2011 have confirmed that the design point for optimal efficiency on the VX-200 is 50 km/s exhaust velocity, or an Isp of 5000 s. Based on these data, thruster efficiency of 72% has been achieved by Ad Astra, yielding an overall system efficiency (DC electricity to thruster power) of 60% (since the DC to RF power conversion efficiency exceeds 95%) with argon as the propellant.
The 200 kW VX-200 had executed more than 10,000 engine firings by 2013, while demonstrating greater than 70% thruster efficiency—relative to RF power input—with argon propellant at full power.
Testing on the International Space Station.
On December 8, 2008, Ad Astra signed an agreement with NASA to arrange the placement and testing of a flight version of the VASIMR, the VF-200, on the International Space Station (ISS). In early 2009, the earliest possible launch date was reported as 2012. s of 2014[ [update]], its launch is anticipated to be in 2016. The reason for the delays have been attributed to funding; and in June 2014, Franklin Chang-Diaz stated that the project is unlikely to proceed unless they're able to receive a funded-SAA from NASA.
Since the available power from the ISS is less than 200 kW, the ISS VASIMR will include a trickle-charged battery system allowing for 15 min pulses of thrust. Testing of the engine on ISS is valuable because it orbits at a relatively low altitude and experiences fairly high levels of atmospheric drag, making periodic boosts of altitude necessary. Currently, altitude reboosting by chemical rockets fulfills this requirement. The VASIMR test on the ISS may lead to a capability of maintaining the ISS or a similar space station in a stable orbit at 1/20th of the approximately $210 million/year present estimated cost.
Ad Astra held a formal PDR for the VF-200 with NASA on 26 June 2013.
The plans were later scrapped.
VF-200.
The VF-200 flight-rated thruster consists of two 100 kW VASIMR units with opposite magnetic dipoles so that no net rotational torque is applied to the space station when the thruster magnets are working. The VF-200-1 is the first flight unit and was going to be tested in space attached to the ISS. Then, the plans were scrapped.
NASA partnership.
In June 2005, Ad Astra signed its first Space Act Agreement with NASA which led to the development of the VASIMR engine. In December 10, 2007, AARC and NASA signed an Umbrella Space Act Agreement relating to the space agency's potential interest in the VASIMR, providing a framework for collaboration between the parties, setting out the general conditions governing aspects of their ongoing relationship. In December 8, 2008, NASA and AARC entered into a Space Act Agreement that could lead to conducting a space flight test of the VASIMR on the ISS. In March 2, 2011, Ad Astra and NASA Johnson Space Center have signed a Support Agreement to collaborate on research, analysis and development tasks on space-based cryogenic magnet operations and electric propulsion systems currently under development by Ad Astra. s of 2011[ [update]], NASA had 100 people assigned to the project to work with Ad Astra to integrate the VF-200 onto the space station. On December 16, 2013, AARC and NASA signed another five-year Umbrella Space Act Agreement.
VX-200SS.
In March 2015, Ad Astra announced development of the VX-200SS (SS is for steady state). It is supposed to be able to fire for 100 continuous hours.
Potential future applications.
VASIMR is not suitable to launch payloads from the surface of Earth due to its low thrust-to-weight ratio and its need of a vacuum to operate. Instead, it would function as an upper stage for cargo, reducing the fuel requirements for in-space transportation. The engine is expected to perform the following functions at a fraction of the cost of chemical technologies:
Other applications for VASIMR such as the rapid transportation of people to Mars would require a very high power, low mass energy source, such as a nuclear reactor (see nuclear electric rocket). NASA Administrator Charles Bolden said that VASIMR technology could be the breakthrough technology that would reduce the travel time on a Mars mission from 2.5 years to 5 months.
In August 2008, Tim Glover, Ad Astra director of development, publicly stated that the first expected application of VASIMR engine is "hauling things [non-human cargo] from low-Earth orbit to low-lunar orbit" supporting NASA's return to Moon efforts.
Use as a space tug or orbital transfer vehicle.
The most important near-future application of VASIMR-powered spacecraft is transportation of cargo. Numerous studies have shown that, despite longer transit times, VASIMR-powered spacecraft will be much more efficient than traditional integrated chemical rockets at moving goods through space. An orbital transfer vehicle (OTV)—essentially a "space tug"—powered by a single VF-200 engine would be capable of transporting about 7 metric tons of cargo from low Earth orbit (LEO) to low Lunar orbit (LLO) with about a six-month transit time. NASA envisages delivering about 34 metric tons of useful cargo to LLO in a single flight with a chemically propelled vehicle. To make that trip, about 60 metric tons of LOX-LH2 propellant would be burned. A comparable OTV would need to employ 5 VF-200 engines powered by a 1 MW solar array. To do the same job, such an OTV would need to expend only about 8 metric tons of argon propellant. The total mass of such an electric OTV would be in the range of 49 t (outbound & return fuel: 9 t, hardware: 6 t, cargo 34 t). The OTV transit times can be reduced by carrying lighter loads and/or expending more argon propellant with VASIMR throttled up to higher thrust at less efficient (lower "Isp") operating conditions. For instance, an empty OTV on the return trip to Earth covers the distance in about 23 days at optimal specific impulse of 5,000 s (50 kN·s/kg) or in about 14 days at "I"sp of 3,000 s (30 kN·s/kg). The total mass of the NASA specs' OTV (including structure, solar array, fuel tank, avionics, propellant and cargo) was assumed to be 100 metric tons (98.4 long tons; 110 short tons) allowing almost double the cargo capacity compared to chemically propelled vehicles but requiring even bigger solar arrays (or other source of power) capable of providing 2 MW.
s of October 2010[ [update]], Ad Astra Rocket Company is working toward utilizing VASIMR technology for space tug missions to help "clean up the ever-growing problem of space trash." They hope to have a first-generation commercial offering by 2014.
Mars in 39 days.
In order to conduct a manned trip to "Mars in just 39 days", the VASIMR will need the kind of electrical power that can only be delivered by nuclear propulsion (specifically the nuclear electric type) by way of nuclear power in space. This kind of nuclear fission reactor might use a traditional Rankine/Brayton/Stirling conversion engine such as that used by the SAFE-400 reactor (Brayton cycle) or the DUFF KiloPower reactor (Stirling cycle) to convert heat to electricity, but might be better served with non-moving parts and non-steam based power conversion using a thermocell technology of the thermoelectric (including graphene-based thermal power conversion), pyroelectric, thermophotovoltaic, thermionic, magnetohydrodynamic type, or some as yet undiscovered technology or thermoelectric materials for converting heat energy (being both black-body radiation and the kinetic thermal vibration of molecules and other particles) to electric current energy (being electrons flowing through a circuit). In order to avoid the need for "football-field sized radiators" (Zubrin quote) for a "200,000 kilowatt (200 megawatt) reactor with a power to mass density of 1,000 watts per kilogram" (Díaz quote) this reactor will also need efficient waste heat capturing technology. For comparison, a Seawolf-class nuclear-powered fast attack submarine uses a 34 megawatt reactor, and the Pilgrim Nuclear Generating Station uses a 690 megawatt reactor.
Missions closer to the Sun than Jupiter.
Planet Jupiter is on average just over 5 astronomical units (AU) distance from the Sun, receiving only 4% of the sunlight received by planet Earth. For trips to Ceres (avg. of 2.8 AU from the Sun), Mars (1.5 AU), the Moon (1.0 AU) or the two planets closer to the Sun than Earth (Venus (0.7 AU) and Mercury (0.4 AU)), solar photocell technology can be used in addition to nuclear fission thermocells, via large and highly efficient solar panels on spacecraft. Sufficiently large solar panels might be 3D printed in space by such contracted companies as Deep Space Industries and Tethers Unlimited, Inc., the former of which NASA has given $100,000 and later $500,000 (Aug. 2013) grant money to study the process.
Criticisms of VASIMR by Robert Zubrin.
Mars manned mission advocate Robert Zubrin is critical of the VASIMR, claiming that it is less efficient than other electric thrusters which are now operational. Zubrin also believes that electric propulsion is not necessary to get to Mars; therefore, budgets should not be assigned to develop it. His second point of criticism concentrates on the lack of a suitable power source. Ad Astra subsequently responded to the criticism in a press release: "It is abundantly clear that the nuclear reactor technology required for such missions is not available today and major advances in reactor design and power conversion are needed" on very fast manned transits to Mars. Zubrin's Mars Direct mission plan also calls for nuclear power reactors, though for purposes other than direct powering of propulsion, including fuel production on the surface of Mars. Ad Astra further argued that "In the near term, using solar-electric power at levels of 100 kW to 1 MW, VASIMR® propulsion could transfer heavy payloads to Mars using only one to four first-generation thrusters in relatively simple engine architectures." 
Further reading.
</dl>

</doc>
<doc id="40249" url="http://en.wikipedia.org/wiki?curid=40249" title="Mongolian alphabets">
Mongolian alphabets

Many alphabets have been devised for the Mongolian language over the centuries, and from a variety of scripts. The oldest, called simply the Mongolian script, has been the predominant script during most of Mongolian history, and is still in active use today in the Inner Mongolia region of China. It has spawned several alphabets, either as attempts to fix its perceived shortcomings, or to allow the notation of other languages, such as Sanskrit and Tibetan. In the 20th century, Mongolia first switched to the Latin script, and then almost immediately replaced it with the Cyrillic script for compatibility with the Soviet Union, its political ally of the time. Mongols in Inner Mongolia and other parts of China, on the other hand, continue to use alphabets based on the traditional Mongolian script.
Precursors.
The Khitan spoke a proto mongolic language called Khitan language and had developed two scripts for writing their language: Khitan large script, a logographic script derived from Chinese characters, and Khitan small script, derived from Uighur.
Classic Mongolian script.
Traditional alphabet.
At the very beginning of the Mongol Empire, around 1204, Genghis Khan defeated the Naimans and captured an Uyghur scribe called Tata Tunga, who then adapted the Uyghur alphabet — a descendant of the Syriac alphabet, via Sogdian — to write Mongol. With only minor modifications, it is used in Inner Mongolia to this day. Its most salient feature is its vertical direction; it is the only vertical script that is written from left to right. (All other vertical writing systems are written right to left.) This is because the Uyghurs rotated their script 90 degrees anticlockwise to emulate the Chinese writing system.
Galik alphabet.
In 1587, the translator and scholar Ayuush Güüsh created the Galik alphabet, inspired by Sonam Gyatso, the third Dalai Lama. It primarily added extra letters to transcribe Tibetan and Sanskrit terms in religious texts, and later also from Chinese. Some of these letters are still in use today for writing foreign names.
Oirat alphabet.
In 1648, the Oirat Buddhist monk Zaya Pandita created this variation with the goal of bringing the written language closer to the actual pronunciation, and to make it easier to transcribe Tibetan and Sanskrit. The script was used by Kalmyks of Russia until 1924, when it was replaced by the Cyrillic alphabet. In Xinjiang, China the Oirats still use it.
Buryat alphabet.
Another alphabet was created in 1905 by the Buryat monk Agvan Dorjiev (1850–1938). It was meant to also reduce ambiguity, and to support the Russian language in addition to Mongolian. The most significant change however was the elimination of the positional shape variations: All letters were based on the medial variant of the original Mongol alphabet.
'Phags-pa script (Square script).
The traditional Mongolian alphabet is not a perfect fit for the Mongolian language, and it would be impractical to extend it to a language with a very different phonology like Chinese. Therefore, during the Yuan Dynasty (ca. 1269), Kublai Khan asked a Tibetan monk, Drogön Chögyal Phagpa, to design a new script for use by the whole empire. Phagpa extended his native Tibetan script to encompass Mongolian and Chinese; the result was known by several descriptive names, such as the "Mongolian new script", but today is known as the 'Phags-pa script. The script did not receive wide acceptance and fell into disuse with the collapse of the Yuan dynasty in 1368. After this it was mainly used as a phonetic gloss for Mongols learning Chinese characters. However, scholars such as Gari Ledyard believe that in the meantime it was the source of some of the basic letters of the Korean hangul alphabet.
Soyombo script.
The Soyombo script is an abugida created by the Mongolian monk and scholar Bogdo Zanabazar in the late 17th century, that can also be used to write Tibetan and Sanskrit. A special glyph in the script, the "Soyombo", became a national symbol of Mongolia, and has appeared on the national flag since 1921, and on the national coat of arms since 1992, as well as money, stamps, etc.
Zanabazar had created it for the translation of Buddhist texts from Sanskrit or Tibetan, and both he and his students used it extensively for that purpose. Aside from historical texts, it can usually be found in temple inscriptions. It also has some relevance to linguistic research, because it reflects certain developments in the Mongolian language, such as that of long vowels.
Horizontal square script.
At around the same time, Zanabazar also developed the "Horizontal square script", which was only rediscovered in 1801. Its actual use is unknown. It was also largely based on the Tibetan alphabet, read left to right, and employed vowel diacritics above and below the consonant letters. Additionally, a dot was used below consonants to show that they were syllable-final.
Latin script.
On February 1, 1941, Mongolia officially adopted a Latin alphabet. Only two months later, on March 25 the decision was reversed. According to later official claims the alphabet had turned out to have not been thought out well. It was said not to distinguish all the sounds of the Mongolian language, and to be difficult to use. However, those seem to have been pretexts rather than the true reasons. Using "y" as feminine "u", with additional feminine "o" ("ө") and with additional consonants "ç" for "ch", "ş" for "sh" and ƶ for "zh", it successfully served in printing books and newspapers. Many of the Latin letters (f, h, p, v) were even rarely used while q, w and x were completely excluded. The adoption of the Cyrillic script a short time later, almost simultaneously with most Soviet republics, suggests political reasons.
Cyrillic script.
The most recent Mongolian alphabet is a based on the Cyrillic script, more specifically the Russian alphabet plus the letters, Өө /ö/ and Үү /ü/. It was introduced in the 1940s and has been in use as the official writing system of Mongolia ever since.
Foreign scripts.
Before the 13th century, foreign scripts had to be used to write the Mongolian language. And even during the reign of the Mongol Empire, people in the conquered areas often wrote it in their local systems. Most often it was transcribed phonetically using Chinese characters, as is the case with the only surviving copies of "The Secret History of the Mongols". Subjects from the Middle East hired into administrative functions would also often use Persian or Arabic scripts to write their Mongolian language documents.
External links.
 Media related to at Wikimedia Commons

</doc>
<doc id="40250" url="http://en.wikipedia.org/wiki?curid=40250" title="Specific impulse">
Specific impulse

Specific impulse (usually abbreviated "I"sp) is a measure of the efficiency of rocket and jet engines. By definition, it is the impulse delivered per unit of propellant consumed, and is dimensionally equivalent to the thrust generated per unit propellant flow rate. If mass (kilogram or slug) is used as the unit of propellant, then specific impulse has units of velocity. If weight (newton or pound force) is used instead, then specific impulse has units of time (seconds). The conversion constant between these two versions is the standard gravitational acceleration constant ("g"0). The higher the specific impulse, the lower the propellant flow rate required for a given thrust, and in the case of a rocket, the less propellant needed for a given delta-v, per the Tsiolkovsky rocket equation.
Specific impulse is a useful value to compare engines, much like "miles per gallon" or "liters per 100 kilometers" is used for cars. A propulsion method and system with a higher specific impulse is more propellant-efficient. While the unit of seconds can seem confusing to laypeople, it is fairly simple to understand as "hover-time": how long a rocket can "hover" before running out of fuel, given the weight of that propellant/fuel. Of course, the weight of the rocket has to be taken out of consideration and so does the reduction in fuel weight as it's expended; the basic idea is "how "long "can any given amount of "x" hold itself up". Obviously that must mean "...against Earth's gravity", which means nothing in non-Earth conditions; hence "I"sp being given in "velocity" when propellant is measured in mass rather than weight, and the question becomes "how "fast" can any given amount of "x" accelerate itself?"
Note that "I"sp describes efficiency in terms of "amount of propellant", not the engine (or engine/propellant design/combination). Higher "I"sp means less "propellant" needed to impart a given momentum, but it says nothing about the overall system's ability to supply needed thrust, especially with respect to time. Some systems with "very "high "I"sp (cf. ion thrusters) may have relatively very heavy/massive power generators, and/or produce thrust over a long period; thus, while "efficient" in terms of propellant mass carried, they may actually be quite poor at delivering high thrust quickly vs. "less efficient" engine/propellant designs.
Another number that measures the same thing, usually used for air breathing jet engines, is specific fuel consumption. Specific fuel consumption is inversely proportional to specific impulse and effective exhaust velocity. The actual exhaust velocity is the average speed of the exhaust jet as it leaves the vehicle. The effective exhaust velocity is the exhaust velocity that the propellant would need to produce the same thrust. The two are identical for an ideal rocket working in vacuum, but are radically different for an air-breathing jet engine that obtains extra thrust by accelerating air. Specific impulse and effective exhaust velocity are proportional.
General considerations.
The amount of propellant is normally measured either in units of mass or weight. If mass is used, specific impulse is an impulse per unit mass, which dimensional analysis shows to be a unit of speed, and so specific impulses are often measured in meters per second and are often termed effective exhaust velocity. However, if propellant weight is used instead, an impulse divided by a force (weight) turns out to be a unit of time, and so specific impulses are measured in seconds. These two formulations are both widely used and differ from each other by a factor of "g0", the dimensioned constant of gravitational acceleration at the surface of the Earth.
Note that the rate of gain of momentum of a rocket (including fuel) per unit time is equal to the thrust.
The higher the specific impulse, the less propellant is needed to produce a given thrust during a given time. In this regard a propellant is more efficient if the specific impulse is higher. This should not be confused with energy efficiency, which can even decrease as specific impulse increases, since propulsion systems that give high specific impulse require high energy to do so.
In addition it is important that thrust and specific impulse not be confused with each other. The specific impulse is a measure of the "impulse per unit of propellant" that is expended, while thrust is a measure of the momentary or peak force supplied by a particular engine. In many cases, propulsion systems with very high specific impulses—some ion thrusters reach 10,000 seconds—produce low thrusts.
When calculating specific impulse, only propellant that is carried with the vehicle before use is counted. For a chemical rocket the propellant mass therefore would include both fuel and oxidizer; for air-breathing engines only the mass of the fuel is counted, not the mass of air passing through the engine.
Units.
By far the most common unit used for specific impulse today is the second, and this is used both in the SI world as well as where Imperial units are used. Its chief advantages are that its units and numerical value are identical everywhere, and essentially everyone understands it. Nearly all manufacturers quote their engine performance in seconds, and it is also useful for specifying aircraft engine performance.
The effective exhaust velocity in units of m/s is also in reasonably common usage. For rocket engines it is reasonably intuitive, although for many rocket engines the effective exhaust speed is considerably different from the actual exhaust speed due to, for example, fuel and oxidizer that is dumped overboard after powering turbo-pumps. For air-breathing engines the effective exhaust velocity is not physically meaningful, although it can be used for comparison purposes nevertheless.
The values expressed in N·s/kg are not uncommonly seen and are numerically equal to the effective exhaust velocity in m/s (from Newton's second law and the definition of the newton.)
Another equivalent unit is specific fuel consumption. This has units of g/(kN·s) or lb/(lbf·h) and is inversely proportional to specific impulse. Specific fuel consumption is used extensively for describing the performance of air-breathing jet engines.
Specific impulse in seconds.
General definition.
For all vehicles specific impulse (impulse per unit weight-on-Earth of propellant) in seconds can be defined by the following equation:
where:
When using the more common English unit pounds/sec for mass, the conversion constant "g"0 is unnecessary, because the slug is dimensionally equivalent to pounds divided by "g"0:
"Isp" in seconds is equal to the amount of time a rocket must be fired to use a quantity of propellant with weight (measured at one standard gravity) equal to its thrust.
The advantage of this formulation is that it may be used for rockets, where all the reaction mass is carried on board, as well as aeroplanes, where most of the reaction mass is taken from the atmosphere. In addition, it gives a result that is independent of units used (provided the unit of time used is the second).
Rocketry.
In rocketry, where the only reaction mass is the propellant, an equivalent way of calculating the specific impulse in seconds is also frequently used. In this sense, specific impulse is defined as the thrust integrated over time per unit weight-on-Earth of the propellant:
where
In rockets, due to atmospheric effects, the specific impulse varies with altitude, reaching a maximum in a vacuum. This is because the exhaust velocity isn't simply a function of the chamber pressure, but is a function of the difference between the interior and exterior of the combustion chamber.
It is therefore important to note whether the specific impulse refers to operation in a vacuum or at sea level. Values are usually indicated with or near the units of specific impulse (e.g. "sl", "vac").
Specific impulse as a speed (effective exhaust velocity).
Because of the geocentric factor of "g"0 in the equation for specific impulse, many prefer to define the specific impulse of a rocket (in particular) in terms of thrust per unit mass flow of propellant (instead of per unit weight flow). This is an equally valid (and in some ways somewhat simpler) way of defining the effectiveness of a rocket propellant. For a rocket, the specific impulse defined in this way is simply the effective exhaust velocity relative to the rocket, "v"e. The two definitions of specific impulse are proportional to one another, and related to each other by:
where
This equation is also valid for air-breathing jet engines, but is rarely used in practice.
It is related to the thrust, or forward force on the rocket by the equation:
where formula_4 is the propellant mass flow rate, which is the rate of decrease of the vehicle's mass.
A rocket must carry all its fuel with it, so the mass of the unburned fuel must be accelerated along with the rocket itself. Minimizing the mass of fuel required to achieve a given push is crucial to building effective rockets. The Tsiolkovsky rocket equation shows that for a rocket with a given empty mass and a given amount of fuel, the total change in velocity it can accomplish is proportional to the effective exhaust velocity.
A spacecraft without propulsion follows an orbit determined by the gravitational field. Deviations from the corresponding velocity pattern (these are called Δ"v") are achieved by sending exhaust mass in the direction opposite to that of the desired velocity change.
Actual exhaust speed versus effective exhaust speed.
Note that effective exhaust velocity and actual exhaust velocity can be significantly different, for example when a rocket is run within the atmosphere, atmospheric pressure on the outside of the engine causes a retarding force that reduces the specific impulse, and the effective exhaust velocity goes down, whereas the actual exhaust velocity is largely unaffected. Also, sometimes rocket engines have a separate nozzle for the turbo-pump turbine gas, and then calculating the effective exhaust velocity requires averaging the two mass flows as well as accounting for any atmospheric pressure.
For air-breathing jet engines, particularly turbofans, the actual exhaust velocity and the effective exhaust velocity are different by orders of magnitude. This is because a good deal of additional momentum is obtained by using air as reaction mass. This allows a better match between the airspeed and the exhaust speed, which saves energy/propellant and enormously increases the effective exhaust velocity while reducing the actual exhaust velocity.
Energy efficiency.
Rockets.
For rockets and rocket-like engines such as ion-drives a higher formula_16 implies lower energy efficiency: the power needed to run the engine is simply:
where ve is the actual jet velocity.
whereas from momentum considerations the thrust generated is:
Dividing the power by the thrust to obtain the specific power requirements we get:
Hence the power needed is proportional to the exhaust velocity, with higher velocities needing higher power for the same thrust, causing less energy efficiency per unit thrust.
However, the total energy for a mission depends on total propellant use, as well as how much energy is needed per unit of propellant. For low exhaust velocity with respect to the mission delta-v, enormous amounts of reaction mass is needed. In fact a very low exhaust velocity is not energy efficient at all for this reason; but it turns out that neither are very high exhaust velocities.
Theoretically, for a given delta-v, in space, among all fixed values for the exhaust speed the value formula_20 is the most energy efficient for a specified (fixed) final mass, see energy in spacecraft propulsion.
However, a variable exhaust speed can be more energy efficient still. For example, if a rocket is accelerated from some positive initial speed using an exhaust speed equal to the speed of the rocket no energy is lost as kinetic energy of reaction mass, since it becomes stationary. (Theoretically, by making this initial speed low and using another method of obtaining this small speed, the energy efficiency approaches 100%, but requires a large initial mass.) In this case the rocket keeps the same momentum, so its speed is inversely proportional to its remaining mass. During such a flight the kinetic energy of the rocket is proportional to its speed and, correspondingly, inversely proportional to its remaining mass. The power needed per unit acceleration is constant throughout the flight; the reaction mass to be expelled per unit time to produce a given acceleration is proportional to the square of the rocket's remaining mass.
Also it is advantageous to expel reaction mass at a location where the gravity potential is low, see Oberth effect.
Air breathing.
Air-breathing engines such as turbojets increase the momentum generated from their propellant by using it to power the acceleration of inert air rearwards. It turns out that the amount of energy needed to generate a particular amount of thrust is inversely proportional to the amount of air propelled rearwards, thus increasing the mass of air (as with a turbofan) both improves energy efficiency as well as formula_16.
Examples.
An example of a specific impulse measured in time is 453 seconds, which is equivalent to an effective exhaust velocity of 4,440 m/s, for the Space Shuttle Main Engines when operating in a vacuum. An air-breathing jet engine typically has a much larger specific impulse than a rocket; for example a turbofan jet engine may have a specific impulse of 6,000 seconds or more at sea level whereas a rocket would be around 200–400 seconds.
An air-breathing engine is thus much more propellant efficient than a rocket engine, because the actual exhaust speed is much lower, the air provides an oxidizer, and air is used as reaction mass. Since the physical exhaust velocity is lower, the kinetic energy the exhaust carries away is lower and thus the jet engine uses far less energy to generate thrust (at subsonic speeds). While the "actual" exhaust velocity is lower for air-breathing engines, the "effective" exhaust velocity is very high for jet engines. This is because the effective exhaust velocity calculation essentially assumes that the propellant is providing all the thrust, and hence is not physically meaningful for air-breathing engines; nevertheless, it is useful for comparison with other types of engines.
The highest specific impulse for a chemical propellant ever test-fired in a rocket engine was 542 seconds (5,320 m/s) with a tripropellant of lithium, fluorine, and hydrogen. However, this combination is impractical; see rocket fuel.
Nuclear thermal rocket engines differ from conventional rocket engines in that thrust is created strictly through thermodynamic phenomena, with no chemical reaction. The nuclear rocket typically operates by passing hydrogen gas through a superheated nuclear core. Testing in the 1960s yielded specific impulses of about 850 seconds (8,340 m/s), about twice that of the Space Shuttle engines.
A variety of other non-rocket propulsion methods, such as ion thrusters, give much higher specific impulse but with much lower thrust; for example the Hall effect thruster on the SMART-1 satellite has a specific impulse of 1,640 s (16,100 m/s) but a maximum thrust of only 68 millinewtons. The Variable specific impulse magnetoplasma rocket (VASIMR) engine currently in development will theoretically yield 20,000−300,000 m/s, and a maximum thrust of 5.7 newtons.
Larger engines.
Here are some example numbers for larger jet and rocket engines:
Model rocketry.
Specific impulse is also used to measure performance in model rocket motors. Following are some of Estes' claimed values for specific impulses for several of their rocket motors: Estes Industries is a large, well-known American seller of model rocket components. The specific impulse for these model rocket motors is much lower than for many other rocket motors because the manufacturer uses black powder propellant and emphasizes safety rather than maximum performance. The burn rate and hence chamber pressure and maximum thrust of model rocket motors is also tightly controlled.

</doc>
<doc id="40252" url="http://en.wikipedia.org/wiki?curid=40252" title="Rowrbrazzle">
Rowrbrazzle

Rowrbrazzle is an Amateur Press Association magazine devoted to funny animal cartoon illustration.
History.
"Rowrbrazzle" was founded in 1983 by Marc Schirmeister, who published the first issue in February 1984, and was editor for the first nineteen quarterly mailings. Fred Patten was then editor from February 1989 (Issue 20) through February 2005 when he retired due to poor health after Issue 84. Edd Vick became Official Editor from April 2005 (Issue 85) to April 2007 (Issue 93), and William Earl Haskell has been the Official Editor from Issue 94 (July 2007) to the present (Issue 122, July 2014).
The first Rowrbrazzle was distributed to the association membership in February 1984.
Number 122 was distributed in July 2014, in a continuing uninterrupted run of over 30 years.
Significance.
Fred Patten, onetime editor of "Rowrbrazzle", had this view of Rowrbrazzle's significance:

</doc>
<doc id="40253" url="http://en.wikipedia.org/wiki?curid=40253" title="Precognition">
Precognition

Precognition (from the Latin "præ-", "before" and "cognitio", "acquiring knowledge"), also called future sight, and second sight, is an alleged psychic ability to see events in the future.
As with other forms of extrasensory perception, there is no evidence that precognition is a real ability possessed by anyone, however it still appears within movies, books, and discussion within the parapsychology community.
Scientific investigation of extrasensory perception is complicated by the definition which implies that the phenomena go against established principles of science. Specifically, precognition would violate the principle that an effect cannot occur before its cause. There are established biases affecting human memory and judgment of probability that sometimes create convincing but false impressions of precognition.
Belief.
Belief in precognition has been related to superstition. A 1978 Gallup poll found that 37% of Americans surveyed believed in precognition. According to psychologists Tobacyk and Milford, belief in precognition was greater in college women than in men, and a 2007 Gallup poll found that women were more prone to superstitious beliefs in general.
A 2013 study discovered that greater belief in precognition was held by those who feel low in control, and the belief can act as a psychological coping mechanism.
Experiments.
In the early 20th century J. W. Dunne, a British aeronautics engineer, recorded each of his dreams as they occurred to him, identifying any correspondences between his future experiences and his recorded dreams. In 1927, he reported his findings, in "An Experiment with Time". In this work, he alleges that 10% of his dreams appeared to represent some future event, pertaining to some relatively trivial incident in his own life, or some major news events appearing in the press after the dream. Dunne concluded that precognitive dreams are common occurrences: he claims that many people have them without realizing it, largely because they do not recall the details of the dream. Dunne also wrote about an experiment he conducted recording the dreams of other participants, and sought to associate them with subsequent experiences. Dunne felt these confirmed his claims, but a 1933 independent experiment failed to replicate his findings.
The first ongoing and organized research program on precognition was instituted by Joseph Banks Rhine in the 1930s at Duke University's Parapsychology Laboratory. Rhine used a method of forced-choice matching in which participants guessed the order of a deck of 25 cards, each five of which bore one of five geometrical symbols. The experiment was not blinded, so participants were able to read the symbols through the back of the cards, and were able to see and hear the experimenters throughout the experiment. This sensory leakage contributed to Rhine's experiments being discredited.
Experiments by Samuel G. Soal ran forced-choice ESP experiments in which someone attempted to identify which of five animal pictures a subject in another room was looking at. Their performance on this task was at chance, but when the scores were matched with the card that came "after" the target card, three of the thirteen subjects showed a very high hit rate. Rhine described Soal's work as "a milestone in the field". George Price reviewed the experiment in "Science" in 1955, and concluded that the positive results not attributable to error were more likely the result of deliberate fraud. This prompted several replies that Price's criticism was unfair. In 1978, the experiments were exposed as fraudulent. The statistician and paragnost Betty Markwick, while seeking to vindicate Soal, discovered that he had altered his data to create all the extra hits and give the study its statistical significance. The untainted experimental results showed no evidence of precognition in the hits or the ratios.
Following these experiments, a more automated technique of experimentation was introduced that did not rely on hand-scoring of equivalence between targets and guesses, and in which the targets could be more reliably and readily tested at random. This involved testing for precognition with the use of high-speed random event generators (REG), as introduced by Helmut Schmidt in 1969, and at the Princeton Engineering Anomalies Research Lab. The psychologist C. E. M. Hansel found flaws in all of Schmidt's experiments into precognition. Hansel found that necessary precautions were not taken, there was no presence of an observer or second-experimenter in any of the experiments, no counterchecking of the records and no separate machines used for high and low score attempts.
"Feeling the Future" controversy.
In 2011, the parapsychologist Daryl Bem published the article "Feeling the Future: Experimental Evidence for Anomalous Retroactive Influences on Cognition and Affect" in the "Journal of Personality and Social Psychology" that offered statistical evidence for precognition. The article's findings challenged modern scientific conceptions about the unidirectional nature of time. Its presentation by a respected researcher and its publication by an upper tier journal engendered much controversy. In addition to criticism of the paper itself, the paper's publication prompted a wider debate on the validity of peer review process for allowing such a paper to be published. Bem appeared on MSNBC and "The Colbert Report" to discuss the experiment.
Jeffrey Rouder and Richard Morey who applied a meta-analytical Bayes factor to Bem's data concluded "We remain unconvinced of the viability of ESP. There is no plausible mechanism for it, and it seems contradicted by well-substantiated theories in both physics and biology. Against this background, a change in odds of 40 is negligible.
After evaluating Bem's nine experiments, psychologist James Alcock said that he found metaphorical "dirty test tubes," or serious methodological flaws, such as changing the procedures partway through the experiments and combining results of tests with different chances of significance. It is unknown how many tests were actually performed, nor is there an explanation of how it was determined that participants had "settled down" after seeing erotic images. Alcock concludes that almost everything that could go wrong with Bem's experiments did go wrong. Bem's response to Alcock's critique appeared online at the "Skeptical Inquirer" website and Alcock replied to these comments in a third article at the same website.
In 2012, the same journal that published Bem's original experiments, the "Journal of Personality and Social Psychology" (Vol. 103, No. 6), published “Correcting the Past: Failures to Replicate Psi” by Jeff Galek of Carnegie Mellon University, Robyn A. LeBoeuf of the University of Florida, Leif D. Nelson of the University of California at Berkeley, and Joseph P. Simmons of the University of Pennsylvania. The paper reported seven experiments testing for precognition that "found no evidence supporting its existence.”
Scientific reception.
There is no known mechanism for precognition. Precognition would violate the principle of antecedence (causality), that an effect does not happen before its cause.
The physicist John Taylor has written "since only positive energies are possible, particles going backward in time cannot exist. Any claim that they do is purely a fantasy in the mind of the parapsychologist. There is therefore no direct justification for precognition from physics... experimental evidence from high energy physics is strongly against it."
Neuroscientist Samuel Schwarzkopf has written that precognition contradicts "most of the neuroscience and psychology literature, from electrophysiology and neuroimaging to temporal effects found in psychophysical research."
Various psychological processes have been offered to explain experiences of apparent precognition. These include:
Some psychologists have explained the apparent prevalence of precognitive dreams in terms of memory biases, namely a selective memory for accurate predictions and distorted memory so that dreams are retrospectively fitted onto subsequent events. In one experiment, subjects were asked to write down their dreams in a diary. This prevented the selective memory effect, and the dreams no longer seemed accurate about the future. Another experiment gave subjects a fake diary of a student with apparently precognitive dreams. This diary described events from the person's life, as well as some predictive dreams and some non-predictive dreams. When subjects were asked to recall the dreams they had read, they remembered more of the successful predictions than unsuccessful ones.
In dreams.
An early inquiry into allegedly prophetic dreams was done by Aristotle in his "On Divination in Sleep". His criticism of these claims appeals to the fact that "the sender of such dreams should be God", and "the fact that those to whom he sends them are not the best and wisest, but merely commonplace persons." Thus: "Most [so-called prophetic] dreams are, however, to be classed as mere coincidences...", here "coincidence" being defined by Aristotle as that which does not take "place according to a universal or general rule" and referring to things which are not of themselves by necessity causally connected. His example being taking a walk during an eclipse, neither the walk nor the eclipse being apparently causally connected and so only by "coincidence" do they occur simultaneously.
In 1932 Charles Lindbergh's infant son was kidnapped and murdered. The psychologists Henry Murray and D. R. Wheeler tested precognitive dreams by inviting the public to report any dreams of the child. A total of 1,300 dreams were reported. Only five percent envisioned the child dead and only 4 of the 1,300 envisioned the location of the body as buried amongst trees. This number was no better than chance.
David Ryback, a psychologist in Atlanta, used a questionnaire survey approach to investigate precognitive dreaming in college students. His survey of over 433 participants showed that 290 or 66.9 percent reported some form of paranormal dream. He rejected many of these reports, but claimed that 8.8 percent of the population was having actual precognitive dreams.
Dreams which appear to be precognitive may in fact be the result of the Law of large numbers. The psychologist Stuart Sutherland has written:
Suppose that you can remember ten incidents from a night's dreaming, at least when prompted by a similar incident occurring a day. Now consider how many incidents occur during a day, including those you read about in the paper, watch on television or hear from your friends. There are a vast number and it is highly probable that from time to time one of them will, at least to some extent, resemble one of those from your dreams. When one or more of these coincidences occur, people are likely to conclude that dreams foretell the future.
Robert Todd Carroll, author of "The Skeptic's Dictionary" put it this way: "Say the odds are a million to one that when a person has a dream of an airplane crash, there is an airplane crash the next day. With 6 billion people having an average of 250 dream themes each per night, there should be about 1.5 million people a day who have dreams that seem clairvoyant."

</doc>
<doc id="40254" url="http://en.wikipedia.org/wiki?curid=40254" title="Genetic algorithm">
Genetic algorithm

In the field of artificial intelligence, a genetic algorithm (GA) is a search heuristic that mimics the process of natural selection. This heuristic (also sometimes called a metaheuristic) is routinely used to generate useful solutions to optimization and search problems. Genetic algorithms belong to the larger class of evolutionary algorithms (EA), which generate solutions to optimization problems using techniques inspired by natural evolution, such as inheritance, mutation, selection, and crossover.
Genetic algorithms find application in bioinformatics, phylogenetics, computational science, engineering, economics, chemistry, manufacturing, mathematics, physics, pharmacometrics and other fields.
Methodology.
In a genetic algorithm, a population of candidate solutions (called individuals, creatures, or phenotypes) to an optimization problem is evolved toward better solutions. Each candidate solution has a set of properties (its chromosomes or genotype) which can be mutated and altered; traditionally, solutions are represented in binary as strings of 0s and 1s, but other encodings are also possible.
The evolution usually starts from a population of randomly generated individuals, and is an iterative process, with the population in each iteration called a "generation". In each generation, the fitness of every individual in the population is evaluated; the fitness is usually the value of the objective function in the optimization problem being solved. The more fit individuals are stochastically selected from the current population, and each individual's genome is modified (recombined and possibly randomly mutated) to form a new generation. The new generation of candidate solutions is then used in the next iteration of the algorithm. Commonly, the algorithm terminates when either a maximum number of generations has been produced, or a satisfactory fitness level has been reached for the population.
A typical genetic algorithm requires:
A standard representation of each candidate solution is as an array of bits. Arrays of other types and structures can be used in essentially the same way. The main property that makes these genetic representations convenient is that their parts are easily aligned due to their fixed size, which facilitates simple crossover operations. Variable length representations may also be used, but crossover implementation is more complex in this case. Tree-like representations are explored in genetic programming and graph-form representations are explored in evolutionary programming; a mix of both linear chromosomes and trees is explored in gene expression programming.
Once the genetic representation and the fitness function are defined, a GA proceeds to initialize a population of solutions and then to improve it through repetitive application of the mutation, crossover, inversion and selection operators.
Initialization.
The population size depends on the nature of the problem, but typically contains several hundreds or thousands of possible solutions. Often, the initial population is generated randomly, allowing the entire range of possible solutions (the "search space"). Occasionally, the solutions may be "seeded" in areas where optimal solutions are likely to be found.
Selection.
During each successive generation, a proportion of the existing population is selected to breed a new generation. Individual solutions are selected through a "fitness-based" process, where fitter solutions (as measured by a fitness function) are typically more likely to be selected. Certain selection methods rate the fitness of each solution and preferentially select the best solutions. Other methods rate only a random sample of the population, as the former process may be very time-consuming.
The fitness function is defined over the genetic representation and measures the "quality" of the represented solution. The fitness function is always problem dependent. For instance, in the knapsack problem one wants to maximize the total value of objects that can be put in a knapsack of some fixed capacity. A representation of a solution might be an array of bits, where each bit represents a different object, and the value of the bit (0 or 1) represents whether or not the object is in the knapsack. Not every such representation is valid, as the size of objects may exceed the capacity of the knapsack. The "fitness" of the solution is the sum of values of all objects in the knapsack if the representation is valid, or 0 otherwise.
In some problems, it is hard or even impossible to define the fitness expression; in these cases, a simulation may be used to determine the fitness function value of a phenotype (e.g. computational fluid dynamics is used to determine the air resistance of a vehicle whose shape is encoded as the phenotype), or even interactive genetic algorithms are used.
Genetic operators.
The next step is to generate a second generation population of solutions from those selected through a combination of genetic operators: crossover (also called recombination), and mutation.
For each new solution to be produced, a pair of "parent" solutions is selected for breeding from the pool selected previously. By producing a "child" solution using the above methods of crossover and mutation, a new solution is created which typically shares many of the characteristics of its "parents". New parents are selected for each new child, and the process continues until a new population of solutions of appropriate size is generated.
Although reproduction methods that are based on the use of two parents are more "biology inspired", some research suggests that more than two "parents" generate higher quality chromosomes.
These processes ultimately result in the next generation population of chromosomes that is different from the initial generation. Generally the average fitness will have increased by this procedure for the population, since only the best organisms from the first generation are selected for breeding, along with a small proportion of less fit solutions. These less fit solutions ensure genetic diversity within the genetic pool of the parents and therefore ensure the genetic diversity of the subsequent generation of children.
Opinion is divided over the importance of crossover versus mutation. There are many references in Fogel (2006) that support the importance of mutation-based search.
Although crossover and mutation are known as the main genetic operators, it is possible to use other operators such as regrouping, colonization-extinction, or migration in genetic algorithms.
It is worth tuning parameters such as the mutation probability, crossover probability and population size to find reasonable settings for the problem class being worked on. A very small mutation rate may lead to genetic drift (which is non-ergodic in nature). A recombination rate that is too high may lead to premature convergence of the genetic algorithm. A mutation rate that is too high may lead to loss of good solutions, unless elitist selection is employed.
Termination.
This generational process is repeated until a termination condition has been reached. Common terminating conditions are:
The building block hypothesis.
Genetic algorithms are simple to implement, but their behavior is difficult to understand. In particular it is difficult to understand why these algorithms frequently succeed at generating solutions of high fitness when applied to practical problems. The building block hypothesis (BBH) consists of:
Goldberg describes the heuristic as follows:
Limitations.
There are limitations of the use of a genetic algorithm compared to alternative optimization algorithms:
Variants.
Chromosome representation.
The simplest algorithm represents each chromosome as a bit string. Typically, numeric parameters can be represented by integers, though it is possible to use floating point representations. The floating point representation is natural to evolution strategies and evolutionary programming. The notion of real-valued genetic algorithms has been offered but is really a misnomer because it does not really represent the building block theory that was proposed by John Henry Holland in the 1970s. This theory is not without support though, based on theoretical and experimental results (see below). The basic algorithm performs crossover and mutation at the bit level. Other variants treat the chromosome as a list of numbers which are indexes into an instruction table, nodes in a linked list, hashes, objects, or any other imaginable data structure. Crossover and mutation are performed so as to respect data element boundaries. For most data types, specific variation operators can be designed. Different chromosomal data types seem to work better or worse for different specific problem domains.
When bit-string representations of integers are used, Gray coding is often employed. In this way, small changes in the integer can be readily effected through mutations or crossovers. This has been found to help prevent premature convergence at so called "Hamming walls", in which too many simultaneous mutations (or crossover events) must occur in order to change the chromosome to a better solution.
Other approaches involve using arrays of real-valued numbers instead of bit strings to represent chromosomes. Results from the theory of schemata suggest that in general the smaller the alphabet, the better the performance, but it was initially surprising to researchers that good results were obtained from using real-valued chromosomes. This was explained as the set of real values in a finite population of chromosomes as forming a "virtual alphabet" (when selection and recombination are dominant) with a much lower cardinality than would be expected from a floating point representation.
An expansion of the Genetic Algorithm accessible problem domain can be obtained through more complex encoding of the solution pools by concatenating several types of heterogenously encoded genes into one chromosome. This particular approach allows for solving optimization problems that require vastly disparate definition domains for the problem parameters. For instance, in problems of cascaded controller tuning, the internal loop controller structure can belong to a conventional regulator of three parameters, whereas the external loop could implement a linguistic controller (such as a fuzzy system) which has an inherently different description. This particular form of encoding requires a specialized crossover mechanism that recombines the chromosome by section, and it is a useful tool for the modelling and simulation of complex adaptive systems, especially evolution processes.
Elitism.
A practical variant of the general process of constructing a new population is to allow the best organism(s) from the current generation to carry over to the next, unaltered. This strategy is known as "elitist selection" and guarantees that the solution quality obtained by the GA will not decrease from one generation to the next.
Parallel implementations.
Parallel implementations of genetic algorithms come in two flavours. Coarse-grained parallel genetic algorithms assume a population on each of the computer nodes and migration of individuals among the nodes. Fine-grained parallel genetic algorithms assume an individual on each processor node which acts with neighboring individuals for selection and reproduction.
Other variants, like genetic algorithms for online optimization problems, introduce time-dependence or noise in the fitness function.
Adaptive GAs.
Genetic algorithms with adaptive parameters (adaptive genetic algorithms, AGAs) is another significant and promising variant of genetic algorithms. The probabilities of crossover (pc) and mutation (pm) greatly determine the degree of solution accuracy and the convergence speed that genetic algorithms can obtain. Instead of using fixed values of "pc" and "pm", AGAs utilize the population information in each generation and adaptively adjust the "pc" and "pm" in order to maintain the population diversity as well as to sustain the convergence capacity. In AGA (adaptive genetic algorithm), the adjustment of "pc" and "pm" depends on the fitness values of the solutions. In "CAGA" (clustering-based adaptive genetic algorithm), through the use of clustering analysis to judge the optimization states of the population, the adjustment of "pc" and "pm" depends on these optimization states.
It can be quite effective to combine GA with other optimization methods. GA tends to be quite good at finding generally good global solutions, but quite inefficient at finding the last few mutations to find the absolute optimum. Other techniques (such as simple hill climbing) are quite efficient at finding absolute optimum in a limited region. Alternating GA and hill climbing can improve the efficiency of GA while overcoming the lack of robustness of hill climbing.
This means that the rules of genetic variation may have a different meaning in the natural case. For instance – provided that steps are stored in consecutive order – crossing over may sum a number of steps from maternal DNA adding a number of steps from paternal DNA and so on. This is like adding vectors that more probably may follow a ridge in the phenotypic landscape. Thus, the efficiency of the process may be increased by many orders of magnitude. Moreover, the inversion operator has the opportunity to place steps in consecutive order or any other suitable order in favour of survival or efficiency. (See for instance or example in travelling salesman problem, in particular the use of an edge recombination operator.)
A variation, where the population as a whole is evolved rather than its individual members, is known as gene pool recombination.
A number of variations have been developed to attempt to improve performance of GAs on problems with a high degree of fitness epistasis, i.e. where the fitness of a solution consists of interacting subsets of its variables. Such algorithms aim to learn (before exploiting) these beneficial phenotypic interactions. As such, they are aligned with the Building Block Hypothesis in adaptively reducing disruptive recombination. Prominent examples of this approach include the mGA, GEMGA and LLGA.
Problem domains.
Problems which appear to be particularly appropriate for solution by genetic algorithms include timetabling and scheduling problems, and many scheduling software packages are based on GAs. GAs have also been applied to engineering. Genetic algorithms are often applied as an approach to solve global optimization problems.
As a general rule of thumb genetic algorithms might be useful in problem domains that have a complex fitness landscape as mixing, i.e., mutation in combination with crossover, is designed to move the population away from local optima that a traditional hill climbing algorithm might get stuck in. Observe that commonly used crossover operators cannot change any uniform population. Mutation alone can provide ergodicity of the overall genetic algorithm process (seen as a Markov chain).
Examples of problems solved by genetic algorithms include: mirrors designed to funnel sunlight to a solar collector, antennae designed to pick up radio signals in space, and walking methods for computer figures.
In his "Algorithm Design Manual", Skiena advises against genetic algorithms for any task:
[I]t is quite unnatural to model applications in terms of genetic operators like mutation and crossover on bit strings. The pseudobiology adds another level of complexity between you and your problem. Second, genetic algorithms take a very long time on nontrivial problems. [...] [T]he analogy with evolution—where significant progress require [sic] millions of years—can be quite appropriate.
I have never encountered any problem where genetic algorithms seemed to me the right way to attack it. Further, I have never seen any computational results reported using genetic algorithms that have favorably impressed me. Stick to simulated annealing for your heuristic search voodoo needs.—Steven Skiena:267
History.
In 1950, Alan Turing proposed a "learning machine" which would parallel the principles of evolution. Computer simulation of evolution started as early as in 1954 with the work of Nils Aall Barricelli, who was using the computer at the Institute for Advanced Study in Princeton, New Jersey. His 1954 publication was not widely noticed. Starting in 1957, the Australian quantitative geneticist Alex Fraser published a series of papers on simulation of artificial selection of organisms with multiple loci controlling a measurable trait. From these beginnings, computer simulation of evolution by biologists became more common in the early 1960s, and the methods were described in books by Fraser and Burnell (1970) and Crosby (1973). Fraser's simulations included all of the essential elements of modern genetic algorithms. In addition, Hans-Joachim Bremermann published a series of papers in the 1960s that also adopted a population of solution to optimization problems, undergoing recombination, mutation, and selection. Bremermann's research also included the elements of modern genetic algorithms. Other noteworthy early pioneers include Richard Friedberg, George Friedman, and Michael Conrad. Many early papers are reprinted by Fogel (1998).
Although Barricelli, in work he reported in 1963, had simulated the evolution of ability to play a simple game, artificial evolution became a widely recognized optimization method as a result of the work of Ingo Rechenberg and Hans-Paul Schwefel in the 1960s and early 1970s – Rechenberg's group was able to solve complex engineering problems through evolution strategies. Another approach was the evolutionary programming technique of Lawrence J. Fogel, which was proposed for generating artificial intelligence. Evolutionary programming originally used finite state machines for predicting environments, and used variation and selection to optimize the predictive logics. Genetic algorithms in particular became popular through the work of John Holland in the early 1970s, and particularly his book "Adaptation in Natural and Artificial Systems" (1975). His work originated with studies of cellular automata, conducted by Holland and his students at the University of Michigan. Holland introduced a formalized framework for predicting the quality of the next generation, known as Holland's Schema Theorem. Research in GAs remained largely theoretical until the mid-1980s, when The First International Conference on Genetic Algorithms was held in Pittsburgh, Pennsylvania.
As academic interest grew, the dramatic increase in desktop computational power allowed for practical application of the new technique. In the late 1980s, General Electric started selling the world's first genetic algorithm product, a mainframe-based toolkit designed for industrial processes. In 1989, Axcelis, Inc. released Evolver, the world's first commercial GA product for desktop computers. The New York Times technology writer John Markoff wrote about Evolver in 1990, and it remained the only interactive commercial genetic algorithm until 1995. Evolver was sold to Palisade in 1997, translated into several languages, and is currently in its 6th version.
Related techniques.
Parent fields.
Genetic algorithms are a sub-field of:
Related fields.
Evolutionary algorithms.
Evolutionary algorithms is a sub-field of evolutionary computing.
Swarm intelligence.
Swarm intelligence is a sub-field of evolutionary computing.
Other evolutionary computing algorithms.
Evolutionary computation is a sub-field of the metaheuristic methods.
Other metaheuristic methods.
Metaheuristic methods broadly fall within stochastic optimisation methods.
Bibliography.
</dl>

</doc>
<doc id="40255" url="http://en.wikipedia.org/wiki?curid=40255" title="Jupiter (mythology)">
Jupiter (mythology)

Jupiter (Latin: "Iuppiter"; ; genitive case: "Iovis"; ) or Jove is the king of the gods and the god of sky and thunder in myth. Jupiter was the chief deity of Roman state religion throughout the Republican and Imperial eras, until Christianity became the dominant religion of the Empire. In Roman mythology, he negotiates with Numa Pompilius, the second king of Rome, to establish principles of Roman religion such as sacrifice.
Jupiter is usually thought to have originated as a sky god. His identifying implement is the thunderbolt, and his primary sacred animal is the eagle, which held precedence over other birds in the taking of auspices and became one of the most common symbols of the Roman army (see Aquila). The two emblems were often combined to represent the god in the form of an eagle holding in its claws a thunderbolt, frequently seen on Greek and Roman coins. As the sky-god, he was a divine witness to oaths, the sacred trust on which justice and good government depend. Many of his functions were focused on the Capitoline ("Capitol Hill"), where the citadel was located. He was the chief deity of the early Capitoline Triad with Mars and Quirinus. In the later Capitoline Triad, he was the central guardian of the state with Juno and Minerva. His sacred tree was the oak.
The Romans regarded Jupiter as the equivalent of the Greek Zeus, and in Latin literature and Roman art, the myths and iconography of Zeus are adapted under the name "Iuppiter". In the Greek-influenced tradition, Jupiter was the brother of Neptune and Pluto. Each presided over one of the three realms of the universe: sky, the waters, and the underworld. The Italic Diespiter was also a sky god who manifested himself in the daylight, usually but not always identified with Jupiter. Tinia is usually regarded as his Etruscan counterpart.
Jupiter and the state.
The Romans believed that Jupiter granted them supremacy because they had honoured him more than any other people had. Jupiter was "the fount of the auspices upon which the relationship of the city with the gods rested." He personified the divine authority of Rome's highest offices, internal organization, and external relations. His image in the Republican and Imperial Capitol bore regalia associated with Rome's ancient kings and the highest consular and Imperial honours.
The consuls swore their oath of office in Jupiter's name, and honoured him on the annual "feriae" of the Capitol in September. To thank him for his help (and to secure his continued support), they offered him a white ox "(bos mas)" with gilded horns. A similar offering was made by triumphal generals, who surrendered the tokens of their victory at the feet of Jupiter's statue in the Capitol. Some scholars have viewed the "triumphator" as embodying (or impersonating) Jupiter in the triumphal procession.
Jupiter's association with kingship and sovereignty was reinterpreted as Rome's form of government changed. Originally, Rome was ruled by kings; after the monarchy was abolished and the Republic established, religious prerogatives were transferred to the "patres", the patrician ruling class. Nostalgia for the kingship "(affectatio regni)" was considered treasonous. Those suspected of harbouring monarchical ambitions were punished, regardless of their service to the state. In the 5th century BC, the "triumphator" Furius Camillus was sent into exile after he drove a chariot with a team of four white horses "(quadriga)"—an honour reserved for Jupiter himself. After the Gallic occupation ended and self-rule was restored, Manlius Capitolinus took on regal pretensions and was executed as a traitor by being cast from the Tarpeian Rock. His house on the Capitoline was razed, and it was decreed that no patrician should ever be allowed to live there. Capitoline Jupiter finds himself in a delicate position: he represents a continuity of royal power from the Regal period, and confers power on the magistrates who pay their respects to him; at the same time he embodies that which is now forbidden, abhorred, and scorned.
During the Conflict of the Orders, Rome's plebeians demanded the right to hold political and religious office. During their first "secessio" (similar to a general strike), they withdrew from the city and threatened to found their own. When they agreed to come back to Rome they vowed the hill where they had retreated to Jupiter as symbol and guarantor of the unity of the Roman "res publica". Plebeians eventually became eligible for all the magistracies and most priesthoods, but the high priest of Jupiter "(Flamen Dialis)" remained the preserve of patricians.
Flamen and Flaminica Dialis.
Jupiter was served by the patrician Flamen Dialis, the highest-ranking member of the "flamines," a college of fifteen priests in the official public cult of Rome, each of whom was devoted to a particular deity. His wife, the Flaminica Dialis, had her own duties, and presided over the sacrifice of a ram to Jupiter on each of the "nundinae", the "market" days of a calendar cycle, comparable to a week. The couple were required to marry by the exclusive patrician ritual "confarreatio", which included a sacrifice of spelt bread to Jupiter Farreus (from "far", "wheat, grain").
The office of Flamen Dialis was circumscribed by several unique ritual prohibitions, some of which shed light on the sovereign nature of the god himself. For instance, the "flamen" may remove his clothes or "apex" (his pointed hat) only when under a roof, in order to avoid showing himself naked to the sky—that is, "as if under the eyes of Jupiter" as god of the heavens. Every time the Flaminica saw a lightning bolt or heard a clap of thunder (Jupiter's distinctive instrument), she was prohibited from carrying on with her normal routine until she placated the god.
Some privileges of the "flamen" of Jupiter may reflect the regal nature of Jupiter: he had the use of the curule chair, and was the only priest "(sacerdos)" who was preceded by a lictor and had a seat in the senate. Other regulations concern his ritual purity and his separation from the military function; he was forbidden to ride a horse or see the army outside the sacred boundary of Rome "(pomerium)." Although he served the god who embodied the sanctity of the oath, it was not religiously permissible "(fas)" for the Dialis to swear an oath. He could not have contacts with anything dead or connected with death: corpses, funerals, funeral fires, raw meat. This set of restrictions reflects the fulness of life and absolute freedom that are features of Jupiter.
Augurs.
The "augures publici", augurs were a college of "sacerdotes" who were in charge of all inaugurations and of the performing of ceremonies known as "auguria". Their creation was traditionally ascribed to Romulus. They were considered the only official interpreters of Jupiter's will, thence they were essential to the very existence of the Roman State as Romans saw in Jupiter the only source of state authority.
Fetials.
The fetials were a college of 20 men devoted to the religious administration of international affairs of state. Their task was to preserve and apply the fetial law "(ius fetiale)", a complex set of procedures aimed at ensuring the protection of the gods in Rome's relations with foreign states. Iuppiter Lapis is the god under whose protection they act, and whom the chief fetial "(pater patratus)" invokes in the rite concluding a treaty. If a declaration of war ensues, the fetial calls upon Jupiter and Quirinus, the heavenly, earthly and chthonic gods as witnesses of any potential violation of the "ius". He can then declare war within 33 days.
The action of the fetials falls under Jupiter's jurisdiction as the divine defender of good faith. Several emblems of the fetial office pertain to Jupiter. The "silex" was the stone used for the fetial sacrifice, housed in the Temple of Iuppiter Feretrius, as was their sceptre. Sacred herbs "(sagmina)", sometimes identified as vervain, had to be taken from the nearby citadel "(arx)" for their ritual use.
Jupiter and religion in the secessions of the plebs.
The role of Jupiter in the conflict of the orders is a reflection of the religiosity of the Romans. Whereas the patricians were able to claim the support of the supreme god quite naturally being the holders of the auspices of the State, the plebeians argued that as Jupiter was the source of justice he was on their side since their cause was just.
The first secession was caused by the excessive burden of debts that weighed on the plebs. Because of the legal institute of the "nexum" a debtor could become a slave of his creditor. The plebeians argued the debts had become unsustainable because of the expenses of the wars wanted by the patricians. As the senate did not accede to the proposal of a total debt remission advanced by dictator and augur Manius Valerius Maximus the plebs retired on the Mount Sacer, a hill located three Roman miles to the North-northeast of Rome, past the Nomentan bridge on river Anio. The place is windy and was usually the site of rites of divination performed by haruspices. The senate in the end sent a delegation composed of ten members with full powers of making a deal with the plebs, of which were part Menenius Agrippa and Manius Valerius. It was Valerius, according to the inscription found at Arezzo in 1688 and written on the order of Augustus as well as other literary sources, that brought the plebs down from the Mount, after the secessionists had consecrated it to "Jupiter Territor" and built an altar ("ara") on its summit. The fear of the wrath of Jupiter was an important element in the solution of the crisis. The consecration of the Mount probably referred to its summit only. The ritual requested the participation of both an augur (presumably Manius Valerius himself) and a pontifex.
The second secession was caused by the autocratic and arrogant behaviour of the "decemviri" who had been charged by the Roman people with writing down the laws in use till then kept secret by the patrician magistrates and the "sacerdotes". All magistracies and the tribunes of the plebs had resigned in advance. The task resulted in the XII Tables, which though concerned only private law. The plebs once again retreated to the Sacer Mons: this act besides recalling the first secession was meant to seek the protection of the supreme god. The secession ended with the resignation of the "decemviri" and an amnesty for the rebellious soldiers who had deserted from their camp near Mount Algidus while warring against the Volscians, abandoning the commanders. The amnesty was granted by the senate and guaranteed by the "pontifex maximus" Quintus Furius (in Livy's version) (or Marcus Papirius) who also supervised the nomination of the new tribunes of the plebs, then gathered on the Aventine Hill. The role played by the "pontifex maximus" in a situation of vacation of powers is a significant element underlining the religious basis and character of the "tribunicia potestas".
Myths and legends.
A dominant line of scholarship has held that Rome lacked a body of myths in its earliest period, or that this original mythology has been irrecoverably obscured by the influence of the Greek narrative tradition. After the Hellenization of Roman culture, Latin literature and iconography reinterpreted the myths of Zeus in depictions and narratives of Jupiter. In the legendary history of Rome, Jupiter is often connected to kings and kingship.
Birth.
Jupiter is depicted as the twin of Juno in a statue at Praeneste that showed them nursed by Fortuna Primigenia. An inscription that is also from Praeneste, however, says that Fortuna Primigenia was Jupiter's first-born child. Jacqueline Champeaux sees this contradiction as the result of successive different cultural and religious phases, in which a wave of influence coming from the Hellenic world made Fortuna the daughter of Jupiter. The childhood of Zeus is an important theme in Greek religion, art and literature, but there are only rare (or dubious) depictions of Jupiter as a child.
Numa.
Faced by a period of bad weather endangering the harvest during one early spring, King Numa resorted to the scheme of asking the advice of the god by evoking his presence. He succeeded through the help of Picus and Faunus, whom he had imprisoned by making them drunk. The two gods (with a charm) evoked Jupiter, who was forced to come down to earth at the Aventine (hence named "Iuppiter Elicius", according to Ovid). After Numa skilfully avoided the requests of the god for human sacrifices, Jupiter agreed to his request to know how lightning bolts are averted, asking only for the substitutions Numa had mentioned: an onion bulb, hairs and a fish. Moreover, Jupiter promised that at the sunrise of the following day he would give to Numa and the Roman people pawns of the "imperium". The following day, after throwing three lightning bolts across a clear sky, Jupiter sent down from heaven a shield. Since this shield had no angles, Numa named it "ancile"; because in it resided the fate of the "imperium", he had many copies made of it to disguise the real one. He asked the smith Mamurius Veturius to make the copies, and gave them to the Salii. As his only reward, Mamurius expressed the wish that his name be sung in the last of their "carmina". Plutarch gives a slightly different version of the story, writing that the cause of the miraculous drop of the shield was a plague and not linking it with the Roman "imperium".
Tullus Hostilius.
Throughout his reign, King Tullus had a scornful attitude towards religion. His temperament was warlike, and he disregarded religious rites and piety. After conquering the Albans with the duel between the Horatii and Curiatii, Tullus destroyed Alba Longa and deported its inhabitants to Rome. As Livy tells the story, omens "(prodigia)" in the form of a rain of stones occurred on the Alban Mount because the deported Albans had disregarded their ancestral rites linked to the sanctuary of Jupiter. In addition to the omens, a voice was heard requesting that the Albans perform the rites. A plague followed and at last the king himself fell ill. As a consequence, the warlike character of Tullus broke down; he resorted to religion and petty, superstitious practices. At last, he found a book by Numa recording a secret rite on how to evoke "Iuppiter Elicius". The king attempted to perform it, but since he executed the rite improperly the god threw a lightning bolt which burned down the king's house and killed Tullus.
Tarquinius the Elder.
When approaching Rome (where Tarquin was heading to try his luck in politics after unsuccessful attempts in his native Tarquinii), an eagle swooped down, removed his hat, flew screaming in circles, replaced the hat on his head and flew away. Tarquin's wife Tanaquil interpreted this as a sign that he would become king based on the bird, the quadrant of the sky from which it came, the god who had sent it and the fact it touched his hat (an item of clothing placed on a man's most noble part, the head).
The Elder Tarquin is credited with introducing the Capitoline Triad to Rome, by building the so-called Capitolium Vetus. Macrobius writes this issued from his Samothracian mystery beliefs.
Cult.
Sacrifices.
Sacrificial victims ("hostiae") offered to Jupiter were the ox (castrated bull), the lamb (on the Ides, the "ovis idulis") and the wether (on the Ides of January). The animals were required to be white. The question of the lamb's gender is unresolved; while a lamb is generally male, for the vintage-opening festival the flamen Dialis sacrificed a ewe. This rule seems to have had many exceptions, as the sacrifice of a ram on the Nundinae by the "flaminica Dialis" demonstrates.
During one of the crises of the Punic Wars, Jupiter was offered every animal born that year.
Temples.
Temple of Capitoline Jupiter.
The temple to Jupiter Optimus Maximus stood on the Capitoline Hill. Jupiter was worshiped there as an individual deity, and with Juno and Minerva as part of the Capitoline Triad. The building was supposedly begun by king Tarquinius Priscus, completed by the last king (Tarquinius Superbus) and inaugurated in the early days of the Roman Republic (September 13, 509 BC). It was topped with the statues of four horses drawing a quadriga, with Jupiter as charioteer. A large statue of Jupiter stood within; on festival days, its face was painted red. In (or near) this temple was the "Iuppiter Lapis": the Jupiter Stone, on which oaths could be sworn.
Jupiter's Capitoline Temple probably served as the architectural model for his provincial temples. 
When Hadrian built Aelia Capitolina on the site of Jerusalem, a temple to Jupiter Capitolinus was erected in the place of the destroyed Temple in Jerusalem. 
Other temples in Rome.
There were two temples in Rome dedicated to "Iuppiter Stator"; the first one was built and dedicated in 294 BC by Marcus Atilius Regulus after the third Samnite War. It was located on the "Via Nova", below the "Porta Mugonia", ancient entrance to the Palatine. Legend has attributed its founding to Romulus. There may have been an earlier shrine "(fanum)", since the Jupiter's cult is attested epigraphically. Ovid places the temple's dedication on June 27, but it is unclear whether this was the original date, or the rededication after the restoration by Augustus.
A second temple of "Iuppiter Stator" was built and dedicated by Quintus Caecilus Metellus Macedonicus after his triumph in 146 BC near the Circus Flaminius. It was connected to the restored temple of "Iuno Regina" with a portico ("porticus Metelli").
"Iuppiter Victor" had a temple dedicated by Quintus Fabius Maximus Gurges during the third Samnite War in 295 BC. Its location is unknown, but it may be on the Quirinal, on which an inscription reading "D]iovei Victore" has been found, or on the Palatine according to the "Notitia" in the "Liber Regionum" (regio X), which reads: "aedes Iovis Victoris". Either might have been dedicated on April 13 or June 13 (days of "Iuppiter Victor" and of "Iuppiter Invictus", respectively, in Ovid's "Fasti").
Inscriptions from the imperial age have revealed the existence of an otherwise-unknown temple of "Iuppiter Propugnator" on the Palatine.
Iuppiter Latiaris and Feriae Latinae.
The cult of "Iuppiter Latiaris" was the most ancient known cult of the god: it was practised since very remote times near the top of the "Mons Albanus" on which the god was venerated as the high protector of the Latin League under the hegemony of Alba Longa.
After the destruction of Alba by king Tullus Hostilius the cult was forsaken. The god manifested his discontent through the prodigy of a rain of stones: the commission sent by the Roman senate to inquire was also greeted by a rain of stones and heard a loud voice from the grove on the summit of the mount requesting the Albans perform the religious service to the god according to the rites of their country. In consequence of this event the Romans instituted a festival of nine days ("nundinae"). Nonetheless a plague ensued: in the end Tullus Hostilius himself was affected and lastly killed by the god with a lightning bolt. The festival was reestablished on its primitive site by the last Roman king Tarquin the Proud under the leadership of Rome.
The "feriae Latinae", or "Latiar" as they were known originally, were the common festival ("panegyris") of the so-called Priscan Latins and of the Albans. Their restoration aimed at grounding Roman hegemony in this ancestral religious tradition of the Latins. The original cult was reinstated unchanged as is testified by some archaic features of the ritual: the exclusion of wine from the sacrifice the offers of milk and cheese and the ritual use of rocking among the games. Rocking is one of the most ancient rites mimicking ascent to Heaven and is very widespread. At the "Latiar" the rocking took place on a tree and the winner was of course the one who had swung the highest. This rite was said to have been instituted by the Albans to commemorate the disappearance of king Latinus, in the battle against Mezentius king of Caere: the rite symbolised a search for him both on earth and in heaven. The rocking as well as the customary drinking of milk was also considered to commemorate and ritually reinstate infancy. The Romans in the last form of the rite brought the sacrificial ox from Rome and every participant was bestowed a portion of the meat, rite known as "carnem petere". Other games were held in every participant borough. In Rome a race of chariots ("quadrigae") was held starting from the Capitol: the winner drank a liquor made with absynth. This competition has been compared to the Vedic rite of the vajapeya: in it seventeen chariots run a phoney race which must be won by the king in order to allow him to drink a cup of "madhu", i. e. "soma". The feasting lasted for at least four days, possibly six according to Niebuhr, one day for each of the six Latin and Alban "decuriae". According to different records 47 or 53 boroughs took part in the festival (the listed names too differ in Pliny NH III 69 and Dionysius of Halicarnassus AR V 61). The "Latiar" became an important feature of Roman political life as they were "feriae conceptivae", i. e. their date varied each year: the consuls and the highest magistrates were required to attend shortly after the beginning of the administration, originally on the Ides of March: the Feriae usually took place in early April. They could not start campaigning before its end and if any part of the games had been neglected or performed unritually the "Latiar" had to be wholly repeated. The inscriptions from the imperial age record the festival back to the time of the decemvirs.
Wissowa remarks the inner linkage of the temple of the Mons Albanus with that of the Capitol apparent in the common association with the rite of the triumph: since 231 BC some triumphing commanders had triumphed there first with the same legal features as in Rome.
Religious calendar.
Ides.
The Ides (the midpoint of the month, with a full moon) was sacred to Jupiter, because on that day heavenly light shone day and night. Some (or all) Ides were "Feriae Iovis", sacred to Jupiter. On the Ides, a white lamb ("ovis idulis") was led along Rome's Sacred Way to the Capitoline Citadel and sacrificed to him. Jupiter's two "epula Iovis" festivals fell on the Ides, as did his temple foundation rites as "Optimus Maximus", "Victor", "Invictus" and (possibly) "Stator".
Nundinae.
The "nundinae" recurred every ninth day, dividing the calendar into a market cycle analogous to a week. The market days gave the rural people "(pagi)" the opportunity to sell in town and to be informed of religious and political edicts, which were posted publicly for three days. According to tradition, these festival days were instituted by the king Servius Tullius. The high priestess of Jupiter "(Flaminica Dialis)" sanctified the days by sacrificing a ram to Jupiter.
Festivals.
During the Republican era, more fixed holidays on the Roman calendar were devoted to Jupiter than to any other deity.
Viniculture and wine.
Festivals of viniculture and wine were devoted to Jupiter, since grapes were particularly susceptible to adverse weather. Dumézil describes wine as a "kingly" drink with the power to inebriate and exhilarate, analogous to the Vedic Soma.
Three Roman festivals were connected with viniculture and wine.
The rustic "Vinalia altera" on August 19 asked for good weather for ripening the grapes before harvest. When the grapes were ripe, a sheep was sacrificed to Jupiter and the "flamen Dialis" cut the first of the grape harvest.
The Meditrinalia on October 11 marked the end of the grape harvest; the new wine was pressed, tasted and mixed with old wine to control fermentation. In the "Fasti Amiternini", this festival is assigned to Jupiter. Later Roman sources invented a goddess "Meditrina", probably to explain the name of the festival.
At the "Vinalia urbana" on April 23, new wine was offered to Jupiter. Large quantities of it were poured into a ditch near the temple of Venus Erycina, which was located on the Capitol.
Regifugium and Poplifugium.
The "Regifugium" ("King's Flight") on February 24 has often been discussed in connection with the "Poplifugia" on July 5, a day holy to Jupiter. The "Regifugium" followed the festival of "Iuppiter Terminus" (Jupiter of Boundaries) on February 23. Later Roman antiquarians misinterpreted the "Regifugium" as marking the expulsion of the monarchy, but the "king" of this festival may have been the priest known as the "rex sacrorum" who ritually enacted the waning and renewal of power associated with the New Year (March 1 in the old Roman calendar). A temporary vacancy of power (construed as a yearly "interregnum") occurred between the "Regifugium" on February 24 and the New Year on March 1 (when the lunar cycle was thought to coincide again with the solar cycle), and the uncertainty and change during the two winter months were over. Some scholars emphasize the traditional political significance of the day.
The "Poplifugia" ("Routing of Armies"), a day sacred to Jupiter, may similarly mark the second half of the year; before the Julian calendar reform, the months were named numerically, "Quintilis" (the fifth month) to "December" (the tenth month). The "Poplifugia" was a "primitive military ritual" for which the adult male population assembled for purification rites, after which they ritually dispelled foreign invaders from Rome.
Epula Iovis.
There were two festivals called "epulum Iovis" ("Feast of Jove"). One was held on September 13, the anniversary of the foundation of Jupiter's Capitoline temple. The other (and probably older) festival was part of the Plebeian Games "(Ludi Plebei)", and was held on November 13. In the 3rd century BC, the "epulum Iovis" became similar to a lectisternium.
Ludi.
The most ancient Roman games followed after one day (considered a "dies ater", or "black day", i. e. a day which was traditionally considered unfortunate even though it was not "nefas", see also article Glossary of ancient Roman religion) the two "Epula Iovis" of September and November.
The games of September were named "Ludi Magni"; originally they were not held every year, but later became the annual "Ludi Romani" and were held in the Circus Maximus after a procession from the Capitol. The games were attributed to Tarquinius Priscus, and linked to the cult of Jupiter on the Capitol. Romans themselves acknowledged analogies with the triumph, which Dumézil thinks can be explained by their common Etruscan origin; the magistrate in charge of the games dressed as the "triumphator" and the "pompa circensis" resembled a triumphal procession. Wissowa and Mommsen argue that they were a detached part of the triumph on the above grounds (a conclusion which Dumézil rejects).
The "Ludi Plebei" took place in November in the Circus Flaminius.
Mommsen argued that the "epulum" of the Ludi Plebei was the model of the Ludi Romani, but Wissowa finds the evidence for this assumption insufficient. The "Ludi Plebei" were probably established in 534 BC. Their association with the cult of Jupiter is attested by Cicero.
Larentalia.
The "feriae" of December 23 were devoted to a major ceremony in honour of Acca Larentia (or "Larentina"), in which some of the highest religious authorities participated (probably including the Flamen Quirinalis and the pontiffs). The Fasti Praenestini marks the day as "feriae Iovis", as does Macrobius. It is unclear whether the rite of "parentatio" was itself the reason for the festival of Jupiter, or if this was another festival which happened to fall on the same day. Wissowa denies their association, since Jupiter and his "flamen" would not be involved with the underworld or the deities of death (or be present at a funeral rite held at a gravesite).
Name and epithets.
The Latin name "Iuppiter" originated as a vocative compound of the Old Latin vocative *"Iou" and "pater" ("father") and came to replace the Old Latin nominative case *"Ious". Jove is a less common English formation based on "Iov-", the stem of oblique cases of the Latin name. Linguistic studies identify the form *"Iou-pater" as deriving from the Indo-European vocative compound *"Dyēu-pəter" (meaning "O Father Sky-god"; nominative: *"Dyēus-pətēr").
Older forms of the deity's name in Rome were "Dieus-pater" ("day/sky-father"), then "Diéspiter". The 19th-century philologist Georg Wissowa asserted these names are conceptually- and linguistically-connected to "Diovis" and "Diovis Pater"; he compares the analogous formations "Vedius"-"Veiove" and "fulgur Dium", as opposed to "fulgur Summanum" (nocturnal lightning bolt) and "flamen Dialis" (based on "Dius", "dies"). The Ancient later viewed them as entities separate from Jupiter. The terms are similar in etymology and semantics ("dies", "daylight" and "Dius", "daytime sky"), but differ linguistically. Wissowa considers the epithet "Dianus" noteworthy. "Dieus" is the etymological equivalent of ancient Greece's "Zeus" and of the Teutonics' "Ziu" (genitive "Ziewes"). The Indo-European deity is the god from which the names and partially the theology of Jupiter, Zeus and the Indo-Aryan Vedic Dyaus Pita derive or have developed.
The Roman practice of swearing by Jove to witness an oath in law courts is the origin of the expression "by Jove!"—archaic, but still in use. The name of the god was also adopted as the name of the planet Jupiter; the adjective "jovial" originally described those born under the planet of Jupiter (reputed to be jolly, optimistic, and buoyant in temperament).
Jove was the original namesake of Latin forms of the weekday now known in English as Thursday (originally called "Iovis Dies" in Latin). These became "jeudi" in French, "jueves" in Spanish, "joi" in Romanian, "giovedì" in Italian, "dijous" in Catalan, "Xoves" in Galician, "Joibe" in Friulian, "Dijóu" in Provençal.
Major epithets.
The epithets of a Roman god indicate his theological qualities. The study of these epithets must consider their origins (the historical context of an epithet's source).
Jupiter's most ancient attested forms of cult belong to the State cult: these include the mount cult (see section above note n. 22). In Rome this cult entailed the existence of particular sanctuaries the most important of which were located on "Mons Capitolinus" (earlier "Tarpeius"). The mount had two tops that were both destined to the discharge of acts of cult related to Jupiter. The northern and higher top was the "arx" and on it was located the observation place of the augurs "(auguraculum)" and to it headed the monthly procession of the "sacra Idulia". On the southern top was to be found the most ancient sanctuary of the god: the shrine of "Iuppiter Feretrius" allegedly built by Romulus, restored by Augustus. The god here had no image and was represented by the sacred flintstone ("silex"). The most ancient known rites, those of the "spolia opima" and of the fetials which connect Jupiter with Mars and Quirinus are dedicated to "Iuppiter Feretrius" or "Iuppiter Lapis". The concept of the sky god was already overlapped with the ethical and political domain since this early time. According to Wissowa and Dumézil "Iuppiter Lapis" seems to be inseparable from "Iuppiter Feretrius" in whose tiny templet on the Capitol the stone was lodged.
Another most ancient epithet is "Lucetius": although the Ancient, followed by some modern scholars as e. g. Wissowa, interpreted it as referring to sunlight, the "carmen Saliare" shows that it refers to lightning. A further confirmation of this interpretation is provided by the sacred meaning of lightning which is reflected in the sensitivity of the "flaminica Dialis" to the phenomenon. To the same atmospheric complex belongs the epithet "Elicius": while the ancient erudites thought it was connected to lightning, it is in fact related to the opening of the rervoirs of rain, as is testified by the ceremony of the "Nudipedalia", meant to propitiate rainfall and devoted to Jupiter. and the ritual of the "lapis manalis", the stone which was brought into the city through the "Porta Capena" and carried around in times of drought, which was named "Aquaelicium". Other early epithets connected with the atmospheric quality of Jupiter are "Pluvius", "Imbricius", "Tempestas", "Tonitrualis", "tempestatium divinarum potens", "Serenator", "Serenus" and, referred to lightning, "Fulgur", "Fulgur Fulmen", later as nomen agentis "Fulgurator", "Fulminator": the high antiquity of the cult is testified by the neutre form "Fulgur" and the use of the term for the "bidental", the lightning well dug on the spot hit by a lightning bolt.
A group of epithets has been interpreted by Wissowa (and his followers) as a reflection of the agricultural or warring nature of the god, some of which are also in the list of eleven preserved by Augustine. The agricultural ones include "Opitulus", "Almus", "Ruminus", "Frugifer", "Farreus", "Pecunia", "Dapalis", "Epulo". Augustine gives an explanation of the ones he lists which should reflect Varro's: "Opitulus" because he brings "opem" (means, relief) to the needy, "Almus" because he nourishes everything, "Ruminus" because he nourishes the living beings by breastfeeding them, "Pecunia" because everything belongs to him.
Dumézil maintains the cult usage of these epithets is not documented and that the epithet Ruminus, as Wissowa and Latte remarked, may not have the meaning given by Augustine but it should be understood as part of a series including "Rumina", " Ruminalis ficus", "Iuppiter Ruminus", which bears the name of Rome itself with an Etruscan vocalism preserved in inscriptions, series that would be preserved in the sacred language (cf. "Rumach" Etruscan for Roman). However many scholars have argued that the name of Rome, "Ruma", meant in fact woman's breast. Diva Rumina, as Augustine testifies in the cited passage, was the goddess of suckling babies: she was venerated near the "ficus ruminalis" and was offered only libations of milk. Here moreover Augustine cites the verses devoted to Jupiter by Quintus Valerius Soranus, while hypothesising "Iuno" (more adept in his view as a breastfeeder), i. e. Rumina instead of Ruminus, might be nothing else than "Iuppiter": "Iuppiter omnipotens regum rerumque deumque Progenitor genetrixque deum...".
In Dumézil's opinion "Farreus" should be understood as related to the rite of the "confarreatio" the most sacred form of marriage, the name of which is due to the spelt cake eaten by the spouses, rather than surmising an agricultural quality of the god: the epithet means the god was the guarantor of the effects of the ceremony, to which the presence of his flamen is necessary and that he can interrupt with a clap of thunder.
The epithet "Dapalis" is on the other hand connected to a rite described by Cato and mentioned by Festus. Before the sowing of autumn or spring the peasant offered a banquet of roast beef and a cup of wine to Jupiter : it is natural that on such occasions he would entreat the god who has power over the weather, however Cato' s prayer of s one of sheer offer and no request. The language suggests another attitude: Jupiter is invited to a banquet which is supposedly abundant and magnificent. The god is honoured as "summus". The peasant may hope he shall receive a benefit, but he does not say it. This interpretation finds support in the analogous urban ceremony of the "epulum Iovis", from which the god derives the epithet of "Epulo" and which was a magnificent feast accompanied by flutes.
Epithets related to warring are in Wissowa' s view "Iuppiter Feretrius", "Iuppiter Stator", "Iuppiter Victor" and "Iuppiter Invictus". "Feretrius" would be connected with war by the rite of the first type of "spolia opima" which is in fact a dedication to the god of the arms of the defeated king of the enemy that happens whenever he has been killed by the king of Rome or his equivalent authority. Here too Dumézil notes the dedication has to do with regality and not with war, since the rite is in fact the offer of the arms of a king by a king: a proof of such an assumption is provided by the fact that the arms of an enemy king captured by an officer or a common soldier were dedicated to Mars and Quirinus respectively.
"Iuppiter Stator" was first attributed by tradition to Romulus, who had prayed the god for his almighty help at a difficult time the battle with the Sabines of king Titus Tatius. Dumézil opines the action of Jupiter is not that of a god of war who wins through fighting: Jupiter acts by causing an inexplicable change in the morale of the fighters of the two sides. The same feature can be detected also in the certainly historical record of the battle of the third Samnite War in 294 BC, in which consul Marcus Atilius Regulus vowed a temple to "Iuppiter Stator" if "Jupiter will stop the rout of the Roman army and if afterwards the Samnite legions shall be victouriously massacred...It looked as if the gods themselves had taken side with Romans, so much easily did the Roman arms succeed in prevailing...". in a similar manner one can explain the epithet "Victor", whose cult was founded in 295 BC on the battlefield of Sentinum by Quintus Fabius Maximus Gurges and who received another vow again in 293 by consul Lucius Papirius Cursor before a battle against the Samnite "legio linteata". Here too the religious meaning of the vow is in both cases an appeal to the supreme god by the Roman chief at a time when as a chief he needs divine help from the supreme god, even though for different reasons: Fabius had remained the only political and military responsible of the Roman State after the "devotio" of P. Decius Mus, Papirius had to face an enemy who had acted with impious rites and vows, i. e. was religiously reprehensible.
More recently Dario Sabbatucci has given a different interpretation of the meaning of "Stator" within the frame of his structuralistic and dialectic vision of Roman calendar, identifying oppositions, tensions and equilibria: January is the month of Janus, at the beginning of the year, in the uncertain time of winter (the most ancient calendar had only ten months, from March to December). In this month Janus deifies kingship and defies Jupiter. Moreover January sees also the presence of Veiovis who appears as an anti-Jupiter, of Carmenta who is the goddess of birth and like Janus has two opposed faces, "Prorsa" and "Postvorta" (also named Antevorta and Porrima), of Iuturna, who as a gushing spring evokes the process of coming into being from non-being as the god of passage and change does. In this period the preeminence of Janus needs compensating on the Ides through the action of Jupiter "Stator", who plays the role of anti-Janus, i. e. of moderator of the action of Janus.
Epithets denoting functionality.
Some epithets describe a particular aspect of the god, or one of his functions:
Syncretic or geographical epithets.
Some epithets of Jupiter indicate his association with a particular place. Epithets found in the provinces of the Roman Empire may identify Jupiter with a local deity or site (see syncretism).
In addition, many of the epithets of Zeus can be found applied to Jupiter, by "interpretatio romana". Thus, since the hero Trophonius (from Lebadea in Boeotia) is called Zeus Trophonius, this can be represented in English (as it would be in Latin) as Jupiter Trophonius. Similarly, the Greek cult of Zeus Meilichios appears in Pompeii as Jupiter Meilichius. Except in representing actual cults in Italy, this is largely 19th-century usage; modern works distinguish Jupiter from Zeus.
Theology.
Sources.
Marcus Terentius Varro and Verrius Flaccus were the main sources on the theology of Jupiter and archaic Roman religion in general. Varro was acquainted with the "libri pontificum" ("books of the Pontiffs") and their archaic classifications. On these two sources depend other ancient authorities, such as Ovid, Servius, Aulus Gellius, Macrobius, patristic texts, Dionysius of Halicarnassus and Plutarch.
One of the most important sources which preserve the theology of Jupiter and other Roman deities is "The City of God against the Pagans" by Augustine of Hippo. Augustine's criticism of traditional Roman religion is based on Varro's lost work, "Antiquitates Rerum Divinarum". Although a work of Christian apologetics, "The City of God" provides glimpses into Varro's theological system and authentic Roman theological lore in general. According to Augustine, Varro drew on the pontiff Mucius Scaevola's tripartite theology:
Jovian theology.
Georg Wissowa stressed Jupiter's uniqueness as the only case among Indo-European religions in which the original god preserved his name, his identity and his prerogatives. In this view, Jupiter is the god of heaven and retains his identification with the sky among the Latin poets (his name is used as a synonym for "sky".) In this respect, he differs from his Greek equivalent Zeus (who is considered a personal god, warden and dispenser of skylight). His name reflects this idea; it is a derivative of the Indo-European word for "bright, shining sky". His residence is found atop the hills of Rome and of mountains in general; as a result, his cult is present in Rome and throughout Italy at upper elevations. Jupiter assumed atmospheric qualities; he is the wielder of lightning and the master of weather. However, Wissowa acknowledges that Jupiter is not merely a naturalistic, heavenly, supreme deity; he is in continual communication with man by means of thunder, lightning and the flight of birds (his auspices). Through his vigilant watch he is also the guardian of public oaths and compacts and the guarantor of good faith in the State cult. The Jovian cult was common to the Italic people under the names "Iove", "Diove" (Latin) and "Iuve", "Diuve" (Oscan, in Umbrian only "Iuve", "Iupater" in the Iguvine Tables).
Wissowa considered Jupiter also a god of war and agriculture, in addition to his political role as guarantor of good faith (public and private) as "Iuppiter Lapis" and "Dius Fidius", respectively. His view is grounded in the sphere of action of the god (who intervenes in battle and influences the harvest through weather).
In Georges Dumézil's view, Jovian theology (and that of the equivalent gods in other Indo-European religions) is an evolution from a naturalistic, supreme, celestial god identified with heaven to a sovereign god, a wielder of lightning bolts, master and protector of the community (in other words, of a change from a naturalistic approach to the world of the divine to a socio-political approach).
In Vedic religion, Dyaus Pitar remained confined to his distant, removed, passive role and the place of sovereign god was occupied by Varuna and Mitra. In Greek and Roman religion, instead, the homonymous gods "*Diou-" and "Διϝ-" evolved into atmospheric deities; by their mastery of thunder and lightning, they expressed themselves and made their will known to the community. In Rome, Jupiter also sent signs to the leaders of the state in the form of auspices in addition to thunder. The art of augury was considered prestigious by ancient Romans; by sending his signs, Jupiter (the sovereign of heaven) communicates his advice to his terrestrial colleague: the king ("rex") or his successor magistrates. The encounter between the heavenly and political, legal aspects of the deity are well represented by the prerogatives, privileges, functions and taboos proper to his "flamen" (the "flamen Dialis" and his wife, the "flaminica Dialis").
Dumézil maintains that Jupiter is not himself a god of war and agriculture, although his actions and interest may extend to these spheres of human endeavour. His view is based on the methodological assumption that the chief criterion for studying a god's nature is not to consider his field of action, but the quality, method and features of his action. Consequently, the analysis of the type of action performed by Jupiter in the domains in which he operates indicates that Jupiter is a sovereign god who may act in the field of politics (as well as agriculture and war) in his capacity as such, i.e. in a way and with the features proper to a king. Sovereignty is expressed through the two aspects of absolute, magic power (epitomised and represented by the Vedic god Varuna) and lawful right (by the Vedic god Mitra). However, sovereignty permits action in every field; otherwise, it would lose its essential quality. As a further proof, Dumézil cites the story of Tullus Hostilius (the most belligerent of the Roman kings), who was killed by Jupiter with a lightning bolt (indicating that he did not enjoy the god's favour). 
Varro's definition of Jupiter as the god who has under his jurisdiction the full expression of every being ("penes Iovem sunt summa") reflects the sovereign nature of the god, as opposed to the jurisdiction of Janus (god of passages and change) on their beginning ("penes Ianum sunt prima").
Relation to other gods.
Archaic Triad.
The Archaic Triad is a theological structure (or system) consisting of the gods Jupiter, Mars and Quirinus. It was first described by Wissowa, and the concept was developed further by Dumézil. The three-function hypothesis of Indo-European society advanced by Dumézil holds that in prehistory, society was divided into three classes (priests, warriors and craftsmen)
which had as their religious counterparts the divine figures of the sovereign god, the warrior god and the civil god. The sovereign function (embodied by Jupiter) entailed omnipotence; thence, a domain extended over every aspect of nature and life. The colour relating to the sovereign function is white.
The three functions are interrelated with one another, overlapping to some extent; the sovereign function, although essentially religious in nature, is involved in many ways in areas pertaining to the other two. Therefore, Jupiter is the "magic player" in the founding of the Roman state and the fields of war, agricultural plenty, human fertility and wealth.
Capitoline Triad.
The Capitoline Triad was introduced to Rome by the Tarquins. Dumézil thinks it might have been an Etruscan (or local) creation based on Vitruvius' treatise on architecture, in which the three deities are associated as the most important. It is possible that the Etruscans paid particular attention to Menrva (Minerva) as a goddess of destiny, in addition to the royal couple Uni (Juno) and Tinia (Jupiter). In Rome, Minerva later assumed a military aspect under the influence of Athena Pallas (Polias). Dumézil argues that with the advent of the Republic, Jupiter became the only king of Rome, no longer merely the first of the great gods.
Jupiter and Minerva.
Apart from being protectress of the arts and craft as Minerva Capta, who was brought from Falerii, Minerva's association to Jupiter and relevance to Roman state religion is mainly linked to the Palladium, a wooden statue of Athena that could move the eyes and wave the spear. It was stored in the "penus interior", inner penus of the "aedes Vestae", temple of Vesta and considered the most important among the "pignora imperii", pawns of dominion, empire. In Roman traditional lore it was brought from Troy by Aeneas. Scholars though think it was last taken to Rome in the third or second century BC.
Juno and Fortuna.
The divine couple received from Greece its matrimonial implications, thence bestowing on Juno the role of tutelary goddess of marriage ("Iuno Pronuba").
The couple itself though cannot be reduced to a Greek apport. The association of Juno and Jupiter is of the most ancient Latin theology. Praeneste offers a glimpse into original Latin mythology: the local goddess Fortuna is represented as milking two infants, one male and one female, namely Jove (Jupiter) and Juno. It seems fairly safe to assume that from the earliest times they were identified by their own proper names and since they got them they were never changed through the course of history: they were called Jupiter and Juno. These gods were the most ancient deities of every Latin town. Praeneste preserved divine filiation and infancy as the sovereign god and his paredra Juno have a mother who is the primordial goddess Fortuna Primigenia. Many terracotta statuettes have been discovered which represent a woman with a child: one of them represents exactly the scene described by Cicero of a woman with two children of different sex who touch her breast. Two of the votive inscriptions to Fortuna associate her and Jupiter: " Fortunae Iovi puero..." and "Fortunae Iovis puero..."
In 1882 though R. Mowat published an inscription in which Fortuna is called "daughter of Jupiter", raising new questions and opening new perspectives in the theology of Latin gods. Dumezil has elaborated an interpretative theory according to which this "aporia" would be an intrinsic, fundamental feature of Indoeuropean deities of the primordial and sovereign level, as it finds a parallel in Vedic religion. The contradiction would put Fortuna both at the origin of time and into its ensuing diachronic process: it is the comparison offered by Vedic deity Aditi, the "Not-Bound" or "Enemy of Bondage", that shows that there is no question of choosing one of the two apparent options: as the mother of the Aditya she has the same type of relationship with one of his sons, Dakṣa, the minor sovereign. who represents the "Creative Energy", being at the same time his mother and daughter, as is true for the whole group of sovereign gods to which she belongs. Moreover Aditi is thus one of the heirs (along with Savitr) of the opening god of the Indoiranians, as she is represented with her head on her two sides, with the two faces looking opposite directions. The mother of the sovereign gods has thence two solidal but distinct modalities of duplicity, i.e. of having two foreheads and a double position in the genealogy. Angelo Brelich has interpreted this theology as the basic opposition between the primordial absence of order (chaos) and the organisation of the cosmos.
Janus.
The relation of Jupiter to Janus is problematic. Varro defines Jupiter as the god who has "potestas" (power) over the forces by which anything happens in the world. Janus, however, has the privilege of being invoked first in rites, since in his power are the beginnings of things ("prima"), the appearance of Jupiter included.
Saturn.
The Latins considered Saturn the predecessor of Jupiter. Saturn reigned in Latium during a mythical Golden Age reenacted every year at the festival of Saturnalia. Saturn also retained primacy in matters of agriculture and money. Unlike the Greek tradition of Cronus and Zeus, the usurpation of Saturn as king of the gods by Jupiter was not viewed by the Latins as violent or hostile; Saturn continued to be revered in his temple at the foot of the Capitol Hill, which maintained the alternative name "Saturnius" into the time of Varro.
A. Pasqualini has argued that Saturn was related to "Iuppiter Latiaris", the old Jupiter of the Latins, as the original figure of this Jupiter was superseded on the Alban Mount, whereas it preserved its gruesome character in the ceremony held at the sanctuary of the Latiar Hill in Rome which involved a human sacrifice and the aspersion of the statue of the god with the blood of the victim.
Fides.
The abstract personification Fides ("Faith, Trust") was one of the oldest gods associated with Jupiter. As guarantor of public faith, Fides had her temple on the Capitol (near that of Capitoline Jupiter).
Dius Fidius.
"Dius Fidius" is considered a theonym for Jupiter, and sometimes a separate entity also known in Rome as Semo Sancus Dius Fidius. Wissowa argued that while Jupiter is the god of the "Fides Publica Populi Romani" as "Iuppiter Lapis" (by whom important oaths are sworn), Dius Fidius is a deity established for everyday use and was charged with the protection of good faith in private affairs. Dius Fidius would thus correspond to "Zeus Pistios". The association with Jupiter may be a matter of divine relation; some scholars see him as a form of Hercules. Both Jupiter and Dius Fidius were wardens of oaths and wielders of lightning bolts; both required an opening in the roof of their temples.
The functionality of Sancus occurs consistently within the sphere of "fides", oaths and respect for contracts and of the divine-sanction guarantee against their breach. Wissowa suggested that Semo Sancus is the "genius" of Jupiter, but the concept of a deity's "genius" is a development of the Imperial period.
Some aspects of the oath-ritual for Dius Fidius (such as proceedings under the open sky or in the "compluvium" of private residences), and the fact the temple of Sancus had no roof, suggest that the oath sworn by Dius Fidius predated that for "Iuppiter Lapis" or "Iuppiter Feretrius".
Genius.
Augustine quotes Varro who explains the "genius" as "the god who is in charge and has the power to generate everything" and "the rational spirit of all (therefore, everyone has their own)". Augustine concludes that Jupiter should be considered the "genius" of the universe.
G. Wissowa advanced the hypothesis that Semo Sancus is the genius of Jupiter. W. W. Fowler has cautioned that this interpretation looks to be an anachronism and it would only be acceptable to say that Sancus is a "Genius Iovius", as it appears from the Iguvine Tables.
Censorinus cites Granius Flaccus as saying that "the Genius was the same entity as the Lar" in his lost work "De Indigitamentis". probably referring to the "Lar Familiaris". Mutunus Tutunus had his shrine at the foot of the Velian Hill near those of the Di Penates and of Vica Pota, who were among the most ancient gods of the Roman community of according to Wissowa.
Dumézil opines that the attribution of a Genius to the gods should be earlier than its first attestation of 58 BC, in an inscription which mentions the "Iovis Genius".
A connection between Genius and Jupiter seems apparent in Plautus' comedy "Amphitryon", in which Jupiter takes up the looks of Alcmena's husband in order to seduce her: J. Hubeaux sees there a reflection of the story that Scipio Africanus' mother conceived him with a snake that was in fact Jupiter transformed. Scipio himself claimed that only he would rise to the mansion of the gods through the widest gate.
Among the Etruscan "Penates" there is a "Genius Iovialis" who comes after "Fortuna" and "Ceres" and before "Pales". Genius Iovialis is one of the "Penates" of the humans and not of Jupiter though, as these were located in region I of Martianus Capella' s division of Heaven, while Genius appears in regions V and VI along with Ceres, Favor (possibly a Roman approximation to an Etruscan male manifestation of Fortuna) and Pales. This is in accord with the definition of the Penates of man being Fortuna, Ceres, Pales and Genius Iovialis and the statement in Macrobius that the Larentalia were dedicated to Jupiter as the god whence the souls of men come from and to whom they return after death.
Summanus.
The god of nighttime lightning has been interpreted as an aspect of Jupiter, either a chthonic manifestation of the god or a separate god of the underworld. A statue of Summanus stood on the roof of the Temple of Capitoline Jupiter, and "Iuppiter Summanus" is one of the epithets of Jupiter. Dumézil sees the opposition Dius Fidius versus Summanus as complementary, interpreting it as typical to the inherent ambiguity of the sovereign god exemplified by that of Mitra and Varuna in Vedic religion. The complementarity of the epithets is shown in inscriptions found on "puteal"s or "bidental"s reciting either "fulgur Dium conditum" or "fulgur Summanum conditum" in places struck by daytime versus nighttime lightning bolts respectively. This is also consistent with the etymology of "Summanus", deriving from "sub" and "mane" (the time before morning).
Liber.
"Iuppiter" was associated with Liber through his epithet of "Liber" (association not yet been fully explained by scholars, due to the scarcity of early documentation).
In the past, it was maintained that Liber was only a progressively-detached hypostasis of Jupiter; consequently, the vintage festivals were to be attributed only to "Iuppiter Liber". Such a hypothesis was rejected as groundless by Wissowa, although he was a supporter of Liber's Jovian origin. Olivier de Cazanove contends that it is difficult to admit that Liber (who is present in the oldest calendars—those of Numa—in the "Liberalia" and in the month of "Liber" at Lavinium) was derived from another deity. Such a derivation would find support only in epigraphic documents, primarily from the Osco-Sabellic area. Wissowa sets the position of "Iuppiter Liber" within the framework of an agrarian Jupiter. The god also had a temple in this name on the Aventine in Rome, which was restored by Augustus and dedicated on September 1. Here, the god was sometimes named "Liber" and sometimes "Libertas". Wissowa opines that the relationship existed in the concept of creative abundance through which the supposedly-separate Liber might have been connected to the Greek god Dionysos, although both deities might not have been originally related to viticulture.
Other scholars assert that there was no Liber (other than a god of wine) within historical memory. O. de Cazanove argues that the domain of the sovereign god Jupiter was that of sacred, sacrificial wine ("vinum inferium"), while that of Liber and Libera was confined to secular wine ("vinum spurcum"); these two types were obtained through differing fermentation processes. The offer of wine to Liber was made possible by naming the "mustum" (grape juice) stored in amphoras "sacrima".
Sacred wine was obtained by the natural fermentation of juice of grapes free from flaws of any type, religious (e. g. those struck by lightning, brought into contact with corpses or wounded people or coming from an unfertilised grapeyard) or secular (by "cutting" it with old wine). Secular (or "profane") wine was obtained through several types of manipulation (e.g. by adding honey, or "mulsum"; using raisins, or "passum"; by boiling, or "defrutum"). However, the "sacrima" used for the offering to the two gods for the preservation of grapeyards, vessels and wine was obtained only by pouring the juice into amphors after pressing. The "mustum" was considered "spurcum" (dirty), and thus unusable in sacrifices. The amphor (itself not an item of sacrifice) permitted presentation of its content on a table or could be added to a sacrifice; this happened at the "auspicatio vindamiae" for the first grape and for ears of corn of the "praemetium" on a dish ("lanx") at the
temple of Ceres.
Dumézil, on the other hand, sees the relationship between Jupiter and Liber as grounded in the social and political relevance of the two gods (who were both considered patrons of freedom). The "Liberalia" of March were, since earliest times, the occasion for the ceremony of the donning of the "toga virilis" or "libera" (which marked the passage into adult citizenship by young people). Augustine relates that these festivals had a particularly obscene character: a "phallus" was taken to the fields on a cart, and then back in triumph to town. In Lavinium they lasted a month, during which the population enjoyed bawdy jokes. The most honest "matronae" were supposed to publicly crown the "phallus" with flowers, to ensure a good harvest and repeal the "fascinatio" (evil eye). In Rome representations of the sex organs were placed in the temple of the couple "Liber Libera", who presided over the male and female components of generation and the "liberation" of the semen. This complex of rites and beliefs shows that the divine couple's jurisdiction extended over fertility in general, not only that of grapes. The etymology of "Liber" (archaic form "Loifer, Loifir") was explained by Émile Benveniste as formed on the IE theme *leudh- plus the suffix -es-; its original meaning is "the one of germination, he who ensures the sprouting of crops".
The relationship of Jupiter with freedom was a common belief among the Roman people, as demonstrated by the dedication of the "Mons Sacer" to the god after the first secession of the "plebs". Later inscriptions also show the unabated popular belief in Jupiter as bestower of freedom in the imperial era.
Veiove.
Scholars have been often puzzled by Ve(d)iove (or Veiovis, or Vedius) and unwilling to discuss his identity, claiming our knowledge of this god is insufficient. Most, however, agree that Veiove is a sort of special Jupiter or anti-Iove, or even an underworld Jupiter. In other words Veiove is indeed the Capitoline god himself, who takes up a different, diminished appearance ("iuvenis" and "parvus", young and gracile), in order to be able to discharge sovereign functions over places, times and spheres that by their own nature are excluded from the direct control of Jupiter as Optimus Maximus. This conclusion is based on information provided by Gellius, who states his name is formed by adding prefix "ve" (here denoting "deprivation" or "negation") to "Iove " (whose name Gellius posits as rooted in the verb "iuvo" "I benefit"). D. Sabbatucci has stressed the feature of bearer of instability and antithesis to cosmic order of the god, who threatens the kingly power of Jupiter as "Stator" and "Centumpeda" and whose presence occurs side by side to Janus' on January 1, but also his function of helper to the growth of the young Jupiter. In 1858 Ludwig Preller suggested that Veiovis may be the sinister double of Jupiter.
In fact, the god (under the name "Vetis") is placed in the last case (number 16) of the outer rim of the Piacenza Liver—before "Cilens" (Nocturnus), who ends (or begins in the Etruscan vision) the disposition of the gods. In Martianus Capella's division of heaven, he is found in region XV with the "dii publici"; as such, he numbers among the infernal (or antipodal) gods. The location of his two temples in Rome—near those of Jupiter (one on the Capitoline Hill, in the low between the "arx" and the Capitolium, between the two groves where the asylum founded by Romulus stood, the other on the Tiber Island near that of "Iuppiter Iurarius", later also known as temple of Aesculapius)—may be significant in this respect, along with the fact that he is considered the father of Apollo, perhaps because he was depicted carrying arrows. He is also considered to be the unbearded Jupiter. The dates of his festivals support the same conclusion: they fall on January 1, March 7 and May 21, the first date being the recurrence of the Agonalia, dedicated to Janus and celebrated by the king with the sacrifice of a ram. The nature of the sacrifice is debated; Gellius states "capra", a female goat, although some scholars posit a ram. This sacrifice occurred "rito humano", which may mean "with the rite appropriate for human sacrifice". Gellius concludes by stating that this god is one of those who receive sacrifices so as to persuade them to refrain from causing harm.
The arrow is an ambivalent symbol; it was used in the ritual of the devotio (the general who vowed had to stand on an arrow). It is perhaps because of the arrow and of the juvenile looks that Gellius identifies Veiove with Apollo and as a god who must receive worship in order to obtain his abstention from harming men, along with Robigus and Averruncus. The ambivalence in the identity of Veiove is apparent in the fact that while he is present in places and times which may have a negative connotation (such as the "asylum" of Romulus in between the two groves on the Capitol, the Tiberine island along with Faunus and Aesculapius, the kalends of January, the nones of March, and May 21, a statue of his nonetheless stands in the "arx". Moreover the initial particle "ve-" which the ancient supposed were part of his name is itself ambivalent as it may have both an accrescitive and diminutive value.
Maurice Besnier has remarked that a temple to "Iuppiter" was dedicated by "praetor" Lucius Furius Purpureo before the battle of Cremona against the Celtic Cenomani of Cisalpine Gaul. An inscription found at Brescia in 1888 shows that "Iuppiter Iurarius" was worshipped there and one found on the south tip of Tiber Island in 1854 that there was a cult to the god on the spot too. Besnier speculates that Lucius Furius had evoked the chief god of the enemy and built a temple to him in Rome outside the "pomerium". On January 1, the "Fasti Praenestini" record the festivals of Aesculapius and Vediove on the Island, while in the "Fasti" Ovid speaks of "Jupiter" and his grandson. Livy records that in 192 BC, "duumvir" Q. Marcus Ralla dedicated to Jupiter on the Capitol the two temples promised by L. Furius Purpureo, one of which was that promised during the war against the Gauls. Besnier would accept a correction to Livy's passage (proposed by Jordan) to read "aedes Veiovi" instead of "aedes duae Iovi". Such a correction concerns the temples dedicated on the Capitol: it does not address the question of the dedication of the temple on the Island, which is puzzling, since the place is attested epigraphically as dedicated to the cult of "Iuppiter Iurarius", in the "Fasti Praenestini" of "Vediove" and to Jupiter according to Ovid. The two gods may have been seen as equivalent: "Iuppiter Iurarius" is an awesome and vengeful god, parallel to the Greek "Zeus Orkios", the avenger of perjury.
A. Pasqualini has argued that Veiovis seems related to "Iuppiter Latiaris", as the original figure of this Jupiter would have been superseded on the Alban Mount, whereas it preserved its gruesome character in the ceremony held on the sanctuary of the Latiar Hill, the southernmost hilltop of the Quirinal in Rome, which involved a human sacrifice. The gens Iulia had gentilician cults at Bovillae where a dedicatory inscription to Vediove has been found in 1826 on an ara. According to Pasqualini it was a deity similar to Vediove, wielder of lightningbolts and chthonic, who was connected to the cult of the founders who first inhabited the Alban Mount and built the sanctuary. Such a cult once superseded on the Mount would have been taken up and preserved by the Iulii, private citizens bound to the "sacra Albana" by their Alban origin.
Victoria.
Victoria was connected to "Iuppiter Victor" in his role as bestower of military victory. Jupiter, as a sovereign god, was considered as having the power to conquer anyone and anything in a supernatural way; his contribution to military victory was different from that of Mars (god of military valour). Victoria appears first on the reverse of coins representing Venus (driving the quadriga of Jupiter, with her head crowned and with a palm in her hand) during the first Punic War. Sometimes, she is represented walking and carrying a trophy.
A temple was dedicated to the goddess afterwards on the Palatine, testifying to her high station in the Roman mind. When Hieron of Syracuse presented a golden statuette of the goddess to Rome, the Senate had it placed in the temple of Capitoline Jupiter among the greatest (and most sacred) deities.
Although Victoria played a significant role in the religious ideology of the late Republic and the Empire, she is undocumented in earlier times. A function similar to hers may have been played by the little-known Vica Pota.
Terminus.
Juventas and Terminus were the gods who, according to legend, refused to leave their sites on the Capitol when the construction of the temple of Jupiter was undertaken. Therefore, they had to be reserved a "sacellum" within the new temple. Their stubbornness was considered a good omen; it would guarantee youth, stability and safety to Rome on its site. This legend is generally thought by scholars to indicate their strict connection with Jupiter. An inscription found near Ravenna reads "Iuppiter Ter.", indicating that Terminus is an aspect of Jupiter.
Terminus is the god of boundaries (public and private), as he is portrayed in literature. The religious value of the boundary marker is documented by Plutarch, who ascribes to king Numa the construction of temples to Fides and Terminus and the delimitation of Roman territory. Ovid gives a vivid description of the rural rite at a boundary of fields of neighbouring peasants on February 23 (the day of the Terminalia. On that day, Roman pontiffs and magistrates held a ceremony at the sixth mile of the Via Laurentina (ancient border of the Roman "ager", which maintained a religious value). 
This festival, however, marked the end of the year and was linked to time more directly than to space (as attested by Augustine's apologia on the role of Janus with respect to endings). Dario Sabbatucci has emphasised the temporal affiliation of Terminus, a reminder of which is found in the rite of the "regifugium". 
G. Dumézil, on the other hand, views the function of this god as associated with the legalistic aspect of the sovereign function of Jupiter. Terminus would be the counterpart of the minor Vedic god Bagha, who oversees the just and fair division of goods among citizens.
Iuventas.
Along with "Terminus", " Iuventas" (also known as "Iuventus" and "Iuunta") represents an aspect of Jupiter (as the legend of her refusal to leave the Capitol Hill demonstrates. Her name has the same root as Juno (from "Iuu-", "young, youngster"); the ceremonial litter bearing the sacred goose of Juno Moneta stopped before her "sacellum" on the festival of the goddess. Later, she was identified with the Greek Hebe. The fact that Jupiter is related to the concept of youth is shown by his epithets "Puer", "Iuuentus" and "Ioviste" (interpreted as "the youngest" by some scholars). Dumézil noted the presence of the two minor sovereign deities Bagha and Aryaman beside the Vedic sovereign gods Varuna and Mitra (though more closely associated with Mitra); the couple would be reflected in Rome by "Terminus" and "Iuventas". Aryaman is the god of young soldiers. The function of "Iuventas" is to protect the "iuvenes" (the "novi togati" of the year, who are required to offer a sacrifice to Jupiter on the Capitol) and the Roman soldiers (a function later attributed to Juno). King Servius Tullius, in reforming the Roman social organisation, required that every adolescent offer a coin to the goddess of youth upon entering adulthood.
In Dumézil's analysis, the function of "Iuventas" (the personification of youth), was to control the entrance of young men into society and protect them until they reach the age of "iuvenes" or "iuniores" (i.e. of serving the state as soldiers).
A temple to "Iuventas" was promised in 207 BC by consul Marcus Livius Salinator and dedicated in 191 BC.
Penates.
The Romans considered the Penates as the gods to whom they owed their own existence. As noted by Wissowa "Penates" is an adjective, meaning "those of or from the "penus"" the innermost part, most hidden recess; Dumézil though refuses Wissowa's interpretation of "penus" as the storeroom of a household. As a nation the Romans honoured the "Penates publici": Dionysius calls them "Trojan gods" as they were absorbed into the Trojan legend. They had a temple in Rome at the foot of the Velian Hill, near the Palatine, in which they were represented as a couple of male youth. They were honoured every year by the new consuls before entering office at Lavinium, because the Romans believed the Penates of that town were identical to their own.
The concept of "di Penates" is more defined in Etruria: Arnobius (citing a Caesius) states that the Etruscan Penates were named Fortuna, Ceres, Genius Iovialis and Pales; according to Nigidius Figulus, they included those of Jupiter, of Neptune, of the infernal gods and of mortal men. According to Varro the Penates reside in the recesses of Heaven and are called "Consentes" and "Complices" by the Etruscans because they rise and set together, are twelve in number and their names are unknown, six male and six females and are the cousellors and masters of Jupiter. Martianus states they are always in agreement among themselves. While these last gods seem to be the Penates of Jupiter, Jupiter himself along with Juno and Minerva is one of the Penates of man according to some authors.
This complex concept is reflected in Martianus Capella's division of heaven, found in Book I of his "De Nuptiis Mercurii et Philologiae", which places the "Di Consentes Penates" in region I with the "Favores Opertanei"; "Ceres" and "Genius" in region V; "Pales" in region VI; "Favor" and "Genius" (again) in region VII; "Secundanus Pales", "Fortuna" and "Favor Pastor" in region XI. The disposition of these divine entities and their repetition in different locations may be due to the fact that "Penates" belonging to different categories (of Jupiter in region I, earthly or of mortal men in region V) are intended. "Favor(es)" may be the Etruscan masculine equivalent of "Fortuna".

</doc>
<doc id="40256" url="http://en.wikipedia.org/wiki?curid=40256" title="Trusted client">
Trusted client

In computing, a trusted client is a device or program controlled by the user of a service, but with restrictions designed to prevent its use in ways not authorized by the provider of the service. That is, the client is a device that vendors trust and then sell to the consumers, whom they do not trust. Examples include video games played over a computer network or the Content Scramble System (CSS) in DVDs.
Trusted client software is considered fundamentally insecure: once the security is broken by one user, the break is trivially copyable and available to others. As computer security specialist Bruce Schneier states, "Against the average user, anything works; there's no need for complex security software. Against the skilled attacker, on the other hand, nothing works." Trusted client hardware is somewhat more secure, but not a complete solution.
Trusted clients are attractive to business as a form of vendor lock-in: sell the trusted client at a loss and charge more than would be otherwise economically viable for the associated service. One early example was radio receivers that were subsidized by broadcasters, but restricted to receiving only their radio station. Modern examples include video recorders being forced by law to include Macrovision copy protection, the DVD region code system and region-coded video game consoles.
Technically knowledgeable consumers and other manufacturers frequently bypass the limiting features of trusted clients — from the simple replacement of the fixed tuning capacitor in the early locked radios to the successful DeCSS cryptographic attack on CSS in 1999. Manufacturers have resorted to legal threats via the Digital Millennium Copyright Act and similar laws to prevent their circumvention, with varying degrees of success. However, the nature of the internet enables any crack that is discovered and published to be virtually impossible to remove.
Trusted computing aims to create computer hardware which assists in the implementation of such restrictions in software, and attempts to make circumvention of these restrictions more difficult.

</doc>
<doc id="40258" url="http://en.wikipedia.org/wiki?curid=40258" title="Harmony">
Harmony

In music, harmony is the use of simultaneous pitches (tones, notes), or chords. The study of harmony involves chords and their construction and chord progressions and the principles of connection that govern them. Harmony is often said to refer to the "vertical" aspect of music, as distinguished from melodic line, or the "horizontal" aspect. Counterpoint, which refers to the interweaving of melodic lines, and polyphony, which refers to the relationship of separate independent voices, are thus sometimes distinguished from harmony.
In popular and jazz harmony, chords are named by their root plus various terms and characters indicating their qualities. In many types of music, notably baroque, romantic, modern and jazz, chords are often augmented with "tensions". A tension is an additional chord member that creates a relatively dissonant interval in relation to the bass. Typically, in the classical common practice period a dissonant chord (chord with tension) "resolves" to a consonant chord. Harmonization usually sounds pleasant to the ear when there is a balance between the consonant and dissonant sounds. In simple words, that occurs when there is a balance between "tense" and "relaxed" moments.
Etymology and definitions.
The term "harmony" derives from the Greek ἁρμονία ("harmonía"), meaning "joint, agreement, concord", from the verb ἁρμόζω ("harmozo"), "to fit together, to join". The term was often used for the whole field of music, while "music" referred to the arts in general. In Ancient Greece, the term defined the combination of contrasted elements: a higher and lower note. Nevertheless, it is unclear whether the simultaneous sounding of notes was part of ancient Greek musical practice; "harmonía" may have merely provided a system of classification of the relationships between different pitches. In the Middle Ages the term was used to describe two pitches sounding in combination, and in the Renaissance the concept was expanded to denote three pitches sounding together. Aristoxenus wrote a work entitled "Harmonika Stoicheia", which is thought the first work in European history written on the subject of harmony. 
It was not until the publication of Rameau's 'Traité de l'harmonie' (Treatise on Harmony) in 1722 that any text discussing musical practice made use of the term in the title, though that work is not the earliest record of theoretical discussion of the topic. The underlying principle behind these texts is that harmony sanctions harmoniousness (sounds that 'please') by conforming to certain pre-established compositional principles.
Current dictionary definitions, while attempting to give concise descriptions, often highlight the ambiguity of the term in modern use. Ambiguities tend to arise from either aesthetic considerations (for example the view that only "pleasing" concords may be harmonious) or from the point of view of musical texture (distinguishing between "harmonic" (simultaneously sounding pitches) and "contrapuntal" (successively sounding tones). In the words of Arnold Whittall:
While the entire history of music theory appears to depend on just such a distinction between harmony and counterpoint, it is no less evident that developments in the nature of musical composition down the centuries have presumed the interdependence—at times amounting to integration, at other times a source of sustained tension—between the vertical and horizontal dimensions of musical space.—
The view that modern tonal harmony in Western music began in about 1600 is commonplace in music theory. This is usually accounted for by the 'replacement' of horizontal (of contrapuntal) writing, common in the music of the Renaissance, with a new emphasis on the 'vertical' element of composed music. Modern theorists, however, tend to see this as an unsatisfactory generalisation. As Carl Dahlhaus puts it:
It was not that counterpoint was supplanted by harmony (Bach’s tonal counterpoint is surely no less polyphonic than Palestrina’s modal writing) but that an older type both of counterpoint and of vertical technique was succeeded by a newer type. And harmony comprises not only the (‘vertical’) structure of chords but also their (‘horizontal’) movement. Like music as a whole, harmony is a process.—
Descriptions and definitions of harmony and harmonic practice may show bias towards European (or Western) musical traditions. For example, South Asian art music (Hindustani and Carnatic music) is frequently cited as placing little emphasis on what is perceived in western practice as conventional 'harmony'; the underlying 'harmonic' foundation for most South Asian music is the drone, a held open fifth (or fourth) that does not alter in pitch throughout the course of a composition. Pitch simultaneity in particular is rarely a major consideration. Nevertheless many other considerations of pitch are relevant to the music, its theory and its structure, such as the complex system of Rāgas, which combines both melodic and modal considerations and codifications within it.
So, intricate pitches combinations that sound simultaneously do occur in Indian classical music—but they are rarely studied as teleological harmonic or contrapuntal progressions—as with notated Western music. This contrasting emphasis (with regard to Indian music in particular) manifests itself in the different methods of performance adopted: in Indian Music improvisation takes a major role in the structural framework of a piece, whereas in Western Music improvisation has been uncommon since the end of the 19th century. Where it does occur in Western music (or has in the past), the improvisation either embellishes pre-notated music or draws from musical models previously established in notated compositions, and therefore use familiar harmonic schemes.
Nevertheless, emphasis on the precomposed in European art music and the written theory surrounding it shows considerable cultural bias. The "Grove Dictionary of Music and Musicians" (Oxford University Press) identifies this clearly:
In Western culture the musics that are most dependent on improvisation, such as jazz, have traditionally been regarded as inferior to art music, in which pre-composition is considered paramount. The conception of musics that live in oral traditions as something composed with the use of improvisatory techniques separates them from the higher-standing works that use notation.—
Yet the evolution of harmonic practice and language itself, in Western art music, is and was facilitated by this process of prior composition (which permitted the study and analysis by theorists and composers alike of individual pre-constructed works in which pitches (and to some extent rhythms) remained unchanged regardless of the nature of the performance).
Historical rules.
Some traditions of Western music performance, composition, and theory have specific rules of harmony. These rules are often described as based on natural properties such as Pythagorean tuning's law whole number ratios ("harmoniousness" being inherent in the ratios either perceptually or in themselves) or harmonics and resonances ("harmoniousness" being inherent in the quality of sound), with the allowable pitches and harmonies gaining their beauty or simplicity from their closeness to those properties. This model provides that the minor seventh and ninth are not dissonant (i.e., are consonant). While Pythagorean ratios can provide a rough approximation of perceptual harmonicity, they cannot account for cultural factors.
Early Western religious music often features parallel perfect intervals; these intervals would preserve the clarity of the original plainsong. These works were created and performed in cathedrals, and made use of the resonant modes of their respective cathedrals to create harmonies. As polyphony developed, however, the use of parallel intervals was slowly replaced by the English style of consonance that used thirds and sixths. The English style was considered to have a sweeter sound, and was better suited to polyphony in that it offered greater linear flexibility in part-writing. Early music also forbade usage of the tritone, as its dissonance was associated with the devil, and composers often went to considerable lengths, via musica ficta, to avoid using it. In the newer triadic harmonic system, however, the tritone became permissible, as the standardization of functional dissonance made its use in dominant chords desirable.
Most harmony comes from two or more notes sounding simultaneously—but a work can imply harmony with only one melodic line by using arpeggios or hocket. Many pieces from the baroque period for solo string instruments—such as Bach's Sonatas and partitas for solo violin and cello—convey subtle harmony through inference rather than full chordal structures. These works create a sense of harmonies by using arpeggiated chords and implied basslines. The implied basslines are created with low notes of short duration that many listeners perceive as being the bass note of a chord. (See below):
Types.
Carl Dahlhaus (1990) distinguishes between "coordinate" and "subordinate harmony". "Subordinate harmony" is the hierarchical tonality or tonal harmony well known today. "Coordinate harmony" is the older Medieval and Renaissance "tonalité ancienne", "The term is meant to signify that sonorities are linked one after the other without giving rise to the impression of a goal-directed development. A first chord forms a 'progression' with a second chord, and a second with a third. But the former chord progression is independent of the later one and vice versa." Coordinate harmony follows direct (adjacent) relationships rather than indirect as in subordinate. Interval cycles create symmetrical harmonies, which have been extensively used by the composers Alban Berg, George Perle, Arnold Schoenberg, Béla Bartók, and Edgard Varèse's "Density 21.5".
Close harmony and open harmony use close position and open position chords, respectively. See: voicing (music) and close and open harmony.
Other types of harmony are based upon the intervals of the chords used in that harmony. Most chords used in western music are based on "tertian" harmony, or chords built with the interval of thirds. In the chord C Major7, C-E is a major third; E-G is a minor third; and G to B is a major third. Other types of harmony consist of quartal harmony and quintal harmony.
Unison is considered a harmonic interval, just like a fifth or a third. What's unique about unison is that it is two identical notes being played or sung together. Most people only consider thirds and fifths and sevenths to be "harmony". But, unison does count as harmony, and is very important in orchestration, especially. In Pop music, unison singing is usually called "doubling" which is what The Beatles used to do a lot in their early music. As a type of harmony, singing in unison or playing the same notes, often using different musical instruments, at the same time is commonly called monophonic harmonization.
Intervals.
An interval is the relationship between two separate musical pitches. For example, in the melody "Twinkle Twinkle Little Star", the first two notes (the first "twinkle") and the second two notes (the second "twinkle") are at the interval of one fifth. What this means is that if the first two notes were the pitch C, the second two notes would be the pitch "G"—four scale notes, or seven chromatic notes (a perfect fifth), above it.
The following are common intervals:
Therefore, the combination of notes with their specific intervals —a chord— creates harmony. For example, in a C chord, there are three notes: C, E, and G. The note C is the root. The notes E and G provide harmony, and in a G7 (G dominant 7th) chord, the root G with each subsequent note (in this case B, D and F) provide the harmony.
In the musical scale, there are twelve pitches. Each pitch is referred to as a "degree" of the scale. The names A, B, C, D, E, F, and G are insignificant. The intervals, however, are not. Here is an example:
As can be seen, no note always corresponds to a certain degree of the scale. The "tonic", or 1st-degree note, can be any of the 12 notes (pitch classes) of the chromatic scale. All the other notes fall into place. For example, when C is the tonic, the fourth degree or subdominant is F. When D is the tonic, the fourth degree is G. While the note names remain constant, they may refer to different scale degrees, implying different intervals with respect to the tonic. The great power of this fact is that any musical work can be played or sung in any key. It is the same piece of music, as long as the intervals are the same—thus transposing the melody into the corresponding key. When the intervals surpass the perfect Octave (12 semitones), these intervals are called "compound intervals", which include particularly the 9th, 11th, and 13th Intervals—widely used in jazz and blues Music.
Compound Intervals are formed and named as follows:
The reason the two numbers don't "add" correctly is that one note is counted twice.
Apart from this categorization, intervals can also be divided into consonant and dissonant. As explained in the following paragraphs, consonant intervals produce a sensation of relaxation and dissonant intervals a sensation of tension. In tonal music, the term consonant also means "brings resolution" (to some degree at least, whereas dissonance "requires resolution").
The consonant intervals are considered the perfect unison, octave, fifth, fourth and major and minor third and sixth, and their compound forms. An interval is referred to as "perfect" when the harmonic relationship is found in the natural overtone series (namely, the unison 1:1, octave 2:1, fifth 3:2, and fourth 4:3). The other basic intervals (second, third, sixth, and seventh) are called "imperfect" because the harmonic relationships are not found mathematically exact in the overtone series. In classical music the perfect fourth above the bass may be considered dissonant when its function is contrapuntal.
Other intervals, the second and the seventh (and their compound forms) are considered Dissonant and require resolution (of the produced tension) and usually preparation (depending on the music style used). It should be noted that the effect of dissonance is perceived relatively within musical context: for example, a major seventh interval alone (i.e. C up to B) may be perceived as dissonant, but the same interval as part of a major seventh chord may sound relatively consonant. A tritone (the interval of the fourth step to the seventh step of the major scale, i.e. F to B) sounds very dissonant alone, but less so within the context of a dominant seventh chord (G7 or D♭7 in that example).
Chords and tension.
In the Western tradition, in music after the seventeenth century, harmony is manipulated using chords, which are combinations of pitch classes. In tertian harmony, so named after the interval of a third, the members of chords are found and named by stacking intervals of the third, starting with the "root", then the "third" above the root, and the "fifth" above the root (which is a third above the third), etc. (Note that chord members are named after their interval above the root.) Dyads, the simplest chords, contain only two members (see power chords).
A chord with three members is called a triad because it has three members, not because it is necessarily built in thirds (see Quartal and quintal harmony for chords built with other intervals). Depending on the size of the intervals being stacked, different qualities of chords are formed. In popular and jazz harmony, chords are named by their root plus various terms and characters indicating their qualities. To keep the nomenclature as simple as possible, some defaults are accepted (not tabulated here). For example, the chord members C, E, and G, form a C Major triad, called by default simply a C chord. In an A♭ chord (pronounced A-flat), the members are A♭, C, and E♭.
In many types of music, notably baroque, romantic, modern and jazz, chords are often augmented with "tensions". A tension is an additional chord member that creates a relatively dissonant interval in relation to the bass. Following the tertian practice of building chords by stacking thirds, the simplest first tension is added to a triad by stacking on top of the existing root, third, and fifth, another third above the fifth, giving a new, potentially dissonant member the interval of a seventh away from the root and therefore called the "seventh" of the chord, and producing a four-note chord, called a "seventh chord".
Depending on the widths of the individual thirds stacked to build the chord, the interval between the root and the seventh of the chord may be major, minor, or diminished. (The interval of an augmented seventh reproduces the root, and is therefore left out of the chordal nomenclature.) The nomenclature allows that, by default, "C7" indicates a chord with a root, third, fifth, and seventh spelled C, E, G, and B♭. Other types of seventh chords must be named more explicitly, such as "C Major 7" (spelled C, E, G, B), "C augmented 7" (here the word augmented applies to the fifth, not the seventh, spelled C, E, G♯, B♭), etc. (For a more complete exposition of nomenclature see Chord (music).)
Continuing to stack thirds on top of a seventh chord produces extensions, and brings in the "extended tensions" or "upper tensions" (those more than an octave above the root when stacked in thirds), the ninths, elevenths, and thirteenths. This creates the chords named after them. (Note that except for dyads and triads, tertian chord types are named for the interval of the largest size and magnitude in use in the stack, not for the number of chord members : thus a ninth chord has five members "[tonic, 3rd, 5th, 7th, 9th]", not nine.) Extensions beyond the thirteenth reproduce existing chord members and are (usually) left out of the nomenclature. Complex harmonies based on extended chords are found in abundance in jazz, late-romantic music, modern orchestral works, film music, etc.
Typically, in the classical Common practice period a dissonant chord (chord with tension) "resolves" to a consonant chord. Harmonization usually sounds pleasant to the ear when there is a balance between the consonant and dissonant sounds. In simple words, that occurs when there is a balance between "tense" and "relaxed" moments. For this reason, usually tension is 'prepared' and then 'resolved'.
Preparing tension means to place a series of consonant chords that lead smoothly to the dissonant chord. In this way the composer ensures introducing tension smoothly, without disturbing the listener. Once the piece reaches its sub-climax, the listener needs a moment of relaxation to clear up the tension, which is obtained by playing a consonant chord that resolves the tension of the previous chords. The clearing of this tension usually sounds pleasant to the listener, though this is not always the case in late-nineteenth century music, such as Tristan und Isolde by Richard Wagner.
Perception of harmony.
Harmony is based on consonance, a concept whose definition has changed various times during the history of Western music. In a psychological approach, consonance is a continuous variable. Consonance can vary across a wide range. A chord may sound consonant for various reasons.
One is lack of perceptual roughness. Roughness happens when partials (frequency components) lie within a critical bandwidth, which is a measure of the ear's ability to separate different frequencies. Critical bandwidth lies between 2 and 3 semitones at high frequencies and becomes larger at lower frequencies. The roughness of two simultaneous harmonic complex tones depends on the amplitudes of the harmonics and the interval between the tones. The roughest interval in the chromatic scale is the minor second and its inversion the major seventh. For typical spectral envelopes in the central range, the second roughest interval is the major second and minor seventh, followed by the tritone, the minor third (major sixth), the major third (minor sixth) and the perfect fourth (fifth).
The second reason is perceptual fusion. A chord fuses in perception if its overall spectrum is similar to a harmonic series. According to this definition a major triad fuses better than a minor triad and a major-minor seventh chord fuses better than a major-major seventh or minor-minor seventh. These differences may not be readily apparent in tempered contexts but can explain why major triads are generally more prevalent than minor triads and major-minor sevenths generally more prevalent than other sevenths (in spite of the dissonance of the tritone interval) in mainstream tonal music. Of course these comparisons depend on style.
The third reason is familiarity. Chords that have often been heard in musical contexts tend to sound more consonant. This principle explains the gradual historical increase in harmonic complexity of Western music. For example, around 1600 unprepared seventh chords gradually became familiar and were therefore gradually perceived as more consonant.
Western music is based on major and minor triads. The reason why these chords are so central is that they are consonant in terms of both fusion and lack of roughness. they fuse because they include the perfect fourth/fifth interval. They lack roughness because they lack major and minor second intervals. No other combination of three tones in the chromatic scale satisfies these criteria.
Consonance and dissonance in balance.
Post-nineteenth century music has evolved in the way that tension may be less often prepared and less formally structured than in Baroque or Classical periods, thus producing new styles such as post-romantic harmony, impressionism, pantonality, Jazz and Blues, where dissonance may not be prepared in the way seen in 'common practice' harmony. In a jazz or blues song, the tonic chord may be a dominant seventh chord.
The creation and destruction of harmonic and 'statistical' tensions is essential to the maintenance of compositional drama. Any composition (or improvisation) which remains consistent and 'regular' throughout is, for me, equivalent to watching a movie with only 'good guys' in it, or eating cottage cheese.—Frank Zappa, "The Real Frank Zappa Book" page 181, Frank Zappa and Peter Occhiogrosso, 1990

</doc>
<doc id="40259" url="http://en.wikipedia.org/wiki?curid=40259" title="Harthacnut">
Harthacnut

Harthacnut, Harðacnut, or Canute III (Danish: Hardeknud; "Tough-knot"; c.1018 – 8 June 1042) was King of Denmark from 1035 to 1042 and King of England from 1040 to 1042.
He was the son of King Cnut the Great (who ruled Denmark, Norway, and England) and Emma of Normandy. When Cnut died in 1035, Harthacnut struggled to retain his father's possessions. Magnus I took control of Norway, but Harthacnut succeeded as King of Denmark and became King of England in 1040 after the death of his half-brother Harold Harefoot.
Harthacnut died suddenly in 1042 and was succeeded by Magnus in Denmark and Edward the Confessor in England. Harthacnut was the last Scandinavian to rule England.
Early life.
Harthacnut was born shortly after the marriage of his parents in July or August 1017. Cnut had put aside his first wife Ælfgifu of Northampton to marry Emma, and according to the "Encomium Emmae Reginae", a book she inspired many years later, Cnut agreed that any sons of their marriage should take precedence over the sons of his first marriage. In 1023, Emma and Harthacnut played a leading role in the translation of the body of the martyr St Æelfheah from London to Canterbury, an occasion seen by Harthacnut's biographer, Ian Howard, as recognition of his position as Cnut's heir in England.
King of Denmark.
In the 1020s, Denmark was threatened by Norway and Sweden, and in 1026, Cnut decided to strengthen its defences by bringing over his eight-year-old son to be the future king under a council headed by his brother-in-law, Earl Ulf. However, Ulf alienated Cnut by getting the Danish provinces to acknowledge Harthacnut as king without reference to Cnut's overall authority and by failing to take vigorous measures to meet Norwegian and Swedish invasions, instead waiting for Cnut's assistance. In 1027, Cnut arrived with a fleet. He forgave Harthacnut his insubordination in view of his youth but had Ulf murdered. He drove the invaders out of Denmark and established his authority over Norway, returning to England in 1028 and leaving Denmark to be ruled by King Harthacnut.
Cnut had left Norway under the rule of Håkon Eiriksson, but he was drowned in 1029, and Cnut appointed his son Svein to rule Norway with the assistance of Ælfgifu, Cnut's first wife and Svein's mother. However, they made themselves unpopular by heavy taxation and favouring Danish advisers over the Norwegian nobles, and when King Magnus I of Norway, the son of the former King of Norway, Olaf, invaded in 1035, they were forced to flee to Harthacnut's court. Harthacnut was a close ally of Svein, but he did not feel his resources were great enough to launch an invasion of Norway, and the half-brothers looked for help from their father, but instead they received news of his death in November 1035.
England and Denmark.
In 1035, Harthacnut succeeded his father on the throne of Denmark as Cnut III. He was unable to come to England in view of the situation in Denmark, and it was agreed that Svein's full brother, Harold Harefoot, should act as regent, with Emma holding Wessex on Harthacnut's behalf. In 1037, Harold was generally accepted as king, Harthacnut being, in the words of the "Anglo-Saxon Chronicle", "forsaken because he was too long in Denmark", while Emma fled to Bruges, in Flanders. In 1039, Harthacnut sailed with ten ships to meet his mother in Bruges but delayed an invasion as it was clear Harold was sick and would soon die, which he did in March 1040. Envoys soon crossed the channel to offer Harthacnut the throne.
While the general outline of events following Cnut's death are clear, the details are obscure, and historians give differing interpretations. M. K. Lawson in his "Dictionary of National Biography" article on Harthacnut states that it is unclear whether Harthacnut was to have England as well as Denmark, but it was probably a reflection of a formal arrangement that mints south of the Thames produced silver pennies in his name, while those to the north were almost all Harold's. There might have been a division of the kingdom if Harthacnut had appeared straight away. He probably stayed in Denmark because of the threat from Magnus of Norway, but they eventually made a treaty by which if either died without an heir, his kingdom would go to the other, and this may have freed Harthacnut to pursue his claim to England.
According to Ian Howard, Harthacnut agreed to help Svein recover Norway and planned an invasion in 1036. Svein died shortly before it was to set out, but Harthacnut proceeded anyway. War was avoided by the treaty between Harthacnut and Magnus, which Harthacnut agreed to because he had no plausible candidate to rule Norway after Svein's death, and he was in any case temperamentally inclined to avoid campaigns and wars. Howard dates the treaty to 1036, whereas other historians date it to 1039 and believe it freed Harthacnut to launch an invasion of England.
In exile in Bruges, Emma plotted to gain the English throne for her son. She sponsored the "Encomium Emmae Reginae", which eulogised her and attacked Harold, especially for arranging the murder of Alfred Atheling (the younger of Emma's two sons by Æthelred) in 1036. The work describes Harthacnut's horror at hearing of his brother's murder, and in Howard's view, was probably influential in finally persuading the cautious Harthacnut to invade England. According to a later edition of the "Encomium", the English took the initiative in communicating with Harthacnut in 1039, possibly when they became aware that Harold had not long to live.
King of England.
Harthacnut travelled to England with his mother. The landing at Sandwich on 17 June 1040, "seven days before Midsummer", was a peaceful one, though he had a fleet of 62 warships. Even though he had been invited to take the throne, he was taking no chances and came as a conqueror with an invasion force. The crews had to be rewarded for their service, and to pay them, he levied a geld of more than 21,000 pounds, a huge sum of money that made him unpopular, although it was only a quarter of the amount his father had raised in similar circumstances in 1017–1018.
Harthacnut had been horrified by Harold's murder of Alfred, and his mother demanded vengeance. With the approval of Harold's former councillors, his body was disinterred from its place of honour at Westminster and publicly beheaded. It was disposed of in a sewer, but then retrieved and thrown in the Thames, from which London shipmen rescued it and had it buried in a churchyard. Godwin, the powerful earl of Wessex, had been complicit in the crime as he had handed over Alfred to Harold, and Queen Emma charged him in a trial before Harthacnut and members of his council. The king allowed Godwin to escape punishment by bringing witnesses that he had acted on Harold's orders, but Godwin then gave Harthacnut a ship so richly decorated that it amounted to the wergild that Godwin would have had to pay if he had been found guilty. Bishop Lyfing of Worcester was also charged with complicity in the crime and deprived of his see, but in 1041 he made his peace with Harthacnut and was restored to his position.
The English had become used to the king ruling in council, with the advice of his chief men, but Harthacnut had ruled autocratically in Denmark, and he was not willing to change, particularly as he did not fully trust the leading earls. At first he was successful intimidating his subjects, though less so later in his short reign. He doubled the size of the English fleet from sixteen to thirty-two ships, partly so that he had a force capable of dealing with trouble elsewhere in his empire, and to pay for it he severely increased the rate of taxation. The increase coincided with a poor harvest, causing severe hardship. In 1041 two of his tax gatherers were so harsh in dealing with people in and around Worcester that they rioted and killed the tax gatherers. Harthacnut reacted by imposing a then-legal but very unpopular punishment known as 'harrying'. He ordered his earls to burn the town and kill the population. Very few people were killed, however, as they knew what was coming and fled in all directions.
The earl of Northumbria was Siward, but Earl Eadwulf of Bernicia ruled the northern part in semi-independence, a situation which did not please the autocratic Harthacnut. In 1041 Earl Eadwulf gave offence to the king for an unknown reason but then sought reconciliation. Harthacnut promised him safe conduct but then colluded in his murder by Siward, who became earl of the whole of Northumbria. The crime was widely condemned, and the "Anglo-Saxon Chronicle" described it as "a betrayal" and the king as an "oath-breaker".
Harthacnut was generous to the church. Very few contemporary documents survive, but a royal charter of his transferred land to Bishop Ælfwine of Winchester, and he made several grants to Ramsey Abbey. The 12th-century "Ramsey Chronicle" speaks well of his generosity and of his character.
Harthacnut had suffered from bouts of illness even before he became King of England. He may have suffered from tuberculosis, and he probably knew that he had not long to live. In 1041 he invited his half-brother Edward the Confessor (his mother Emma's son by Æthelred the Unready) back from exile in Normandy and probably made him his heir. He may well have been influenced by Emma, who hoped to keep her power by ensuring that one of her sons was succeeded by another. Harthacnut was unmarried and had no known children.
Death.
On 8 June 1042, Harthacnut attended a wedding in Lambeth. The groom was Tovi the Proud, former standard-bearer to Cnut, and the bride was Gytha, daughter of the courtier Osgod Clapa. Harthacnut presumably consumed large quantities of alcohol. As he was drinking to the health of the bride, he "died as he stood at his drink, and he suddenly fell to the earth with an awful convulsion; and those who were close by took hold of him, and he spoke no word afterwards..." The likely cause of death was a stroke, "brought about by an excessive intake of alcohol", though in "The Death of Kings: A Medical History of the Kings and Queens of England" (2000), Clifford Brewer suggested a cardiac arrest as the immediate cause of death.
Harthacnut was buried at Old Minster in Winchester, his father's place of rest. His mother donated a valuable relic, the head of Saint Valentine to New Minster, her offer for the salvation of his soul. In 1052, Emma herself was buried at Old Minster. Her surviving son, Edward the Confessor, had assumed the throne on Harthacnut's death, restoring the Saxon royal line of the House of Wessex. A contradictory account in the "Knýtlinga saga" (13th century), reports Harthacnut buried in the city of Morstr, alongside his half-brother Harold Harefoot and their father Cnut. While mentioned as a great city in the text, nothing else is known of Morstr. The Heimskringla by Snorri Sturluson reports Harthacnut buried at Winchester, alongside Cnut and Harold Harefoot.
Ian Howard speculates that Harthacnut could have been suffering from a terminal illness, such as tuberculosis, something known to himself and his court for a while. This would explain why Emma turned her attention to her other son, Edward, why Magnus seriously expected to succeed the rival king, and why Henry III was eager to have a connection to the Danish monarch (see "Succession" below). While Harthacnut was fairly young, several people were interested in designating an heir for him, as if the young man was already dying and was not expected to have sons of his own. Alan R. Rushton notes that Harthacnut was son to Emma of Normandy, and that there was a pattern of sudden deaths among descendants of the House of Normandy. In 1027, Richard III, Duke of Normandy, died with no apparent reason. Widespread rumours suggested that his brother and heir, Robert I, Duke of Normandy, had him poisoned. Robert I himself went on pilgrimage to Jerusalem. In 1035, Robert died in Nicaea, Bithynia during his return journey. A contemporary chronicler suspected poisoning as the reason behind the sudden death. In 1040, their cousin Alan III, Duke of Brittany died of unexplained causes. Again poison was suspected as the reason. In 1066, his son Conan II, Duke of Brittany also died of unexplained causes. His cousin William the Conqueror was suspected of having him poisoned.
Rushton notes that historians for centuries believed that poison was indeed the most likely explanation behind "an otherwise unexplained death". He speculates, however, that the actual cause could be a hereditary disease, an autosomal dominant pattern. He admits that William the Conqueror, another descendant of this dynasty, generally enjoyed good health but points out that William fell seriously ill following the Battle of Hastings (1066), resting for a month near Canterbury. He then had to return to Normandy for further medical attention. His health problems were attributed to a combination of exhaustion, dysentery, and chronic gout. Twenty years later, William was incapacitated by abdominal colic, supposedly caused by the bow of his saddle. He rested in a monastery near Rouen for three weeks, then died. Symptoms of his last days included a fever and a marked sensitivity to noise. Rushton suspects that William himself could have been suffering from ""an unknown ailment"."
On the other hand, David C. Douglas had pointed out that "allegations of secret poisoning" were rather common in the primary sources from 11th-century Normandy. Any writer on Norman affairs attributed to venom any sudden death, except those involving violence. Surprisingly, these allegations were rare in sources from 11th-century England, even when the sudden deaths would justify the suspicion. He noted that the deaths of Harthacnut (1042), Godwin, Earl of Wessex (1053), and Edward the Exile (1057) formed a suspect pattern, though the primary sources were silent on the subject. He believes that if the deaths had occurred in the Duchy of Normandy, the matter would be seen in a different light. Kelly DeVries noted that while Douglas implied that Harthacnut was poisoned, he did not further explore the notion, never mentioning potential murderers or their motivation. Sten Körner also noted that the death of Harthacnut could be part of a plot, but also did not further explore the notion, though the implication would be that Edward the Confessor was behind this plot. In "The Death of Kings: A Medical History of the Kings and Queens of England" (2000), Clifford Brewer pointed that Edward benefited from the sudden death of Harthacnut and that while Godwin, Earl of Wessex, was the father-in-law to Edward, he had once led an uprising against his son-in-law. He died suddenly after dining with said son-in-law, again pointing suspicion at Edward as the probable culprit behind both deaths. Katherine Holman was certain that Harthacnut was poisoned but felt that the culprit will never be known with certainty due to "no shortage of discontented candidates." 
Succession.
The political agreement between Harthacnut and Magnus I of Norway included the appointment of the latter as heir to Harthacnut. At the time, the agreement would have only affected the throne of Denmark. The Heimskringla reports that when Harthacnut died, Magnus extended his claim to England. He reportedly sent a letter to Edward the Confessor, pressing his claim to the English throne and threatening invasion. His own heir, Harald Hardrada, would also press this claim. Both considered themselves legal heirs to Harthacnut. The Fagrskinna contains a scene where Magnus proclaims that "I will take possession of all the Danish empire or else die in the attempt."
According to the "Encomium", Edward the Confessor already served as co-ruler of England since 1041. There is an emphasis on Harthacnut, Edward, and Emma serving as a trinity of rulers, in emulation of the Holy Trinity. Edward, by surviving his co-ruler, would be king by default. The Heimskringla depicts Edward portraying himself as brother and legal heir to both Harold Harefoot and Harthacnut, while pointing out that he had already won the support "of all the people of the country". Unstated in both is that the marriage of Edward to Edith of Wessex would also support his claim by earning him both the political support of her father Godwin and an additional connection to Cnut. She was a niece to the king. The Fagrskinna has Edward point out that he was the son of Æthelred the Unready and Emma of Normandy, the brother to Edmund Ironside, the stepson of Cnut, the stepbrother of Harold Harefoot, and the half-brother of Harthacnut. In short, he had a much stronger family claim to the throne than Magnus. All the leaders of England had already acknowledged him as their king, and he was consecrated by an archbishop. England was his own heritage. Whether Magnus managed to defeat him in war or not, "you can never be called king in England, and you will never be granted any allegiance there before you put an end to my life." This was supposedly enough to cause Magnus to doubt the strength of his own claim.
The marriage agreement between Gunhilda of Denmark (sister of Harthacnut) and Henry III, Holy Roman Emperor would allow descendants of this marriage to claim the throne of Denmark and potentially of England. The marriage, from Henry's perspective, was probably orchestrated to allow the Holy Roman Empire to claim control of Denmark and the western areas of the Baltic Sea. However, Gunhilda had died in 1038 with no known sons. Her only daughter was Beatrice I, Abbess of Quedlinburg, who never married.
If Harthacnut was known to be dying from an illness (see above), the early attempts of several people to regulate his succession could be seen in a different light. It appears the "sudden" death was actually long expected.
Reputation.
Apart from the "Ramsey Chronicle", medieval sources are hostile to Harthacnut. According to the "Anglo-Saxon Chronicle" he "did nothing worthy of a king as long as he ruled." Modern historians are less dismissive. In the view of M. K. Lawson, he had at least two of the requisites of a successful medieval king, he was "both ruthless and feared"; had he not died young, the Norman Conquest might not have happened. Ian Howard praises Harthacnut for keeping peace throughout his empire, benefiting trade and merchants, and ensuring a peaceful succession by inviting Edward to his court as his heir. Had he lived longer, Howard believes, his character might have enabled him to become a successful king like his father.
Henry of Huntingdon (12th century) claimed that Harthacnut ordered for the dining tables of his court to be "laid four times a day with royal sumptuousness" which O'Brien says is likely a popular myth. Henry of Huntingdon viewed this detail in the context of the monarch sharing these meals with the members of his household, making Harthacnut more generous than his own contemporaries, who ""through avarice, or as they pretend through disgust, ...set but one meal a day before their dependents". His account produced the image of Harthacnut as a "very generous Bon viveur."" Ranulf Higden (14th century) viewed the same detail in a negative light. He claimed that Harthacnut insisted on having two dinners and two suppers per day. His example influenced the English people, who supposedly were to Higden's day gluttonous and extravagant. Higden so claimed that Harthacnut had a lasting effect on the English national character. The association of Harthacnut with gluttony was well-known enough to appear in the novel Ivanhoe (1819) by Walter Scott. The character Cedric comments on his friend Athelstane, whose main character trait is a love for food and drink, that "The soul of Hardicanute hath taken possession of him, and he hath no pleasure save to fill, to swill, and to call for more."
The "Knýtlinga saga" treats the death of Harthacnut as the end of an ancient line of kings, and notes that he was the last Danish king to rule over England. But otherwise Harthacnut is treated as a mere footnote in the line of monarchs, while there are many observations on Cnut. Morkinskinna covers Harthacnut's death in some detail, but records next to nothing about his life, suggesting a lack of memorable details on him, presumably due to his short reign.
The "prose Brut chronicle" was an Anglo-Norman work, covering British and English monarchs from Brut (Brutus of Troy) to the death of Henry III in 1272. It was probably written during the reign of Edward I (reigned 1272–1307), though the oldest surviving manuscript dates to 1338. The text often includes notable errors. The original author remains unknown, but there were a number of continuations by different hands, continuing the story to the Battle of Halidon Hill (1333). The material on Harthacnut is largely positive. The author considered both Harold Harefoot and Harthacnut to have been sons of Cnut and Emma of Normandy. He portrays Harold as lacking in chivalry, courtesy, and honour. While Harthacnut was "...a noble knight and stalwart of body, and he greatly loved knighthood and all virtues." He praises Harthacnut for his generosity with food and drink, claiming that his table was open "...for all who wished to come to his court to be richly served with royal dishes". He concludes by portraying Harthacnut as a loyal son for accepting his mother, Emma, back to court.
Contradictory account of his death.
There is a contradictory account of Harthacnut's death featured in the "Morkinskinna" (13th century). According to this account, Magnus I of Norway (reigned 1034–1047) visited the court of Harthacnut in Denmark, received with all official honours. The two monarchs then argued on a matter of etiquette, on whether the host or the guest should drink first, each man offering the honour to the other. The two eventually agreed that the host should drink first. Then Álfífa (Ælfgifu of Northampton) entered the royal hall, welcoming Magnus. She poured a drink for him. But the guest offered the drink to Harthacnut. He drank from the drinking horn and fell dead, poisoned. Álfífa had thus intended to poison Magnus, but accidentally killed Harthacnut instead. She fled to escape punishment.
The tale is probably fictional in origin, though consistent with the villainous depiction of Ælfgifu in this work. A nearly identical story appears in the "Egils saga", though the three protagonists are different, with Egill Skallagrímsson as the intended victim, with Bárðr of Atley and Gunnhild, Mother of Kings as the would-be poisoners.

</doc>
<doc id="40261" url="http://en.wikipedia.org/wiki?curid=40261" title="Harold Harefoot">
Harold Harefoot

Harold Harefoot or Harold I ( 1015 – 17 March 1040) was King of England from 1035 to 1040. His cognomen "Harefoot" referred to his speed, and the skill of his huntsmanship. He was the younger son of Cnut the Great, king of England, Denmark, and Norway by his first wife, Ælfgifu of Northampton.
Paternity.
The "Anglo-Saxon Chronicle" reports that Harold said that he was a son of Cnut the Great and Ælfgifu of Northampton, ""although it was not true". Florence of Worcester (12th century) elaborates on the subject. Claiming that Ælfgifu wanted to have a son by the king but was unable to, she secretly adopted the newborn children of strangers and pretended to have given birth to them. Harold was reportedly the son of a cobbler, while his brother Svein Knutsson was the illegitimate son of a priest. She deceived Cnut into recognizing both children as his own. Harriet O'Brien doubts that Cnut, the shrewd politician who "masterminded the bloodless takeover of Norway"" could have been deceived in such a way. She suspects that the tale started out as a popular myth, or intentional defamation presumably tailored by Emma of Normandy, the other wife of Cnut and rival to Ælfgifu.
Harthacnut's reign.
Upon the death of Cnut on 12 November 1035, Harold's younger half-brother Harthacnut, the son of Cnut and his queen Emma of Normandy, was legitimate heir to the thrones of both the Danes and the English. Harthacnut, however, was unable to travel to his coronation in England because his Danish kingdom was under threat of invasion by King Magnus I of Norway and King Anund Jacob of Sweden. England's magnates favoured the idea of installing Harold Harefoot temporarily as regent or joint monarch, due to the difficulty of Harthacnut's absence, and despite the opposition of Godwin, the Earl of Wessex, and the Queen, he eventually wore the crown. There is some dispute in primary sources (the "Anglo-Saxon Chronicle") about Harold's initial role. Versions E and F mention him as regent, the others as co-ruler.
Ian Howard points out that Cnut had been survived by three sons: Svein, Harold, and Harthacnut. The "Encomium Emmae Reginae" also describes Edward the Confessor and Alfred Aetheling as the sons of Canute, though the modern term would be step-sons. Harold could claim the regency or kingship because he was the only one of the five present at England in 1035. Harthacnut was reigning in Denmark, and Svein had joined him there following his deposition from the Norwegian throne, while Edward and Alfred were in Normandy. Harthacnut could reign in the name of his absent brothers, with Emma rivaling him as candidate for the regency.
The "Anglo-Saxon Chronicle" ignores the existence of Svein, or his claim to the throne, which Howard considers as evidence of the relative entries being unreliable, of failing to give a complete picture. The Heimskringla of Snorri Sturluson claims that Svein and Harthacnut had agreed to share the kingdom between them. This agreement would include Denmark and (probably) England. Snorri quotes older sources on the subject and could be preserving valuable details.
Assumption of the throne.
Harold reportedly sought coronation as early as 1035. According to the "Encomium Emmae Reginae", however, Æthelnoth, Archbishop of Canterbury, refused to crown Harold Harefoot. Coronation by the Archbishop would be a legal requirement to become a king. Æthelnoth reportedly placed the sceptre and crown on the altar of a temple, possibly that of the Canterbury Cathedral. Offering to consecrate Harold without using any of the royal regalia would have been an empty honour. He refused to remove the items from the altar and forbade any other bishop from doing so. The tale goes on that Harold failed to sway Æthelnoth, as both bribes and threats proved ineffectual. The despairing Harold reportedly rejected Christianity in protest. He refused to attend church services while uncrowned, preoccupying himself with hunting and trivial matters.
The "Encomium" stays silent on an event reported by the "Anglo-Saxon Chronicle" and other sources. Harold was accepted as monarch in a Witenagemot held at Oxford. His chief supporter in the council was Leofric, Earl of Mercia, while the opposition was led by Godwin, Earl of Wessex. There is evidence that Ælfgifu of Northampton was attempting to secure her son's position through bribes to the nobles. In 1036, Gunhilda of Denmark, sister to Harthcanut and half-sister to Harold, married Henry III, King of Germany. On this occasion Immo, a priest serving at the court of the Holy Roman Empire, wrote a letter to Azecho, Bishop of Worms. It included information on the situation in England, with messengers from there reporting that Ælfgifu was gaining the support of the leading aristocrats through pleas and bribery, binding them to herself and Harold by oaths of loyalty.
Initially the Kingdom of England was divided between the two half-brothers. Harold ruled the areas north of the River Thames, supported by the local nobility. The southern nobility under Godwin and Emma continued to be ruled in the name of the absent Harthacnut. The "Anglo-Saxon Chronicle" reports that Godwin and the leading men of Wessex opposed the rule of Harold for "...as long as they could, but they could not do anything against it. " With the north at least on Harold's side, in adherence to the terms of a deal, which Godwin was part of, Emma was settled in Winchester, with Harthacnut's huscarls. Harold soon "sent and had taken from her all the best treasures" of Cnut the Great
The situation could not last for long, and Godwin eventually switched sides. William of Malmesbury asserts that Godwin had been overwhelmed "in power and in numbers" by Harold. In 1037, Emma of Normandy fled to Bruges, Flanders, and Harold "was everywhere chosen as king". The details behind the event are obscure. The account of the "Anglo-Saxon Chronicle", version E, jumps from Harold being a mere regent to Harold being the sole king. Versions C and D do not even make a distinction between the two phases. Ian Howard theorises that the death of Svein Knutsson could have strengthened Harold's position. He went from being the second surviving son of Cnut to being the eldest living, with Harthacnut still absent and unable to press his claim to the throne.
Harold himself is somewhat obscure; the historian Frank Stenton considered it probable that his mother Ælfgifu was "the real ruler of England" for part or all of his reign. Kelly DeVries points that during the High Middle Ages, royal succession in Northern Europe was determined by military power. The eldest son of a king could have a superior right of inheritance but still lose the throne to a younger brother, or other junior claimant, possessing greater military support. Harold managed to win the throne against the superior claim of Harthacnut in this way. The 11th century provides other similar examples. Magnus I of Norway (reigned 1035–1047), who wasn't a warlord, had reigned for more than a decade when his uncle Harald Hardrada (reigned 1047–1066) challenged his rule. With Harald being a famous military leader, his claim would end Magnus' reign early. Baldwin VI, Count of Flanders (reigned 1067–1070) was effectively succeeded by his brother Robert I (reigned 1071–1093), rather than his own sons. Robert Curthose, Duke of Normandy (reigned 1087–1106) lost the throne of England to his younger brothers William II (reigned 1087–1100) and Henry I (reigned 1100–1135).
With the Kingdom of England practically owned by Harold, Harthacnut could not even approach without securing sufficient military strength. His decision to remain in Denmark probably points to him lacking sufficient support, though he would certainly wait for an opportunity to forcefully assert his claim and depose his half-brother. Harold reigned as sole king from 1037 to 1040. There are few surviving documents about events of his reign. The "Anglo-Saxon Chronicle" mostly covers church matters, such as the deaths and appointments of bishops and archbishops. There is, however, record of a skirmish between the Anglo-Saxons and the Welsh in 1039. The named casualties were Eadwine (Edwin), brother to Leofric, Earl of Mercia, Thurkil, and Ælfgeat. But there are no other details concerning this event. Also in 1039, there is mention of a great gale, again with no details.
Invasion by Ælfred and Edward.
In 1036, Ælfred Ætheling, son of Emma by the long-dead Æthelred, returned to the kingdom from exile in the Duchy of Normandy with his brother Edward the Confessor, with some show of arms. Their motivation is uncertain. William of Poitiers claimed that they had come to claim the English throne for themselves. Frank Barlow suspected that Emma had invited them, possibly to use them against Harold. If so, it could mean that Emma had abandoned the cause of Harthacnut, probably to strengthen her own position. But that could have inspired Godwin to also abandon the lost cause.
The "Encomium Emmae Reginae" claims that Harold himself had lured them to England, having sent them a forged letter, supposedly written by Emma. The letter reportedly both decried Harold's behaviour against her, and urged her estranged sons to come and protect her. Barlow and other modern historians suspect that this letter was genuine. Ian Howard argued that Emma not being involved in a major political manoeuvre would be "out of character for her", and the Encomium was probably trying to mask her responsibility for a blunder. William of Jumièges reports that earlier in 1036, Edward had conducted a successful raid of Southampton, managing to win a victory against the troops defending the city and then sailing back to Normandy "richly laden with booty". But the swift retreat confirms William's assessment that Edward would need a larger army to seriously claim the throne.
With his bodyguard, according to the "Anglo-Saxon Chronicle", Ælfred intended to visit his mother, Emma, in Winchester, but he may have made this journey for reasons other than a family reunion. As the "murmur was very much in favour of Harold", on the direction of Godwin (now apparently on the side of Harold Harefoot), Ælfred was captured. Godwin had him seized and delivered to an escort of men loyal to Harefoot. He was transported by ship to Ely, blinded while on board. He died in Ely soon after due to the severity of the wounds, his bodyguard similarly treated. The event would later affect the relationship between Edward and Godwin, the Confessor holding Godwin responsible for the death of his brother.
The failed invasion shows that Harold Harefoot, as a son and successor to Cnut, had gained the support of Anglo-Danish nobility, which violently rejected the claims of Ælfred, Edward, and (by extension) the Aethelings. The House of Wessex had lost support among the nobility of the Kingdom. It might also have served as a turning point in the struggle between Harold and Emma, resulting in the exile of Emma.
Death.
Harold died at Oxford on 17 March 1040 at the relatively young age of 24, just as Harthacnut was preparing an invasion force of Danes, and was buried at Westminster Abbey. His body was subsequently exhumed, beheaded, and thrown into a fen bordering the Thames when Harthacnut assumed the throne in June 1040. The body was subsequently recovered by fishermen, and resident Danes reportly had it reburied at their local cemetery in London. The body was eventually buried in a church in the City of Westminster, which was fittingly named St. Clement Danes. A contradictory account in the "Knýtlinga saga" (13th century) reports Harold buried in the city of Morstr, alongside his half-brother Harthacnut and their father Cnut. While mentioned as a great city in the text, nothing else is known of Morstr. The Heimskringla by Snorri Sturluson reports Harold Harefoot buried at Winchester, again alongside Cnut and Harthacnut.
The cause of Harold's death is uncertain. Katherine Holman attributes the death to "a mysterious illness". An Anglo-Saxon charter attributes the illness to divine judgment. Harold had reportedly claimed Sandwich for himself, thereby depriving the monks of Christchurch. Harold is described as lying ill and in despair at Oxford. When monks came to him to settle the dispute over Sandwich, he "lay and grew black as they spoke". The context of the event was a dispute between Christchurch and St Augustine's Abbey, which took over the local toll in the name of the king. There is little attention paid to the illness of the king. Harriet O'Brien feels this is enough to indicate that Harold died of natural causes, but not to determine the nature of the disease. The Anglo-Saxons themselves would consider him elf-shot (attacked by elves), their term for any number of deadly diseases. Michael Evans points out that Harold was only one of several youthful kings of pre-Conquest England to die following short reigns. Others included Edmund I (reigned 939–946), Eadred (reigned 946–955), Eadwig (reigned 955–959), Edmund Ironside (reigned 1016), and Harthacnut (reigned 1040–1042). Evans wonders whether the role of king was dangerous in this era, more so than in the period after the Conquest, or whether hereditary diseases were in effect, since most of these kings were members of the same lineage, the House of Wessex.
It is unclear why a king would have been buried at the Abbey. The only previous royals reportedly buried there were Sæberht of Essex and his wife Æthelgoda. Emma Mason speculates that Cnut had built a royal residence in the vicinity of the Abbey, or that Westminster held some significance to the Danish Kings of England, which would also explain why Harthacnut would not allow a usurper to be buried there. The lack of detail in the "Anglo-Saxon Chronicle" implies that, for its compilers, the main point of interest was not the burial site, but the exhumation of the body. Harriet O'Brien theorises that the choice of location might simply reflect the political affiliation of the area, the area of Westminster and nearby London being a power base for Harold.
A detailed account of the exhumation appears in the writings of John of Worcester (12th century). The group tasked with the mission was reportedly led by Ælfric Puttoc, Archbishop of York, and Godwin, Earl of Wessex. The involvement of such notable men would have had a significance of its own, giving the event an official nature and avoiding secrecy. Emma Mason suspects that this could also serve as a punishment for Godwine, who had served as a chief supporter of Harold, and was now tasked with the gruesome task.
Offspring.
Harold may have had a wife, Ælfgifu, and a son, Ælfwine, who became a monk on the continent when he was older – his monastic name was Alboin. Ælfwine/Alboin is recorded in 1060 and 1062 in charters from the St. Foy Abbey Church in Conques, which mention him as son of "Heroldus rex fuit Anglorum" (Latin: Harold, who was king of the English People). Harold Harefoot is the most likely father as the only other king Harold was Harold Godwinson, who would not rise to the throne until 1066. Either way, an underage boy would be unable to claim the throne in 1040. His possible hereditary claims would not be enough to gain the support of the leading nobles against the adult Harthacnut.
Ælfgifu of Northampton disappears with no trace after 1040. According to the "Anglo-Saxon Chronicle", Harold Harefoot ruled for four years and sixteen weeks, by which calculation he would have begun ruling two weeks after the death of Cnut.
Reputation.
The "Prose Brut chronicle" was an Anglo-Norman work, covering British and English monarchs from Brut (Brutus of Troy) to the death of Henry III in 1272. It was probably written during the reign of Edward I (reigned 1272–1307), though the oldest surviving manuscript dates to 1338. The text often includes notable errors. The original author remains unknown, but there were a number of continuations by different hands, extending the story to the Battle of Halidon Hill (1333). The material on Harold Harefoot is rather unflattering. The author considered both Harold and Harthacnut to have been sons of Cnut and Emma of Normandy. He proceeds to portray Harold as follows: "...He went astray from the qualities and conduct of his father King Cnut, for he cared not at all for knighthood, for courtesy, or for honour, but only for his own will...". He accuses Harold of driving his own mother Emma out of England, by the advice of Godwin, Earl of Wessex. He paints Harthacnut in a more favorable light.
The "Knýtlinga saga" (13th century) considers Harold Harefoot to be the oldest son of Cnut and Emma of Normandy, though its author frequently misrepresents family relationships. Harthacnut and Gunhilda of Denmark are regarded in the text as his younger siblings. The narrative has Harold and Harthacnut dividing the realms of their father in an agreement. It also features Harold offering hospitality to his half-brother Edward the Confessor, but they were actually step-brothers, and Edward only settled in England following the death of Harold.
External links.
 Media related to at Wikimedia Commons

</doc>
<doc id="40270" url="http://en.wikipedia.org/wiki?curid=40270" title="Vibrator">
Vibrator

Vibrator may refer to:

</doc>
<doc id="40272" url="http://en.wikipedia.org/wiki?curid=40272" title="Industrial sociology">
Industrial sociology

Industrial sociology, until recently a crucial research area within the field of sociology of work, examines "the direction and implications of trends in technological change, globalization, labour markets, work organization, managerial practices and employment relations to the extent to which these trends are intimately related to changing patterns of inequality in modern societies and to the changing experiences of individuals and families the ways in which workers challenge, resist and make their own contributions to the patterning of work and shaping of work institutions."
Labor process theory.
One branch of industrial sociology is Labor process theory (LPT). In 1974, Harry Braverman wrote "", which provided a critical analysis of scientific management. This book analyzed capitalist productive relations from a Marxist perspective. Following Marx, Braverman argued that work within capitalist organisations was exploitative and alienating, and therefore workers had to be coerced into servitude. For Braverman the pursuit of capitalist interests over time ultimately leads to deskilling and routinisation of the worker. The Taylorist work design is the ultimate embodiment of this tendency.
Braverman demonstrated several mechanisms of control in both the factory blue collar and clerical white collar labor force.
His key contribution is his "deskilling" thesis. Braverman argued that capitalist owners and managers were incessantly driven to deskill the labor force to lower production costs and ensure higher productivity. Deskilled labour is cheap and above all easy to control due to the workers lack of direct engagement in the production process. In turn work becomes intellectually or emotionally unfulfilling; the lack of capitalist reliance on human skill reduces the need of employers to reward workers in anything but a minimal economic way.
Braverman's contribution to the sociology of work and industry (i.e., industrial sociology) has been important and his theories of the labor process continue to inform teaching and research. Braverman's thesis has however been contested, notably by Andrew Freidman in his work "Industry and Labour" (1977). In it, Freidman suggests that whilst the direct control of labour is beneficial for the capitalist under certain circumstances, a degree of 'responsible autonomy' can be granted to unionised or 'core' workers, in order to harness their skill under controlled conditions. Also, Richard Edwards showed in 1979 that although hierarchy in organisations has remained constant, additional forms of control (such as technical control via email monitoring, call monitoring; bureaucratic control via procedures for leave, sickness etc.) has been added to gain the interests of the capitalist class versus the workers. Gallie has shown how important is to approach the question of skill from a social class perspective. In his study, the majority of non-manual, intermediate and skilled manual workers believed that their work had come to demand a higher level of skill, but the majority of manual worker felt that the responsibility and skill needed in their work had either remained constant or declined. This means that Braverman's claims can't be applied to all social classes.
The notion the particular type of technology workers were exposed to shapes their experience was most forceufully argued in a classic study by Blauner. He argued that some work is alienating more than other types because of the different technologies workers use. Alienation, to Blauner, has four dimensions: powerlessness, meaninglessness, isolation, and self-estrangement. Individuals are powerless when they can't control their own actions or conditions of work; work is meaningless when it gives employees little or no sense of value, interest or worth; work is isolating when workers cannot identify with their workplace; and work is self-estranging when, at the subjective level, the worker has no sense of involvement in the job.
Blauner's claims however fail to recognize that the same technology can be experienced in a variety of ways. Studies have shown that cultural differences with regard to management-union relations, levels of hieararchical control, and reward and performance appraisal policies mean that the experience of the same kind of work can vary considerably between countries and firms. The individualization of work and the need for workers to have more flexible skills in order to respond to technological changes means that Blauner's characterization of work experience is no longer valid. Additionally, workers today may work in teams to alleviate workers' sense of alienation, since they are involved in the entire process, rather than just a small part of it. In conclusion, automative technologies and comupeterized work systems have typically enhanced workers' job satisfaction and skill deployment in the better-paid, secure public and private sector jobs. But, in more non-skilled manual work, they have just perpetuated job dissatisfaction, especially for the many women involved in this type of work.

</doc>
<doc id="40275" url="http://en.wikipedia.org/wiki?curid=40275" title="Kayaking">
Kayaking

Kayaking is the use of a kayak for moving across water. It is distinguished from canoeing by the sitting position of the paddler and the number of blades on the paddle. A kayak is a boat where the paddler faces forward, legs in front, using a double-bladed paddle. Most kayaks have closed decks, although sit-on-top and inflatable kayaks are growing in popularity as well.
Design.
Kayaks can also be classified by their design and the materials from which they are made. Each design has its specific advantage, including performance, manoeuvrability, stability and paddling style. Kayaks can be made of metal, fibreglass, wood, plastic, fabrics, and inflatable fabrics such as PVC or rubber, and more recently expensive but feather light carbon fiber. Each material also has its specific advantage, including strength, durability, portability, flexibility, resistance to ultraviolet and storage requirements. For example, wooden kayaks can be created from kits or built by hand. Stitch and glue, plywood kayaks can be lighter than any other material except skin-on frame. Inflatable kayaks, made from lightweight fabric, can be deflated and easily transported and stored.
Types of kayaks.
"Sit on tops", as the name suggests, involve sitting on top of the kayak in an open area. "Cockpit style" involves sitting with the legs and hips inside the kayak hull with a spray deck or "spray skirt" that creates a water resistant seal around the waist. "Inflatables" are a hybrid of the two previous configurations, these boats have an open deck, but the paddler sits below the level of the deck. "Tandems" are configured for multiple paddlers, in contrast to the single person designs featured by most kayaks. Tandems can be used by two or even three paddlers.
Activities involving kayaks.
Because of their range and adaptability, kayaks can be useful for other outdoor activities such as diving, fishing, wilderness exploration and search and rescue during floods.

</doc>
<doc id="40276" url="http://en.wikipedia.org/wiki?curid=40276" title="Blackboard bold">
Blackboard bold

Blackboard bold is a typeface style that is often used for certain symbols in mathematical texts, in which certain lines of the symbol (usually vertical or near-vertical lines) are doubled. The symbols usually denote number sets. One way of producing Blackboard bold is to double-strike a character with a small offset on a typewriter. Thus they are referred to as double struck.
Origin.
In some texts these symbols are simply shown in bold type: blackboard bold in fact originated from the attempt to write bold letters on blackboards in a way that clearly differentiated them from non-bold letters i.e. by using the edge rather than point of the chalk. It then made its way back in print form as a separate style from ordinary bold, possibly starting with the original 1965 edition of Gunning and Rossi's textbook on complex analysis. 
Rejection.
Some mathematicians, therefore, do not recognize blackboard bold as a separate style from bold: Jean-Pierre Serre, for example, uses double-struck letters when writing bold on the blackboard, whereas his published works consistently use ordinary bold for the same symbols. Donald Knuth also prefers boldface to blackboard bold, and consequently did not include blackboard bold in the Computer Modern fonts he created for the TeX mathematical typesetting system.
The Chicago Manual of Style in 1993 (14th edition) advises: "blackboard bold should be confined to the classroom" (13.14) whereas in 2003 (15th edition) it states that "open-faced (blackboard) symbols are reserved for familiar systems of numbers" (14.12).
Encoding.
TeX, the standard typesetting system for mathematical texts, does not contain direct support for blackboard bold symbols, but the add-on AMS Fonts package (codice_1) by the American Mathematical Society provides this facility; a blackboard bold R is written as codice_2. The codice_3 package loads codice_1.
In Unicode, a few of the more common blackboard bold characters (C, H, N, P, Q, R and Z) are encoded in the Basic Multilingual Plane (BMP) in the "Letterlike Symbols (2100–214F)" area, named DOUBLE-STRUCK CAPITAL C etc. The rest, however, are encoded outside the BMP, from codice_5 to codice_6 (uppercase, excluding those encoded in the BMP), codice_7 to codice_8 (lowercase) and codice_9 to codice_10 (digits). Being outside the BMP, these are relatively new and not widely supported.
Usage.
The following table shows all available Unicode blackboard bold characters.
The symbols are nearly universal in their interpretation, unlike their normally-typeset counterparts, which are used for many different purposes.
The first column shows the letter as typically rendered by the ubiquitous LaTeX markup system. The second column shows the Unicode codepoint. The third column shows the symbol itself (which will only display correctly on browsers that support Unicode and have access to a suitable font). The fourth column describes known typical (but not universal) usage in mathematical texts.
In addition, a blackboard-bold Greek letter mu (not found in Unicode) is sometimes used by number theorists and algebraic geometers (with a subscript "n") to designate the group (or more specifically group scheme) of "n"-th roots of unity.

</doc>
<doc id="40277" url="http://en.wikipedia.org/wiki?curid=40277" title="Corpus linguistics">
Corpus linguistics

Corpus linguistics is the study of language as expressed in samples "(corpora)" of "real world" text. This method represents a digestive approach to deriving a set of abstract rules by which a natural language is governed or else relates to another language. Originally done by hand, corpora are now largely derived by an automated process.
Corpus linguistics adherents believe that reliable language analysis best occurs on field-collected samples, in natural contexts and with minimal experimental interference. Within corpus linguistics there are divergent views as to the value of corpus annotation, from John Sinclair advocating minimal annotation and allowing texts to 'speak for themselves', to others, such as the Survey of English Usage team (based in University College, London) advocating annotation as a path to greater linguistic understanding and rigour.
History.
Some of the earliest efforts at grammatical description were based at least in part on corpora of particular religious or cultural significance. For example, Prātiśākhya literature described the sound patterns of Sanskrit as found in the Vedas, and 
Pāṇini's grammar of classical Sanskrit was based at least in part on analysis of that same corpus. Similarly, the early Arabic grammarians paid particular attention to the language of the Quran. In the Western European tradition, scholars prepared concordances to allow detailed study of the language of the Bible and other canonical texts.
A landmark in modern corpus linguistics was the publication by Henry Kucera and W. Nelson Francis of "Computational Analysis of Present-Day American English" in 1967, a work based on the analysis of the Brown Corpus, a carefully compiled selection of current American English, totalling about a million words drawn from a wide variety of sources. Kucera and Francis subjected it to a variety of computational analyses, from which they compiled a rich and variegated opus, combining elements of linguistics, language teaching, psychology, statistics, and sociology. A further key publication was Randolph Quirk's 'Towards a description of English Usage' (1960) in which he introduced The Survey of English Usage.
Shortly thereafter, Boston publisher Houghton-Mifflin approached Kucera to supply a million word, three-line citation base for its new "American Heritage Dictionary", the first dictionary to be compiled using corpus linguistics. The AHD took the innovative step of combining prescriptive elements (how language "should" be used) with descriptive information (how it actually "is" used).
Other publishers followed suit. The British publisher Collins' COBUILD monolingual learner's dictionary, designed for users learning English as a foreign language, was compiled using the Bank of English. The Survey of English Usage Corpus was used in the development of one of the most important Corpus-based Grammars, the "Comprehensive Grammar of English" (Quirk "et al." 1985).
The Brown Corpus has also spawned a number of similarly structured corpora: the LOB Corpus (1960s British English), Kolhapur (Indian English), Wellington (New Zealand English), Australian Corpus of English (Australian English), the Frown Corpus (early 1990s American English), and the FLOB Corpus (1990s British English). Other corpora represent many languages, varieties and modes, and include the International Corpus of English, and the British National Corpus, a 100 million word collection of a range of spoken and written texts, created in the 1990s by a consortium of publishers, universities (Oxford and Lancaster) and the British Library. For contemporary American English, work has stalled on the American National Corpus, but the 400+ million word Corpus of Contemporary American English (1990–present) is now available through a web interface.
The first computerized corpus of transcribed spoken language was constructed in 1971 by the Montreal French Project, containing one million words, which inspired Shana Poplack's much larger corpus of spoken French in the Ottawa-Hull area.
Besides these corpora of living languages, computerized corpora have also been made of collections of texts in ancient languages. An example is the Andersen-Forbes database of the Hebrew Bible, developed since the 1970s, in which every clause is parsed using graphs representing up to seven levels of syntax, and every segment tagged with seven fields of information. The Quranic Arabic Corpus is an annotated corpus for the Classical Arabic language of the Quran. This is a recent project with multiple layers of annotation including morphological segmentation, part-of-speech tagging, and syntactic analysis using dependency grammar.
Methods.
Corpus Linguistics has generated a number of research methods, attempting to trace a path from data to theory. Wallis and Nelson (2001) first introduced what they called the 3A perspective: Annotation, Abstraction and Analysis.
Most lexical corpora today are part-of-speech-tagged (POS-tagged). However even corpus linguists who work with 'unannotated plain text' inevitably apply some method to isolate salient terms. In such situations annotation and abstraction are combined in a lexical search.
The advantage of publishing an annotated corpus is that other users can then perform experiments on the corpus (through corpus managers). Linguists with other interests and differing perspectives than the originators' can exploit this work. By sharing data, corpus linguists are able to treat the corpus as a locus of linguistic debate, rather than as an exhaustive fount of knowledge.
Recent studies have suggested treatment outcome in adolescents with social anxiety disorder can also be assessed by analysing language by means of Corpus Linguistics 
References.
Journals.
There are several international peer-reviewed journals dedicated to corpus linguistics, for example,
Corpora,
Corpus Linguistics and Linguistic Theory,
 and the
International Journal of Corpus Linguistics.
Book series.
Book series in this field include
Language and Computers,
 and 

</doc>
<doc id="40282" url="http://en.wikipedia.org/wiki?curid=40282" title="Type theory">
Type theory

In mathematics, logic, and computer science, a type theory is any of a class of formal systems, some of which can serve as alternatives to set theory as a foundation for all mathematics. In type theory, every "term" has a "type" and operations are restricted to terms of a certain type.
Type theory is closely related to (and in some cases overlaps with) type systems, which are a programming language feature used to reduce bugs. The types of type theory were created to avoid paradoxes in a variety of formal logics and rewrite systems and sometimes "type theory" is used to refer to this broader application.
Two well-known type theories that can serve as mathematical foundations are Alonzo Church's typed λ-calculi and Per Martin-Löf's intuitionistic type theory.
History.
The types of type theory were invented by Bertrand Russell in response to his discovery that Gottlob Frege's version of naive set theory was afflicted with Russell's paradox. This theory of types features prominently in Whitehead and Russell's "Principia Mathematica". It avoids Russell's paradox by first creating a hierarchy of types, then assigning each mathematical (and possibly other) entity to a type. Objects of a given type are built exclusively from objects of preceding types (those lower in the hierarchy), thus preventing loops.
The common usage of "type theory" is when those types are used with a term rewrite system. The most famous early example is Alonzo Church's lambda calculus. "Church's Theory of Types" helped the formal system avoid the Kleene–Rosser paradox that afflicted the original untyped lambda calculus. Church demonstrated that it could serve as a foundation of mathematics and it was referred to as a higher-order logic.
Some other type theories include Per Martin-Löf's intuitionistic type theory, which has been the foundation used in some areas of constructive mathematics and for the proof assistant Agda. Thierry Coquand's calculus of constructions and its derivatives are the foundation used by Coq and others. The field is an area of active research, as demonstrated by homotopy type theory.
Basic concepts.
In a system of type theory, each term has a type and operations are restricted to terms of a certain type. A typing judgment formula_1 describes that the term formula_2 has type formula_3. For example, formula_4 may be a type representing the natural numbers and formula_5 may be inhabitants of that type. The judgement that formula_6 has type formula_4 is written as formula_8.
A function in type theory is denoted with an arrow formula_9. The function formula_10 (commonly called successor), has the judgement formula_11. Calling or "applying" a function to an argument is usually written without parentheses, so formula_12 instead of formula_13. (This allows for consistent currying.)
Type theories also contain rules for rewriting terms. These are called conversion rules or, if the rule only works in one direction, a reduction rule. For example, formula_14 and formula_15 are syntactically different terms, but the first reduces to the latter. This reduction is denoted as formula_16.
Difference from set theory.
There are many different set theories and many different systems of type theory, so what follows are generalizations.
Optional features.
Normalization.
The term formula_14 reduces to formula_15. Since formula_15 cannot be reduced further, it is called a normal form. A system of type theory is said to be strongly normalizing if all terms have a normal form and any order of reductions reaches it. Weakly normalizing systems have a normal form but some orders of reductions may loop forever and never reach it.
For a normalizing system, some borrow the word element from set theory and use it to refer to all closed terms that can reduce to the same normal form. A closed term is one without parameters. (A term like formula_20 with its parameter formula_21 is called an open term.) Thus, formula_14 and formula_23 may be different terms but they're both from the element formula_15.
A similar idea that works for open and closed terms is convertibility. Two terms are convertible if there exists a term that they both reduce to. For example, formula_14 and formula_26 are convertible. As are formula_27 and formula_28. However, formula_20 and formula_30 (where formula_21 is a free variable) are not because both are in normal form and they are not the same. Confluent and weakly normalizing systems can test if two terms are convertible by checking if they both reduce to the same normal form.
Dependent types.
A dependent type is a type that depends on a term or on another type. Thus, the type returned by a function may depend upon the argument to the function.
For example, a list of formula_4s of length 4 may be a different type than a list of formula_4s of length 5. In a type theory with dependent types, it is possible to define a function that take a parameter "n" and returns a list containing "n" zeros. Calling the function with 4 would produce a term with a different type than if the function was called with 5.
Dependent types play a central role in intuitionistic type theory and in the design of functional programming languages like Idris, ATS, Agda and Epigram.
Equality types (or "identity types").
Many systems of type theory have a type that represents equality of types and terms. This type is different from convertibility, and is often denoted propositional equality.
In intuitionistic type theory, the dependent type is known as formula_34 for identity. There is a type formula_35 when formula_3 is a type and formula_37 and formula_38 are both terms of type formula_3. A term of type formula_35 is interpreted as meaning that formula_37 is equal to formula_38.
In practice, it is possible to build a type formula_43 but there will not exist a term of that type. In intuitionistic type theory, new terms of equality start with reflexivity. If formula_15 is a term of type formula_4, then there exists a term of type formula_46. More complicated equalities can be created by creating a reflexive term and then doing a reduction on one side. So if formula_47 is a term of type formula_4, then there is a term of type formula_49 and, by reduction, generate a term of type formula_50. Thus, in this system, the equality type denotes that two values of the same type are convertible by reductions.
Having a type for equality is important because it can be manipulated inside the system. There is usually no judgement to say two terms are "not" equal; instead, as in the Brouwer–Heyting–Kolmogorov interpretation, we map formula_51 to formula_52, where formula_53 is the bottom type having no values. There exists a term with type formula_54, but not one of type formula_55.
Homotopy type theory differs from intuitionistic type theory mostly by its handling of the equality type.
Inductive types.
A system of type theory requires some basic terms and types to operate on. Some systems build them out of functions using Church encoding. Other systems have inductive types: a set of base types and a set of type constructors that generate types with well-behaved properties. For example, certain recursive functions called on inductive types are guaranteed to terminate.
Coinductive type are infinite data types created by giving a function that generates the next element(s). See Coinduction and Corecursion.
Induction induction is a feature for declaring an inductive type and a family of types that depends on the inductive type.
Induction recursion allows a wider range of well-behaved types but requires that the type and the recursive functions that operate on them be defined at the same time.
Universe types.
Types were created to prevent paradoxes, such as Russell's paradox. However, the motives that lead to those paradoxes – being able to say things about all types – still exist. So many type theories have a "universe type", which contains all other types.
In systems where you might want to say something about universe types, there is a hierarchy of universe types, each containing the one below it in the hierarchy. The hierarchy is defined as being infinite, but statements must only refer to a finite number of universe levels.
Type universes are particularly tricky in type theory. The initial proposal of intuitionistic type theory suffered from Girard's paradox.
Computational component.
Many systems of type theory, such as the simply-typed lambda calculus, intuitionistic type theory, and the calculus of constructions, are also programming languages. That is, they are said to have a "computational component". The computation is the reduction of terms of the language using rewriting rules.
A system of type theory that has a well-behaved computational component also has a simple connection to constructive mathematics through the BHK interpretation.
Non-constructive mathematics in these systems is possible by adding operators on continuations such as call with current continuation. However, these operators tend to break desirable properties such as canonicity and parametricity.
Practical impact.
Programming languages.
There is extensive overlap and interaction between the fields of type theory and type systems. Type systems are a programming language feature designed to identify bugs. Any static program analysis, such as the type checking algorithms in the semantic analysis phase of compiler, has a connection to type theory.
A prime example is Agda, a programming language which uses intuitionistic type theory for its type system. The programming language ML was developed for manipulating type theories (see LCF) and its own type system was heavily influenced by them.
Mathematical foundations.
The first computer proof assistant, called Automath, used type theory to encode mathematics on a computer. Martin-Löf specifically developed intuitionistic type theory to encode "all" mathematics - to serve as a new foundation for mathematics. There is current research into mathematical foundations using homotopy type theory.
Mathematicians working in category theory already had difficulty working with the widely accepted foundation of Zermelo–Fraenkel set theory. This led to proposals such as Lawvere's Elementary Theory of the Category of Sets (ETCS). Homotopy type theory continues in this line using type theory. Researchers are exploring connections between dependent types (especially the identity type) and algebraic topology (specifically homotopy).
Proof assistants.
Much of the current research into type theory is driven by proof checkers, interactive proof assistants, and automated theorem provers. Most of these systems use a type theory as the mathematical foundation for encoding proofs. This is not surprising, given the close connection between type theory and programming languages.
Multiple type theories are supported by LEGO and Isabelle. Isabelle also supports foundations besides type theories, such as ZFC. Mizar is an example of a proof system that only supports set theory.
Linguistics.
Type theory is also widely in use in formal theories of semantics of natural languages, especially Montague grammar and its descendants. In particular, categorial grammars and pregroup grammars make extensive use of type constructors to define the types ("noun", "verb", etc.) of words.
The most common construction takes the basic types formula_56 and formula_57 for individuals and truth-values, respectively, and defines the set of types recursively as follows:
A complex type formula_60 is the type of functions from entities of type formula_37 to entities of type formula_38. Thus one has types like formula_64 which are interpreted as elements of the set of functions from entities to truth-values, i.e. indicator functions of sets of entities. An expression of type formula_65 is a function from sets of entities to truth-values, i.e. a (indicator function of a) set of sets. This latter type is standardly taken to be the type of natural language quantifiers, like " everybody" or " nobody" (Montague 1973, Barwise and Cooper 1981).
Social sciences.
Gregory Bateson introduced a theory of logical types into the social sciences; his notions of double bind and logical levels are based on Russell's theory of types.
Relation to category theory.
Although the initial motivation for category theory was far removed from foundationalism, the two fields turned out to have deep connections. As John Lane Bell writes: "In fact categories can "themselves" be viewed as type theories of a certain kind; this fact alone indicates that type theory is much more closely related to category theory than it is to set theory." In brief, a category can be viewed as a type theory by regarding its objects as types (or sorts), i.e. "Roughly speaking, a category may be thought of as a type theory shorn of its syntax." A number of significant results follow in this way:
The interplay, known as categorical logic, has been a subject of active research since then; see the monograph of Jacobs (1999) for instance.
References.
</dl>

</doc>
<doc id="40283" url="http://en.wikipedia.org/wiki?curid=40283" title="Melting point">
Melting point

The melting point (or, rarely, liquefaction point) of a solid is the temperature at which it changes state from solid to liquid at atmospheric pressure. At the melting point the solid and liquid phase exist in equilibrium. The melting point of a substance depends on pressure and is usually specified at standard pressure. When considered as the temperature of the reverse change from liquid to solid, it is referred to as the freezing point or crystallization point. Because of the ability of some substances to supercool, the freezing point is not considered as a characteristic property of a substance. When the "characteristic freezing point" of a substance is determined, in fact the actual methodology is almost always "the principle of observing the disappearance rather than the formation of ice", that is, the melting point.
Examples.
For most substances, melting and freezing points are approximately equal. For example, the melting point "and" freezing point of mercury is 234.32 kelvin (−38.83 °C or −37.89 °F). However, certain substances possess differing solid-liquid transition temperatures. For example, agar melts at 85 °C (185 °F) and solidifies from 31 °C to 40 °C (89.6 °F to 104 °F); such direction dependence is known as hysteresis.
The melting point of ice at 1 atmosphere of pressure is very close to 0 °C (32 °F, 273.15 K); this is also known as the ice point. In the presence of nucleating substances the freezing point of water is the same as the melting point, but in the absence of nucleators water can supercool to −42 °C (−43.6 °F, 231 K) before freezing.
The chemical element with the highest melting point is tungsten, at 3687 K (3414 °C, 6177 °F) making it excellent for use as filaments in light bulbs. The often-cited carbon does not melt at ambient pressure but sublimes at about 4000 K; a liquid phase only exists above pressures of 10 MPa and estimated 4300–4700 K (see ). Tantalum hafnium carbide (Ta4HfC5) is a refractory compound with a very high melting point of 4488 K (4215 °C, 7619 °F). At the other end of the scale, helium does not freeze at all at normal pressure, even at temperatures very close to absolute zero; pressures over 20 times normal atmospheric pressure are necessary.
Melting point measurements.
Many laboratory techniques exist for the determination of melting points.
A Kofler bench is a metal strip with a temperature gradient (range from room temperature to 300 °C). Any substance can be placed on a section of the strip revealing its thermal behaviour at the temperature at that point. Differential scanning calorimetry gives information on melting point together with its enthalpy of fusion.
A basic melting point apparatus for the analysis of crystalline solids consists of an oil bath with a transparent window (most basic design: a Thiele tube) and a simple magnifier. The several grains of a solid are placed in a thin glass tube and partially immersed in the oil bath. The oil bath is heated (and stirred) and with the aid of the magnifier (and external light source) melting of the individual crystals at a certain temperature can be observed. In large/small devices, the sample is placed in a heating block, and optical detection is automated.
The measurement can also be made continuously with an operating process. For instance, oil refineries measure the freeze point of diesel fuel online, meaning that the sample is taken from the process and measured automatically. This allows for more frequent measurements as the sample does not have to be manually collected and taken to a remote laboratory.
Thermodynamics.
Not only is heat required to raise the temperature of the solid to the melting point, but the melting itself requires heat called the heat of fusion.
From a thermodynamics point of view, at the melting point the change in Gibbs free energy (ΔG) of the material is zero, but the enthalpy ("H") and the entropy ("S") of the material are increasing (ΔH, ΔS > 0). Melting phenomenon happens when the Gibbs free energy of the liquid becomes lower than the solid for that material. At various pressures this happens at a specific temperature. It can also be shown that:
Here "T", "ΔS" and "ΔH" are respectively the temperature at the melting point, change of entropy of melting and the change of enthalpy of melting.
The melting point is sensitive to extremely large changes in pressure, but generally this sensitivity is orders of magnitude less than that for the boiling point, because the solid-liquid transition represents only a small change in volume. If, as observed in most cases, a substance is more dense in the solid than in the liquid state, the melting point will increase with increases in pressure. Otherwise the reverse behavior occurs. Notably, this is the case of water, as illustrated graphically to the right, but also of Si, Ge, Ga, Bi. With extremely large changes in pressure, substantial changes to the melting point are observed. For example, the melting point of silicon at ambient pressure (0.1 MPa) is 1415 °C, but at pressures in excess of 10 GPa it decreases to 1000 °C.
Melting points are often used to characterize organic and inorganic compounds and to ascertain their purity. The melting point of a pure substance is always higher and has a smaller range than the melting point of an impure substance or, more generally, of mixtures. The higher the quantity of other components, the lower the melting point and the broader will be the melting point range, often referred to as the "pasty range". The temperature at which melting begins for a mixture is known as the "solidus" while the temperature where melting is complete is called the "liquidus". Eutectics are special types of mixtures that behave like single phases. They melt sharply at a constant temperature to form a liquid of the same composition. Alternatively, on cooling a liquid with the eutectic composition will solidify as uniformly dispersed, small (fine-grained) mixed crystals with the same composition.
In contrast to crystalline solids, glasses do not possess a melting point;
on heating they undergo a smooth glass transition into a viscous liquid.
Upon further heating, they gradually soften, which can be characterized by certain softening points.
Freezing-point depression.
The freezing point of a solvent is depressed when another compound is added, meaning that a solution has a lower freezing point than a pure solvent. This phenomenon is used in technical applications to avoid freezing, for instance by adding salt or ethylene glycol to water.
Carnelley's Rule.
In organic chemistry Carnelley's Rule, established in 1882 by Thomas Carnelley, stated that "high molecular symmetry is associated with high melting point". Carnelley based his rule on examination of 15,000 chemical compounds. For example for three structural isomers with molecular formula C5H12 the melting point increases in the series isopentane −160 °C (113 K) n-pentane −129.8 °C (143 K) and neopentane −16.4 °C (256.8 K). Likewise in xylenes and also dichlorobenzenes the melting point increases in the order meta, ortho and then para. Pyridine has a lower symmetry than benzene hence its lower melting point but the melting point again increases with diazine and triazines. Many cage-like compounds like adamantane and cubane with high symmetry have relatively high melting points.
A high melting point results from a high heat of fusion, a low entropy of fusion, or a combination of both. In highly symmetrical molecules the crystal phase is densely packed with many efficient intermolecular interactions resulting in a higher enthalpy change on melting.
Predicting the melting point of substances (Lindemann's criterion).
An attempt to predict the bulk melting point of crystalline materials was first made in 1910 by Frederick Lindemann. The idea behind the theory was the observation that the average amplitude of thermal vibrations increases with increasing temperature. Melting initiates when the amplitude of vibration becomes large enough for adjacent atoms to partly occupy the same space. The Lindemann criterion states that melting is expected when the root mean square vibration amplitude exceeds a threshold value.
Assuming that all atoms in a crystal vibrate with the same frequency "ν", the average thermal energy can be estimated using the equipartition theorem as
where "m" is the atomic mass, "ν" is the frequency, "u" is the average vibration amplitude, kB is the Boltzmann constant, and "T" is the absolute temperature. If the threshold value of "u2" is "c2a2" where "c" is the Lindemann constant and "a" is the atomic spacing, then the melting point is estimated as
Several other expressions for the estimated melting temperature can be obtained depending on the estimate of the average thermal energy. Another commonly used expression for the Lindemann criterion is
From the expression for the Debye frequency for "ν", we have
where θD is the Debye temperature and "h" is the Planck constant. Values of "c" range from 0.15–0.3 for most materials.
Melting point open data.
In February 2011 Alfa Aesar released over 10,000 melting points of compounds from their catalog as open data. These data have been curated and are freely available for download. These data have been used to create a random forest model for melting point prediction which is now available as a free-to-use webservice. Highly curated and open melting point data are also available from Nature Precedings.

</doc>
<doc id="40284" url="http://en.wikipedia.org/wiki?curid=40284" title="Cam">
Cam

A cam is a rotating or sliding piece in a mechanical linkage used especially in transforming rotary motion into linear motion or vice versa. It is often a part of a rotating wheel (e.g. an eccentric wheel) or shaft (e.g. a cylinder with an irregular shape) that strikes a lever at one or more points on its circular path. The cam can be a simple tooth, as is used to deliver pulses of power to a steam hammer, for example, or an eccentric disc or other shape that produces a smooth reciprocating (back and forth) motion in the "follower", which is a lever making contact with the cam.
Overview.
The cam can be seen as a device that rotates from circular to reciprocating (or sometimes oscillating) motion. A common example is the camshaft of an automobile, which takes the rotary motion of the engine and translates it into the reciprocating motion necessary to operate the intake and exhaust valves of the cylinders.
Displacement diagram.
Certain cams can be characterized by their displacement diagrams, which reflect the changing position a roller follower (a shaft with a rotating wheel at the end) would make as the cam rotates about an axis. These diagrams relate angular position, usually in degrees, to the radial displacement experienced at that position. Displacement diagrams are traditionally presented as graphs with non-negative values. A simple displacement diagram illustrates the follower motion at a constant velocity rise followed by a similar return with a dwell in between as depicted in figure 2. The rise is the motion of the follower away from the cam center, dwell is the motion where the follower is at rest, and return is the motion of the follower toward the cam center.
However, the most common type is in the valve actuators in internal combustion engines. Here, the cam profile is commonly symmetric and at rotational speeds generally met with, very high acceleration forces develop. Ideally, a convex curve between the onset and maximum position of lift reduces acceleration, but this requires impractically large shaft diameters relative to lift. Thus, in practice, the points at which lift begins and ends mean that a tangent to the base circle appears on the profile. This is continuous with a tangent to the tip circle. In designing the cam, the lift and the dwell angle formula_1 are given. If the profile is treated as a large base circle and a small tip circle, joined by a common tangent, giving lift formula_2 , the relationship can be calculated, given the angle formula_3 between one tangent and the axis of symmetry (formula_3 being formula_5), while formula_6 is the distance between the centres of the circles (required), and formula_7 is the radius of the base (given) and formula_8 that of the tip circle (required)
formula_9
and
formula_10
Plate cam.
The most commonly used cam is the plate cam (also "disc cam" or "radial cam")
which is cut out of a piece of flat metal or plate. Here, the follower moves in a plane perpendicular to the axis of rotation of the camshaft. Several key terms are relevant in such a construction of plate cams: base circle, prime circle (with radius equal to the sum of the follower radius and the base circle radius), pitch curve which is the radial curve traced out by applying the radial displacements away from the prime circle across all angles, and the lobe separation angle (LSA - the angle between two adjacent intake and exhaust cam lobes).
The base circle is the smallest circle that can be drawn to the cam profile.
A once common, but now outdated, application of this type of cam was automatic machine tool programming cams. Each tool movement or operation was controlled directly by one or more cams. Instructions for producing programming cams and cam generation data for the most common makes of machine were included in engineering references well into the modern CNC era.
This type of cam is used in many simple electromechanical appliance controllers, such as dishwashers and clothes washing machines, to actuate mechanical switches that control the various parts.
Cylindrical cam.
A cylindrical cam or barrel cam is a cam in which the follower rides on the surface of a cylinder. In the most common type, the follower rides in a groove cut into the surface of a cylinder. These cams are principally used to convert rotational motion to linear motion parallel to the rotational axis of the cylinder. A cylinder may have several grooves cut into the surface and drive several followers. Cylindrical cams can provide motions that involve more than a single rotation of the cylinder and generally provide positive positioning, removing the need for a spring or other provision to keep the follower in contact with the control surface.
Applications include machine tool drives, such as reciprocating saws, and shift control barrels in sequential transmissions, such as on most modern motorcycles.
A special case of this cam is constant lead, where the position of the follower is linear with rotation, as in a lead screw. The purpose and detail of implementation influence whether this application is called a cam or a screw thread, but in some cases, the nomenclature may be ambiguous.
Cylindrical cams may also be used to reference an output to two inputs, where one input is rotation of the cylinder, and the second is position of the follower axially along the cam. The output is radial to the cylinder. These were once common for special functions in control systems, such as fire control mechanisms for guns on naval vessels and mechanical analog computers.
An example of a cylindrical cam with two inputs is provided by a duplicating lathe, an example of which is the Klotz axe handle lathe, which cuts an axe handle to a form controlled by a pattern acting as a cam for the lathe mechanism.
Face cam.
A face cam produces motion by using a follower riding on the face of a disk. The most common type has the follower ride in a slot so that the captive follower produces radial motion with positive positioning without the need for a spring or other mechanism to keep the follower in contact with the control surface. A face cam of this type generally has only one slot for a follower on each face. In some applications, a single element, such as a gear, a barrel cam, or other rotating element with a flat face, may do duty as a face cam in addition to other purposes.
Face cams may provide repetitive motion with a groove that forms a closed curve, or may provide function generation with a stopped groove. Cams used for function generation may have grooves that require several revolutions to cover the complete function, and in this case, the function generally needs to be invertible so that the groove does not self intersect, and the function output value must differ enough at corresponding rotations that there is sufficient material separating the adjacent groove segments. A common form is the constant lead cam, where displacement of the follower is linear with rotation, such as the scroll plate in a scroll chuck. Non-invertible functions, which require the groove to self-intersect, can be implemented using special follower designs.
A variant of the face cam provides motion parallel to the axis of cam rotation. A common example is the traditional sash window lock, where the cam is mounted to the top of the lower sash, and the follower is the hook on the upper sash. In this application, the cam is used to provide mechanical advantage in forcing the window shut, and also provides a self-locking action, like some worm gears, due to friction.
Face cams may also be used to reference a single output to two inputs, typically where one input is rotation of the cam and the other is radial position of the follower. The output is parallel to the axis of the cam. These were once common is mechanical analog computation and special functions in control systems.
A face cam that implements three outputs for a single rotational input is the stereo phonograph, where a relatively constant lead groove guides the stylus and tone arm unit, acting as either a rocker-type (tone arm) or linear (linear tracking turntable) follower, and the stylus alone acting as the follower for two orthogonal outputs to representing the audio signals. These motions are in a plane radial to the rotation of the record and at angles of 45 degrees to the plane of the disk (normal to the groove faces). The position of the tone arm was used by some turntables as a control input, such as to turn the unit off or to load the next disk in a stack, but was ignored in simple units.
Heart Shaped Cam.
This type of cam, in the form of a symmetric heart symbol, is used to return a shaft holding the cam to a set position by pressure from a roller. They were used for example on early models of Post Office Master clocks to synchronise the clock time with Greenwich Mean Time when the activating follower was pressed onto the cam automatically via a signal from an accurate time source.
Snail drop Cam.
This type of cam was used for example in mechanical time keeping clocking-in clocks to drive the day advance mechanism at precisely midnight and consisted of a follower being raised over 24 hours by the cam in a spiral path which terminated at a sharp cut off at which the follower would drop down and activate the day advance. Where timing accuracy is required as in clocking-in clocks these were typically ingeniously arranged to have a roller cam follower to raise the drop weight for most of its journey to near its full height, and only for the last portion of its travel for the weight to be taken over and supported by a solid follower with a sharp edge. This ensured that the weight dropped at a precise moment and which delivered theaccurate timing. This was achieved by the use of two snail cams mounted coaxially with the roller initially resting on one cam and the final solid follower on the other but not in contact with its cam profile. Thus the roller cam was initially carried the weight, until at the final portion of the run the profile of the non-roller cam rose more than the other causing the solid follower to take the weight.
Linear cam.
A linear cam is one in which the cam element moves in a straight line rather than rotates. The cam element is often a plate or block, but may be any cross section. The key feature is that the input is a linear motion rather than rotational. The cam profile may be cut into one or more edges of a plate or block, may be one or more slots or grooves in the face of an element, or may even be a surface profile for a cam with more than one input. The development of a linear cam is similar to, but not identical to, that of a rotating cam.
A common example of a linear cam is a key for a pin tumbler lock. The pins act as the followers. This behavior is exemplified when the key is duplicated in a key duplication machine, where the original key acts as a control cam for cutting the new key.
History.
An early cam was built into Hellenistic water-driven automata from the 3rd century BC. Cams were later employed by Al-Jazari, who used them in his own automata. The cam and camshaft appeared in European mechanisms from the 14th century.

</doc>
<doc id="40287" url="http://en.wikipedia.org/wiki?curid=40287" title="William B. Ogden">
William B. Ogden

William Butler Ogden (June 15, 1805 – August 3, 1877) was the first Mayor of Chicago.
Life.
Ogden was born on June 15, 1805, in Walton, New York. When still a teenager, his father died and Ogden took over the family real estate business. He assisted Charles Butler, his brother-in-law, with business matters related to opening a new building for New York University, attending the law school for a brief period himself. He was a member of the New York State Assembly (Delaware Co.) in 1835. He married Marianna T. Arnot.
Ogden designed the first swing bridge over the Chicago River and donated the land for Rush Medical Center.
Ogden was a leading promoter and investor in the Illinois and Michigan Canal, then switched his loyalty to railroads. Throughout his later life, Ogden was heavily involved in the building of several railroads. "In 1847, Ogden announced a plan to build a railway out of Chicago, but no capital was forthcoming. Eastern investors were wary of Chicago's reputation for irrational boosterism, and Chicagoans did not want to divert traffic from their profitable canal works. So Ogden and his partner J. Young Scammon solicited subscriptions from the farmers and small businessmen whose land lay adjacent to the proposed rail. Farmer's wives used the money they earned from selling eggs to buy shares of stock on a monthly payment plan. By 1848, Ogden and Scammon had raised $350,000—enough to begin laying track. The Galena and Chicago Union Railroad was profitable from the start and eventually extended out to Wisconsin, bringing grain from the Great Plains into the city. As president of Union Pacific, Ogden extended the reach of Chicago's rail lines to the West coast."
In 1853, the Chicago Land Company, of which Ogden was a trustee, purchased land at a bend in the Chicago River and began to cut a channel, formally known as North Branch Canal, but also referred to as Ogden's Canal. The resulting island is now known as Goose Island.
Post-Chicago.
Later he served on the board of the Mississippi and Missouri Railroad and lobbied with many others for congressional approval and funding of the transcontinental railroad. After the 1862 Pacific Railroad Act, Ogden was named as the first president of the Union Pacific Railroad. Ogden was a good choice for the first president, but his railroad experience was most likely not the primary reason he was chosen; Ogden was a clever man who had many political connections. When Ogden came to lead the Union Pacific, the railroad wasn't fully funded and hadn't yet laid a single mile of track—the railroad existed largely on paper created by an act of Congress. As part of the 1862 Pacific Railroad Act, Congress named several existing railroad companies to complete portions of the project. Several key areas needed to link the East (Chicago) to the West had none, and hence the Union Pacific was formed by Congress. Ogden was a fierce supporter of the transcontinental railroad at a time of great unrest for the country and was quoted as saying
As history now shows, eventually Ogden and many others got their wish. Several railroads later, Ogden Flats, Utah, where the Golden Spike was driven, was named for him.
On October 8, 1871, Ogden lost most of his prized possessions in the Great Chicago Fire. He also owned a lumber company in Peshtigo, Wisconsin, which burned the same day.
In 1860, Ogden switched his loyalty to the Republican Party, which shared his views regarding slavery, although he left the party over a dispute with Abraham Lincoln. Ogden felt that the Emancipation Proclamation was premature. Following his defection from the Republican party, Ogden retired from politics and moved back to his native New York.
He named his home in the High Bridge area of the Bronx (now called Aqueduct Bridge over the Harlem River) Villa Boscobel. He died there Friday, August 3, 1877. The funeral was held August 6, 1877, with interment following at Woodlawn Cemetery, Bronx.
Namesakes of William B. Ogden include a stretch of U.S. Highway 34, called Ogden Avenue in Chicago and its suburbs, Ogden International School of Chicago, which is located on Walton Street in Chicago, and Ogden Slip, a man-made harbor near the mouth of the Chicago River. Ogden Avenue in The Bronx is also named after him.
Further reading.
</dl>

</doc>
